Good job! As for the next part, I thought you mind find interesting this [blog post from a minecraft developer](https://tomcc.github.io/2014/08/31/visibility-1.html) talking about "only rendering stuff that is actually going to be visible".
Sounds like a viable solution then, thanks.
we recently added [Rust support in beta on Clever Cloud](https://www.clever-cloud.com/doc/rust/rust/). This could be a good test to get the performance profile of Rust on our servers. You just need to **git push** your application to deploy it, and it will run directly if your app can start with **cargo run** (if not, there are other ways). What kind of load are you expecting? How do you want it to scale? More servers or bigger servers? We have an autoscaling feature, but since the traffic for the next 2 days will probably be unpredictable, I'd recommend that you monitor response time externally, and add or remove instances as needed.
To explain this further, new users' posts are automatically withheld by our Auto moderator, because new accounts are very often used by spammers. Unfortunately, new users get the same treatment. It may take a few hours until a mod sets things right – we're people with lives, too, after all. So rest assured that we're here for you and when in doubt ask us mods. Thank you.
Awesome
&lt;shamelessplug&gt; With respect to caching, I wrote [PLRU](https://docs.rs/plru/0.1.0/plru/), a very fast multithreaded caching algorithm. If you need a good implementation of a LRU-based cache replacement policy, I think PLRU is a pretty good candidate. &lt;/shamelessplug&gt;
You are right. However, I think what I said applies to both forms of authentication.
Link doesn't work on Firefox; seems to work on Chromium. In case anyone cares, here's the error log on Firefox: ReferenceError: require is not defined ReferenceError: Ember is not defined ReferenceError: require is not defined 
Works for me with Firefox 47.0.2 with uBlock and uMatrix (with a manual allow for scripts on cdn-business.discourse.org).
Now, *that's* synergy! :)
I think discourse is pretty terrible anyway, it takes ages to load a page on my phone. I wish there was a mobile version without all the JS.
&gt; Hitting the limits of Cargo for an embedded framework Welcome to the club! :highfive: First, I'd recommend you open an issue in the [rust-embedded/rfcs] repo or check the ones already there; you'll get more answers/discussion that way. [rust-embedded/rfcs]: https://github.com/rust-embedded/rfcs/issues As for the topic at hand. &gt; Mutually-exclusive Features Not 100% sure what this means? Are you talking about Cargo features? It seems that you want to use a single crate for different boards using Cargo features to pick the board. I can't tell you whether that's a good idea or not at this point. But, yeah, you'll probably run into the problem of multiple boards (Cargo features) being selected at the same time -- which doesn't make sense. There's also the problem that a board may not be the same architecture as another, so the user will have to select a different Cargo feature *and* pass a different target to `cargo`. Something like this: # One board has a ARMv7-M micro $ cargo build --target thumbv7m-none-eabi --feature teensy3_2 # The other board has a ARMv7E-M micro $ cargo build --target thumbv7em-none-eabihf --feature teensy3_3 # this leaves the door open to many bad combinations. Oops! $ cargo build --target thumbv7m-none-eabi --feature teensy3_3 IMO, Cargo features don't seem the right place, or rather don't seem enough, to encode the idea of different boards. Down that road, it seems that you'll end up requesting things like "let build scripts select the --target" which I don't think fit in with how Cargo works today. Custom targets (`*.json` files) feel more adequate for "board selection". `*.json` files already contain pretty much all the codegen options and have fine control over linker arguments. Although some `cfg` mechanism based on target name would have to be added for conditional compilation of library crates. Also, you don't want users to write those `*.json`s themselves or have to copy paste them from somewhere else. So perhaps we could have a centralized database of (versioned) `*.json` that some transparent Cargo wrapper (like Xargo) can pull on the fly? I've heard this idea before. Another approach could be a "scaffolding tool" that fills all that stuff that's always the same when you target a certain board: rustflags (codegen options), .cargo/config (linker args), etc. # embedded + Cargo = embargo # this crates a new Cargo project. `embargo` also fills the new project with # some other stuff $ embargo init --bin app --target teensy3_2 $ cd app $ cat .cargo/config [build] target = "thumbv7em-none-eabihf" [target.thumbv7em-none-eabihf] rustflags = [ "-C", "cpu=cortex-m7", "-C", "target-feature=-fp-only-sp", "-C", "link-arg=-Tlayout.ld" "-C", "link-arg=-nostartfiles" ] # NOTE the teensy3 crate has to generate the `layout.ld` linker script $ cargo add teensy3 --features teensy3_2 $ cargo build So, yeah, I don't have a solution for you. I do would recommend experimenting with Cargo subcommands or Cargo wrappers before trying to land any extra feature in Cargo. Then your Cargo RFC can just refer to that widely accepted "out of tree" solution and the tools team would be more likely to accept your RFC. &gt; Ability to specify codegen args in build scripts This sounds like a thing that would be hard to "sell" to the tools team :-). &gt; Right now if you want to retarget, you would need to copy the updated linker &gt; script into your application crate Not really. You can synthesize the linker script in a build script (or just copy one from a dependency) and then drop it somewhere in `OUT_DIR` then pass that `OUT_DIR` path to the linker search path (`-L`) and the linker will pick it up from that location. Check [this build script](https://github.com/japaric/f3/blob/master/build.rs) and its history. &gt; then change .cargo/config this part would still be needed because as you mention there's no way to pass linker flags to `rustc` via build scripts. &gt; a simple Makefile (or other script) that can turn the rust-generated ELF into &gt; a binary blob, and flash it do the device. You could replace this with a Cargo subcommand. EDIT: Argh, Reddit. y u no code fences?!
NICE
In both languages, the order of declaration defines the order of destruction (which is opposite to that of declaration). Therefore, if you write this: void foo() { vector&lt;* vector&lt;int&gt; &gt; a; vector&lt;int&gt; b; a.push_back(&amp;b); } (Or equivalent code in Rust.) The compiler will insert destructors like this: void foo() { vector&lt;* vector&lt;int&gt; &gt; a; vector&lt;int&gt; b; a.push_back(&amp;b); b.~vector&lt;int&gt;(); a.~vector&lt;* vector&lt;int&gt; &gt;(); } If vector used the pointer in it's destructor, then it would cause use-after-free error. C++ allows you to shoot yourself in the foot by writing this code. Rust finds it and wouldn't allow you to compile such thing.
Hmm - if you're hosting one in New York I'd definitely join you!
In case, like me, someone would also like to take a look at his thread, it's [this one](https://redd.it/5a5v3v/).
Here in the example `U8Ref` is a struct that holds a reference to another object, so the object being held may actually have a longer lifetime than the holder. See the [SO answer](http://stackoverflow.com/a/40451609/1184354) for a concrete example.
I fully understand this :) Just wander whether the classifier can be further improved with training data from real first-time users...
I recently discovered Windows does have a package manager, [Chocolatey](https://chocolatey.org/), and a [cURL package](https://chocolatey.org/packages/curl) containing a `libcurl.dll`.
To call another function in the same impl block you can use Self::num_series(slice). Without the Self:: or self. in the case of a function that takes self, it'll look for a free function.
Seems like a good start, however in Elm the update function is something like fn update(msg: Msg, model: Model) -&gt; (Model, Vec&lt;Cmd&gt;) With a list of Cmd you can dispatch commands to the platform, usually for things like making http request, creating a task... The simpler version fn update(msg: Msg, model: Model) -&gt; Model only works in, well, simple cases. In addition, a more complete implementation would need to provide common Cmds, a view library to render these models to something. The Elm architecture is awesome, huge props for trying to bring it to Rust.
You're certainly welcome. :) Just don't forget to pay it forward and help out folks who were in your same situation! Even if you don't consider yourself an expert in Rust, what you have learned so far may still be enough to enable you to teach others.
I had the same thought, but it just seemed very verbose. Now each shape has to have an impl block for each shape that it supports "intersects" with instead of it all being contained within the impl block of the Shape trait. It makes me wish there was a better solution to method overloading in Rust. 
This would not actually work. The way to calculate intersection is more efficient, albeit a little more complex, than looping over "all the points in a circle". Also my Shape trait already has those methods I just did not include it on the small sample code :p
Are you saying that you're doing Zelda modding with Rust‽ Please teach me your ways!
Grubby the Wc3, SC2, &amp; HotS player?
Thanks，actually I was trying to import Cmd to Rust, but it's not that easy, so I decide to let users handle async jobs, I am thinking about using future.rs for async task
This is a pretty neat looking platform! Awesome work. I'm afraid I already went ahead and invested the effort in deploying to AWS, but I'll take a look at your platform next time I deploy another Rust app. It's really cool to see something tailored to Rust in the ecosystem. 
We had an awesome time learning some Rust and taking a look at the Servo code base in our hackerspace. And since our little event got coverage on the last [TWIR](https://this-week-in-rust.org/blog/2016/11/01/this-week-in-rust-154/) I thought I'd share the summary here :) Special thanks to the Servo team for providing a list of easy issues to get started and being very responsive on the github issues and PRs.
Use methods to mutate fields instead of exposing the fields directly if you need additional behavior when they are mutated.
&gt; Rust will sacrifice some development speed I wonder whether this is true if you count debugging too, provided that you want (have to) deliver high-quality application (as few bugs as possible). Sure, Rust requires you to think more but does it make you less productive?
In this case, the 'classifier' is a very simple set of rules and a certain percentage of false positives is to be expected; that's why we have mods to deal with them. The problem with a 'sufficiently clever' classifier is that we'd probably start relying on it too much.
Nope. Sorry
embargo is a great name for it XD
Nah just the juice
Implicit property getters and setters are available in [JavaScript](http://stackoverflow.com/a/813332), [C#](https://msdn.microsoft.com/en-us/library/x9fsa0sw.aspx), and [Python](https://docs.python.org/3/library/functions.html#property), all of which are quite popular. The feature is a double-edged sword and certainly wouldn't make any sense in a systems language like Rust - but I don't know if I'd call it *puzzling*. It makes certain things easier.
**TL;DR: Either write getters and setters, or do [this](https://is.gd/1XWlCP) instead :)** As others have mentioned, Rust does not provide a way to override property assignment *directly* (a la [JavaScript](http://stackoverflow.com/a/813332), [C#](https://msdn.microsoft.com/en-us/library/x9fsa0sw.aspx), and [Python](https://docs.python.org/3/library/functions.html#property)). You could implement this by making your properties private, providing getters and setters, and coding the setters to modify some field (i.e. `self.dirty = true`). A better strategy might be to implement `Clone` and `PartialEq` and store a snapshot by calling `clone`. Instead of dirty checking, you can just compare the value to the snapshot directly (e.g. `foo == snapshot`). You can even add `#[derive(Clone, PartialEq)]` to your `struct` definition to get this without writing any code. I threw together [a quick Rust Playground example](https://is.gd/1XWlCP) to illustrate. Obviously, this isn't a catch-all for running arbitrary code when a value is changed; you'll need getters and setters for that. But if all you want to do is modify some flag, this will suffice, as you can just compare to the snapshot whenever you would normally access the flag. --- To provide a bit of rationale, Rust is first and foremost a low-level systems language. "Magical" things like implicit property getters/setters are generally avoided, because in the systems word, you generally want to have a fine level of control over *exactly* what your code is doing. Rust's philosophy is that you should only pay for what you need; hence, you can implement getters and setters without too much fuss, but they aren't baked into the language. That would affect *everyone* - even those who aren't using them!
Yeah I do. I can show you how to get everything up and running if you want. Add me on Skype I guess (cryze1992).
&gt; of boilerplate code, you can use this macro I just cooked up, though there is probably a better way: https://is.gd/KTwPg1. It's not so much boilerplate, than people will want to access fields instead of using getters/setters.
Yes and that is part of why I hate JavaScript. At least in C# static typing help to distinguish where side effects are possible.
I've found it quite useful as a building block in frameworks like Polymer, where you can update an attribute and have the DOM instantly reflect your changes. But yeah, *abusing* the feature is a slippery slope to awful spaghetti code.
That is true. It's just that writing this sort of code (setters and getters) is probably one of the most boring parts of software development in my eyes, and I know a bunch of people who think likewise. That's why I added the macro.
Hey, if you are trying to build a board support package for the teensy, check out my crate [teensy3-rs](https://github.com/jamesmunns/teensy3-rs). I'd gladly welcome pull request if you find a great way to make things generic across different teensy versions!
:-) Someone mentioned this name in the #rust-embedded IRC channel but I can't remember who now. Still, credits go to them not me.
&gt; Is there a Rust/Cargo issue for that? Not that I know of. In general, I *dislike* the idea of conditional compilation based on target *name* because you can create two custom targets with the exact same name but totally different specifications. However, I reckon that the whole target specification won't be enough in this case (targetting "boards"). &gt; Are there any concrete plans for this database? None yet. Opening an issue in rust-embedded/rfcs would be great way to start working on this (get feedback, get the people with the right skillset on board, etc.)
That should be easier if/when Hyper starts using [rust-native-tls](https://github.com/sfackler/rust-native-tls)
Thanks for the feedback! We definitely have a chapter planned for explaining composition over inheritance and design patterns to use instead of OOP patterns in Rust. [I'm gathering some links on this issue](https://github.com/rust-lang/book/issues/109) (it's closed, but that's just because we decided where that chapter is going, the chapter isn't actually written yet).
Right. The impl can be qualified. Totally forgot about that. Thank you.
You shouldn't, its a bug that its allowed right now :(
That's only true for some of the stuff in /mnt/c/. The rest of the Linux filesystem (like ~/.ssh) follow the basic Linux permissions model. Full disclosure: I'm in the middle of migrating to Windows 10.
I have never really used HKT in the past and it was a bit struggling to follow exactly what is happening in part1&amp;2 with this "family type" thing. I get what is happening but i find it hard to wrap my head around it and my thinking process slows down substantial. Part3 and the "real" HKT &lt;the part from&gt; "Supporting families directly in the language via HKT" feels like its just a natural advancement and it immediately "clicks". I don't know if its just me, but if i where to learn HKT from the beginning without reading anything else, this part and syntax was super easy to understand where i need a few moments to track my thoughts on whats happening with "family types". ... and i don't like "Higher-kinded self types" either :P just to give a feedback from someone mostly unfamiliar with HKT 
I'm not sure about how the docs get generated, to be honest. I was just thinking about how the code works.
Basically, what I mean, is that the C++ templates allow two different type of arguments broadly: type and non-type template parameters (and some extra variation for these, and packs and autos, but that's some fancy stuff, which is not relevant here). In C++ you can create a generic vector like this: template&lt; typename BaseType, int Dimension &gt; struct generic_vector { typedef generic_vector&lt; BaseType, Dimension &gt; Self; typedef BaseType base_type; static const int dimension = Dimension; base_type elems_[ dimension ]; }; typedef generic_vector&lt; float, 3 &gt; vec3f; static_assert( vec3f::dimension == 3 ); typedef generic_vector&lt; int, 2 &gt; vec3i; static_assert( vec3i::dimension == 2 ); So in this case I used a non-type argument, int that is (there are some limitations here, float can not be a template argument, nor a string) to define this type. I haven't seen anything like this in Rust, The struct Something&lt;T&gt;... statements assumes that T is a type. Riiiiight? Not sure though, I'm a new comer to Rust.
Also, they have the umask set to 0000 by default for some reason. Run `umask 0002` to fix it.
HKTs seem a lot simpler to understand (to me).
I'm going to come at this post from a Haskell perspective, since the author is clearly familiar with the ideas from Haskell. fn floatify_hkt&lt;I&lt;_&gt;&gt;(ints: &amp;I&lt;i32&gt;) -&gt; I&lt;f32&gt; // ^^^^ the notation `I&lt;_&gt;` signals that `I` is // not a complete type // added, I'm assuming it was omitted from the post where I : HkCollection What's the kind of _? In another situation, do I need to specify `I&lt;_&lt;_&gt;&gt;` or is _ kind-polymorphic? &gt; For example, is there any treatment of higher-kinded types that adds the ability to constrain parameters in some way? There are two recent additions to Haskell that are somewhat aimed at this problem. First, there is a new constraint representing type equality (I think Rust has this already? `where I=int32`?) The second is a new kind that represents constraints (in Rust, these are things like the `where I : HkCollection` above). This means that types and traits can be polymorphic over constraints, and those constraints can be instantiated as required. For example (pardon the horrible made-up syntax here) trait Collection&lt;Item&gt; { fn empty&lt;T&gt; -&gt; Self; fn add&lt;T&gt;(self: &amp;mut Self, value: T); }; trait CollectionFamily&lt; where&lt;_&gt; C &gt; for Self&lt;_&gt; { type Family&lt;T&gt; : Collection&lt;T&gt; where&lt;T&gt; C; // add the constraint to this type definition }; // polymorphic implementation impl&lt;T&gt; Collection&lt;T&gt; for List&lt;T&gt; { fn empty&lt;T&gt;() { return List::new(); } ... }; impl CollectionFamily&lt;where&lt;T&gt; ()&gt; for List { type Family&lt;T&gt; = List&lt;T&gt;; } // BitSet is a collection where the only member type is bool struct BitSetFamily&lt;T&gt; {}; struct BitSet { ... }; impl Collection&lt;bool&gt; for BitSet { ... }; impl CollectionFamily&lt;where&lt;T&gt; T = bool&gt; for BitSetFamily { type Family&lt;T&gt; = BitSet where T=bool; }; There's probably a more elegant way to do this; requiring the collection type to be higher-kinded is certainly ugly. But hopefully this gets the idea of Constraint Kinds across. In addition, this would probably be cleaner if the constraint was an associated type instead of a parameter to CollectionFamily.
Works here -- right now http://portier.io just redirects to our GitHub pages, so maybe try that? https://portier.github.io/
Any idea when we'll be able to use ATC in nightly? I paused working on dbkit because I ended up in a place where each of Cursor operation implementation internally might have different lifetime rules. I couldn't make Cursor trait and then operations on it that would work in all cases. So I gave up for now.
As far as I know, the RFC hasn't been accepted (yet). In some cases an implementation has preceded the RFC being accepted, like with `impl Trait`, but even in that case I think the implementation PR wasn't merged until after the RFC was merged.
Same for me. I really like this blog post series :)
Not just qualified, but arbitrary use of the type parameters. Type parameters are introduced after `impl` and used in the type: `impl&lt;I&gt; HasFoo&lt;I, Vec&lt;I&gt;&gt; { }` `impl&lt;X, Y, Z&gt; HasFoo&lt;i32, (X, Y, Z)&gt;`
In the [linked example](https://is.gd/Cn6iAN), what do we currently do with Box syntax? I.e. how would one implement this uses `Box`? My understanding is that currently we can implement everything `impl Trait` does with `Box`, but that it'll be on the heap instead of the stack.
I understand the desire to use type matching instead of `action.type` string matching, but wouldn't that make interoperability with web applications written in redux.js more difficult? Is it even a goal for this project to be interoperable?
Count me in :-)
Now to install Rust instead of just downloading Rust I have to download a package manager too. Yeay! *Surely* you can see that that is a horrible solution?
&gt; Isn't it "Linux Subsystem for Windows"? Well, it's not my wording, that's what Microsoft is calling the feature. &gt; Also, any particular reason to not just use Linux? That's like asking Wine users "any particular reason to not just use Windows". I would think the answer is obvious.
It's unclear whether ATC will ever make it in Rust. The problem is that it's unclear whether ATC is (a) sufficient and/or (b) limiting. This serie of blog posts is about exploring the space design, because to make an *informed* decision on whether ATC is a good step forward for Rust, one must first inform oneself. Therefore, Niko is looking at the design of HKTs in other languages, exploring the adaptations in Rust, seeing what's working and what's not, attempting to divine the limitations and work-around of each pieces, ... that's quite the herculean task!
Yes, it seems to be that issue. I'm having some trouble understanding the full discussion, though. I have the feeling that the problem I'm referring to is a very specific case of "non-supertrait bounds are not propagated", in particular *equality* bounds on associated types are not propagated. Maybe this more specific problem has a simpler solution?
Hm, it seems like there's a bit more indirection here than I'd expect. In particular, I'd have expected something more along the lines of: trait Reducer: Default + Clone { type Action; fn reduce(&amp;mut self, action: Self::Action) -&gt; &amp;mut Self; } or perhaps trait Reducer: Default + Clone { type Action; type Error; fn reduce(&amp;mut self, action: Self::Action) -&gt; Result&lt;&amp;mut Self, Self::Error&gt;; } This would allow eliminating the `Item` type entirely, allows the caller to avoid clones unless necessary, eliminates `init` in favor of the standard `Default` trait, and (in the latter case) permits propagating errors. In addition, [making `!` a type was accepted](https://github.com/rust-lang/rfcs/blob/master/text/1216-bang-type.md), and so once that's stable users could instantiate `Error` with `!` if their reducer cannot fail. Note the use of `&amp;mut self` - `&amp;self` would require the user clone the state on every invocation, and `self` would either require a `(Self, Self::Error)` tuple on the `Err` side of `Result` to avoid losing all state, or the caller doing pre-emptive cloning on every invocation. In Javascript, where heap allocation happens all the time and copies are GC'd references, that would be fine - but in Rust, that could be a severe performance hole. EDIT: In addition, you can define the latter as `TryReducer`/`try_reduce`, and implement `TryReducer` for `T: Reducer` pretty trivially - that could offer the best of both worlds. (Stealing the naming from `From` vs. `TryFrom`) This also opens up further options, like implementations of `FromIterator` and `Extend` that take an iterator of `Action` values, and feed them in (calling `Default::default` first, in the `FromIterator` case).
Everybody is indeed welcome! Maybe this is a good opportunity to dive into the language
Currently incredibly busy with exams but I'd love to be surrounded by people actively using the language. Might indeed be the last needed push to dive in.
Thanks so much! So, in this world, I would `impl Reducer` on my state object? Is that right?
One of the design constraints of redux.js is the immutability of the store, which allows for some neat tricks, like time travel and undo and such... Any thoughts on that?
Yea, they should be totally possible to do with this library as well [= One of the motivators of taking this approach was trying to coral data changes in my roguelike. A user inputs a command, it moves an actor, which needs to update graphics and an internal representation of the map. Tracking ownership of all this data was getting hard, and tracking down where it could change was harder. This makes it more clean in my mind.
Rust is pretty strongly in favor of not hiding places where code might be run. So no implicit copy/move constructors, no properties, and no life-before-main.
The third case won't stack overflow, but would be impossible to construct. In order to make `A`, you'd need a `Box` pointer to `A`; but in order to construct *that* `A`, you'd need another pointer to `A`; *ad infinitum*. (And you won't be able to make it a circular reference, i.e. pointer to self, because of memory ownership rules.)
Same here! Are you studying at UU as well? I know a couple of students who are big fans of Rust and are planning to come to the meetup as well.
Well, sure. *Maybe* you could get away with `Rc&lt;RefCell&lt;T&gt;&gt;`, but I don't know off the top of my head.
I'd be very interested! What is the time frame you're thinking of and in what form do you envision the meetup? :)
Well to add context, this is for type annotations so it actually is like: pub enum Type { Int, Ptr(Box&lt;Type&gt;), } Type::Ptr(Box::new(Type::Int)) Seems to work fine.
Maybe! What have you found? Edit: read through these. I'm particularly fond of [this one](https://github.com/rust-lang/rust/issues/31567). Leaking `&amp;mut` references! Pretty awesome.
Any examples?
I haven't had a chance to read through these posts, but in all the discussion I had with niko/aaron/woboats, it seemed pretty clear that ATC was sufficient to do collection traits ergonomically, which was the motivating use case. Did they find something to the contrary?
That sounds very interesting. Count me in. 
I'm trying to reconcile this approach with Redux's goal of having "pure reducers" which create no side-effects (they create a completely brand new state on ever reduce). I gave it a try [here](https://github.com/jaredonline/redux-rs/pull/4/files) and struggled with the `Result&lt;&amp;mut Self, Self::Error&gt;` 'cause the reference to `Self` didn't live long enough. I'd be curious to hear more of your thoughts though. Edit: Got the `Result&lt;&amp;mut Self, Self::Error&gt;` to work, was just returning from the wrong place [=
And a totally unofficial [rados_hi](https://crates.io/crates/rados_hi), which is a wrapper over the Official Ceph Rust Interface that ships [some of] the [RADOS](http://ceph.com/dev-notes/the-rados-distributed-object-store/) AIO operations as [futures](https://crates.io/crates/futures).
For me the big advantage of fibers over futures was that fibers compose more naturally, e.g. let result = start_async_task().await(); // Do something with `result`. Seems more natural to me than start_async_task() .then(|result| { // Do something with `result`. });
One of the things I'm most excited about in Rust and linux land. If everything works out we could start getting more security provided by Rust and a lot of interfacing with other languages thanks to the GIR. Replacing the lower parts like gstreamer with bits of rust seems something so sweet :3. And the boost of incoming developers to both rust and gnome would be great (I'm expecting it, because I know many people (including me) that prefer not touching something as hard as C when we have not idea what we are actually doing without any help from the language :/ )
This seems very useful.
One thing I'd suggest reading is [this post on formally verifying Rust's binary search implementation](https://kha.github.io/2016/07/22/formally-verifying-rusts-binary-search.html) - a key insight is that `fn foo(&amp;mut self); foo(&amp;mut x)` is equivalent to `fn foo(self) -&gt; Self; let x = foo(x)` As that latter one is honestly the single most common manner in which a reducer is applied, it makes sense to optimize for it. In addition, that immutability is only observable if you retain the old value - in Redux, that's done simply by retaining a reference, and hoping the reducer follows the rules (as Javascript does not enforce them). Meanwhile, in Rust, it's much cheaper to update in-place than to make a copy. Thus, it pays off to make in-place modification the default for the common case, and then use `Clone` to provide much stronger (and more costly) immutability guarantees when it's actually needed. The borrow checker, then, keeps us honest. The end result is the same: If you retain the old state, Rust's type system enforces that it is immutable (by mandating a call to `clone` lest you run afoul of the borrow checker). However, the common case gets faster. It's sort of a "Schrödinger's cat" optimization: If you don't look inside the box, the state is both mutable and immutable. However, once you open it (by retaining the old state), you force it to collapse into "the state I have retained is immutable."
I went through the exact same frustrations when i tried to use Iron. Ironically, this blog post is now a very valuable piece of documentation to get started with Iron.
&gt; higher-kinded types 5Bthat vim?
Using `unsafe` is too easy! Let's think of other ways. I know you can use `std::mem::forget` to freely leak memory, for example. You may be able to do the same thing by creating circular references with `Rc&lt;RefCell&lt;T&gt;&gt;`. Hardly undefined behavior, but definitely bad memory management :)
We've been on it since 2 minutes after it expired. Hopefully it will be resolved soon. Sorry about that!
Exactly. That's why I asked cause it's too easy to make these kinds of errors with C. Heheh.
*Noooo, all my CI builds are failing!* Good to hear you guys are working on it.
THATS THE JOKE!
Im getting crates.io is down: http://www.isitdownrightnow.com/crates.io.html
Wow, I feel like I've learned more about Iron than reading the docs. Yikes. Bookmarking.
[removed]
Well, we can wait for it. cargo build Downloading modbus v0.4.2 warning: spurious network error (2 tries remaining): [7] Couldn't connect to server warning: spurious network error (1 tries remaining): [7] Couldn't connect to server error: unable to get packages from source
HTTP is not HTML.
There's a lot of good information here, but I did *not* enjoy the presentation. I know it can be cathartic to write things like this, but jeez. In general, I think the author's frustrations come from the fact that the things they want - that they take for granted in the frameworks they are used to using - *do not exist yet*. They seem to anticipate that iron doesn't have these features as an intentional design choice (there are several references to 'how web apps are written these days' and such), but its just that no one has written the layer of conveniences that to them seem natural. The awesome abstractions django or rails or w/e gives you are not easy to write.
IIRC, there was a *huge* pre-1.0 debate about whether `std::mem::forget` should be marked `unsafe`. The decision they made was that `unsafe` in Rust has a very specific meaning (potentially accessing bad memory or triggering UB), and `forget` doesn't fall under that umbrella; ergo, it shouldn't be marked `unsafe`. Not sure if I agree, but it's a moot point now :) And I did manage to create a cycle with `Rc` and `RefCell`: https://is.gd/Z8cMjB Notice only `c` actually gets dropped. That was... disturbingly easy.
The author is not whining about some crazy feature missing, like an ORM. Considering how old the project is, I would think it's a design choice from iron to externalize the router and the static file handler. 
You should write another blog post about having a state in iron (like a db). That one is a tough nut too. 
A lot of valid gripes. However... impl&lt;'a&gt; Modifier&lt;Response&gt; for &amp;'a str impl Modifier&lt;Response&gt; for Status impl Modifier&lt;Response&gt; for Vec&lt;u8&gt; ... &gt;This is really just regular-ass dynamic dispatch, except backwards, so it’s the variant type that determines what the hell is going on, not the type being affected. So we can rewrite the above code as The resulting code will actually use static dispatch, and it's the type implementing `Modifier` that determines what is actually going on. Just looking at it, my guess is that `str` and `Vec&lt;u8&gt;` impls modify the response body, and `Status` impl will modify the response status. The tuple implementations are pretty clever too. You should be able to rewrite your example as follows: let mut r = Response::with((status::Ok, rendered_markdown)); Ok(r) It's almost too clever, to the point where it's not at all intuitive. But it's also a testament to the really neat abstractions rust is capable of. 
This looks cool, does it work on Windows? 
Oh, yeah. Because syntax documentation shouldn't be expected, we just take it for granted since we were spoiled by all those other frameworks!
Thanks for the link! That was super helpful, and for your clear explanation =D I've made a bunch of the edits you suggested [=
I love rants like this, but I lost it at RequestProcessor. In fact, we should implement a KernelProcessor into a BrowserProcessor. Processing the Process Process.
YAS
Abuse early returns as much as possible. By combining the `try!` macro and the [`map_err`](https://doc.rust-lang.org/stable/std/result/enum.Result.html#method.map_err) function, you can quit early if either of those results you're matching on returns an `Err` variant. I also like putting things in a functional style, so replacing let mut result = Vec::new(); for row in rows.iter() { result.push(something(row)); } with let result = rows.iter().map(|row| something(row)).collect();
Reminds me of vertx. Vertx defines a host of handlers. 
There are two types of companies; those that have had certificate problems and those who will have certificate problems.
Something I thought was interesting was the suggestion of subclass objects in Rust leveraged by OS apps in a way that allows other languages to be used on top of these services. However, its suggested that gtk-rs isn't ideal at this yet. I am wondering what sort of shortfalls the Rust gtk implementation is currently facing since it wasn't outlined specifically.
&gt; skittleware Lol
I enjoy this level of transparency, specially attributing exact steps and their respective roadblocks. &gt; We had made this an automated process in order to not have these kinds of issues crop up, but it obviously failed in this case. It's possible that switching providers can help here. I like the level of automation of Let's Encrypt. You don't get an e-mail of renewal, you simply have a server periodically generating new certificates. --- As an aside, in terms of cost, is Heroku the right choice for a high traffic site like crates.io? Do Rust receive some kind of discount for being a high profile open source project?
Ha IRONically. nicely done :-)
Maintainer here: That's because it needs patches that haven't been released in the crate. (I provided several of those) So we need to pull the git version.
Man, thank you so much for explaining all of this, let alone taking the time to read through my profane ramblings. I'm legitimately happy to hear that all of this wackiness has a reason, and half of it is just a case of me cutting myself on too-sharp tools. I sort of got the feeling that might be the case, and I'm glad it all makes sense to someone! ...so can you explain how an `AroundMiddleware` is different from a Handler that is just constructed from another Handler?
Yeah, dynamic is the wrong word. I'm just too sleepy to think of the right way of phrasing it, and at the time I was frothing a bit so perhaps not the most precise in my use of terminology. It's just that, in this case, those abstractions aren't explained anywhere and don't follow any remotely common patterns. ...but seriously. Literally right below the part you quoted I have an example showing how the type implementing `Modifier` determine what's going on. and right above that is `Ok(Response::with((status::Ok, rendered_markdown)))`.
NO
I honestly do not see the benefits of this abstraction compared to something like `res.body = foo;` or a setter. Or the mentioned builder pattern if you like it functional and immutable. When having a look at the out-of-the-box [supported modifiers](https://github.com/iron/iron/blob/master/src/modifiers.rs) they are rarely more complex than changing a single state. The modifier for file content is doing a bit more but nothing that couldn't be provided as a simple a function, or the responsibility for it could have been handed to the library user. It's much like any other error handling common in Rust, nothing magical. Is there maybe a non-trivial example to convince me otherwise?
You're being downvoted because you're being a jerk, but you're also not entirely wrong. I'm not going to hate on the Iron devs; I've done enough hating for one day, and documenting ain't easy. But I am forced to observe that in one day, starting from less than zero, I have written more about how Iron actually works than anyone else has, ever. At least as far as I can tell. The flip side of the coin is that I *was* supposed to be doing other things today, and rather wish I had...
&gt; except any sane explanation of how to put these things together. Right, or more importantly, an _easy_ way to put these together. That's what I think is missing in the iron framework - iron sits below all of these components, so that they can coordinate, but they can easily be replaced. What I got from your blog post is that what you really want is something that sits above them - something that makes using them fluid and finding them discoverable.
&gt;Anyone who’s done cross-platform development on Windows knows that getting things to compile can be a huge pain in the ass. This statement is totally misleading because WSL does not solve this problem at all. WSL is great for Windows users who want to test their code on Linux without setting up a separate machine or using a virtual machine or dual booting. WSL is downright terrible for Linux users who want to test their code on Windows, because WSL is not Windows! If you compile your code in WSL, you end up with Linux binaries. Thus, as you can clearly see, WSL does not solve the problem of compiling and testing your code on Windows.
&gt; Buy me enough alcohol to make me think it's a good idea to delve into this junk again and I'll spend a weekend documenting Iron for you How much alcohol are we talking about? I'm willing to contribute something if your offer is actually serious :).
I wrote IcoGrid quite awhile ago. The reason I wrote it was because I thought Eskil Steenberg's game Love [1] was pretty interesting, but it seemed less than ideal that stretching a square grid "cube" onto a sphere results in grid cells that come out rather squashed near the corners, and it seemed like a hex grid icosahedron would be better. It seemed like an interesting challenge, so I went ahead and threw together an implementation. Writing IcoGrid was sufficiently exhausting that I didn't do anything with it for a year or two, and then I started playing with crude environmental simulations, based on simple rules. I made liberal use of the random number generator, so it wasn't exactly the same as Conway's game of life, but it was a fun project. Without much complexity, I was starting to get emergent behavior that I hadn't expected. (My simulation obeys conservation of matter, so when trees burn their stored water goes out into the atmosphere, and then it rains. I remarked on the peculiarity of this to one of my coworkers at the time, and he replied that that's a phenomenon that happens with real life forest fires.) Then I got distracted by a ray-tracer I've been working on. I haven't seen your cellular automata before now, but that's pretty cool. [1] http://www.quelsolaar.com/love/index.html
The fun thing is you either get it right the first time and it's great, or you get banned for a week and use that time to set up a bunch of pre-LE style infrastructure that you never tear down.
I would like to present my last crate: **office**, an excel file reader in rust. I am working in this kind of company where most user data is an excel file that we need to process. I couldn't find a Rust library which could read all type of files (xls, xlsx and xlsb) so I decided to write my own. This is a very alpha stage but I've just reached the point where it understands all excel files. I'd love having some feedback from the community. **EDIT:** The name was obviously a bad choice. I'll change it tomorrow once I find a good candidate. **EDIT 2:** office crate has now been migrated to [**calamine**](https://crates.io/crates/calamine). Thanks everyone for the renaming brainstorming. I have yanked the *office* crate. If anyone wants the name let me know!
Awesome project! Is this backed by mio? If not, might it be in the future? How does it fit in with the Futures stuff that is on the horizon?
For what it's worth, *I* enjoyed it. The Rust community tends to be correct and polite, which 95% of the time works really well. However, 5% of the time it may cause one to think that the problem is inside one's own head when it is in fact external. A brave rant from somebody who has been having the same problems can make that feeling vanish... perhaps even work as motivation to write a better library.
The other half of the argument is that there are (and probably always will be) other ways to create memory leaks in safe code. So having forget() be safe is kind of a reminder that you can't rely on other people's code calling your destructors.
How do you do network/file io without blocking other actors?
Love your article. I just read the first lines and can really understand that frustation. Even better yet, you did turn it into a valuable document that is fun to read and yet teaches people how to write software. You should do that more often!
Indeed! I think it also sets a precedent that `unsafe` means "unchecked memory access or potential UB", and not "this could backfire if used incorrectly," which are very different concepts.
Actors should not wait. I added the external notification feature for integration with an external event loop. The idea is that a MIO or select()/kqueue()/etc. loop would wait and tell the scheduler if something happened. While one actor does the write()/read()/anything, the other actors can only run if there are more than 1 threads started.
All of it :-)
With my custom framework, doing some HTTP basic auth is as simple as that, which is a flat structure: https://is.gd/ZFHiL9 Using sessions is a bit more middleware-looking: https://play.rust-lang.org/?gist=1ce1a88d24ab894dd4179b69e9cd7837&amp;version=stable&amp;backtrace=0 (had to make a gist because the shorten button wouldn't work by the way) Obviously you're going to argue that it's exactly a middleware. But I'd argue that it's not because it has none of the disadvantages of middlewares: it's much less confusing as it uses only closures which everyone is familiar with, the order of execution is clearly readable, there's no risk of typo, everything is strongly-typed, and so on. Sorry if my answer here is not very satisfactory because I'm a bit tired of repeating my arguments all this. It's not the first time I rant about middlewares and it's not the last. In fact I try to avoid debating this and so my own things in my corner, but with a top comment with 44 upvotes I thought that I had to say something. 
Thanks! Beware that this is really alpha stage. It may break all lot if your file is not *simple*
This is logical : there is only one owner to the Request (hence the '&amp;'). The mutable specifier is there because you can pre-process data and make some changes (such as adding headers to the request, that you can use in the next middlewares).
Well the erlang way is to block the actor behind the scenes and provide an easy socket/file interface. This is a real killer feature of it as it makes writing servers really easy.
I'd like to add that from my experience many people who tried Iron and Nickel (or any other middlewares-using library in Rust) tend to agree with the kind of criticism that are in the blogpost, and people who argue in favor of middlewares often didn't try them. I think that even the authors of Iron and Nickel are not *that* in favor of middlewares, they chose to use them because they're the de facto design for webdev frameworks nowadays (and you can't blame them for that). That doesn't make your arguments invalid, but I hope that you and the people who upvoted you actually made their own opinion by actually trying these frameworks. 
I think I understand your reasoning. "Traditional" middleware is agnostic about its execution time, so it's very easy to misplace them and introduce bugs(especially with long middleware chains)? You should write a blog post about your argumentation(maybe you did already?), then you could post that instead of spending your time repeating yourself over and over again.
Hey, cool initiative! As a web developer starting out with rust, i'd love to meet with some more advanced rustaceans. I signed up to the meetup!
I agree the name is very broad. I wanted to parse other files as well (some logic is shared). I just focused on excel for the moment as they are the most useful for now.
Awesome I hope you get around to doing that.
Again the intention was not to *steal* the name. I can definitely rename it (I don't know how to tell crates.io that someone else will take it). Very sorry for that.
Unfortunately, it's not a very discoverable way to do things. You have to go to the docs and see what implements `Modifier`. That doesn't work well across crates (Iron's docs don't know about other crates), and it's not something you can tab-complete, so if you're using Rust in an IDE it's inconvenient.
Ownership in Rust is most certainly not expressed as a mutable reference. 
Thanks for the follow up, it turns out I don't have a choice: the crates I wanted to develop independently and then merge into one bigger crate turned out to be not-so-independent. And since you can't have circular crate deps (you can have circular module deps) it forces me to have them all in one crate anyway 'solving' the problem.
It's the same thing, but again, making it a trait allows you to use structs. (This reasoning is similar to why you don't just register callback functions instead of After and BeforeMiddleware). There should be a included impl for functions just like there's for Handler though.
That's alright, I mean you can take w/e name you want, you're doing exactly what Rust wants you to do =p About crates.io, they very much like their "everything is permanent" to avoid breaking hypothetical dependencies. I believe the only strategy for releasing a name is a manual hand-over if someone asks and that new person can then only push new versions with a higher semantic version.
Of course we do, unless you're going to intersperse your writing with snark about Iron's design. Because we have a bugtracker for that.
&gt;About crates.io, they very much like their "everything is permanent" to avoid breaking hypothetical dependencies. Christ that's nasty. crates.io should have an 'unstable' flag that turns off these restrictions but restricts your crate to being used only in nightly and beta rust and not in stable.
You really shouldn't call this office. That heavily implies it's an official Microsoft product. 
My apologies for my poor explanation : what I meant is that Iron owns the request, and for each middleware it will give a mutable reference to it. This way you have only one structure in-memory. (IMHO) the mutable reference is due to the fact that there is no simple "inter-middleware" communication style for a single request.
A very common use case to have middleware that enriches the request. For example if you are on a URI `user/1234` you can provide a `User` struct that corresponds to the user ID. Then you can use `User` in the controller.
&gt; is Heroku the right choice for a high traffic site like crates.io? Remember, the crates themselves are stored on s3, and the index on github. Heroku would only handle the backend stuff for when you're using the website itself.
It's a security issue; if you depended on a crate, but what's in the crate is mutable, the new owners could release a new version with malicous code and you'd get owned.
If anyone has a good idea, please [tell me!](https://github.com/tafia/office/issues/41)
&gt;I was expecting something like Django or Flask, where you define routes that match a particular URL pattern, and then functions that are called when a request hits those routes. Flask gives me that instantly. How the flying fuck do you do that in Iron? Ah, but this is GREAT WEB STUFF, so obviously you can’t have anything that simple. You need more layers of indirection in the mix, young padawan! With Python, you can just put a decorator above a function to make it a route and you get a function which gets arguments from the URL and you're done. But the shit that happens behind the scenes is trickier than that. It can inspect the function signature and see how many parameters there are, whether there's keyword arguments, and do a hell of a lot more. Python makes it very easy to do crazy shit. Functions can take variable number of arguments, they can take arbitrary keywords in kwargs, they're dynamically typed... It allows some crazy stuff, like an easy flask route API. It might look easy because you just drop `@app.route('/foo/&lt;bar&gt;')` and get yourself a foobar route, but that doesn't mean the functionality is simple or obvious. Python has tons and tons of metaprogramming potential with very little syntax, and even function signatures are flexible. In Rust, you're going to be stuck with creating a Router object, calling some gets and posts on it to create routes, then wrapping the router with Chain::new(router), etc. That's just what a lot of statically typed languages are forced to look like at a certain point. You have a function which expects some number of bytes as arguments, a 64 bit pointer to a string and a 32-bit unsigned int, and that's what it always gets. It doesn't sometimes take **kwargs with arbitrary magic. Rust has tons of metaprogramming, but it's still statically typed and it has to know some specifics about what arguments get passed in functions. Rust for web dev works, but that's just because Rust is a bad ass and expressive language. That's not its strong suit, it can just do it because Rust can do pretty much anything. You're still going to be stuck with the tediousness of a typed language, but the fact that a language that has a lot of the same use cases as C can be pretty easily used for web dev is a statement in itself I think.
&gt; I'll change it tomorrow once I find a good candidate. Excellerator? :D
What's in a crate is mutable anyway, because you can release a new version. Anyway, my point was specifically that 'unstable' (or whatever name you want to give them: something obviously bad like 'completely-insecure' or 'fucked-up' if you really want to) crates would obviously not be expected to be secure.
&gt; What's in a crate is mutable anyway, because you can release a new version. We have very different definitions of "mutable", then.
Yes.
&gt; Good job completely ignoring the second half of my post. I don't have anything in particular to say about it.
To be fair, an evil author could release a new version with malicious code and only bump the patch version number. Any place where dependencies are not locked (such as testing a library on CI) would get owned. That is orthogonal to who owns the crate or a hypothetical “unstable” label being attached to it. When you say “what's in the crate is mutable”, do you mean being able to publish new code under the same version number? I agree that would be bad, not only from a security perspective, simply from a reproducible builds perspective too.
I can spring for a pallet if needed!
The simplest way to explain how floating point storage works at the hardware level is to say that each floating-point variable is a fill-in-the-blanks [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation) form with a fixed number of spaces for digits... ⎕⎕⎕⎕⎕⎕⎕⎕ x 10^⎕⎕ ...except that computers use binary rather than decimal, so each box in the "form" is a bit. This has two consequences: 1. Numbers which don't have 2 as a factor cannot be cleanly represented in base 2, so they have to be rounded. (Similar to how 1/3 can be cleanly represented in base 3, but it's a repeating decimal in base 10 because 3 is not a factor of 10. This property is one of the reasons people argue that, if we could get people to do it, we'd be better off using base 12.) Languages often hide this error by truncating the result though. For example, depending your Python setup, `1.0 / 10` will output either `0.1` as you'd expect or the actual under-the-hood value`0.10000000000000001` which results from truncating the repeating fractional value in the binary representation. 2. When your number gets very large or small, the most significant N digits are preserved and the remaining digits on the least-significant end are discarded. In day-to-day math, this isn't an issue and there are specialized libraries for situations where you really do need the *exact* answer and are willing to sacrifice speed to get it. (It's called [arbitrary-precision arithmetic](https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic) and Wikipedia says it's also referred to as bignum arithmetic, multiple precision arithmetic, or infinite-precision arithmetic.)
This is so cool. I haven't had time to read through all of it yet, but this is my favorite so far: https://github.com/graydon/rust-prehistory/blob/master/doc/notes/module-system.txt
https://github.com/rust-lang/rfcs/issues/1151
You're right of course as greed implies intent to be greedy (which isn't the case), but I couldn't think of a better description (my native language isn't English). Here's Rust's official stance: https://internals.rust-lang.org/t/crates-io-package-policies/1041 &gt; When we looked at package ecosystems without namespacing, we found that people tended to go with more creative names (like nokogiri instead of "tenderlove's libxml2"). Only works if people actually do get creative, but not everyone (including myself) is fond of this.
I'm guessing this might not make sense if you haven't done much web hacking before. Say your web app needs to know a bit about the geographical location of requests. Perhaps to choose a default language or currency, or ban access based on country. A request comes in, so you look up the IP address with your geoip API. It gives you back a structure with country, region, city, etc. Now, you might send back an error immediately after the lookup if the request is from a banned country, but for everything else… where do you hang the data so that it's accessible to other parts of your application? The Request structure is the only thing that is passed around, at least until you start passing a Response structure back the other way. That's why it's mutable: On the way through your app, you need to add to (and sometimes modify) the Request structure as context for each part of your app to function.
Yeah, there is a consensus on how bad is the name. Thanks for the comment on the lib!
You'd have to get Microsoft to fix those - a file reader outside of MS Office won't help fix issues in Office itself.
You meant to post in /r/playrust
It's still very early in Iron's history, I don't think anyone thinks that it's "done" yet. The problem is that there's a lot more work to be done to get it from the point it is to the point where you want it to be, and there aren't enough people helping do that work.
You should help write some then.
Hmm. I would suggest you actually go ahead and attempt to build a non-trivial app in iron. Actually, start by building a trivial app with a few routes. Then re-read the article above. Frankly, I find iron over-complicated and the documentation incredibly poor. For ease of use it compares poorly to frameworks in other languages (Go, Python, Java, Ruby). I've been able to knock together a quick web app in all those languages in substantially less time than it took me to work through the basics with iron. Moreover, the frameworks I'm comparing iron to made the basics dirt simple and (generally) scaled with your app requirements. Based on the above I honestly can't say that Rust is web-app ready right now. And a big part of that is iron.
Think about how it would feel to be someone who has put a lot of their free time into Iron already, and who already *knows* that Iron isn't perfect nor adequately documented, but there's only so much time in the day. Then imagine what it would be like to read this about how much someone hates what you've done, and that they chose to write this rant rather than contributing to Iron's docs. Would you want to keep working on Iron, knowing that this is the thanks you'd get? That's my real concern with posts like this.
I would agree if it was called microsoft-office.
Right, and I was talking about arbitrary precision numbers, not reals. If you want arbitrary precision, then fractions of arbitrary precision integers is the best you can do with computers.
What you could do is some sort of security scanner
Plenty of legit criticisms here, not least of which is missing docs. However I think what the author has missed here (and I haven't seen mentioned yet) is that iron isn't much like django or flask, it's more like wsgi -- the low-level components you can build a framework out of. I don't think anyone has built a general purpose high-level framework yet (maybe individuals have built it for their own projects, but building a general purpose one is much harder).
Think about how it would feel to write a post that explicitly states "Iron is pretty darn good. ", and then have it represented as "how much someone hates what you've done". The author clearly spent a lot of time trying to figure it all out and writing the post. Yes, that effort could have been partly spent improving the documentation, but would those changes have been accepted if none of the committers understand how it feels to be a frustrated beginner? Ultimately it's your choice how you're going to interpret something, but I choose to interpret this post as a fair representation and constructive criticism, and I struggle to see how the frustration could be described better than to have it come across as genuine frustration. It is completely irrational to believe all this effort was spent just to make someone feel bad, and if your suggestion is to be less informative in order to protect someones irrational bubble, then I respectfully disagree.
&gt; would those changes have been accepted if none of the committers understand how it feels to be a frustrated beginner? https://www.reddit.com/r/rust/comments/5bph98/actually_using_iron_a_rant/d9quxw2/ &gt; Ultimately it's your choice how you're going to interpret something Yes, it is. And the author should know how it's coming across to people. &gt; It is completely irrational to believe all this effort was spent just to make someone feel bad I never said that, and I don't think the author was only trying to make someone feel bad. But intent doesn't eliminate culpability for when it *does* make someone feel bad.
&gt; How do you jump from "you want to support user logins" to "you need a middleware"? What happens when you want to support *a different* user login system? Or even multiple ones? In your custom framework below, you're coupled to HTTP basic auth. That completely doesn't work for me - I want to support Google/Facebook login via OAuth2, with a fallback to email/password with verification, with a second fallback to anonymous cookie users. It seems hard to see how you would do this in any sane way without some sort of middleware system. Custom frameworks are very often the right solution, particularly when you're just starting out on a project, but the Iron/Nickel guys explicitly want to build something widely usable for a lot of different projects. That means being able to swap out different parts when requirements differ, which requires some level of abstraction. &gt; These 5 different web frameworks you're thinking of are probably all in weakly-typed and dynamic languages, which means that it's a different situation. The mainstream (as in, used by other people) ones were in Python, C++, Java, Javascript, and Javascript - it was Django, 2 Google-internal ones, Express, and Koa. Good mix of statically &amp; dynamically typed languages in there.
It also gives a place &amp; a type signature for the framework to hang metadata about each level in the middleware stack. Common reasons you would want this include: * Many production webapps collect timing stats for each part of the request handling pipeline, so that if your users complain "The website is slow", you can diagnose the problem immediately. * If a middleware layer is consistently throwing errors, this gives the framework a chance to collect stats on the errors and possibly shut off the middleware entirely if it's threatening the stability of the server. This is even more important in a static language like Rust than a dynamic one like Python. * This lets you conditionally enable features via experiment or A/B test. For example, if you were to do middleware to inline images, you might A/B test it against omitting that middleware from the stack and then compare latency &amp; conversion numbers against straight HTTP.
Why do you have to be mean and non-constructive? :(
Reals aren't a representation, they're a space. Since the space of reals is unrepresentable, one provides approximating representations. Floating point is one possible representation, but there's no intrinsic reason it's any more a "true" approximation of a real number than a fraction.
And you still get OOM if you try to represent sqrt(2) accurately.
&gt; Since the space of reals is unrepresentable, one provides approximating representations. That's my point. You can't provide arbitrary precision for reals.
Initial commit: https://github.com/graydon/rust-prehistory/commit/b0fd440798ab3cfb05c60a1a1bd2894e1618479e
Nowhere did I ever say censoring. And I'm not *encouraging* anyone to feel bad, I can't change how anyone feels. I just have hope that by pointing out ways in which we can have empathy for our fellow OSS contributors and human beings, we can go farther in our common goal of making these projects better.
The second article seemed to confirm that; Niko took a detour by introducing a "Family" trait but I think it is unnecessary as you should be able to use an associated type constructor to move to a sibling (much like `std::allocator&lt;T&gt;::rebind`). I also find ATC quite ergonomic, and it meshes well with the rest of the language. But I'll let smarter people than me check that Rust is not painting itself into a corner before clamoring for it :)
You can use staging environment to test your setup. This way you won't exceed the limit. --test-cert, --staging Use the staging server to obtain test (invalid) certs; equivalent to --server https://acme- staging.api.letsencrypt.org/directory (default: False) [Source](https://certbot.eff.org/docs/using.html#certbot-command-line-options).
GCC uses GMP so that it can precisely emulate the floating-point behavior of a target platform, even if it differs from how floating-point on the host platform works.
Looks like Rust had [coroutines](https://github.com/graydon/rust-prehistory/commit/b0fd440798ab3cfb05c60a1a1bd2894e1618479e#diff-49c90a6a07b847b076385456c6fc214e) back then? What was the syntax/semantics?
Ah, here you're mixing up the stack iterator coroutines with the green threading / "proc" system. It originally had both. Escaping coroutines had isolated memory, indefinite extent, their own budgets and scheduler entries etc; stack iterators (single-frame coroutines with bounded lifetimes) were just cheap resumable functions.
That doesn't explain why it has to be part of the Request struct. Perhaps there should be a struct representing the actual HTTP request and a struct that represents the current context?
&gt; Are you not implying that the post should have been moderated to protect the feelings of the authors of Iron? If not, I've completely misunderstood and have no idea what you're on about. No, I am not advocating moderation. I am advocating that people think about whose work they're shitting on, how readers of the post might feel (which includes the people who did the work being shit on), and whether or not the way in which they're presenting the information is constructive towards accomplishing what they're advocating for or not before they write blog posts like this in the future. &gt; Also, I don't mean you're encouraging the post author to feel bad, but that you're encouraging the behaviour of being offended based on irrational assumptions. In simpler words: You're making it okay for people to take offence for stupid reasons. I absolutely encourage anyone to feel however they feel for whatever reason they want. I encourage the author of this post to feel frustrated! It's all about how you express those feelings and how your actions affect others.
They are considering using Rust in GNOME, the meeting is about exploring what that would be like.
Thank you (and the others who have commits in here) for doing this. It's great that we can have the full history. &gt; but I would appreciate keeping the repo a bit quiet / not drawing a ton of attention to it ... of course I read this after. let me delete some tweets, sorry :(
No worries. I mean, at some level it's just public and that's that. ¯\_(ツ)_/¯ (Also just noticed that github isn't correctly picking out / attributing all the commits that Andreas and Patrick put in. There were a number of authors in 2009/2010!)
Not sure "shitting on" is a good way to describe the OP? Or are you using inflammatory language to make a point and stumbling on the irony of that...
oh I thought it was about re-writing gnome in rust
It's worse if thought was given to this concern and they proceeded anyway! I believe there's a high probability that someone who worked on Iron would feel their work had been shat upon while reading this post, yes. &gt; Great. Thanks for involving me in this pointless thought experiment of yours. It's been absolutely non-constructive. You're welcome, anytime!!!!!!
The client I used basically had a bug related to switching from staging to prod*, so despite my tests, I blew things up when I switched to prod and got banned for a week. I posted on the LE forums and they said they're considering a more sane system of more frequent and much shorter suspensions, but it's very low priority. I am going to try again because I'm in a particularly good spot to wait a week, but that's luck. *I think. It's also possible it's my fault but I'm not really sure.
What's the definition of `application::cookie::Cookie`? It's apparently not the same as `iron::header::Cookie`. I'm betting you'll need to introduce a conversion to `iron::header::Cookie`.
Maybe the emails they used at that time aren't registered with their Github accounts?
Right, so you're not advocating moderation, but you also think "It's worse if thought was given to this concern and they proceeded anyway!". Are you fucking with me or do you really not see the contradiction here? I think you should read the post again with a more constructive mindset. You must have a very negative attitude to be able to characterize this as shitting on something: &gt; Iron is pretty darn good. Really! It seems generally solidly written, very functional, and reasonably simple. All of the batshit stuff I struggle with here is either a matter of documentation, which will get smoothed out in time, or architectural quibbles that, honestly, are pretty minor. If all this madness is just how web app servers get written these days, Iron is a quite solid example of such.
It's not about having to bump the version. The issue is that if you want to rename a package while it's in development (such as this one) you should be able to.
I'd be very interested in seeing the type signatures of the framework you wrote (because I am exploring this design space myself).
Well, Erlang has more freedom because of the VM. To provide a similar functionality I would need to wrap socket/file calls. I chose to make it easy to integrate with other solutions, so the user can chose what to use and also free me to reimplement things.
How so? FF re-wrote their core engine (from my understanding) in rust.
That's not what's happening with FF. Mozilla has written an experimental new engine in Rust (Servo), and is now incorporating some of its components into FF. Servo is not feature complete and is much smaller (in terms of lines of code) than Gecko (FF's engine).
I was under the impression from some videos on rust that Mozilla was like "we re-write this now. K Thanks" But this is interesting :D Kind of like dog fooding.
When you have hundreds of thousands or millions of lines of code, as FF and GNOME both do, rewriting the whole thing at once is just not possible. So the only way it happens is rewriting one component at a time and writing new components in Rust, until 10 or more years later its mostly a Rust project.
Sounds like you want the `crossbeam` crate. You can use `crossbeam::scope` and `scope::spawn` to create a thread that is guaranteed to be dropped at a certain point. This satisfies Rust's lifetime system. Check out https://users.rust-lang.org/t/defining-a-global-mutable-structure-to-be-used-across-several-threads/7872/4 for a more in-depth explanation and some usage examples.
Ahh makes sense. I was unclear with how large OSS projects really worked when it came to revolutionary new concepts and languages they want to incorporate or use.
Depending on what `something` is you can also just write `let result = rows.iter().map(something).collect();`.
I really like your solution though, it is really in line with how these things can work in rust. 
To appease the Rust borrow checker, convincing it that passing the chunks around is thread-safe, you might use Arc and Mutex, for example: https://is.gd/72TJ74. Problem with `Vec` is that it allows you to *change the size of the vector and thus invalidate the existing chunks*. Rust prevents you from doing that by only allowing one thread at a time to work with the `Vec`. If you need multiple threads handling different chunks of the same vector at the same time, then you need to protect yourself from the possibility of the chunks being invalidated. In other words, you need a thread-safe collection. Such as a version of `Vec` that doesn't know how to change size and reallocate the underlying buffer. Implementing that kind of collection would allow you to mark it `Sync` (thus telling Rust that it's safe to access it from different threads). (One way of implementing such thread-safe vector is by wrapping a normal `Vec` in a struct (https://aturon.github.io/features/types/newtype.html) and forwarding some of its methods, but hiding the methods that can change the vector size). You can also cut the corners with `unsafe` (by just abusing `unsafe impl Sync`, for example), but in my opinion it's better to actually implement a thread-safe (non-resizable) version of the `Vec`.
Okay, thanks for the input. 
I agree! Iron (and middleware) is actually pretty good. The rough new user experience is just coming from the lack of documentation, and the lack of batteries in the main crate.
Sorry, but I'm going to make an executive decision that today of all days is not a day that I want to deal with politics on the subreddit. :P Try submitting this again tomorrow.
Sure! I totally understand! :)
This is pretty nice, I was looking for something like this but didn't know what to search. It even found a bug in the terminal emulator I'm making, so thanks. If anyone is wondering how to use this with zsh in a way that isn't explicit, I just modified the script provided by Selecta, it uses ripgrep to find the files because that's fast and it's probably what you want to open anyway. # Run heatseeker in the current working directory, appending the selected path, if # any, to the current command, followed by a space. function insert-heatseeker-path-in-command-line() { local selected # Move cursor down. echo -n -e "\e[B" # Find the path; abort if the user doesn't select anything. selected=$(rg --files | hs | tr "\n" " ") || return # Append the selection to the current command buffer. eval 'LBUFFER="$LBUFFER$selected "' # Move cursor up once. echo -n -e "\e[A" # Redraw the prompt since Selecta has drawn several new lines of text. zle reset-prompt } zle -N insert-heatseeker-path-in-command-line # Bind the key to the newly created widget bindkey "^[a" "insert-heatseeker-path-in-command-line" Change the bindkey first parameter to anything you'd prefer.
A `Mutex` allows the data to be accessed for reading and writing in a single place. A `RwLock` allows *multiple* readers to access at the same time, or a single writer. That's the difference.
Sure, the URL in the index’s `config.json` can always be changed at that point.
#### This is a very simple web browser, running on top of orbclient, that can run on Redox OS. It is rendering these pages: - http://www.redox-os.org/news/the-internet-on-redox/ - http://www.redox-os.org/news/this-summer-in-redox-15/ - http://www.redox-os.org/screens/ Source code is here: https://github.com/redox-os/orbutils. It is not very clean at the moment, it is contained in this file: https://github.com/redox-os/orbutils/blob/master/src/browser/main.rs As always, Redox can be pulled from here: https://github.com/redox-os/redox
I absolutely think we should discourage posts like this. Hoping that folks give feedback in a way that's constructive isn't the same as asking that they be "covered in makeup."
https://doc.rust-lang.org/std/sync/struct.RwLock.html "The priority policy of the lock is dependent on the underlying operating system's implementation, and this type does not guarantee that any particular policy will be used." It is possible (in some implementations), under heavy load to starve one side (typically writers). See http://stackoverflow.com/questions/2190090/how-to-prevent-writer-starvation-in-a-read-write-lock-in-pthreads and similiar ones online.
Interesting, so `Mutex` might get you "fairer" results since readers and ~~readers~~ writers are treated equally? Great link, thanks!
They both have interior mutability; the difference is performance.
They don't seem to be. Try replacing `use self::cookie::Cookie as CookiePair` with `use self::iron::header::Cookie as CookiePair` and see what happens. Also you should avoid using `*` for your dependencies. I suggest picking a major and minor version and sticking with that.
I'm glad that it had it's intended effect of being a good tutorial! Don't worry we'll abstract that boolean away. I needed an easy way to show immutability vs mutability to new users. We'll be making it more idiomatic soon. As for a gitbook I think that might be a possibility in the future. Maybe when it's all completed I'll wrap it all together, possibly reorganize then put it out when it's all done.
It would get the latest version, but that might not match the version that Iron used. Oh, and it might be `iron::headers::Cookie` instead of `iron::header::Cookie`. I should be more careful about typos!
Nice to see another user of html5ever :)
Note that on Windows both `Mutex` and `RwLock` use almost identical implementations. The only difference is that `Mutex` has fallback code to work on Windows XP so it has a bit more overhead. So `RwLock` is faster but `Mutex` will work on Windows XP.
fwiw, I took a crack at creating an echo server with `mio` since it updated to 0.6, code's [here](https://github.com/jeromefroe/echo-rs/blob/master/src/bin/echo_mio.rs). Hope it helps.
&gt; Let's say we have two futures queued on a single connection, do they wait on each other? My SQL protocol is similar to HTTP1.1 with Connection: keep-alive, so you must execute and collect result of previous query before you can perform new query on same connection. Multiple futures queued on a pool will be executed and collected asynchronously, but on two different connections, which is usually already spawned. Purpose of pool here is to manage connection lifetime - connecting/disconnecting it from server or dropping result if connection was dropped before result was fully collected, I.e. Drop trait alternative with ability to run asynchronous code. &gt; What about transactions? API for transactions is one of things to be implemented.
Hah, I was just trying to follow this http://www.norvig.com/lispy.html in rust the other night :)
&gt; What they do might as well be the definition of correctness, since they are the standard, so it is difficult to use the word incorrect Incorrect being, the browser renders it perfectly itself, but the print to PDF version is incorrect with the issues I mentioned for each not being consistent with their browser representation. I will look into changing my layout CSS to work around the issues I guess. I'm in control of the html/css, just a document template that I wanted to utilize web technolgies for their great layout and templating for dynamic data capabilities. &gt; something designed to render in a web browser will not necessarily translate perfectly to a standard size PDF I've specifically targeted the content to fit to an A4 size, it looks fine in the browser and in print previews(inconsistencies from browser aside). &gt; web pages usually aren't awesome in PDFs because the page breaks do horrific things. Could you expand on that? I thought with a linear flow of the document there shouldn't be any issue in assigning page break rules to elements?
RwLock also has slightly stricter bounds on its generic parameter, because the contained type had to be safe to access concurrently, whereas a value in a Mutex never has to deal with that.
One more detail you might want to mention at the end: why semicolon on one clause in the if statement and not the other. Something like "Semicolons inhibits the return value of expressions. We need it to stop the if statement returning 'true'. But macros don't return a value, so it's not needed there." If, that is, it's the right explanation which I frankly don't know for sure. 
What is the license of [The Rust Programming Language](https://doc.rust-lang.org/book/)? Are there some CCBYSA/GFDL/PD resources on Rust?
So.. why semicolon for one branch and not the other?
By serious project I meant to basically re-write whole thing in Rust. But anyway, it'd help to have at least a reader, so you could read suspicious files safely.
I think it is constructive. Not only does it seem to very accurately describe the genuine frustration of first using Iron, but it balances that out with a lot of praise too, and it's actionable. What's not constructive about that? Sure, sometimes reality can hurt a bit. That doesn't mean it's a good idea to cover it up.
Makes sense, thanks!
&gt; * [Implement RefUnwindSafe for atomic types.](https://github.com/rust-lang/rust/pull/37178) Can somebody explain to me why this is correct? Non-poisoned mutable state seems like exactly the sort of thing which is `UnwindSafe`'s purpose to rule out. But maybe I'm missing something about this specific situation.
Is there a way to tell clippy to ignore a specific warning at a specific spot in the code rather than just globally?
&gt; Arbitrary precision is not possible for reals, real(1/3) would OOM. Arbitrary precision is in fact possible for _computable_ reals, and no, you don't do it by trying to store every single digit. You do it by storing how to _compute_ arbitrary decimal places of the number. Then when you need to display it, convert it to floating point, etc, you compute as many decimal places as are needed. EDIT: For the record, `1/3`, `pi`, `sqrt(2),` and any computable combination thereof, are all computable.
Did you try any of the other popular ones? I've experienced the empty CVs at least with text missing, higher rate of 1 in 20 I'd say. I've heard about Athena as being a successor/improvement to wkhtml, will look into soon, I just have to sort out some docker issues.
Sure, I think non-constructive intent should be discouraged. And personal insults seems to generally fall under that description. But I would discourage the intent, not the mechanical expression of it. You should try to avoid feeling the need to personally insult someone, but if you actually do then I believe it's better to express it. If you don't it'll just fester inside and eventually get Trump elected POTUS.
Are you dead set on html and css? I had a similar problem at one point, and I was able to hack up a solution using a templating system and LaTex to pdf. 
&gt; readers and readers Yep, that's how we smother the writers
Found it! https://github.com/Manishearth/rust-clippy#usage #[allow(_)]
Its not Rust, and its not free, but we use https://www.princexml.com/ at my company with a lot of success for years now.
I recall they said they want to follow the L4 steps: make a minimalist kernel interface and add compatibility layers in userspace.
Not sure if this qualifies: fn recurse(i: u32) { if i == 1_000_000 { println!("Bottom reached"); } else { recurse(i + 1); } } fn main() { recurse(0); } This causes a stack overflow without unsafe: $ ./test thread 'main' has overflowed its stack fatal runtime error: stack overflow Aborted (core dumped) If I'm not mistaken this could be prevented by tail call optimization, but that's not implemented in the compiler so far. And even simpler: fn main() { let huge_arr = [0i64; 10_000_000]; } This segfaults too: $ ./test2 Segmentation fault (core dumped) It's not undefined behavior though.
I think so, I haven't looked into LaTex so I'm not sure how flexible that is with layout and styles. I'm currently using Adobe InDesign but not in an advanced way, data is all manual, no template like features in use either(I think it has them). I'd like to use some web technologies to expand on just dynamic document generation where I can expand with new features and develop it into more of a service.
I didn't mention it at all but I responded to someone else in this thread about it. I think it'll be built using Combine or Nom, but we can do some things by hand for syntax checking that is parsing such as counting the number of ( and ) to make sure nothing is off. Also thank you! One of the reasons I started this was because I heard lots of new users saying what can I build to learn Rust but the answers were never satisfying. I'm hoping this will work well.
*Thousands*? If this is libc or some other big generated crate, I'd recommend always using namespaced versions instead of importing individual items. Things like `extern fn void_thing(x: libc::c_int) -&gt; *mut libc::c_void`.
Yea, thousands. And the imported items are being used hundreds of times. If you want a more concrete example, this is what I'm dealing with: https://github.com/retep998/winapi-rs/blob/dev/src/um/winbase.rs I'm working on the winapi 0.3 overhaul with the ultimate goal being shorter compile times. I *could* do namespaced versions, but it would have to be a significant compile-time win. It would be really tedious to go through all of winapi and replace everything. 
You didn't answer my most important question: how is discouraging personal insults not covering up reality? It's important because you've used "cover up reality" is a tool to insist that discouraging rants is bad. &gt; not the mechanical expression of it Expression is everything. I don't think we're going to see eye to eye. I will say that I think the OP has a ton of valid complaints and criticisms, and I think it's *very* unfortunate that the OP chose to package them up inside in a rant. The rant doesn't change the validity of those complaints/criticisms, but it *does* make it much harder for someone to act on them, because the style of writing specifically limits said people to those with incredibly thick skin. While I think thick skin is generally a good quality and is incredibly useful to have, not everyone has it. More than that, this style of writing has a very good chance of making *someone* feel pretty bad. I don't know about you, but I don't like it when I make people feel bad. I do my best to avoid it (but don't always succeed). I will continue to discourage this kind of content in the Rust community.
Actually I think it's awesome to have a minimal browser written in rust. Can we port this to Linux and Mac as well? :)
This is fantastic and I look forward to the rest of the series. I'm an electrical engineer by trade and the only programming language I know well is C++. I've written some small utilities for work, and have been considering on learning Rust and porting parts of them over slowly. One is basically a transpiler between 2 proprietary formats for a controllers program. This seems like an excellent tutorial to learn about doing the parsing in Rust.
I don't think those situations are comparable for a number of reasons. One is a private conversation between a few people that know each other well where one is complaining about their *own* work, while the other is a publication for the whole world to read ranting about some stranger's work. The former situation is also different because there's presumably an established *rapport* between individuals. Not. Even. Remotely. Similar.
Somewhat? It's still a bit different from C++ however: An input iterator is any type implementing [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html). The equivalent to C++ output iterator is any type implementing [`FromIterator`](https://doc.rust-lang.org/std/iter/trait.FromIterator.html). This isn't an iterator, but rather a type that can be constructed from an iterator. Think `String` can be constructed from an iterator over `char`. Forward-only which can both be read &amp; written to is a type implementing [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html), where the type being iterated over can be mutated, eg `&amp;mut T` for any `T`. Eg. `Vec&lt;T&gt;` has an inherent method `iter_mut()` to create an iterator over its elements where you can modify the elements. I don't think Rust has anything like bidirectional iterators or random-access iterators. Rust has [`DoubleEndedIterator`](https://doc.rust-lang.org/std/iter/trait.DoubleEndedIterator.html) which allows you to take from the end of the iterator as well as the front, but you cannot 'undo' a step in the iteration. Rust has [`ExactSizeIterator`](https://doc.rust-lang.org/std/iter/trait.ExactSizeIterator.html) which just knows the exact length but doesn't guarantee O(1) access to its elements. I think it's supposed to be useful when collecting into a container when it knows the exact number of elements beforehand. Rust has [`IntoIterator`](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html) which is automatically invoked to convert a collection into an iterator for the `for element in collection {}` syntax. 
Wow, yea. That's what I was looking for.
Though disliked by some, the first one is considered the idiomatic solution.
The first 12 tickets are available for registration on https://novembrsetsy.eventbrite.com/ , the second wave will open up next friday at 2pm
Maybe too late (only managed to read the whole thing this morning), but: I think your original rant was pretty entertaining. It was informed, gave good feedback, you didn't give up at the first failure but tried to unterstand why stuff was implemented that way, and introduced me to far too many variations of the word 'middleware'. 5/5 – would read more of your rants.
It seems like your code _is_ the test case to find out if wildcards grow compile times pathologically. Most crates are dealing with significantly smaller numbers of imports.
Is there a reason that Task::name() returns &amp;String? Returning &amp;str would allow for greater flexibility, like returning a string literal.
One important advantage: Using the first variant gives you a chance to tell people that the `::&lt;&gt;` syntax is called "turbo fish"! ;)
Thankyou for writing documentation, but **please stop degrading the discourse in my community**. Your tone here is nasty, immature, and totally inappropriate. The way you communicate has an impact on the community and you are currently behaving harmfully. http://lesswrong.com/lw/c1/wellkept_gardens_die_by_pacifism/
&gt; please stop degrading the discourse in my community Although I agree the OP could have done without the last couple of sentences of this post, the rant itself was actually very informative and I didn't feel that it was offensive in any way. By the way, it isn't *your* community. It's *our* community. If the community actually thought this post was problematic, it would either be downvoted off the page, or a moderator would step in.
&gt; I really don't understand this attitude. Getting swamped by a wave of feedback after writing a popular article can be emotionally draining, especially if people aren't accustomed to the experience. (I don't know if the OP is used to it.) After the 30th person asks "are you angry?", with varying degrees of politeness, it's hard to resist becoming hardened.
This is a great approach, and sometimes one I use. Other times, figuring out how something actually works is so painful that I write about it so that hopefully the next guy to try it doesn't have to go through the same growing pains.
I'm so proud that [I invented this](https://github.com/steveklabnik/rust/commit/4f22b4d1dbaa14da92be77434d9c94035f24ca5d#commitcomment-14014750).
Heads up, I am working on implementing error recovery in LALRPOP https://github.com/nikomatsakis/lalrpop/pull/160 to make it possible to swap out [gluon's current parser](https://github.com/gluon-lang/gluon/pull/103).
To design a parser from scratch, make an Iterator that produces tokens (an enum of possible patterns) based on character-by-character pattern matching. That's where you start.
Thanks for the heads up! This looks like some solid work.
Can we not draw a distinction between writing useful content and telling people to fuck off? Someone can make a useful contribution at the same as they are doing harm. These aren't mutually exclusive actions!
As far as I understand crossbeam lets you create a thread that will die before the end of the current scope. But I don't want that, my spawned thread must stay alive for the whole duration of the execution. Corrent me if I'm wrong.
I've temporarily removed this post, pending a discussion with the other moderators. I for one enjoyed your original post (and I know many others did too), but it was clearly controversial. We have to figure out what the best approach to dealing with such flavourful posts is - we have a duty to the entire community, and whatever we do here sets a precedent. &gt; So fuck off. I'd like to point out that regardless of what we decide: this *is* personal, and *is not* ok here.
In this case I would prefer the first one (it's shorter) but for Iterator::collect I usually use the second notation.
Higher-kinded types as expressed in Haskell are not very suitable for Rust: * they don’t cover bounds, which we need; So higher-ranked trait bounds (HRTB) [as discussed in part3] are not an option because of the higher complexity they introduce in the compiler? I did not really get it because i liked HKT wit HRTB quite a bit. 
Thanks. When I initially wrote the getting started page, I used the second notation but I have since switched to the first one since all the feedback here is pointing to it.
Diesel's query builder would be much easier to represent and abstract over with HKTs. 
first: impenetrable alien language second: decades of familiarity 
You're looking for /r/playrust.
Also see [the discussion](https://www.reddit.com/r/programming/comments/5c0vab/help_rust_make_the_most_informed_decisions_on_hkt/) on /r/programming
Great job, it's an awesome name!
Yeah, you're right. I shouldn't take my own shit out on people who don't deserve it.
One example that springs to mind would be abstracting over smart-pointer types. For example, you might be building an immutable tree map of some kind, and want to be able to parameterize over being sharable across threads (using Arc) or a single thread (with Rc). Or, even, avoiding the reference counting overhead at the expense of deep copying (via Box).
It sounds like you need better tooling.
is there a "quickstart guide" for someone coming from C? I want something that will give me a quick overview of the language while relating to C the stuff that can be related.
Humans aren't that slow. Even a modern machine can be too slow to respond for an average user to update the changes in a GUI. These cache misses don't just hurt the GUI application but all other applications and software running on the system that are fighting for access to the CPU. This is especially true of AMD processors. You have to remember that the single-most cause of poor performance is memory and I/O speed, not the CPU cores themselves. Overclocking cores just happens to also overclock the underlying cache related to that core. A better analogy is a backpack. The more applications you have in your backpack, the heavier it is on your back, and the slower you will move. If you can't fit everything in the backpack then you have to leave some objects at home and come back to get them later, and if you have grabbed all the wrong items, you'll have to drop them and go back home to pick out what you need. If all your applications are written with OOP, that just adds to the weight and occurrences of having to come back home to pick up more objects as a result of consistently missing the cache on a regular basis. At least for AMD processors, especially the FX processors, cache misses are one of the single-most causes of poor performance. Many of the core's cycles are wasted waiting on recalling data to the cache. It is a big reason for why C software typically achieves better performance on AMD than C++ software. Intel is less affected due to having larger cache sizes, but the fact remains that there's never a good reason to waste performance. We should take the time to write solutions that do not require expending hardware that could otherwise be saved. Wasted CPU cycles still costs time and energy. As for GUI's specifically, they are most apt for cache misses because of the plethora of possible virtual methods via OOP. The more possible methods, the higher the incidence of cache misses.
Regular expressions and a good editor?
Yes, it is! It works wonderfully, very fast rendering in release mode.
Really nice, I'm glad I'm not the only one who hates this web framework junk. For me the saddest thing about this though is not the abstraction disaster, but the commandeering of the crate names router, staticpage and mount. These seem like they should have all be namespaces under iron. Are there no kind of checks on crates.io to stop this kind of "crate name parking"? If not, should there be?
Extended or arbitrary precision is almost never the answer to numerical instability. You usually just push your problem ahead of you a few steps, at the cost of huge increases in running time. The right approach is almost always to rewrite your numerical code in a way that is numerically stable. Reformulate it so you don't deal with tiny differences of large numbers, or add numbers of vastly different magnitudes and so on. There's even plenty of special functions in math libraries to help you do that. 
I tried hello world from the documentation but it doesn't run.. any idaes? ~/scrape/hello_world:.cat main.rs fn main() { println!("Hello, World!"); } ~/scrape/hello_world:.rustc main.rs ~/scrape/hello_world:. I'm running rust-1.12.1 installed with homebrew
I think implementing a basic parser by hand would be a very good step. You could switch it out for a "real" one later in the series, when we understand how the parser works. 
I was thinking about that. Lisp is fairly simple compared to languages like Rust. We could easily represent it with a simple grammar when we parse it. If we need a more complicated parser we can use it but it seems like a lot want to learn how to hand roll one.
Doesn't look like you actually tried to run it. Try `./main` after compiling. $ echo 'fn main() { println!("Hello, World!") }' &gt; main.rs $ rustc main.rs $ ./main Hello, World!
We're also working on a second edition; the bits that are done are here: http://rust-lang.github.io/book/
If you're asking about winapi... Don't use glob imports, do use regular imports, and don't use namespaced versions.
Why Rust source code still relies on GCC and make? I think Rust is mature enough to be developed itself in Rust/Cargo. Is there any blockers for not doing that?
I like the second one.
I think the `&lt;&gt;` is the fish, and the `::` is the bubbles it creates behind itself by going so fast :D
Good point. Thanks.
Why can't I declare multiple variables at once, like this: `let x,y,z : isize;` I understand it's probably intentional, but what's the logic behind it?
And it is more compact to read what actual kind of work is done. let res = query.run........ vs. let res: ......... = query.run();
With `crossbeam` (or a bunch of other libraries, like `scoped-pool`) you can do something along these lines: on your main thread you create the scope, you allocate the vector inside that scope, you get the chunks of that vector using the borrow-checker-friendly methods and distribute those chunks among the scope-bound worker threads. Your main thread (with its scope and its vector) stays alive and kicking, doing its job in some kind of a loop until the program ends. That's neat, but not necessarily the most scalable application design. BTW, you should check `rayon` out, it brings some automation to vector parallelization.
Hi, I want to ask about `BTreeMap`, why there is no `lower_bound` function to get a single smallest element that is larger or equal to my bound. As I see the code of `range`, it needs 2 searches to define both bound.
It's always the way that Plan 9 did it first, and better
Rust is a modern systems programming language with a powerful type system which protects the programmer from many errors, including free-after-use and race conditions, all at compile-time! As such, it does not need a garbage collector and delivers predictable performance. It's easily integrated into other languages and is great for low-level programming. In Rust, you can write reliable, high-performance, multithreaded code. In the past half year since our last meeting, there have been some interesting changes, including the advent of a futures library supporting async IO, the first release of a system for supporting IDEs, and support for incremental compilation. Gaps in the language and ecosystem are quickly evaporating. The time to familiarise yourself with the tools is rapidly approaching! On November 22nd, we'll be meeting again at the Kasperskii Labs office. We will discuss real-world application experiences with using Rust in a few systems-level tasks and tests, the good and the bad. We will also discuss how Rust can help you and how to setup and get started with Rust. So come! It'll be interesting! *my very shitty translation, do not fire nukes before consulting a real translator*
Coming from C#, I want a special case `.to_vec()` so badly. OK, not _so_ badly. But it would feel familiar.
I don't know about that guy, but while I would be happy to write decent documentation for Iron, that would involve actually understanding how Iron works. I have neither the time nor the inclination to read through the source code of a project of this scope multiple times in order to get a good enough idea of how the system works to actually write decent documentation for it that doesn't assume that the user is an experienced web developer.
Want no more! trait ToVec : IntoIterator { fn to_vec(self) -&gt; Vec&lt;Self::Item&gt;; } impl&lt;T: IntoIterator&gt; ToVec for T { fn to_vec(self) -&gt; Vec&lt;Self::Item&gt; { self.into_iter().collect() } }
You don't have to understand all of Iron to be able to document how to use one part. Every little bit helps! If you try to make Iron do something, and you find you have to look in multiple places or read a bit of source to figure out how to do it, but you do figure it out, putting what you figured out into the spot in the docs where you expected to find it to begin with will save someone else the time you spent. If everyone did this for one little thing, the docs would improve immensely.
OK, that's a fair point.
Latex is primarily designed to create something which looks nice when printed on paper. As a result, it does the vast majority of the layout for you, but gives you a lot of options for when you want to specify something. It also has a lot of plugins for adding features which only work when viewing the document as a pdf rather than as a printed document, including one which adds a bunch of previously adobe exclusive features such as forms and embedded javascript.
Hello, I'm writing backend for out web application with Hyper+Iron in RESTful manner, and I desperately need some hint of how to implement integration testing. The most preferable option for me is a separate binary with `rust-curl` based online-testing. Is that possible to make `cargo test` compile and run my server, then launch tests and finally kill the server after testing is complete? It would be really nice to have such integrated solution. P.S. I can't just add `rust-curl` as a `dev-dependency` and have the server run just in the separate thread because `rust-curl` wants a different version of `libssl` linked and that causes a conflict.
You probably want to repost this in /r/playrust
D's LTO strategy sounds like Rust's. Pile everything into one LLVM module. But the cross language features seem to depend on the LLVM's Gold Linker. As you are linking LLVM-IR not object files. I just linked because having LTO between C/C++/Rust would be awesome, albeit a far out dream.
Thanks for writing this, the interesting part for me was about how `Result` and `Option` work and how those two allow Rust to do things safely without exceptions. Algebraic datatypes are confusing because the names don't really describe in plain language why they are called what they are. A sum type is really a sum of the values of the types that the sum type could be. enum SumType{ Byte, // Could have 256 values 0-255 Boolean // Could have 2 values True, False } // So our SumType could be one of (2 + 256) different values
The same basic approach (e.g. using `cargo rustc -- --emit=bc` to get the LLVM bitcode, and linking with `clang -flto`, with a clang using an LLVM sufficiently close to the Rust one) works with Rust now.
Thank you!
You are not meant to format an error string there. In the `description` method you should just return a static string like `"file does not exist"`. A more descriptive error can be printed in the `std::fmt::Display` implementation of `MyError`. `std::error::Error` requires it so you know all errors can be printed. I too find this a bit odd but w/e...
The best matching I can find is [r4cppp](https://github.com/nrc/r4cppp) but it's quite old. Honestly just go with the [official book](https://doc.rust-lang.org/book/).
Yes, by dying I meant joining.
&gt; The first one looks wrong, because on reading this I would think the vars are related in some way. It's important to remember that it's not `let variable: type = expression`, it's `let pattern: type = expression`. And patterns deconstruct things. So that's what's happening here, just like if you used it in a match. &gt; I'm really interested if there's some reason the syntax from my question isn't implemented, it looks quite logical to me. It would mean, instead of being able to re-use patterns, we'd have to make up some sort of new syntax, which would be a special case and make the language more complex.
We already have an alternate build system based on Cargo; it's not on by default yet, pass `--enable-rustbuild` to `./configure` to try it out. `gcc` is used to link rust programs; we didn't want to re-write our own linker. Also, `rustc` still depends on some C/C++ libraries: LLVM, hoedown, jemalloc, etc. So we have to build those.
I am very interested in having Bloaty support Windows executables. Patches welcome!
I've removed this per rule #5 - please feel free to re-post this as a self post
Patches welcome! The platform support is abstracted away very cleanly, so it should be very straightforward to add.
🎉 I'm seriously excited about `?` landing. All of the Rust code I've written in the last few months has used `?`, and any time I've had to deal with `try!` since starting to use it has been mildly annoying. Here's hoping that `Carrier` will be stabilized in a way that makes `?` usable with non-`Result` types and eliminate the need for `otry!`-like macros.
I am really happy about the stabilization of the '?' feature, but: 1) I feel it cool be nice for searchable purposes if we call it e.g. the "questionmark" operator or something like that when we talk about it because I totally can imagine myself in a few months having to google "rust version stabilisation for ? operator" and being all "!!!" at the results ^^ 2) I know there have been some heated discussions on this features, but is there some reasonably consensual(-ish) style guide on how to use it? I mean, if I start using it in my code, should I use it everywhere and drop `try!` entirely, or should `try!` still be used in some cases? Reading the announcement, I'm under the impression that `?` should (in long term) replace `try!`, but I'm not entirely sure?
the syntax highlighting on the blog highlights the new `?` operator as error, but honestly that kind of visibility (a background color or bold+color) makes sense for it, given it’s an early return.
So like a tuple in Rust would be a product type. fn tuple(x: (i32, bool)) // i32 has 4294967296 possible values // bool has 2 values // So the type of x has (4294967296 * 2) possible values It's the product of the possible values of the component types. Quotient types have to do with how the values of a type relate. So given a type `i32`, and a relationship (equivalence relation) of the values where `x % 2 == 0`, our quotient type would be the set of all the even numbered values. But I don't think this is built-in to Rust in the type system. Intuitively, it seems like quotient types would be important for query languages though.
I guess I'll try jumping in head first: cargo install untry --git https://github.com/japaric/untry.git find -name '*.rs' -type f | xargs untry 
I've removed this since it is not specifically about Rust, and you have provided no explanatory text (see Rule 5). Please feel free to re-post this as a self-post with some discussion of its relevance.
Thanks very much for the explanation!
I think you'll find this is one of the friendliest programming languages communities. Discussions about language features always happen in a civilised manner and even if something has been discussed many times before, you will not be scolded yet friendly referred to why such a feature is a good or bad idea.
It's very open. Anyone can submit an idea via the [RFC process](https://github.com/rust-lang/rfcs) and it will be discussed fairly and constructively.
We're a bunch'a jerks. Actually, no, the rust community prides itself on being open-minded, kind, and open to criticism. The Rules section to the right does an excellent job capturing that, I think.
That would result in `O(n)` rather than `O(log n)` comparisons.
I think this should be f32, not float? enum Animal { Cat { weight: float, legs: usize }, [...] also, isn't it better to write the `match` like this? match animal { Animal::Cat { weight, .. } | Animal::Dog { weight, .. } | Animal::Monkey { weight, .. } | Animal::Fish { weight, .. } | Animal::Dolphin { weight, .. } | Animal::Snake { weight, .. } =&gt; weight }
Early return is nothing new; the `try!` macro has done this forever. There's another part of the error handling RFC which adds `catch` functionality where error handling can be localized instead of always using early return. Until such a thing lands you have to be aware that `try!` and `?` will perform the early return and plan accordingly.
welp, just did this by hand earlier today. This would've helped a lot \^\^'
Or perhaps more abstractly from category theory, where [categorical sums](https://en.wikipedia.org/wiki/Coproduct) and [categorical products](https://en.wikipedia.org/wiki/Product_category) appear as [duals](https://en.wikipedia.org/wiki/Dual_(category_theory)) of each other – this makes it rather perplexing why products were so common in traditional languages but sums weren't. But they are all related in some sense. Table 1 on page 11 of the [HoTT book](https://hott.github.io/book/nightly/hott-online-1075-g3c53219.pdf) outlines the relationship nicely. It's common in type theoretic literature to simply denote sums and products using `+` and `×` respectively, and dependent sums and dependent products using `∑` and `∏` by analogy. The examples in the blog post could be written as: Animal = float × usize + float × usize + float × usize × usize + float × usize + float × usize + float × usize Option(T) = T + 1 Result(T, E) = T + E Function types could be written using superscripts in principle (like exponentiation), although most people stick to `→` in practice: &gt; (A → B) ≡ B^A And as u/aridsnowball observed, one can trivially translate an algebraic type expression into one involving the cardinality of the types. By extension, one can use this to discover isomorphisms between types. For example, if we set `E = 1` then `Option(T)` and `Result(T, 1)` would be the same: Result(T, 1) = T + 1 = Option(T) This suggests that `Result&lt;T, ()&gt;` and `Option&lt;T&gt;` are isomorphic. There's a lot more examples like this though :3
The community is in general very friendly, and open to honest discussion. You may find that some new ideas and fair criticism are pushed back at a lot for a couple of reasons; for one, the language has stabilized, so no backwards-incompatible changes are allowed any more (if there ever is a 2.0 that has backwards-incompatible changes, it's likely to be by dropping long-deprecated features that have already had a replacement for a while, not doing any major restructurings). For another, the Rust language team does tend to be a bit conservative about throwing on a lot of new features that would increase complexity greatly. That's not to say that they aren't adding any; `?` just stabilized, the initial `impl Trait` is in nightly and is working its way through stabilization, there's significant discussion of extension of the type system to allow associated-type constructors which give you many of the benefits of higher-kinded types being a lot simpler to design and implement. There are some people who come to Rust not understanding that, and so who go through and try it out and write a critique of Rust as a new user and how these things really don't work and should be changed, and they may not get the response they're looking for when trying to discuss changing features that have already been stabilized or proposing their favorite feature that there isn't much of a compelling argument for or which they don't yet have enough experience with Rust to articulate how it would work with Rust. So, it's hard to tell if this is what you'd consider "open to new ideas and fair criticism" or "extremely conservative and arrogant." I know that some people get very off-put if they suggest what they think is a great idea and it gets shot down, even if there's good justification for doing so, so those people might find some responses "conservative and arrogant." Rather than asking that, better to just start to discuss the things that you see that might be missing or frustrating, ask about what might already exist or has already been discussed to mitigate them, and if there isn't anything start discussing ideas and strawman proposals, and keep an open mind to fair criticism of your own ideas as well.
&gt; Is such support off the table now, or can it be made backwards compatible? It's backwards compatible to add it later.
Congratulations and kudos to the team(s). Another release that improves on important metrics. I think while the performance focus on compile time is good, we should extend our benchmark corpus to ensure runtime performance does not unduly suffer. What is the current status in this regard?
Also: with `Reflect` deprecated, is generic reflection unsupported / fails to compile now? Or it just works without the `Reflect` bound? edit: actually I'm reading [this](https://github.com/rust-lang/rust/issues/27749#issuecomment-244489589) but it's a bit long, perhaps linking to a relevant comment on there is sufficient.
**Feature request:** a clippy lint suggesting to replace try! with ?
I mean, just calling it `?` wouldn't be parser ambiguous either.
&gt; for a couple of reasons Another reason is that Rust has a long and illustrious history and a lot of the ideas _have been tried_ in some form before :)
I haven't been following those changes very closely, personally.
I'd expect this to be a rustfmt option rather than a lint tbh.
The latest code is here: https://github.com/hjr3/mob I have not worked on that since tokio came out, but I believe it compiles on the latest mio and rust. It is not multi-threaded either. Feel free to ask me questions on irc about mio and I am happy to assist where I can.
Now that I am slowly seeing `?` appear in code, I think I actually prefer `try!`. It takes just a tad more real estate (and it highlights in orange in my editor) which makes the control flow easy to spot. I find `?` a bit too subtle sometimes.
Sounds pretty awesome :) Like a super charged markdown?
Good news: it already is!
Still reading, but there's a typo -&gt; search for "Augest"
I feel like this is a simple question, but I just can't figure out what to google. I'm trying to test code that uses a struct from another crate underneath. I want to be able to provide my own fake implementation of this dependency in my test, so I'm trying to create a generic trait that my application code can use. // Concrete struct from crate struct Client { data: i32 } impl Client { fn some_method(self) -&gt; Client { ... } } // My generic trait trait GenericClient { fn some_method(self) -&gt; GenericClient; } // How do "impl" this trait for the Client struct? How do I add this trait to a struct from another crate? I can't seem to get anything to work.
**e**xception **h**andling?
It's amazing what procrastination from homework can do. I banged out all the answers from yesterdays questions so you don't have to wait!
personally I read it more like "huh?" (I remember the first time I watched videos on functional programming that used `!` quite a lot to highlight function mutating state, it was quite an epiphany knowing that `set!` was usually pronounced `set bang`, until then when I read such functions I subvocalized them by screaming in my head ("SET!") and it was quite exhausting)
It's a fine interjection, [eh?](https://en.wiktionary.org/wiki/eh#Interjection) But your backronym also works, that sells it.
I think you want something like: impl GenericClient for Client { ... } Although I'm also a rust noob
This is a deeply important insight, and you may have forever changed the landscape of PL design. /u/desiringmachines we need to call a truce and unify on this proposal.
I guess it leaves at least a symbol table so you can get proper stack traces on panic when running the executable with `RUST_BACKTRACE=1`. I'm not sure why it would be so large compared to the stripped binary; perhaps you're stripping a hello world? The "debug information" isn't just a symbol table but some DWARF section (at least on Linux; perhaps LLVM emits something else on other platforms). See [this](https://users.rust-lang.org/t/dwarf-debug-format/2100/2). Also, whether you include extra debug information and whether you optimize your executable for release are actually separate options. Release builds by default optimize and doesn't include this debug information; Debug or "normal" builds (actually called development builds in the docs) by default don't optimize and include extra debug information; but you can tweak them with flags on `Cargo.toml`. See `debug` and `opt-level` [here](http://doc.crates.io/manifest.html#the-profile-sections). (on a side note, even release builds don't include link-time optimization by default, so inlining across crates doesn't happen unless you enable `lto`)
To anyone interested, I have been working on support for Redox as a [tier 3 platform](https://forge.rust-lang.org/platform-support.html) for a while. I have finally ironed out the problems and produced a usable build using the ported `libstd` This is a critical step for Redox, as it will allow compilation of much more Rust software without modification, and is a very important step towards self-hosting
An idiomatic GUI library. General category: GUI Specific category or usage: An idiomatic GUI library as described [here](https://www.reddit.com/r/rust/comments/52cnw5/designingbrainstorming_an_idiomatic_flexible_rust/). Most important features: being idiomatic :) Missing features from existing libraries: `conrod` is missing many widgets that we can find in heavier toolkit like GTK+.
Could be both. 
Yet another release of Rust without a usable ordered map type in collections. All it needs is a "find smallest less than by key" method that returns an iterator. That's it. But no, we get a no progress for a year because Ranges are too hard.
&gt; `?Mark` You're a monster.
My first instinct was to read it as 'quoi', fwiw.
Here's a larger portion of the match: match *token { InfixToken::Operand(_) =&gt; output.push(token), InfixToken::Operator(ref op) =&gt; { if stack.len() == 0 {stack.push(token); } else { match *op { Operator::Add | Operator::Sub | Operator:: Mul | Operator::Div =&gt; { while let Some(o) = stack.pop(){ if op.precedence() &lt;= o.precedence() { output.push(o); } else { stack.push(o); break; } } stack.push(token) }, } } } Inside the `InfixToken::Operator(ref op) =&gt; { ... }` branch, we know that `op` is an `Operator` (because only `Operator` can go inside `InfixToken::Operator`). But we don't know whether `o` here contains an `Operator` - it could be any variant of `InfixToken`: while let Some(o) = stack.pop(){ What you could do is this: while let Some(o) = stack.pop() { match o { InfixToken::Operator(ref op2) =&gt; { ... }, // something else } } This is what I mean by matching the `InfixToken` (the `o`) to get the operator inside (the `op2`). Now, this code needs to handle the case where there is no operator inside (this is the `// something else`). Perhaps there is some design error in your code that makes you push non-operators in the stack in the first place. I mean, if you have pushed an `InfixToken::Operand` here: match *token { InfixToken::Operand(_) =&gt; output.push(token), How can you later compare it for precedence? PS: I highly recommend you run [`rustfmt`](https://github.com/rust-lang-nursery/rustfmt) on your code, to get consistent formatting (such as always having spaces before `{`).
https://en.wikipedia.org/wiki/Eh#Canada
One might even say that Canadians have a tendency to say "eh". An [`eh_personality`](https://doc.rust-lang.org/book/no-stdlib.html#writing-an-executable-without-stdlib), if you will.
[removed]
It seems to be fully covered in the text actually, so I jumped the gun in asking about it here. 
[There's an example on the issue tracker](https://github.com/rust-lang/rust/issues/31436#issuecomment-247465972) Looks pretty readable.
I believe that this would work too (with better performance): cargo install untry --git https://github.com/japaric/untry.git find ~/ -name '*.rs' -type f -exec untry '{}' \; Also, you've forgotten path...
Did you find a satisfactory solution for this?
[removed]
You basically nailed it; everything in Rust uses RAII. (I mean, I guess you could write code that didn't, but `std` does, and every library I've used does as well, so it seems to be the style, and for good reason.)
Also, instead of `&amp;'static str` it's probably better to use `Box&lt;Error&gt;` which * lets you keep and output the original error message, which is hopefully more detailed anyway * lets you use `try!()` or `?` without any mapping of result types With that, it becomes use std::error::Error; pub fn list() -&gt; Result&lt;Vec&lt;ResourceType&gt;, Box&lt;Error&gt;&gt; { let s = get_conn_str(); let conn = Connection::connect(&amp;s, TlsMode::None)?; let rows = conn.query("SELECT id, handle FROM commerce.resource_types", &amp;[])?; let result = rows.iter().map(|row| { ResourceType { id: row.get(0), handle: row.get(1), } }).collect(); Ok(result) } Depending on the scale of the project you'd probably also implement `From&lt;Row&gt;` for `ResourceType`, so that the iteration can become Ok(rows().iter().map(From::from).collect())
The community is so great that even the folks at /r/playrust can't stop posting here.
Yeah, it's a pet peeve of mine. People go to a _lot of trouble_ to write the code, then won't write that necessary little bit of prose for API comments. As for examples, you can't have enough, though.
It's unfortunate that a lot of promising rust projects are mostly there to scratch someones itch and not be seriously used by someone else. Or they are way too early to be used.
&gt; Also, what do you think are those part of Boost that aren't interesting to translate to Rust because Rust already implements it, `Option&lt;T&gt;` is obvious example.
That's correct. I think "types generic over integers" is something that is in the works, but I don't have a source for that atm. **Edit**: [Tracking issue](https://github.com/rust-lang/rfcs/issues/1038), [latest RFC proposal](https://github.com/rust-lang/rfcs/pull/1657) (there have been several rejected proposals so far).
It's just so easy to publish a crate, and so hard to find the gems among the 'me too!' bargain bin.
Didn't knew xargs has this feature. Thank you!
Would you also mind participating in other projects? I'm currently attempting to write something akin to PouchDB (https://github.com/pouchdb/) in Rust and am searching for contributors. It's a lot of work.
Ok, sad that Rust is adopting a feature that servo doesn't want to use.
Nope, but I think this issue, when solved, solves this: https://github.com/brson/error-chain/issues/1 ("Some environmental variables not set!" being the primary error, and a Vec of the individual errors being the set of the secundary errors.)
The problem is that this is implemented for `&amp;mut [u8]` (allow stack buffers), `Vec&lt;u8&gt;` (just gimme convenience buffers) and `&amp;mut Vec&lt;u8&gt;` (give me both convenience and buffer reuse). But I agree that this API design could be improved, I'll be pondering on this today.
That actually sounds like something I would feasibly be able to implement. I've worked with NetworkX before, have some experience writing graph code myself, and it seems like something that can be grown fairly incrementally. If it's a port of NetworkX then it would be quite straightforward to write test cases that run the equivalent python code.
is there a place where contributors can search for libs that are activeley searching contributors?
I can definitely see specific use cases for it (e.g. linear algebra types like `Matrix&lt;4, 4&gt;`), but better macros (e.g. macros in type position, which were just stabilized!) could obviate many of them.
A Rust implementation of [Docco](https://davidwalsh.name/javascript-documentation) . Will be helpful for documentations in many projects which need to show more examples. 
wait how does this work, I'd expect a million $ in my back account rather than measly few thousand.
It works without the `Reflect` bound now. In particular, the bound on `TypeId::new` has changed from `'static + Reflect + ?Sized` to just `'static + ?Sized`.
I think the current mio architecture allows plugging those. Aio is a landmine though, bugs and undefined behavior in a lot of kernels / file systems. 
MIO has no method to make file descriptors non-blocking unless it is a socket, network stream, or pipe. So for general File IO, you can't use it. It really isn't so much a plugin as it is an Enum has allows you to pass a `RawFd` type. Which is only defined on for `unix` build environments of Rust. So effectively mio can't do async File IO on windows. 
Some basics: icalendar and vcard parsing libraries with a high level interface.
I understand what it does, I just have to develop habit using it. While thinking about it, maybe a shortcut syntax for it would be useful...
I'll toss up a crate to handle UNIX file system w/ mio. 
Looks like there is http://rust-vobject.unterwaditzer.net/vobject/, though it has been ~9mo since it was last updated, and I can't say I'm thrilled with the API.
Just the other day I was refreshing up on Python because I wanted to play around with NetworkX. I'd love for Rust to have something like this. A wrapper would be nice, but it would also be great to have a home grown solution. I wonder if we need better GUI libs first. Or maybe we could build it with SDL.
It is now*ish*. The feature is available on nightly builds of Rust, as there is more testing to fully flesh out support. [similar discussion](https://www.reddit.com/r/rust/comments/5awc5o/rustupcargo_compile_to_wasmwebassembly/) [DOM bindings](https://github.com/tcr/rust-webplatform) [Internals discussion](https://users.rust-lang.org/t/compiling-to-the-web-with-rust-and-emscripten/7627) I believe all of `std` works for everything not related to threading.
As far as I know, I am the only member of the team that has expressed a strong opinion in opposition to `?` to date. My reasoning at the time was that I didn't want to the code to contain a mixture of `?` and `try!`, and since the feature had not stabilized yet it wasn't clear that converting all the code to `?` would be worthwhile. I don't see any reason to prevent using `?` in Servo now that it's stabilized.
rust nightly can compile to wasm32-unknown-emscripten and asmjs-unknown-emscripten. WebAssembly is a standard. The webassembly code should run the same on browser supporting the standard. Right now I'm waiting support for threads on the web. Some javascript features are in development.
Yes, it has a pretty low-level API... that's why I'm asking! :-)
I think every control flow operator (`?` as well `break`, `return`, ... - and for that matter `try!`) should be highlighted using the same, highly-visible color.
I find this too be too much complexity for not enough benefit, personally.
This autumn, I am teaching a Rust programming course at my university (Osnabrück, Germany). Sadly, most of you won't really be able to follow it, because everything is in German. But maybe a few Rustaceans from Germany could be interested in it. Right now, around 50 students are actively participating :) Any kind of feedback is welcome!
What is `h`?
The function `precedence` is part of the `Operator` `impl`, but you're trying to call it on `o`, which is an `&amp;InfixToken`. One of the enum variants of `InfixToken` is an `Operator`, so you could do something like this: if let InfixToken::Operator(oper) = o { // can call oper.precedence() here } or match o { InfixToken::Operator(oper) =&gt; { // can call oper.precedence() here }, InfixToken::Operand(n) =&gt; {}, // do whatever if it's this // other matches here }
Awesome! How are your students liking it so far? Maybe you can convince some of your colleagues in Bonn to offer a Rust course as well…? ;)
Oh shit, duh. Sorry, totally misread the quoted text.
Here is the [link](https://play.rust-lang.org/?gist=eb7590a16d789dce6536afc4c7c21d4c) to playground with code and constant examples.
I see your String lesson is long over, but Unicode does in fact not have 32-bit code points: the maximum code point is 0x10ffff … and Unicode scalar values don't even have the entire range (they exclude the surrogate ranges). Otherwise, your String presentation is pretty good. I kind of envy your students to be able to learn Rust at university … sadly, I'm already immatriculated at [HSW](http://hsw-hameln.de/) in Hamelin … I would have loved being able to help explain things to them.
To test your assumption I've tried to change loop to this: for (b, j) in block.iter_mut().zip(T.iter()) { *b = P[h[*j] as usize]; } But benchmark showed the same numbers.
Holy shit YES!!! I was looking into Rust for a while and this is quite handy. I will watch this course *closely* ;)
A couple follow-up notes to anyone who cares: * I've made a cleaned-up version that is an actual tutorial, linked to from the beginning of the same page. * The Pencil web framework uses a minimalistic model similar Flask, which is much simpler and has a much shallower learning curve. If you just want to make something simple and functional, I suggest you check that out first.
`h` is an input array with arbitrary data. `P` is array in which `P[i] != P[j]` for all i != j and all values lie in range [0, 255] (inclusive). And `T` is array with values in the range [0, 63] (inclusive) with additional condition `T[T[i]] == i`. You can see example values in the link down below.
Oh very true! I didn't want to imply that all possible 32-Bit values are valid unicode symbols. I just wanted to provide something easy to think of as "unicode code point" (and 16 bits won't cut it). But maybe I'll still change the slides to avoid confusion and be more precise... I also have to admit that I'm not too familiar with Unicode either. I certainly lack understanding of some of its concepts :/
Mind moving to Essen?
Note: bold + background colors also really make these things stick out.
&gt; For critical path code you generally want to avoid iterators in Rust. They're a performance determent. You are using iterators [here](https://gist.github.com/anonymous/f0278fcb080297504024d7f1ed100da7#file-playground-rs-L8), though...
Try returning `Self` from the trait method, then add an impl of the trait for your structs. https://is.gd/8tfxwx Returning `Self` says "this method returns the type implementing this trait".
Hervorragendes Timing. Ich werd online folgen ;)
No problem. I think if someone wants to learn more about Unicode, that is the least difficult problem to grasp. It's not like popular processor architectures (or any that I know of) have 21-bit registers ☺
Luckily I record my lectures ;-) So while you won't be able to get ECTS for it, you can still watch the lectures and do the tasks to learn Rust \^_^
&gt; Osnabrück The original Oxbridge.
&gt; How are your students liking it so far? I'm not quite sure for several reasons... but overall I think they are fairly interested in it! They have to hand in their solutions to weekly tasks via GitHub; as a result they struggled a lot more with Git than with Rust in the beginning (although I even spent 2 hours trying my best to explain Git). I think only now are the tasks hard enough to challenge my students and give them a real impression of what learning Rust will be like. &gt; Maybe you can convince some of your colleagues in Bonn to offer a Rust course as well…? ;) Well... let's put it this way: I'm not a professor, not even a PhD, I am just a very lucky student and my professor allows me to do the stuff I want to do ;-) I doubt that I can convince anyone of "my colleagues" :P
&gt; I believe all of std works for everything not related to threading OR NETWORKING.
... where those 21 bits aren't even used to their fullest potential. &gt; I certainly lack understanding of some of its concepts To be sarcastic: What concepts? Really, it's just "Be backwards compatible to ASCII" and "Don't you break UTF-16".
Can we ban Gankro for trolling yet? :-)
Quite the opposite on the "in German", this might actually motivate me to blow the dust off of my German!
Ooo, that looks like something I was thinking about writing! (To be precise, I was thinking about writing community book similar to Clean code which would teach people how to design stuff in Rust, how to write idiomatically etc.) Thank you for link, I'm making bookmark and will look into it bit later.
Did you compile with `--release`?
Yes! We need more info in that! :)
&gt; I need to create quite simple application, which just performs one select on two tables, processes something and then does update/insert. Nothing fancy. Do you really need a database? Depending on the concrete use case a simple file based persistence might be enough. I had a situation where I just need to save some small amount of data and read them once in an hour or so. I started with sqlite but then I realized that it could be much simpler by using a couple of plain simple JSON files :) In fact, this was useful and lightweight for some other projects, so I came up with [rust-json-file-store](https://github.com/flosse/rust-json-file-store) :)
Thank you. I'm now going through my code base and implementing the `From` trait - which is a very nice idiom. Thank you for that. Now I need to dig in and understand exactly what the `Box&lt;Error&gt;` is doing. Error in this case is the base trait - right? 
I invite you to read this: [A relational model of data for large shared data banks](http://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf).
Is there a specific section (edit: or aspect) you like to share? 
I did the same! Apologies ; /
Ah I see :) Don't get me wrong, there are definitely very good reasons to use relational databases that are ACID! But there are also cases where it's not needed and where you can start with a good abstraction layer and just replace the persistence detail if needed (at a later timer).
 find -name '*.rs' -type f -print0 | parallel -0 untry
Of course you can ;-) Create two "collections" and iterate/filter/map/reduce/whatever over their content :) edit: [here](https://gist.github.com/flosse/cf7713847716d4d134b6fe3fc6a791f3) is a super simple example for you. But instead of using jfs directly I'd recommend to create an abstraction layer first.
Ethcore uses Rust in production for quite some time now, and they are based in Berlin.
I'm using diesel and I like it. Not sure if it's worth the effort for something this small, but once setup you get readable, type safe queries with low overhead.
If you could translate RTIMULib from C++ to Rust that would be cool. I may do it myself next summer if I have time. The plan is to translate the SenseHat API from python to Rust and it would be cool to not work around C++ for that. https://github.com/RPi-Distro/RTIMULib https://github.com/RPi-Distro/python-sense-hat https://www.raspberrypi.org/documentation/hardware/sense-hat/
Hello everyone. I want to add a CLI version of my rust program. How do I go about doing that?
A simple and nice to use graphics library. Something like rustic SFML. No, Piston is not such library. 
Have German friend, recommending.
This was discussed fairly extensively on [the RFC](https://github.com/rust-lang/rfcs/pull/243) (e.g. search for "do notation"). There's a few reasons why it was introduced without being the fully general version, which include `?` doing some conversions that make sense for error handling but maybe not in general, and fully general do notation requiring a far more complicated transformation (using closures etc.) that may actually cause significant problems for "normal" error handling.
&gt; And yet ridiculous things like Add for String somehow manage to slip into stable. At least this was prevented for `Vec`.
Oh yeah, probably. But I'm currently doing scripting by packing all the relevant modules into individual `Rc&lt;RefCell&lt;T&gt;&gt;` and making that accessible to the scripting context, which is a strategy that would work for slots/signals too, so the *best* solution could only be *at most as bad* as what I've got now. I mean, the rub with scripting is that (until something like [Rhai](https://github.com/jonathandturner/rhai) becomes mature enough to match LuaJIT in performance and/or ecosystem) whatever language you're working with isn't going to respect lifetimes *anyway*, so you're already in for a lifetime/allocation nightmare. So one can't just write off attempts to work within the confines of a nightmarish-lifetime/allocation situation quite yet. (Unless someone has a much smarter solution than I have, which is entirely likely.)
as an implementer or user of the API? As someone using the API it's so much nicer for me. I try to remember that when implementing an API...but like most, I am lazy. It would be nice if there was a tool that could scan your code and make suggestions over the surface area of your API and make suggestions to improve things.
Setup should be barely more than any other crate. You'll see the payoffs in performance.
That article deserves bags of kudos. Thanks for taking the time to put it together! Coming from a language like C#, I think the biggest hurdle after borrow checking is how to effectively wield the type system for the betterment of all mankind. It's good to have some guidelines to point people to.
I tried compiling something yesterday, and it already works with very little sweat. This project contains helpful. The author explains how to compile it in the README. https://github.com/tcr/rust-webplatform
You could create a library which generates various types of SVG charts. There's simple crates like `svg` and `simplesvg` which you can use to manually create charts from scratch, but nothing high level enough to simply create charts automatically, like how modern spreadsheet applications are able to do with just a table of basic information. You can also contribute to any part of the [Redox project](https://github.com/redox-os/). Or you can contribute to any existing library. Pretty much everyone is accepting pull requests for their crates.
I'm sure it won't be hard for IDEs (or just advanced text editors) to highlight the expression that might return early in some special way, if there will be need for it.
fair enough. Personally I would rather have an API which provides all kinds of ease of use features like that *and* has decent docs with plenty of examples. Without the examples i have to go and read the signatures and figure things out, then this would be annoying. It's the lack of examples everywhere that annoys me the most.
Some sort of event-dispatching system would be very nice to have in Rust, and I always did like signals-and-slots in C++ (Qt and Boost). 
Trying to record the last modified time of a file. It returns std::time::SystemTime. I can't figure out how to serialize/deserialize this. Using rustc_serialize currently. Anyone mind giving some assistance? Thanks in advance!
I tried to implement something like Google Charts, but current problem is a good font library to determinate text bounding boxes. Only way is throw bindings, which is not good.
Yes.
Initially I wrote the same loop as you, afterwards, I've started to experiment with iterators. In playground both loops produce essentially the same asm code. One strange point in the perf results is that one `mov` takes a lot of time compared to other instructions.
You want the /r/playrust subreddit. You should check to see what a subreddit is about *before* posting.
Yeah, I've seen strange things like that in other code too. I don't understand enough about how cache misses and pipelining affect perf's sampling. You could try a different sampling frequency to see if that affects it, or see if there are any hardware counters that give you more insight (eg cache misses). My opinion though is that you're not going to be able to make it faster without algorithm changes that allow SIMD.
Although I think I've read, that /r/playrust doesn't want server announcements either. 
No measurable improvements with unrolling proposed by you. Using gather-scatter instructions seems the best way to optimize this code, but unfortunately I don't have much experience with SIMD and asm. Also it will be a very platform specific solution.
This is a good idea - once you give them a metric, people like to improve it. It would save a lot of time for potential users, if they knew this upfront without having to browse the crate's repo.
Ah, but nothing stopping someone from writing that high-level, well-documented interface as a crate that depends on vobject.
I pretty much want to [untry](https://github.com/japaric/untry) Servo’s style crate (at least CSS parsing) as soon as Firefox is OK with requiring 1.13.
My issue isn't really upcasting, which can always be done manually eg `i64 + (i32 as i64)` but adding signed and unsigned integers together with correct overflow semantics. Eg. `i32 + u32 -&gt; i32` (should catch overflow on the `i32`) and `u32 + i32 -&gt; u32` (should catch overflow on `u32`) with all possible methods for overflow handling. I'm sure it's probably not this simple (for starters this addition isn't commutative) and I'm not even sure how I'd do it if I had direct access to the CPU flag register.
While rather ugly, I've found the following to run quite a bit faster on my machine (about -30% runtime): pub fn process_block(input: [u8; 64]) -&gt; [u8; 64] { #[inline(always)] fn add(a: &amp;mut [u8; 8], b: [u8; 8]) { for n in 0..8 { let res = (a[n] + b[n]) % 64; a[n] = res; } } #[inline(always)] fn process_eight(start: usize, input: &amp;[u8; 64], result: &amp;mut [u8; 64], indices: &amp;mut [u8; 8]) { for n in 0..8 { result[indices[n] as usize] = P[input[start + n] as usize]; } } let mut result = [0u8; 64]; let mut indices = [63, 8, 16, 24, 32, 40, 48, 56]; process_eight( 0, &amp;input, &amp;mut result, &amp;mut indices); add(&amp;mut indices, [1, 0, 0, 0, 0, 0, 0, 0]); for n in 1..7 { add(&amp;mut indices, [1, 1, 1, 1, 1, 1, 1, 1]); process_eight(8*n, &amp;input, &amp;mut result, &amp;mut indices); } add(&amp;mut indices, [1, 1, 1, 1, 1, 1, 1, 2]); process_eight(56, &amp;input, &amp;mut result, &amp;mut indices); result } compared to: pub fn original(input: [u8; 64]) -&gt; [u8; 64] { let mut block = [0; 64]; for (b, j) in input.iter().zip(T.iter()) { block[*j as usize] = P[*b as usize]; } block } As you can see I calculate the translated indices rather than using the table (there is a pattern, sort-of), and I process the data in chunks of eight. Edit: I should note the above code is horror for your icache, because it compiles to a huge sequence of loads and stores, without any loops.
I remember having the debate of how to store our configuration for a project that was starting. We knew it would be relatively small; basically a few MBs. There were a few ideas thrown around: - json - xml - custom But in fine I prevailed: *sqlite*. Why *sqlite*? - Reliable: it's already debugged, and used everywhere, so you'll probably never hit a corner case that causes it to corrupt your data, and quirks are well documented - Self-Describing: you're even provided a CLI (`sqlite3` or `sqlite4`) to explore the file on your own, and can easily query the data - Ubiquitous: there's a sqlite driver in every single programming language that you'd care to use, which means that not only you can use it within your program, but it's easy to bang together a script to update/explore it and a small Django/whatever application to provide an admin GUI - Scalable: your configuration is today a couple lines, it may grow to a couple MBs in the worst case; a custom format may start lagging (especially on updates), sqlite will continue to work (you can add indexes) - SQL: your configuration is today just a key-value store, but it's worth having constraints on column values, relational constraints, and being able to sometimes perform slightly more complicated queries. SQLite implements enough of SQL that you can have all that I'll be honest with you, to use anything else than sqlite, you need a really good reason.
Meanwhile there's people doing totally fine with redis out there
Like Uncle Bob said: the "Databases and frameworks are details!" (see also [this post](https://8thlight.com/blog/uncle-bob/2012/05/15/NODB.html)) I'd start with no DB at all during the development. At the end you know much more about your entities and use cases and are able to decide if a relational db, a no-sql db or maybe a graph db suits to your needs. update: I invite you to read this too: [A Little Architecture](http://blog.cleancoder.com/uncle-bob/2016/01/04/ALittleArchitecture.html)
Jup! Definitively! Would do it myself, actually, but I'm stressed by my masters degree and that causes me to slow down on imag already, so another crate would slow me even more down... And here was the opportunity to suggest ideas, so I did it. I would love to join a team for implementing this and offer my opinions on interface design and so on... But I guess I cannot contribute that much code because I have only little time for non-studying things.
:) well there isn't much to optimize in both versions, my version just gets slightly luckier with the optimizer. I've also seen the optimizer compile my whole thing to a loop and use separate 8 registers for the translation indices.
Why neocargo?
I expect I would. Bold orange would be nice.
You can ban me as soon as the lang/libs team stops trolling BTree :(
The disassembly shows that the bounds checks are elided anyway.
We kinda need to make debugging experience without any -O flags tolerable first (its getting there, step by step). After that adding an equivalent of -Og is essentially free.
So I was experimenting some more, and now it semi-works, when I save it runs cargo, but then I have to move the cursor a line up or down before it shows me the error. Any idea how I could fix this? I already tried `redraw`, but that isn't the solution.
I looked at Chrono for over an hour last night and can't find a way to convert from a SystemTime into a Datetime. Only thing I could find was to concert to a duration, parse into string, feed string into DateTime, which is obviously not desired. 
&gt; Type macros what do you use them for if I may ask?
Point. I'd forgotten that arguments are passed through registers, which means you can't just read a few extra fields while you build your stack trace.
I asked around when it stabilized and that was basically what everyone said. We don't use try much outside of style, and style is shared with geckolib so we would need to wait for stabilization anyway.
I'm not the author but wanted to add some links that were missing in the article. - Benchmark code is [here](https://github.com/lfairy/maud/tree/39602a075cfc14fe86964fcd2a119ce97f355a3b/benchmarks) - The other crates are: 1. [handlebars](https://github.com/sunng87/handlebars-rust) 2. [liquid](https://github.com/cobalt-org/liquid-rust) 3. [tera](https://github.com/Keats/tera) 4. [horrorshow](https://github.com/Stebalien/horrorshow-rs) As mentioned in the post, the first three creates are actually interpreters for template languages, so it's no wonder that maud and horrorshow are so much faster.
HTTP2, websockets, or, honestly working on tokio/iron.
It will certainly be interesting to see how they implement it.
Ahh, that definitely makes sense. Once again, I habitually forget to consider how much metadata the compiler is throwing out when compiling down to machine code. (I've spent over 20 years programming managed languages and, while I've dabbled slightly in C and C++, Rust is the first un-managed language I've seen to have an appealing value proposition for non-toy projects... mainly because my main interest in Rust lies in "reliability and performance are parts of UI/UX design too" thinking.)
The issue is, I would need "generate stable code with unstable" configuration. I very strongly prefer using stable release.
Well, if you don't need so huge performance and are confident that you won't cause reference cycles, it might be useful.
it took me a while to realize that this comparison was not with handlebarsjs, but with handlebars-rust (which is a much more fair comparison!)
In practice, I'm fairly sure performance is not an issue -- As far as the engine goes, data are processed using an entity-component system, meaning that the `Rc&lt;RefCell&lt;T&gt;&gt;` typically only need to be dereferenced and borrowed once per system in a frame update, followed by processing many thousands of entities in sequence. I haven't profiled it yet, though, so it depends on if runtime borrow checking actually is expensive enough that doing it 20 or 30 times a frame actually makes a significant impact. And as far as scripting goes, I don't know if there's actually any better way to mutably expose Rust objects that still preserves memory safety/mutual exclusion during mutation. As long as Lua itself doesn't understand lifetimes, runtime checks are the only option.
That’s also what `find` would do with `+` instead of `\;`. find -iname '*.rs' -type f -exec untry '{}' +
As always, I'd love to get feedback! Code, writing style, typos, whatever. This was not the post I had planned to write for Part 2, but I think it turned out ok. If someone wants to know more about the last part I cut off ("Removing the recursion"), please ask! Sadly, I can't work on Part 3 until somewhere in the new year. But I definitely intend to continue this series. 
Oh, and I just saw that handlebars.js includes a [handlebars.yy](https://github.com/wycats/handlebars.js/blob/7535e48a7969229f44489124a8ef07bd17363f06/src/handlebars.yy) file defining the (short) handlebars grammar!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/neovim] [Neovim Neomake cargo completion?](https://np.reddit.com/r/neovim/comments/5clqh8/neovim_neomake_cargo_completion/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
&gt; Other engines also let you edit a template without re-compiling the app Unfortunately that's really critical for me for example. My medium-sized website takes about 137 seconds to compile (with the latest stable version, and excluding the dependencies). And the code consists almost only in route handlers and database queries, nothing I could extract in an utility crate. I can't imagine having to wait more than two minutes every time I want to make the slightest change in the HTML code during development. High compilation times are fine if you can guarantee that "it compiles" equals "it works as expected 95% of the time", but that's not possible with the HTML/CSS/Javascript technologies. 
I agree fully it's a detail; and that it should be hidden behind a suitable abstraction (which will also make unit-testing easier anyway). As for no-sql DB or whatever; note that I was talking specifically about *configuration files* here, not databases. And I re-iterate that for configuration I'd start with SQLite over any other file format.
This will actually solve my issue. Instead of storing the time stamp I can just store the u64 (which is serializeable), and do the same conversion when I need to compare against it later. Thanks!
IMO the dream would be a template engine that could be an interpreter in debug builds and compiler in release builds. One thing I've been worrying about lately is how well web frameworks in Rust will actually take to incremental compilation, given the kind of module graphs they encourage.
I write a lot of cli tools and have been looking for a good general-purpose rust templating engine (not just html, but plaintext and others). I'm looking to generate things like config files, application skeletons, etc. Any recommendations?
Telling by his username, I guess he's a co-worker of mine. We're located rather close to you, in Bielefeld.
Is it at all possible to use a slightly more flexible code generation method that would let someone use the writev system call on the backend (so I can serve html super fast)? Then you don't even have to do the reallocations and copy for string appends. This would make it almost certainly the fastest way to serve html that I am aware of. 
Any creative way to have a `&amp;'static CStr` const?
Yeah, that should do it, all you'd need is a way to change out that string initialization in the generated code. :)
Is there a way to check in a macro if the current build is debug or release? I see a couple things in [a urlo post](https://users.rust-lang.org/t/conditional-compilation-for-debug-release/1098/7) but both of them depend on `cfg` magic, which I haven't ever tried using in macros. Additionally, unless you're doing this with procedural macros it seems like the difference in implementation between debug and release builds would be too different to give enough assurance that you're doing the same thing in both builds.
Wouldn't incremental compilation in nightly reduce this pain a lot? 
We have multiple options for stable. One is to use syntex (which is what I'd recommend), another is to use our codegen-free macros which basically just means that instead of doing #[derive(Queryable)] pub struct User { id: i32, name: String, } instead you would do pub struct User { id: i32, name: String, } Queryable! { pub struct User { id: i32, name: String, } } Codegen will "just-work" on stable soon though, as Macros 1.1 is looking like it'll be stabilized very soon.
This would require some sort of user-defined literal syntax like C++ has. Best you can do is use byte string literals: `b"byte string literal\0"` and then converting that to `CStr` using one of its constructors. Don't forget to manually null terminate it.
Sorry, I thought you meant for the development cycle. Edit and test again. You could use nightly for that, to speed up your development. Spending a few minutes compiling for a release to production doesn't seem that bad to me. Then again, we only release every 2 weeks, unless hot fixes. 
A JSP-like solution (listen to template changes, recompile to module, unload/reload module, rinse, repeat) could make for a viable solution.
&gt; Is there a trait to be generic over T, &amp;T, &amp;mut T Will `Borrow` work for you? Or maybe `From`? &gt; should AsRef&lt;T&gt; be defined for every T? While that makes sense, it's not currently possible due to coherence. It would conflict with existing blanket and reflexive impls. See [this](http://smallcultfollowing.com/babysteps/blog/2016/10/24/supporting-blanket-impls-in-specialization/#fourth-example-asref) for some discussion. The `impl A` is what you want, and `impl B` is what exists now.
`Monad` and `do` notation are a way to express control flow in a language which does not have it built-in. But Rust *does* have it built-in, and `?` is a lightweight way to integrate the `Result` 'monad' with it. (If I had more time and stamina, I'd try to work out what precise combinator in Haskell `?` would correspond to. I suspect it'd be something translating from `Either` to maybe `ContT IO` or something similar, although Rust only has local control flow, not full-blown continuations.)
I know [Ruma](https://www.ruma.io/) that implement [Matrix](https://matrix.org/) communication standard.
If the dynamic linking story was better this could be solved by having the template code in a dynamic library wrapped by an automatic reloader. Templates alone do not take long to compile, the issue is the size of compilation units (although there's a lot of work to decrease that size recently).
WOAH, thanks man, idk how my googlingz didn't find that.
`foo::bar` means "from the current module, look up the name "foo" then look inside it for "bar". `::foo` means "from the root of the crate, look up the name "foo".
&gt; I only want to push back on the idea that this is a rule Rust has, because it defintely isn't. Rust's entire value proposition is that "safe," "fast," and "productive" are not trade offs. Hm, I really didnt think about it from this point of view, maybe its exectly this basic thing I got wrong. 
The chunks of eight processing seems like a convoluted way of tricking the compiler into completely unrolling it. I think it would be much clearer and less reliant on the optimizer doing the right thing if you manually unroll it instead. This gives the same performance in my tests. Still a horror for the icache of course. pub fn process_unroll(input: [u8; 64]) -&gt; [u8; 64] { let mut block = [0; 64]; macro_rules! process_eight { ($start:expr) =&gt; { block[$start + 0] = P[input[T[$start + 0]] as usize]; block[$start + 1] = P[input[T[$start + 1]] as usize]; block[$start + 2] = P[input[T[$start + 2]] as usize]; block[$start + 3] = P[input[T[$start + 3]] as usize]; block[$start + 4] = P[input[T[$start + 4]] as usize]; block[$start + 5] = P[input[T[$start + 5]] as usize]; block[$start + 6] = P[input[T[$start + 6]] as usize]; block[$start + 7] = P[input[T[$start + 7]] as usize]; } }; process_eight!(0); process_eight!(8); process_eight!(16); process_eight!(24); process_eight!(32); process_eight!(40); process_eight!(48); process_eight!(56); block } 
He praises Rust at one point, so it's positive exposure. That's it, nothing meaningfully related to Rust. 
Yeah, you can have rustup download and maintain source with rustup component add rust-src On Linux at least (not sure about other operating systems), racer uses the environment variable `RUST_SRC_PATH` to tell it where to find Rust source. That directory is ~/.multirust/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/src for me, for stable Rust.
Awesome, thanks!
thank you!
Thank you!
That *is* better!
&gt; My medium-sized website takes about 137 seconds to compile How is it so slow...? Actually, I'm wondering if there's something to profile the compilation process and tell where it's spending most time.
Good posts. I agree that abstraction is great. However, in case of this project, the costs wouldn't outweigh the benefits. The project should be simple and has very strict deadline. I don't expect tons of features and very long development.
Thank you!
Interesting. But why you need to duplicate the struct? I believe it should be possible to use macro for both things.
I re-considered it and finally decided to use `rusqlite` (see update of the post). Part of my decision was based on /u/matthieum [comment](https://www.reddit.com/r/rust/comments/5cgv5k/which_sqlite_crate_is_the_best_and_why/d9x342p/), other part was native support for `[u8]` in `rusqlite` as opposed to stringly-typed Json. Similarly, Json uses only strings for keys, sqlite can use other types too. Anyway, thank you for your suggestion!
I didn't know either. TIL, thank you. 
I don't see anything dumb about replacing the binary.
To line up with "neovim" and "neomake", I guess.
If you really wanted chrono interop with `SystemTime`, you could achieve it through the epoch as well: let ts = UNIX_EPOCH.elapsed()?; let naive = NaiveDateTime::from_timestamp(ts.as_secs(), ts.subsec_nanos()); // you can serialize/deserialize NaiveDateTime, or use it to construct a timezone-aware DateTime&lt;Tz&gt; It would be nice if chrono provided an `impl From&lt;SystemTime&gt; for NaiveDateTime` to do that conversion. I think that'd be a reasonable feature to request in chrono. In general it seems preferable to use `SystemTime` for measuring elapsed time, and a crate like `chrono` for anything more complex, but if you have a hard requirement of working with `SystemTime`, hopefully now you have a few options. :-)
Does anyone know how to apply this in vim plugins? [YouCompleteMe](https://github.com/Valloric/YouCompleteMe#rust-semantic-completion) and [vim-racer](https://github.com/racer-rust/vim-racer) say `$RUST_SRC_PATH` variable has to be set in .vimrc like `let g:ycm_rust_src_path = '/usr/local/rust/rustc-1.5.0/src'`, so I have to include username in the abs PATH to take effect. macOS `let g:ycm_rust_src_path = '/Users/username/.multirust/...'` Linux `let g:ycm_rust_src_path = '/home/username/.multirust/...'` I want to write in a more concise way, any ideas? Thanks.
Sorry, what's wrong with replacing the binary besides the it "seems kind of idiotic"?
Is panicking a valid way to halt a thread? I have main and another looping thread communicating via channels. When main returns the channel goes out of scope, which causes the looping thread's rx.unwrap() to panic. Is this a valid way to stop a thread, ie does everything get dropped correctly? Or do I need to implement some sort of channel message to send before ending main.
Integrated Development Environment integration development?
I tried out the code given in the concrete example [here](https://doc.rust-lang.org/book/references-and-borrowing.html#borrowing) with a tiny change as follows: 10,11c10,11 &lt; let s1 = sum_vec(v1); &lt; let s2 = sum_vec(v2); --- &gt; let s1 = sum_vec(&amp;v1); &gt; let s2 = sum_vec(&amp;v2); `rustc` compiles and runs the code even though I have assigned a reference, `&amp;`, to `v1` and `v2`, in which the original code doesn't. Why is the original code written without assigning a reference to `v1` and `v2` within `foo()` (and compiles)? Am I missing something? [EDIT]: Current hypothesis after some playing around is that `v1` and `v2` are references within the scope of `foo()`, hence an additional reference is not necessary when passing `v1` and `v2` to `sum_vec()`. Let me know if I'm wrong.
Unfortunately you can't execute code from a dynamic library in safe Rust (as Rust has no way of knowing that the code inside the library is safe). 
From the examples it looks to me that the templates are just macros. In other words, if you want to interpret them at runtime you would have to embed the Rust compiler in the website.
The macros, in debug, could dynamically load the templates from disk, but compile them in the binary in release.
I already using it, but it doesn't support complex text layouts.
The screenshot and description look cool. I'm going to try this thing out :)
It's not that uncommon in web development either, for example if you're using ReactJS then any change to your templates results in a new JS file. Not exactly a binary but same effect.
&gt; I would assume a good template engine allows you to just give it some buffer that `impl`s `io::Write` (like a `std::net::TcpStream`). Previous versions of Maud actually did that! Sadly, that kind of thing didn't work out that well in practice. Having to pass the writer around made templates hard to compose, which is important in any non-trivial project. Furthermore, Iron (and other middleware frameworks) likes to take ownership of the response body, so we'd need to do some closure gymnastics to get everything to work together. I remember in a old project of mine, just writing a single template would involve `FnOnce`, where clauses, and `impl Trait`; and the resulting function signature would wrap across two lines. That kind of complexity is okay for a `HashMap` implementation, but it's way too much for view code.
The templates can include arbitrary Rust expressions though, so they must involve the Rust compiler somehow.
The description mentions the Ultimaker 2, but most of the tips should apply to any printer.
Author here. Yes, I definitely had this in mind. Most design decisions in the library relate to playing the "long game". The use of procedural macros and specialization will be great when they're stabilized in a few years. Long compile times won't matter when everyone uses incremental compilation. And so on. Given that web development in Rust is immature anyway, I don't find it a big deal to use cutting-edge features. Using Rust in production is *itself* cutting-edge. It's a risk you take for using a language that's been stable for little over a year.
1. Nightly isn't as bad as it sounds. Since a commit will never land without passing all tests, issues aren't as common as you'd think. 2. I thought this is standard practice? That's what technologies like Docker are about after all &amp;ndash; the ability to deploy something with a single copy.
&gt; IDEID OMG! What did I just do!
Handlebars, Liquid and Tera from that list should be usable for any kind of file
Handlebars, Liquid and Tera from that list should be usable for that purpose. Handebars and Liquid don't seem to allow logic in templates (correct me if i'm wrong, haven't used them) but Tera does. Other than that, it's more preference than anything. (I'm the author of Tera)
Looks like `Borrow` is reflexive, so that'll work, thanks! Still curious why multiple blanket impl on the same trait where a different associated type is used is not allowed, these can never overlap. Eg: impl&lt;I: Iterator&lt;Item = u8&gt;&gt; MyTrait for I { ... } and impl&lt;'a, I: Iterator&lt;Item = &amp;'a u8&gt;&gt; MyTrait for I { ... } The compiler rejects these I don't see how these can ever overlap. Is there a legitimate concern or just something that hasn't been come around to yet?
Why not play with macros all along the way and use yours above `include!` to allow templates' updates with some file watch? Like this, you add the missing part and keep performances.
I write Go full-time. It helped me get used to the composition patterns that are required when you lose inheritance. But after a few years of Go, it had left me wanting more features, such as a more complete type system, which Rust provided. 
Haskell
Ruby (professionally for 6+ years). Honestly, I think it made learning harder. You do not have to worry about (almost) anything while programming in Ruby, so the transition to Rust was quite painful. Did some programming in C &amp; C++ during my studies and if I would stick to this in my professional life (and not forget pointers, references, stack &amp; heap etc.), it would be much easier to start programming in Rust.
Came from C++/Python and had one semester of Haskell in Uni, which I think certainly helped and steered me in the direction of Rust, as I wanted to have a not strictly functional language but with concepts like pattern matching and the ease of use functional concepts can provide.
You're right, Rust could learn that those are separate. The issue is https://github.com/rust-lang/rfcs/pull/1672
C++, Python and Haskell. (Python still is my favorite language). Rust has a mix of features from those: RAII and strong typed pointers from C++, match (including guards) and very strong type checking from haskell, slices and good default collections from Python. I like the future rust features: associate types (more simple than high kind types) and better lifetime elision. (Also, I love compreehensions, would be fun to have something like them on Rust!) 
There are also different features than logic that can have some importance in some cases. E.g. I use Mustache for LaTeX templates and I really appreciate that it can specify alternate delimiters to `{{...}}`.
C++ and Haskell, so Rust was kind of the language I'd always wanted.
That can help isomorphic Rust web programming, that will change everything , Evil Rein of JS will come to an grinding END.
Hey Rustaceans, I've wrote this small blog post about the topic "Rapid prototyping C applications with Rust". Maybe you have some other tips related to this as well. What do you think about the concept of cargo in relation to other programming languages like C or C++? Best wishes from Germany!
Thanks, I'll have a look.
Python, C, Go, Haskell and Lua. I still write lots of Go and Python. While I've learned to read it, I have never actually written any meaningful C++ code.
Haskell, Ruby, C, D. I also had familiarity with SML. All of it contributed very well to my understanding of Rust.
Neat. Reading the discussion makes me really appreciate the technical complexity behind what appears to be trivial.
Oh, I'm very sorry about that. I scanned it at least twice. Glad to see that!
it's only a puzzle piece
Such a long list! Great experience to compare Rust with. Never thought of the relationship between Rust and Haskell before. Cool
How do I match with the Options I am getting out of a Vec&lt;bool&gt;? I am trying to do something like dummy = vec.get(0); match dummy{ bool::Some(true) =&gt; Something } But it wouldn't work at all.
I'm very much a beginner in C, but to understand you clearly you're saying is I could use rust/cargo as a cmake/makefile replacement..? How would I organize my headers then?
My primary language for the last 15 years has been Python and, using it, I got into the habit of following a hybrid imperative-functional programming style very in-line with Rust idioms. While I do have experience with other managed or interpreted languages, like PHP, JavaScript, shell script, and others, I always felt that the programming styles they favoured were cripplingly limited subsets of what Python encouraged. (While Rust may not have Python's metaprogramming capabilities, what it does have is solid and comfortable for a wide range of uses.) As for the memory management, I've played around with C, C++, and Java (mainly for courses) but, as a UI/UX-focused guy, the value trade-offs for the low-level APIs (C), risk of crashes (C/C++), or sluggish/non-native UIs (Java) never even approach being worthwhile. C++ did help prime me for Rust, however, in that I've always been paranoid about `malloc/free` and `new/delete`, so I was familiar with the manual/design-pattern version of the single-owner pattern Rust enshrines. As for motivations, while it does have its pain points, I intend to eventually develop purely in Rust for several reasons: 1. I like how the type system is being used set up a strong yet reasonably comfortable balance point between compile-time verifiability and comprehensibility to mainstream programmers. (Plus, it'll help to stop me from burning myself out reinventing pale shadows of it in unit test suites) 2. I seem to never have enough RAM and CPU time on my system. Avoiding the overhead of the Python runtime and taking advantage of how easy Rust makes it to reason about data lifetimes and overhead should help with that. 3. Given that I can't justify the cost of SSDs and I tend to have enough tabs open to end up pushing out my disk cache, anything that causes more seeking than strictly necessary (multi-file programs, files that were big enough that the only available space was fragmented, etc.) is quite undesirable. (Using Rust instead of Python is also nice for when I distribute compiled binaries for Windows users. It's embarassing to have to offer up a trivial little utility and have it be 3+ MiB after py2exe-ing, even after applying tools like [UPX](https://upx.github.io/) and [AdvanceCOMP](http://www.advancemame.it/comp-readme).) For example, I just finished experimenting with my Rust build process and, for "compile-time-checked shell script with strict reliability requirements and very nice `--help` output"-type projects, I managed to crunch a "just finished defining my clap-rs options" codebase down to 156K **including** musl-libc for fully static binaries. In case anyone is curious about point #3, here's what I used: * `lto = true` [to jettison unneeded code](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html) from dependencies. * `panic = "abort"` [to save the cost of the unwinding machinery](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html) in release builds, since the only use for unwinding in this codebase is debug-build backtraces. * `opt-level = "z"` (using a `release.sh` that `sed`s my `Cargo.toml` when given `--nightly` since I couldn't find a better way to make it conditional) * [alloc_system](https://doc.rust-lang.org/book/custom-allocators.html) (to use musl's compact `malloc` rather than the much bigger jemalloc... conditionally on a build feature I've named `nightly`.) * `strip --strip-unneeded` (probably the biggest pre-UPX savings) * [sstrip](http://www.muppetlabs.com/~breadbox/software/elfkickers.html) (knocks an extra kilobyte off the final output and doesn't appear to hurt anything) * `upx --ultra-brute` (Going from `--best` to `--brute` knocks a couple dozen kilobytes off my result and `--ultra-brute` doesn't seem to take noticeably longer on this kind of tiny codebase) (For comparison, on Lubuntu 14.04, `/usr/bin/python3.4` is 3.6MiB, not counting the standard library, `/bin/dash` is 119K not including tools like `getopt` and `cut` that scripts are likely to need, and neither of those are statically linked.)
I'm pretty sure I lowered the productivity of my high school with the sheer amount of games I wrote for those calculators. good ol' TI-BASIC was so slow that you really had to abuse builtin things to get decent drawing rates though. Nowadays everyone just has those on their cellphones though. 
I'm pretty sure that TreeView is a wrapper around a reference-counted pointer, so clone just adds a reference and returns a copy of the pointer.
 dummy = vec.get(0); match dummy { Some(true) =&gt; {} Some(false) =&gt; {} None =&gt; {} }
The only caveat in my &gt;1 year of Rust I have ever come across for using nightly is that some features may or may not make it to stable. But if you check TWiR or internals you will find what the overall plan is and judge for yourself.
It should be pointed out that neither cmake nor makefiles force you to organize your headers in one specific way. There are [*rules*](https://cdn.meme.am/instances/53180476.jpg), but a lot of projects openly violate them. 
* Bash * Perl I started learning with languages that came stock with Mandriva at the time. * C++ I was interested in KDE at the time I learned it. * JavaScript And later, web stuff. * Java And Android, later than that. * PHP Professional.
Yes that is what I wanted to say. Your header files could be organized like in other C libraries: - public headers into "include/" - internal headers somewhere into "src/..." With the gcc crate you can easily add new includes with the ".include()" function: http://alexcrichton.com/gcc-rs/gcc/struct.Config.html
Nope. See also [this RFC](https://github.com/rust-lang/rfcs/pull/1628).
Your answer is very helpful /u/zzyzzyxx! Thank you!
The only (working?) crate I know is [strophe](https://docs.rs/crate/strophe/) that wraps the C library [libstrophe](http://strophe.im/libstrophe/). I was already thinking about writing a pure rust library but then I realized that this takes too much (unpaid) time ;-)
Really cool! Rust is fantastic, but Python still is my favorite language (even being overweight ;~~)
C / Cpp / Java / Scala
Interesting to see how many people are coming from Haskell. As a Haskell user myself who is interested in Rust but hasn't had the chance to fully dive in, what is seen as the main benefit of switching to Rust? Performance? Libraries?
Just use extern crate piston_music; and it will work.
Oh - so it's not something that's implied by the HTTP/2 spec? (That's what I first assumed) I'm a fan of experiment early, but I can totally understand the hyper dev's rationale.
Well not specifically, however a single multiplexed channel would benefit from async io. Server push is also part of the spec, so that would also benefit I'd imagine.
Since it doesn't handle dependencies and when to recompile what, it doesn't scale to bigger C projects.
Right, my bad, missed this part
Python 
I have always been a Microsoft developer, so my stack was always .NET and prior to that Visual Basic. At one point I did have a qualification which included a C++ certificate for Game Development. I never found .NET to fullfil the skillset I want properly though and as such I have always sought out more interesting outlets (even though C# pays my bills). So I have jumped ship from Go in my "other languages" toolset.
We've wanted this in Cargo proper for a long time, but nobody (including me) ever got it over the finish line. If you can, you should send in a PR!
Okay this could be an optimization point 😌
Thanks! :) Yeah, `clippy` complained about `scc_strongconnect` already, because of the 8 parameters. It's definitely ugly code. But it's also wrong code, and a view into my intermediate results, so I didn't refactor it. I *did* refactor the non-recursive implementation, which indeed has a [separate struct](https://github.com/Apanatshka/dnfa/blob/cc4b5ad939882a8fa18e50371dbe90ee23f70bf1/src/scc.rs) for most of the info; as well as some methods defined on it that do parts of Tarjan's algorithm. I do need warn about this kind of refactoring though, because I saw the [same in `cargo-benchcmp` doing wonders for code readability](https://github.com/BurntSushi/cargo-benchcmp/commit/d8db46df371aebdd92fecfe2ccd475ac92dbd7cc#diff-639fbc4ef05b315af92b4d836c31b023R81), but later needed to be [partially reverted](https://github.com/BurntSushi/cargo-benchcmp/pull/10) ([example](https://github.com/BurntSushi/cargo-benchcmp/commit/7d32715c702df2dee94cb7a211d29183f333b953)) because the methods that took a `self` were harder to test. 
Java by education, Haskell and Elm by hobby. I knew enough C to shoot myself in the foot and I knew that. I also knew I didn't know manual memory management. I have just enough experience with C++ to know I don't want to get near that kind of crazy any more. So I already knew the C-like syntax, some concepts -- especially type level stuff -- but all the memory specific stuff was new to me. 
I always enjoy seeing things like this from new users of the language. It allows us to know where as a community we can focus our efforts to make it more ergonomic. You mention having had trouble with unwrapping on a `None` value and how it doesn't print anything out. Unlike an error message it's considered a panic and so those bits of information are left out. I'm glad you figured it out though! I recommend in the future using `expect` that way if it does crash you have a message so you can know where. Generally using `unwrap` isn't the best way to do it but sometimes as a coder you can guarantee that it will always have a value which is the perfect time to use it. When you were learning it what was probably the hardest part for you? I seemed like lifetimes but there were a couple of things that you seemed to have trouble with at first so I wasn't too sure.
While this is a neat idea and I applaud the creative application of cargo/rust outside of the typical use-cases, to me it speaks more to the state of the C ecosystem and general purpose build tools. It strikes me as odd that it can be easier in some trivial cases to use another language's build system than the tools designed for the job. Make and CMake both have their pitfalls and from my recent experience with CMake I wish there were a better general-purpose solution for building large and complex projects across languages and systems.
Nice! But note the log scale on the Y axis: A linear change in Y means an exponential change in popularity.
Most of my professional work has been C# to develop simple non-web systems (WinForms). But I have also used: - C for embedded work - LabVIEW for lab automation - Ladder (RSLogix5000) for industrial automation - VHDL in a research project that involved an FPGA - Matlab and, when I can, Julia, for numeric work - C++ in rare occasions for the same reason as C#
Number of active projects over 10kb in size during the period of time in question. The [main repository](https://github.com/emmanuel-keller/github-language-statistics/) has a clear explanation of this graph.
I am just about finished University, and picked up Rust for a hobby just before 1.0 release. At Uni, they introduced me to C and Java. Is definately say knowing C has made me appreciate what Rust does for us. I have also picked up C#, and have dabbled a little in Python. Edit: also vaguely competent in C++,
Yup, good for deserializing, but it's capabilities seem to make it so writing / reading attributes would have to be done manually, which is what I'll probably end up doing. So yeah, not quite the end of the world. In fact, I could make a fork of serde_xml... I got time. Thanks tho. 
That sounds incredibly nice. This was one of the major things missing when I was working on documentation for compiler plugins and the only workaround I could make at the time was patching in cross-links using javascript (eww).
Ruby, Haskell, Go Never a huge fan of Ruby's magic. Loved Haskell for a while, realized it's gone too far. Go is somewhat refreshing despite all it's obvious flaws, just sitting down and typing is nice. Just write a for loop, mutate some variables, it'll be fine. Rust is a nice inbetween place with Haskell and Go. Good type system, nice iterators, trivial to just write some straight forward imperative code when you want to.
I'm actually surprised that Rust hasn't passed Haskell yet.
&gt; I recommend in the future using `expect` that way if it does crash you have a message so you can know where. I'd rather just re-run the test case with `RUST_BACKTRACE=1`, so I don't have to come up with error messages for every condition that I think is impossible.
Python and Go. Also javascript, but that's not something I can replace with Rust yet ;).
&gt; Honestly I really wish they had sat on this operator longer This was one of the most debated changes in Rust's history; sept 16, 2014 was when it was suggested. That's over two years. I am also not sure about Option.
Glad that you asked about `lifetime`. - Consider a function which takes two arguments like `fn f(key: &amp;'a str, cache: HashMap&lt;&amp;'a str, &amp;'a str&gt;)`. This `key` can be a field in `struct`, `key` can't be inserted directly into `hashmap`. The `key` is still referenced in `struct`. The situation may look obvious, but while learning, I couldn't figure out quickly. Then I decided to stick with `String` as much as possible solved the problem. Finally made a decision, don't declare lifetime `'` at all. Let compiler infer the lifetimes. Latter `key` and `value` type was changed to `String`. - I vaguely remember adding lifetime to the second argument when the `function` returned a value with `lifetime`. The compiler error was two arguments with different lifetime can't be used. I don't exactly have the code to reproduce. - I couldn't visualize when will the variable with lifetime `'a` end. What happens when the `attribute/variable` with `lifetime` is passed across three or four layers. Since I haven't programmed with pointers before, I felt hard and reading the docs multiple times helped a bit. Probably this is just me. I have programmed extensively in `dynamic` languages. 
If you want to return a reference, Rust will only allow you to do that if the data it points to already exists before entering the function. In this case, your data is in the `World` struct which was created beforehand. You can signify to Rust that you are going to return a reference from the struct by taking self as `&amp;'a self` and returning `Option&lt;&amp;'a Room&gt;`. Sometimes you need to also specify a lifetime parameter for the function, like `fn function&lt;'a&gt;()`. You could probably have your signature as so: pub fn get_previous_room&lt;'a&gt;(&amp;self) -&gt; Option&lt;&amp;'a Room&gt; { }
Being opinionated is good to lower the barrier of entry. In my opinion, the reference implementation idea with VSCode should definitively be more advertised, even If not ready.
Returning a copy would also work.
Python, Javascript, and a bit of C. Rust has been a challenge, but I can see the advantages very clearly. 
&gt; Probably this is just me. I don't think it's just you :) Lots of people struggle with pointers, I wouldn't worry about it! Maybe you'll find comfort that Rust gave compile errors where your C++ programs would have mysteriously crashed :)
Using `expect` will still cause a panic and result in a backtrace, but you also get a custom error message. Use whatever works best for you though.
It'll happen. Rust is going to skyrocket in popularity as more and more people discover it. 
And don't forget that it allows your fellow coders (including your future self) to understand why it's presumably safe to unwrap :) foo.bar().expect("Foo is guaranteed to be barable because of Baz");
How about firefox WebIDE? Mozilla has a lot of good technology, but does not build a good ecosystem and platform, there should be outstanding architects to integrate these technologies
I come from a managed background as I work with .Net (VB more than C#). I have no prior experience with C or C++ and I didn't want to (is it all right if I said they scared me?) due to all the footguns they presented. Rust interested me back when it was pre-1.0 but the unstable ABI put me off it slightly as well as my programing inexperience. Fast forward to now, I love using Rust as a way of learning how to build things that are more efficent and easier to follow. I write in it whenever I can!
Yeah, I noticed! I opened some issues on your repo about crashes related to that config stuff that only happens on first install. Works well otherwise, very colourful too :)
Hey there, conrod author here, I'll do my best to answer your Qs. &gt; Firstly, can/should I assign a created widget to a variable. In the examples, I see that they generally use a struct with the changing values referenced by the widgets. There shouldn't be any need to do this normally - conrod widgets are instantiated within the update loop (or when input is received for non-animated GUIs) via a small amount of stack data. Any allocations or expensive calculations that might be necessary are cached into a widget graph within the `Ui` using the given `widget::Id`. I'd recommend checking out the `glutin_glium.rs` or `all_widgets.rs` examples - they demonstrate how to instantiate your widgets within the `Ui::set_widgets` stage and use them to update your application state. &gt; Secondly, can I create/destroy widgets on the fly? Widgets in conrod only exist visibly as long as they are being instantiated in your `Ui::set_widgets` stage. If you have some condition which instantiates widgets depending on an application mode like this if let Mode::TitleScreen = app.mode { /* set title widgets */ } then the widgets that are instantiated within that condition will only be visible while the `app` is in that mode. &gt; How can I set what font a block of text uses? I think Styles will work, but do I need to set up a whole style? We only just recently added support for using multiple fonts, and currently there are no nice builder methods for accessing this functionality (see [this issue](https://github.com/PistonDevelopers/conrod/issues/843)). It should be pretty simple to add, I'll do it tonight and report back here when it is published. Edit: [finished!](https://github.com/PistonDevelopers/conrod/pull/863) In the meantime, you can specify the font you'd like to use by setting the `font_id` field within the [Text](http://docs.piston.rs/conrod/conrod/widget/primitive/text/struct.Text.html)'s [Style](http://docs.piston.rs/conrod/conrod/widget/primitive/text/struct.Style.html) field. E.g. let mut text = Text::new(str_of_my_text); text.style.font_id = Some(Some(my_font_id)); text.color(some_color) .font_size(some_font_size) .set(TEXT, ui); Certainly not as nice as a builder method, but I'll try add that tonight. &gt; Finally, I have an image that I would like to use as a background. I can get that to work, but I need to use float. Is there an easier way to set that. By this, do you mean you'd like an easier way than manually setting the dimensions? One way you could do this is by setting the `Image`'s dimensions to those of the window. You can do so with the `Sizeable::wh_of` method like this: Image::new().wh_of(ui.window).set(IMAGE_ID, ui); This should auto-size the image so that it fits to the dimensions of the window. Let me know if I misinterpreted your question! Edit: I should have clarified, `wh_of` is shorthand for `width_and_height_of`, and is a method provided by the Sizeable trait. Both the [Positionable](http://docs.piston.rs/conrod/conrod/trait.Sizeable.html) and [Sizeable](http://docs.piston.rs/conrod/conrod/trait.Sizeable.html) traits have a lot of useful methods for positioning and sizing widgets - I'd recommend getting familiar with them as in many cases they can reduce the need to manually specify absolute positions or sizes at all. Also, feel free to post these sort of questions as issues to [the repository](https://github.com/PistonDevelopers/conrod) - I find it can be a little more searchable for other users that way. Hopefully though we can improve our documentation soon to the point where people don't have to search so hard for answers to these questions! Hope this helps!
How does it differ from `readelf -S &lt;program&gt;`?
Thanks, I see the bit I was missing in the fonts. Didn't think to access the style property like that. I had a bit of a play with the update loop and had some success. How can I force an update inside the event loop? I have a button that I want to hide when it is pressed. Of course it doesn't refresh until another update is triggered. On the image front, I mean I had trouble overlaying text on it. Is there a z-index somewhere that could help? I might try again and add a bug report. 
That's pretty standard for piston crates. https://github.com/PistonDevelopers/glutin_window/blob/master/Cargo.toml
Pre-shuffling the `LIN_TABLE` entries so you need one level less of indirection gives a nice boost: Before: running 6 tests test streebog256_10 ... bench: 182 ns/iter (+/- 34) = 54 MB/s test streebog256_1k ... bench: 18,033 ns/iter (+/- 778) = 56 MB/s test streebog256_64k ... bench: 1,148,692 ns/iter (+/- 122,360) = 57 MB/s test streebog512_10 ... bench: 181 ns/iter (+/- 2) = 55 MB/s test streebog512_1k ... bench: 18,013 ns/iter (+/- 887) = 56 MB/s test streebog512_64k ... bench: 1,147,861 ns/iter (+/- 3,413) = 57 MB/s After: running 6 tests test streebog256_10 ... bench: 146 ns/iter (+/- 1) = 68 MB/s test streebog256_1k ... bench: 14,365 ns/iter (+/- 14) = 71 MB/s test streebog256_64k ... bench: 918,655 ns/iter (+/- 1,129) = 71 MB/s test streebog512_10 ... bench: 146 ns/iter (+/- 7) = 68 MB/s test streebog512_1k ... bench: 14,368 ns/iter (+/- 60) = 71 MB/s And then, you can unroll the loop once like this: for i in 0..4 { for j in 0..8 { let b = h[2*i + 8*j] as usize; buf[2*i] ^= SHUFFLED_LIN_TABLE[j][b]; let b = h[2*i+1 + 8*j] as usize; buf[2*i+1] ^= SHUFFLED_LIN_TABLE[j][b]; } } That gives me: running 6 tests test streebog256_10 ... bench: 138 ns/iter (+/- 6) = 72 MB/s test streebog256_1k ... bench: 13,570 ns/iter (+/- 684) = 75 MB/s test streebog256_64k ... bench: 864,701 ns/iter (+/- 32,735) = 75 MB/s test streebog512_10 ... bench: 137 ns/iter (+/- 1) = 72 MB/s test streebog512_1k ... bench: 13,548 ns/iter (+/- 83) = 75 MB/s test streebog512_64k ... bench: 863,499 ns/iter (+/- 2,775) = 75 MB/s 
[removed]
You're looking for /r/playrust
If there are any remaining questions about lifetimes, feel free to ask for more details here or on IRC. :)
&gt; where your C++ programs would have mysteriously crashed My experience while learning C pointers was like: SIGSEV
The alternative seems to be the proliferation of more methods, which has its own costs. I think I prefer sticking with one concept ("slicing") and one method ("copy_from_slice"). They tie together nicely IMO. It works well in other places too, for example, if `s` is a `&amp;str` and `i` lies at a UTF-8 boundary, then `s[i..].chars().next()` gives you the codepoint encoded at position `i`.
smells like a systematic error to me tbh.
Haskell has some serious academic inertia - for real world code, it might have passed it or not. This metric here is really not accurate or representative.
I work in both Haskell and Rust. My feeling from both communities is that Rust has surged ahead already. I just found the charts surprising, though I'm not exactly sure what the numbers mean.
You can get the `min` effect using the zip iterator: for (dst, src) in dst.iter_mut().zip(src) { *dst = *src } Not as simple as built-in method, but not overly verbose. And you can easily modify it to `clone()` or add a limit (`.take(limit)`). Maybe a better idea would be to add an extension method (called `copy` or `clone` etc.) on `Iterator&lt;Item=(&amp;mut T, &amp;T)&gt;`?
The thing with slices is that AFAIK they use some more efficient (hardware) implementation for copying.
Imagine a CMS, where users can create their own templates.
It's maybe kind of a red flag that `current_room` and `previous_room` are of type `Room`. If all your rooms live in the `rooms` vec, then having these other members of type `Room` implies that they're _copies_ of rooms from the vec, rather than references to some shared set of rooms. That might be fine if rooms are small and immutable, but as soon as you start trying to make mutations having those copies is going to cause problems. (Edit: It sounds like I read this wrong. /u/SavishSalacious didn't intend them to be copies, but actually unique owned values. More in the thread below.) That said, making `current_room` and `previous_room` references to rooms is also going to cause problems with the borrow checker. In general, it's very-tricky-bordering-on-impossible for a struct to hold references to another part of itself. As far as the compiler knows, doing that would imply that the `rooms` vec is _permanently_ borrowed, and you won't be able to e.g. insert anything into it. (And to be fair to the compiler, doing that would be totally unsafe, and it's right to complain. If you have a reference to something inside a vec, and then append something to the vec, the vec could reallocate and turn your reference into a dangling pointer.) There are two common workarounds to this sort of issue. One is to put the rooms inside `Rc` shared pointers. Then you can hold `Rc` references to rooms in your vec and still append to the vec. (Though if you want to mutate the rooms you need something like `RefCell` too, which is a little annoying.) The other workaround is to have `rooms` store the only copy of every room, and then have `previous_room` and `current_room` refer to them by _index_. Then when you need to return references to those rooms, you use the indices you're storing, and the vec is borrowed only temporarily while those references are alive. (It might be more convenient to use a `HashMap` instead of a `Vec`, if you plan on ever deleting rooms.)
&gt; It's maybe kind of a red flag that current_room and previous_room are of type Room. The concept here is that a player will need to know the current room they are in and the previous room they came from. All worlds contain a vector of rooms, each room contains description, title and a vector of items. The idea was that as you traverse the rooms I will store the current room you are in and the previous room you came from, by removing the room you are going into (via index) and storing it as the current room and moving the current room to the previous room. &gt; That might be fine if rooms are small and immutable, but as soon as you start trying to make mutations having those copies is going to cause problems. Once you define a room, so you set its name, description and items and monsters - you cannot mutate the room. Which is a lie of sorts. As you enter a room there may be items or monsters, as you collect or fight these are removed from their appropriate vectors so that if you leave and come back in you cannot collect or fight the same monster again. This is why room does not implement copy or clone. &gt; That said, making current_room and previous_room references to rooms is also going to cause problems with the borrow checker. I don't make them references to the room in the vector, I literally pop the room off the vector at the index and assign it to current room as stated. So I don't think I'll have a problem here. The only issue is that `Option&lt;Room&gt;` is a life time for previous room, where it can be `None` or a `Room` The only issue that I pointed out I could not get around is the concept that previous room apparently has to return a reference to the room stored in the struct. As stated as you go to Room A from Room B you are setting Room B as the previous and A as the current. The issue now is: **If I go to room A from a vector of 60 rooms, theres now 59. Which isn't such a big issue, but the issue comes in when I go to room D, I can go back to room C but not B or A because they have been popped off the vector and basically erased as I traverse down more rooms.** The solution I was thinking is to store previous rooms as a vector, this allows me to go back and forth, but then the question is why not just use the vector of rooms and store a reference of the room as the current or previous room. The issue with that is that monsters and items in the room are mutable. Issue after issue. Any advice you can give would help. 
&gt; why not just use the vector of rooms and store a reference of the room as the current or previous room This is the assumption that /u/oconnor663 made about what you were ultimately trying to do-- their advice is in the context of the `World` owning `Vec&lt;Room&gt;` and `current_room` and `previous_room` being references to items in `rooms`.
If you don't mind me asking, why statically link musl-libc, especially given your obvious desire to limit binary size. Do you have to support both glibc and musl systems?
I just thought the same :)
/u/nikomatsakis did you consider unifying `Reducer` and `Folder` into one trait? Or at least provide some default impl so that one needs only to define one of them.
For **slices** it does, Rust even has a codegen test that makes sure it's a memcpy (at least for slices of bytes). Using copy_from_slice seems just as good to me though, even if it requires some arithmetic to slice the inputs. Not being a slow copy without optimization can be a benefit too.
Thanks for the response. I asked because I am using mac OS, that does not come with GCC. Instead, it seems like they provide a fake "gcc" binary that calls clang. Of course, cc is also available!
if you set CC=clang then it should just pick it up, i thought.
/u/nikomatsakis, you write some of the most accessible technical writing I've come across without glossing over important details or "dumbing it down". Big thanks, and please keep it up.
I didn't even have to do that, just worked out of the box. Thanks!
Sure! When I learned myself a little Haskell, some dormant mathematical part of my brain lit up, but I really couldn't think of anything to do with it. Whereas Rust is much more obviously a real-world language.
glad to see another one who came from PHP :)
Are there docs hosted for the compiler internals? I was looking to play around with MIR passes for ToC. It seems like 90% of the ToC work can be done re-directing GOTO's to the labels within a function's body.
Why not just write a free function that does what you want? It doesn't seem like it'd be a lot of code.
&gt; why not just use the vector of rooms and store a reference of the room as the current or previous room Yes, this is what I want to suggest. Popping off unique owned `Room` objects is clever, but it isn't going to work when multiple different types of things in your game need to refer to the same room. (Many rooms might be adjacent to each other. Monsters and players need to be able to talk about the room that they're in. Etc. etc. It sounds like /u/SavishSalacious has already run into some of this.) Though like you've noticed, using actual references for this is going to run into confusing and unsolvable lifetime issues. A reference into a `Vec` is the same as a promise that that `Vec` will never change. Regular `usize` indices, or `HashMap` keys, or `Rc` pointers, are all possible workarounds for that problem.
Excellent, many thanks for taking the time. I'll check out the issues soon.
RC? I know what a hashmap is, but whats an RC?
A "reference counted" pointer, similar to a `shared_ptr` in C++. It's a big topic, but there are a couple good starting points about how to use them in the docs: - https://doc.rust-lang.org/book/choosing-your-guarantees.html#rct - https://doc.rust-lang.org/std/rc/
thanks you 
Yup these are the two reasons I recommended it.
Not officially. Manish hosts some on his github.
 let a: [i32; 10] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]; let b = (&amp;a[..4]).clone(); println!("{:?}, {:?}", a, b); works. You can do `a[..4].as_ref()` instead of `(&amp;a[..4])`, to taste. I don't know why `a[..4].clone()` doesn't work. Anyone want to hazard a guess?
I agree. Furthermore, I think it's better for the reducer to have access to the intermediate state, not only the final result. For example, the [Kahan summation algorithm](https://en.wikipedia.org/wiki/Kahan_summation_algorithm) uses an accumulator to keep track of the error so far. We can get a more accurate result if the reducer takes this accumulator into account. I think it's worth taking a look at /u/edwardkmett's library [reducers](https://hackage.haskell.org/package/reducers-3.12.1/docs/Data-Semigroup-Reducer.html), if you haven't already. He observes that consumers can be modeled as semigroups with a canonical conversion from the input type. The "fold" operation, then, is no more than these two existing operations fused together. On [porting this idea in Rust](https://github.com/lfairy/origami), I found that it models the relationship between owned/borrowed types really well. (Paging /u/nikomatsakis in case he doesn't see this)
Cheers!
That's awesome--I didn't realize that could act as a static method rather than an instance method in that case. Thank you.
Not all things that are foldable are reducible: you cant reduce immutable slices into a Vec. Not all things that are reducible are foldable: if the type has no effective "zero" value, then you cannot initialize an accumulator without using a value from the sequence itself. Or to put it in a more mathy way: Folding works for any type that can be mapped to a monoid. Reducing works for any type that is a magma. Neither of these completely subsumes the other.
This reddit is about Rust, The Programming Language. /r/playrust is about the game.
Not knowing all the context, and references being a bit limiting sometimes, if you have issues passing references or having a self referential structure, you could also pass/reference the same value with an rc/arc or use an index number...
What is the problem? Your code runs, it appears to do what you intended (probably?), it's short.
Only thing I can think of is read line might be tacking on a new line character causing the comparison to fail. Using the trim() function on your strong might fix your issue. Your code looks correct otherwise though I'm not next to my computer to check.
Rust has two types of strings ~~and you're probably running into problems there~~. You can read more about the two types of strings [here](http://www.steveklabnik.com/rust-issue-17340/). For your reference: let mut input = String::new(); // This is an owned String if input == "Hello" { .... } // the string "Hello" is of the type &amp;str. edit:: apparently it shouldn't affect the comparison! Thank you /u/pas_mtts for the correction. 
yeah, sorry! When the program reads the line it does not go through the if statement. I put in an else statement to see if it just wasn't reading it all but it was. when putting in "Hello" it just outputs the else code. 
Yes, you are exactly right. OP, you could have printed out `input` to see what was going wrong! Like this: use std::io; fn main() { let mut input = String::new(); io::stdin().read_line(&amp;mut input); if input == "Hello" { println!("Hello to you too!"); } else { println!("I expected you to say hello, but instead you said this: {:?}", input); } } ----------------- I expected you to say hello, but instead you said this: "Hello\n" 
No you don't need that for comparing String and &amp;str, the String type implements PartialEq&lt;str&gt;, so "==" should work without you having to do anything. https://doc.rust-lang.org/std/string/struct.String.html
I don't know what the OP's concern about tokio-curl is, but my experience is that tokio-curl does not seem to take advantage of futures. The curl API is to register a callback for when the response comes back, and this API is exposed verbatim by tokio-curl. Looking at it myself I couldn't figure out how to use it with future combinators.
I have no problem with writing it. I was just wondering, whether it already exists in some crate. If not, I might create such crate.
Interesting, thank you!
for your information, here is a link to the `trim()` documentation: https://doc.rust-lang.org/nightly/std/primitive.str.html#method.trim
Careful, though; AFAIK the newline isn't guaranteed before an EOF.
FWIW, the example you give is basically guaranteed to be inlined anyway, and normally it's better to let the compiler decide in such cases.
OCaml, Haskell, shell scripting (with a bit of sed and awk), Ruby, Python, Javascript, C, C++, Java. But mostly shell scripting :) I'm familiar with C++ stuff (RAII, smart pointers, move semantics) but I only really understood modern C++ after learning Rust.
&gt;I'm basically only doing this to avoid a closure Writing `.all(SfvRecord::validate)` would do the same thing. Also, `.all(|record| record.validate())` is trivial for the compiler to optimize away, and it will do so. You can trust the compiler more.
I wrote the (incorrect) rust function #[no_mangle] pub extern fn getValue(ptr: *mut MyStruct) { cast(ptr).getValue(); } that I could call in c as extern double getValue(MyStruct * ptr); // ... printf("%f", getValue(&amp;s) and get gibberish values. Can anyone explain to me what was getting printed? I am not particularly familiar with c, nor rust.
It makes me wonder about the speed difference between Rust and C++ for converting strings to numbers :-) 
There's an optimisation in GCC called inline-functions-called-once. I assume LLVM has the same optimisation. (which should work even without the `#[inline]`
Could you expand a bit more on how vec-arena differs from existing arena crates, such as [typed-arena](https://crates.io/crates/typed-arena)?
The optimizer should be smart enough to do it for you. If the function is only called once, and it's not on a very cold path, the code size disadvantages of inlining go away, so there's no reason for it to not do it.
Your vec-arena crate appears to be identical to "stash", https://crates.io/crates/stash. Which is nice, very useful for building these kinds of things. I just would have liked if the struct was generic over the index type, same like petgraph does it. Usize is unnecessarily big for many cases.
that reminds me of using array indices to simulate pointers back in my basic days :) (or, more recently, [this code](https://github.com/martindemello/updawg/blob/master/dawg.h) i copied from graham toal which defines a dawg using array indices rather than pointers so that they can be packed into 21 bits)
`foo.validate()` is just sugar for `SfvRecord::validate(&amp;foo)` so it makes sense that it works. Sometimes though, for the sake of brevity, I wish Rust had currying/partial application, but I think that'd be a little too Implicit to be compatible with Rust's philosophies, plus something something higher-kinded types.
There's a couple distinctions to make here, actually. There's function items (or function rvalues) and function pointers. The former coerce to the latter, kind of how `&amp;()` coerces to `&amp;Any`, but the distinction is that function items are zero-sized and called like a static function, which means they can be inlined, whereas function pointers are (obviously) pointer-sized and have a dynamic value and thus cannot be inlined--they have to be invoked through the normal channels. The other is that closures, at least at one point, could be `Copy` if their captures were `Copy`. However, because of coherence issues, they didn't implement `Clone`, so you had this weird behavior where you could copy a closure value, but calling `.clone()` on it would either give you a "method not found" error or cause an ICE. I guess instead of deriving `Clone` for these closures, they just decided to remove the automatic `Copy` impl.
Does the palindrome imply that the absolute value of Bitcoin core's stability is equal to Rust's stability? :P
We've written a linked list, but is it easy to use?: fn main() { let mut l: List&lt;i32&gt; = List::new(); l.push_back(1); l.push_back(2); l.push_back(3); l.push_back(4); { let mut inode = l.head; loop { if inode == NULL { break; } let node = &amp;l.arena[inode]; print!("{} -&gt; ", node.value); inode = l.arena[inode].next; } println!("END"); // from my understanding, in C++, the above could look like: // for (auto node = l.head; node != 0; node = node-&gt;next) { // printf("%d -&gt; ", node-&gt;value); // } // printf("END\n"); } // the borrow checker just kills us here // { let mut inode = l.head; loop { if inode == NULL { break; } let node = &amp;mut l.arena[inode]; mutate_node(node); inode = l.arena[inode].next; // error: cannot borrow `l.arena` as immutable becase it is also borrowed as mutable } } { let mut inode = l.head; loop { if inode == NULL { break; } let node = &amp;l.arena[inode]; if node.value == 2 || node.value == 3 { l.remove(inode); // cannot borrow `l` as mutable because `l.arena` is also borrowed as immutable } inode = l.arena[inode].next; } } } fn mutate_node(node: &amp;mut Node&lt;i32&gt;) { node.value += 1; } If we ignore the borrow checker, we still have to treat nodes and "node pointers" (indices) differently which is a bit annoying in my opinion. 
This one isn't really an arena - it's a more convenient API around `Vec&lt;Option&lt;T&gt;&gt;`.
I found it, it's peek!([some_parser])... I guess I'm blind :p
It is certainly possible to create a future from tokio_curl. I've written a small example (for sake of simplicity it's using return impl) https://gist.github.com/833d034f1671f83c47cd5a100e786dd0
For an API server, you might want to look at Rustless (https://github.com/rustless/rustless) which is built upon Iron. If you want to roll your own, then with Iron, you would need to create a Chain with a BeforeMiddleware which would read and validate the header: http://ironframework.io/doc/iron/middleware/. Iron uses Hyper, which has typed headers: http://hyper.rs/hyper/master/hyper/header/index.html You can use a macro to define what X-API-KEY is, read that via the BeforeMiddleware trait and then validate that accordingly. Something along the lines of: #[macro_use] extern crate hyper; header! { (XApiKey, "X-API-KEY") =&gt; [String] } struct ValidateHeader impl BeforeMiddleware for ValidateHeader { fn before(&amp;self, req: &amp;mut Request) -&gt; IronResult&lt;()&gt; { match req.headers.get::&lt;XApiKey&gt;() { Some(string) =&gt; /* validate here */ , None =&gt; Err(/* no header*/) } } } fn main() { let mut chain = Chain::new(); chain.link_before(ValidateHeader); Iron::new(chain).http("localhost:3000").unwrap(); } 
The infamous `Slab`. There's also the `slab`crate on crates.io.
Python first. Amazingly easy but prone to a lot of bad programmer habits. Then I moved to C++. It felt fast (like, 15x faster, lel) and most of the problems with regards to runtime type-checking was gone. But when I started creating interconnected networks (and 1000+ lines), pointers became a PITA. Then Rust happened.
`typed-arena` can only allocate space for new objects - it can't remove objects to reuse their space. It's implemented as a list of vectors with fixed capacity. When inserting an object into `TypedArena`, it will try to append it into the last vector. If the last vector is full, a new vector with twice the capacity of the last one is created and appended to the list of vectors. In other words, on allocation there won't be costly `memcpy`s, only new `malloc`s. If we assume the cost of `malloc` is `O(1)`, then the cost of allocation is strictly `O(1)` (not amortized). `vec-arena` uses only one vector and can remove objects to reuse their space. When inserting an object into `Arena`, it will try to find an empty slot and reuse it. If it doesn't exist, the object will be appended to the vector. In case the vector is full, it will reallocate and possibly `memcpy` old data into newly allocated buffer. Since there is a `memcpy` involved, the cost of allocation is amortized `O(1)`. There is another important difference. Once you allocate an object using a `TypedArena`, you can't retrieve it again. But if you allocate an object using `Arena`, you will be able to retrieve it by index. **TL;DR:**`typed-arena` provides very fast allocation only, while `vec-arena` provides allocation, deallocation, and accessing objects.
I'd say it's scripting. It's a small piece of code, designed to do a simple task.
I presume the statement about 'without ever having to leave your Mac!' would actually be true in this case?
Yes. Except `slab` is a fixed-size buffer, which never grows. Now I'm curious, why is it infamous?
I don't know whether you are the author, but it could've been written like this: let path = match args.value_of(path_arg_name).expect("You didn't supply a path"); instead of let path = match args.value_of(path_arg_name) { Some(path) =&gt; path, None =&gt; panic!("You didn't supply a path"), };
It's because it implemented over and over again with different names. I'm pretty sure that the Slab crate will grow on demand if you ask. 
I heard that async postgres driver is in development (see sgrif's comment here https://users.rust-lang.org/t/announcing-mysql-async-tokio-based-asynchronous-mysql-driver/7952/4)
Isn't said bundle enormous though?
It's not as bad as you think - the bundler strips out the stuff you don't use. That said it depends on how many libraries you use. I think this is the standard one (I think the python docs links it), but not sure, please check yourself if you need to use it: https://cx-freeze.readthedocs.io/en/latest/ 
Oh, you're absolutely right. My bad. Yeah, the problem is that there is no way to slice a constant-size array as a constant-size array (like, the compiler doesn't know that the size of `a[3..7]` is 4). I'm pretty sure this is essentially technically possible without new language features, but it would require const functions to be more ubiquitous (although that itself might require more language features, const functions are quite restrictive at the moment). `GenericArray` could do this in theory today, but I don't think it has an implementation of it.
Yep, that's exactly why I put "scripting" in "scare quotes." I don't know what to call this, and it's the kind of thing historically relegated to "scripting language" as a "scripting job". ¯\\\_(ツ)_/¯ But I agree, this isn't, strictly speaking, scripting!
**TL;DR:** Type in ¯\\\\\\\_(ツ)\_/¯ for proper formatting Actual reply: For the ¯\_(ツ)_/¯ like you were trying for you need three backslashes, so it should look like this when you type it out ¯\\\_(ツ)_/¯ which will turn out like this ¯\\\_(ツ)\_/¯ The reason for this is that the underscore character (this one \_ ) is used to italicize words just like an asterisk does (this guy \* ). Since the "face" of the emoticon has an underscore on each side it naturally wants to italicize the "face" (this guy (ツ) ). The backslash is reddit's escape character (basically a character used to say that you don't want to use a special character in order to format, but rather you just want it to display). So your first "\\_" is just saying "hey, I don't want to italicize (ツ)" so it keeps the underscore but gets rid of the backslash since it's just an escape character. After this you still want the arm, so you have to add two more backslashes (two, not one, since backslash is an escape character, so you need an escape character for your escape character to display--confusing, I know). Anyways, I guess that's my lesson for the day on reddit formatting lol ***CAUTION: Probably very boring edit as to why you don't need to escape the second underscore, read only if you're super bored or need to fall asleep.*** Edit: The reason you only need an escape character for the first underscore and not the second is because the second underscore (which doesn't have an escape character) doesn't have another underscore with which to italicize. Reddit's formatting works in that you need a special character to indicate how you want to format text, then you put the text you want to format, then you put the character again. For example, you would type \_italicize\_ or \*italicize\* in order to get _italicize_. Since we put an escape character we have \\\_italicize\_ and don't need to escape the second underscore since there's not another non-escaped underscore with which to italicize something in between them. So technically you could have written ¯\\\\\\\_(ツ)\\\_/¯ but you don't need to since there's not a second non-escaped underscore. You ***would*** need to escape the second underscore if you planned on using another underscore in the same line (but not if you used a line break, aka pressed enter twice). If you used an asterisk later though on the same line it would not work with the non-escaped underscore to italicize. To show you this, you can type _italicize* and it should not be italicized.
Absolutely true; I've done it in the past. But two points: 1. Doing that from a Mac (not inside a VM) is, as far as I can tell, basically impossible. And since I don't have Python installed on my Windows VM… 2. cx-freeze is worth admiring (seriously), but it's _way_ more work than just typing `cargo build --release`. It's actually way easier to build cross-platform *executables* with something like Go or, once you know where to snag the libraries, Rust. None of that is a critique of Python, which is still one of my favorite languages.
 impl&lt;T&gt; Index&lt;usize&gt; for List&lt;T&gt; { type Output = Node&lt;T&gt;; #[inline] fn index&lt;'a&gt;(&amp;'a self, index: usize) -&gt; &amp;'a Node&lt;T&gt; { &amp;self.arena[index] } } impl&lt;T&gt; IndexMut&lt;usize&gt; for List&lt;T&gt; { #[inline] fn index_mut&lt;'a&gt;(&amp;'a mut self, index: usize) -&gt; &amp;'a mut Node&lt;T&gt; { &amp;mut self.arena[index] } } fn main() { let mut l: List&lt;i32&gt; = List::new(); l.push_back(1); l.push_back(2); l.push_back(3); l.push_back(4); { let mut node = l.head; loop { if node == !0 { break; } print!("{} -&gt; ", l[node].value); node = l[node].next; } println!("END"); } { let mut node = l.head; loop { if node == !0 { break; } mutate_node(&amp;mut l, node); node = l[node].next; } } { let mut node = l.head; let mut next: usize; loop { if node == !0 { break; } next = l[node].next; if l[node].value == 2 || l[node].value == 3 { l.remove(node); } else { l[node].value += 1000; } node = next; } { let mut node = l.head; loop { if node == !0 { break; } print!("{} -&gt; ", l[node].value); node = l[node].next; } println!("END"); } } } fn mutate_node(l: &amp;mut List&lt;i32&gt;, node: usize) { l[node].value += 1; } Fair enough, but when one wants to pass a node to a function they would have to pass the list as well, i.e 1 more argument. PS: love the !0 (```if node == !0 { ... }```) to represent the null node =) 
Sidenote, i really hope we can improve cross compiling. I have all but given up on it, as i have wasted significant time _(day+)_ and have little to show for it. For reference: I was trying to compile OSX -&gt; Linux, and the source code used hyper to make some https calls. So, i needed to install openssl _(at least, i believe)_, and because i wanted to make a standalone binary, i needed musl. After much headache, i finally figured out how to get musl on my mac and instruct rust/cargo how to locate musl, and openssl. I then come to find out my brew installation of openssl was pointless, because i needed to somehow compile it by hand with support for linux. In the end i gave up. All i wanted to do was make a https call with hyper, fwiw. I can't ask our devs to go through the same hell i went through, it's easier and more reliable just to set up a compile server in the back office.. but still, considering how easy it is to do this in Go, i was a bit embarrassed in the office i was trying to push Rust into. I'd appreciate any tips/etc, but my main point of this post was just to express a pain point for a young user of this side of things. **edit**: Due to this being a _(imo)_ "problem with Rust and/or my usage", i figured i should take the time to make a post. I've done that here: https://www.reddit.com/r/rust/comments/5d2uqt/cross_compiling_from_osx_to_linux_with_openssl_how/
Looks like a copy/paste error to me, they stripped the match body off the end but forgot to remove the keyword from the beginning.
Thank you, I wasn't sure how to report it since all I had was a patch against an existing project.
It occurs to me... I can't borrow again mutably because the HashSet.get is going to hold an immutable reference to the HashSet. I never intend to remove items from the HashSet, so I guess what I need is some kind of HashSet (or wrapper with some kind of unsafe) which can return a reference without keeping the immutable reference. I have managed to get around the mut borrows by splitting the mutable insert from the immutable get, but I am going to run into this next. Does anything like this exist? Even a kind of insert-only Vec with these properties would be usable, although I'd have to keep a separate HashSet with references into it, which seems less efficient...
It probably depends on what you want to learn... I don't think Go introduces a new programming paradigm. Rust certainly does introduce very innovative programming concepts (borrowing, lifetimes), but I am not sure if you could call that a new paradigm (borrow oriented programming? :P).
I haven't verified it yet, but I was recently looking at [this Dockerfile](https://github.com/clux/muslrust/blob/master/Dockerfile#L30-L42) for compiling openssl with musl. But I think build-your-own-openssl is the best [musl+openssl](https://github.com/sfackler/rust-openssl/issues/434) story today. Of course, if all you want is to make https calls, you might now take a look at the recent first release of [`reqwest`](https://github.com/seanmonstar/reqwest) which builds on top of `native-tls` to avoid needing openssl on OSX.
&gt; Wait, why would it mean that? Well, as you say &gt; They're just not installed by default, Given that the friend is not super-technical, assuming that they have a particular programming language installed is a bad assumption.
Ah, sorry, you're right; I reacted reflexively. :)
&gt; i really hope we can improve cross compiling It's on the agenda for sure.
Ah yes I missed that, the `match` keyword in the first snippet is probably a copy/paste error indeed, it's a syntax error.
The entry API does what you want: `path_pool.entry(path).or_insert(path.to_owned())`
Got a good link? I'd love to take a gander at some point.
As a Go dev: Go is a "get shit done" language. For the level of safety it offers _(more than dynamic languages, way less than Rust)_, it offers a nice compromise between Safety and Performance. However, Go is boring. It introduces pretty much nothing new. Rust however introduces quite a bit of safety. Not a new paradigm perhaps, but definitely some different ways to think about problems, and solving them safely.
Why do the particulars matter? It looks like the rust function isn't returning anything and yet something is printed. Anyways: pub struct MyStruct { first: f64, second: f64, } fn cast(ptr: *mut MyStruct) -&gt; &amp;'static mut MyStruct { unsafe { assert!(!ptr.is_null()); &amp;mut *ptr } } pub fn getValue(&amp;mut self) -&gt; f64 { // do some stuff self.first / self.second }
[deleted] ^^^^^^^^^^^^^^^^0.0216 &gt; [What is this?](https://pastebin.com/64GuVi2F/18649)
&gt; Why do the particulars matter? Well, your question is about "what happens when I mess up this edge case," so knowing the full information is just generally helpful. Anyway. As far as gibberish being printed. I would expect that this is "undefined behavior", and so it's not possible to say what it is in a general sense; the compiler is allowed to do anything. In your specific case, something may happen, but something totally different may happen in another case. Which is not super satisfying... I think the answer is "whatever happens to be in the rax and rdx registers, interpreted as a floating-point number", which would depend on a _ton_ of things. I am not 100% sure, though, that's just an educated guess. This `cast` function is _extremely_ unsafe, by the way...
Ah, geez, I looked through the `cargo` repo yesterday and only saw an open feature request issue. Guess that's an evening wasted :P
Naw it's all good! I mean, that PR is a re-do of an older PR, getting the feature upstream has taken a while (and hasn't even landed yet!) so this helps people out in the meantime!
For UPX? The website is https://upx.github.io/ but you can just `brew install upx`. (The great thing about UPX is that it's in [pretty](https://github.com/Homebrew/homebrew-core/blob/master/Formula/upx.rb) [much](https://chocolatey.org/packages?q=upx) [every](https://packages.debian.org/jessie/upx-ucl) [package](https://www.archlinux.org/packages/community/x86_64/upx/) [repo](https://fr.rpmfind.net/linux/rpm2html/search.php?query=upx) [of](https://software.opensuse.org/package/upx?search_term=upx) [note](https://packages.gentoo.org/packages/app-arch/upx-ucl).) As for the other stages, I went into detail on them at the bottom of [this post](https://www.reddit.com/r/rust/comments/5cpis2/rustaceans_what_languages_do_you_come_from/d9ygkuk/) but I haven't blogged about it yet because I'd like to make time to write some testing automation and generate a chart showing the effects of all possible combinations.
How much time do you have? I like to learn/try out new languages as a 'hobby'. Rust is great if you like type systems and/or thinking about low level details. If you have enough time, you might also want to read a book on Haskell/Erlang/Prolog/Lisp – all languages that get you to think in a new way IMHO.
Awesome! I'd buy a tshirt with that ;) (I'm not sure if you violated a trademarked design here, though. Oh, and I'm so glad I don't have to write "you were looking for /r/playrust" here!)
Concur! I may add a note to that effect later. :)
Constraints on traits are not propagated that way, currently. See [this issue](https://github.com/rust-lang/rust/issues/20671).
Neat. Is there a shopping cart or something that has all the components ready to order?
Plus you probably got some good practice out of it with Rust so it didn't go to waste!
it's great to have more tooling for JNI, it's always a pain to manage from Rust
I'm not arguing with throwlikepollock, they asked a question about why https in Rust was more difficult than Go. Expanding on that, I think everyone is in broad agreement that a Rust TLS stack would be great and the world would be better off with less dependencies on openssl. But getting robust crypto takes time and careful effort. Rust has also chosen to eschew crypto from the standard lib, unlike Go, because deprecating crypto has historically been difficult and is only compounded by putting it in the standard lib.
No problem. None of those return a `&amp;'static`, which is the issue here. You're asserting that the MyStruct will live forever, but you can't know that from `*mut MyStruct`.
PowerShell always manages to make everything look horribly complicated, sometimes even being much more verbose and difficult to write than an equivalent C application.
Neat! It might be worth using https://crates.io/crates/jni-sys for the FFI definitions to avoid having to keep around your own copy. I'm not sure it is the case that `JniEnv` is FFI compatible with the raw JNIEnv pointer, and similarly for the other wrapper types. Some ABIs could treat structs differently than pointers. It might be a bit safer to have people use the raw types in the function definition and then have them wrap those in the wrapper types?
[Pretty sure this is the one true Rust fan poster](https://ca.movieposter.com/posters/archive/main/100/MPW-50070)
I saw that when I initially went to push my own version of it. By the time I discovered its existence, the amount of effort to switch over to it would have been non-trivial (or at least more effort than I wanted to expend at that time) due to various differences between the crates.io version and the one that I got directly from bindgen. Yeah, that's one of the things I wasn't sure about and was hoping someone more knowledgeable could chime in on :) 
Disclaimer: I have limited experience with bare metal x86 programs I don't think it would help much. For once, microcontrollers don't (ever?) use bootloaders *like* coreboot (they use a different kind of "bootloaders" for different reasons). Also, coreboot targets very different devices, "full blown" processors (e.g. with MMU) so they deal with different low level details (x86 16-bit mode and the MMU for instance). Both, (usual) microcontroller applications and coreboot, have to deal with initialization of "peripherals" but each one has to deal with different set of peripherals. coreboot always (?) has to deal with DRAM controllers whereas that peripheral is not that common in microcontroller applications.
Cool, I may take some time to convert things over and send a PR your way :) I'm not totally sure either, but I tend to be pretty paranoid and always try to define my methods exactly how they're declared in C-land, even in cases where it may not strictly be necessary. There are certainly cases where there are ABI differences (like `f64` vs `#[repr(C)] struct Foo(f64)`), but I don't know about this case.
I don't think you can buy everything from a single shop, at least not in the US. For Rust Belt Rust, we had to get the components from different places.
The project is making an xml configuration file generator. There's are probably at least 30 or 40 fields, along with logic to repeat and sanity check them. The xml file is to configure some analysis software for physics. Are there any good graphics libraries for rust? Originally I planned on using qt creator and c++, but since christmas break is approaching, I figured I would do this for a project. EDIT: Also, is there a rust community for micro controllers like the node mcu board? 
Ah, I realized that but was punting on writing the correct lifetime annotations, they're scary when not elided :).
I expect tokio_core::channel will go away as soon as this lands: https://github.com/alexcrichton/futures-rs/pull/245 (and by go away, i mean deprecated in 0.1 and removed in 0.2)
Sorry, I misunderstood you in this point. It isn't impossible to use the library in a futures project style though. If you have further ideas please open an issue, this one got the number 6. ;) https://github.com/tokio-rs/tokio-curl/issues/6
There are simpler ways. :-/
Hyper's client API is moving to be more flexible and low level (and thus cover many use cases). Request exists for a high-level and immediately more stable API for making synchronous requests. Hyper won't be replaced by reqwest. If anything, hyper is positioning itself to be the backbone of any higher level HTTP API you might imagine.
Just to get a sense of what level of the 'stack' this is at: if I'm writing a client for a website's API (e.g. GitHub or whatever else), would it make more sense to build it on top of reqwest::Client or hyper::Client?
http://seanmonstar.com/post/153221119046/introducing-reqwest#fn:p153221119046-1 seems like maybe a good time to bring up that we should have a policy around name squatting and abandonware
What needs to happen to transfer ownership of 'request' when the current owner doesn't answer? Sending donuts with a nice thank-you card to /u/acrichto? Doing that and publishing a new major version by a different author seems far better than telling generations of rust users how the spell the name of the 'good request crate'.
I think the best policy would be to simply rule out obvious simple names and force people to use longer or more distinct names. Also requests would lead to confusion with the Python library.
That is very useful, thank you very much!
Yesss, this looks awesome. Thanks for all your work on making HTTP in Rust great, Sean!
Interesting. Couldn't it be expressed in the type system directly, so there would be no need for `unwrap`?
Awesome, I love it !!! ...and just ordered one ;)
Ok, so you're saying "channel" will be moving to the futures crate? Also, unrelated question so answer if you have the time; would using the channel API be a good idea in a messaging application per chance? I had an idea to have a channel-per-user chat app, and use senders and receivers to send messages received over a TCP stream. Right now I got the idea from the tokio chat example. Thanks for your time. 
Actually, I want to copy one slice to other, *existing* slice (via `&amp;mut [u8]`) &gt; const functions are quite restrictive at the moment Do we even have them?!
Just remembered while replying to another comment that I never replied to this. Thanks for the correction; apparently i'm not 100% clear on what guarantees the stable line provides. Indeed, it seems this would be a difficult one to make!
&gt; very difficult API to learn I'm not expert for this exact case, so it might be true. On the other hand, you might en up with very difficult API to screw up. :)
A macro can expand to another macro, but there's no way to escape `$`.
Does this deal with codepage/encoding issues on Windows? If you're passing an argument via a cmd window, your input will be in the console code page. If all your're on a US code page and all your paths are ASCII, this probably won't matter. It wasn't obvious from the documentation for the clap crate as to whether this is all handed transparently. Maybe you could try with a non-ASCII character. See http://stackoverflow.com/questions/40455338/how-do-i-read-os-compatible-strings-from-stdin for some of the hoops I used when solving this. Would have been nice for a library to take care of it.
We can't establish a precedent of unilaterally transferring ownership of a name to a new user. See also the npm "kik" fiasco. &gt; telling generations of rust users how the spell the name Given that most communication of this sort happens via written mediums, I'm not too worried about that. :P
To give more context, that something could break inference does give people pause. For example, if adding a method would conflict with a method in a common library, this is considered a big negative. This presents problems for moving itertools adapters to std, for example, because if you're already using that adapter this will break inference.
Wish you hadn't started this up again with such a disingenuous summary of the situation. My take - as someone who thinks namespaces do have some advantages - is that namespaces absolutely would not solve the squatting problem because the "best" name would then be `request/request`. The advantage of namespacing is the ability for multiple crates to have a shared branding between them, identifying that they are managed by the same person(s) and work toward a common purpose. This has nothing to do with squatting/abandonware.
That's a bummer, because I need my generated macros to have parameters. Perhaps an RFC is due.
The AsyncClient doesn't exist yet, since the design of async in hyper is still a work-in-progress. However, once it does exist, it may be that OneSignal could switch to a reqwest::Client.
It definitely wouldn't be the common case for most users. Here's some possible cases, though: - You wanted to make another higher level client abstraction, but used rustc_serialize (or some third serialize library), or some different Cookie Jar library. - Something like Servo may need want to use hyper's Client since the rules behind the Fetch API are a little bit different/peculiar than your typical Client. - You really don't want any of the convenience, and just need to make a super simple GET without any other pieces. As a parallel to other languages: rust | hyper | reqwest -----|-------|--------- nodejs | http | request python | urllib2 | requests java | URLConnection | OkHttp (or similar) The point is that there are several extras that are related to HTTP, but being able to use them requires having an opinion on what library or process to utilize for them. hyper choose to just provide HTTP, and let anyone build the extras however they see fit. reqwest says "we use this serialization library and this cookie policy and that proxy strategy" etc. 
Wow, I was just thinking about creating one simple tool and I'd definitely need something like this. Thank you!
Thanks for the example! This situation actually sounds like it could be rather common, and it makes sense not to provide such a guarantee. It doesn't seem like much of a problem for actively maintained projects, but I can imagine it will be a source of bit rot.
is it possible to stop auto-publishing documentation to docs.rs when I publish to crates.io?
Leaving the current cargo crate policies alone, I think the larger issue with this is that it looks like it would be a very nice general purpose crate that is unfortunately purposefully named with a typo. Maybe it could be published instead under something like `httpclient`, `httpcli`, `easyhttp`, `simplehttp`, `httpreq`, etc. (all of those seemed to be available on crates.io).
I'll have to check this out some point soon.
Forwarded you the email.
[novemb.rs](http://novemb.rs/) would be a good time to do so :wink:
Further unanswered questions: 1. How do we determine "appears abandoned"? If it's "amount of time since last release", then how long is that amount of time? It would have to be quite long, since it's not uncommon for authors of less-notable libraries to take time away for a while to focus on life, pushing out a release perhaps once a year or less. I'd say the minimum period would have to be two years at least, which drastically reduces the number of crates that could be reclaimed. Few are going to want to wait months or more before publishing their crate just to initiate a process that might possibly eventually get them a name that is a more common word. In the meantime, determined squatters will defeat this method by writing a script that automatically bumps and commits a new bugfix version of the crate every so often. 2. Who will be allowed to request ownership of abandoned crates? Will any rando be allowed to ask for one, or will there be some threshold for user notoriety? If there is a threshold for notoriety, how do we keep it from being gamed? And if there isn't a threshold, then the Rust developers themselves become morally culpable if someone hijacks a crate for malicious purposes. 3. Who's to say that the new owner of the crate won't immediately lose interest and abandon it as well? This happens even to well-known library authors. We could say that the new author has to already have some sort of vision for the new version of the crate, but then we're suddenly getting involved in something like an RFC process for the thousands of public crates out there, which we definitely don't have the manpower for, and if somebody codes up their new version of a library (and it would *have* to be a new *major* version, for security and stability purposes), then ironically the best way to demonstrate that it represents an improvement over the old version would be to publish it outright on crates.io under a unique name and monitor its popularity, in which case people would perpetually continue using that new name anyway. 4. How do we handle it the first time that a prolific library author finds out that one of their crates has been yanked out from under them, causing them to storm out of the community entirely (leaving the remainder of their crates abandoned in the process)? crates.io doesn't demand contact information to upload crates, and there's very often no good way to contact people based only on knowing their Github username, so the contact step is inevitably going to be fallible.
https://doc.rust-lang.org/book/getting-started.html#platform-support
I'm soooo much looking forward to the RFC *"Document all the things immediately"* becoming accepted. This is right now my single complain about Rust: You don't the fuck know all the features, unless you read the docs, the book, the reference, all the accepted RFCs, all the PRs, and - of course - all the source code. All of Rust should be in the reference, and all library stuff in the docs. Period.
Hey /r/seanmonstar, Why not build this into the tokio ecosystem? Why not make `reqwest` follow a Futures based interface (i.e. `Future&lt;Response, Error&gt;`)? With such an interface, the implementation can switch from sync to async to "magically" provide better performance, best practices, timeouts, etc. It is also trivial to call `.wait()` on a Future to retain the ergonomics of a blocking call.
The canonical location for this information is https://forge.rust-lang.org/platform-support.html as far as I know. (The info is already removed from the nightly version of the book).
As I understand it, the concept of "triples" originated with and was named by GCC, where they appear to take the form `&lt;cpu arch&gt;-&lt;binary format&gt;-&lt;desired libc&gt;`. LLVM-based projects (eg. rustc) seem to use 4-tuples of the form `&lt;cpu arch&gt;-&lt;???&gt;-&lt;binary format&gt;-&lt;desired libc&gt;` where the additional value seems to always be either "pc" or "unknown" or flat-out missing. I haven't gotten around to researching what purpose it's actually *supposed* to serve.
That is a goal, as the end of the post explains. However, this can be released now, where as tokio and async hyper are still not ready. Once they are, reqwest will use futures internally, making timeouts more reliable, and an AsyncClient can also be exposed. 
Meh. In a way, yes. On the other hand, my extractor from rustc's MIR to formal-MIR (which should probably have its own name) can adapt to rustc's internal instability.
Doesn't the precise shape of your formal MIR depend on the exact feature set of regular MIR? And won't you need to formally reprove that your extractor is sound each time that MIR changes?
Very nice and informative series of articles.
I learned a lot by going through ArcadeRS: http://jadpole.github.io/arcaders/arcaders-1-1
 pub extern fn rsvg_path_builder_move_to (raw_builder: *mut RsvgPathBuilder, x: f64, y: f64) Would look better as: pub extern fn rsvg_path_builder_move_to (builder: Option&lt;&amp;mut RsvgPathBuilder&gt;, x: f64, y: f64) I believe [nullable pointer optimization](https://doc.rust-lang.org/book/ffi.html#the-nullable-pointer-optimization) will take care of you.
This is good advice, but one problem in practice is if your error type happens to contain [`std::io::Error`](https://doc.rust-lang.org/std/io/struct.Error.html), which doesn't impl `PartialEq`, `Eq` or `Clone`. It certainly doesn't impl `Copy` either (and in my experience, errors being `Copy` is a little rare, since they often contain strings or other such things). (Even if your error type contains `io::Error`, you may still be able to impl things like `Clone` and `PartialEq`, but you'll need to write the impls out by hand, and they may not be 100% correct.) But yeah, I agree, these impls are really useful for tests (especially `PartialEq`/`Eq`).
The best advice I can give is, **build something you'll use**. You'll retain the information a lot better working on something that's relevant to you.
Blog posts should be exposition and explanation, not documentation. Blog posts are good for "hey here's an interesting feature you can use it for this and that" possibly with explanation as to why they were built that way. PyMOTW is not bad for that. It's for thing which are too wordy to go in the doc, extended or long-form examples and the stuff which go beyond the basics of the API.
Keep in mind that `*mut T` and `&amp;mut T` have some serious differences in semantics that you are absolutely not allowed to violate. I'd recommend keeping the raw C bindings as close as possible to how the C code is defined (using raw pointers) and only introduce rust's references in the idiomatic Rust wrapper.
Raw pointers have `as_ref` and `as_mut` methods that do this. But these are `unsafe`, while `From::from` isn’t.
What you want exists as [`unsafe fn as_ref`](https://doc.rust-lang.org/std/primitive.pointer.html#method.as_ref) on the pointer type. Here's some [discussion](https://github.com/rust-lang/rust/issues/27780) on the subject. 
/u/acrichto, kixunil wants to send you a tip for a highfive (6,815 bits/$5.00). Follow me to **[collect it](https://www.changetip.com/collect/954632)**. -- [^^what ^^is ^^ChangeTip?](https://www.reddit.com/r/changetip/wiki/tipping-on-reddit)
I should look at it. Sounds great!
(Opinions) 1. While some nominal timeout is probably appropriate (a few months), primarily appears abandoned should be a guideline for when this is a appropriate, not a minimum. The timeout waiting for a response is the part intended to give crate authors time, it should be long (a month or two). Crate squatters is not a problem this proposal attempts to fix, you are explicitly allowed to say no when someone allows to take a crate over. 2. I would assume anyone, that's how it works right now. Rust developers would be no more culpable than they are for allowing someone to hijack close mispellings of popular crate names. (The major version bump means that people should be checking what changed anyways) 3. Nothing. I don't see this as a problem though, it still strictly improves the amount of abandoned crates. 4. Given sufficiently long timeouts, attempts to contact, and a well known standardized procedure, I don't see people getting angry about it to be a likely possibility. How to contact them is a more difficult question. Grandfathering old crates and requiring future crates to come with a (not publicly published) email address doesn't seem like an entirely unreasonable option, though it isn't ideal.
You don't actually need to create a complete project to learn Rust – many existing projects (among them [servo](https://github.com/servo/servo), [rust](https://github.com/rust-lang/rust) and [clippy](https://github.com/Manishearth/rust-clippy)) have *mentored issues*, which means you'll get to contribute to those awesome projects while being actively mentored by the actual project maintainers live and in color. I think This Week in Rust also has a list of those issues. I cannot think of a better way to learn the language. TL;DR: Mentored issues rock.
&gt; borrow oriented programming :D
Yet, I had to go hunting for blog posts to understand how to do Rust FFI on Windows, which just wasn't that ergonomic experience. Simple things like how to use UTF-16 across Windows official languages / Rust, use of *mem::forget* to pass allocated memory across languages, and a few other use cases, aren't documented on official FFI documentation. Right now, using Rust on Windows means blog searching. 
Cool, that's nice! I had a similar idea for a project (on my ever growing todo list...) You said that you plan to add features from your 2d c++ library. Do you also have plans to extend the 3d part ? Like adding more primitives (box, sphere, cone, cylinder, ...) and algorithms (csg, ...). So that in theory one could build a simple ray-tracer on top of your crate for example.
To speed up alloc times wouldn't a separate redblack tree make more sense then jumping all over the arena? As object size grew large cache misses would greatly hurt performance. 
&gt;You don't the fuck know all the features Yeah this is really annoying right now. To actually get an idea of what features exist you basically have to look into the source code for libsyntax, and to look up the status of each feature then look for their tracking issues, rfc's, etc. This seems to be especially a pain for the stabilization of lesser used features (abi's for instance).
Still, using `f64` does not seem very future-proof.
Note that in many cases, what's needed to move stuff between tiers is someone to take up the work. That is, we don't think this is a static list, and we'd love to add more architectures and/or move them up towards tier 1. Usually that takes someone who's familiar with and invested in the platform to write the patches.
There was a discussion about implementing methods on primitive types a couple weeks ago, so instead of rehashing any arguments from that I will just drop the link here: https://www.reddit.com/r/rust/comments/5aat03/why_is_implementing_traits_on_primitive_types/ My personal opinion is that I agree with you, I like the impl'd version better, but I can see both sides.
Nice promotion video! A tiny remark about Garbage Collection: I am afraid we'll see a deluge of comments deriding edunham's remark about the pause because some run-times have managed to get it down (Go's latest improvements come to mine). Brace yourself, a flamewar is coming.
IEEE-754 specifically defines 32-bits as single precision and 64-bits as double precision, so it seems quite unlikely that `double` will ever be anything but 64 bits. Note that this is independent of whether the program is compiled (or executed) for 32-bits or 64-bits targets.
You can implement the first to also basically expose a variant of the second. Example: https://is.gd/S4ATbJ 
Oh yeah, I use results and options throughout where appropriate for sure. I was just getting to the point.
Is there a reason why io::Error doesn't have `Clone` at least? Forward compatibility?
It's meant to operate more like `try!` (or the `?` operator now). Going from a nullable pointer to its `Option` analogue isn't terribly useful when the end goal is to either get at the value behind the pointer or raise an error because something is very wrong. The problem with converting it to an option is that you either need to a) attempt to unwrap it and raise an error if that fails or b) use a series of `Option::map` or `Option::and_then` calls to get an `Option&lt;FinalType&gt;` at the end. Scenario A is essentially what the `deref!` macro is doing, but with an extra step. Scenario B is OK, except that it loses information about *where* the `None` occurred in the chain.
Yeah, but the pause is still there. I don't really see what argument can be made against what she said. I can see people saiyng "oh but it's only a few ms" but... no one said otherwise.
I thought it was because an `std::io::Error` can contain a `Box&lt;std::error::Error+Send+Sync&gt;`. I don't think you can actually utter `Box&lt;std::error::Error+Clone+Send+Sync&gt;`, which would be required if `std::io::Error` were `Clone`. There may be another reason though. I can't remember.
It may have made more sense when I worked on Persona (BrowserID), as the it was part of the Identity Team. Technically, I'm still in Identity Services, now working on Firefox Accounts. I've seen people at other companies working on similar projects call themselves the same thing. It just felt more fun than saying "Software Engineer", I guess. 
&gt; "oh but it's only a few ms" you mean [microseconds](https://groups.google.com/forum/?fromgroups#!topic/golang-dev/Ab1sFeoZg_8) ;)
Or truly pause-less GCs like Azul's C4 :)
Yes, the formal MIR is currently very similar to regular MIR, modulo a few changes that make it easier to reason about in the theorem prover. The extractor can't be proven sound. It's part of the "trusted computing base" for now - if you don't have a verified implementation of Rust, the best you can do is trust rustc and, if you want to do program verification, the extractor.
For context, quoting the first e-mail: &gt; Today I submitted changes to the garbage collector that make typical worst-case stop-the-world times less than 100 microseconds. The e-mail also suggests that this is only a step, and further improvements are coming. This means that today whether there is one pause or not is a probably not noticeable is services with a 10ms response time, and if they manage to push the GC further and drop another order of magnitude (easier said than done), even services with a 1ms response time would not show significant impact from one pause during the processing.
This is good: if you've seen words like "covariant" and "invariant" in RFCs and wondered what that means, Felix explains! This video is essential to understanding the [nomicon](https://doc.rust-lang.org/nomicon/subtyping.html) page if your brain often goes numb when reading dense technical documentation like mine does.
1. replacing the global allocator works, but isn't stable 2. per-data-structure allocators is desired, but still needs designed. IIRC /u/pnkfelix is the one working on this?
If I'm designing a trait with some methods that could possibly require a `&amp;mut self` parameter, but could also be just fine with `&amp;self`, depending on the library user's implementation and preferences, should I just go for `&amp;mut self` or are there potential downsides to this?
Good point.
For those who can afford it. :-)
its all good until I have my own github page docs with images. My problem is now I have 2 places for my docs, docs.rs and github.io.
I won't have the time to review the RFC myself for a little while, but do you happen to know offhand if composition of allocators was considered? I'm thinking of something similar to [Andrei Alexandrescu's awesome allocator talk at CppCon 2015](https://www.youtube.com/watch?v=LIb3L4vKZ7U). It couldn't be exactly the same in Rust today since constants are not usable as type parameters, but I think some of his design points are worth considering (even though it's well past FCP for the RFC). There seem to be some nice properties that fall out from composition.
Type aliases don't change anything, they are just different names for the same type. If you implement something for an alias, it's exactly the same as implementing it for the type for which it's an alias.
There's no formal definition of Rust. I *do* have a definite semantics of MIR-as-understood-by-rustc. I *don't* have a semantics of Rust-as-understood-by-rustc, to show that *all of rustc* from text -&gt; MIR is correct.
Meh. Wait until we get to an actual round number, like 32768.
Yes, garbage collectors (and, I guess, software in general) have a throughput-latency trade-off: minimising worst-case latency for individual requests often sacrifices average-case throughput (i.e. how quickly requests actually get processed long term).
Well they said the pause can be noticeable by the user on slower hardware, which is pretty clearly overstating the impact of garbage collection. Makes it sound like your code won't run well on phones if you use a garbage-collected language. I think of all the benefits of Rust to highlight, the lack of garbage collection is one of the weakest honestly, since it makes no practical difference to the 99% of programmers who are not building real-time traffic control systems or targeting tiny embedded devices. Most of the GC hate comes from a subjective aversion to having a runtime and losing a non-zero amount of performance and control to it, which is fine if it isn't disguised as objective superiority. (And I say that as one of those borderline irrationally GC-averse people myself)
Meh. All of it seems like blatant karma whoring.
So stupid question time, is there an easy way to decode a JSON response?
Rust uses a nominal type system, which means types are differentiated by their name, not whether their sub-structures match. I get that that the details of implementing something on a type alias would be the same details as if you were implementing the feature direction on the type. But my understanding is that a type alias allows you to implement those features on the type in a manner that the compiler would reject calling those methods on the base type based on a nominal type check.
A type alias is a statement like this type X = i32; and anytime you use it, it is interchangeable with using the type it alises. It makes no difference here if I implement something for `i32` or for `X`. You may be thinking of the newtype pattern, which looks more like this: struct X(i32); and is a distinct type, with all the properties you describe.
I was under the impression that the type alias behaved like the newtype pattern. Thanks for clearing that up.
Apart from super-cool Azul's algorithm if one looks at amount of over-provisioning of memory / hardware etc and very elaborate setup to avoid GC pauses, Azul's JVM looks lot less magical and lot more sysadmin effort.
`tokio_core::channel` constructs in-memory channels. You can't use them over the network. You need to do something based on `TcpStream`, but there's not much in the way of a friendly high-level API for that yet. 0.2 might improve things.
That would be pretty good. Certainly matches how Post works.
Definitely CSS trickery.
If I'm doing a project that *requires* nightly, I just pin to a specific nightly anyway to avoid problems. Don't forget you can set per-directory defaults (though I wish you could set the default in a file you can check in to source control...). You can also go into your toolchains directory, rename `nightly` to `nightly-YYYY-MM-DD` (get the date with `rustc +nightly -vV`) before you update, and then you don't have to redundantly re-download everything.
*If you are wondering why it's getting tons of downvotes (like me), see also the [thread](https://www.reddit.com/r/rust/comments/5da47l/rust_and_the_future_of_systems_programming/) for the Medium version of this post.*
I really enjoyed watching this presentation. Ashley did a great job of keeping it easy to follow and fun but still focused on the content. &gt; If you make the array too small, it just prints a bunch of horrible text into your editor while you're giving a talk in front of a bunch of people. Was my personal favorite. Also I didn't realize intermezzOS was still active when the "this week in..." posts stopped popping up. 
Rust also runs in OS-free contexts, where truly pauseless can mean truly pauseless.
That would be pretty unwieldy in my case as the inner macro has a lot of parameters.
Say I'm defining a macro in crate `parent` and using it in `child`. Is it possible for the generated code in `child` to use a feature of `parent`? I tried `#[cfg(feature = "parent/feature")]`, but it doesn't seem to work.
That's kind of sad. You'd think we had: println!("&gt;{:.*}"), 2, 20.000) ...by now. Edit: Fixed (editing code on a phone is hard!)
We have an RFC for parametising by constants already, right? Or at least associated constants. If we want to go down that route we can consider it blocked on improving the story there.
It is, it's just a long-term project and we don't always have time to hack on it every week. Plus, we were preparing for Rust Belt Rust, so we were working on that workshop and not other stuff. Oh and the book is fairy far behind the actual kernel at this point. All my writing time has been going to TRPL...
I've already seen one implementation of this kind of thing [here](https://rphmeier.github.io/allocators/allocators/index.html), but it just keeps the constants as internal state. So you can already do this, even if it isn't exposed through the language. Though you might lose some flexibility if you have to wrap such a design in another API.
Totally :)
Just to be sure, are you compiling with optimizations? (`rustc -O` or `cargo --release`)?
cargo --release
It kind of gives non-C++ programmers the idea that most C++ programs are full of memory leaks and crash all the time, which is kind of silly.
Hello. This is a text post, so I'm not earning any karma from it. It's just that I saw that we've hit 20.000 subscribers and that I couldn't find any post about it, so I made one.
I second this. A 9k by 10k grid of single digits, separated by single spaces (the minimal case) would be about 172MiB and the console is slow. I did a quick test in Python. Generating and writing that to disk by calling `.write(test_string)`on an open file in binary mode, then closing it, completes in under 2 seconds. I had to abort the `sys.stdout.write(test_string)` because it was still streaming out after I came back several minutes later. (My terminal is a urxvt+screen stack.)
We even get name-dropped as a beneficiary. As someone with some AVR chips, this makes me incredibly happy.
One should look at Zing Install and Admin guide it is 300+ pages document. It is lot more setup than that.
Cool that rust is now part of the driving force behind LLVM changes!
I'm having the same problem. I have a project that uses `hyper` and `diesel`, so I need to get `openssl` and `libpq` linked, at least. Originally, I was thinking of building the project on a Docker image, but as `diesel` uses build-time-information to infer the database schema, and setting up a database just for building is a hassle, I prefer to build on my computer and then distribute the binaries... only if I could cross-compile.
Okay so I added: &lt; /dev/null &gt; out.log 2&gt; err.log To the end of the openssl command and I am still getting the same thing. Nothing in the "err.log" and the "out.log" file only has the two items that it was showing before. I've tried printing out stderr before but that was meet with the same result. I should point out that I am running the rust application on a mac when testing this, but late last night I ran it on Fedora and the first 'ACCEPT' appears but nothing else. So my guess is that something is eating the ACCEPT? I'm not sure about the presence of a TTY. Not sure why that would be an issue.
Those sacrifice throughput. Throughput is just as important, if not more important, than latency (pause times).
IIRC, text posts do earn karma now, unless they undid that change.
esp is avr arch? lmfa0
I think that there may be some difference when using floats compared to the single digits. I use floats to precision of 3 decimal places for example (1, 0, 0.999, 0.001)
No, the esp8266 is a 32bits RISC Tensilica Xtensa LX106 architecture, Atmel AVR is a different 8 bit RISC. The current only hope is a LLVM to C backend : https://github.com/JuliaComputing/llvm-cbe
I'm not actually this big of a jerk (I swear!), I just find it amusing. I really just wanted to know what it printed, as I don't have a built-in interpreter for format strings. Assuming it should be println!("&gt;{:.*}", 2, 20.000) Then the output is: &gt;20.00 So maybe this was all a roundabout joke about OP using `.` as the thousands separator instead of the [decimal mark](https://en.wikipedia.org/wiki/Decimal_mark)? I just assumed that was [normal internationalization](https://docs.oracle.com/cd/E19455-01/806-0169/overview-9/index.html): &gt; Great Britain and the United States are two of the **few places in the world** that use a period to indicate the decimal place. Many other countries use a comma instead. (emphasis mine)
Send the design to http://www.teetee.eu/en/. It may become a nice shirt
Yes. I can't remember what the URL was, but it's been mentioned that formatting IEEE 754 floats in a standards-compliant way is an inherently heavy operation.
In general `to_string` is implemented as use core::fmt::Write; let mut buf = String::new(); let _ = buf.write_fmt(format_args!("{}", self)); buf.shrink_to_fit(); buf so you're just doing an extra allocation. 
&gt; though I wish you could set the default in a file you can check in to source control It would be nice if rustup supported something like this. I've gotten into the habit of writing out a `rustc-version` file with the specific nightly a project is pinned to and checking it into git. The trouble is forgetting to update the file when upgrading rustc, and it's easy to forget to update rustc when the `rustc-version` file changes.
Or even better fn to_bool&lt;B: Boolify&gt;(b: B) -&gt; Option&lt;bool&gt; { Boolify::to_bool(b) } just because the function pointer machinery is less optimisable than the static dispatch machinery (I don't know if dispatching on a const pointer is treated as static dispatch, it would seem like a strange special-case)
How do I convert an `OsStr` or `OsString` to the platform specific pointer? I'm attempting to call into the Win32 api, and it is nice that `OsStr` handles converting the utf-8 to utf-16 but how do I get the pointer? I understand what I'll get out is platform specific but at least which tuple field is it?
So what functionality are we missing? There's not as much flexibility as there could be, but I'm no longer sure where one would need to escape `$` (to go from ident to macro argument, I guess, but I don't see why you'd need that).
Note that Alexandrescu's video is (mostly) on how to implement allocators, whereas for the per-data-structure what matters most is what interface should such an allocator have. Since it possible to have two interfaces (one for allocator building blocks, and one for the final allocator), there isn't much need to think about building blocks ahead of time.
It's a trade-off, but I would argue that gaining x10 in latency by sacrificing 10% of throughput is definitely the right trade-off to make. It's much harder to achieve reduce latency as a user than it is to increase throughput (assuming things can be parallelized).
I guess I can make that separate and include it in the main one. Any reason you can't have the whole thing?
I had a guy in my CE classes who just loved the ever living daylights out of MSP430s. Every problem we had, his solution was always "Add more MSP430s". To the point where most of his projects were just networks of MSP430s. Either way. Fun. It is neat having the LLVM support some of these more niche platforms.
If it's up to the consumer then the most flexible option is to take `self`. Then they can implement the trait separately for `&amp;'a T` and/or `&amp;'a mut T`, whichever they require. Your library will have to be generic enough to work with whatever they choose.
I don't quite follow. What do you mean by "building blocks"? How are you relating those back to data structures?
Just as a reminder, /u/Breaking-Away won't get notified of your comment if you nest it like this (reply to yourself).
I mean that you can use Andrei's way of building allocators under the covers (as building blocks) and yet expose a completely different interface (such as `std::allocator` in C++). The data structures expects a standardized interface, and does not care that the implementation is monolithic or uses multiple small allocators and the decorator/composite pattern.
Ah, okay, got it. Makes sense.
When piping many tools enter a buffered mode such that the pipe sink won't see any data from the pipe source until the buffer has been filled or closed. On linux you can disable that with unbuffer (from the expect package) or stdbuf -i0 -o0 -e0 command. I suspect at least one those has been ported over to OSX. I think there's a way to disable the buffer with code, but I can't remember off the top my head. Alternatively maybe ACCEPT is lacking a following '\n', and lines is waiting for that.
Sure, but if crates.io was doing a `cargo build` for each crate after a Rust update, things would break. That's kind of what is happening to me; our build system enforces that if you update the compiler you don't break things. I think what you're saying is we should turn off `deny(warnings)` for third-party code. That seems reasonable.
If you are wondering about semver, this issue is well known (hence the cargo defaults), and it's policy that lints can be updated. An existing lint can also be improved to detect more cases and find new warnings.
If the issue is only with deprecated things, you should be able to put `warn(deprecated)` after `deny(warnings)`.
If you're looking for a mid-level tutorial, I recommend: [Learn Rust With Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) It goes beyond syntax, and looks at some of the techniques you'll need to learn to be really productive with Rust.
You want /r/playrust.
Years ago I made an [MSP430 emulator](https://github.com/adwhit/uCTF-rs) in Rust (for the [microcorruption](https://microcorruption.com/) CTF). It's an elegant instruction set. Definitely won't compile any more but I sometimes like looking at it to see how much the language has changed since. Never really understood what MSP430 was meant to be used for though. Maybe this will give me the impetus to get hold of a dev kit. Any suggestions?
That was really great and I enjoyed it. I still haven't quite interned variance but at least I can follow along if I stop to think long enough.
I've seen it used in IoT applications. Can't get much more specific, unfortunately.
I don't believe `rustc` is currently configured to consume MIR, it's mostly used as an internal datastructure that can be dumped to text for debugging. I believe MIR lowering occurs after some number of important passes in the compiler, so mistakes in generating it could cause correctness issues later during compilation. The current approach is to just compile to Rust, really. There's at least one or two existing language projects that do this, though I can't recall them off the top of my head and Google's not returning anything useful.
How is someone interested in the claims and asking about people's opinions a "troll"? This is way too reactionary. If you think the claims make no sense just point it out. It's not like somebody posting an article from the Onion on a serious news discussion site and asking whether it's legit or not. Totally different things. Many claims there do have virtues and are not just random garbage/"satire" or whatever. Equating the site with the Onion looks more like trolling, in fact. 
Cool! Did you measure gain from this? I think people often call this structure skip list (even when they have only one level).
Do you really need hundreds of megabytes of formatted text?
Really loving these videos! And I'm loving that Mozilla are taking the time to focus on this sort of super accessible outreach. As someone who has only been programming for a few years, I think these videos will be *perfect* for planting the seed about Rust. The kind of thing that devs - no matter how new to the game - can check out on their lunch break and eventually find their way to the punchline at rust-lang.org :) PS: Those animations are awesome.
To his credit, the MSP430 *is* a sweet MCU
Live transcript can be found [here](https://public.etherpad-mozilla.org/p/rust-bay-area-2016-11).
[Rayon's gitter room](https://gitter.im/rayon-rs/Lobby) is fairly active if folks want to chat about implementing these, or of course you can just comment directly on the github issues.
After the next update to Rust's LLVM submodule, all of the necessary AVR stuff will already be sitting inside upstream Rust's LLVM submodule, and then it'll be trivial to enable the backend! It has been really hard maintaining the current fork of AVR-Rust due to the state of Rust's version of LLVM (many extra patches). Rust tends to bump LLVM versions about every month, so it shouldn't be long until the possibility of having AVR enabled in upstream Rust is possible. There's some really cool projects that could then be done Take a Look at /u/shepmaster's [Rust Arduino](https://github.com/avr-rust/arduino) repository.
I don't think this does what you expect: the deny means that any warnings that gets generated is an error, it isn't quite the same as `#[deny(all lints)]`.
How difficult would it be to implement the backend for it?
In the frequent-seldom case, like the one described in the post, its a 10x speedup. This structure differs from skip lists. All the skip data is stored centralized in `HotIndexingChunk`. Which entails two benefits: 1. No pointer chasing 2. O(log(n)) access with minimal storage overhead But, too be honest, I didn't really think skip lists through for my case. It just felt natural to put everything into `HotIndexingChunk`
Do you really have to use two thread? Wouldn't Futures/Tokio help? Try to describe the bigger picture, so we can help better.
&gt; Changes which may force you to disambiguate method calls. It could be changed without introducing error using extension traits, if I'm not mistaken. (Instead of implementing `Foo.bar()` create trait `FooExt` and then `impl&lt;T: Foo&gt; FooExt for T { fn bar() { /*...*/ } }` So if someone wants to use additional methods, he could `use FooExt;`. Of course, this approach may lead to many `Ext1`, `Ext2`... traits but on the other hand, it would guarantee perfect compatibility. Maybe even using names like `FooV1_2` to indicate version might be interesting.
If out.log does not contain ACCEPT that would suggest it's not output to stdout so your rust program is working correctly. It might be quicker to glance at openssl source code to see if it reveals anything.
Currently you can develop `no_std` crates which do not depend on `std`, so we have tools to develop ecosystem for embedded development. Main thing which we miss today in my opinion is a way to search for such crates. (related [proposal](https://users.rust-lang.org/t/target-os-architecture-environment-as-a-crate-property/7748)) As for type level integers we have `typenum` and crates built on it (e.g. generic-array) which you can use in `no_std` environments too. Of course it's a good hack, but a hack netherless and I would like to see type-level integers in the Rust too one day.
Advantages of rust-crypto: - Larger number of supported algorithms (not only because `ring` is based on BoringSSL, but also because it's a Brian Smith's decision to minimize number of algorithms) - Nicer code as it's mostly written in pure Rust (only `crypto-ops` and `aes` have C parts, which I hope will be changed in the future). So you can say it's audit friendlier. (as you probably know ring uses a ton of C and assembler, 40% and 42% respectively against Rust's 13%) - Modular structure allows you to use only that you need which for example can be very important for embedded applications Advantages of ring: - Faster code - Readiness for production (mainly thanks to extensive audit of BoringSSL) - More attention from Rust community compared to rust-crypto Personally I see ring as a mid-term solution for cryptograpy in Rust and rust-crypto as a long-term one. P.S.: I've done extraction of bcrypt, you can see it [here](https://github.com/RustCrypto/rust-crypto-decoupled/tree/master/etc/bcrypt). Some tweaks will be probably needed, as it's not ready for publishing, but I think it's in usable state.
Thanks for doing this. I'm currently using your crate (pre-refactor) in one of my personal projects. One question- which hashing algorithm would you recommend for my code? Speed is critical, but there's no security component at all, so an algorithm that has been compromised to hell is perfectly fine for me.
Yeah, maybe I will. I'll see how md4 compares with md5 which I'm currently using. Do you have recommendation on a non-crypto hash library? Finding the right crate can be challenging in rust...crates.io search leaves something to be desired. 
There was a thread started surrounding an org a few months back. I don't think there was ever a formal answer, but contact DaGenix and see what he has to say. He's quite receptive! I agree maintaining two code bases is silly. I'd also consider putting algorithms per crate, but that's a big change and definitely not universally supported. 
I've emailed to DaGenix (palmercox@gmail.com) with description of my work almost a month ago but didn't get an answer. I was warned about potential negative reaction, but I hope we will be able to settle this with him peacefully. About "putting algorithms per crate" it's exactly that I did in `crypto-hashes`. All algorithms located in their respective crates and `crypto-hashes` simply reexports them.
`md5` on my machine processes up to 400 MB/s slightly faster than `blake2` (380 MB/s). About non-crypto hashes, I don't have much experience with them, but quick search gave this list of crates: - fnv - farmhash - murmurhash64 - xxhash Try to test them and to look into other crates. (start from wiki and search by algorithm names)
I think it is a good idea to put all the skip data in the same place yes. That helps minimizing the IO. I believe Lucene does that to.
Expected a penetration tester's view, but this is really cool too!
I've think the rationale for keeping with all that assembly is to avoid timing attacks by having. This is the same reason BitCoinJ uses BitCoin's [libsecp256k1](https://github.com/bitcoin-core/secp256k1) through the java JNI (since libsecp256k1 is written to do everything in constant time). Similarly Ethereum's rust client *Parity* is also using libsecp256k1 through Rust's C integration - https://github.com/ethcore/rust-secp256k1 So while I think that having the hashing functions factored out is a good idea and they might as well be written in pure rust, you are opening yourself up to potential attacks and some folks are sensitive to this. On the other hand EthereumJ just uses BouncyCastle, and similarly the python client just uses Python's built-in arithmetic. And despite this for all of Ethereum's problems I've never heard of anyone pulling off a timing attack.
&gt;I've think the rationale for keeping with all that assembly is to avoid timing attacks by having. As I understanding it, it's only a part of the story (though important one), using platform specific carefully optimized assembly of critical paths also allows you to achieve the best performance platform can give. Concerns about timing attacks is the reason why I've started with hash functions first. In my knowledge there is two ways how to deal with this problem, one way is to write constant time code (which is theoretically possible in Rust, at least in nightly), to do it you'll need a way to test it (e.g. ctgrind or cyclometer from 2014 talk by Tony Arciery). If such tools give you a green light then you are good, at least in case of symmetric ciphers. Second way is to randomize timing enough to hide sensitive data behind noise. (example of such approach is [here](https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2011/february/double-hmac-verification/)) So I thinks first we can start with timing dependent implementations with security warnings in docs and then work on making them constant time using specialized tooling to control it. Currently rust-crypto uses C bindings for `fixed_time_eq` (moved to `crypto-ops` crate) and for constant time AES.
Yep this is a known problem. Code that is `#[cfg(...)]`'d to a specific platform or feature won't be included in the docs generated for other platforms and unselected features. (holy double negatives batman!)
I don't think you can do it directly but you should be able to `#cfg` the macro itself providing multiple implementations depending on features available when the parent is compiled.
https://cdn.rawgit.com/Gankro/hash-rs/7b9cf787a830c1e52dcaf6ec37d2985c8a30bce1/index.html TL;DR: It depends on the size of the thing you are hashing.
This gives me a couple more things to try. I will see if one of these provides a fix. Thank you.
&gt; How is someone interested in the claims and asking about people's opinions a "troll"? When those questions are asked not out of genuine interest but to waste time and generally annoy/frustrate people, then it is trolling. I'm not saying that this was the case here; it's hard to tell now because OP has since deleted their question, but I upvoted it before it was deleted, so clearly I wasn't convinced that they were trolling. &gt; This is way too reactionary. I fail to see how. Asking questions can be a form of trolling when it is done for the wrong reason, e.g. when you don't really care about the answers. And I never said that OP was definitely trolling. &gt; If you think the claims make no sense just point it out. Many others in this thread have addressed the claims and did so before I originally posted the reply that you are replying to, why would you want me to repeat them? &gt; Many claims there do have virtues and are not just random garbage/"satire" or whatever. Many of the claims are either true or grounded in some truth, which incidentally also applies to good parody. Does Rust have six string types? Yes. Does that mean Rust sucks? *That* is a matter of opinion. Rust wants to interoperate with C, so it must support zero-terminated C strings. Rust also wants allocated memory to get freed automatically when it goes out of scope, so now we have two string types: one that owns its memory, and one that does not. Rust wants the guarantee that strings are utf-8 encoded, so now we are at four string types: two for C support (one that owns (`CString`), one that does not own (`CStr`)), and two for guaranteed utf-8 (one that owns (`String`), and one that does not own (`str`)). Now it turns out that not all operating systems use utf-8 everywhere, and we would still like to be able to talk to those operating systems, so now we have six string types: the four I mentioned previously, and two for 'operating system strings': one that owns (`OsString`), and one that does not own (`OsStr`). We ended up in this situation because we had four requirements: a clear distinction between owned and borrowed data, C interoperability, utf-8, and interoperability with whatever the OS provides. We could sacrifice one or more of those requirements, but then the YLS website would say "Rust sucks because it can't handle C strings" or "Rust sucks because you have to manually free memory in 2016". So attempting to address the issues raised on YLS is inherently a pointless exercise, and as such the site should not be taken seriously. Anyway, if you still feel I'm a troll that's fine, I would disagree but the existence of sites like YLS wonderfully demonstrates that you can't please everyone, and I'm not going to try.
It is doing it automaticaly you can see it in here https://github.com/mystor/rust-cpp/blob/master/src/mac.rs Also when I want to pas single struct but not whole slice everything is ok. Because of that I am using dirty hack, I have rust extern function that is adding single objects recived from C++ to Rust vec. 
Me too. :)
Unfortunately documentation is one of the weakest part for rust-crypto. Someday I'll get to it, but for now it's not a top priority for me. Of course docs contributions are extremely welcomed! :)
As I also said on this rust-crypto issue, I would be strongly in favor of feature-gating insecure algorithms: https://github.com/DaGenix/rust-crypto/issues/365#issuecomment-242954084
You should consider renaming anyway....
I'm curious to know your views on /u/Manishearth's articles on Rust GC. I'm not sure if those are all the articles, but: * (Sept 2015) [Designing a GC in Rust](http://manishearth.github.io/blog/2015/09/01/designing-a-gc-in-rust/) * (Aug 2016) [GC Support in Rust: API Design](http://manishearth.github.io/blog/2016/08/18/gc-support-in-rust-api-design/) And the same regarding /u/pnkfelix's articles: * (Nov 2015) [GC and Rust Part 1: Specifying the Problem](http://blog.pnkfx.org/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/) * (Jan 2016) [GC and Rust Part 2: The Roots of the Problem](http://blog.pnkfx.org/blog/2016/01/01/gc-and-rust-part-2-roots-of-the-problem/) (I'm also pinging them so they don't miss your article)
&gt; (Maybe at least publishing a last version under the old names with "crate renamed to foo_bar" in the description?) Yes, this is the right way to do it. Possibly also with a "if you'd like this crate email me and I'll give it to you"
Release a new major version which moves a recently broken algorithm behind a feature gate. It's not like this happens terribly often. SHA1 has been known to be shaky for several years, for example, and it's the only one of note in recent history.
They are low cost low power solutions with a good balance of sensors. It isn't really meant for anything (like most MCUs). It is just a good option if you want small, low power, and a good array of ports.