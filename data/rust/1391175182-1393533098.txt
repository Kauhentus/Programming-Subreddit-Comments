It will be a library, the compiler support is just to allow those libraries to (slightly) restrict what data types they accept, to ensure that they are guaranteed to be thread &amp; memory safe. Essentially a generalisation/refinement of the `Freeze` and `Send` [kinds](http://static.rust-lang.org/doc/master/std/kinds/index.html) that we have now. (I.e. afaict, the only different the compiler support will make compared to what we can do now, is whether the interface will be safe (compiler support) or be required to either be unsafe or very restricted/inflexible (now).)
I'm not going to argue that Rust should support them natively, but bitfield support *is* requested with some manner of frequency (I imagine, by people looking for an alternative to C for embedded purposes). What part of C bitfields aren't well-defined? I thought the rules were exactly as well-defined as structure layout is, which we claim to support. At least, that's the impression that I got from this article: http://www.catb.org/esr/structure-packing/
Homebrew is only for OS X and is significantly worse than many Linux package management systems + repositories. 0install is a working cross-platform solution.
&gt; Why doesn't rust have a fully-contained standalone binary installer? It doesn't have one because you haven't written one. It's not much different than any of the other 1500 issues in the tracker.
Don't forget that we're hiring interns for Servo too!
Other than 0install and Gentoo, what other package managers are meant for compiling from source? Two things I like about Homebrew: uses git to handle build instructions, anyone can easily submit a pull request to update a script; although it's intended to be used in /usr/local, I regularly use it rooted in my home directory -- i know of no Linux package manager that allows me to build from source and install into my home directory.
Agreed. The goal of Rust is to make the world a better place by drawing C++ programmers toward a language where safety (as well as some measure of concomitant security) is the default. To that end, the syntax needs to be at least marginally familiar (or at least, not wholly alien). It will be up to other languages to advance the art of making programming language syntax intuitive for novices.
&gt; Other than 0install and Gentoo, what other package managers are meant for compiling from source? [Paludis](http://paludis.exherbo.org/) is one of many. &gt; i know of no Linux package manager that allows me to build from source and install into my home directory All Linux package managers support local workspaces, because you can use containers. Not many package managers support a coherent mix of both system libraries and local libraries like 0install though.
Support for higher-kinded types and GADTs would be *very* nice for &gt;1.0.
If this ever becomes a todo-list, Rust will have out-complexed c++ by a huge margin. Not sure whether it's desirable or not.
One could employ conditions in d-tors, too.
You might want to take a look at the [House](http://programatica.cs.pdx.edu/House/) and [Habit](http://hasp.cs.pdx.edu/) projects. House is an operating system kernel implemented in Haskell, on top of the GHC (Glasgow Haskell Compiler) runtime system. Habit was inspired by that work (and the desire to remove the dependency on the GHC runtime system) and is a type-safe systems programming language based on Haskell. There are published academic papers about both of these projects. You could argue to your supervisor that a similar project based on a runtimeless Rust would serve some of the same purposes as these projects, but would be more realistic as Rust is a more plausible language for systems programmers to actually write systems in than Habit.
/r/playrust
http://www.reddit.com/r/playrust/ These guys might be able to help you out. ;)
Here is an example makefile that I wrote last night to replace the rustpkg setup I had been using. Don't take it as an example of excellent make, but it works: https://gist.github.com/derwolfe/8752809 An example where dependencies are built in is the line: single_cipher: score $(CC) src/single_cipher.rs $(CCFLAGS) -L $(BUILDDIR) single_cipher depends on the score library, so it builds score, then links against it.
The complexity of C++ comes from the messy interactions of ill-fitting pieces being glued together in haphazard and bug-compatible ways, not actual features...
/r/playrust
Excellent work! I wonder if we should upstream this as an optional replacement of `SipHash` as we redesign the hashing API. Have you thought about mixing in a few rounds of `AESENC` to provide some measure of cryptographic security? I would love to see the performance results of this.
Can this fulfill the hashmap interfaces erickt is working on in https://github.com/mozilla/rust/pull/11863?
C++ already has variadic generics, integer type parameters, higher-order generics, bitfields, and you could consider `constexpr` to be a really simple effects system. The few language features on this list don't come anywhere close to C++. 
Arbitrarily long integers, monad syntax sugar, HTML embedding, etc. etc. were in the list. Admittedly they may sound scarier than the eventual implementation would be. But I hope the mission of rust is not to include every language feature known to man ;)
Yeah, I'm skeptical too, but I'm no crypto expert so it may well actually be brilliant. I've emailed agl about it.
Because functions are semi colon separated in an implementation?
I've actually never even noticed that before! As far as I can tell there's no reason that it couldn't be a comma rather than a semicolon. Simply a syntactical decision.
I do want to remark that there's a precedent for the semicolon as well as the comma. In older versions of Rust, we sometimes allowed a semicolon to stand in for an empty pair of braces. For example, we used to allow empty struct definitions to be written as `struct Bar {}` or `struct Bar;`, and likewise we used to allow empty trait implementations to be written `impl Foo for Bar {}` or `impl Foo for Bar;`. We've since gotten rid of this option (now you must write `struct Bar;` and `impl Foo for Bar {}`). But it's possible that the original syntax for trait members was influenced by this, since they are usually without bodies. I don't know if it makes sense to change it, though. Because we *do* allow functions in traits to have function bodies, and mixing body-having and body-less function definitions looks less weird with the semicolon IMO.
The [implementation of `.hash`](https://github.com/mozilla/rust/blob/master/src/libstd/hash.rs#L84-L91) uses `IterBytes`, rather than calling `.write` directly (which it's required to do so that types can control how they are hashed). Unfortunately, for vectors, it has to pass each element individually, even for `&amp;[u8]` since there's (currently) no way to detect that the type is actually `&amp;[u8]`. So bench_base(bench, |v| { v.hash(); }) is calling `.write` once for each `u8` in the vector.
I added your project to the [wiki](https://github.com/mozilla/rust/wiki/Doc-examples). Trying to figure out what's out there, try to consolidate eventually.
Closing a file isn't actually the right place to handle an error. It doesn't guarantee the data is on the disk at all, but rather just that the application-level buffers are flushed. You can retrieve the same errors as you would get from `close` by calling the `flush` method. Neither of these actually guarantees that you'll get an error reported, as the OS itself usually does buffered I/O and calling `fsync` is required to know if the data is actually stored.
It's not necessary as `close` isn't the correct place to handle an I/O error.
Hey, Yes, custom fonts look horrible on Windows. I'll definitely try different mechanism for using decent fonts for Windows.
thanks, fixed
I'm slightly confused as to why string literals being `'static` by default would cause problems: every lifetime is a sublifetime of `'static`, i.e. you can (theoretically) use `&amp;'static str` in place of `&amp;'a str` for any `'a`.
Doesn't Rust aim to take on the big ones, like C++? If the world is to be 'stuck' (I mean that in the kindest possible way) with cruft from Rust 1.0 for a long time, it would seem the cost of making tough choices is still fairly low compared to the cost of complacency, unless one would want to engage in bigger revisions every so often.
&gt; As you can see, you can unwrap the value straight away, but that might give you runtime errors What kind of errors? Do you get a stack trace at least? I prefer exceptions over having to check every return value.
Usually it doesn't. It only applied to certain functions, and I'm not entirely sure of the behaviour. The only other place I've seen the ::&lt;sometype&gt;() pattern is mem::size_of::&lt;sometype&gt;()
I mean, I get why it's required to specify the type... it can't determine what you want to convert the string to otherwise, but why not `from_str&lt;uint&gt;(10)` instead of `from_str::&lt;uint&gt;(10)`?
Parsing: `foo&lt;bar&gt;()` could be parsed either as (what is now) the `foo::&lt;bar&gt;()` function call, or `(foo &lt; bar) &gt; ()` and likely requires information from the resolution pass (to work out if `bar` is a type or not) to parse correctly. Using `::&lt;&gt;` means there is never an ambiguity.
Well, custom fonts don't generally look bad; as long as you use one that has hinting it works nicely (the one I showed is an example). `:)`
Every string of type `&amp;str` from inside a dynamic crate will be a dangling pointer when the crate is unloaded (even ones that are not `'static`... `'static` is the "least dangling" string literal possible). If you want to be able to keep a string around, you either need to directly pass back a `~str`, or copy the string to a `~str` before you unload the other crate. (NB. I don't fully understand the situation so what I'm saying may be a complete tangent. :) )
Does [#11839](https://github.com/mozilla/rust/pull/11839) relate to [#8613](https://github.com/mozilla/rust/issues/8613) ?
That is a bad formatting runtime IMHO and I hope to replace all the vectors in it with explicit function invocations in the expansions of format strings.
&gt; The evil environment pointers has been removed from bare functions, as well as self now being a mostly-normal argument, to the compiler. This was a huge effort (88 changed files with 1,436 additions and 2,138 deletions) by Eduard Burtescu, and is awesome! It certainly looks like an heroic effort, however I must admit the impact is not so clear. I gathered from the discussions that there was consensus that the environment pointers were evil, but I must I don't quite understand why. Is there an explanation somewhere about the motivation behind such a change and how the various function types were/are represented in memory (before/after) ?
I'll admit, I'm not the fan of the syntax. My main gripes are: 1. It's very verbose. `forall` seems like a pretty long keyword. I'd prefer it was shorter like `gen` or something. 1. I don't really think it conveys the right meaning `for`, `for each` are loop constructs, and this seems dangerously close to a loop (e.g. `for all in range(0,Inf)`). 1. There is too much `for` in `forall&lt;T, U&gt; impl Trait&lt;T&gt; for Foo&lt;T, U&gt; { ... }`
So what made this evil? And does this change mean that bare functions can no longer be coerced to closures, or does it just involve the implicit construction of a shim now?
I also like the current syntax better. Here's another alternative. Turn the current: struct Foo&lt;T, U&gt; { ... } impl&lt;T, U&gt; Trait&lt;T&gt; for Foo&lt;T, U&gt; { ... } fn foo&lt;T, U&gt;(...) { ... } into: struct&lt;T, U&gt; Foo { ... } impl&lt;T, U&gt; Trait&lt;T&gt; for Foo&lt;T, U&gt; { ... } fn&lt;T, U&gt; foo(...) { ... } Edit: I still prefer the original syntax though for the following reason. The impl line refers to "Foo&lt;T, U&gt;" but in the definition of the struct the parameters &lt;T, U&gt; follow the identifier, Foo, in neither my alternative nor cmr's. The original syntax is clearer on this point.
g++ -ffreestanding Assert that compilation targets a freestanding environment. This implies -fno-builtin. A freestanding environment is one in which the standard library may not exist, and program startup may not necessarily be at "main". The most obvious example is an OS kernel. This is equivalent to -fno-hosted. 
I tend to agree with all of this. `forall` makes sense from a type theory point of view, but most programmers aren't type theorists. And it's verbose. I appreciate the effort that went into the proposal though!
@Uniq&lt;strncat&gt;: thanks for the answer! I believe that the calling convention used by Rust is: put the arguments in registers, until you run out, then spill the rest on the stack. In this case, this (useless) environment pointer would uselessly clobber a register. I am as curious as you as to how functions are transformed into closures, I read on the PR comments there had been some issues of lifetime in the first tries with `static` functions.
Aha! Thank you. Been awhile since I've written C++ but I definitely remember some weirdness when you wanted to do templates of templates,... you had to throw some spaces in so it didn't think it was a shift operator or something.
Sorry :(
&gt; It might be the language with the best potential as a substitute for C. I don't know about C but I hope that for me it will replace C++ ... I'm just hoping there will be a usable (read: non ugly) GUI library for Rust so I can write my desktop software in it.
I still don't understand why. It is said that rustpkg served no good purpose, but for me it felt kind of nice, just using rustpkg build and rustpkg test. Short and easy. I suppose this also works with rustc and i just didn't know about it? :)
The Rust game subreddit is here: http://www.reddit.com/r/playrust/ Here it’s for «The Rust Programming Language».
Sorry
Possible optimizations that come to my mind are (some might not be implemented): * In a way that generics work Rust have mostly static dispatch (as C++) so the compiler can just emit direct jumps and calls instead of indirect ones (the latter tend to be expensive even on modern processors), while in C you'd need to use macros or copy'n'paste code (or just use function pointers and indirection. * Mentioned by you alias analysis - especially that AFAIU you cannot use borrowed reference and mutable borrowed reference so you DO know that writes can be reorganized with reads for borrowed pointers while you cannot express it in C. * Escape analysis - if you have `int x = 0; foo(&amp;x); for(int i = 0; i &lt; x; i++) bar()` you need to load and unload `x` on each loop iteration because `x` might've escaped by `foo` and `bar` was modifying it - rust can see if it's mutably borrowed or not. 
task local GC
Well I removed it because it was blocking a snapshot. But, `rustc --test lib.rs; ./cratename`
&gt; `Foo&lt;int&gt;` (that is, type `Foo` instantiated with type `int`) is not the same type as `Foo&lt;**unit**&gt;` (that is, type Foo instantiated with type `uint`) Minor typo, but I had to think for a second to figure out which should be which. :D Personally, I like the syntax because it's declarative. I think the verbosity (though is six characters really "verbose"?) is a cognitive benefit because it's immediately obvious when scanning code that the declarations are polymorphic. I find the "`forall` is too close to `for` and `for each`" argument a little weak, though. I guess I should check the ML for more convincing arguments in the other direction.
Reading this over on the mailing list, I really like the idea of adding generic blocks or generic modules to help with reducing the verbosity of the language when writing several types and functions that all share common type parameters with common bounds. That would really help clean up some verbosity.
If you're just interested in using SDL2, someone's already made Rust bindings [here](https://github.com/AngryLawyer/rust-sdl2). If you want to know how it's done, just look at the source.
Do we currently guarantee such an optimization? If not, can we? Does it require us to actually begin handing aliasing information to LLVM?
I gather that the biggest benefit of completely removing the env pointer (as opposed to changing the env argument order) will be for the relationship of trait objects to closures. Right they have different implementations, but with this change the compiler can start to think of the 'self' pointer the same way it thinks of the environment pointer. It is a useful step on the way to making closures an implementation of traits.
Is there a roadmap for traitifying closures, and is it a blocker for 1.0? Are there any other semantic changes necessary for such an initiative, e.g. variadic type parameters?
Compare it with the removal of `rusti`. The problem with `rusti` was that it does not do what you expect (it is just a hack to get a crappy REPL without global states) and still it comes by default. It is exactly same as the problem with `rustpkg`: everyone tries to use `rustpkg` since it comes by default and becomes frustrated as a consequence. It *can* be useful to some extent, but keeping it as is cannot be justified for that reason alone. That said, please note that this version of `rustpkg` is actually the third (I think) attempt to get a sane package manager. We've done the same thing three times and still we didn't come up with a workable design at all. That's why brson wants to hire a domain expert in my opinion---the good design, in this case, seems hard to achieve only with the community efforts. (And `rustpkg` is largely designed by one person, tjc, anyway.) I've personally seen the similar cause in D, and while I think the removal of `rustpkg` and consequent explosion of discussion is unfortunate, it makes some sense now.
It's somewhat two fold. I want to both play around with SDL2 and learn how to use the FFI, which is helpful since that does the git version of rust rather than a release.
We need to start handing alias info to LLVM, yeah.
I like the idea, maybe a different keyword. Just an idea, perhaps: given&lt;T, U&gt; struct Bob { ... } 
This used to be the case with C++, but no longer applies with C++11. Don't remember how they fixed it off the top of my head. 
An [unloadable crate](http://redd.it/1u2b6a) will only be unloaded when all functions in it have returned from execution. Please see the previous post I linked to. I don't mind this post turning into a discussion of unloadable crate, I rather hope to get the researchers' thoughts on this. It might be a cool way to implement plugins and is related to sandboxing as well. 
Yep, create an empty struct: struct MyFoo; extern { fn extern_func(a: *MyFoo); } 
The issues are similar, but separate. The only thing pull request [#11839](https://github.com/mozilla/rust/pull/11839) does is give an error on types that would be infinitely large in memory (avoiding a few places rustc could stack overflow). I think issues [#8613](https://github.com/mozilla/rust/issues/8613) (and the related [#4287](https://github.com/mozilla/rust/issues/4287)/[#8727](https://github.com/mozilla/rust/issues/8727), and the more distantly related [#4363](https://github.com/mozilla/rust/issues/4363).. whew) are still a problem, since they deal with ways of causing infinite instantiations of generics, without any individual type necessarily being infinitely large.
As I posted on the ML, I think this proposal is on to something because neither of C++, C# or Java put the type bounds between the function name and the function parameter list. Even if the proposed syntax is not for everyone, I think we will really, really want something like it as people write more sophisticatedly typed programs.
That might be true... but it's not at all relevant to the post.
Although struct works, the recommendation is to use empty enums so the constructor is removed. enum MyOpaqueStruct {} See the [cheat sheet](http://static.rust-lang.org/doc/master/complement-cheatsheet.html#ffi-foreign-function-interface) for more information. You could also use std::unstable::intrinsics::{Opaque}.
To be blunt about it, I think the main reason rustpkg failed to catch on was that few people were interested in giving feedback during the point in the design process when that feedback could easily have been applied, while many people became interested in expressing opinions once the work had already been done. It's true that I did most of the work on rustpkg, but another Rust team member (Graydon) contributed to the design extensively, and several other core team members reviewed every pull request I made against rustpkg. Despite that, none of them pointed out the apparently major problems with the design (which, admittedly, I still haven't seen an articulation of; perhaps that's being discussed privately) while the work was ongoing. I'm not exactly sure how one person with a lot of domain knowledge would handle this problem. I can still imagine a situation where that person comes up with a well-crafted solution and yet, another explosion of mutually contradictory ideas ensues. Perhaps the community is just too big now for a single package management solution to be accepted, and the only solution that remains is for rustc to generate dependencies to be read by other tools, and for there to be no officially "blessed" tools for building and packaging. I've moved on now and am not particularly disappointed about this work being discarded, but I hope there is some sort of transferable knowledge that the community can extract from this episode.
I really am sorry about removing rustpkg... I hate to see so much work be `git rm`d. I don't even know what the problems are with it either. (What follows is a poor excuse to soothe my conscious:) If there wasn't an issue open about removing rustpkg, I would have ended up fixing it instead. Path of least resistance.
Can we extract it into its own project? or does it need to be part of the core repo? 
There's no reason it needs to be in the core repo, just makes updating it easier.
say I wanna review Rust-pkg, and compare it to the suggested replacements in two issues at github, would it be the best to just get and install the latest Rust-commit until its removal? 
&gt; the good design, in this case, seems hard to achieve only with the community efforts Something something cabal nix. In general, this is a solved problem, and neither the requirements [nor the implementation](http://www.well-typed.com/blog/12) are any kind of trivial: &gt; Note that this is actually an NP-complete problem. It's possible to encode 3-SAT into the package dependency problem. Fortunately most real instances are fairly easy so we need not give up hope. Once the technical side is taken care of, yes, please, let the community bikeshed about command line syntax. But trying to re-invent the underlying wheel by community design is abandoning good ole meritocracy for the worst aspects of democracy.
If someone does wish to extract it into a separate repo, I've [downloaded](https://api.github.com/search/issues?q=label:A-pkg+repo:mozilla/rust) the current list of bugs tagged `A-pkg`: https://gist.github.com/huonw/de80d81e202c05c86d9f (The main purpose of that is to record which are still an issue *now*, since they'll likely be closed progressively and any other information about the bugs can be retrieved from the github API.)
&gt; I don't even know what the problems are with it either Wait, what. Is it just me or does that sound bit crazy? Not even the person removing rustpkg knows why it is removed. Who actually decided this? Who does know what the problems are? brson alone? I quickly checked this years weekly meeting notes and twir and could not find anything relevant. There is some serious communication issue going on here now.
Great! I think this should be a standard language feature.
I am also quite disappointed by the lack of justification for this decision. I've been watching the development of Rust since v0.4, and the development process has been very transparent all this time. I really don't get why it's different, for this one.
Standard language feature should be global values initialized before main (as in C++), not lazily.
Reminder that the term "meritocracy" is [literally a joke](http://www.garann.com/dev/2012/you-keep-using-that-word/): &gt; The word meritocracy comes from a political satire. It was never meant to be something we should aspire to. It was the opposite, actually, a warning about how we rationalize what we believe we’ve “earned” I think that's a point that's extremely relevant to this discussion (and many others related to Rust), lest we elevate decisions made by people to the status of objective.
&gt; A meritocracy is a system for centralizing authority in the hands of those who already have it, and ensuring that authority is only distributed to others like them or those who aren’t but are willing to play by their rules. So much for that old definition of meritocracy, I don't see much centralising in the FLOSS community, on the contrary. Many political terms shifted in meaning, over time. &gt; I think that's a point that's extremely relevant to this discussion (and many others related to Rust), lest we elevate decisions made by people to the status of objective. You completely miss my point. My point is that we should re-use all that research and development that specialists in that field already have done, because it is *objectively* superior to what the rust community would come up with if left to its own bikeshed. Because virtually noone knows what they're talking about, in this case. I certainly don't, I just know some rough outlines and that I'm out of my depth. Cabal has gone through a good decade of development and refinements, nix is an academic project. This is not me saying "Duncan Coutts is god, let's all worship him, for he knows monads". It's me saying "let's steal their work, because it has merit".
See Rule #2: Constructive comments only.
I'd be opposed to this. This has caused us no end of performance problems in Firefox and you get into nasty ordering issues in which you don't know what order to initialize variables with separate compilation.
If you want safe, manually initialized global statics without the atomic checking overhead on every access, you can do something like this: mod example { static mut MY_STATIC: *MyType = 0 as *MyType; pub struct Inited { priv x: () } pub fn init() -&gt; Inited { unsafe { static mut ONCE: Once = ONCE_INIT; ONCE.doit(|| { MY_STATIC = ... }); } Inited { x: () } } pub fn get(evidence: Inited) -&gt; &amp;'static MyType { unsafe { &amp;*MY_STATIC } } } The only way to get ahold of an `Inited` is to call `init()`, therefore passing one to `get()` is sufficient evidence that initialization has happened, and so the check can be omitted. Of course this requires plumbling around the evidence wherever it's needed. No free lunch. (Though you *can* still call `init()` in separate places, at the cost of the atomic check.) (You could also enforce single-access rules (implying single-thread-at-a-time) if you wanted to by making `Inited` non-copyable, and `init()` return `Option&lt;Inited&gt;`, returning `Some` only the first time it's called, or something like that.)
I seem to remember that Rust allows dependency cycles ? AFAIK, if there is no dependency cycle, then you can topo-sort the modules and load/unload them in an order that involves neither initialization nor destruction issues.
Yeah, no doubt there are solutions with less overhead. My goal here was to get as near as possible to a regular static variable in definition and usage, and I'd say that went pretty well. ;) If we get the Deref trait, I could even get rid of the .get() there - but of course, the question is if that kind of obfuscation is actually wanted.
YES! I’ve been wondering how to do this for a while. Maybe overhead can be reduced by not calling `ONCE.doit()` if `s` is already non-null?
It cannot be done in shared libraries in sane and portable way. Windows DllMain (entry point of shared library) prohibits various operations there, including loading libraries - all you can do is call some Kernel.dll functions - and not all of them IIRC (no, the list of safe functions does not exists) - you don't even have necessary access to C library. In certain cases you don't know the order of unloading of libraries as it is not defined on this platform as well - if you do it always manually you are probably relatively safe but if you terminate program all bets are off. Finally there are subtle differences of how threads and libraries behave on termination which also poses problems for the post-main unloading if you want to be portable. This is of course in addition to problems mentioned by others which are on all platforms.
&gt; Many political terms shifted in meaning, over time. The problem is that this assumes that meritocracy can ever actually exist. The point of coining the term was that it cannot. Meritocracy is (literally) a joke.
I'd expected `ONCE.doit` to do something similar internally, but no idea. I have done zero performance testing or IR analysis here. :)
 pub mod ffi { pub enum Something {} extern "C" { pub fn init_something() -&gt; *Something; pub fn some_method(x: *Something); } } pub struct Something { priv ptr: *ffi::Something, } impl Something { pub fn new() -&gt; Something { Something { ptr: unsafe { ffi::init_something() } } } pub fn some_method(&amp;self) { unsafe { ffi::some_method(self.ptr) } } } fn main() { let x = Something::new(); x.some_method(); }
It's not impossible but [not so simple][1]. You still need additional memory barriers and/or TLS. I have no idea how performance compares between the various options. (And `ONCE` itself [isn't so trivial][2] either.) [1]: http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html [2]: https://github.com/mozilla/rust/blob/e1580f6d09f0cd990c3eed55b1d6181af3258791/src/libstd/unstable/mutex.rs
TIL about re-ordering issues. Thanks.
I really like this proposal. I don't pretend to understand the objective pros and cons, but based on the way I've used generics in other languages, this syntax *feels* incredibly appropriate. It's sometimes hard to grok that templates actually act like their namesake, even if you're very familiar with them.
This subreddit is for Rust the programming language. You are probably looking for [http://www.reddit.com/r/playrust].
Wrong sub reddit my good fellow. This is the sub reddit for Rust the programming language by Mozilla, not Rust the video game.
/r/playrust
Yes
No operator overloading for 1.0?
Haha, yes I am. Thank you for the help.
Yeah this was just meant as "apropos, here's another thing you can do", not a commentary on the OP. :) (In this specific instance the code I posted doesn't even make so much sense, because if you're storing the `Inited` evidence you could just as well store the result of `get()` instead, and be no worse off. But this is a useful technique in many similar situations (like initializing a foreign library), and it's good to have it floating around in the general consciousness.)
Welcome! :)
Neat! But how come you can't chain them? 
A limitation of the sanitizers. They all want to intercept the same functions. clang also has this restriction.
To add to your first point: because of the way generics work in rust, values can be represented unboxed and without any type tags. This reduces memory usage and improves cache behavior.
Yeah, this was actually the plan all along: bootstrap Rust from OCaml, spend a few years iterating until the language is good enough, then bootstrap Alex Crichton, we're just at the start of this last phase now (bors was the first version of this AI; you can see the difference using Rust makes over using Python).
Great. Can't wait for alexcrichton.js via emscripten.
Slightly unrelated, but how do you copy the code and keep all the git history for the files in place?
Also note that Alex landed the one-mutex-to-rule-them-all yesterday: https://github.com/mozilla/rust/commit/984727ff87bb8a9f345ababf473d1141f9e05c08
git filter-branch --subdirectory-filter
Whoa, cool! Are there any benchmarks on this? I'm really glad that M:N is still getting love.
It has never been intended to drop out M:N afaik.
True! Didn't mean to imply otherwise, sorry. It's probably just a perception issue on my end, but when I first started following Rust it seemed like they were aiming to provide cheap Erlang-like green threads that you could spawn in the millions. Of late, (in part due to the impending switch to a 1:1 default) it's seemed like that's not a goal / priority. I'm not sure what the intended use case for M:N is so long as there isn't much per-thread savings in cost compared to 1:1, but I'm happy to see it's still getting dev attention. (Thanks, achricto!)
Heh, I could like being 'the gorilla dude'
thanks!
Actually I'd have liked to have TSan support when developing the concurrent data structures in Servo. If you aren't creating your own fancy concurrent data structures, then TSan isn't very useful in Rust (yay data race freedom!), but when you are it's useful to have assistance. Perhaps it'll be the case that, as Rust libraries get more and more mature, the need for TSan will wither away as the vast majority of concurrent applications can just use the data structures provided by the libraries. That isn't the case for Servo yet though, because the problems it faces are not embarrassingly parallel.
Welcome aboard!
To be honest, there has been talk about combining them, and it is not like it's been said it would never been done, however each sanitizer uses shadow maps and interceptions and apparently combining them would pose a significant challenge.
Thank you for clarifying.
Why are you doing this to me?
ta!
I think you have the wrong subreddit - did you mean to go to /r/playrust? This is the subreddit for Mozilla's programming language called [rust](http://rust-lang.org).
Sure, no disagreement there.
But I guess they won't be cheap to spawn because of the relatively large stacks?
Are conditions going to say in the language, or are they going away eventually?
The `--pretty expanded` flag runs (and prints) macro expansion.
8MB is the default, correct? How does one specify a smaller stack? What would be a reasonable stack size for something that doesn't recurse? Could one go as small as a few hundred kb? Sorry to pepper you with questions. :P
You can only select on std::comm::Port, i.e. on Rust's inter-task communication port, not on TcpStream or other i/o streams (yet?). There's some documentation in the module std::comm::select (which for some reason doesn't seem to appear in the HTML docs): https://github.com/mozilla/rust/blob/master/src/libstd/comm/select.rs
Conditions are implemented as a library, so it's not like they can be removed from the language. Whether they'll remain in the stdlib, though, I have no idea. They certainly haven't seen as much use as we thought they might.
There's the [`Select` structure](http://static.rust-lang.org/doc/master/std/comm/struct.Select.html), to which you can add `Port`s for selection, and retrieve [a `Handle` in return](http://static.rust-lang.org/doc/master/std/comm/struct.Handle.html). Without testing, it looks like it may be something like: use std::comm::Select; let mut sel = Select::new(); let h1 = sel.add(&amp;p1); let h2 = sel.add(&amp;p2); let id = sel.wait(); let data = if h1.id == id { h1.recv() } else { h2.recv() }; // use data There is [a macro](https://github.com/mozilla/rust/blob/ef53b7a97c58f65ac6967dfc6d30a4354afa34a3/src/libstd/comm/select.rs#L63-L77) that does this for you, but it has to be copied out of the source, for now. In any case, it's not complete.
The module is private, but the relevant contents are reexported at the top level of `std::comm` so the docs are appear there, i.e. [the `std::comm::Select` struct](http://static.rust-lang.org/doc/master/std/comm/struct.Select.html) and [the `std::comm::Handle` struct](http://static.rust-lang.org/doc/master/std/comm/struct.Handle.html).
[2 MB is the default](https://github.com/mozilla/rust/blob/acb1ec0b6715a529e3f6a7053737d99f03971c27/src/libstd/rt/env.rs#L20), and `std::task::TaskBuilder` ([docs](http://static.rust-lang.org/doc/master/std/task/struct.TaskBuilder.html)) &amp; `std::task::TaskOpts` ([docs](http://static.rust-lang.org/doc/master/std/task/struct.TaskOpts.html)) allow you to specify the size manually: let mut task = std::task::task(); task.opts.stack_size = Some(100 * 1024); // 100 KB task.spawn(proc() { ... }); (NB. I haven't tested that, and the interface will possibly change in small ways in future.)
&gt; *T doesn't seem to have an iter() method, and I've shadowed the slice. Ah, true... maybe don't shadow it then? :P
System LLVM would be nice just for compile times.
You can push the optimisations a little harder with `--opt-level=3`, although it doesn't make much difference in this case (the operations are not particularly vectorisable). In any case, I just tested, and the Rust Alder32 is actually 20-25% faster than zlib on my computer: test adler32::test::bench_native ... bench: 1038120 ns/iter (+/- 77773) = 2019 MB/s test adler32::test::bench_rust ... bench: 798313 ns/iter (+/- 60731) = 2625 MB/s 
I'm hoping they are on their way out. They look a lot nicer on paper than they are in practice. Not going to miss them at least.
What is meant by "System LLVM", and how does it help compile times? Is that just referring to the local install of llvm instead of a bundled one?
Brilliant, thanks! I'll be sure to play with that this evening.
Oh, *that* compilation time. Makes sense, thanks.
How is my life at risk by using exceptions? C++ can be memory safe with a reasonable subset of exception handling. Sure.. you can screw stuff up.. like in any language.
Yay for any change that solidifies semantics around borrowing in the language. Boo for anything that necessitates `Cell&lt;T&gt;`. Amusingly, "responsible" Rust closure semantics continue to converge on something more like pre-lambda strategy pattern usage in C++/Java/C# (referring specifically to the `try_finally` workaround outlined in the post). I recall joking about this to either nmatsakis or pcwalton once, several months back, when the original plan for converting closures to Thunks/Traits was floating around (I believe there was also some discussion of the idea of explicit capture specification ala Obj-c or C++11). He said we (perhaps he meant the *royal we*, because *I* certainly had no part in driving this) had some hat-eating in store as the language moves away from magic-env-capture-based closures towards something more explicit. That's progress!
Seems like a reasonable plan to me. Anyone know what a single-sentence summary of the "high-level idea" of how it *currently* works might be? I.e. if the future will be that: &gt; the borrow checker will treat a closure as if it were constructing a record with one borrowed pointer for each variable mentioned in the closure then what we presently have is: &gt; ???
Hm, i find both required work-arounds quite awkward here. But i'm not sure i fully understand the problem it is addressing.
I kinda have one issue with `Result` in general. What would be best approximation, when you know error occurred, but there are couple of ways to handle it: a) sometimes just `fail!` b) attempt to return partial data but notify error happened c) ignore error occurred I don't see Result really fitting the use case b). Anyone got any idea, what would be closest approximation?
Okay, thanks for the information. Basically, I only wanted to know whether select on channels exists. As it does I'm happy and pleased :-).
A weird mix of sometimes borrowing and sometimes not, leading to memory unsafety, e.g. [#11873](https://github.com/mozilla/rust/issues/11873).
Surely any library meant to be distributed as a .so and linked with C/C++ code, where it would probably be an advantage not to be dependent on the full Rust runtime. Another environment would be bare metal on microcontrollers, though that is so constrained you'd probably have a separate customised standard library anyway.
You'd have to ask Niko for a more comprehensive list (I don't see a "closures" tag on the bug tracker), but here's one of the issues that dbaupp linked above: https://github.com/mozilla/rust/issues/11873 EDIT: I bet quite a few of the open bugs mentioned in https://github.com/mozilla/rust/issues/2202 relate to this as well.
I don't have code off the top of my head, but it can violate memory safety (and I'm sure you could craft security exploits around it), so we absolutely must fix it.
What are the exact plans for overloading? What will be overloadable and how? Do you plan to add some syntax sugar like pythons array[2:2, 2:2]?
That would be great! The humble dual core netbook I use for Linux takes a few hours to build a Rust release. :(
Stay tuned we're close to announce a meeting in this month. :)
/u/Jemaclus FYI, there is another impl here: https://github.com/Hoverbear/rust-rosetta/blob/master/lzw.rs
Cool, yeah, I noticed that Hoverbear had started a rust-rosetta repo. That file is similar to my lzw_compression.rs file here: https://github.com/brianseitel/rust-rosetta/blob/master/lzw_compression.rs The main difference is that he's using matching, which I'm not (it makes sense to use that, though), and I'm using u32s while he uses ints as the dictionary key. Also, these examples read/write ~strs, whereas my original post is about a byte-based compression. In other words, the input/output is ~[u8] instead of ~str. Thanks for the tip!
er, oops. I'm actually just decompressing the ~[u16] that ```fn compress()``` returns and not actually re-reading the file. I'll fix that shortly. It would still be the same data, though, so I doubt this would fix the problem.. 
No time today to read code, so instead I'll hijack this thread to ask: coming from a web language background, what inspired you to start learning Rust? How has your experience been so far? What areas of the language are you most mystified by, and what areas make intuitive sense?
Sorry?
Cool, great questions. I'll answer them separately below: &gt; coming from a web language background, what inspired you to start learning Rust? I'm inspired because I'm a Senior Software Engineer who has been working with PHP/Ruby/Python/Javascript for almost 8 years. I feel that I've mastered the web language thing. Not so much that I know everything there is to know about them, but that I'm confident enough in my abilities with them that I can do anything I want to with minimal effort. For instance, I could recreate the LZW Compression algorithm in PHP in under an hour, most likely. I'm not really interested in doing that, but I could. I want to try something new. I messed around with C a few months ago. I tried to write a MUD from scratch, something I did back in the late 90s when I actually used to code C. That was 15 years ago and I've forgotten nearly everything. I ultimately decided that C was a bit too... what's the word... archaic? complex? annoying? ...it doesn't really fit what I would consider modern programming or follow what I consider modern practices. I actually wound up writing a super basic MUD in Ruby shortly after that. C++ is fine, I guess, but I recall using it in college and realizing that it was bloated even then. I picked Rust mainly because I saw a few Hacker News articles about it, and it looked enough like C that I could potentially do some cool stuff with it. I'm a bit bummed that I can't make a MUD out of Rust, but maybe someday... It would be awesome to have the opportunity to contribute the kinds of things to Rust that would make that possible (if it even is). &gt; How was your experience been so far? I love it. I'm challenged, and I'm learning new things every day. Coming from high-level languages that are OOP and/or functional, I'm having a hard time wrapping my head around a lot of the things that lower level languages have to worry about, like ownership, borrowing, lifetimes, bits/bytes, and so on. I know enough about strongly typed languages from my Java experience, but casting back and forth is giving me some headaches. I've found that the folks on #rust are super, super helpful when I have really dumb questions. Nobody talks down to me and nobody treats me like an idiot (even though I feel like one and I don't have a clue what you folks are talking about when you do something like Rc&lt;`a, T&gt; or whatever. Someday...). The documentation is fantastic, though I wish there were some more examples. I hope to contribute to some of the documentation when I figure things out, but I'm not confident enough to do so yet. Sorta related, I wrote [a blog post](http://blog.brianseitel.com/2014/01/17/learning-rust-0-9-the-hard-way-read-on-my-own/) about learning Rust and writing a Fibonacci sequence generator. I'm probably **totally** wrong about a lot of things, but I'm making an attempt to document my process so far. &gt; What areas of the language are you most mystified by, and what areas make intuitive sense? At this point, I'm most mystified by Traits, Enums, Structs, and Impls and how they relate to each other. Every time I think I need one of those, I'll go back to the tutorial/manual and check it out and see if I can wrap my head around what I'm supposed to be doing. So far, though, I have wound up just making a lot of variables and using those instead of using structs or enums. I haven't really come across a good use case for the Chan/Port thing yet, either, though it is featured prominently in the manual/tutorial. The most intuitive part has just been the regular logic -- if-else, pattern matching, types, etc. I think the way Rust handles Options and stuff is neat, but sometimes it's frustrating to receive an Option type when I think I should receive something else. For instance: let path = Path::new("file.txt"); let file = File::open(&amp;path); if (file.eof()) { } // throws an error, because File::open() returns an Option. I sorta get why it has to be matched or unwrapped before using it, but I'm not used to that kind of thing, so it's jarring. &gt; What kinds of things are you interested in doing with Rust? You didn't ask this question, but I think I'd like to answer it anyway. I want to eventually be able to use Rust to build fast, memory-efficient compiled apps that can assist with my web stuff. For instance, I'm currently working on a system that does a lot of work with addresses (i.e., 123 Main St, New York, NY). With PHP, it's trivial to do certain things -- but it's also very slow. Concurrency doesn't work very well. I'd eventually want to be able to write something to offload a lot of these address manipulation tasks to a background process to handle them efficiently. We're talking over 100MM addresses. Right now it takes *days* to do some kinds of analysis with that kind of data. I realize speed isn't a priority with Rust, but you know what I mean. I would also like to be able to get to the point to contribute to Rust core. If I learn enough, perhaps I can get Rust to the point where it could support something like a MUD or something along those lines. I'm most interested in solving real-world problems. Recreating an old compression algorithm is just a learning exercise, but if there's a real situation out there that can be solved, I want to do it, and I want to use Rust as another weapon in my arsenal. I'd also like world peace, a house in Hawaii, and to tour with Garth Brooks. Hey, a man can dream.
zlib is installed as libz.so on linux systems. So I assume this is related.
On a similar note, `read_compressed` is reading an extra `0u16` at the end, that isn't in the file. This is leading to an extra `'\0'` byte being written to the decompressed file.
In case you miss my message on #rust, there's an extra `\0` byte at the end of the output file which I traced it back to `read_decompressed`. It looks like `read_be_u16` isn't reporting `eof` correctly until after it has encountered a read error. EDIT: I tried diffing pg20.txt with pg20.txt.decompressed. Something in your implementation isn't dealing with repeating characters correctly. For example, "BOOK VIII." gets changed to "BOOK VII.", and "http://www.gutenberg.org/2/20/" is changed to "http://ww.gutenberg.org/2/20/". Other examples are multiple newlines between paragraphs, and "\*\*\*" strings around headings. EDIT 2: Try the following input: aaa aa a I get: aa a a As the decompressed result.
Thanks a ton for the detailed reply! &gt; I realize speed isn't a priority with Rust, but you know what I mean. This is wrong! We care so much about speed. We'll either be as fast as C++ or we'll die trying. &gt; I would also like to be able to get to the point to contribute to Rust core. Maybe take a look at the "easy" tag on the bug tracker: https://github.com/mozilla/rust/issues?direction=desc&amp;labels=E-easy&amp;page=1&amp;sort=created&amp;state=open . They are not always very easy! Sometimes we are bad at tagging. And if you do get ambitious, feel free to ask around in #rust-internals if you need some mentoring.
I've looked at the "easy" tags, but it's all Greek to me... I'll keep digging around. Thanks. :)
Most of my work is in web development as well--though I did some app/systems programming in college--and I'm interested in Rust because sometimes I want to do something really really fast (especially graphics), but C and C++ have what seem to me to be silly restrictions based on historical context. So I'd love to see a modern bare-metal language built from the ground up.
Yep, I'm a web programmer too! Rust was the first systems programming language that actually let me focus on program logic instead of constantly stressing out over memory or memorizing decades of accumulated corner cases and minutiae. I asked this question because I think we really have a chance to make systems programming appeal to a lot of people to whom C and C++ are just too apprehensive, and I'd like to know how we can continue to make it better.
pidigits is "just" because `extra::bigint` hasn't had much optimisation or maintainence and is very very slow.
I like to open it in my browser without downloading it, so here's a link with the `download/` part removed: http://api.cld.me/3q1V3w352v18/Hello%20Rust.pdf
/r/playrust
Ubuntu LTS. The times of bleeding edge distros are long gone for me.
What about using a struct functional update? ParamsBuilder{ run: true, .. DEFAULT_PARAMS }
I am not so sure this is a good thing. Closing thousands of issues means you are writing buggy code. On the other hand having zero issues means either your code is perfect or nobody gives rats ass about it. hmm .... On the serious note: I wish rust succeed because c/c++ is pain 
 Params{ run: true, .. Params::default() }
Issues are not just for bugs. One issue might be to "implement feature X". Feature X being missing is not a bug.
that would work ;)
Pretty neat. It seems that you could probably macro this all away, too, as long as you don't need extra logic in the setters. I don't know if you omitted this for simplicity or not, but you might as well formally implement the `Default` trait since you made the method anyway.
I couldn't get it into a one liner, this would work, though let p : ParamsBuilder = Default::default(); p.foo(1).baz(2).bar(~"foo");
The point of rust is that you can't screw stuff up.
Yes, this, exactly.
I want to expand on the Trait/Enum/Impl/Struct confusion that I mentioned earlier. I understand what Structs are, since C uses them heavily and they seem to be pretty much the same thing. Structs are pretty similar to C structs (though, I think, a bit more powerful/flexible.) I get Traits. We use them in PHP and there are similar things in Ruby. The Impl's are what screw me up. I can never remember if you impl a struct, an enum, or a trait. And also coming from an OOP background, I have an instinct to do something like: class Animal { fn sound() { print!("I say {}!", self.sound); } } class Dog extends Animal { self.sound = "woof"; } But it seems like in Rust, I have to have a struct called Animal, then another struct called Dog implement ```fn sound()``` for every specific item, rather than having a generic function on a parent thing and giving the children specific attributes. In the tutorial, you have an example that says: struct Circle { ... } then you do something like: impl Shape for Circle { fn draw(); } It seems to me that Shape is generic, and I should be able to specify a bunch of generic Shape functions -- such as draw() -- that would be able to draw from Circle's attributes. I think the shape/circle thing is a poor example, though, because each shape is drawn differently. A circle is pi * d, a square is 2l + 2w, and so on. But if you had a struct for Dog and impl'd Animal, you could have multiple kinds of Animals and they all make sounds in similar fashions, which means that I should be able to implement a generic sound() function and get the "woof" or "meow" or "ow ow ow" from the more specific Struct... Anyway, I've gone through the tutorial a handful of times and I still haven't quite figured out how do to something like the above example without repeating a lot of code. (I'm a big fan of DRY principles.) As always, I'm open to correction. Once I wrap my head around it, I'd be happy to write a tutorial or something for other noobs.
Yeah, I noticed that too. I'm unable to track down exactly what the issue is. Any ideas? :(
Rust is probably one of the few major projects on Github using the issue tracking system, but this certainly puts it in the major project category. Good job!
In rust you achieve 'inheritance' using `Traits` and sometimes `Enum`. True inheritance is planned, but not sure if it's for Rust 1.0 or later. trait Loud { fn sound(&amp;self); fn say(&amp;self) { println!("I say, {:?}!", self.sound); } impl Loud for Dog { fn sound(&amp;self) { println!("woof!"); } } impl Loud for Cat { fn sound(&amp;self) { println!("meow!"); } } let cat = Cat; cat.say(); // I say, Meow! Yeah `Impl` take some getting used to. But think of them this way - `Impl` are ways to attach functions to a data structure. That's all. They come in two flavors - freely standing implementation that add arbitrarily functions or you can implement functions defined in a `Trait`. The function attached can either be a function that takes self and is written as `SomeStruct.attatched_to_self()` or a statically called function `SomeStruct::some_func` For example struct A {...} enum B { B1, B2 } impl A { fn attach() -&gt; int { 0 } } impl B { fn attach_to_self(&amp;self) -&gt; uint { 3 } } //Example usage let some_int = A::attach(); // some_uint = 0 let some_uint = B.attach_to_self(); // some_uint = 3 If you have a `Trait` like for example a theoretical trait that does nothing, trait DoesNothing { fn does_nothing(&amp;self); } impl DoesNothing for A { fn does_nothing(&amp;self) { println!("Nothing"); } } impl DoesNothing for B { fn does_nothing(&amp;self) { println!(" Zilch"); } } As expected you can call for instance `A{...}.does_nothing() ` to write `Nothing` in console, or `B1.does_nothing()` (note `B2.does_nothing()` achieves similar ) to write `Zilch`. After that come the generics, which are a whole new can of gummy worms :) Hope it helped. See also: http://www.rustforrubyists.com/book/chapter-08.html http://www.rustforrubyists.com/book/chapter-10.html#traits
Right, I understand that. I'm just saying I'm having a hard time wrapping my head around it. I want to do *this* and I can't. I'm more than happy to work within Rust constraints, I just need to figure out how to switch my mindset over to the new process :) 
That helps a lot. I actually already went through the Rust for Rubyists book. It was super helpful :)
There is a nightly rust ppa [here](https://launchpad.net/~hansjorg/+archive/rust). 
&gt; Closing thousands of issues means you are writing buggy code. No it does not.
Start playin already Varmit!!!!
I mean in my steam library. It is just all the sudden started to work!
oh lol my bad! Sorry about that!
Thanks!
Famous last words :D
Yep, I managed to get that far today, as well. I'm baffled about that extra byte.
As I mentioned above, I think `file.eof()` might be misbehaving. But the IO functions have changed in master, so they return `IoResult&lt;T&gt;` instead of a plain `T`, which makes the error (and EOF) handling more straight forward.
Quite frankly I think using ~str is a bad idea in general, and the default string type for Rust should be something like this: ``` enum Str { Shared(Arc&lt;~str&gt;), Owned(~str), Static(&amp;'static str) } ``` Perhaps even skipping the Owned variant. Or even better, a rope data structure where each piece is one of those. After all, strings are fundamentally immutable, because no string mutation in correct in all human languages, and the only correct way to produce text, formatting with localizable format strings, intrinsically makes a new string. 
Exportable macros require `#[phase(syntax)]`, so you cannot easily use it as a primary library interface.
There already is [`std::send_str::SendStr`](http://static.rust-lang.org/doc/master/std/send_str/enum.SendStr.html) for the last two variants. `Shared` variant is an interesting idea, but will force the use of `Arc` then. If you happen to use such strings a lot, I guess an adaptive heavy-weight string will have its place, complete with an automatic promotion from `Owned` to `Shared` and so on. But it would have to live in its own library (or `libextra` and friends at least?). &gt; Or even better, a rope data structure where each piece is one of those. In general the rope does not work without a smart pointer. It is not a string but a data structure built on top of a string. &gt; After all, strings are fundamentally immutable, because no string mutation in correct in all human languages, and the only correct way to produce text, formatting with localizable format strings, intrinsically makes a new string. Strings are not only for human languages, and support for human languages needs (sometimes ambiguous or sub-optimal) sophisticated algorithms rarely related to the internal representation and/or mutability of strings anyway. :)
Any info on what rust.rb actually is? Slides don't give much away.
But how was it blocking progress? 
The goal is to come up with a dynamic loading scheme that maintains safety as per Rust. If the literal string's lifetime is bounded by the function in which it appears, then the Rust compiler will make sure a pointer to it won't remain after the function returns. In our dynamic loading scheme, the unloadable crate won't be unloaded as long as any function it defines is still on the stack. Taken together, the unloadable crate scheme maintains safety. If the writer of the dynamically loaded crate wants the string to stay around, then he will have to use an owned or managed string. Here is the output of a modified 0.8 with an example of literal string: #[crate_type="lib"]; #[dynamic_loading]; fn foo() -&gt; &amp;str { let localstr = "Hello world!"; return localstr; } temp.rs:6:17: 6:31 note: str literal made fn-bounded temp.rs:6 let localstr = "Hello world!"; ^~~~~~~~~~~~~~ temp.rs:7:9: 7:17 error: mismatched types: expected `&amp;str` but found `&amp;str` (lifetime mismatch) temp.rs:7 return localstr; ^~~~~~~~ temp.rs:5:0: 8:1 note: the block at 5:0... temp.rs:5 { temp.rs:6 let localstr = "Hello world!"; temp.rs:7 return localstr; temp.rs:8 } temp.rs:5:0: 8:1 note: ...does not necessarily outlive the anonymous lifetime #1 defined on the block at 5:0 temp.rs:5 { temp.rs:6 let localstr = "Hello world!"; temp.rs:7 return localstr; temp.rs:8 } error: aborting due to previous error Does this plan seem feasible? Thanks! 
So do you think the `static` can be removed as I suggested?
|| is a stack closure. Quoting from the tutorial, "they cannot be stored in data structures or returned from functions". So what you are trying to do is not possible with a stack closure.
&gt; they cannot be stored in data structures FWIW, the tutorial is a completely wrong on that, [modulo bugs](https://github.com/mozilla/rust/issues/11211) struct Foo&lt;'a&gt; { f: 'a || } works perfectly. It's [even used in libstd](https://github.com/mozilla/rust/blob/master/src/libstd/unstable/finally.rs#L59). (However, the second thing is true: a `||` with captures is rooted to the scope in which it was created and cannot ever leave it, including if it is placed in a data structure.)
&gt; But... oh no! Who gets to decide what words are okay and which words get you sent to the gulag?!?!?!!? This is not what happened at all! It was claimed that *"all that needs to be said is that "guys" makes some (...) feel unwelcome and disincluded"* and /u/OverAnalyzingBBFan makes the obvious point that this alone cannot be a criteria. You, talking about *"who gets to decide what words are okay"*, assumes already someone does need to decide, and if anything proves him right. There is no denying that people crossed the line with Lindsey. Everyone agrees with that. But expect me, and I would guess most people, to at best politely ignore requests to 'tumblerise' my english. Whenever I drop by the irc channel I'm there to get stuff done and discuss Rust. Not to get distracted with some fringe groups' opinion on how people should talk. 
I really want libprim (although I'm biased as my only real use so far for Rust has been for kernel development). 
Interfacing Rust with Ruby?
Use the to_utf16() function: fn main() { let foo = [0x73u16, 0x74, 0x30EA, 0x6E, 0x67]; let bar = "stリng".to_utf16(); for i in range(0, foo.len()) { assert!(foo[i] == bar[i]); } } 
A macro would be a good idea there (we already have the `bytes!("foo")` macro, after all). I see no technical reason why it couldn't be provided, but it might require more Unicode support than we currently have.
The thing is, a `u16` doesn't actually represent a UTF-16 character - Unicode has more than 2^16 code points. As you're probably aware, UTF-8 sometimes requires multiple code units per code point, and UTF-16 is no different. By having a string be a different type from a `[u8]`, Rust can check that you never make an invalid UTF-8 sequence. If were to use `[u16]` arrays everywhere then you won't get the same safety guarantee. (Rust could have a UTF-16 string type, but I do like Rust's opinionated simplicity on the matter.) Many people recommend using UTF-8 everywhere and only converting to UTF-16 at library boundaries. Check out [utf8everywhere.org](http://utf8everywhere.org/) for their reasoning.
Theory is nice. In practice, its purpose is to define "merit" as ability to satisfy the caprices of existing power structures and hierarchies. I'm not making this up; there is scientific evidence that the more a particular organization self-identifies as a meritocracy, the less fair it actually is, in ways that can be measured objectively.
Failing tests etc
Won't be able to attend, sadly. :(
Some macros to help translate Rust things into Ruby things, some patterns, etc.
This is why we build Rust binaries on CentOS 5 - because it has a very old version of glibc that is forwards-compatible. You are probably trying to build on a newer Linux then run on an older one. Besides building on a different system I don't know the solution (but there may be one!). We may eventually be more flexible in the libc's we use, or remove the dependency completely in some cases.
Thanks for reply! I am not much knowledgeable about building standalone binary but could not all dependency be packaged inside the generated binary? I did the same thing for Go e.g. generate binary locally and put on other box but it ran just fine. Anyway it is not that important. I am happy Rust performance looks much better than Java without even reaching 1.0. Thanks for that!
Your app is standalone for a compatible platform. Here, the two machines seem to have no compatible glibc shared libraries: you may have compiled your program on a recent Ubuntu machine and are now trying to get it run on a RedHat/CentOS server like machine which have less recent version of the shared libraries your app depends on (?). Although I would advise to recompile your app for your target platform, you may still get it to work on the target computer without recompiling but your mileage may vary. Below is the recipe. This is not restricted to Rust, it may work for all kind of programs compiled with shared libraries. Say your app binary is named app; copy it to a temporary directory, change directory to it then execute this command: for f in $( ldd app | awk '{print $3}' | grep -vP '\(|^\s*$' ); do cp $f . ; done This will filter the output of ldd to copy the shared libraries your app depends upon into the temporary directory. If you have extra data or configuration files and/or directory, you'll also have to copy them appropriately. You'll then have to copy all those file to the target machine. Once on the target machine, you can then try to launch your app with: LD_LIBRARY_PATH=`pwd` `pwd`/app If this does not work, it may means that the two machine loaders are uncompatible. Try to copy the source machine /lib/ld-linux.so.2 with all the other files and launch your app with: `pwd`/ld-linux.so.2 --library-path `pwd` `pwd`/app You may want to launch your app using a script, named like "app-launcher.bash": #!/bin/bash dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )" $dir/ld-linux.so.2 --library-path $dir $dir/app $@ This may still not work - I once got a message like "Cannot execute: kernel is too old"; your best option is then to recompile your app on the target machine. Also, to minimize the shared libraries to copy, you will want to compile your app statically - however some libraries come only packaged as shared objects. Hope this helps. 
Thanks for detailed reply. You guess my situation right. It was local machine with recent ubuntu but old hardware and company server with better hardware but old OS. Yes once I have some usable application I will try to install Rust on other machine for now I am just playing around comparing and contrasting Rust with Java. 
I'd love to read the implementations in all three languages, if you care to paste them somewhere!
Lol, wrong Rust.
It is on my work machine. Will post that on monday. More or less it is Rust / Go implementation of heap based Java code from link I put in my original post. The Rust version is missing memory stats as I could not find Rust lib for that.
Curious, did you let the jvm warm up before measuring? 10x seems a bit too much, I'd expect 1.5-3x the speed of java.
Report these so they end up in the modqueue.
I saw huge number of context switches and page faults for Java compared to Rust / Go. So I think it may not be a JVM warmup issue. Also I executed 5 iterations of same test in 1 run and time was almost same for each iteration. So I presume JVM would be warm enough. Also I copied Java code from above link and naively implemented Rust and Go code which should not work against Java. I used following versions of Langs Java: 1.7 |Go: trunk | Rust: trunk To me the story is there should be more awareness of Rust among Java / Scala type developers who would like to write resource efficient applications. 
I think I tried `--link-args -static` It then gave some other error. Anyway my issue I wanted to run app on bigger box with large data size. But ended up running on local machine by reducing data size. I guess Go does not use glibc since Go binary just ran fine on both machines. Considering Rust binary was 50% larger than Go I thought it would include all it need to run on similar arch.
It says that LLVM doesn't translate popcnt correctly, but was the correct CPU specified? On x86, popcnt has been added in Nehalem, so of course it won't be generated by default. It seems surprising that it wouldn't be emitted with the proper CPU specification. 
Even on x86-64 it seems to have to be explicitly enabled with `--target-feature=+popcnt`: use std::num::Bitwise; pub fn f(n: uint) -&gt; uint { n.population_count() } `rustc -O popcount.rs --emit asm --crate-type lib` gives (removing the function prelude) movq %rdi, %rax shrq %rax movabsq $6148914691236517205, %rcx andq %rax, %rcx subq %rcx, %rdi movabsq $3689348814741910323, %rax movq %rdi, %rcx andq %rax, %rcx shrq $2, %rdi andq %rax, %rdi addq %rcx, %rdi movq %rdi, %rax shrq $4, %rax addq %rdi, %rax movabsq $1085102592571150095, %rcx andq %rax, %rcx movabsq $72340172838076673, %rax imulq %rcx, %rax shrq $56, %rax and `rustc -O popcount.rs --emit asm --crate-type lib --target-feature=+popcnt` gives popcntq %rdi, %rax 
Ah, and compiling the HAMT code with `--target-feature=+popcnt` gives a nice speed up: before after bench_find_copy_50000 120 97 bench_find_share_50000 141 107 bench_insert_copy_50000 18461 15106 bench_insert_share_50000 25530 23846 bench_iterate_copy_50000 2206 1587 bench_iterate_share_50000 3226 2430 bench_remove_copy_50000 11944 8851 bench_remove_share_50000 13963 11856 (All the `hamt::test::...` benchmarks, in microseconds/iter.)
Does using `--target-cpu` not work? It's not part of the base x86_64 instruction set so it can't generate it without a more specific target.
Seems it does work.
This thread has been linked to from elsewhere on reddit. - [/r/programmingcirclejerk] [Rust is 10 times faster than Java.](http://np.reddit.com/r/programmingcirclejerk/comments/1xcdka/rust_is_10_times_faster_than_java/) *^I ^am ^a ^bot. ^Comments? ^Complaints? [^Send ^them ^to ^my ^inbox!](http://www.reddit.com/message/compose/?to=totes_meta_bot)* 
Cool! I'll update the readme shortly.
Nice! popcnt is used rather heavily for indexing and item counting within nodes. I also use a lot of assertions that could be disabled for release builds. I found that commenting them out brought another 20-30 percent in time reduction as does -Zlto ...
Memory/resource management works via reference counting, just as with sync::Arc smart pointer. The map can take anything of Send+Freeze kind (keys must also implement Eq+Hash of course). As long as T is Send+Freeze, it shoudn't be a problem to store a ~[T], for example.
Why would you reimplement that Java code? Rust's structs live on stack by default.
Using `--target-cpu=westmere` with a relatively recent i7 gave me a few percent more speed too. (It includes popcnt among other things.)
Rust does offer limited compile-time reflection via the combination of traits and syntax extensions, e.g. `#[deriving]` is nothing more than an complicated macro.
I'm unsure how flexible this facility is. Could you point me in the general direction of more information? Would it, with current facilities, be possible to implement opt-in reflection with something like: #[reflect] struct Foo { foo: str }
Not sure about the first, but having some experience with the second: The needs of an entity system tends to be quite diverse, and I've seen and implemented more than one. Rust is sufficiently low level that you should be able to implement such a system yourself, and do so generically enough that it is re-useable. I suspect such an approach would work for DB stuff too.
That's great, I'll try to be there !
I just did [one in Go](https://gist.github.com/logicchains/8882549) and [one in C](https://gist.github.com/logicchains/8883534). For me, the standard Java one runs in around 1.018s, the Go in 0.1s, the C in 0.086s, and the Java unsafe one in 0.14s (taking the quickest run for each). Note this is testing with NUM_RECORDS = 50 * 1000 * 100 rather than NUM_RECORDS = 50 * 1000 * 1000 As this machine doesn't have enough memory to run the former in Go (process just gets killed). The Go one was quite smooth to write; ~~only hassle was duplicating the switch statement, as Go, unlike Java, doesn't fall through~~ okay, it can fall through via use of an explicit 'fallthrough', nevermind.
I did a [Go version](https://gist.github.com/logicchains/8882549) and a [C one](https://gist.github.com/logicchains/8883534); for me, the standard Java one runs in around 1.018s, the Go one in 0.1s, the C one in 0.086s and the Java unsafe one in 0.14s (taking the quickest run for each). Note that's with only 50 * 1000 * 100 records, as my laptop doesn't have enough ram to run the Go and Java ones if an extra zero is added.
I have some experience with entity systems for game engines in C++, where templates and member pointers can facilitate much of this functionality (even if some boilerplate to inform the system about members must be written/generated). Specifically, what would be a workable approach to this in Rust?
That's really weird. On the plus side, if those numbers are meaningful then Rust's twice as fast as C on the Fasta and Binary Tree benchmarks, which is pretty impressive.
The pidigits test uses big integers, and Rust's current big integers library is *very* slow. That accounts for the ¹⁄₁₀₆₄ result.
While it would be great to improve the performance of `extra::bigint`, I am glad that Rust does not embed GMP on its own. Anyone willing to use GMP can always create bindings for its specialized case, and a gmp.rs could be created, but it is really specialized enough that I really do not feel it to be necessary in the core language/library.
&gt; Anyone willing to use GMP can always create bindings for its specialized case GMP is "specialised" to fast computations with big integers, so if bigints are deemed useful enough to be in the stdlib, I think we should definitely have fast ones. Anything else makes Rust look bad.
I can't decided if it's annoying or funny every time this happens.
In fact, I think `pidigits` is indeed an FFI benchmark, since every fast program uses GMP no matter the target language has a built-in bigint or not: [Python](http://benchmarksgame.alioth.debian.org/u64/program.php?test=pidigits&amp;lang=python3&amp;id=2) uses [gmpy](http://code.google.com/p/gmpy/), [Racket](http://benchmarksgame.alioth.debian.org/u64/program.php?test=pidigits&amp;lang=racket&amp;id=2) uses a DSL translates into GMP library calls, [OCaml](http://benchmarksgame.alioth.debian.org/u64/program.php?test=pidigits&amp;lang=ocaml&amp;id=1) uses [gmp-ocaml](https://github.com/ytomino/gmp-ocaml) and so on. Seriously, we just need to update [rust-gmp](https://github.com/thestinger/rust-gmp) and plug it into the benchmark; I'm very sure that this will make Rust on par with C.
What I never understood is.. Why not include as much as possible in the stdlib? Only the stuff that is used even gets compiled in, but it lowers the barrier of entry to have everything, even graphics and physics libraries, in the stdlib...
I find "Rust++" sort of amusing, but i agree. 
I did not. I should have been clearer that I just made Rust struct and referred it fields. The point was structs are not possible in Java with out `unsafe`whereas in Go / Rust they are first class type.
GMP is licensed as GNU LGPL. This was one [reason](https://ghc.haskell.org/trac/ghc/wiki/ReplacingGMPNotes#ReasonsforReplacingGMPastheBignumlibrary) that GHC wanted to replace GMP in favor of pluggable bigint implementations. Unfortunately, it is plain impossible to replace GMP with something fast enough with more liberal license: GMP achieves both the asymptotic optimality and the architectural optimality on almost every possible range (see the list of [algorithms](https://gmplib.org/manual/Algorithms.html#Algorithms) if you are interested); the only range that GMP fails to achieve the optimality is (as far as I know) for "very large" inputs that do not fit in the main memory, which require specialized offline algorithms.
I think it is because the poster can [submit](http://www.reddit.com/submit) a new link without visiting the subreddit at all. Unfortunate :S
Which graphics and physics libraries? All of them? I think that kind of policy would make for quite a messy standard library. Then you'll have the situation where people will only use libraries that have been "blessed" for inclusion even if other external libraries may exist that are faster/easier/better-in-some-way. You kind of see that with the "batteries included" Python world... external libraries that "compete" with any part of the standard library generally have to be a lot better to even get noticed. Do you believe using external libraries in Rust is really a large barrier to entry?
I don't know Rust. I'm following it's development. However, I can safely say that any language with a small stdlib not capable of at least blitting an image to the screen is much more difficult to get in to **when coming from an interpreted language**. Lots of people start with Python, JavaScript, Game Maker (for me), and we think in terms of graphics and on-screen positions... Not having that in the stdlib means the first thing we have to do is find a library, install it, etc. Suffice to say, I would find Rust much more inviting if I could start making pacman right off the bat.
 main.rs:2:67: 2:68 error: unexpected token: `+` main.rs:2 [DE]-=RUST.CASPAZ=-[PvP/Sleepers/Doorshare/25% Crafttime/Rust++] 
Can python really blit things to the screen from the stdlib? Rust is a general purpose language. It can make games, but it's not just a games programming language. Should we include database adapters for web developers? qt bindings for people writing desktop apps? curses bindings for people writing graphical command line apps? You see it becomes a slippery slope. We can't just give libs for one niche (gamedev) and not the others. And then when someone inevitably creates a better library for graphics than what is included in Rust, it creates a kind of weird decision for devs. Do I use the crappier one which is standardized, or the better one which is a 3rd party lib? Just keeping them all outside of the stdlib keeps them more equal. Once Rust gets a good package manager, what's wrong with just roping in whatever you need from there?
steam: vugrinmarko2 if anyone have it you can gift it to me :D
Which is because we just haven't tried to optimize bigints and/or provide interfaces for faster custom arithmetics. The latter is related to [#5992](https://github.com/mozilla/rust/issues/5992). But technically speaking, if Rust used more verbose syntax (so that it minimizes the allocation) there is not much difference between go's [math/big](http://golang.org/src/pkg/math/big/nat.go) and Rust's bigint since both uses the typical Karatsuba algorithm.
Disclaimer: I don't mean to sound angry in this post, just blunt. First, I think calling gamedev a niche is a huge mistake. 3d, gui and sockets are possibly some of the most-used functionalities provided to a program, and those 3 alone let you develop almost everything you would ever need to. Second, it sounds like having a package manager will be required for any serious development in Rust. If that's the case, then when a new, better "socket" lib is designed, it could be interfaced with the exact same function signatures as the existing lib and updated by all of the package managers automatically. It's like.. stdlib in the cloud, constantly updated at each stable release of any sub-library. Third, if Rust got a good package manager, why **have** an stdlib at all? It would blur the lines so much... With some library repo online, you could import anything, even basic math functions from a math library.. What about raw file operations? Those are usually included in the language, but they don't necessarily have to be... What about even just memory allocation as a library? To summarize, I simply dislike half-baked stdlibs. Either have it a living, breathing being that updates and improves all the time, in which case, it should include basically every verified library but in some online repo.. Or, have it a very small library of extremely important functions that'll let you do nothing more than computation. C++ is strange. I can make the entire logic for a game, emulate all of the physics, render the entire scene to a software "buffer"... But I can't get it to show on screen without a graphics library of some kind. Again, don't mean to sound rude, just being blunt. I'm open for constructive criticisms. 
Funny thing you posted that, I was just having problems with BigInts in my AKS tester for primes: https://gist.github.com/Denommus/8871959 For bigger inputs, Rust is slower than SBCL!
Do the numbers given in the readme reflect these optimizations?
BigInts are known to be slow. They're a super naive implementation that are entirely unoptimized.
Strange... it did work for me. Maybe it is because you have `&amp;'a str` reference in the structure. However, writing that macro without references, like in your original example, is quite straightforward. BTW, this bit is not really correct: fn default() -&gt; Foo&lt;'a&gt; You don't have any parameters of the method annotated with `'a`, so `'a` lifetime here is essentially `'static` as it is a "superlifetime" for all lifetimes. Maybe this is the reason too.
There isn't really any documentation for this kind of thing yet. The best place to look would be at the `#[deriving(...)]` implementation code here: https://github.com/mozilla/rust/tree/master/src/libsyntax/ext/deriving. The general idea is that you're passed the AST for your struct, and can generate the ASTs for things like `impl` blocks based off of that. For example, a simplified implementation for `#[deriving(Eq)]` would take the AST for struct Foo { bar: int, baz: ~str, } and then output the AST for impl Eq for Foo { fn eq(&amp;self, other: &amp;Foo) -&gt; bool { self.bar == other.bar &amp;&amp; self.baz == other.baz } } These can be implemented outside the compiler with the new external syntax extension API. There's a simple example here: https://github.com/mozilla/rust/pull/12034. You'd want to make an `ItemDecorator` instead of a `NormalTT`.
I've been following the Rust project for a long time now, but this small library is my first real project using Rust. The change with the I/O error handling was a good opportunity to update some toy code that I wrote a year ago (one year to the day !) for Rust 0.5. So, I'll gladly accept all criticisms on any aspect of the code.
This is the reason we haven't included gmp. With the direction the standard libraries are going in Rust though it's conceivable we could endorse crates with non-ideal licenses (OpenSSL is another) as long as they are kept out of the main repository.
This is the model I am counting on for Rust because it lets us start small and expand over time organically.
I imagine the C benchmarks have gotten much more attention than the Rust, so if nothing else it's promising that it required relatively little effort to best C. Furthermore, if the shootout is using the implementations from our repo (I can't find his source) then these are completely safe Rust. I'm very encouraged.
I'm not even sure how or when they started including numbers for Rust. Perhaps they're still working out the kinks. In any case, I'm guessing that they took the implementations for each directly from those in our test suite: https://github.com/mozilla/rust/tree/master/src/test/bench
This kind of benchmarking is mostly pointless. The Rust language has no costly abstractions and is thus as fast as C and assembly, except for array bounds checking. So any difference in non-array code is just measuring a difference in the way the programs or system libraries are written, GCC vs LLVM, or the way the LLVM bitcode is compiled. 
I'm not an expert on how we currently achieve this. That said, currently if you tag a type with the `#[deriving(Encodable)]` attribute, it automatically (at compile-time) generates all the machinery necessary to serialize the object. I'm not sure what the limitations of this approach are (this is likely what the OP means by "effective, if crude, serialization support"), but it's good enough for our JSON library.
Ouch, you should probably use the ```if_ok!``` macro instead of this verbose functional monstrosity. 
Well, I guess you're right, `if_ok!` seems to be the way to go. Sadly I didn't know about it, and I can't find any documentation about it. I wasn't too far off in my conclusion, that a dedicated macro may be useful ! I wonder if any real usage of `and_then`, `map` etc. is doomed to end up as a "functional monstrosity".
How does that work? From quickly looking at the docs, I get the impression that boost::fusion::for_each just iterates through the elements of a container. You're saying it can iterate through all the data members of an object, of various different types? How does it manage to do that? I should just look at the source, but advanced template metaprogramming scares me...
The haskell way is horrible to maintain and use in a distro. For example, distro x has plataform y installed, if app a just needs that, ok, but then if app b needs a different plataform or even if app c wants plataform y but also 3 libs more updated all hell starts to break loose.
I wrote up some parser combinators for use in my (incomplete) port of the code from Typing Haskell in Haskell into Rust: 1. The parsers: https://github.com/nikomatsakis/typing-haskell-in-rust/blob/master/src/parse.rs 2. Using the parsers: https://github.com/nikomatsakis/typing-haskell-in-rust/blob/master/src/grammar.rs Nothing fancy, but I thought they worked just fine...
An alternative to using the built-in `if_ok!` macro is to roll your own variant of it to suit your needs. I recently did this in some code; it was useful because I was able to throw a debugging println! into the macro after I realized that none my calls were succeeding, and I wanted to know why: #[feature(macro_rules)]; macro_rules! if_from ( ($e:expr) =&gt; ({ let i = $e; match from_str(i) { Some(s) =&gt; s, None =&gt; { // println!("failed to parse {}: {}", stringify!($e), i); return None } } }); ) fn ts_from_str(line: &amp;str) -&gt; Option&lt;TimeStamp&gt; { let year = line.slice_chars( 0, 5); let month = line.slice_chars( 5, 8); let day = line.slice_chars( 8, 11); let hour = line.slice_chars(11, 13); let min = line.slice_chars(14, 16); Some(TimeStamp { year: if_from!(year), month: if_from!(month), day: if_from!(day), hour: if_from!(hour), min: if_from!(min) }) } One particularly cute trick here is that since I'm feeding in variable names like `year` or `day` into the calls to `if_from`, the resulting `println!` calls will stringify those names into readable output, so that I can see log output like `"failed to parse year 2014J"` (which led to me eventually realizing that the slice inputs were bogus; I've preserved that error in the source above).
Rust is free. Although I wasn't aware it was a game. In fact, I'm not sure how hunting down bugs due to incorrect borrowing or moved owned pointers is fun, but it's not for me to tell other people what is and isn't fun. ... Jokes aside, you're looking for /r/playrust.
Interesting, thanks for sharing that.
my bad!! sorry ill delete this
I don't think boost::fusion makes good comparison, since it is ultimately a heterogeneous container library and cannot be used for use cases that normally require structs or classes. Well, you can inherit from `boost::fusion` (and define methods using `boost::fusion::at_c` etc.) much like Python's `namedtuple`, but in more verbose way than a plain struct/class.
This subreddit is for the Rust programming language.
I really like compile-time reflection in D: well-designed templates + [CTFE](https://en.wikipedia.org/wiki/Compile_time_function_execution). Building a serilaizer is pretty easy and feels fast. I don't know too much about Rust (I mostly lurk), but if this isn't already implemented in Rust, perhaps this is a direction it could go?
Thank you 
Well I'm glad to know that is the case then. Hope not to see those mistakes happening here :)
That'd be because your distro doesn't support multiple versions installed simultaneously per package. Cabal supports it, thus people are using it, thus lesser package managers have trouble. From all I hear, rustpkg (may in rise from the ashes) is going to, too. 
Two points: - regarding the requirement of returning `IoResult`: you may either write your own custom macro that translates the error, or just use an inner function that does the job with `if_ok` and then let the user facing function with the job of translating `IoResult` to a suitable type. - I believe there is some interest in the Haskell `do` notation used to chain monadic interactions; so it might get easier/more expressive in the future. I am afraid you are at the low-point of the redesign where much was stripped out and things are just starting to pick up.
I've asked about semantic autocomplete a few times but thus far nobody seems to have tried approaching it - I imagine it won't really show up until the language stabilizes more (post 1.0). Syntax highlighting can be slow to update as it is, having broken autocomplete is worse.
I heartily recommend you to try the Qt Creator IDE. Yes I know, there is Qt in the name of this IDE, but I can guarantee you that it is not a Qt only tool. I personnaly use it as my main C++ IDE at work, and I started to use it for coding with Rust. Qt Creator is useful for coding with Rust, because it already understands the syntax coloration file format use by Kate, and Rust comes with a [well-crafted Kate syntax coloration file](https://github.com/mozilla/rust/blob/master/src/etc/kate/rust.xml). Also, Qt Creator is able to guess the meaning of the compiler output. This means that when you compile, all errors and warnings are shown in a list at the bottom of the screen, and you can click on them to jump to the file/line where the error occurs. A right-click will show you the full error message. I'd sincerely like to write a Rust plugin for Qt Creator, I actually already thought starting one. Like many IDE, Qt Creator is a plugin-based platform, and my first impression is that it would not be that hard to provide a minimal support for Rust. It's unfortunately difficult for me to find the time to work on it.
&gt; Can you cite a source for this? I've never heard them say anything to that effect. I came across a mailing list posting that expressed this, but it might have been old or made by someone who isn't central to the development team — of course I'm unable to find it right now, but the general attitude seems to be "not a priority, potentially harmful". Others here have described the possibility of implementing opt-in reflection via attributes, which is a solution I whole-heartedly support! I'll be attempting an implementation of such a system some time soon, but it's a bit overwhelming with no mentionable previous experience in Rust.
Even Emacs' Rust mode provides these features. But no auto completion for now. 
Great new server! Love it!
&gt; Btw. Rust doesn't seem to use headers, so how compiler knows about methods / types from external crates? Is that information bundled in dlls? Yes, and it is called the metadata. For shared objects (\*.so/\*.dll/\*.dylib), a `rust_metadata_*` symbol stores the metadata. For statically linkable archives (\*.rlib), the archive has a `rust_metadata.bin` file. Additionally, every exported symbol has a hash in its name (e.g. `__ZN3foo3bar21h81d79eb4570fe165JpaF6v0.0E`) so there are only small chances for executables to fail dynamically.
Another macro approach that can cut down on boilerplate ([gist](https://gist.github.com/jfager/8901713)): *Edited to handle struct assignment* #[feature(macro_rules)]; extern mod std; use std::io::IoResult; macro_rules! if_ok_all( //Note that the Err case in these just returns, b/c this little demo is just running //from main and so can't return an IoResult. ( $($a:expr &lt;- $e:expr),+ ) =&gt; ( { $( $a = match $e { Ok(e) =&gt; e, Err(_) =&gt; return } );+ } ); ( $($a:ident = $e:expr),+ ) =&gt; ( let ( $( $a ),+ ) = ( $(match $e { Ok(e) =&gt; e, Err(_) =&gt; return }),+ ); ); ) fn something() -&gt; IoResult&lt;bool&gt; { Ok(true) } fn something_else() -&gt; IoResult&lt;~str&gt; { Ok(~"hello") } struct foo { a: bool, b: ~str } fn main() { let mut f = foo { a: false, b: ~"" }; if_ok_all!( f.a &lt;- something(), f.b &lt;- something_else() ); if_ok_all!( a = something(), b = something_else() ); println!("{:?}, {:?}, {:?}", f, a, b); } 
If a sample to this code is provided I'd be happy to.
I generally agree with what you've been saying in this thread, I just wanted to point out that your name violates rule #2.
Great ! Honestly, I'm a bit hesitant to put lots of code inside one big macro. Maybe it's harmless to do that after all, I'm not sure... I like the general idea, though !
I feel like it is unreasonable to authoritatively request others not use the gender-neutral second-person plural "you guys" in this community. It's not like English has some better alternative, because yes, in that case, usage of "you guys" would be a clear choice by the speaker to be exclusionary. But as it stands, it does not. If you disagree with me, [take a look at this](http://i.dailymail.co.uk/i/pix/2013/06/06/article-0-1A2B955F000005DC-299_634x450.jpg). This plot indicates that the way a majority of Americans use the English language would offend you. I'm not saying you're wrong to be overly literal and thus offended, I'm just saying that asserting yourself as an authority and using your authority to persuade everyone in this community to not use "you guys" is unreasonable because **you're setting yourself up for a fight against the average usage of language in a community where that is not the focus.** I do generally wish people would use gender-neutral pronouns, such as the [Spivak pronouns](http://en.wikipedia.org/wiki/Spivak_pronoun), and I do intend to use them in any technical work I do, but I feel we are creating a toxic environment if we require people to stop using "you guys" or risk perpetually offending people on the core team. I think there is work to be done convincing people to use these gender-neutral pronouns, but that is to be done by separate groups working in society at large.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Spivak pronoun**](http://en.wikipedia.org/wiki/Spivak%20pronoun): --- &gt; &gt;The **Spivak pronouns** are a proposed set of [gender-neutral pronouns](http://en.wikipedia.org/wiki/Gender-neutral_pronoun) in [English](http://en.wikipedia.org/wiki/English_language) popularized by [LambdaMOO](http://en.wikipedia.org/wiki/LambdaMOO) based on pronouns used by [Michael Spivak](http://en.wikipedia.org/wiki/Michael_Spivak). Though not in widespread use, they have been employed in [gender-neutral language](http://en.wikipedia.org/wiki/Gender-neutral_language) by some people who dislike the more common alternatives "he/she" or [singular they](http://en.wikipedia.org/wiki/Singular_they). &gt;Two variants of the Spivak pronouns are in use, highlighted in the [declension](http://en.wikipedia.org/wiki/Declension) table below. &gt; &gt; --- ^Interesting: [^Singular ^they](http://en.wikipedia.org/wiki/Singular_they) ^| [^Gender-neutral ^language](http://en.wikipedia.org/wiki/Gender-neutral_language) ^| [^Michael ^Spivak](http://en.wikipedia.org/wiki/Michael_Spivak) ^| [^Spivak](http://en.wikipedia.org/wiki/Spivak) *^\/u/youses ^can ^reply ^with ^'delete'. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less.* ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/) ^| [^flag ^a ^glitch](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=Glitched comment report&amp;message=What seems wrong: (optional description goes here\)%0A%0A---%0A%0AReply no. 50315:%0Ahttp://www.reddit.com/r/rust/comments/1nvsdh/a_note_on_conduct_please_read/cfaztwi)
I'd like to see Rust sprout support for a Haskellish do-notation for things like this. I agree that trying to approximate it in macros is tricky and probably not suitable for 'real' use.
Why is the LGPL considered problematic? I'm a bit surprised that Mozilla takes a stance like that.
Seeing that KDevelop is moving from its own 55K LOC homebrewed C++ language support plugin to a new 2K LOC plugin which uses Clang, improving both functionality and performance in the process, it makes me wonder whether effort wouldn't be better spent making `librustc` more suitable for use by an IDE. Obviously that's a really huge project, but writing a language support plugin with all the trappings from scratch isn't a small one either. (Or were you already planning to use `librustc` somehow?)
I don't see any reason you couldn't make an orm based on marcos. How often do you structure a program where a schema changes at runtime and the program has to adapt to that dynamically?
geany has full rust support
I've been working on a plugin for Eclipse, but haven't made a start on the autocompletion just yet, although it is certainly my motivation for doing so. The source can be found here: https://github.com/redoxide/ruste Version 0.0.1 is very basic; basically delegating work to the Rust parser library to generate the outline, add markers for errors and call rustpkg to build the project. There is a small utility in the 0.0.1 release that can generate an XML representation of a crate and will follow any crates defined in other files. This utility generates the AST for the outline view and I had planned to use it to generate an autocompletion index of the std and extra libraries until a more official representation was created. I've been working on a version based on Xtext to try and get as many autocompletion bells and whistles as possible, but it's an entirely different approach. I also need to push the Xtext branch up to Github. I was hoping to at least have some autocompletion working before getting too excited, but I've been directed to this discussion by one of the Rust guys. I haven't finished the website yet either - was going to do that after I had enough of the autocompletion in place. Not that that matters too much. As an aside: I also quite like Qt Creator, so would be interested to see how that goes. 
Wrong subreddit. You want /r/playrust
The Go code is listed [here](http://benchmarksgame.alioth.debian.org/u64/program.php?test=pidigits&amp;lang=go&amp;id=4), but you will also need to do a careful port of its `math/big` library for it to be a valid comparison.
&gt; In any case, pidigits will always be an unfair comparison as long as we aren't using GMP, which the top languages will be doing. It's a fair assessment of the performance you get with the libraries shipping as part of the official Rust distribution. This is the first big integer library most users are going to reach for. There are entries for other languages not using GMP, and they're usually no more than 5x slower on this benchmark as the integers aren't big enough to show off GMP's asymptomatically better performance.
&gt; Why is the LGPL considered problematic? I'm a bit surprised that Mozilla takes a stance like that. It's considered problematic because of the misconception that it cannot be used with proprietary code, or that it cannot be used by a statically linked proprietary program. In reality, you can write proprietary software linked statically against an LGPL library as long as you make linkable object files available.
&gt; Another issue with GMP, at least the last time I checked, is that you can't safely handle allocation failures. This isn't a problem, as Rust can't handle allocation failures anywhere else and won't be able to do so without changing many of the core API designs. I doubt this will happen.
&gt; This kind of benchmarking is mostly pointless. It shows the out-of-the-box performance provided by the libraries Rust is choosing to ship. This is the experience people are going to have with the language without going out of their way to find and build a third party big integer library.
Thanks for the detailed explanation. So if I understand correctly, boost::fusion::for_each cannot (yet) operate on an arbitrary type, but it can operate on any tuple-like "view" type created from an arbitrary type through BOOST_FUSION_ADAPT_STRUCT etc. That makes more sense, given what I know about the limitations of C++ metaprogramming. It's still very impressive that for_each can take a generic lambda, as in your earlier example. I guess if you really want to avoid repeatedly listing the members of a type, you could use a variadic macro that both generates the type declaration as well as the BOOST_FUSION_ADAPT lines. But hopefully someday Rust will eliminate the need for such hacks :)
That's a bit of investment. 
Discarding the best library in existence for some use case, just because it includes some extra rarely-used functionality seems dumb.
Yep; my statement was more hypothetical than an actual suggestion.
What made you go with eclipse instead of the more polished intellij idea? The community edition has been free for years now.
There are also two other Eclipse plugins that I know of, including https://github.com/reidarsollid/RustyCage (written in Scala) and https://github.com/ianbollinger/oxide (2 years out of date.) Both seem to be compatibly licensed, however. Edit (griping): I personally found Xtext unusably inefficient but maybe you'll have better luck. Both Java and especially Eclipse's API are horribly unpleasant to work with. (Let's use nulls and lazy initialization everywhere and have thread containment be our only strategy concerning concurrency!) Also, Tycho Maven is god awful nightmare; I don't know what you're using for package management and builds. Also, I'd recommend writing new code in Scala, though, since Java is basically inferior in every regard (except for Scala's compiler being pitifully slow.) 
Familiarity I guess. I don't think there was a free version back when I was a poor student. I've heard good things, so would like to try it at some point.
My buddy started a plugin for IntelliJ but it'll be a while before it has more features than any of the other editors.
Creating a plugin. Xtext seems geared toward DSLs and in my experience didn't scale up to something of Rust's grammar's complexity. It also uses a stripped-down version of ANTLR that makes certain parsing tasks impossible out of the box (e.g., it doesn't support ANTLR's semantic predicates). Last I used it (2 years ago), it was impossible to fully specify Rust's grammar, and even the maximal working subset of Rust's grammar created something unusably slow. Perhaps it's better now; and Rust's grammar has also changed drastically. EDIT: Another Eclipse technology I tried and ultimately ditched was Sapphire (which may still be in incubation.) It allows you to create forms in a declarative style which is fantastic and eliminates reams of boilerplate, and allows you to link editors with their associated models. Except that it uses obsolete annotation processing which is slightly annoying to integrate. The real problem is that the whole thing is lazily initialized so the first time it's used to construct a form the user is left waiting for a second or two while nothing happens (say, they try to open the new project wizard). Completely unacceptable. I found that switching to Scala was a better way to factor out the boilerplate, since it actually has mixins. I guess if you use a WYSIWYG GUI builder to generate forms it doesn't matter if the code looks like vomit, though. Probably the way to go in retrospect. 
Yeah there are some aspects that I am concerned about, but at the very least should be educational, and getting an insight into the grammar by digging around the Rust parser has been beneficial. Interesting that you mention the DSL focus - I was a bit worried about that too.
/r/playrust
Do you think that metadata could be useful for completion? I mean, is it possible to extract nonhashed type names, their fields, methods, implemented traits, etc. Sort of like reflection, but from outside.
&gt; how ? &gt; when The timestamps are [13 Jan 2014](http://benchmarksgame.alioth.debian.org/u64/program.php?test=nbody&amp;lang=rust&amp;id=1#log), so 4 weeks until someone noticed. 
Anyone knows if Vim will get some Rust love?
People have known about it for a while, but this post is the first time it's been publicly questioned. :)
There's syntax highlighting at least: https://github.com/wting/rust.vim
As in, we discussed it on IRC a few weeks ago. (General announcement: join us if you haven't already, links in the sidebar.)
/r/playrust
Very interesting. Never thought of doing something like that.
&gt;So if I understand correctly, boost::fusion::for_each cannot (yet) operate on an arbitrary type, but it can operate on any tuple-like "view" type created from an arbitrary type through BOOST_FUSION_ADAPT_STRUCT etc Briefly, when you pass an object to a fusion algorithm, it will try to use it as a fusion sequence. If the object does not provide the interface, it will look into an special fusion namespace for a way to use the object as a fusion sequence. There is a section in the docs about extending Boost.Fusion that goes into this in greater detail and that you might find interesting. What these macros do is they add to this namespace the code that tells fusion how to use an object as a fusion sequence (e.g. how to iterate over it).
/r/playrust
AFAIK there is no builtin compile-time reflection in C++ (yet). The macros are doing what the compiler (e.g. deriving) should do for you. However, I consider that if you have to write _anything at all_ to reflect on a type at compile-time, then `#[deriving(Eq)]` is not true compile-time reflection either. IMO it is (way way) better than `ADAPT` macros, but conceptually the same (you have to generate somehow reflection information). Anyhow compile-time reflection and required libraries (e.g. MPL and Fusion) are such an empowering facility for library writers that getting them right is fundamental for generic programming. As an example, almost all Boost libraries (or all of them?) depend on MPL and fusion even tho macros and template metaprogramming in C++ are horrible. &gt;The adaptation is not same as the reflection :) For me `deriving` isn't either then, since you can't write generic libraries that employ reflection without requiring your users to _do something_ with their types (which might be third-party and not modifiable). &gt;Rust currently supports the last two approaches. Then such a generic serialization function should be possible for types that have been `#[deriving(Eq)]`, which I think it's great.
Wow... that's a lot of changes. I assume this is a few months work that just happened to show up at the same time.
it is indeed really important to have a IDE integration for rust, however, I'd like to push for a "rust parsing" lib or something that would fuel all autocompletion library for your favourite editor (vim, sublime, eclipse, QT Develop,...)
Chris Morgan has put a lot of effort into the vim support in the main repo at `src/etc/vim` (and mirrored at the link /u/ehsanul gives), so much so that it's probably the best supported editor (from what I've heard, vim's not my thing ;P ).
&gt; Why is the LGPL considered problematic? I'm a bit surprised that Mozilla takes a stance like that. Lots of problems with it. In game development for instance LGPL is frowned upon because the belief you cannot legally use it on consoles. Ogre3D, cocos2d and SDL for instance re-licensed as MIT as a result of this. Lots of companies will not touch any GPL version because of licensing fears. Also it's LGPL 3 which means you cannot use it with (L)GPL 2.0 projects of which there are quite a few.
That's what I thought the first time I saw a "This Week in Rust". Then it was just as packed the next week. And the week after. And the week after...
&gt; In reality, you can write proprietary software linked statically against an LGPL library as long as you make linkable object files available. How do you think this will work for instance on iOS? Or an xbox game etc.
What would you say eclipse is better at than intellij? Intellij, from what I have seen, is the best-in-class IDE for any language that it exists for: Java, PHP, Ruby, Python (maybe), Javascript. Its memory profile is also better.
In case you want to look, here is the code: https://gist.github.com/anonymous/8917891
For Python, I want to disband the 'maybe'. PyCharm is better than the other stuff for python out there, and is free (unlike e g. WebStorm)
jdm's slides for this talk: http://www.joshmatthews.net/fosdemservo/
How would that be helpful? It doesn't seem like being able to place an artificial end of file at an arbitrary place in a file would be very nice...
That's what I assumed, I just hadn't used it.
Although slightly hidden, once again Alex blesses us with a great explanation on one of his changes: [How does libgreen work][1] ? [1]: https://github.com/alexcrichton/rust/commit/1508b6e953fd7f689a4ef7c0c01e989f942b695a
I looked at a few threads, and I can't find the reason rustpkg removed. You don't even know, and you removed it! Is there any more info about that?
Eclipse is much more modular and half of its features aren't behind a paywall. Plus, it has a plugin for pretty much anything.
My opinions: * IntelliJ IDEA is harder to extend. * Eclipse's workspace-project hierarchy makes many things easier. * IntelliJ IDEA's launch options (for Java) are lacking. * IntelliJ IDEA is overrated. It wins over newbies because its easier to use at first, but once you get used to Eclipse, it will be just as fit for the job or better.
I tried creating a Rust plugin for Eclipse a year ago. I wrote the grammar in Antlr (took me about a week to interpret the crappy documentation). When I got to testing it on actual Rust code I gave up. There was too much undocumented syntax. Now the syntax is a little bit more stable and there is an official grammar definition, so it should be easier to create a parser for the language. I wish you luck and hope that you will succeed!
I dunno which threads you looked at specifically, but the start of the chat around removing it is here https://mail.mozilla.org/pipermail/rust-dev/2014-January/008224.html I think the general idea is that it does something, but not the something that people want. The main problem is determining what that something is, so they decided on moving it out temporarily (permanently maybe?) until everything is settled.
The proper way to do this is to use `Option&lt;char&gt;`.
yeah, I read through that, and I didn't see any compelling reason to scrap everything and start over. Someone mentioned worrying about it becoming too entrenched if it wasn't perfect right now, but since rust is still breaking stuff constantly, anyone using rust right now shouldn't be suprised that rustpkg too. There's also a subthread about supporting using multiple version of the same library at the same time isn't important. That's the most compelling feature of rust to me, even more than memory safety.
Does anyone know of a good autocomplete API, which would be worth standardizing? Note that Rust's compilation model (whole crate at once) could make it more challenging to have a responsive auto-complete for it, than for file-at-a-time languages such as C.
More prosaically, it was blocking a snapshot because of the `extern mod extra;` vs. `extern mod extra = "extra#0.10-pre";` issue, and removal was deemed simpler than fixing the snapshot scripts up to write the version number.
The reason those features are behind a paywall is because they're simply an order of magnitude better than anything Eclipse offers. The amount of time saved not having to deal with Eclipse inefficiencies pretty quickly than makes up for the cost of a license. 
monadbobo might be talking about synchronous blocking API timeout. Considering a synchronous blocking socket API, it's necessary to have a max timeout on the blocking part to not block the application for too much time. And on the asynchronous non-blocking API a timeout might be needed as to guarantee that the thread will not try to connect forever. 
Website license is revised BSD and I didn't want to think about how that would work with the repo license -- so I didn't publish the sources on the website or in CVS. Rust programs [**not from the repo**](http://benchmarksgame.alioth.debian.org/play.php#contribute) but contributed directly by the program author through [the web form](https://alioth.debian.org/tracker/?atid=413122&amp;group_id=100815&amp;func=browse) will be shown.
That's actually a very common use case, especially while developing in other environments (Ruby on Rails famously does this). 
You're right, I also think it's good practice to have timeouts on those operations!
Oh, oops. Well, bug report. Thank you.
&gt; Anyone willing to use GMP can always create bindings for its specialized case, and a gmp.rs could be created, but **it is really specialized** enough that I really do not feel it to be necessary in the core language/library. Your original objection seemed to be entirely the inclusion of specialised algorithms, not licensing issues.
&gt; Also, are you still a core Rust team member? Didn't you leave Mozilla and stop contributing several months ago? I feel like you're trying to assert yourself as an authority and give your opinion to represent others, and they're too scared of being deemed an oppressor to correct you. Correct me if I'm wrong. Note the date that catamorphism's comment was written: 4 months ago, when he was still a core team member.
Bad subreddit, you are looking for /r/playrust /r/rust is about the rust programming language, not the game.
wrong topic, delete it please and sorry
There are some things in this talk that might be relevant to Rust. The changes they're making to goroutines I think are particularly relevant for libgreen.
I really like this kind of somewhat retrospective, because it explains very well some important design choices and planned evolution. Thus we can avoid the errors they make, take the good (rusted!) ideas, and finally it’s really interesting to see how a young language evolve.
To disambiguate `&lt;` meaning "less-than" and `&lt;` meaning "introduction of type substitutions". It keeps our parser 100% separate from the rest of the compiler.
Ah sorry for the confusion :x
I think that copying the stack was already discussed, and the main issue is that it needs to be followed-up by a pass that finds all the pointers to the old stack and fix them up so they point to the same item on the new stack. Go went the road of GC, so they already have a precise map of everything, and thus it's a viable (if possibly expensive) strategy. Rust does not have this map, and tries hard to avoid expensive operations.
You want /r/playrust
This is one aspect of Rust I dislike. I would like to see an uniform syntax for introducing type substitutions. The syntax for calling static trait functions is also unintuitive, ie. it's currently `let x: uint = Default::default()` whereas, at least in my mind, `let x = uint::default()` is the intuitive choice (also the shorter one).
Sorry I'm new to rust but something I don't quite get is what is considered 'the type' of an object. &gt;// why is mut on the left side here? &gt; &gt;let mut map: HashMap... &gt; &gt;// why not? &gt; &gt;let map: mut HashMap Isn't mut considered part of the 'type'? Much like a * or a &amp; is considered part of the type in C++? It makes it seem inconsistent vs parameters in a rust function, which do have mut on the right side. Sorry for the stupid question? 
Wrong subreddit?
&gt; Isn't mut considered part of the 'type'? No, it's not part of the type. Mutability is inherited from the owner. The split between `&amp;T` and `&amp;mut T` exists because they are non-owning references and can only observe immutability or mutability. &gt; It makes it seem inconsistent vs parameters in a rust function, which do have mut on the right side. It's not inconsistent. The syntax for `let` is `let pattern: type = expression` and function parameters are also `pattern: type`. For example, `let mut a: int = 5` and `fn foo(mut a: int)` are both binding an integer to a mutable variable `a`.
&gt; This is one aspect of Rust I dislike. I would like to see an uniform syntax for introducing type substitutions. Having to write `HashMap::&lt;~str,uint&gt;` everywhere would be very verbose. Also `[]` and `()` are equally ambiguous. &gt; The syntax for calling static trait functions is also unintuitive, ie. it's currently let x: uint = Default::default() whereas, at least in my mind, let x = uint::default() is the intuitive choice (also the shorter one). We are planning to allow `uint::default()` as well. `Default::default()` should still be supported though.
I think it's completely gone now.
That's an `&amp;mut T` stored in an immutable variable. &gt; The split between `&amp;T` and `&amp;mut T` exists because they are non-owning references and can only observe immutability or mutability.
That `to_owned` method is useful, wish I had known about it before! I wish there was a nice cheatsheet of all these niceties (the `if_ok!` macro is another one, though recently added). Right now I basically have to comb the entire standard library docs in order to find these it seems (or just read code I guess).
Go is a language oft-compared to Rust (and indeed, it does have a fair number of similarities), so I thought I'd perhaps stir up some conversation about where they're going and how it might affect our choices.
That's true. But, it'd make the only place where type parameters are *strictly required* far more uglier.
I suspect the main issue is the suitability/maturity/existence of LLVM's support for stack maps. An impossible operation can be regarded as infinitely expensive, so being able to move stacks can't be slower than not being able to. (The circumstances where you would *want* to, of course, depend heavily on its performance.) The main cost would be increased binary sizes (from the stack maps) I think. Using [Bill Myers's plan][1] green tasks could be switched in and out on a given OS thread freely, it's only when migrating a task from one OS thread to another that the pointer fixing-up would be needed. The frequency of this could be made arbitrarily small by spawning more OS threads. (So this is more like L:M:N, with L green tasks mapped onto M OS threads of which N are executing at any given time.) (Contrast to the same plan without this capability: then the penalty is not having to fixup pointers, but lost concurrency due to not being able to migrate at all.) [1]: https://mail.mozilla.org/pipermail/rust-dev/2014-January/008172.html
It's not broken, it is a side effect of hygiene macros first introduced in 0.8 (AFAIK). Basically, free identifiers (not bound by `let`, for example) defined in the macros follow the scope of its *definition* and cannot coincide with identifiers available at the usage. It is less obvious but the same rule applies to generated identifiers: there is a [test](https://github.com/mozilla/rust/blob/master/src/test/run-pass/syntax-extension-minor.rs) which has been xfailed (marked as "expected to fail") due to this change.
Aha! Thank you for this explanation, that clears it up. So changing the code to this made it compile: static foobar: u32 = 123; fn main() { let other = concat_idents!(foo, bar); println!("other = {}", other); } I would say this behaviour is quite surprising, but perhaps I am expecting macros to be something they are not. I'm still quite confused about where it is legal to invoke a macro and where it isn't. For example, this code: struct TestStruct { name: ~str } fn main() { let t = (concat_idents!(Test, Struct)) { name: "Hello" }; } fails with another error. Overall, the limitations on macros seem a bit random (though I'm sure there are good reasons, such as parsing), or I'm just missing something that'll let them do what I want them to do. EDIT: I might have figured this out, please correct me if I'm wrong: The parser makes a hard distinction between types and identifiers, and an identifier macro argument cannot be used where a type was expected.
Yes, you cannot put a macro invocation at that position. This is because the macro invocation *is* also a node in the abstract syntax tree (AST), and has to be explicitly parsed at the appropriate position long before the actual expansion occurs at the completely parsed AST. [syntax::parse::parser](https://github.com/mozilla/rust/blob/master/src/libsyntax/parse/parser.rs) has several routines related to the macro invocation parsing, but they are currently limited to items and expressions. As the entire macro facility is still evolving (most recently by the procedural macros), the documentation has been stagnated a lot unfortunately though.
According to [Go FAQ] Go always compiles everything statically (if you use the native toolchain not gccgo). That's why the Go binary doesn't care about the version of libc on the other host. I guess you can do the same with Rust, but am not able to come up with the right command from the top of my head (and BTW libgcc and libc are not the same animal). [Go FAQ]: http://golang.org/doc/faq#Why_is_my_trivial_program_such_a_large_binary
Damn, I was working on this. But I'm having problems with my Internet provider. Glad someone was faster. 
&gt; having problems with my Internet provider. &gt; &gt; &gt; &gt; Glad someone was faster. Umm, even if it's 20 times faster now, it's still a LOT slower than referent C implementation ([See benchmark](http://benchmarksgame.alioth.debian.org/u64/benchmark.php?test=all&amp;lang=gcc&amp;lang2=rust&amp;data=u64)). It's no longer 1/1064 but 1/53, which is still longer than 1/3 which could be considered ok.
Oh, I understand. There are some stuff that I'm doing that are not in the pull request. 
Great, I'm actually quite interested in BigInt and others for DateTime library, so it's probably best it's as fast as humanly possible :)
/r/playrust
By "OS thread" I was thinking of the "large stack" concept from Bill's message, sorry for the confusion.
&gt; edit: I assumed the thread was new when in fact it was stickied 4 months after its creation. It was stickied immediately.
Ah! Indeed, I now get your point. So to sum up: - L green tasks - M very large stacks - N OS threads With: - green task bound to 1 very large stack (unless you have fix-up of pointers or guarantee their absence) - very large stacks freely able to migrate from one OS thread to the other The only advantage I see compared to the typical M:N (with large stacks) is the (potential) memory reduction. However as mentioned you can have 8,000,000 of 8MB stacks (2^23 tasks of 2^23 bytes stacks) in only half of the user address space in a typical Linux. And if over-commit (and lazy allocation of pages) does not save you from OOM, then Bill's scheme would probably not save you either, unless it's also compacting the green tasks. I (honestly) wonder if it's worth optimizing for this usecase: - instead of insanely large stacks, you can propose a "stack-extend" intrinsic (which may create a discontiguous stack) that people with deep recursions can depend on; those who don't touch the intrinsic never pay for the check; those who fail to call it in times will hit the dreaded stack-overflow (oopsie) - and building on this, you can have people specify the initial stack size when creating a task, so a web-crawler could for example allocate 8,000,000,000 tasks of 8KB stacks (assuming you have more than 32GB of memory available for it) and for those few stacks that start running deep invoke the "stack-extend" intrinsic; and on the other hand "regular" people with much less parallelism could create 8,000 of 8GB stack each (or even 8 tasks of 8TB each) and never worry about hitting a stack-overflow Of course, the web-crawler case is only possible without copy (+ fix-up) if you accept a non-contiguous stack; is it such a drag ? Did I miss something else ? 
Why would a datetime library need big integers?
It's not 20 times faster: it's *asymptotically* faster, and so the ratio between the old and new versions gets larger and larger as N increases. pnkfelix [said he measured](https://botbot.me/mozilla/rust-internals/msg/10835123/) the N=10000 case: 8.7 seconds for the new version, killed at ~20 minutes for the old version, so this is 140+ times faster there. (And assuming that his computer is comparable to the benchmarker, we're then only single-digits times slower than the best C one.)
Yeah it was a mistake in calculation (I'm not afraid to admit I don't know much about Big O behavior). Either way my point still stands, if this was the lowest hanging fruit, there are bound to be more for picking.
GMP also has asymptotically faster algorithms than Rust is using, but the pidigits benchmark doesn't have large enough integers for it to show.
The existing `block` variable is holding a mutable borrow to your buffer. As long as that mutable borrow is in scope, you can't borrow the buffer again. What you can do is re-borrow `block`. You'll need to make a few changes. `fn read_block` needs to become fn read_block&lt;'a&gt;(r: &amp;mut Reader, buf: &amp;'a mut [u8]) -&gt; IoResult&lt;&amp;'a mut [u8]&gt; Then you can reassign `block` like block = read_block(&amp;mut reader, block.unwrap()); This is, of course, unsafe, but I assume you'll be unwrapping the `IoResult` yourself before you try to re-run this line.
You didn't answer my question. Dates and times are not big; they are small, constant sized things. I don't see how BigInt can be used in a datetime library.
&gt; Dates and times are not big; they are small, constant sized things That's clearly not true. What if you're wanting a single second that's 10^30 years in the future? (One might be able to say that `u64` or (a simulated) `u128` would be enough for any sensible range of dates.)
He expected the borrow to end before the assignment, when the old value of `block` dies. The kind of analysis that would be needed to make it work is quite sophisticated: a lifetime would have to be able to begin partway through a loop and end partway through a subsequent iteration of the same loop. It's unfortunate that the `read_block` has to be sacrificed here, though.
Actually, there is a vague plan to allow for lifetimes to start and end in semi-arbitrary places, so this might work one day. 
It doesn't need to be in the standard library if there is a good dependency management system that understands rust code and how to understand and acquire its dependency tree. Preferably both from source and from semi compiled or fully compiled binaries. Our shop uses a combination of C++ and Java and I have to say build management with Maven/Ivy is a godsend after dealing with the nightmare that is cmake/configure and make.
I was assuming that it was a *normal* datetime library under consideration. I do not expect that one uses regular datetime libraries for zillion year simulations.
Another good way to safely encode state machines is through newtypes. pub struct Step1(Data); pub struct Step2(Data); impl Step1 { pub fn step(self) -&gt; Step2(Data) { ... } } and so on. This is slightly less nicer to deal with now that you can't dereference newtypes, but the inability to do so also makes it harder to break.
Dates and times store their time as number of mili/nano seconds from date X as `int`/`float` of various sizes. Why couldn't you use `BigInt` to achieve a larger (potentially infinite depending on implementation) span of values.
Well, let's see. 1. It's not as complicated as C++. 1. It's safer than C. 1. It's (at least in theory) faster than Go/D. 1. And has wider reach than the really obscure PL/* from IBM and similar one shot langs.
1. It's low level like C/C++, but safe like C# 2. It doesn't force OO down your throat 3. It has closures (that don't suck) 4. Enum types are too damn good
1. Strongly typed. I like it that you have to coerce everything explicitly. You always know which type to expect. 2. Safe. No out-of-bounds array, and no null-pointers 3. Fast (enough). 4. In active development. Issues (not just bugs) turning up with the libraries/backend can and will be fixed fast.
1. It's more type-safe than C++, but gets theoretically equivalent performance. 2. It's multiparadigm: It doesn't force OOP down your throat. It doesn't force FP down your throat. 3. It's easy to approach from a C++ background, where "good practice" is to think in the paradigms of Rust anyway (pointer ownership, lifetimes, etc.) 4. It's slightly more expressive than C++, and doesn't require you to memorize the 9,001 ways by which you can shoot yourself in the foot in C++. 5. Its macro system is AST-based instead of lexical. 6. It has a somewhat sane module system.
Exactly. What about allowing reassignment with the same or a subset of borrows based on original assignment?
Well the whole point of read_block was not to pass len around =)
For supreme safety it would be better to use a private field (which isn't possible via newtype/tuple structs): pub struct Step1 { priv data: Data } with the appropriate unwrapping/getter functions, since that will disallow creating a `Step1` outside the current module without going through the proper path. (This also makes it easier to work with, since one can write `x.data` instead of `let Step1(data) = x; /* ... */ data`.)
&gt; It has closures (that don't suck) The closures kinda do suck still; we need unboxed closures ala C++ for full flexibility.
Yes, but for mut variable I was expecting that reassignment with the same borrows would be legal
Any links for some info on this?
&gt; I see the a.slice(5,10) method, but can this be changed to something more intuitive like a[5:10]. [#4160](https://github.com/mozilla/rust/issues/4160). &gt; Are 2-dimensional arrays possible (dense in memory, allocated on heap at runtime, probably column major format) Of course: any vector with the appropriate indexing routine (`a[i * LENGTH + j]`) is 2D.
True. Yet another alternative is to make the newtype structs private (so they can't be (de)constructed), but leave the methods on them public (so they can be manipulated). Add getter functions as necessary. You can even make things noncopyable in the newtype method by wrapping a tuple of (Data, NonCopyable/NoPod) instead of just Data.
I haven't chose Rust yet (I'm waiting for the 1.0) but for me the appeal is: Ocaml with linear types and a potentially larger/more active community. It's funny to see so many people from the C++ community (whereas I'm from quite the opposite).
It would be nice to be able to do a[(i, j)]. I couldn't find out if the lang item is generic over the type of the index.
The [Index trait](http://static.rust-lang.org/doc/master/std/ops/trait.Index.html) is (however, note that [this trait will be changing](https://github.com/mozilla/rust/issues/6515)).
At the moment I think the solution is to wait for the remote end to lose the connection. Which is dumb.
but doesnt work at all for udp
Point taken. We really could do with .shutdown() (or a timeout, but that relys on you setting a timeout BEFORE the unexpected happens).
Because you *never* ¹ need such a large span of values. Whether you're dealing with normal dates or ridiculously wide-spanning dates, you will care about performance. Big integers must necessarily be slower, and that performance cost is unbearable when 99% of use cases want small and 1% might want big or might want small with lower granularity, and won't expect to be served by regular datetime libraries anyway. (¹ *What, never?* No, never! *What, never?* Hardly ever.)
It's true that storing the number of seconds since the Unix epoch in a 32-bit integer is a bad idea in the long run. See the 2038 problem: https://en.wikipedia.org/wiki/Year_2038_problem However, a bigint should not be necessary here, when we can just use a 64-bit integer instead: &gt; Using a signed 64-bit value introduces a new wraparound date that is over twenty times greater than the estimated age of the universe: approximately 292 billion years from now, at 15:30:08 on Sunday, 4 December 292,277,026,596. Even if you set the epoch to the big bang, you'd still be able to express any time in history to the nearest second.
Has anyone tried to use state function like the one used in this [video](http://www.youtube.com/watch?v=HxaD_trXwRE) to create state machines?
It doesn't depend on a garbage collector so it's easier to reason about precise real time dependencies. This likely makes it suitable for hard real time safety critical systems. 
I've been working on and off on a library based on expression templates (i.e. implementing your second point) for a bit now: [RustAlgebloat](https://github.com/SiegeLord/RustAlgebloat). I'm focusing on the API beauty over raw performance (so there won't be any SSE magic of Eigen), but it should be about as fast as writing things out in a loop. Note that it is in its very stages, as I'm not completely sure I like how I handle Rust's mutability rules: I bypass them using Cell, but that opens me up to the same sort of aliasing issues as you encounter in Eigen... I'll see what can be done about it. For plotting, I'm also making a library: [RustGnuplot](https://github.com/SiegeLord/RustGnuplot). I've never been a fan of matplotlib, personally... if I'm putting something in a paper, I usually do it in Gnuplot (either through an interface library or manually).
I believe it's an instance of [the lexical borrow checking scopes bug](https://github.com/mozilla/rust/issues/6393): the first borrow actually lasts until the end of the `main()`, not just until the next assignment or whatever. And thus you can't perform a second borrow nested within it. See http://blog.ezyang.com/2013/12/two-bugs-in-the-borrow-checker-every-rust-developer-should-know-about/ which covers it (and an other borrow checker issue) and attempts to provide workarounds.
https://github.com/mozilla/rust/issues/6393
I am a C++-person but the reasons that I am interessted in Rust are: * It doesn't have to be compatible to the stone-age. * It provides a better module-system then C++14 (this doesn't say much). * The designers understood the concepts of ownership and RAII. * It doesn't force GC on everyone who doesn't need it. * Compiler-checked safety is a cool feature. * It tries to be multi-paradigm and doesn't force people to inappropriate OOP. * I really like that many things are expressions. On the other hand: * I am not sure about the exception-system, even though I usually don't catch much in C++ too. * I am not yet sure that macros and generics will be a sufficient replacement for C++-templates. * I really like that C++ is an iso-standard and not defined by implementation.
1. Safety. It simply isn't practical to use a language where a typo could lead to a 1 byte buffer overflow, which could lead to thousands of your customers being compromised. Not everyone can audit millions of lines of code they're using. 2. Null safety. I'm not capable of always knowing every place that every variable can possibly be null. 3. Garbage collection is not always appropriate. Rust provides good safe memory allocation options before needing to resort to garbage collection or unsafe code. 4. Rust's real module system should theoretically lead to a debug cycle that takes seconds instead of minutes. To me, those are the major points. All the other great things are just niceties. It blows my mind that it's 2014 and so many people are writing unsafe code, dealing with null pointers, and waiting 15+ minutes for compiling. And most people don't even know or care that these are theoretically solved problems. I think the garbage collection might scare them away from languages like Go or D, but I can't think of an excuse to resist switching to Rust.
&gt; the same sort of aliasing issues as you encounter in Eigen Could you elaborate or link to something where I can read about this?
&gt; Strongly typed. I like it that you have to coerce everything explicitly. You always know which type to expect. As a general rule, I like this, but I really wish rust would allow for safe coercion. It's annoying to have to upcast an `i8` to an `i32`, for example.
I make video games, and I'm a perfectionist when it comes to UX. Garbage collection pauses are a complete dealbreaker. Any hundred-megabyte dependency is a dealbreaker. Twenty-second-long cold-start times are a dealbreaker. To the best of my knowledge, this rules out *every* living language other than C, C++, Nimrod, Ada and Rust. C# and Java have concurrent-incremental GCs, but they also have huge runtimes, and I quite dislike both languages. Every other language suffers from GC pauses which last for double-digit milliseconds (which is to say, eons). C is cute, but too feature-poor for real use. C++ might be fairly usable if you wait until 2020 and then carefully avoid two-thirds of the language. Ada is bondage-and-discipline while still being unsafe and feature-poor. Nimrod has disfiguring featuritis. Only Rust remains. Luckily for me, Rust isn't just the "least bad" option - it's also an excellent language with a very bright future.
The lack of a garbage collector, but people like to ignore that the GC is can be disabled (but that in turn requires parting with a chunk of the standard library). There's been lots of discussion in the D forums right now about removing GC allocations from the stdlib, and the development of a precise GC for D.
I'd also argue that the Nimrod compiler just isn't quite up to par yet (lots of annoying compiler errors last time I played around with it).
The merits of the whole approach are kinda independent of the point I was making, which is just that stack maps and pointer fixups could be used to gain the ability to migrate green tasks under this scheme, which is a capability it otherwise lacks. I'm not super-qualified to judge the broader question, but it makes me uneasy that it's so tied to the particulars of a 64-bit address space + virtual memory + overcommit + lazy allocation of pages + smallish (4KB) pages, and removing any of those makes it fall over. (Obviously 32-bit systems don't have a 64-bit address space, but neither does x32, which uses 32-bit pointers on an x86-64 CPU to improve memory/cache utilization; it's mostly embedded systems that don't have virtual memory, but neither will the much-hyped Mill family of processors; I've heard lots of conflicting information about the presence of absence of overcommit and lazy alloc on Windows (no idea about other OSs); and there's also movement in the direction of having 2MB "huge pages" instead of 4KB, precisely because with large amounts of memory the book-keeping overhead of 4KB pages becomes non-negligible.) Basically the implicit idea seems to be that "if you want to spawn a large number of green tasks, you're presumably using 64-bit Linux" and/or "if you want to spawn a large number of green tasks, you should use 64-bit Linux", and either that's OK or it's not. &gt; instead of insanely large stacks, you can propose a "stack-extend" intrinsic (which may create a discontiguous stack) that people with deep recursions can depend on; those who don't touch the intrinsic never pay for the check; those who fail to call it in times will hit the dreaded stack-overflow (oopsie) This seems like an enticingly worse-is-better solution, but I'm rather skeptical of it. How would the affected code know if it needs to invoke stack-extend? Would it always? It feels like this would break important properties of abstraction and compositionality. To be sure of handling it correctly you'd want something like a caller/handler to be called when you're exhausting the stack, but at that point you might as well just do it automatically.
&gt; 9,001 ways by which you can shoot yourself in the foot in C++ This would be a great book title, or a band name.
Indeed, there are lots of dependencies on the OS in what I was citing... When I proposed the `stack_extend` on the Rust mailing list, Niko remarked that it should rather be `stack_reserve`: you say `stack_reserve(71471)` and the runtime makes sure that you have `71471` bytes available on the stack =&gt; either it's already the case and nothing happens or it's not the case and it switches you to another stack (exponential growth ?) somehow so that it works. The main advantage of being explicit about it is that this avoids the case of `__morestack` being invoked repeatedly in a tight loop because it just happened to run on a segment boundary. It also avoids repeated useless checks if not necessary.
Yeah, I'd like to have a `type Foo(priv int);` syntax for this.
I take it you haven't written lots of lifetime/borrowing code in Rust. (I kid, I kid! I kid because I love)
Object pooling can be a major pain. Managing the pool can add a bunch of complexity to what could otherwise be very simple programs, and reusing mutable objects introduces a path for some really horrible bugs that can be hard to track down. If the options are going through that mess versus just having guaranteed stack allocation or using an arena, it's a pretty clear choice. 
You can re-borrow a mutable borrow, you can't re-borrow the thing the mutable borrow borrowed while it's still in scope. let x = 3i; let y = &amp;mut x; let z = &amp;mut y; is legal (and `y` is considered inaccessible while `z` is alive), but let x = 3i; let y = &amp;mut x; let z = &amp;mut x; is not.
&gt; - I am not sure about the exception-system, even though I usually don't catch much in C++ too. Exceptions introduce broken invariants whenever it is possible to use state altered by the throwing scope outside of it; aka: `Something st; try { st.mutate(); } catch(...) {} /*unsafe ? -&gt;*/ st.doit();`. Rust uses the Task boundary to enforce the concept; though in the future I could see the idea of *inline task* where you could invoke *locally on the current stack* a closure wrapped into a try/catch kind of block and let ownership transfer semantics ensure that nothing corrupted could escape the closure. &gt; - I am not yet sure that macros and generics will be a sufficient replacement for C++-templates. C++ templates are very powerful (though not exactly well thought-out, since their power was more discovered than designed), and while generics might not be as powerful they can probably be extended in the future as necessary. At least I hope ;) &gt; - I really like that C++ is an iso-standard and not defined by implementation. I like the Standard part; however one of the reasons for bloat, immobility &amp; backward compatibility is the design by committee which seems inherent to ISO standardization. Design by committee has never led to elegance (you need a common agreed vision between designers, not a tug of war), so I am ready to throw out ISO standardization if it's what it takes.
Agreed for the emphasis on compile-time safety. Throwing exceptions around is kinda cool, but nothing beats compile-time safety in terms of "REPL" experience.
yes, i understand the problem with borrowing like that, but borrowing again and write that to the same variable should be legal (right?) (its not about what the current implementation does but what it could allow)
`block` is in scope, which means that the borrow it holds against `buf` is active. The only way to remove that borrow is to have it fall out of scope (this is a nasty problem with the borrowchecker, unfortunately). My suggested change lets you re-borrow from `block` instead of trying to re-borrow from `buf`.
I've been bitten by silent up conversion more than once and, at least for me, I welcome the restraints. I'm curious about your experience, though. What's your reason? Pure convenience? (convenience is a perfectly acceptable answer) 
Interesting. I never really thought of Rust as a competitor to OCaml. OCaml is mostly used for high level applications that could really benefit from the ease of use a GC brings and I don't see how Rust fills that niche. However, perhaps it would be useful to use Rust as OCaml's C. For example rewriting the OCaml bytecode interpreter in it.
One advantage with phantom types is there can not be two functions with same name, since their implementation intersects the same namespace, so one avoids ambiguity: let step1 = ... let step2 = ... step1.a(42) // a can only be implemented for step1 and not for the other steps.
This isn't the subreddit you want. /r/playrust 
&gt; Because Rust conflates the constructor and the type, that's the only way to make an opaque newtype No, `struct Foo { priv x: T }` works too, since it makes the field inaccessible externally but not the name of the type itself: unlike Haskell all values are unboxed by default, so there's no difference between "newtypes" and normal structs. &gt; I'm not sure if it's really useful at all, but it doesn't break anything so I don't see much purpose in forbidding it. It does; it's very easy to accidentally return a private type, and if you only have in-crate tests you won't detect until much later when you try to use the library and name that type, or if you happen to glance at the docs to see that a type isn't listed at all. The std lib has done this repeatedly.
Came here to say the same. Anyone?
Yes, just convenience. If I have a vector of `i8`, I have to cast an element to `int` to work with most stdlib functions. Curious, when have you had issues with the limited application of upcasting that I mentioned above?
Unlike Haskell, there's no difference between normal structs (`Foo { ... }`) and "newtypes" (`Foo(...)`) other than syntax. (And without automatic dereferencing of newtypes, the normal struct syntax is *much* nicer to use (although less nice to construct).)
I meant specifically regarding the newtype syntax. I'm aware there's no semantic difference between the two. Sure, but returning a private type outside a crate isn't a safety issue just a design one, which is what I meant by "doesn't break anything". Nothing 'goes wrong' in the type/memory safety sense. Things just (unexpectedly) fail to compile with a completely understandable error message of "type is private" and the fix is trivial (just add a 'pub'). I think this is more a job for a lint than a reason to make the privacy system more complicated and restrictive. 
I'd say the ease of use of newtypes versus structs depends a lot on how they're being used. If you want to access the interior a lot, then structs are probably the better choice because of field projection. If all you're doing is calling methods or functions, then newtypes are probably better because of easy of construction.
I think that would be great. Especially if we decide to ban returning private types.
&gt; more powerful type system, able to encode more invariants Can you elaborate on this point please? 
ah, I forget this. I mostly used D with the runtime disabled.
I wanted a system language ... 0. that is cross platform. 1. on pair with building abstractions in C# 2. closer integrated with C than C#. 3. closer integrated the open source community and free software platforms. 4. with no vendor lockin (Microsoft or Apple). 5. easier to maintain a large codebase. 6. safer to deal with threads/concurrency. 7. with no null pointers. 8. that can express code beautifully in many different ways. 9. exhaustive match - great for adding new features to a large codebase. 10. a sane module system tied to the file system. 11. generics. 12. abstract data types. 13. phantom types - makes it possible to build compiler safety abstraction across statements. 14. utf8 strings. 15. static linking. 16. does not suffer from old design mistakes unlike Java. 17. future aggressive, but still keeping its root in history. 18. type inference. 19. has macros, unlike C#. 20. that does not require to learn C++. 21. possible future integration with a web engine (Servo). 22. being able to write safe high performance code when I need it. 23. vibrant and great community!
Thanks for pointing that out, I think I'll keep trying.
That is certainly not Rustic. Iteration is the idiomatic way of doing things, and for good reason. If you wish to operate upon a vector, iteration is safer *and faster*, because the iterators skip bounds checking. You also avoid the possibility of the standard off-by-one errors. If you wish to just do something N times, `range` will yield nicer code and the performance characteristics will be *the same*. LLVM optimises many things, and the iterator methods are marked for inlining; iterators are generally optimised to the same as a C-style for loop. Embrace the iteration! It's all round nicer.
While you can do stuff in C++ and it has a big ecosystem, Rust is probably easier to learn, it covers a lot of practical applications and it might grow with new generations of system programmers. I don't expect it to take over the market share of C++ that fast. I guess it will take 2-3 years after 1.0 to get adopted on large scale in the industry before I see Rust mentioned in job advertisements.
C++ overload resolution can be used to perform compile-time pattern matching on types. It can also perform arbitrary compile-time calculations as part of this pattern matching. For example, a different overload can be selected based on whether an integer type parameter is prime. Since C++11, the calculations can now be performed via compile-time function evaluation, rather than instantiating types recursively. C++14 (which `clang` implements) relaxes the restrictions on CTFE quite a bit too, so it no longer requires strict adherence to recursive algorithms. The power of templates can be used to encode complex invariants like [arbitrary combinations of units with arbitrary dimensions](http://beta.boost.org/doc/libs/1_55_0/doc/html/boost_units.html), [type-safe generic tagged unions](http://www.boost.org/doc/libs/1_55_0/doc/html/variant.html) and even features like pattern matching. Rust is explicitly designed to deny this kind of power by forcing the usage of trait bounds. It has more features baked into the language itself to make up for this (sum types, pattern matching), but libraries have much less power. Rust will likely gain support for neat features already in C++ like compile-time function evaluation, associated types, associated constants and integer type parameters. It will never have the same kind of power in the type system though, because it's not going to have this kind of type pattern matching via template instantiation and overload resolution.
In embedded contexts with non-32 bit architectures. I don't remember the exact setting. Sorry I can't be more helpful. 
I know. It still bothers me.
Awesome, I had hoped that it was smart enough to turn a standard range into a c style thing/avoid lots of function calls, but what about something of the form.. for(i)//either c or range style { if(some_reason) { i+=1;//changing i in a for loop is poor form, but is still sometimes useful } } Now using ranges i will still be the next number in the range.... Of course this could fall under making it harder to write "bad code"
While I won't Ever use this in code, I mangaged to write something that should handle continue and break. It is ugly as sin, and uses variables so it could name clash, but here in all its ugliness, my second macro... I just like a challenge sometimes macro_rules! fer { (($initializer:expr ; $condition:expr ; $increment:expr) $block:expr)=&gt; ({ $initializer; while($condition) { let mut fst=true; let mut normal_exit=false; let mut con; while({con=true;false}||fst)//if we continue we reset con to true in the head { con=false;//won't get reset on break fst=false;//ensures we break the inner loop $block normal_exit=true;//didn't break or continue } if(normal_exit || (!normal_exit&amp;&amp;con)) { $increment;//if we got continued, or just dropped normally we get here } else { break;//normal exit is false, and continue is false } } }) } But don't use this, I just wanted to see if I could do it. I honestly bet it would be less trouble to implement this as an actual keyword than as a macro. (Which I might do for fun, although I doubt such a contribution would make it in....)
I'm mostly referring to things discussed on this page: http://eigen.tuxfamily.org/dox/TopicLazyEvaluation.html As far as I can tell, Eigen does not statically disallow aliasing. Rust, in principle, does, but I've escaped it using Cell. I haven't explored the issue completely though, and it may be the case that I can leverage Rust's aliasing rules just for the operations that are problematic (such as matrix multiplication).
I think $initializer; let mut first = true; while { if first { first = false } else { $increment; } $condition } { $block } should also work.
If you're really constructing it a lot you can write a tiny constructor `fn S(x: T) -&gt; Struct { ... }`.
&gt; That is certainly Rustic What is Rustic? Using a manual C-like for loop or while loop when there is a nice iterator alternative is certainly not idiomatic or good style (even via a macro).
You can, but you must provide a custom allocator: https://gmplib.org/manual/Custom-Allocation.html#Custom-Allocation 
Whoops—I meant “*not* Rustic”! Corrected now.
/r/playrust
my bad. Thanks
A segfault is certainly not what should be happening. Other matters: - Your crate_id should probably be `echo#0.1pre`. - The `#[crate_type = "bin"];` is not necessary, either. - With things like `let mut m_stream = stream;`, I recommend just reusing the `stream` name: `let mut stream = stream;`. Same deal when you're wrapping it in a `BufferedStream`; I'd write `stream = BufferedStream::new(stream);`. - Your `match buffered_stream.read_line()` I would probably write thus: match buffered_stream.read_line() { //Disconnect the client on the quit command. Ok(ref line) if line.trim() == "quit" =&gt; break, //Otherwise we echo everything. Ok(line) =&gt; { buffered_stream.write(line.into_bytes()); buffered_stream.flush() }, Err(err) =&gt; continue, }; - Continuing on error makes no sense whatsoever, by the way. Errors (which includes `IoError { kind: EndOfFile, .. }`) will be unrecoverable.
Regarding the mut stream: you should also be able to just write `Ok(mut stream)` :) EDIT: Err, maybe you can't? -- I didn't test this. Maybe the proc can't capture mutable variables? I don't remember.
Thank you for the help! I managed to stumble on the cause of the error when I fixed the naming as you suggested. In the below code, I assigned stream to m_stream, and then proceeded to use stream again for the my BufferedStream. This does not result in any compiler warnings, but it does however result in a segv. Thank you again! let mut m_stream = stream; let peer_name: ~str = m_stream.peer_name().unwrap().to_str(); // //The println! macro uses the fmt! macro internally. // //https://github.com/mozilla/rust/commit/948334f33398f0ba073107585b8dfaa0dc9feaa9 println!("Client connected: {}", peer_name); //BufferedStream allows for tuning buffer sizes, //but it is not required for this case. let mut buffered_stream: BufferedStream&lt;TcpStream&gt; = BufferedStream::new(stream); buffered_stream.write(bytes!("Welcome to this host.")); buffered_stream.flush(); I will post another reply to this thread once I've fixed the gist. Edit: Spelling.. Edit: Just to expand on this, if one does not re-assign stream to m_stream, there is not problem with BufferedStream. The cause seems to be re-assigning to a new mutable variable, and then using the old immutable variable for the BufferedSteam
Just tested and it results in a compiler error :-/ cannot borrow immutable captured outer variable in a heap closure as mutable let peer_name: ~str = stream.peer_name().unwrap().to_str();
That's fixed on master, so what /u/jmgrosen suggests is possible for a sufficiently new compiler.
I finally realized why the approach (using contiguous stacks) was somewhat important in Go. The issue with segmented stacks, even with pre-reserved segments, is that crossing segment boundaries (one way or another) has a cost in switching. If that crossing happens in a time-sensitive area or a tight loop you suddenly are in trouble; and though a programmer could explicitly opt-in / opt-out, once the hot-spot is identified with a profiler. I also realized that pointer fix-ups was no different than the mark-phase of a traditional mark &amp; sweep GC; it requires a precise GC approach to fix all (and only) stack pointers. This seems a no-go (!) for Rust, because of the extra cost... though perhaps it could be opt-in... --- *Copy without Fix-Up ?* I wonder if there is an alternative for fix-ups. I somewhat thought back to using shared-memory, where pointers are a no-no because various processes might map the shared-memory segment to different address ranges (by default). As a result, all pointers in shared-memory have to be transformed into an offset since a known point (usually the start of the segment). Now, why can't we apply this to pointers into the stack ? Accessing a pointer value would then require some magic: pointer = ptr &amp; mask ? ptr : (stack-start-ptr + (ptr &amp; ~mask)) which should compile to a conditional move (branchless!) and hopefully should be simple enough that the overhead would be really, really, low: - when playing with an array, it's hoisted at the start of iteration - when playing with a linked-list, it should be dwarfed by the cost of pointer chasing Furthermore, in Rust, there are also cases where it could be optimized out (a `~` pointer always points to the heap) or Rust could provide an annotation to mark some pointers as "non-stack" for performance conscious people. With this, Rust could have stack copy (and exponential growth thus amortized constant cost) without pointer fix-ups.
I just tried this on the newest master, it still results in that error. Just to be clear, the actually Ok(mut stream) and BufferedStream works fine. Doing stream.peer_name..... on the mut stream causes that compiler message. rustc 0.10-pre (22c34f3 2014-02-13 20:36:55 -0800) host: x86_64-unknown-linux-gnu 
Hmm, rereading the error messages suggests that you don't have the `mut` in the correct place (it should be `Ok(mut stream) =&gt; spawn(...)`). Can you post the code that generates that error?
I added a gist for this. https://gist.github.com/elyzion/8997277
(BTW, I think the segfault was caused by [#12041](https://github.com/mozilla/rust/issues/12041).)
First bug I managed to stumble across in Rust =D I presume you created the issue? Thank you very much! :)
General points: - [the commit you point to for `println!`](https://github.com/mozilla/rust/commit/948334f33398f0ba073107585b8dfaa0dc9feaa9) is not [the current implementation](https://github.com/mozilla/rust/blob/master/src/libstd/macros.rs#L162-L170) - as such, `println!("Client connected: {}", peer_name);` is better than `stdio::println("Accepted client " + peer_name);` since the former can have no allocations when printing - for a single condition `if line.trim() == "quit" { break } else { ... }` is much much *much* better than `match line { _ if line.trim() == "quit" ... }`, although if you've got multiple commands something like match line.trim() { "quit" =&gt; { ... } "some command" =&gt; { ... } "yet another command" =&gt; { ... } _ =&gt; { ... } } is better. 
Thank you, I updated the gist accordingly. 
It is a common pitfall with floating point arithmetic. 123.1230011 is not exactly representable in binary, so the compiler tries to use the closest value in f32/f64, in this case: 0xf63efa / 2^17 = 123.1230010986328125 and: 0x1ec7df400177cf / 2^46 = 123.1230010999999961995854391716420650482177734375 Obviously, they are different to each other. You should never ever compare floating point values with `==`; okay, there is an exception but you won't need it anyway. You should account for the relative errors instead.
From what i know you should never assume that a float is 100% accurately represented by a computer because of those "rounding" errors.. Basically IEEE floating point in a computer chip just has this limitation. There are decimal floating points which are accurate, but they are not done in hardware, but software, afaik. https://en.wikipedia.org/wiki/Decimal_floating_point
Thanks! I found ApproxEq.
As others have said this is an artifact of floating point, but it can be understood via normal base 10. Imagine you're trying to represent 1.123123 in two data types, one is d2 and the other is d4 (for 2 and 4 decimal digits respectively). let x = 1.123123d2; // truncated to 1.12 let y = 1.123123d4; // truncated to 1.1231 let z = x as d4; // extended to 1.1200 y == z // false, because 1.1200 != 1.1231 Now, for the `as d4` step, it looks like `z` is incorrect because it's lost the last two digits, but it's actually because `x` couldn't store them at all, and so the intermediate precision is lost. The exact same thing happens with `f32` and `f64`, the fact that they print identically is just because the `f32` rounding and the `f64` rounding are very close (as if I did the above example with `d8` and `d16` and a longer decimal). Printing with `{:.20}` demonstrates the difference: fn main () { let x = 123.1230011f32; let y = 123.1230011f64; println!("x = {:.20} x as f64 = {:.20} y = {:.20}", x, x as f64, y); } prints x = 123.12300109863281250000 x as f64 = 123.12300109863281250000 y = 123.12300109999999619959 
[The `native` crate](http://static.rust-lang.org/doc/master/native/index.html) can be used for this purpose, see the second example ("Force spawning a native task").
While decimal floating point does fix this exact example, this problem is fundamental to finite precision types, e.g. [my example below](http://www.reddit.com/r/rust/comments/1xvv8i/equality_of_floats/cff3y83) (or, for another example `1.0 / 3.0` will be different between a long and short decimal type).
Now I'm trying to avoid mentally picturing a horrible mess of green threads spawned from native threads spawned from green threads spawned from... and so on.
I see your point, but it is good to have the option of starting a kernel thread. In Go you haven't. Being guaranted able to run down the nuclear power plant immediately when some external event arrives is not possible in Go. If at the time of the event there are simply too many long-runners active the external event is simply not handled in foreseable time. So, I'm personally very happy it can be done in Rust. 
This is an amazing and challenging project to work on. If you'd like to join us, we hang out in #servo on irc.mozilla.org or just dive right into the code[1]. You don't need previous browser hacking experience, and we're happy to mentor you through a bug. We're opening three full-time positions on the Servo team at Mozilla Research within the next couple of days; they should be up on the careers[2] page soon. Also, if you're a graduate student, Mozilla Research is still looking for summer interns for Servo, Daala, Shumway, and other projects. Those positions are also on the careers page. [1]: https://github.com/mozilla/servo/ [2]: https://careers.mozilla.org/en-US/
(Well, the segfault was also a bug!)
I second that. I was playing around with rust-zmq lately and i figured that it's not async, so i had to put some stuff into native threads, but am able to keep green threads (which i usually would prefer, even if it has no great benefits in rust right now, as i understand it).
&gt; because of the extra cost What kind of extra cost are you referring to? &gt; Copy without Fix-Up ? Could you describe this more precisely? Do you mean that `&amp;`-references would be represented using pointer-tagging to be either pointers or ptrdiffs? What's the advantage of that over making them be ptrdiffs always? And in either case, I think this would mean that `&amp;` couldn't be `Pod`, which would be unfortunate.
[Or a tumblr](http://xkcd.com/1025/)
[Image](http://imgs.xkcd.com/comics/tumblr.png) **Title:** Tumblr **Title-text:** Dot Tumblr Dot Com, on the other hand, would be an awful name for a band, if only because of how hard it would be to direct people to your band's website. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=1025#Explanation) **Stats:** This comic has been referenced 29 time(s), representing 0.23% of referenced xkcds. --- ^[Questions/Problems](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Website](http://xkcdref.info/statistics/) ^| ^[StopReplying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me)
&gt; &gt; because of the extra cost &gt; &gt; What kind of extra cost are you referring to? &gt; The cost of going through the whole stack and task-local heap to fix all the potential pointers into the stack being copied. &gt; &gt; &gt; Copy without Fix-Up ? &gt; &gt; Could you describe this more precisely? Do you mean that &amp;-references would be represented using pointer-tagging to be either pointers or ptrdiffs? What's the advantage of that over making them be ptrdiffs always? And in either case, I think this would mean that &amp; couldn't be Pod, which would be unfortunate. Yes, this is the representation I had in mind. You cannot always use ptrdiffs because pointers into the heap cannot be computed relatively to the stack root since they do not move when the stack does (or you would need a `0` heap-root and a stack-root and tag which root should be used). Regarding `Pod`, I ignore what it means, and what it's supposed to do. If this is related to memcpy-ability, then the tagged-pointer is perfectly bitwise copyable; there is no real difference between a tagged-pointer and real pointer for copyability, it's only when dereferencing that the difference shows... ... and of course you absolutely need *never* pass a tagged-pointer to either a C-routine (it would not understand it) or another stack (the diff from root would be off). 
Ah, the diff would be relative to the stack root! For some reason I was thinking relative to the pointer itself (in which case it would have to change at every copy, hence non-`Pod`). Interesting idea. 
Haha, I have the same perfectionism. Before I saw Rust a few years ago I was almost considering writing my own language with similar characteristics. They did a way better job than I would have though. I would also like some simple dependent types for static array bounds checking (again, perfectionism), higher-kinded types, and a little nicer closure organization (although the last two are in progress).
(weird feeling to browse reddit and see my face in the middle of my frontpage…)
Can someone make a cookbook recipe for the callback thing (that doesn't involve tasks &amp; channels), this got me worried a bit :). I thought closures could be used for this...
In the 4 allocations remaining listed, I'd like to understand what the difficulty is in allocating `~Task` and `~GreenTask` at the top of the task. The only issue I could see is that generally `~` owns its memory area (on top of ensuring the destruction) and thus having 3 `~` point into the same area is not really feasible; which would require changing this code a bit. Are there any other issues I am missing ? (Oh and: well down!)
Very interesting experiment. This is about the right quantity and density of information to put on the home page. The 'latest news', 'learn rust', and 'community' sections are great right where they are. The next three sections 'foundations', 'efficiency-first', and 'polyvalant' seem like they are just reaching for subjects to fill space. I might rather combine them all into a single concise elevator pitch above the fold (possibly instead of "The World needed a safe..."). As I see it this has two taglines ("safe, concurrent, practical language", and "The World needed a ...") and three elevator pitches, and we only need one of each. I love the overall conversational tone, as well as the unicode "♥" in "Rust is developed in the open with ♥ from Mozilla". Presumably we can just source the news directly from the @rustlang twitter feed. I've opened a new issue just about the www.rust-lang.org home page: https://github.com/mozilla/rust/issues/12273
Looks nice! BTW the print function doesn't need to be a macro there; `println` would work just fine.
I really don't like basically stealing another langauge's (and one that sounds so much like Go!) website.
Thanks for your feedback! &gt; The next three sections 'foundations', 'efficiency-first', and 'polyvalant' seem like they are just reaching for subjects to fill space. Hahaha, I've never been much of a marketing guy! I agree and I will try to implement your suggestions.
Nope, `println` isn't in the prelude anymore; it's been decided that simply using `println!` everywhere would make things simpler.
Oh wow! Guess I've been out of the loop. Good to know.
Yea I know, I think it looked a bit disproportionate (vs. the text on the right) without it. As I make more changes to that pattern I will probably change the paragraph on the right and make it a bit longer so I could use a simple example in a few lines.
As a mobile user, it looks good here too! 
Yup, I always make sure that my work is responsive. `:)`
It's all there, just with small sentences instead of just a list. I do not really get what the download thing means but there was a bug with the conditional display of the download button and I fixed it, thank you. I will simplify it later on, no worries. I had planned to do that already.
Why is it any different/more concerning to just calling `pthread_create` in a loop in C?
I think the the current website is too much functional* while this one here is not enough of it. You are probably stroked by the difference. *You still have to be newcomers-friendly to some extent. I see about the Downloads. The link still goes nowhere right now but I will keep that in mind.
&gt; I disagree with the premise that the visitors will already know what Rust is all about... when I shop for languages, I certainly don't know much about them except maybe if they are compiled or not, a list of key features is a must for me. I meant that you don't need to caught their interest and tell to sell it completely from the first sentence (like with the huge paragraph of the current homepage) and I certainly expect that people want to know more about it, that's why I argued in favor of a Rust tour that would stand out from the main page. 
Furthermore, it's possible to explicitly create green and native Schedulers and spawn tasks on them as needed.
This has nothing to do with Rust. The comparison will succeed if you do it by converting both to f32, but of course it generally won't as f64. 
Honest question: why do you need dynamic typing for actors? And about your question: you can spawn lots of tasks. The runtime will create the needed number of kernel threads for them. 
&gt; Design by committee has never led to elegance I may be the only one (especially in this subreddit), but I honestly believe that most of what the committee added with C++11 is very elegantly designed. It may not be obvious, but behind all the backwards-compatibility and complexity C++ is a very beautiful language and the recent additions mostly underline that. If you need examples: Take a look at the random-header or `std::tie`: While it may not be obvious at a first glance both are pretty awesome and well designed libraries. The main reason why I am willing to give Rust a chance is that the the designers didn't throw all of the great concepts of C++ away because the language looked unsexy to people who didn't know it well.
Just an idea: It would be nice to have a wrapper around the numpy c api. http://docs.scipy.org/doc/numpy/reference/c-api.html
Again, hitting the nail on the head. That's exactly the response I was hoping for! Thanks a lot! &gt; (BTW, traits aren't normally dynamic dispatch, only a trait object (i.e. &amp;Trait or ~Trait) is dynamic dispatch; using generics (fn foo&lt;T: Trait&gt;(x: T) { ... }) or calling a trait method on a concrete type are both statical calls.) Right, I'm relatively clear on the distinction between traits as used with generics and trait objects, I'm just not sure I have the terminology down yet. Thank you for this clarification regardless.
Oh, I definitely thing there are good things in C++. Resources handling for example is unparalleled in many a language (languages with GC have a hard time competing here). However, I would not say that `&lt;random&gt;` and `&lt;tuple&gt;` were designed by committee. They are nearly complete clones of the Boost libraries, and those libraries were crafted by only a couple people. The committee did ratify their use, and there may have been a bit of polish here and there, but the committee did not design them... ... and anyway this is kind of a moot point. Although languages and their "standard" libraries are generally seen as indivisible, the truth is that they are not. *Some* parts of a Standard Library will rely on a close interaction with the compiler (intrinsic, implementation-defined behavior, ...), but really `string`, `map` or `ostream` are pure library implementations. I am more interested in *Rust as a language* than *Rust as libraries*, because I can always pick up another library utility if the Standard one does not suit me (for most parts); whereas it's tough to integrate another language.
Ah! Sorry for not making it clear :/
Of course you can pass a closure as a callback parameter, but also in this case you must guarantee that anything the closure closes over is valid for as long as the callback is valid. In practice that means that "immediate" callbacks (which happen in the same scope as you define them) are no problem. Callbacks that may happen at a later point of time (e.g. something like an onClick event) in a UI toolchain are a big problem. 
No problem. (To be completely clear for you and anyone else reading this:) The jargon ["dynamic dispatch"](http://en.wikipedia.org/wiki/Dynamic_dispatch) refers (for trait objects) the fact that a trait object stores a pile of function pointers to its various methods in itself as a vtable (similar to what's described in the C++ section of that article) and so any method calls do a virtual call and the exact function that is called is only known at runtime i.e. dynamically. I think you were using it to mean all trait-based polymorphism?
An interactive tutorial like tryHaskell, tourofGo or codecademy like is very valuable. :0 It reduce friction to adopt a technology for a newcomer, which is cool! :) Yep it's definitely a must have for 1.0. 
`~` calls free when it goes out of scope, so "allocating" them at the top of the task would be invalid; they'd have to just be placed on the stack and used as `&amp;'static Task` everywhere (or some equivalent wrapper).
Yep, I was thinking you could do callbacks where you could refer to some top level App or View classes that last for a longer time. It's bizarre if safety rules prevent this.
Generally so the Actor abstraction can be used both in process as well as across the wire without changes to client code.
I live here too!
If you like ML-like languages, you might be interested in [ATS](http://www.ats-lang.org/). It's another 'system language', and it has a relatively sophisticated type system. 
They currently do :-) We will see if the new smart pointers will change that situation and allow it in reasonable way. If not then rust won't be an option for quite a large set of applications.
/r/playrust
What was the rationale for going with 'extern crate' instead of just 'crate'? I don't think I was paying attention to that discussion.
&gt; i admit i forgot the details from CS class :P Now in my case I'm not sure if I should be happy or totally crying in a corner, because in my entire CS course I never ever heard anybody talking about floating points stuff. So until recently reading these threads I had no idea that floats could cause problems... I can picture myself in the future trying to debug some crazy stuff about this having no idea what's going on. At least now I learned that I shouldn't trust floats :P. Just a little just over here, sorry.
&gt; Channels have been rewritten to use the internally-upgradable design that was hashed out on the list. Rather than having a separate SharedChan, Chan is now cloneable. Wow, it sounds like the new design is really great. The performance gain for one-shots, in particular, is very welcome. Between that and the green task spawn improvement, it seems like concurrent programming once again gained a lot :)
Hmm, I think simple links would be enough. The paragraphs are hard to scan through for somebody wanting to get to things fast. Some friendly copy and personal touches are nice because it reflects the friendly nature of the community, but this can probably be kept to the elevator pitch and the footer. You don't want it to get in the way of the functionality of the site.
Is it possible to run the Gecko test suite against Servo? I appreciate that the results right now aren't going to look stellar, but it'd be an interesting thing to graph over time.
The pidigits benchmark as displayed on the shootout was almost certainly improved by far more than 20x. But I guess this is what I get for being impatient and not gathering the actual data -- as in, not waiting &gt;20min for the original implementation to finish running on the full workload. :)
It is not possible to run the Gecko test suite directly against Servo right now. That said, we could probably pick up many of the ref tests and reuse them pretty much directly - a ref test is just two versions of a page that are supposed to render to the same result, and we have infrastructure that supports that mode of testing already. We're also working with jgraham, who is porting the W3C Platform Tests (https://github.com/w3c/web-platform-tests ) to run against Firefox. He has also gotten those tests running against Servo, and we're planning to both use those directly and contribute to making them better for all browsers. 
I know that servo is intended for research and has no integration plans with firefox, but I still don't know what that means exactly. Is it something that could be integrated into firefox if it ever gets production ready? Is it an engine that warrants an entirely new browser? Is it a prototype for something that will eventually be built from scratch? Is it just a proving ground for Rust?
Does Servo just act as the layout engine? Does it also encapsulate a Javascript VM, or would one of those need to be integrated with it? If so, is it in Servo's best interests to have the JS VM/JITC written in Rust for it? 
From what I've read, it's a research project in making a rendering engine that is safer and parallelized, as well as providing a large scale Rust project so feedback from its development can be used to improve Rust. I don't know if it make it into Firefox itself, but what the devs discover from making will be used in the future.
Some big improvements compared with [6 months ago](http://about-rust.blogspot.de/2013/08/some-pages-in-servo-as-of-2013-08-10.html)!
Ignoring the practicality of writing a JS compiler, what would the benefits of a JS compiler written in Rust be for the Servo project?
still waiting for rust 1.0 :/
But still much worse, then Plan 9's Mothra and Abaco browsers. 
The ultimate goal of Rust will be to replace C++ in the engine used by Mozilla, that is why they are funding its development. Of course that's not gonna happen tomorrow.
I see your point, however a list of elements like now seems to not be very friendly. This particular pattern seems to tie more into [brson's guidelines](https://github.com/mozilla/rust/issues/9875#issuecomment-26961895) (imo).
No, no need for that; you did not write anything incorrect. (and plus, I still have not bothered to gather the before/after data for the full workload of ‘pidigits 10000‘). We can just let this be a little surprise for whenever the shoot out refreshes its version, presumably post v0.98.
Apologies, I can't edit the title now. It should really read "Patches for precise GC in LLVM..." &lt;shameless_plug&gt;If you want to keep track of LLVM developments, check out my [LLVM Weekly](http://llvmweekly.org/issue/7) newsletter and consider subscribing&lt;/shameless_plug&gt;. As many of you may know, the current state of GC in LLVM is that precise GC is not easily possible using the llvm.gcroot attribute (which attaches to stack slots). Azul Systems have been working in this area for a while, you'll find interesting messages from Philip Reames and his colleagues over the past few months. Excitingly, this message confirms they'll be attempting to upstream their precise GC support modifications and we can expect patches in the not too distant future.
GetElementPtr: http://llvm.org/docs/LangRef.html#getelementptr-instruction http://llvm.org/docs/GetElementPtr.html
Really? Wikipedia says that Mothra doesn't support CSS or JS at all (and a glance [at Abaco's source](http://plan9.bell-labs.com/sources/plan9/sys/src/cmd/abaco/) indicates that it doesn't either). (And all the screenshots I can find are from 6+ years ago, when websites were much much simpler.)
&lt;3 your LLVM weeklies.
Golang just got precise GC as well, this is great news for my two favorite concurrency languages!
Note that this is a future pathway for adding *support* for fully precise GC to LLVM, not an actual implementation, and not to the Rust compiler. (A fully precise GC in Rust will take more work, but will be able to build on the LLVM support.)
Gotta save all the meaningless PRs for the important numbers. This possibly beats [#10000](https://github.com/mozilla/rust/pull/10000).
&gt; I would also like some simple dependent types for static array bounds checking By this do you mean actual dependent types (like Agda Idris etc.), or just type-level uints a la C++'s non-type template parameters? If the former, do you have ideas about how it could/would/should work?
This is a momentous day. On our current trajectory, I'm sure it will only be months before we reach #123456.
I've detected a hexadecimal color code in your comment. Please allow me to provide visual representation. [#123456](http://color.re/123456.png) *** [^^Learn ^^more ^^about ^^me](http://color.re) ^^| ^^Don't ^^want ^^me ^^replying ^^on ^^your ^^comments ^^again? ^^Respond ^^to ^^this ^^comment ^^with: ^^'colorcodebot ^^leave ^^me ^^alone' 
Thank you! It helps massively with motivation to hear from people who find it useful.
It seems we will have problems with reddit when we reach the 6 digits Issues.
The same as writing a browser engine in Rust. The impact might indeed be smaller though, since a JIT implementation is unsafe by nature.
I would expect things to be even better after the work that we are doing in conjunction with Samsung to get ACID2 passing lands. That represents a huge portion of the remaining layout issues. (there will still be a lot to do to make the web "work" after that, though! we don't even have cookie support...)
No problem, switch to the hexadecimal notation past #99999 (e.g. #x186a0). We should convince Github to implement this.
"Someone" said in a presentation that Servo aims to implement the webkit embedding interface, after which it could be 'dropped in' to a WebKit based browser.
How about `debug!`?
I applaud whoever made this! It looks very convenient. However... it's also a demonstration of how desperately we need a good packaging and distributing system. I know this is a sore topic, but it's sore for a good reason.
&gt; Reason I avoided debug! was that flags for testing and logging weren't really compatible What do you mean by this? Theoretically `RUST_LOG=path::to::your::module ./testrunner` should work.
#123456 is one of my favourite colours. I've used it in quite a few designs; it works really well.
I think the test runner captures stdout now and only displays it if there's a failure. This is interesting fallout.
It would also allow better integration between the browser and JS engine, rather than having to go via the FFI boundary.
Sorry for being ignorant. What exactly is precise gc? What advantages does it bring? 
I wonder how much [#3533](https://github.com/mozilla/rust/issues/3533) (and the other "redesign how the compiler prints errors" issues) would help make error messages easier to understand. I know I find it difficult to isolate the actual content of an error from the crufty file name/line numbers at the start of each one. e.g. test.rs:3:5: 3:9: error: cannot infer an appropriate lifetime for borrow expression due to conflicting requirements &amp;x.y ^~~~ first, the lifetime cannot outlive the anonymous lifetime #1 defined on the block at 2:24... fn bar(x: &amp;Foo) -&gt; &amp;int { &amp;x.y } ...so that reference does not outlive borrowed content &amp;x.y ^~~~ but, the lifetime must be valid for the anonymous lifetime #2 defined on the block at 2:24... fn bar(x: &amp;Foo) -&gt; &amp;int { &amp;x.y } ...so that types are compatible (expected `&amp;int` but found `&amp;int`) &amp;x.y ^~~~ Of course this particular error message ends up with a lot of duplication and rather verbose (and the "expected A but found A" part of the last message could be better...), but at least it's easier to read. And, having the awesome did-you-mean lifetime suggestions would make it a million times better.
At first I laughed, but then I saw that it was a decent colour.
Oh, don't get me wrong, I know it's **quite** a difficult problem. Many a time have I thought of my own solutions that seem ludicrously simple and wonder why we don't use them, only to find some fatal flaw in it :) Still, I don't think we should simply push it off and say "we'll worry about it closer to 1.0." The ideas need a good amount of time to be developed and battle-tested, and if we're only ~9 months out from 1.0, that doesn't leave us much time!
&gt; I would love for someone with a good 30,000ft view of the project (either brson or tjc, I reckon) to write an AAR of why they think rustpkg turned out the way it did and what we can learn so as not to repeat history. Yes please!
Here is the problem. My test doesn't fail. It **freezes**. I was trying to debug where it froze. Is there an explanation how to get debug to display method invocation?
&gt; t flags for testing and logging weren't really compatible. I'm curious why println! doesn't work as well. I think you needed to pass `--debug` flag to even show `debug!` information.
I don't understand what you mean by "display method invocation" but // debug_test.rs #[test] fn test() { debug!("start"); let x = 1; debug!("middle"); assert!(x &gt; 0); debug!("end") } Compiled with `rustc --test debug_test.rs` and run with `RUST_LOG=debug_test ./debug_test` prints: running 1 test start middle end test test ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured (If you have one test you wish to focus on you can pass (a substring of) that test's name to the runner to only run that one, e.g. `./debug_test test`.)
Not now (maybe for a brief period a long time ago). If you pass explicitly pass `--cfg ndebug` then the `debug!()` statements get compiled out completely, but they're there by default. (In any case, I don't see why the flags would be incompatible at all.)
I mean like a debugger in IDE that steps through code. But if `debug!` works I guess I could try those. What I tried was several months ago, on Windows, there debug would cause test to crash. I haven't touched debugger from that. Tbh I kinda prefer Java style of being able to set debugging level at runtime.
LLVM is getting precise GC? This makes me so happy. 
Nothing beats "chartreuse". I find that if I make something "chartreuse" I'll come in the next day to a beautifully styled UI (and a very tired designer). 
Wikipedia has a good definition: http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29#Precise_vs._conservative_and_internal_pointers Basically, a conservative garbage collector will fail to collect garbage in cases where it can't tell whether a value is a pointer or an integer.
&gt; but they won't be usable on the Web But now servo is even less usable, then “tyny” engines. I wonder, why not to implement sort of “primitive mode” and basic features first, and get an usable thing? I mean, the engine framework should be flexible enough for this.
Have you tried running the test runner in your favourite debugger and using whatever technique for halting execution it provides? (e.g. ctrl-C in gdb.) The `-g` flag to `rustc` will cause DWARF debuginfo to be generated and make line-by-line debugging possible. &gt; set debugging level at runtime Isn't that exactly what I'm demonstrating with `RUST_LOG`? It's selecting it at runtime.
Ah, I see: setting the level inside the code. Yeah, no possibility for that (and even OS variables won't help: the `RUST_LOG` setting is read once, at start up). Compile with `rustc -g --test`, run `gdb --args ./testrunner &lt;testname&gt;`, wait until it hangs and then ctrl-C to halt execution and put you into a debug session. `bt` (or `backtrace`) should show you a call stack. The default rust runtime starts multiple threads, so you may have to switch threads (`thread 1` `thread 2` ...) until you find one with your functions in the backtrace.
I don't think I fully understand the lifetime inference bits.. Could someone give me an example of a function where it's necessary to treat the arguments as free lifetimes? In general, I often find these types of error messages annoying (not as much as the confusing error message you get now though), as it seems the compiler already knows what to do, but forces you to manually do it anyway. It always makes you wonder if a smarter compiler could do the inference all on its own.. In this case, I just don't understand the lifetime inference, so I understand my complaint above will seem ridiculous to those in the know. Still, I'd like if someone could explain why this is not possible
&gt; Mind you, rustpkg was something that tjc dedicated several months to, with extensive discussion both within the community and amongst the team. Just about every aspect of it was discussed and documented in many many many weekly meetings. This isn't how I perceived it. I raised very major issues with rustpkg's design (*not* the implementation) last June and was basically told that the design was fixed in stone and that it couldn't be altered since that would mean that rust 0.8 would be without a package manager. I was told that we were copying Go's package manager (which makes no sense... Go is all about formatting convention inducing semantic meaning unlike Rust, and their package manager reflected that) and that was an immutable design tenet. While simple use cases were documented, once you got to any level of complexity there was no documentation anymore, and the whole thing creaked from being made to do what it wasn't supposed to do (by design). It seemed clear to me back then that ignoring these design issues early on meant that the whole thing would end up being scrapped, and it wasn't a surprise to me when it finally happened (glad it was before 1.0!). In my opinion, all that's needed is to make a package manager that supports existing repositories, which are complicated and "messy" compared to the idealized "src/lib.rs" repository, rather than be procrustean about it. If we are copying another language's system, let that other language have similar levels of 'magic' in its ecosystem.
&gt; "Relatively sophisticated" huh. :D When in doubt, I tend to err on the side of understating these things.
This is awesome! I was seriously considering doing more gamedev in rust, but when I tried it, I ran into the same problem I had with Haskell. Which is that you see all these cool libraries, but everyone just keeps using rolling releases from Github. This always seems to cause problems down the line, if they aren't actually broken already (due to not pointing to a stable release). Projects like this are really helpful because I don't want to take the time to piece together working revisions to prototype stuff and see if it's plausible to port my engine, etc ...
Any problems regarding, [cgmath-rs](https://github.com/bjz/cgmath-rs), [color-rs](https://github.com/bjz/color-rs), [gl-rs](https://github.com/bjz/gl-rs), [glfw-rs](https://github.com/bjz/glfw-rs), and [noise-rs](https://github.com/bjz/noise-rs) can be directed to me (bjz) on irc.mozilla.org #rust-gamedev. Thanks rlane for bundling these together!
ktt3ja's new error message looks really nice. I am looking forward to the day when this implemented in an IDE-daemon :-)
This makes me think a Rust version of [Reconstructing Cave Story](http://www.youtube.com/playlist?list=PL006xsVEsbKjSKBmLu1clo85yLrwjY67X) would be a very nice resource when rust hits 1.0
Been playing the server for a little while, really nice community and never seen one hacker! The admins are really fair and sort any problems you may have. Its a really fun server and you should come check it out :)
For discussion of the game Rust, please see /r/playrust. This subreddit (/r/rust) is for the Rust programming language.
Good server! love it! no cheaters for once
This subreddit is for the programming language called Rust. Rust is a systems programming language (like C, C++, or D) with an interesting type system that allows expressiveness and enforces memory safety. The language was started by Mozilla so they could experiment with crazy browser technology that they wouldn't be able to easily do with the Firefox codebase. The experimental browser that is being developed using Rust (and by some of the same people) is called Servo. A key question that Servo is trying to answer is whether it's feasible and beneficial to make a web browser that does as much work in parallel as possible. Rust is still in active development and programs developed now are not guaranteed to work with whatever Rust looks like when it reaches version 1.0. This means that it's not used in production much (but it is used by a few brave folks).
I've been following along with that series in rust! Using `rust-sdl2` as well :) https://github.com/drbawb/rust-story builds w/ `rust@master`. (As of 8:00 this morning when I build my "nightlies" anyways...) --- Worth pointing out that I am currently using a locally patched copy of `rust-sdl2`. Had to replace `extern mod` with `extern crate` and work around the removal of `to_unsafe_ptr()` to build it against the latest version of `rust`.
From my intro programming class, we used something like if(abs(num1-num2) &lt;epsilon) where epsilon is some small constant depending on your precision.......
As a rust newbie/stalker, in this code conn.query(~"USE mysql"); Why did you use `~` in front of the string? From the tutorial I know that `~"a string"` makes a heap-allocated string, but I don't know why you would need one for a query string, or the other strings in fact.
Overusing `~str` is a pretty common new-to-Rust kind of thing.
I built http://issue2pr.herokuapp.com/ to deal with the 'turn an issue into a pull request' thing. I still don't see why the git command is not sufficient for seeing which issue is associated, if you really need to know that.
So query is something like: fn query(q : ~str) -&gt; () { // stuff } Which means you have to give it a heap string?
&gt; pcwalton: We may end up removing string types anyway. I assume that this is being done to make way for a redesign, which is always fun to watch. Could someone enlighten me?
I like the idea of having both `assert` and `enforce`. Any large project is going to have some assertions that are too expensive to check, or that indicate a bug but shouldn't abort in production software.
Awesome! I think I'll be looking through it when I get caught up with the original.
It's currently fn query&lt;'a&gt;(&amp;'a mut self, query: ~str) -&gt; Result&lt;Option&lt;~MyResult&lt;'a&gt;&gt;, ~str&gt;; Which is basically the same. It should probably be fn query&lt;'a&gt;(&amp;'a mut self, query: &amp;str) -&gt; Result&lt;Option&lt;~MyResult&lt;'a&gt;&gt;, ~str&gt;; Takes a reference to a string, rather than explicitly requiring a heap string.
Yes, I'm sure there is a way, just no-one's implemented it for Rust. It's just a library limitation, not some fundamental language one (although it's still possible at this point of Rust's development cycle to modify the compiler slightly to make it easier if necessary).
That's right. A better solution is to take a string slice, like this: fn query(q : &amp;str) { // stuff } (Note that the `-&gt; ()` part is implicit; you don't need to write it out.)
Yeah, I've used my fair share of chartreuse. My Dad uses it quite a bit too. But I prefer #123456.
I've detected a hexadecimal color code in your comment. Please allow me to provide visual representation. [#123456](http://color.re/123456.png) *** [^^Learn ^^more ^^about ^^me](http://color.re) ^^| ^^Don't ^^want ^^me ^^replying ^^on ^^your ^^comments ^^again? ^^Respond ^^to ^^this ^^comment ^^with: ^^'colorcodebot ^^leave ^^me ^^alone' 
I swear you must be trolling
You may have been confused by the #rust-gamedev IRC channel. Rust is getting some interest from game engine developers.
This is the subreddit for the Rust programming language. You may want [the rust game subreddit](http://www.reddit.com/r/playrust). (There may be multiple rust games, I'm not sure if this is the one you want).
I believe you mean /r/playrust
I thought that was a medium term plan to allow some basic browsing/dogfood-ing without worying about building a shell.
&gt; But now servo is even less usable, I'm pretty sure the goal of servo is not to be usable anytime soon or they would have made a useable shell. The goal seems to be to implement all web standards(or nearly all except recent ones which they can add iteratively) while being faster and more secure then gecko and then to replace gecko in firefox(or make a new shell and replace firefox with it)
&gt; Queries &gt; 16mb &gt; wut `INSERT ...` 
Also `IN` queries generated programmatically.
(/r/playrust is the subreddit for the game, btw.)
Oh thanks! I will fix it.
Things related to `QMetaObject` are simply removed in PyQt4 APIv2 and PySide, in favour of Pythonic ways of doing things. I have not attempted to do a deep assessment of the situation for Rust, but I would expect a really good job of it to require a little in the way of syntax extensions and to do things in a Rustic manner.
In many other languages you use assertions for checks used in development and execpetions for code that is used by "users". Since Rust has no exceptions and conditions are gone, the substitute would be `Result`. So in Rust-land we'd have assertions and the `try!` macro.
This is great! Thanks for advice. My todo list is slowly grows..
Sounds like you want an ADT that tracks how many Foo-Accessors are still enqueued, i.e. holds a reference count RC(Foo). RC(Foo) gets decremented whenever a Foo-Task has been completed. When dequeing ApplyChangesets(Foo) while RC(Foo) &gt; 0 register it with the RC. Once RC(Foo) = 0 re-enque ApplyChangesets(Foo). Would that work for you?
Speaking of overusing `~str`. How does one painlessly transfer an `Enum` with a `str` inside between two structs/mods? There seems there are two options: 1. `Enum(~str)` incur allocation penalty 2. `Enum(&amp;str)` and now lifetime pointers need to viraly spread through your code (if you didn't start with it :( which you won't if you're new to Rust and lifetimes ) Why can't there be a `str` that easier to allocate, but doesn't' incur the heap allocation penalty?
So I assume `Vec&lt;T&gt;` replaces `~[T]`?
I believe the essence of this is merely that with DST, `str` can be implemented as a library, and only requires compiler support for string literals. I don't think users of `str` would feel much if any difference. (This is if they're thinking of the same thing I'm thinking of, which isn't certain.)
Yeah, but I'm asking are there any plans to re-implement all the current `str` functionality in a new library (I use both `&amp;str` and `~str` functionality). This will pretty much break all of my code if all functionality isn't moved to a new library. To me it looks, like I'll have to wait with upgrades until this issue is fully resolved.
A move to string as a library feature with DST would probably involve - defining `struct str { priv data: [u8] }` in the std lib - removing the compiler generated type `str`. The end result should involve no change for user code directly, though the resulting flexibility might lead to more library redesigns. pcwalton certainly didn't mean with that that we should throw out the existing string APIs.
(We'd need some handling of string literals too.)
Yes, currently `std::vec_ng::Vec` and rather bare-bones, but improving when [#12253](https://github.com/mozilla/rust/pull/12253) lands.
If such a type could be defined without some other major problem, we'd have done so already.
&gt; You can just say -&gt; Struct and have it allocated/returned on the stack. In C++, unless Return Value Optimization is available, you'd shun this for larger structs. What is the situation with Rust?
But the prefered system is &amp;str, right?
If you super-really-do-need a never-expiring string (e.g. it needs to be Send), without having to copy unnecessarily, there's SendStr (a.k.a. MaybeOwned&lt;'static&gt;). Although in this case you don' need it, I found it useful.
mm, I suspect the reason that lars is far better at taking minutes than I am is that he is not stressed about typos like this.
Thanks. Is Rust's RVO unconditional?
This may show my naivete, but why does the passed string have to be a reference? Is this just so we don't have to make a copy of the string, especially since it's large? Or is it not possible to have a plain `str` in a function a la fn myfunc(somestr : str) { println!("str is: {:s}",somestr) } 
see my reply to steveklabnik1 for another question...
I've been thinking about this and I've come to the same conclusion. I basically need a mixture of `RWArc` and `Rc`. So, a `RWArc` that is aware of how many cloned instances of it are out there. Once this hits 1, it should be ok to use the remaining one as a writer. This assumes that all of the `RWArcs` are allocated up front, and that I don't add any jobs after-the-fact. But for my use case this is true. As an aside, I really think something along these lines would be useful in the std lib. I don't like that as soon as just one fn needs to write to a piece of data, all of the readers suddenly need a `RWArc`. I would like it if `RWArc` was able to hand out `Arc`s that point to the data. This way you can pass these into tasks and remove their ability to do a `write`. 
Does replacing `~[T]` with `Vec&lt;T&gt;` means that very nice type syntax (i.e. `~[T]`, `&amp;[T]`) will be lost? That is very unfortunate :( And what about vector literals, e.g. how would `~[1, 2, 3]` look with new vectors?
Yes, this is the correct answer.
There is no such thing as `str`. There is `&amp;str` and `~str`. You've basically outlined the problem: If you don't want to make explicit lifetime guarantees, you need to heap allocate. It's inherent.
With any kind of pointer, the preferred way to accept something is via `&amp;`, as you can accept any other kind of pointer.
The syntax will actually stay, but the semantic will change. Todays `~[T]` is a growable vector, that is it has both a length and a capacity, and amortized O(1) push of new elements. `Vec&lt;T&gt;` is a more efficient implementation of a growable vector (for example, a empty vector will not allocate), and is meant as long term replacement for todays `~[T]`. After that, the plan is to introduce the concept of dynamically sized types in the language (DST). With DST, the `~[T]` type will cease to exist, and instead `[T]` will be a valid dynamically sized type that needs to be paired with a pointer, like `~[T]`, `&amp;[T]` or `Rc&lt;[T]&gt;`. In case of such a paring, the pointer becomes a fat pointer that that stores the length of the vector alongside itself. However, this means that `~[T]` will not be special cased to contain a capacity, so it will behave more like a heap allocated array: Any size change would mean a complete reallocation of it. So, in conclusion: `~[]` as type and initialization expression will continue to exist, but for more efficient dynamic building of an vector you should use `Vec&lt;T&gt;`. (Conversion between both will be supported without reallocation.)
Just type-level integers. I would imagine something like this paper: http://www.cs.cmu.edu/~fp/papers/popl99.pdf
Fixed upstream: https://github.com/mozilla/rust/pull/12359
ty, didn't find that with google or github (dropping the keyword buffer from search query did the trick =)
&gt; `str` doesn't exist. Sorry, I'll be more concise. The new change will see `str` becoming a struct like this, no? struct str { priv data: [u8] } After that is done it will be possible to write `Enum(str)`? Like you can do for other structs? I assume that `struct` (where `struct` is a pointer to some arbitrary struct) is the middle ground between `~struct` and `&amp;struct`. I.e. it's not heap allocated, and doesn't have benefit of having lifetimes set.
Ah ha! Okay. Yes, my understanding is that that's a goal. I don't fully understand all of the implications. I _think_ you are correct, because basically, we'd be eliminating `&amp;str` and `~str` as types, they would simply be of type `T`. There are some conventions about Rust types that are making this a tad confusing as well. `struct` is not a type, and if it were, it would be a bare type, not a pointer. A bare struct would be of type `T`.
I don't think it's guaranteed that the syntax will stay for `Vec`.
/r/playrust might appreciate this more (and they may appreciate it even more with some paragraphs).
Yeah, all values larger than a word use a return pointer and are allowed to write directly to it. (There are some problems with it (i.e. it could be implemented better).)
`&amp;[T]` is unlikely to go away, but yes, `~[T]` will become `Vec&lt;T&gt;` (and likely to stay that way). The literals may become a generic macro `let v: Vec&lt;T&gt; = seq!(1, 2, 3);` or a constructor methods defined for a few small fixed length vectors `let v = Vec::fixed([1, 2, 3])`.
The only fault I see with having such a type is that this repeats C++'s naming stupidity. It really should be called by what it is - a kind of Array. A vector is (e.g. from google): "a quantity having direction as well as magnitude, esp. as determining the position of one point in space relative to another. "
So in rust, this (pseudocode): SomeBigStuct function init() { return SomeBigStruct{x = 1, y = 2...} } struct = init(); has the same performance characteristics as this: void init(*SomeBigStruct struct) { struct.x = 1; struct.y = 2; } struct = SomeBigStruct; init(&amp;struct); ?
yup! Exactly. I love 'em.
That's really cool! Is that mentioned in the tutorial/reference manual anywhere? I was playing around with writing bindings in the second style for efficiency reasons, not knowing that performance would be the same either way.
That's a surprising way for the program to fail from infinite recursion. Running off the end of the stack *should* abort in a slightly more controlled way, by printing "task {} has overflowed its stack". This `!ptr.is_null()` failure though is an error in the runtime.
I get the same in 0.9. I ran a similar program in C and I got a SIGSEGV instead of a SIGABRT. The C program got way further (~260k runs on my machine vs 13k with `rust`), so it makes sense that it would get segfault instead.
I was a bit surprised about small number of recursions as well.
Oh, great, thank you)
Moving to trait objects is intended as more or less a one-way transition. There *are* ways of getting back to the original type. For example, with a `~Any`, you can get back to a `~T` with `.move()`: let any = ~std::io::MemWriter::new() as ~Any; let writer = any.move::&lt;std::io::MemWriter&gt;().unwrap(); … but you cannot safely get a `~MemWriter` out of a `~Writer`, because it does not have that interface. You can, however, copy what `Any` does by looking at `src/libstd/any.rs`; the relevant parts are `impl&lt;'a&gt; AnyRefExt&lt;'a&gt; for &amp;'a Any` `fn is` and the `impl AnyOwnExt for ~Any` `fn move`. I won't paste the relevant code here because this is Dangerous Code in the Wrong Hands. (i.e. you probably shouldn't do it, so I won't help you *too* much. If you need it as a `MemWriter`, make sure things use `&amp;mut Writer` and not `~Writer`.)
Rust defaults to a smaller stack size (2MiB) than C does (typically 8MiB). I don't know why so few frames are fitting in that 2MiB though.
I'm guessing C is just overflowing its stack whereas Rust is preventing it from overflowing. I don't know much about either runtime, but I imagine Rust's is *much* more sophisticated. My C stack size is 8MiB (`ulimit -s`), so that means each frame is roughly 32 bytes (assuming 250k is the magic number of frames) and in rust each stack is roughly 150 bytes (assuming 13k frames). I compiled with clang 3.4 and rustc 0.9 respectively. Here is both programs for reference: recurse.c: #include &lt;stdio.h&gt; void recurse(int i) { printf("%d\n", i); recurse(i + 1); } int main() { recurse(0); } recurse.rs: fn recurse(i: int) { println!("{:d}", i); recurse(i + 1) } fn main() { recurse(0) }
The previous discussion: http://www.reddit.com/r/rust/comments/1v7hqb/the_periodic_table_of_rust_types/ (It was submitted with a temporary URL at that time.)
Yeah: http://static.rust-lang.org/doc/master/tutorial.html#more-on-boxes
would be so nice if rust had some form of tail call support
eddyb is working on them.
No, just default params. I agree though, the recursion would probably be TCO'd, especially since I'm not returning anything.
No it won't, as far I'm aware. It will generalize the current ways for putting them behind pointers.
Does Rust have TCO?
It has no guaranteed TCO. In this case there is no TCO because println!() leaves us with a call that takes a pointer to a value on the current stack frame, and it's not marked as "nocapture", so LLVM has to assume that there are still references to that stack frame and can't reuse the stack frame for the call.
I posted that because of [that](http://www.reddit.com/r/rust/comments/1xfjo7/ide_support/), I guess it’s an equivalent of gocode that is also interesting to look at.
That's very unfortunate :( Have you considered calling the type `vec&lt;T&gt;` instead of `Vec&lt;T&gt;`? Maybe it's just for me, but `Vec` is really ugly. `vec&lt;T&gt;` is nicer, but still bad compared to `~[T]` (and does not follow camelcase convention... not good). Though I understand the reason behind it.
Niko Matsakis wrote in his [last post](http://smallcultfollowing.com/babysteps/blog/2014/01/05/dst-take-5/) about DSTs that enums cannot have dynamic type arguments (search for 'enum' on that page). Don't know, maybe something changed since then.
There is still no official grammer. The stuff in the manual is outdated, wrong, and incomplete.
This looks pretty cool. I think using this along with the open source IntelliJ Platform(The platform the JetBrains IDEA's are based on) would make for an awesome Rust IDE.
OK, I've done this, and I can make the types work out. But I haven't gotten the 'move' part working yet. I.e. I can get an &amp;-pointer to the Writer back out. But I can't move the writer out yet, which is needed to unwrap a MemWriter.
And yeah, it's like C++ templates. What do you mean by switching the Writer type at runtime? Like, keeping the same logger, but changing out the enclosed Writer for a different Writer with a different type? This approach would foil that, yeah. (Of course, then it's super-mega-unsafe to try to pull a Writer back out, since you really have no clue what type it might be.)
Well, just for fun, whether or not you can use it, here's the working version: http://kib2.free.fr/pastebin/view_paste.php?id=216
Just for fun, I put together a version with my solution -- using polymorphism with a trait bound, instead of moving into a trait object. http://kib2.free.fr/pastebin/view_paste.php?id=216
Not guaranteed TCO like Scheme, but LLVM still optimises many instances of tail calls (well, specifically, it optimises ["sibling calls"](http://llvm.org/docs/CodeGenerator.html#sibling-call-optimization)).
That's against convention. (I personally like `Vec&lt;T&gt;`, but I can understand why others would disagree.)
I need to re-read all these discussions, but, I *think*, if we get static tracking of moves/drops (as opposed to the current dynamic, zeroing / drop flag based approach), then *possibly* the only major obstacle left would be the calling convention. But that's definitely an obstacle. (I'm also not sure what this part's about: &gt; Tail calls also "play badly" with assumptions in C tools, including platform ABIs and dynamic linking. )
Hadn't heard of sibling calls, thanks!
Why doesn't it get TCO in this case? fn print_n(n: int) { println!("deep: {:d}", n); } fn recursion(n: int) { print_n(n); recursion(n + 1); } fn main() { recursion(0); } 
Because `print_n` got inlined. This gets TCO'd: #[inline(never)] fn print_n(n: int) { println!("deep: {:d}", n); } fn recursion(n: int) { print_n(n); return recursion(n + 1); } fn main() { recursion(0); } Edit: To clarify, after inlining we're back at the original case.
Duh. Thanks! My first attempt was fn recursion(n: int) { { println!("deep: {:d}", n); } return recursion(n + 1); } but I guess there's no way to get that to not inline.
For discussion of the game Rust, please see /r/playrust or /r/playrustservers. This subreddit (/r/rust) is for the Rust programming language. (I wonder if there's some way to automate these comments...)
You don't need `~T` there; `T` would be a better idea. And things like ` return Logger { writer: new_w };` should just be `Logger { writer: new_w }` with no semicolon after.
Thanks. I did have a bit of a go but ran into some syntax issues so that should help me figure out what I got wrong so should be useful for learning.
For discussion of the game Rust, please see /r/playrust or /r/playrustservers. This subreddit (/r/rust) is for the Rust programming language.
Aha, thanks. Note that I started with OP's code and pretty much cargo-culted from there; I haven't looked at Rust much since last year sometime. (But I'm very excited about it, and I hope to get back into it.)
/r/playrust
I've started writing a little code-autocomplete utility in my spare time, mainly as a way to learn the language. It is early days but if nobody else is tackling the problem then I'll put something public together. Won't be for at least a couple of weeks though. 
Thanks for contributing! :) It's a really neat bit of code. 
There are a couple of these posts every week. Is it possible to prevent them from showing in the rss of the rust reddit ?
I don't think anything can be done on reddit's end. But there are some solutions for [filtering feeds via a third party server](http://readwrite.com/2008/03/04/6_ways_to_filter_your_rss_feeds#awesm=~owvKBcLvJXHgfz) and depending on your reader, [filtering the display of feeds](http://lifehacker.com/reader-filter-adds-keyword-filtering-to-feedly-and-the-894015688).
As an alternative proposal I made a tiny rust makefile helper: https://github.com/mitsuhiko/redis-rs/blob/master/rust.mk And how it's used: https://github.com/mitsuhiko/redis-rs/blob/master/Makefile
This is really neat and a nice addition to the D tooling available. 
I would love to see Rust get an intellij plugin. A friend of mine started looking into it recently and I hope something comes out of the experiment.
Yay for libraries rather than frameworks. mitsuhiko’s design is elegant as always :)
There is the same thing in OCaml (called Merlin) and yes, it's extremely nice, I advice to check it out.
I would have thought it was immutable as well, but I get the same results as you on Rust 0.9. Confused as well as to what causes x to be mutable.
Inside the pattern match, the variables (x) are assigned to local variables in the block. You are then changing x, which is a local variable. You can verify that after the match block, the value of bar has not changed (it still contains 1). So the only surprise is that the local variable is mutable. Maybe this should be submitted to the Github issue tracker, where it can be (at least) discussed by people with more Rust-fu than me.
It's the same behavior you'd get in most languages, it's just that in Rust not all variables can be copied (so the pattern match may destroy the head) and variables aren't mutable by default.
The values bound into new variables by a match are moved. However, `enum Foo` is implicitly copyable (by virtue of containing only other implicitly copyable types, and having no destructor), so the move in the match is actually a copy. If you want to bind a reference without moving, you can use the `ref` keyword in the pattern, as in match bar { Bar(ref x) =&gt; { // x is now a &amp;int } }
I am not surprised about the copy, but I imagined x deriving it's mutability from bar, like the OP. Having only a few months of Rust experience, I guess I imagined you would need to do something like match bar { Bar(mut x) =&gt; // copy of x is mutable } The comment below this attempts to explain why, but I don't quite grok the reason yet.
`x` is not supposed to be mutable in the OP's code. That's why I said in another comment that this appears to be a bug. Your expectation is correct.
Under what circumstances would a match destroy or alter the argument being matched? What do you mean by head in your explaination? Thanks :)
Understood, thanks for explaining.
&gt; match bar { Bar(mut x) =&gt; // copy of x is mutable } Note that x is not copied, it is out of `Bar` and 'unfrozen'. The long way to write it is: match bar { Bar(x) =&gt; { let mut x = x; // the moved value of `x` is now 'unfrozen', shadowed by a new binding of, also called `x` } }
The "head" is the expression being matched. If you use a plain pattern, it will move values out of the head. Here is an example: let msg = Some(~"value"); match msg { Some(x) =&gt; println!("some: {}", x), None =&gt; println!("none") } // The second match will fail to compile match msg { Some(x) =&gt; println!("still: {}", x), None =&gt; println!("none") } You can fix this by avoiding the move: Some(ref x) =&gt; println!("some: {}", *x),
I feel like traits might help with card definitions, but I could be way off base. It seems like you can capture the card effects in traits and have each card type implement the appropriate traits.
Try posting this on /r/playrust instead, you will probably get a better response. 
My rationale for creating static `CardDef`'s and passing around pointers to them is that each instance of a card is exactly the same as each other instance, and it's cheaper to pass around pointers to static references than to clone each one as needed. Though if I can typedef cards to different `int` values and implement their methods through traits... hmm, this might require more research.
I would love to see `libdominion` as a dependency to something.
No, this is a perfectly relevant post for this sub. Did you actually read it?
It started as kind of a solution to a specific problem (large telecom switching) and I think never caught on mainstream because of its functional nature and no real benefit for single core computers compared against C. That said, it is very interesting to hack with, but there are some warts. See http://damienkatz.net/2008/03/what_sucks_abou.html Also, you can check out Elixir, which is a new language that runs on Erlang's VM and fixes some of those warts. I haven't done much with it, but Joe Armstrong likes it.
Large `unsafe` blocks are only allowed to compile if you beat the compiler in Dominion.
I think this is caused by the compiler handling it the same as it handles: let x; // no initialisation x = 1; // initialise later I.e. the first assignment is fine. However anything that borrows it to an `&amp;mut` fails, e.g. even just writing `&amp;mut x;` instead of `x += 1;` will make the compiler crash.
Maybe it could be included in the random output after a runtime failure. :)
For discussion of the game Rust, please see /r/playrust or /r/playrustlol. This subreddit (/r/rust) is for the Rust programming language.
The convention is for `static COPPER: CardDef = Money { ...` (i.e. upper-case). Unless you have parallelism (i.e. reading the supply of each game from multiple threads) using `Rc&lt;RefCell&lt;...&gt;&gt;` for shared-mutability (of `supply`) will be *much* faster. You don't need [`read_ptr`](https://github.com/dradtke/rust-dominion/blob/74f050a847cac67d6bc7716db7cb9a16303f015d/dominion/mod.rs#L378) here. `&amp;mut **player` should work fine (and similarly below). And, that function can actually be: unsafe fn other_players&lt;'a&gt;(&amp;'a mut self) -&gt; ~[&amp;'a mut Player] { self.player_refs.slice_from(1).iter().map(|p| &amp;mut **p).collect() } You could even write `-&gt; &amp;'a mut [&amp;'a mut Player]` to avoid allocating the new vector, by just writing `cast::transmute(self.player_refs.slice_from(1))`. Note that this is all ridiculously unsafe, and would be safely implemented by storing players as `Rc`s and having the other references as [`std::rc::Weak` references](http://static.rust-lang.org/doc/master/std/rc/struct.Weak.html). I would strongly recommend this: it's easy to screw up unsafe code, and breaking invariants is liable to cause the compiler to optimise your code in ways you don't expect and which break it (due to undefined behaviour). (Yet another option would be having a "game manager" object stores all the players, and handles `manager.other_players(this_player)` etc.) [The `*` pointer here](https://github.com/dradtke/rust-dominion/blob/74f050a847cac67d6bc7716db7cb9a16303f015d/dominion/card.rs#L20) could be either just `PlayerFunc` (no need for the extra indirection of placing the `fn` function pointer behind another one). Or `&amp;'static` if you definitely need the pointer. (I strongly council against using `*` and `*mut`.) Also, what does &gt; Card actions. Since Rust apparently doesn't support defining a struct field as a method directly mean? &gt; How would I go about writing a more flexible method for playing cards that can take any input that may be needed? What other input is needed other than the currrent player? (Since it contain references to all the other players.)
You want http://www.reddit.com/r/playrust This is r/rust, which is for the Rust programming language.
(Oh, thought of another thing: `.other_players` could return an iterator, saving on the allocation (similar to the `.slice_from` solution).)
I wouldn't use the term "type inference" for this, but yes, the fact that you have to repeat the (appropriately-specialized) signature of trait methods in impls is an inconvenience relative to e.g. Haskell. (On the other hand, it might be a convenience for the reader.) Rust *does* have type inference, but only locally, i.e. inside function bodies. Edit: I see now you're also somewhat misunderstanding how traits work. In Rust traits are always over a pre-declared type parameter `Self`. If you introduce an additional one, as `Eql&lt;T&gt;` above, you now have two of them, `T` and `Self`. You probably wanted to write `pub trait Eql { fn eq(one: &amp;Self, two: &amp;Self) -&gt; bool; }`. You can also write `&amp;self` instead of `one: &amp;Self` for the first parameter if you want to be able to call it as a method.
Rust *does* perform Hindley-Milner type inference, but only within functions so that one can always know the type of a function without having to inspect the body. Hence writing impl Eql for int { fn eq(one: int, two: int) -&gt; bool { ... } } works (I guess you'll complain about this though...). It does seem semi-reasonable to allow it in trait impls (and *just* there), since the trait itself determines the exact signature. But this would be a special-case of the "no global inference" rule. I opened [#12468](https://github.com/mozilla/rust/issues/12468) (but, as I say there, I'm not particularly keen on it).
Alas, it does notice if I try to squeeze the wrong type in, so it actually does type inference but forces you to violate DRY principle anyway. This is utterly illogical.
Well, it's just enforcing the kind of thing which is done by convention in Haskell: explicit types improve clarity for the reader. For example, in order to understand the code you want to write, you'd need to both look at the impl and the trait definition (which could easily be far seperated).
&gt; It's a shame such a promising language hasn't even the most basic type system features. &gt; This is utterly illogical. Could I ask you to tone down the inflammatory adjectives? The nice people of the Rust community will be more much willing to spend time discussing and going back-and-forth with you if it doesn't seem like you're just here to attack. :) (I know you probably don't mean it, but it's a possible impression one might get from you using language like that.)
It's not doing type inference for that; it's just doing type checking, i.e. what every statically typed language does (C++, C#, Go, Java, ...). Type inference of that kind is pretty much restricted to "fringe" languages like Haskell. (In any case, see that bug I filed for a few negatives of trait-impl-inference, in particular, the silent breakage.)
Ah, I see, thank you. And with dummy parameters we can even have ad hoc-polymorphic trait functions. And with "TraitName::" prefixes the compiler can even infer the trait. The only thing that's missing is being able to "open" a trait so you can omit the "TraitName::" if there's no ambiguity. Not bad, thanks.
Sorry, I expressed unclearly, I meant that it knows what types to expect yet makes you repeat them anyway. This should be optional not enforced. Redundant type decls make the impl more readable only if you don't know the trait; if you know the trait decl, then they are just visual clutter. And "I want type errors after subtle upstream type changes" should be optional too. After all, one of the purposes of a trait is to be a code interface that changes as rarely as possible (ideally never). Traits should give you an option of trusting the upstream trait, not force you to be paranoid about it. Ah well, enough ranting, I'll get to coding, thanks.
About 2, if I understood correctly, I had the same problem until I realized that apparently you have to extract the field from the struct before calling it, as in: (struct.field)(lambdaArg) 
Sorry you're having problems getting Servo compiled on OSX 10.9! Do you both: 1) Have the Apple Command Line Tools installed: https://developer.apple.com/downloads/index.action?=command%20line%20tools 2) Have an updated autoconf: sudo port install autoconf ? If so, can you put the config.log file that was generated by configure up on pastebin so that we can see what the error was? You can also drop by #servo on irc.mozilla.org for more real-time help.
Pasted the wrong error message. First one (now changed in question) after `configure` is llvm-gcc is known to be broken, please use gcc-4.2 or clang. Do I really need the command line tools? There's a gcc in /usr/bin with the same file date as the day I upgraded to Mac OS X 10.9 and XCode 5. I followed the steps on https://github.com/mozilla/servo which include autoconf213. No config.log.
I would highly suggest getting on the irc.mozilla.org #rust IRC channel. We are most open to providing immediate feedback! Why does the `Game` type have to be stored in an unsafe pointer? Changing let game : *mut engine::Game = unsafe{transmute(~engine::Game::new())}; to let mut game = engine::Game::new(); Would remove a great deal of unsafe code. It is also not clear why you need to get references of your scene nodes when you initialize them. This: let ref mut s1 = engine::Scene::new(); Could be: let mut s1 = engine::Scene::new(); There is plenty of other stuff, but that is some to start off with.
I do exactly that to call each user-defined `play` function; the problem with 2 is that Rust to my knowledge doesn't let you write pub static SMITHY: CardDef = Action { name: "Smithy", cost: 3, action: &amp;fn(p: &amp;mut Player) { ... }}; Instead you have to define it as a top-level function and set a pointer to it, which is not much more difficult, but it would be nice to keep card definitions more self-contained.
Why not use [lambda expressions](http://static.rust-lang.org/doc/master/rust.html#lambda-expressions)?
Hi, I'd gladly join the IRC channel, but the problem is that I cannot be constantly at the pc.. my free time is unfortunately is not much, and randomly placed during the day (and essentially only in the weekend).. that said, thanks for the suggestions, but having tried that (I think it was one of my first attempts), the compiler reacted.. not well (I updated the gist the modified main.rs and relative compiler output)
Related to this: I just got [`rust-find`](https://github.com/am0d/rust-find) (by dobkeratops, which I've forked) working again (at least on a fairly recent version of rust). This provides some of the infrastructure to help text editors / IDEs understand rust a bit better. Note though that it can't handle partial parsing as far as I know. I've only just gotten it building, so I'm still trying to wrap my head around all the code at this point.
You'll get a much better response if you post on the right subreddit.
If your goal is to simply have a bleeding edge copy of rust, you don't necessarily have to build it yourself.There is a great guide [here](https://github.com/mozilla/rust/wiki/Doc-how-to-install-an-unofficial-nightly-for-Windows) on how to install rust nightlies. There is a Nuget repo maintained that has a built rust uploaded every night. I followed this a week ago and had no issues.
Thanks for the advice. I think I actually got the cygwin build working, though, and I figure if I came this far, I might as well see if I can. And if it doesn't work, I'll probably run it from a linux VM. I'm just getting my feet wet in Rust.
My goal is really to avoid having to install and maintain an entire second suite of unix dev tools over in msys, when I do serious work already in cygwin. I'm just being a primadonna whiner. :)
I did not know Rust worked in cygwin. Neat.
Great Buy. Happy Bday btw.
Thanks man
&gt; It uses a lot of symbols. Hmm, syntax-wise, I think it's more to do with the fact that it is heavily descended from Prolog, which is unfamiliar to many programmers today.
Wrong sub. Try /r/playrust
[Documented here](http://static.rust-lang.org/doc/master/complement-cheatsheet.html#how-do-i-store-a-function-in-a-struct)
This subreddit is for the Rust programming language, not the game. 
Wrong subreddit, try http://www.reddit.com/r/playrust This is r/rust, for the Rust programming language.
[Example](http://static.rust-lang.org/doc/master/collections/hashmap/index.html). (IMO, the colour scheme could do with some tuning to fit in with the theme of the rest of the docs.) Edit: [old example](http://www.contrib.andrew.cmu.edu/~acrichto/doc/std/hashmap/index.html).
Hmm, doesn't seem to be syntax highlighted at all?
It's also not particularly good syntax, with all the punctuation differing so much that swapping lines is impossible. Still better than C, though.
I'm not sure how you feel about submitting relevant LLVM links to this subreddit? There was a lot of interest last week when I submitted Philip Reames' mailing list message which mentioned his (and his colleagues) plans to submit support for precise garbage collection to LLVM in the coming months. This blog post describes the problem with implementing a precise relocating GC using LLVM's currently gcroot intrinsic, and even gives enough background for those not familiar with GC implementation to understand it.
&gt; the punctuation differing so much that swapping lines is impossible Agreed. It has its charms, but it definitely can drive you up the wall.
Thanks for the link, I watched it and it made some stuff clearer. I updated the code, trying to get rid of unsafe blocks and unnecessary pointer usage. ~~Now I'm stuck trying to store Scene instead of *mut Scene inside my Game struct, but when I try to do so the compiler complains with "error: cannot move out of captured outer variable" when, in the main.rs file, I add the scenes to the game.~~ ~~I understand that that is because the compiler doesn't know if I'll call that function again (..though it could potentially check that it is a literal lambda). Is there a way to get around this?~~ Fixed, now there are no unsafe blocks, yay! but, it looks pretty clumsy. Here are a couple of random thoughts: * I couldn't find a way to involve the "game" object inside a "scene" listener. Perhaps it is all right, it would be too complex to understand when these listeners are safe. Right now I'm thinking, perhaps I should return some kind of command pattern and the game itself will react (e.g., right now I return an Option&lt;&amp;'static str&gt; which is the name of the next scene). * At a certain point I was forced to change all "~str" to "&amp;'static str". I don't understand yet quite why. * I find the engine::start function *Extremely* clumsy: essentially, I borrow a "game" reference for: * handle events, and perhaps return the name of the next scene to display * set, maybe, the next scene * display the scene it this really idiomatic rust? or perhaps there's a better way to handle these kind of situations? code: https://gist.github.com/cheng81/2556026a3a7b03d20f57 
I like it. 
Nope, it is a segmentation fault. Below the failure message the console says "Segmentation fault" I localized it: It happens right here: https://github.com/mozilla/rust/blob/a88654977234d18b57e2a1842549941397ab0d59/src/libstd/sync/arc.rs#L83 &gt; You said current master branch, but how long ago did you update it? a few hours ago
I'm eating spam just now.
Philip Reames (author of the article) is an employee at Azul, yes.
I think this is fine. Relating it to rust in the title would be good if you can though.
I'm fine with just making it clear that it's related to LLVM.
`mut_iter` gives `&amp;mut Player` references. One fix would be `players.move_iter()` which consumes the `players` vector, yielding the `Player`s by value.
I don't understand what you mean?
I find that the blocks leave a different colour behind them—a dark grey, rather than the dark purple of my terminal.
Ah, yes, it's just a small peculiarity ([#10105](https://github.com/mozilla/rust/issues/10105)), where both `"..."` and `&amp;"..."` have type `&amp;str`, so `&amp;("...")` or `&amp; &amp;"..."` is required to get a reference to one, i.e. a value of type `&amp; &amp;str`. (Those methods take references, because they don't need ownership: that is, they take `&amp;K` where `K` is the type of the keys of the hashmap, and so those contortions are needed for a hashmap that is storing `&amp;str`s or `&amp;[T]`s. It's unfortunate. :( )
Thanks for the link! Finally decided to install Rust on windows. A year ago this wasn't feasible so I kind of slacked off.
Right. To erase a block, the program currently sets the terminal's background color to hard-coded black (*control sequence indicator* 40 m), then moves the cursor to all terminal locations covered by it and prints spaces. If you have a different background color, then obviously printing black does't correctly clear a block. I suppose one way to fix this would be to just print black over the whole terminal before starting the game. Otherwise, the better fix might be to figure out how to detect your terminal's background color, and use that to erase. This could require virtualizing the the colors instead of the current hard coded colors coupled to ANSI Select Graphic Rendition parameters. Notice the definition of the `Color` enum pub enum Color { Black = 0, Red, Green, Yellow, Blue, Magenta, Cyan, White } Has the same ordering as the colors listed in the ANSI escape code [color table](http://en.wikipedia.org/wiki/ANSI_escape_code#Colors) and that the `set_background_color` function just prints: *csi* (40 + offset) m where offset is a value of type `Color` cast to `u8`. See what happens if you change the Color ordering: pub enum Color { Magenta = 0, Red, Green, Yellow, Blue, Black, Cyan, White } 
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 7. [**Colors**](http://en.wikipedia.org/wiki/ANSI_escape_code#Colors) of article [**ANSI escape code**](http://en.wikipedia.org/wiki/ANSI%20escape%20code): [](#sfw) --- &gt;Text colors (and SGR parameters in general) are manipulated using CSI n1 [;n2 [; ...]] m sequences, where each n1, n2, ... is an SGR parameter as shown above. Thus, for instance, you use codes 30+i to specify foreground color, 40+i to specify background color, where i is the number in the desired color's column header in the table below. The following examples can be used with the printf utility, where \x1b[ implements the CSI: To switch the foreground color to black, use \x1b[30m; to switch to red, use \x1b[31m; utilizing the "bold" parameter, gray would be \x1b[30;1m; to get bold red, use \x1b[31;1m. To reset colors to their defaults, use \x1b[39;49m (or reset all attributes with \x1b[0m). &gt; --- ^Interesting: [^ANSI ^art](http://en.wikipedia.org/wiki/ANSI_art) ^| [^ASCII](http://en.wikipedia.org/wiki/ASCII) ^| [^VT100](http://en.wikipedia.org/wiki/VT100) ^| [^Computer ^terminal](http://en.wikipedia.org/wiki/Computer_terminal) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cfn612g) ^or[](#or) [^delete](http://www.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cfn612g)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/) ^| [^flag ^a ^glitch](http://www.reddit.com/message/compose?to=/r/autowikibot&amp;subject=Glitched comment report&amp;message=What seems wrong: (optional description goes here\)%0A%0A---%0A%0AReply no. 68649:%0Ahttp://www.reddit.com/r/rust/comments/1yr2uz/tetris_game_in_rust/cfn60wu)
I don't know precisely how it's all implemented, but the purple in my terminal is equivalent to those transparent terminals (the default, but I couldn't stand it), just *sans* transparency. Is it not possible to tell it to clear a space in raw mode? (I know that ncurses makes a habit of filling the entire screen on starting. Maybe it isn't.)
BTW, have you seen [the `term` crate](http://static.rust-lang.org/doc/master/term/index.html)? It contains a `terminfo` parser and so retrieves the appropriate colours based on the value of `TERM`.
I'm a contributor, yay! (ok, I just fixed some docs, no code...)
♥
Author and others: What is the code quality of this thing? I've been wanting to read a small Rust program as a part of my learning of the language. Another thing, when I try to compile the game I get "error: can't find crate for `time`". How do I get this time thing (I checked the documentation and it doesn't seem to be a part of the standard library).
Cool! It even has synchronised-scrolling/token-matching.
The [docs are being uploaded](http://static.rust-lang.org/doc/master/time/index.html), just they forgot to be listed on the front page. &gt; online in the wiki (NB. that's not [the wiki](https://github.com/mozilla/rust/wiki/), but rather a [page in the main repo](https://github.com/mozilla/rust/blob/master/src/doc/index.md).)
Crazy! I compiled Rust 5 days ago and I already can't run code from the internet :-) But thanks for your help. I'm looking forward to when things gets more stable. 
Show your ♥ for #12345
Nice to know that you found it cool. I do fear that I might have sacrificed editing experience and browser compatibility for the effects (there is a bug that I once encountered in Chrome where live editing gets stuck but couldn't reproduce).
Awesome &lt;3 this server, friendly community &amp; cool admins. 
I think you have the wrong subreddit - did you mean to go to /r/playrust? This is the subreddit for Mozilla's programming language called [rust](http://rust-lang.org).
If you use Ubuntu, there's an (unofficial) [Rust PPA](https://launchpad.net/~hansjorg/+archive/rust) that contains nightly builds. I've been using it to avoid having to recompile rust from source so frequently, which takes some time.
Thanks for the tip! I'm on Fedora though.
You mean you didn't name it *tetanus*? (Or just 'tetrust', but that's way less fun.)
It is NOT even solving the trivial syntax translation problem at this stage as interesting Rust syntax features are not supported, eg., macros, `..` match patterns, vector destructuring. And as you correctly pointed out, (if you allow me to change a few words) it is completely unaware of memory management. However, I wouldn't say it is *totally* broken. The translation does support defining functions (polytypes supported), structs, impls and using them; supports tuple destructuring and struct destructuring for match and let statements; has a type inferencing built in (HM with a twist - it assumes properties instead of complaining); has npm style conversion of use statements. All this is demonstrated from the contrived `lexer` example. Getting back to your comment - thanks for pointing this out. It is important information for the uninitiated users who might use the tool and end up wondering why converted JS gives different results when run. And, yes, calling it Rust to JavaScript is misleading at this stage. (In fact, I had written to Brian Anderson earlier, seeking advice on naming the language accepted by this tool's parser instead of calling it 'Rust to JavaScript' so as to avoid confusion.)
&gt; I just fixed some docs, no code... even _better_ than fixing code!
Please try to reduce a test case and file an issue.
&gt; The Rust programming language Wrong sub, man.
Turned out this issue was already known: https://github.com/mozilla/rust/issues/12041
Wouldn't it be worth to wait for the syntax to stabilize before attempting these?
[Issue 11178](https://github.com/mozilla/rust/issues/11178). As someone affected by the bug, I found it (both the failures, and the workarounds) absolutely hilarious. Something tells me I won't miss it, though.
I found the workarounds amusing, but was very disappointed by *not* being able to use arbitrary multi‐byte characters. As anyone who spends much time at all near text that I have written, I ♥ [`Compose + &lt; + 3`; whaddayaknow?] my Unicode characters.
It seems that the Fedora repo was last build over a month ago: http://copr-fe.cloud.fedoraproject.org/coprs/fabiand/rust-unofficial/builds/
What was the reception? (What was their background?)
A few physicists (in the world of numerical simulations, C++ and GPU programming etc.) and a software developer. Positive, we had an engaged discussion and Q&amp;A going throughout. They were somewhat disappointed when I mentioned that the one thing I'm not sure if Rust will ever be appropriate for is template metaprogramming / expression templates: because Rust's type system is primarily concerned with being a good type system, which is in tension with those other things (we're not going to have unrestricted template specialization like C++). I've been meaning to ask about this for quite a while: what *is* our story on that front? What's the Rustic alternative? (For a concrete example: to, say, [Eigen][1]?) Or am I simply mistaken - about us not gaining those kind of capabilities, and/or them being necessary? I know there's an intent to gain associated types at some point, but those aren't as powerful as what C++ has (no overlap, for instance). [1]: http://eigen.tuxfamily.org/index.php?title=Main_Page
&gt; "Then we're thinking why not go even further? Why not take unsafe C code, which we need for certain performance reasons, and just run that inside a sandboxed NaCl process and you get multiple layers of protection." Is this referring to an existing C library they're using, or do they actually have to write their own C because for $given_thing, Rust isn't fast enough (yet)? (If so, what's $given_thing?)
The performance reasons might be "we don't have thousands of man-hours to pour into micro-optimising a new library" (e.g. the spidermonkey JS engine) rather than something about Rust itself.
I've seen suggestions for coroutine-like objects that are effectively a task (i.e. isolated heaps, a boundary for unwinding/failure), but without spawning a new thread, i.e. it becomes a blocking function call that executes this pseudo-task on the current stack. Something like this is likely to be relatively easy to implement now, with unsafe code. (It's not clear if it's possible to expose a safe interface to it, though.)
Right, that would fall under "existing C library". :)
Variadic generics, in some form or other, will likely be added at some point. (An important word in that sentence was "ever". There are many things where the capabilities of *current* Rust don't match up to C++. There's far fewer where I don't see how *future* Rust could close the gap.)
Coroutines would be very neat for this. They might incur some cost if a stack needs to be set up but I guess that it can be pre-allocated. *Edit: missed the part about coroutines being stackless.*
I just think that generic and metraprogramming is important enough that a solid concept should be in 1.0. Python 2 vs Python3 and D2.0 vs D1.0 have shown that breaking backwards compatibility significantly hurts a language. P.S.: nice slides!
Ouch, sad :( Should try getting in touch with the maintainer.
What do you specifically mean by generic- and metaprogramming? Rust already has strong support for generics (parametric polymorphism), and this will only grow stronger in the future. This is a different thing from encoding entire syntax trees into types and (ab)using the type system to interpret them, which is what template metaprogramming is about. ...I see you edited the original comment: &gt; it should be way more powerful e.g. offer type constraints/type classes/concepts/concept maps... Rust has these. &gt; and play well with compile-time reflection. Could you elaborate? &gt; I just think that generic and metraprogramming is important enough that a solid concept should be in 1.0. Depending on what you mean, either: * It's already in there, or * No, it's not that important (not *everything* can be important enough to be in 1.0, if we ever want to release 1.0), what might be important is having a clear path to adding it in a backwards-compatible way in a later version.
C++ is alone with its weird generics-as-not-quite-macros. What need is not served by variadic (non-template) generics and macros?
You're looking for /r/playrust.
I have a few over here: https://github.com/brianseitel/rust-rosetta
Please don't bite my head off, but doesn't this protect against race conditions? I didn't see it specified explicitly in the document, but maybe I just missed it.
I only half know what I'm talking about here, but would this help enable STM? I think we could already implement STM, yeah?
Yes, I think the data parallelism section is implicitly "guaranteed data-race-free data parallelism". Although, it should be noted that it just guards against data races (like `i += 1` running non-atomically in multiple threads), not higher-level races like printing output out-of-order (which are impossible for the compiler to full guard against anyway). (And, sorry, we can't resist biting heads.)
True coroutines would be nice too, but, yeah, a way to execute a function in a new isolated context without creating a new task/stack would get us as close to C++ as is possible in safe Rust.
You probably know most of this, but I thought this might help other rustaceans understand a little more about what C++'s templates are, and how they relate to Rust's current parametric polymorphism and type classes. Bear in mind, I am still inexperienced myself, so I could have made some mistakes and omissions. I have a [more nicely formatted version on gist](https://gist.github.com/bjz/9220415). --- **C++'s Templates** C++'s templates could be seen as forming a duck typed, purely functional code generation program that is run at compile time. Types are not checked at the initial invocation stage, rather the template continues to expand until it is either successful, or runs into an operation that is not supported by that specific type – in that case the compiler spits out a 'stack trace' of the state of the template expansion. To see this in action, lets look at a very simple example: template &lt;typename T&gt; T fact(T n) { return n == T(0) ? T(1) : fact(n - T(1)) * n; } int main() { auto x = fact("hi"); } This gives us the error: Untitled 3.cpp:3:46: error: invalid operands to binary expression ('long' and 'const char *') return n == T(0) ? T(1) : fact(n - T(1)) * n; ~~~~~~~~~~~~~~ ^ ~ Untitled 3.cpp:7:14: note: in instantiation of function template specialization 'fact&lt;const char *&gt;' requested here auto x = fact("hi"); ^ 1 error generated. As you can see, the template has attempted to expand, and only errors once it is actually *inside* the templated function and can't find an appropriate operation for that type. This can be very confusing for a user of a library because the error messages expose implementation details. In template heavy code, the the error might only present itself very deep in the expansion, which causes C++'s famous mile-high error messages. The advantage of C++'s template system, like any other duck typed language, is that it is very expressive and flexible. A templated function can be written without any interface needed up front, and will work for any type that implements the required operations. Like any duck type language however, this inevitably pushes the specifications into the documentation, and when these specifications are ignored (or never read!) errors will most certainly result. This has caused the push for the so called 'Concepts' in a future version of the C++ standard. --- **Rust's 'generics'** Rust's parametric polymorphism and type classes (of which I will now refer to under the more colloquial term of 'generics') follows in the ML and Haskell tradition in that the type checking is like constraint program that is run at compile time. When an generic item (or also in Rust's case, region labels, like `'a`) is invoked, the specification of that type is immediately checked for consistency at the call site, otherwise the typechecking fails. Let's have a look at the previous factorial example in Rust: use std::num::{One, one, Zero, zero}; fn fact&lt;T: Eq + Zero + One + Mul&lt;T, T&gt; + Sub&lt;T, T&gt;&gt;(n: T) -&gt; T { if n == zero() { one() } else { fact(n - one()) * n } } fn main() { println!("{}", fact("hi")); } This gives us the error: Untitled 6.rs:8:20: 8:24 error: failed to find an implementation of trait std::num::Zero for &amp;'static str Untitled 6.rs:8 println!("{}", fact("hi")); ^~~~ note: in expansion of format_args! &lt;std macros&gt;:2:23: 2:77 note: expansion site &lt;std macros&gt;:1:1: 1:1 note: in expansion of println! Untitled 6.rs:8:5: 8:32 note: expansion site As you can see, the specification must be given up front, which means that any error is caught at the call site, as opposed to deep in a template expansion. Rust's generics are much more principled than templates, but they are dependent on types conforming to *specific* APIs. If a type does not implement the required interface, then it is impossible to use the associated functions, even if they may be perfectly valid. --- **Macros and syntax extensions are not a replacement for templates** Those who are more experienced at Rust might be wanting to call me out, crying, "what about macros and syntax extensions?". Indeed Rust's macros are powerful. They share many qualities with templates. But they certainly feel like second class citizens in the language: - They exist in a separate, global namespace. - Exporting macros feels like a hack. - Importing macros feels like a hack. - They also do not follow the same conventions as other language constructs – for example they cannot have no optional type parameter lists, and there is no way to invoke them like methods. This is certainly not an extensive exposition on how Rust's macros do not fill the same gap as templates, but it at least gives you a taste. --- **Compile time computation** C++'s templates also provide a powerful, if unwieldy form of compile time computation, that can allow for advanced static code generation that enables libraries like Eigen. Rust on the other hand provides no answer to compile time computation apart from syntax extensions, of which I have written about previously. --- **Conclusion** Rust's current generics are powerful, safe, and provide excellent errors at compile time. They will most likely serve it well heading into the 1.0 release cycle. However templates are still more flexible and expressive. Whether Rust would benefit from having a templated extension to the language in the future is up for debate (I am not even sure), but we should be up front about the both the positives and negatives when comparing Rust to C++. --- *Edited for clarity and removed some incorrect/non-essential things - see /u/glaebhoerl's comment*
Loved, I totally lost it on the first I saw - http://servomemes.tumblr.com/post/77840619499/lets-all-look-the-other-way-and-push-the-retry 
Hi! You're welcome to include them in [this repo](https://github.com/Hoverbear/rust-rosetta/) if you're feeling like it!
The article says: &gt; This change is not motivated by soundness, as I believe the current rules are sound. But actually, shouldn't this move be motivated by soundness? Reading from a non-atomic type while it is being written could easily lead to undefined/catastrophic behavior.
As of now, the time is 7:12 PM PST, so it won't be up for another 48 minutes :)
ah right, saw the stream kinda come on and got excited. thank you
One way to implement pointers would be representing every value as an object. E.g. let mut x = 3; let mut p = &amp;mut x; *p = 6 let mut y = 30; p = &amp;mut y; *p = x; let pp = &amp;mut p; **p = 10; Would be translated into var x = { val: 3 }; var p = { val: x } p.val.val = 5; var y = { val: 30 } p.val = y; p.val.val = x.val; var pp = { val: p }; pp.val.val.val = 10; This will probably come at a huge speed cost.
Trait objects have very simplified lifetime model: they have to be fully owned or at least alive throughout the program (i.e. `&amp;'static T`). In this code, `Single&lt;'a&gt;` contains a reference which should always be alive in order to create a trait object out of `Single&lt;'a&gt;`, therefore `'a` has to be `'static` as well. Clearly it is not desirable; in fact, the bigger problem is that the program overly generalizes for `Access` interface which does not fit well with Rust. I'd store the current state directly into `Single` and others in order to avoid lifetime problems. I have seen many similar questions in IRC, but my general recommendation is to avoid making a struct with references if it is going to be allocated in the heap. It simply does not work, and even while it might work with smart pointers, such struct would complicate other parts (as many safety features in Rust are built around the concept of lifetimes and smart pointers actively disable them). Edit: Oops, I think I failed to address the first error message. See the reply for details.
It makes sense to me to think of a borrowed mutable pointer as a temporarily owned pointer that returns ownership to the original when running out of scope. As I understand it this will not change the semantics, only make it impossible to write confusing code, such as: let mut x = 10; { let y = &amp;mut x; *y = x + 1; } Trading confusing code with better concurrency sounds like a good deal!
I am fully aware this code is definitely not in harmony with rusts safety system. However, when looking at "Tweening" libraries from other languages I recognized that most of them used heavy "magic", in Java it was reflection, in C++ raw pointers (not so much magic). The whole point of a tweening system is that's its very easy to plug into your game/app. You don't want to build your whole code around those Tween objects, which is why I allow access via Cells and &amp;mut T. So, what I'm trying to do is to modify the users (programmers) values "from the background", in order to minimize the changes to the users code. Nonetheless it should still avoid memory corruption/leaks/dangling pointers. If I have a &amp;'a Cell or a &amp;'a mut, why can't I return ~Single which does live at least as long as these?
Most of this looks right to me, thanks! &gt; Rust's parametric polymorphism is much more principled than templates, but it is very much dependent on types conforming to specific APIs. If a type does not implement the required type classes, then it is impossible to use certain functions, even if they may be perfectly valid. Of course rustaceans know this, but `impl`s allow adapting any type to any trait, so this is not that big of an issue. It mainly just requires you to state your assumptions up-front. &gt; Rust on the other hand provides no answer to compile time computation. This could be remedied to some extent in the future via dependent types, but these are very hard to retrofit to a language that has not been designed for it. Dependent types are something different entirely. They allow (much) stronger theorems and proofs to be expressed in the type system, but that's a different use case. &gt; Interestingly, there is an extension to GHC called Template Haskell. This is irritatingly confusingly named. It's essentially GHC's equivalent of our macro system, including procedural macros, not an analogue of C++ templates. &gt; but they still definitely feel separate to the core language when used at the invocation site as opposed to being part of the language as a whole Ditto Template Haskell. :)
Ok, I removed the template Haskell bit, and the part about dependent types. &gt; Of course rustaceans know this, but `impl`s allow adapting any type to any trait, so this is not that big of an issue. It mainly just requires you to state your assumptions up-front. The issue there is our coherence rules. If you have a type from one crate that doesn't `impl` the trait from another crate, there is no way to use that type with that other library – the compiler will complain about you `impl`ing an external trait on an external type. This harms the composibility of libraries. But I don't know how much of an issue that is. It is also probably an issue for templated libs in C++, it's just that it is less obvious.
&gt; brson: bors is COMPLETELY overloaded right now. We have 44 things in the queue. We're in the process where we start to have to roll multiple pull requests into one. Anyone want to work on adding an optimism flag to bors? I wrote some form of spec of what I reckon is needed: https://github.com/graydon/bors/issues/23 (first nutted out a few weeks back at https://botbot.me/mozilla/rust-internals/msg/10373869/). (bors' code is at &lt;https://github.com/graydon/bors&gt;.)
&gt; Why on earth is everyone talking about sorting only requiring partial orders? Sorting requires a total order! How can you sort incomparable elements? In practice, sorting an array of floats in practically every programming language I'm aware of uses the CPU float comparison instructions, which return false for NaN &lt; NaN, NaN == NaN, and NaN &gt; NaN. I'm not saying that's how it should be, I'm saying that's how it is. We have no other choice, given that we need fast sorting of floats. I know it's weird and messed up—blame IEEE 754. :(
Yeah, the idiomatic solution is to make a newtype wrapper of the type and implement the trait for that. I agree that this is annoying though. C++ doesn't have this problem, C++ has other problems. As in many other cases, Rust is making a tradeoff of reduced expressiveness in exchange for stronger invariants (here coherence). There's no free lunch, but I think this is a very worthwhile tradeoff. C++ suffers from a dearth of invariants.
In that case, why not just make that the default total order for f32 and f64?
Oops, at the first glance, I thought you are trying a trait object which lifetime cannot be statically verified, especially since the `Tween` trait is not bounded by lifetimes. But now I realized that the problem was not the trait object coercion; it was the possibility of arbitrary `T`. So the solution in this case would be: fn from_to&lt;'a, T: Tweenable + ToStr + 'static&gt;(val: &amp;'a Accessible&lt;T&gt;, start: T, end: T, ease: fn(f64) -&gt; f64, duration: f64) -&gt; ~Tween: { ~Single::new(val.create_access(), start, end, ease, duration) as ~Tween: } ...and similar. (Note `'static` in the *function bounds*, as indicated by the first error message.) It turns out that the compiler can reason about the unbounded trait object which nevertheless has a lifetime (it is really subtle, as [the comment](https://github.com/mozilla/rust/blob/06e1281198da31219b89a7cdb32f3c05b76afc07/src/librustc/middle/kind.rs#L496) says), but `T` can contain references (it currently does not, but `Tweenable` does not inherently prohibit that) so the compiler demands that `T` should not contain references, and in the other words, should be of the `'static` kind. While the problem was solvable in this time, my recommendation does not change: it is hard to reason about the complicated interaction between lifetimes and trait objects both for the user and for the compiler.
Bors needs an upgrade.
&gt; (bors' code is at https://github.com/graydon/bors.) That's a 404 error :( Any more recent repo? 
(Hmm, didn't D copy them?)
Well, pcwalton's initial proposal is to have two kinds of methods in the single `Ord` trait: 1. Totally ordered `cmp` method; and 2. Partially ordered `lt`, `le`, `gt`, `ge` methods which are implemented in terms of `cmp` by default but overridable. So the implementors of `Ord` will decide the relevant total ordering via `cmp`. Technically speaking `f32` and `f64` may implement `cmp` to return the random ordering via the thread-local RNG (the similar logic actually [exists in the golang runtime](http://golang.org/src/pkg/runtime/alg.c#L226)), but the sanest way is to implement it as a simple bitwise operation (transmute to `i32`/`i64`, take a sign bit, XOR every bit sans the sign bit with it).
Remove the trailing dot. (Blame autolinking!)
Does this differ much from traits-inheriting-from-structs other than the "optional" bit in "optionally fixed"?
Single inheritance has a very simple low level representation (i.e. common fields just sharing the same offsets within a datastructure... its easy enough to do it in ASM), and it has uses - I would definitely like to see this feature. I very commonly find myself having to add extra access layers places where it feels clunky to do so. You have an additional name to create. Anything that reduces the amount of naming needed is good IMO. "Inheritance" has negative connotations for people skeptical about OOP, but this is just simple structure element naming optimization. Its not to do with interfaces or anything, its not a philosophy intended to be applied across your entire source base.. 
i started this intending to work toward IDE/code search tools for rust, but ended up leaving it as a tool for generating a browsable HTML view (see the example) http://dobkeratops.github.io/rftest/librustc/rustc.rs.html#176 https://github.com/dobkeratops/rustfind However I haven't updated it since rust 0.8 ... I needed to practically replicate the Rust AST to do this (getting from a code location back to nodes) - and I've read the internal compiler representation of the AST is going to change a LOT. (for a start it was all @ based when I was doing this) I wonder if they need a seperate "tooling" AST and "internal compiler" AST. As I understand you can't partially compile at the minute, which would be too slow for completion? Have any of those issues changed since I looked into it 
It only restricts you to single-inheritance-like constructs for fields you "pin down". Even then, you could have a pyramidal inheritance scheme and share fields from the root through a trait while hiding everything else or allowing only virtual access.
I think it has the same "fixed layout" benefits without interfering with eventual fields-in-traits. +1
Hm, how does this interact with trait inheritance? i.e. it would require single inheritance of traits too (or, at least, single inheritance of traits with fields).
I need to learn how to write shorter RFCs while still covering the important information. If that's possible at all. Halp? Also in case anyone else had trouble with this: [12:15:16] &lt;Yurume&gt; I actually don't understand why HasPrefix and Coercible has to be distinct [12:16:36] &lt;glaebhoerl&gt; Yurume: struct XY { x: int, y: int }; struct XYZ { xy: XY, z: int } [12:16:57] &lt;glaebhoerl&gt; Yurume: now you can convert &amp;XYZ to &amp;XY [12:17:09] &lt;glaebhoerl&gt; and you can convert &amp;[&amp;XYZ] to &amp;[&amp;XY] [12:17:17] &lt;glaebhoerl&gt; but you can't convert &amp;[XYZ] to &amp;[XY] addendum: you also can't convert `XYZ` to `XY` (so `XYZ: HasPrefix&lt;XY&gt;` and `&amp;XYZ: Coercible&lt;&amp;XY&gt;`)
Sorry for that. :S In my opinion, `HasPrefix` is an implementation detail which is not important to the users of `Coercible`. (In fact, if I understand it correctly, `HasPrefix` is *not* a real trait, right?) Some examples, as you've just pasted, may also help understanding the inner working of `Coercible`.
&gt; Sorry for that. :S Thanks for asking! I have no idea what needs clarification if people don't ask. :) &gt; In my opinion, HasPrefix is an implementation detail which is not important to the users of Coercible. It's important, because you sometimes want to have it as a bound. In fact, you want it in those cases where under the single inheritance proposal, you would have a superstruct bound. If you have: struct Node { ... } trait INode: HasPrefix&lt;Node&gt; { ... } due to the make-believe wired-in impls, for any `T: HasPrefix&lt;Node&gt;` you have `&amp;T: Coercible&lt;&amp;Node&gt;`, so you can instantiate `coerce()` with the types `&amp;T` -&gt; `&amp;Node`, and because `&amp;INode` points to some unknown `T: HasPrefix&lt;Node&gt;`, you can coerce `&amp;INode` to `&amp;Node` and access the fields of `Node`. (Without having to go through virtual calls in the trait or anything, which was the primary motivation for the single inheritance proposal.) &gt; In fact, if I understand it correctly, HasPrefix is not a real trait, right? It's exposed to the user, but as with Coercible it's wired-in to the compiler and doesn't allow manual impls. (again similarly to e.g. `Freeze`)
(Why are you apologising for asking a sensible question? ;) I believe /u/glaebhoerl just thought it was a question that others may be wondering about it.)
The `min`, `max` and `clamp` functions also require special versions to deal with floating point.
&gt; But actually, shouldn't this move be motivated by soundness? Reading from a non-atomic type while it is being written could easily lead to undefined/catastrophic behavior. It's not possible to do that in Rust with the current rules. The change is motivated by the ability to allow data parallelism with mutable references, and the same guarantees are helpful for alias analysis.
There's [#7643](https://github.com/mozilla/rust/issues/7643) about searching for and suggesting traits with similar/the same method names to import if a method look-up fails.
No. Niko Matsakis' [proposal on associated items](http://smallcultfollowing.com/babysteps/blog/2013/04/02/associated-items/) partially addresses that (e.g. `fn dot&lt;V:Vec3Like&gt;(a: &amp;V, b: &amp;V) -&gt; V::dot_type`), but in general C++ template are prone to the compile error and do not fit well in the Rust's type system. In the programming language theory, C++ template is classified as [*ad hoc* polymorphism](https://en.wikipedia.org/wiki/Ad_hoc_polymorphism) in order to emphasize the fact that template expansion is not connected to the type system; in contrast, Rust generics is strongly connected to the type system.
Thank you so much for this answer! I absolutely misunderstood where I had to put the static bound. I thought it was on Single, not on the types Single contains...
So do I, hence the first answer. The first error message is technically correct but elusive about where to put the `'static` bound :S
About relative paths, I quite like Python's `import .foo` for relative and 'import foo' being absolute. About channel names, how about In and Out? Is that not descriptive enough?
I guess this isn't mutually exclusive with struct inheritance, it "just" makes struct inheritance unnecessary from the perspective of the primary motivation for it, which was performance. But you could also conceivably add inheritance *alongside* this proposal, with the effect that `struct B: A { ... }` makes `B` inherit the fields of `A`, and implies `B: HasPrefix&lt;A&gt;`, but this would only be a *syntactic* convenience over `struct B { a: A, ... }` (which also implies `B: HasPrefix&lt;A&gt;`), and wouldn't add anything in terms of expressiveness.
It would require the fields you "pin down" to be at the same offset in all the supertraits, instead of restricting you to single inheritance.
&gt; is there any general plan of ever bringing them into the language? Yes, but that's about all I know. :)
I think as long as you state the Rust version it doesn't really matter. I've encountered out of date samples on coderosetta. Figuring out how to update them gives me a chance to learn something and a clue as to where to start looking.
Doesn't that just depend on whether the chosen sort is stable?
Looks like I digressed from the interesting part (implementation of pointers) and focused on defending the *broken* converter. But you brought the conversation back on track! Actually, I saw your comment earlier but set out to create a tiny uglier [version](http://bilalhusain.com/rust-lexer/memory_lab.html) for playing with this particular example. To be frank, pointers are tricky and I am not very clear about the internals of different type of pointers, borrowing, mutability, even about `x = y` and `x = &amp;&amp;y` sort of stuff in Rust. 
Not quite. Stable sorts just preserve the relative order of equal elements. If the constructed total order considers all incomparable elements equal, then their relative order will be preserved by a stable sort. The relative order may not be preserved by an unstable sort, but there's no guarantee that identical incomparable elements will be adjacent. If the constructed total order doesn't consider all incomparable elements equal, then all identical elements will be adjacent after any sorting algorithm. Say we have incomparable elements A and B and we're sorting a list [A, B, A]. If we choose an ordering where A &lt; B and B &lt; A this list is already sorted. If we run it through a stable sort, then the order will be preserved. If we run it through an unstable sort, then the order may be permuted. If we chose an ordering where just A &lt; B, then any sorting algorithm will return [A, A, B].
I'm likely not qualified to spot any drawbacks in this proposal, but the upsides are numerous and appealing! I love the increased flexibility that this manages to bring without a runtime performance cost. Very cool.
I'm wondering - are you still doing anything with rustfind? I've forked it and got it compiling with rust-master again, and am keeping it up to date by building it on travis-ci with rust-ci. However, I didn't send you a pull request because I wasn't sure what your intentions were. I've also started cleaning up some code formatting and removing some unsafe code which seemed unnecessary, so the code may not be they way you like it anymore (sorry, it's easier for me to play with), which is a big part of why I didn't send the PR. Currently I'm trying to see if I can speed it up, which is looking kind of tough, but I'm still playing with it when I get the chance. Please let me know if you're okay with me doing this. My fork is at http://github.com/am0d/rust-find/.
I wrote [a thing](https://gist.github.com/bjz/9220415) yesterday comparing Rust's generics to C++ templates. It might make some things more clear.
For the channel bikeshed and the naming of it, I just want to say that the (source, sink) names make no sense in my head, probably because english is not my main language and those names are really weird for me. For the ( port, chan ) the first time I saw that I was also like "wtf dafuq does those mean?" so it took me a while to even get what was going on. Anything with drain is also completly weird. (source, destiny) and ( sender, receiver ) are clear names that everyone has seen somewhere so they map ok in my head. They are probably verbose and the stuff about sender.send and receiver.recv is weird, but meh, better the current maybe. I saw some people proposing something like TxPort or Transmitter and receiver. Those are clear at least. I just don't know, there's so many options here... 
Just had a go at the Gray Code exercise (http://rosettacode.org/wiki/Gray_code). I'm still learning so this might not be very Rust-ish (Rustey? Rusty?). http://pastebin.com/yV6tQnYB If you want it for inclusion in a repo, I can look into getting git working tomorrow.
Ah thanks. I left my editor in C style.
I make friends by posting to the right subreddit.
Almost there!
Maybe Rust's `try!` macro could be extended in this way. Currently `try!` returns.
Very nice. Maybe this could be preserved at https://github.com/mozilla/rust/wiki/Rust-for-CXX-programmers .
Some syntactic sugar for the Option.and_then function? parent?.child becomes parent.and_then( |x| -&gt; { Some(x.child) } )
(You appear to have misformatted your comment.)
That's pretty cool. (Although I imagine it's even slower than my object idea, but it's more obvious how it works, given everything has a place in that `memory` object.)
Reminds me of the common Ruby idiom, `try`. someobj.try(:map, &amp;:to_i).try(:flatten).try(:join, ', ').try(:strip)
What about `try_get!(parent, child, child, child)`?
It's basically an operator implementing a maybe monad.
Maybe it is just me, but I would far prefer monadic-do (a la haskell), or scala's for-comprehensions to a special operator. I like that fact that is is clear that you are dealing with optional values, but without having a bunch of explicit checks.
But the operator is only really useful when navigating through DOM-like structures. Thus they implemented an operator for a single use-case. That smells (or am I missing something).
Fixed, thanks.
...or *any* tree-like structures with Nulls as possible leafs. Trees are pretty common throughout programming.
It's when it's combined with non nullable references that makes it shine. (This was mentioned at the end of the article.) It means using "." On a nullable reference can be made a compile error. Kotlin is an interesting language that uses this same syntax on the JVM. Edit: clarification
Since I asked this I discovered Rust now has default typeparameters - that's helped alot, in that many of these cases I can just default to 'f32' or whatever.. great to see the language advancing. They help streamline more of my cases than this would have. The next thing I'm slightly missing is ints in the typesystem , eg for creating tiled arrays tweaking the size, or fixed-point types passing a shift value. It doesn't block me from acheiving anything, just means more cut/paste or macros
I'm new to rust, but if it has a function composition operator and a way of making x.child into a function child(x) then you can do the slightly cleaner: parent.and_then(Some&lt;compose&gt;child) For those familiar with haskell, and_then is essentially bind for Option/Maybe. It'd also make sense to have a liftM equivalent which is basically liftM(f) = Some &lt;compose&gt; f for this type (excuse my half-rust-half-haskell pseudocode).
Only [4640 places to go](http://redditmetrics.com/r/rust) before we're the most popular subreddit!
I don't think this is a soundness issue (not that C++ isn't one big soundness issue...), it's just surprising behavior. As /u/pnKYe4IIA also notes, if you have `struct B: A`, with `B` overriding some virtual methods of `A`, and you have a function `void foo(A*)` and you give it a `B*`, it'll be polymorphic: `B`'s version of the virtual functions will be used. OTOH, if you have `void bar(A)` and give it a `B`, it'll copy out the `A` parts of `B` and discard the rest, which is probably not what you wanted. And yes, this is part of why we need separate HasPrefix and Coercible. If `B: HasPrefix&lt;A&gt;`, we allow you to `coerce()` from `&amp;B` to `&amp;A`, but *not* from `B` to `A`.
Not quite: [see here][1]. This would work: let mut my_a: &amp;A = coerce( &amp;my_b ); (Also fwiw, the `mut` modifiers aren't necessary here, not sure why you had them.) [1]: http://www.reddit.com/r/rust/comments/1yz7oi/a_simpler_and_more_flexible_alternative_to_single/cfpmt64
Something like? var g1 = parent?.child?.child?.child; let g1: Option&amp;amp;lt;Foo&amp;amp;gt; = do!( Some(a) &amp;amp;lt;- parent; Some(b) &amp;amp;lt;- a.child; Some(c) &amp;amp;lt;- b.child; c.child ); Which expands to something like let g1: Option&amp;amp;lt;Foo&amp;amp;gt; = match parent { Some(a) =&amp;amp;gt; match a.child { Some(b) =&amp;amp;gt; match b.child { Some(c) =&amp;amp;gt; Some(c.child), _ =&amp;amp;gt; None } _ =&amp;amp;gt; None } _ =&amp;amp;gt; None };
Assuming a linear growth, that'll be in 2016.
At this rate we'll be getting 1000 a day by the end of June.
The reason we do this is because str is a Unicode string, and the fact that the underlying storage is an implementation detail. There are many ways at iterating over the things in a string. First , you could go over the bytes, which is what you would get with ImmutableVector. However those bytes don't correspond to characters, since strs are UTF8, multiple bytes may make up one character. But then there are even more choices. Some languages can perceive two characters being combined into one, and so on. Iternationalization is complicated. I would suggest checking out this [link](http://www.utf8everywhere.org/) that goes into way more detail about this topic. 
(All references already are nullable in .NET)
I would like to have associated constants, so that you can write `T::SOME_CONSTANT`. Then we could perhaps make type-level numeric literals that just expand into an anonymous type with an associated constant.
Linear growth? Talk about setting your sights low. To be the biggest sub, every subscriber just needs to find another two new subscribers to learn Rust, subscribe, and recurse. And we can do it safely, and concurrently.
I think you're right. You can't have the type of the l-value be anything other than compatible with all the subtypes in the chain of "?." expressions, in order for this to work. So it's *only* useful for graphs of homogeneous objects, or graphs of heterogeneous objects with a common base. Or as you put it, a DOM. That makes this a killer feature for duck-type systems (Python, Javascript, etc.), but a poor fit for static-type systems (C++, C#, Rust, D, etc). What I really don't like about this is that if you're almost certainly using a DOM structure, you're better off with some kind of one-shot path navigation expression method instead; like XPath or CSS selectors. Not only are those more flexible, but they give you an opportunity to communicate an error condition for how and why the expression failed to match the tree.
Yeh, I was talking about the feature in comparison to something like haskell or rust
Having this more general than ints would be nice also. I recently got frustrated by this restriction in C++.
Sounds like one big hack (the literals), but it would be better than nothing.