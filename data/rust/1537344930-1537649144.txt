For whoever want to change the color theme, the theme page is here, https://github.com/jwilm/alacritty/wiki/Color-schemes
I'm probably missing something, but what is the harm in adding the desired impls after the fact in a later version of Rust?
Is this a cheating quine? $ ./quine ./quine: line 1: ./quine:: No such file or directory $ cat quine ./quine: line 1: ./quine:: No such file or directory $ 
&gt; a maximized window on a 4k monitor And with scaling that Wayland compositors do — e.g. for 1.5x, render at 2x and downscale — I think macOS does the same. That's rendering at 7680x4320 :D Alacritty is way faster for me than libvte (gnome-terminal). But interestingly, other software-rendered things like [nvim-gtk](https://github.com/daa84/neovim-gtk) are pretty fast too.
I'd describe 2.5 years as "relatively old" :D FreeBSD also had it packaged for over a year.
Does anyone remember/figure out what project it was Graydon was working on that copied a project Bryan worked on? Kind of curious, but quick searching doesn't reveal anything so far...
Tap I'm doing this too. It's really easy to copy the small TryFrom trait from nightly into a project.
It's covered in the post. It would break people's code if they had implemented From and TryFrom.
That's interesting, but I must have missed the story. Do you mind linking to a summary somewhere?
I hope so because I just bought 5 of them last week !
In general, battery life and performance go hand in hand. The more optimized your software is for performance, the less CPU time it uses and the more time the CPU spends sleeping in its powersave states. The time spent in low-power sleep states is the single biggest factor in the power usage of modern CPUs. So my blind guess would be that alacritty should be great for battery life!
Give `cargo run` a shot.
What is preventing your future from being Send? You might want to explicitly return `Box&lt;Future&lt;Item=MyString, Error=()&gt; + Send&gt;` and see if that'll work.
 That's a good habit! "Sandboxing" helps with learning and recall. My python directory of examples is massive and my rust directory is growing quickly. Playground is useful for single file examples that use a subset of crates, but anything written there ought to be saved locally for future use. 
Dumb question, I want to try this out on debian but I don't see any instructions for: 1. Updates 2. Uninstallation Can someone please share how to achieve this on debian? Thanks!
Thanks mate
Sandboxes, playgrounds... Do you see the pattern?
People learn differently. There isn't one best way for all to learn. I couldn't sit and digest chapters of a programming book, in sequential order, without losing control of my attention. A programming book isn't a goal, for me. It's a resource I can reference as I learn concepts.
SystemTap, a DTrace competitor
The DAO and Parity multisig hack are two examples that come to mind. Although I'm not sure they were caused by exceptions.
It might also be more cache-efficient for certain access patterns.
If it's any consolation, years ago, Rust was quite a different beast. The 1.0 stabilization was only back in May of 2015. (OK, I guess that's technically "years ago" too. Time flies!)
It is also included in my [crates list](https://users.rust-lang.org/t/list-of-crates-that-improves-or-experiments-with-rust-but-may-be-hard-to-find/17806).
Nix is a package manager, Nixpkgs is a package collection for it (the most popular one, that is), NixOS is a Linux distro using nixpkgs. We probably both thinking of nixpkgs.
&lt;3 &lt;3 &lt;3
It used to be there =)
I think this might depend on the specific use case. By boxing the enum itself like you do in BinaryExpression you can avoid a heap allocation for Expression types that don't have a subexpression (e.g. a `ConstantExpression` or `VariableExpression`?). Not having to chase pointers for types like that may be faster, if they are common. On the other hand, because the size of an enum is the size of its largest variant (plus the variant tag), if you `Box` every enum variant you can save some space, especially if you have one rare Expression struct that is much larger than the rest. Memory tends to be cheap, so I think I would prefer the strategy you chose for `BinaryExpression` in this case. But I don't think there's a best practice that works in all cases.
Thanks very much! I'll try this later.
This is the first time I've written a long-form post. If you find any errors or have editorial notes, please don't hesitate to message me and I'll update the post. :) /u/kyrenn: I wasn't sure which salutation you prefer, or if you prefer to be known by your handle. If you don't like "Ms. West", I'll be happy to update it.
Anyone have experience with using `build.rs` for compile time feature detection? &amp;#x200B; Trying to use features, and default features for every platform. I setup my features and they work by calling it on cargo: `cargo build --features "backend-dx12 logging"` I have different features for different platforms (using `gfx-hal` and there are different desired backends for different platforms) but I can't get a different default feature set for each target. Trying to use `println!("cargo:rustc-cfg=backend-dx12");` in the `build.rs` gives me the following error `error: invalid --cfg argument: backend-dx12` It seems something isn't right in the docs? The [Build Scripts Book entry](https://doc.rust-lang.org/cargo/reference/build-scripts.html#outputs-of-the-build-script) mentions you can use `cargo:rustc-cfg=FEATURE` to pass the feature to `rustc` using `--cfg` and the build error implies its being passed as `--cfg backend-dx12` where as [the Manifest Format entry](https://doc.rust-lang.org/cargo/reference/manifest.html#the-features-section) says that using `--features backend-dx12` will pass `--cfg feature="backend-dx12"` to `rustc`
My natural assumption is that if the compiler can automatically assume now that it is a templated function call then it doesn't need to consider the possibility that it is operator chaining [per the RFC](https://github.com/varkor/rfcs/blob/undisambiguated_generics/text/0000-undisambiguated-generics.md#syntax-ambiguity), and I would have assumed that makes it deterministic again/not requiring backtracing.
&gt; he didn't say "the serde author". I'd still interpret saying one's "author of" as "the author of" or "the main author of", unless it's specifically qualified like "an author of".
This is _extremely_ helpful, thank you!
I'm not sure how I missed that section of the book, seems to be close to what I'm after. Thank you!
There’s also a crate.
Haha, learning as I go is pretty much the plan! I'd like to imagine I figure out a cool new pattern, but it might have to stay imagination for now...
This is not my book, but I’m only aware of one edition. I think the older one you see was the original intended ship date.
I believe that Rust has a huge potential in robotics area, but the biggest obstacle is the ecosystem age, which is quite young. A lot of existing work is heavily geared toward Python/C++ and it will be very hard to use it from Rust. It's possible to implement low-level bits here and there (e.g. data acquisition from sensors, basic processing, etc.), but for higher-level work you'll have to use Python/C++. So it will depend on what exactly you want to accomplish, generally I think C++ will be a safer bet. But if you like re-implementing stuff from grounds-up, to understand how stack works and to work in (arguably) a much better language, then Rust can be a golden opportunity! Plus as was mentioned some companies already use Rust in their products, so having Rust (in addition to C++) in your CV will be certainly a nice plus.
how many people coming from say ml ? lisp ? haskell ? cpp ?
How many people coming to Rust from those languages? It's hard to say; we have this year's survey data coming out sometime soonish. I'd look to that...
Cool, that would be lovely.
I have updated my blog post to acknowledge that you can do this. Thanks! Niko Matsakis pointed out that there is even another way to write this program, by using the `by_ref` function. fn main() { let mut squares = (0..10).map(|x| x * x); println!("{:?}", squares.by_ref().min()); println!("{:?}", squares.max()); }
now I want Gary Bernhardt blog article on rust
No, this is awesome! Knowing someone besides me is actually using this is really great :) Feel free to reach out if you have any questions or run into any problems. Also I'd love to know what you're going to use Varisat for. (Twitter @jix\_ or Discord jix#2651 are good ways to reach me.)
[removed]
I'd normally agree with you. However, the problem of OP is happening just because he's mixing the two concepts 
You'd have to do that manually, It's probably going to be a while until an official Debian package shows up. Alacritty just started tagging releases which is essential for archlinux in almost every case. Our tooling in Debian operates on data on crates.io, so alacritty needs to be uploaded there. Right now there's only a 0.0.0 placeholder.
The DAO hack was (arguably) caused by a programming model that gives too much control to untrusted callees (as opposed to, say, an asynchronous model that does not have this problem). The multisig hacks (there were two) were two different problems. The first was caused by Solidity functions being public by default and so a function that needed to be private was marked public. The second was caused by an extremely filthy workaround that was essentially an implementation of dynamic linking for Ethereum (in order to reduce deployment cost). The problem is that because Ethereum doesn't have dynamic linking natively, this is extremely hacky error-prone and so the "library" also acted like an uninitialised version of the contract. Someone initialised it and then destroyed it, meaning that all the contracts that linked to it were locked forever. The DAO contract was audited but they did not find that issue. No-one can say for sure but IMO it's probable that an audit would have found the bugs in the Parity wallet, it was an experimental piece of technology that wasn't treated as such. Disclaimer: I work for Parity Technologies.
&gt; Supporting executable Rust scripts via UNIX hashbangs and Windows file associations. So cool!
No worries! At this point I consider /u/dtolnay a co-author or the project! He’s done a great job stewarding the project. 
Thanks, I must've misread that.
He tweets about it sometimes. He hasn’t had the same head over heels reaction. He and I go way back, incidentally.
oh yeah he was into ruby quite a lot :)
use the quotes? println!(r#"cargo:rustc-cfg="backend-dx12""#); Not sure if it'll work but the manifest format entry you are quoting has an extra set of quotes around the cfg value
This doesn't prevent the Rust community to attempt consensus on much more controversial topics, like code formatting RFCs.
This is an awesome resource! Thanks for pointing it out!
Minor note: Serde is even awesomer, because instead of doing `#[allow(non_snake_case)]` on your struct, and then having a camelCase attribute polluting your rust code, you can instead do: ```rust #[derive(Deserialize, Debug)] #[serde(rewrite_all="camelCase")] struct StatemapInputMetadata { start: Vec&lt;u64&gt;, title: String, host: Option&lt;String&gt;, entity_kind: Option&lt;String&gt;, states: HashMap&lt;String, StatemapInputState&gt;, } ``` or ```rust #[derive(Deserialize, Debug)] struct StatemapInputMetadata { start: Vec&lt;u64&gt;, title: String, host: Option&lt;String&gt;, entity_kind: Option&lt;String&gt;, states: HashMap&lt;String, StatemapInputState&gt;, } ```
From the discussions in [the tracking issue](https://github.com/rust-lang/rust/issues/53668) I got the impression that there was a decision made somewhere to apply the change to all editions.
Just started learning Rust, and of course like everyone else I am struggling to get along with the borrow checker and other semantics. Anyway, for my first program (this is right after I started reading about structs), I tried to create a singly-linked list: [https://play.rust-lang.org/?gist=798b9f0d4f253f351dd6a81a59c71d94&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=798b9f0d4f253f351dd6a81a59c71d94&amp;version=stable&amp;mode=debug&amp;edition=2015) Now this doesn't compile, because (if I understand this correctly) I am trying to have two mutable references to the same variable. My question is: what's the idiomatic way to do something like this? I haven't gotten to reading about iterators yet so I would appreciate a solution that doesn't implement those traits. Thanks Rustaceans!
Pointers are pretty much 100% necessary at some level.
Wow, that seems strikingly irresponsible, to agree to an edition change through the RFC process and then bait-and-switch it to a breaking change later.
It's a really common beginner question -- you learn the generic syntax, but then it doesn't work in seemingly random places (*actually, in expressions*), and you learn to add this weird extra `::` that's only there to make parsing easier. If there's a way to remove it, that's great... but since it changes the meaning of code it should only go into Rust 2018 if anything.
yup https://crates.io/crates/try_from/reverse_dependencies
I "came from" C++. But, to be fair, I'm more of a dual citizenship case now than an all out immigrant. I really prefer Rust in concept, but in practice, I'm just so much faster in C++...
Yes, I know. ;) I seriously considered putting a footnote on this linking to [my rationale for this being camel cased](https://github.com/joyent/statemap/pull/28#issuecomment-417711020) \-- in hindsight, that probably wouldn't have been overkill after all. And agreed that this capacity of Serde is terrifically useful! (Just not for me in this instance.)
can you elaborate?
&gt; The line `foo[3] = None;` is cleary similar to assigning null. If Rust were garbage collected, this would “free” memory. In fact this _will_ free memory if the array is of `Option&lt;String&gt;` (or anything else that owns memory). Garbage collection doesn't enter into it, except that you can consider `Drop` to be a form of garbage collection.
Thanks for the post. I think this is a good conversation to have. A lot of people were very defensive about Blow's video because he doesn't use or like Rust (he wouldn't be creating his own language otherwise), but I think it's a good reminder that writing "safe" code goes beyond just doing what the borrow checker tells you. Look forward to the next one.
Taking a little break from working on my toy [image library](https://github.com/Robzz/ndimage), so I rebooted an old library library of mine that interacts with cryptocurrency exchange APIs, in order to make requests asynchronous and add WebSocket capabilities, and generally rewrite the thing better, I've improved quite a bit with Rust since I started learning it, pre 1.0, with this very project actually. I haven't done much async even in other languages, so learning how to use futures and tokio has been very painful (at times, it felt like being new to rust again!) but I think it'll be worth it in the end. I still struggle to get some things working, but it's starting to come together nicely. I'll probably open source the thing at some point. And I'll just take a second to mention that [serde](https://serde.rs/) is quite literally the best thing to happen to the world since [tartiflette](https://en.wikipedia.org/wiki/Tartiflette), which is a rather high bar to clear.
Turbofish is not that bad, really, and people quickly get used to it, especially if they're coming from C++. The question is: let's suppose C++ didn't have the &lt;&gt; template stuff, nobody knew there was a language that generics can be called without a `::&lt;&gt;` syntax and we came at this with a completely blank mind. Would people still advocate for removing turbofish? Or do they just want to remove it because C++ doesn't have it? Is just that I don't see any practical advantages at all. Turbofish kinda sucks, yeah, but it would suck even more if we adopted the C++ syntax, because that comes with a whole lot of other problems too - not necessarily now, but possibly in the future. 
I clicked on this thinking it was /r/ProgrammerHumor/
As far as a computer is concerned? Only what you do with it.
LOL what? A pointer is just a memory address. Your computer wouldn't work at all without them.
An integer is a number that is not a fraction. On 64 bit cpus, you can have 64 bit integers. On 32 bit cpus, you can have 32 bit integers. Both integers and pointers require 32 or 64 bits of space to hold data. Some languages like Python abstract the data size out and can use a big number library by default. The real difference between an integer and a pointer is how you use it. With an integer, you are assuming you are counting. With a pointer, you are assuming lookup of an address space. By casting an integer can be used as a pointer and vice versa. 
And if Rust was garbage collected, assigning `None` to a value would not free anything.
Trying and failing to think of a punch line for this. How about: "What's the difference between an integer and a pointer? You use integers to represent numbers. You use pointers to ensure job security."
Only once you reach the assembly or machine code. As shown here, compilers treat them differently.
There are two essential differences: 1. The caller is expecting a response of type Result, and will need to handle that to use the Ok() result anyway. 2. It's isomorphic in the exact same way that opt-in and opt-out mailing lists are isomorphic. You have to explicitly opt-out of exceptions to keep them from propagating up the stack. You have to explicitly opt-in to Results to propagate them up the stack (and provide a return value that matches the results you are handling).
Thanks a bunch! Will go through it ASAP.
Even without comparing to C++/C#/Java, it's an inconsistency within Rust's syntax. Some places you need a turbofish, other places you don't.
I liked the comment in the Boehm GC FAQ (paraphrasing from memory): No, it's not alright to XOR your forwards and back pointers in a linked list to save space.
I did chuckle at this one. It's probably nervous though, considering the pointer orgy I'm about to refractor in the next month :(
&gt; Indeed, this is no different than reading a pointer whose memory was reused! Yes, it is different. Reading a freed pointer invokes undefined behavior, which comes with the risk of crashes, over-eager compiler optimizations, and [other](https://blog.regehr.org/archives/213) bad stuff. Modifying the wrong monster in the game does not. There is a real, qualitative difference between undefined behavior and using the wrong index. So indices are a demonstrably _better_ design, regardless of what you say. This potential issue is even acknowledged in the accompanying [blog](https://kyren.github.io/2018/09/14/rustconf-talk.html) post: &gt; One more criticism of this style is that you might say that using indexes instead of pointers is “safe” in the strict sense, but possibly only technically, you’re trading UB and potential crashes with pointers for “random but unspecified” behavior if you access the wrong or outdated index, and potentially panics. You’d be right, btw! We’ll visit this some more later, but just accept for now that it’s possible and safe and this design doesn’t run directly against the borrow checker. &gt; This solves the problem, but strengthens the argument that satisfying the borrow checker is expensive. Generational indices (as I see them, at least) are a somewhat minor extension to the idea of object pooling. They don't have to be "expensive", and can even improve performance when compared to non-pooled allocations.
In the context of Rust, safety has a specific meaning: thread-, and memory-safety. That is what the borrow checker gives you. It does not guarantee that you're writing correct code, it simply guarantees that you're not running into undefined behavior.
But what you're arguing is beyond the point of syntax. Removing the turbofish syntax doesn't remove the need to specify types in some places.
I think it's because ... * If it returned the PathBuf value, then it would have to take ownership of the PathBuf to do this. Then `.push` would no longer work on mutable references. * If it returned a mutable reference to the PathBuf then you couldn't do `let path = PathBuf::new().push(foo)`. It means chaining works in some places but not others. I don't know if this is the case for Rust, but there is also a potential third reason. For stylistic reasons you only return a new value if you make a new value, and to never return if it's mutating. I personally adhere to this. For example in JavaScript there is `Array.sort`, and it sorts in place. But it also returns the array for chaining. Because it returns the array I've seen developers first hand misunderstand what the method does. They presumed it returned a new array, when it didn't.
No, but it makes it more symmetric to do so. Now: ``` let x = Foo::&lt;Bar&gt;::new(); let y: Foo&lt;Bar&gt; = Foo::new(); ``` Hypothetical: ``` let x = Foo&lt;Bar&gt;::new(); let y: Foo&lt;Bar&gt; = Foo::new(); ```
not a bug: https://users.rust-lang.org/t/dependencies-does-not-follow-target/20563/2?u=geobomatic
The default/most supported installation channel for Rust is rustup. Currently, by default, the `rls-preview`, `rustfmt-preview`, and `clippy-preview` components are not installed when you install Rust. They need to be installed by a separate `rustup component add` call. This may change in the future: as these components graduate to 1.0 non-preview status, there's talk of adding "profile"s of components to rustup, such that more components can be chosen to be installed by default. For the RLS specifically, the RLS plugin for your editor _should_ be able to transparently install the component. (I know the vscode one does at least.)
As mentioned in the blog post, this is closely related to ralfj's own [pointers and bytes](https://www.ralfj.de/blog/2018/07/24/pointers-and-bytes.html) post, which includes more Rust-specific info and was discussed here [previously](https://www.reddit.com/r/rust/comments/91hzre/pointers_are_complicated_or_whats_in_a_byte/).
Blow's argument essentially, is, firstly, "crashes are better than logic errors" (which I agree with), and there are several approaches which do different things when they go wrong: unsafe pointers lead to UB, indices lead to logic errors, and something more clever like generational indices lead to panics. The next part of the argument is "UB is, in practice, often a crash (i.e. a segfault), although sometimes leads to logic errors, so it's better than always having logic errors" - this part I don't agree with.
Or [Stack Overflow](https://stackoverflow.com/questions/7021295/difference-between-class-and-package)
There was an interesting comment in the RFC. You can also see `Foo::&lt;Bar&gt;::new()` as a Foo module that gets auto-monomorphised with the Bar type and you're calling the new() function in it. So technically the current turbofish is also symmetric with the module syntax. So basically the discussion could shift to which symmetry would be better, which I don't think will go anywhere.
Great. Thank you and happy cake day!
This question is actually the title of a blog post which attempts to provide an insightful answer. It was not actually a request for information.
I'm just saying, I've never heard programming language spectrum abbreviated before, when I googled it, Google hadn't heard of it either. If this is an academic paper, he might want to use known terms.
No. I've just got 25 years of professional C++ experience, including contributing to the standards, authorship of multiple libraries, full mastery of TMP, etc. C++ is as natural as speaking to me, Rust, so far, is not.
damn you ! :)
Composition over inheritance isn't that uncommon in OOP circles though. The decorator design pattern in particular comes to mind. 
Wrong subreddit. 
&gt; First, does this C program execute undefined behavior? It does not! &gt; &gt; Second, does the C standard mandate the behavior that we saw here? It does not! This is too nuanced for me. What distinction is being made? The behavior of this program is not defined by the C standard and yet the behavior isn't undefined? Okay it could be implementation-defined, but that doesn't seem like it would be the case here.
Can someone who has watched this video comment on its relevance to Rust, for the purpose of satisfying our on-topic rule?
I've found several instances where native Rust was more performance than naive C++, though the tendency of less experienced developers to untangle borrow knots by cloning does negate some of that. I've found instances where the performance (and even the generated asm with clang) was nigh-identical, where I was completely shocked by that outcome. But, so far, I have not found examples where Rust significantly outperformed well designed C++. The biggest point of performance (as opposed to safety) pain, really, that Rust could solve much more easily than C++, with a minor change, is movable coherent data. The fact that move-by-default negates local references could be fixed with a genuine local reference semantic, which C++ does not have a way to make natural. In Rust, though, there is already a concept of a unit of ownership, that must be borrowed as a unit. This could be extended to reference locality, which could enable several significant cache locality improvements...
The profiler is written in Rust and small part of the talk is about why Rust was chosen.
There is a transcription: https://www.deconstructconf.com/2018/julia-evans-build-impossible-programs tl;dr Julia Evans has written a sampling Ruby sampling profile in Rust. An "impossible program" because 1) no-one seems to have written something like that at all 2) she considered herself a Rust beginner with no knowledge of Ruby internals.
I guess in most low level capable languages, careful profiling and design will approach the same level of performance. Thanks a lot
I'm not too well-versed on the edges of the C standard to say if it's your second assumption, but I'm guessing that some of the specifics (as in, what the value of `diff` is) aren't defined, but the general idea (`y + (x - y) == y`) holds. Swapping `diff` for the value of one run of `diff` *is* undefined behavior because `diff` may not always be 96 (`malloc` can change). So, undefined behavior comes in when you get `diff` by some other means than direct arithmetic, and the value of `diff` can change across compilers, but you're within defined behavior when you only use (correct) arithmetic for pointers.
I agree, the book was postponed several times.
Nice, I just removed `alacritty` because it took too long to compile the AUR package and I didn't use it often enough to justify that. I'll definitely be playing with this now :)
I've been looking for a way to do simple precondition / assertion checks and return a result. Is there a crate to do this? Something like: ```rust let name: String = get_name().check(|&amp;s| !s.is_empty(), "Name is empty"); ``` Is this possible / available somewhere? Trying to minimize having lots of if statements.
I have to express my appreciation of the diction in this article. It is almost poetic. 
They have that, it's called kernel pages. You still need pointers to do a ton of shit.
They have that, it's called kernel pages. You still need pointers to do a ton of shit.
Given struct A; struct B { inner: A }; Is there a safe way to write a function `wrap(&amp;A)-&gt;&amp;B`?
Dramatic reenactment: https://www.smbc-comics.com/comic/2014-07-11
https://www.reddit.com/r/programming/comments/9gyumh/you_cant_always_hash_pointers_in_c/
The real trick is designing a language where the idiomatic expression of a solution is both (elegant/ergonomic) and optimally performant... along with whatever other goals your language has. I'm currently trying to design a language that naturally expresses cache-optimal data layout. Getting something that provides that and is also easy enough to write is tricky as hell...
When something is "undefined behavior" then the compiler is free to do literally anything and often it will just assume that case never happens and optimize a branch resulting in undefined behavior out of the program. In this case there's a finite set of things that could happen, mostly involving re-ordering operations around stores to memory that are actually the same place but not provably the same place to the compiler.
With a slight rephrasing: "What's the difference between a pointer and an integer?" "A pointer."
Well, it prints it's source code to stderr rather than stdout for one thing
This depends on who owns what. Do you want struct B to own its A data, or only have a reference to it? If you want B to own its inner A, then: struct A; struct B { inner: A } fn wrap(inner: A) -&gt; B { B { inner } } This will move 'inner' into a new B struct. On the other hand, if you want B to only have a *reference* to A: struct A; struct B&lt;'a&gt; { inner: &amp;'a A } fn wrap(inner: &amp;A) -&gt; B { B { inner } } This will work assuming that the reference to A doesn't outlive wherever A is stored (which the compiler will enforce for you).
They want a function from &amp;A -&gt; &amp;B, which as far as i'm aware can only be done with a transmute, i.e. fn wrap(a: &amp;A) -&gt; &amp;B { unsafe { ::std::mem::transmute(a) } } 
Assuming that B indeed only contains A as the only member, and A is valid, it should be sound. In any case, I was reading his intent by the fact that he called the function 'wrap'. If he just wants to construct a new wrapper type from A, it seems like it'd be better to just make a new B.
Shucks, it's only 2:45pm! O\_O
 fn check(input: String, f: impl FnOnce(&amp;str) -&gt; bool, default: &amp;str) -&gt; String { if f(&amp;input) { input } else { default.to_owned() } } Should do it. You can also create a generic solution, but then you'll have to pass in a String, not a &amp;str (if that makes a difference to you).
I'm not sure it's adding up for me. Could you give me a few pointers for understanding this joke? :p
&gt; This is the same confusion that the blog post does. I did not mean to imply that there's no difference between safe and correct. If you have advice on how I can avoid communicating that, I'm welcome to hear it, and update the linked article accordingly.
You're welcome. Just so we're clear, though, I intend to refute his argument. :)
I own the \~600 pages book (and it is really an excellent resource, btw). &amp;#x200B; The page before the Table of Contents says: Revision History for the First Edition 2017-11-20: First Release 2018-01-05: Second Release 2018-06-22: Third Release &amp;#x200B; I bought my copy in august 2018 and it is the first edition (December 2017). I don't think there are second/third release around.
I'd like to avoid discussing the particulars of Rust's types, so I deliberately simplified this explanation. Would it make more sense to use `Option&lt;String&gt;` for the examples, so that I can talk about what Rust does instead of relying on another language?
I was talking about OS. I think bare metal pi efforts are still pretty alpha at this time.
&gt; So indices are a demonstrably better design, regardless of what you say. Just to be clear, I'm restating his argument. I intend to spend the rest of the series demonstrating its naiveté. I'm open to advice on how to make my position more clear.
I'm still a confused. Why or how did `p` reference a third address in the GCC example? What memory is it pointing to? Did the compiler try to just optimize everything away and made a hard assumption that `p` would reference some mysterious third address based on its rules?
Hence why I said "computer", not "compiler". I suppose I should have been more specific and said "CPU".
Darn it, I want to know more about this, but can't find it in the current FAQ: http://www.hboehm.info/gc/faq.html
I would be very to finally remove the turbofish language ward. Having type ascription be inconsistent because of a hypothetical ambiguity is bad and I am glad that we can change it without having any crate on crates.io break. In my opinion we should lint against this ambitious writing anyway for readability.
&gt; if banks adopt blockchains like this I don't believe it will happen because of the key property of blockchains: they are expensive and the only value they provide is independence of third parties. Since banks don't want to remove themselves and blockchains don't offer any other benefit, it's not logical for banks to adopt blockchains. The only thing imaginable to me is banks adopting bitcoin (the currency) out of necessity (if it becomes world money just like the Internet became the world communication medium) and providing services on top of it (loans etc). But enough philosophy, I guess you're more interested in technology. :) &gt; Does this mean a smart contract was introduced and thus created a fork of the chain? Smart contract is always a contract between voluntarily participating individuals. It's always validated by whole network (those who have enough resources to validate). The more boring term for *Ethereum* smart contract is "program". It takes some inputs, and performs some actions (like changing the balances of participants). &gt; And only this fork is affected? The contract is executed by every fully validating machine, but its outcome only affects those who participated. Of course, unless it's too popular, in which case critical vulnerability in it might lead to Ethereum price drop (see the DAO fiasco). &gt; How are contracts signed/added to the chain? First they are broadcast to other participants by their creators. In order to prevent spam or DoS attacks, the contracts must pay a fee proportional to the resources it consumes (in theory, there were miscomputations before). Then the miners validate them by executing and if they succeed, they put it into the block they are mining. If they mined the block, they gain the fee coming from the contract plus the block reward. &gt; How is a smart contract used? Just like broadcasting contract, anyone who wants to cal its function must broadcast their intention to the network (again, they have to include fee). And the execution is carried out similarly to creation. &gt; Is the whole code of the contract part of any transaction that makes use of said contract, or is it able to refer to a previous version of the contract that is already a permanent part of the chain? I have no clue about this when it comes to Ethereum - I know only some high-level concepts. However I know Bitcoin-based smart contracts much better (to the binary level, actually). In Bitcoin, it's simple: any contract is a set of transactions and every transaction can only access data from next transaction (next transaction provides proof of validity to the previous transaction, which decides whether spending the coins is valid). Here's the thing about smart contracts: while they look exciting at the first sight, one eventually realizes that they aren't *that* useful and they don't even need to be too powerful - not even Turing complete. Currently there are only few useful smart contracts out there and I doubt there will be much more in the foreseeable future.
I may have missed it, but I don't think you've got the 'this bind operator'? It's `::`. It's supported by Babel, and is probably going to become a standard.
I'm talking about some other CPU altogether, not x86. For example Lisp hardware or a CPU that can execute Java byte-code directly. There is no need for conversion between a reference and an integer in a JRE. Yet it can still do lots of useful work.
Yes, but you don't need to convert between pointers and integers to do all of that. The hardware could make it impossible to get hold of the integer representation of a pointer. Not x86 hardware or ARM hardware, something else.
The author has some great posts about that: https://blog.regehr.org/archives/213
https://docs.rs/quicli/0.1.1/quicli/prelude/index.html Here's a good example of a useful prelude outside the standard library
I think it's that in the first case, the compiler knows that p is derived from x and y and so might alias one of them; wheras in the second case it is only derived from x and so shouldn't alias y, and optimises it as such. I'm not sure what would happen in cases where the compiler couldn't know what it was derived from, such as writing diff to a file and later reading it back, or sending it over the network, but my guess is that that's UB like in the case with a constant there
[kuchiki](https://crates.io/crates/kuchiki) might be what you're after.
p is pointing to the same memory as x in both examples. The difference is whether the compiler thinks that either of x or p have changed and whether it assumes that the pointers might alias each other. I haven't looked at the assembly, so I might be wrong, but I think what happens is as follows: In the first example, gcc assumes that x has changed and thus reloads its value before printing. In the second example, gcc assumes that it hasn't changed and uses the initial value in printf. 
I want to use tokio to make a TcpListener that keeps an open connection and, whenever it reads a set of bytes, it appends those bytes to a file, and, if successful, write these same bytes to some TcpStreams. I noticed that `copy` consumes TcpListener's reader, so what can I do here?
This is as close to documentation as you can get. Good luck. https://forge.rust-lang.org/cross-compilation/to-windows.html
I've read some comments here and elsewhere regarding that 32% claim that are IMHO overexcited about Rust performance. **This is harmful to Rust**, and you should try to contain such excitement when it happens in popular discussion boards, not encourage it. Are there specific cases where Rust code may perform better than C? Of course. But the tagline should be something along the following lines but better worded: "Rust performance should be at worst within a factor of 2 of C performance, but very close on average, and even faster in some specific cases". Here is a recent example where a RealVideo 4 decoder written in Rust performed worse than C, but stayed within a factor of 2, which is not bad, really: https://codecs.multimedia.cx/2018/08/nihav-some-progress-to-report
Why would that be the case? Presumably the `Some` would be detected as a non-live object (nothing references it) and thus freed by the GC.
One is a subtle construction plagued with overflows, platform quirks, and undefined behavior. The other just points to some data.
Assuming a tracing GC (that is, not `Rc` or `Arc`), assigning `null` or the equivalent to a variable does not immediately free it. Its space may or may not be reused on the next GC cycle, but that doesn't happen immediately. And technically GCs don't "detect" dead objects (if you ignore finalizers), they just care about the live ones. So the latter might be moved / compacted / whatever else, and that might overwrite dead objects, but it's not something relevant to the process.
Functions are opaque to lifetime analysis. All that the compiler can tell is that the return value borrows some part of the vector. It has no information about what part that is.
In the mean time, just for fun, I was playing around with a macro for this: macro_rules! trait_alias { ($alias:ident, $($args:tt)*) =&gt; { trait $alias: $($args)* {} impl&lt;T: $alias&gt; $alias for T {} } } Use it as `trait_alias!(Foo, Future&lt;Item=MyItem, Error=MyError&gt;);`
Just dropping in to say this; I didn't watch the keynote, but I've read your blog post last night and really liked the "from the first principles" approach you were trying to make. Games aren't my thing, so it was refreshing to see an explanation of ECS that doesn't say "you should use ECS because data-oriented design is good". I think it felt a bit rushed at the end (the registry section and afterwards), but that's entirely understandable considering it was supposed to be the basis for the keynote. But if you ever get to write more on the subject, I'd love to read that. --- Also, if you don't mind the nit-picking, you have a reversed type alias declaration (search for `type usize = `) and a couple of minor typos that I can't recall, but are easy to find with a spell checker.
If you subtract an integer from a pointer, you get another pointer. Say "a" is a memory address, i.e. a pointer; "b" is a memory offset, i.e. an integer; then "a - b" is another memory address, i.e. a pointer.
I ran through it with a spell checker and caught a bunch but clearly not all, can you name a few so I know where to look?
OH DIFFERENCE LIKE MATH gotcha, thanks :p
You lost me. What do integers have to do with any of this? What do you mean by "the integer representation of a pointer?" Do you mean the i64 you get when you dereference an &amp;i64?
Rust has no undefined behavior. This means the compiler cannot do eat you alive if you fuck up. That's the only strong guarantee rust makes. Creating your own heap with your own pointers will absolutely avoid Undefined Behavior, even if you do all the traditional mistakes like off-by-one, use-after-free, or double-freeing. That has one fairly useful property: Errors should reliably fail, independent of optlevel or other factors.
I don't doubt that! Rust has a huge potential in robotics area. I've decided to go with C++ because if I don't notice the issues with C++ then I won't be able to appreciate what Rust has to offer. Thanks for the advice!
&gt; Ms. West's presentation anticipated the free-and-reuse case, proposing the ECS track reuse with a counter that increments when an entity is reallocated. This counter, aka the generation, can be checked to avoid free-and-reuse. This solves the problem, but strengthens the argument that satisfying the borrow checker is expensive. This is exactly what _many_ game engines do... even in C or C++. Satisfying the Rust borrow checker is just a consequence of Rust making sure you're doing things correctly rather than letting you write simpler but incorrect code. :) The solution is also hardly "expensive" since the alternatives are generally worse in either runtime or memory overhead or both.
This helps motivate me to continue working on dumb-exec! Now if only I knew how I could test it.
I honestly don't see the problem with turbofish. If anything I'd like to get rid of `&lt;&gt;` as use for generics. IMHO it was a terrible mistake for C++, if C++ didn't have the `&lt;&gt;` template stuff I would argue that turbo fish is a hint that `&lt;&gt;` are symbolically overloaded (ie. being used for completely semantically unrelated stuff in similar contexts) and therefore are the wrong syntax to use. Personally I could see two solutions: * The turbofish shows that we can make the symbols separate enough to say that modules whose name is between `&lt;&gt;` are abstract/generic modules and really map some values to a template. This would mean that `Bar&lt;Foo&gt;` makes no sense, instead we have a module `Bar` which contains a module `&lt;Foo&gt;` and which is a type, so we'd write it *always* `Bar::&lt;Foo&gt;`. In a world with no C++ I would argue for using something else. * The turbofish shows that we are using the wrong symbols. What we really want to say when we say `Bar&lt;Foo&gt;` is that `Bar` is statically computed function that returns a type (static item) for us, the closest thing is a statically computed function that returns a token tree (static item), or macro, so we would write it instead as `Bar!(Foo)` which is the way D does it. * The turbofish shows that we are using the wrong single. We want something that always encloses things syntactically and never means anything else, we could conclude later the semantics and decide if it's meant to be a generic specification or not. We could use `()`, `[]` or `{}`. IMHO this one is not as easy to read for humans.
At the top of the thread, the guy suggested that pointers were a bad idea, in the context of Regehr talking about pointers being represented as integers (and interchangeable with integers at various levels, e.g. in CPU registers, or in machine code, or at the C language level). So I was wondering what kind of computer would we have if we didn't have pointers like that? Maybe a pure stack machine, or a hardware Lisp machine, or something like a JRE implemented in hardware (there was one hardware JRE at least IIRC). Not the typical common CPUs that we know where all of memory can be accessed as bytes if you want. In this kind of model of how a CPU could work you'd still have references in some form, but you can't get at the underlying address. So just like Rust still has null in the form of None, you'd still have addresses in the form of references, but not addresses like x86/ARM have them, nor pointers like C has them.
Fetching array elements as arr[n] instead of arr.get(n). It's unsafe and it should not work by default.
You can't do this with stable cargo today, but there is an unstable feature to allow dependency renaming that should enable this kind of thing: https://github.com/rust-lang/cargo/issues/5653
I said this below, but it bears repeating: I agree with you. Jonathan Blow decided to take a small part of your keynote and talk about it at length. I believe the best way to respond to that is to flesh out what you were getting at, describing in depth how Rust assists that process. I'd originally tried to put this all together in one post, but it turned out that it was either too abstract (requiring a large amount of knowledge of Rust, which Jonathan lacks), or way too long. It seems that my goal somehow was lost in translation, and for that I apologize. I would like to say, though, that I thoroughly enjoyed your presentation. It connected a few dots that I'd been struggling with in specs, and the "TicTacToe" ECS I'll be building in the next post was directly inspired by the "UR-ECS" you showed on your slides. :)
It is not unsafe is it? You just get a panic if your index is out of bounds
Lol, "just panic". Yes, it's not "unsafe" for data, it's unsafe in terms of program execution. I can't understand people who can say "just panic". Not sure what kind of software you write if panicking is acceptable there.
What do you do when you get None but expect Some?
Panicking is perfectly acceptable in many cases. - If you're just writing a quick script. - If the invariants are so broken that recovery is simply impossible. Worth noting that panicking is recoverable, e.g. if you're in a server, and want panics to just bring down a single request instead of the whole server, you can use [catch_unwind](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html) to gracefully recover. Or to show a prettier message to the user in a CLI tool. Furthermore, indexing is very useful when you just *know* your index is going to be valid. There are many situations in which this is the case, and you'd just have to unwrap() the result of get anyways.
Right, that's what I meant here ^^'. My bad.
Try installing cargo deb and then use cargo deb --install
small scripts don't worth to be mentioned or discussed. Panicking in hope to catch, when you can just return an error - for perverts. Maybe Rust was wrong choice at all if you prefer old crappy try-catch-throw instead of Result&lt;&gt; or Some&lt;&gt;. And yes, there are some low-level cases when panicking is unavoidable, but they are just rare cases. Even if you know you have an element by that index - it will not kill anybody to fetch it using "get" method.
Responding to my own post, let me see if I can think of a few that aren't just superficial syntax nits... * The module system is a little hairy, but is getting made better in the 2018 edition and isn't actually terribly complex * I'm a little unhappy that `{number}` is a special magic thing in the compiler, but don't know how it would be improved * Macros are kind of silly and 90% of the most common uses of them would be eliminated by better compile-time metaprogramming, but I'm not sure that would really make life *simpler* :-P * Having structs and tuples and enum-structs and enum-tuples be almost entirely unrelated to each other seems like it should be improved * I don't think I've ever actually seen a union in the wild. But, I don't do much C FFI either. * I'm a little unhappy with traits because they get used for at least three different things that *feel* like they should be orthogonal: specialization of compile-time generics, and run-time dynamic dispatch, and language-special-meaning markers like `Copy` and `Send`. * Attributes are kind of a catch-all garbage-pail of useful but random bits and pieces of information * Auto-deref may or may not actually make life easier in most places, I'm not sure. Would be interesting to see what Rust looked like without it, but we might be able to do that just by digging through pre-1.0 history. * Are unsized types worth the trouble? I think they are, but it's one of the questions I'd want to revisit. * Does the `!` type actually make life better? I expect the type checker needs it no matter what, and I understand it makes some optimizations possible, but it's another thing I'd ponder. * Closure capturing has got to be able to be simplified *somehow*. * I see why unsized `[T]` types exist but life might be nicer if they didn't. Don't know if that would end up being super restrictive though. * Box as a special case. As far as I know it's basically just there for hysterical raisins. * Various things like method call syntax, if-let, associated consts and functions, and so on are basically just syntactic sugar... but *damn* are they nice for quality of life. * Various things that have already been slap-fight-ed to death, like `impl Trait` in argument position, `..=` range expressions, and other such nonsense that isn't necessarily actually important in the grand scheme of things and I really don't want to consider them here. Hmm, looking back on this, the only ones that seem like *actual* design problems that could be smoothed over by Doing Things Differently are structs/enums/tuples, traits, and attributes... And I don't really see that they would really eliminate complex features, just move them into more bite-sized and convenient parts. Most of these are small nits that are pretty orthogonal to the language as a whole though. The big things are all pretty essential to have without either crippling Rust's functionality or its safety in one area or another.
&gt; It seems that my goal somehow was lost in translation, and for that I apologize. Oh, no worries at all! I'm sorry if I misinterpreted where you were going with your post, and I definitely didn't mean what I said as criticism. I was responding kind of to a lot of threads of discussion all at once, not necessarily your particular post, I just rudely used your post as an excuse to do so. &gt; I would like to say, though, that I thoroughly enjoyed your presentation. It connected a few dots that I'd been struggling with in specs I've heard this from a lot of people and this makes me *really* happy, because this is more or less what I set out to do. Thank you for the kind words!
&gt; Not sure what kind of software you write if panicking is acceptable there. This comment seems unnecessary to me.
Most programs written are small scripts, and pretty much every program *starts* as a small script. That said, `unsafe` has a specific meaning in Rust, and panicking is not unsafe. If panicking is unsafe then calling `system::exit()` is as well. There are also high-level cases where panicking is unavoidable, such as a poisoned mutex or a backhoe interrupting an internet connection. I would agree that I wouldn't mind switching the meaning of `array[n]` vs `array.get(n)` so the non-panicking version is the default, and having the compiler tell you whether a function can or can't panic would be interesting.
I mentioned already what I meant by unsafe, not sure what else you expect. No, small scripts are not real programs. Eggs are not chickens.
I forgot to ask you what is necessary to write in my comment.
The borrow checker is one of the best features of Rust
You will get it, trust me. It just takes work. I read the docs a half dozen times and wrote four or five shitty broken programs before I was able to grok it.
I’m pretty fine with the borrow checker. Biggest problem is I don’t know what code I want to write. 
I write partial functions in just about every application/library I've published, so, yeah. And no, panicking is not unsafe, and it is misleading to claim otherwise, because unsafe is a term with a specific meaning in the Rust ecosystem.
&gt; I'm a little unhappy with traits because they get used for at least three different things that feel like they should be orthogonal: specialization of compile-time generics, and run-time dynamic dispatch, and language-special-meaning markers like Copy and Send. &gt; Attributes are kind of a catch-all garbage-pail of useful but random bits and pieces of information You've nicely expressed a couple of the things that I had felt but had not considered for long enough to put into words.
But what if that means that there is a bug in the program and there's not really a useful error to produce or way to recover? There's always get() if you actually need to get an Option instead.
"so yeah" what? Not what are you trying to say. And yes, panicking is not unsafe, I answered it already. Edited my comment to avoid distracting misunderstanding.
That’s being interpreted as “break ()” - ie break out of the loop, and make the loop (as an expression) evaluate to ()
 fn main() { let x: () = loop { break (); }; let y: i32 = loop { break 5; }; } 
My point was that total functions are rare and specialized. Specifically, you said you couldn't understand: &gt; I can't understand people who can say "just panic". Not sure what kind of software you write if panicking is acceptable there. So the answer to "what kind of software do you write" where panicking is acceptable is pretty simple: the vast majority of the Rust ecosystem. I don't know, maybe the levity of your claim is clear to you, but it's a pretty sensational one from my perspective.
[Turbofish](https://github.com/rust-lang/rfcs/pull/2544), and it looks like it might actually happen :)
I definitely have not grokked the BC, but it (and the compiler more generally) is one of the reasons I am using rust.
So just so you know, I personally define unsafe as it being safe, so if you could all just use this new definition I just came up with that would be amazing. Panicking is safe. It's clearly defined behaviour. Are divisions unsafe too because they will panic if you put in non sensical data? It's obvious to everyone when and why these functions will panic. If you are not making sure your input data is correct that doesn't make the function unsafe. Making arr[•] return a result is arguably a good decision. That's not what I'm criticizing.
wrong subreddit, this one is about programming language.
Forget about word "unsafe", it was wrong word and I edited my comment. Panicking is safe in terms of data.
Panicking is not an accepted way of reacting to an error, no. Panicking is however a accepted way of reacting to a bug in a program, such as a broken invariant. Whether it's by an index out of bounds error or an assert or whatever doesn't really matter. To be clear, I'm not expressing an opinion here. I'm describing a fact. Most libraries and applications contain plenty of functions that are not total, that is, they can panic under some condition. This answers your question where you wonder what kind of software can panic: the answer is almost all of it. To say that one should never panic is literally a sensational claim because virtually nobody employs that advice in practice for any piece of software.
I'm not sure if you're trolling or if you're actually this abrasive, but these clauses are in the [Code of Conduct](https://www.reddit.com/r/rust/comments/2rvrzx/our_code_of_conduct_please_read/): &gt; Please be kind and courteous. There's no need to be mean or rude. &gt; We will exclude you from interaction if you insult, demean, or harass anyone. That is not welcome behaviour. I'd recommend taking a look.
&gt;You don't always need way to recover, sometimes it's enough just to have way to gently finish your part of the execution flow. Or sometimes it indicates your program is hopelessly broken and it's better to panic than to do anything gentle.
What all are you interested in? Rust has a lot of areas you could jump in to start leaning it. You could try to implement a simple package manager. For an example of a command line app or if frontend is more your thing. You could start out with a simple text editor. I know you said you wanted to venture away from the web, but a good starting point might be trying a simple project with rocket or any of the other web backends. Right now to learn the language I'm working on creating a d&amp;d 5e character sheet app. 
I suggest trying a simple command-line tool. That's how I (and apparently a lot of other people) got started. 1. It'll let you produce something useful without having to learn things like tokio. 2. You'll have the satisfaction of seeing how fast your creations start compared to command-line tools written in things with big runtimes like Node.js, Java, or Python without the inconveniences that crop up when working in C or C++. Beyond that, I'm not really good at making suggestions. I always focus on what itches I need scratched and they wouldn't apply to you.
A series of bad decisions has unfortunately familiarized me with the C standard. [The C standard](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf) distinguishes between "undefined" and "unspecified" behavior [&amp;sect;3.4]. A program that executes undefined behavior is not required to do anything in particular. A program that executes unspecified behavior is required to do one of several possible things. Unspecified behavior isn't portable. It isn't necessarily stable between compiler versions. It might not even be stable between invocations of a program. But at run-time, exactly one of the possibilities will happen. Here's a perfect example: void *x = malloc(4); uintptr_t xi = (uintptr_t) x; printf(PRIxPTR, xi); The C standard says almost nothing about the value of the unsigned integer `xi`. In fact, it says only that `(void *) xi == x` [&amp;sect;7.20.1.4]. That integer could be any number whatsoever — but it is a real, definite number. In fact, you can probably see the unspecified behavior if you run the program multiple times. Before the program runs, you simply *cannot* predict what memory address `x` will have [&amp;sect;7.22.3]. But once it happens, there definitely is a single number that represents that pointer. You can do whatever arithmetic you want on it, because it's just a number with some unspecified value. Furthermore, (as long as `x` remains valid, *i.e.* as long as you don't `free` it,) *every* time you convert the number `xi` to a void pointer, you get a pointer to the same allocated object. If you do legal math that results in a number equal to `xi`, casting it back to a void pointer is still just fine. "Unspecified" behavior is unpredictable but legal. Whereas dereferencing a pointer you invented yourself might crash your program, unspecified behavior never will. For more examples, see [&amp;sect;J.1].
I'm almost certain you meant to link to [this turbofish](https://turbo.fish/). ;)
It's like asking what kind of software might be written not good enough - yes, all of it. But it doesn't mean writing bad code should be considered "normal". If there's a way to avoid panicking - it have to be used. We can avoid panicking by not using "unwrap", for example - only thing what stops us is laziness. Same with array indexes. Some panicking is unavoidable, like integer overflow or division by zero - it's pure bugs. But people use panicking even when parse XML and it's not valid. It's a real shame.
A pointer, an integer, and a denormalized floating point value walk into a bar....
your arrogant response was offensive to me.
That does what? In theory the only time you would hit that code path is when there is a bug, so how do you respond to that?
That's how we get library which will ruin whole your server because user input contained invalid phone number.
Another reason I forgot to mention: Rust's error-handling strategy will make it much easier to ensure they're reliable. Rust actually taught me about some possible failure conditions I'd overlooked. For example, that getting the current directory is an unavoidably fallible operation. (ie. You can't ensure it'll succeed if you bypass enough of the library stack. The system call itself may return failure.)
no, it will hit this code path when there's no such element in array. For example, if you received that index by some computations or by parsing user input. There's a lot of cases.
That doesn’t happen because requests are processed in separate unwind contexts. 
Regarding unions: we were waiting for them too long, most of ffi crates had been created before unions. Also old Rust versions support (some of crates stuck even with Rust 1.9).
I'd remove \`let mut\`. I have yet to see any evidence of that actually being helpful. What is helpful is the distinction between \`&amp;T\` and \`&amp;mut T\`, but mutability on bindings has yet to uncover a potential bug for me. It also just doesn't work well imo. \`let foo = &amp;mut String::new();\` is mutable despite there not being a \`let mut\`. You could argue that this is a distinction between the binding being mutable and the data being mutable. And you'd be right. But what exactly does binding mutability even give me? If I want to rebind I can do so anyway by shadowing the binding (yes, there's differences around dropping, but that's irrelevant from a mutability point of view).
You want /r/playrust.
Did you compile with --release?
Nah, in the context of a request/response server, you still want isolation even if you believe your code is bullet-proof.
I'm also feeling this. I find myself with this vague frustrating feeling like what I used to experience when I was writing a lot of Java and before I "got" functional programming. The whole swampy software architecture that comes from explicitly writing out hierarchies of types that implement an interface. Composing functions in rust feels noisier than I want. I'm sorry I'm not yet able to articulate better than that.
NLL is the best thing since sliced bread. And don't forget about the RLS. I can imagine how anyone not using the RLS would really struggle with the borrow checker.
Sorry for nitpicking, but I think that talking about "integers" and "pointers" kind of assumes the higher-level, "compiler" kind of viewpoint, so how the CPU sees the thing isn't actually relevant. The CPU, after all, isn't concerned about integers and pointers, but bytes and words.
Sorry, I thought the fact that a GC doesn't immediately free memory in the general case was assumed. I believe the original text implied "eventually" when it speaks of freeing memory.
I hate the special behaviors of _ , just hope it gensyms a special "_blahblahblah" and put it there. For the current "touch" behavior, use something like "..".
&gt; Macros are kind of silly and 90% of the most common uses of them would be eliminated by better compile-time metaprogramming, but I'm not sure that would really make life simpler :-P &gt; Attributes are kind of a catch-all garbage-pail of useful but random bits and pieces of information Attributes and macros go hand in hand. They're ways of extending the language without forcing complicated syntax discussions outside of their named delimited area. They _are_ your compile time metaprogramming (and also grab-bag feature bin e.g. `format!()` and `#[must_use]`, but meh). &gt; I don't think I've ever actually seen a union in the wild. But, I don't do much C FFI either. Getting rid of something just because you don't see them used doesn't mean they don't get used. `ManuallyDrop`, for example, is a union. &gt; Auto-deref Auto-deref means not having to worry about wrappers and avoids having to consider putting the same methods on e.g. String and &amp;str. It lowers cognitive load a lot for me. &gt; Are unsized types worth the trouble? I think they are, but it's one of the questions I'd want to revisit. Yes. Trait objects and runtime dispatch is basically not possible without it. &gt; Does the ! type actually make life better? I expect the type checker needs it no matter what, and I understand it makes some optimizations possible, but it's another thing I'd ponder. It helps with generic trait impls. E.g. `impl&lt;T, U&gt; TryFrom&lt;T&gt; for U where U: From&lt;T&gt; { type error = !; ... }` &gt; Various things like method call syntax, if-let, associated consts and functions, and so on are basically just syntactic sugar... but damn are they nice for quality of life. Associated functions and consts aren't sugar, because trait objects and generic functions. &gt; Having structs and tuples and enum-structs and enum-tuples be almost entirely unrelated to each other seems like it should be improved This is on the ever-long todo list.
I do not know these languages, but this means that the compiler makes the program keep the values around and read not them from the memory adresses ?
Please keep in mind our [code of conduct](https://www.reddit.com/r/rust/comments/2rvrzx/our_code_of_conduct_please_read/), using “perverts” here isn’t appropriate. Panics are acceptable in some applications, and not in others. Please don’t make value judgements on the people who use them. 
Depends on the machine. The Mill CPU folks got bit by LLVM making that assumption, when it's not necessarily always true.
I'd remove all special cases that possibly can be removed, because I think it makes the language less elegant and harder to learn. E g: * the special handling of auto traits (Send and Sync). Why can't we just derive them like all other traits? * Specialization (although that is not stable yet) * The special case of `println!` not needing `&amp;` to take a reference to their arguments. * Go through all "lang items" known to the compiler, and see which ones can be replaced with more elegant solutions. Bundle the rest up in just a few modules and let that be a new libcore, maybe libtinycore or something like that. With that, we can remove the special case of libstd/libcore, which makes it possible for people to write other libstd's and libcores depending on their requirements. In addition, panics are difficult because they make life easier in a lot of places, but they also make life harder in a lot of other places - and it kind of depends what type of code you write (and what platform you're targeting) which one matters the most. It would be interesting to see where a panicless version of Rust would go.
Implicit shadowing is horrible and the one thing that I would remove!
Implicit shadowing. 
It doesn't do the equivalent of generating a unique symbol. It literally matches any value **without** binding it. This means that the value gets destructed in that match if the pattern fully matches. `..` is also used, but it means "and the rest of the data".
The `as` operator. Make it a trait, even if it's not allowed for custom types to implement it. `5i32.as::&lt;u32&gt;()` or something.
[removed]
&gt; `()`, `[]`, or `{}` All of those would have the same issue that turbofish solves.
[removed]
This was my first useful Rust project I wrote and I haven't devoted a whole lot of time to it but I thought some other people may find it useful. The UX is kind of bad (i.e. error messages aren't that friendly), the source structure needs some work, and I'm doing some very non-idiomatic things, but it gets the job done.
[removed]
Please, stop the magic compiler trickery with Box. Just give us memory allocation methods that return `*mut [T]` already! Let people makes their own Boxes!
Fun project, thanks for sharing. However git rev-list --all | xargs git grep &lt;regex&gt; is probably an easier way to do this in practice.
multiple ways of assigning trait bounds. I would just prefer the where syntax TBH, but that is just me.
i_hate_snake_case. I don't see any advantages and it takes up more space on my lines. I vastly prefer Pascal case.
I thought it was one of the points in favor of the trait system, that it solves a number of different problems at the same time. Do you think some of the problems make it less effective at solving the others? Or more complicated than it needs to be?
Looking for /r/playrust rather than /r/rust, methinks. Nice base, though!
str or string, pick one
I kind of disagree. Something like this can be a nice idiom: let stdin = std::io::stdin(); let stdin = stdin.lock();
i love it &lt;3 
I think this is because you use explicit state `AppState` in your ha dele function, but register function uses generic type
Having written a lot of Go and Rust, I think the problem is _much worse_ in Go, for two reasons: - The `:=` operator is ambiguous. Sometimes it declares all new variables on the left. Other times it declares some new variables, and assigns to other existing variables. But which of those it's doing will change if you take it from the outermost block of a function and move it into a nested block. - Named return types are especially confusing if you accidentally shadow them.
I'd remove the affinity for abbreviations and initialisms. I don't need Java style `JsonValueFactoryBuilderProvider` verbosity up in here but I'd like to see `dynamic` instead of `dyn`, `mutable` instead of `mut` (or go the way of Scala's `var` and `val`), `ReferenceCounter` or `RefCount` instead of `Rc`, etc. I think it would ease onboarding and approachability but new programmers, new Rust programmers, and non-native English speakers alike.
Yeah, disagree on let mut. The number one thing it does is catch things I meant to mutate but forgot to implement. 😂
The difference between those two things is kind of fundamental to Rust's ownership model. It's kind of like saying "Vecs or slices, pick one."
In Rust 2018 and the new module system, how do you consume `proc_macro`? In more recent nightlies (in the last week I believe), `use proc_macro::TokenStream;` produces the error `Could not find `proc_macro` in `{{root}}` `
As others have pointed out, this is part of a really cool feature, where you can make loops evaluate to a value.
An invalid phone number might have a reasonable fallback. (Just store the string regardless of the format, whatever.) But there are a lot of things that don't have a reasonable fallback, and for which pulling a fallback out of thin air can only lead to more suffering. If I have a `Vec&lt;File&gt;`, and I try to index into it, but my index is out of bounds, what should happen? Should we try to figure out what the "default `File`" should be and soldier on?
https://doc.rust-lang.org/stable/std/alloc/fn.alloc.html
Yeah, this blew my mind one day when I accidentally did: err := FuncThatReturnsACustomErrorType() ... val, err := SomeOtherFunc() if err != nil { // Would not execute even when SomeOtherFunc() returned nil }
I think allowing lossy casts to an inferred type would be a source of bugs
&gt; I'm fairly certain that there is absolutely no need to have let mut (mut bindings) for the compiler and that its mostly just a psychological thing. Yes, this is something that has been known for a long time, but prior to 1.0 when one of the Rust developers even hinted at the possibility of removing `mut`, the pushback was so severe that we historians remember it as "the mutpocalypse". So yes, `mut` isn't strictly necessary for the compiler, and yes it exists as basically a language-level lint. But that doesn't imply that it's useless, because giving the programmer the ability to restrict the operations that are possible in order to more easily keep a handle on what's happening in the code is pretty useful, and pretty much the whole reason anyone uses a statically-typed language in the first place.
If you want `Enum::Variant(0)` and `Enum::Variant(1)` to be in the same lookup in the `HashMap`, _they have to be `Eq`_. All this will do make `HashMap&lt;Buff&gt;` slower as it will have to deal with hash collisions. (Actually, I notice that you aren't deriving `PartialEq`, but just `Eq`. If you're implementing `PartialEq` to respect this strange equality, then it'll work fine, though it probably is a misuse of `PartialEq`. I'm leaving this warning here.) The way I would implement this is with a single `Buffs` structure that stores all of the buff levels. #[derive(Clone, Debug)] pub struct Buffs { coal: bool, oil: bool, solar: bool, resourceTrading: u32, .. } If this structure gets too large for your liking you can `#[repr(packed)]` it for a more compact representation on-disk, at an expense of having to copy out members (at a slight runtime expense) to use them. Alternately, you can use a simple C-like `BuffType` enum: #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)] pub enum BuffType { Coal, Oil, Solar, ResourceTrading, .. } You can then use this in a `HashMap&lt;BuffType, u32&gt;`, though this will still require your domain logic to avoid buffing yes/no past `1`; however, I doubt your `u32` buffs can go up to `u32::MAX` either, so you still have this problem. (And it's an easy one to fix: just treat `&gt;BUFF_MAX` as being `BUFF_MAX`.) This is also probably the simplest approach to handling a custom `Hash`. Whenever possible, I avoid writing a `Hash` implementation (in every language; I still generate them when I have to provide them); instead adapt your type to a facade type that has the desired semantics. Having a `Hash` and `PartialEq` implementation that doesn't match "simple" equality as expected by a glance can and will trip you up though; I suggest going with either the single large struct or the map. A `HashSet` doesn't even offer a `get` method to see what value is in it anyway; so if you do this, you'll be able to know there's _a_ buff of type `ResourceTrading` in the set, but you'll have no way of knowing the attached `u32` value.
Why not just implentent it so you have a hash map instead of a hashset from your enum without the levels to a \`Option&lt;u32&gt;\` or something
Reminds me of the goes-to operator in C: #include &lt;stdio.h&gt; int main() { int x = 10; while (x --&gt; 0) // x goes to 0 { printf("%d ", x); } }
I’m the opposite. Something about camel case seems immature to me. 
This seems like a really good candidate for a macro.
Oh whoops I copied the wrong link
In the future please keep in mind the threshold beyond which a heated comment thread can no longer be interpreted as mere technical disagreement and begin to veer in a direction whose only foreseeable trajectory seems likely to be an ever-escalating series of personal attacks.
Cool! (Salty side note: I was going to do something like this for an open-ended researchish undergrad CS course, so uh... congrats on scooping me? I'll end up either designing a slightly different API/design and calling it innovative/unique, or maybe I'll U-turn over to the other topic (a merging of PEG generator and parser combinator techniques) I've been considering.) I need to look at this more in depth soon; I need (read: really would like some FEARLESS CONCURRENCY) some sort of key-value map I can append to from multiple threads safely for a personal passion project I'm working on. Interestingly, I don't need `remove`; just the ability to add new members and drop the whole thing as a unit. There are a very few options for concurrent maps on the market today (for Rust), but the only other ones I know of are persistent (the most notable being `im`) and don't offer a in-place value-in-a-box mutation (that's safe on a shared ref).
Indexing out of bounds is also a pure bug - all invariants are broken. Like what should you do? Continue with your dick in your hands?
TIL you can nest unsafe blocks
[Fixed link](https://play.rust-lang.org/?gist=55a565b21d2d6cf987dcb007f5a3ed62&amp;version=stable&amp;mode=debug&amp;edition=2015)
Lack of function overload(as consequence there is no function with variable number of arguments) Lack of integer generics(and as consequence shit load of array types) 
Maybe this goes without saying, but one more point: you definitely should not have two things compare equal but hash to different outputs.
In addition to what was already said (that UB is a fundamentally different class of issues than logic bugs, and one it's really worth not having), "reinventing the heap" is something basically all games do. That's needed when you don't have enough resources -- whether you have a limited amount of hardware sprites you can draw or you don't want to spend CPU time mixing 100 audio channels when 2 or 4 suffice. This is already described quite well in the blog about the keynote. You also want this on modern hardware because: * dynamic allocation (and deallocation) is still slow * you don't want your heap to get fragmented like crazy * you don't want to manually keep track of lifetimes So what most games do is use arenas, which are linear regions of memory that you allocate from at will and clear out all at once. You allocate everything you need for producing a frame, clear it when it's rendered, then start again. Arenas aren't heaps, they're special allocation patterns that work especially well when you have limited memory, long-running processes, or strict time budgets. Is that messy? Sure is, but then I imagine most game code is. Look at some Handmade Hero screencasts to see some code that bears no resemblance to what one might expect after reading articles about language features and best practices about how to use them. Of course, that's not to pick on Casey -- it's his intention and preference to write code like that because it's either throw-away, because conceptual purity matters less than being pragmatic, or because he is distrustful of the platforms he'll run the code on. It's not like the Visual Studio STL implementation is perfect, and I imagine that console ones are much worse, _if_ they are at all. --- Anyway, as I was saying, this isn't "reinventing the heap". but using a special allocation pattern that doesn't fit into the conceptual purity of `malloc` and `free`. It's a pattern that most game devs have arrived at, either independently, or because it's a common practice (it is). Rust does makes it hard to write code in the "sea of pointers" style that's common in e.g. Java, and nudges you towards object pools, arenas, or indices instead of pointers. But that's a well-established design pattern in game development, and the point of the keynote is that Rust _forces_ you to use the better design. In C++, if you don't learn it from someone else, you might spend a couple of months fighting memory leaks and random crashes until you arrive at it. Rust has the borrow checker, so you either figure that design on your own -- faster than in C++ because you can't spend time debugging crashes if you game doesn't run --, or you give up. And I believe that was one of the points the keynote was trying to make.
well, I'd like to see example of your code for definition "dick in your hand". I wasn't saying code shouldn't panicking on index out of bounds, you somehow forgot about it.
Yeah, sorry for dropping the ball on that. I didn't recall them, it was late, and I figured the post must be on GitHub, so I can just make a PR whenever.
What magic compiler tricks are you referring to?
Very detailed argument to the statement I wasn't even saying. Re-read my initial comment and you'll find that I'm talking about usage of get() instead of direct access EXACTLY to avoid "index out of bounds panicking" (which is pretty legit). If we have ability to avoid this kind of panicking, we should use it.
[removed]
Enums could be done away with in favor of structs. I can't think of a use case a struct couldnt cover over an enum. 
After spending a few days doing some particularly annoying refactoring... - Enums and structures should be unified (i.e: you can declare arbitrary nested sum and product types in a single type definition). Example: ``` struct A { a: enum { A, B }, b: u32 } ``` This also implies that anonymous enums and structures should be permitted too. (Note: what does this mean for pattern matching?) - `.lock()`ing a Mutex probably shouldn't return a `LockResult&lt;T, LockError`: it clouds code with misleading unwraps that aren't the original source of a panic. Better to just make `.lock()` panic, and then have another method to replace the original functionality. - I understand why Rusty's orphan rules exist, but that doesn't mean I can't hate them. - Inherent associated types seems like an obvious thing to have. Why are they not already a thing by default?
I would like a CLI/nurses file manager written in rust with concurrency. I have used ranger and vifm but those are both single thread and you have to wait if you are moving/copying large files. I am thinking to write one myself but I haven't started yet. There is a file manager already in rust but it isn't very usable.
This, so much
''' the special handling of auto traits (Send and Sync) ''' Because deriving `Send` and `Sync` manually would be a nightmare. In most programs you'd end up deriving them on virtually every type anyway, adding to the noise and the cognitive overhead of "oh that's another thing I have to remember".
You're right, you'd need trait objects to get to the common struct instances if you'd store them in the children directly. However, if you need to call several methods on common struct this will provide a performance benefit over calling each method via trait object. But in many situations this performance win might not be worth the refactoring. It is nonetheless good practice in any OOP language to try to abstract distinct functionality into its own class. This avoids incomprehensible, bloated classes. I'd generally advise against using OOP inheritance in Rust. The borrow checker will often force you to box, which is unnecessary when using other paradigms; you'll end up using a lot of dynamic dispatch, etc. It doesn't map well to the language.
You're kidding, right?
Type inference is allowed for `as` casts today already: `let a: u8 = -1i32 as _;`
Don’t take away my shadowing. It’s a great feature for both making code easier to read and codegen clearer. 
Well I like shadowing just not implicit shadowing. I do agree its needed for use crate::predlude::* functionality.
Not at all. The aliasing feature of an enum can be done with a struct. Theres a reason json has no enum support. 
Thats a good point and something I had not considered! 
Oooh I'd never realised you could fall into typed nil territory with that, this is fun.
I hate them but this site makes me want to keep them now
For the .lock thing, look into the antidote crate. Would be really nice if it was a function on the type itself though
How exactly you will write enum Result&lt;T, E&gt; { Ok(T), Err(E), } as struct without unnecessary overhead and with safe API? I bet you will write union ResultUnion&lt;T, E&gt; { ok: T, err: E, } struct Result&lt;T, E&gt; { value: ResultUnion&lt;T, E&gt;, which: u8, } And impl visitor pattern to access stored value and then add few more convenient methods. To implement niche filling you will need bunch of specializations. But asking user to write lot of unsafe code each time he want to make an enum is too much.
For noobs like me, could you give an example of different ways of assigning trait bounds? I think I only know the `where` syntax.
Json also has no integer and unsigned types, structs, lifetimes etc. How would you encode Option or any other ADT struct without a ton of runtime invariants?
Json doesn't have enum support because js doesn't have enums
JSON? Seriously? JSON doesn't have a type system in the Rust sense *at all*. It just has six types and they don't do anything. Here's a simple example of an enum: a cell of a linked list. The tail of the list can be (a) another linked list or (b) the end of the list. How would you implement that using structs?
I'm currently using `parking_lot`, which is a very refreshing experience. I presume antidote does a similar thing for `std` lock types?
That doesn’t make any sense. Json isn’t even typed in the first place. But in Rust, do tell how you’re supposed to use product types to emulate sum types? Those are orthogonal concepts. 
Use `get` method then. I usually have index that must be in bounds unless there is a bug.
I love Rust, but I think I would have preferred the community to have standardised on Allman form for the curly braces: i.e. this() { that() } instead of this { that() }
I'm not suggesting making `.lock()` on a `Mutex` require `&amp;mut self`. Obviously that would be ridiculous and would make any sort of effective concurrent programming impossible. What I am suggesting is a way to mark functions 'impure' (i.e: can't be arbitrarily reordered or elided) and for that impurity to be inherited by any callers of that function. This would be a practical way to enable these sorts of optimisations without requiring major changes to the language semantics.
I think they meant fn some_func&lt;T: SomeTrait&gt;(t: T) { vs fn some_func&lt;T&gt;(t: T) where T: SomeTrait {
Use `get` method then. I usually have index that must be in bounds unless there is a bug so I use `arr[index]` more often tgan get.
that's what I do.
&gt;&gt; Having structs and tuples and enum-structs and enum-tuples be almost entirely unrelated to each other seems like it should be improved &gt; This is on the ever-long todo list. Do you (or does anyone) know what the rough plan would be here? 
Doesn't removing turbofish introduce an ambiguity into the syntax? 
I don't 100% get why though. I tend to use the "inline" version `fn foo&lt;T: Tr&gt;()` when stuff is very short, and `when` when I want to put it on multiple lines. I guess this is more or less the same discussion and the argument position `impl Trait`?
I wouldn't call it "unsafe" because that has a very specific meaning in Rust, but I still kinda agree with you. Imagine this alternative reality: We use brackets for type parameters, and slices implement Fn(-like) traits so you can use `slice(1)` or `slice(1..2)` (omitting the `.get` but also inferring the return type as mut in cases like `slice(2).get_or_insert(42)`). Rust code would look very different! I love how small (imaginary) changes can have large (imaginary) impact.
Autoborrow. I got confused for ages that 'x &lt; y' will autoborrow, but 'x+y' can't (so I need &amp;x + &amp;y)
How is the latter with a visitor pattern (ugh?!) nicer than the former? And how does it even differ; i.e., why write a union AND a struct while you can write an enum?
A lot of panicless code would call `std::process::exit` or `abort` the moment it hits some code that it cannot sanely do error handling for. E.g. `let nums = [1, 2, 3]; let two = nums.get(1).unwrap_or_else(|_| abort());` everywhere.
All types using interior mutability *must* have an [`UnsafeCell`](https://doc.rust-lang.org/std/cell/struct.UnsafeCell.html) somewhere inside them, so the compiler is perfectly aware which referenced objects are truly 'immutable' and which ones are merely pretending to be. LLVM can detect purity of functions during compilation (for its own definition of purity) and use this information when optimizing.
As far as I understand, being `mut` only gives you the capability of taking an exclusive reference on an object. The issue, again as I understand, is that the two kinds of references in Rust are called "shared" and "mutable", but it is more honestly "shared" and "exclusive". Having a shared reference *typically* means the referend is immutable, but that is only the default property. Depending on the type of the referend, it could mean something weaker as long as it's still memory-safe to share references. `Cell` is the primary example of this. 
"this clicked in my head instantly" -- no Rust programmer, ever. I haven't looked at your code, so I can't discuss your architecture. Maybe some other Rustaceans will look it over. But I can tell you that I struggled for at least a year to 'get' Rust. I actually gave it up many times, but always the siren song of Fearless Concurrency brought me back. I'm pretty comfortable with Rust now, but the borrow checker still trips me up from time to time! Rust is a tough, uphill climb, but the view is worth it. 
Does this bubble up as a qualifier on the function signature? Or does the compiler have to walk the call tree down to discover any hidden impurity ugliness?
CamelCase with any abbreviations looks like that infuriating SpongeBob meme.
`ManuallyDrop` is no longer an union, but a lang item. This actually simplifies *a lot*. `MaybeUninit` would be an union.
The LLVM IR has a couple of [attributes](https://llvm.org/docs/LangRef.html#function-attributes) like `readnone`, `readonly` and `argmemonly`. They're not exactly `pure`, but it's pretty similar to what you want for. These attributes can be propagated by an analysis pass (and I imagine they are). Of course, that's LLVM-only and it's not a way to mark functions as pure, as a contract for the caller, but probably gets the job done most of the time.
&gt; Inherent associated types seems like an obvious thing to have. Why are they not already a thing by default? I actually went and tried to solve that only to run into a wall of "this is blocked by a bigger refactoring of the compiler". Someday though. Also, that's an addition, not a removal. &gt; I feel like Try should be implemented for (). That way, we can use ? to return from functions with no return type when errors occur. Given my propensity to forget to change the signature to actually return a result when using `?`, this would mostly bite me. Also, not a removal from the language.
this idea looks really attractive to me.
&gt; One thing I found odd though is how counter intuitive the solution provide was, it did not feel clean like code written in other languages often can. It's worth noting that the fastest game engines have been using entity-component based code architecture for almost two decades.
Ick, no thank you. You do you, but for me the former causes my mental parser to backtrack briefly when it realises it's in a new scope.
I'd call them a removal of relatively arbitrary rules, even if they're not a removal in terms of what is considered syntactically valid.
[Yes]((https://rust.godbolt.org/z/5TQvu6)), LLVM can annotate the functions and functions that don't do anything impure and only call other pure functions are themselves pure. I think it would be better if you would produce an example (on rust.godbolt.org) where compiling with `-O3` *fails* to optimize something that you would expect to optimize, instead of voicing theoretical concerns. A confused compiler might look like [this](https://rust.godbolt.org/z/_j0WNH). Now you produce an example based on your concerns about (inner) mutability.
Hmm. I feel like this is something to consider for MIR, if it has not already been done. Thanks for your really useful points :) regardless, I still see this as a problem since lack of purity qualifiers can also make life difficult for Rust-level compile-time evaluation, and also goes against the aforementioned intuition of what immutability "should" mean in practice.
Amen to that.
Rust has always had an emphasis on "immutability", but for pragmatic reasons rather than ideological ones. When you write C code, where everything looks mutable, the compiler has to do analyses to determine what is actually unchanging for optimization sake. So, there have always been mechanisms for interior mutability and shallow immutability and I attribute this in no small part to the Rust compiler using LLVM which is similar in that respect. What the Rust language calls immutable and mutable, I think would be better described as shared and exclusive access and maybe it would, except that the Rust language has evolved over time and it did start out with a stricter notion of immutability and also purity.
&gt; So I am not really sure what the best course of action is. I guess that's why I'm on the "keep both" camp. I use both in different cases... Maybe `rls` should support refactoring them on a per-bound basis from one place to the other! :D
I'll give it a go.
What if the very fact that you would have had an index out of bounds means *there is no valid way to continue execution*? That is the point that everyone is making and you are densely ignoring completely.
no, I'm not arguing with it. I'm arguing that "panicking is a normal way to return errors, because there's catch_unwind". Panicking should be literally panicking, and index out of bounds is such case.
Indexing should be parens. That free's up square braces for types and kills turbofish... it's one thing scala got right.
I see `!` (and relatedly `#[]`) as markers saying "The meaning of what follows is dependent upon the name. I see generics as saying "This can be parameterized over any type that has this interface". These are not reconcilable definitions. The semantics are entirely different. &gt; we can solve this issue by allowing an optional extra parenthesis that means that it takes parameters and outputs something. `x(y)(z)` is already valid today as a function that returns a closure tat is immediately invoked. &gt; But where clauses are not inherent to generics, and impl types prove that. Generics only take type parameters (atm) and they can, uniquely, infer those parameters based on use. `impl Trait` in argument position is basically an anonymous generic. In return position, it isn't inferred, but rather unified based on the types actually in return position, so generics aren't really in play there. So, like, I'm either missing the point badly, or this is actually false. &gt; Parsing can be done in a none confusing manner for the parser. Humans, on the other hand, may find it hard sometimes. Turbofish solves ambiguous parsing. Turbofish keeps Rust as an LL-1 grammar or whatever it's called where backtracking isn't required. Well, except for raw strings, but that's required to have them accept any arbitrary string.
&gt; One thing I found odd though is how counter intuitive the solution provide was, it did not feel clean like code written in other languages often can. There are some comments about that keynote in a [sibling thread](https://www.reddit.com/r/rust/comments/9h4k7i/a_reference_by_any_other_name/). As /u/anttirt mentions, ECS is a very common design pattern in games.
We have a standard at work to mark every variable final in Java unless it cannot be. This is a bit annoying, but it instantly tells you where the suspicious complex variabe logic is and I find it worthwhile. Rust just choses the less verbose version, and I like that.
Function overloading means yet another lookup rule in method call syntax and has the same problems w.r.t. specializing trait impls. They also mess up type inference.
Totally agree with this one. `as` is... fine. But iy always seems outbof place when I encounter it.
I think you need to tell the compiler that the argument will outlive the function. https://play.rust-lang.org/?gist=52fea3bcb7aba19b627694338c1794b9&amp;version=stable&amp;mode=debug&amp;edition=2015
Yes, one of users tried to prove that invalid phone number is a reason to panicking when reading user input :) Just as example. People are different.
&gt; it did not feel clean like code written in other languages Different languages have better support for different idioms. Even though Rust looks like your everyday OOP language (it has methods, `struct`, and so on), it is not an OOP based language. The initial shock I got with the borrow checker was basically this. I was trying to write C# like code, and if Rust was Java it would've worked fine. The thing is, when you look at a functional programming language, for example, you clearly see that the OOP code won't fly, but when you look at Rust this distinction is not so clear, as Rust syntax kinda seems like your traditional OOP language (and Rust does support OOP, but it gets kinda ugly). Most common languages don't care that you're potentially introducing data races by having mutable references everywhere, they'll only get to you at runtime (and only if you use multiple threads). &gt; method calls another with a reference to self passing self While you're learning and exploring, I would suggest that you try to write it as just a function and call [`clone` ](https://doc.rust-lang.org/std/clone/trait.Clone.html) to avoid borrowing, until you feel more comfortable with Rust idioms. Forget a little bit about your diagram and try to code small bits of functionality towards your end goal of having an HTPP snake game. 
Well in some applications that might be a valid reason to panic while in others it might not. Just like in some applications it might be valid to panic on an out of bounds lookup into an array while in others it would not. In any case, that user didn’t try to prove that panicking was a good way of returning an error, they were trying to prove that their might be a situation in which an invalid phone number would mean an irrecoverable state. 
&gt; "this clicked in my head instantly" -- no Rust programmer, ever. Literally. I even wrote my own Rust-like language before I found Rust, and it *still* took me months to learn to use Rust effectively.
Everything-is-an-expression
 no, it can't be a valid reason to panic. When you parse something you by definition checking if your input is valid, otherwise parsing wouldn't be needed. So parser should always return error in case of invalid input, not panic. 
&gt; or go the way of Scala's var and val I think that making `mut` explicit and additional is actually a good thing. This way the language encourages you to use immutable values by default.
That also assumes that the value referenced by foo[3] is referenced nowhere else, which isn't guaranteed in a GC collected language.
Wow! I did not know loops could evaluate to an expression. I've always been told to avoid using break and continue if you can help it though, so I guess I'm not likely to use it.
&gt; Lack of function overload(as consequence there is no function with variable number of arguments) It is just my opinion, but I think that fully-featured function overloading is too error-prone. If a function does different things when called with different input types, it is actually several unrelated functions and thus should not share the same name. If a function does similar things when called with different types of input, it means that it should rather be a generic function with trait bounds which clearly shows that a function has similar logic for constrained types.
Tuple struct visibility modifiers on every tuple element. The visibility of all tuple fields should have been equal to the visibility of the tuple struct itself. I'm willing to make a concession where you have a single visibility modifier for all the fields separate from the visibility modifier on the tuple struct. In general, I really like how Rust has stability modifiers and puts such a huge effort in managing and maintaining them. I really wish the rest of the world had such an awesome stability story as Rust. Imagine the browsers / C++ vendors only implementing strictly what the standard says and you can unlock all the platform specific stuff if you 1. download and install a separate nightly version and 2. require you to declare all the unstable features used. This means there's far less to complain about that should never have been in Stable Rust.
Also: - Vec -&gt; Vector - &amp;str -&gt; &amp;string (like Path) - String -&gt; StringBuf (like PathBuf)
I'd hate typing 'mutable' or 'dynamic' or 'RefCount'. Long keywords are noise. Non-native English speakers might prefer shorter keywords because long words are harder to remember, easier to make mistakes in.
 let _ = foo(); and let _bar = foo(); has totally different meanings: the second one binds the returned value to `_bar` and thus the value is kept until `_bar` goes out of scope while the first one introduces no binding thus dropping the returned value _immediately_.
You missubed.
&gt; I still see this as a problem since lack of purity qualifiers can make life difficult for Rust-level compile-time evaluation "Pure" doesn't mean "can be evaluated at compile-time" and `miri` seems to be doing [quite fine](https://github.com/rust-lang/rust/pull/53804) without this (in that it's finding really non-obvious bugs). &gt; also goes against the aforementioned intuition of what immutability "should" mean in practice That intuition probably depends on your background. If you come from C, you might expect `const` to offer rather weak guarantees; if you come from C#, you know that `readonly` is "read-only after construction". And so on.
Having dynamic dispatch as part of the syntax. Why can't `dyn` just be a normal trait like `Dyn&lt;Foo&gt;`? But at least we now have the `dyn` keyword which is a huge improvement over how things used to be.
You can get rid of structs with enums (e.g. `enum Foo { Bar(u8) }` isomorphic `struct Bar(u8);` up to namespacing concerns), but not the reverse.
Congratulations on your hash map. I haven't given the code a thorough look at yet, I plan to this weekend, so excuse me if I'm mistaken. Having given it a quick look it seems you don't do memory reclamation - have you thought about how you might do it?
Nah, not this time, anyway. I occasionally read/post to other subs as well... 
&gt;I got into a genuine internet slapfight &amp;#x200B; OK, where's the video? We all HAVE to see this!
&gt; I did not know loops could evaluate to an expression. It's a mildly recent addition: https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1190-2017-07-20
I think s/he was looking for an opinion more than docs.......
What the shell! Wonderful
Out of curiosity, does implementing `remove` introduce some different "gotchas" in terms of thread safety that `add` does not?
Yes, in Rust I would agree. In the world of the JVM where everything is indeterministically dependent on the whims of HotSpot and GC, predictable performance doesn't carry the same weight. Coming from Java to Scala it's just very nice to finally get rid of all of Java's API inconsistencies.
`Some` is really just a function that takes one an argument and returns an `Option`. The reason why you write `(())` and not just `()` is because like with any function you can't omit it. The reason why it's not `break (())` is because `break` is not a function. It's a special keyword which can be followed by an expression (e.g. `()`), which is unlike `Some`, where the outer `()` is not an expression but rather signifies a function call.
Here is you problem: the snake is OO. Make it non-OO. To say it in a single sentence: separate functions that modify snake (and other world objects) from these objects. In good OO, we would call such objects PDO (plain data objects) or simply _structs_. Then the functions that mutate the world would be _systems_. On every world update, a bunch of systems (that we would run sequentially, each taking a mutable reference to world), would look at latest user input and modify world objects based on that. Other systems would simply advance the world forward if there was no user input. Limit the functions on the structs themselves only to helpers that help set and get the values, and you will find this to be much more straightforward way to develop the game, even in non-Rust projects.
Sure, I think some people - while usually well-intentioned - try to change culture too quickly, and then sometimes get really toxic about it and they forget about their original goals and start to play blame games instead. Where I *disagree*, however, is in that the Rust community displays this trait. I do not believe it does. The governance and culture has been overwhelmingly pleasant and successful, IMO
It's not like someone implemented it to torture you. It's there *for a reason*. Rust could not function without it.
[removed]
That's not exactly the same when dealing with multiple arguments, though. For example: fn some_func(t: impl SomeTrait, u: impl SomeTrait) { vs fn some_func&lt;T: SomeTrait&gt;(t: T, u: T) { The first one can take in two *different* types that both implement `SomeTrait`, whereas in the second both parameters must be the same type.
Pretty sure I never suggested Rust should be a purely functional language.
It isn't. I'm dealing with visitors currently and I'm missing my ADTs. Quite a painful design pattern
It takes time. I suspect it should be easier for **experienced** C++ developers. But if you worked only with GCed languages before or just entry C++ level you'll have a hard time for couple of month before you figure it out. There is no instant "click" happening. You gradually get experience in implementing design patterns in Rust way. Just don't give up. Take a break if you need - revisit later. You don't enjoy strict languages when you prototype - you enjoy them later when you refactor and your program works flawlessly with no leaks or crashes.
So you have here a list of 15 things and not one of them a concrete suggestion for what would be better than the current solution. By default this discussion was pretty useless to begin with, because due to the commitment to backwards compatibility we don't really want to remove any features unless there's a very good reason to do so. But if this post were only useless, I'd just downvote it and move on. But your post is not just useless, you're actively breeding dissatisfaction with rust, which would *still* be ok if you had valid criticisms about actual issues, but no, literally all of your criticisms are in the form of "I don't really use or even understand feature X, and I have absolutely no idea about how it could be done better, but I'm still unhappy about it, and it "should be improved", but no idea how though". It's been a pretty long time since I've gotten as irrationally angry at a reddit post as this one...
Yeah I know, I do it from time to time, but I don’t really agree that it makes it clearer. :)
I don't really understand the .lock thing. How would you replace it? With a .tryLock()?
Why isn't it allowed to call struct's method using turbofish syntax? And, if I try, the error is misleading: it says the method is not found. But I would like to specify that it is a method implemented on a struct itself, not some trait method. Here is a simplified version: struct Foo; mod foo_impl { impl super::Foo { pub fn foo() {} // If you don't put pub here, trait impl below will recurse } } trait FooTrait { fn foo(); } impl FooTrait for Foo { fn foo() { Self::foo() // &lt;Self as Foo&gt;::foo() doesn't compile: foo not found in Foo } } The version that does compile looks like it would recurse when you look only at trait implementation, which is why I would like to be specific.
If you have the time, check out these two podcast episodes with Jim Blandy: https://corecursive.com/013-rust-and-bitter-c-developers-with-jim-blandy/ https://corecursive.com/016-moves-and-borrowing-in-rust-with-jim-blandy/ 
 We are not “rewriting the browser”. That's impossible. Put down the gun. Heh
https://docs.rs/lock_api/0.1.3/lock_api/struct.Mutex.html#method.lock
&gt; In Scala, indexing is a function call It may sound superficial, but the use of parenthesis for indexes was one of the biggest things I hated about Scala. Syntax is important. You see a square bracket and it implies what it's there for, and this is super common too. That's useful.
The float Eq and Ord thing, while I understand the argument, is really annoying.
only part of the css engine and some parsers :ff
Use `mut` when you want to change the value of the variable. This works: let mut a = 5; a = 10; This doesn't: let a = 5; a = 10; // compiler says nope
I believe OOP experiences are actually hurting people to understand the so-called "data-oriented design". I had some (off topic) interesting experience: Every time someone ask me to teach them game programming, I always tell them to write snake and Tetris. If they come from an OOP background, the design are always more of the same: * Snake, foods, and obstacles are three different classes * Each type of tetris are different classes, or a class with different "type" attribute. then, it's usually a giant mess to: * extend the snake every time it ate a food. * constantly update Tetris position and a weird check to clear rows. After that, I show them the classic data-oriented design: use an 2d int array to represent the whole snake/tetris game board. Everything else is data-specific updating logic. And then, they started to think with data-oriented design.
Sure, but it's a lot easier to forget the turbofish than it is to put an underscore after `as`.
Something like C++ like variadic templates though would be less error-prone
So I tried this `println!(r#"cargo:rustc-cfg=features="backend-dx12""#)` and it doesn't give me any errors, but it also doesn't work. I found this issue while searching [Issue #5499](https://github.com/rust-lang/cargo/issues/5499) which looks like the issues is that adding that rust flag only adds it to `rustc` and doesn't actually add it as a feature in cargo. _Alex Crichton_ says it is expected behavior for features to **not** be changeable from the `build.rs`.
Wow, I didn't notice that. Can you point me at some reasoning behind that?
Check out the language forum thread here: https://internals.rust-lang.org/t/pre-rfc-unions-drop-types-and-manuallydrop/8025
This reminds me of something I was playing with this morning (I'm new to rust too). So the borrow checker errors on this code (it passes in the 2018 ed, btw): self.set_nz_reg(self.mem[X_REG]); This, however, is perfectly fine: let r = self.mem[X_REG]; self.set_nz_reg(r); So i can't retrieve the value from `self.mem[X_REG]` and pass the value to this method unless I store it in a temporary variable first? I realize this gets optimized away, but it adds verbosity and I think it hurts readability. So next I wrote a function, which i don't know what you call it. It's in the struct's implementation block, but not a method. Kind of works like a C++ friend function or static method to me. self.status = CPU::calc_nz_reg(self.status, self.mem[X_REG]); It's a little more verbose, but I think more readable than the temporary variable version. Performance isn't super critical here, (it's just a 6502 emulator I'm doing as something to help me learn Rust), but I did wonder if there would be a performance hit. As it turns out both versions produce exactly the same optimized code. I would classify the first attempt using a temporary variable to be a work-around, and I don't like it. Is the final version a work-around? To me it just feels like a more correct way to do it in Rust, but maybe there is an even better solution. Anyway, the hardest thing about Rust for me is learning not to think about solutions the way I do in C++.
I have this setup for my current `gfx-hal` project, and I works, though its a simple project so far with only a handful of dependencies but I think it will be sustainable. The plan was to make a docker image that could build both Linux &amp; Windows binaries so I could just have `travis-ci` build it when I push the right tags to the repo. I haven't setup that part yet as its pretty much a hello world right now (getting the backend to work) Before I used `gfx-hal` i was playing around with `sdl2` and that crate required to compile the library in C, so that would need setting up the same imports and sources on the linux version as you would on the windows (sdl2 lets you build it a number of ways so I op'd for an already compiled version and [followed this guide](https://github.com/Rust-SDL2/rust-sdl2#windows-with-build-script) to make it work on my linux cross-compile). **In Short** I feel its pretty manageable but I would try and stick with as many Pure Rust crates as possible, this will not only make Linux-&gt;Win compiling easier but also make other platforms easier to build for (like mobile in my case). **How I did it?** I just made a file in my project root `.cargo/config` with this content `[target.x86_64-pc-windows-gnu]` `linker = "x86_64-w64-mingw32-gcc"` `ar = "x86_64-w64-mingw32-gcc-ar"` and then installed mingw32 for ubuntu `sudo apt update &amp;&amp; sudo apt install mingw-w64` and added the target for rust `rust add stable-x86_64-pc-windows-gnu` Then finally I just added another line in my build script to build it `cargo build --target=x86_64-pc-windows-gnu` [This issue was helpful for me setting it up.](https://github.com/rust-lang/rust/issues/32859)
Depends on the app? I actually just found [Gutenberg](https://www.getgutenberg.io/) but I just opted to installed the binary and add it to my path. If you were to build from source you'd have to `cargo build --release` and then add the binary in `target/release` into your path
"crashes are better than logic errors" seems like a false choice. Like you say, 'crashes' in this day and age mean UB and that is a horrible can of worms. With logic errors it's hard to tell at all if something is wrong. I've been there in the C++ side of things where I thought crashes were great... until it kept crashing on my clients' machines, they have a different perspective on these things. So I wrapped it in a `try catch (...)` and suppress those pesky access violations due to subtle race conditions :) But why choose? The point of the generational indices is that you can catch these logic errors and turn them into panics if you wish. The concepts are still very simple, anyone could program this without specialized knowledge so just write it. With Rust I've come to see the light and take these issues more serious. Rust makes you care about these issues (at gunpoint, sure) and at the same time offers alternative ways to achieve your goals. It does take time to adjust to a new way of thinking however. This isn't a critique of your post as much as it is a critique of Blow's arguments, I just started writing and this came out :)
Hi, The Arch Linux Maintainer of Alacritty here. That's why we ship only official releases in our official repositories. NixOS just shipped specific checkouts of the git repository.
terminal.sexy supports alacritty as well: https://terminal.sexy/
I agree with your sentiment. I haven't had the pleasure of doing any 2018 Rust yet, but it seemed like some of the "ergonomics" work was adding these kinds of special cases. But I much rather the language be smaller and consistent than introduce inconsistency for small syntactic sugar gains. Even the lexical lifetimes thing gave me mixed feelings. If `if` is an expression, then it *should* be like every other expression- you can't take multiple mutable references within it. But, since we *know* that the `if` and the `else` will never both run, the compiler is just smarter to know that `if` is special.
I always thought the same thing. Except I disagree about `mut`, `val`, and `var`. I freakin' *hate* `val` and `var` because they look so similar. Swift does `let` and `var` which is better. But I think `let mut` is perfectly nice. Here are some that I thought were ridiculous when I started with rust: * `fn` -&gt; `func` * `u8` -&gt; `uint8` (Would a programmer who hasn't done C/C++ just "know" that "u" means "unsigned integer"?) * `Vec` -&gt; `Vector`
&gt; Nice, I recently alacritty-git [Insert *accidentally 89MB* joke here]
I like your edit and mirrors my understanding of the situation. TL;DR: West makes a keynote about how Rust (notably the borrow checker) pushed her towards a good design for her problem of organizing game state. Blow argues that the borrow checker doesn't solve her problem (missing the point of being pushed towards a good design). The community reacts to Blow by (not incorrectly, mind you) pointing out that logic errors are better than UB. The fix is known (use generational indices) but the lines are drawn and everyone seems to make arguments without fully understanding the position of the other. Everyone is 'correct' from their perspective and misses the point the other is trying to make. Except for a few people of course :P
&gt; I've always been told to avoid using break and continue if you can help it though Where? In university? Do whatever makes your code most readable.
&gt; Partially mutable tuple structs. Why would you want that ever? Could you elaborate? What is a partially mutable tulpe struct?
Tho I do not agree we should remove them, as they are certainly different, the naming sure is _very_ ambiguous!
You just reinvented HOCON @ https://github.com/lightbend/config/blob/master/HOCON.md . Which is great, actually, I was very much looking forward to having HOCON in Rust, still wish it'd be exactly HOCON because then you could reuse config files from Java apps and not teach the Ops subtle differences.
What actually happens here is an optimization called "load forwarding": ``` int *x = malloc(sizeof(int)); *x = 3; return *x; // can optimize to "return 3" ``` If a load is right after a store, we *know* the value in there, so we don't have to go to memory. Now things get interesting if there is stuff happening between the store and the load. As long as that "stuff" cannot change the value of `x`, the optimization still happens: ``` int foo = 8; int *x = malloc(sizeof(int)); *x = 3; foo = 16; // cannot change *x return *x; // can optimize to "return 3" ``` In the example above, the "stuff" in between is `*(int *)(yi - 96) = 7;`, which the compiler concludes cannot change `x` because `x`'s address was not involved in computing this pointer. So the `*x` later is optimized to `3`. That's what happens in the compiler to explain the behavior we are seeing. But another way to put it is that a C program runs in some kind of ["abstract machine"](https://www.ralfj.de/blog/2017/06/06/MIR-semantics.html) that works very different from a real CPU, where pointers are far more than an integer, and where the write `*(int *)(yi - 96) = 7;` is determined to have undefined behavior. This is why the compiler is *allowed* to do what it does.
Generally speaking, adding to some concurrent collection is easier in the absence of concurrent removes. In the world of concurrent hash maps a lot of space in academic papers is spent dedicated to *proving* (really just arguing) the safety/correctness of concurrent operations. Some examples are [Maged Michael's lock-free separate chaining](http://www.liblfds.org/downloads/white%20papers/%5BHash%5D%20-%20%5BMichael%5D%20-%20High%20Performance%20Dynamic%20Lock-Free%20Hash%20Tables%20and%20List-Based%20Sets.pdf), [Split-Ordered Lists](http://people.csail.mit.edu/shanir/publications/Split-Ordered_Lists.pdf), [Wait-Free Hash Map](https://rd.springer.com/content/pdf/10.1007%2Fs10766-015-0376-3.pdf) (this one is similar to Ticki's and OPs if I understand correctly), and [Hopscotch Hashing](http://mcg.cs.tau.ac.il/papers/disc2008-hopscotch.pdf). Having been personally spent a lot of time involved implementing these algorithms I can say the bulk of the problems are due to concurrent adds and removes. &amp;#x200B; To be more formal, removing an entry from a collections means the remover must recycle the memory used to hold the entry. In Maged Michael's case one must recycle the list node, the same for split ordered lists and the Wait-Free Hash Map. The problem with the aforementioned data-structures is that in order to increase speed they allow for what's referred to as *invisible reads*. This means that readers do not leave a trace in the data-structure as they traverse it, making it really really fast. The problem is - When is it safe to call "delete" on a removed entry? This is called the *memory reclamation problem*. &amp;#x200B; Memory reclamation has been tackled in many different ways. There's pointer based schemes like [Hazard Pointers](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.395.378&amp;rep=rep1&amp;type=pdf), [Hazard Eras](https://github.com/pramalhe/ConcurrencyFreaks/blob/master/papers/hazarderas-2017.pdf), and [Cadence](https://infoscience.epfl.ch/record/218413/files/qsense-techrep.pdf). Your typical reference counting algorithms. Epoch based reclamation, like the [original](https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-579.pdf), [crossbeam](https://github.com/crossbeam-rs/crossbeam), [Debra+](http://www.cs.utoronto.ca/~tabrown/debra/fullpaper.pdf). And finally you have hybrid methods like [Qsense](https://infoscience.epfl.ch/record/218413/files/qsense-techrep.pdf), [Threadscan](http://web.mit.edu/willtor/www/res/threadscan-spaa-15.pdf) and [Forkscan](https://people.inf.ethz.ch/aldan/papers/forkscan.pdf). Threads reading aren't the only issue in using `remove`, other threads calling `add` or `remove` often run into the [ABA problem](https://en.wikipedia.org/wiki/ABA_problem) without memory reclamation. For instance the naive [stack implementation](https://en.wikipedia.org/wiki/ABA_problem#Examples) in the ABA Wikipedia entry works perfectly without pop, which is remove in this case. &amp;#x200B; Reading back over what I've written it seems I went off on a small rant but without `remove` a lot of these memory reclamation problems just disappear. If any of this is unclear let me know, I haven't articulated this thought very well.
I Disagree. That would be getting a little bit too much like C++ where, parenthesis do far too much stuff as an operator.
Having a linked list in the standard library imo serves two purposes. A) It presents an implementation of a linked list that people can examine and B) it provided good documentation as to why you dont want a linked list
We've used and are using HOCON in production extensively. The best features we love about it is reusing objects and time/size types: default-http-settings = { connect-timeout = 50ms read-timeout = 50ms } microservice-a-client = { http-settings = ${default-http-settings} { connect-timeout = 500ms } } We also use includes, yeah, to remove security-sensitive settings like passwords from the general config file, so you could give the production general file to developers or testers without sanitising it first. API-wise, we love how you can chain config files, use fallbacks. I haven't yet looked at your API though.
You should check out the [specs](https://github.com/slide-rs/specs) library. ECS isn't taught in schools, so few people outside the game industry are familiar with it. It's initially a bit complex to set up when you're not familiar with them, but afterwards it's pretty simple to expand and maintain. It's useful in systems software, too, as I've been using it to create a disk management library. In your case, `Game` would be your `World`. `spawn_food` and `new_game` would be `System`s that you apply to the world. `Snake`s would be entities, whereas `Point`s and optional fields of a `Snake` would be components. - A world contains a collection of storages -- one for each component. They need to be registered when you initialize your world. - Entities are akin to structures whose fields can be dynamically removed and added. - Resources are like global variables, specific to that world. - Systems that act upon the world define the storages and resources that they will use, and how they'll access them. Entities are also a type of resource. The storages in specs can be used in a join to filter out incompatible entities with the search. Systems may also define dependencies on other systems, so that they may be run in parallel if they're evoked through the dispatcher. Though they may be called manually.
That's fair. I personally find the spew of `[dependency.*]` sections much harder to navigate, as I normally only care about the names of dependencies (and only when something goes wrong do I need to put that little bit more effort into comparing details), but I can see why someone might prefer to have the details of each dependency exposed more obviously.
Parsing C++ requires calculating *semantic* information about previous code to know whether something is a type or value. The proposal in that RFC is *much* simpler and less nasty: it will try to parse as a type, and if that fails it’ll switch to parsing as a value. There’s no feedback from semantic information. So if you write `a&lt;b,c&gt;(d)`, it’ll assume you meant a generic; if it turns out a,b,c,d are all variables, too bad, it won’t compile until you add parentheses to disambiguate – e.g. `(a&lt;b),c&gt;(d)`. The parser would have to go through some sequences of tokens multiple times to try to parse them two different ways, but in realistic code, only for rather short sequences, and only occasionally. As described in the RFC, a prototype implementation has actually been benchmarked, and it did not measurably increase parse times. You mention a few languages, but part of the impetus for this proposal was someone pointing out that Kotlin already works this way: using &lt;&gt; for generics, allowing them in expressions without special notation, disambiguating by statically preferring the generics interpretation. I think Swift – another newer language – does something similar, although I’m not sure of the details. 
I'm hoping this will allow us to do something like: ``` #[cfg(feature = "1_0")] extern crate foo1_0 as foo; #[cfg(feature = "1_1")] extern crate foo1_1 as foo; ``` This would help a lot with a crate I'm working on
AFAIK, Rust has had minor breaking changes before, so this is not a new thing. But it doesn’t hurt trying to bring the issue to light, I guess. In my opinion, taking such a strict approach to backwards compatibility only hurts the language and its users in the long run, and does no good. I don't think it's worth making such a fuss over code like `if let false = foo &amp;&amp; bar`, because I don't think anyone has written that before the RFC discussion. Someone in TC39 has written there that they've found out there's a bit of wiggle room wrt. breaking changes, and I think that's a wise lesson to learn. Even C++ has had a lot of breaking changes before, in code that was much more plausible than `if let false = foo &amp;&amp; bar`. C# had breaking changes. Java had (minor) breaking changes. Legal systems everywhere have that bit of that wiggle room. It seems to me that "no breaking changes, ever" is just trying to tick a check box. I agree it's desirable, and backwards compatibility should always be a concern. But I don't think anyone is trying to dismiss it without the due process. You seem to be very upset about these changes, but please try to think at the bigger picture, instead of considering only the rule from above. Rust remains the same language, with the same values as before. Some never-uttered-before code might break, probably with a trivial and easy to automate fix.
I think styles that add ritualistic white space are very broadly a bad idea, because they make the white space that you actually need for code clarity more difficult to discern. White space can be an important part of the communication between the human reader and writer, even if the compiler is indifferent.
The current `core` lib has no IO at all, no allocation, no random number generation (so there's no `HashMap` even in `alloc`). These can't be added without OS requirements, which obstructs portability. However, desktop platforms have all this stuff so *most* programmers want it in their `std` lib — i.e. there needs to be two different cases. Okay, one could use `cfg` to enable bits instead. And one could cut down `std` a little. But fundamentally it's the same picture.
UB is an arbitrary concept. There are things that are UB in C, but logic bugs in Rust. They're all logic bugs, it's just the level of consequence, and it depends on what your language happens to define standard behavior for. My point about inventing your own heap was fairly specific. I wasn't talking about custom allocators, since those still work with normal references. I also said that there are good reasons for using indexes instead of references. What I am saying though is that using indexes instead of references just to avoid the borrow checker is an anti-pattern. Are there good patterns that use indexes? yes. Are all patterns that use indexes good? no, oh god no. Running away from the borrow checker and just using indexes so you can still have your "sea of ~~pointers~~indexes" isn't helping anybody. You can still have your couple of months of memory leaks and random crashes. When a user gets to a point where they feel like they can't get the borrow checker to work with their design, they could switch to a better design, or they could switch to a terrible one. My suggestion would be that Rust provide some guidance for those in that situation, and specifically warn them to *not* use indexes. For the use cases, like games, where a handle/index based approach makes sense, standard implementations of common good patterns (like generational indexes) could be pointed to. 
I am using a technique I called "incinerator". Every thread has a local queue of deletion. Also, there is a global state that counts threads executing sensitive code. A thread only deletes its local queue after checking the global state, otherwise, garbage is added to the queue without deleting.
Indexing is already a function call in rust, via the `Index` and `IndexMut` traits.
In short: `Some(42)` -&gt; `Some(())` `break 42` -&gt; `break ()` 
&gt;A thread only deletes its local queue after checking the global state Nice, sounds like some variant of epoch. Is that in the codebase currently pushed online?
If we have to go there: - Pattern matching. It's very convenient, but there are *so many* complexities involved, and the number of tweaks since 1.0 says this feature set wasn't ready for stabilisation at the time. On the other hand, there are several features I feel are sorely missed: - Macros 2.0 - multi-trait objects - reborrowing for user types (with required HKT features)
Have you looked at [‘crossbeam-epoch’](https://github.com/crossbeam-rs/crossbeam-epoch)? This crate provides Epoch-based garbage collection, which sounds a lot like the things you were describing.
Yeah that seems like a decent option. I do like /u/CAD1997's idea of having a singular flat struct. But I still need something like an enum to identify individual buffs. So going this way might be a simpler middle ground.
You're probably right about that. I like the explicitness of it but acknowledge that `let mutable` might get onerous. Maybe it should be so to keep people from using it? Hehe.
Text and TextBuf
I have https://github.com/Keats/scl/issues/4 for time interval type but it is kinda tricky since not all languages have a duration type in their std. In Rust I could use https://doc.rust-lang.org/nightly/core/time/struct.Duration.html but you would need to add the `time` crate to use it meaningfully, or I could package the `time::Duration` type in SCL but that adds Rust-specific bits to the parser. &gt; reusing objects Interesting. Although I think I would probably add it differently from your example if I add it though: default-http-settings = { connect-timeout = 50ms, read-timeout = 50ms, } microservice-a-client = { http-settings = ${default-http-settings}, http-settings.connect-timeout = 500ms } SCL has no much code yet so not much API! Only a very basic parser so far.
Great, thank you. I'll check this out at the weekend.
If a C++ compiler "ate you alive" for doing super common UB like use after free, people would stop using it. As Blow said in his video, use after free in C++ is going to get you stale data, garbage data, or a crash. Use after free with indexes gets you versions of all 3. Maybe it's not as bad, but even if it's only 50% as bad, I don't see how you can call that good design. The talk claimed that Rust pushes you towards good design, and the example they gave was the borrow checker leading to using indexes instead of references. Indexes instead of references is a bad idea. Generational indexes are a good idea, but nothing in Rust pushed them to do it that way, they just knew to do it.
&gt;If there is an empty table, it cannot be removed in concurrent context. Yeah, that is a particularly difficult problem. In the published [Wait-Free Hash Map](https://rd.springer.com/content/pdf/10.1007%2Fs10766-015-0376-3.pdf) the authors do not deal with the shrinking problem. I suspect doing it without the use of some [multi-word CAS](https://www.cl.cam.ac.uk/research/srg/netos/papers/2002-casn.pdf) it would be very difficult.
&gt; Code that generates code from some other source, either in `build.rs` Just nitpicking, but of course code generated by `build.rs` is tested.
We don't; 
Just to make sure people aren't confused, this is actually parsed as ((x--) &gt; 0), and is just the standard decrement and &gt; operators.
Yeah, it's definitely isn't a deal breaker. I just prefer 80 char lines and descriptive variable names and snake case makes it difficult. Just a peeve more than anything.
That certainly. I was more hinting towards things like `bindgen` that are used *from* `build.rs`. If it can generate code like that that would have to be currently exercised by someone for breakage to show up.
Im not well versed in the idea of editions, but wouldnt it be a rust 2.0 update, and therefore semver dictates possible breaking changes?
An edition can do breaking changes, because you opt-in to the new syntax on a per-crate basis. And you would opt-in to the 2018 edition as a whole. This is about breaking backwards compatibility *outside* of editions, in normal minor releases.
Where should I put the link?
[Here you go.](https://www.youtube.com/watch?v=dQw4w9WgXcQ)
It's also not exactly the same even with one argument; the `impl Trait` version doesn't allow turbofish call syntax: some_func::&lt;int&gt;(42)
Because the difference between `fn foo(val: &amp;Trait)` vs `fn foo&lt;T: Trait&gt;(val: &amp;T)` is too confusing.
LikeABoss
There is a benefit to being consistent in syntax and functionality between functions and "operators" though. It makes it easier to create new collections and DSLs that are just as natural to use as the standard library. That's the scalable part in SCAlable LAnguage. They do keep it pretty C-ish if you compare it to say Haskell, where everything is also functions. Function syntax are made a bit more operator-like, and operator syntax is made a bit more function like, until they're the same.
Oh, I meant the word "public". `pub struct X(i32, pub i32)`.
I don’t think Scala’s DSLs is something I would like to copy tbh.
You benefit from losing the overloading of &lt; and &gt; operators creating amiguity. You defeat the bastion of the turbofish.
Crater can also execute the test suite of the crates it tests, so those crates can check that the generated bindings are good. Tests are not executed on every Crater run, but a run with tests is always executed on the betas (so we're sure regressions don't slip in).
Fair, though my point does still stand - even without Rust or the borrow checker, you have to do this stuff _anyhow_. :)
That's up to you, but I value consistency within the language more than consistency with older languages. Then again, I teach it to beginner programmers where C style syntax is less important than being intuitive. :)
ah, the old sigil-rich rust. In some ways I miss the sigils, in some ways I really, really don't :-P
I would extend this to structs, actually. I don't find particularly useful having a mix of public/private fields. Actually, I don't think I've ever used it.
that's awesome, I was looking for something like this for sozu's config file :)
&gt; One thing I found odd though is how counter intuitive the solution provide was, it did not feel clean like code written in other languages often can. Have you ever written a game in any low-level language (C, C++, etc. )? Using data-oriented design is pretty much a pain in all of them, that's just the way it is.
I hate this "criticism must be only constructive" attitude. Not everyone has the expertise or experience to be able to work out a nice solution to the problems they articulate, but that doesn't make the problems invalid. What *are* invalid, however, are your complaints about the criticism coming from a place of ignorance. Reading through the parent comment, I didn't get the feeling that /u/icefoxen was in any way lacking knowledge on how to use the things they criticized. Perhaps they didn't know the motivating factor for some lang features, but that's fine because only a few people outside the language designers know that info
&gt; About impact, I could very well imagine A crater run did not find this type of code anywhere. That does not mean it does not exist, but if it exists, breakage will be minimal.
Nice! Is there any particular reason why you aren't using csv 1.0?
A couple other people have mentioned this. After looking through the wiki page and going down that rabbit hole, I am starting to see why this is a good idea. Thank you
That is good to know, I think I need a lot more practice in Rust and will definitely keep going forward with it. Thank you.
That's pretty amazing you wrote your own language! Its good to know others struggled with Rust in similar ways. Thank you
Please note the post made by aaron: :warning: :warning::warning: Unfortunately, this beta release has a critical misfire around the module system, which prevents migration from working. We will be fixing this and producing a point release ASAP. :warning: :warning::warning: In the meantime, if you want to try out migration, you need to use nightly and add the following to your crate before running cargo fix --edition: #![feature(rust_2018_preview)] This is exactly why you do release candidates :)
**Unfortunately, this beta release has a critical misfire around the module system, which prevents migration from working**. We will be fixing this and producing a point release ASAP. In the meantime, if you want to try out migration, you need to use **nightly** and add the following to your crate before running `cargo fix --edition`: ```rust #![feature(rust_2018_preview)] ```
The rust compiler could, in theory, use it's understanding of UnsafeCell (the base of all interior mutability) to determine if a function has potential side effects. The sorts of optimizations this would allow are ones easily applied manually, though, such as locally caching the result of a pure function call. I just can't imagine the optimizations being all that useful.
A lot of people have mentioned that non OO is definitely the way to go. It is the only thing I really know right now but I will definitely teach myself to think in other ways and hopefully that will solve a lot of my issues. Thank you
Funnily, just yesterday I was thinking similar like that. Midnight commander is very useful, but e.g. large copies are much slower than cmdline commands, and sometimes I want a third or fourth pane because we have widescreen monitors, why not? Went looking for Rust projects but didn't find any. Went looking for crossplatform terminal libraries.... hmm... how much work could it be.... :-)
This is my first experience with a not garbage collected language, its definitely a bigger change than I anticipated. I will keep working at it. Thank you
Given: \`\`\` // A struct with two fields struct Point { x: f32, y: f32 } \`\`\` Currently: \`\`\` let point: Point = Point { x: 0.3, y: 0.4 }; \`\`\` What I would like: \`\`\` let point: Point = Point { x = 0.3, y = 0.4 }; \`\`\` Not removing a feature, but making field assignment use the assignment operator \`=\`.
This was litigated four years ago during [the mutapocalypse](http://smallcultfollowing.com/babysteps/blog/2014/05/13/focusing-on-ownership/). Basically, mutability and uniqueness are two sides of the same coin. Both terms are useful in their own ways. We decided to go with the mutability terminology because programmers are more familiar with it. The discussion around Niko's post produced a *lot* of confusion and upsetness. Programmers are used to immutable/mutable distinctions, and not really familiar with shared/unique. This is something where i feel like we made the right call for Rust, but hopefully in the future the discourse will have changed enough in the future that whatever language that comes after Rust can use the shared/unique distinction instead.
Thank you, that's awesome. So low-level hello world is easy, whether postgres needs something else, we'll see. I currently also use a Docker container as a defined, reproducible Rust environment and I want to add now Win and later ARM as targets - because a terminal app should be very portable. 
It's not that his criticisms don't give practical and RFC-ready suggestions for viable alternatives that would be better, that's indeed asking too much. But his criticisms don't even give any indication of which general direction the situation should change towards, or even what the problem is in the first place. The criticisms seem to be that the features merely *exist* and he's not using them. Like these points: &gt; * I don't think I've ever actually seen a union in the wild. But, I don't do much C FFI either. &gt; &gt; * Does the `!` type actually make life better? &gt; &gt; * I see why unsized `[T]` types exist but life might be nicer if they didn't. /u/icefoxen would remove unions, the never type, and unsized slices from the language, not because there's anything specific about these things that he doesn't like, no just because he hasn't used them yet.
You've run afoul of the limitations of lexical lifetimes. This is exactly the sort of issue non-lexical lifetimes are designed to solve: https://stackoverflow.com/questions/50251487/what-are-non-lexical-lifetimes See also: https://github.com/rust-lang/rust/issues/43234
It was a joke. 
Here you go, more example code might help. Honestly just dive into the source files is how I learned https://github.com/bjadamson/softland/blob/master/src/ui.rs
So basically, separate how I am getting the inputs away from the snake struct, then use a function when the inputs are received to mutate the snake struct? Also I think I am going to restart this project from the ground up once again. I am going to create the original snake game, then move to the snake game with two players then worry about the HTTP part and only then make it 3D. Thanks for the help
I think they were trying to say the opposite, that invalid phone numbers from input would be a reasonable case for using the non-panicking get() because there could be a reasonable way to recover, versus something like an off-by-one error when calculating an index where there is no way to recover.
I get it :) Thank you very much for this detailed answer !
I will definitely go through the specs book and try to understand this a bit further and come back to your comment. Thank you for the resource and your time!
Ooh, that's interesting! I've prototyped a similar thing at some point, but it was all ad-hoc in Python. Nice to see it generalized! My problem with recommendations based on user interactions is that it suffers from a chicken-and-egg problem. People mostly discover (and express interest) in popular artists, so this method ends up just suggesting popular artists whom I have already discovered. In other words, it will not discover an artist that was not already discovered by lots of people through other means, which kind of defeats the point - I can just go use those other means instead. I've prototyped a radically different approach a while ago with an explicit goal to avoid these issues. Plus an added design constraint that it should not require me to have a huge database locally, because those who have such a DB ain't sharing it, and I can't scrape the entirety of last.fm or deviantart. Based on the (admittedly limited) feedback I got, it worked, although it does require you to tune a couple of knobs. You can check out the result at https://github.com/Shnatsel/fluffy-garbanzo
Or, perhaps, do some trickery such that arr[n] has to be done in an unsafe block or something. The performance difference will be important in some cases, so it shouldn't leave the language altogether.
&gt; I rewrote the GitHub scraper and soon we're going to import something like ~23k new repos into Crater. Is the repository list publicly available somewhere?
&gt; var would be a great synonym for let mut. This doesn't work, because `let mut` isn't a thing. Or rather, it *would* work, but only as a very niche special case. `let` accepts a pattern, and `mut` is part of the pattern. that is, it's let (mut var) not (let mut) var For example: let (a, mut b): (i32, i32) = ...
&gt; (called [Orphan Rules] – unofficial link) I think you forgot a link here
1. `Ord` and `PartialOrd`. Having `Ord` just return `Option&lt;Ordering&gt;` is sufficient. The compiler can remove the `Option&lt;T&gt;` when its unused. 2. I still stand by the `?` operator is bad. I like `match` for error handling. It reminds to make meaningful error handling decisions when you encapsulate operations that fail. But I'm weird and have strong opinions about error handling. 3. `String`, `str`, and `char` should be traits that encoding specific format types can implement. It feels weird having `OSString` and `CString` which all just re-implement everything `String` does already. 
Box is still technically special. It won't be someday, but for now it is. https://manishearth.github.io/blog/2017/01/10/rust-tidbits-box-is-special/
&gt; Anyways, I prefer Allman form if I have to put a where clause on a new line, rustfmt does this, try it on this code: https://play.rust-lang.org/?gist=30877259344caa606e5bae903ff9fa75&amp;version=stable&amp;mode=debug&amp;edition=2015
&gt; called [Orphan Rules] – unofficial link link isn't there. should probably link to https://doc.rust-lang.org/reference/items/implementations.html?highlight=orphan#trait-implementation-coherence
&gt; println! is not some special case. It is just not a function. Isn't a special case, though, in that it (or by delegation `format!`) inspects the actual string literal at compile time? I suppose procedural macros in general can do that (maybe, I don't know how much they get), but IIRC it really was a special case for a while.
Thanks for the link! I must say, I side with Niko. But the current state of things is understandable.
Thank you very much for working on this awesome tool! While I love crater and how it allows the Rust team to test changes on a huge percentage of code, I came to think that its usage might give a wrong impression to some folks out there. Being used in companies is an important goal for the Rust project. There have been multiple working groups actively working on things to improve adoption in the professional sector (custom Cargo registries, ...). Crater obviously can't test closed source projects. And if we make important decisions based on a crater run, that puts private projects at a disadvantage. And this in turn might give the impression that Rust primarily targets Open Source and is not a good fit for professional/closed source use. Don't get me wrong: I -- like probably many others here -- would love if all software would be open. But that's not reality. And I really want to write Rust in my future job! So yeah, I think this might be something we should think about.
Yep, it's in the [rust-ops/rust-repos](https://github.com/rust-ops/rust-repos) GitHub repo. The file is `data/github.csv` and it's updated daily. Crater won't test the whole list, but just the repos with `Cargo.toml` and `Cargo.lock` in them.
I did not have a particular reason (been working on the code for quite a while). I updated to 1.0, thank you for the hint!
Ah great, no worries! I was only asking to see if there were any specific blockers preventing folks from upgrading. If there were, I'd want to know about them! :)
Thanks for so detailed response, appreciate it. I really do not mind to use direct access when you absolutely know there is an element. I answered "what you would remove", but it doesn't matter "what you can't live with, in Rust". Really, I'm not SO much against direct access to indexes. Yes, I would like to see some warning from compiler and ability to turn it off, like we have for "dead code", for example. But it doesn't mean I'm so critically against this language feature.
Do you mean a "linear" hash table? A single array of linked lists? The problem or having a single array is: how are you going to make more room/reallocate without locking the table?
oh I see. thanks! 
I'd like a GTK one :-).
Yep, that's one of my concerns as well, and we have a rough plan on how to solve this problem. The idea we had is a Crater agent companies can run on their own infra, which reports limited results to our own server (probably just a bool "some crates regressed?"). This way the code doesn't leave the company's infra and we still get to see the impact of the changes we do. Most of the details about this still needs to be finalized and the implementation is not started yet so expect some changes in the plan, but this is surely a direction we're going to expand Crater to.
[Piqi](http://piqi.org)'s data definition language ("the type/schema layer") supports modules and includes, too, but it's not part of the general data representation language ("the value level"): You could be sending data over sockets or such, where includes definitely do not make sense. Of course, the data definition language uses the data representation language as its syntax, so it's just a matter of writing a data definition that includes such things as module includes, just as the self-definition of the data definition language does. I'm quite sure that wasn't a particularly good or unconfusing elevator pitch... [just look at some exapmles](http://piqi.org/examples/)? I've yet to come across a neater general-purpose markup language.
Do you have any examples of that? I ask in good faith because I have seen one person or another complaining about this, but they were too aggressive for me so I didn't engage. I haven't seen anything that could be labeled as "social justice zealotry" but maybe I missed something
I'm not really fluent in LLVM inline assembly, but the error should give you a good idea of what is going wrong: &gt; error: unknown use of instruction mnemonic **without a size suffix** You need to pass the size. For example this should work: `mov i32 ecx, esp`. 
Will that writeup be about the process failure or about the policy change WRT backwards compability? Because the latter seems more important to me as it is more permanent.
When 2018 is out, the 2018 chapter is closed. Which means jack squat in terms of what's allowed to change in the future. Editions are marketing and you should ignore them if you are familiar with the language. Here's the *actually in bold* part of the editions RFC you should focus on: we do not hold features back until the next epoch.
You need one more : in your asm block [build able version](https://play.integer32.com/?gist=cc7120db4c75a3a4357c72429339a1b3&amp;version=nightly&amp;mode=debug&amp;edition=2015)
Research/Novelty doesn't imply "not giving a shit about lessons from the past unlike most of the tech industry". It means that "Hey, looks like we don't really have a good solution to X within our constraints W, perhaps Y or Z might be useful for solving X while satisfying W, as they haven't been tried before."
Thank you for making this! I am keeping an eye on your progress. One day I'd like to use a SAT solver to check the output of cargo's resolver. I have made a lot of [improvements](https://www.reddit.com/r/rust/comments/87ss76/cargo_got_some_new_tricks_but_is_it_still_correct/) just based on wikipedia's description of CDCL. But I know that the SAT community has developed many devious extension to the basic ideas. So I look forward to a rust implementation with good comments linking to the papers/blogposts/explanations of how each idea works. Also what keeps you on nightly rust?
A mutable borrow is a once in a lifetime sort of thing
C++ does have a turbofish (really several). They're just not required as consistently, because C++ uses semantic information to disambiguate when it can. C++'s turbofish is the relatively-obscure sprinkling of `typename` and `template` keywords around "dependent names." These are the sites that you can't disambiguate semantically until after template instantiation- without this syntactic disambiguation C++ would have to actually re-*parse* each instantiation basically from scratch. (And some older compilers actually do this!) For example: template&lt;typename T&gt; struct S { template&lt;typename U&gt; void foo(){} }; template&lt;typename T&gt; void bar() { S&lt;T&gt; s; // s.foo may be a template, or it may not, depending on `T`! // this is equivalent to rust's s.foo::&lt;T&gt;() s.template foo&lt;T&gt;(); }
&gt; As described in the RFC, a prototype implementation has actually been benchmarked, and any performance difference was small enough to be lost in the noise. AIUI, this benchmark did not test code that actually takes advantage of the new syntax, only code that uses turbofish to disambiguate.
It's not about avoiding controversy, and it's not a recent improvement either. (Though the team is always learning :)
Thanks! Though I'm not sure that's what I'm looking for. Note: I don't actually want to print anything, it was just for the example. I know how to do it with macros, but I was trying to get a regular function to do it.
This is more something I'd _change_ rather than remove. The way that lifetime variance propagates is very unintuitive and it's really the only weird action-at-a-distance effect that occurs in Rust. Rust has borrowed a lot from Haskell, but Haskell doesn't have subtyping, so you generally don't have to worry about type variance. Rust does have subtyping, so variance can have an impact whenever lifetimes are involved. Invariance due to mutability can be a huge pain at the best of times, but the biggest design flaw in Rust is how any type that contains a cell type, will _leak_ invariance in a way that is invisible when you just look at the types. I'm not sure what the solution is exactly, and I suspect we're come too far already for there to be a chance to change anything backwards-compatibly anyway. But that would be the thing I'd want to revisit if I could.
`&lt;T as Trait&gt;::f()` is called "Fully Qualified Syntax" (see [docs](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html#fully-qualified-syntax-for-disambiguation-calling-methods-with-the-same-name)). It is used to disambiguate when you have functions of the same name in a type and a trait, and is used to call the trait method (otherwise it would call the type's method). You need `pub`, because implementing a trait for a type doesn't give you special privileges on the type. If you want to restrict to your crate, you can use `pub(crate)`. Also, FYI, turbofish is something else. It is the syntax `foo.collect::&lt;Vec&lt;i32&gt;&gt;()` and is used to indicate which generic impl to use.
So promising! But this only works if you bind the lifetime in the `run_bar` method, which restricts what you can give to the given function. For instance, this would not work: ```rust fn run_bar&lt;'a,'b:'a ,F: 'a+ Fn(&amp;'b str)&gt;(f: F) { let b = "abc".to_string(); f(&amp;b) } ```
Fixed, thanks.
Huh, wasn't expecting that, considering that `extern crate` is no longer required in 2018, but it at least made it work for the time being. I can live with that for now. Thanks!
I agree about numbers and I’d go even further: it’s the same thing for all kind of literals. I had an RFC planned for that but I stopped writing it. The idea would be to consider literals a form of *unit* representation of something (for instance, `&amp;'static str` is pretty good to represent literal strings). However, when actually writing a literal in some code, the type wouldn’t be `&amp;'static str` but something like `T: Literal&lt;&amp;'static str&gt;` or whatever and you’ll have: ``` trait Literal&lt;L&gt;: Sized { fn from_literal(lit: L) -&gt; Self; } ```
Fixed, thanks.
It seems to me you're probably most familiar with OO patterns, your code certainly looks like it's pretending to be OO. The best advice I can give it: don't do that. Rust isn't an object oriented language and trying to shoehorn your OO patterns on it is going to leave you feeling frustrated.
Structs are overrated, let’s just use registers and jump instructions, goddammit!
Hey everyone! /u/carols10cents and I have been working on this video series with Manning and it's now in early access and available for purchase. You can use the discount code **vlrust1p** to get 50% off, but only until September 27. 
If we're getting rid of abbreviations, it should be StringBuffer and PathBuffer :-)
Parsing C++ removes some years of lifespan, too.
they're already using `current_exe`, but not all of their code got formatted as code because they didn't indent, so it's easy to miss it.
Interesting opinion. I actually love those abbreviations. :)
This. Completely. It makes no sense to use `:` because it’s used everywhere else to annotate a value with a type or describe a trait bound.
Because both sending and receiving allocate in crossbeam's linked list channel, and because sending could block in a fixed-size channel. My goal is to be rigorously nonblocking, meaning no allocations at all in the real time thread. This is a nearly impossible constraint to satisfy. One of the things I'm planning to do is install a custom allocator which will log a stack trace if any allocation or free operation happens on the real time thread. That should help track down any hidden allocations.
At first it should be uniformed. String vs PathBuf drives me crazy.
Centril is going to add a page in the guide for it. There’s an open ticket. 
Wow. The non-lexical lifetimes explanation is really something. Now I likely spend far less time fighting with the borrow checker for silly things that *should* "just work."
A good rule of thumb I have (which goes contrary to java-style OO, but IMO is good idea even in languages like Java and C#) is that helper functions that only concern a single object are good candidates for methods (e.g. `snake.increment_length`), but as soon as two objects are involved, interaction should be mediated by a 3rd object/system. (e.g. you shouldn't have `snake.collide(block)` or `block.collide(snake)`, but `collide(snake, block)`)
This issue will be solved by specialization.
Thanks!
If you say so. I thought it confusing that they introduced `fn foo(val: &amp;impl Trait)`.
Okay that makes sense thanks
Beyond simply because its not explicitly licensed as "MIT", what issues to users take with the License? I know telemetry is referenced, but its hard to tell what that even means. Is there something I should legitimately be aware of or worried about as an average user?
My hope is that you'll lead with this comment next time. ;-)
Since I assume you'd like to limit latency anyway, would a ring buffer work as a base for a bounded channel?
&gt; Maybe rls should support refactoring them on a per-bound basis from one place to the other! That actually sounds amazing.
Agreed on this one. Rust doesn't care about immutability as an end unto itself, it's only concerned with shared-xor-unique, which the reference system already captures.
I think this is a good summary of possible issues: [https://carlchenet.com/you-think-the-visual-studio-code-binary-you-use-is-a-free-software-think-again/](https://carlchenet.com/you-think-the-visual-studio-code-binary-you-use-is-a-free-software-think-again/) &amp;#x200B; For me it's not so much what I'm "worried about," I just prefer using (fully) open source applications over closed ones when I can. The official Microsoft build of VSCode doesn't come with any extra features or any compelling reason to use it over a completely open build, so I prefer the open build.
I have migrated my little [web browser project](https://github.com/FreeFull/runt) using Rust nightly, and mostly the transition went without many problems. After using cargo fix, I still had to manually remove things like `use std;` and `use url::{self, ...}`, and I had to manually go from `#[macro_use] extern crate failure;` to `use failure::format_err;`. Overall, this got rid of all my `extern crate` statements and a big chunk of my `use` statements.
One thing that I noticed today that is unfortunate about editions: example code from crates is not always copy&amp;pastable, and there is no indication anywhere in the examples which edition this particular piece of code is supposed to compile with. I expect that in the future most crates will provide examples with Rust 2018, but some will not, and you would need to scan the example for edition differences to understand how to use it. Any way to mitigate this?
The one place I've used it is to add a single or a few private fields to an otherwise user-modifiable struct. They would either be there to prevent them from creating it, to store extra metadata I don't want to make stable, or to ensure adding new fields to the struct isn't a breaking change. 
^The linked tweet was tweeted by [@AndreaPessino](https://twitter.com/AndreaPessino) on Sep 18, 2018 18:37:25 UTC (210 Retweets | 561 Favorites) ------------------------------------------------- A THREAD ABOUT LEARNING THE RUST PROGRAMMING LANGUAGE [@rustlang](https://twitter.com/rustlang) Rust is a practical solution to concrete problems that have hindered progress in software development for the last two decades. It is a leap forward in potential performance, scalability and productivity. ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
My understanding of the fork is that it's similar to the Chrome/Chromium fork and the Firefox/IceWeasel fork. Remove all the branding, but keep the code.
I have just r+’d a PR that allows you to set which edition an example is run under. By default it’s the edition of the package itself. We could use this info to display something on the example.
Any chance that you'd be willing to adapt this to the "`lib` and a `bin `which uses it in the same crate" pattern? I have a Django project which I was expecting to have to write this for myself eventually, but I really prefer to use a proper API (ie. wrap a `lib` crate using `rust-cpython`) rather than using a subprocess, which, aside from assembly language, is probably the only kind of API with less compiler/runtime type-checking than Python or JavaScript.
I'm very interested in rust for pro audio! I will try to contribute if I can!
&gt; I agree that ideally nothing would ever break from any update, even in theory. But that would be holding Rust to a standard that no other popular language holds itself to, and such a hardline stance could impede Rust's development to just as much or more detriment as minor breaking changes would. But do those have editions as a way of managing the breakage? I'm not saying don't make the changes at all. I'm saying use the edition facilities.
I'm very interested in this topic. Do you have any further information on building your customized lock-free queue? What were the challenges? Surprises? It seems like fixed-size queues/channels are a good fit when you have more control over the underlying system, but perhaps not in the audio context? 
&gt; I find it amusing that people feel so strongly about this parsing ambiguity that nobody has run into, when other breaking changes with a higher potential to break user code are being merged every day. There's a reason I'm very selective about imports. I'm having some ideas for making old code in these cases runnable again temporarily, For breaking syntax changes such a facility would be the edition system.
I think crater will always have blind spots, but even if it just tests a small segment it's extremely valuable. I just don't think it's a good enough justification to skip the edition system. But outside of that I believe it has huge potential.
Huh, so you can actually compile code under one edition, but have examples in the documentation in another edition? Do doc tests pass in that case?
Yup!
&gt;thought yinz should know) &amp;#x200B; I haven't heard "yinz" in ages. I always thought it was spelt "yunz" though. Learn something new every day!
Completely agree! One of my biggest annoyances is `format!` should be `fmt!` haha.
I really can't stand TWITter! I wish it would go away. If I never have to see another "Twitter Thread" it will be too soon. Why? Who in the hell wants to communicate like that? I can't stand it.
About the edition guide. I think there should be two separate guides (or at least two distinct parts of the guide): One for migrating Rust 2015 to 2018 (rustfix doesn't cut it -- it's good for automating the migration for large projects, but Rust programmers need to understand what it's doing, IMO). And another one for the recap of all changes and new idioms since Rust 1.0. Right now, it's jarring. I'm reading the edition guide, and at one point I'm thinking "Okay, so this is how I port things", and on the next page, "Wait `? operator`? This has been in the language forever!"
&gt; (rustfix doesn't cut it -- it's good for automating the migration for large projects, but Rust programmers need to understand what it's doing, IMO) The intention is that you should be able to follow the warnings. If those warnings are confusing, we should fix them. Any guide would be sort of like the error index, with extended information about the warning, but there aren't *that* many, and the diagnostics should be good. If you or anyone else finds them confusing, please file bugs.
You don't always port complete projects -- you might want to port an example without creating a project to port it with. Suppose I'm already working with an edition 2018 project. I find some old guide whose practices I want to integrate. I need to be able to translate in my mind how to write the same thing, but in the 2018 dialect. Right now, there seems to be no resource that allows you to gain this skill.
Why can you not run `rustfix` on that example?
This was an oversight that I think was admitted by at least one of the core devs
The problem with telemetry + forced updates is that you never know whether there actually is anything you should worry about. Maybe right now there isn't, but it's going to come in the next update, or the one after that. Maybe it's not. You never know.
To prevent from creating or adding new fields, `#[non_exhaustive]` will eventually be a thing. https://github.com/rust-lang/rfcs/blob/master/text/2008-non-exhaustive.md
SalmonCannon? This sound cool
Yes, but this way you learn by making mistakes. I would prefer not to rely on making every single possible mistakes to learn things -- having a structured way to learn this would be preferable to me.
 macro_rules! fmt { ($(a:tt)* =&gt; { format!($($a)* } :D
I think fixed-size queues are more traditional in audio, actually. The specific reason I'm using unbounded is that the dropping in the real-time thread is accomplished by sending the object through the return channel. For the usual direction, it would be fine for the main thread to block if the channel were full, but blocking on the real-time thread would be very bad. No real surprises implementing this, but that's because I had quite a bit of experience (previously I had implemented a ring buffer for the [msfa](https://github.com/google/music-synthesizer-for-android) core) and studied the topic. Dmitry Vyukov has [very good information on lock-free queues](http://www.1024cores.net/home/lock-free-algorithms/queues/queue-catalog). It probably makes sense to expand this to a full blog post, and I also plan on talking about it some at the Rust Meetup. 
&gt; it's one thing scala got right. You mean BASIC, right? ;)
You don't get it - if you not bashing MS then you doing it wrong. You must shame every company that has opensource and makes money. 
&gt; There's a reason I'm very selective about imports. Being selective about imports does not help you a little bit. If you have a trait with a trait method implemented for a type in std, and the std library adds a method of the same name to the type, your code breaks. If you have a trait, and `libstd` adds a trait of the same name to the _prelude_, your code breaks unless you are never importing the prelude. 
An argument can be made that while we had to endure minor breakage before, now we have a tool to deal with it, namely editions, so we can afford to be more strictly backwards compatible.
If you add a lot of the function ranger has, it could grow into a not small project. You would have to have a user config file because people like to personalize there terminal apps.
I believe this was a long and twisted bikeshed in the pre-1.0 days.
It's sugar but I like it because it makes it much more clear what is actually going on, especially in a large project where you don't know at a glance what types are and are not traits.
I sympathize. I don't terribly like telling people how to behave either. But it's actually really important for people who are traditional targets for persecution to have a public message posted saying "we will not turn a blind eye to you being treated like shit just because you're X" for any value of X. That sort of statement should be the default, so it's quite annoying that we have to publicly shout it out, but it really really matters.
If you can, file tickets for these so that we can add lints with `MachineApplicable` suggestions for `rustfix` to do these automatically. the `#[macro_use]` one might be tricky, but the other seem possible.
Typically if your using break and continue, you're writing your loop wrong. I can think of one example where you should use break though. ```rust let item = for item in items { if condition_satisfied(&amp;item) { break Some(item); // Don't want to keep looping if we've found our item. } }; ``` This can be re-written to use higher order functions, though, so I'd argue there is less need. It probably uses `break` behind the scenes, but that's an implementation detail that we don't care about. ```rust let item = items.iter().any(condition_satisfied); ``` I've also seen people use break in a game loop, and I've used it myself in that situation. One could argue you should use a while bool {} loop though. Again, if I ever find myself thinking I need `break`, I'll use it, but I contend you shouldn't reach for it unless it really is the best way to describe what you're trying to accomplish -- a while loop, or a for loop, or (even better) a higher order function is probably a better idea.
The `dyn` keyword, and `impl trait` in argument position. Too soon? 
&gt; The `?` and `try!`. It encourages leaky abstractions which don't fully encapsulate handling the failure states of the operations they encapsulate. I'll admit I'm in an minority here, and have rather unorthodox opinions when it comes to error handling. What do you mean by leaky abstraction, here? I know the term, but I can't put it into context with error handling …
I 100% agree. I just put the smiley in because I said "**break** the rule"
Yeah, but then I need to import it everywhere, which is a nuisance. 
Do you have any examples of the pain you're hitting? Interestingly, I've mostly not had to care at all about variance. But I also don't spend a huge time building low level generic primitives like those found in `std`.
It would be really cool to look at the source for this! There aren't hardly enough examples of Rust on mobile out there right now. It would be great to be able to peek and see how this was done! 🎉
[Leaky Abstraction](https://en.wikipedia.org/wiki/Leaky_abstraction) means you need to understand the underlying operations to use the abstraction. Most error values in, honestly most API's/Frameworks are inherently leaky. You need to understand what underlying operations are taking place to understand how to handle the error. This is failure of encapsulation. &gt;but I can't put it into context with error handling Yes you can, and I do. Personally I believe error handling is a critical part of API design. We should not consider errors exempt from encapsulation and abstraction, as ultimately they are just another result, and a different direction of flow execution. The problem is we often just assume that everyone else _wants_ to handle the errors, or will know how to handle them better then us. This really just a rationalization to avoid implement common handling schemes within the abstraction itself and exposing methods of configuring them. But this is just my opinion, as I stated: &gt;I'll admit I'm in an minority here, and have rather unorthodox opinions when it comes to error handling.
That may be true, but it's conceptually wrong in the first place, even if something else is coming down the pike that lessens the burden.
My apologies for being offensive. That wasn't my intent. I appreciate the post and the content, I just hate Twitter. I've never liked it. I love to read. I really enjoy other's thoughts, but, Twitter just feels like a travesty of a way to communicate to me. Every time I click a link and it ends up being a link to a Twitter thread, I get a gnarly pit of despair in my gut.
I've used both the never type and unsized slices, but they didn't make my life significantly better over not having them. Anyway, the intent of the question was less "what should we remove" and more "what could we remove if we wanted to"; sorry that was unclear. Everything in Rust is there because lots of very smart people put it there for a particular reason, and it's resulted in the best programming language I've ever used. The list is just the things that either don't seem worth the payoff in my quite limited experience, or which are very complicated and make me wonder "what if things were different?"
I never realized I agreed with you until I read your comment.
I agree, actually. It's just SAD!
Speaking of which, I haven't seen mentions of how one would enable the 2018 edition when using bare rustc.
It's not very often, but it's one of those things that hits hard when it does. You introduce a RefCell as a private struct field and some code in a different module won't compile any more. I also wonder about new users who stumble into this before they really understand the basics. How might tits affect their experience?
It's not awkward, it's adorable!
Explicit declarations are still required for crates in the standard distribution because otherwise `rustc` doesn't know to look for them. When Cargo invokes `rustc` it passes all the dependencies on the command line, and then the compiler assumes `extern crate` declarations for them.
If you want a better example of how it can work in practice, check out my WIP ecs disk management library: https://gitlab.com/mmstick/ecs-disk-manager Source is documented to make it easy to learn.
I'm not familiar with either, but perhaps it would be possible to make your config language a strict subset of HOCON? It sounds like you may be able to use lots of the useful parts and just leave out the more hairy bits.
It was 7 weeks ago, so I think it would be worth asking :)
Is there an open issue with GitLab about the needs of Crate that they should implement? i know they have an open issue tracker and are pretty responsive I believe. It's my preferred platform, so I'd love to track that bug if one exists.
You're right. I should find some time for that.
It's kind of a mess, but I made this a couple weeks ago: https://github.com/WimbledonLabs/imgui_gfx_example It's not the most minimal example out there, but it has 3d rendering, mouse input, and keyboard input. It's based off of this example from the imgui-rs repo: https://github.com/Gekkio/imgui-rs/blob/f7ffac7c8d4abb14896dbae4c02f44205a465ff8/imgui-examples/examples/support_gfx/mod.rs
You can always “cargo build —verbose”, or look at the rustc book. TL;DR you pass —edition=2018, IIRC.
Are you sure you aren't being bit by the type no longer implementing Sync rather than variance issues? Sorry, I'm just having a hard time groking without an example.
Edited. Better?
I'd argue it isn't, and that \`let stdin = std::io::stdin().lock()\` ought to work, but doesn't.
You mean like, the lock object could've been redesigned to avoid borrowing the stdin object? I think you're probably right in this case, since stdin doesn't inherently have anything to do with the local stack, though there must be other cases where borrowing is unavoidable.
Oh yeah, I think there's a lot of agreement that sticking with some sort of "ThingBuf" or "ThingSlice" or "OwnedThing" convention would've been a better choice, with the benefit of hindsight.
Unroll is a thing: https://threadreaderapp.com/thread/1042120425415700480.html
repo\* I don't think I can edit my topic.
I had been thinking about this a day or two ago; it would be interesting to have a tracing allocator where I could run test cases and then verify no allocations happened during the test. The intention would be to implement a custom allocator, and then just pass calls through to the system while recording where/when it happened. Is that kind of what you had in mind?
The intention is to eventually use Polonius; that’s what I’d look into if I were you.
Yes. The extra trick is to have a thread-local variable which is set during the render callback, and only report allocations when this variable is true.
We don’t generally guarantee exact algorithms (same as type inference). It’s too specific for this stage of rust’s maturity. If you want details, the code is the way to get it.
Per `serde`'s recommendation, your feature to enable serde should be `"serde"`. The crate itself exposes a `serde_derive` feature to add a re-export so you don't need to add it separately. This is actually a pretty common pattern, if not the most obvious one.
So, the borrow checker will be a black box now? I can't say I like that...
&gt;sozu's thx, i'd really appreciate any feedback
The `str` type - default strings should be byte strings (i.e. `[u8]`) not utf-8 strings. Assuming utf-8 strings everywhere leads to brittle code against non-utf8 input. The `str` type should just be some form of newtype wrapper around `[u8]`. String literals should be `[u8]` literals.
I was an intern on the Rust team in 2011 and 2012. We used to amuse ourselves by trying to see how many different symbols we could string together and still make it compile.
Dave Herman used to point out that language design in and of itself tends to be language research. Rust tried not to have any new ideas, but the specific combination of features is unique and making those work well together requires solving novel problems.
I'm not sure if there's a crate for this, but it is possible ([playground](https://play.rust-lang.org/?gist=cfa101081a139c5caea9aa191728c5a5&amp;version=stable&amp;mode=debug&amp;edition=2015)): trait Check: Sized { fn check&lt;E&gt;(self, pred: impl FnOnce(&amp;Self) -&gt; bool, err: E) -&gt; Result&lt;Self, E&gt;; } impl&lt;T&gt; Check for T { fn check&lt;E&gt;(self, pred: impl FnOnce(&amp;Self) -&gt; bool, err: E) -&gt; Result&lt;Self, E&gt; { if pred(&amp;self) { Ok(self) } else { Err(err) } } }
Yeah. Microsoft is no longer the same. [Microsoft intercepting Firefox and Chrome installation on Windows 10](https://www.ghacks.net/2018/09/12/microsoft-intercepting-firefox-chrome-installation-on-windows-10/)
[removed]
I'm not asking about algorithms, I'm asking about the mental model for the programmer.
Yep!
I think `Fail` from `failure` crate is what `std::error::Error` should have been.
One of the things about rust is it isn’t afraid to do better than before. This is good!
You might take a look at how I implemented redirection to file for Response's body in my client library https://gitlab.com/Douman/yukikaze/blob/master/src/client/response/extractor/mod.rs#L474-611 There is though one edgy case when I cannot retrieve back File from io::BufWriter which is possible only when for some reason flush fails
A few years ago, the company I work for has transitioned from using C to Rust as the primary language for software development. As a result, we have accumulated a *very* large code base that is not available publicly (at least in a manner accessible to crater). Seeing that quite a few companies have started to invest heavily in rust, I expect that some of these companies will just opt to maintain a private fork of rust if breaking changes become too expensive. That said, given the effort the rust team puts into targeting companies and their use-cases, I think companies are still strategically important to Rust's success, and I don't think rust will abandon it's commitment to backwards compatibility. At least not yet.
Thanks. I've been iterating on this all evening too. Slowly pushing through all of the Futures magic and trying not to lose track of references when using futures combinators. I wish the rust error, 'cannot move out of borrowed content' showed where the borrow happened. My brain just wasn't working today :-) &amp;#x200B; &amp;#x200B; &amp;#x200B;
That's how it is been with futures 0.1 since the begging. They really suck when you need to implement it
It's hard to understand code from mobile, but - Try to use "move" for closure - Try to cast closure to correct trait object (the one you have defined as value in hashmap) before inserting it.
I'd be happy to do this. I don't have much experience in structuring crates, could you give me some more details on how you would like me to change the layout? Conceptually, it should not be too hard to directly call the corresponding functions.
I think that's the sort of thing that would be fine in this case and other simple cases, but which would create very confusing results in more interesting cases. If the temporary has a destructor that does something important, it might be important to know exactly when it runs, and it could be a problem if that timing depends on the subtle lifetime details of all the functions involved in the expression. In particular, the introduction of NLL could change the places where destructors run.
There are probably a lot of answers to "why not just use [dhall](https://github.com/dhall-lang/dhall-lang)?", but … it's worth considering, I think.
Heh, they've vendored WinApi for a Linux OS
Not necessarily. AFAIK, any wrapper class for arrays in Java is not gonna be able to use the square bracket indexing syntax, because they went with a special case syntax just for arrays. So you *can't* be consistent. While in Scala you're at least given the option, but a programmer can always write bad libraries. Of course, if someone writes a library completely unlike any other functionality in the language it might be hard to be "consistent" with the rest of the language, but if they still manage to give it a seamless feel to it that makes it a natural part of the language, then the language has all of a sudden gotten more functionality! If you want an example, look at the Akka libraries. They introduced actors to Scala as a concurrency abstraction. If you didn't have to include it in your build tool as a dependency, you wouldn't know it wasn't part of the standard library. On top of that they built Akka streams, where they made a custom DSL for declaratively building graphs. All very nice. But yeah, DSLs don't have to be consistent with the rest of the language. But they can be.
I'm happy with UTF-8 `str`. It _would_ be nice to have convenient string-like manipulation on `[u8]` though.
You're not an idiot, Rust is a pretty difficult language. That's not meant to be a dig, C and C++ are also pretty difficult languages, but look deceptively easy at first. Rust doesn't hide its complexity. That's a good thing. I'm a reasonably experienced game programmer, and I've spent the past month or so learning Rust, and I have yet to write any meaningful code. It's frustrating it, but what I realized after my first foray into the language (nearly a year ago), is that I can't learn it like I learned C#. I can't just jump right in writing programs, because the memory model is fundamentally different. &amp;#x200B; So what am I doing instead? Slowly working my way through the rust book, Rust by Example, and the Rustonomicon. I'm making sure I know what each thing I'm doing *means*. My first big project is going to be this: * Simple Structures * Vector * Singly and Doubly Linked List (done) * Stack, Queue, Dequeue (done) * Linked Binary Search Tree * Pre-order, in-order, and post-order traversals * Advanced Structures * Graph * Adjacency List * Adjacency Matrix * Breadth First Search * Depth First Search * A-Star on a grid * OR * A-Star Sliding Puzzle? * Heap * Priority Queue * Fixed-point number * Sortable Float * Sortable Fixed * Algorithms * Bubblesort * Quicksort * Selection Sort * Heapsort * Mergesort
idk, I almost feel the opposite. On the one hand, you'll have a better idea of what's going on, but on the other hand, C++ is so anarchic that I've found experienced C++ devs have a *harder* time, because of the lifetime rules.
Yeah I think I am trying to learn rust the wrong way. I went through the book but I didn't think to hard about everything and I think that's fundamentally where I am going wrong. I have been breaking my project up further now but I think I am going to put it off for a bit untill I am more comfortable with rust as a language. Thanks for all the help!
Though notably, [it's not like he doesn't seek it out](https://youtu.be/4t1K66dMhWk). I assume those comments on the keynote are why they thought to ask him.
https://twitter.com/AndreaPessino/status/1042120425415700480 I posted this elsewhere, it was already the way I've been learning Rust, and it's pretty relevant.
I know about it video, though I didn't watch it. But he's been saying for years that he doesn't like Rust and he thinks the borrow checker is useless. I think asking him about the most effective ways of learning the language is kind of useless and probably aggravating. --- On an unrelated note, I wrote the post above thinking JAI can be an alternative to Rust for game development. But now I realize it's not, so it's a moot point. You can start your game today in Rust (or C++, C#, JS, or whatever), wait a couple of years until JAI comes out, or start working on your own language. I suspect it's better to start today than wait.
ditto - my upcoming project is a guitar pedal in pure rust. Parts are on the way, I'll probably write a too-lengthy medium post about the adventure. 
Long-term I believe the intent is for `meta` to become a crate to replace `proc_macro`. `meta` is able to be referred to in the same was as `std` and `core` are (without an `extern crate` or an `--extern` passed to `rustc`), but `proc_macro` was deliberately taken out of that list. https://github.com/rust-lang/rust/pull/54116 This was _required_ to prevent `alloc` from being usable on stable. Eventually we'll get a way to declare toolchain/builtin crate dependencies in `Cargo.toml`, and you'll use that instead of having to fall back onto `extern crate` temporarily.
Thought this might be of interest here! Not sure how well it works in practice, but it's nice to see C++ trying to improve itself.
The main answer at least for me would be from the first line of their repo: &gt; Dhall is a programmable configuration language I don't really want a programmable configuration language. I would just use whatever language my project is using if I wanted that.
If it's not in your distribution's package system, and it's a widely-enough used piece of software that you'd expect it to be, then perhaps something's wrong. My rule of thumb is: trust as few packagers as possible.
&gt; it's conceptually wrong in the first place Can you clarify?
Thanks, it's always nice to see where SAT solvers can be used. \*\*\* The comments could be much better. I don't think I link relevant literature anywhere :/. There are some references in the Varisat solver description for this year's SAT competition [http://jix.one/sc18/varisat.pdf](http://jix.one/sc18/varisat.pdf). I'd be happy to give an in-depth walk-through of the code base to anyone interested though. If someone wants to contribute better comments / internal documentation after that, even better (but not a condition). I'll probably improve that area on my own over time, but it's not a high priority. \*\*\* I'm on nightly for these features: `#![feature(alloc, ptr_wrapping_offset_from, nll, raw_vec_internals)]` NLL is unnegotiable, but as I understand it, that will land soon. It wouldn't be hard to avoid ptr\_wrapping\_offset\_from, but that's used in the inner loop, so any alternative would need careful benchmarking. The remaining alloc and raw\_vec\_internals features are used for the convenient RawVec, but I think there is no problem replacing it with stabilized APIs. All in all I'd be happy to attempt to switch to stable rust as soon as NLL is available.
Repost
Ah, so you don't mean that the error handling is the leaky abstraction but the "leak" itself for some other abstraction (data structure, library, …), right? But isn't that, that you usually actually want to leak a detail of information, if e.g. a file could not be openend, so that the user could a) enter another filename (file not found) or b) change permissions (access denied) etc. ?
Rust check mate :D
Ok, a contrived example: https://play.rust-lang.org/?gist=3073bdae571f3cd1a49923448ed512d7&amp;version=stable&amp;mode=debug&amp;edition=2015 If you uncomment the two commented lines and then comment the ones above instead, it will change the internal implementation of `Problem` to use a `Cell`. This causes the example not to compile, even though none of the visible types have changed. This is the action-at-a-distance that I'm talking about.
Ooooh &lt;3 As always, don't hesitate to reach out if there are any issues on the lyon side of things.
It would be nice to at least provide a link to the old post when writing this. Writing "Repost" isn't really helping anyone in itself.
Not sure if it is! Rust's type system is probably on a much better footing to be formally verified. Also, the ecosystem and programming style is already set up for it.
True, but you also have to consider the whole ecosytem when comparing languages, type system is a tiny portion of it. If I can use this in the context of Java/.NET interop, GUI and GPGPU programming, than it is a win for safety in general.
&gt; Whether a name is a variable or a type is semantic information. Yes, that’s what I said. A C++ compiler requires this information in order to parse the rest of the file, but a Rust compiler does not – and still would not after this proposed change, because it disambiguates purely based on syntax.
Yes, this is the one I saw too. It doesn't have a lot of functionality. Maybe it's still early days for it. With ranger you can configure how many panes you want.
I see, thanks for the clarification.
Well, the question is, since there is ambiguity (type's method vs trait's method), my can you only resolve it to specify the trait's method? Problem is, when you see `Self::foo()` you can not tell whether it is type's method or trait's method without knowing which exist
While the following seemed intuitive to me, I still feel compelled to ask (just to be sure): The --edition flag would *generally* be used in the context where I've installed a newer version of rust stable but have my default set to a lower version? I assume that the edition is implied by by the rustc version. Any release beyond this December would automatically be of the 2018 edition, correct? 
If old code will not compile, as authors of Rust promised, Rust lose reputation - companies right now have, simultaneously, doubts and desires to try Rust. Without reputation of reliable language doubts will outweigh desires. I love Rust very much, and I hope old code will compile - it's important to attract companies for the future of Rust as a platform.
Interesting! Thanks for that. Interestingly, with `nll` enabled, your specific example compiles. But that's probably just a property of the example itself, but maybe `nll` will reduce some pain here? Not sure.
Neither statement results in a heap allocation, so there is nothing to free.
I'm currently trying to implement the bytecode vm from [Crating Interpreter](http://www.craftinginterpreters.com) to learn Rust and the guide is written in C. So in the bytecode vm you store the opcode and the data as bytes, in C, you could just use a defined enum and the value could be casted to uint8_t and compared to the original enum value. While in Rust you could specify the enum to be repr as u8 and get the value with `as u8`, but then you could not compare it with the original enum value. Is there is any way to do this, like, idiomatically so I don't have to create a separate map and have to maintain the enum and the map definition.
&gt;The problem or having a single array is: how are you going to make more room/reallocate without locking the table? There are methods for doing efficient concurrent resizes, lock-free and everything! I've got my own implementation, which I can't release yet, but there are two main methods for doing it. The first is [Cliff Click](https://web.stanford.edu/class/ee380/Abstracts/070221_LockFreeHash.pdf) (the man, the legend) and the second is that of [Jeff Preshing](http://preshing.com/20160222/a-resizable-concurrent-map/) (the man who got me into concurrency research in the first place, he's amazing). Effectively you can reserve a particular value, in your case a pointer to a value, to indicate an ongoing resize, writing them over the current values once copied. The table becomes a linked-list (lock-free of course) of hash tables, each potentially experiencing an ongoing resize. That's an incredibly terse explanation! Check out their code. Their methods are very similar, except Preshing's is blocking while Click's if lock-free. Mine is mostly lock-free with one single double checked locking pattern when allocating a new table - this stops 40 threads allocating a 3 gig table each...
I've written a small bit about concurrent resizing below [here](https://www.reddit.com/r/rust/comments/9hbl5s/a_lockfree_map/e6dg02i).
I'm not sure if I understand the semantics of the current `nll` implementation sufficiently to be able to easily find an example - coming up with this example was fiddly enough! But I'm quite sure that one exists because this is really about `T` becoming invariant, which is necessary for correctness, and the main reason that you can't safely implement interior mutability without `UnsafeCell`. Perhaps the answer is an optional marker syntax, a bit like `dyn`, to indicate an invariant type argument. Omitting it becomes a warning, and and error in a later edition. I can't imagine any syntax that looks good though.
Yeah, I agree. Variance is hard. :)
This fails to compile with nll: https://play.rust-lang.org/?gist=40c3f8a81cc6455b12ed38ef8f7eb9d6&amp;version=nightly&amp;mode=debug&amp;edition=2015 The trick I think is that with nll, it knows that the lifetime of `first_ref` ends immediately after calling `do_stuff` such that it frees up `second`. If we push the lifetime of `do_stuff` past `second`, then we get back to your problem. (And this example does compile if you remove the use of interior mutability.)
&gt; Because deriving Send and Sync manually would be a nightmare. Not more difficult than deriving Clone, Debug, PartialEq, etc etc... &gt; In most programs you'd end up deriving them on virtually every type anyway, adding to the noise and the cognitive overhead of "oh that's another thing I have to remember". No, because you likely won't have to send most types between threads, so it probably won't be as many derives as you have for e g Debug and Clone. At least not in application code. The current situation is problematic because if I'm writing a library with a public type, I can't add a new private field in it without breaking backwards compatibility, if that field is e g an `Rc&lt;String&gt;`. It would be better if I had to continuously choose if my public types were to implement Send and Sync, or not.
Looks like they're now compromising soundness in order to get something working. The goal is now to detect *common* cases of use-after-free, not *all* cases of use-after-free. This makes sense to me. I didn't see how it was possible to soundly detect use-after-free in C++, with aliasable/mutable pointers being everywhere in the ecosystem.
Sure. But libcore still have formatting code, atomic types, UTF8 handling, and more. This might lead to code bloat in cases where tininess matter (tiny microcontrollers, wasm to some degree). The libtinycode I envision would, ideally, not have *any code at all*, just: * declarations of built-in types (e g `usize`). * declarations of built-in traits (e g `ops::Add`). * declarations of built-in functions (e g `memcpy`. Also called intrinsics). Then we can build a `libcore` around that, and then `libstd` around `libcore` (and alloc, and collections etc) like we do today. The point is making the interface between the compiler and the libraries as minimal and elegant as possible.
The default is always 2015.
&gt; Deriving Send and Sync have few problems. Expanded code will have unsafe impls and will require dead code to ensure that all fields implement them. Hmm, right. I would ideally like deriving Send and Sync to be safe if all fields inside implement Send and Sync; just like deriving Clone only works if all fields inside implement Clone.
As someone who watched the video, he stated that the borrow checker adds too much friction to writing software, not that it's useless. It might result in safer software with less bugs, but at the expense of time spent. He acknowledges that spending more time with the language will remove some of that friction, but isn't convinced that it ever fully goes away.
thanks :) 
`println!()`
The linker should be able to remove unused code.
&gt; It goes a bit further than I would like though, how often are macros used? I think the biggest user I've seen is [rspamd](https://rspamd.com/doc/configuration/), which uses `.include`'s fancier options quite a bit and also registers its own `.include_map` macro. &gt; I assume `on`/`off` for boolean values are there for YAML compatibility? It looks more limited than YAML, which supports partials too. `y` etc.
I'm currently working on a TUI app and am missing the ol' println debugging. A lot. :(
Kids, don't use `println!()` to debug. Use [log](https://crates.io/crates/log) instead.
The mental model for the programmer is “borrows are based on usage (aka control flow) rather than on lexical scope”.
If you're on OSX you can use the ```lldb``` component
I don't know how many crate authors would consider it a breaking change to add interior mutability to a struct. I imagine very few.
I think it used to be a slash waaay back. So `&amp;a foo` was `&amp;a/foo. E.g. see [here](https://github.com/rust-lang/rust/pull/10585/files#diff-ff81b7d4951c4d38eee0fc24ab89310c).
What is impossible about those example lines you gave?
I always call them both `thing`; variable shadowing isn't an antipattern in rust, as the typechecker prevents you from e.g. accidentally using an option when you wanted the value inside.
Do you have a more concrete example? For having to do this most of the time just hints at code that should be restructured. But if you really need to the Rust way would be to give them the same same name and use shadowing with the help of the Rust type checker.
&gt; which becomes impossible Why, what do you mean it becomes impossible? Rust supports name shadowing, those all [completely possible](https://play.rust-lang.org/?gist=fa278fef14233ff97d826a9753c18209&amp;version=stable&amp;mode=debug&amp;edition=2015).
I am interested in your ideas and would like to subscribe to your newsletter. (thank you for saving this project's bacon! this is cool stuff i've never heard of before)
gdb tui can be really handy if your logging into docker images. for may day to day desktop i primarily use clion but i have good experiences with KDBG. 
Well, if it changes the type from implementing `Sync` to not implementing `Sync`, then I think most folks would definitely consider that a breaking change. Whether they notice it or not is perhaps a different story. :-) But I think if it's pointed out, then most folks would say it's a breaking change. Now... if it doesn't change a `Sync` bound but does change variance and breaks some code because of that, yeah, you're right, I don't know how many would consider that a breaking change. It would probably depend on the nature of the breakage.
Often `println!()` for smaller things. For heap corruption in unsafe code, [nothing beats rr](http://fitzgeraldnick.com/2015/11/02/back-to-the-futurre.html)
rustc (:P), println, gdb, rr
I see what you did here ;)
I'm not the OP, and "impossible" is a strong word, but I do think that shadowing makes it harder to understand the types at a glance even if it's technically sound.
I guess the op might be talking about when drop will be called for types implementing Drop.
From what I've heard, he doesn't dislike Rust so much as he doesn't think it's the right language for game programming specifically.
This is what I do, esp if I know that I'll return early if it's not `Ok` or `Some`: ``` let thing = get_thing(); ... let thing = match thing { Ok(t) =&gt; t, Err(err) =&gt; return Err(err), }; ... ``` However, in most cases, I just check as it's being returned without a local variable. If it's going to be around later and keeping the value as `Err` or `None` is valid, I'll prefix with `opt` or `res`.
For those who don't kno what this is: &gt; RPCS3 is an open-source Sony PlayStation 3 emulator and debugger written in C++ for Windows and Linux.
I do the thing that you say is impossible.
Can you say specifically what things you want in `pytest` that are lacking in the current testing infrastructure? I've used both `pytest` and Rust's testing infrastructure quite a bit, and I can't say I miss much of anything from `pytest`.
I try to either call the option `thing_opt` and call the method that returns an option directly in the match statement, i.e. `match getThing() { Some(thing) =&gt; ... `
at a minimum, am looking for: - Test fixtures of various scope levels (resource sharing across tests) - Parametrized tests (run same test function over a series of different inputs) 
I just switched to using the `pretty_assertions` crate, which replaces `assert_eq!` with a version that pretty-prints its output, and shows the left and right arguments as a colorized diff. It's made it much nicer to debug my failing unit tests for the AST transformation code I'm currently working on.
This. LLDB works perfectly and integrates nicely with vscode for example. 
In c# I must admit with a little shame that I have resorted to `System.IO.File.AppendAllText(@"C:\Some\Where.txt", "&lt;debug msg here&gt;\n");` for GUI applications. Of course one can use "proper" logging or debug with Visual Studio but sometimes you just want some quick log lines rather than jumping through all those hoops...
I think that's just the way it is. Normally traits are pretty small, so at a glance you should know the set of methods it has. I also think that using conflicting names should be avoided if possible.
\`maybe\_thing\` for \`Option\`.
Seconded. Depending of success certainty also hopefully_thing
What's the backend of the gfx-hal here, GL or Metal?
There are also implementations in crate sha1 (by mitsuhiko) and ring.
A bit late but [this blog post](https://www.ralfj.de/blog/2018/07/24/pointers-and-bytes.html) imagines pointers differently. A way to represent a pointer very different from common hardware (x86, ARM). Since the representation of a pointer is not defined for Rust (even 32/64 bit pointers differ quite a bit) one cannot assume integer arithmetic. Given the number of undefined behaviour bugs that follow from pointer arithmetic in C/C++ and how pointers are the second component of nullpointer exceptions I joked.
I was mistaken about how scopes work in Rust ([comment](https://old.reddit.com/r/rust/comments/9hpyam/question_what_names_do_you_use_for_option_and/e6drkqu/)), in most languages you can't redeclare variables in the same scope.
&gt; Can you clarify? [sure](https://www.reddit.com/r/rust/comments/9ce1t8/blanket_from_impl_woes/). More generally, though, I think a reasonable heuristic for "should I have a blanket impl?" is "is there exactly one way this could ever be correctly implemented for what I'm blanketing?". If the answer is `no`, that suggests that you shouldn't. And `impl&lt;T&gt; From&lt;T&gt; for T` rules out implementing a sensible `From` for `struct W&lt;T&gt;(T)` (namely, you can't `impl&lt;T: From&lt;S&gt;&gt; From&lt;W&lt;S&gt;&gt; for W&lt;T&gt;`, because they collide when `S` = `T`). It's possible that specialization will help with that. It's not what specialization is *for*, as I understand it, but it might help. But the blanket impl is just *wrong*, in my opinion, because there *isn't* only one correct implementation, as soon as you get past simple types.
It is
Yeah I do most of that with different uses of `macro_rules!`, or in exceptionally complicated cases, I just build out the infrastructure to do it in normal code. It ends up being quite a bit more flexible that way, but does require more work. For example, if you want setup/teardown, then the simplest incantation is just this: struct MyResource { ... } impl MyResource { fn new() -&gt; MyResource { // setup goes here } } impl Drop for MyResource { fn drop(&amp;mut self) { // teardown goes here } } #[test] fn mytest() { let resource = MyResource::new(); ... } If you want to share `MyResource` across multiple tests, then I'd just stick it in a `lazy_static!` and call it a day. This won't give you teardown functionality in that specific case, but usually you can get away without it. For parameterizing tests, there are a few ways to do it, depending on the situation. For cases where I have one function that I want to test with lots of inputs, I'll just do something like this: macro_rules! testit { ($name:ident, $input1:expr, $input2:expr, $expected:expr) =&gt; { #[test] fn $name() { let result = do_the_thing($input1, $input2); assert_eq!($expected, result); } ) } testit!(test1, "foo", "bar", "foo"); testit!(test2, "bar", "foo", "bar"); Or if you want something more faithful to pytest parameterization, then you can do that too: macro_rules! paramtest { ($name:ident, $thetest:expr) =&gt; { #[test] fn $name() { let (resource1, resource2) = setup(); $thetest(resource1); $thetest(resource2); } } } paramtest!(test1, |resource: Resource| { let result = do_something(&amp;resource); assert_eq!("foo", result); }); Tests are probably where I make the most use of `macro_rules!`. They are often fairly simple incantations and make it pretty flexible to write all sorts of parameterized tests.
This is really good info. Thank you for taking the time to share! 
This is super interesting! I've been working on RT synth stuff in Rust, and have never quite been satisfied with the state of the art on queues. (Currently I most often reach for the \`bounded\_spsc\_queue\` crate, which is a fixed-length ring buffer.) I would \*love\* if you would have the time to abstract your \`Queue\` and \`Item\` into a separate crate. &amp;#x200B; "The dream," maybe, is that I'd love to use Rust's generics to compose and optimize UGens in a JIT compiler, similar to \[Max/MSP's gen object\]([https://docs.cycling74.com/max7/vignettes/gen\_overview](https://docs.cycling74.com/max7/vignettes/gen_overview)). I'm not exactly sure how you might do that in a visual environment, without just generating Rust code. And, furthermore, I've found that my students reach for the higher-level elements in Max/MSP anyway, meaning that optimizing all the \[+\~\] and \[\*\~\] objects is maybe less crucial.
Sometimes this is easier said than done, take https://github.com/rust-embedded/wg/issues/41 as an example of how the panic machinery easily links in formatting code even when not strictly needed.
You actually can: fn main() { let a = 0; let a = 42; println!("{}", a) } [Compiles fine](https://play.rust-lang.org/?gist=25d23ab7e25c7f6408393610cd4131de&amp;version=stable&amp;mode=debug&amp;edition=2015).
Thanks! Is Blake2b from another crate?
Since SHA1 is not collision-resistant, I advise against using it in new projects.
Ups, I've used an example from [RustCrypto/hashes](https://github.com/RustCrypto/hashes) readme and forgot to fix this part. The example is updated.
Well, I need collision resistance as a way to know if file has been changed.
Consider using non-cryptographic hash or BLAKE-2b from [`blake2`](https://docs.rs/blake2/) crate, which is faster and more secure than SHA-1.
It might be worth rewording how you represent John's statements, he's usually clear in pointing out he thinks the borrow checker adds too much friction during game development. Saying he doesn't like the language (when he recently complimented the borrow checker as being a novel idea justifying a new language) misrepresents his stated opinion on a negative way.
Yes and No. It really depends what the abstraction is trying to expose. For example if your creating a temporary file the name may not matter so opening an existing file could be an error, or getting permission denied is easily handled by generating a new random name. This the crux of my problem. Most abstractions in the form of frameworks and libraries are normally just providing documentation, and authorial opinions on how code which does certain operations should look. Few actually solve underlying and avoidable errors which are trivialized by the frameworks goals. Further few offer methods of just telling the abstraction when errors are or are not dismiss-able by its existing methods. 
Aaarg Damnatio. It's true now it works.
C++ does everything to stay alive while rust kicking it in the ass.
When running into weird issues while using C FFI: use std::alloc::System; #[global_allocator] static A: System = System; this reveals e.g. double-free issues (`jemalloc` can silently fail due to the way it works). [https://github.com/polypus74/trusty\_rusty\_snippets](https://github.com/polypus74/trusty_rusty_snippets) \- for `pdb` snippet (`println!("... = {:?}", ...);` [https://github.com/vadimcn/vscode-lldb](https://github.com/vadimcn/vscode-lldb) \- for debugging, but current master is a bit broken and current stable has problems with some Rust projects, so I use my fork [https://github.com/pzmarzly/vscode-lldb/tree/patch-3](https://github.com/pzmarzly/vscode-lldb/tree/patch-3) If I suspect external dynamic library to be at fault, I set up [vagga](https://vagga.readthedocs.io/en/latest/index.html) Ubuntu container.
&gt; On the other hand, having worked with pytest, I've also found myself sometimes spending a lot of time trying to fit what I was doing into its framework, especially with all of the magic parameters. Right on. This is my experience as well. Types might help though, if a similar framework comes to Rust.
What is rr?
&gt; he doesn't think it's the right language for game programming specifically. I think that's the main point to remember when discussing Jonathan Blow, Jai, and Rust. He said repeatedly that he's looking for a language that has as little friction (for him) as possible so that he can go from an idea about gameplay to a prototype as quickly as possible. In a sense, his language of choice should be made with _him_ in mind. In contrast, I think that Rust is a language made with the _end user_ in mind: crashing software, or worse, exploitable software is a scourge on users, and Rust is an attempt at making that situation better. The Rust core team is fine with imposing extra rules and some extra friction on developers in order to reach this goal.
I mostly use the AK with explosive rounds to raid and clear out pesky neighbours or bugs as I call them 
Yes. I think you could do a better job in Rust with types and attribute macros.
Thanks, and sorry for that. I updated my comment to clarify.
Is there a Rust project for compression like Rust Crypto?
I tend not to name those kinds of things, especially results, I typically either chain some operation on the returned result or use `?` to pull the value out. For options, depending on the context I might chain on an `unwrap_or` if there's a sane default value, or I might `if let Some(thing) = maybe_get_a_thing(args) {`.
metal
I don't really appreciate the sarcasm. I see no part of any of this that is "bashing MS," or shaming companies for trying to make money. I'm obviously biased, but I think my position is a fairly reasonable one (from my above comment [https://www.reddit.com/r/rust/comments/9hi6v6/vscode\_alternative\_mitlicensed\_build/e6c6w1l/](https://www.reddit.com/r/rust/comments/9hi6v6/vscode_alternative_mitlicensed_build/e6c6w1l/)) : &amp;#x200B; &gt;For me it's not so much what I'm "worried about," I just prefer using (fully) open source applications over closed ones when I can. The official Microsoft build of VSCode doesn't come with any extra features or any compelling reason to use it over a completely open build, so I prefer the open build.
For context, is there a specific reason you need SHA1? There are newer hash functions available that can be faster and more secure. But I know some protocols require SHA1, so sometimes you don't have a choice.
Then you should not be using a broken hash, period. The only reason to use SHA-1 today is for compatibility with an existing protocol. 
Thanks, I'll give it a look.
Alrighty. Thanks for the input. I'll go digging through it.
Custom test frameworks will definitely improve the situation (as will the stabilizing attribute proc macros). Currently, a framework basically has to meet the `#[test]` API. You could almost certainly throw together a `#[paramatized_test]` macro to expand #[paramatized_test(params = [ "a", "b", "c", ] fn do_test(param: &amp;str) { .. } into #[test] fn __do_test() { for param in [ "a", "b", "c", ] { do_test(param); } } fn do_test(param: &amp;str) { .. } (You could do this with a `macro_rules!` even), or maybe even, with a bit more proc-macro love, #[test] fn do_test__0() { do_test([ "a", "b", "c", ][0]); } // and so on I'm on mobile I'm not typing this all out on mobile and this is all _without_ custom test frameworks. I'm not sure exactly what the current nightly situation is, but I'm fairly sure that the end target wants to support test functions with a different signature than the built-in test runner.
Do the code points defining that struct automatically get excluded in a release build because the compiler identifies it as dead code since the test functions get excluded?
I'd say if you want something modern and as fast as possible, use BLAKE2b like /u/newpavlov recommended. Or if your users demand a NIST standard, use SHA512/256.
Ahh, I was thinking it would be like those tests that can be intermixed with regular code.
This `match` is just the `?` error propagation operator, you should use it! let thing = get_thing()?; // Roughly equivalent to: let thing = match get_thing() { Ok(ok) =&gt; ok, Err(err) =&gt; return Err(err.into()), };
So does Debian. Patching everything to get rid of winapi isn't really worth it.
But what about the new accepted `dbg!` RFC? Is that not for debugging? Printf debugging is still useful as a temporary thing. Logs are for continuing tracking of execution, and `dbg!` is for quick `eprintln!("got here")` kind of things. Basically when recompiling is easier than setting up a visual debugger.
&gt; collision resistance [SHA1 was broken](https://shattered.io/) at least once already.
I've taken to using a full name for my "main" variable (e.g. `nextline`), and then if I need to temporarily destructure it, I use a fixed abbreviation (e.g. `if let Some(nl) = nextline`). It makes reading my own code pretty relaxed. Side note: I've got a lot of mileage out of `Option::map` when processing options, give it a shot!
C++ community should just write a Rust to C++ transpiler, so they can write Rust, and then pretend it was correctly written in C++ all along. ;) Seriously though, would Rust -&gt; transpiler be feasible?
Do you not get console output if you run GUI stuff in visual studio?
Hey fahhrd91, I've tried passing the AppState as a parameter but it didnt' work, I've god the same error but changing S with AppState on it
So is Brainfuck.
I'd never heard of it until I saw Carol Nichols &amp; Steve Klabnik use it at various times here on /r/rust, and it's become my preferred second-person-plural pronoun!
True, but the point was about shadowing `thing`. In that scenario, there'd be more complex logic, and I didn't really feel like coming up with a complete example. For example, maybe something like this: let thing = get_thing() if thing.is_err() { thing = get_thing_some_other_way(); } // shadow thing with the non-err value let thing = thing?; Again, this is just a toy example to show that shadowing is a thing.
I've had limited success with the IntelliJ/CLion debugger with the Rust plugin. It's gotten better in recent releases, but it unfortunately cannot debug a test in isolation.
logging, `cargo test` + random `println`'s Generally, I'm of opinion that if you need a debugger then you've failed already and you should take a step back, and analyze what are you doing wrong. You should have enough visiblity and debugability, that you don't need debugger. Make sure the buggy part is well tested first, then check if your logs are good enough, and if there's really no way to figure it out this way, stuff it with println until it's clear. Then double check your testing and logging assumptions.
I believe [this issue](https://gitlab.com/gitlab-org/gitlab-ce/issues/20217) to allow searching by language type would be the one. It's been open for quite a while, but looks like there has been a little movement on it recently.
While we can imitate a lot of the features using macros, one of the key aspects is lowering the barrier to do stuff. In pytest, I'm a lot more likely to turn something into a reusable fixture than in Rust even though the largest amount of work is creating a struct with an `impl Drop`. I also appreciate that pytest let's me do runtime skipping of tests, even in fixtures. I wrote one python package for $DAYJOB that had hardware integration tests. I wanted to keep the barrier low for contributors. This meant the tests should not expect everyone to have all hardware. I plugged into pytests argument parsing to accept hardware fixture identifiers, wrapped that in a fixture with a `skip` if the parameter wasn't specified, and used that in my tests. What blew me away is that I didn't see that I could `skip` in my fixtures but did it anyways and it actually worked as expected.
If you are willing to forfeit `#[test]` it is possible to disable rust's default test harness and get a plain `main` function to drive the tests. It can be quite cumbersome but when flexibility is important it is a possibility. (I had a need for generating testcases at runtime so I made a tiny test framework for that purpose, its limited but works quite well https://crates.io/crates/tensile).
like to point out, why carry all that bagggae of C++ and add more shit to it? I will never go back to C++. it has too much shit in it and I dont want to read a 500 page manual on how to use auto pointers.. then 2 weeks later they use something else.
I'm trying to build an executable with Diesel that connects to a MySQL database on OS X. I can build it fine, but it links to libmysqlclient dynamically, and I'd like to not require the user to have MySQL installed. Is there a good way to build it statically linked, or distribute the dylib with the executable?
Sounds like you're after (higher-rank trait bounds)[https://doc.rust-lang.org/nightly/nomicon/hrtb.html]
There was a long discussion on Hacker News about a month ago that might be relevant to people debating between the two: https://news.ycombinator.com/item?id=17850960
/r/rustjerk
&gt; Looks like they're now compromising soundness in order to get something working. Oh, they were aiming at detecting *all* lifetime issues before? That's... ambitious. Do you know how they were planning on pulling that off?
Which parts are rust? oh the gfx-rs I guess?
the compiler :P
Yes. They don’t use Rust directly. But they use a Rust project – \`gfx-portability\` – for Mac version.
It is in Arch Linux repos fwiw, https://www.archlinux.org/packages/community/x86_64/code/
VSCode + LLDB for interactive full featured debugging, though I also tend to insert `debug!()` statements during development.
&gt; could Rust code be translated to a reasonably idiomatic C++? Probably not.
Editions are always opt-in. All future versions of the Rust compiler will continue to support Rust2015, as well as Rust2018 (and further future editions when they become available). The default will always remain 2015, so that old and unmaintained code continues to compile in the future. If you want to use any newer edition, you have to specify it explicitly.
thank you for clarifying that
Things like this make me wish that rust had panic on integer overflow enabled all the time, not just in debug mode. Still nice this is being taken seriously.
&gt; why carry all that bagggae of C++ Because backwards compatibility is a fact of life for a language that's so widely used for revenue-generating software? &gt; and add more shit to it? Because people want to improve the language? &gt; I will never go back to C++. That's easy for an individual to say, but it isn't nearly that straightforward for companies with large amounts of revenue-generating C++ code. &gt; then 2 weeks later they use something else. Isn't this more of an issue for web-related code? I didn't think C++ is affected nearly as badly by Framework Du Jour Syndrome
Why not provide updates for previous affected major versions? Seems like not a huge burden to produce 1.26.3, 1.27.3 and 1.28.1…
In general, we only support the latest stable Rust. We’ll make exceptions in cases of extreme severity, but this isn’t it.
I've thought about something like this, but ended up making a trait like `into_ok` instead. Wanted to bea little bit more explicit in that it only converts to the `Ok` variant.
Where's the rfc you are talking about?
&gt; C++, as usual, tries to include whatever good feature exists in other languages, but fails to do it properly due to huge pressue of backward compatibility. Unfortunately, business considerations are quite strong when there's so much C++ code used in revenue-generating software. It's a tradeoff between language purity and pragmatism. &gt; And now we get unsound feature that will make us feel safe while program eats our laundry. Couldn't you make the same sort of argument for existing compiler warnings in pretty much any language? They aren't complete in that they aren't guaranteed to catch all code that should theoretically trigger a warning (or end up catching code that shouldn't trigger said warning(s)), they make devs feel better about their code, and they don't prevent ill-behaved programs from compiling. But using them well almost always results in a better codebase. This falls under the same umbrella, in my opinion. No, it's not sound; yes, it makes devs more confident in their code; yes, programs can still eat your laundry with this enabled. But using it hopefully results in fewer errors, and I'm pretty sure everyone can agree that fewer errors are better. 
I'd remove pattern autoref/-deref. In my opinion, the wins aren't that big and it removes one of the visual cues we had about the types, namely how much indirection they had.
People want to improve the language but adding more and more features make the language more complicated and harder to use instead of the opposite. In fact, every year I hear more and more ppl saying something like 'I will never go back to c++'. My company decided to use rust and I hear sentence like that on nearly every rust developer interview. And I'm not surprised, I invested years in mastering c++ 10 years ago and I think throwing it was one of my best decisions in life.
Whenever I have several closely related variables that differ by type, I add a suffix to the variable name indicating the type, so I can remember what is a string vs. the integer Option vs a parsed unsigned integer vs a validated odd integer and so on.
&gt;could Rust code be translated to a reasonably idiomatic C++ I'm guessing this would be quite challenging given that the programming styles and idioms in Rust and C++ are so different. For example, enums and matching/destructuring are pretty common in Rust from what I've read, but as far as I know that style of coding isn't particularly prevalent in C++ code. I'm guessing "well-written" C++ code that does the same thing as reasonably complex Rust programs would have a significantly different architecture and so would be quite difficult to transpile to.
Yes, test frameworks solve all sorts of problems. In the work I do though, they just tend not to solve the right ones, or not solve the problems I think are most important or otherwise make the task harder or even _increase_ the barrier to do stuff. There is value in flexing the tools available to you that _everyone_ is familiar with before reaching for the big and powerful stuff. Reasonable people can disagree. Experiences can diverge. :-)
&gt; You can enable it for your own code if you’re willing to take the performance hit! But it wouldn't catch this bug unless you also recompile libstd yourself, since the official standard libraries are compiled without checked overflow. This bug wasn't even caught at run-time in Rust programs compiled in debug mode, because those still link to standard libraries that were compiled in release mode.
My bigger issue is refactoring code. Best example I can give is changing a `-&gt; String` into `-&gt; Result&lt;&amp;'static str, String&gt;` Any `"Failure!".into()` calls now implicitly return `Ok(&amp;'static str)`where before `.into()` was creating a `String`. Wouldn't cause any runtime errors as you'd just get ambiguous method call errors, but still. It's a source of implicitness. 
That's true; good call. Someday...
It seems Rust doesn’t have something like a map2, extending the option behavior into a tuple. Additionally, I find the use of “and_then” to be a little weird for what some other communities call “bind”. Are here any commonly accepted utility libraries out there? And is there anywhere I can read about the design of the Option interface? Thanks!
github.com/rust-lang/rfcs/blob/master/text/2361-dbg-macro.md
&gt; If you are not using str::repeat, you are not affected. While the functionality seems a bit niche perhaps, but it might be interesting to have a way to determine whether any of your dependencies use this function. Best thing I can think of is compiling in debug mode and grep'ing the debug symbols for the function name. Devil's advocate example: some suid root binary that uses a terminal library that parses an integer from the `COLUMNS` environment variable and passes it to str::repeat to print a full row of dashes. 
Distros that are shipping older affected versions of rustc can apply the patch cleanly to their version; it is common for distros to maintain backported patches for this reason. The Rust project doesn's support any older versions. It might be the case that at some point in the future certain older releases are supported for longer terms than a complete release cycle, as LTS releases for example, but at the moment there isn't much demand for that.
&gt; I think lldb and gdb can both support remote debugging, so you could connect over an opened port to your container. We have an environment at work like that (for C++, but same thing applies for rust). Remote debugging into the container can work but there are a few catching points: * You have to set up path mappings since they usually don't line up inside vs. outside the container. * If the environment inside the container is different from outside (e.g. different version of glibc) you have to extract the container's filesystem to be visible outside the container so that you can set the sysroot for the outside GDB. It might be possible to avoid this with newer versions of GDB (I've seen references to remote file transfers) but I'm not sure. 
Thanks, those are some really great pointers!
The fact that stdlib is full of unsafe code yet is not covered by tests well enough to catch such regressions is concerning. There is a community effort to cover some stdlib functions and data structures with QuickCheck at https://github.com/blt/bughunt-rust - and it could really use more attention! It mostly focuses on complex, stateful things such as VecDeque ([already found vulnerable once](https://cve.mitre.org/cgi-bin/cvename.cgi?name=%20CVE-2018-1000657)) or HashMap. I wonder if test for stateless functions such as `str::repeat` could be automatically generated based on the signature? For stateless testing all you need is generate a random string, generate a random number (with some bias toward special values such as MAX_INT, as QuickCheck already does), run `str::repeat` with both as input and check that Address Sanitizer does not complain (panics are allowed). This can be combined with a feedback-driven fuzzer for more intelligent "random" input. That doesn't sound hard to implement at all, could be applied to new modules or functions almost automatically by generating tests based on definitions, and would catch this issue as well as many more potential vulnerabilities. Is there any reason why this can't be done that I'm missing?
Personally, I wish Rust used the newtype pattern more. The culprit here is the innocuous expression `let mut buf = Vec::with_capacity(self.len() * n);` If `[T]::len()` hadn't returned a generic, "untyped" `usize`, but instead returned an integer type that specifically represents an array size, e.g. `struct ArraySize(usize)`, then we could enable panic on overflow for that particular integer type without sacrificing performance for other integers. Unfortunately, newtypes are cumbersome to use in today's Rust, which is why they aren't used much.
Have you considered shooting off a pre-RFC in the URLO&gt;
You can use [cargo vendor](https://crates.io/crates/cargo-vendor) to download all your dependencies in source form, and then ripgrep through them.
[removed]
The task boils down to the following: 1. List all methods on `str` in stdlib 1. Parse types of input arguments for functions 1. Generate Rust code based on input argument types - in the simplest case, insert appropriate generator function into a template Does the tooling for doing such things with Rust code exist? If yes, I can handle the rest. I'd also appreciate pointers on applying it to stdlib code.
that's...exactly what my post is about? I don't quite know what you're getting at
If it's not sound, and all it does is turn *some* UB-producing code into a compile diagnostic, why are they even bothering with submitting this stuff for standardization? In a Technical Report (TR), even? Shouldn't this be a pure quality issue, as with, e.g. ASan, valgrind and the like? It's a bit confusing, I think.
For C# I wrote myself a little utility that I named "recon", the source to which I cannot find. The gist is: The first arg is the process to run, the remainder are its arguments. Reassemble the argument line, Process.Start the process, and redirect its standard out and error to recon's. Then recon is running in a console window and echoing your GUI's console.
I often use \`opt\_thing\` and \`res\_thing\`. I know, this is not idiomatic, but I do not like shadowing and prefer explicitness.
 using System; using System.Diagnostics; using System.Linq; internal class Program { private static int Main(string[] args) { try { string fileName = args[0]; string arguments = string.Join(" ", args.Skip(1).Select(ProcessArg)); using (Process process = Process.Start(new ProcessStartInfo(fileName, arguments) { RedirectStandardOutput = true, RedirectStandardError = true, UseShellExecute = false })) { if (process != null) { process.ErrorDataReceived += (o, e) =&gt; Console.WriteLine(e.Data); process.OutputDataReceived += (o, e) =&gt; Console.Error.WriteLine(e.Data);; process.BeginErrorReadLine(); process.BeginOutputReadLine(); process.WaitForExit(); return process.ExitCode; } } } catch { } return 1; } private static string ProcessArg(string arg) { string text = arg; if (text.Contains('"')) { text = text.Replace("\"", "\\\""); } if (text.Contains(' ')) { text = "\"" + text + "\""; } return text; } }
Is there any... "reasonable" use-case where wrap on overflow is desired? However, I think panic-ing on integer overflow is kinda worst of both worlds - it's not undefined behavior, so the compiler can't optimize for it, but also it's less efficient to do, since most back-ends can handle wrapping efficiently already.
I opened an issue with the request [here](https://gitlab.com/gitlab-org/gitlab-ce/issues/51759). You also might want to subscribe to the [scraper's tracking issue](https://github.com/rust-ops/rust-repos/issues/20).
&gt;It breaks previously supported behavior, so I couldn't see the change being made anyway. We defined the rules specifically so that this behavior can change. 1. Overflow is a "program error", not UB 2. when `debug_assertions` is on, implementations must panic on overflow 3. Overflow is well-defined as two's compliment wrapping There's no requirements on which behavior is required when `debug_assertions` is not on, which is the case in release builds, by default.
That was not reported as a security vulnerability. It should have been treated as one, but nobody involved treated it that way. Basically, a process mistake.
It is used fairly widely in an embedded context, as well as at lower layers of operating systems development. For example, if you want a 16 bit nonce for your packet IDs, it is easy to just do something like: nonce += 1; send_packet(payload, nonce); Or, I have used these when implementing math in a fixed point library (where the hardware has no floating point). You can represent the unit circle as where the angle is 0..u16::MAX. So if you have an angle of 180 degrees, and add 270 degrees, it correctly overflows back to 90 degrees. 
&gt; Is there any... "reasonable" use-case where wrap on overflow is desired? When you have more than a single add or mul operation, the simple `checked_op` implementation can be more restrictive than necessary, whereas wrap might lead to a correct result. But it's probably still worthwhile to require explicit annotation for these "tricks" (either converting to `Wrapping&lt;&gt;` and back, or using an `unsafe` block, or whatever) and use checked ops for everything else. Particularly because such calculation *do* need to check for non-overflowing inputs if they are to be correct, and this can be non-trivial anyway.
Numerics in any language are quirky. Having mathematical notation at all in a programming language's syntax can lull developers into a false sense that they understand what their code does. There are just so many pitfalls. Division by zero faults. Multiplicative overflow *is the norm*. Floating point addition doesn't commute. And comparison is totally broken. I think it would be better language design (not talking about Rust, but in general) to abolish the built-in arithmetic operations entirely from the base syntax. And if you wanted the notation for convenience, it would have to be something that you opt into explicitly. And then hopefully the ceremony of doing so (just as with the case of Rust's `unsafe`) will lead you to be mindful that arithmetic is fraught with exceptional behavior.
I think if you do that the stack frame for your function may be slightly larger, which I believe counts as a performance penalty. Compiler might be smart enough to optimize this out, however. Also, for larger data types, this pattern would lead to a lot of wasted cycles copying data instead of reusing data from the past.
`precedence_list.insert(1, "clippy");`
Neat.
&gt; Isn't "adding more and more features make the language more complicated" true for any language, not just C++? Almost and this is sad. When I follow rust evolution, ppl are afraid that it 'become second c++' in terms of features bloat. But atleast for now, it is reasonable big. And there are already threads like 'what features would you remove from rust if you could redesign it'. Thats good. I'm also afraid that c# just started failing into same issue. You are right that not are features make language _harder_. Some things are nice, constexpr is great example. But on the other side, new way to initialize vars (`{ }`) co-existing with all the old ones is a mess. &gt; Now I'm curious how many people are taking a new/second look at C++ after the changes in recent years. I think all of the ppl I talked with were excited about c++11 before its release and then they were very disappointed. So were I. I gave c++ another chance a couple of months before I've heard about rust (I guess it was 2014 or 15). I started creating a game, which is something where c++ should shine. It didn't. It only reminded my why I switched to c# years ago. I've used some of the new features. I definitely tried to use proper smart pointers (I've read a lot and still not sure which one should I use. I remember some recent video, I guess from Herb Sutter, which tried to explain it, but it turned out that one should even use raw pointers in some cases... It really needs way too much effort to understand it because other languages show that it is not necessary). Since then, I only watch videos and read news and unless breaking changes happen, I'm not going to write a single line in c++. 
iceweasel used to have to remove various non-free bits of Firefox, before the maintainer got them removed upstream. (Also, Firefox's trademark policy got more reasonable, and Debian ships Firefox with the branding these days.)
It doesn't mention but the problem comes from underlying `slice::repeat`
&gt; I think it would be better language design (not talking about Rust, but in general) to abolish the built-in arithmetic operations entirely from the base syntax. I think there is a fairly strong case for doing this wrt. *floating point* operations, which are badly behaved enough that expression notation makes no sense at all for them. Then again, lots of people seem to be happy with `-ffast-math` compiles, which rely on neglecting the very same "exceptional behavior" that you're pointing out here. I think both use-cases *can* be supported at the same time, but it's not exactly trivial.
Awesome! I've been following the development excitedly.
Isn't "[mutagen](https://github.com/llogiq/mutagen)" somewhat tailored for that?
Yes, because that function is not stable.
&gt;If it's not sound (not even in the sense of having a well-defined sound subset, like Rust without unsafe), and all it does is turn some UB-producing code into a compile diagnostic, why are they even bothering with submitting this stuff for standardization? Herb actually addresses this in the abstract: &gt;Initially, I did not intend to propose this work in WG21 for Standard C++ for two reasons: &lt;snip&gt; Second, I believe much of the value of this work can be realized if dangling detection could become de facto implemented in C++ compilers (similar to some other popular-and-common warnings), even if it were never de jure standardized; as long as the major C++ compilers could reliably diagnose these problems as common vendor extensions, it would improve or eliminate C++’s reputation for being a breeding ground for dangling pointers/iterators/string\_views/etc. &gt; &gt;However, since this work was started, there have been parallel EWG/LEWG proposals from other authors, notably \[P0936R0\], that propose de jure standardization of widespread annotations in the language and the standard library for cases that are covered by this work (and, in this proposal, typically without annotation; §2.6.2 describes how all examples from \[P0936R0\] are diagnosed without any annotation). So I thought I should at least submit this work as a WG21 paper and give an evening session about it at a WG21 meeting, possibly in San Diego or in Kona. If there is strong committee interest in standardizing these errors so they are available in the box in all C++ compilers, I could do the additional work to turn this into an actual EWG/LEWG proposal (but even then I would prefer to initially target a TS, not C++23).
You also have to remember that you have to know what the company is using. It's not very likely a company using C++ for their projects is just going to let you start making libs in Rust. If most of the codebases in your field are C++ then that is what toy should learn. 
I have written a [blog post](https://medium.com/@shnatsel/how-rusts-standard-library-was-vulnerable-for-years-and-nobody-noticed-aebf0503c3d6) on the history of that one back when I filed a CVE for it. Check it out if you want to learn more - or perhaps skim it, it might be overly detailed from the perspective of someone familiar with Rust.
Thank you for the nice and clean communication. You rock! 
&lt;3
I'm a beginner with Rust but this makes me think that if Rust had an equivalent to Ruby's [tap method](https://ruby-doc.org/core-2.5.1/Object.html#method-i-tap) (which I don't think it does) then you could end your chain of method calls with \`.tap(Ok)\` to get the same effect without the ambiguity of `into`. This could be implemented for all Sized types similar to OP's suggestion like this: trait Tap { fn tap&lt;R&gt;(self, f: impl Fn(Self) -&gt; R) -&gt; R where Self: Sized; } impl&lt;T: Sized&gt; Tap for T where T: Sized { fn tap&lt;R&gt;(self, f: impl Fn(T) -&gt; R) -&gt; R { f(self) } } fn main() { println!("{:?}", " foo ".trim().tap(Some)) } ([playground](https://play.rust-lang.org/?gist=b64640a738a81bffcb80cd5b9e397fdf&amp;version=stable&amp;mode=debug&amp;edition=2015))
Pittsburgh represent!
Why are so many of these simple standard library functions implemented as unsafe code?
You can, but not by default. The windows GUI subsystem doesnt create a console window, but you should be able to just call `AllocConsole` at program start to get one, but then you need to redirect stdout and friends to it.
Hey guys does anyone have any experience with the RustDT eclipse plugin that aims to provide IDE functionality for Rust language inside Eclipse? Having Rust toolchain configured (I believe) on my Windows 7 box I've installed the plugin and also successfully installed the RLS (language server). Now the IDE provides me with the go to definition functionality and some autocompletion but the least is very poor. If for instance I write Vec:: I get no suggestions that make sense no matter if I press CTRL+Space. Is that normal, e.g. the state of the plugin/language-server is very immature or I am missing something? Sorry I am very new to the language, wanted to play with it so bare with me if the question seems trivial.
Fast simulation of digital logic, but that's about it.
&gt; When I follow rust evolution, ppl are afraid that it 'become second c++' in terms of features bloat. What features do you consider to be bloating Rust? And of course, one person's feature bloat is another person's killer feature. &gt; And there are already threads like 'what features would you remove from rust if you could redesign it'. And C++ doesn't [have](https://www.reddit.com/r/cpp/comments/2e52t4/if_you_had_the_power_to_completely_overhaul_c/) [these](https://www.reddit.com/r/cpp/comments/7639sf/what_would_you_change_in_c_if_backwards/) [threads](https://www.reddit.com/r/cpp/comments/7uo9br/what_would_a_c_remastered_look_like/)? I think people are well aware that C++ is a mess; it's just that their hands are relatively tied. &gt; I think all of the ppl I talked with were excited about c++11 before its release and then they were very disappointed. Yeah, no kidding. Unfortunately, while C++ is evolving much more quickly than it has in the past, it is by no means extremely fast. And it's probably better that those features got put off to be improved rather than be frozen into a state that no one is happy with. &gt; I started creating a game, which is something where c++ should shine. Well, even for games, C++ isn't always the right answer. I think C++ in its current state does much better when you need control, not necessarily if you need productivity or ease of use. Other languages do just fine with games, too. &gt; I've read a lot and still not sure which one should I use... It really needs way too much effort to understand it Are smart pointers hard? I thought they were relatively straightforward in principle; it's more that the problem they're trying to solve (lifetimes and ownership) isn't easy, and reducing a particular problem to one that fits neatly into the solutions `std::unique_ptr` and `std::shared_ptr` solve isn't simple. &gt; because other languages show that it is not necessary No, they may not be strictly necessary, but they are undoubtedly useful in C++. Other languages deal with the issues that C++'s smart pointers try to solve by not having pointers in idiomatic code (Java, C#, Python, Ruby, Javascript), ignoring the issue completely (C), or by using other "better" mechanisms (Rust). C++ doesn't want to just ignore the relevant issues, but can't use a VM and isn't compatible (yet?) with compiler-based tracking of lifetimes/ownership. So smart pointers are the solution that fits within those constraints.
One answer to this question is "because it needs to be". &amp;#x200B; Another answer to this question is that, historically, "needs a lot of unsafe code to implement" was a deciding factor in "should be in the standard library." The idea is that the standard library is audited better than a random crate, and is likely to have the most experienced rustaceans working on it.
Could you elaborate on why the casts are zero-cost? Is that a property that LLVM or rustc guarantees?
rustc actually, you can see it here: https://doc.rust-lang.org/reference/expressions/operator-expr.html#semantics
You can delete comments yourself, there should be a delete link under your comment or if you're on mobile, it's probably in the `...` menu when you select your comment in the app.
I'm not seeing it. pub fn repeat(&amp;self, nn: usize) -&gt; String { let mut ys = String::with_capacity(nn * self.len()); for _i in 0..nn { ys.push_str(&amp;self[..]); } ys } 
Are you trying to map `Option&lt;T&gt;` to `Option&lt;(U, V)&gt;` or to `(Option&lt;U&gt;, Option&lt;V&gt;)`?
You're not far from the code as it was before [PR48657](https://github.com/rust-lang/rust/pull/48657). In this change, `unsafe` was used to improve performance.
Haskell's great for writing a C compiler, but that doesn't mean writing C code is therefore a great way to write Haskell. The Akka DSLs might be great languages for writing actors and building graphs, but that doesn't mean they're a good way to write Scala. The whole value proposition of a DSL is that you don't have to write the original language. This means the language *will* become inconsistent, because everybody is constantly writing code which tries to avoid using it. In part, it can't be helped, because any time you use a new library you're introducing new things, but if you need language support for custom syntax on top of that, you're either being inefficient or going out of your way to not use the language's existing mechanisms.
&gt; Haskell &gt; * Performance: ?/5 Lol. If you're dealing with inherently stateful I/O, Haskell isn't that much worse than imperative languages. `do-notation` by itself pretty much is an imperative DSL. It just means you end up writing 2 different languages: normal, pure, functional haskell, and impure, imperative do-notation.
How much work is being done on improving the ability to evaluate rust expressions in gdb? I'm just curious because that would be super cool.
Thank, that sounds interesting. Why do you use pur gdb more if rr has more features?
The operators would not be "inaccessible" though; they'd just be hidden behind a language feature, say a macro like `float_arith!{a + b * c}`. The point is that by using such a macro, you're acknowledging that `+` and `*` will have quirky semantics.
People scream bloody-murder when they can't use +, -, \*, /, etc. with things like BigInteger and BigDecimal in Java. You'd think the sky was falling even though Java's way of doing it (forcing you to specify either via a Context object or on parameters to the arithmetic methods the exact behavior you expect with respect to rounding, precision, scale, overflow, etc) is arguably the superior solution (compared to for example C# Decimal type).
Right, I for some reason got it confused with another project that I saw that I can't recall right now....maybe it was "proptest"? Yeah, I think that is what I was thinking about perhaps.
Sure, but what other semantics would they have? If you don't say what the quirks are, you're just wasting time with ceremonial keystrokes. The ability to type them does not imply any understanding of what the quirks are.
No great reason. rr has infinitesimally more friction. I.e. `rr program`, let program finish/do whatever I'm interested in, `rr replay` instead of just `gdb program`. I'm pretty sure I've hit some bugs in rr that weren't there in gdb but I couldn't name any off the top of my head. There are certain circumstances (e.g. kernel development) were `rr` doesn't work.
The turbo fish rfc rather explicitly makes old previously valid code invalid. E.g. [(a &lt; b, c &gt; (d))](https://play.rust-lang.org/?gist=94a4c94e26e5f1a1e9e008dca39d2515&amp;version=stable&amp;mode=debug&amp;edition=2015) where a is a number. I haven't read the const fn and if/while let chaining threads.
This sounds reasonable on first glance, but I think that panic on overflow for `struct ArraySize(usize)` would be likely to cause nearly as many performance issues as just enabling panic on overflow. The problem with panic on overflow is that you have to check for overflow on every operation. `usize` is generally used for allocating buffers and indexing, so panic on overflow for `struct ArraySize(usize)` is likely about equivalent to just enabling panic on overflow for `usize` in general, and those are likely a lot of the overflow checks in many programs.
I strongly agree that these type of breaking changes are the type that I believe the rust team explicitly said they would not make, many times (that RFC, blogpost, comments here and on HN, etc). I've also been of the opinion since the rust first started to prepare to stabilize itself that it was slightly too early and stabilized far too fast. As such I'm surprised it took this long for the rust team to really start breaking those guarantees. I'd even cautiously support it, except the edition system means it's now entirely unnecessary. The value lost by breaking any old code, and the reputation hit associated, seems far greater than waiting for the edition, and if necessary pushing the edition back long enough to get these changes (or at least changes that make them backwards compatible) in.
&gt; I think it would be better language design (not talking about Rust, but in general) to abolish the built-in arithmetic operations entirely from the base syntax. And if you wanted the notation for convenience, it would have to be something that you opt into explicitly. And then hopefully the ceremony of doing so (just as with the case of Rust's unsafe) will lead you to be mindful that arithmetic is fraught with exceptional behavior. Well stuff like `Integer` in Haskell doesn't bother me - as far as I know it behaves properly by mathematical standards and it's fast enough for most use cases. But ya, I would at least prefer that stuff like `Integer` be the default, with stuff that breaks mathematical rules for performance reasons like fixed-size ints and floating point arithmetic being explicitly opt-in rather than something you're encouraged to use by default.
Thanks! Will do. So far I haven't had any issues
This is just not something with a universal answer - there are good reasons for wanting it either way, it just depends on what you want. Best thing that can be done is make it clear what the default choice was and how you can change it.
[PR54004](https://github.com/rust-lang/rust/pull/54004) will probably land soon and this will "improve" (it's mostly broken currently) the inspection of enum values which imo is very important for the general debugging experience. I am not sure about the general evaluation of rust expression though, /u/tromey?
Right. But even something like `usize`-based index arithmetic causes these kinds of bugs. The thing that surprises me in Haskell (but is universal) is how irregular the numeric tower is. I don't think typeclassese or traits address the issue very well at all.
Oh! You are the third person to suggest proptest to me in the last 8 hours. In unrelated threads. Proptest evangelism strike force really is a force to be reckoned with! :D For posterity, and in the interest of not getting any more suggestions for tools I'm already aware of, I'll list all the ones I've already considered: * https://github.com/BurntSushi/quickcheck * https://github.com/altsysrq/proptest * https://github.com/rust-fuzz/cargo-fuzz * https://github.com/rust-fuzz/afl.rs * https://github.com/rust-fuzz/honggfuzz-rs * https://github.com/CENSUS/choronzon However, suggestions for tools doing Rust code **introspection** or at least parsing would be *really* appreciated.
Switches to start debuggers in every configuration would be awesome. I'm primarily on Windows and a `cargo run --vsdb` would really be extremely helpful.
&gt; I like the idea, but only if it means those symbols can be used to resolve some ambiguity in the language or simplify other things. They can be used to simplify the use of traits like `Num`, which is a pretty big pain point, e.g. in Haskell. The point of the special syntax would be to make the symbols available for use as pure ad-hoc additions, with no rigorous semantics being implied.
Fixed-size ints don't really "break mathematical rules", though. They just have a wrapping behavior that's somewhat counterintuitive, and means we need to carefully distinguish between "this fixed-size int is expected to wrap" and not. But that just means you need checked ops as a sane default, with Wrapping&lt;&gt; and bignum being easily-available alternatives.
The bug occurred because there is currently no way to append contents of a vector to the same vector, so `unsafe` was used. And someone forgot add an overflow check. Curiously, I have recently [proposed](https://internals.rust-lang.org/t/pre-rfc-fixed-capacity-view-of-vec/8413) a safe abstraction for doing exactly this. The security vulnerability was discovered once one of the participants of that discussion dug into how that's currently solved in stdlib. This makes me think that I might be on to something with that proposal.
And worst time ?
Absolutely. I mean to endorse `Integer`, not the wild numeric hierarchy Haskell somehow ended up with. The classes should ideally probably be more algebraic, like group, semiring, etc., but I doubt a change like that will come any time soon.
Yeah too soon. Maybe once we have proper existential type though.
`b rust_panic` doesn't work half of the time (due to codegen units, ThinLTO or something like this, not sure) and I found `b __rust_start_panic` to be more reliable. For C++ code you can use `catch throw` to break on exception and I assumed that it just breaks on unwinding start, but apparently not, because it doesn't work for Rust panics. It would be nice to make it work.
Why not implement the Index trait? First index returns a temporary, undocumented, intermediate struct and second index returns an ImageView. Then you can get the whole image with `image[..][..]` like we do with slices and vectors.
Doesn't fp overflow just result in an inf value in rust?
Do you mean a single test? If so it can, you have to hit the run button next to the individual test. This saved me a lot of time once I found it (was struggling to figure out a bug doing the Iridium tutorials when one of the tests was failing).
Quick check with a syn based generator maybe?
Yes, that's what the IEEE754 standard for floats requires, I believe. The above just applies to integers.
I’m taking about integers. Floats follow IEEE
this is insubstantial.
No, it doesn't. `Index` returns a *reference* to something already part of the subject value. It cannot create and return a new value.
is rr working on mac?
I’m trying to take a tuple of two options, and do the regular map behavior if they are both Some, and None if either is None. Otherwise I have to use and_then and a nested map to achieve he same thing. I’m just trying to avoid the nesting here. 
Yeah. The problem with the algebraic ones is that it *still* doesn't give a good breakdown. Fixed-width integers form rings, of course, but not ordered rings. Floats don't form a semiring. I think Rust did the world a big favor to show how stupid it can sometimes be by refusing to make floating types comparable or orderable.
So at work we were trying to do some cosine similarity queries using sklearn's built in tools for that. Parallelism was puny and depending on the input memory usage would blow up and we'd get tons of OOM errors. We tried Gensim and a bunch of other stuff, nothing was fast enough to our liking and more often than not it would use a ton of memory. Eventually I got fed up with all that, serialized the matrix we were querying with JSON, and wrote a little Rust script that would read it with serde and basically shred those similarity queries with Rayon. The result is absurd levels of parallelism, all while using less RAM than Reddit's Chrome Tab. Special thanks to this subreddit and the rust-begginners IRC!
I have had a pet theory for a long time that operators shouldn't be tied to typeclasses / traits at all. Symbols are too fluid for that, and any concrete choice of typeclass / trait would be a disservice to anyone who works in another domain. If I say `*`, so I mean multiplication? Group composition? Monoid composition? If I want group composition, do I use `*` or `+`? Do I not use `+` for floats, since you don't have associativity? (That's seems pretty lame, since floats are the more important place for having clear notation).
Wow that's a lot of cores, that's your load average while running this?
From assembly point of view, `u32` and `i32` are identical, the only real distinction is that you use different instructions sometimes, for instance on x86 you use `imul` instead of `mul` for multiplication.
Well, yeah, you're right. The original mistake was using symbols for generics that don't have to be balanced (since they are used for comparisons as well). It would have increased Rust's "weirdness budget" to use a different generics syntax than C++, but it would have made some things a lot easier, including macros.
&gt; c - simplicity 5 / 5 I may be wrong but c is not simple. 
Yes you are wrong.
hehehe :P 
That's a bit scary!
`cargo install cargo-edit`
xcode via lldb, but sometimes just regular lldb on osx. I Frankensteined [this](https://github.com/mtak-/rust-xcode-plugin) which surprisingly makes the GUI super [useful](https://postimg.cc/NyRBSTYp).
I think someone had gotten cargo fuzz to work with the stdlib at some point. It's all compatible it's just that rustc has its own shim build system. An easy thing to do is just rip out code for various abstractions and fuzz that directly. If folks want to help with this let me know, most of this is just writing fuzz targets (test cases that take the fuzzer input and turn it into a set of actions to perform)
Listing all methods is tricky without having a module level proc macro while compiling the stdlib. I suggest just directly scraping that off of the `str` rustdoc page, and for the non generic ones, note down the types of the arguments. For fuzzing you don't even need to insert the appropriate generator function, cargo-fuzz supports accepting random types provided they implement `Arbitrary`. So you just need to write a fuzzer that takes the argument list and self type as input. Generic methods are trickier.
Thanks for the success story!
My current project, powered by Rayon: https://github.com/oconnor663/bao On a 96 core AWS machine, it hashes 60 GB/s &lt;3
It's usually stated that C is a simple language, meaning it has few constructs and little to learn. It says nothing, though, on the simplicity of usage.
Even if it is not stable, it should be mentioned since this is the function where problematic code is
I can't wait to try this!
That worked, thank you :)
Thanks!
I think the confusion here is somewhat in the likes of simple (complexity) and easy (to use). Think of it as chess has a simple ruleset but it's not easy to play. There are a lot of moves, depending on context, to get you in a bad position (without even knowing it) that will make you loose. 
Hey, I remember seeing the reddit post for that the other day, at the time I thought "Well this is interesting, but I don't think it will be relevant again soon", crazy that they discovered this right after you made your proposal, good luck o7
Well, sure. Even with this we shouldn't rely __only__ on Crater for those decisions. I still think this will be useful for companies, also to make sure no regressions affecting them will slip into a stable release.
You’re not wrong. Superficially C is relatively simple, but there are tons of small but important details around things like overflow, pointer aliasing, ...
About the `TUI mode`, there's also the very minimalistic ncruses interface [cgdb](https://cgdb.github.io/) which - in contrast to a lot of other gdb wrappers - just always works.
Even shorter (well, two letters!) than what you're proposing, just write this, which works today: fn something_which_may_fail(some_data: SomeData) -&gt; Result&lt;MyData, MyError&gt; { Ok(some_data.rust()?.mold()?.yeast()?.funghi()) } 
&gt;I feel like `Try` should be implemented for `()` . That way, we can use ? to return from functions with no return type when errors occur. If I understand what you mean, hard disagree. `?` is for error propogation; I don't want it to start being used for silently swallowing errors.
It’s a Rust language spec guarantee: „as“ is specified as a no-op for integer types of the same size.
Additionally, if the memory usage is so low, and OP is using a 64 core system, he might be running into some NUMA bottlenecks. Make sure to copy the data once for each core complex (unless it's small enough to fit into the local cache, in which case it won't matter)
Impressive, most impressive. And I want your computer.
Very keen to hear more. If any of your code is public, would love to take a look
Yeah that is typically easier. But doesn't work as well if you want it in your editor
I pushed a new version of the code that should also create a lib. Could you have a look and let me know whether that works for you?
It's all based on the flawed assumption that addition, subtraction and all other basic mathematical operations are simple. 
If you don't mind me asking, what hardware is that? What is your CPU configuration? How much RAM do you have? Asking, because my htop looks exactly the same :D I just built a system with 2x AMD EPYC 7301s and 128GB RAM to run server and compute workloads on. I got 7301s because they have absurdly huge caches (64 MB L3 for a 16-core CPU).
Had similar experience with Rayon, needed to do some high resolution Fourier analysis at &lt; 1Hz on a large sample series. I wrote the code with Rayon in mind, but was still blown away by the dramatic effect of adding the int_par_inter() in the end. I got 100% utilisation on all cores, and speedup x 32.
I do find it particularly ironic that I noticed it after I posted the code of the method in a thread about how people write unsafe code unsoundly...
Hi. I had this problem before and I wrote a browser extension to handle it. I posted it here before and it handles more than just rust dependencies. [Check it out](https://github.com/BrainMaestro/packagehub) (sorry for the plug) 
In terms of useful work, though, that's half the speed and twice the memory, so... Also, "safe version of ptr::copy_nonoverlapping" exists: it's called [`[T]::copy_from_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.copy_from_slice). But the problem is in proving to the Vec that you initialized the memory, not in the copy, so that doesn't help.
LLVM doesn't have different types for signed/unsigned integers: http://llvm.org/docs/LangRef.html#integer-type
Testing this stuff is easy, the problem is that we cannot do this without making rust-lang/rust unusable. We can test many methods on libcore for all inputs (e.g. all methods taking a single 32-bit argument or smaller), exhaustively test all other methods, using fuzzing, sanitizers, code coverage to drive the tests, etc. Testing `core::arch` minimally takes ~30 min, per build bot, ~20 buildbots. Testing `core::simd` minimally takes ~50min, per build bot, ~30 build bots. Testing all of core and std semi-exhaustively would take a very long time.
Ha "pronounced bough"... to rhyme with cough and though and through. Maybe "rhymes with cow" instead?
The load is measured in # of cores used. There are 64 cores each working on 100%. The load is 64 here. If all the cores would run at 50% the load would be 32, ...
Would https://crates.rs/crates/quickcheck_derive have any inspiration for you?
I get that doing the full run for every PR might be prohibitive, but doing it for every release should be viable. There are other ways to cut down on computation time. Large chunks of stdlib are platform-independent, so fuzzing just one architecture would be sufficient. When it comes down to it, testing is embarrassingly parallel. Also, [OSS-fuzz](https://github.com/google/oss-fuzz) is a thing.
Why does rust standard library need `i32` module? The module only include `MAX` and `MIN` constants, and the two constants are available as static methods - `max_value()` and `min_value()` too.
const fns were only recently stabilized, and associated consts aren't stable yet, so they had to put them *somewhere*.
Thanks. I wasn't aware of this. I am glad rust got some `constexpr` features like `C++`. For whoever wondering what's `const fn`, this is the RFC, https://github.com/rust-lang/rfcs/blob/master/text/0911-const-fn.md.
&gt; For fuzzing you don't even need to insert the appropriate generator function, cargo-fuzz supports accepting random types provided they implement `Arbitrary` This is the first time I hear about it. Could you link me some relevant documentation? I'd be interested in at least prototyping an automatic fuzz harness generator based on function definitions.
Very cool!
Could you give some examples? I want to understand the use cases for it so we could come up with an API that suits them.
look at all that green cpu usuage... very low system cpu usage. i wonder what the cpu cache looks like... &amp;#x200B; man im sexually excited and my gf is not home now. fml.
Yep, so even non-LLVM backends provide this property too :-).
&gt; Large chunks of stdlib are platform-independent, so fuzzing just one architecture would be sufficient. This is not true at all. First, platform-independent Rust code almost doesn't exist (if your code uses references, pointers, usize/isize,... it is platform-dependent). Second, Rust only generates platform-dependent LLVM-IR, which at some point gets lowered by a platform-specific backend to platform-specific machine code. 
Capitalize the name of languages please.
As a generalization for assembly, as long as the numbers are between certain values before starting to use different instructions, the instructions will behave as expected. There are still data considerations to prevent unexpected future behaviors; for example if the high end bit is set. Assembly is kind of easier when treating everything as bit vectors.
Oof ouch owie. My cores. 
again, I believe my post was pretty reasonable. if you could be more specific about what part of it is "fearmongering," I might be able to understand your point and correct my mistakes.
I know how the load is measured, but I have a 2 core machine that sometimes goes up to 3 when I rsync files, so I was curious to know if rayon was overloading the machine or keeping it smooth.
That will be the disk IO. Disk IO is actually weighted higher than CPU. I've seen 8 core machines hit 300+ load... Yeah fun times :)
&gt; It works with anything that derefs to Self, AFAIK. Yep, I've tried this with my own types and it works here too.
A reasonably idiomatic C? Quite possible, and work is ongoing to achieve this (see `mrustc`). A reasonably-idiomatic C++? I don't think so, the impedance mismatch between Rust and the stuff C++ adds to C is just too large in many cases.
That's Amazon's computer :P https://ec2instances.info/?selected=r4.16xlarge
Thanks, been a Rust Buster for nigh upwards of, oh at least a year now and I really can't say I really ever did hear about this before as far as I can tell. Can really imagine it being quite useful in more situations than one, which is like many things in life, but this is more useful in more situations than the average thing, so thank you for bringing this to my attention. You have won all my adulations.
Rayon will gladly gobble up more cores if there are any, and is happy to do so since cosine similarity for a matrix is a O(n^2) CPU-bound algorithm. This was on an r4.16xlarge, but we tested on a x1.32xlarge and the HTOP looks just as pretty :)
&gt;opt\_ Just realized, I answered the same :D
So the way it works is I load the entire matrix into memory, to what is essentially and array of structs, and from then on all lookups on it are done by reference. The calculation part is essentially having one heap per worker keeping top-n results for the similarity score, and every worker does one pass on the matrix for a given reference product (quadratic algorithm). Then when I get a result, I serialize the result for the query into JSON and print it to STDOUT. This is really just a cheeky trick to avoid keeping stuff in memory, since Rust's printing functions are thread-safe. Here's source if you're interested https://github.com/luizberti/vek Mind you there's no documentation and I might have abandonned master in the middle of a refactoring, so I'm not sure which version of this compile's anymore. Last I touched this was a month ago :/
Honestly I really don't see the point. This has not been accepted yet, the only rfc that I found is this https://github.com/withoutboats/rfcs/blob/arbitray-receivers/text/0000-century-of-the-self-type.md The rfc also doesn't really explain the benefit at all. What is wrong with wrapping your types? struct FooInner; struct Foo(Arc&lt;FooInner&gt;); impl Deref for Foo {..} Everyone seems to be on board with this rfc, what am I missing?
`fn foo(self: Self)` can be written as `fn foo(self)`, and `fn foo(self: &amp;Self)` can be written as `fn foo(&amp;self)`, and `fn foo(self: &amp;mut Self)` can be written as `fn foo(&amp;mut self)`. So why can't `fn foo(self: Box&lt;Self&gt;)` be written as `fn foo(Box&lt;self&gt;)`, and so on?
See my comment :) https://www.reddit.com/r/rust/comments/9hzn45/i_just_learned_of_arbitrary_self_types_in_nightly/e6fruwk/
That can get [a bit out of hand](https://en.wikipedia.org/wiki/Hungarian_notation), though ;P
Might be a nice addition
To me that feels like a code smell and I'd want to refactor at that point...
Depends on the algorithm you want. I've been using [`brotli`](https://crates.io/crates/brotli) for some web projects and it's pretty good.
AFAICT the idea has been floating around for a bit, but the motivating push has been `Future`'s taking a self of `Pin&lt;Self&gt;`, or some other type passing a Context wrapper. 
It's not necessarily disk I/O. Load average is the measurement of the times process have entered the running and runnable states (and on Linux specifically, uninterruptible sleep states like those performing I/O) minus the number of times a process has terminated,, over (mostly) the last 1/5/15 minutes. I use the word "process" but Linux and a few other UNIXes count threads as well. Simply put with an example, if your load average is 3, it means you have may have had 33 tasks running or waiting, and 30 tasks finished. If you have a 4-core system that's usually okay because you have 3 extra tasks but 4 cores to handle them. If you have a load average of 3 but you're on a 2-core system, you might be seeing tasks backing up. It could be lots of processes waiting on disk or it could be that there are more processes in the CPU wait queue than the cores can handle. So it's possible OP's box is way above the 64 load that /u/gerl1ng suggested. If rayon decided to go ahead and spawn one thread for every task it could possibly need and throw them in all the wait queue, the load could skyrocket, because each of these threads would add 1 to the load. Instead rayon grabs the [number of CPU cores](https://github.com/rayon-rs/rayon/blob/8ba64ab93068004770d002116066aa7d91d8401a/rayon-core/src/lib.rs#L215) by default and creates a work-stealing pool of threads. OP's load is probably a little above 64, because while Rayon is adding 64 threads in the `runnable` or `running` state (and none of them have terminated), other system processes are also running.
URLO?
One I often bring up is locality – preserve the ability to reason about your code without looking elsewhere. That's why we limit type inference to function bodies, and only have basic elision in items.
`Box&lt;self&gt;` would be brand new syntax, as it's the only time you would have something that seems like a type parameter but isn't. The current ones are all patterns, and so are consistent with other places where that works. Ideally, you would want `Box(x)`, but that's only valid if `Box` is a tuple struct (it is) with a public field (which it isn't).
This (https://github.com/withoutboats/rfcs/blob/arbitray-receivers/text/0000-century-of-the-self-type.md) seems to suggest so, yes. I've not actually tried it yet.
I run into this all the time https://github.com/rust-lang/rust/issues/49013 I use "rb rust_panic" instead of the break (b) command in gdb to work around this. 
&gt; If [T]::len() hadn't returned a generic, "untyped" usize, but instead returned an integer type that specifically represents an array size That's what usize is…
You could generalize the pattern by having `self` mean "replace the `self` in the type with `Self`, and name the argument `self`. This works for `self -&gt; self: Self`, `&amp;self -&gt; self: &amp;Self`, and it would also work for arbitrary self types, like `Foo&lt;Bar&lt;self&gt;&gt; -&gt; self: Foo&lt;Bar&lt;Self&gt;&gt;`. It would also work for multiple uses of `self` in the same type, like `(self, self) -&gt; self: (Self, Self)`. It's probably too complicated and not really necessary, but you could do it while keeping all the patterns consistent, I think.
Sure, they are expensive, but compared to the competition it's rather cheap. Intel's 28-core Xeon CPU goes for at least € 10.000. Due to their shortage recently it's only going to be more expensive.
Can you elaborate on this? If you have `serde` as a dependency then you can't also have it as a feature, can you?
Would you argue this is one reason why Rust doesn’t do something like Go’s: func blah( a, b, c, d string)
I more meant something attempting to create solid, consistent bindings and utilities, possibly with the goal of creating pure Rust versions.
Also a newly popular food. At least in the UK.
What's confusing? Func blah takes 4 variables named a,b,c,d which are strings . Looks ok to me.
Nobody has ever proposed (that I’m aware of) it, nor tried to implement it.
There is no crate with a unified compression interface like `rust-crypto` afaik if that’s what you mean.
&gt; locality [..] That's why we limit type inference to function bodies Seems like a bit of a strawman, given that most OCaml/Haskell code in practice adds type signatures to functions anyways. I can see the parallel type checking argument for this point but locality doesn't seem like a big enough reason to disallow inferring function signatures, given current best practices.
https://users.rust-lang.org. :) Although IRLO (https://internals.rust-lang.org/) is probably more appropriate in this case...
A bar at full 100% strength should be added to the Rust logo
It requires a more complex parser and makes it easy for stupid mistakes to happen, mind you the compiler would catch such mistakes but I don’t see that much benefit from it. When I work in statically typed languages I usually use GNU-style for function parameters when they go past an 80-120 (depends on the language) character gutter anyway and at that point such syntax just makes things less readable anyway.
Totally. Another thing that occurred to me is that "cha siu bao" kind of rhymes (in English anyway) with "SHA-2 bao". I'm not sure I'll ever make anything of that, but there it is :)
That would be correct, yes :)
Thanks for the explanation! I've seen Box&lt;Self&gt; before, but never knew what kind of magical exception this was. Good to know!
So does that mean that `foo(box self)` might be legal if `box` patterns end up sticking around?
Safe bet. You would need code that wants to make 1 billion contiguous copies of a string, then call that code with an input string which is 18 gigabytes. Or code that wants to make 1 million copies, and call it with an input that is 18 terabytes. It just doesn't happen.
Depends on your programming background, coming from a progressively typed JS perspective, I thought a, b and c were untyped and the last typed as string until I read your comment.
Is 40 buildbots really outside of Rust's budget? Mozilla has hundreds of millions of dollars. How much is one buildbot to operate? Also, why test / fuzz all of libstd? We only need to focus on the core components with unsafe, right? At least, that seems like the most meaningful target. Given that a buildbot is unlikely to be doing work most of the time, is hardware you own (so a real asset that you can resell later), and is at most a few thousand dollars upfront cost (I assume, per buildbot), if the barrier to improving testcases is adding more computers I think that's an obvious win.
This is really awesome. I've been lurking around rust for some time now and have done a few tutorials. I really really want to use it more but get stuck on two points: 1) I need to be able to use it as an extension to python in a way that we can also package and deploy it using pip (this looks very possible now so yay) and 2) the autocomplete kinda sucks (looking at you racer...) and will supposedly be fixed with incremental compiling which I keep hearing about but seems to never happen :(. I'm not a very smart man and without the nice discoverability given by good intellisense I get very confused. Do you (or anyone else here) have advice for how to overcome 2?
I personally value the rich and high quality tool ecosystem (Cargo, rustup, rls, etc...). I think these really set Rust apart and make it not just a novel new language, but a competitive option for a huge range of projects and developers. 
Data Ownership. No matter what you're writing in Rust, the language will enforce where data is and how it can be relocated/referenced. This is something made explicit in Rust rather than no boundaries like C while avoiding abstracting it all away like JS/Java like languages. 
There is a difference, `Cow` has `T: ToOwned`.
Sure does. Does that cause a problem in this use case? 
You are trying to push elements to a vec that borrows from the vec itself. So the elements of the vec need to outlive the vec itself… What if you put them in an `Rc`? The easiest way I think would be to make it a recursive function that passes along a closure parameter to do the formatting. But this is less flexible.
My guess would've been that a, b and c are either untyped (or I guess `interface` in go?), inferred, or generic. I can't get my mind to parse that as (a, b, c, d) string.
Here’s a philosophical question for you, if there was some option that enabled safer memory usage that wasn’t data ownership, would you add it? Concrete example: arrays bounds checking all the time. Why isn’t array access unsafe? which “safety” are we really talking about.
If you haven't already, try IntelliJ community edition with the [IntelliJ Rust](https://intellij-rust.github.io/) extension. It's a fairly heavy IDE, but it does have good autocompletion and other rust language support. Besides that, I'd recommend using the rust language server (rls) rather than raw racer plugins into IDEs. It still uses racer under the hood for a lot of completion, but it has a few things on top of that which might help.
Thank you for the advice, I'll try it out tomorrow. 
Yes! The most useful element is that it gives the method access to the `Arc&lt;Self&gt;` rather than just the underlying `Self`, which permits things like cloning it for use in a worker thread or other such things.
I guess the general idea is that negative offsets are allowed sometimes? Like, you're allowed to subtract 1 from a pointer, if you know it's not the first element in an array, or something like that.
I personally feel like it benefits the writer of the code at the cost of the reader.
They’re not really patterns, though. The pattern `&amp;foo` matches `&amp;Foo`, dereferences it, and binds the value `foo: Foo`. But the parameter `&amp;self` matches `&amp;Self` and binds the reference `self: &amp;Self`.
OVH and such can get you some nice temporary hardware. I think it is hourly or monthly. &amp;#x200B;