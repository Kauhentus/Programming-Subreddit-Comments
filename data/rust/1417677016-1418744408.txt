Hi, I wrote this yesterday. I've kinda been curious for a long time whether some form of Turing completeness would slip in; AFAIK this became possible with the [multidispatch changes](http://smallcultfollowing.com/babysteps/blog/2014/09/30/multi-and-conditional-dispatch-in-traits/) which relaxed the rules on conflicting trait impls. (I was originally trying to use associated types, but I think they are currently too limited to use for computation; let me know if I'm wrong.) For the record, rustc's trait selection currently has a recursion limit of 64, so adding complexity causes errors pretty quickly. It would be cool to have a real way to inspect and generate types using plugins. (You currently have a choice of one or the other, as lint plugins can inspect types but run too late to add anything new.)
I would say something like “let x of type int equal five”, a distinctly simpler syntax breakdown (where the colon becomes “of type” and the equals sign “equal”). It becomes a lot more interesting if you take into account that the LHS is a pattern. Go figure how to speak some more complex things like these: - `let Foo { bar, baz, .. } = *self;` Probably “let bar and baz equal the so-named fields from star self”. - `let Foo { box bar, baz: ref quux, .. } = *self;` I’d probably go for something like “operating on the Foo star self, let bar be the bar field, unboxed, and let quux be a reference to the baz field”.
Other things that are accidentally turing complete: http://beza1e1.tuxen.de/articles/accidentally_turing_complete.html
From what I've seen, the worst abuses of C++ templates exist not so much because people want complex types, but because they want to add new functionality to the language or do interesting things at compile time, and C++ has no other way to do it (other than the C preprocessor, which is very limited). Rust, however, has a much saner way to do many of the same things (and more) in the form of compiler plugins. If they became a little more powerful, hopefully nobody would have any excuse to bother abusing this type of thing for serious work :)
Try looking for the bit of code that should print that line and checking where it's going wrong.
Try this: `fn foo&lt;Sized? T: ToCStr&gt;(param: &amp;T) -&gt; Bar` and `foo("hey")`.
A string literal is always of type `&amp;'static str`. Your function `foo` was asking for `&amp;T`, so if you give it a string literal it understands that `T` must be `str`. And `ToCStr` *is* implemented for `str`, so the only problem is that of unsized types, that `str` is an unsized type while the function definition hasn’t made it clear that unsized types are supported (this must be done explicitly by changing `&lt;T: ToCStr&gt;` to `&lt;Sized? T: ToCStr&gt;`). It works for `&amp;"hey"` because that is of type `&amp;&amp;str`, thus `T` is `&amp;str`, and `&amp;str` implements `ToCStr` as required.
Dependently typed languages which are TC usually have some form of conservative totality checker to make it possible to actually prove things in them. A totality checker and effect system would be really useful to have in Rust too (even if you don't use it for theorem proving).
Very well put, I understand now. Thank you very much!
Just have decent language features, so you don't need to abuse templates to fudge your way around language omissions. Thats' the real problem in C++, IMO.
The library support probably isn't there yet for your interaction strategies, unless you feel like writing a lot of code to interface with e.g. a webpage properly.
If I had to read that out loud, left-to-right, it would probably sound like this: A function select generic over a lifetime r and a type T, that takes the parameters shape of type reference with lifetime r to Shape, threshold of type f64, a of type reference with lifetime r to T, and b of type reference with lifetime r to T, and returns a reference with lifetime r to T However, thats quite a mouthful, so in practice and depending on context I would shorten it. For example, if I'm already familiar with the type system, and only care about the type signature, not the names of the parameters, then I'd vocalize it like this: A function generic over T that takes a Shape-reference, a f64 and two T-references that returns a T-reference where all references share the same lifetime. 
You are using impredicative type parameters, which are unsound and will be removed (https://github.com/rust-lang/rfcs/pull/447), like `N` in your recursive case of `Append` (this one: `impl&lt;Car: Nice, Cdr: ConsCell, B: Nice, R: ConsCell, N&gt; Append&lt;Cons&lt;Car, Cdr&gt;, B, Cons&lt;Car, R&gt;&gt; for Nothing where N: Append&lt;Cdr, B, R&gt; {}` ) 
Why was it decided that the types of top-level functions etc. shouldn't be inferred? Because it is easier to implement? If they mostly did it because it is *good practice*, that is something that can be done by convention (like in Haskell). Which also means that you might have to type less if you are just prototyping.
If it's Turing complete, does that mean somebody could make a higher kinded polymorphism library?
This seems to be similar in spirit to GHC's `UndecidableInstances`. (Note: *not* to be confused with `OverlappingInstances`, which is something entirely different.) I don't think it's that big of a problem in practice. What decidable type checking gives you *in theory* is that no matter what input program you give it, one of two things will happen: * The compiler says "yep, this is a valid program" and generates code for it. * The compiler says "nope, sorry, not a valid program" and tells you why. Whereas if type checking is undecidable, there is a third possibility: * The compiler says "oops, sorry, can't tell if this is a valid program or not", hits some sort of recursion limit, or (worst case) gets into an infinite loop or some kind of resource exhaustion scenario. The second and third cases here aren't *all that* different. The second should be more helpful for figuring out what the problem is and fixing it, but in either case, your program doesn't compile. Then there's the fact that even some popular sub-turing systems [have exponential worst-case complexity](http://www.reddit.com/r/haskell/comments/2cka6d/just_look_at_the_humongous_type_that/) for some pathological inputs. The fact that it always terminates *in theory* is nice, but taken together with the fact that computers have limited resources and humans have limited lifespans, the practical importance of this is questionable. All that *truly* matters in practice is that the compiler is able to reliably check and accept the programs which people actually write. And in that respect, I think it's hard to write a type-level infinite recursion *by accident*, at least outside of type-level metaprogramming. (Likewise, the exponential cases for H-M went undiscovered for over a decade.)
I think the terminology you're looking for is 'unreferenced' rather than 'dead code'. While not formally defined, the meaning of dead code is pretty clear. You follow the call tree from the entry point(s) (main in a executable, exported funcs in a library) and every thing you touch is a live code. Anything else is dead and can be safely stripped out of the binary. That Your const is warned about is makes perfect sense in this context. What you want is a warning on all 'unreferenced variable/name/item/thing'. I'd argue that you should get two for your example - the function 'assign' and ANOTHER_INT. Everything is else is mentioned. What you're asking for is reasonable instrumentation, but you need to be careful about what you call it, because otherwise it sounds like you're trying to change the meaning of the phrase 'dead code'.
Hahaha that's cool! Why doesn't Rust require functional dependencies to be able to do something like this? Apparently, the equivalent code in Haskell would be ambiguous because someone could add another Add&lt;A, B, R&gt; instance with the same A and B. (I'm seeing [an email](https://www.haskell.org//pipermail/haskell-prime/2006-February/000289.html) in which associated types are referred as an alternative to functional dependencies. Perhaps an way to not have ambiguity would be to make R an associated type. But Rust doesn't require it anyway)
Oh man, this brought back some memories. While I was more of a silent lurker in the PSP hacking scene I just freaking loved the thing as well. I still vivdly remember all the various firmware upgrades and all the cool homebrew apps. It was my first "real" endeavour into C and lower-level computing in general. Sadly my device is in a miserable state, I'd be suprised if it still booted up at all, heck I'm not even sure if I have a battery or charger for it around. I recently bought a Nintendo 3DS and while it didn't seem to be hackable for a long time, recently there seems to be some hope for it and I'd be really delighted if I could bust out some Rust on that :) And thumbs up for X220 and i3 combo, also rocking that setup!
I just tried to upload my project but there is already a crate with that name, because it's a generic name ("promise"). I feel like namespacing with the username would definitely help on that front, or at least the ability to assign an 'alias' in the cargo.toml for crates.io so I don't need to rename my project.
That's also how I read it. I tend to use "of" when I come across generic parameters. "Function inverse of T takes x of type T and returns Result of T and String".
Here we go...
"Hey guys, I found 4 nucleotides that are turing complete! Look what I can make with them..." - Nature
Here is one that I made recently. https://github.com/scialex/bassert It defines the `bassert_internal`macro using quote_expr!().
I forgot to trim my toenails and now they're Turing complete.
Go would probably be a good solution for this too. Granted there are approximately 2,307 ways to skin this cat :P
yes, you should add a lifetime parameter to `Baz` (or have `foo: Box&lt;Foo + 'static&gt;` which is much more restrictive and seldom useful). Note that in the declaration of `Baz`, there is no inference at work, because you're declaring `foo`'s type, not assigning a value to `foo`; the `'a` in `foo: Box&lt;Foo + 'a&gt;` is a bound like the `Foo` itself. What you're stating is "whenever I create an instance of `Baz`, its `foo` field will contain a Box that points to something that is bound to implement Foo and have lifetime 'a (as Baz itself)". You can't have foo point to something that dies before Baz itself is destroyed, or you would risk (whenever you're reading from foo) to try reading something that does not exist any longer. That's the kind of errors that rust tries to prevent you from doing here. In `main`, by contrast, you are creating an instance of Baz. In that case rust can infer correctly that the `box Bar` satisfies both bounds (implements Foo, lives as long as Baz). 
Great idea. Great name. Top lad (or lady).
AFAIK it's a bit of both. It does make implementation easier, and since it was going to be convention anyway the complexity trade-off probably isn't worth it.
And on the flipside of the coin, it's worth observing that if the recursion limit is considered a formal part of the system, rather than an incidental detail of the implementation, then it probably stops being Turing-complete. (Not totally sure, though.)
I know [where the code is](https://github.com/rust-lang/rust/blob/master/src/test/debuginfo/evec-in-struct.rs#L23). I guess I should have mentioned this to the OP. I just have no idea what to do with this information. In any case, it looks like it doesn't matter at the moment, because in my PR I was told to wait for an RFC to add the features.
it'd be cool if this was in json format, so when rust editor plugins start happening, they can parse this and inform the user. that and api docs. just a thought :D
The source code is at https://github.com/mrmonday/bitrust - pull requests welcome! I have no plans to implement this functionality myself, but I'd be willing to accept the changes if someone made the effort/justified it in a pull request.
It's already supposed to end up being *possible* in a hackish sort of way. See: [RFC #195 Associated Items — Encoding Higher-Kinded Types](https://github.com/rust-lang/rfcs/blob/master/text/0195-associated-items.md#encoding-higher-kinded-types)
You should probably either escape some characters (replace `&lt;` with `&amp;lt;` and `&gt;` with `&amp;gt;` at least) or output it as plain text. (Author names like `bors &lt;bors@rust-lang.org&gt;` are displayed as `bors` since browsers will try to interpret the email address as an HTML tag. The same goes for generic parameters in comments, e.g. `Vec&lt;C&gt;` is shown as `Vec`.) *Edit:* Just saw your link to the source code. I'll send you a PR. *Edit 2:* Merged already :)
&gt; There is nothing about the standard library that guarantees code quality or good documentation. No, but it's far more likely than a random package. There's barely anything to stop anyone putting a package up on crates.io but for something to get into the stdlib there will have to be many people who have checked it. It's incredibly difficult to "guarantee" anything.
I think the natural progression as we become more experienced with a language/syntax is to get more and more terse with how we "say the code" to ourselves. I know that after reading Ruby code for almost 15 years I don't really vocalize at all, but kind of suck in what the code's doing in big chunks. Until you can just "intuit" the meaning of the code, though, it's so helpful to be able to vocalize it to yourself. I really appreciate both your terse/ambiguous reading and the much more detailed read through you gave - thanks!
That'd work too! I have it in other places, not just the guide, for example, http://doc.rust-lang.org/guide-pointers.html#cheat-sheet , which has "arr cee pointer" A blog post would be great!
I was going to suggest this.. well, I think that it would be easier to understand its purpose with a name like `should_fail!` or `expect_failure!`.
And this is generally not a problem, because you only run into that situation when you do crazy things like this post or other template-metaprogrammy things. In practice you'll just hit a recursion limit or something like that in the compiler and say "oh well, I guess I can't run conway's game of life in the type system, I'll go do something useful now."
I had the same error, without modifying the rust code. I have updated gdb (from 7.5.1 to 7.8) and now it work.
I've already thought about using the `Zero`/`Succ` trick (Pareto numbers?) for compile-times units. I was more afraid of the error messages that would get generated though; it's hard enough with `si_unit&lt;0, 0, 0, 0, 0, 1, -2&gt;`, `SiUnit&lt;Zero, Zero, Zero, Zero, Zero, Succ&lt;Zero&gt;, Minus&lt;Succ&lt;Succ&lt;Zero&gt;&gt;&gt;&gt;` would quickly become tedious.
They meant that the completeness of *Rust's* type system was an accident. 
My procedure is typically to open up a few of the Rust open-source libraries maintained by actual team members, and look for a commit message like "Updated to latest Rust nightly", and see what they changed. Really not the most scalable approach, but hopefully in a couple months things will have stabilized sufficiently that it won't be necessary anymore. Though this BitRust thing may also help quite a lot for the interim.
While it might cause wider breakage than the enum change, it would also be a more mechanical change to fix it. Unlike the enum change, you're just re-arranging information within the same line of code. You don't have to look up what enum type that identifier comes from. A bit of a PitA to go through all your code to fix it up, but won't likely take that long. Like GolDDranks said, you could probably even write a tool to automate it.
another argument for `Vec[C]` as generics syntax. i’d also accept chevrons `Vec⟨C⟩`, but unlike `Vec&lt;C&gt;`, they aren’t ASCII.
I would love for somebody to work on this.
I should have clarified...I am writing a syntax extension that expands to then create another independent macro to be used...A simplified example would be //syntax extension foo! that creates a macro called bar to be used on its own foo!(bar); bar!(...); Any ideas there?
I feel a bit dumb now, I found a similar post just after posting mine. http://www.reddit.com/r/rust/comments/229xoh/sizeof_an_enum/
Can I hack on my PSP go? Would really like to try this out but everybody seems to use older model psps 
All the kids are already doing Android programming, one of these less popular devices is far cooler to hack and program for
From my quick google search: Yes, there seem to be Custom Firmwares available (meaning someone already exploited the original firmware)
Although ideally breaking changes won't be happening for much longer. :)
Out of curiosity, fix what exactly? (serious question)
Would Rust work with Vita too? I'm thinking about buying one, and if I could do some Rust programming on it, that would convince me. 
Yeah, agreed... :( Would love something like F# too, that supports arbitrary units (not just SI), but I imagine that would be even uglier from the error perspective. You'd have to have some craziness involving sorting the different units in a consistent way at compile time. &gt; Pareto numbers? [Peano numbers](https://www.haskell.org/haskellwiki/Peano_numbers).
Rust already works on Android, where's the fun in that? ;) Joking aside, I'm not a big fan of the Android platform in general, not to mention that getting the NDK to work is even more painful than setting up the PSP toolchain, and that says a lot. I think Android is a mediocre platform for gaming, not really fit for quality games. I got the PSP solely as a gaming device back then, being able to run homebrew software on it was a bonus that came later. Like I said, I'd rather write code for the 3DS than Android.
So you want `foo!(bar)` to basically synthesize some `macro_rules! bar(...)`? Sounds crazy, but plausible. :) It would help to show a full example which fails. Regardless, an ICE is a bug to be reported, even if the resolution might be to forbid what you're trying to do.
From what I found right now it was much harder to hack the Vita. Sony learned from the first PSP and improved on several aspects. But nothing is unhackable, so some progress was made according to this post: http://wololo.net/vita-cfw4dummies/
It's all good, it happens all the time: http://www.rubberduckdebugging.com/
Yeah, "named lifetime" or "explicit lifetime" might be clearer.
Python can handle that, but the problem is in the runtime and middleware (does it need it?)
Yeah, I know that and can wait :) The doubt that is bothering me is like "is rust a right tool for that job?" If I would like to build next graph database than I would choose it without any questions.
I think so too. Go is really a good fit with the only one exception - I can't get rid of the feeling that I'm doing something completely wrong when using it))))
In my case it's a cubietruck 3 but utility should be also able to run on much less power devices like raspberry pi and ideally on I386 also.
So they won't get my money. Sucks to be them. :D
Make it *not* Turing Complete, if that feature is not desirable.
Did you [open a ticket on GitHub](https://github.com/rust-lang/rust/issues)? I can nominate it as a 1.0 blocker.
Logged: https://github.com/rust-lang/rust/issues/19537
When I first read this, I thought, "No, the borrowchecker cannot be *that* naive." But I was wrong: $ ./borrowchk Foo { buf: [bad, stuff], map: {5: stuff, 3: bad} } Foo { buf: [test], map: {5: stuff, 3: tes} } It looks like it's not segfaulting because the `Vec` doesn't deallocate after truncating, so `"test"` ends up where `"bad"` was in `buf` and the slice points to a valid, if truncated, string. It still works even if you remove the push to `buf` in `do_bad_stuff()`. It gets really interesting if you don't do the push to the vector after clearing: $ ./borrowchk Foo { buf: [bad, stuff], map: {3: bad, 5: stuff} } Foo { buf: [], map: {3: bad, 5: stuff} } It's funny because those two should have been dropped and deallocated in the call to `Vec::clear()`.
Good job :| So I'm trying to figure out what's going on here... is it because `map` contains references into the strings stored in `buf`, which then gets cleared in `do_bad_stuff` and subsequently accessed when printing `foo` using the default `Show`?
/u/Gankro beat me to it
Yeah, I did that at first, but added the push to show that we actually get corrupted data and not just stale data. I believe the Strings might get deallocated, but that their memory isn't cleared, so the pointers point into stale memory.
That's what happens. The borrow checker seems to believe that adding a reference to map is ok, since map lives as long as buf does (the lifetime of Foo). However, there is no guarantee that the items in buf live as long as buf does, and if those items disappear then we have a reference into nothing (or old stale memory).
You don't necessarily have (all of) the input tape, though, only the program: Deciding program equality for all possible inputs.
Must be the behavior of the heap allocator to reuse recently freed regions instead of new ones. I thought we did zero on drop though?
An enum in Rust is basically identical to a C struct containing a union of the data members and an integer tag. There are a few special cases, like any enum like enum Something&lt;T&gt; { HasData(T), NoData, } will, for non-nullable pointers (`&amp;` references, `Box`es, etc.), replace the tag byte with just a null pointer for the no data version.
&gt; I thought we did zero on drop though? Rust doesn't zero on drop. It zeroes *variables* when they're moved from and that's going to change.
&gt; It works great but it looks terrible. It looks fine to me, beyond not scaling the output panel properly. It doesn't replace the standard button / select / scrollbar elements... but that's common across countless sites and replacing them tends to hurt browser integration. The theme is subjective and the current choice (old GitHub style) was made because there's both an Ace (editor) and Pygments (asm / LLVM IR output) theme. &gt; The only syntax highlighting is bolding keywords It has more syntax highlighting than that. It covers string literals, integers, comments and a few other things. It still seems to be missing a few things like the attribute syntax, but anyone who cares is free to submit a small pull request to Ace. &gt; there is no way to use crates other than the ones that are shipped with rust It builds Rust every day and any extra libraries would need to be rebuilt at the same time. Most libraries aren't going to be useful since it doesn't allow many things like networking.
Well, python and pip is in any unix-distro by default. You can't go wrong in my opinion.
Well, python and pip is in any unix-distro by default. You can't go wrong in my opinion.
I have a feeling this is a regression. Could you test against a version of Rust from 1 month ago or so?
This works until you're the first one who updated. My goto place ~~is~~ was GitHub's pulse page: https://github.com/rust-lang/rust/pulse which shows you the recently merged PRs.
I learned a bit more about enums today. Thanks for posting your question!
The first &lt;T&gt; in inverse&lt;T&gt; can be omitted when reading aloud, given enough context, because it just declares that T is a generic parameter and not a concrete type (and indeed, in some languages like OCaml or Haskell there's a difference in syntax between types like Result and type variables like T, so declaring the type variables isn't necessary) I would read it "inverse receives a x of type T and returns a Result of T and String". If you want to say the &lt;T&gt; explictly, one nice way is to say *for all T*. Like: "for all T, inverse receives a x of type T and returns a Result of T and String" I think it's unnecessary to say the word "generic".
Fixed :) (ostensibly) https://github.com/rust-lang/rust/pull/19544
If I put gcc in PATH the I get link errors: error: linking with `gcc` failed: exit code: 1 note: gcc '-Wl,--enable-long-section-names' '-fno-use-linker-plugin' '-Wl,--nxcompat' '-static-libgcc' '-m64' '-L' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib' '-o' 'C:\users\mitchell\desktop\conrod-example\target\conrod-example.exe' 'C:\users\mitchell\desktop\conrod-example\target\conrod-example.o' '-Wl,--gc-sections' 'C:\users\mitchell\desktop\conrod-example\target\deps\libsdl2_window-7bda6d64958c6199.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libsdl2-a291b804f48837e4.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libconrod-8c8e132a2f50bcb8.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libopengl_graphics-4350b0f7f800109a.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libimage-e34f27ec35bf4230.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libgraphics-97cf825a272bee12.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libflate-4e7c5e5c.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libshader_version-be2bb9fb7463fbbb.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libevent-037aa9aff5b1d4c8.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libwindow-487dedf56ffc0b08.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libvecmath-cb72b1b0b9fb4b3e.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libtexture-112abc309cf687dd.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libinput-0f8d5acb58e11f21.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libread_color-bf9e48c3c6e4fdf0.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libgl-bb78cdc3bae0f4e0.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libgl_common-66a5d21dea94490e.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libevent_loop-0e1c0f650e1ab71f.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libtime-8e1f818dd133e7bc.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libserialize-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\liblog-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libregex-4e7c5e5c.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libcurrent-b47ba0d628e1f433.rlib' 'C:\users\mitchell\desktop\conrod-example\target\deps\libfreetype-22b82507e3ace047.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libstd-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\librustrt-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libcollections-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\liballoc-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\liblibc-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\librand-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libunicode-4e7c5e5c.rlib' 'C:\Program Files\Rust\bin\rustlib\x86_64-pc-windows-gnu\lib\libcore-4e7c5e5c.rlib' '-L' 'C:\users\mitchell\desktop\conrod-example\target' '-L' 'C:\users\mitchell\desktop\conrod-example\target\deps' '-L' 'C:\users\mitchell\desktop\conrod-example\target\build\time-8e1f818dd133e7bc\out' '-L' 'C:\users\mitchell\desktop\conrod-example\.rust' '-L' 'C:\users\mitchell\desktop\conrod-example' '-Wl,--whole-archive' '-Wl,-Bstatic' '-Wl,--no-whole-archive' '-Wl,-Bdynamic' '-lSDL2' '-lfreetype-6' '-lws2_32' '-lcompiler-rt' note: C:\users\mitchell\desktop\conrod-example\target\deps\libtime-8e1f818dd133e7bc.rlib(r-time_helpers-time_helpers.o):time_helpers.c:(.text$rust_time_gmtime+0x27): undefined reference to `gmtime_r' C:\users\mitchell\desktop\conrod-example\target\deps\libtime-8e1f818dd133e7bc.rlib(r-time_helpers-time_helpers.o):time_helpers.c:(.text$rust_time_localtime+0x27): undefined reference to `localtime_r' ld: C:\users\mitchell\desktop\conrod-example\target\deps\libtime-8e1f818dd133e7bc.rlib(r-time_helpers-time_helpers.o): bad reloc address 0x27 in section `.text$rust_time_localtime' 
Hi, the failing test probably has nothing to do with your changes. Some versions of GDB have a bug in them causing this error. For more information see: https://github.com/rust-lang/rust/issues/17808
I like it, but prefer `is!` over `matches!`. Shorter and feels more natural to me somehow. Sort of like how your function name `is_slash` reads.
I can see someone lumping a bunch of smaller crates together into larger crates by category, like the Apache Commons project. That might be something rewarding to curate. Maybe `rust-commons` or something. 
We can have both in this crate, right? What do you think OP? 
It was named `is_match!` at some point. I don’t have a strong opinion on the name. `is!` kinda sounds close to `==`.
Feel free, but I personally don’t see the benefit. Any random aggregation of libraries is bound to contain something I won’t use and not have some other things I want. And declaring multiple dependencies in Cargo for just what I need is easy.
That was fast, good work.
Well, if the types are fully specified, i.e. you have the whole program to analyse and the system is not dependently typed, that's the case. But then type inference is about inferring the most general types from the expression level upwards, each layer in isolation, not analysing the whole thing. "I can't infer a type for that function, show me all use sites first" is certainly a strange thing to do for type inference.
&gt; Fix two bugs in HRTB: &gt; &gt; Categorize early-vs-late bindings on impls when constructing generics, so that we don't add unnecessary region parameters. &gt; &gt; Correct the DeBruijn indices when substituting the self type into the method signature. &gt; &gt; Previously, the DeBruijn index for the self type was not being adjusted to account for the fn binder. This mean that when late-bound regions were instantiated, you sometimes wind up with two distinct lifetimes. Sounds intense. **EDIT:** I'm looking at the test you wrote to catch any future regressions. I don't understand how the test works, could you please elaborate?
Two things: * `&amp;mut 0i` on line 7 is taking the address of a temporary on the stack. If you put this address in a struct and then returned it, score would be a dangling pointer. Rust is correctly preventing you from doing this. * Even without this problem, you wouldn't be able to modify the mutable reference through an immutable one. In Rust, you can't abstract over mutability. To expand on the last point a bit: in general Rust encourages "inherited mutability." Essentially, if an instance of some type `T` is in a mutable slot (e.g. through a `let mut x: T = foo()` binding): 1. The data referred to by `x` can be replaced (provided you find another instance of `T` to move into `x`). 2. If `T` is `&amp;mut U` for some type `U`, then `*x` can be used in mutable slots. 3. If `T` is `&amp;U` for some type `U`, then `*x` cannot be used in mutable sots. 4. All of `x`'s fields (if `T` is a struct) can be used in mutable slots. Immutable slots have basically the same rules except that "can" changes to "cannot". So when you have a binding `x` of type `&amp;T` for some struct type `T`, under normal circumstances you won't be able to mutate any of `*x`'s fields, even if they have type `&amp;mut U` and `x` is in a mutable slot. There are ways of modifying data through shared references to certain types, like `Cell`. These types are said to provide "interior mutability," which they accomplish using unsafe code under the hood. But it's not generally possible to treat interior mutability as an implementation detail either, since all the safe types that provide it also add restrictions to the surrounding code and/or come with significant caveats. For example, `Cell` can only be used with `Copy` types (plain old data without `&amp;mut` references, drop glue, or explicit opt out), and shared references to structures that contain `Cell`s are not thread safe (in Rust, "thread safe through shared references" is represented by the `Sync` kind, which `Cell` explicitly opts out of). Thus, these types should be used only where they bring meaningful performance improvements or provide brand new functionality, not as an implementation detail.
Thanks for the thorough reply! So in other words; no need for lifetimes, mutability shouldn't be abstracted over. Thanks again!
yes, it is official - you can't implicitly convert between numeric types, even literals. If Rust has enough contextual information you can drop the suffix: let x = 1.0 + 2.1; let y: f32 = x;
But can you drop the decimal digit after the point? let x = 1. + 2.; let y: f32 = x; It seems you can, and this is nice and concise, but this doesn't seem to match what's written in the reference.. 
There is [Awesome Rust](https://github.com/kud1ing/awesome-rust).
What exactly is the error message? Also note that the old closures have some inference issues, and the new ones are still buggy, so a solution might look awkward to call either way at the moment.
Sorry, forgot to add it to the post. Error: &gt;linked_list_with_sort.rs:42:24: 42:39 error: binary operation `&lt;` cannot be applied to type `|uint, uint| -&gt; int` &gt;linked_list_with_sort.rs:42 list.sort = if sort_option &lt; 0 { &gt;linked_list_with_sort.rs:44:19: 44:34 error: binary operation `&gt;` cannot be applied to type `|uint, uint| -&gt; int` &gt;linked_list_with_sort.rs:44 } else if sort_option &gt; 0 { &gt; error: aborting due to 2 previous errors
Ah, well, you need to actually _call_ the closure. Eg, by doing `if sort_option(a, b) &lt; 0`
but a and b are not given and they shouldn't be given to the implementation file, since the compare function is in main. When I write (a, b) it tells me: &gt; unresolved name `a` &gt; unresolved name `b` My problem is that I don't know how to implement it. I want to do something like this: When I call insert function it will check if it's data is bigger then data of first node, second node and so on till the end, till it won't find the place where the data of the previous node is less then it's data and the next node is greater then it's data (this example is ascending sort) That's why I wrote the compare_function in main so that, user could write a custom function for his needs (in this example it doesn't make sense, but if I implement it with templates, then for example I have a struct with id and url I would be able to sort them due to id, url size, etc...) 
The `extern crate "my-crate" as my_crate` thing is encouraged by the `*-sys` naming convention, which is [officially recommended](http://doc.crates.io/build-script.html#*-sys-packages). Whether or not this is a good convention, I leave to others to discuss. :-)
I meant in your `new_with_sort` function. That one needs to actually call the closure in the implementation with two elements of the list you want to have compared, and then do that for enough of them to know how to sort it. 
Niko wrote it, not me. I have no idea how debrujin indices work.
We had a meeting about all of this at the workweek last night, expect a blog post from the team soon. In the meantime, your first and last questions have easy answers: * The naming scheme is 'the same as Rust identifiers'`, with the exception of the `-sys` convention. * you can tag crates as part of the metadata in the `Cargo.toml`, and then they show up on the site.
but at new_with_sort function, the List is empty and I don't want to insert any Node at that time, especially two nodes in order to compare them. I just want somehow to set sort property to Descending, Ascending or NoSort at new_with_sort call and not to check the sort property every time I call insert function
This is intended, yes. Despite attempts to modernize it, for the time being the reference should still be considered incomplete and inaccurate.
But how do you want to set it? What does the SortProperty actually mean? The idea behind such a closure is that the behavior of the closure determines how to sort, you can't just convert its behavior down into one of three possible choices.
Yes!!! For the answer. The problem is I want to implement the idea, but I don't know how. Your first idea with storing closure itself makes a lot of sense, but now I have three questions. 1) How O(logN) and not O(N) in the worst case, since I am looking through the list. 2) How can I store closure as a structure field? I write pub struct List { head: *mut Node, current: *mut Node, sort: |uint, uint| -&gt; int } I get error &gt; linked_list_with_sort.rs:10:11: 10:30 error: explicit lifetime bound required &gt;linked_list_with_sort.rs:10 sort: |uint, uint| -&gt; int 3) What if I want to have no sort, can I set the closure struct field to be NULL ? Or I have to use Option&lt;|uint, uint| -&gt; int&gt; to do that.
I believe it should be _, not -, but we need real docs around this. Identifiers use _
This is because https://github.com/rust-lang/cargo/commit/41de2918fa69fa7e48bcfe7b3e68974befb0d5e6 landed a day ago, and the most recent windows build of cargo for download is 11/30th, which is older than that, so the HOST variable is not being exported. This is once again because the nightly builds are not up to date. You may have to compile cargo yourself in the short term.
If I understand right, then both `foo_bar` for module and crate names, with only the conventionally "special" native system packages using the `-sys` suffix. So you could have these two crate names for example: foo_bar foo_bar-sys EDIT Actually, seems like that will change to `_sys` as well, nevermind. 
From Walter: &gt; Despite its length, this is a fairly simple proposal. It adds the missing semantics for the 'scope' storage class in order to make it possible to pass a reference to a function without it being possible for it to escape. &gt;This, among other things, makes a ref counting type practical. It also makes it more practical to use other storage allocation schemes than garbage collection. &gt;It does not make scope into a type constructor, nor a general type-annotation system. &gt;It does not provide an ownership system, though it would complement one. As someone unfamiliar with D's semantics, it would be great if someone familiar with both languages could contrast this proposal with Rust. As ever, please keep in mind rule #4 from the sidebar.
*/me exerts monumental effort to adhere to #4* Back when I was using D, `scope` was (outside of scope guards) a storage class that basically guaranteed an object would be destroyed when its reference went out of scope. It would also (if possible) stack-allocate the object instead of putting it on the heap. My reading of this is that it's *far* simpler than what Rust does... It looks like it gives you the equivalent of local lifetime inference, input parameter elision, and a very specific form of output lifetime where the returned reference is an rvalue and must either be used *immediately* or discarded. It's not entirely clear whether or not these are usable in UDTs... but it doesn't look like it.
Thank you for your restraint. :) Does UDTs == user-defined types?
talking about theoretical possibilities, am I right in thinking lifetimes must be specified manually for use by indirect function calls that return borrowed pointers(e.g. trait objects, virtual functions, non-inlined lambdas) - beyond that they could in theory be inferred (in code where calls are known at compile time linking and especially inlining) - perhaps there are additional cases like references cached in pointed objects which would be impossible to infer? Of course inferred lifetimes might be harder to reason about, lengthen compile times, and make writing a compiler harder
Yes it does. I've only had a cursory glance, but I get the same impression as /u/Quxxy. The main question in my mind was "where's the equivilant of `fn foo&lt;'a, T&gt;(&amp;'a T) -&gt; &amp;'a T` and `struct Foo&lt;'a&gt; { ... }`?".
I did not read extensively on the subject, but it seems that the chrome code base does not take much advantage of C++ features nor use sensible conventions to hint devs whether a string is safe to change, or if it should be copied. For example, a proper use of std::string with references could make advantage of a copy-on-write implementation with limited memory footprint. But proper rust would make the use of conventions unnecessary though.
Walter Bright: Yes, it would be written as... scope ref T setVal(ref T t) { t.val = 12; return t; } &gt; Another question, how would a reference counted pointer take advantage of scope, &gt; i.e. avoid the increment/decrement when being passed to a function? &gt; One solution would be to add a function that returns a scoped reference to the &gt; underlying value. &gt; struct RefCounted(T) &gt; { &gt; scope ref T borrow() { return *p; } &gt; } &gt; Will it be possible to deduce, that the lifetime of that scoped value is tied to &gt; the smart pointer? struct RefCounted(T) { T t; scope ref T borrow() { return t; } alias this t; } This enables RefCounted!T to be implicitly converted to a T, but with a scoped result. This is a critical feature, one I spent a lot of time thinking about, and hope it's right :-)
Where is that conversation happening? I'd love to follow it.
I'm surprised this never came up when I was searching around. I feel like an idiot since when I google "rust evec-in-struct fails" it's the first result. Thanks!
Sure, curation can be good. But you still do curation by pointing out a number of small crates, without having a single big all-or-nothing crate.
If I could give gold for this, I would.
might be interesting to have /u/walterbright drop by too, if he feels like it :)
&gt; recently there seems to be some hope for it [You are refering to Ninjhax I assume?](http://smealum.net/ninjhax/) I really wish that I had a copy of the game so I could have homebrew on my 3DS as well. I'm in the same boat that I think it would be awesome to have Rust on a 3DS just for the fact that it would be Rust on a 3DS :)
erickt made a heroic effort in discovering this. We're still investigating why it's happening, but at the moment it may be due to strangeness around LLVM's inlining thresholds.
[I think there are some problems with COW strings in C++11](http://stackoverflow.com/questions/12199710/legality-of-cow-stdstring-implementation-in-c11).
The signature of HashMap::get (and also Index&lt;...&gt;) has recently been changed to take a `BorrowFrom&lt;T&gt;` instead of `T` so no need to do complicated stuff. just key by String (it was actually never a good idea to key by MaybeOwned).
The `HashMap` example is outdated because now `HashMap` natively supports `String` keys with `&amp;str` lookup. You just pass an `&amp;str` to `HashMap&lt;String, _&gt;::get()`. If you look at `Cow`, it's just a two-variant enum: pub enum Cow&lt;'a, T, Sized? B: ToOwned&lt;T&gt; + 'a&gt; { Borrowed(&amp;'a B), Owned(T), } The `Borrowed` variant only holds an immutable reference, so if you want a mutable reference to the contained data, you have to clone it and convert the `Cow` to the `Owned` variant. And that's exactly what `to_mut()` does: pub fn to_mut(&amp;mut self) -&gt; &amp;mut T { match *self { Borrowed(borrowed) =&gt; { *self = Owned(borrowed.to_owned()); self.to_mut() } Owned(ref mut owned) =&gt; owned } } If the `Cow` is already `Owned`, it just returns a mutable reference. The `B` type parameter must implement `ToOwned` in some fashion. There's a default implementation of `ToOwned` for types that implement `Clone` (to create an owned version of themselves), and then a specialized one that converts an `&amp;str` to `String` by making a copy. 
Unfortunately, it seems `cargo build`, both with gcc in the path and without it because of the linking and compiling issues, as well as `make -f Makefile.in`, is failing to compile cargo. Seems I'll just have to wait until the supposed "nightly" is updated. Thanks for the info though :)
Yeah, there's no real point passing around references of references.
This reminds me of an issue I discovered with Clang not long ago, where this… (x ? f : g)(…); …was dramatically slower than this. if (x) f(…); else g(…); [Check it out.](https://gist.github.com/evincarofautumn/976a430685e3fa0b9516) I haven’t looked into why, and I don’t know if it’s been fixed. I’m using 3.6.0 (trunk 218459) (llvm/trunk 218263). 
Don't get too excited everyone, this may have been a fluke, where the build without the patch ran abnormally slow :(
Just saw this. AMA.
There's a lot to be said to avoiding an npm-like nightmare, where you have 10K files just to build a trivial project. Curation of a few more "standard libraries" is a good thing indeed.
That result isn't really surprising at all. In the `if` case, each of the calls is direct and gets inlined. In the case of the ternary operator, the calls are indirect through a conditional expression producing a function pointer, so they don't get inlined.
I was going to write something longer and address each point individually, but the short answer is: exception safety problems exist in every language with resumable exceptions, and it takes superhuman effort to actually get them right. Most people don't. Failing to account for exception safety is a major source of bugs in every language I have ever seen with resumable exceptions, because the possibility that an exception might be thrown means there is potential hidden control flow *everywhere*, particularly in generic code. Nothrow / checked exceptions can help in isolated cases (that is, if you have nothrow you can avoid some of the performance problems that result from entirely unchecked exceptions), but in general this divides the world into exception-free vs. exception-ful camps, since it limits your ability to interact with generic types (similar to `Sized?` in Rust right now). If you are looking for a reason why exceptions *can't* be used correctly (which it seems like you are above?), you won't find one. But my real-world experience tells me that it's probably about as easy as writing memory safe code in C++: once you are familiar with how to ensure exception safety, and have features like nothrow that you can use to limit their prevalence, you can be very careful and almost never slip up. But you have to be perfect every single time, and the compiler will give you no indication when you mess up. And even if you do miraculously get exception safety right *everywhere*, the cognitive overhead required to keep everything straight means you have less brainpower for the rest of your program.
&gt; All of this has me thinking that sensibly designed C++ conventions and APIs would take these realities seriously, and require a "not aliased" `&amp;&amp;` qualifier not only in the conventional "moving out" positions, but *anywhere that memory may be invalidated* (so, anywhere that Rust requires `&amp;mut`). For instance, this would mean most of the methods on `vector`. Perhaps this would be ergonomically painful, but then life is pain, and C++ doubly so. So you'd like libraries that had most of their mutating methods be vector&lt;T&gt; sorted(vector&lt;T&gt;&amp;&amp; nums) instead of void sort(vector&lt;T&gt;&amp; nums) ? That actually would be kind of nice. Not very ergonomic thanks to how the language works, though, since everything would be full of `std::move`s. Kind of makes me appreciate Rust's approach.
Is there any reason the former can't be converted to the latter? Aren't they equivalent semantically? Or is the compiler just not doing that particular analysis?
I might be missing it, but it seems to me that you wouldn't be able to create a safe `Mutex` under this system since the lifetime only lasts for the scope of the function call. If that's the case, it's not really analogous to `&amp;mut` in its full generality. I suppose it depends whether you consider lifetimes fundamental to Rust references or not.
For his exact example, the LLVM IR looks like a `select` followed by a `call`: %8 = select i1 %7, i32 (i32, i32, i32, i32)* @sum, i32 (i32, i32, i32, i32)* @product %9 = tail call i32 %8(i32 1, i32 2, i32 3, i32 4) #4 This particular idiom would be very easy to detect and turn into a branch and two calls. It would be a bit more difficult if the conditional expression producing the function pointer were more involved, but if all of the potential results are known functions then it should be possible. The reason why this isn't implemented in compilers is that code like this isn't found in existing codebases, which is a bit of a chicken-and-egg problem. C/C++ programmers tend to avoid indirect calls when they are not strictly necessary.
I agree with you. An effect system would make it much easier to write unsafe code. However, I wasn't actually talking about the memory safety concerns in low-level destructors (which are very real), more about the general difficulty of preserving invariants in languages with exceptions without at least an opt-in effect system of some sort (e.g. nothrow). I'm not suggesting that it be considered unsafe to catch exceptions in Rust. There are definitely times when you might want to do it, e.g. for better fast-path performance for recoverable errors in tight loops. But explicit control flow is way easier to reason about and I find overall that it massively boosts program correctness over exceptions, so that being the default mode of error handling is really refreshing. I think for catchable exceptions to really *work* you have to be able to present your invariants to the compiler so it can detect anomalies, a la database queries (or lifetimes I guess, to continue the memory safety analogy). That seems way beyond the scope of anything Rust is trying to do. (Also, belatedly: the old solution Rust had [that I think is gone now] was to poison any mutex on failure, so that tasks that attempted to subsequently access it would also fail. It was a nice thought, but (1) it added a lot of overhead and complexity to the implementation, (2) it doesn't really solve the problem in general [since shared state isn't necessarily always part of the stdlib's concurrency suite, or even memory at all], so I'm happy it's gone / going).
Some notes that I feel need pointing out (some of the stuff you said I am not commenting on I like very much): You can move out from any reference variable. It is not unique to rvalue references. You might think it’s *privileged* to rvalue references, since they may very well refer to a soon-to-expire value which are prime targets for a move (values that you can mutate, unlike with lvalue refs-to-const that otherwise share this property); but there are many cases where you’ll use the reference without moving out its referend, and conversely where you’ll move out of an lvalue reference. Very, very often you move out a non-reference variable, too. What you pilfer (because 'move out from' is a mouthful) is dictated by the circumstances and needs of the code. Those very circumstances might call for rvalue reference variables, it’s true. But I think making the rvalue reference–move association is a bit knee-jerk. (And referring to rvalue references as 'moving references' is very misleading. Rvalue reference variables won’t move anything once initialized, that’s a common misconception.) And then there is the whole matter of forwarding references (aka universal references) in generic code. Note that for code such as: let f: Foo = make_me_a_foo(); let magic_number = network::give_magic_number(); if magic_number &gt; 7 { consume_a_foo(f); // move } else { read_more_foo(&amp;f); } it will need to do the right thing and drop `f` at the right time. So a move in Rust and one in C++ need not be so different—although of course having it first class in the type system is very, very much helpful. And I don’t think that describing C++ types as 'traditionally' having a null state is accurate. (I won’t bring up `restrict` as it tends to aim for another domain altogether.)
I worked on a units of measurement type system built on Java annotations for a year or so before I started doing Rust related work (I was trying to make a improvement over the existing Units checker in the Checker Framework. I think it would have done more than F#'s checker). I warn you: units checkers are endless pits of madness. That 'Abyss' Neitzche mentions? I'm pretty sure he was talking about type checking units of measurement. It will consume your soul. That said, it's probably better to take a compiler extension/plugin approach. You'll want to do unit arithmetic in the types of arithmetic operations (*/ in particular) and you probably won't convince people to let you change the their types to some weird encoding of arithmetic.
Wait, to be clear, I'm not talking about resumable exceptions. I just mean regular exceptions. Panic + catch. It's one thing to say exceptions are as problematic as C++ memory safety. But is that borne out by experience? There's myriad examples of lack of memory safety being a problem, and a serious one at that. What are the pervasive bugs from your assertion that most people don't get exception handling? Offhand, the only one that I can remember is a C# compiler codegen bug, where their code acquires a lock before entering a try/finally. In Rust this isn't an issue since the dtor will always run (that seems to fix some of the C++ issues, too). Other than that, I cannot think of any exception-caused bugs in programs I've written in the last while (whereas I can think of memory safety issues all over). Writing code like unwrap is not the same as saying you cannot continue. It's just tight, concise, code to perform a whole bunch of operations and treat them as a single failure block. Which is exactly why Rust promotes the try! macro in the first place. Edit: To make my tone clear, I'm not saying you're wrong. It's just that in a long time of programming with exceptions, I haven't seen them cause the difficult-to-reason issues that seem to be the showstopper here. Also, what is special about task that it must be the boundary for panic recovery? Why not a lightweight process that doesn't require a new thread?
And compilers like GHC are doing it on their own before passing code to LLVM. First it has to do it anyway as it also has its own native codegen and can generate C, secondly such things, on rough estimation, are easier to do in System FC than in LLVM IR, anyway.
Grass goes in, milk comes out the dangly bits. (sorry couldn't resist) Is cow Could Own? I forgot.
Unfortunately syntax extensions have no idea about types. Wouldn't you have to fork the compiler for that? I just think that compile time units are a critical aspect of writing safe code, but I do agree that without good ergonomics or error messages, it probably would not be worth it :( I can imagine doing some of this in such an inexpressive language as Java would be extremely painful. Did you look at the F# papers? They seem to have a good approach, but it relies heavily on compiler support. There are also interesting Haskell libraries for units, but they probably suffer from poor errors as well.
&gt; But if that impl was bundled with hyper... gently prodding the maintainers :-) You could submit a pull request implementing this :) Nice writeup, it was an informative read.
Ideally Rust will eventually support arbitrary compiler plugins via custom attributes. That's probably the best way to go about this sort of thing in general. The main issues I ran into weren't so much Java problems (though that certainly made things worse) as they were framework problems. The Checker Framework is basically a forked `javac` that lets you layer additional type systems onto Java via annotations (i.e. extremely heavy compiler support). My issues mostly had to do with the annotation mechanisms in Java and the Framework not supporting the kinds of things I was trying to do (particularly in regards to generics). Theoretically, there's now a general workaround for those issues, but I'd already switched over to my Rust type system proof work so I haven't gone back to check. Honestly, what I wanted to do with units checking is pretty ambitious compared to the F# and Haskell stuff. If I ever go back to it, then I'll probably do it in some toy model rather than on top of a real language. Much easier to focus on the actual issues that way.
That’s what I figured, but it’s disappointing considering that the functions involved are known statically. The reason I used the expression version in the first place was to avoid having to name the argument values or duplicate the argument list.
You could use [hyper](https://github.com/hyperium/hyper) for this. [html5ever](https://github.com/servo/html5ever) lets you parse HTML but complex headless interaction would be tough. Rust would be quite efficient for this task (runtime efficiency), but the libraries may be missing things you need (though for most of these libraries feature requests get implemented without too much delay unless they require large rewrites). So I'd suggest holding off on using Rust if you have time constraints on this. Otherwise, go for it; it should be fun and the maintainers of these libraries are quite open to suggestions in my experience :)
Increase your performance with this one weird trick! Compilers hate it!
&gt; (Also, belatedly: the old solution Rust had [that I think is gone now] was to poison any mutex on failure, so that tasks that attempted to subsequently access it would also fail. It was a nice thought, but (1) it added a lot of overhead and complexity to the implementation, (2) it doesn't really solve the problem in general [since shared state isn't necessarily always part of the stdlib's concurrency suite, or even memory at all], so I'm happy it's gone / going). It's not gone, and I don't believe there's any intention for it to go. It's not really that complicated: at the core, all it takes for poisoning is a boolean that gets set when the mutex guard destructor is run while the task is failing (easy to detect: `std::task::failing()`) and then `.lock()` checks it after acquiring the lock. The current implementation in `std::sync` is shared between two types and is a little more complicated for the purposes of nicer messages. All the boolean operations occur inside the critical section and so can be nonatomic, and hence are very low overhead.
I had thought it was going away with the runtime, but perhaps it isn't. &gt; All the boolean operations occur inside the critical section and so can be nonatomic, and hence are very low overhead. For many applications *any* operations inside a critical section, even nonatomic reads, are a performance concern, as are extra data in the mutex. Those applications won't use the builtin Mutex, I guess, but that is my point: it doesn't protect against exception safety issues for any types other than the builtin Mutex. It's still a problem in the general case.
Ada still uses GC to be memory safe, if I recall correctly.
Oh, the tagging is called keywords: http://doc.crates.io/manifest.html#package-metadata
Thanks!
Rust didn't really seem shy about GCed pointers a ~couple of years ago, before it became apparent that using no garbage collection at all in a safe way was very doable, and preferable to most Rust users. No?
Rust's std::sync::lock::Mutex does not free itself when it is destroyed by unwinding, but rather marks itself as abandoned and propagates the panic, so this isn't a problem.
A non-atomic in-cache read is much faster than the `cmpxchg` involved in locking a mutex. And at least on Linux, mutexes already come with a poisoned bit (which we currently don't use, mostly because our Mutex implementation is crap, but could), which would make this not take space at all. 
I'm not hugely familiar with Ada but from what I've seen most of its safety was enforced at runtime (unless you were using a formally verifiable varient like SPARK), which is not really all that useful (and in fact was responsible for the explosion of an Ariane 5 rocket). Also, there's the more political aspect of Ada having just completely failed to take off outside of the aerospace industry for many years.
Rust's "GC" pointers were just reference counted, with a linked list through them to ensure that cycles got destroyed on task exit. They were an awful hack.
That would explain why people did not consider using Ada to write a browser by itself, I think. Browsers would not get very far without dynamic memory allocation.
I think this is why Ada does not like GC. Just like Rust does not. Maybe the key difference is unique/moving ownership.
You misunderstood me. Ada has all the features that C and C++ have in terms of memory allocation. For example, here is how you could implement a generic class for reference counted pointers. http://www.adacore.com/adaanswers/gems/gem-97-reference-counting-in-ada-part-1/ Systems programming languages that aren't part of OS SDKs don't tend to live long. 20 years ago we had plenty to choose from that were way safer than C and C++, but only C, C++ and Ada survived. C and C++ are available in all operating systems out there. Either because they are based on UNIX/POSIX compatible or because their vendors eventually adopted them. Ada kept being used thanks to its use in the military, aerospace, traffic control and medical devices. Where safety comes before programmer convenience. So you don't have Ada compilers in any mainstream OS SDK, only in real time OS for the industry where it matters, which already limits choice. Secondly besides GNAT, which is only around 10 years old, all Ada compilers are commercial, which in this day and age you only get the enterprise to pay for software tools. Finally, which may came out as a rant, many developers in the C school like write only languages, while Ada is a bit verbose because code readability counts more than programmer convenience. This is very important for Rust, looking for the history of programming languages, only systems programming languages that managed to be part of an OS SDK survived in the long run. 
&gt; I apologize for bringing up what must be an often-discussed question. The IRC link in Graydon's email didn't work, and the only other log I found didn't seemed to indicate key people thought Rust was just "philosophically against" exceptions. Personally I believe that unwinding is a horrible idea and there are plans to make unwinding optional (vague plan). I write all my code so that unwinding does not matter and I treat it as if it was fatal. I am pretty sure that in two, three years there will be a consensus that supporting unwinding was a pretty stupid idea because it forces people to write much more complicated code which is slower for the rare case that someone will need it. There is already loads of code in Rust which is not unwinding safe. :-/
... I guess I'll go first, then :) thanks for responding to the bat-signal. How do you see this propsal and what Rust does differing? Obviously, adding a feature to an existing language is quite different than starting out with it. What was the primary motivation here? Sorry of that's in the article, I read it last night and don't rmemeber. Will this help with D's removal of GC from much of the standard library?
&gt; Designed for hard-realtime system/hardware programming It was designed as a general-purpose language for all DoD needs, replacing Fortran and COBOL as well. &gt; Fully deterministic automatic memory management with no need for tracing GC I'm not sure where you got this information. Ada has some facilities in this area, but they are generally too restrictive for many real-world use cases. It is possible to implement smart pointers as a library, like in C++, but compared to C++, the syntax when using them is very verbose (due to explicit instantiation of generics and the requirement to name them), and there is both a performance penalty (rather heavy if you do not disable asynchronous transfer of control support, which is enabled by default), and a completely superfluous tag word in every smart pointer object. (Both problems apply to RAII in general.) A lot of code uses manual resource management due to this. &gt; Task based lightweight concurrency In the most widely used implementation, tasks map to POSIX threads, so they are only lightweight when compared to full OS-level processes. (The Ada marketing literature is a bit dated.) &gt; Awesome level of safety There's a [hole in Ada type safety](http://www.enyo.de/fw/notes/ada-type-safety.html) even without using library constructs which are labeled as unsafe. But for the most part, Ada clearly separates safe and unsafe constructs, which means that it is easier to notice if something bogus is going on (e.g., string manipulation is completely safe, and if you can live with the additional copies, you can often use Ada's ability to return dynamically sized objects without heap allocations to good effect). &gt; Data race free Not true, or only true in the C11 sense that valid programs do not have them.
&gt; It's easy to explicitly swallow Results: &gt; let _ = println!("{}", foo); For errors I want to ignore, I append "is_ok()", like: something_that_returns_result().is_ok(); Dunno which one is simpler :-)
&gt; alias this t; I think you mean: alias borrow this; Also, I'm hoping `borrow` won't be necessary: alias scope ref t this; 
&gt; Secondly besides GNAT, which is only around 10 years old, all Ada compilers are commercial, which in this day and age you only get the enterprise to pay for software tools. [GNAT is commercial as well](http://www.adacore.com/), and it's about 20 years old now.
Are those enhancements compatible with this DIP?
Thanks for correcting the age. I just wrote it down from memory. Yes it is commercial as well, but the point is that it is the only open source production quality implementation of Ada. All the other alternatives are commercial.
&gt; failed to take off outside of the aerospace industry for many years. Ada is used a lot in train control systems, factory control and medical devices, places where human lifes are at risk if the usual quality of desktop software is used. Also known as High Integrity Software.
I didn't misunderstand you. If memory deallocation is considered unsafe (not guaranteed to be safe at compile time), it can't compete as a *safe* language for writing a browser (which I think is what the OP was asking). I also don't really think the OS SDK thing means much. C++ spent a very long time as a popular language before it was incorporated as an OS SDK.
https://github.com/rust-lang/rust/issues/19595 Thanks!
Oh, `&amp;mut` is definitely stronger than `&amp;&amp;`, I never suggested otherwise. The point was more that `&amp;mut` is what `&amp;&amp;` *wants to be*, and that it probably helps to think about it in this sense.
Hyper is very low level. Gives the user great powers but it almost hurts while doing simple things.
I would. The reason being that I want a more modern language to replace all the uses of C in code for weird embedded architectures. That being said, there's nothing stopping you from using rust types in your API. Just cast your integers using the as-operator. This will be a no-op on modern architectures, but will work (modulo overflow) on weird architectures as well. If you are afraid of overflows you can always use assert to make sure that they don't occur.
&gt; But I think making the rvalue reference–move association is a bit knee-jerk. (And referring to rvalue references as 'moving references' is very misleading. Rvalue reference variables won’t move anything once initialized, that’s a common misconception.) Yes, this is what the first two paragraphs or so were essentially about. I had a superficial impression and it turned out be wrong. The association between rvalue references and "move semantics" is however very strong and pervasive. How would you more precisely phrase the connection between the two? And do you think the basic insight that `&amp;&amp;` is (or wants to be) a (hopefully) non-aliased reference type is correct? &gt; And then there is the whole matter of forwarding references (aka universal references) in generic code. ...yeah. I haven't C++11ed for a couple of years now. At one point I had some primitive mechanical understanding of how this worked - it's some kind of hack at the intersection of templates and `&amp;&amp;` types - together with the higher-level heuristic "use `std::forward` if you want to forward template arguments as-is". But I never had a deeper understanding, and by now I've mostly forgotten even the mechanical one. Do you know of a good high-level (but not hand-wavy) way to think about these? &gt; Note that for code such as: &gt; &gt; ... &gt; &gt; it will need to do the right thing and drop `f` at the right time. This is connected to the [whole static vs. dynamic drops debate](http://github.com/rust-lang/rfcs/pull/320). But notably, if you want to keep using `f` after the `if`-`else` (the typechecker will prevent you accessing it if it might've been moved out of, as in the first branch), then you need to use an `Option` and `take()` from it instead, so that the `Option` itself will still be in a valid state after the `if`-`else`. Which is essentially what you do in C++ behind the scenes. &gt; I don’t think that describing C++ types as 'traditionally' having a null state is accurate. `std::unique_ptr` and `std::shared_ptr` can be null, `std::Box` and `std::rc::Rc` can not be. Possibly there are contrary examples, but as far as I can tell, this is the general trend. &gt; (I won’t bring up `restrict` as it tends to aim for another domain altogether.) Actually, someone recently linked me some draft proposal (I only skimmed it) where they're trying to figure out how to integrate C's `restrict` with the next C++. What would you say is the critical difference between `*restrict` and `&amp;&amp;`, not in their precise technical definitions, but in their meaning and intended use (if there is one)?
&gt; Should I worry about c_int being smaller than i32? Yes, but no. Just fail at compile time with a static assertion and let people who want to use it figure it out. YAGNI, and they are going to know better what they want.
Hyper dev here. I have a Client interface very nearly complete. It does what you prodded for, and more :) 
&gt; string -&gt; char const* -&gt; string, maybe a string const&amp; would have sufficed? Taking a reference to a std::string still forces allocation with static strings and slices into other strings. Chromium has a StringPiece type similar to &amp;[u8]/&amp;str but it doesn't solve the problem when a NUL terminated C string is required.
I think the case for Rust over Ada should be clarified and featured in Rust marketing materials. While most of Rust's target users are probably currently using C and C++, they're still all going to ask "OK, if I'm going to learn something new, why not Ada?" Otherwise, marketing Rust may just increase Ada adoption, for better or worse.
We generally try to stay away from talking about other languages when it comes to marketing.
You're trying to cast it to a trait object, which must have a size. box stream as &amp;mut Box&lt;Reader&gt; Will box it up, and boxes have a concrete size, which will remove the error. I have doubts that `stream` is actually a `&amp;mut Stream` and not someting that implements `Stream`.
As I see it you basically have to choose between three different strategies. 1. Use C types everywhere and force the user of your library to convert between C and rust types. 2. Use rust types everywhere except in your extern-declarations, and convert between rust and C types in your library. 3. Use rust types that you know are as big as the C types on your platform (maybe adding static asserts to make sure that is correct). Option one is bad, since it makes it much harder to use the library for your users. But to be honest, I don't really see that much of a difference between option 2 and option 3. The thing is that if there is a C library for an unknown architecture that is still POSIX-compliant, then your code would work for that library automatically instead of failing at compilation time. It isn't harder for you to write option 2, and if you map to rust types that are of the same size on common architectures there won't be any overhead due to the casting. P.S. I know that the language is perfectly capable to be used on 16-bit architectures, my point is that having better library support might be a factor for people considering using rust on an embedded architecture. D.S.
Wouldn't that have to be: box stream as Box&lt;&amp;mut Reader&gt; Either way, it results in a non-scalar cast error: error: non-scalar cast: `Box&lt;&amp;mut std::io::Stream&gt;` as `&amp;mut Box&lt;std::io::Reader&gt;` Also, wouldn't a reference not have a size anyway? (i.e. the architecture pointer size?)
&gt; Do modern 16-bit things even have a libc? Libc, not unlikely. Likely, actually, at least to some degree. POSIX, not so much. If you've got a full POSIX system you probably have a UNIX at hand, which means that you need a MMU to run it without being guilty of blasphemy. If you want a MMU on modern CPUs, though, you generally also get at least 32 bits. Of course, people might want to run things on their PDP-11s, which obviously run UNIX. But then, as I said: Let them care about that.
Could you post your code please?
I agree that we should not market by comparison, but it would be useful as documentation. As long we are objective, honest and humble, it should be fine. Documenting transition strategies for existing code bases could also be useful.
Yes, I constructed a simple example of my problem: http://is.gd/dG0A5X **EDIT*: Wait a second, with the offending lines commented out that code actually core-dumps: http://is.gd/FV5sPB Smells extremely like a bug. Oddly though, this construct doesn't crash in my actual code, so maybe this crash has nothing to do with my problem. 
&gt; I just got hired a company that is starting a project using Rust in the telecom/networking space. Off topic, but... that is exciting! Congratulations on finding the job. :)
Thanks for clarifying, I answered a bit late at night and I needed it. &gt; The association between rvalue references and "move semantics" is however very strong and pervasive. How would you more precisely phrase the connection between the two? &gt; And do you think the basic insight that &amp;&amp; is (or wants to be) a (hopefully) non-aliased reference type is correct? I’m a bit uneasy making blanket statements regarding the reference *types* of C++, because they’re a bit weird and ad-hoc. But I think we should find common ground if we focus on rvalue reference *variables* and particularly rvalue reference *parameters*. It’s been a while since the C++11 standardization process, but I’m fairly sure that the matter came up. In fact, and I should really have brought that up earlier, while the language (in the strictest sense) does nothing to regulate aliasing of such parameters there *is* a rule when it comes to the Standard library: &gt; If a function argument binds to an rvalue reference parameter, the implementation may assume that this parameter is a unique reference to this argument. (In 17.6.4.9/1, [res.on.arguments].) On the other hand if we pretend we’re the only C++ programmer in the world and have no regard for clarity then consider the following: void foo_ref(bar&amp; b); void foo_rref(bar&amp;&amp; b); void foo_ptr(bar* b) { b-&gt;qux(); // compiler allowed to assume non-null arg // ... } With nasty tricks like `Val&amp; as_lvalue(Val&amp;&amp; ref) { return ref; }` then you can do things like `foo_ptr(&amp;as_lvalue(bar {}))`—and so as it turns out, there isn’t a great deal of difference between the three declarations. That’s why I’m not sure how to reconcile those two opposite views: the language proper tends to treat references at a mostly syntactic level; while the community certainly is leaning towards imbuing a no-alias guarantee to rvalue reference parameters (at the least). Should another step be made where we imbue rvalue references in the language with a no-alias guarantee in select circumstances? If I have to be very honest, I’m of two minds on the matter. If I objectively take a look at how I program, I certainly tend to keep track of when I ‘move’ (i.e. form an rvalue reference to) a variable, and I certainly treat use-after-move (or use-after-forward) as a bug. IOW, I’m performing borrow-analysis and affine type-checking by hand, hence it’d make sense to let the language benefit from it. But the truth is that I’m very, very likely to mess up from time to time. In the present state, finding those bugs have been relatively easy because pilfered variables are very obvious in the debugger†. If on the other hand the compiler would be free to make no-alias assumptions, I would be very afraid of the subtle, almost invisible changes to the generated code that could result. Perhaps I’d be swayed if I knew what benefits we would get from those assumptions. Speaking of, C has very much of a use for `restrict` because you can’t pass arrays but have to pass pointers (and runtime-sized arrays don’t appear in the type-system anyway). So it’s helpful for number-crunching code where you can specify which strips of memory are promised not to overlap, so that the compiler may optimise accesses (consider `memcpy` vs `memmove`). C++ can have a use for that too, because having no-alias references to vectors will not tell anything about the underlying strips memory they stand for (plus it’s more sensible to pass iterators/ranges for that, and so you end up needing restrict iterators anyway). So from a high-level perspective, I suppose that restricted pointers and exclusive slices are two sides of a same coin, depending on how smart you want alias/borrow analysis. ----- †: This is where circle back to types with null states. I don’t necessarily need a null state that is observable in code, but there are many types for which an observable pilfered state or behaviour in the debugger is a boon—empty vectors, null smart pointers, `std::terminate`ing objects and so on. And so if I define struct my_own { vector_type foos; smart_ptr bar; some_type baz; // terminates if used after move … }; I won’t provide an empty constructor+null state and accompanying null state query unless it makes sense to, but I still get nice behaviour in the debugger.
You cannot cast from one trait to another. The Stream definition is better understand as implicit bounds for the trait then as inheritance. You can check it on minimal example here: http://is.gd/c5PNKs
If it gives you a warning when you don't include #[deriving(Copy)] anyway, doesn't that undermine the point?
&gt; wouldn't a reference not have a size anyway? (i.e. the architecture pointer size?) Right, it has a known size: the size of a pointer. As /u/burntsushi says, seeing more code is going to be helpful.
[Is this enough?](http://is.gd/dG0A5X) *bar* is supposed to only read stuff so a Reader is enough. I could use Stream instead of Reader but then Writer would needlessly be required to be implemented as well.
I wasn't aware that you used bindgen. I retract my previous statement :)
Thanks for the mention of pretty-printing JSON! I was looking into how to do it for a project later, but there aren't very many examples of it in use. Didn't know about using Vec&lt;u8&gt; for it's Writer, for instance.
&gt; Does anybody know if something is in the works, or of a good crate I could import? Just make your own! :D
Fantastic! Is it open source already?
To what degree does this make the NoCopy marker obsolete? I've always found Markers to be weird language constructs, if there is a #[deriving(Clone)] for opt-in to Clone, there should be a corresponding #[noderiving(Send)] for stuff that's opt-out rather than opt-in IMO. (With the "noderiving" name subject to bikeshedding)
How can you do this with a static assert?
I like your version less, because it's less clear to me that the author understood that he's supressing the error check.
Does the warning message for not_deriving_copy indicate that suppressing that message is sometimes the right thing to do? I can imagine people seeing a message and assuming that they're expected to derive Copy. It's a different kind of lint from unused_must_use, which is something that probably shouldn't be allowed as often.
It makes the `NoCopy` marker entirely obsolete, IIRC. Someone who knows better, feel free to correct me.
My biggest annoyance here is that it prevents you from using `Cell` on those larger types, where it would be memory safe (albeit slow) to do so. I do understand the rationale, I just wish `Pod` (what `Copy` was before) was a separate trait from "silently copy" (what `Copy` is now).
It's quite unlike Rust's method of borrowing and ownership. It's necessary in order to implement a memory safe ref counted type.
What do you mean by code that's not unwinding safe? Like a shared object that won't keep its invariants if a task using it panics?
In F#, there is ignore. something_that_returns() |&gt; ignore. 
Rust has regular C++ style exception safety problems in unsafe code, which is probably what mitsuhiko is referring to. When you use unsafe blocks, not writing exception safe code becomes a memory safety concern. For example, if you use `::std::mem::uninitialized()` with a type with a destructor, and `panic!()` without assigning to its elements, you will have undefined behavior when `drop` is called.
OK, I'm gonna go back over a lot of C# and F# code I've written and look at the catching. _Most_ of the time the catching is done at a fairly high level, just not thread-aborting level. It sounds like the real issue is programs screwing with global state. The more pure a function, the less issue there is with exceptions. The exact thing I'll be working on receives a high volume of messages/sec, and for each message there's a lot of ugly logic that I really don't want to have to thread Results through. If any particular message fails, it doesn't matter, and it was a pure function anyways so there's no possibility of side effects. But the cost of a task/thread per message is completely unusable. Anyways, I'll try writing it with explicit error handling everywhere and see how painful that ends up to be. Perhaps it's not that bad in reality. I just know from experience, even in F#, it was very handy to just write code that made assumptions, and let a higher-up handler take care of if it failed. "determineUser(msg)" threw? OK, fine, no user, continue processing.
Exceptions are themselves a side effect, so any function that throws isn't completely pure (which has practical implications for compilers, e.g. they can't optimize them in the same ways). But you're right that exceptions-as-a-side-effect are not so bad by themselves without mutable state (and exceptions-as-a-side-effect is what Rust tries to emulate with its `panic!` system).
Thank you for your tireless explanations here, honestly.
Catchable exceptions aren't *always* faster, unlike unchecked arithmetic. They can make many common patterns a lot slower by inhibiting compiler optimizations and preventing you from using algorithms because of exception safety concerns. And people do arithmetic in tight loops a lot more often than they throw exceptions in tight loops, so it's more likely to show up in benchmarks. All that being said, as you know lots of people still want Rust to have it by default :) FWIW, I do think unchecked arithmetic is really bad from a correctness perspective, but I don't like panic! / abort on overflow as the answer. I would really love for Rust to get compiler-verified range types.
C++ began as a "preprocessor" (C++-to-C translator), so it could mostly run wherever C could run.
That could be said of a lot of modules in `std`. :P
&gt;&gt; "Can someone let me know the why? What made them to develop a new language?" This is how the world evolves. New things appear blending ideas from others, with incremental improvements. Even if rust disappears its' doing good. I'm basically a C++ programmer and I'd never have considered using Ada, but Rust got my attention.
Sure, but writing your own mutexes is already very dangerous – you should really know what you are doing, especially because setting up a poison bit is very cheap – so if you avoiding it for performance reasons you're already very careful about the code inside, and if you're too cheap to test it, you get the robustness you deserve.
Part of it is in the 'client' branch, part of it is still one my computer. It'll be part of Hyper within the next couple days. 
Usually in these cases people will use drop() as their preferred noop (which has the advantage of also working if `Result` was a true linear type, which `must_use` tries to approximate): `drop(println!("{}", foo));` I actually really like this, I think I'll start using that instead of `let _` to swallow `Result`s. It has a nice symmetry with `try!`.
Fair enough. And in case I haven't made it clear, I *do* like that Rust is "usually" exception safe, I just think it's important for people to realize that it isn't totally immune to these problems.
In regards to using pretty printing to troubleshoot stuff, I find using a JSON viewer a much better alternative than emitting human readable JSON, especially one that has some basic querying and can collapse nodes.
YES!!! It was so confusing to me to have magical copy semantics. Thanks.
Yehuda Katz wrote a [very nice blog post](http://blog.skylight.io/rust-means-never-having-to-close-a-socket/) that motivates Rust's ownership/borrowing system and explains it at a high level. Might be helpful in laying some of the conceptual groundwork, at least.
Looks good. Thanks.
or republish it with the uncapitalized name?
I am sorry, I don't want to disappoint you, but I do mind. Because I don't want specifically nationalised preconception or being treated like an alien though my English is a kind of horrible :) (I feel a little guilty on it) I love (pseudo?) anonymity and world-citizenship of Internet. And no, obviously it's not English. If you're still interested in my first language please send me a personal message, and I think I can satisfy your curiosity.
I don't think that really does matter. Because (at least in theory) Ada front-end can be used on LLVM via DragonEgg, and I think there's a movement to use Ada front-end directly on LLVM --- http://www.dragonlace.net (if I correctly understood it)
It certainly does require compiler integration. Fortunately, the necessary compiler integration is well-understood. It's not trivial, but it's also quite well-understood. For the CLR GC, the main things you need: 1) to insert write-barrier calls whenever you modify a reference that could potentially be within the heap (because CLR GC is generational); 2) you need method descriptors, which describe the locations in the stack frame and registers which are GC types; 3) you need type descriptors, which describe the layout of types that can contain GC types. None of this is rocket science. It's not a day's work, of course, but if someone is committed to it, it can be done.
Did you read [The Guide](http://doc.rust-lang.org/guide.html)? It is tailored to people who do not know low level programming. Along with the main guide, there is also the new [Ownership Guide](http://doc.rust-lang.org/guide-ownership.html) to read through.
I'm currently going through the guide, I suspect I will have to run it twice to really let everything sink in. I'm also experimenting on my own simultaneously by building a simple web server, among other things. I'll check out the ownership guide; thanks! I'm just trying to collect as many resources as I can on the more difficult concepts so I can get a clearer picture. 
A lot of people bring up the "Ariane story" when you say Ada but have no trouble using C after "heartbleed" every other month, which potentially has cost more money than the logical error of Ariane disaster consistently misattributed to Ada. This hatred for Ada is just a cultural artifact handed down generations of "C cowboy programmers" to spite "The Man" ie., DoD. Ada 2012 is not Ada '83. edit: missing words.
&gt; Think of the out of memory panic. You'll probably never see it, as in moderns OSes would have either solved the problem or killed your program If you're running a process in an unconstrained memory you might have a hidden security/availability issue. It's like running under root. Hey, you can do everything. Hey, you can take all my memory. And even if we forget that, there's a lot of mobile devices with memory constraints now. Designing a systems language around a concept of unconstrained server programming is just wrong. And BTW, you call killing my program a modern solution to the problem? That barbaric Linux-specific thing smells. I'd take an OS telling me there's a memory shortage over an OS killing me, thank you very much. &gt; So again you shouldn't be able to recover from a panic. That's very surprising and discouranging from a language that is supposed to be safer in production than C++. &gt; To prevent misuse the interface is complex and hard on purpose. Rust claims to be a practical language borrowing from the best practices around the world, but the way it handles exceptions seems to be an exception. A completely unpractical and backwards way of vindicating the programmer for trying to isolate the subsystems and deal with something unexpected happening.
You are right that you can make it a println panic. I think you can cause it with a redirect to/dev/null (not certain though). This, though is an example of the issue. It's easy to make println panic if you can recover, "real programs" should recover from *every call to println*. Instead the way the language works it shows that panicing from println is clearly wrong and an alternative should be sought. My friend you have to understand how powerful rust's type system can be. Check the map and and_then methods for Result. They let you use functions that don't know how to handle input errors. Functions can be made assuming that errors don't happen and the calling code (that knows of the error) can describe how to handle the error itself separately of the ideal no-error case. It does mean that if your code can generate an error you must report this to other users through the return type. It does mean that if your code can assume input error it'll have to state that through parameter types.
I am still getting that version 0.1.1 is already uploaded...when I got this the first time and bumped the version it did not change the name of the package :(
The new owernship guide landed too http://doc.rust-lang.org/guide-ownership.html EDIT: just saw it was linked downthread as well.
It's also poorly named.
(The `-sys` convention is planned to be renamed to `_sys` too)
This sounds like a bug.
If you use generics everywhere (not just in the `deserialize` function), your problems simply [go away][1]: use std::io::{TcpStream, Stream}; fn main() { let mut conn = TcpStream::connect("google.com:80").unwrap(); foo(&amp;mut conn); } fn foo&lt;S: Stream&gt;(stream: &amp;mut S) { bar(stream); } fn bar&lt;R: Reader&gt;(r: &amp;mut R) { // ... } In general, use generics whenever possible. They rely on static dispatch instead of dynamic dispatch, which is usually faster (although generates larger binaries, due to monomorphisation), and let you do a few things that trait objects (dynamic dispatch) can’t (e.g., call generic functions, take things by value). For example, you could remove all of the `&amp;mut`s from that code and it should still work. If generics aren’t suitable for your particular case, and you have to use dynamic dispatch for whatever reason, then I’m afraid I don’t think there’s any safe way of casting a trait object to a trait object for its supertrait. There is [a GitHub issue](https://github.com/rust-lang/rust/issues/5665) for it, though, so maybe you’ll be able to do so some day. (The signal 31 you’re experiencing in the playpen is due to the fact that the playpen is not allowed to do certain things, such as (I presume) network calls. So it’s not a bug in rustc. 😉) [1]: http://play.rust-lang.org/?code=use%20std%3A%3Aio%3A%3A{TcpStream%2C%20Stream}%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20mut%20conn%20%3D%20TcpStream%3A%3Aconnect%28%22google.com%3A80%22%29.unwrap%28%29%3B%0A%0A%20%20%20%20foo%28%26mut%20conn%29%3B%0A}%0A%0Afn%20foo%3CS%3A%20Stream%3E%28stream%3A%20%26mut%20S%29%20{%0A%20%20%20%20%2F%2F%20I%27d%20like%20this%20to%20work%3A%0A%20%20%20%20bar%28stream%29%3B%0A}%0A%0Afn%20bar%3CR%3A%20Reader%3E%28r%3A%20%26mut%20R%29%20{%0A%20%20%20%20%2F%2F%20...%0A}
It won't be fine - D tried this many years ago - http://dlang.org/comparison, and you can see how that ended up. Even if you remain objective, people from other languages will still pick holes in it, and rule #4 quickly gets broken. You also end up with discussions beginning "Language Foo has features W, X and Y; but Rust has none of these!" - regardless of the merits (of lack thereof) of those features. There's simily no way to comprehensively compare languages in a way that won't upset people. I personally think that any comparison to other languages beyond "traits are kind of like interfaces in Java or type classes in Haskell" does not belong in official documentation.
What's a good JSON viewer?
I don't much like C either, funnily enough, which is why I'm interested in Rust (and have looked at Ada). &gt;logical error of Ariane disaster consistently misattributed to Ada You can claim the same for basically any bug in any program written in any language.
yeah i updated cargo just to be sure but I still get the same issue...which sucks because i just finished a library I want to release :(
Yeah, you might be right on this. It would easy to let things slide if we were not careful, and we try to be a friendly community.
The Rust Guide is just a single large text/markdown HTML page, you should be able to download it and view it offline
Don't choose. Slurp everything there is on the official pages, clone the whole rustc repo including the RFCs etc. IRC logs, mailing lists, everything. It's just text, so don't worry about space. You'll probably want a way to search through all of that, I can recommend [recoll](http://www.lesbonscomptes.com/recoll/). Clone all and every library there is, you'll need code to build on and examples.
Inspired of [cmr's devlog](http://devlog.octayn.net/), this is a worklog about what I'm doing with Rust. This particular post is far-fetched then I've first imagined (because, well, I wanted to share the problem) but typical posts are going to be one or two paragraphs plus some additional sections. Any feedback on either this post or Rustlog itself is appreciated.
Are you the author of this blog-post? If so, there's a typo in the paragraph of "Pretty printing": "there are **now** newlines or indents" should be "there are **no** newlines or indents" Also thanks for the series and is there a list of all "24 days of Rust" blog posts? because I don't want to search through the archives to find them..
See also [this ticket](https://github.com/rust-lang/rfcs/issues/415) and links therein.
Perhaps some tricksiness [like this](https://botbot.me/mozilla/rust-internals/2014-10-08/?msg=23126513&amp;page=10) courtesy of /u/eddyb could work?
Yes. It will also build Rust, which may or may not be what you want if you're doing a fresh clone. `make docs NO_REBUILD=1` will make that not happen.
It will still have to build `rustdoc` which needs to be stage1 otherwise it can't be much better than no `NO_REBUILD`.
Even if you already have a `rustdoc` on your PATH? ... I guess that would be a pretty rare case, though.
I wouldn't think redirecting to `/dev/null` should panic it. That's the whole *point* of doing that... discarding output without breaking the program. I think you meant `1&gt;&amp;-` and `2&gt;&amp;-` to actually *close* stdout and stderr.
Thanks for the comment, /u/dobkeratops. Indeed, some types of simulations benefit greatly from GPUs and data parallelism in general. However there are situations to which this approach doesn't fit. For example in a simulation that has hundreds of interrelated (complex, interwoven) objects that are constantly influencing each other one cannot just split "the data" across tasks that execute similar (or the same) instructions. For example: a massively multiplayer game would not be a candidate for a data parallelism approach.
Yes, /u/steveklabnik1, thanks for the link. I will keep an eye on that. What I have in mind may be similar in spirit to reactive programming and/or actor model of concurrency. For example read: http://danielwestheide.com/blog/2013/02/27/the-neophytes-guide-to-scala-part-14-the-actor-approach-to-concurrency.html http://www.reactivemanifesto.org/ I am, of course, beginning to explore these paradigms and approaches, and as such I have no idea whether (and how far) Rust will go in this direction.
I agree that OOM should not automatically panic, which is why it doesn't in the low level allocator APIs. But if you look at most programs that aren't databases, operating system kernels, etc., they do not handle OOM correctly at all, usually just aborting. Also, even in languages with exceptions like Java and C#, OOM pretty much aborts the program. If the stdlib wants to work in those systems every function that allocates needs to be able to explicitly return an Option or Result, which would be a dramatic API change. In any case, you can't do proper exception handling and still recover on OOM because you can't allocate, hence you don't have room to store the stack trace. Systems that do deal with OOM have to explicitly preallocate space for dealing with this stuff. So catchable exceptions are a _nonoption_ on out of memory. If you are actually writing a system that needs to handle OOM, you *have* to think about stuff like that. It's really, really hard. Trying to isolate handling of it to a subsystem is not useful when it affects the semantics of your entire program.
Honestly if `cURL` or `wget` (whichever one is recursive) doc.rust-lang.org you should get a pretty good local copy. It's all static files. The only trouble I can foresee is the `[src]` links which do some JS magic.
When I saw you were working on this in Github I was pretty excited! Nice to see what on earth was actually happening here.
Author here. Thanks for noticing the typo, fixed. Regarding the list for the series, I try to tag all these posts so a list should be here: http://siciarz.net/tag/24%20days%20of%20rust/
Besides, Toyota's [2009-2011 vehicle recalls](http://en.wikipedia.org/wiki/2009%E2%80%9311_Toyota_vehicle_recalls) was likely caused by a software bug in the C software.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**2009–11 Toyota vehicle recalls**](https://en.wikipedia.org/wiki/2009%E2%80%9311%20Toyota%20vehicle%20recalls): [](#sfw) --- &gt;Three separate but related [recalls](https://en.wikipedia.org/wiki/Product_recall) of [automobiles](https://en.wikipedia.org/wiki/Automobile) by [Toyota Motor Corporation](https://en.wikipedia.org/wiki/Toyota) occurred at the end of 2009 and start of 2010. Toyota initiated the recalls, the first two with the assistance of the U.S. [National Highway Traffic Safety Administration](https://en.wikipedia.org/wiki/National_Highway_Traffic_Safety_Administration) (NHTSA), after reports that several vehicles experienced [unintended acceleration](https://en.wikipedia.org/wiki/Sudden_unintended_acceleration). The first recall, on November 2, 2009, was to correct a possible incursion of an incorrect or out-of-place front driver's side [floor mat](https://en.wikipedia.org/wiki/Car_mat) into the [foot pedal](https://en.wikipedia.org/wiki/Automobile_pedal) well, which can cause pedal entrapment. The second recall, on January 21, 2010, was begun after some crashes were shown not to have been caused by floor mat incursion. This latter defect was identified as a possible mechanical sticking of the [accelerator pedal](https://en.wikipedia.org/wiki/Accelerator_pedal) causing unintended acceleration, referred to as *Sticking Accelerator Pedal* by Toyota. The original action was initiated by Toyota in their *Defect Information Report*, dated October 5, 2009, amended January 27, 2010. Following the floor mat and accelerator pedal recalls, Toyota also issued a separate recall for hybrid [anti-lock brake](https://en.wikipedia.org/wiki/Anti-lock_brake) software in February 2010. &gt;==== &gt;[**Image from article**](https://i.imgur.com/9vodU7Q.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:Toyota_Camry_LE.jpg) --- ^Interesting: [^Automobile ^platform](https://en.wikipedia.org/wiki/Automobile_platform) ^| [^The ^Toyota ^Way](https://en.wikipedia.org/wiki/The_Toyota_Way) ^| [^Toyota](https://en.wikipedia.org/wiki/Toyota) ^| [^Toyota ^iQ](https://en.wikipedia.org/wiki/Toyota_iQ) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmnwxnf) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmnwxnf)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
So now only ints and floats implicitly copy? What about C-like enum members?
Not rust specific, but yesterday I was offline most of the day, and I had the chance to study R and pythons and be able to give my full attention to it, totally the opposite of when I am online. With I R I went to the help section they have some good guides there.
I was in the same boat as you last week. was able to poke at rust pretty effectively on my 4 hour flight. If you download the nightly packages, theres a docs/ folder in it. packages are [here](http://www.rust-lang.org/install.html). do a "npm install -g http-server" then run "http-server ." inside the docs folder, and you should be able to see all the online docs from localhost:8080 an alternative i've done is "wget -r http://docs.rust-lang.org" and then host the result locally. The above will get you the main documentation and the std API docs. The main problem you are going to have is libraries. Some essential functionality is not going to be in the std, like the "num" or "time" crates. I would look at crates.io and clone the git hub repos (and their docs like above), as well as any other libraries you find on there you might want to use. (hyper was pretty fun to get up and running) I will say cargo and the ecosystem its build around which demands "always online" is pretty frustrating. I'd like to see an offline path for people to take. Its especially frustrating to accidentally do a "cargo clean" when you don't have an internet connection. 
You are assuming a HashMap only relocates its elements on a rehash, which is not the case since it uses [Robin Hood hashing](http://en.wikipedia.org/wiki/Hash_table#Robin_Hood_hashing). You could probably keep a pointer to a boxed person, though. But why not just use the simple safe solution: struct Database { persons: HashMap&lt;int, Rc&lt;Person&gt;&gt;, index_by_name: HashMap&lt;String, Rc&lt;Person&gt;&gt;, } I don't *think* there is going to be much of a performance difference, since you don't actually need to copy the Rc pointer, and thus don't actually need to increment/decrement the reference counter. Edit: Well, lookup performance is probably the same. You get more allocation overhead, but once Rust gets custom allocators that might be easier to alleviate. Edit 2: But that would not avoid the problem of the name being copied, of course.
I'm pretty sure a string is just a vec, that is, a pointer off to actual storage, and a size (maybe some other statistics about the storage, idk). Changing the string will change that heap pointer. In any case, your person struct isn't going to be moving around, the string contents are. You'd have the same problem in any language - using mutable data as hash key. That means you have to rebuild your index_by_name. The easy way to go is to provide some special function to update name, that removes and reinserts into all your indexes. A messier solution would be to consider your fast_index as a cache, where you verify the name matches before returning. if it's a cache miss, you could delete than index. 
&gt; do a "npm install -g http-server" then run "http-server ." No need to install and run an HTTP server from npm, especially since not everyone has npm installed already. You can just do `python -m SimpleHTTPServer 8080` (or `python -m http.server 8080` if your system Python is Python 3) to serve the current directory, and almost all distros have Python and its standard libraries installed by default. &gt; I will say cargo and the ecosystem its build around which demands "always online" is pretty frustrating. I'd like to see an offline path for people to take. Its especially frustrating to accidentally do a "cargo clean" when you don't have an internet connection. Yeah, I'm not terribly happy with the whole "we must re-invent a build and packaging system yet again, and go through all of the pain points that that entails, such as having to re-invent ways of cloning local repositories for people who don't want their builds to have to grab packages from the internet" approach that Cargo takes. Actually, I'm really unhappy about the fact that this seems to have become a de-facto standard for new languages in general; if you use Ruby, you're expected to use rake, gems, and bundler, Python setuptools, pip and virtualenv, JavaScript/Node npm, Perl cpan, Haskell cabal, I've lost track of what you're supposed to use for Java these days (Maven, Ant, who knows), Leinengen for Clojure, sbt for scala, and then C and C++ generally use make, autotools, and your system package manager but may also use cmake, scons, waf, gyp, etc, and each of them has its own unique ways of solving these problems and integrating with the other systems. The combinatorial explosion of combinations of possible build and packaging systems, if you have long running projects that have had several developers who have chosen different tools for different components, is just getting ridiculous.
That is a good point, worthy to consider in some scenarios. Rc&lt;Person&gt; would have the following drawbacks: * The Person will be entirely readonly in this scenario, you will need a Rc&lt;RefCell&lt;Person&gt;&gt;, with the extra overhead of that, if you want to update individual fields. * As you point out yourself, the name will be stored twice (both in the key and value of index_by_name). &gt; You are assuming a HashMap only relocates its elements on a rehash, which is not the case since it uses Robin Hood hashing. Could you generalise this, for any collection (Vec, DList, TreeMap, HashMap etc) and say: * Any function call that mutates the collection is free to move the elements that it owns around in memory, and thus all raw pointers to elements in that collection could become invalid. * If the element is a box, the raw pointer (if it points inside the box) would always be the same as long as the element is still in the collection. Is this correct?
This sounds good, but I can't get it to work - if I change my index to this: fast_index_by_name: HashMap&lt;*const str, *mut Person&gt;, Then the program does no longer compile: error: type `std::collections::hash::map::HashMap&lt;*const str, *mut Person&gt;` does not implement any method in scope named `get` 
the worst part is that I have a macro package for ergonomics that uses the capitolized package and no matter which version I put in its dependencies cargo says it doesn't exist in the registry
Shouldn't apply() be called forEach()?
In Rust it'd be `for_each`
I'm maintaining this, it's mostly for fun, to give those methods &amp; macros a home. Things have improved in libstd too, we now have the .cloned() iterator adaptor, and soon we will have a .map() adaptor using unboxed closures. The iterator comprehensions are fun, but the regular Rust style isn't bad either: `icompr!`: let rows = icompr!(line.words().collect::&lt;Vec&lt;_&gt;&gt;() for line in lines); let bytes = icompr!(row[2] for row in rows if row[0] != "POST"); let total = icompr!(from_str::&lt;uint&gt;(b).unwrap() for b in bytes).sum(); Regular rust: let total = lines.map(|line| line.words().collect::&lt;Vec&lt;_&gt;&gt;()) .filter(|row| row[0] != "POST") .map(|row| row[2]) .map(|b| from_str::&lt;uint&gt;(b).unwrap()) .sum(); of course, you'd want to write that without collect, which is easy since we inspect element 0 before element 2.
&gt;The Person will be entirely readonly in this scenario, you will need a Rc&lt;RefCell&lt;Person&gt;&gt;, with the extra overhead of that, if you want to update individual fields. Oh, right. I was only considering immutable data. Though you could still replace a Rc&lt;Person&gt; with another Rc&lt;Person&gt;, although that might not work in all cases. &gt;Any function call that mutates the collection is free to move the elements that it owns around in memory, and thus all raw pointers to elements in that collection could become invalid. Pretty much. Unless the specification says that it won't relocate elements, don't assume it won't. &gt;If the element is a box, the raw pointer (if it points inside the box) would always be the same as long as the element is still in the collection. Right. Although you could take the box out of the collection and any raw pointers to the boxed element would still be valid. Once you drop the box it deallocates the data it points to, though.
Use Rc&lt;String&gt; to avoid having to store the string twice, and if the hashmap double-lookup really hurts that much you should: 1. Switch to FNV hashing. SipHash is quite a bit slower iirc. 2. If that's STILL too slow, store the hash in a struct next to the String, and save it the first time it's computed. Hand it out every other time it's requested. 3. If that's STILL too slow, refcount the Person struct, too. You'll probably want something like Rc&lt;RefCell&lt;Person&gt;&gt;, though, and the types start getting a little complicated. This is probably an optimization of last resort. Also, profile first! I really doubt 2 hashtable lookups are going to kill you. It takes ~150ns -200ns per lookup with an out-of-the-box HashMap. If your SLA is on the order of milliseconds, a hashtable lookup is nothing. Unsafe code is unnecessary for tasks as simple as this.
I agree that the regular Rust is fine just as it is and hopefully it will improve even more. Although I like `icompr!` with the conditional expression as an alternative to `filter_map` without explicitly using `Option&lt;T&gt;`.
Without the collect: let total: int = log.lines() .map(|line| line.words()) .filter_map(|mut row| if row.next().unwrap() == "POST" { row.skip(1).next() } else { None }) .filter_map(from_str) .sum(); 
I think typically `filter_map` isn't used so much as a way to combine `map` and `filter` as it is a way to prevent this this pattern: iter.map(|foo| foo.opt_bar()) // returns an Option&lt;Bar&gt; .filter(Option::is_some) // hopefully this syntax will work soon .map(Option::unwrap); However, filter takes the value by immutable reference, and I don't think there's a `filter_mut`, so if you do need a mutable filter, then filter_map is currently the best bet.
My main use of filter_map is the fact that you get the iterator element by value, which apart from being useful, feels natural.
Whats the protocol for opening a bug?
Screenshots would be great!
I remember there being a `'self` lifetime at one point when I first discovered Rust, but I don't think it worked like what I'm asking. I think it was removed before the rfc system, too. EDIT: Yea, `'self` was just the default name for a lifetime before. https://www.reddit.com/r/rust/comments/291hrw/lifetime_of_reference_as_struct_field_self/cigvtbq
&gt; Is there a design or safety reason that there isn't a 'self lifetime, or is it simply the issue of no one has implemented it yet? The reason is that if a self lifetime exists it opens up a big question: if you want to make the lifetime something else? For instance `'static`. Do you disallow it? Ir you allow it, how would the syntax for customizing look like?
The real WTF here is that packages can differ in casing. "foo" and "Foo" are different packages? Cargo should probably normalize case here.
To be fair, a struct: Foo&lt;'a&gt; { .. } Implies that the struct cannot contain any references &lt;= 'a. However, 'a cannot be &lt; 'b, which is the lifetime of the instance of struct itself. You could argue for a 'self which implies that the lifetime of any member of the struct must be &lt;= 'self, which is always 'b, and implicitly expands: struct Foo { x: &amp;'self int } -&gt; struct Foo&lt;'a&gt; { x: &amp;'a int } and: foo: &amp;Foo -&gt; foo: &amp;'a Foo&lt;'a&gt; In both definition and usage. This would let you go: struct Bar { foo: Foo } However, 'self would necessarily be infecting in its own right. Any struct containing 'self could only contain references which were 'self, and any struct containing a struct which was 'self wouid *also* implicitly be 'self. So this code would fail: struct Bar&lt;'a&gt; { foo: Foo, guard: &amp;SemaphoreGuard&lt;'a&gt; } With some obscure error like 'Invalid lifetime 'a on struct Bar is not 'self' You'd end up with all kinds of obscure edge cases where implicit and explicit lifetimes interacted poorly. ...but I suppose in some simple cases it might be useful? Not really proposing it gets added; just saying I can see how it might work.
In theory I think it's doable. For example we can make this simple rule: when there is exactly one lifetime parameter in `&lt;&gt;`, you can save the declaration and use `'self` to refer to it in reference pointer. But that can lead to more confusion (like what you pointed out in your comment) and more rules to cover all corner cases. 
This is my out of tree attempt to fix https://github.com/rust-lang/rust/issues/15470 The syntax is ugly and subject to change (I'd prefer `#[doc(file = "foo.markdown")]` for sure), but it works and should also work for cross-crating docs since the documentation is expanded into a `#[doc="..."]` attribute before rustdoc even sees it. Thoughts, questions, and feedback please!
While the Ariane 5 crash was the result of a software error (an overflow, to be specific), the language Ada was not to blame. The underlying problem was that code for Ariane 4 was taken into the new codebase without evaluating if it would work within the flight parameters of the new rocket. Somewhat unsurprisingly, it didn't.
I don't like 'self but could this be solved by lifetime inference? struct Foo { x: 
Dammit, my reddit client has screwed up my comment. Will edit later
&gt; Also, even in languages with exceptions like Java and C#, OOM pretty much aborts the program. I have an image scaling application which periodically OOMs trying to allocate memory for some very large photo. I never had a single OOM-related issue with it, Java catches and handles it just fine. &gt; In any case, you can't do proper exception handling and still recover on OOM because you can't allocate, hence you don't have room to store the stack trace. Stack trace shouldn't me mandatory in that case. Exception stack traces are a separate feature, it isn't present in C++ and you can still profit from the exceptions there. Even in Java stack trace generation is optional, JVM can choose to optimize it away for frequent exceptions. &gt; If you are actually writing a system that needs to handle OOM, you have to think about stuff like that. It's really, really hard. It's only hard when you're trying to solve a problem you can't solve, like trying to handle OOMs yourself in the language, instead of dumping them at the programmer. A good solution, for example, would be for the language to have a task-local handler installed which is called on OOM. It could then decide whether to dump core and abort or to unwind the entire task or to throw a recoverable exception which turns into the nearest Result failure ( http://www.reddit.com/r/rust/comments/2of8ox/apologies_in_advance_arent_exceptions_mostly/cmn1i7t ). When the OOM is expected, most of the time it happens with allocating a large array, like when trying to manipulate an image with GraphicsMagick/ImageMagick. It is perfectly safe to throw a recoverable exception in that case. In fact, the default OOM handler could use the same semantics. Someone's allocating 10 MiB and failing? No problem, that's to be expected, and it doesn't prevent us from using mutexes and stuff, so turn it into a recoverable exception. Someone's can't allocate 128 bytes? Now we might have a problem. It's also safe if the task has been tailored by the programmer to be OOM-friendly, like when programming an important daemon and preallocating all the scary stuff. Then failure to allocate even a small buffer or structure is just a nuisance which can be reported and handled as a normal Result error. Yay! My Android app doesn't just die anymore when the OS has a memory fluke. See? It's not that hard suddenly when the language doesn't try to pretend that the problem isn't even there. Right now the infinite memory is just a leaky abstraction. It can never be infinite, and there is no mechanism in place to let the programmer handle the shortage.
You might also like [grabbag::iter](https://github.com/DanielKeep/rust-grabbag/blob/master/src/iter.rs) and the associated [grabbag_macros](https://github.com/DanielKeep/rust-grabbag/blob/master/grabbag_macros/src/lib.rs) (no baked docs up anywhere; probably easiest to just look for `#[test]` for examples).
shades of grey &amp; hybrid approaches games do try to use a lot of data-parallel code the "constantly influencing each other" is mitigated by separating the independent and interacting parts into multiple passes; for example, games have a lot of interaction with immutable data (scenes, animation skeletons,navigation maps) ; and even the mutable state can be divided up into a pass that checks the previous state (immutable), accumulating a set of changes to apply. e.g. a physics system would build a list of interactions, (the scene being immutable), then process the interactions after splitting into 'islands' (then process each 'island') r.e. 'going over data twice' - it's sometimes beneficial i.e if you can separate out passes where it's is processed in a simpler way. ..eg. 2 passes over everything with no sync primitives might be better than a single pass approach with everything using mutexes
Lifetimes are type parameters. All other type parameters in Rust are explicit. Lifetime elision is already confusing enough. And the virality is *necessary* to be able to actually reason about the structure. Otherwise you'd be sitting there stumped as to why it didn't implement Send.
Sure. This is an example and I was wondering more about how to combine safe and unsafe code, pointers/memory layout etc, rather than the details of HashMap and hashing. The "profile first" argument is valid, but if you're writing a library, you don't know what parts of your code will end up being in a hot path in the final programs using the library (which is written by someone else). So better optimise everything :-)
Another good alternative is to store your actual data in a vector and only store indexes into the vector in the HashMap. This avoids lifetime issues and the lookup is very quick. Another thing you can do is use a TypedArena to allocate each Person and then just store references directly to the Person from the HashMap. This is safe (because the TypedArena is stable) and lets you follow raw pointers around. If the Person is immutable, it can even let you avoid copying the String (since you can just reference it with &amp;str).
###Screenshots ####[Select File][1] ####[Save File][2] Conrod doesn't have a scrollbar yet so I had to settle for pagination. The implementation of `Ord` for `Path` is case-sensitive, so that's why capitalized folders are sorted before lowercase ones. I might use a case-insensitive sort instead. [1]: http://imgur.com/YYlAMbn [2]: http://imgur.com/SZekC2Y
Screenshots added as top-level comment.
Your problem stems from a common misunderstanding about persons and names: Namely (pun unintended) that one person has (exactly) one name. This is probably not correct even within a single moment. As an example, let's say I've married and taken on the name of my wife (which I did, incidentially): Would you drop my birthname from your index (as it is no longer valid)? Or keep it around for the time being just in case. Also, I've met people who have very common names and are likely to lead to name clashes in your example. So you'd need to use a HashMap from &amp;str to Vec&lt;&amp;str&gt; in any event.
There generally is a trade-off between lifetime/type inference/elision and explicit annotations in that while elision may improve ergonomics and readability, it is also bound to make it much harder for the compiler to produce good error messages when your program does not type check. I think we're seeing this already with the limited lifetime elision in function signatures. I'm not necessarily arguing that the kind of elision you're after would indeed be particularly problematic but that tends to be the case. 
Good stuff, makes me happy to see Conrod getting used :) Also I just want to apologise quickly for Conrod's bare-bones'ness! There are a couple things I'm particularly looking forward to fixing: - Overlapping of widgets - Add a Scrollable trait - Pick a nice, OS font that doesn't alias in a super hardcore manner! - Flesh out `Theme`s - Flesh out the `TextBox`functionality Once I'm finished in DSP land I'll be back to this business. Thanks for your contributions btw! Just realised you're cybergeek94 :)
I wish there was a way to use one `GlyphCache` instance for all `UiContext` instances, so the user didn't have to load a new one from a file to pass to the `FileDialog` instance. I should also consider forward-compatibility with `Theme`. For scrolling, I could probably hack something together with `slider` and `widget_matrix` but it would take a lot of work to feel as smooth as a native file browser. Something like Android's `ListView` + `ArrayAdapter` API would be nice. I lamented the lack of support for relative positioning so that I could implement the dialog to be agnostic of the window resolution. If I wanted to do it that way right now I'd have to do a lot of manual math in the `draw_dialog_ui()` function. It'd also be nice if I could specify the size of `TextBox` in characters and lines though I understand that'd be difficult to implement reliably.
Agreed with all of the above, maybe add an issue for each (with a small example of how you'd like to use it) and we can start chipping away at all this! As for the TextBox size via characters, this would be dependent upon the characters for non-monospaced fonts, otherwise it would be quite easy to set size as the width of some given string.
&gt; false sense of security Am I missing something and it is really possible to fool the compiler and write safe code that crashes or did I just misunderstand your words?
Do you have a better tool? There is no git of dependency / build systems because frankly, there is no technical solution that fits all use cases. I think the worst problem is that there is no way to uniformly refer to "native" C/C++ libraries. The closest is package names of distros, but they vary (and some distros may split upstream software into many packages). And depending on a package of another high-level language is problematic not only in a technical sense but also social/cultural (I mean, who want to use a Python library in Ruby?) I think Rust may change this a bit since it makes sense to use a Rust library in Python. So perhaps we will see a way for a Python library to depend on a Cargo package? Ideally we would have all actors (Debian, Arch Linux, Gentoo, but also Rubygems, NPM, Cabal, Cargo) implement a simple API for cross-tool dependency resolution. The systemd of package managers if you will.
Not tested it, but something like this should work: for (_, line) in br.lines().enumerate().filter(|(l, _)| l % 100000 == 0) { println!("{}", line); }
Did you compile with optimizations? `rustc -O`? is it possible to profile and see where the bottleneck is?
Optimization was the key. Since I use Cargo to build I needed to add --release for full performance. $ cargo build --release
This looks nice, should try it. But as said in a previous comment, it's only slow without optimization optimization. So I guess it would likely the same performance wise.
I tried some different opt-levels and it seems that opt-level=2 is needed to yield some performance.
Fair enough - so for this example let's assume a Person's name is not the real/given name, given the implications of name clashes, name changing, and so on. Let's assume it's something like a username instead.
Isn't this virality something that could be addressed by tooling? With proper refactoring it's the kind of information you could propagate. It is annoying though, in the same way that propagating generic types was annoying. In the same way that propagating generic types was annoying... @wrongerontheinternet says: &gt; Lifetimes are type parameters. All other type parameters in Rust are explicit Would there be a way to have associated lifetimes in the same way there are associated types??
I think the virality of lifetimes could be addressed, but I think the solution is way more complex than just adding a special lifetime `'self`. I think a real solution would allow for users to make references generic over type of reference.
I have written a java class that does something like this – basically a hashmap where the key is stored within the value and is extracted on lookup. So basically a mixture of Set and Map. If I had the time I'd port it to Rust just to learn the language a bit.
`ci)` is nice! Thanks :)
Using your username to achieve uniqueness is problematic, when the maintainance of the crate is passed from one user to another. Sure GitHub has organizations for that, but many projects are started by an individual and then turn into something bigger, so the problem is still there. I think it's better to pick a non-generic, unique name upfront.
I have a hunch that that's what it does, and that's what's causing the problem, it's just a very, very poor error message.
Is there a link which is not behind a paywall?
Strangely I can only get the first page of the paper from my Uni Access anyway. :/
Updated, you were right.
&gt; Do you have a better tool? There is no git of dependency / build systems because frankly, there is no technical solution that fits all use cases. In the absence of a next generation build system that is all things to all people, like Git has pretty much wound up being for SCM, make is pretty much the universal standard. It's like C; it's not ideal, but it gets the job done, and is the universal glue that everything else can talk. If you design your tools so that you can build using Make, it's likely that people who prefer some other build system can use it too. To do this, what you need is some program that can be used to calculate dependencies from your source (like `makedepend` or `gcc -M`), so that people don't have to tediously list dependencies by hand that can be generated automatically, and some program that can tell you what build flags certain packages need to use (in the C world, that's `pkg-config`, though some packages have their own like `llvm-config`). If you have these two things, then people can use the build system that they want or that integrates into their existing infrastructure, rather than having to use a new one that may not play with their other tools and policies. Now, that's just for build systems. For package managers, there's really nothing so universal; there is no existing package manager that is available on almost every system already. Part of the reason for these language-specific package managers is to provide a repository that is easier to get packages into than the distro package managers to bootstrap the language ecosystem. I don't have a good answer here, but I'd be inclined to say that rather than also writing a package manager from scratch, it would be better to just reuse one that already runs cross platform, and can build a lot of existing packages as well. One good example of this would be `pkgsrc`, which is the NetBSD package system but which runs pretty much everywhere. Now, of course, one problem with these two answers is that they're very Unix-centric; they leave Windows as a second class citizen, and Rust, in theory, is supposed to target Windows as one of its primary platforms (though the experience on Windows does still tend to lag behind that on Unix like platforms). I don't really have a good suggestion there. &gt; And depending on a package of another high-level language is problematic not only in a technical sense but also social/cultural (I mean, who want to use a Python library in Ruby?) Happens all the time; not necessarily at the library level, but at the helper program level. For example, Ruby based web apps calling out to Pygments to highlight source code (GitHub was an example of this until recently, when they switched their highlighting backend away from Pygments).
Please remember rule 2. While it's true that bazaar isn't popular today, that wasn't as clear long ago, and so it's what Launchpad uses. If I remember correctly, all of Canonical's stuff did/does. I thought they had migrated, but I guess I remember wrong...
Some discussion about Rust here.
[Safe code can crash](http://play.rust-lang.org/?code=fn%20oops%28%29%20-%3E%20%26%27static%20uint%20{%0A%20%20%20%20unsafe%20{%20std%3A%3Amem%3A%3Atransmute%280u%29%20}%0A}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20%2F%2F%20No%20unsafety%20here!%0A%20%20%20%20println!%28%22And%20the%20magic%20number%20is%3A%20{}%22%2C%20oops%28%29%29%3B%0A}). It just needs unsafe code to set things up, which is the situation you get into when you start casting pointers into references.
&gt; Also, how is AtomicPtr typically used, They're not. Atomic types are _primitives_, which is why they're unsafe: they can be used in a way which causes memory unsafety. Generally speaking, your code should be using an `Arc&lt;T&gt;` to share data between threads, not use `AtomicPtr` manually.
see `:he text-objects` to get a list of all of them 
You're hacking out a transpiler in an experimental language; you are no longer a beginner! RE that anecdote, I was told something similar when my parents got a commodore 64, our first computer. Basically it was "The way you program games is, you buy a magazine, type in the entire program, and if you make a single typo it won't work and you have wasted your time. You are probably better off practicing piano." Unfortunately I listened to them and had to start programming at the level of Matlab when I got to uni.
Nothingness can be represented as Nil, or Null, while still avoiding NullPointerException: http://crystal-lang.org/2013/07/13/null-pointer-exception.html The following code is OK: match x { Some(val) -&gt; println!("{}", val), None -&gt; println!("Sad") } But it can be written in a shorter way that has the same effect (in Crystal): if x puts x else puts "Sad" end
&gt; You're hacking out a transpiler in an experimental language; you are no longer a beginner! And if you name-drop Microsoft, you probably don't consider yourself one anyway.
&gt; The nil part of the language, at least, seems interesting and promising. It looks like checking the value of a pointer in C: if the pointer is `0` (let's assume that `0` is `NULL`), then the conditional fails, since `0` is `false` (or rather; it is not `1`, the `true` value).
Yes. In fact it's more close to the way Ruby does this. There are "truthy" values and "falsey" values. The only "falsey" values are "nil" and "false". Everything else is "truthy". The compiler uses this knowledge to allow things like the above code.
What's the context? Is this a new home for cargo?
But the lang spec says the only falsey values are `nil` and `false`? And.. that's better than the five (or six - I don't even remember any more) falsey values of JS.
I don't know how it works in Crystal. I guess the value would be `nil` in this case.
Ah, actually, if "everything else is truthy," then I'm not sure how promising this is any more - it's similar to the JS way (I don't know Ruby) then. While I like the truthy/falsey approach with if statements in JS, and use it all the time, I'm of the opinion that truthy values should be limited, just as falseys are restricted to few.
Rust By Example has been the most useful tool for me learning Rust. I'm one of those people that learn so much more quickly/easily with the "by example" style. Thanks to all involved!
&gt; Mr. Thought-Police. I do not care what you think. I do care what you say.
To be clear, that will not be the official way to install things once 1.0 hits. We all agre e that overall, it is much better.
It's important that we have many ways of learning Rust, agreed completely.
I see null pointer exceptions as a problem with type system. Basically every single type has an extra value in them, namely `null`... which is not actually of that type. That is, if for instance `foo` is defined for your type, then it isn't necessarily for defined for `null`, but the time system will allow you to say `foo(null)`. With what he calls loose typing(aren't we actually talking about dynamic typing here?), you have not only the annoying case of `null`, but actually most of the values which the type system will allow you to call `foo` with, will fuck shit up. So I think it is a bit weird how he first defends dynamic typing, then goes on to say how much he dislikes `null`. `null` seems like a consequence of dynamic typing to me.
Thanks to all contributors!
&gt; Thoughts, questions, and feedback please! I am always torn between the in-file and out-of-file way of doing things.
/u/playrust
Definitely. I have a very short attention span and at the time, the guide didn't exist, so I likely wouldn't have gotten far without Rust By Example. But even now that the guide exists, I still use it as a quick reference. Reading the guide and seeing efforts such as this makes me hopeful. It's saddening how many projects fail to see that successful adoption (as well as adoption rate) relies on good documentation.
Is it just a mirror of https://github.com/rust-lang/cargo? AFAIK Ubuntu doesn't require packages to be on Launchpad, so this is more than a way to have `apt-get install cargo-rust`, right?
I think the package name should be the other way round. There's `python-pip`, `ruby-bundler` etc.
Looks great...love that you can edit and re-run the code as well...Is there a library that people can include in their blog posts and things that gives that functionality? It looks like the same code from rust-lang.org or at least similar
See also [this comment] about a temporary feature-gate I added to make transition easier. [this comment]: http://discuss.rust-lang.org/t/psa-copy-is-becoming-opt-in/982/4?u=nikomatsakis
Interested. Simple 2D game.
Theoretically you could still implement an `Option` type in a dynamic language (you could create this convention yourself in JavaScript with an object like `{has_value: true, value: ...}` or `{has_value: false}`, but like anything in dynamic languages, there's no way to explicitly declare that type in method signatures. Forcing users to check for the value explicitly might still be impossible though, since it requires algebraic data types.
It uses `play.rust-lang.org` to run the examples, which is a bit behind master, so that's a bit weird. https://github.com/rust-lang/rust-by-example/tree/master/node_modules/gitbook-plugin-rust-playpen/book is the code that handles this integration, but really, its just generating a link to play, then some javascript to update the page.
The [Overloaded comparison trait](https://github.com/rust-lang/rust/pull/19167) PR looks very good. I imagine that I was not the only one annoyed at the extra `.as_slice()` required to compare a `String` with a `&amp;'static str`!
&gt; I admit I'm not entirely certain about the distinction between loose vs dynamic typing. Well, "loose typing" isn't even that well defined. Basically, almost no non-JavaScript langauges have loose typing. Many, many languages have dynamic typing. There are two axis. The first: * loose typing: "automatically coerce things of different types" * strong typing: "no automatic coercion" The other axis: * dynamic typing: "check that two things have the same type at run time * static typing: "Check that two things have the same type at compile time" Ruby and Python are strongly and dynamically typed. Rust is strongly and statically typed. JavaScript is loosely and dynamically typed. I'm not aware of a language which is dynamically and statically typed.
Thanks for mentioning 24 days of Rust! :)
Asymmetric solution to reduce the number of copies: let mut fst = range(0u64, 10).collect::&lt;Vec&lt;_&gt;&gt;(); let snd = fst.slice_from(5).to_vec(); fst.truncate(5); println!("{}", fst); println!("{}", snd); // fst and snd now contain the two halves http://is.gd/qNRg2V
You can use gh-pages like itertools does
 some_vec.iter().take(n) where `n` is the number of things you want to take. Unsure about the last elements in a very simple way. If you know it's always just ten, you can let (a, b) = some_vec.split_at(5); and `a` and `b` will be what you want.
I landed [another PR](https://github.com/rust-lang/rust/pull/19378) afterwards, removing several (nearly 1K) `as_slice`/`to_string` calls (mainly from tests) that are now unnecessary. :-D 
To expand on that: Generally, you shouldn't need *any* unsafe code whatsoever. As I see it, the reasons to use `unsafe` are: 1. Making a safe abstraction, i.e. something in the `std` libraries like `Arc&lt;T&gt;`. Outside the `std` libraries, this should be rarely needed unless you need to build some exotic collection or something. 2. Interfacing with C or C++ code directly. Note that the preferred way of interacting with C / C++ code is by building a wrapper, which would internally use `unsafe` but externally not, so anyone *using* the wrapper doesn't need to use `unsafe`. 3. Micro-optimizing performance. I don't know if this is an actual use-case, as most things Rust (/u/steveklabnik1 or anyone else, feel free to correct me!) I imagine 99% of Rust users will *never* need to use `unsafe`. They'll use abstractions (like `Arc&lt;T&gt;`) that have been made safe by those before them, they'll use C++ wrappers with safe APIs, and they will not be so incredibly obsessed with the last 1% of performance that they'll want to mess with `unsafe`. Basically: If you're using unsafe, you should either really, really know what you're doing, or there's probably a better way to do it.
&gt; Generally, you shouldn't need any unsafe code whatsoever. In applications, yes. In libraries, maybe. As you say, 'making a safe abstraction' means that unsafe code should end up being pushed down into the implementation of your library, as small as possible. And often, it's not even needed. There are some classes of problem (like intrusive data structures) where you do, but generally, unsafe is an optimization, rather than absolutely neccesary. this is sorta re-stating what you said. :) Cargo, for example, has no unsafe code.
I think namespacing crates on crates.io under usernames (like on GitHub) would make naming fair for everyone.
I'd use the slicing syntax like so #![feature(slicing_syntax)] fn main() { let the_vec = vec!(1i,2,3,4,5,6,7,8,9,10); let n = 5; let a = the_vec[0..n].to_vec(); let b = the_vec[the_vec.len()-n .. the_vec.len()].to_vec(); println!("{} {}", a, b); } edit: Simplified it even more.
You're a hero!
The whole point of it is to make things safe!
Interesting. I'd be down for a game of life.
&gt; I'm not aware of a language which is dynamically and statically typed. I assume you mean loosely and statically typed? Loose typing, of course, comes in degrees. PHP is extremely loosely typed, as it will implicitly convert virtually anything to a string, and implicitly convert a string to virtually anything. C, on the other hand, is somewhat loosely typed. It will implicitly convert a number of numeric types, but only in cases where you're unlikely to loose numeric precision. However, it also implicit converts any pointer types, so you can assign a *int to a *widget, with no compile or runtime errors (aside from the runtime errors generated indirectly from the fact that you're now treating an int as a widget). C++, C# and Java are a little bit loosely typed. They still support implicit coercion of numeric types by similar rules to C. In C++, it will also use any single-argument constructor as an implicit coercion (unless it includes the "explicit" keyword added in C++11). So C is arguably a loosely and statically typed language, and C++, C# and Java are slightly-loose statically typed languages.
I suppose the main problem with having a 'self lifetime is that it doesn't solve that many usecases, since lifetimes act in reverse. Adding a lifetime argument to a struct tells it must live as long as it's references, while adding a 'self lifetime would tell references they have to live as long as the struct. It would need some language item that tells the containing struct it has to live as long as a property, while still having an infered lifetime :( It's a shame, since I really, really would love some way to have non-viral lifetime annotations to avoid things like [this](https://github.com/Kintaro/wtftw-core/commit/dbbeab6e7d6272bb1021cd5dde0d82f49b51cb30)
Boost.Units is actually pretty simple and does just this in C++.
It appears that what Crystal gives you is basically a built-in linter that checks, at compile time, that you do the necessary null checks before using a value. I used to work on a large C codebase that had such a linter (which blocked the build, so you had to satisfy it). It required you to be a little more explicit, marking function arguments and return values as NOTNULL, where appropriate. This was a huge benefit, making large classes of bugs much harder to write. What we have in Rust is actually largely equivalent. It just reverses the semantics, so pointers default to non-nullable, and have to be explicitly marked as nullable, via Option&lt;T&gt;. As I think things really should be non-nullable unless you have a specific need for null, I prefer Rust's approach.
&gt; let (a, b) = some_vec.split_at(5); I'm getting this error: error: type `collections::vec::Vec&lt;u64&gt;` does not implement any method in scope named `split_at` Is this on a specific trait or something?
I don't think dynamic vs. static typing is an axis, because dynamic typing is strictly less expressive than static typing. Static typing includes dynamic typing. (See [this](https://existentialtype.wordpress.com/?s=dynamic+typing) for a longer discussion.)
Appreciate both the answers! I was a little confused with steve's answer at first in that he states atomic types are primitives, so inherently unsafe; that seemed a bit sweeping. I was already using atomicbool and that has been rather successful for me; really I was just getting out of my box and trying things out with atomicptr-- which is much more complex I realize now. I also was trying to reduce my use of a mutex and thought this would be a good start, lock-less is always smarter but I might put that on the back burner until I learn and understand more. Thanks again for the clarification on things. edit: I also rewrote the example using straight up unsafecell to see how things could operate and noticed expected output, so I still don't know why atomicptr was so different other than the reference to the pointer going out of scope, perhaps
Are you not including the prelude or something? It's included in http://doc.rust-lang.org/nightly/std/slice/trait.SlicePrelude.html#tymethod.split_at , which is, of course, imported in the prelude, as the name says.
Forth is the ultimate loosely and statically typed language.
Note that in Crystal if you have a variable of type `Foo`, it is of type `Foo`, never `Nil`. Now, if you assign `nil` to that variable, the type becomes `Foo | Nil`, which is similar to Rust's `Option&lt;Foo&gt;`. So things are really non-nilable by default unless you use nil. Both approaches are good. We should make NullPointerException something of the past, no matter what language we use. I just wanted to point that `Option&lt;Foo&gt;` is not the only way to deal with this issue.
Thanks for the input. Your point about `Nil` in Crystal is one of the things I found interesting. I agree, NPEs should be gone, and Option&lt;T&gt; of course isn't (and shouldn't be) the only way :) Appreciate it.
You would also need to always do it, while in a statically typed language there would be much better syntax and you would only have to handle that case when it's explicitly declared.
&gt; I am always torn between the in-file and out-of-file way of doing things. I think for documenting types, functions, methods, and the like, it would usually be best to write that documentation inline as we do today, with a doc comment. Those docs are typically short, and also nice to have directly at hand when reading the code. `#[doc(file = "...")]`, to me, seems much more useful for including long exposition into a crate's documentation. For example, the rustc crates have [a few](http://doc.rust-lang.org/rustc/middle/borrowck/doc/index.html) [examples](http://doc.rust-lang.org/rustc/middle/infer/doc/index.html) where a detailed explanation is useful. Moving long, essay-like docs out into a separate file mean those docs are easier to edit (because an editor will be put into "Markdown mode") and also don't get in the way when reading code.
Very true. Using a programming language that enforced this would be awful, and is definitely not as useful as ```Options``` in statically typed languages. The comment was more addressed to the 'is it possible' side of the question. And technically, wouldn't every single value in a language that allows null values be Optional?
It was amusing to come across the following article on HN, while this discussion was taking place: https://codewords.hackerschool.com/issues/one/option-and-null-in-dynamic-languages
Ohhh, thank the lords. It was slightly embarrassing to show typical Rust code to new people before that change.
Except there's often no nice syntax for handling nulls like static languages with Optionals tend to have.
I'm interested. Static site generator seems like a cool one to me. It also seems like it has the most potential for feeding back into the rust ecosystem. Static asset serving libraries and conversion libraries could come out of it.
tl;dr: This finally marks the end of the "runtime" in Rust, in the sense that there is no more setup or teardown in order to safely call into Rust code. (It still has a sort of runtime services, but they are all initialized whenever required.) Kudos to @aturon!
So with this change, it'll be painless to have a C main file that links to Rust auxiliary functions?
Yes, racer is slowly growing a type inference engine. E.g. let (tx, rx) = channel(); rx.&lt;tab&gt; offers you the fields and impl'd trait methods for the Receiver type. The type inference is by no means complete (you can easily confuse it with a nested lambda or macro) but is getting better over time. 
Wow! This has made my day - thanks /u/zsiciarz! 
What is the functional distinction between a variable being nilable, and being able to assign nil to it to make it nilable? This sounds like it's really just an implementation detail, allowing the linter to detect potential nil-ness of default-nilable values. The fact that you can, by default, assign nil to a variable means that the variable (if not the type) is default-nilable. I suspect the C linter I described works in a similar way internally. (And I'm so used to having this discussion about nulls that the word "nilable" feels really unnatural to me. :-) ) [Edit: Expanding on my point a little.]
I selfishly hope Rust hits 1.0 soon so I can use it in my OS class next semester.
I think you could just do "some_vec.iter().skip(n)" to get the last half of the Vec.
Can I finally use an RWLock from within a pthread? yay!
You can do the same thing in typed Racket. Some functions return something of type (U some-type nil), and if you use it in an if expression like that then inside the if clause it's treated as just some-type.
I'm hopefully going back to school next fall to start my CS degree. Since I'm already pretty good at programming and have a solid grasp on the abstract concepts, I'm hoping to have the opportunity to experiment and tinker in my classes. But I don't know if any professor would want to deal with someone skirting the lesson plan. 
Yeah, if you know how long it is. Which I guess you could calculate from the `.len()`, but I wonder if that introduces a second traversal? I guess not.
"release candidate around the end of the year" http://blog.rust-lang.org/2014/09/15/Rust-1.0.html
&gt; I don't know if any professor would want to deal with someone skirting the lesson plan. I went to school a while ago now, but even if a professor said that they were okay with it, they really weren't okay with it. :/
Thanks for Racer! I use it with sublimetext, works really well.
Yeah, that's why I'm hoping to fast-forward through as many classes as I can. I've been told that's possible.
Discuss forum would be probably better. http://discuss.rust-lang.org/
One thing I'll say about my degree: while a lot of it sucked, a lot of it ended up being very useful for a foundational understanding. I wish I had paid more attention in several of my classes. But not all of them. Web stuff was particularly bad.
String literals can span multiple lines. A trailing \ removes all white space from the beginning of the next line.
Could you copypaste this answer into the reference.html? :D
You can use "Ok(read) if read == BUF_SIZE" in the pattern match at L106, but then you need to either add another match or change the Err pattern to _. 
&gt; Line 57: Can number conversion be easier than what I came up with? Source string is taken from matches.opt_str("r"). If you use [Docopt](https://github.com/docopt/docopt.rs) then it will do basic type conversion for you. e.g., extern crate serialize; extern crate docopt; use docopt::Docopt; static USAGE: &amp;'static str = " Usage: xorfile [options] [-n NAME ...] Options: -h, --help Show this help message. -r SECTOR, --resume SECTOR Resume from sector SECTOR. -n NAME, --name NAME Filename to read. Can occur multiple times. Example: xorfile -n file1.bin -n file2.bin -n file3.bin -r 512 This will check if PD of selected files is the same. Start from sector 512. "; #[deriving(Decodable)] struct Args { flag_name: Vec&lt;String&gt;, flag_resume: Option&lt;u64&gt;, } fn main() { let args: Args = Docopt::new(USAGE) .and_then(|dopt| dopt.decode()) .unwrap_or_else(|e| e.exit()); println!("Names: {}, Resume: {}", args.flag_name, args.flag_resume); } And running it just works: ./xorfile -n file1.bin -n file2.bin -n file3.bin -r 512 Names: [file1.bin, file2.bin, file3.bin], Resume: Some(512)
 let resume_sector = match matches.opt_present("r") { true =&gt; { /* */ }, false =&gt; 0, }; This can be rewritten a little shorter as: let resume_sector = if matches.opt_present("r") { /* */ } else { 0 }; And this: for i in range(0, BUF_SIZE) { xorbuf[i] = 0; } Might be more "rusty" to write as: for i in xorbuf.iter_mut() { *i = 0 }; Or even faster as: use std::slice::bytes::MutableByteVector; xorbuf.as_mut_slice().set_memory(0);
There's an open ticket for it, I just haven't gotten around to it yet. In genera, I'm waiting to update the reference until right around 1.0.
Definitely not t-shirt weather around here. You should try again next summer.
Any comments on what exactly it means?
&gt; XPSP2 &gt; brson: How long will you support it? &gt; eshan: Once we stop having users. We still had millions of XPSP2 users. &gt; gps: Around 10%. &gt; glandium: There are more XPSP2 than Linux users. Slightly offtop - is it just Linux users being outnumbered by Windows users or do Linux users prefer other browsers?
I'm actually giving that one a try, though I've not got much yet. For a real Lisp, we need a garbage collector. Right now, I've got some memory-safety issues with destructors, so it's (the gc) not too usable yet... Other than that (even with it?), a Lisp is a decently easy goal, so... go for it! ^^
Perhaps this is a good place to mention that someone with a lot of Cargo experience is [needed on the racer issue tracker](https://github.com/phildawes/racer/issues/73).
This is interesting, having others to push you to work is a good idea. I'm game for any topic from the list, although Lisp Interpreter or Any Game is cool. Edit: How about an IRC channel or some other form of group chatting platform to discuss things, eg cool techniques, problems etc.
&gt; #[newtype_deriving(Add, Sub, Mul, Div)] &gt; struct Centimeters(f64); &gt; &gt; fn do_something(cm: Centimeters) -&gt; Centimeters { &gt; cm + cm * cm / cm - cm &gt; } Actually, I'd say this hides an argument against itself: What is the meaning of multiplying and dividing centimetres by centimetres? Surely, the type of `Centimeters * Centimeters` should be `SquareCentimeters` or something to that extent — what the authors perhaps intends is to implement `cm * scalar`, where `scalar` is a plain `f64`. I'm not saying it couldn't be useful, just that it may actually defeat the purpose of newtypes and lead programmers to not think through their design decisions properly.
http://gs.statcounter.com/#desktop-os-ww-monthly-201409-201411 gives 11.8% for Windows XP market share. I think 10% is a neutral reflection of this share, showing no particular preferences.
&gt; It's going to take a real push to get the 30 issue for 1.0 finished in the next three weeks AIUI, the idea is to get the train release model running by the end of the year, but that doesn't mean we'll get 1.0-stable by then. In fact, I expect we'll have *at least* two 1.0-betas (i.e. 12 weeks of beta) with more breaking changes before getting a stable 1.0. (See the [release channels RFC](https://github.com/brson/rfcs/blob/release-channels2/text/0000-release-channels.md#exceptions-for-the-100-beta-period)) &gt; 23 backcompat-lang and 15 backcompat-libs tickets, most but not all of which are counted as part of the 1.0 milestone. AIUI, issues marked as backcompat, but not part of the 1.0 milestone are well ... not 1.0 blockers. That means that if they don't get done in time by 1.0, they'll get deferred until the next major version.
Oh god, this is beautiful.
The simple answer to that is to just not derive those traits. I think the reduction in boiler-plate is worth the risk of people getting complacent. In other words, I don't think the risk is enough to warrant the boilerplate when there's an alternative.
I think you are right. The example could be improved to avoid multiplication and division.
This part of your comment is weird "GPL license for a compiler is unacceptable for a lot people"(paraphrased), technically this is true but: 1) GCC is also licensed under the GPL like GNAT, yet it is still very successful. 2) FreeBSD has a much smaller market share than Linux? So I don't think that they matter for Ada's lack of adoption. 
Can you provide the error messages from the compiler?
&gt; All the other alternatives are commercial. Why does this matter? You only need one (good) free software compiler to support a very big number of programs, I don't know if GPL GNAT is good or not, but the fact that the competitors are closed source doesn't really matter..
And here goes detailed description: &gt; jack: We had a meeting (see notes) about how to get a component of Gecko written in Rust into the build infrastructure. We didn't talk yet about what component to land initially. We've talked before about image decoders, the URL parser, or other things. I talked a bit to seth, the image decoder owner for Gecko, and he had some suggestions. In particular, the BMP parser could be a good candidate. He also suggested some possible new projects (things that don't exist in Gecko today but are wanted). One was code to return some early information from the head of a network request, like the width and height of an image file, before the entire request is received. The other project is to do something with JPEG thumbnail data in JPEG files. This hurts things like the photo app in Firefox OS since it has to decode and scale down the full-size image instead of using the precomputed thumbnail. &gt; zwarich: Can't you also subsample JPEG while decoding it? &gt; jack: That may be something to investigate too. He did mention a potential security issue with JPEGs where people could maliciously make the thumbnail differ from the image, so maybe we just do that for images that Firefox OS creates. Anyway, Seth kind of volunteered to help define requirements for those projects. [Source](https://github.com/servo/servo/wiki/Meeting-2014-12-08#rust-in-gecko)
How is this different from a type alias?
For me it doesn't matter. I am old enough that I had to buy all the software back in the day. For may youngsters that grew up with GNU/Linux this matters a lot.
&gt; In particular, the BMP parser could be a good candidate. Sweet! We finally get the first class bitmap decoder we deserve. ;D Seriously though I can understand not wanting to start with something as high traffic and mission critical as the JPEG decoder (while still putting it through its paces in a production environment).
I agree that avoiding boilerplate is a good idea, but I guess I just feel that the argument is a little less convincing when the amount of boilerplate for a realistic example is actually just two traits — two traits that could actually serve to clarify the purpose of the newtype. There are probably examples out there that are much more suited to illustrate the usefulness of this.
A newtype is different from a type alias in that a newtype is a separate type altogether, and you need to explicitly convert between newtypes and their underlying types, whereas a type alias is a different name for the same type.
[**@larsberg_**](https://twitter.com/larsberg_): &gt;[2014-12-03 00:20:41 UTC](https://twitter.com/larsberg_/status/539937229049581568) &gt;The amazing Michael Wu from the [#b2g](https://twitter.com/search?q=%23b2g) team got [#servo](https://twitter.com/search?q=%23servo) running on a Flame using the FFOS platform! b2s incoming... [*pic.twitter.com*](http://pbs.twimg.com/media/B34-C_MCYAESU8t.jpg) [^[Imgur]](http://i.imgur.com/LK12fH1.jpg) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2orhhh%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
Indeed, the *real* objective of this first project will be to integrate Rust into the Firefox build process, and all the architectural and political legwork that entails. Once that's done, it opens the door for more substantial components to be written in Rust.
While in this case it is a relatively small effort, I still don't think the slight risk of someone being over-zealous in their deriving is worth it. I also think that (in more complicated cases) it's better for readability. It's easier seeing "it behaves like the underlying type" than having to go check the `impl` and making sure it's doing what you expect.
For now it is, yes. We'll move to guard pages for detecting stack overflow eventually.
I've didn't though yet about the details, but I think Naive Mark &amp; Sweep GC would be pretty easy to implement, I've never did any yet thgouh so this is going to be fun learning experience :)
(Sorry, this is TWiS 14, my bad)
I think `split_at` operates on slices? Try `some_vec.as_slice().split_at(5)`.
This is the first time I've used them in a game, and wrote up what I learned from it!
Ahh, okay. I understand what you meant. I was imagining an enum with only a single variant.
Several folks on IRC helped me with this question, and Benjamin Herr provided sample code which detected panics at the C-&gt;Rust boundary and aborted the process. I've packaged this as a library, but I'd love to find some way to emulate `std::task::try` without the threading overhead. I'm wrapping a lot of C libraries these days, and I'd love to know if there's a better way to do this.
I remember the web classes I took. Being taught good ol' HTML 3. Even though at the time HTML 4 + CSS were the current.
From what I've understood, the code compiles fine, but the function without the unsafe block produces an EndOfFile error unexpectedly.
I think "running on Firefox OS" is a bit of a stretch here. We're just using the same base device platform (Gonk) on a device that also runs Firefox OS. The bits that make Firefox OS interesting do not run in Servo yet.
Or build with `-C no-stack-check`.
The problem is that `Vec::with_capacity` doesn't actually create a vector of a given length (that's clearly stated in the documentation http://doc.rust-lang.org/collections/vec/struct.Vec.html#method.with_capacity ). Try `Vec::from_elem(len, 0)` instead.
I would note that `panic` *should* mean: "The in-memory state is broken beyond repair, there is no hope of recovering". The only reason that Rust allows `panic` not to abort the whole process, but only a single thread, is that shared memory should be rare, and therefore chances are (but there is no guarantee) that only the thread's memory was corrupted. I've heard arguments toward actually calling `abort` in case of `panic` even if pure Rust both by people citing the "no guarantee" issue and by people claiming it would speed up programs.
Relatedly, check out the [meeting notes](https://github.com/servo/servo/wiki/Mozlandia-B2S) from when the Servo team recently met with the B2G (Boot2Gecko) team to discuss requirements for B2S (Boot2Servo)
Every time this topic is discussed, Servo gets mentioned for relying on per-thread crash. I would like to know if the situation is the same today that we are moving toward native OS facilities (native threads and synchronization primitives) 
&gt; In fact, I expect we'll have at least two 1.0-betas (i.e. 12 weeks of beta) with more breaking changes before getting a stable 1.0. (See the release channels RFC) steveklabnik1's "release candidate" terminology (which isn't used in either the blog post or RFC), is what was confusing me. I generally consider a release candidate to be something that is feature complete, and will only receive bug fixes and no new features before release. And that is also how "betas" are supposed to work under the RFC. But the RFC does contain the exemption for the 1.0 betas, allowing that they may not go straight to release but instead be replaced by a new beta for a new cycle that pulls in new features, making them not really real betas under the definition of the RFC nor "release candidates" under the common definition. What I can't tell from either of these sources is if the first 1.0.0 beta will be released while there are still outstanding 1.0 nominated backcompat issues outstanding. It seems to me like there are enough of those that "near the end of this year" is still a bit of a stretch goal if all of the 1.0 backcompat issues need to be fixed by then. If 1.0.0 beta is allowed to still have open, 1.0 nominated backcompat issues, then it's guaranteed that there will be future beta cycles, as you need more beta cycles for those backcompat changes. &gt; AIUI, issues marked as backcompat, but not part of the 1.0 milestone are well ... not 1.0 blockers. That means that if they don't get done in time by 1.0, they'll get deferred until the next major version. Yeah, I realize that's the intent, I was just pointing out the number of issues that are currently tagged as backcompat and so, if it was decided that they were important enough to be nominated for 1.0, could wind up being blockers.
correct
&gt; Web stuff was particularly bad. The main reason I want to get a CS degree is to get *out* of webdev, hopefully break into systems where I can use all of this Rust experience :) 
I had a friend doing a minor in CS and I had to hold my tongue a lot because his profs were teaching Java which is my strongest language, and it seemed like they were teaching him entirely ass-backwards. I think they had him implement `ArrayList` *without* generics. 
Dammit! Thanks. that made it work.
FWIW, we plan to make an announcement soon clarifying all of these points, including the timeline. Stay tuned!
Will do!
&gt; I think they had him implement ArrayList without generics. Pedagogy and real world practice are allowed to differ IMO. e.g., If the professor wants the students to focus on the differences between static and dynamic memory allocation and not bother with bounded polymorphism.
Is a web framework not a good example? You might have plenty of readonly state, not want to deal with multi-process (and anyways, switching threads for processes doesn't fix anything, once you are sharing memory), and are running buggier "user" code. It seems that the options should either be "panics, handled however the user wants" or "no unwinding at all". The halfway state is making no one happy.
Is that image supposed to be broken up or is that a bug?
So certainly I can see value in having a standard library. Just not value in putting every bit of needed functionality into it. For example, I think that a the standard library of any language should have a healthy selection of collections, mostly because they are extremely useful in pretty much every sort of application and library. On the other hand, an http client doesn't really doesn't belong in the standard library, most apps don't need it (even if many do). To me the test should be something like "Will this be used by 50% of all rust applications". If the answer is no, then it doesn't belong in the standard library.
It's a bug in Servo's graphics / layers support. Not the best test page to show an image, but it was the first one I got :-)
This would be awesome! But IMO it would be obsoleted by inheritance if/when that happens.
I've been looking into Rust but not really programming in it. I think this would work best with a single theme, changing periodically. From the themes presented, a static site generator seem more useful. Perhaps there could be a subreddit for this, in style of /r/GEB?
Where does this leave libgreen? I haven't seen any news regarding what the plans are for it wrt 1.0
This is brilliant!
It would be an incredible amount of work. I think our aim right now is to implement enough to run the homescreen and see how our swiping performs.
To be fair, you often have like 1 low-pay TA per 60 students. They're already ready to blow their brains out from the heaps of garbage they have to process in bulk without beautiful snowflakes kicking down the door with their experimental programming languages and brilliant design "tricks". Although sometimes you really need the real garbage to get you through the day, you know? Just something really truly awful to share with your peers. It can be really cathartic to just experience legitimate nonsense. Actually, yeah man, go right off the rails. I believe in you.
You should probably call `drop` on the guard explicitly at the end of the block. If the change to non-lexical lifetimes is made, you *might* end up with the guards silently being destroyed before the inner expression is evaluated.
/u/dobkeratops, yeah, games and "stuff" use many and mixed approaches to speed things up. I don't think I was aware of multiple passes strategy. I'll definitely have to look into it. By "islands" you mean something like Binary Space Partitioning, Quadtree, Octree? Right now the most interesting approach to task parallelism (not doable with GPGPU) is what Akka offers for Scala language (see my [previous answer](http://www.reddit.com/r/rust/comments/2nrm66/design_and_implementation_of_a_complex_parallel/cmnst90)). Scala looks great by the way. Too bad it is so slow compared to many compiled languages...
Yes, Servo relies on unwinding. It is also not just Servo, we have production users (Skylight) relying on it.
Nope, the types don't have to be related at all (what common superclass do i32 and f32 have?).
 macro_rules! echo { ($($e:expr),+) =&gt; ( { $(println!("{}", $e))+ } ); }
Thanks for both the enthusiasm and feedback, everyone. The votes are pretty close, so I'll need to specify some extra guidelines. Could you make sure to provide an unequivocal choice? Either a ranking of topics you care about or just state that everything is equally acceptable. Then we can go with a majority vote and a possible tie breaker. No other forms of multiple choice, please. As for a dedicated channel, I like the idea, but I'd prefer to do a first iteration here. Just to keep overhead minimal and acquire some traction.
Thanks for the macro. What I meant is like this: (probably not well-written) macro_rules! echo { ($($e:expr),+) =&gt; ( { $(print!("{} ", $e))+ println!("") } ); } I hope `prelude` can provide such thing but it seems unlikely to happen. 
Is there a better way to avoid the trailing space? Here’s what I wrote but it looks verbose: macro_rules! echo { ($e:expr) =&gt; ( { println!("{}", $e) } ); ($head:expr, $($tail:expr),+) =&gt; ( { print!("{}", $head) $(print!(" {}", $tail))+ println!("") } ); } 
&gt; By "islands" you mean something like Binary Space Partitioning, Quadtree, Octree? &gt; more specifically in a physics engine, after an initial pass you can divide the scene up precisely into regions that you know can't affect each other (by contact), and worker threads can deal with solving each independantly. Its one of many possible approaches. In games its' common to have some big chunks of processing that area easy to guarantee being independent e.g. physics of individual cars (the suspension of one does not affect the next unless there is a pile-up), clothing on characters, etc. Of course if *everything* in your scene simultaneously collides that defeats this - but in practical cases there usually is some division possible. I think you were talking more about AI simulation .. in these cases you still have some heavy non-interacting computations like Path Finding (each character can run its' path-find or line-of sight checks in parallel with the others) I agree scala looks nice, from what I've seen of it, but I've only really dabled superficially with anything other than C++; Rust is the only other language i've put any time into. I definitely like languages that emphasise being multi paradigm rather than OOP vs FP
I'm in aswell.
I'm on the conservative side of this one. I think the additional boiler-plate is worthwhile. It's like import * being bad practice in python.
It seems that rust allow to free resources by manually deleting/droping their handler using the `drop` function [0]. If you don't manually call this function, it will be done automatically at the end of the scope. Is that correct? [0]: http://rustbyexample.com/drop.html
I think you're correct. I shall correct a sentence in my writing. Thanks for reminding.
[potentially relevant, skylight.io blog post](http://blog.skylight.io/rust-means-never-having-to-close-a-socket/)
I just wanted to hop in and say that the work you and other Piston devs are doing is really important and vital. It annoys me that there aren't, often, a lot of discussions on the topics you and other Piston devs post (despite being quite prolific). Piston is great form what little of it I've used (mostly cobbling stuff together from the sprite example). I started, just about a year ago, working on a toy project that uses rust-sdl2 for a grid/sprite-based game. A lot of that stuff is now superfluous, with Piston, so it's been interesting to review previous work to find out what can be dumped/replaced. You hint, in the blog post, about the other possible approaches to modeling the same system (ECS or FSMs were put forward) and this is a topic that interests me as well. Having worked on several toy game projects in the past, I have a hard time scaling out the codebase and keeping things coherent as it grows. Coming from a primarily enterprise software background, a premium is usually placed on the idea of "everything having its right place". So I look for design patterns that can organically push me in that direction. The combination of working in Rust, whose type system and semantics provide the opportunity to build different APIs from what I'm used to professionally (C#), combined with the problem domain of games, ends of creating a sort of confusing situation for me. My goal is find a set of abstractions that can help drive my programming in the direction of a sustainable/scalable codebase. It's a great challenge. I think the ai_behaviors stuff is a really useful way to model *graphics and input* in the game system (specifically on the client), but I'm curious how it works for non-realtime systems or for modelling domain logic/decision-making in a distributed system where tight-coupling to presentation/input isn't desirable. Lot's of stuff to cover here. We all appreciate the contribution Piston is making to the discussion. It's quite challenging stuff.
It makes sense if you're trying to advertise a more obscure subreddit to a more popular one, which is why I encourage people to include it when cross-posting content from /r/rust_gamedev.
Hopefully Rust is/becomes popular enough so I don't have to write "x-post /r/rust" on /r/programming :)
Ah, confusing. Please check my understanding so far. * std::mem::drop disposes of a value by getting the ownership transferred. The value is destroyed at the end of the empty function body. That's interesting. * The Drop trait is analogous to the C++ destructors, especially in the sense that the drop() method of the trait gets called at the end of the block. Question: * So in the Rust by Example piece, do they mean the same std::mem::drop() ? // Variable can be manually dropped using the `drop` function
Ah, interesting justification!
I don't really know much about raii except I've see it recently being mentioned. rust mentions it a few times, last I saw was within mutex, among other things. To my knowledge, rust's ownership infers when the resource goes out of scope and is no longer needed, so things like file i/o, network sockets, thread communication channels, are closed for you-- though you can call drop manually. To what extent I don't know, I supposed in theory all things resource related. In addition you can impl drop for something and have a custom drop function-- most recently I did this for [rust-promise](https://github.com/viperscape/rust-promise/blob/master/src/promise.rs#L70) where the promise gets 'destroyed' [if needed](https://github.com/viperscape/rust-promise/blob/master/src/promise.rs#L113) Thanks for the blog posts 
Your understanding is correct! Also, any time anyone talks about "calling" anything named `drop`, they're referring to `std::mem::drop`. This is because Rust prevents you from invoking a destructor manually: foo.drop(); // error: explicit call to destructor This exchange has actually inspired me to write up an RFC to change the name of `std::mem::drop` before 1.0. Now I just need to think of what we should name it instead...
Thanks !kibwen!
 macro_rules! echo { ($head:expr $(, $tail:expr)*) =&gt; ({ print!("{}", $head); $(print!(", {}", $tail);)* println!(""); }); }
Yes, that one is really surprising. I can guess at the intent (stopping the process upon BROKEN_PIPE for example) but still...
I put up an [echo crate](https://crates.io/crates/echo) on crates.io. Two macros are provided: `echo!` and `echon!` (without newline, like Linux `echo -n`). It’s such a tiny crate...
Call me crazy, but it used to ship with just source and it built itself up automatically. When did this change? If it did as this post says, could a single distribution be created that is built entirely from scratch? While having the quicker versions for those who could use them. I like my cake, I want to eat it too, though. 
~~Any idea why `foo.drop()` needs to be illegal?~~ ~~The signature for `drop` is `fn drop(&amp;mut self)`. If it becomes `fn drop(mut self)`, then `foo.drop()` could be legal to call explicitly, also implicitly at end-of-scope.~~ ~~(I'm sure destructors are more involved/complicated than I currently appreciate, though.)~~ Ignore me. I only ever realise how bad my ideas are until I click "Post." Before that though, I am a genius.
What about the `Cursor`-type you talked about?
I’ve renamed it `show!` and uploaded it to crates.io: * https://crates.io/crates/show * https://github.com/SimonSapin/rust-std-candidates#the-show-debugging-macro
It is solved by cross-compiling... But cross-compilers are kind of a pain to set up. I think (hope?) there's a better solution.
FWIW, Haskell's cabal [self-bootstraps via POSIX `sh`](https://github.com/haskell/cabal/blob/master/cabal-install/bootstrap.sh). ...and depends on GHC, which needs cabal to bootstrap. Yay mutual recursion! ...but actually, that's no problem, as GHC needs GHC to bootstrap, too, so there's a GHC available to build the first cabal. The issue with shipping LLVM IR is that it's as hard to ship platform-independent IR as it's to ship platform-independent assembly... all the platform choices are generally already baked in at that point. I learned that the hard way when trying to port GHC. So even if you compile IR on the target, you still need good cross-compiling support. Being able to do that two-stage, with the IR being compiled on the target means you don't need a cross-llvm, though, which would be a bonus.
back-compat to add, and not ready yet. I have a prototype out-of-tree, though: https://github.com/Gankro/collect-rs/pull/11
Did you look at every instance of `as_slice` or `to_string`, or do you have a way to automate this a bit more?
Here's the relevant code from a scanner I wrote recently (for SQL, definitely incomplete). impl&lt;'a&gt; Iterator&lt;Token&gt; for Scanner&lt;'a&gt; { fn next(&amp;mut self) -&gt; Option&lt;Token&gt; { if let Some((_, o)) = (regex!(r"^\s*")).find(self.buf[self.pos..]) { self.pos += o; } if self.pos &gt;= self.buf.len() { return None; } match self.buf.char_at(self.pos) { '\'' =&gt; self.lex_strlit(), '"' =&gt; self.lex_ident(), '*' =&gt; { self.pos += 1; Some(Token::Op(Opr::Mult)) } '+' =&gt; { self.pos += 1; Some(Token::Op(Opr::Plus)) } '%' =&gt; { self.pos += 1; Some(Token::Op(Opr::Mod)) } '-' =&gt; { self.pos += 1; Some(Token::Op(Opr::Minus)) } '/' =&gt; { self.pos += 1; Some(Token::Op(Opr::Div)) } ';' =&gt; { self.pos += 1; Some(Token::Semi) } '&lt;' =&gt; self.lex_gt(), '&gt;' =&gt; self.lex_lt(), x if x.is_alphabetic() =&gt; self.lex_bareword(), x if x.is_numeric() =&gt; self.lex_numlit(), _ =&gt; None } } } I hold the input text and the current position separately, which makes "backing up" a simple subtraction. However I never end up needing that since everything is matched with regex, which drops the cursor at the character immediately after the last character of the match. It does create that ugly (in my opinion) `self.buf[self.pos..]` slice, but it makes advancing the text position super easy. Here's the full struct: struct Scanner&lt;'a&gt; { buf: String, pos: uint, sym: Vec&lt;String&gt;, idents: HashMap&lt;&amp;'a str, uint&gt;, kw: HashSet&lt;&amp;'a str&gt;, } And then the function that pulls out string literals, for example: fn lex_strlit(&amp;mut self) -&gt; Option&lt;Token&gt; { let (start, end) = match (regex!(r"^'([^']|\\')*'")).find(self.buf[self.pos..]) { Some((s, e)) =&gt; (s + self.pos, e + self.pos), None =&gt; return None }; self.pos = end; Some(Token::StrLit(self.buf[start + 1..end - 1]).to_string())) } The rest are mostly similar to that: define a regex for the token, match it, advance the text position, and return the token. I have no idea how fast it is, but it doesn't seem to be excruciatingly slow at least. Quickly running the whole program (which at the moment just reads tokens from stdin) on 4,500,000 tokens (mixed operators, string literals, keywords, identifiers) takes about 3 seconds. I'm fairly certain that would be fast enough to make the parser the bottleneck. :)
&gt; It doesn't seem like there should be that many platform-specific decisions that the compiler core would rely upon... The core not, but the standard library, and as such the compiler. If you compile a program with linux headers (that is, libc) and try to run that thing on a BSD you'll get into situations where the program will, say, confuse regular files for directories because all the `stat`-related constants are different. With C, it's never "just call some function". Sure, one can write platform abstraction code for that but at that point having proper cross-compilation support would probably be the better idea. Not to mention that there's platforms that can't sensibly compile stuff themselves, and one shouldn't limit rust to non-embedded platforms.
You are right that there are things that are easy to parallelize in many systems languages. AI stuff (heavy calculation) is certainly something like that. Simple threads/tasks (maybe a tuned a little bit) would suffice. The problem becomes complicated when these threads/tasks communicate with each other a lot and influence each other (state variables, behavior, etc.). Designing, reasoning about, debuggin such systems is particularly difficult. Hence the need for a programming language features (and/or cool libraries) that help with this. [Akka](http://doc.akka.io/docs/akka/2.3.7/scala.html) looks pretty awesome in this regard.
I'm having a problem grabbing the nightly build package via *ppa:torkvemada/rust*. I'm using LinuxMint 17.1, and there are two packages in this ppa that I should be able to see: cargo - 0.1.1+201407041602-1~ubuntu14.04.1 cargo-nightly - 201412092116-0.1-92~ubuntu14.04.1 However, apt-get can only find the first one, which is very out of date. I am a newbie to apt/dpkg/launchpad and I don't know how to diagnose what is going wrong. Can anyone help?
It would be useful if the fixed size arrays implemented some traits that made them generically useful as arrays.. for example `AsSlice&lt;T&gt;`
Fair. I guess my imagination was lacking :P
This sounds pretty good. And rust having strong static typing should make this easy to implement.
I've found out that instead of putting `pi` or `tau` in the code, it is easier to read if you name it `_360`, `_180` etc. Therefore in the vecmath library there is a trait `Radians` that lets you do `Radians::_360()`, `Radians::_90()` etc. After all, it is just a name for something. https://github.com/PistonDevelopers/vecmath/blob/master/src/consts.rs
Wouldn't convention be `echo` and `echoln`?
Depends what your background is. I'm a maths guy and I haven't used degrees in years. Not to mention that `pi` turns up in more contexts than trig.
Is there a use-case other than indirectly calling the destructor for std::mem::drop? If not, I don't really see a reason to change the name. Just add a 'Well, technically...' to the documentation for the function. If it does have another use, I'll throw in my bike-shedding skills and proffer the name 'consume'.
This is the opposite of brilliant. Every time I see this kind of collection, it sounds cool at first, but then someone tries to stick two different things into it that have the same type, but different uses. Today your web server has one domain name (or port, or whatever). Tomorrow, it'll have two domain names -- but you screwed up and chose AnyMap for your configuration store, so now you have a mess to clean up. The point is that now you have created the opportunity for *dynamic* failures, rather than catching failures at compile time. If you need to store connection info for a web server, you should probably use a struct or something sensible. That way, if you add a new field, or change "Domain" to "DomainList", your compiler will catch every place where you create or use this connection info, and you can quickly fix your code. But if you use this dynamic stuff, you have *no* compile-time assurance. You'll only know that problems have occurred when you happen to run the right test, or one of your users complains that some part of the web site doesn't work correctly. You might as well just use JavaScript, at that point.
Yes, another potential use case is to force an object to be deallocated at a certain point without going through the hassle of introducing an explicit scope. You can also use it to ensure that a particular value can never be accidentally referred to after a specific point in the program (though `let _ = foo;` also works for this use case). In any case, `std::mem::drop` is different enough from the `drop` method that it's only going to cause further confusion by conflating them. Especially with UFCS meaning that the `drop` method can also be called as a function. In addition, `std::mem::drop` can take any type, even ones that don't implement `Drop`, and even types that it makes no sense whatsoever to call `std::mem::drop` on (like implicitly copyable things (although this particular example would be solvable with negative bounds (I think I'll write up an RFC for this too))). I like `consume` for this. I think I'll use it!
As someone who constantly uses Tau in calculations, Pi is really just [ancient cruft](http://www.tauday.com/tau-manifesto). I imagine the people who want to keep Pi are the same people who vehemently deny Pluto's dwarf planet status. I say keep tradition out of my science.
To be fair, you might as well say "keep bikeshedding out of my science".
I think `take_while` is a pretty confusing name for this function to begin with... perhaps something like `take_until_not` would be better; while the latter sounds very similar, it at least doesn't suggest that what is happening amounts to while(cond) { take }. Something like `take_and_repeat_unless` would be even less ambiguous, but is probably too clunky.
Maybe I'm misinterpreting, but char_at seems to be okay. transit% cat test.rs fn main() { use std::io; let mut b = [0, ..4]; for line in io::stdin().lock().lines() { let c = line.unwrap().char_at(0); c.encode_utf8(&amp;mut b); println!("char at 0 ({}): {}", b, c); } } transit% ./test hello char at 0 ([104, 0, 0, 0]): h 😆 char at 0 ([240, 159, 152, 134]): 😆 😶👷 char at 0 ([240, 159, 152, 182]): 😶
I'm writing an implementation of a logical language. This is probably the least interesting part of the process, but I've written a lexer in just about in every language I know, so I can draw comparisons between them. I like how you use the regex to group expressions together. It feels like a classic string rewriting system. 
/u/SimonSapin has uploaded a `show` crate which I think is a better work. The macro name `show!` is good, too. I will “deprecate” my crate in favor of `show`.
Thanks /u/SimonSapin for the work! I’m going to use the `show` crate. Hope someday it'll get merged to lib std or prelude.
`char_at` returns the Unicode character at the given *byte* index. So if you change that example to use `.char_at(1)` instead, it panics because you’re trying to get a character from the middle of a multi-byte codepoint.
While I strongly agree that tau would have been a better choice than pi, that ship has sailed. Most people just aren't going to use it; continuing to make a deal of it seems quixotic at best.
For those of you on the Cargo team reading this: this is why many of us want non-global-level crates...
Dispose?
I know that! But there are trait implementations for certain traits for certain sizes. Why not some useful traits like AsSlice too?
I think that the ideal for using AnyType is to use a different type for each intended value to be stored, using newtypes if necessary. I guess there's no way to enforce that usage though.
Couldn't you write .take_while(|| self.iter.peek().is_uppercase()) instead? I'm still learning rust, so apologies in advance if that's a silly suggestion. 
It's meant as a Joke! At least, that's my gist of it.
Eh, depends on OS. In Linux, the libc is *not* part of the OS: The kernel syscall API is a stable userland interface. As a systems language, rust should actually not need libc under Linux, at all. It should run on bare Xen, too, and even on bare metal (that has been polished a bit with some inline asm). Other systems have C-level interfaces. But even there a cross-platform layer would incur impedance mismatches: Once you're cross-platform, you can't be low level any more. Currently the rust stdlib is using things like `libev`, but personally I see that as a compromise, as there's not sufficient manpower to properly NIH: The lowest-level OS interfaces should be available via rust code by default, no matter what OS, and "cross-platform rust" be build on top of that, in rust. That all doesn't mean that rust can't and musn't support a cross-platform layer. I'm just questioning how useful it is, especially a custom one. Heck in the end may be more sensible to have an asm.js target and bootstrap via SpiderMonkey. Compile to lua? Lua is probably even more portable than NetBSD. Anything that *already exists*, and doesn't move the lowest level of the rust system interface APIs higher, even if it's creeping. Treating a well-chosen interpreter as a platform would achieve that.
Hmmm might be interesting ...
Nice. I've deployed large production applications using wxWidgets, and my experiences were good. Here's my experience, which is probably out of date: - Windows: It produced solid, native-feeling apps. - Linux: It produced reasonable Gtk+ apps. - Mac: It produced working applications, but at the time, they didn't feel completely native without a fair bit of extra work. Things were improving rapidly when I last used it. - It was very easy to write custom native extensions for each platform. If I recall correctly, the Audacity audio editor uses wxWidgets.
I know `pi` appears in statistics and other areas of math, but for game programming degree/radians conversions are still frequently used, and it is the most common units that does not consists of irrational numbers. It improved the readability of triangulation algorithms quite a bit. There is nothing wrong with having both and pick the one that gives best readability.
Aside: How about a list of community-wanted libraries, in particular those that were in progress but stalled? This could give people visible targets to contribute and improve.
I thought awesome-rust was more about already usable libraries and not about those who need workers / maintainers / everything. I've just started a list of the projects that seemed to need contributors / maintainers here : https://github.com/gamazeps/Useful-Rust-Projects
I wish! That would be a perfect solution, but I couldn't make the compiler happy given some lifetime and type issues.
At school I was always wondering why the hell did they choose 3.14... for Pi and not 6.28... It is far more useful especially for trigonometry. I'm happy to discover I am not alone.
This coercion already works: fn main(){ let x = [1,2,3,4,5]; let z: &amp;[u32] = &amp;x; } So what use is `as_slice`? Generics? Edit: if you have a concrete list of traits you want added you can make another RFC to address this, or try to post the list on this one, I suppose.
why is core std crate api unstable? every nightly upgrade breaks my projects.
It needs htmlrunner at the moment (it's completely broke when viewed in even normal firefox), so not yet. &gt; Firefox.html requires a runtime: a special build of Gecko we call "htmlrunner". The runtime code is based on Firefox. See the htmlrunner branch branch on my gecko-dev repository. But we're hopeful we might be able to use it as a possible chrome for Servo. In the meantime, [MiniServo](http://github.com/pcwalton/miniservo) is pretty awesome if you have a Mac (there's a Linux version in progress too, but I don't know if it works yet)
https://github.com/pcwalton/miniservo-mac
https://github.com/paulrouget/firefox.html/issues/50
Your question is off topic but... http://doc.rust-lang.org/core/ "It is not recommended to use the core library. The stable functionality of libcore is reexported from the standard library."
Now we can have an epic flamewar on Tau vs Pi
Neat!
Because we're not at a stable release yet. http://blog.rust-lang.org/2014/09/15/Rust-1.0.html and http://blog.rust-lang.org/2014/10/30/Stability.html are good reads :)
badly needs documentation. Expecting people to read through code instead of reading through docs and examples is usually a good way not to get adopted :-) So, I will wait for the docs...but in general this feature is great, it brings in line with what Erlang/Elixir have on the OTP side. 
What kind of documentation? The API (including some examples) is [here](http://www.rust-ci.org/dradtke/superchan/doc/superchan/), and the [unit tests](https://github.com/dradtke/superchan/blob/24d261548b80e06cba87ba8459b3940f2bf0d067/src/tcp.rs#L129) should provide some idea of how it works. I am planning on writing up a README for the repo and include more comprehensive examples, but I did add enough documentation that it shouldn't be too difficult to get started, at least until I add more features. EDIT: fixed documentation url
I thought that Rust aimed at making cross-compiling easy.
I looked at the github repo and it's pretty bare: https://github.com/dradtke/superchan usually docs are in the README.md or at least have a pointer to the actual page, ie.e. http://htmlpreview.github.io/?https://raw.githubusercontent.com/dradtke/superchan/master/target/doc/superchan/index.html reading through them now
the examples look pretty simple. I feel what is missing is * service discovery (how do you discover other receivers on the network) * support for other serialization formats like Thrift (which I prefer over protocol buffers), e.g. https://github.com/sgnr/rust-thrift but this is definitely a great step in the right direction for Rust, congrats!
Keep in mind that this *is* just an initial prototype, and there's a good amount of work to do polishing it up and doing things like adding the README.
Adding support for other serialization formats is definitely on my TODO list. As far as service discovery, I don't know how that would really work, and the current design assumes that you have a specific IP address and port that you want to use. It's something that I could look into since it does sound very useful and interesting, but I'm not really sure how to go about implementing it. Thanks for the feedback. =)
I hate to ask this way, but your preferred solution sounds a lot like re-implementing `libc` in Rust, doesn't it? If not, where does the boundary naturally fall, between which libraries the compiler should re-use, and which should be re-implemented? To me, it'd be a big benefit if the task of porting rust were simplified to the task of porting rust's portability layer, which would itself be inherently much more portable because it would rely on portability standards (like POSIX) rather than details that are obscured in header files. For example, how rust implements `errno` on Unix platforms: if a rust_errno.c file existed, exporting a rust_errno function, then that file could just #include &lt;errno.h&gt;, int rust_errno() { return errno; }, and portability problem solved for that symbol, no `#[cfg(dragonflybsd)]` overall volume of code lowered, portability improved, and no reliance on undocumented OS implementation details to get there... I don't know, I don't fully understand the resistance to the idea...
Of interest in this episode: # syntax/lang items * replace `&amp;` with `^` for address-of operator and pointer types (experimental bikeshed fun) * array literals `x : [100] u32` * specifying that an array is indexed by a particular size-class of integer. e.g. `x : [100: u16] u32` * `remove` keyword for removing elements during iteration. Currently implemented as `swap_pop` for arrays (on the assumption that usually when you want to do this, you're using the array as simply an unordered container of "things"). * Values must be initialized, but types can have default values. Values can be explicitly uninitialized with `x : u32 = ---`. * `inline` and `no_inline` as mandatory compiler directives, and not hints, with the ability to mark a function declaration as such, or a callsite as such (which overloads the declaration). * Also an `#inline` directive to redclare the inline-ness of a function (useful for making "perf templates" based on platform). * enums have a `.strict` type and a `.loose` type for specifying a variable as being a type-safe member of the enum, or just the same type as the underlying repr (e.g. u16). * introspection of enums with `names` and `values` arrays # Avoiding build tools * Being able to add files and set flags during compilation as normal "runtime" function calls at compile time. * Being able to specify arbitrary code to execute to the compiler on the command line `jai foo.jai build_debug()`
I agree, discovery is a nice-to-have that can be built on top of this. There are lots of [gossip protocols](http://en.wikipedia.org/wiki/Gossip_protocol) out there, there are tradeoffs on reliability and performance. You can find some sample code just by googling "gossip protocol &lt;language&gt;". Here's an example in Java: http://gossiplib.gforge.inria.fr/
*Any* language but C re-implements libc. The question is what that library uses as its system interface. Rust does *not* need `printf`. If you want to ship on an embedded Linux, even uclibc might be overhead you don't want. POSIX also has less features than people generally think, heck, windows implements it... &gt; if a rust_errno.c file existed, exporting a rust_errno function, then that file could just #include &lt;errno.h&gt;, int rust_errno() { return errno; }, and portability problem solved for that symbol, no #[cfg(dragonflybsd)] overall volume of code lowered I see that as an orthogonal issue: C macros are an issue no matter what. They are *the* reason why POSIX is hard to target as any language other than C, because you can't just call them. Yes, wrapping those makes sense, but things get ridiculous, and slow, once you start having #include &lt;sys/stat.h&gt; int rust_S_IFREG() { return S_IFREG } Any C program would inline `#define`s into its source, and so does every bindings generator ever. Otherwise you'd have quite some runtime overhead, which is IMO untenable in the general case. Though, granted, writing such a layer for the *subset* of stuff `rustc` itself needs might make sense. Can't be much: `malloc`, `stat`, `readdir`, `open`, `read`, `write`, `exit`. Abstract those so that everything is a plain function, no `#define`s leak out, just what `rustc` actually needs, put it in a `.so`, and you should be done. Doesn't really work in the general case, though. And, yes, that, too, would be re-implementing libc, this time in predictable C on top of libc.
Cool stuff. What strikes me when browsing through the code is that it looks like every sent packet is [spawned in its own thread](https://github.com/dradtke/superchan/blob/master/src/tcp.rs#L28). Not only would this cause a lot of overhead, but it also enables messages to arrive in another order than they are sent, if you're unlucky. (Unless I'm misreading the code?) Also, the other limitation seems to be that while a TCP connection is usually dual direction, currently one can only send messages in one direction, from the TCP client to the TCP server, is that correct?
I'll echo others - the basic documentation that I think you should strive for would be a README that explains the intent. Tests are just that - tests of the things you believe describe the exact behavior of the functions under test. They don't describe whether you think it should make coffee. Documentation should suggest or explicitly describe what you think it does. E.g. you use ipv4. Should this work for ipv6 and it's just not tested? Or is that unknown? PRs accepted? Etc.
Spawning each send in its own thread was my admittedly somewhat hacky way to ensure that sends are non-blocking. Refactoring that is on the top of my list of optimizations to make, though. And yes, it is only one direction, mostly because that's consistent with how channels work. I'm considering implementing something like the old DuplexStream type that would allow both sending and receiving, but it hasn't been implemented yet.
This is an all-day hands-on workshop / hackathon. Should be a lot of fun! Here's the meetup.com description: The Rust compiler and standard library have over 2,000 open issues. There is important work for everyone, from seasoned compiler hackers to absolute beginners. Besides improving the compiler and library code, you can write tests, update documentation, tweak the website design, organize and follow up on bugs, or do anything else that will help make Rust great! This event will supply you with - a quick description of how to contribute to Rust, - ideas of what to work on, and - mentors who can provide answers and advice. If you're attending: You know a bit of Rust. Ideally you have a little experience contributing to open source software. You do not need to know anything about compiler internals. Bring a laptop or other device that can handle web and SSH. To save you time, we have prepared a virtual machine image that has Rust already checked out and compiled. For the duration of the event, every student can SSH into a private instance of this virtual machine. This is at no cost to you; the cost to us is less than the cost of lunch, so don't sweat it :) If you'd rather develop on your local machine, that is fine too. You should plan to arrive around 9:30. At 10:00 we'll start with some short talks, followed by dev environment setup. Lunch will arrive at noon and we'll spend the afternoon working on projects.
I wasn't aware that nanomsg existed, and while it looks useful and more fully functional than mine, the idea of superchan is to mimick Rust's channel types, which nanomsg doesn't do. Plus, superchan is born out of my desire to experiment with networking; I just happen to be naming and sharing the result of it.
I'm organizing this event so feel free to ask me any questions about it!
&gt; the idea of superchan is to mimick Rust's channel types, which nanomsg doesn't do That what bugs me. What's the API difference, besides naming it a channel rather than a socket?
&gt; Adding support for other serialization formats is definitely on my TODO list. If it is, then check http://kentonv.github.io/capnproto/, it has a first-class Rust driver.
That looks really neat! Instead of using Json for serialization, consider using [bincode](https://github.com/TyOverby/bincode). Bincode is a library that I wrote specifically for [fast encoding / decoding](http://erickt.github.io/blog/2014/11/13/benchmarks-2/), and it also has a very small network footprint. I also started writing a TCP-channels library called [wire](https://github.com/TyOverby/wire).
I think the main difference is that superchan's channels are designed to be generic, and to automatically handle serialization and deserialization. It's pretty trivial to define a struct or enum and to send those values through a channel directly without needing to convert them to and from byte strings; the only requirement is that the type derives Encodable and Decodable.
We'll at least post slides and we'll try to record video too. The talk component isn't huge, though. It'll just be 45 - 60 minutes (if that) on how the Rust codebase is organized, how to write tests, how to submit a PR, etc.
You’d go: enum Step&lt;T, O, R, F&gt; { Stop , Yield(O, R) , Await(F, T, R) } and then you’d be storing the unboxed closure. Of course that ties the closure type to the enum type no matter which variant is chosen. In a sense that’s precisely what unboxing is about, as a sort of opposite approach to information hiding; but that also makes our life a tiny bit harder. E.g. now the use of `Step::Yield` needs a type hint in your program. In fact right now there are discussions to box the error in `Result`, although that’s more about the size footprint than information hiding. Food for thought still! [Demo on playpen](http://is.gd/vRyoIU). (Incidentally does anyone know if there are stock versions of `Id` and `Compose`? I sort of made them up on the spot. Although with the blanket impl of `FnMut` blocking specializations, I suppose now is a bit too early to have them.)
I see, thanks. Rust channels need Send (http://doc.rust-lang.org/std/kinds/trait.Send.html) and I wondered whether you're using some magic to make it work. Encodable is a different matter, using it on top of nanomsg is kind of trivial. Your crate is a part of the library ecosystem now and it would be nice if you pointed out (in the README) that it's mostly an experiment as of yet. Otherwise one can't help but compare it with heavy-duty libs.
Submitted a pull request to fix the thread spawning thing.
Sounds like a case for a `Cow`.
&gt; unboxed closures are (or at least can be) sized. AFAIK, all "sugared" unboxed closures (`|:| {}`, `|&amp;:| {}`, etc) are `Sized`. They are just structs after all. &gt; Which means it should be possible to put them into that enum without the Box, its nasty *mut pointer, and the load indirections bear on poor llvm's mind. Sure, it can be done: enum Step&lt;T, O, R, F&gt; where F: Fn(T) -&gt; R { Stop, Yield(O, R), Await(F, T, R) } Where `F` can be an unboxed closure or a bare function. &gt; ...or am I barking up the unboxed abstract types tree, here? Well, sort of. The reason you can't write your `map` function with just unboxed closure sugar is that you are creating a new closure `|x| f(g(x))`, and the type of that closure needs to appear in the return type of the `map` function. The problem is that sugared unboxed closures have anonymous types so it can't be done without "unboxed abstract types". However, it's not impossible to do what you want, it's just very verbose. You can work around the lack of "unboxed abstract types" with "named" (or unsugared) unboxed closures. A "named" unboxed closure is just a struct that implements one of the `Fn` traits: #![feature(unboxed_closures)] use std::os; enum Step&lt;T, O, R, F&gt; where F: Fn(T) -&gt; R { Stop, Yield(O, R), Await(F, T, R) } // A named unboxed closure struct Nuc&lt;A, B, C, I, O&gt; where I: Fn(A) -&gt; B, O: Fn(B) -&gt; C, { // captures inner: I, outer: O, } // closure call function impl&lt;A, B, C, I, O&gt; Fn(A) -&gt; C for Nuc&lt;A, B, C, I, O&gt; where I: Fn(A) -&gt; B, O: Fn(B) -&gt; C, { extern "rust-call" fn call(&amp;self, (x,): (A,)) -&gt; C { (self.outer)((self.inner)(x)) } } impl&lt;T, O, A, B, G&gt; Step&lt;T, O, A, G&gt; where G: Fn(T) -&gt; A { fn map&lt;F&gt;(self, f: F) -&gt; Step&lt;T, O, B, Nuc&lt;T, A, B, G, F&gt;&gt; where F: Fn(A) -&gt; B + Copy { match self { Step::Stop =&gt; Step::Stop, Step::Yield(o, a) =&gt; Step::Yield(o, f(a)), Step::Await(g, t, a) =&gt; Step::Await(Nuc { outer: f, inner: g }, t, f(a)), // `Nuc { outer: f, inner: g }` is the unsugared form of `|x| f(g(x))` } } } fn main() { let args = os::args(); let before: Step&lt;(), String, String, fn(()) -&gt; String&gt; = Step::Yield("1".into_string(), args[0].clone()); let after = before.map( |x| { x + " bar" } ) ; match after { Step::Yield(o, r) =&gt; println!("{} {}", o, r), _ =&gt; () } } Prints: `1 ./uc bar` HTH!
Shameless plug... [libpnet](https://github.com/libpnet/libpnet) ([docs](http://octarineparrot.com/assets/libpnet/doc/pnet/)) provides a channel-like API for working with datalink/network/transport layer networking rather than application layer, it might be interesting for you to look at.
Yeah, on closer inspection that does seem to be exactly what I need. Here is what I ended up with for the example: use std::collections::HashSet; use std::borrow::Cow; #[deriving(PartialEq, Eq, Hash)] struct Wrapper&lt;'a&gt;(Cow&lt;'a, Vec&lt;uint&gt;, Vec&lt;uint&gt;&gt;); fn main() { let mut a = HashSet::new(); let b = vec!(0u,1,2); a.insert(Wrapper(Cow::Owned(b.clone()))); assert!(a.contains(&amp;Wrapper(Cow::Borrowed(&amp;b)))); } Thanks! Edit: Hmm.. I'm not quite sure whether this actually avoids the clone or just hides it behind the scenes.
For implementing non-blocking without (as many) threads, I would recommend having a look at mio: https://github.com/carllerche/mio There are quite a few commits now from several different committers and the library is pretty mature. I am currently working on a reactive-streams networking API and I'm using mio under the hood. So far so good. 
After dealing with Java Spring issues today... I completely agree with you. But I can imagine not knowing what types should be present specifically. Maybe something like an HList, where the types present are statically known? I don't see how to guarantee that there is exactly one value of a given type present without negative type bounds, though. But imagine a type HCons&lt;SomeStruct, HCons&lt;SomeOtherStruct, HNil&gt;&gt; , which implements Contains&lt;SomeStruct&gt; and Contains&lt;SomeOtherStruct&gt;. .insert() would have to consume by value instead of just a mutation, so it can change the type.
It's hard to retrofit type constraints onto a language, runtime, or library that wasn't designed with them from the beginning. C# / .NET still has two different collections APIs -- the nasty old dynamic one (``System.Collections``) and the halfway-decent generic one (``System.Collections.Generic``). But the shitty thing is, the generic collections API in C# is harmed by its need to coexist with the non-generic API. If you implement ``IEnumerable&lt;T&gt;``, you are *also* forced to implement the non-generic ``IEnumerable``, and it's ugly. Even worse, there are still lots of places in the generic collections that use vtable-based polymorphism, rather than generics. So the new collections are *still* forced to use the inefficiencies of dynamic type checking / dispatch.
I do quite like the idea of per call inlining. The other things are not very applicable. Maybe vectors could gain a fast remove though ;)
I've found this from [Hacker News](https://news.ycombinator.com/item?id=8734307). It uses [Rustbox](https://github.com/gchp/rustbox) for terminal interfacing. I guess this is more like a proof of concept with Rustbox, but still it's neat ;)
http://doc.rust-lang.org/std/vec/struct.Vec.html#method.swap_remove ;)
I really like this project and was wishfully thinking of doing something similar with rustbox myself. I hope to contribute to this eventually. Needs racer integration, and could probably do syntax highlighting by using the rustc parser directly.
On the other side of North America, but is there anything I can do to help?
For your information, there is another [natural ordering library](https://github.com/lifthrasiir/rust-natord) ;) I guess your library has some advantage with non-ASCII digits, though.
Yeah, nanomsg.rs doesn't really abstract over that kinda stuff and I'd probably want to leave that for another library (either built on-top or using something else).
I see no point in having the inner module `natural_sort`; just put everything in the crate root.
What problems were you having getting postgres-macros to build? Its build setup is pretty sketchy right now, unfortunately :(
Yeah, that I definitely agree with. It's all context dependant.
Unfortunately I won't be able to get a PR in until after the weekend. It's an annoying case that only comes up with certain types of code, but comes up really often in those types. 
&gt; replace &amp; with ^ for address-of operator and pointer types (experimental bikeshed fun) I'm sorry if you(?) discussed this in the video, was there a good reason given for this? I can't watch videos where I'm at and I'm slightly intrigued.
This *is* compile-time failure catching, especially when compared with string keys. The only variable left open is whether or not a type is present; beyond that, it’s all very strongly typed. I would prefer to be able to use absolutely rigid data types which define everything needed and no more, exhaustively, but this is simply not possible to do at a library level where you wish it to be extensible. Something based on AnyMap or similar can cope with that; in a web framework, for example, each piece of middleware can have its own data type that it and only it works with; this ends up in practical terms no different from storing an `Option&lt;MyMiddlewareConfig&gt;` which you expect to be filled. If you wish to store a thing on a per-site basis, you could do things like tie it in with phantom types (e.g. with https://crates.io/crates/phantom-enum to make it more elegant). I really don’t see any better approach. And I call straw man on “you might as well just use JavaScript”; that claim is preposterous, and you know it.
Not me :) I kinda glazed over it because I didn't really care. Basically he thought it looked nicer, and disagreed (at least partially) with the idea of declaration should = usage (for `*`). Mostly I think it was just some good ol' fiddlin' with conventions.
I really like the array declaration syntax, and transparently handling (address, length) pairs for the various kinds of array.
You’re right. The cloned reference escapes from the borrow checker, as this simple example shows (copied from issue #19261): let x = { "Hello world!".to_string().as_slice().clone() }; let _ = "---------".to_string(); println!("{}", x); It prints `---------ld!`. 
Thanks for the parser examples! You guys inspired me to take a shot at writing a metafont parser as a learning exercise. I'll post a link if it gets interesting.
[Hush hush...](https://github.com/FranklinChen/rust-tau/blob/df4c5e8d0ab0562264ee3c6a900754679a3b950c/src/lib.rs#L16)
But if it does not clone, then why do the elements inside the `Vec` need to implement `Clone`? For example, this is not possible: use std::collections::HashSet; use std::vec::CowVec; #[deriving(PartialEq, Eq, Hash)] struct NonClonable(u8); #[deriving(PartialEq, Eq, Hash)] struct Wrapper&lt;'a&gt;(CowVec&lt;'a, NonClonable&gt;); fn main() { let mut a = HashSet::new(); let b = vec![NonClonable(0u), NonClonable(1), NonClonable(2)]; assert!(!a.contains(&amp;Wrapper(b[].into_cow()))); }
Wow, it’s [live now](http://www.rust-lang.org/). Thank you guys!
Yesyesyesyesyesyesyespleasepleasepleasepleasepleasethankyou
Huh, it got moved :)
Also, someone should write a blog post explaining lines [572 - 597](https://github.com/gereeter/rust/blob/slimmer-btree-node/src/libcollections/btree/map.rs#L572) (The with method and the trick with an invariant lifetime). I feel I have something profound to learn.
The implicit address,length pair is just a slice in Rust. Jonathan's language doesn't have a notion of ownership, so that's part of how he can get away with less syntax for array types; he certainly doesn't have mut annotations. He also doesn't have a strict separation between the part of his language that can do memory management and the part that can't (core vs. std). That explains why the syntax for Vec and slices isn't more uniform in Rust, although who knows, maybe they will think of some nicer sugar to clean things up.
I also really like the idea of compile time function execution (CTFE). Rust will get that too eventually, just not before 1.0. 
 https://github.com/ucarion/natural-sort-rs/blob/master/src/natural_sort.rs#L78 Might be able to avoid a few allocations using slice_from and updating an index. Hell, with some lifetime brain surgery, you should be able to create HumanString with the same lifetime as the underlying source string, and be almost allocation-free. https://github.com/ucarion/natural-sort-rs/blob/master/src/natural_sort.rs#L83 `if let` would save the unwrap in the first branch no? 
Feel like doing another one in NYC? If there is interest, I am sure I can come up with a venue :) 
Very cool! If you're looking for a scripting language, there's [rust-lua](https://github.com/kballard/rust-lua), and I'm working on [wrapping duktape](https://github.com/emk/duktape-rs), a lightweight JavaScript interpreter.
That's my fault, I was missing the `libreadline-dev` package. I agree about the build process, it took me a moment to understand why I was getting linker errors from cargo. Now the crate compiles successfully so I'll try to update the article soon-ish.
This is a first a-bit-bigger thing I put into separate library and published. My plans are to use this (or something that this might evolve to) for plugging in different parts of my app.
*please* don't support more than one scripting language. In vim, it's a mess (and vimscript is a mess, too). A gazillion dependencies and nothing works seamlessly together with nothing. Lua is a good idea, not that many people love it but even less hate it, it's stable and sane (unlike javascript) and it's meant for embedding. Another project to look at would be [Yi](https://github.com/yi-editor/yi), which never really took off. One of its nicest features involves being binding-agnostic: It's really more of a library to implement editors in, and emacs emulation works as well as vi (well, actually, the vi mode is in need of love from someone who actually uses vi. No ex? WTF?). It also does fancy things when it comes to parsing: It's incremental to stay fast, and, most importantly, not limited to regexen and what's on-screen so you don't get the usual nastiness with comment blocks that are highlighted wrong because their start isn't on screen and such. Technically, very nice, practically I don't use it because it'd take too much investment to get to where I am with vim.
:+1: here
&gt; please don't support more than one scripting language. For whatever it might be worth, I also prefer editors with a single, well-integrated scripting language. But I thought it was worth listing all the Rust-friendly alternatives that I knew about.
Congrats to the Rust team! 
But we control crates.io, let's just update all their code for them! :P
 ( ) (@@) ( ) (@) () @@ (@@@) ( ) (@@@@) ( ) ==== ________ ___________ _D _| |_______/ \__I_I_____===__|_________| |(_)--- | H\________/ | | =|___ ___| / | | H | | | | ||_| |_|| | | | H |__--------------------| [___] | | ________|___H__/__|_____/[][]~\_______| | |/ | |-----------I_____I [][] [] D |=======| __/ =| o |=-~~\ /~~\ /~~\ /~~\ ____Y___________| |/-=|___|=O=====O=====O=====O |_____/~\___/ \_/ \__/ \__/ \__/ \__/ \_/ 
Kudos to gereeter's perserverance, I just read the whole story and this really reads like an epic novel.
There's no stopping this Rust-engine! No stopping it at all! Choo, mo'fos! Choo, choo!
I'm down for IRC, let's get separate channel for that #rust-lg (learning group?) irc://irc.mozilla.org:6697/#rust-lg HN thread (https://news.ycombinator.com/item?id=8740751) I see that there are many similar similar peeps that will be glad to join there and collaborate on learning experience. 
...as long as rustc stays lean and mean, that works, yes. You'll regularly hear complaints about Xmonad from non-Haskellers because, well, it comes with hundreds of megabytes of GHC as a requirement. Once compiled it's an (unstripped) seven megabytes, quite the difference. There's a different issue still: Security. Lots of people download all kinds of stuff for their editor, you want that to be sandboxed, and I don't think it's easy to sandbox parts of rust. No need to allow file access in a syntax highlighting module.
This is incredibly exciting! Congrats Rust team! I'm now really looking forward to Jan 9 =D
There may be some feature of Cargo which allows you to specify a minimum version.
Yep, that helps clarify the plan. Thanks!
This solution might not be that great after all. Due to the lifetime in `Cow`, any object that we pass to `contains` must live at least as long as the collection itself, which is not really useful. For example, the following is not possible because the lifetime of `a` is longer than the lifetime of `d`: use std::collections::HashSet; use std::vec::CowVec; #[deriving(PartialEq, Eq, Hash)] struct ClonePrint(uint); impl Clone for ClonePrint { fn clone(&amp;self) -&gt; ClonePrint { println!("Cloning!"); ClonePrint(self.0) } } #[deriving(PartialEq, Eq, Hash)] struct Wrapper&lt;'a&gt;(CowVec&lt;'a, ClonePrint&gt;); fn main() { let mut a = HashSet::new(); let b = vec![ClonePrint(0u), ClonePrint(1u), ClonePrint(2u)]; println!("Insert"); a.insert(Wrapper(b.clone().into_cow())); { let d = b.clone(); println!("Testing"); assert!(a.contains(&amp;Wrapper(d[].into_cow()))); } }
The more material you can post the better. It'd be great to be able to use them to host similar meetups in other cities.
Would it make sense to make String and &amp;amp;str generic over their encoding with a default of UTF-8, instead of introducing a whole new parallel String infrastructure? Surely the same problem will present itself again in other domains? I don't know if this is feasible though.
Is there reliable sandboxing for Rust? Not that I know of, and if not, then your users can get burned by running add-ons that install malware because they can run arbitrary code. If you want a really flexible add-on system, then that's a problem you have to deal with, but sometimes you just want basic scripting that doesn't allow for arbitrary file IO etc.
[Link to discussion on GitHub](https://github.com/rust-lang/rfcs/pull/517)
https://www.reddit.com/r/Pareidolia/search?q=train&amp;restrict_sr=on&amp;sort=relevance&amp;t=all
Patches are always interesting :) You should open up a cargo issue, and we can discuss it there.
It might, but it's too late in the game to change such a fundamental aspect of Rust's strings. In the long run, though, you could imagine using [generics](https://github.com/aturon/rfcs/blob/io-os-reform/text/0000-io-os-reform.md#the-future) to do something like that.
Wait, did you use `sl` for that, while we have a reimplementation in Rust? (haven't implemented steam yet, that gives you away...) https://github.com/skade/sl-rust
Done: https://github.com/rust-lang/cargo/issues/1044 Thank you!
You can't do regular UI stuff, it ends up being just like C/C++, in that you need to use opengl and draw your own stuff.
Done. :)
It's possible to run rust on android just fine the last time I tried, months ago, but android itself has an ugly build process for native code; there's some makefile voodoo required (you do indeed build a rust library and get its' makefile to include that)
Isn't there an NDK? For the record, I know nothing about Android.
pcwalton and brson are well-versed in C++, so I wouldn't worry. And we've got smart people in the systems language camp pushing hard on Rust from the outside, like eddyb and strcat.
IMO, GUI code is sadly heavily tied to languages... UI APIs are usually built around a specific languages' OOP system. apple objC/(swift..); android-java. Qt - C++ (can't make nice rust bindings last time I looked). So Rust really needs a dedicated gui system built around its own concepts (enums &amp; trait objects), some piston projects might be doing this (conrod?) I think people are trying various macro approaches to improve bindings though? I do think Rust enums would rock for GUI messages. Imagine building a completely new GUI library , around Rust's language details, around modern touchscreen UI paradigms, in portable GL code, that seems like a decent project. but if you want to use legacy libraries on existing platforms .. you've got to mess around with shims, and you'll be left wondering why you bothered - its' not the problem Rust is designed to solve.
None taken :) I did more systems stuff in college, in many ways, I see Rust as returning to stuff I used to do, even though I've been out of the loop for a while. I first learned C in ~1997.
For what it's worth, my use of Rust is precisely *because* it provides low-level control over memory like C and C++. I talked about it on the Skylight blog: http://blog.skylight.io/bending-the-curve-writing-safe-fast-native-gems-with-rust/ So I am extremely interested in making sure that the relevant learnings from C and C++ are incorporated into Rust: if I wanted a high-level, memory-managed language, I would use Ruby, JavaScript or Java. A lot of myopia can be addressed through humility: assume that if someone coming from a different context feels strongly about something, they do so for a reason. A diversification of people participating in the most important design decisions is critical as well.
Yeah, I am, too, a little worried about the growing web-dev focus of the project and the community. I hope the dev team won't forget the systems roots of the language during future development.
I suggest you don't take a look at btree/node.rs ;)
Wasn't it a fact that the ABI is the same as C?
The whole UI story currently is a mess. There's not many well maintained bindings for GUI libraries and for the few that exist you have to put up with "unrusty" idioms to make it work. For the time being - until there's a usable GUI lib - I think the best way to use Rust in your mobile/desktop project would be to implement the business logic in Rust as a library and then use that library from Obj-C/Java. But that requires you to write/generate C bindings for your Rust library. And with Android you'd need to bridge over to Java land. Currently Rust is great for command line projects or background daemons, etc. But anything that needs a GUI is a lot of work.
you have to use 'extern C' functions so when interacting with the platform you lose Rusts' expressiveness. thats the thing, as soon as you're outside of Rust-land it can't help with problems generated externally. (how do all the events work.. how do you access android resource bundles.. what texture formats does it's version of GL support)
Nope.
&gt; You keep all of Rust's benefits and apart from the moment that the thing ... the real work is the details of each platform. rust doesn't help,because the real problems are outside of it. here's the problems you need to solve:- - GL details (texture formats, shader versions) - details of the filesystem.. some abstraction over the differences between iOS bundles and android NDK bundles - yes , you make an abstraction layer but that is trivial, the actual work is doing the iOS and android specific implementations. - details of the android "activity cycle". how the application transitions between sleep/active state, screen changes. - details of input. you'll be stuck working with raw C messages or need to accumulate it into some sort of cross platform interface *that you need to implement* if you want to 'solve these problems in rust' you need to port sample code *to rust* first (and remember that is itself a fudge around what is really a java system). or you're left jumping yet another language in the middle. - Are you doing something commercial? stick with C++. mature tools count for more and costs shared economically over a huge user base - are you doing something for pleasure? ... I grew up coding assembly and there's way more enjoyable programming projects than all this mess. Writing actual 3d engine code, or writing a language, *anything*. It doesn't sound that much above but multiply that by android *and iOS* (and desktop ... personally I found it much more pleasant to develop on desktop first because the turnaround time is faster, and debugging is more pleasant). As an aside [1], I wonder if rust would suit a JVM backend aswell - I don't personally know much about the JVM or like it , its just a tangential thought. I wonder if you could get closer integration with the android ecosystem that way. asside [2] I do think it would be really interesting to build a complete Rust GUI system from the ground up starting with raw gl primitives, built around its' own concepts (enums &amp; trait objects) then you might have something you *want* to port to android. I do think rust Enums would make for a really pleasant GUI API.... really good for messages. 
it can do gl cross platform graphics code just fine,like C++ - its just platform specific details that get messy, and that's not rusts fault of course... just the nature of platforms themselves going out of their way to create vendor lockin.
I've built things like this before in other languages. I was thinking of making something similar (but a bit more specialized) for my current Rust project, for combining noise functions to build procedural terrain. It's essentially building up an AST for an expression. But as I thought about how to architect it in a Rustic way, I realized that good lambda support means I don't really need a special system for this. So, the example in your documentation could be rewritten as: let meta_sum = |a: int, b: int| a + b; let meta_twice = |a: int| a * 2; let double_sum_factory = || meta_twice(meta_sum(3, 2)); assert_eq!(double_sum_factory(), 12); So it's quite possible that I'm not understanding the full intent of the this library, but right now it looks like a more complicated way of encoding what you can get pretty easily out of composing lambdas. It doesn't even really require higher order functions.
Congrats! Steve is definitely an excellent communicator. Whenever I post some question here, he's usually the first with a response and usually provides the most help in answering my question. I enjoy the way he communicates and I'm happy to see him being a part of the team. He'll be key to the adoption of rust.
/me blushes Thanks so much!
Are the scripting systems for most code editors really that sandboxed? Arbitrary file access seems to be a very common use case, as editor add-ons are often doing various forms of project management, interacting with version control systems, etc. And I've never used a package manager for editor add-ons that requests any kinds of permissions.
&gt; you have to use 'extern C' functions so when interacting with the platform you lose Rusts' expressiveness. Not really: you just have to write `extern fn` instead of `fn`.
In practice, the sorts of cases where this would be done would end up needing to be stored as `Option&lt;T&gt;` anyway, so there is no loss. AnyMap is certainly not the optimal container for every purpose, but for a substantial set of problems, as described already, it *is* optimal.
confirmed: aturon hates virtual trees
&gt; By publishing your code on crates.io you are consenting to a controlled Man in the Middle attack in the case that the administrators determine that your code is suboptimal. Seems legit.
I agree wholeheartedly. Maybe its something I can put some time on.
It doesn't default to no_mangle, but it works perfectly well for defining callbacks etc, which I imagine is more common with tools like the Android NDK than exporting function symbols with particular names (but I don't have much experience with it so I could be wrong). Your underlying code has the full power of Rust, it's just the boundaries between Rust and C that need to be careful about what features are exported (and with the callback thing, if there's a `void*` opaque data slot, it's fine to pass in a pointer to an enum or whatever). In any case, it's certainly not the requirement for 'extern C' functions that causes this impedance mismatch: it's purely C lacking these sort of features.
the way I did it was I started with the android NDK example code, and inserted calls from C *into rust* at dedicated points.. its not based on any callback system (unless you write one yourself), it's based on a message loop. so my rust-android code looks like this extern "C" fn app_display_create(..){ } extern "C" fn app_display_destroy(..){ } extern "C" fn app_update(..) extern "C" fn app_create(..){ } extern "C" fn app_destroy(..){ } etc... debug log malarchy aswell //stuff call to these at the appropriate points in the NDK sample native app project. I implemented the same 'stubs' for iOS aswell ...which again works completely differently,their objective-C frameworks, but you have some sample code with points where you can make same analogous calls... effectively declaring my own "statically linked cross platform mobile interface"* etc etc. The alternative is to rewrite and maintain all the android stuff in Rust. That would be better but you'd have to love both the language and the platform more than I do to do it. Then you go to iOS and .. hmm,better to just stuff C calls in sample code... or just stick with "Objective-C++" and get a mature IDE and native access to at least one platform. (*) This is why I've suggested "extern 'C' methods" with a simplified name mangle... imagine if you could write impl App { extern "C" fn update(&amp;self){..} extern "C" fn display_create(&amp;self){..} extern "C" fn display_destroy(&amp;self){..} // etc... } and it generated C symbols prefixing the typename:- // void App_update(App*,...) App_update() App_update() App_display_create() etc **EDIT** (maybe we could do this with a macro, if theres something to concat symbols? do i remember right that rust has the ability to manually specify the external name?) imagine if we could convince other languages to follow suit, we could have slightly more pleasant interoperability via extern "C" bindings - it would suit any language with namespacing and/or receivers. i'll put this feature in my pet language
I'm having trouble picturing exactly what's going on here, but it sounds like you want to store a mutable reference to a D-Bus connection within an object? Is there any possibility that rather than storing a mutable reference you just pass a mutable reference as an argument to the object's methods as it is needed?
I feel this is kind of early 
RIP web browser loading
I had completely missed we are getting a `?` operator after all… It strikes me as rather odd to have an operator that only works on two specific `enum`s. I was under the impression we were avoiding such things. Will `?` be more general in some way that I'm missing?
The RFC that aturon is alluding to there proposes a new lang item called `Carrier`, which is a trait that you could implement in order to use the `?` operator on your own types.
Well, dependency injection container. This is small part of that. I am trying to re-imagine how it might look in Rust, and I would be more than happy to achieve more elegant design. You know, I had many failed attempts at this, and this might be just one more :) I have my own likes and dislikes about various containers that I have seen, and actually none of them looks like what I want to do. First of all, the use of singleton-pattern is a big NO. Second, having a dependency on di itself is another big NO. Once built, container should remain immutable for the lifetime of its use. Right now I am no longer sure I need a "container" as such, more like a place to register what exists ("metafactories"), and a way to pull out immutable factories from them. This place should live between config and libs, in my main function, it is very project-specific. di &lt;- feature with config -&gt; lib So, let's say meta_twice is a feature that is enabled only if something exists in some config file and only if meta_sum feature exists. "feature with config" is the place where I write these "if" statements, instead of scattering them all over the place. I think I should stop here, before it becomes unnecessary essay :). I guess the reason I chose to do it this way is that I found one way how to get rid of Any once the factory itself is constructed. I figure I should be able to improve the guts later, or maybe I will find completely another way to implement di once I implement enough of it :)
I think you might be using an old version of Rust. Are you using the latest nightly build or 0.12? In general, people in the Rust community are using the nightly builds for everything until 1.0 comes out and the language and libraries are stabilised.
Loosely related: I was using extern for defining callbacks, but if you define any two callbacks with the same name, rustc ICEs (and not in a nice way): https://github.com/rust-lang/rust/issues/16403 Does that sound like something you should be able to do? I don't want to export function symbols, just declare a callback and get a pointer to it, so it doesn't seem like that should crash. I ask because my issue was closed as a dup of https://github.com/rust-lang/rust/issues/10883, but 10883 sounds like a case that actually should be an error (exporting a duplicate symbol with no_mangle). Sorry to ambush you in this thread, I'm not very familiar with this topic so I wasn't even sure if what I'm trying to do should work :)
The guide is about 130 pages printed, last I heard, and is longer if you consolidate the other guides into it. I prefer printed material, so I'd love to have it in paper, but there's no official plan right now. I'm not aware of any book projects currently, but I know publishers are interested...
Rust is already pretty impressively popular, if you go by GitHub and Reddit stats... But you never can tell until release :) I'm not sure of the team size. If you count Servo too, maybe a dozen? 
Every day is an AMA around here! What do you want to know?
Yes, that does seem like something that should work; I investigated a little and reopened it for you. :) 
Your regex could be a lot simpler: \\[uU]0*([0-9A-F]+) A little more naive, yes, but the cases where it screws up will be few and far between, and easy to fix.
And then they turn around and make it even better the next day :D https://github.com/rust-lang/rust/pull/19782
I'm still here.
Thank you, I really appreciate it. That's a much more thorough analysis than I could have done!
See this: http://www.reddit.com/r/rust/comments/2g3l5l/hacking_the_custom_linker_system_to_make/ Servo is going to use it if everything goes well. 
The problem is "drop(&amp;mut self)", which should execute automatically when the ObjectPath struct goes out of scope. Any chance I can get a mut ref of the connection inside that method, without storing it in the ObjectPath struct?
I still don't see any aspect of this which can't be accommodated with simple lambdas. You can absolutely dependency inject a lambda, provided you know what it's signature is: struct Widget { func: || -&gt; int, } impl Widget { fn new(func: || -&gt; int) -&gt; Widget { return Widget { func: func }; } fn activate(&amp;self) -&gt; int { return self.func(); } } fn main () { let meta_sum = |a: int, b: int| a + b; let meta_twice = |a: int| a * 2; let double_sum_factory = || meta_twice(meta_sum(3, 2)); let widget = Widget::new(double_sum_factory); println!("Widget value: {}", widget.activate()); } I think you may need to add an explicit lifetime to make that compile, but you get the idea. Your Widget can now accept any function which takes no arguments and produces an int, which is functionally equivalent to taking a metafactory, but requires no special libraries and a lot less boilerplate to construct. This kind of system is basically building an infrastructure to simulate the behavior of lambdas. Which is useful in languages where you don't have lambdas, which for a long time described Java and C++ (though they've both gotten lambdas in recent years). However, lambdas render such systems redundant.
that does look nice
Seems you didn't get the memo... glutin has been Servo's only android port since two days or so ago \o/.
I think you may have confused a Rust panic (program did something it wasn't supposed to) with a Kernel panic (entire system is screwed, everything is on fire, cats and dogs living together). I suspect you'll get a quicker resolution if you specify the code you're trying to use and what version of the compiler you're using. Most likely, you're trying to use old code with a new compiler, or new code with an old compiler.
sure :) claudiu@Bender-Rodrighez-4 ~/startups/rust/rust_tut/src *$ cat hello.rs fn main() { println!("Hello claudiu!"); } -------------------------------------- claudiu@Bender-Rodrighez-4 ~/startups/rust/rust_tut/src *$ RUST_BACKTRACE=1 rustc hello.rs error: internal compiler error: unexpected panic note: the compiler unexpectedly panicked. this is a bug. note: we would appreciate a bug report: http://doc.rust-lang.org/complement-bugreport.html note: run with `RUST_BACKTRACE=1` for a backtrace task 'rustc' panicked at 'assertion failed: end &lt;= self.len()', /Users/rustbuild/src/rust-buildbot/slave/nightly- mac/build/src/libcore/slice.rs:432 stack backtrace: 1: 0x10cc615c0 - rt::backtrace::imp::write::h276c1d3da30d25d7bVx 2: 0x10cc647d0 - failure::on_fail::h26104c4e5109e22dPhy 3: 0x10ceb6d95 - unwind::begin_unwind_inner::hfa8e57738653fe8fFBc 4: 0x10ceb6a77 - unwind::begin_unwind_fmt::hce0b1d6c212ce31f2yc 5: 0x10ceb6792 - rust_begin_unwind 6: 0x10cf044ac - panicking::panic_fmt::h114ee3e43194a3bcRtl 7: 0x10cefef32 - panicking::panic::h656c692e521ecf6chrl 8: 0x10a4dd91d - metadata::loader::Context&lt;'a&gt;::extract_one::h95913ef11cfa2002Pww 9: 0x10a4d68ce - metadata::loader::Context&lt;'a&gt;::find_library_crate::he78668e40fe129cbbnw 10: 0x10a4d18bf - metadata::creader::PluginMetadataReader&lt;'a&gt;::read_plugin_metadata::h598469ede704807bfdv 11: 0x10a507b9d - plugin::load::PluginLoader&lt;'a&gt;.Visitor&lt;'v&gt;::visit_view_item::hc1947c9f90ac5776E6z 12: 0x10a506f3b - plugin::load::load_plugins::h43c7ebf92813c5adu5z 13: 0x10969d6ef - driver::phase_2_configure_and_expand::h00d90292531ce126Qha 14: 0x10969171f - driver::compile_input::hde6371ddee42c3f7pba 15: 0x10972928d - run_compiler::h06c79cf9e1e33dfbEYb 16: 0x109727cee - run::closure.21409 17: 0x10973912e - task::TaskBuilder::try_future::closure.22863 18: 0x10cc3a833 - task::TaskBuilder::spawn_internal::closure.30632 19: 0x10ceb499d - task::Task::spawn::closure.5567 20: 0x10cf1c16c - rust_try_inner 21: 0x10cf1c156 - rust_try 22: 0x10ceb4a77 - unwind::try::he77b5a8881543410Wqc 23: 0x10ceb484c - task::Task::run::he429ca3c5047a629fIb 24: 0x10ceb454f - task::Task::spawn::closure.5543 25: 0x10ceb5e57 - thread::thread_start::h6870b75b36f51b8cwZb 26: 0x7fff8d842899 - _pthread_body 27: 0x7fff8d84272a - _pthread_struct_init --------------- version: rustc --version=verbose rustc 0.13.0-nightly (193390d0e 2014-12-11 22:56:54 +0000) binary: rustc commit-hash: 193390d0e48f6d8fb58acb7d0460c14acf907322 commit-date: 2014-12-11 22:56:54 +0000 host: x86_64-apple-darwin release: 0.13.0-nightly mac: 10.9.5 
Funny, I was wondering why /u/steveklabnik1 didn't have core team flair just this morning.
Works fine here using the same version (OS X 10.10). Try re-installing, maybe that helps.
I've use the lastest rust build, 3 hours ago :) Not a friendly way... installing like this works: sudo curl -s https://static.rust-lang.org/rustup.sh | sudo sh using the pkg from the website failed :) strange...
It sounds like the connection could live inside a RefCell yes -- so that you can call mutators on it with a &amp; reference.
In the last remaining days of 2014 just one question remains: Will this bring us nearer to hover boards? 
&gt; and these traits are in turn "lifted" over IoResult Related issue: Iterators over those. If I have a say `Iterator&lt;u8&gt;`, I can do two things: Funnel some in-memory sequence through it... or slurp up a file so that's in-memory, collapsing all the `IoResults` (cf. [sequence](http://hackage.haskell.org/package/base-4.7.0.1/docs/Data-Traversable.html#v:sequenceA)) and then funnel it through the iterator. What doesn't work is hooking the iterator directly to the reader, that'd need an `Iterator&lt;IoResult&lt;u8&gt;&gt;`. Current solution to do both with the same code? Wrap your pure `u8`s in bogus `IoResult`s. *Even though* `next()` already has a notion of "failing", that is, `None` signals the end of stream. Haskell's (yeah I know I talk about Haskell a lot) streaming libraries generally internalise that error handling, in a nutshell, `next` should return `enum IterStep&lt;T,E&gt; { Item(T), End, Error(E) }`. Most iterators such as map can just ignore the additional details, treat `End` and `Error` the same: Pass them through.
It would be very cool. I feel like the BTree module is a center of innovation in Rust right now, these are some useful patterns we need to get out in the open!
This library is very readable, which is really nice. The `HumanString` construct captures the essence of the problem domain pretty well, I think. There are two things I'd suggest changing: 1. You don't have a defined ordering for comparing a String to a Number... This seems likely to be a problem for this library's intended audience. Probably Number should be unconditionally less than String? 2. It looks like the efficiency could be improved. The big thing I notice is that you do a full translation to `HumanString` each time the comparison routine is called, which would be inefficient against large data sets. Without changing your design much, you might want a new sort routine that operates against an array of `HumanString`s directly, allowing callers to pre-parse the string ahead of time (and, I believe, avoiding all dynamic allocations during the sort execution). Another approach that would help the efficiency would be to eliminate the HumanString type, and instead read through both strings linearly, with some bookkeeping to see whether you are currently parsing as a number or a string. Unfortunately, that would also lose your nice abstraction. I'd suggest making a `StringElem` iterator that can be used to parse over a `String` in place. This could be used to build up a `HumanString` via the `collect` consumer, and could also be used during the regular `sort` routine so that you'd only examine the parts of the `HumanString` you need to, and you avoid unnecessary dynamic allocation during the `sort` operation. HTH
My guess is that it happens because you set the buffer size to 0 and there is no receiver. Relevant part of the documentation: http://doc.rust-lang.org/std/comm/fn.sync_channel.html
Yes ;-) At least, I'd want my hover board's firmware to be written in Rust rather than Ada (runtime memory errors, but at least they're not intermittent) or other low-level memory corrupting languages.
I don't think so, the whole point of the buff length of 0 is such that the test will block until the receive happens, rendering the flow essentially synchronous. The receive happens here: https://gist.github.com/timonv/9e938230721de6acf0ad#file-chat_server-rs-L33
Reddit doesn't allow you to, unfortunately. I don't find 'hobby' to be too negative in the context it was written.
Thank you for great responses, they give me some food for thought. Regarding lack of lambdas in other languages - well, we called them listeners, same thing. But that's not the "main" function I would like to have - it is essentially library-level. I wish to get out of it and leave only declarative feature-list. For example (using my metafactory I know how to do): fn main () { let mut registry = di::Registry::new(); blog::configure(registry); blog_comment::configure(registry); blog_rss::configure(registry); blog_comment_rss::configure(registry); what_this_client_wanted_to_add_possibly_a_mess::configure(registry); // do not reuse let container = registry::validate_all_the_things_and_make_container(); do_init_stuff_with_something_in(container); } This way I leave each part of app to "inject" itself by registering as a plugin to the registry. Also I want to do the validation once, at the beginning of runtime (since I do nothing at compilation). Now that I look at it, I wonder if I could get rid of registry by defining dependencies of the modules themselves explicitly, something like this: fn main () { let mut blog_factories = configure_blog(); let blog_comment_factories = configure_blog_comment(blog_factories); ... } ~~This might be one of those "duh" moments. Pretty embarrassing.~~ EDIT: well no, not really. I see guys are resorting to such things like AnyMap or TypeMap to do similar "value discovery". I think I am going to push this forward and see how the result looks like :)
That's what I thought initially. But when I add `collect()` it blows up again. &lt;anon&gt;:2:42: 2:51 error: the trait `core::iter::Iterator&lt;_&gt;` is not implemented for the type `collections::vec::Vec&lt;_&gt;` &lt;anon&gt;:2 a = a.iter().flat_map( |&amp;x| vec![x, x] ).collect(); ^~~~~~~~~ &lt;anon&gt;:2:14: 2:41 error: the trait `core::iter::Iterator&lt;_&gt;` is not implemented for the type `collections::vec::Vec&lt;_&gt;` &lt;anon&gt;:2 a = a.iter().flat_map( |&amp;x| vec![x, x] ).collect(); ^~~~~~~~~~~~~~~~~~~~~~~~~~~ From this it looks like `flat_map()` returns a `Vec`. Or I completely misunderstood the error message.
Here's the signature of `flat_map`: http://doc.rust-lang.org/std/iter/trait.IteratorExt.html#tymethod.flat_map That error message is very strange.
`flat_map` returns an iterator, but it also *demands* the function to return an iterator. Since `Vec` is not an iterator you need to convert it to an iterator, as like this: let mut a: Vec&lt;int&gt; = vec![1, 2]; a = a.iter().flat_map( |&amp;x| vec![x, x].into_iter() ).collect(); (I've used `into_iter` here since you need `Iterator&lt;int&gt;` instead of `Iterator&lt;&amp;int&gt;`. ~~If you want, you can use `.iter().map(|&amp;x| x)`.~~ Thinking about that, /u/TimNN is right about that: you cannot easily use them in that context.)
Congratz! Good luck!
You can use `iter().cloned()` for de-reffing the contents now.
Your code does not work on the nightly (`rustc 0.13.0-nightly (ffc111889 2014-12-12 21:07:19 +0000)`). With some fixes(*) I could get the code compile, but then I only see an indeterministic output from `read_output` (it can return an empty string when the spawned task is yet to `recv`). Maybe you should get the recent nightly and try again. (*) `downgrade` is no longer a thing, if you want to release the lock early you should use `drop` instead; `read_output` needs to return a `String` or an [`RWLockWriteGuard&lt;&amp;str&gt;`](http://doc.rust-lang.org/nightly/std/sync/struct.RWLockWriteGuard.html).
I suspected that I need to return an iterator in the `flat_map` block but I missed the difference between `iter` and `into_iter` so it didn't work for me. Thanks.
Oh really? Things go so fast! Let me check it out
Sure, but now that I’ve written the more complicated but correct form, other people can just copy/paste it :)
You can host them on RustCI for now. I hope to have 'here's how to easily deploy to gh pages' up as a blog post sometime in the next few days. Eventually, we'll have something that just automaticlaly does it for all packages.
I actually have a small script named `cargo-doc-publish` in my $PATH: #!/bin/bash USERNAME=insert-your-github-user-name-here PKGID="$(cargo pkgid)" cargo doc &amp;&amp; cd target/doc &amp;&amp; rm -rf .git &amp;&amp; git init &amp;&amp; git checkout --orphan gh-pages &amp;&amp; git add . &amp;&amp; git commit -m 'updated docs.' &amp;&amp; git push git@github.com:$USERNAME/$(basename ${PKGID%#*}).git gh-pages -f `cargo doc-publish` would automatically compile a documentation and overwrite it to `gh-pages`. It's not that robust though, so use with a caution.
Oh interesting! I implemented https://github.com/rust-lang/rust-by-example/blob/master/deploy.sh , which when combined with https://github.com/rust-lang/rust-by-example/blob/master/.travis.yml#L14 deploys on successful builds to master. Our two things are quite close.
Thanks!
There's quite a few people working on operating systems: there's even an IRC channel for people interested in that sort of area (#rust-osdev, see the sidebar for more details).
just a hobby
Everything is common within a certain context ;)
Well, I have created that post: http://www.reddit.com/r/rust/comments/2p6zxy/heres_how_to_easily_deploy_doc_to_github_pages/ For better or worse...
Rust is used in production by a couple of companies right now. [Skylight](https://www.skylight.io/) is one [prominent example](http://blog.skylight.io/bending-the-curve-writing-safe-fast-native-gems-with-rust/). That said, the language is not yet stable; that is, there are breaking changes still happening to the language itself, so it's currently expected that if you write code with the language as it exists now, you may have to port it to the language that exists a week from now. Hitting the 1.0 milestone, when breaking changes will stop happening, is quite close, expected within a couple of months, but until then, you should be ready to port. An internal compiler error is just a bug. Given that you're using a nightly build, it's generally expected that a few of those may slip through. It's pretty unusual for such a bug to slip through just for hello world, since there are extensive test suites run on every build, but it may be that something is different about your configuration that is unexpected.
Hey, it's great that you want to learn Rust, especially at your age this is a very ambitious goal and one I would fully support if you want to learn low level programming. Note that Ruby syntax and that of Rust are not very similar, if at all, and that Rust is definitely not a "faster Ruby", but more a "nicer, safer C++". Also, if you think that C++ is a bit too low-level for you, Rust might feel this way too! Rust is essentially as low-level as C++, but it provides much stronger memory safety guarantees and somewhat higher level constructs and syntax. Don't be fooled trough, you'll need to get into the low-level territory of C++ for any substantial app that you'll presumably, eventually, want to write - the difference being that Rust will not simply let you trash your computer and burn it to the ground while not producing any useful result, \s something C++ is very good at. :-) /s [#4: This is a joke, I think C++ is a good language that has its place] Another thing to note is that it is not even clear that Rust is a great fit for webdev, or at least not as productive as Ruby or Go might be for this particular task. On the other hand, Steve Klabnik, who is himself a Rubyist has been writing a very accessible set of Guides for the Rust language that should be understandable fairly easily. Start with [the Guide](http://doc.rust-lang.org/guide.html) and if it makes sense, progress from there. Of course, if you get stuck, we're here (and on #rust at irc.mozilla.org) to help you out! **tl;dr**: Rust's syntax is not even close to that of Ruby and if you don't like low-level programming I am not sure how much you'd like Rust, but why not give it a shot? EDIT: Ok, so maybe Rust and Ruby have a bit of a similar syntax, or at least naming conventions, (I believe what Steve says). My point is that the similarities won't probably help you much with Rust anyway, because Rust is a different kind of language from Ruby, but it may ease you in. Also, obligatory rule #4 edit.
&gt; Note that Ruby syntax and that of Rust are not very similar, if at all, A lot of the naming convention is actually very similar. Depending on how you squint, it can look kinda the same. I do agree that that's kind of irrelevant, though. /u/xSnowCrash, you're so young, you should learn _all_ the things. Don't worry too much about learning the "right" things.
Fixed, thanks!
Do you have any project in mind? I've always needed a project to work on in order to motivate me. It also helps me decide what language to use based on what fits the project best. Rust works well in some areas, but not in others. On the other hand, if you are just want to broaden your horizons, then do what Steve said and learn everything. Learn a C derivative (like JS), a Lisp derivative (like Clojure), and an ML derivative (like Haskell). Rust gives you a bit of all three.
Rust is developing in the webdev area correct? and isnt Scala a lot like Java?
Rust is really different to Ruby, semantics-wise (and, mostly, syntax-wise too). Rust is actually as low level than C++, and is appropriate to the same kind of software. The dividing line between "low level" (like Rust or C++) and "high level" (like Go or Ruby) nowadays seem to be the presence of a garbage collector (or GC). In C you manage memory either using the stack (which stores local variables) or by calling malloc() to allocate memory on the heap, and free() to release this memory. On C++ to allocate on the heap you use new/delete which is like malloc/free, but you can also use smart pointers, that are released when they go out of scope (alongside any resources they have, such as open files; this is called RAII). Rust manages the heap with smart pointers. All the above strategies require you to keep track of who "owns" a given piece of memory and is responsible for freeing it. On C and C++ you need to do this manually (and failing to do so may be a performance or security issue), in Rust the type system does this for you. On higher level languages, keeping track of ownership isn't needed, because there's only one piece of software that releases memory: the garbage collector (which isn't written by you). But this also means that the GC needs to run periodically, usually blocking execution of your own program. Other things that low-level languages worry about is how to avoid needlessly copying data (which in C++ and Rust is accomplished by "move semantics"; in C you need to use pointers appropriately) and how to avoid allocating things in the heap in the first place. So writing low-level code comes with a a different mindset. It forces you to worry about things that, on a first approximation, has nothing to do with the task your program needs to do. Whether this is appropriate for a learning language I don't know. Can I suggest Haskell too?
Well nickel.rs seems promising, and many people are actively developing to make that work for Rust in that area(as I see). since JS is such a higher level language, I guess I do need to get into low-level languages. Question though, would Rust,like C, help me comprehend other languages to learn after I know Rust?
I'm confused... does casting a `c_long` to a `c_uint` *necessarily* panic? What if you know its a number between 0 and 10000, and *want* to cast it? I'm just not familiar with casting c pointers from within Rust...
Yes, there definitely are efforts to get Rust to be a player in the web dev space, none of them are very mature yet, but they're all very promising, including nickel.rs As far as whether Rust would help you comprehend other languages, I'd say yes, most definitely. It would show you how the machine works and as a result it will certainly teach you how to write more efficient code in any language. Also, a lot of the low-level stuff isn't really language dependant so Rust will help you with any low-level language too. Rust may also help you with functional languages as it's got many ideas from them.
I would suggest you learn what you feel the most excited about and what you find fun. I find Rust and Haskell fun because they have ideas on how to do things better.
I don't think that's what it does. The source for this is actually very short. It just checks to see if you are going to do something silly like cast a negative number to a unsigned number and returns None instead. The logic is if negative if its in the min and max number of the type you are casting to Some(casted number) else None else // its positive if its in in bounds Some else None
Scala runs of top of the JVM, (the Java Virtual Machine is what runs the bytecode that is produced when you compile Java code) and can reuse Java libraries and call Java code directly, however it's more functional whereas Java is purely object-oriented and as a result has a more succinct syntax, compared to Java.
Hey, what i can read from your post and your comments is a high interest in "webstuff". I think quite a bit of the younger programmers started at this stage. To be honest i don't know which way rust is going considering the web and it is quite a bit to reach a level to "stable web stuff" see http://arewewebyet.com/ other than Nodes.js and javascript in particular rusts goal is not to be some sort of webframework. yes rust is a multipurpose language but this does not mean you can or should use it for anything (yet). i would really think of rust as a save c with plans to be a c++ what it today should be. There is no way to waste time on learning the wrong programming language, at the end they all help you understanding the computer better and languages at a hole, as concept. if you wanna stick to the web for a while maybe try python an django but if you want to try something for the desktop i would recommend something like d-lang, rust or python as well. if you want to learn more about how computers work than try c and assembler you can learn a lot from that. this all depends an your particular interest but at least every language that you learn is beneficial. I like programming in C++ Qt in a sense of C with Classes. I think its not wrong to learn C/C++ the industry depends a lot from it. But C++ has its quirks caused by its long existence and backward compatibility but still evolving. which leads to a lot of clutter. I hope rust or d-lang can replace them someday as a fully restart and take over what mankind have learned from C/C++ and what makes a good programming language. 
Im not really looking for a replacement for Node.js, more like to learn another language that specifies in a totally different area, since JS can be used in alot of things.
Higher-kinded (associated) types will not be landing for 1.0; [this RFC](https://github.com/aturon/rfcs/blob/collections-conventions/text/0000-collection-conventions.md#lack-of-iterator-methods) explains the problem you're running into in slightly more detail. HKT is something that is increasingly well-motivated for exactly these reasons, and without it we cannot create strong collections traits, among many other things. It will definitely be an area of interest after the 1.0 release.
Maybe I'm wrong, but doesn't NumCast in libstd do the same thing?
Right. I saw that RFC, too. Just wasn't sure whether something happened in that department. It's hard to keep up with all the progress. :)
Using `InvariantLifetime` to track the origin of handles is genius! I'm sure there's a some kind of generally useful construct to draw here.
Mine's easier to type into Vim. :P
With all due respect, there is nothing more pointless than going to a group of people whose common interest is X and asking them if X is good. As others have said, if you don't have specific goals except for learning, you pretty much can't go wrong; just pick a language. Some have bigger ecosystems that make it easier to build real programs, some have great features that make it a joy to code, and some have wild new paradigms that make you think in new ways.
If you are interested in using Rust for web stuff, I'm one of the authors of Hyper and the main author of Iron, which are an http implementation and a web framework respectively and am always looking for new contributors and users. I'm `reem` on IRC and github, ping me if you are interested.
Oh! so its bounds-checking, and returning an `Option`. That makes a lot of sense!
Neat! Be interesting to have some on-the-ground performance numbers (to compare to C).
I've written [an implementation of Tee](http://bluss.github.io/rust-itertools/doc/src/itertools/tee.rs.html#16-20) now. It's specialized for only two halves, so the code is much simpler than grabbag. Thank you for the inspiration, although -- last time I implemented this adaptor was [back when @mut T still existed!!](http://www.reddit.com/r/programming/comments/1fkhwa/removing_garbage_collection_from_the_rust_language/cab9es6) (yes that's my comment).
Rust compiles to LLVM bitcode, which is then compiled directly to machine code. There's no virtual machine involved. I believe the first Rust compiler was written in OCaml, then the current compiler written in Rust which was compiled with the OCaml compiler.
Well, LLVM stands for "low-level virtual machine". But there is no virtual machine *at runtime*; only an intermediate implementation detail of the compiler.
You shouldn't use a different type in the API if it's a logic error to actually use it that way. Code that's needlessly incorrect is not idiomatic. If it uses `long`, then you should either use `i32` or `c_long`. The integers will usually be for flags (usually `int` or an enum) or sizes (`size_t`) but if it's something else you can still manage without incorrect code. Checked casting is useful, but I don't think this specific use case is sensible.
&gt; &gt; /u/xSnowCrash , you're so young, you should learn all the things. This. A hundred, thousand times **this**. Your brain is *so much* more malleable at your age. Learn every programming language you can get your hands on. And learn as many *different* languages as you can: Lisp, Prolog, Fortran, Haskell, BASIC on a C64, assembler... Doing it now will pay off *hugely* over time. Hell, while you're at it, throw a natural language in as well, if you don't already know one. Pick one that's as different as possible from your native tongue to learn as much as possible. One of my big regrets from my teenage years was that I never learned a second language. They made me do a mandatory 6 months of Japanese and French in high school, but never gave me any reason to *want* to learn them.
The term "virtual machine" sort of encompasses everything in computer science. It's a better succinct description of the field than most I could come up with...
[The Rust blog](http://blog.rust-lang.org/) has several articles on the plan for stabilizing the language.
This looks very, very slick. I have question about a particular use-case, though. Right now, I'm working on [Rust bindings for duktape](http://www.rust-ci.org/emk/duktape-rs/doc/duktape/), which allow me to do things like: use duktape::{Context,Value,DuktapeResult}; // Add two numbers using JavaScript. `Value` will soon be replaced // by proper deserialization. fn add_example() -&gt; DuktapeResult&lt;Value&lt;'static&gt;&gt; { // Create a new JavaScript interpreter. This will be automatically // cleaned up when `ctx` goes out of scope. let mut ctx = try!(Context::new()); // Load some code from a string. try!(ctx.eval("function add(x, y) { return x+y; }")); // Call the function we defined. ctx.call("add", &amp;[&amp;2.0f64, &amp;1.0f64]) } But this will also work with user-defined types: #[deriving(Encodable, Decodable)] struct Point { x: f64, y: f64 } ctx.call("plot_point", &amp;[&amp;Point{x: 1.0, y: 2.0}]).unwrap(); Under the hood, this makes heavy use of `Encodable` and `Decodable` to build and parse Duktape heap values using a stack API. The really nice thing about this approach is that `#[deriving(Encodable, Decodable)]` makes arbitrary user-defined types JavaScript compatible, and that I can encode and decode non-string representations. Is this too far out of scope for serde? Or if this is in scope, should I junk my serialize integration and switch to serde? I'm not quite sure if I understand what's going with with the `RustcDecodable` and `RustcEncodable` changes for 1.0.
PROTIP: If you're going to show a code sample on your homepage, show a COMPLETE example, don't pass magic variables that aren't declared into your example function. That tells me, the potential user, exactly nothing.
Actually, LLVM only used to stand for "low-level virtual machine". Now it just isn't an acronym.
Thank you for your advice! Do you see any obstacle to "serializing" Rust types as JavaScript heap objects (instead of strings), and "deserializing" them back to Rust? If this should be possible, my plan will be to: 1. Use `Encoder`/`Decoder` as a stop-gap solution, but stop trying to fix their peculiarities. 2. Move on to higher-level duktape-rs features. 3. Convert over to serde(2?) at an opportune moment. If I'm going to be sticking with `Encoder`/`Decoder` long-term (or at least `RustcEncodable`/`RustcDecodable`), then there are API fixes I want to work on before Rust 1.0. But if there are going to be high-quality third-party libraries that do what I need, I'm happy to hack around any limitations I hit in `serialize`.
Yeah, I don't think you should have major obstacles, and your plan sounds pretty good. And I wouldn't necessarily say you have to stick with `Encoder`/`Decoder` long term. I'm hoping to have `serde` in a usable form by the first beta. We've got a really good chance of getting nearly a zero-cost generic serialization framework. One of my benchmarks, [bench_log::bench_manual_vec_escape](https://github.com/erickt/rust-serde/blob/master/benches/bench_log.rs#L1021) measures how quickly we can write to a Writer with no serialization abstraction. It benchmarks at about 234 MB/s, in comparison to 201 MB/s with serde. So only smidgens away from it (and serde2 is a bit closer!). Deserialization is another story. I haven't built an equivalent test, but I think we can get there too. But any kind of serialization is going to be faster than no serialization at all. That's how Cap'n Proto dominates my benchmarks. I don't really know much about how browsers integrate with their JavaScript engines, but I imagine they are not serializing in most circumstances. I recommend exploring how [servo](https://github.com/servo/servo) is doing things, talking to folks on #servo, or possibly trying to summon /u/mozilla_kmc o /u/pcwalton to chime in here :) There is also a very experimental possibility with `serde` and `libserialize` to have a serializee know the concrete type of the serializer. This would allow you to, say, have a special `JavaScriptString` in rust that acts like a `String` in rust, but then has a special `Encodable`/`Serialize`/etc that can call a method on the concrete type, as in: impl Encodable&lt;JavaScriptEncoder&gt; for JavaScriptString { fn encode(&amp;self, e: &amp;mut JavaScriptEncoder) -&gt; Result&lt;(), JavaScriptError { e.encode_javascript_string(self) } } This pattern may help you save some allocations, but you'd be pushing the boundaries if you go down this route.
* More detailed description here: https://github.com/graydon/bors/pull/46 * Original issue here: https://github.com/graydon/bors/issues/34 * Announcement: http://discuss.rust-lang.org/t/batched-merge-rollup-feature-has-landed-in-bors/1019 TL;DR we can now mark a PR as "rollup" to mark it as low-priority/low-risk. When one such PR hits the top of the queue, bors will then automatically rollup and bulk-test all PRs marked as such! This can be forced by making a rollup PR high priority. Yay automation! Barosl is a machine!
Glad to help! Feel free to reach out to me anytime, here, on serde, or as erickt on #rust.
I know it's not possible at the moment, but IMO it would look better if it can be written as checked_cast!(foo as c_uint) as this makes it clear about the order of arguments.
I like the simplicity of the project homepage a lot :D, but I do agree here that the example should be more complete. Looking at the API docs I see that you have a bunch of functions like: render_file_from_hb render_file_from_json_enum render_file_from_json_file ... Would it be possible to break this up into a single generic function with an accompanying trait such as fn render&lt;T: Render&gt;(data: T) { // ... } Then you can implement `rustache::Render` for all those data sources you have but it also allows the API to be extended? **EDIT:** This probably doesn't make as much sense as I initially imagined because I'm not sure how to get a unified interface over all those data sources. I kind of hand-waved the `rustache::Render` trait away :D
I also got confused between cargo new mdbm cd rust-mdbm And then editing the `Cargo.toml` to set the name.
So something that is seriously awesome is testing that you get a **compile error** when using the library incorrectly. How would you write an automated test for this that doesn't, well, not compile? What I mean is, if your test suite doesn't compile (even though this is correct), you can't run any of the other tests and they seem to be failing. What I'm getting at here is: if non-compilation is a "correct" behaviour but is considered "incorrect" by the compiler and the test runner, how do you automatically test for this?
&gt; Create github token access for public repos, copy that token to travis configuration environment variable named TOKEN. Don’t publish your token unencrypted! It’s equivalent to a password, for pushing to any of your repositories. Use this: http://docs.travis-ci.com/user/encryption-keys/ If your token has been leaked, revoke it here https://github.com/settings/applications and create a new one.
How many other github project regularly batch up 15-25 PRs in one and merge them in? It's pretty cool.
I've actually wanted this quite a few times in Rust, but it doesn't provide a built in way to do it. rustc has its own custom test suite which can do this.
Having so many pending pull requests that bors is saturated really feels like a "rich's problem", it's boding well for the success of Rust.
Serialization is a component of a lot of interesting code (for example network and messaging), so I hope some kind of #deriving for the needed traits will stay for maximum compatibility across 3rd party crates.
Good Job!
I believe env variables in repository settings are also hidden and might be a bit more convenient: http://docs.travis-ci.com/user/environment-variables/#Using-Settings I have edited the post to add a warning though. 
And there is the one used by nickel (maybe that's the one you're talking about).
I needed to do something similar for a research project once (except with Java), and I ended up invoking the compiler as a library and analyzing the results.
Could you please elaborate with a quick example?
Intersting timing, I came across this problem myself just now. When seeing that the implementation of PartialEq for Rc compares the values pointed to, my initial reaction was to think that it seems an odd choice. I would think comparing the pointers would be the expected behaviour. But I also know that it's clever people that have written rust, so I'll save my judgement until I've thought some more about this... Have you looked into any other possible solution/work-around, other than wrappers?
They are [officially hosted](https://github.com/rust-lang/rust/issues/14796#issuecomment-62053531). wget https://static.rust-lang.org/dist/2014-12-08/rust-nightly.tar.gz wget https://static.rust-lang.org/dist/2014-12-12/rust-nightly.tar.gz
TIL. That looks alright. I thought you suggested putting it in a `.travis.yml` file that might be in a public GitHub repository.
Thankyou
&gt; since they have the exact same underlying binary representation Rust does not currently guarantee this unless they're both `repr(c)` ~~Anyway I'm not sure how referential equality is supposed to work with collections in Rust? If you put a value in a collection, you can't get a reference to it without... searching for it. If you put a reference in a collection, then you still need to use the same old Hash/Eq implementation to actually *find* the element. Are you storing values that *contain* references? Can you elaborate on your precise usecase?~~ Ah I see, working with Rc's. Also of course for this particular example you can just do: use std::collections::HashSet; fn main() { let mut a = HashSet::new(); let b = vec![0u, 1u, 2u]; a.insert(b.clone()); assert!(a.contains(&amp;b)); } But yes this is in general more complex searching is A Problem. One suggestion has been to offer up basically full blown Comparators. Another option, once we have HKT, would be to allow it to return a *value* whose lifetime is tied to &amp;self (which HKT is necessary for, to my knowledge).
Nickel uses (a fork of) erickt's library.
If `rc1 == rc2` compares the pointers, you could always just do the noisier `*rc1 == *rc2`.
Think you mean RAII here: &gt; // Lock the key. RIAA will unlock it when we exit this scope.
http://doc.rust-lang.org/complement-lang-faq.html#is-anyone-using-rust-in-production?
I did! The recording industry has nothing to do with this project :) I pushed up a fix.
Ah thanks, good point. I pushed up that change.
Also match self.next() { Some(Ok(token)) =&gt; Ok(token), Some(Err(err)) =&gt; Err(err), None =&gt; Err(self.end_of_stream_error()), } [`unwrap_or`](http://doc.rust-lang.org/core/option/enum.Option.html#method.unwrap_or) match self.tokens.next() { None =&gt; None, Some(token) =&gt; Some(Ok(token)), } [`map`](http://doc.rust-lang.org/core/option/enum.Option.html#method.map)
Look at that! nickel's [rust-mustache](https://github.com/nickel-org/rust-mustache) is forked from mine. I should definitely talk to them about merging back together.
So you want something like below? #[should_not_compile] fn foo() { let bar = 1 + "abc"; }
&gt; 1) What's the best way to share different parts of a vector amongst multiple threads? (~ line 22) Am I successfully using references or am I accidentally copying values all over the place? `Arc` is a ref-counted pointer, so you're correctly sharing instead of copying the vector. &gt; 2) Am I creating those threads properly? Looks like it. Does the program use multiple cores when you run it? &gt; 3) Previously I was using a fixed size array to store the points, which I had to mark with box so that it wouldn't overflow the stack. I don't seem to need to do this with the Vector, are they always on the HEAP or do they do change location depending on size? Vectors always put their buffer on the heap. &gt; 4) Other comments on my code are appreciated! Minor things. Lines 39-42 would be better with `+=` instead of `=`. Lines 10-11 you're duplicating the use of `10000000` for the number of points. Those variables should be [const, not static](https://github.com/rust-lang/rfcs/blob/master/text/0246-const-vs-static.md). The return value of `sum_parts` would be easier to follow if you made it a struct with named fields instead of a tuple.
Very much so.
One random stylistic comment: four spaces instead of two. (I also love two spaces, but that's not Rust's style.)
Instead of doing your own timing, you can use the built-in benchmarking stuff: http://doc.rust-lang.org/guide-testing.html#microbenchmarking (This guide has a total re-do in the queue, so the # part might not link in the future)
&gt; I thought I'd break up the list into different chunks and go through them in parallel, before adding them up at the end. My math is terrible, so this may or may not be possible, but if you can truly break them into distinct chunks, you can save a lot of overhead, since `Arc` wouldn't be needed.
Great points, thanks! It does use multiple cores, runs extremely quickly!
Oh hey, you're redoing the benchmarking docs? Rad. It was *really* hard trying to figure out how that worked before. Off topic: Shouldnt #[bench] and #[test] imply #[allow(dead_code)]?
I’ve heard that self-publishing with on-demand printing is relatively easy this days. Is there a PDF version of the guides available?
Yeah, so it becomes a bit like a conditional compilation flag, and it integrates with the test process. Does conditional compilation allow compile-time errors? I mean with something like #[debug]. **EDIT:** I'm assuming it does, which is why some libraries compile fine on linux but not on OSX?
If I understand it correctly, fork-join style data parallelism is currently impossible in Rust without using `unsafe`.
PR here: https://github.com/rust-lang/rust/pull/19627/files it says it got merged, but isn't up yet. I need to investigate... (EDIT: looks like it might have _just_ missed the nightly upload, so tomorrow!) &gt; Shouldnt #[bench] and #[test] imply #[allow(dead_code)]? It's useful to see what code you haven't tested, no?
We build one, so you could make your own, yes.
I left a comment on the blog, but cross-posting here: I wonder which version of Rust you're using here? Alex Crichton recently rewrote the concurrency primitives in std::sync to use e.g. pthreads directly. (See https://github.com/rust-lang/rust/pull/19274/). So if you try this on a recent Nightly, you won't be using channel-based mutexes. The reason, by the way, that mutexes used to be this way has to do with the old "green threading" model, which has been dismantled over recent months. (See https://github.com/rust-lang/rfcs/pull/230 for more). 
I don't know why you would think that. Do you have any particular question or stumbling point?
Ahh yes that'd be bad.
It is impossible to take a `vector = [1, 2]`, then send `&amp;mut vector[0]` to one thread and `&amp;mut vector[1]` to another. The compiler has no way to know that the parts that you send are non-overlapping.
Have you ever gone back and read the rust posts from ~2 years ago? It is absolutely insane how much the language has changed.
There have been lots of changes. I liked Niko's talk on it at the Bay Area Meetup a few months back.
I like others am not entirely sure what you mean. The code I have here compiles and also works. That's also not quite what I'm doing if you look at the code. There aren't any mutable references because the vector doesn't need to change at all.
You can take a small Rust program and trace its journey through the compiler. The first step is parsing. We can ask `rustc` to stop after parsing and just pretty-print the code: $ rustc --pretty normal foo.rs fn main() { println!("Hello, world!"); } The next step is expansion of [macros](http://doc.rust-lang.org/guide-macros.html) and [syntax extensions](http://doc.rust-lang.org/guide-plugin.html#syntax-extensions). You can see the result with $ rustc --pretty expanded foo.rs This contains some [libstd](http://doc.rust-lang.org/std/index.html) imports that were implicit in the source. Also the `println!` macro has expanded to a dozen lines of code. The result is 23 lines in total. Now the code is ready for typechecking. `rustc` infers a type for every expression, then checks that they all make sense together. You can see the inferred types with $ rustc --pretty typed foo.rs That's 38 lines. Next we can look at the [LLVM code](http://llvm.org/docs/LangRef.html) produced by the compiler: $ rustc --emit ir foo.rs &amp;&amp; cat foo.ll 107 lines. As others pointed out, the "VM" name is misleading. This is a [SSA](http://en.wikipedia.org/wiki/Static_single_assignment_form) intermediate representation like you might find in any traditional compiler. It looks a bit like assembly code for a hypothetical machine that has an infinite number of registers. LLVM itself, the C++ library, is responsible for turning this into assembly for an actual machine. You can see the result with $ rustc --emit asm foo.rs &amp;&amp; cat foo.s 111 lines. LLVM is an extremely impressive piece of software. It contains about 2 million lines of code, developed by hundreds of people over a decade. Rust performance utterly depends on LLVM's optimization passes, which can rip through the abstractions used in idiomatic Rust code and produce machine code equivalent to what you'd get from C. Compared to LLVM, Rust is a tiny project; it's really fantastic that we get to use all of this machinery developed by others. If you run the above commands with `--opt-level 3`, you'll see that `rustc` itself doesn't perform much in the way of optimization; it's all LLVM. There are a ton of steps I left out of this description. You can give the flag `-Z time-passes` to `rustc` and it will print a full list of what it's doing.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Static single assignment form**](https://en.wikipedia.org/wiki/Static%20single%20assignment%20form): [](#sfw) --- &gt;In [compiler](https://en.wikipedia.org/wiki/Compiler) design, __static single assignment form__ (often abbreviated as __SSA form__ or simply __SSA__) is a property of an [intermediate representation](https://en.wikipedia.org/wiki/Intermediate_representation) (IR), which requires that each variable is assigned exactly once, and every variable is defined before it is used. Existing variables in the original IR are split into *versions*, new variables typically indicated by the original name with a subscript in textbooks, so that every definition gets its own version. In SSA form, [use-def chains](https://en.wikipedia.org/wiki/Use-define_chain) are explicit and each contains a single element. &gt;==== &gt;[**Image**](https://i.imgur.com/o0HRzDl.png) [^(i)](https://commons.wikimedia.org/wiki/File:SSA_example1.1.png) --- ^Interesting: [^Sparse ^conditional ^constant ^propagation](https://en.wikipedia.org/wiki/Sparse_conditional_constant_propagation) ^| [^Three ^address ^code](https://en.wikipedia.org/wiki/Three_address_code) ^| [^Mark ^N. ^Wegman](https://en.wikipedia.org/wiki/Mark_N._Wegman) ^| [^Continuation-passing ^style](https://en.wikipedia.org/wiki/Continuation-passing_style) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmux0hf) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmux0hf)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Hey thanks for the pointer. I tried an obvious implementation but am running into an issue that has to do with sending the points vector to the iterator closure. #[bench] fn test_regression(b: &amp;mut Bencher) { let points = Vec::from_fn(POINTS, |i| f64x2(i as f64, i as f64)); b.iter(|| { linear_regression(points) }); } 93:39 error: cannot move out of captured outer variable b.iter(|| { linear_regression(points) }); I assume I need to clone it or something in the closure, but how do I do so without performing a costly operation in the benchmark?
I can, how would you suggest I go about that? I tried before but I think I just ended up copying the vector into N different other vectors which couldn't be good for performance.
Good answer!
Here is a version without using unsafe, although it might be a bit slower due to the added bookkeeping and indirection. use std::fmt::Show; use std::cell::RefCell; use std::rc::Rc; struct stream&lt;W&gt; where W: Writer { out: Rc&lt;RefCell&lt;W&gt;&gt; } impl&lt;W&gt; stream&lt;W&gt; where W: Writer { fn new(writer: W) -&gt; stream&lt;W&gt; { stream { out: Rc::new(RefCell::new(writer)), } } } impl&lt;T,W&gt; std::ops::Shl&lt;T, stream&lt;W&gt;&gt; for stream&lt;W&gt; where W: Writer, T: Show { fn shl(&amp;self, output: &amp;T) -&gt; stream&lt;W&gt; { write!(self.out.borrow_mut(), "{}", output); stream { out: self.out.clone() } } } const endl: char = '\n'; fn main() { let out = std::io::stdout(); let cout = stream::new(out); cout &lt;&lt; 1i &lt;&lt; 2u &lt;&lt; 3f64 &lt;&lt; "good C++" &lt;&lt; endl; // outputs: 123good C++ } 
Could you provide a bit more of your surrounding code, because the following compiles without problem in the [playpen](http://is.gd/wCLhtx): use std::collections::TreeMap; fn main() { let bar: Option&lt;TreeMap&lt;u8, u16&gt;&gt; = None; let foo = match bar { Some(tree) =&gt; tree, None =&gt; TreeMap::new(), }; println!("{}", foo); } **Edit**: Or do you want the compiler to infer the type of bar, because even that works: use std::collections::TreeMap; use std::default::Default; fn main() { let bar = Default::default(); let foo: TreeMap&lt;u8, u16&gt; = match bar { Some(tree) =&gt; tree, None =&gt; TreeMap::new(), }; println!("{}", foo); }
I'm confused the compiler doesn't complain about the first line, since `var` means nothing, and you would use `let` there.
Sorry for that. Still, the question remains.
I entered the following on the playpen: fn main() { use std::collections::TreeMap; let bar = None; let foo: TreeMap&lt;u8, i8&gt; = match bar { Some(tree) =&gt; tree, None =&gt; TreeMap::new() }; println!("But it works?"); } and it compiles just fine. I can't reproduce your problem. Edit: have you considered that perhaps your problem is not actually on the line that the compiler points out? Perhaps something else could confuse the type inference (perhaps Type1 and Type2?). Unless you post more code I don't think anyone can help.
I also come from a strong C++ background. But I find Vec::new() to be much more clear than C++. In C++, T() could mean several things. It could be a call to a constructor of T. It could be a call to a function named T. It could even be a declaration of a function named T, that takes no args. But in Rust, there is much less confusion. T::new() is the idiom, and it seems fine to me.
Jeah, it does work. Found my mistake. I don't think I'll post problems after 1am, but rather sleep on it. Thanks anyways.
Why not just impliment mutexes via atomics rather than futex?
Has anyone complained that Tuple Struct constructors are ambiguous. has anyone complained that Enum Variant constructors are ambiguous. a constructor is really just a function even in C++; its the 'new' that makes it special. in Rust, T() is just as unambiguous as T::new(). grep "fn T" will find it. the ( vs { distinguishes it from a struct. You could even adapt a 'find thing at point' extention in emacs: if a '(' follows the ident under cursor, grep for `fn &lt;ident&gt;`, if a { follows, grep for `struct &lt;ident&gt;`. fix one problem ('fn' for unambiguous declarations) and the other problem goes away.. people are conflating multiple problems unnecessarily here. 
Not sure which, but perhaps it's [one of these](https://air.mozilla.org/channels/rust/)? (there are a few Bay Area meetups listed)
Fixed! Keep em coming! :)
There's some talk about getting this functionality in Rust/Cargo/in-a-3rd-party-crate. This [ticket](https://github.com/rust-lang/cargo/issues/521) should be tracking this feature.
Yeah, that's why I'm hoping I can have a `cargo new mdbm --to-dir rust-mdbm` someday.
Your post began by giving an aesthetic reaction to Rust. I have the opposite aesthetic reaction to that particular difference in the language.
It is impossible to do fork-join parallelism on a `&amp;[T]` (or a `&amp;mut [T]`) without `unsafe` in Rust... but only in the same sense that it is impossible to store values on the heap (`Box&lt;T&gt;`) or a variable number of values (`Vec&lt;T&gt;`) without `unsafe`: Rust provides the low-level power for people to write safe libraries for this sort of thing. For example, the `split_at_mut` function mentioned in this thread is implemented using `unsafe` internally but exposes a safe interface. (I've heard rumours of such libraries existing now on IRC, but I don't know of any off the top of my head.)
You can implement spin locks via atomics, but if you do you had best be very, very careful. They are not what you want most of the time, for a whole host of reasons. To name two: they burn a lot more power, and they are highly susceptible to priority inversion. Generally speaking spin locks are only for extremely responsible programs that will always hold them only for a brief time, and never deadlock. They are used in kernels and databases and so on. Most of the time you shouldn't touch them.
&gt; Most of the time you shouldn't touch them. glibc has a `PTHREAD_MUTEX_ADAPTIVE_NP` type using adaptive spinning and falling back to `futex`. It's a better choice than the normal mutex types when fairness isn't of utmost importance. It's used for arena locking in jemalloc because it provides a significant performance win.
There's a huge problem with the Rust atomics version, in that there is an extra pair of unintended atomic ops in every iteration: https://github.com/jvns/fun-with-threads/pull/1
I don't see the problem with asking a general question like "how do I return a reference to `self`" and giving context.
I checked out her code, and tried it out with nightly, and had similar results. I also tried removing the extra `Arc` around the mutex, using a static mutex and static mut variable (along with unsafe access), to make it work exactly like the C version (in case the extra `Arc` was causing a problem, as [cmrx64 pointed out in the atomics version](http://www.reddit.com/r/rust/comments/2pabnd/diving_into_concurrency_trying_out_mutexes_and/cmv3kbl)), but am still seeing the rust version take about twice as long: $ perf stat ./counter_with_mutex Final value of counter is: 20000000 Performance counter stats for './counter_with_mutex': 8226.710290 task-clock (msec) # 3.469 CPUs utilized 484,916 context-switches # 0.059 M/sec 68,418 cpu-migrations # 0.008 M/sec 102 page-faults # 0.012 K/sec 18,260,439,632 cycles # 2.220 GHz &lt;not supported&gt; stalled-cycles-frontend &lt;not supported&gt; stalled-cycles-backend 8,079,527,301 instructions # 0.44 insns per cycle 1,791,415,713 branches # 217.756 M/sec 19,180,740 branch-misses # 1.07% of all branches 2.371322584 seconds time elapsed $ perf stat ./rust_counter_mutex 20000000 Performance counter stats for './rust_counter_mutex': 18373.041857 task-clock (msec) # 3.267 CPUs utilized 1,533,700 context-switches # 0.083 M/sec 182,752 cpu-migrations # 0.010 M/sec 485 page-faults # 0.026 K/sec 40,407,275,913 cycles # 2.199 GHz &lt;not supported&gt; stalled-cycles-frontend &lt;not supported&gt; stalled-cycles-backend 22,019,885,160 instructions # 0.54 insns per cycle 5,302,745,968 branches # 288.616 M/sec 33,297,822 branch-misses # 0.63% of all branches 5.623077264 seconds time elapsed 
I guess I was imagining only transferring the pointer over, but you'd have to do the splitting up and reassembling yourself, and yeah, maybe that's too expensive.
thanks。It works well
I've just downloaded the entire series so far to my kindle. I should make a proper epub version once you're done!
That sounds like something I'd love! Half of my little scripts/programs are things to stick in between unix pipes, so efficient streaming IO is a dream!
I'm very optimisitic that _something_ will happen here after 1.0, because lots of libraries would benefit from this. Basically, as I understand it, the missing piece is the ability to pass "lifetime" parameters to generic types: `T&lt;'a&gt;`, for example. Without this, it's hard to write APIs that work with generic types without copying data somewhere. I actually think this would be an amazing use-case for Rust: Zero-copy parsers can be ridiculously fast, but in languages like C and C++, they're also an open invitation to segfaults and security holes. If Rust's type system gets just a _little_ bit more expressive in this area, it will allow people to write some really cool libraries. To give just one example, BurntSushi has some awesome ideas for [rust-csv](https://github.com/BurntSushi/rust-csv) that would become possible if we could only write `T&lt;'a&gt;`. Keep your eyes peeled. :-)
I don't think so... Does it? I can't say I fully understand Rust's lifetime inference.
Thank you very much!
I'm pretty sure that one elision rule is that if you have unannotated references on both an input and an output, it assumes that they have the same lifetime. Test it out. Try handing it a prompt with a very short lifetime (`"asdf".into_string().as_slice()`), and see if it lets the return value outlive the prompt. Also, it's really bad practice to have a function with such different signatures on different platforms anyways. Just have it return an `Option&lt;String&gt;` like the linux/OSX version.
Update: as [issue #19261](https://github.com/rust-lang/rust/issues/19261) got fixed, the issue I posted has been fixed, too. Now the borrow checker reports error correctly: &lt;anon&gt;:12:45: 12:49 error: `line` does not live long enough &lt;anon&gt;:12 if let Some(caps) = re.captures(line.as_slice()) { ^~~~ &lt;anon&gt;:5:11: 21:2 note: reference must be valid for the block at 5:10... &lt;anon&gt;:5 fn main() { &lt;anon&gt;:6 let re = Regex::new(r".*").unwrap(); &lt;anon&gt;:7 let mut v = vec![]; &lt;anon&gt;:8 { &lt;anon&gt;:9 let mut reader = MemReader::new(b"12345\nABC\n!".to_vec()); &lt;anon&gt;:10 for line in reader.lines() { ... &lt;anon&gt;:10:36: 18:10 note: ...but borrowed value is only valid for the block at 10:35 &lt;anon&gt;:10 for line in reader.lines() { &lt;anon&gt;:11 let line = line.unwrap(); &lt;anon&gt;:12 if let Some(caps) = re.captures(line.as_slice()) { &lt;anon&gt;:13 v.push(caps.at(0)); &lt;anon&gt;:14 // This triggers error: `line` does not live long enough &lt;anon&gt;:15 // v.push(line.as_slice()); 
Wow... I can't believe I missed that. I probably should test on Windows before I release this stuff. I tested on Linux and Mac, but not Windows. Thank you so much. Edit: Also, at least for a String, the lifetime doesn't matter, I assume because it's heap allocated. And it's supposed to return an Option&lt;String&gt;.
Looks neat! Speaking of security, has there been any talk of buffer-clearing (and related) features for Rust? I recall Colin Percival had [an interesting suggestion for a sensitive-data-clearing language feature](http://www.daemonology.net/blog/2014-09-06-zeroing-buffers-is-insufficient.html). A memory-safe language makes this sort of thing harder to exploit. But it's still important if your code calls a non-Rust library. My gut feeling: where security is important, the pragmatic route is to write encryption code in C or assembly, and write a Rust wrapper around that. Barring language advancements, it seems like the easiest way to do stuff like constant-time operation and zeroing of sensitive data.
What optimization level are you using for the Rust version?
The C++ examples could be improved, e.g. why pthread and not C++11 threads, oh well....
Great job! A step closer to a pure-rust version of NaCl, then? :)
This is translation of this article: http://habrahabr.ru/post/225003/ The original article was published on 6 June.
HN is right, this is a propaganda piece :-) (It is bringing out the worst in C++)
You miss the point : most of the time Rust prevent you from doing the worst, while C++ doesn't.
It depends on perspective. I think it is more interesting to look at which language has the best tools for building applications. Borrowed pointers, smart pointers etc are bookkeeping tools to make it easier for the programmer. Comparing the tools in Rust vs C++ would be more interesting than comparing the ways you can shoot yourself in the foot.
This is true but analysers can still catch some problems. if you banned raw pointers outside of 'private' + used a static analyser you wouldn't be far off. its' nice that rust can do things more elegantly though. One of the things I like most about Rust is the expression based syntax - this makes it easier to avoid uninitialised variables, in a way that reduces the amount you had to type. If it's less verbose/more intuitive to write *and* safer, thats an unambiguous win-win. 
Yes, exactly, it's mostly about what most people expect to be compared, and also about how difficult it is to accomplish the other behaviour. What I can remember for myself is that I would very rarely put a single value to be shared via pointers, much more common that it is a struct pointed to, a struct with identity.. not just a value like a complex number. I also figured out a way that I could work around this problem of storing Rc pointers to MyStruct in a HashMap: impl PartialEq for MyStruct { #[inline] fn eq(&amp;self, other: &amp;MyStruct) -&gt; bool { self as *const MyStruct == other as *const MyStruct } } impl Eq for MyStruct {} impl Hash for MyStruct { #[inline] fn hash(&amp;self, state: &amp;mut SipState) { (self as *const MyStruct).hash(state); } } By implementing the traits for my struct in that way I basically say that values of this type will have identity. If this is common, is there a #[deriving] implementation to do this for me?
Compare tooling of a 30 years old language with a "not yet 1.0" one seem pretty unfair to me.
That is truly an amazing error message.
This is just something me and /u/Gankro have been working on recently - it defines an `IntrusiveIterator` which is an alternative iterator trait where the iterator is passed a closure to run on each element, rather than yielding elements. As a result, this can be used for streaming iterators and iterators over complex structures like trees. Using this style of iterator instead of a traditional external iterator speeds up iteration over `BList` and `BTree` about 4 times, but is about the same for iterating over a slice. This library also contains a bunch of iterator adaptors like the ones you are used to (and they have the same use pattern unlike old internal iterators) and a bunch of utility iterators like count and various range iterators. EDIT: You can also see a bunch of stuff we've been thinking about/have planned in the issues.
The same can be said about comparing an alpha language unencumbered by backwards compatibility with a language that has to support 35 years of language evolution. Personally I think both comparisons are ok.
Oh awesome! I am going to try to hook this up to `rust-csv` when I get home and see what happens. :-)
Errr, of course, yes, it's cloning once etc. My bad! I wonder where the perf difference jvns was seeing came from.
&gt; Moreover, this code compiles as if we used restrict pointers in C99 (Rust provides LLVM information as for references uniqueness). It gives the optimizer a green light. This is neat! Can someone provide other features of the language that will potentially result in beating C++ in terms of efficiency?
Well, it's just a library, not an RFC… Many users find this style of iteration convenient, especially coming from a Ruby background, and if it even heralds performance benefits [even if those benefits could probably be leveraged in the normal iterator implementation], there's no reason to condemn this.
&gt; Many users find this style of iteration convenient, especially coming from a Ruby background It works in ruby because ruby has non local jumps. We do not have them in Rust. &gt; and if it even heralds performance benefits It might have for some specialized cases but I doubt it has for the average case. At least in theory it should not have.
Did you try setting the lifetime param like this: |i32|: 'a -&gt; i32 Keep in mind that closures cannot escape the scope where they are created if they capture variables local to the function. It would be easier to give advice if you provided the error messages you're getting. 
`rustc -O`; I used the Makefile from her Git repo directly, you can too. I tried compiling both the C version and Rust version to assembler to compare them, but the Rust version was so much longer and more complex it was hard to figure out where to even start in analyzing what was going on. The C version compiled down to pretty much exactly what you would expect, the Rust version was way, way more complicated. It looks like there's some work left to do before the Rust abstractions are zero-cost.
You should use "unboxed" closures, then you can store either closures or functions in your enum. #![feature(unboxed_closures)] enum Foo&lt;F, G&gt; where F: FnMut(i32) -&gt; i32, G: FnMut(f64) -&gt; f64, { Bar(F), Baz(G), } fn foo(x: f64) -&gt; f64 { x + 1. } fn main() { let bar: Foo&lt;_, fn(f64) -&gt; f64&gt; = Foo::Bar(|x| x + 1); let baz: Foo&lt;fn(i32) -&gt; i32, _&gt; = Foo::Baz(foo); let both = [Foo::Bar(|x| x + 1), Foo::Baz(foo)]; } Sadly, you need to provide type hints in the first two cases because your enum variants are "disjoint", for example constructing the `Bar` variant provides the type of `F`, but not the type of `G`, so you need to fill it with a "dummy". In the future, default type parameters may remove the need to annotate the type (you declare the enum as `enum Foo&lt;F = fn(i32) -&gt; i32, G = fn(f64) -&gt; f64&gt; where /* .. */`, and it should Just Work). HTH!
oh, thats how you're supposed to do it? its not in any of the guides well thanks
Are you against *adding* intrusive iterators (like this, in a library form), or just against moving back to *exclusively* intrusive iterators? I certainly understand the latter, but if you are against the former, why?
I don't like the idea of two incompatible iterator traits in the stdlib.
Slow line iteration comes up from time to time yeah. I had the opportuinty to share my buffered line pseudoiterator in the irc yesterday [(gist link)](https://gist.github.com/anonymous/7fb072ab67339e39ce14). It's a line iterator where each line is borrowed from the buffer, so it only allocates when the buffer grows, not once per line.
How far away is that future? Could really use that feature to simplify my WM code. Or is there a feature gate I can use now?
The code looks great! I like the approach of building your own map which supports an update closure. That is a good mechanism for word counting. Now that we have standardized closures, and there is an effort underway to revamp collections, I would hope that such a method makes it into the standard libs. Buffer is, (totally my opinion here) mostly useless, it sits in some middle ground between slices, which are quite useful, and the Readers and Iterators, which are also useful. I think implementing the Iterator interface for words over StdinReader is also the right approach here. Rust moves values by default, copy is a last-resort kind of thing :) So FnOnce is your only option for not operating on refs (Fn), or Mutable refs (FnMut). I was lamenting just the other day that there isn't a way to tell Rust to copy certain values in when it collects them. I rather like this feature of C++'s lambdas. 
Deriving is very inflexible right now.
&gt; There's absolutely theoretical reasons why this should have performance benefits. That's why I said for "the average case". BList and BTree are not the average case.
Oh yes, totally. Most code won't give a fuck. That said, when you're doing something special, and wanna go fast...
External iterators can be trivially converted to internal ones fwiw. But yes two APIs is an unfortunate state of afairs. Scala does live in this state, though. In theory you could upgrade the `for` statement to make "normal" usage completely identical. The adaptors/patterns for both APIs are exactly the same (internal needs associated types to do `rev` right).
Unboxed closures are still feature gated (see code in the parent comment), but are pretty stable. The stdlib and the compiler are already [using them in like 99% of places](https://github.com/rust-lang/rust/pull/19467). Also the plan is to feature gate and then remove the old boxed closures (`||:'a -&gt; T|`), which I expect to happend in a few weeks time.
That's where continuations would shine.
Yes, that is the second inference rule.
There's a `default_type_params` feature gate, but this particular use with the enum constructor is not yet implement. I asked Niko, and he said it's a planned feature, but we need someone willing to implement it (the core team is pretty busy with other features right now).
im trying to do that, but the compiler is not letting me, keeps saying i have to add `#![feature(unboxed_closures)]` even though i have it at the top of my file. any ideas what is happening?
The motivation makes it very interesting: &gt; Cryptographic primitives require constant time behavior regardless of input. However, this is not easy with usual compilers like llvm.
Do you have the `!`? I bet you're missing the `!`.
What is the effect on ChaCha? It should already compile to constant time code, I'm curious what changes with const time. Oh and it's of course and example where vectorization (I guess by manual implementation) is a big win.
You say it's in the top of the file. It can't be in any file, it has to be in the crate root. Are you sure it's in your crate root?
I am not against adding anything in libraries but I agree with /u/mitsuhiko in the sense that I don't want internal iteration to become widely used in Rust. The ubiquity of external iterators in Rust is one of the single nicest things about the language because they compose so well.
This is the stack overflow issue that got me started on this yak shaving journey: http://stackoverflow.com/questions/27461947/how-to-achieve-equivalent-of-take-while-on-a-slice/27484294#27484294
uuugh... is there a way to post a link AND a summary in Reddit? This comment was supposed to stay at the top...
For the record, internal iterators can compose really well too, as seen by a multitude of adaptors in this repo which are just like the adaptors for `Iterator`. I do agree that I don't think this has to be a language feature, but can live entirely in libraries. Whether that library is in the core distribution, so that core types get convenient internal iteration, is a different, unresolved question to me.
I like me some Rust, but this is Propaganda. Frickin language comparisons..
Wouldn't this be better addressed by working on LLVM, rather than Rust? You could annotate methods in Rust with #[deterministic_control_flow] (or something), and then propagate that requirement down the pipeline, where the requirement is that you never alter the control flow stated by the developer.
No, that is not possible.
&gt; at least for a String, the lifetime doesn't matter, I assume because it's heap allocated. It's not that it doesn't matter, it's that a String owns its own data, so the lifetime will always be correct.
&gt; for a first pass I'm trying to mimic how the existing code approaches the problem. As a meta point, before I read the rest of your post, this will often cause your code to be overly complex. Write Rust, not Ruby-in-Rust. :)
&gt; (from my perspective) immutable field (the string being scanned), and a mutable field (the offset into that string). Rust does not have field-level immutability: if the binding is mutable, it's mutable, and if it's immutable, it's immutable.
Oh, yeah now it works when it's at the crate root
`Scanner::getch` constrains the caller too much. Even though you just wanted to update the offset and return an immutable string slice, it makes the return lifetime (of `&amp;str`) an exclusive borrow and you cannot access to the `Scanner` until the borrow ends. Maybe the simplest fix is to make `Scanner::getch` non-exclusive. This can be done by making it a `&amp;self` method and using [`std::cell::Cell`](http://doc.rust-lang.org/nightly/std/cell/struct.Cell.html) for `offset`. [1] This is possible since you have never modified the `String`, so sharing multiple immutable slices from the same string is fine. If you *have* to update the `String` you may have to introduce a dynamic borrowing via [`std::cell::RefCell`](http://doc.rust-lang.org/nightly/std/cell/struct.RefCell.html). [1] We normally say that `&amp;self` methods are immutable and `&amp;mut self` methods are mutable, but only for the convenience. `&amp;self` methods *can* modify the state with an appropriate definition. Exclusiveness is what really sets them apart.
You should make a text post and link from that instead.
This is a case of the borrow checker being unnecessarily restrictive. It marks the entire structure as "borrowed from" when you get that slice into the `String`, even though the `offset` member isn't borrowed. In general you can get around those restrictions by breaking down `self` into its members and then manipulating them separately, but that doesn't work with this specific design because you need `self` to be intact in order to call `peek` on it. One workaround you could do is to call `peek` twice, once to read the length and once to get the return value.
internal iterators are more natural for some cases. I think they suit writing code which can be parallelized. just swap in a par_map().. change it back and forth to get the right granularity. internal and external have different advantages - I think we should have both.
As a general rule, I divide Rust code into two categories: 1. High-performance code, where it's worth trying to do clever things with lifetimes. 2. Ordinary code, where it's OK to occasionally copy data. Treating all code like (1) means that you're going to spend a lot of time learning arcane Rust details. But if you just want to get something working, you can sometimes save yourself a ton of time by replacing one or two instances of `&amp;str` with `String`. C++ programmers copy memory all the time to avoid thinking about complicated pointer safety issues. Not every casual Rust program needs to be zero-copy! In your case, I'd be tempted to return `Option&lt;char&gt;` from `getch` and `peek`. Sure, you'll pay for UTF-8 decoding, but your API seems to be designed around characters, so it might make sense. If that doesn't work in your use case, then lifthrasiir's advice will explain some of the more complicated options. But mostly, I try to avoid picking unnecessary fights with the borrow checker until I've determined that my `#[bench]` results are unacceptable. When I approach Rust this way, it's just a ton of fun, and I waste very little time arguing with the compiler.
Also, I thought that `Gc&lt;T&gt;` was not ready for use yet (and just use `Rc&lt;T&gt;` under the hood) ?
It's not just not ready, it doesn't even exist anymore.
Actually, I just realized that since neither of your closure cases need to mutate their environment, you can use Fn instead of FnMut. 
Well, there is a work-around: play the ranking algorithm so that the comment stays at the top. Getting it upvoted and its children upvoted is a good way.
collect-rs is now experimentally a consumer of this API through BList: https://github.com/Gankro/collect-rs/pull/17
Nice to see that you took up the issue, did you think about returning `Option&lt;&amp;'a [T]&gt;` from `splice` to avoid the `panic!`? It seems better to avoid it in general: fn splice&lt;'a, T&gt;(left: &amp;'a [T], right: &amp;'a [T]) -&gt; Option&lt;&amp;'a [T]&gt; { unsafe { let left: Slice&lt;T&gt; = transmute(left); let right: Slice&lt;T&gt; = transmute(right); let leftB = left.data as *const T; let rightB = right.data as *const T; if base.offset(leftB.len as int) != rightB { return None; } return Some(transmute(Slice{data: left.data, len: left.len + right.len})); } } I am looking forward to the transformation iterator yielding spliced slices.
Nice. It's interesting. Take While doesn't have to return an Option by the way, if there is nothing to take, the empty slice is the natural answer.
I did not know about `Cell`, and it's exactly the kind of thing I was hoping to learn. Thanks!
Yup, and I think I'll migrate to the same approach as I get more comfortable with the language, and probably even for the final version of this tool. This was mostly about not being willing to give up on understanding when the naive approach I started with didn't work. Must understand!
Yup, returning an `Option&lt;T&gt;` rather than `panic!` is much better.
My end goal with a language is always to learn to write it idiomatically, and no difference here. But my brain learns best with high contrast, and taking a solution I already understand in another language and beginning to port it in the most naive way possible creates a *lot* of contrast, and points me at the most important things to grok about the new environment. So it's mostly a personal learning style/approach.
Yup, my challenge was "what if I want to solve a problem shaped like that", and /u/lifthrasiir's pointer to `Cell` is exactly the kind of possibility I was hoping existed for such challenges.
Try self.offset += match self.peek() { ... } and use early return in the None match arm.
Fair enough!
Oh, one more thing: I find myself wanting to use `&amp;str` simply because it's so much cleaner due to static strings being `&amp;str`. I've felt like so far that using `String` in Rust means sprinkling `.to_string()` all over my code, which is feels subjectively gross to me. Maybe I should just be OK with it?
There's also the CowString option.
You shouldn't use `mem::zeroed` here, it's an unsafe function and there's no need for optimization here.
But that is a stupid comparison to make. You take a language as new a rust and compare it with a language as widely used and old as C++. It is obvious that C++ must retain some backwards compatibility while rust can just do whatever.
Got it.
I've answered it, and yes it is okay to link SO questions here. I actually like to think of it as counter-exposure to get people answering Rust questions on SO, so that as Rust grows in popularity we aren't swamped by questions that would be better served by SO's format. :P
What is the connection between the recently-added [higher-rank trait bounds](https://github.com/rust-lang/rfcs/pull/387) and higher-kinded associated types? It seems to me the `for &lt;'a&gt;` thing could be expanded if there were an HKT RFC for it, is that the biggest obstacle?
Yeah, `String` is basically the owned version of `&amp;str`. Most input parameters will be `&amp;str`, because you don't need to copy parameters. But when you try to use `&amp;str` for _everything_, you're saying, "No, I don't need to allocate new memory for this string, because I have a very clever line of reasoning that says it just _happens_ to live long enough." And then the borrow checker says, "Oh, yeah? Prove it." This is how you end up fighting with the borrow checker. :-/ The solution is to say, "You know what, maybe I'm OK owning my own copy of this, rather than trying to prove crazy cross-module ownership invariants." A certain amount of `to_string` and `as_slice` may be ugly, but it's a sign that you're avoiding intricate lifetime coupling. 
Your library doesn't expose anything publicly. If you look at [lib.rs](https://bitbucket.org/g_morgan/xcom1-lib/src/282246c730f5a427b0e69876610724071e6d7991/src/lib.rs?at=master), it contains only 2 modules, neither of which is public. Perhaps you meant to use `pub mod ...`?
Thanks, I was just wondering as I saw golang seemed to use atomics. (forced to use go in cloud computing course, not a bad lang imho)
Every IO call has an overhead to it. The C version reads every character separately, and prints it out separately. emk's version reads and writes in chunks via buffers, which is faster in this case, since the bottleneck was in the syscalls.
There are two types of posts; self posts and link posts. Self posts include text, links posts do not. You can include links within self posts, in the body of the post, just like you can with comments. So usually, if you want some text and a link, that's the best way to achieve that effect.
The `splice` function isn't memory safe. It doesn't respect the `int::MAX` limit on object sizes. The comment about a potential overflow for the `int` cast isn't correct.
I found out today that the arch package I've been using (`rust-nightly-bin`) no longer includes the epubs of the documentation, so I set up a cronjob that updates my local clone of the rust repo, builds the docs, and pushes them to this github repo, in case anyone else doesn't want to build the mammoth just for a few epubs. I hope I'm not the only one who likes to browse the guides on his kindle :P
Ah so those declarations need to be made pub as well? Thanks, that seems to have cleared most of my warnings.
Yup, makes total sense. I'm slowly learning the right trade-off here.
&gt; Maybe because the C version reads and write a character per-byte basis, while the Rust version fills the buffer and uses it? Yes. The C version is bounded by the syscalls. Once you use buffers the IO subsystem takes over as the main cost, and performances flatten as the overhead (from syscalls and plain program code) dies down and the language itself becomes significantly less relevant (e.g. you should get similar performances in Python by reading chunks of stdin and writing those to stdout)
&gt; Inevitably, if someone is going to use this for more than non-trivial work, then the language will need to expand and become more expressive. You don't need that many language features to cover most important crypto primitives. They are designed to be implementable as electronic circuits, so the algorithm itself can usually be understood as an abstract circuit composed of arithmetic / bit shifts, table lookups, permutations of arrays, and a few other simple parts. (This is particularly true for symmetric cryptography, less so for public key.) [Cryptol](http://cryptol.net/) demonstrates several benefits from representing crypto algorithms this way. LLVM is all about complicated non-local transformations, which is exactly what we want to avoid here. If you just want to compile simple expression trees in the most straightforward way, bypassing LLVM codegen seems very sensible.
This is so cool! Just trying to describe it succinctly is like wrapping a Möbius strip of code around and around my mind. It's... a new compiler backend, for a Rust dialect, reusing rustc's parsing / name resolution / trait resolution / type checking / error reporting / etc. And then the compiled instructions are seamlessly inserted into the surrounding Rust program. And the whole thing is under 1,000 lines and it's a library I can just use. :D
this one perhaps: https://air.mozilla.org/bay-area-rust-meetup-august-2014/
These two lines are more of less equal; they both give you a mutable reference to `buffer.lines`. let ref mut lines = buffer.lines; let lines = &amp;mut buffer.lines; 
I believe the `ref` keyword is used in pattern matching and destructuring cases where you have an implicit assignment. let Point { x: ref xx, y: yy } = point; // xx is a referance // yy is a copy or move I don't think it's clear where you'd use `&amp;` in the above code. I'd like to see `ref` removed if someone could fit `&amp;` in the pattern matching and destructuring cases. 
One way (possibly the only way, depending if LLVM has any option to emit diagnostics) to detect vectorisation is to look for vector instructions in the asm or LLVM IR, via `--emit=asm` and `--emit=ir` respectively. I don't know of anyway to get the compiler to tell you why a loop isn't vectorised (again depending on LLVM).
It should be possible to avoid the `collect`, and so reduce the number of allocations, by iterating in reverse: for word in s.split(' ').rev() { ... }
I don't think it will be possible to do this in-place without using `unsafe`. The unsafe version relies on the fact that you can byte-swap the whole array, and then go through and byte-swap each word back again, leaving you with a valid string. But there's no way for the compiler to know you're going to do this correctly; byte-reversing a string is a very unsafe operation, as it's not going to be guaranteed to be valid UTF-8, and you can't reverse UTF-8 by swapping characters, as characters are of variable width. I suppose one thing you could do is convert your string to `[char]`, and then do the reversing on that. Depending on how you count it, this could be safe and reasonably fast; converting your `&amp;str` to a `[char]` is an allocation that will likely take up most of the time, but if you can do that outside of your inner loop then it's reasonably fast. Inside the loop, the allocation will kill your gains. Here are the results, with optimizations on: $ ./byte-reverse --bench running 4 tests test bench_reverse_words_bytes ... bench: 57 ns/iter (+/- 5) test bench_reverse_words_chars ... bench: 65 ns/iter (+/- 2) test bench_reverse_words_chars_alloc_in_loop ... bench: 202 ns/iter (+/- 12) test bench_reverse_words_str ... bench: 183 ns/iter (+/- 55) test result: ok. 0 passed; 0 failed; 0 ignored; 4 measured Here's the code (along with your original code): fn reverse_words_chars(line: &amp;mut [char]) { line.reverse(); for mut word in line.split_mut(|ch| *ch == ' ') { word.reverse() } } #[bench] fn bench_reverse_words_chars(b: &amp;mut Bencher) { let line = String::from_str("this is a string of words"); let mut chars: Vec&lt;char&gt; = line.chars().collect(); b.iter(|| { reverse_words_chars(&amp;mut *chars); }) } #[bench] fn bench_reverse_words_chars_alloc_in_loop(b: &amp;mut Bencher) { let line = String::from_str("this is a string of words"); b.iter(|| { let mut chars: Vec&lt;char&gt; = line.chars().collect(); reverse_words_chars(&amp;mut *chars); }) } However, I think that this problem is one example of where it's reasonable to use `unsafe`; if you have some low-level operation on strings that can be done in a way that you can prove is safe (byte reversing the whole thing, then byte reversing back each word), but there's no good way to prove that to the compiler, then using a very small, easily verified `unsafe` block in your inner loop is reasonable.
Is Option still better if the function is intended to go into inner loops that will hopefully be optimised away? If using interators is significantly slower than the C style implementations people would have written with similar effort due to error checking, I will have a very weak case to recommend this machinery for std. Then again, maybe people would benefit from using machinery that correctly handles the overflow and zero sized type edge cases even if it's a bit slower...
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Register allocation**](https://en.wikipedia.org/wiki/Register%20allocation): [](#sfw) --- &gt;In [compiler optimization](https://en.wikipedia.org/wiki/Compiler_optimization), __register allocation__ is the process of assigning a large number of target program [variables](https://en.wikipedia.org/wiki/Variable_(programming\)) onto a small number of [CPU](https://en.wikipedia.org/wiki/Central_processing_unit) [registers](https://en.wikipedia.org/wiki/Processor_register). Register allocation can happen over a [basic block](https://en.wikipedia.org/wiki/Basic_block) (*local register allocation*), over a whole function/procedure (*global register allocation*), or across function boundaries traversed via call-graph (*interprocedural register allocation*). When done per function/procedure the calling convention may require insertion of save/restore around each call-site. &gt; --- ^Interesting: [^Chaitin's ^algorithm](https://en.wikipedia.org/wiki/Chaitin%27s_algorithm) ^| [^Instruction ^scheduling](https://en.wikipedia.org/wiki/Instruction_scheduling) ^| [^Rematerialization](https://en.wikipedia.org/wiki/Rematerialization) ^| [^Run ^time ^\(program ^lifecycle ^phase)](https://en.wikipedia.org/wiki/Run_time_\(program_lifecycle_phase\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmwcxq1) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmwcxq1)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Compile with `rustc -C remark=all` and that will show you all of LLVM's [optimization remarks](http://llvm.org/docs/doxygen/html/classllvm_1_1DiagnosticInfoOptimizationRemark.html).
`isatty` is still useful. But generally and what most programs do is just check if you have arguments and then read from stdin if they have none.
An example where yours won't work: wc filename &lt; /dev/null Also its sometimes useful to take input from a terminal.
I use Docker with OSX's boot2docker, you will compile on the target OS already.
It works for me, ./pipe_example &lt;/tmp/hello.txt # works as pipe ./pipe_example /tmp/hello.txt cat /tmp/hello.txt | ./pipe_example 
`&amp;` and `ref` are sort of opposites in pattern matching: let &amp;x = &amp;3i; // x is now 3. let ref x = 3; // x is now &amp;3. Edit: hm this example is a bit more symmetric: let &amp;x = &amp;3i; // x is now 3. let ref x = &amp;3i; // x is now &amp;&amp;3.
Try running the second with no stdin like what would happen in a script with no controlling tty.
Because `*foo` doesn’t capture the full meaning of `ref`. `*` means ‘dereference this pointer’ (or ‘de-pointerify this’), so `*` in a pattern should mean the opposite, in the same way that everything else is backwards in patterns, right? But `ref` doesn’t mean ‘pointerify this’, it means ‘*referenceify* this’, specifically creating a `&amp;` reference. If `ref` existed in expressions, then it would actually dereference `&amp;` references and nothing else. It’s unfortunate, but there actually *is* no parallel to `ref` outside patterns. If we had a separate operator for dereferencing `&amp;` and `&amp;mut` references alone, then we could use that for patterns, but we don’t and I don’t think we should. The other option is to remove `&amp;` and `&amp;mut` in expressions and patterns and use `box` instead, and require that all types that can be dereferenced can also be `box`ed. That would mean that `box` would be used to construct `Box`, `&amp;`, and `&amp;mut` in expressions, and `*` would be used to construct all of those in patterns. Unfortunately, that would probably result in inference problems where the compiler can’t figure out what type of pointer to use. Also, `&amp;` and `&amp;mut` behave quite specially in a way I don’t think could be emulated by a trait that would be shared between *all* pointers. Using `*` for `ref` patterns also creates problems when you try to replace `ref mut`. Would it be `*mut` or what? I think that `ref` is a good syntax to stick to for now.
What they mean is that in the unix world it's pretty common for commands that work on files to read from stdin if no file is supplied. `wc` does actually work that way: $ wc -l test.c 22 test.c $ wc -l &lt; test.c 22 Same for `cat`, `sed` and many other commands. Those commands executed directly from a terminal without file parameter and without piping anything in will still wait on stdin for some input: $ wc -l foo bar baz ^D 3 One might consider that behaviour bogus (especially since the user doesn't get any prompt and it might look like the command froze) but I actually find it useful, for instance it lets you paste a bunch of text and the command will work on it. It would actually annoy me if a command tried to be clever and behave differently depending on where stdin comes from. On the other hand, what I've often seen is commands that check if stdout is a tty or something else to change the output to either something human readable or more easily machine-parseable. `ls` is one such command. I think that's generally more useful and "standard" (and a complete hack because the unix pipes are streams of byte instead of structured data, but that's an other problem altogether).
That's the confusing part, `ref` by itself actually should mean **dereferencing**, not **referencing** because it's on the other side of the expression I also don't understand why `mut` comes after instead of before. `&amp;mut` is mutable, but `&amp; &amp;mut` is not? wut? If anything, it should be `mut&amp;` which is clearly mutable and `&amp;mut&amp;` which is clearly not (the first thing decides the mutability)
I think the order of &amp; and mut is correct, it's the contents that's mutable rather than the pointer in the case of "&amp;mut" : let x = &amp;mut 5i; *x = 6i; // works x = &amp;mut 8i; // Does not work, x is not mutable Whereas: let mut y = &amp;7i; *y = 8i; // Does not work, the reference is immutable y = &amp;9i; // Works (well, there is a lifetime error, but w r t mutability it works) 
I doubt this is good timing for speculating about alternative syntaxes giving the upcoming 1.0 release :-) , but what about having the &amp; on the other side instead of using ref, like this: match &amp;foo { &amp;Some(k &amp;) =&gt; do_something(k), &amp;None =&gt; do_something_else(), } It then has the same order as normal let statements: let k = &amp;foo.unwrap() In both cases, k ends up with a reference to foo's inner type.
I was looking everywhere for the amp variable. Now I feel silly.
nice to know, thanks.
How about the reverse? Can I compile a binary for use on OS X from Linux? I've tried cross compiling, but apparently I need OS X's version of `ar` to produce the final executable (if it's lto'd) or `ldd` (if it's not lto'd).
 unsafe{raw::slice_bytes(s.as_slice(), l_index + 1, r_index - 1)} s.as_slice() has many methods, including slice(a, b) and slice_chars(a, b), depending on how UTF-8 aware you are. No reason to be unsafe here?
got it. Thanks.
It's not even an optimization by any means, and you risk a lot by dropping to unsafe.
I think at the time I first wrote that it was the function slice_bytes that was unsafe. Apparently now it's deprecated, so I will probably need to change that.
On my system rust's `fill_buff` attempts to read 65536 bytes at a time, so the following C program should perform similarly (it's not standard C but it should be POSIX, I can't be bothered to remember how the bad standard C IO library works): #include &lt;unistd.h&gt; int main() { char buf[0x10000]; for (;;) { ssize_t n = read(0, buf, sizeof(buf)); if (n &lt;= 0) { break; } write(1, buf, n); } return 0; } On my system on a very quick and unscientific benchmark both the optimized C and rust versions run at the same speed (160MB/s running `dd if=/dev/zero bs=65536 count=10000 | ./test` ) Is there any reason there's no method in Reader to read into a `&amp;mut [u8]` without copy? That would be equivalent to the C code above and IMO easier on the eyes than emk's version (and you'd be able to chose the buffer size to optimize for certain behaviors). It's something I do very often in C when I need to do low level "block" IO. Case in point: augmenting the buffer size to `0x100000` (16x bigger) in the above C code gives me a marginal improvement (from ~160MB/s to ~163MB/s). Not very impressive, sure, but significant.
OK thanks I'll give that a shot, I wasn't aware of that directive. The actual implementation uses multiple objects (actually `enums` and `struct-variants`) but for simplicity sake the example is small :) The issue I see arising with `#[must_use]` is optimally I'd like to find a way to condionally enforce usage for consumers of this lib. I.e. imagine a `gender` field of `Person` and only females must use a particular property that isn't applicable to males (again just an arbitrary example).
&gt; But is there a way to check at compile time is someone didn't set a property (i.e. age for example)? If a property is mandatory, then I'd put in the constructor: `Person::new(age)`. If you want to raise a warning everytime a certain property is not set, then you'll have to write a compiler plugin (lint) for that.
/u/jostmon, Random1DollarTip wants to send you a Bitcoin tip for 2,971 bits ($1.00). Follow me to **[collect it](https://www.changetip.com/collect/263901).** [ChangeTip info](https://www.changetip.com/tip-online/reddit) | [ChangeTip video](https://www.youtube.com/watch?v=_AnfKpypMNw) | /r/Bitcoin
Sure, I'm all for abstraction. That's why I think achieving this makes more sense at the right place in the compiler stack. Which, *naively*, seems like codegen, not front-end syntax. So, I don't have some strong, heels-dug-in stance on this. I'm just giving my opinion. OP obviously thought that this was valuable, and so he/she went ahead and did it. Maybe that's the right balance. If it scales up to something larger, I think the balance may shift toward imposing constraints on codegen in a language that is more widely used. Especially since, inevitably, goals such as type safety will (should) be important for something like crypto code. Then what should OP do -- reinvent Rust, but with constraint control flow? Or integrate constrained code flow into Rust?
For a single variable binding like in your example, one of them would be unneeded, that is true. But both ref patterns and &amp; operators can be arbitraly nested in patterns and expressions, and then you get constructs that are very much not interchangeable. :) Compare: let t1 = (&amp;a, &amp;b); let (ref c, ref d) = t2;
I considered that but in a real world example with many fields, with similar types constructors get unwieldy when consumers have to have intimate knowledge of the constructor signature and the order of parameters. let p = Person::new("Jack", 30u, 69u, "JN"); // vs... let p = Person::new(); p.name("Jack") .age(30u) .initials("JN") .height(69u); One is far more approachable, readable, and maintainable than the other. Also certain fields are only mandatory based on other fields set...if that makes sense :P
If all properties are public and have to be set, then just use: let p = Person { name: "John Dee".to_string(), initials: "JD".to_string(), age: 44u, height: 66u }; Otherwise you can use tuple structs to increase type safety: struct Name(&amp;str); struct Initials(&amp;str); struct Age(uint); struct Height(uint); let p = Person::new( Name("John Dee"), Initials("JD"), Age(44u), Height(66u) ); 
&gt; Also certain fields are only mandatory based on other fields set...if that makes sense :P Then you most likely want to use some kind of enum. Having fields that are only used in certain cases are going to bite you quite fast. 