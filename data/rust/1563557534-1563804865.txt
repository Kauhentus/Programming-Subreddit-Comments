In the blog post that talks about the performance differences, they identified several of the places where the difference came from. They tracked it to things like "a buffer gets copied in openssl that doesn't in ring", and not to things like intentional slow downs.
&gt; I want to code Rust on laptops and Raspberry Pis and such too. I agree that laptops are an important target for fast compilation, but RPis can probably be cross compiled?
Well said, but I don't believe that off puts the inherent risk of ground up development for a sensitive project with a developing language. Even if you win the technical argument with those in the know, if anything should go wrong, the business folks are going to blame it on the IT team using a "new language" and that's a train you won't be able to stop.
Yes, I was just trying to get beyond the idea that "`unsafe` is bad" or "let's use the number of `unsafe` keywords as a metric". If the concept of "safe `unsafe`" code seems contradictory to anyone, then they haven't understood it yet. I agree that soundness is a better way of talking about it.
Yeah I was referring more to Go there. Could've worded it better.
Go has some other compilation performance benefits too, aside from immature optimizations, like its imports and syntax.
Cool. I'm a Hong Konger and even though I mostly use English for tech-related stuff, it's still nice to see Traditional Chinese being added to the Rust website.
OpenSSL doesn't do simplistic "let's sleep for a random time" countermeasures against timing attacks. But it *does* implement various TLS options that can only be implemented safely through extremely inefficient computation. One example is the countermeasure for padding oracle attacks that have been known about since 2002. The [countermeasures were introduced in OpenSSL](https://twitter.com/agl__/status/669182140244824064) circa 2013, and then shown to have *an even worse* [bug in 2016](https://blog.cloudflare.com/yet-another-padding-oracle-in-openssl-cbc-ciphersuites/), as well as accidentally [regressing entirely](https://github.com/openssl/openssl/issues/1438) (stuff like this is, to a first approximation, basically untestable without significant concerted effort). rustls avoids this by not implementing those options. But in any case this benchmark did not target these codepaths in OpenSSL.
That's doable with GStreamer, end to end, and going to be less than 50 lines of code probably. That's a pretty standard task and basically only needs a "uridecodebin ! videoconvert ! multifilesink" pipeline in its simplest variant. If you can wait until Sunday evening then I can send an example. Otherwise ask in #gstreamer on the Freenode IRC network.
Forgot to add, you can find Rust examples here: https://gitlab.freedesktop.org/gstreamer/gstreamer-rs/tree/master/examples The launch.rs example would be a good starting point, only needs a specific pipeline. The one I mentioned above, plus setting the input and output locations.
done
delete sccache cache and rebuild, that fixes it for me, had this once
Benchmark games atleast
Even if he’s not that up to date with technology and his technical team did brief him, the technical terms flowed perfectly. It sounds like he actually knows what he’s talking about. And then the Libra guy doesn’t know shit.
Here is a radical idea: let people write their code the way they want to, be it using unsafe, or in C, or sync or async, or Windows only or cross-platform, or proprietary or GPL or MPL. You shouldn't be harassing or bullying people just because their preferences or priorities are different from yours or the wider community.
In my opinion the real gain is not here. You can always devise a fast an reliable code in C for those computations. And Rust won't prove better. This kind of game of micro-benchmark isn't fair nor realist. But try to write a concurrent program for a real complex problem and there you'll see how Rust is more convenient, more reliable and more efficient than C.
Thanks
Nice to hear that we're adopting languages, which help reduce some risks. Now we need safe hardware!!
It's these people are doing their job.
r/rustjerk is a *very* pro-rust sub, dedicated to Rust evangelism.
Neither left or right codes look like code written by anybody experienced. This isn't C++ vs Rust.
This touches on the need for better crate review and trust models. `std` has quite some `unsafe` (and is every now and then found unsound), how do you assess it's standard?
Apart from the fact that the code looks like shit you're not even consistent in how you name your functions. Rust functions should be named in snake_case https://doc.rust-lang.org/1.0.0/style/ There also is an autoformatter called rustfmt you can use that may tell you stuff like that (Heck maybe even rustc does)
You may gain even more if the disk is NOT an SSD. For spinning drives, the disk-arm scheduler is pretty important, but powerless if requests come one by one.
thanks. sure, I'll try to figure out how to use gstreamer until Sunday too. I need the base and the video crate then?
I don't know if it applies, but looking at the use of both languages for embedded might be interesting. Go technically can run on embedded, but it's nowhere near Rust in terms of real world or professional use.
rustls uses [ring](https://github.com/briansmith/ring) for the crypto-level things. Which works to mitigate those issues. It specially avoids a lot of "fancier" things openssl does which increase crypto-throughput, but can lead to timing attacks. It also (where possible) avoids `unsafe`/`asm` as those become maintenance disasters in the long run. It doesn't shun them completely, as they are needed in a of cases. Ring's author has worked with the TLSv1.3 standardization committee on a few issues, and has a background in cryptography so I generally trust their advise/implementation. To address the main issue. Timing attacks are complex, it is a complex implementation detail as optimizing compilers are your enemy. I've [authored crates which have attempted and failed](https://github.com/valarauca/consistenttime) to do this. If you'd like to know more I previously created writeups [here](https://github.com/klutzy/nadeko/issues/4) and [here](https://github.com/rust-lang/rfcs/issues/1814) which get into it the details.
&gt; congress people ask about if Facebook can see their data when texting on WhatsApp, and why Trump's face comes up when you googl3 "idiot". I have hypotheses that let me sleep at night about this. Look at it with “House of Cards” kind of thinking. They’re after something. A reaction from someone. They’re asking what a typical person would inquire about. It makes sense that they would be after answers that would either soothe or enrage their audience. They’re poking at the fire hoping some embers fall where they shouldn’t. It’s a manipulation game. It’s also a way to fuck with Trump. A way to publicly call him an idiot on record without “actually being the one saying it”.
Thanks. That would apply very well
Jesus, is this how you talk to people in real life?
I mean, sure, the if statements can be replaced with match I guess. But what variables do I even need there? Just alias all of the member variables for my struct? I have no intermediate variable to compute.
Reading this reminds me of Microsoft's experimental Midori OS http://joeduffyblog.com/2015/11/03/blogging-about-midori/
based on the great suggestions by the parent post i remembered [this video](https://www.youtube.com/watch?v=B5xYBrxVSiE) that might help you with some ideas.
We had Joe keynote RustConf a while back for exactly this reason!
Yeah that's how things "Go". (Just had to do it.)
I don't know your data structures (which probably are most of the problem) so I won't rewrite the code for you but I really suggest you look at the code of the most popular Rust crates.
It's an implementation of poker, but like board is just a vector or cards, there's nothing really complex going on in the data structure department. One way or another I do have to burn and turn the flop, I have to post the blinds, and update currentTurn and currentBet, and either all of those accesses are done with self, or they're done with an alias I guess, as far as I understand. Unless there's some complete overhaul that has to be done because the current way it's written is way off or something
Using match to cover the bettingRound states would be more idiomatic: match self.bettingRound { BettingRound::Preflop =&gt; { ... }, BettingRound::Flop =&gt; { ... }, } You'd probably also do well to add some helper functions that ensure your invariants: fn advance_turn(&amp;mut self, refpoint: u8) { self.current_turn = (refpoint + 1) % self.numPlayers; } That way you've single-sourced the logic for ensuring that changes to the current\_turn are always in the range of 0..numPlayers. &amp;#x200B; I'd make other suggestions, but I don't know anything about poker, so I can't readily suggest refactorings relating to the button or blinds that contain their behavior better.
Perfect. Thanks for the vid
You could probably get by with a single socket Threadripper system too. The new ones are supposedly going to have 64 cores.
That's cool. Is this it? https://www.youtube.com/watch?v=CuD7SCqHB7k
He promoted actual Bigfoot erotica on Instagram, but it wasn't a book written by him. You're right that his book is just regular Bigfoot hunting stuff.
Looks like on the Rust side initBettingRound is a member function of some struct, whereas on the c++ side it's a free function? If you wrote the C++ side as a member function you would have `this` in every place you use `self` on the Rust side.
I’ll start one with you. I’m in the area.
I agree with the refactors, that match is pretty nice (Some googling shows that I can use "|" for or in pattern matching, which is awesome for doing Turn | River =&gt; {} as they both involve the same action). But, there's still a "self." prepending literally every variable; my main question is what exactly am I doing wrong for there to be so much self in my code?
Smart people aren’t ones who know everything, they are people who know what questions to ask and what problems to solve.
When I have a numeric variable for which I know the maximum value, I often try to be clever and use the smallest reasonable type that fits, thinking that it may save resources. However, if I have to total up a collection of these small variables, it seems like there is no way to do so without first converting them into a type with more capacity (even though to me it makes sense to add e.g. `u16 + u8`, the compiler doesn't like it even with `.fold`). This seems like it may negate any space benefit that I've gained by using the smaller type in the first place. Does it? And if so, would it be more idiomatic to just create the initial collection with the larger type (to save effort doing type conversions later), even though I know its maximum value will never be nearly that large? As a toy example, if I know that the elements of `foo` will always be nonnegative and &lt;256: [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4225ac968e64c6d4841636ad6823ab61) fn main() { let foo: Vec&lt;_&gt; = (0_u8..255).collect(); dbg!(foo.iter().map(|&amp;n| n as u16).sum::&lt;u16&gt;()); dbg!(foo.iter().fold(0_u16, |acc, &amp;n| acc + n as u16)); }
Yep!
... it's not clear why yet, but very interesting!
On the self thing. It's called "explicit self" or "explicit this", versus C++ which uses "implicit this." C++ is actually the odd duck out in supporting it. So you're just going to have to live with it. In many cases, implicit this is considered a bad thing. Just keep in mind, Rust isn't object oriented.
Not necessarily. I started with C and transitioned to C++ by basically just writing C and compiling with a C++ compiler, that’s before learning much of the C++ idioms. So I would C++ a continuum of C and would lump them together. They also share a lot of the same ecosystem and build system.
Nope. You only need to explicitly use `this.` when you've got ambiguity.
I wouldn't say it's wrong per-se, but Rust intentionally omits the magical `this` to be more explicit and avoid C++'s complex name resolution rules. In general you will notice that Rust tries to eschew "magic" wherever possible; the primary exceptions are automatic deref coercions and lifetime elision. A bigger problem with your code that I see is the amount of repetition and nesting, which could be solved by a good amount of refactoring. With less nested code and repetition, and better encapsulation, you would not notice `self` quite so much.
The compiler also assumes that it will never happen within `unsafe` blocks as well. The Rustonomicon stresses that [transmuting a `&amp;` to a `&amp;mut` is *always* UB](https://doc.rust-lang.org/nomicon/transmutes.html). What `unsafe` lets you do is dereference raw pointers, which are allowed to alias. While I can't find an explicit statement that using a raw pointer to write to an address that's aliased by `&amp;` is UB, I suspect that writing through any pointer that's aliased by a reference (`mut` or otherwise) is UB: the compiler assumes the value behind a reference won't change between accesses unless an `UnsafeCell` is involved.
They put every dependency in their repo(s), right? If so... Rust has just become an Android dependency?
This reminds me of Microsoft's experimental Midori OS http://joeduffyblog.com/2015/11/03/blogging-about-midori/ Joe Duffy even spoke at RustConf 2017 https://www.youtube.com/watch?v=CuD7SCqHB7k
This reminds me of Microsoft's experimental Midori OS http://joeduffyblog.com/2015/11/03/blogging-about-midori/ Joe Duffy even spoke at RustConf 2017 https://www.youtube.com/watch?v=CuD7SCqHB7k
It could still be vulnerable to attacks such as [SMACK](https://mitls.org/pages/attacks/SMACK), though. Crypto is a complex beast and memory safety is nowhere near enough to ensure its correctness.
Parts of Fuchsia are written in Rust in case they are starting to integrate Fuchsia technologies into the Android platform now...
Why specially thoose 2 languages? What are you looking to prove ? Comparing both on 'perf' have few interest. It's like comparing Java and JavaScript ... Rust and go, both aims to beat C++ at system level programming but each approach is totally different. Rust thesis is 'C++ is hard because it is unsound and unsafe' so Rust focus on safe and sound programming, with a memory model that avoid garbage collection and manual memory management. The last point is important because other langage like OCaml is also as fast as C++ and safe and sound but is garbage collected and so have a bigger memory blueprint than Rust. Go thesis is 'C++ is old style programming' and Go provide a way of programming closer to script languages. It is sound but less safe than Rust (Go type system is weaker) but provide built in green thread implementation that make easy and fast to do async programming. So Rust is focus on safety and code maintainability while Go is focus on programmers efficiency.
&gt; Crypto is a complex beast and memory safety is nowhere near enough to ensure its correctness. That's certainly true, but Heartbleed had been around for a long time before anyone noticed it, which is troubling given the ubiquity and importance of OpenSSL, and I if I understand Heartbleed correctly it can't occur if you use non-unsafe Rust.
Java is using it too, btw
Actually I took the two because I programmed go for like 4 years and started using rust for a bit. It was way harder to learn, but I think it pays off. For many things I wrote in go, rust is just more efficient. It's faster and from what I saw for now needs less RAM and CPU. Therefore I try to figure out what is better for which sort of task.
gopher's answer is the most correct one, but I think there's a secondary contributing factor here, which is whatever type this method is on has some of the characteristics of a [god object](https://en.wikipedia.org/wiki/God_object) \- looking at initBettingRound, there's strong sense of there being a single actor that's twiddling all the bits, controlling all the state. That actor winds up needing to know too much, and is exposed to too much complexity. Refactoring to separate concerns won't make all the "self"s go away, but will make them less of an impediment to readability and maintainability.
But the question is what it is a dependency of.
What does this mean?
I trust `std` because, though I recognize that all humans are fallible, I trust the Rust team's standards for determining when `unsafe` is necessary, and their standards for code review. Plus, `std` and the crates maintained by the Rust team are a bit of a special case, since their whole *purpose* is to provide a trusted base of safe abstractions that 3rd-party crates can build around.
Rust is in a better position to hedge against SMACK than other languages imo, but yeah you don't just get it for free. Still, because of Rust's encouragement of enums, I think *idiomatic rust* will be less likely to have issues around invalid states.
Honestly, from my anecdotal experience it seems to be ridiculed much less than I would have expected for such a "new popular kid on the block" language.
&gt;Edit: to complete the thought, maybe # of repositories is a better metric? Or depending on what exactly you're trying to measure, the number of users/organizations the repositories belong to.
That's a nice little presentation, thank you for sharing! I find one part especially interesting: are we using the right API for the GUI stuff to begin with? Clearly, the current path-based one is *hard* to implement on GPUs (even if possible). Leaves an open question if there is a nice middle ground between what there is today and just raw triangles.
Okay, so long as they put a big notice at the top of their repository and in the docs saying that they are not respecting Rust safety conventions. Then everyone can keep away -- no problem. However if you write unsafe `unsafe` code, then you've also broken your programmer's contract with the compiler, so anything could happen on upgrading the compiler.
&gt;or being at risk of e.g. not getting security fixes of some libraries (because the author might decide to depend on the last compiler all the time) is a clearly a no-go But then, without updating the compiler, you don't get any fixes for the compiler and standard library. Not that security issues in the standard library are common, but really the same concern applies.
I think that's mostly a result of a) not overselling it in the first place as the answer to everything, b) being *fairly* conservative in only incorporating ideas that had already proven themselves at least in a research setting, and c) making it clear that the main practical target was building a better web browser, one of the most daunting undertakings known to man. a) avoided the sort of backlash Sun's initial marketing brought down on Java, b) avoided accusations of living in cloud-cuckoo land, c) avoided the "yeah, nice Fibonacci function, what else you got?" reflex that overly-pure functional languages tend to provoke.
I think this doesn't mean anything concrete. They can remove it back at any minute. I've seen some other libraries included in the tree and then removed at next android version.
Update your version of sccache, if that does not fix it file a bug with sccache.
Yeah people can write code however they want, it's true. But if they are writing it for the purposes of providing it to a community that will use it, then they'll have to start taking that community's needs and preferences into account. This can be a pretty thankless job, which is unfortunate.
It really depends on where you look; it gets \*nasty\* in several corners of the internet. But yes, in many places things are also pretty positive.
I think that is a good question indeed, and I believe the answer is yes, based on the fact that I believe a good GPU implementation of the traditional 2D graphics API is possible. However, that last is a claim that requires evidence. As I'm sure you know, we're working on it. Observers should check back in a couple of months to see what progress we've made. If it's not looking good, it makes sense to take a more critical look at this question. But I'm optimistic.
&gt; This seems like it may negate any space benefit that I've gained by using the smaller type in the first place. &gt; &gt; Does it? No, because the widening is done lazily and is basically free on modern hardware. The second and third statements are effectively the same. Using the smallest element type suitable is generally a good idea when storing a large number of elements because more are loaded per cache line.
Right, but that can be said for every language with the slightest bit of popularity. My feeling is that it's not as prominent as I would have thought.
I have some revelations on the use of unsafe in the ecosystem that I should get around to publishing. It's one of the numerous items on my Rust to-do list.
It's hard to judge, but I get the feeling this would be a lot cleaner and more idiomatic if you broke up some of this state into different structs, possibly implementing a BettingRound trait. &amp;#x200B; It might not apply directly to this, but [this is a great article about state-machines in Rust](https://hoverbear.org/2016/10/12/rust-state-machine-pattern/) (\*), and I think it'll help get a better idea of how you can use *types* to handle flow. &amp;#x200B; \*note: this is from 2016 so it is very old in Rust-years, but it's still generally accurate.
As someone else mentioned, I'm not sure that's a good comparison. For this sort of simple computation C and JavaScript might as well be the same language (perhaps even in terms of performance, since it's easy to infer types and optimize). Implementing parallel algorithms would be much more interesting. Go and Rust both prioritize parallelization in the design, but in a fairly different way. Implementing generic data structures seems like a clear win for Rust, since Go lacks generics (I believe they are now planning to add those?). That said, I haven't tried to do that in Go, so I don't actually know what this is like in practice (it's certainly a pain in C). Designing web apps is a fairly high priority for Go, so it might be better suited for that. Notably, the standard library includes much of what is needed. Is it possible to use Go for embedded development? I think either it's currently not, or probably fairly poorly supported. `![no_std]` Rust isn't perfect, but it's a fairly prominent option in this area where C and C++ are the main competition.
What was ridiculed was zealots constant bashing to “RITR” aka “rewrite it in Rust”. That was idiotic and was raising the hostility to the Rust and was needless and brainless attempt to make something to use “new shiny things”.
``` Developer borrowed here ---v ^--- but not backfilled here
I saw this on Hacker News: [https://news.ycombinator.com/item?id=20480723](https://news.ycombinator.com/item?id=20480723)
This is because they pull everything needed to build Android into the tree. If there is a single tiny component somewhere that needs a lib, that lib gets included. If that component is replaced by a 20-line script in the next version, then the lib is pruned. This implies that they intend to ship something built in rust. Whether that is something tiny and unimportant, which might just as well get replaced in the next version, or if they intend to start using rust in a major way, we can only guess at.
RIIR, actually
Found this helpful, and more measured than several other discussions I’ve read recently. Thanks.
Interesting read. Funnily enough, I had similar problem with using unsafe. I'm writing parser for a file format, where data can consist of only one of 6 primitive types. I've decide users can specify that type generically so they don't have to match on proper type every time. When reading the type from reader I considered to just use cast reference to variable as u8 array and read into it. But I ended up just defining small trait and impl it with macro using only safe code. I started with the unsafe code not because it would be faster, but because it would be less code.
Previously posted at https://www.reddit.com/r/rust/comments/cfbzma/rustc_has_been_added_to_the_android_tree/
Ah, didn’t notice. Thank you!
For context: http://strlen.com/lobster/.
Rust isn't ridiculed in my experience, it's the insane cult followers it has that gets ridiculed.
I am using crossbeam and still getting errors around borrowed data - hence the need for a real-world example. Thanks though.
r/playrust
`p` is still an `Arc&lt;Mutex&lt;_&gt;&gt;`, so even if you're only reading from it you need to do `.lock().unwrap()` in order to call `.iter()` on the `Vec` inside.
I think I understand more. For rust to implement a cpp object there needs to be a C implementation of that object. So essentially we have a class with a void* member. The objects methods will pass the pointer to rust functions that will then unwrap the pointer to be a rust struct(no need for repr C or anything) and call the method. It should be safe to unwrap the pointer as the cpp object will be simple and will only use values passed FROM rust as the value of the ptr. For rust calling into functions exported from the rest of the application regular ffi rules apply... whatever they are, FWIW. I'm going to attempt this.
Look at any popular, quality rust code and you won't see nearly as many uses of `self`. It seems like you're trying to write in a very object-oriented way, putting the main logic in a single struct's `impl`, instead of just in the top-level `main()` or other functions that you would have to write. If you choose to keep the OOP style, your code could still use some refactoring to get rid of a lot of uses of `self` and some repetitive code (for example, the three uses of `self.board.push(self.deck.get_card())`).
[The PR](https://github.com/rust-lang-nursery/rustc-perf/pull/430), which has already been merged and deployed. Thanks, 0xpr03!
or, two of them, 128 cores!
The forth case is unsafe trait.
There won't be any 100x improvements in the future :) The main significant improvement in the short-term is pipelined compilation. See details at the end of [this blog post](https://blog.mozilla.org/nnethercote/2019/07/17/how-to-speed-up-the-rust-compiler-in-2019/). For a lot of projects it saves 10%, 20%, 30%; the speedups depend heavily on your project structure and machine configuration.
[This post](https://blog.mozilla.org/nnethercote/2018/05/17/the-rust-compiler-is-getting-faster/) describes things in detail. The data is out-of-date, but the descriptions of the various things being measured are still useful.
IMHO in pure computing point of view Rust is always better. But regarding project management it depends of your priorities, skills of your team, ... While Rust community is amazing, Go have a bigger one and a little bit more history ☺️ Go is also easier to learn. You have more Go developers available. ... But Rust worth the little additional effort 😄 Maybe comparing goroutine vs rust+tokio for async computation may be in favor of go 🤫
The mandated Chinese characters are, as i said, rare. But i had forgotten about emojis! I think i'll classify those as a dead language, just one that's not dead yet.
Sure for all practical purposes, but I like to use them as a strange technology purism outlet. Apline Linux and only text/nc UI running in the terminal. Maybe games in dispmanx/DRM/KMS but I thing you get the point.
I know this is an old thread, but a prisoners dilemma would be when the best choice in overall utility would be for both players to choose to wait. That is not the case here.
I agree with you except for the user requirements. I published a crate back in january for parsing DS_Store files on Macs. It's probably not gonna be used that often, but I think it can still be helpful at some point. If someone wants to try to take it over just because I havent worked on it since then, I feel like that would be a worse outcome, said person could simply contribute to my codebase.
&gt;If that component is replaced by a 20-line script in the next version, then the lib is pruned. Given how large Rust is and how long it takes to build, I presume they would go to some effort to avoid adding it for minor reasons, and just write that 20 line script. So I expect Rust is at least a dependency of some moderately sized and significant component, not something "something tiny and unimportant". But yeah, we'll see what this actually implies. And they definitely could remove it later.
I'm still trying to learn Rust, I know how basic stuff works but the syntax/naming convention is still a bit different than what I am used to so I still make mistakes which puts me off a bit.
RISC-V is pretty cool and open source
I enjoyed the read as someone new to the language - thanks for clearly explaining the simple demonstration.
Or even worse, "oh I'm sure it'll be good for compilers, but it's just not very *practical*". I don't know where the meme started that the one thing functional languages are good at is compilers.
I'm working on [async/await in ruma-client](https://github.com/ruma/ruma-client/tree/async_await). Things are already working (with the exception of TLS, because hyper-tls still needs updating) and I'll look probably into how async/await might lead to a nicer-to-use API tomorrow.
“Rust: One quarter after holding at #23, Rust inched up two spots to #21 this quarter. Placing one spot behind a high growth language like Kotlin and ahead of popular JVM-based languages such as Clojure (#25) or Groovy (#24) is a remarkable accomplishment given Rust’s low level, safety-oriented nature. It’s one thing to pick up JavaScript or even TypeScript quickly; fluency and competency in Rust is, by comparison, more difficult to achieve. For a systems language to continue its upward trajectory in this fashion suggests that some combination of the design, the language’s community and market demand is combining to have it outperform its natural expectations.”
Cool, thanks!
I legit sh f some tests watching that. Thought we would have to wait 20 years to see any technical competence in congressional oversite.
UTF-16 has 4 byte support. Do you mean USC-2?
But UTF-16 is not fixed width.
Got an elevator pitch for the content? I'm intrigued.
Lets go into more details: Lets separate objects into objects that act and do things and objects that simply are things. For things that we have: * The cards. They have an immutable value. * The deck. A set of cards, handles shuffling and making sure that only one of each type of card exists. Decks also allow discarding cards (dropping them basically). * The river: a set of cards that starts as 3 and increases to 5. * The hand: a set of two cards which appear hidden. * The BigBlind/LittleBlind chips: just an identifier of which player is the big blind. * The pool(s): the amount of money that has appeared on each round and which players are still in it. Pools can split when a player goes all in, but others continue betting. * The table, that contains the River and Pools. Now on to the actors, people that will mutate the above: * The dealer: Handles distributing the cards, and moving the Big/Little blind around. Each turn starts with the dealer handling things. The dealer owns the deck and distributes cards from it. * The player: May receive cards (but not take!). The main thing they do is decide to bet, fold or increase. They do this decision based on holding the Big/Little Blind, the cards they have, the river and other players actions. It doesn't matter because it's all internal details now. The players have their hand, and the money they have, they may also have the little/big blind. Now on to think of ownership. The game is lead by the dealer, so naturally the dealer owns the table (and guides most of its mutation). The dealer does not get mutated. The table itself has players seated at it that play around. So our code looks like the following: fn play_game(dealer: &amp;mut Dealer, players: &amp;mut Players, table: &amp;mut Table) { table.clear(); players.clear(); dealer.shuffle_new_deck(); dealer.deal_hands(players); // Gives out the little and big blind, also two cards. players.play_bets(table); // Play bets cycles through each upping until all bets are in, then they are added into the pools. Splitting and such happens here. dealer.set_river(table); players.play_bets(table); for 0..3 { dealer.play_round(table); player.play_bets(table); } let game_results = players.rank_hands(table); // Each player shows their hand to the dealer, who then ranks them based on the highest hand they could form. table.distribute_winnings(game_results, players); // Distributes pools to winners } Why is this better? * By separating the stateful data members from the doers, we have clear isolation of decisions. It's easy to add new players, it's easy to change how the dealer works, it's easy to see where each card is. * The core function, which isn't owned by any player or the utensils, represents the core rules of the game. It's easy to read and understand. * State is hidden or implicit in the structure. Doers do things * We can look into more complex rules as we keep going deeper. * A player is not shown here, instead we see Players, a collection that handles the agreements of what is a valid bet or not. The player handles the individual action. Now clearly we need to go deeper to see how this works. For example `rank_hands` would look like: impl Players { fn rank_hands(&amp;self, &amp;Table table) { // Note that we do not expose the river here. We exposed named hands to the table. table.order_by_hands(self.all_players.iterate().map(Player::get_named_hand).collect()) } } impl Table { fn order_by_hands(&amp;self, &amp;vec&lt;NamedHand&gt; hands) { // The Table creates a scorer ranker using the river. Then it sorts based on that ranking. // Special note: this doesn't handle ties, that's left as an excercise to the reader. hands.sort_by(HandScorer::with_river(self.river)); } } And so on and so forth. Now you can do it the way you do. But in Rust the language will give you a strong warning that you are putting all your eggs in a basket by having you use `self` too much. Also the solution I gave was very much how I'd expect good C++ code to look, with a very OO approach. Rust would look a bit more functional, with less methods and more functions.
This is the guy I've seen Chuck Tingle talking about, right?
I mean, isn't this the kind of thing we want out of our representatives? Officeholders should hopefully be experts in a few fields, but they should surround themselves with advisors in areas in which they aren't experts. Now maybe it was a bit presumptuous for him to say that *he* was looking at the nightly build releases, but it's a valid question and I'm glad he asked it.
Fair enough, I didn't figure there'd be a 100x plan any time soon lol was just curious if there was anything out there in that ballpark. &amp;#x200B; Thanks for the link I forgot about pipelined compilation.
Us Gophers accept our inferiority. You go fight the compiler. I don't wanna deal with that. ^(Those generics though)
Isn't RustTLS indirectly based on BoringSSL?
Good post, especially the emphasis on avoiding _unnecessary_ or _unsound_ `unsafe`, not _all_ `unsafe`.
Note that at work, our coding style _requires_ that we use `this.` enough though we're in C# where it's optional. So I wouldn't read anything into the language not having implicit self.
At pure perf stuff, Rust will win given sufficient effort. It's not really a contest there, and that's not a downside to Go -- it intentionally chose a different spot on the tradeoffs curve. I'll +1 the other suggestions here: try doing parallel things in the two, trying to find things that are good fits for channels, for goroutines, for async/await, for data race bugs, etc.
Though, to be fair, while C++ began as a superset of C, they have diverged since, with C99 adding details which a C++ compiler will either refuse or interpret differently.
I don't disagree, I was just explaining where he comes from.
But both those calls are going to be on the exception path and I don't care how slow that is (and I hope that stuff never gets inlined (all my exception branches I usually mark as cold/unlikely anyways to help the compiler move them out of the way (with expect built-in) unrecoverable error code paths the same too. I'm going to do some simple tests in the next week or two. I'll send you results when I get done.
By the response of the maintainers to any unsoundness found. For `std`, the response is things like &lt;https://blog.rust-lang.org/2018/09/25/Rust-1.29.1.html&gt;, so I trust it. If the response for that were "meh, just don't write code that does that", I wouldn't use it any more.
I believe you're looking for /r/playrust. This subreddit is for the programming language Rust.
pssshh Rust/WinRT is the new hotness
The main problem is that you need to drop the *lock*, not the arc or mutex. Also, you may first have to drop `iter`, or just not use that temporary variable. [Try reading this chapter of the Rust book to understand what Mutex and Arc are.](https://doc.rust-lang.org/book/ch16-03-shared-state.html) (Also, read through the book from the start if you haven't, it is *very* helpful)
I think adding `let peers_clone = Arc::clone(&amp;peers);` at the beginning of the function and giving it to `join` will solve your issue. The `Arc` is borrowed by `lock` so as long as it's alive you can't move `peers`. &amp;#x200B; Also, as said in the previous thread, you might want to use [any](https://doc.rust-lang.org/core/iter/trait.Iterator.html#method.any) instead of `find().is_some()`.
Nice, thank you :)!
This has to be in core. I believe, there could be a benefit from support for those new auto marker traits by default.
C++ was never really a strict superset of C, at least since it was renamed to C++. It rejected some C constructs from the beginning, such as non-typed functions and paramaters, non-cast malloc calls, shadowing, function hoisting ...etc. These were things from C++ that influenced C89 and then C99.
*satirically pro-Rust
We don't know. There might be some components in the Android source tree that require or will require Rust in the future. It might be something to do with Google's ongoing efforts with Fuchsia, which already contains a lot of Rust. It will be interesting to see if any Rust code crops up in critical parts of Android or AOSP in the future.
Just remember, it's vitally important that you don't let anyone else use `unsafe` either, especially in your dependencies. /s
In terms of speed you should worry too much both will be equally fast. In terms of building, maintainability etc rust is better imo. On the other hand all of it depends on the proficiency your team already has with rust. If you are all discovering it then it may not be the best choice except if you don't have any particular timing constraints. Rust is not the typical beast and needs some time to gets used to, more than c++.
Very cool, thanks
Do you have any opinion on actix vs rocket vs ___ vs ___ (so many options!)?
I'm seeing a lot of refcounted languages coming out nowadays. What's the process for auditing a refcounted program for memory leaks like? Is it easy to catch them all? Have many large pieces of software been written in say, Swift, that don't leak? Even though the web is supposed to be garbage collected, it seems like every large web app leaks, so this stuff kind of worries me.
/u/andygrove73 Any thoughts you can share on what you are thinking about a Rust DataFrame library for Ballista. I saw it briefly mentioned in your notes.
It's very noticeable when paired with RLS. The speed at which errors/warnings/etc show up in vim is incredible compared to a year ago. The Rust team and community just keeps crushing it, so grateful for everyone's work!
https://www.reddit.com/r/programmingcirclejerk is a better example.
I mean, if he’s got a DoD background it’s not too far to think that he’d pull it up himself. He’d have people looking at it with him and pointing things out but he technically probably looked at it.
Really excited to see this! Great work :)
Every Time i play a "browser game" it usually leaks horribly. Even Twitch does
A Workspace Is a set/list/bunch of crates all joined together (So you can i.e test them all together in one cargo command). Splitting parts of your program into crates (library crates and one binary, probably) can help compile times. Iirc either the book or the cargo book have a chapter on workspaces
This Is why i use no-std /s
&gt; Rust is 37 people That seemed like a nothing but an attempt to undermine it by making it sound small. He (or his expert advisers) can't talk about GitHub and all the rest and not know how open-source works. The questioning on the use of Nightly from a security standpoint is reasonable (though it may prove irrelevant), the rest is fluff and some comes across at subtle character assassination of the technology.
Thanks but as I remember they mentioned that need to avoid clone(). Is that the only way/best practice to fix this?
Ok, now that everyone here is speculating what the dependency is that needs rust on Android in the future here is my guess: ripgrep
As noted, it's not at all unusual. Java, C#, C++ and Delphi (and no doubt others) use it in a very similar way, requiring it to disambiguate fields and variables/arguments of the same name. It's not unusual for team policies in Java and C# to require 'this' on any reference to a field whether or not it is currently ambiguous. From this perspective Rust is no worse.
I think this will remove &gt; 90% of my unsafes. I will try it out. Thanks.
Trying to access the page gives me this weird error (Brave browser, chromium based) : Your clock is ahead A private connection to svartalf.info can't be established because your device's date and time (Saturday, July 20, 2019 at 8:34:37 AM) are incorrect. NET::ERR_CERT_DATE_INVALID
We’re still in the honeymoon phase.
is android using librsvg? that one was rustified some time ago, right?
If we exclude css from list, we will get Rust in top 20! :)
Many words to describe "world domination" :P Jokes aside. I am really a big fan of exactly how rust is growing. For example Swift and Go are heavily promoted by it's mother company. There is nothing inherently wrong with it (I guess) but it gives the language very little time to adopt to the outside world. See there are ideas in the "inside group" (the very few that build rust in the beginning) and they have something more or less like a coherent goal/vision of the language. Bits and pieces get outside and those ideas - hypothesis - gets tested against the real world. This works very well or sometimes it's a Desaster and the hypothesis about the "outside world" need to be readjusted in the "inside group". Step by step the hypothesis of the inside group about what the outside world looks like (what features do the users want) gets more and more correct. And in that process more people from the outside world could leak into the inside team because their set of ideas has an increasing intersection. This process takes time! It's exactly like a child is adopting/learning how the outside world works. Almost all hypothesis a child have about the outside world are wrong and needs to be adjusted. Therefore you don't have a press speaker that is 7 years old. As someone who can navigate the outside world/society you need time to readjust your hypothesis. It is very hard to sit in the basement with your assumption of the outside world and make a programming language that is what people wants. In my opinion that is what happened in Swift 1 - 4 and with aspects in go that are heavily discussed. Those language never had the time to adjust to the outside world and are promoted to early in bigger roles. Like the parents that are pushing their children in positions that their are not ready for. Rust seems like it's growing naturally in it's position - wherever this is.
I think I figured it out: it's to enable crosvm usage. Evidence: * "[Build CrosVM for Cuttlefish](https://android-review.googlesource.com/c/platform/manifest/+/987243)" (Jun 21) * "[adding the rustc repo to the manifest](https://android.googlesource.com/mirror/superproject/+/da7b9e00114dc9c9a339ac2ec275e68850680c92)" (Jun 26, six days later). Later it [got moved](https://android.googlesource.com/mirror/superproject/+/eee61aae12be27c933a673f7429646ec3f147015) to the location it's now at. * Link to crosvm android repo: https://android.googlesource.com/platform/external/crosvm/
&gt; **Unsafe is not easy.** It gives you the tools to potentially introduce UB. The rules are not fully specified, and are sometimes quite subtle. Acknowledge and respect the complexity of the area. This is going to be the hard one, it's pretty much a fact of life that people who don't fully understand the complexities of something will assume that thing is less complex than it is. And I don't think it's as simple as just repeatedly hammering into people that unsafe is subtle and complex because they're just going to see that as a load of hot air if they don't understand why. Personally I think we really need to dedicate some resources to teaching people how to get unsafe _wrong_ so that they understand why it's not something to be taken lightly.
Huh, weird. And fixed already, ty for a notice
idk, but that is also a very good suggestion!
Where are you seeing inconsistent casing of type names? The official stance on casing of type names is that an IO Error should be named IoError instead of IOError (which I disagree with, but as far as I know, there aren't random exceptions). Every cast that isn't between `T` and `U` where `T` and `U` are represented precisely the same way in memory is actually a conversion. If you want to get rid of casts that do conversions, you have to get rid of practically every cast. Structs and enums don't take arguments. A struct *initializer* can be thought of as taking arguments, but the context in which those "arguments" are used is significantly different than the context of function arguments. Enum *variants* already take arguments. Saying that generics should use `[]` instead of `&lt;&gt;` is like saying that boolean negation should use `~` instead of `!`: Sure, you could, and some languages even do it, but if you saw a random person jump off a bridge, would you follow them? This just amounts to which sort of delimiter you want, and that has nothing to do with the language. What problems does the naming in the standard library have? What is library stutter? Assuming capitalization rules are followed, `foo::bar::Bar` refers to a type named `Bar` inside the module `bar`, which is itself inside the module foo.
Because you have not yet released the lock. The compiler is pointing out that your code is defective. The compiler is correct.
I think I have to maintain that it is definitely very possible to create very difficult bugs without using unsafe. For example, you can easily introduce unexpected memory leaks with Rc by creating cycles, or call mem::forget(). You can also create deadlocks without unsafe. Again, the benefit of unsafe is definitely substantial. But its absence is not enough to say that something is high-quality. In many cases, religiously avoiding unsafe can be a sign of the opposite.
I completely agree with those points. So instead of accusing its developer of insisting on unsafe for no reason, even calling him untrustworthy, it is perhaps better to try to understand why. Someone said it looks like burnout. If that is the case, this reaction probably aggravates the underlying issue...
I agree about your last point. Auditing dependencies is very hard. But if you want to be absolutely sure that your dependencies do not introduce bugs, it's the only way. It's the hidden cost of using other people's code, as anyone who has used Node.js and NPM a lot, and is not incompetent, will tell you... Admittedly the situation in Rust is much better, for several reasons, but the fundamental reality is what it is.
So it completely looks like burnout due to being understaffed working on something that a lot of people have opinions on, but few are contributing to. Throwing accusations is completely the wrong way to handle that, and open source would be a better place if everyone was a little cognizant of that.
So your point is that it's more about the specific reaction on the part of the Actix developer? As mentioned in other comments, the issue seems to be burnout more than anything else, which nullifies any discussion about that person's competence. It's a sad reality of our industry, and it's our job to recognize that, and deal with it compassionately first and foremost. My arguments in this thread are entirely about the notion that unsafe in general is by itself a reason to dismiss a piece of code, regardless of justifiability.
You only need the gstreamer crate, nothing else. All those pipeline elements come from plugins loaded at runtime. The other gstreamer- crates are only needed if you need other library API. Take the launch.rs example and try to understand that code as a first step. Then for what you want to do, in the simplest case, you only have to change the string that is passed to the parse_launch() function. You can of course also build the pipeline manually with the API. Look at the decodebin.rs example then for starters. It's more complicated though. Documentation-wise, I would recommend reading the tutorials on the GStreamer website and the application developers manual before reading the API reference. The API reference does not explain the concepts. The tutorials are also partially ported to Rust here: https://gitlab.freedesktop.org/gstreamer/gstreamer-rs/tree/master/tutorials https://gstreamer.freedesktop.org/documentation/application-development/ https://gstreamer.freedesktop.org/documentation/tutorials/
It doesn't and Google is generally very allergic to LGPL licensed code and would rather reimplement themselves. Chrome (inherited from WebKit) has an SVG renderer, maybe they use that renderer for SVGs outside the browser too.
How do I know if I can use this crate for my data types? What kinds of questions should I ask myself to ensure I will not have any bad surprises when converting binary data into a specific data type?
What are actual rules about pointer casting? For example in C casting `char*` to arbitrary type is UB, but allowed by major compilers if there is valid bit pattern and alignment is right. But I can't find what Rust rules are.
Many of libraries we all rely upon use unsafe unnecessarily and rather recklessly, and the only way I see out of it is a community effort similar to Libs Blitz to cleanse them of `unsafe`, and where that's not possible, document that and propose new safe abstractions that make it possible. Here's just the stuff I've found and fixed (most of it is also UB): https://github.com/sile/libflate/pull/30 https://github.com/sile/libflate/pull/32 https://github.com/sile/libflate/pull/34 https://github.com/sile/libflate/pull/37 https://github.com/Frommi/miniz_oxide/pull/47
&gt; Google is generally very allergic to LGPL licensed code and would rather reimplement it themselves Wow, really? Could you point me to examples of that?
RLS does something similar to `cargo check` (or possibly the same thing, I'm not sure): it quickly goes through the code looking for compile-time and saves some information about the available types, functions and so on, so that the RLS features like "go to definition" work. `cargo run` does that, but also has to produce the compiled code.
The easiest way (of course) is to have a background in C or C++, where there are no safety guards on the buzz saws. But we can write C in Rust, and showing people how to do this and showing \_how easy it is to get wrong\_ should be educational. (A certain amount of pain goes into successful learning)
You can't move borrowed values, first you need to drop borrowing. Thanks to nll it is now very easy, just drop values that borrows, the lock guard in your case.
There's nothing flawed about that. If true it would be good that he gives enough of a shit to hire a panel of experts so he knows what he's talking about. That's how it should've been done for the *bleep bloop ZuCkErBoRg* hearing.
Slightly off topic: Another HK based Rustacean here, I wonder how extensive the community is in HK?
Even I used std::men::drop(peers) gave me error. Can’t drop it
You need to drop `lock` first
I agree with your edit, and with your comment in principle, but some of the loudest detractors of Rust that I've seen are actually C or C++ programmers, which either feel you can avoid UB with enough discipline, or don't care about UB that much.
This looks pretty neat, have you considered adding it to`awesome-rust`?
Rust does not have type-based aliasing (instead &amp;mut provides uniqueness guarantees) which changes the rules a bit.
Do you have link to documentation? Does clang explicitly tell llvm about its aliasing restrictions and rustc don't?
This is so useful and I've wished for this since pre-Rust 1.0. Always struggled to make this work with internal padding and other traps---but your derive-based solution seems really cool, I tried to make it work with autotraits previously, but never got anywhere.
Ah, the 'sufficiently clever programmer' idea. People tend to overestimate their ability in this department! Plus, there are working C or C++ programmers who actually don't even know what UB means. (I prefer 'sufficiently clever language' myself)
&gt; all my exception branches I usually mark as cold/unlikely anyways to help the compiler move them out of the way (with expect built-in) unrecoverable error code paths the same too This should be unnecessary, the compiler already treats any path leading to an exception or an abort as unlikely. &gt; I'm going to do some simple tests in the next week or two. I'll send you results when I get done. I certainly encourage you to. I'm NOT trying to combat a cargo cult (exceptions are fast) by another (exceptions are slow); my point is more than it seems to be a mixed bag and results may vary on a case by case basis so there's no substitute for actually measuring.
Sadly, I'm not involved in any local techie communities. I'm also not the social type...
Not OP, but presumably: - The type doesn't implement `Drop`, and does not have any bizarre `Clone` semantics. - All possible bit representations are valid (`bool` and `enums`s probably do not fit into this category).
If you are not aware of it, have a look at the TinyGo project which aims at bringing Go to the embedded world.
I don't think typed should automatically implement these traits. It's not so much of a memory safety issue, but more of an stability, compatibility and portability issue: some code might rely properties such as endianness or layout without realising it, so I think these should be opt in.
They have their own libc called bionic https://en.m.wikipedia.org/wiki/Bionic_(software) and they are strongly focussing on LLVM instead of GCC in order to avoid the GPL.
&gt; "Noise_NN_25519_ChaChaPoly_BLAKE2s".parse()? This seemed pretty strange to me; is there no way to specify this combination with a tuple of `enum` which would avoid the use of `?` entirely?
Despite claims to the contrary, avoiding leaks is hard. In the most absolute terms, an object is "leaked" between its last use and its reclamation: it unnecessarily occupies memory, after all. It can be pretty challenging, however, to divine whether an object will be used in the future or not; you'd need an oracle! For example, imagine a texture map for a game. As the player progresses, more textures are added to the map for the new areas explored; but when should you *remove* a texture from the map? If you never remove them until the end of the game, the map is going to balloon up out of control. If you remove them too eagerly, the player may experience jitter if they go back on their track. And of course, it's possible that a texture has been "recycled" being both in the first level and in a secret room of the second level... Should you remove it after the first? Or after the second? If the player never finds the secret room... You can use memory profilers to understand where memory is used, but the profiler cannot tell you whether it's used unnecessarily or not.
Depending on your system and use-case, [vmtouch](https://linux.die.net/man/8/vmtouch) might also be of use.
I wonder about padding... for deserialization it wouldn't matter, but for serialization you'd be attempting to writes uninitialized bytes.
Hi there, In your opinion what complementary technologies/languages or perhaps knowledge/skills generally would benefit a programmer looking to transition to Rust professionally? Thanks
Which should be fine, since all bit patterns are valid for a `u8`. It just means you have a little extra junk data you never use, but in reality that's probably dwarfed by the cost of actually removing that junk.
Indeed. LLVM calls this kind of restriction TBAA (Typed-Based Alias Analysis), see [Pointer Aliasing Rules](https://llvm.org/docs/LangRef.html#pointer-aliasing-rules), and specifically: &gt; Consequently, type-based alias analysis, aka TBAA, aka `-fstrict-aliasing`, is not applicable to general unadorned LLVM IR. Metadata may be used to encode additional information which specialized optimization passes may use to implement type-based alias analysis. Which references [`tbaa` Metadata](https://llvm.org/docs/LangRef.html#tbaa-metadata). Rust does not use TBAA metadata, and instead explicitly annotates the IR with the equivalent of the `restrict` C keyword as suitable. If you look at the [Parameter Attributes](https://llvm.org/docs/LangRef.html#parameter-attributes), you'll find `noalias` for example.
But doesn't rust expects particular bit pattern for pad bytes?
I can't find anything that suggests that in the Rustonomicon, although I'd gladly bow to someone with a deeper understanding of this.
That "junk" data could be parts of a secret value stored there previously. It is pretty important to clear those sections of memory when serializing to prevent such security issues.
Sure, but lack of security does not imply that something is `unsafe`. That onus is still on the developer to take security into consideration, even in safe code.
Neat! One question though: How does it handle padding? It's important to prevent reading uninitialized memory, especially when passing that data around to untrusted applications. It could hold sensitive data that poses a security risk if leaked.
You set travis to deploy on tags, but the deploy step doesn't read in the tag it just runs deploy every time a tag is encountered. The [0.4.0](https://github.com/aspera-non-spernit/cyrconv/releases/tag/0.4.0) tag points to commit [ed8534116919d261aa614478004f14a66555fb19](https://github.com/aspera-non-spernit/cyrconv/commit/ed8534116919d261aa614478004f14a66555fb19). However the Cargo.toml didn't get bumped to `version = "0.4.0"` until the commit after, [0a56bd7e4426fd65406ad3c1aa7f84fa53c8529e](https://github.com/aspera-non-spernit/cyrconv/commit/0a56bd7e4426fd65406ad3c1aa7f84fa53c8529e). That means under the 0.4.0 tag the version in Cargo.toml still says 0.3.3 - https://github.com/aspera-non-spernit/cyrconv/blob/0.4.0/Cargo.toml The thing to do now would be yank 0.4.0 if that release should've been breaking and release a 0.4.1, ensuring the tag points to a commit with the Cargo.toml version also increased
That's a really nice analysis. I think this also relates well to the "Once burned, twice shy" attitude of developers. As a software developer, we are bombarded by new technologies popping up left and right: languages, frameworks, libraries, best practices, ... As a result, we have little time to dedicate to each, and we're therefore unlikely to test one single technology **twice**. If it didn't pan out the first time, why ever lose time with it ever again? I am of mind that D is in such a position. It's probably a nice language (now), but was hyped way too soon leading developers to try it out, be disappointed, and swear never to use it again. This might be amended in the future, with pressure from other exalting its virtues and news of its successes, however it remains a risk: too many developers getting burned at an early stage might forever curb its growth, and possibly condemn it to a perpetual limbo state. A language like Swift probably doesn't care; it's got a captive audience, to a degree. A language like Rust, however, needs to tread with caution. Going slowly but surely.
`Clone` in itself isn't bad, sometimes it's the right choice, sometimes it's not. If you have a `String` containing all books in a library, you might not want to clone it. On the other hand `Arc` is meant to be cloned, it's its purpose, if you never clone it you should remove it. An `Arc::clone` will only increment a number.
They have inherited Bionic from Android, so Google did not make that choice. LLVM is much easier to develop than GCC, which is probably more important than the licensing. For example, then they needed ThinLTO for Chrome, they've easily added it to LLVM; changing GCC in a similar way would be much harder.
Except that padding is not `u8`, it's... nothing. This also has practical implications: access to uninitialized memory is Undefined Behavior. The bytes may not have the same value every time they are read (computing the CRC is going to be annoying), or just attempting to reading them could cause the optimizer to do weird things...
I'm referring specifically to the bytes after they've undergone serialization. Those padding bytes will then be considered part of the serialized slice.
thank you. It seems I haven't understood the workflow yet.
I'm concerned that the very fact of undergoing serialization is already UB though.
There are disadvantages *for optimizations*. It's not like compiler writers are lazy, it's that the *compiler* has to work more to figure out of optimizations apply, making compilation slower, and the compiler will not always succeed in finding a way to do the optimizations correctly, also making the resulting programs slower. We do unfortunately not have good data for *how much* it would slow down. I expect it to be significant. But I do not deny that there is a cost to "unstable memory". It would be interesting to do the experiment of a language with stable memory, but otherwise comparable to Rust in terms of the kinds of UB it has. I don't know anyone who would have the resources to run such an experiment, though. LLVM would need a serious overhaul.
The crate seems to handle that correctly: `FromBytes` allows padding but `AsBytes` does not.
Neat!
There is a discussion. [https://twitter.com/tigercosmos/status/1146621911536824320](https://twitter.com/tigercosmos/status/1146621911536824320)
I think the stereotype of functional languages being well-suited to compilers has a lot to do with sum types (`enum`) and `match`. They can be a pretty big win for certain kinds of code.
Thanks a lot! This is an interesting crate. Happy to see that padding is treated properly; this is an often-overlooked source of issues. :) One question: &gt; zerocopy provides marker traits for certain properties that a type can have - for example, that it is safe to interpret an arbitrary sequence of bytes (of the right length) as an instance of the type Seeing that [uninitialized memory is complicated](https://www.ralfj.de/blog/2019/07/14/uninit.html), do you mean here an arbitrary "initialized"/"frozen" sequence of bytes? I see that `FromBytes` is implemented for the integer types, and it is important to communicate that, as of now, `mem::uninitialized::&lt;i8&gt;()` *is* UB. See [this discussion](https://github.com/rust-lang/unsafe-code-guidelines/issues/71). There are only very few types for which an uninitialized sequence of bytes is a valid instance: things like `()`, empty arrays, and `MaybeUninit&lt;T&gt;`. I also have a proposal for another trait that would be interesting to have: types for which the all-0 bit sequence is valid. This would allow a safe `mem::zeroed`. Certainly any `FromBytes` type qualifies, but there are more -- for example, `bool` and `Option&lt;&amp;T&gt;` also qualify.
Yep. Basically cargo check and rls do a 'could i compile this' and cargon run actually compiles it.
Yeah, padding bytes are uninitialized memory and that [has its own rules](https://www.ralfj.de/blog/2019/07/14/uninit.html).
I agree. Until Rust stabalizes and more compiler options are available, Ada/Spark is the safe choice.
We're working on it! I made a proof of concept last week, and I'm going to try to prepare a PR for zerocopy sometime this coming week: https://github.com/jswrenn/fromzeros It would be _very_ nice if MaybeUninit::zeroed or mem::zeroed were const fns!
How does the Rust job scene in Europe looks like ? I'm currently a Javascript developer with both knowledge in building UIs and REST back-ends/services/databases. Is Rust popular in this area or is it adopted for other kinds of jobs ?
Great stuff! Can it also handle the vulkan dialect or does it even care?
Why would we exclude css? It's a rather nice declarative accidentally-turing-complete layout language.
Can't wait for `yue-hant-HK`! ^joking
High praise indeed. Now we need not rest on our laurels and continue to improve Rust in all aspects so it will convince even more developers to join our ranks. In related news, Rust clearly popularized the ownership model, with similar implementations being considered in D, Swift and other languages. This is great news for both performance and memory safety in general. Also let's not forget that Rust is not the endgame. Someone may at one point find or invent a language that will offer an even better position in the safety-performance-ergonomics space. We should be careful not to get too attached to Rust, lest we stand in progress' way.
&gt; This is great news for both performance and memory safety in general. It's also, possibly, great news for Rust. The main reason for the "steep learning curve" plaguing Rust is admittedly its innovative Ownership+Borrowing concept. The concept getting mainstream means more people getting exposure: earlier exposure, more tutorials suiting a variety of learning preferences, etc... until the point where Ownership+Borrowing is as mundane as any other concept, and no longer an obstacle to learning Rust.
&gt; We're working on it! I made a proof of concept last week, and I'm going to try to prepare a PR for zerocopy sometime this coming week Awesome! I just looked over it, it could need some more comments for sure. :) I am confused by this though: ``` unsafe impl&lt;T&gt; FromZeros for [T] {} ``` Why should slices of any type be `FromZeros`? Also why are `*const T` and `*mut T` not unconditionally `FromZeros`? &gt; It would be very nice if MaybeUninit::zeroed or mem::zeroed were const fns! See https://github.com/rust-lang/rust/issues/62061
The `AsBytes` documentation explicitly says that it may only be implemented for types with no padding.
It turns out that I actually *do* have a concern about how `AsBytes` handles padding... the documentation says &gt; Its layout must have no inter-field padding. But what about trailing padding (after the last field)? That has all the same problems, after all. Trailing padding occurs in types like ``` #[repr(C)] struct TrailingPadding { f1: u64, f2: u8 } ``` (Is there a public bugtracker for this somewhere? Having to report this on reddit doesn't seem great.)
is it possible to create a new bool type with the semantics of 0 = false else true and then it wont be unsafe?
I think it's only Turing-complete of the user manually pumps the page, no?
&gt;but I don't think that it was ever ridiculed Non-rustacean here. Somebody who has ridiculed it occasionaly for the lulz. Yes there has been ridicule, mostly due to overselling Rust when it was still under progress. Also here on a small Lispers' camp it also gets ridiculed for whar we percieve as ridicule decisions or events. Exhibit a: What we would percieve as horrible lack of safe defaults for a language oversold on safety: https://www.reddit.com/r/LispMemes/comments/brlww5/lisp_cheetsheet_for_crabmen/ Or for your endless bikeshedding of the async syntax: https://www.reddit.com/r/LispMemes/comments/bnynf2/elite_rust_insiders_debate_a_syntax_for_the_rust/ Or when it's oversold as the only choice for safe systems, while safe high-performance systems are also pretry much factible in Ada, Erlang, Lisp, ML dialects and others. https://www.reddit.com/r/LispMemes/comments/bdkql4/practical_applications_of_lisp_and_rust/ Rust *is* a perfectly good alternative to C++ when extreme speed coupled with safe code is needed. Perhaps maybe the only alternative. Don't sell it as the panacea for every use case and all will be fine.
You're right on all points. I blame the perils of copy-paste-coding after a long day of work. :)
I'm working on learning the language, I am committed. Just reading has already been a huge milestone for me, it's exciting!
Yes this is correct. Thanks for your help
Hey that's neat! Can't wait to see if this turns into something
Zero cost if string to be used in a way where everything is zero cost. If you use it to mean "if you implemented it this you, you would do the same thing". What isn't zero cost on that sense? I don't even think the phrase is useful anymore, just hype. Think of an arrrsy with index method. If you statically analyzed all bound checking out, that would be zero cost. If you bounds checked every access, not zero cost definitely (although I'm sure some would argue the case, sigh). Rust doesn't get rid of every check, and in many cases a human probably can get rid of a few more that are impossible to happen (over I've seen some cases when changing the loop index type degrades performance terribly from this).. Where does this become "zero cost"?
Very helpful thanks
Padding bytes are uninitialized memory. This is pretty important for things like Option&lt;SomeHugeType&gt;::None being a single byte to initialize.
The derive code checks for no padding by checking if the size of the struct is equal to the sum of the field sizes.
A careful reading of my comment will reveal that i wrote: &gt; fixed-width (per UTF-16 code unit, that is!) UTF-16 and Latin-1 do indeed have a fixed width per UTF-16 code unit.
Presumably. ``` #[repr(packed)] pub struct Bool(u8); impl PartialEq&lt;bool&gt; for Bool { ... } impl Eq&lt;bool&gt; for Bool { ... } ```
&gt; Honestly, from my anecdotal experience it seems to be ridiculed much less than I would have expected for such a "new popular kid on the block" language. Same. Though i will say that the last year with the year before has been a different experience. A lot of people *(purely my opinion)* are getting sick of Rust being shown/praised/explored so frequently. The Rewrite it in Rust tags, especially to C and C++ devs, seem to cause quite a bit of pushback. I'm not really commenting on the validity of any of this; just that i've seen more resentment towards Rust this year than the year prior. Even though it's a better language than it was before - it's largely articles like this rubbing people the wrong way, imo.
Perhaps, then, all types that fit the trait that OP mentions must have a packed representation?
 &gt;This should be unnecessary, the compiler already treats any path leading to an exception or an abort as unlikely. So what you are saying is that the compiler can generate faster code with exceptions because it knows the fast path? (Lol, I say this half jokingly but really useful to know and probably gets rid of at least half the times I use it).
Or for example, an enum representing the state of your state machine might be effectively just an int, but it might be an important correctness property that you can't just copy it.
I guess the reasoning is the following: - Exceptions are for exceptional cases, and already lead to a hefty penalty when used, might as well move the code out of the way. - Aborts lead to the program shutting down abnormally, nobody will care if it's a bit slower. So, in my experience, when compiling a program with a branch that throws an exception, the code for the "throw" case is moved at the bottom of the assembly generated, which is the effect `unlikely` hints lead to.
Sorry, I think our miscommunication lies elsewhere. I’m not an expert on the JVM, but I still don’t understand the advantage of UTF-16 over UTF-8 when both are variable width. So my question is, why is constant time indexing advantageous when you still have the same problem of potentially landing in the middle of a surrogate pair? I guess it would happen less often, but the problem still exists.
I did not come here expecting an educated question and boy am I baffled...
Unfortunately I've been down this road, and convinced myself that auto traits aren't sufficient. The problem is that some of the rules are not just of the form "this type is X if all of its fields are X." E.g., a type is only `AsBytes` if all of its fields are `AsBytes` *and* there is no inter-field padding. The inter-field padding rule can't be expressed using auto traits. I have been working on an RFC to propose a more powerful version of this crate to add to the language, but it'd require first-class compiler support. Instead of `T: FromBytes`, it would allow `T: FromBytes&lt;U&gt;` - given an arbitrary, valid `U`, its bytes correspond to the bytes of a valid `T`. It's been on the back burner recently, though, because for our purposes, converting to/from `[u8]` (which is all this crate supports) is good enough.
Generally speaking, I've been erring on the side of caution. There are some rules that we have that are probably more restrictive than they need to be, but I would obviously much prefer to be too restrictive than to be unsound. That said, if somebody can make a convincing argument that `f64: FromBytes` and friends would be sound, I'd be happy to add that impl.
The rules that we use are not the same as the rules that Rust language defines. For one, they are more conservative since some of Rust's soundness rules are in flux, and soundness is obviously the most important criterion for the crate. For two, though, it's not really that Rust explicitly says anything about reinterpreting bytes as types. Rather, they have rules that logically imply that it is safe. So you can think of our rules as being derived from theirs. Concretely, the documentation on each the three marker traits - `FromBytes`, `AsBytes`, and `Unaligned` - lays out the rules. That said, you shouldn't implement those traits yourself. You should just use the custom derives that we provide.
&gt; Rather, they have rules that logically imply that it is safe. Could you share your knowledge here?
Yeah that's just poor wording on my part. What I meant to say - and what our derive checks for - is that no padding exists, period. Currently, that's implemented by making sure that the size of the type is equal to the sum of the sizes of each field. As for a public bug tracker, unfortunately not yet. I'll see what I can do to fix that.
Ah, very good point about uninitialized memory. It's poor wording on my part - it should really say "interpret from an arbitrary (initialized) sequence of bytes" or something like that. Do folks generally use "initialized" to mean "initialized or frozen," or should I explicitly say "initialized or frozen"?
Yeah that's just poor wording on my part. What I meant to say - and what our derive checks for - is that no padding exists, period. Currently, that's implemented by making sure that the size of the type is equal to the sum of the sizes of each field. As for a public bug tracker, unfortunately not yet. I'll see what I can do to fix that.
Is it possible to implement string interner like https://github.com/rust-lang/rust/blob/master/src/bootstrap/cache.rs or https://github.com/Robbepop/string-interner without `unsafe`? If not, how to prove impossibility?
Good idea, thanks! Not sure if those downvotes are because folks don't like `awesome-rust` or they just disagree that this crate is awesome ;)
Just use the custom derives! They will fail compilation if your type doesn't uphold the invariants of the traits.
&gt; People occasionally confuse or conflate UB with unsafe. The two are not the same, and neither implies the other. Shouldn't the compiler prevent UB for safe code? So UB does imply unsafe?
Hmm this is an interesting point. We don't actually reason in terms of `Drop`. I don't think this is a soundness concern because, if your `Drop` does unsafe things, then it's on you to do it correctly (and if both implementing, e.g., `FromBytes` for your type and implementing `Drop` is unsound, that's on you). But it shouldn't be possible to cause unsoundness with a `Drop` impl with no unsafe code and an impl of `FromBytes` or `AsBytes` or `Unaligned`. It can cause incorrectness depending on your own code's definition of "correct", but it's up to you to not derive those traits in that case. /u/ralfj, any thoughts?
That's not actually true, it turns out! https://www.ralfj.de/blog/2019/07/14/uninit.html
Also, check out the other thread on here about padding. Not sure whether that's something you've considered.
It's actually worse than that - operating on uninitialized memory (such as padding) is actually UB - https://www.ralfj.de/blog/2019/07/14/uninit.html
They don't necessarily need to be `repr(packed)`, but they can't have any padding. `repr(packed)` is just one way to achieve that. You can also achieve it with `repr(C)` or `repr(transparent)`.
Yeah, they definitely need to be opt-in. I have a (still in-progress) proposal for adding a more powerful version of these traits to the language, and they'd require compiler built-in logic. In exchange, you need some kind of `IOptIntoBeingFromBytes` trait for exactly the reasons you mention.
It'd take a lot of time to write out everything, but here's an example: - It's UB to operate on uninitialized memory - Padding is uninitialized memory - `AsBytes` allows you to operate on all of the bytes of a type by viewing them as a `&amp;[u8]` - Therefore, it would be unsound to implement `AsBytes` for a type with padding
Made me understand them less. Maybe I should learn about compilers first.
Yeah, we get padding right thankfully. See my various responses to that question :)
This is kinda same as in C for type to bytes reinterpretation (even stricter). But what about going the other way around?
Correct. Specifically, all the low-level timing-attack resistant assembly is from BoringSSL. It should be noted that ring (which RustTLS uses), has also upstreamed a bunch of changes to BoringSSL, so it’s not a one-way relationship.
Any thoughts on creating some even higher level than editions where changing std is possible? I just always feel uncomfortable thinking that once this or that is put in place then we cannot ever change it. Rust is such a great language I would hope that in the future we can smooth out all the naming conventions to apply to everything more consistently.
As mentioned this is my first rust crate, so constructive feedback is especially welcome. There are some spots that I consider improvable, but don't know how. Some of these seem to me to be limited by rust, some are just design decisions I am not sure about. 1. The trait asks you to specify the type of ChildIterator. This is annoying to do if you compose iterators or want to use closures. Rust does sadly not (yet) support impl Trait for traits. 2. I would like to allow different kinds of closures&amp;functions to be used for filtering, sadly that does not work, because the compiler can not guarantee that one item does not implement multiple Fn-types. (see documentation for the type M) 3. I can't seem to manage to get rid of a forced lifetime-annotation when passing filters. I can't pre-annotate them in the Trait implementation bc rust does not believe im using them ever though they are used. (see doc for impl FilterBuilder Fn(&amp;T::Content, usize, &amp;T) -&gt; bool) 4. I am unsure about how to design for mutability. 1. I could ask people to pass actual references to their nodes in the trait methods. Right now its any Copy type. So that would basically force double-referencing if the Node internally contains a reference, but would allow mutability with the same API. 2. I could instead have a completely different TreelikeMut trait that takes references. But that splits the "ecosystem" because now everything exists in two slightly different variants, only difference being one taking by value, one by ref. 3. or maybe there is some possibility that I overlooked. 5. cargo test throws some weird error on the doc tests that is related to the alloc crate. Does not actually fail any tests though.
I’m not on the Lang team, but I don’t see how that can work, technically speaking.
Context: https://www.compuphase.com/pawn/pawn.htm.
Ah, that should take care of all padding then. Would be good to update the docs though, IMO. The question about a bugtracker stands. ;)
repr(C) is allowed to pad, and will happily do so. This attribute forbids field reordering, nothing more
To expand on that, e.g. this has no padding: ```rust #[repr(C)] struct Foo { f1: u64, f2: u32, f3: u32 } ```
I don't think we have good standard terminology yet. And "initialized" is sometimes said to mean things like "a `bool` that is 0 or 1", but OTOH "frozen" is barely known jargon. :/ So, probably best to be as explicit as you can.
I don't think we have good standard terminology yet. And "initialized" is sometimes said to mean things like "a `bool` that is 0 or 1", but OTOH "frozen" is barely known jargon. :/ So, probably best to be as explicit as you can.
Try to reimplement one of your python tools in rust, using structopt for command line option parsing. You could also use clap, which has a mode of operation that's similar to python's argparse, and another like docopt. When you find something python does that rust doesn't, try to implement it yourself. If you are feeling ambitious, publish your version as a crate.
Good question about `Drop`. But actually this reminds me that I should ask more generally about non-`Copy` types: couldn't I use this to duplicate an instance of a non-`Copy` type that is both `AsBytes` and `FromBytes`? OTOH, and this applies to both non-`Copy` and `Drop` concerns, a crate has to opt-in to expose a `FromBytes` instance. So if they don't want people to construct instances from a byte slice, they can just not implement that trait. In fact, how would I even use a `FromBytes` instance? `AsBytes` has some "provided methods" but `FromBytes` does not seem to have any?
There is! See: [https://docs.rs/snow/0.6.0/snow/params/struct.NoiseParams.html](https://docs.rs/snow/0.6.0/snow/params/struct.NoiseParams.html). The parse example exists for simplicity similar in ergonomics to how \`SocketAddr\` in the standard library can parse an ip/port tuple from a string.
There is plenty of interest from every language community in making those benchmarks fast, because despite the site telling people want to many people make conclusions about one language being faster than another based on those results.
`f64::from_bits` is in `core` and safe.
If retrieving a `&amp;str` borrows the interner, then you can just index into a collection and return the `&amp;str`. However, if you expect it to be valid for the entire time the interner is around, but not borrow the interner, then you need to use `unsafe`. It is "safe" in the sense that (by how interners are designed and used) you will never drop or change any of the `String`s in your interner's storage, so your `&amp;str`s won't be invalidated. However, there is no way to tell the type system this, so you must use unsafe and make sure to preserve those invariants manually.
Nah there isn’t. It’s very different because Rust is new, and it being new is the incentive for Rust to have great benchmarks. The other older languages only improve theirs in reaction to newer ones. For example Rust beat C on one of the benchmarks. The following week the C benchmark was updated to copy the Rust benchmark, and went back to first place.
I have not looked into this extensively, but from my understanding you have two options: The first option is to use dlopen (or a crate providing that)[https://github.com/szymonwieloch/rust-dlopen]. My understanding was (which is contradicted by a quick scan of this crate) that you need to provide a C api for this to work. The second option is to embed a scripting engine, for example like (lua)[https://crates.io/crates/rlua] or (dyon)[https://crates.io/crates/dyon].
Or better yet a wasm runtime like wasmer.
If you are using gstreamer-rs, look at appsink. It makes it easier to attach a rust function call to a gstreamer pipeline. You can set the apps on your sink to recieve a raw image, or one that's already encoded as a png/jpeg.
What prevents it from happening? Just curious to learn more about this.
Yes, you can implement something similar in safe Rust. Have the interner store a `HashMap&lt;String, usize&gt;` and a `Vec&lt;Rc&lt;String&gt;&gt;`. Define an interned string as `struct Interned(usize)`. O(1) comparisons between `Interned` are trivial. Retrieving the interned string is just taking the index from the `Interned`, and using it to index the `Vec&lt;Rc&lt;String&gt;&gt;`. You can return a clone of the `Rc&lt;String&gt;` if you need it to have an indefinite lifetime, or you can borrow the interner and return it as a `&amp;str`. Generating an `Interned` from a `&amp;str` is just checking the hash map for an existing interned string, and if it doesn't already exist, pushing a newly-allocated `Rc&lt;String&gt;` to the vec and returning its index.
For which there's also an example here: https://gitlab.freedesktop.org/gstreamer/gstreamer-rs/blob/master/examples/src/bin/appsink.rs But if it's only for encoding to PNG and writing to a file that seems overkill. See above
There are multiple parts to this and best practices. &amp;#x200B; First, define the interface that users need to implement to create a plugin. This is *not* the same thing as the interface for the function you want them to implement with the plugin. A good plugin system offers a way to pass back through code a name for your plugin, a brief description of your plugin, version information, license information, plugin developer information, an interface for the 'pre-loading' of the plugin, an interface which describes the behavior being overloaded (if you have multiple behaviors a plugin can overwrite, they will almost never overwrite all of them, this lets them only do the part they want), an interface for the behavior the plugin is allowed to implement, and a 'shutdown' interface. All of this is distinct and separate from a dynamic dll loading code. This is how you create a mature plugin system, it will make debugging easier and both your life and the plugin developers life easier. All this is vital to be able to do things like: Log that a plugin with 'x' name was found (where 'x' is the name of the plugin as defined in the plugin's code). This helps plugin developers to know their plugin is actually recognized. Log that their plugin was loaded successfully as well as make it so users have a nice human friendly name and description for a plugin. &amp;#x200B; Discover that a plugin exists! A common feature for a plugin system to do is to scan through some kind of plugin folder and check what plugins are installed, with human readable names and descriptions. &amp;#x200B; Install plugins! It's very nice to be able to run a single command (and might I recommend a command from \*within\* your plugin instead of just within cargo) for a plugin. Show when multiple plugins are currently installed that they have overlapping behavior which might not work well together. This is a common problem for UI based plugins, but might not apply to you. Why would we want the 'pre-loading' interface? As a plugin developer I might need to setup things before I can actually do my job, but this will take a long time and will slow down things if you assume I'm ready to operate the moment you call me to do something. A great example is a network connection. I likely need one and it should exist at the start before I do anything, but it might take a significant amount of time to get things situated and that might sit there blocking things if you expect me to respond instantly when you click some button. A 'pre-load' gives me a chance to set it all up. The same with the 'shutdown' interface where after that point the plugin code will never be touched. This gives me a chance to clean everything up and pack it away. More over, the 'pre-loading' interface will offer you the chance to pass me my logging channel/function/log file which I then can use through out the rest of the plugin's operation. You are logging things right? etc etc etc. A plugin != an interface that I load with a dll. It's a whole family of things around it that makes life easier.
[Matt Miller's slides from BlueHat IL include it](https://github.com/Microsoft/MSRC-Security-Research/blob/master/presentations/2019_02_BlueHatIL/2019_01%20-%20BlueHatIL%20-%20Trends%2C%20challenge%2C%20and%20shifts%20in%20software%20vulnerability%20mitigation.pdf). Slide 12
A wasm runtine (or any other java-like bytecode interpreter) would surteinly be more efficient than
For your specific use case, I'd suggest sticking with a scripting language. The custum mapper could be a simple lua function.
In particular, its implementation is... #[inline] pub fn from_bits(v: u64) -&gt; Self { // It turns out the safety issues with sNaN were overblown! Hooray! unsafe { mem::transmute(v) } }
True; I mostly associate unsafe traits with those built into and requiring some assistance from the compiler, but of course it's quite possible to have user-level (so to speak) cases. I wanted to simplify the presentation a bit, but perhaps it would be better to mention them for completeness.
Yeah, I know the title is a little hard to parse, so here is an example usage of [the slice-group-by library](https://github.com/Kerollmops/slice-group-by). ```rust use slice_group_by::GroupBy; let slice = &amp;[1, 1, 1, 3, 3, 2, 2, 2]; let mut iter = slice.linear_group_by(|a, b| a == b); assert_eq!(iter.next(), Some(&amp;[1, 1, 1][..])); assert_eq!(iter.next(), Some(&amp;[3, 3][..])); assert_eq!(iter.next(), Some(&amp;[2, 2, 2][..])); assert_eq!(iter.next(), None); ```
Rust needs to use garbage collection
Go has amazing readability and is easier to learn fwiw.. not sure if that’s relevant
It's going to be interesting to see what comes of the rust style safety features as more languages become interested in them. For example, D giving safety optionally gives a similar path towards safety that languages with gradual typing do for making the compiler better able to reason about the types of a language. I feel like we need both, so people who don't THINK they need the safety can start without it but as areas of their code warrant it they can sprinkle it in, while on the other end Rust and any other language that tries to bake these ideas in will give people/projects who need to always enforce it more ergonomic ways of doing so. Mind you I think we also need a new low level "do what thou will" style language that is more sanely designed than C++, but perhaps a well designed version of the gradual safety language can cover that.
FWIW, this appears to be handled correctly via `derive(AsBytes)`. See https://fuchsia.googlesource.com/fuchsia/+/master/garnet/public/rust/zerocopy/zerocopy-derive/src/lib.rs#190 and https://fuchsia.googlesource.com/fuchsia/+/master/garnet/public/rust/zerocopy/zerocopy-derive/src/lib.rs#555
How is endianness handled? Is it just assumed to be matching?
&gt; In fact, how would I even use a FromBytes instance? AsBytes has some "provided methods" but FromBytes does not seem to have any? It looks like `FromBytes` is what gives the power for `LayoutVerified` to impl `Deref`, such that internally it's just a byte slice, but `Deref` makes it "feel" like a struct. Looks quite nice to be honest.
Regarding point 4.2: Currently the standard library doesn't implement 2 `Iterator` traits, (`IteratorMut` doesn't exist). To achieve mutability a simple trick is used: there exists a method (`iter_mut`) in a given collection, such that the method return is a struct that takes a mutable reference to the collection. This struct does implement `Iterator`, but the `Output` type is a mutable reference to the collection's item, so the `IterMut` struct can implement `Iterator` just fine, but at the same time yield mutable references. This trick could be used in future implementations of your crate if you allow the implementors to specify the output type (for example via an associated trait).
Yes, although the crate does provide useful primitives for integers: https://docs.rs/zerocopy/0.2.6/zerocopy/byteorder/index.html See a specific type for more concrete details: https://docs.rs/zerocopy/0.2.6/zerocopy/byteorder/struct.U64.html
&gt; Where are you seeing inconsistent casing of type names? `str`, `i32`, `f64`, ... &gt; If you want to get rid of casts that do conversions, you have to get rid of practically every cast. Yes. Getting rid of the int &lt;-&gt; float casts would be a good start. `-1f32 as i32` should either be `-1082130432` or not compile at all. &gt; Structs and enums don't take arguments. A struct initializer can be thought of as taking arguments [...]. Enum variants already take arguments. Potato, potahto. They are the same. Make a thought experiment and assume they had the same syntax. Now imagine, somebody proposed giving them different syntax. That person would get laughed out of the room. &gt; This just amounts to which sort of delimiter you want, and that has nothing to do with the language. You make it sound like it's just some kind of personal preference – it is not. `&lt;&gt;` for generics has a terrible track record of working poorly in every language that tried to use it (C++, Java, Rust, C#, ...). `[]` has a track record of working without any discernible issues.
This is great. Sounds like a great opportunity for a crate to take care of all that boilerplate.
Backwards compatibility. You'd need something that allowed existing code to call the new functions without being aware of the new change. A better question would be what would enable it to happen?
thank you very much for the detailed answer. I wish I could do all that. At the moment I am in that stage that I am happy if the code snippets compile. I tried [libloading](https://crates.io/crates/libloading) but already failed to load the two fn I need for the Mapper. So I tested a simple "welcome" plugin, which if loaded displays a welcome message, before the actual output of the mapper. I also failed to understand how to pass multiple "plugin" paths from the cli using \`\`\`clap\`\`\`. There's lots to learn already. Never touched plugins before, but thought I should. I guess, it'll take a while until I can read about pre-loading.. The whole thing doesn't look too complicated, but like the borrowchecker, if you haven't understood how it works, simple problems can let you pull back for days. &amp;#x200B; last commit of my program with compiled plugin-library: [cyrconv](https://github.com/aspera-non-spernit/cyrconv)
FYI I'm not the author, just posting it here since it didn't seem to be posted before.
condvar.wait returns the guard.
Confirmed!
Ah, i think the one small piece of context you're missing is that Java's string API is badly designed! Or at least, designed as well as it could have been in the mid-'90s, which wouldn't pass muster today. In particular, note this remark in [`String`'s class documentation](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html) (my emphasis): &gt; A String represents a string in the UTF-16 format in which supplementary characters are represented by surrogate pairs (see the section Unicode Character Representations in the Character class for more information). **Index values refer to char code units**, so a supplementary character uses two positions in a String. For example, the main way of accessing characters by index is [`charAt`](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#charAt(int)), where: &gt; If the char value specified by the index is a surrogate, the surrogate value is returned. And even if you want to get a whole code point, using [`codePointAt`](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#codePointAt(int)): &gt; The index refers to char values (Unicode code units) and ranges from 0 to length() - 1. If the char value specified at the given index is in the high-surrogate range, the following index is less than the length of this String, and the char value at the following index is in the low-surrogate range, then the supplementary code point corresponding to this surrogate pair is returned. Otherwise, the char value at the given index is returned. If you want to view the string as a sequence of code points, your options are to iterate using [`codePoints`](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#codePoints()), or to do your own index arithmetic with [`offsetByCodePoints`](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#offsetByCodePoints(int,int)). None of those methods specify their complexity, but traditionally, `charAt` and the like are O(1), and i would expect `offsetByCodePoints` to be O(n). You can't implement those complexities on top of a simple buffer of UTF-8.
Right, but the point is that `repr(C)` makes the padding well-defined (using the algorithm defined [here](https://doc.rust-lang.org/reference/type-layout.html#the-c-representation)). That allows you to reason about whether Rust will add padding or not. It doesn't guarantee that there won't be padding, but it does guarantee the algorithm used to choose whether or not there will be padding. As long as the code in the custom derive agrees with the algorithm used by the compiler, then you're fine.
That's right, `LayoutVerified` is currently the powerhouse of the crate (but, sadly, not the cell). That may not be the case forever as we evolve the API surface, but it's true for the time being.
&gt;&gt; Where are you seeing inconsistent casing of type names? &gt; `str`, `i32`, `f64`, ... So what you're saying is that there should be no way of knowing whether or not a type is a primitive other than by rote memorization or looking in the spec/documentation? &gt; [...] Getting rid of the int &lt;-&gt; float casts would be a good start. &gt; `-1f32 as i32` should either be `-1082130432`, or not compile at all. I can't say I entirely disagree with that, but that's what *pointer casts* are for, i.e. ```Rust let f = -1f32; let pf = &amp;f as *f32; let if = pf as *i32; let i = *if; ``` If you are using `as` (or casting in general), you usually want the same value in a different type, so converting `-1f32` to `-1i32` with `as` would be the expected behavior for most programmers, if they come from a language with any casting at all. The particular conversions that I was talking about, however, are widening conversions, such as `u8` to `u16`. Since `u8` is eight bits and `u16` is 16, they are not represented precisely the same way in memory, so any such cast is a conversion, and removing casts that are actually conversions would remove the short method of converting a narrower integer type to a wider one. &gt;&gt;Structs and enums don't take arguments. A struct initalizer can be thought of as taking arguments [...]. Enum variants already take arguments. &gt;Potato, potahto. They are the same. &gt;Make a thought experiment and assume they had the same syntax. &gt;Now imagine, somebody proposed giving them different syntax. That person would get laughed out of the room. You literally threw out the most important part of my argument: that the context of the "arguments" to a struct initializer is significantly different from the context of the arguments to a function. The point of making a distinction between the syntax for one thing and the syntax for another thing when it's *possible* to use the same syntax for both is that the context of the two things is different. In this case, the difference in context is that, whereas a function takes arguments and does stuff with them, a struct initializer *always* moves (or copies, if its "arguments" are used after it) its "arguments" into an area of memory that has been provided for that struct *and does nothing else*. &gt;`&lt;&gt;` for generics has a terrible track record of working poorly in every language that tried to use it ([...]). `[]` has a track record of working without any discernible issues. Do you have any citations for that, or are you just making up data points to support your claims? Considering your treatment of my argument against turning struct initializers into functions, I'm more inclined to believe the latter.
Good to know! I'll add the relevant impls.
`assume_init()` copy data to another location (in release mode too). For example: &amp;#x200B; use std::mem; unsafe fn foo(p: *mut [u8; 1024*1204]) { println!("{:p}", p ); } fn main() { let mut p = mem::MaybeUninit::&lt;[u8; 1024*1204]&gt;::uninit(); let x = unsafe { //for example - pass pointer to FFI for init data foo(p.as_mut_ptr()); p.assume_init() }; println!("{:p}", &amp;x ); } prints two different pointers (even in release mode). So, you have at least 1 additional copy. This require additional memory allocate (may consume more CPU if data is big. For example, may occur various caching effects). So, `std::mem::uninitialized()` is broken, `MaybeUninit` may lead to potentially poor performance. May be, avoid both api is better way? For example, something like this: impl State { pub fn init() -&gt; State { let mut state = State(some_init_value); unsafe{ ffi::crypto_sign_ed25519ph_init(&amp;mut state.0 as *mut _); } state } }
You mean the rules for `FromBytes`? Essentially, a) the representation has to be guaranteed by the compiler and, b) all byte patterns are valid. In practice, this means that `FromBytes` is nicely recursive: It's defined for a set of base types (like `u8`, `isize`, etc), and then if all of your field types are `FromBytes`, it's valid for the type itself to be `FromBytes` as well. The way we arrive at that conclusion from the Rust reference is basically to look at the docs about the layouts of each primitive type. Types with validity constraints (like references) are obviously out, but anything else is fair game (since there doesn't exist an "invalid" instance of the type). Now, you still have to worry about uninitialized memory, but `&amp;[u8]` is itself guaranteed to be initialized, so it's not actually a problem.
Isn't that common with many major release updates? New major versions of things often introduce breaking changes. I am not sure why we couldn't, for example, have rustc issue a warning for the next year if anyone uses TypeOne saying "TypeOne will be removed from this or that future release. Please update the name to TypeTwo by running `cargo migrate-names --all` and we will replace all instances of TypeOne with TypeTwo in your code for you." Just one example off the top of my head.
The compiler can't prevent UB in safe code if it calls into unsafe code that violates the invariants it's meant to uphold.
Good point. I'd forgotten that they cleared out some of the legacy stuff along the way.
XxxGroupByKey sounds like a 13 years old's Call of Duty username.
_-oOXxx-group-by-key-xxXOo-_
strlen is a great name for blog that talks about memory management
Here is the suggestion from the compiler when you compile this code. error[E0596]: cannot borrow `*reader` as mutable, as `reader` is not declared as mutable --&gt; src/main.rs:19:9 | 18 | fn run(&amp;self, reader: Box&lt;Reader&gt;) { | ------ help: consider changing this to be mutable: `mut reader` 19 | reader.execute(); | ^^^^^^ cannot borrow as mutable It says to change `reader` on line 18 into `mut reader`. fn run(&amp;self, mut reader: Box&lt;Reader&gt;) {
Currently `Pipeline::run` is consuming the `Box`, which is probably not what you want. You probably want to be agnostic about how the object is stored and just pass a mutable reference to thing inside the box. fn run(&amp;self, reader: &amp;mut dyn Reader) { reader.execute(); } and then call like pip.run(breader.as_mut()); // or pip.run(&amp;mut *breader);
I kind feel embarassed, it actually worked. I don't know why but when it showed me the error I was under the impression that I needed fn run(&amp;self, reader: mut Box&lt;Reader&gt;) But this doesn't work. I didnt even realize that it was possible to use the *mut* keyword in that place, that only when declaring with let and in method signatures only *&amp;mut Type*. I lost my whole morning trying to understand this, should've asked for help sooner.
Nit: the blog is on GitHub pages, not on strlen.com (:. But least it's not `strlenLiQ�pjF�x$�39ݫҴ4�`.
Thank you for your answer, what would be the difference of using Box and getting a dyn Reader ? In a lot of examples I found about this topic, most of them seems to be using Box to work with this kind of scenario.
The idea of understanding which functions in *your* crate ultimately rely on `unsafe` code after following their call graph so that you can prioritize your testing is really neat!
Because of the Neuralink hype recently I decided to check their job offerings. I was surprised to see Rust being mentioned!
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=647dcb57a74263413a5ab0087cceabfe
File an issue on `vulkano`. Include a more detailed description of what's going on, and a minimal complete example. Those are the folks most likely to be able to help you with this. At a guess, you're missing some system (non-Rust) library that `shaderc-sys` depends on, but that's totally a guess.
It works in every binding: `let`, `match` patterns, function parameters, and so on.
golang's approach is badly designed and very error prone, because if you add a new field to a struct, the compiler won't complain, and simply assign the default value to that field.
All `non_exhaustive` does is requiring `_` in enums. It doesn't change this being undefined behavior.
Thanks, didn't see that.
&gt; implement two methods ... on your node-type How did you get this to work with third-party index-trees (e.g. petgraph)? When I was doing a similar thing newtyping the node type then made it incredibly awkward (and possibly even impossible, I can't remember) to work with. My solution was to instead implement the methods on the tree type, and everything became much easier for me.
A `&amp;mut dyn Reader` is agnostic to how the value is stored; a `Box&lt;dyn Reader&gt;` is (obviously) always stored in a box. (Btw people write trait objects like this with `dyn` nowadays; you can still write them as `&amp;mut Reader` or `Box&lt;Reader&gt;` though.) Passing a reference means you can use `run` even for things not stored in a box let mut reader = AReader { n: 1 }; let pip = Pipeline(); pip.run(&amp;mut breader); If all want to do is call some methods that take `&amp;mut self` you almost certainly want to pass as a `&amp;mut dyn Reader`. You only want to pass a `Box&lt;dyn Reader&gt;` if you want ownership of it (eg. to call some method that takes `self` like `downcast`).
There could be more timer-adding ones, so I would rather add a drop to the timer-running struct, which should be only one. I am thinking of an atomic bool.
Thank you very much for the clarification, really helpful. Coming from Java where everything is "mut", it's a little bit different to think with the rust syntax/rules in mind
It's just not a very clean presentation. I don't think knowing about compilers in general would help much.
This is really neat! I especially like your philosophy regarding "conservative" inclusion of dependencies; as a Node.js developer, and one who is highly concerned about security, I can attest that this can very quickly become an absolute nightmare. I'm looking forward to using your framework as soon as I get the chance. It looks to me like a great building block. One that, off the top of my head, will probably need expansion to be truly great (but you admit as much yourself). I'll see if I can provide more feedback when I get around to playing with it properly (perhaps contribute, but let's see).
Goes too complicated IMHO. * Imagine you have a vinyl disk with a great song. You bring it to a party. * Now the vinyl is only around for as long as you are. When you're done you leave the party and you're taking the disk with you. This is the lifetime of the vinyl. * Now I, the host, am here before the party and will be here when it's done. We can assume that all my things will be here through all the party, this is the `'static` lifetime. * You can lend your vinyl to someone. If you do they have to promise they'll return it back before your leave. So we can say the lifetime of the borrow must be less than the the lifetime of the vinyl's stay at the party. * You can lend the thing again, but they need to return it to you, so you can return it to the original owner. The lifetime of a reborrow is smaller than the lifetime of the original borrow. * Only one person can change the vinyl, rotate it, move it around, etc. This is a mutable borrow. * If someone plays the vinyl everyone can sit down and listen to it. But you can only listen to it while you share, if you try to change things people will complain is they're still listening. This is read only borrows. * Now before we had very strict rules, but someone made a good argument that sometimes we can play it a bit more loose with borrowing without breaking the party rules. For example someone wants to DJ choosing what song to go after. Because people get to hear the whole song, them stop listening, the DJ can change the song then. This is kind of what NLL did. * Say that someone instead brings an MP3 and shares it around. Now MP3s are really easy to copy around, so instead of borrowing the song, they just make you get a new copy of the song on your phone. This is what copy semantics are about. And that's what the idea behind borrowing and lifetimes. This article doesn't explain the above as much as explains how the compiler makes sure the rules are followed, which after NLL is a bit complicated. The math and such is good once you have an informal understanding. When you formalize you realize that some use cases that should be ok cannot, understanding the logic of why helps work around.
&gt; Regarding point 4.2: &gt; &gt; there exists a method (iter_mut) in a given collection, such that the method return is a struct that takes a mutable reference to the collection. This struct does implement Iterator, but the Output type is a mutable reference to the collection's item, so the IterMut struct can implement Iterator just fine, but at the same time yield mutable references. Wait i think that might actually already work with the current implementation, you can just implement on &amp;&amp;mut Node, gotta check that out tomorrow. Thank you for the input! &gt; Also great project, bound to be useful. Thank you, its not quite finished yet, but i hope so too :)
That's what I thought. :(
I am not sure i completely understand the question, but i will try answering anyway: You can keep an index and a reference to the underlying connection in your Node type (like LinTree in the example folder does). If your Node type does already do that but is external then yeah, you need to work around the orphan rules.
&gt;The notable exception is memory leaks. This is purely speculation, but I'd hazard a guess that (while you're right that Rust can't prevent these), the strictness around ownership might help somewhat with leaks, as well.
No need in manually dereferencing box here.
And also have a network of smart people around them to fill in the gaps.
That automatic deadlock detection though.
I get error[E0277]: the trait bound `std::boxed::Box&lt;AReader&gt;: Reader` is not satisfied --&gt; b.rs:17:11 | 17 | pip.run(&amp;mut breader); | ^^^^^^^^^^^^ the trait `Reader` is not implemented for `std::boxed::Box&lt;AReader&gt;` |
&gt;You can use VirtualBox to run MacOs Since when?? I thought that was virtually impossible unless you're doing some really hacky open-source build with darwin and gtk or something. I've never seen this in malware reverse engineering. People typically use a real laptop with deepfreeze. There's benefits to using real hardware over a VM of course but if OSX can be run in a VM, I haven't seen it.
Been playing a bit of it and having fun! Question though, will you eventually support speeding it up a lot more than the current max speed? It can take minutes to run a test that goes through each stage, and only fails on the last.
This is perfect for what I need. Thank you!
Huh, it feels inconsistent with deref coercion in other cases
The standard library gives a user-level case: When your safety invariant is dependent upon an actually correct implementation of the trait. For the standard library, it has TrustedLen which says that the .len() method must be correct or it can lead to UB.
FYI, you can switch to a specific stage before running it! It'll do that one first, then the rest. Also, make sure both software and world speeds are maxed.
Dipping my toes in Rust for the first time. It's been like ten years since I last touched systems programming, and that was for a university course. I'm following https://github.com/ssloy/tinyrenderer/wiki but implementing in Rust as I go. I started Thursday and am on adding normal maps now. Did not want to depend on anything so I had to create OBJ and TGA readers as well as the rendering and geometry stuff, and something to export images (PBM rules!). It's been real fun learning with something graphical, and the borrow checker is really not that bad (I only have 686 lines of code though). When it compiles it works (well, except my math but that just gives nice images), which is not my memory of writing a simple ray tracer in C for school, I remember quite a few segfaults.
You can tell that it's still UB by the fact that you can exhaustively match a `#[non_exhaustive]` enum if you're in the crate that defines it.
I think it is relevant. This thesis would be wrong to conclude Rust is better on all points IMO.
By the way, [https://crates.io/crates/zerocopy](https://crates.io/crates/zerocopy) misses a link to [https://docs.rs/zerocopy/0.2.6/zerocopy/](https://docs.rs/zerocopy/0.2.6/zerocopy/). Consider adding.
People can absolutely have burn-out, or want to retire from a project. That's fine. But again there are good ways and bad ways to do it. For an example of it being handled well, see &lt;https://github.com/rust-itertools/itertools/issues/354&gt;: say it's happening, find someone to take ownership, move it to a new org instead of being a personal project, success. (And don't do things like closing PRs with sarcastic messages.)
Basically my worry is that all of your examples are using types that you've implemented yourself, I'm interested to know how awkward it is to use with a third party library. Edit: Something like [this](https://gitlab.com/seamsay/reingold-tilford/blob/master/examples/index.rs), is what I'm talking about. When the trait is implemented on the node instead of the tree, this becomes far more awkward.
Glad to hear it!
&gt; So what you're saying is that there should be no way of knowing whether or not a type is a primitive other than by rote memorization or looking in the spec/documentation? Yes. Special-casing things for the sake of sustaining more special-casing elsewhere is a poor idea. &gt; The particular conversions that I was talking about, however, are widening conversions, such as u8 to u16. Since u8 is eight bits and u16 is 16, they are not represented precisely the same way in memory, so any such cast is a conversion, and removing casts that are actually conversions would remove the short method of converting a narrower integer type to a wider one. These conversions are not casts. Get rid of them. That's the point. &gt; You literally threw out the most important part of my argument [...] I threw them out because I didn't considered them that important. &gt; a struct initializer always moves (or copies, if its "arguments" are used after it) its "arguments" into an area of memory that has been provided for that struct and does nothing else. So if I write a function that wraps nothing but a struct initialization, I should be able to call that function with `makeStruct{myArg1, myArg2}`? I hope this helps you understand why the argument was not worth picking up on. &gt; Do you have any citations for that, or are you just making up data points to support your claims? I provided some initial hints in the part you conveniently snipped away in the quote. I would have been happy to expand on the language you were unsure if if you asked. &gt; Considering your treatment of my argument against turning struct initializers into functions, I'm more inclined to believe the latter. And I think this is where I bow out. I like to discuss things to learn and expand my understanding of things; but I'm getting the impression you are more interested in winning an argument, so I'm leaving you to that.
Top right of the screen is game speed, maxed out means why level will complete in no time
A small repo improvement you can make is moving the examples to the top level; this lets people run them via: cargo run —example=whatever And they can tweak them easily to play around with them.
Thats how i had them originally, but i am also using them in my doctests/examples so not sure how to do that without duplication. Maybe keep the types in-repo and move some methods out?
This is really cool! A suggestion: It looks like if you declare a struct as `derive(FromBytes)`/`derive(AsBytes)`, it will deserialize/serialize (respectively) all of it's fields, including _non-public_ fields. This could break modularity (e.g. adversarial code could use this to read non-public sensitive fields, or craft values for private fields that break invariants of a type). It seems like one guard against this is that the traits are `unsafe`, which means you need `unsafe` (implicitly anyway) to derive this (so you can at least prevent untrusted code from using this crate at compile time). I wonder if there is a way to either restrict this to only public fields, or to only admit structs where all fields are public (and all of fields of each field that is a struct are public, etc)? That might be just as useful for network parsing/serialization while also making it safer to use.
\`mem::forget\` is a clear sign of leaking something, so it won't be too hard to debug (unless you are doing a lot of it, which is unusual outside of working with unsafe code that transforms the forgotten values). Also yes, it is \*possible\*, though not easy, to create loops with \`Rc\`s. Have you tried doing it on purpose? &amp;#x200B; And yes, you can certainly deadlock your threads – though this will be more and more unlikely, with async/await becoming the norm. &amp;#x200B; Even with that, I have to agree that unsafe has its uses. For example, my \[bytecount\]([https://docs.rs/bytecount](https://docs.rs/bytecount)) crate uses it for SIMD, and my \[compact\_arena\]([https://docs.rs/compact\_arena](https://docs.rs/compact_arena)) uses it for unchecked indexing (which is sound because the indices are bound to their arena by a lifetime, so the type system keeps you from messing up) and \`MaybeUninit\`. But if I can reduce the \`unsafe\` code without imposing any pessimization, I'd do so instantly.
I mostly agree with this post, but I think it's implicitly assuming use-cases where e.g. security is critical or important. I touched on this about a half year ago in a [https://blog.cessen.com/](blog post of my own): I think Rust has many different use-cases, and in some of them some of them have (legitimately) different priorities. In short, I don't think every use-case needs to be so concerned about accidentally invoking memory unsafety or other UB. For example, I'm not really concerned about my offline 3d renderer having UB, except insofar as it makes it harder to debug. For that use-case, UB is just another kind of bug, not more or less important than any other. But for things that are e.g. web facing I think the approach laid out in the OP makes a lot of sense!
Not specifically about Rust, but mentions it and the approaches are absolutely applicable and relevant.
By then we may be able to make dependent types really usable for mortals. I hope to live to that day.
I think that those people who "don't THINK they need the safety" should perhaps reconsider if they really need the performance. Going a bit slower in exchange for safety and ergonomics might be a good tradeoff.
Gotta secure that brain link code
You don't wanna segfault mid-neuratransfer
In vec3 does it make a difference (in perf or in the borrow checker) using the xyz getters v accessing the fields of the struct? Using the fields seems more natural.
I have this code that is cropping a folder of images using `par_iter()` for parallelization but am not sure how to handle the Result within the closure. What I want to happen is if the `crop_image` function returns an error, I want to notify the user on stdout and continue to try cropping the rest of the images. The issue I'm having is I can't use ? to bubble up the error and if I use a match expression I end up with incompatible match arm types: match x { Ok(path) =&gt; path, Err(e) =&gt; println!("Error: {:?}", e), } I've read various examples on error handling but don't see many examples for what to do with closures. use glob; use image::imageops; use rayon::prelude::*; use std::error::Error; use std::path::{Path, PathBuf}; pub fn crop_images(image_paths: glob::Paths) -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { // Collect elements into a vector for iteration. let col: Vec&lt;PathBuf&gt; = image_paths .map(|x| x.expect("Unreadable path!")) .collect(); col.par_iter() .for_each(|path| match crop_image(path, 500, 500, 100, 100) { Ok(()) =&gt; (), Err(e) =&gt; println!("Cropping error: {:?}", e), }); Ok(()) } fn crop_image( path: &amp;std::path::PathBuf, x: u32, y: u32, width: u32, height: u32, ) -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let parent = path.parent().unwrap(); let name = path.file_name().unwrap(); let ref mut img = image::open(&amp;path)?; let subimg = imageops::crop(img, x, y, width, height); let save_path = parent.join(Path::new("cropped_images")).join(name); subimg.to_image().save(save_path)?; Ok(()) }
Wrong sub bruh.
Ok, so one solution to this is to collect Results instead of trying to handle the error in that closure: pub fn crop_images(image_paths: glob::Paths) -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; { // Collect elements into a vector for iteration. let col: Vec&lt;Result&lt;PathBuf, glob::GlobError&gt;&gt; = image_paths .map(|x| x ) .collect(); col.par_iter() .for_each(|path_result| match path_result { Ok(path) =&gt; match crop_image(path, 500, 500, 100, 100) { Ok(()) =&gt; (), Err(e) =&gt; println!("Cropping error: {:?}", e), }, Err(e) =&gt; println!("Error: {:?}", e), }); Ok(()) } This works but feels a bit verbose with the nested match statements within the closure.
But if they used C, just imagine all the trendy names security researchers could give their buffer overflow vulnerabilities!
Another option is spawning a separate process and using IPC to communicate with the plugin. This isn't necessarily suitable for all purposes, but allows writing the plugin in any language, and doesn't require unsafe code.
Community yeah (and hiring)
So isnt that a good solution?
You're missing a final }
Hey. I'm not really interested, but I guess you would have a bigger audience by posting what you're actually working on.
I can't imagine a more important place you'd need it.
I think [filter\_map](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter_map) would work well here. Something like: let col: Vec&lt;PathBuf&gt; = image_paths .filter_map(|path| match path { Ok(path) =&gt; Some(path), Err(err) =&gt; { println!("Error: {:?}", err); None } }) .collect();
Require NDA for it. But it's a very good opportunity.
Thanks for the input :)
Thanks, but that was just me writing it out wrong. When the string doesn't have the escapes it parses. Note: edited original post.
Pardon my ignorance but I wonder if this is use-full for implementing a different "enum" where the values are as \*small\* as required? I'm building a interpreter that is similar to kdb: &amp;#x200B; #[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)] pub enum DataType { None, Bool, I32, ISIZE, I64, // Planed: F64, Decimal, UTF8, } #[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)] pub enum Scalar { None, I64(i64), UTF8(String), ... ... } #[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)] pub struct Vector { kind(DataType), len:usize, data:Vec&lt;Scalar&gt;, } So instead of have arrays when each member is as big as the biggest of the enum I could be as small as a native Vec&lt;T&gt;.
Does the NDA stop you from saying where the job is? Whether it supports remote work? What the company is? What skills are expected? What level of experience you’re looking for? These are basic job posting details that aren’t provided in this post.
Even if you can't say the product itself, you'll get more responses and higher signal if you post the space. Rust has promise for so many things, and not all skills overlap. High volume web services, embedded/microcontrollers, big data analytics, video games...all things Rustaceans might want to work in but that are generally separate specialties. Hopefully the space is general enough that you don't need an NDA for it.
Mini-experience report with the caveat that I'm a complete rust newbie. I tried using `zerocopy` to read a structured data file and ran into a couple issues. - I couldn't figure out how to use the `FromBytes` trait to interpret a value from a byte slice. Specifically, I wanted to grab 4 bytes as a little endian `u32`. I'm sure this is straight-forward but I wasn't able to figure it out. I ended up using byteorder like so but I'd like to know how to use zerocopy for more complicated structs. ``` let mut footer_size_bytes = &amp;bytes[bytes.len() - 4..bytes.len()]; let footer_size = footer_size_bytes.read_u32::&lt;LittleEndian&gt;() .expect("4 bytes guaranteed"); ``` - The Intellij Rust plugin froze multiple times using autocomplete with byteorder. I suspect it's from the plugin trying to resolve the macros used for the primitive derives.
Perf-wise, it should get inlined in release mode, so no real difference. The only actual difference is offering read-only access even the caller has write access. Given vectors, it may make more sense to just construct a new one rather than modifying the fields of an old one.
Your recruiting skills need work.
It includes having to relocate, which is a turn off for most when they read and it's easier to convince them personally. I got 5 replies already on PM, should be good to go. PS: Can't talk about the company in public as it will put a record for life on reddit which is why. Different set of skills is possible (Both beginners and advanced).
I hire all the time that way :) Got 12 guys already in the team by using reddit &amp; chats.
Feel free to PM if interested, salary is great.
I'd rather fight the compiler than the production logs any given day
PM, highly interested
honestly, as long as you write sufficiently idiomatic go code and some basic tests for your data structured, you don't need to fight anything. TDD is serving me really well.
Ghi object has been stringlified twice check the place which generates json string.
Well done!
It would be nice to have an “unsafe rating” displayed on the crate page on crates.io. Just the number of unsafe expressions compared to safe expressions. That way you could make a quick validation whether you’re willing to take the risk of using that crate.
I'm in the middle of doing this myself where I work. So far, it has been a pretty painless experience. At first I was hesitant to even introduce Rust as most of the devs are Node.js guys, but once I started talking about rewriting some troublesome C++ code in rust and I got to go ahead. Since then, more and more of the company is getting interested in Rust. Here's some things that helped: - I put together some simple C++/Rust comparisons (out of bounds array access, use after free, iterator invalidation) to show the borrow checker/compiler at work. These even got the Node.js guys who wouldn't touch C++ because its "horribly insecure" interested. After that people seemed to "get" Rust without having to play with it themselves. - I was showing it off to the QA lead and he liked that testing was baked right into language its self. "What, it also tests the examples in your documentation!?!?!" -- mind blown. - I just started posting stuff about Rust in the company's #random Slack channel. Last week I posted an article about Microsoft giving it a try and the CEO responded saying he downloaded Rust and was giving it a try. I don't know, Rust seems to be gaining momentum and just talking about it with other devs at least sparks their curiosity. So far no negative experiences, but we're still in the early stages, so we'll see how it goes.
Judging from this guy's posting history, he's offering $70k to people willing to relocate to the Philippines.
That depend of the profile, but yeah, salary isn't low as i said earlier.
I don't know who you're expecting to reach here, but a plurality if not the majority of the readers are in the US. In the US market, that's very low even for entry level, and ridiculously low for people with any experience, even before you consider the prospect of relocation.
$6500 a month is low? 60% of our guys are from US so you are wrong on this.
Want to bet on whether this is yet another cryptocurrency scam? :)
Dress up in a crab outfit with a boom box playing vanilla ice. Once you gather a small circle start telling them about rust.
Does the network stack do more than "just ping" now? Have you done any benchmarks yet?
I'd recommend making this first project stand out. If you can do some clear measurements of before and after you can make a stronger case for rust. For example, performance benchmark (runtime, system utilization, etc.), Code size, complexity, etc. Anything you can show to further strengthen the argument of why the rewrite was worth it.
Can confirm that this kind of cash in .ph will be very comfortable living. The only downside is the humidity in Manilla.. but if you are good with that I imagine this would be a lovely sea change. Phil people are usually very kind.. corruption has loweree in the past few years and the quality of life seems to be continually increasing. I am Australian and don't know the company and can only talk about the twice yearly visits that I go to Manilla/philipines for the last 12 years for work and family reasons.
Yeah, totally agreed. Living in the PH with that money will get you a villa with swimming pool, restaurants 3 times a day, maids, drivers...
Not crypto related
I'm sure it's great for .ph, but not many people are going to want to take a huge paycut to move to a developing country.
A lot actually do
Lot see it as a chance, it all depend, but millions of expats are voluntary coming to Asia for a better life.
I usually use them mostly instead of regular function parameters as an optimization. For example, see `or()` vs `or_else()` in `Result&lt;T, E&gt;`.
In a previous life, I convinced my company to let me introduce Haskell. ([blog](http://andyfriesen.com/2014/03/25/what-its-like-to-use-haskell.html)) Some of the general principles still apply, I think: Be very upfront about every single thing you are doing. You do not want to surprise your colleagues in any way. In particular, make sure that your superiors agree that you are taking sufficient steps to contain risk. Go the extra mile to open the code up to your colleagues. This is not your code. It is *everyone's* code and it's good for your cause if your colleagues start making changes on their own. If they show any interest, be there to answer their questions. Pick a relatively straightforward coding style. Pick a subset of Rust that your colleagues will recognize. Consider avoiding extensive use of Rust's iterator API, for instance. It's harder to use a bit of code as a positive example if your colleagues think it looks weird. Good luck!
Recently I was thinking on even a more difficult problem. I want plugins in different libraries and I also want to be able to distribute my app as a statically linked binary. The reason is that I want it to be dead simple to execute: wget URL\_WITH\_PLUGIN\_MACOS1 ... wget URL\_WITH\_PLUGIN\_MACOSN wget URL\_MAIN\_APP\_MACOS ./main\_app Obviously the same would be available for other OS. Now, if this is done this way I can imagine each of those plugins even if they have very little code they are going to be pretty big (10 MB for few lines of code). That if it is even possible to compile those libraries that way and load them later. Any advise welcomed
I recommand avoid having unused_import. Warning are here to help you improve your code. Not wasting your time. Anyway: https://lmgtfy.com/?q=disable+unused_import+warning+rust I mean, next time, just google it directly.
Author here. Happy to field questions!
Honestly I don't think that's a great metric. It's hard to know how to count e.g. FFI or macros with unsafe blocks. More importantly, one badly-written unsafe can be a disaster while a hundred proven-correct ones are fine.
#[allow(unused_imports)] But ya... Clean your code and make sure you're using them somewhere in your compilation or this is just time and bin size wasted...
braindrain: researchers discovered a DoS attack that could trigger memory loss anxietyattack: continuously spawning Calendar objects with the "work" tag caused a DoS that triggered paranoia and anxiety they practically write themselves
At a higher level, I tend to think of closures as localized one-off functions that don't really need a name, or even if a name could help and are worth assigning to a variable, they're not worth adding to the class API (even if private). Much like a local variable vs. a field. I am sure the book is trying to be fun, here, walking you along the path of incrementally adding closures into some easy to follow code, but if you want a simpler, real-life example, using closures with lists is how I came to understand why they could be useful. For example, let's say I have a list of String representations of numbers. ["3", "1", "10", "200"] Now, I want to sort them. But should I use the alphabetical sorting, or should I parse them and use numerical sorting? You might imagine at this point creating a `StringNumberList` and adding two methods to it, `numericalSort` and `alphabeticalSort`. OK, but what if I want to sort in descending order? Maybe add a `reverseNumericalSort`? Or add a parameter to `numericalSort` which is a boolean indicating direction? What if the current locale makes a different on the String sorting, e.g. "1,234" vs "1 234" vs "1.234"? OK add another method that takes a locale parameter.... and then also a ascending/descending parameter for that method too... But wait! After you finish `StringNumberList`, now I want you to create a list of "Person" instances. I guess you need a `PersonList` now. And in this case, I want you to sort by their first name. In that case, their last name. Also their age! Oh here, their ID. Here, I'd like you to calculate heir distance from the North Pole and sort by that. Without lambdas, things get out of hand pretty quickly, and your code ends up playing this constant game of catch up. With lambdas, you get to identify the general algorithm you want to support (`sort` in my above examples) but find a piece that you can offload to the caller. For example, provide a closure that takes two values A &amp; B, and returns &lt; 0 if A is smaller, 0 if values are equal, and 1 if A is bigger). Now enjoy your infinite flexibility! ``` // Note: The following is psuedo-code numList = ["1", "2", "3", "4"] numList.sort(|(a, b)| -&gt; a.compareTo(b)) // Alphabetical sort numList.sort(|(a, b)| -&gt; a.toNum().compareTo(b.toNum()) // Numerical sort numList.sort(|(a, b)| -&gt; b.compareTo(a)) // Reverse alphabetica sort numList.sort(|(a, b)| -&gt; rand(-1, 1)) // Random sort ``` I hope that helps. Apologies if you already understood this and just wanted to know why specifically they were using closures in the book example.
I would still get a slice of `MaybeUninit`s instead of slice of `u8`s.
My understanding -- and I'm a novice at best -- is that you're allowed to write a future that always tells the waker to call them again, and to write an executor that always polls everything (that said pending last time). It'll be suboptimal for performance, but it'd work. I think the other way -- a future that never tells the executor to wake it up -- can't be expected to work.
I'm not sure I understand your question, but it seems to be more general, and not specific to Rust. If you need to visualize a tree for debugging purposes, you can try to output a [GraphViz](http://www.webgraphviz.com/) file, and view it later. Since you mention that your nodes have too much text, you can start off by summarizing it (displaying the first and last words, for example). If how, you can print it to the terminal, or convert it to XML, of course. &gt; From my research so far I've found a multitude of crates like "trees" (it's the first one that comes up in a google search (is it the official one?)), rust-forest (but this seems abandoned), cursive tree view, pretty print tree, treeline, pretty.rs and ptree. Some of those crates are designed to help you represent tree data in memory. `pretty` seems to be designed for things like S-expressions, others are for text user interfaces. None of these will work too well directly for text that's as long as yours. There's also `petgraph`, although not necessarily designed for trees. But anyway, there are two points here: - the in-memory representation - the method you use to display your tree The two should be decoupled. Your choice of data structure shouldn't influence the way you show your trees on screen.
You need a few things here. First, you want to derive `Serialize` for the `Packet` type itself - that's required for Serde to know how to serialize it. Then you want to specify that your `T` also needs to implement `Serialize` - otherwise Serde won't know how to serialize it.
Check out my new rust server. [20X][ZombieSquad][MODS][ZOMBIES[RPG][PVP&amp;PVE]
I (quickly) read through the this part of the rust book and I'd say, it's not super great at explaining their value. I prefer: [https://en.wikipedia.org/wiki/Closure\_(computer\_programming)](https://en.wikipedia.org/wiki/Closure_(computer_programming)) There are many reasons closures can be powerful, and wikipedia does it some justice. &amp;#x200B; In your specific case, the advantage to a closure would be reducing code duplication, which means if you make a change you're less likely to introduce a bug: e.g. \`\`\`fn generate\_workout(intensity: u32, random\_number: u32) { let expensive\_closure = || { simulated\_expensive\_calculation(intensity) }; if intensity &lt; 25 { println!( "Today, do {} pushups!", expensive\_result ); println!( "Next, do {} situps!", expensive\_closure () ); } else { if random\_number == 3 { println!("Take a break today! Remember to stay hydrated!"); } else { println!( "Today, run for {} minutes!", expensive\_closure () ); } } }\`\`\`\` &amp;#x200B; Here, lets say you change the input of simulated\_expensive\_calculation to \`simulated\_expensive\_calculation\` from \`intensity\` to \`intensity+some\_other\_expensive\_cal()\`. In your example you have to change the code in two places and you might miss changing one (or more if there are many uses). Also if the logic in expensive\_closure gets more complicated you just end up with code duplication, and people have to read to see is the calls at the different sites the same or not. When you use a closure, code readers, including your future self, know it's the same.
r/playrustservers
You're double escaping xyz?
so i've never used rust, but is there any chance the method you're using to print a string is inserting backslashes before double quotes? that would explain what you're describing, and the unescape function that turned the triple backslach into a single one would probably be what you'd need to use.
I'm prototyping stuff with rust. So, I don't care about unused warning right now. That's why I scope the question to be as narrow as possible. I'd appreciate it if you could tone down your condescending tone. Thank you.
Maybe an example will help. At work we commonly use closures with our 'policy' objects. These policy objects are things which handle some type of behavior which is applied 'around' some chunk of code. Example: only call this closure the first time through this polling loop. Call this closure no more often than every 5 minutes within the polling loop. This closure is tried no more than three times (with incremental back-off!) and on the third failure bubble up the exception, etc etc etc. These policy objects are used all over the place as these policies are pretty standard, but the code these policies are applied \*to\* changes per plugin of the project. The closure is like a function pointer which also captures variables in the scope. That is essentially the entire point of closures, function pointers which can capture variables in scope and pass those along with the function pointer. Think of 'try' in c#. Imagine 'try' was implemented as a function. You could do it with a closure for the try component, a closure for the 'except', and a closure for the 'finally'! the stuff within the try block, the except block, and the finally block would be closures in this case. no, this isn't how it's done, but it's conceptually how you could build a poor mans version. You could build your own 'code that goes around other code' using closures just like this. The classic example is 'sort' where you pass in your own compare closure.
1. You need to `#[derive(Serialize)]` on the struct, otherwise `serde` won't know what to do with it. 2. You have to specify proper bounds for generic arguments, e.g. `Debug` if you use `{:?}` and `Serialize` for `serde`. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a6adb95c9081bacc2746b0d74d816405
I saw this answer before but it seemed I needed to add that line to every file. Is there a better way? Fyi, I am not cleaning imports right now because I'm prototyping with Rust (adding/removing a lot of code). My question didn't contain context because I wanted it to be narrow as possible. Because I'm not sure if I'm ready to debate whether or not we should clean imports while prototyping.
Answering with lmgfy is condescending, borderline hostile, tbh. But it seems you disagree.
You're right (and yes to your questions), but futures are really designed around parking a thread and waiting until the future is ready. The 'context' is just an abstract way to refer to place where the future is executed. Now imagine you have a lot of threads running at once, each trying to execute various futures. Your implementation is going to have every task looping on every future they execute. This has two major consequences on the performance of your operating system (OS), and subsequently your application. One, the only way your tasks are going to be scheduled is by preemptive means, which *generally* means that threads will run for whatever length of time is allocated before the OS replaces it with another thread in its ready (to be processed) queue. This queue also has a problem thanks to the secondary issue of your implementation, *every thread will be in the ready queue* because they all want to be running at the same time. The idea behind future is to park threads for the period of time the cannot do any work because they require the output of some operation out of their control. The wake function is generally implemented as a callback that just un-parks the task (However it is required that the next call to poll will return *Ready*). Really the only thing that is different to your implementation is that the task is parked when *Pending* is returned by poll. The implementation of await looks just like this. However a basic loop can be a perfectly fine way to poll a future, it really depends on what your application is and what you want to do. An example of where this might occur is a bare metal system (no OS).
If you add `#![allow(...)]` at the top of lib.rs and/or main.rs, it will work for the whole crate.
My favorite analogy for the learning curve of dependent pattern matching is indeed the lifetime system, so you may be right...
Converted my website from Racket to Rust using actix-web. Motivated by [web framework benchmarks](https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=json). Memory usage down by 50x, response times are 100x faster. Can't wait Rust to take the #1 spot on the [benchmarks game](https://benchmarksgame-team.pages.debian.net/benchmarksgame/which-programs-are-fastest.html).
You know that there are [raw strings](https://stackoverflow.com/questions/26611664/what-is-the-r-operator-in-rust) in Rust so you don't need to escape your double quotes?
TBH, they’re not alone in disagreeing with you on this. You were given constructive criticism, about both your development habits and your approach to solution discovery. The arrival of the latter in a slightly flippant form doesn’t make it any less constructive. Your initial query could have been answered by a single term search for `unused_imports` in Google, StackOverflow, or indeed Reddit. You’re getting a bit of flippancy because asking a question that easy to answer for yourself is can be interpreted as a way of saying your time is more valuable than others, since anyone who doesn’t know the answer will do precisely the work you could have done on your behalf to get you the answer. Now if you’d done that search and then turned around and asked how to apply `allow` to your whole project, which isn’t quite so trivially discovered, it wouldn’t have invited that criticism, and this also wouldn’t have invited the flippancy. Similarly if you’d added more context to your post you could have avoided at least some of the pushback on what, without context, looks like a bad development habit.
whoa this was… really good. did you just write this or did you read it somewhere, because i need to show this to everyone i know learning rust.
Low-level async I/O primitives, like the implementations of `AsyncRead`/`AsyncWrite` for a socket, use the `Waker` handle to schedule re-polling only when the socket is reported ready by the OS. There are other cases where `Waker` is used to schedule wake up without immediate re-polling; this basically, is what should have occurred somewhere in the async polling "tree" of the future when it returns `Pending`. So if your `Future` implementation involves waiting on an I/O object, or a timer, or any future that may include such waiting, it needs to pass the `Context` from the executor. In the interest of hiding implementation details, the `Context` is always passed down the stack of `poll` methods.
Nodejs guys finding C++ insecure. I work mostly on it, and at least it's in typescript, still do I hate this language and all the lies it makes to you...
Congratulations! Do you have anything in the way of documentation for the workspace support? I've used `cargo-release` before, but only a little, and my workaround was to go to each of the workspace crates and publish them independently, in the proper order.
We actually do have that ability to some extent, but unfortunately there is a long way between "a Coq formalization exists that validates the code" and having it integrated into the Rust compilation toolchain.
While I agree, it's worth noting that proving 100 lines of nontrivial unsafe Rust safe is an *extremely* large undertaking at the moment.
Yeah, "100 proven-correct" is a bit of hyperbole. I am fine with a reasonably large number of unsafe blocks if every one of them has a comment carefully arguing the safety and explaining the need. A single unsafe block that could be easily replaced with safe code is worse. A single unsafe block with actual UB is way worse.
This. Most times you can just use stdin and stdout. FIFOs work too. The only reason this may not be suitable is if the data is too expensive to copy (large, on the GPU, etc) or the latency constraints are incredibly tight.
Thanks /u/WellMakeItSomehow, we will add doc/descriptions on releasing workspaces. At the moment, you can use \`cargo release --dry-run\` to see what \`cargo-release\` will actually do
Nice work. I did something similar. I recommend looking at adding the rayon library for multi threading. It's quite easy to add and your rendering will speed up a lot.
Yeah, I more or less agree. Just currently a bit frustrated with how difficult it is to prove unsafe code correct if you're doing anything interesting, since I think a lot of the complexity is artificial at the moment... but I guess that's not that surprising since this stuff is still in the "if you can even prove the API correct you get to write a paper" phase and probably years off from the "how do we make this ergonomic and actually usable without getting a Ph.D." phase. We were happy (and surprised!) to hear that a class was actually using the Rust formalization to teach students, which apparently means that a bunch of standard library Rust data structures have now been verified without anyone knowing...
Thanks, I'll do once I am back at home - if so I am disappointed in my knowledge of semver though. `shaderc-sys v0.5.0` worked, but the bug-fix release did not.
I can't see any particular disadvantage to it
Braindead: a deadlock occurs that causes an indefinite coma
Pardon me if the question is dumb, but why it's a desirable feature that this doesn't use the standard library at all?
Hey WellMakeItSomehow, thanks so much for your suggestions! Can you explain what part of my explanation is confusing? &amp;#x200B; How much info for starters shouldn't be important as my processing should (for my basic info) basically take a bunch of sentences and deconstruct them (based on key words present) into a tree. Essentially taking an array of information and continuously subdividing it until all key terms have been processed. I can display like a small number of words for now, later on I'll probably change things up anyway. &amp;#x200B; I'll start with the in-memory representation, for this I'm leaning towards: [https://docs.rs/trees/0.2.1/trees/](https://docs.rs/trees/0.2.1/trees/) as it seems to be quite well documented, however I'm confused why exactly it isn't mentioned anywhere on the web? Also I'm confused whether it'll be possible to create the tree going from the bottom nodes and gradually throughout the programs lifetime add in their parent nodes (must have for me). &amp;#x200B; For displaying the tree, GraphViz seems good, however the Rust crate is marked as unstable, so I don't think I'd want to use it (unless you know that it is stable enough to generally output a decent tree without any troubles?). So from what I'm getting from what you're saying the method to display the tree doesn't affect my choice of in-memory representation/datatype at all? So aren't most of these like the same to me then? &amp;#x200B; Feel free to tell me if I'm doing something wrong/in a weird way! Thanks for your help
Might want to use four spaces to indent your code instead of \``` for the code block, since noq your formatting is way off.
Thanks !
I'll look into that, thanks !
Yeah that should work. Maybe "U Can't Touch This" would be a nice addition to the playlist!
Huh neat, I recently attempted implementing an NBT library using serde as well! Can't help you with this one unfortunately, as I got stuck on the distinction between generic Lists and typed Arrays on the Rust side. How are you dealing with that?
Thanks. Can we have Serialize, Deserialize at a same time for the struct or must define only one ?
If you're using wasm, you should know js or similar. If you're looking to do embedded, you might need to make C bindings for libraries not available for rust.
Holy shit, that was a great explanation!
You can, just tyr it.
Brb scouring Craigslist for a boombox
\&gt; If caching (memoization) is a desired goal as it is by listing 13-11, we could implement the hash map cache just as easily without the closure, no? &amp;#x200B; What the book demonstrates is that you can implement an API like \`Cacher\` without regard to how the value is calculcate. So anyone can re-use \`Cacher\` for a completely different calculation by swapping out the calculation closure \`T\` for something else.
&gt; For displaying the tree, GraphViz seems good, however the Rust crate is marked as unstable, so I don't think I'd want to use it (unless you know that it is stable enough to generally output a decent tree without any troubles?). Worst case scenario, you can output GraphViz markup manually and call `dot` as a subprocess. That just relies on `std`.
&gt; Can you explain what part of my explanation is confusing? You're mixing up the data storage and visualization, and it's not really clear whether that's intended or not. &gt; I'll start with the in-memory representation, for this I'm leaning towards: https://docs.rs/trees/0.2.1/trees/ as it seems to be quite well documented, however I'm confused why exactly it isn't mentioned anywhere on the web? Also I'm confused whether it'll be possible to create the tree going from the bottom nodes and gradually throughout the programs lifetime add in their parent nodes (must have for me). I've never seen that crate before, but sure, you can try it. You certainly should be able to create new nodes once the tree is constructed. That's actually what their quick example does (notice how the brackets mean that the tree is constructed bottom-up). &gt; For displaying the tree, GraphViz seems good, however the Rust crate is marked as unstable, so I don't think I'd want to use it (unless you know that it is stable enough to generally output a decent tree without any troubles?). GraphViz is a text format, and there's an suite of external tools (C probably) that can take a graph like that and draw it into an image. As you can see on http://www.webgraphviz.com/, the format is pretty easy to write and understand, so you can simply produce it as text. Just to make it clear, there's a [`dot`](https://docs.rs/dot/0.1.4/dot/) crate. I don't recommend you use `rustc-ap-graphviz`, which is part of the compiler You can also pick another format: a tree view, HTML with highlights/annotations, and so on. It depends on your needs. &gt; So from what I'm getting from what you're saying the method to display the tree doesn't affect my choice of in-memory representation/datatype at all? Yes. How you display your tree shouldn't affect the way you represent it in memory. &gt; So aren't most of these like the same to me then? No. That `trees` crate is a data structure, while [ptree](https://crates.io/crates/ptree) prints a tree to the terminal. Why would they be the same?
Wow, but I have not tried out a way that is ready for production use, though. Nearly all data formats require only one way of serialization for given data types, but problem is NBT sometimes have two. Maybe we can research into serde-with or other libraries, or pass a special param for them, or warp what we want to be serialized as unique types into special structs and impl Serialize specially for them. BTW, I'll benchmarked my stuff out (without typed array serialization support) on my 3.4GHz Core i5, it can serialize NBT binaries up to 0.79 GiB/s. But I have not finished deserialization part.
&gt; I can understand how some futures might want to be _hyper_ efficient by alerting the executor they are ready to continue It's not about being _hyper_ efficient. Polling a future in a tight loop will use a whole CPU (as in 100%). It's about not being useless (nb. embedded software might feel different about this). Perhaps this will help: https://rust-lang.github.io/async-book/02_execution/01_chapter.html.
Brainfart - it confuses you and makes you say the wrong thing at the wrong time.
In the software that installs this on your brain, or maybe in airliners.
https://github.com/anderejd/cargo-geiger should be helpful, as well as https://github.com/dpc/crev/tree/master/cargo-crev
Not data structures, but things like `Cell` and several other container types were.
I'm doing this at my work right now and so far people are loving it! What I've been doing are mostly: - Giving Rust classes. Most of them are overviews of the language principles(?) and few language features, in order help people get what Rust's about. - Overseeing practice projects. There's two separate protoype backend servers being implemented at different completion rates right now. - Sharing cool Rust news and cool crates I stumble upon. People are especially impressed at how good the Rust book is and how crates have abundant documentation (such a luxury coming from the land of javascript). On a similar note, roadblocks so far are of the same flavor from two different directions: lack of low-level comprehension and experience, and lack of functional/high-level abstraction experience. It can be a bit frustrating trying to ease them in, but in general they're pretty eager once you explain to them the reason of why \*insert feature here\* is a good thing. The adoption process is slow, but it's overall a fun and rewarding experience. Definitely recommend trying to convert your workplace.
I mainly use closures in combination with other functional concepts. If you're used to imperative programming (which it seems like you are), you might look at closures on their own and think "what's this thing for?". But functional programming is a very different way to program and closures fit right in to the functional way of programming, just like if statements and loops are right at home in the imperative way. As a simple example of a functional way to process a list: let list: Vec&lt;i32&gt; = vec![1,2,3,4,5]; let list2: Vec&lt;i32&gt; = list.iter() .filter(|item| item%2 != 0) //closure that defines which items I want to filter out .map(|item| item*2) //closure that defines what I want to do to each item .collect(); //list2 contains 2, 6, 10 The same in an imperative way would look something like this: let list: Vec&lt;i32&gt; = vec![1,2,3,4,5]; let list2: Vec&lt;i32&gt; = vec![]; for item in list { if item%2 != 0 { list2.push(item*2); } } //list2 contains 2, 6, 10 Essentially, a closure is an object which defines a thing to do, and I can pass around that object to tell a function to tell it what to do with each item in the list, for example. The functional way above feels (to me) closer to natural language and how I think about that process in my mind (take the list, filter out all even numbers, multiply the remaining numbers by two) compared to the imperative method, where I kind of have to "translate" what I imagined into imperative code using if statements and loops. Despite this, functional is not even any more or less "correct" than imperative, and really it's good to know both styles as you can use both in the same Rust program depending on what fits the task better. Some tasks rwally are better suited for writing in imperative code, but others fit better into a functional style.
https://youtu.be/Pn-1so-Ibsg
I absolutely endorse wasm for plugins but it's just a little too immature for the time being. Give it another year or so and I'll be telling everyone to replace their scripting languages with wasm.
For embedded systems, and for implementing new operating systems, both situations where you can't use the standard library, because it doesn't exist.
If it doesn't depend on std then a wider audience can use it (those using rust for embedded applications where they don't want to or can't depend on std).
Closures are a way to mimic [https://en.wikipedia.org/wiki/Currying](https://en.wikipedia.org/wiki/Currying) It gives you an ability to abstract above components with no common interface, by using the function's signature as that interface. This gives you an ability to push code, along with all the needed types as a function. The caller will execute abstract function made for some specific case, without having any dependency on the executed code. This gives you an ability to make software with completely independent components. In OOP, for one service to use another you need to define an interface and pass services as a dependency on other services in advance, as a feature of the library. By using closures, you remove that dependency by baking it into the closure's code. This way the client code is dependent on both services while the services themselves are unaware that anything besides them exists.
&gt; And yes, you can certainly deadlock your threads – though this will be more and more unlikely, with async/await becoming the norm. The exact opposite seems likely to me. Async/await makes it easier to write certain kinds of code, but a lot harder to debug it (at least until some tooling around it is developed). It makes no difference for mutex-related deadlocks, but introduces a whole new kind of deadlock (where two tasks are unintentionally waiting on each other to finish). &gt; But if I can reduce the `unsafe` code without imposing any pessimization, I'd do so instantly. Absolutely agree, that's the right attitude.
One sure sign of burnout is lacking the ability to deal with it gracefully. If you have ever dealt with stress-related symptoms, you know that it is sometimes just not possible to be the bigger person. I think the public nature of PRs in open source projects can sometimes be very harmful. It sometimes reads like video game fans requesting features from video game developers, which often turn particularly toxic through extreme displays of entitlement. Nobody is entitled to anything from the author of a piece of software that they are giving to you for free. Successful open source projects must have a team, a goal, a policy in place to deal with such issues.
If your executor just calls `poll()` over and over again, you don't need the `Waker`. Your executor will works. You can use `Future 0.1` to make it simpler to implement. But we don't want to keep calling `poll()` like that because it hurts the performance. We want each time we call `poll()`, some meaningfull work is done. So, we must have a way to talk to the executor like "hey, this/that future has something to do". And that, `Waker` existed for this purpose. `Context`, which holding `Waker`, is used for forward compatibility. `Waker` is generated by the executor. Each time `poll()` is called, the `Future` itself do some work. If the work is done, it return the `Poll::Ready&lt;Self::Output&gt;`. Otherwise, it gives the `Waker` from `Context` to its reactor to wake it when it has some work to do and return `Poll::Pending`. In `Future 0.1`, the waker is [`Task`](https://docs.rs/futures/0.1.28/futures/task/struct.Task.html) which can be taken by calling `futures::task::current()`. You should read [this withoutboats' blog post](https://boats.gitlab.io/blog/post/wakers-i/) and some others one for more infomations. English is not my mother language, hope you understand me!
How about a constructor function for \`MyStruct\` ? Or maybe put the \`inner\` field as public ? &amp;#x200B; It seems to me that you fell for the [XY problem](http://xyproblem.info/).
The assumption is that I can not modify the code for MyStruct. Let's say it's an external crate.
You probably want a 'pub new()' function. However, if this is just an academically curious question, I think the direct answer is no.
Yeah I was thinking something similar, turning all regular serde collections into List and creating a special-case type for every typed Array. Not a very elegant solution and I haven't tested it yet, but it should work in theory. It also doesn't help that serde collections can be heterogeneous while NBT Lists are always homogeneous. I believe you could technically do some magic with `std::any::TypeId` and extrapolate the List's type from the serde collection's contents (returning `Err` if not homogeneous) but once again this feels far from elegant and it might not even work as I have never tested it. The benchmark results aren't very meaningful to me because mine never got to a point where I could run benchmarks on it haha
Ok. So let me rephrase it. You want to build `MyStruct` from another module within the same crate, but disallow the access of `inner` field from another crate. You will be happy to known there is actually an existing solution for. Try use `pub(crate)` on `Inner` type.
I think I didn't make myself clear. There is a 3rd-party code in external crate which does not have a public constructor for MyStruct. And I still want to construct it bypassing compiler visibility rules. The question is is it theoretically possible.
Ouch. Indeed this wasn't clear at all to me. So, basically, no you can't. Or maybe with huge hacking skill I do not know of.
Thank you! I didn’t know about it, I’m going to start using it.
Debug it? It's very likely the bug is in your code, not in libloading.
&gt; nb. embedded software might feel different about this HFT also feels differently ;)
You can bitbang it by writing to a same size [u8] and then transmuting it to an instance of your struct. Probably a horrible idea though.
You could make your copy of MyStruct in your crate (à la \`pub struct MyMyStruct { inner: Inner }\`) and transmute an instance of that (\`let my\_my\_struct = MyMyStruct::new(inner); let my\_struct: MyStruct = std::mem::transmute(my\_my\_struct);\`). This is, as you said, wildly dangerous, and AFAIK the compiler makes no guarantees that these two structs will share the same memory layout.
Ah I see! Would be good to mention that in the `FromBytes` docs; I looked at that trait and went "huh?".
Yeah you'd have to do a raw pointer cast. And you are very close to UB here... whether references to uninitialized `u8` are allowed is still being discussed. Also note this warning that I recently added to [the docs](https://doc.rust-lang.org/nightly/std/io/trait.Read.html#tymethod.read): &gt; *Callers* of this method may not assume any guarantees about how the implementation uses buf. The trait is safe to implement. Calling read with an uninitialized buf (of the kind one obtains via MaybeUninit&lt;T&gt;) is not safe, and can lead to undefined behavior.
I don't think there is any way to do this without triggering UB.
I introduced Rust to my team a year ago. First step is to emboard the team. Context : we were doing mainly node.js and some C++ for node native add-ons and for ROS (c++ robotics framework) First step was to made to training classes with my team (first about languages history, memory management and type system), second about Neon (nodejs rust bindings) First project was to made a standalone lib about managing a specific protocol and a node add-ons to use it in an existing app. It was 'easy' to convince js team because C++ add-on writing is really painful and Neon is a really accelerator lib! The we decide to made a more critical lib in Rust. This lib is used by C++ code. It is really easy by generating a .so lib and we used rust [bindgen](https://rust-lang.github.io/rust-bindgen/) to generate .h so it really easy to make Rust accepted step by step.
And even if the segfault happens inside `libloading`, it's probably something you're doing to cause it
You could define a trait that contains all DB related functions, and implement it for `Connection` and a `Arc&lt;Mutex&lt;Fake&gt;&gt;`. You could then then put an enum made up of either the `Connection` or `Arc&lt;Mutex&lt;Fake&gt;&gt;` in Rocket's `State`, and have a function that returns a `Box&lt;YourDbTrait&gt;` that you can use in your handlers. &amp;#x200B; Faking is a little more intensive than mocking because you have to implement your db code effectively twice, once in SQL/Diesel, and once using a bunch of `Vec`s in your `Fake`, but it keeps your tests much faster than doing db integration tests. &amp;#x200B; As another solution that allows you to keep your `Connection` reliant code unaltered, I've worked on a not yet released crate that uses your Diesel migrations to create a fake database and run migrations on it before each test, and then uses the `Drop` trait to tear down the fake db after the test has passed or failed.
&gt;You certainly should be able to create new nodes once the tree is constructed. That's actually what their quick example does (notice how the brackets mean that the tree is constructed bottom-up). Are you sure? From my understanding of the three quick start examples add a root node and then forests with child nodes. I mean instead of setting a root node, then assigning its children, and their children, so forth, I need to create a node and then set its parents, and then later on that node's parents, until I finally get to a single node connecting all, which I'd connect to the root node. So I need to add parents to nodes instead of adding children (which is my understanding of their examples which I've just revisited) &amp;#x200B; Btw, thanks for mentioning that dot crate, I didn't know about it, although they seem to have the same documentation (or from what I've seen so far).
&gt; Debug it? More specifically, debug it with a debugger or other tool that allows inspecting the memory while the program runs. A segfault means that the program is trying to access memory outside the region that has been assigned to it. That means that it tried to follow a bad pointer, which means that you probably either overwrote something you shouldn't have or asked it to dereference something that isn't actually a pointer.
Yeah, that is true. Right now then the final thing I need to clarity is whether trees ([https://docs.rs/trees/0.2.1/trees/](https://docs.rs/trees/0.2.1/trees/)) would allow me to create my tree starting at the bottom, and then add those elements parents until I reach the top of the tree, as otherwise it'll be a lot harder to create the tree using the algorithm I'm planning to use.
Formally: No, it can't be done. As a matter of good practise: Even if you could, you shouldn't. It is better to fork the 3rd party library and implement the changes you want there. In practise: Yes, it's possible. If you copy-paste the struct definition into your own code under a different name, you can create an instance of that struct instead, and then `mem::transmute` it into the desired type. This is formally Undefined Behaviour, since there is no guarantee that the two structs will have the same layout in memory. But in the way rustc is currently implemented it will (AFAIK) always work.
Is the "Sid" in "Siderophile" Debian-inspired? And if so, why did you choose a name so alienating to anti-Debianers like me?
Sure: use trees::tr; fn main() { let leaf1 = tr(1); let leaf2 = tr(2); let leaf3 = tr(3); let inner1 = tr(3) / leaf1 / leaf2; let inner2 = tr(3) / leaf3; let root = tr(6) / inner1 / inner2; println!("{:?}", root); }
My Rust knowledge might be too little right now, but I don't see how I can create my own `Connection` implementation, since Rocket requires concrete connection, e.g. `pub struct ExampleDbConn(diesel::MysqlConnection);` Which is then injected to handlers: fn handler(conn: ExampleDbConn) { }
Why `std::ops::Range` does not impl `Copy`? Oversight or fundamental reason?
What you can do ordered from best to worst: * Create an issue at the repo of the crate explaining why said type should be constructible by the end user/part of the public API * Use a custom fork of the crate with your changes applied * \[1,000 km gap of void\] * Analyze the structure of the type (`MyStruct`, `Inner`, …). Once you "know" (no Rust ABI??) valid bit patterns of the type, `std::mem::transmute` from a buffer (`[u8; N]`) to the type.
Thank. I did debug. It was a wrong return type .Was just confused because of the segmentation fault is so uncommon.
You don't have to use `[u8]`, you can just use `transmute` directly. However, while this should work for a single-field struct, there's no guarantee for a multiple-fields struct as there's no guarantee on how fields are laid out, nor that two different structs with the same fields are laid out in the same fashion.
https://github.com/rust-lang/rust/pull/27186
&gt; Setting up a separate fake db just to run tests seems like an overkill. I haven't needed to use Diesel yet but the solution used by the Django framework for Python is exactly that. It takes advantage of the backend-agnosticism granted by its query-builder API to initialize an SQLite `:memory:` database to run tests against.
If your executor just keeps polling, a waker that does nothing will work just fine, however a typical executor will never poll a future again if it never wakes the waker. Here is an example of a waker that does nothing: ``` use std::task::{Context, Waker, RawWaker, RawWakerVTable}; fn do_nothing(_ptr: *const ()) {} fn clone(ptr: *const ()) -&gt; RawWaker { RawWaker::new(ptr, &amp;VTABLE) } static VTABLE: RawWakerVTable = RawWakerVTable::new( clone, do_nothing, do_nothing, do_nothing, ); fn main() { let raw = RawWaker::new(std::ptr::null(), &amp;VTABLE); let waker = unsafe {Waker::from_raw(raw)}; let context = Context::from_waker(&amp;waker); } ```
Take a look at the [Managed State](https://rocket.rs/v0.4/guide/state/#managed-state) section of the Rocket guide. After managing your provider enum in your initialization function, you could implement a guard (see `FromRequest` trait) that returns the Trait object of your connection; like so (untested, may need some creative interpretation): // Dao is the trait for both the fake and your connection // The DaoProvider provides Dao Trait Objects // impl for FromRequest fn from_request(req: &amp;'a Request&lt;'r&gt;) -&gt; request::Outcome&lt;Box&lt;Dao&gt;, ()&gt; { let provider = req.guard::&lt;State&lt;DaoProvider&gt;&gt;()?; Outcome::Success(match provider { Fake(fake) =&gt; Box::new(fake), ConnPool(pool) =&gt; Box::new(pool.get()) // error handling here is an exercise for the reader }) }
https://lmgtfy.com/?q=siderophile
For me, the benefit of closures, or well, function pointers, that matters day to day is in letting functions abstract over a pattern of computation while letting the caller decide the actual logic. For example, removing elements from a list that match a criteria is often done. If you write it enough times, a pattern emerges for creating a vec and then doing a for loop to push elements that pass a check (a.k.a. predicate) into that new vec. Without closures, you have to either write out the for loop to do it every single time (as seen in C) or you could abstract by making a Filter struct that is created with a type that implements a Predicate interface (as I've only seen in Java, mainly with https://docs.oracle.com/javase/7/docs/api/java/lang/Runnable.html). With closures, you avoid most of the boilerplate and you don't need to name the predicate every time just like you don't with a normal for loop. What follows is a contrast of the three, showing both filtering into odds and filtering into primes. I haven't tested any of it, so some minor details (especially missing `mut`s) may be off. Also, I'm using `is_odd` and `is_prime` calls. You could replace that by any arbitrary expression as long as it evaluates into a `bool`. Initialization: // Before each style, assume this line let nums = [1u32, 2, 3, 4]; For Loop Style: // No abstraction to implement // Usage let mut odds = vec![]; for num in nums { if is_odd(&amp;num) { odds.push(num); } } let mut primes = vec![]; for num in nums { if is_prime(&amp;num) { primes.push(num); } } Struct + Trait style: // Abstraction Implementation stuff that needs to be written once. trait Predicate&lt;T&gt; { fn predicate(&amp;mut Self, val: &amp;T) -&gt; bool; } struct Filterer&lt;P, T&gt; where P: Predicate&lt;T&gt; { predicate: P } impl Filterer&lt;P, T&gt; { fn filter(self, slice: &amp;[T]) -&gt; Vec&lt;T&gt; { let res = vec![]; for elem of slice { if self.predicate.check(&amp;elem) { res.push(elem); } } res } } // Usage struct Oddness; impl Predicate&lt;u32&gt; for Oddness { fn check(&amp;mut self, num: &amp;u32) -&gt; bool { is_odd(num) } } let odds = Filterer { predicate: Oddness }.filter(nums); struct Primeness impl Predicate&lt;u32&gt; for Primeness { fn check(&amp;mut self, num: &amp;u32) -&gt; bool { is_prime(num) } } let primes = Filterer { predicate: Primeness }.filter(nums); Closures: // Abstraction Implementation stuff that needs to be written once. fn filter&lt;T&gt;(slice: &amp;[T], predicate: impl FnMut(&amp;T) -&gt; bool) -&gt; Vec&lt;T&gt; { // This looks a lot like the C style. let res = vec![]; for elem of slice { if predicate(&amp;elem) { res.push(elem); } } res } // Usage let odds = filter(num, |n| is_odd(n)); let primes = filter(num, |n| is_prime(n)); // Alternative usage since we're just calling named functions let odds = filter(is_odd); let primes = filter(is_prime); Note though, that if you wanted to filter once and then add one to all new values, the for loop would be better because you can add it inside the loop instead of creating an intermediary `Vec`. But through more advanced usage of closures, Rust has Iterators (and other languages have streams) that also have that advantage. Also, by using these functions that take closures, if we find some optimization, it automatically applies to all places it gets called instead of having to go back and find all the instances of the pattern to apply the optimization. For example, if our metrics show that most filters keep at least half of their elements, we could change `vec![]` in the filter function to `Vec::with_capacity(slice.len() / 2)`. That's not true in practice, AFAIK, but for things less general than filtering, such optimizations are probably lurking around. It also lets us name the operation we are doing. You have to read the for loop code for a few seconds to understand that it is filtering while the filter() call tells you right away. --- For the book's example, I would not actually replace the code with a closure until I had to actually go back and change the lines together a few times. And even then, I'd probably go with a fn item scoped to the function.
I built my own actor system which took some inspirations from actix but with minimal to zero usage of unsafes. [sekibanki](https://github.com/f5xs-0000a/sekibanki)
I get it. In fact I use it in a macro for route imports. Some routes use all the imports in their handlers and some routes do not. But across all routes I end up using all the imports - this is what I meant.
Yep, which is why I suggested a [u8] in the first place - it's arguably better to guess the layout of your target struct than it is to hope your copy of it will get laid out the exact same way.
I think there's a taste aspect to this as well. As I posted on the help thread here I recently created a nostd elf parsing crate for my kernel. I used a pointer and length in the constructor as this will be set from values coming from asm and similar. It felt wrong having inherently unsafe things in the interface. I'm changing it to a slice as I can always unsafe cast a pointer to the object in unsafe world.
perhaps "cant move this" tandananam danam danam
I will try to add an example that wraps an external node type.
Segfaults being uncommon, well that is the joy of coding in Rust. You should never have to get used to it :-)
That works but i forgot to mentioned that i have another type which is "Arc&lt;Mutex&lt;Vec&lt;Peer&gt;&gt;&gt;" and now keep giving me this error. i've tried to put the arc&lt;mutex... near to the serialize type but doesn't work ``` error[E0277]: the trait bound `std::sync::MutexGuard&lt;'_, std::vec::Vec&lt;Peer&gt;&gt;: _IMPL_DESERIALIZE_FOR_Peer::_serde::Serialize` is not satisfied --&gt; src/main.rs:169:26 | 169 | let packet = write_packet(data); | ^^^^^^^^^^^^ the trait `_IMPL_DESERIALIZE_FOR_Peer::_serde::Serialize` is not implemented for `std::sync::MutexGuard&lt;'_, std::vec::Vec&lt;Peer&gt;&gt;` | = note: required because of the requirements on the impl of `_IMPL_DESERIALIZE_FOR_Peer::_serde::Serialize` for `Join&lt;std::sync::MutexGuard&lt;'_, std::vec::Vec&lt;Peer&gt;&gt;&gt;` note: required by `write_packet` --&gt; src/main.rs:224:1 | 224 | fn write_packet&lt;T: Serialize&gt;(data: Packet&lt;T&gt;) -&gt; String { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ```
It looks like you're trying to serialize the guard returned by the mutex instead of your value. Try dereferencing it, e.g. `*peers.lock()`.
There is no guarantee that two single-field structs `struct A(T);` and `struct B(T);` are laid out in the same way either. Meanwhile, using `[u8]` to transmute back and forth to a given type can invoke UB due to padding bits and whatnot (see https://github.com/crossbeam-rs/crossbeam/issues/315#issuecomment-458911215 for a discussion).
Is transmuting a [u8] inherently UB, or does UB only occur if you mess up the struct layout?
You might want to look at how Python's [YAPSY](http://yapsy.sourceforge.net/) plugin framework does it. That's the example I'd follow were I writing a plugin API for Rust. The approach it takes is: 1. Have the metadata that would be displayed in a plugin enable/disable UI be retrievable without running arbitrary code. (In their case, a `.ini`-like file alongside the plugin itself. In this case, if you want a single-file plugin, maybe take advantage of the support in ELF, Mach-O, and PE for embedding arbitrary metadata within the file. 2. Have the host application define an interface that each plugin must implement... ideally with support for offering different interfaces for different plugin types. (This is also how compiled Python modules work. Each module has an entry point with a name derived from the file name. For example, `PyInit_cv2` for `cv2.so`, if I'm remembering the pattern correctly.)
At `pub fn new(val: &amp;'static [u8]) -&gt; Test`, you're stating the reference `val` needs to be valid for the `'static` lifetime (the entire lifespan of the process), but `arg` only lives until end of `main`.
The arg string is owned by `Args`, so it won't live for as long as `&amp;'static` needs. You can get it to be static by putting it on the heap and leaking it: let arg = Box::new(env::args.nth(1).expect("missing argument")); let arg: &amp;'static str = Box::leak(arg); Test::new(arg.as_bytes());
Thank you, this works fine. Tried to box the arg before, but I missed the leaking part.
Whether you will hit UB I think that depends on the type you are transmuting from and to. For example, due to padding, given a value `x` of some `struct A`, `x` may have bytes with the bit pattern `0xUU` (using Ralf's notation for uninitialized bytes, see https://www.reddit.com/r/rust/comments/cd522f/what_the_hardware_does_is_not_what_your_program/ets5crl/). As a result, when you transmute `x` to `[u8; size_of::&lt;A&gt;()]` there may be some `u8`s that are assigned the bit patterns `0xUU`. This leads back to the question of whether `let x: u8 = uninitialized();` is UB or not. See https://github.com/rust-lang/unsafe-code-guidelines/issues/71 for a discussion re. that. As Ralf notes, using `[MaybeUninit&lt;u8&gt;; size_of::&lt;A&gt;()]` should however be fine as `MaybeUninit&lt;u8&gt;` is able to represent the `0xUU` bit pattern.
Oh yeah, I see how transmuting a `T` to `[u8]` can be UB, but are there cases where transmuting an `[u8; size_of::&lt;T&gt;()]` to a `T` is UB?
Nice to see that you already have the crab costume 👍
If you want it to be (very slightly) more efficient in terms of heap memory, and also maybe nicer to read, you can use a `String`'s innate ability to be turned into a boxed `&amp;str`: let arg = Box::leak(env::args.nth(1).expect("missing argument").into_boxed_str()); Test::new(arg.as_bytes();
Assuming you get the layouts right for that byte array wrt. `T`... I cannot think of any cases right now. cc u/ralfj (This is keeping in mind that `repr(Rust)` is unspecified and that getting that `[u8; N]` in the first place may have problems.)
\&gt; And yes, both languages have the notion of undefined behaviour. Here I think it's important to note that Rust and C++ do not have the same notion of UB. For example, C++ has TBAA while Rust does not. Meanwhile, in C++ and C, a \`char\` is special while there's nothing special about \`u8\` in Rust. So while I agree that at a high level overview the machine models of Rust and C++ are similar, one should be careful about importing too many assumptions about what is and isn't UB from C++ to Rust and vice versa.
whoa thanks TIL
[Relevant commit.](https://github.com/rust-lang/rust/commit/439576fd7bedf741db5fb6a21c902e858d51f2a0)
I have an API server I use Rocket for. Is there an easy way to integrate it with Lambda so I don't have to redo my whole code? Or do I need to undo all the Rocket stuff?
I tried to print hello world from a rust program on an ESP32 micro controller and failed. Spent a whole day compiling llvm, clang and rustc toolchain but I got a message saying there was a bug in rustc that needs to be reported while building sysroot and so now I’m stuck. Congrats on your experiment going much better than mine.
0.x versions technically don't have any compatibility guarantee under semver, as I understand it: &gt; Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable. However, a lot of people do follow the convention that 0.x.y should remain backwards compatible within an x.
Why not talk about the DeserializeOwned trait from serde? [For instance](https://github.com/actix/actix-web/blob/master/actix-session/src/lib.rs#L122) Serialization is very common. The DeserializeOwned trait is a great tool for managing a collection of serializable types.
Microsoft want segfault to be uncommon
Not a bug, that's what flattening a structure means. The serialize function will call serialize_struct on your serializer and then pass all of the fields of the flattened struct as it's own fields to the resultant SerializeStruct value returned from the function.
My team uses Rust and Elixir but other teams in my company use whatever they want. None of them have any interest in rust, we even host a rust meetup at the office and nobody comes. Just getting it in the door doesn’t guarantee adoption. There are two kinds of programmers: those who write bugs so they use a safe language like rust, and those who don’t so they use an unsafe language like C/C++. That is the crux of it. They are good programmers and their code works most of the time so using a language like rust is a waste of time. These are the people who write all the 0-days. You’ve never met any of them because they don’t work there anymore. They left after 18 months. These programmers are also way more productive. Their shit compiles with only a few pages of warnings meanwhile the borrow checker is kicking your ass and it won’t compile. Then when your crappy Rust code finally compiles the C++ app while loads it segfaults and QA files a priority defect saying your Rust code is crashing the application. After wasting a day only to find out the good programmer dereferenced NULL. They respond with “huh, weird” and you repeat again next iteration. Hold unsafe programmers accountable and drive home the message of safety == quality. If people choose unsafe languages they need to justify the costs against the benefits. What is the reward for the added risk? Is it worth it? What does a significant data breach or a 0-day cost your company?
IIRC, `Vec` was one of them? I'd consider that a data structure. I believe `Cell` (and most of the variants of `Cell`, like `RefCell`, `Mutex`, and `RwLock`, along with `Rc`, `Arc`, `Box`, etc.) are already proved in RustBelt.
Actually it is guaranteed that they are both transparent, so you can transmute from one to the other.
Run it with address sanitizer. It might help you narrow down the source of the trouble. Post the finding if it's in an open source crate, at least in the project's tracker, maybe here too since I'm curious. To easily run address sanitizer with rust: https://github.com/japaric/rust-san
This is true only if you use `#[repr(transparent)]` on both `struct A(T);` and `struct B(T);` in which case you can transmute freely between `A` and `B` assuming there are no particular safety (as opposed to validity) invariants.
Have you considered Rust programming language?
As far as I understood the current thinking is that transparent is only a lint and that this would be transparent anyway: [https://github.com/rust-lang/unsafe-code-guidelines/pull/164](https://github.com/rust-lang/unsafe-code-guidelines/pull/164) It's not merged though yet, so it's technically true that it's not guaranteed yet.
I'm actually astonished you didn't suggest the Safety Dance
I believe `pub(crate)` will let you do exactly what you want, make something only visible to your crate, so you could access it but users of your crate wouldnt be able to see it.
Thanks this was a helpful talk.
Thanks this was helpful. I'll keep in mind the straightforward coding style and opening things up to my colleagues.
At this point I feel like there's a 50% chance someone like that is deliberately trolling. Such is life on the internet I guess. The best we can do is to be a better example in the situations we can control. The people who matter know what's up.
This is a proposal in the UCG but it is not normative until the language team signs off on it (through the normal decision making process including RFCs / FCPs, etc.). &gt; It's not merged though yet, so it's technically true that it's not guaranteed yet. As a meta point about the UCG, note that even if the PR is merged into the repo, it is still a non-normative proposal until it is accepted through the normal process.
I strongly suspect most of those comments to be trolls. "Rewrite it in Rust" has become a meme in some non-Rust communities.
Ah thanks for clarifying.
No problem. :)
I don't think you can get anymore elitist then the C++ community, but yeah there's no sense in people trying to trash "C/C++"
Ouch. Really sorry for you... Hope you'll soon be unstuck ;)
I get that these types of comments are bad, but I do think that Rust provides a TON of benefits compared to a lot of other widely used languages. Are we against promoting Rust for those reasons or just against these kinds of worthless comments like "man up and use Rust"?
Thanks for the input. I like the idea of putting a few comparisons together of how rust prevents some really common safety pitfalls.
When encountering a number or an identifier, the lexer advances position one too many times. Taking an example: let five=5; ^ The lexer encounters a letter, and reads until the current character is no longer a letter. let five=5; ^ Then back in the `next_token` method, `read_char` gets called again, advancing the position once more. let five=5; ^ And the equals sign have therefore been missed. To fix this, you may want to return early once these two branches have been entered.
/r/rustjerk
I am generally against promoting a language in a thread that is about C++. People use C++ for very specific reasons and no matter how hard or violent you try to promote Rust you'll likely just achieve the opposite of what you're trying to do. Let these languages coexist, there's no need to convert anybody.
[Hello, my name is Elder Jelly, and today I'd like to share with you this most fantastic book](https://doc.rust-lang.org/stable/book/) [ref](https://bookofmormonlondon.com/)
will try. thank you.
(Reddit often inserts virtual upvotes/downvotes to try to make it harder for vote bots to tell when they've been black-holed.)
Sounds like you just want Rust to remain elitist, so you hide any mention of it with your downvotes
I mean sure, Rust provides a lot of benefits, but hijacking every C++ thread to shill Rust gets real old, real fast. There's a lot of valid reasons for using C++, or simply instances where people have to use a particular language because they don't want to overhaul their stack for the latest trendy language. So I'd say both.
There’s no need to put down an entire community for no reason. I think you will find many people in the C++ community are major Rust users as well.
Wait, `Vec` was proven correct?! Really? I want to see the prooflink!
In particular, the comment from SubstantialTwo is their only comment, posted minutes after they created the Reddit account.
/r/playrust
really cool, check the official channel [Rust](https://www.youtube.com/channel/UCaYhcUwRBNscFNUKTjgPFiA) they make great streams
Happy to edit my comment, but what are you seeing? Since everything looks right on my end so I'm not sure how to know if I fixed anything. Are you using a custom Reddit app maybe?
It was a joke, but I think most people who have started with both C++ and Rust recently will find that the C++ community is a lot more hostile to beginners. I've also run into quite a few C++ developers who turn their nose up at Java developers. For the most part though both languages are fine.
The first rule of Rust club is you don't talk about Rust club. The second rule of Rust club is you don't talk about Rust club.
The exector generally doesn't call `poll` again until after `wake` is called. The executor _may_ call `poll` before `wake`, and a correct future implementation has to account for that, but it can't rely on that happening.
Just the mere that it's possible to delineate and sequester *potential UB* in labeled regions ("unsafe functions") is a huge deal. In C++ you *always* have to consider *all* the ways that any given piece of code could result in UB. This is not the case in Rust. TL;DR: To answer your question: No. You're just wrong.
Don't we all?
These attitudes DEFINE Rust, imo. It's the prevailing attitude I have seen from the Rust community from day one. &amp;#x200B; If the shoe fits......
While I agree and upvoted this post to help reinforce that we, as a community, don't want this type of behavior. I do think it's important that we also temper our disappointment relative to internet culture. These are likely not productive members of this community - they're likely trolls, doing this on purpose to incite anger/pushback/response/etc. My point is, I don't feel this is representative of the community and as a result I ask that we all don't let these trolls ruin what is a great community. Don't feel disheartened, don't get angry at the community/etc, don't embrace their troll. This is a really nice community - and the larger we grow the more trolls we will naturally find. Yet, such is life, no internet community will be without them. TBH I'm not sure what is the best course of action regarding them, I suppose that's an internet mystery haha
But Java genuinely sucks tho
Still getting downvoted a ton. Not sure if it's that. I was under the impression we'd be able to have a civilized conversation about a legit question without just downvoting people.
&gt; I get that these types of comments are bad, but I do think that Rust provides a TON of benefits compared to a lot of other widely used languages. It may, but no one likes those types of comments invading other, non-related content.
Wot
But can it handle the security challenges? I heard that Rust is just made by a handful of people in San Francisco. Doesn't seem very professkonal or dependable...
I thought the consensus was that Rust can do everything C/C++ can (aside from all compilation targets) and that Rust eliminated entire classes of very common bugs in those languages while also generally being faster due to zero cost abstractions. Are those not valid reasons for preferring Rust to C/C++? I'm not promoting hijacking threads. I'm asking if you're against the promotion of Rust for valid reasons.
Why is it non-related? Isn't promoting anything reliant upon talking about it outside of some specific context? If people don't know about Rust then they won't ask about it and those who do know it may not know what else it offers.
I had a feeling it was something like that but I was spending my time in the read\_identifer/number functions. I was also thrown off since the values for Int and Ident were correct, i.e. I never got `Int("5;")`. Thank you so much!
compared to php4?
The last one was literally created to post that comment.
More like 90%.
OP has downvoted any fun mention of Rust. What are you confused about?
&gt; By design, modern OSes never assign address 0 as valid memory so that trying to dereference a null pointer will segfault. And all this time I just assumed part of my kernel or somesuch lived there. It's a shame that this needs to be done in production just to keep the OS debuggable.
Looks like the best candidate at the moment [https://samirjoshi.github.io/NumRu/ndarray/index.html](https://samirjoshi.github.io/NumRu/ndarray/index.html)
If you see comments like this in the wild, then please engage them there respectfully and demonstrate the sort of self-aware humility that a young technology warrants. It's impossible to know for sure whether any given comment of this nature in the wild is genuine or trolling (welcome to the internet), but by engaging in good faith regardless you may at least serve as an ambassador of communities like ours.
https://imgur.com/a/zQPHEsn/ Well, idk, it looks really off in Safari and in Apollo app.
https://imgur.com/a/dLqZNfd/ Well, idk, it just looks really off in Safari and in the Apollo app.
Thanks for the screenshot. How does it look now?
As someone who is still writing some content and exercises to cover traits and generics, I have had some success going through examples using the Eq and Ordering trait. Some exercises that go into sorting structs that contain enums or should ignore a field in favour for others (like Albums and Student Grades). Maybe an exercise that asks someone to construct a generic function to find the pair of closest points in a set of points and you can have two point types (Absolute and Relative).
Thanks for your help. For the moment that type of metadata is just a struct [PluginConfig](https://github.com/aspera-non-spernit/cyrconv/blob/master/src/ext.rs) that has fields "Permissions" currently unused. I am thinking of something instead of permissions to define a trigger in the plugin for the beginning. So struct PluginConfig { ... trigger: [OnStartup, OnUserTextEnter], ... } in the program I would keep a collection for each possible trigger and would iterate over each plugiin in that collection and call the pre-defined function. Later I could add the function name for each trigger. struct PluginConfig { ... execute: [ onStartup: { function: Some("welcome") }, onUserTextEnter: { function: Some("autocorrect") }, onAppClose: { function: None } ], ... } Maybe the second approach is even better for the beginning.
Ndarray is probably the most mature. But depending on the specifics of your code and the machine you run on, [numeric array](https://crates.io/crates/numeric-array) might be an interesting alternative.
It's a bit more complicated than that, because programs in protected-mode operating systems don't see physical memory addresses. They see a virtual memory map set up in the [MMU](https://en.wikipedia.org/wiki/Memory_management_unit). That means that the same address can map to different physical memory locations in different programs. Protected mode OSes generally unmap the [Zero page](https://en.wikipedia.org/wiki/Zero_page) of any given virtual address space to trap null pointer dereferences, but, if you're running a real-mode OS on x86 (eg. MS-DOS), then logical address `0` maps to physical address `0`, which is set up by the BIOS to contain the [Interrupt Descriptor Table](https://en.wikipedia.org/wiki/Interrupt_descriptor_table). That "Zero page" article is interesting because it talks about how, before CPU performance out-paced RAM performance, it was commonplace for the page of memory beginning with address `0` to be used sort of like extra CPU registers, with specialized machine instructions for manipulating with greater efficiency than the rest of the RAM.
Executors aren't required to `poll` a future multiple times. The waker should wake the executor. The reason why is because futures can form a tree of many pending 'leaf' futures. polling all of them wouldn't scale. If you build a future that depends on the executor continuously polling, perhaps you don't need futures at all. In fact, my advice is to stay clear of futures. Rust threading model is among the best. Futures solve a very specific problem and add a lot of complexity.
\&gt; You were given constructive criticism I'm gonna disagree with this one. Using lmgfy is far away from being constructive. &amp;#x200B; \&gt; which isn’t quite so trivially discovered What is trivial for you might not be trivial for someone else. In fact, I've got the answer within this post: [https://www.reddit.com/r/rust/comments/cfvr7p/i\_have\_a\_lot\_of\_unused\_import\_warning\_how\_do\_i/eucydh6/](https://www.reddit.com/r/rust/comments/cfvr7p/i_have_a_lot_of_unused_import_warning_how_do_i/eucydh6/) The first link on lmgfy is [https://stackoverflow.com/questions/25877285/how-to-disable-unused-code-warnings-in-rust](https://stackoverflow.com/questions/25877285/how-to-disable-unused-code-warnings-in-rust) doesn't tell me to put it in [lib.rs](https://lib.rs). I had seen that and tried, and it didn't work. That's why I asked a question here. &amp;#x200B; \&gt; a way of saying your time is more valuable than others Again, I feel sad for your teammates. A simple question gets interpreted in the worst possible way. Moreover, you feel great with wasting even more of your time offensively teaching me a lesson. Also, I feel sad for junior engineers in your team though. lmgfy must be flying off every day since you think this behavior is constructive.
Awesome thanks u/TangerineBot. That makes a lot of sense. The fact Rust plays well in two such vastly different ecosystems is what makes it so interesting. Good luck.
I assume this was prompted by your other [thread](https://www.reddit.com/r/rust/comments/cfzftq/i_am_so_tired_of_seeing_this_shit_this_type_of/). I didn't downvote you there, although I was tempted to. Why? Because those comments are much more often than not posted by people who've never used the language and are not part of the community. So it feel wrong, unfair and rash to hold us accountable for the behavior of some trolls on a random subreddit. &gt; Are we against promoting Rust for those reasons or just against these kinds of worthless comments like "man up and use Rust"? Who exactly are you criticizing here? Besides that, you say you've been a member of the community for more than a year. You may, then, be familiar with Rust's [Code of Conduct](https://www.rust-lang.org/policies/code-of-conduct), which disallows that kind of trolling. So if you see that kind of behavior from someone in the community, you can remind them of it. On the other hand, your comments were relatively unkind, and even unconstructive. Implying that the people here (whom I assume to be mostly of good faith) are the ones who post things those in your screenshot is about as useful as telling someone asking how to read a line from `std::cin` to learn Rust instead.
you really want to add undefined behavior on the top of an implementation behavior ? you ask for trouble.
You're on the open internet. This is a waste of time.
Emm, if I were right, the inner struct name is to be erased due to the flattening attribute, but the outer struct should keep its name and be regarded as a struct only with its fields added (from the inner struct).
That description seems correct yes
&gt; I assume this was prompted by your other [thread](https://www.reddit.com/r/rust/comments/cfzftq/i_am_so_tired_of_seeing_this_shit_this_type_of/) It was promoted by that as well as every other community I am a part of (e.g. political discussions). &gt; I didn't downvote you there, although I was tempted to. Why? Because those comments are much more often than not posted by people who've never used the language and are not part of the community. So it feel wrong, unfair and rash to hold us accountable for the behavior of some trolls on a random subreddit. I'm not sure what you're saying. I didn't hold anyone accountable for anything. I simply asked what specifically the community is against. Trolling (this I understand) or promoting Rust in other communities in general (this I don't understand). &gt; Whom exactly are you criticizing here? I wasn't criticizing anyone. I asked a question. That's it. I was trying to understand in more detail what specifically the community is against. &gt; Besides that, you say you've been a member of the community for more than a year. You may, then, be familiar with Rust's [Code of Conduct](https://www.rust-lang.org/policies/code-of-conduct), which disallows that kind of trolling. So if you see that kind of behavior from someone in the community, you can remind them of it. Yes i know Rust has a CoC. I didn't say anything about the trolling / screenshot comments being acceptable. I am aware they are not. What I asked was if our community is simply against stupid Evangelical promotion of Rust (not necessarily trolling) or if it is against promoting Rust with facts in other communities. I asked this because I've seen numerous comments like in the same discussion saying there is nothing wrong with C/C++ and we should not take a stance that one language is better than another. Then, on the flip side, every other thing I read about Rust is that it's better than C/C++ because it makes it almost impossible to have large classes of certain memory related bugs as well as other benefits. &gt; On the other hand, your comments were relatively unkind, and even unconstructive. Which comment of mine was unkind or unconstructive at all? &gt; Implying that the people here (whom I assume to be mostly of good faith) are the ones who post things those in your screenshot is about as useful as telling someone asking how to read a line from `std::cin` to learn Rust instead. I don't believe I ever implied that. Which comment implied this to you?
Upvoted. I don't believe it is a waste of time if some people read it and it changes their minds.
&gt; If I saw the question I didn't like, I'd just skip it. But hey that's just me. I didn’t skip your question; I saw it, went to answer it, saw your unreasonable responses to people trying to be helpful — even if you don’t appreciate the form of their help — and responded to that instead. As I said your _initial_ query, as worded, didn’t require anything more than Google and finding that first SO post. Your _real_ query (how to apply `allow` to an entire project) _did_ require more than that, but, importantly, wasn’t communicated in your initial post. Asking your _real_ query wouldn’t have gotten you pushback because you’d have appeared to have put in the bare minimum amount of effort to solve your own problem. Thus does communication work. Also, truthfully, I couldn’t possibly care less who you think you feel sad for; you’re really not gaining anything by resorting to even more immature behavior in order to avoid considering _more_ constructive criticism.
Before you collect more negative karma: The OP of this post is not the OP of the post you linked to. The OP of this post has some comments in that other post though.
I'm sorry, didn't want to be so mean. But this lesson has to be learn the hard way (this is how I learnt it as well). I will always help a friend, teammate or even stranger if I can. However, I think it's important to understand that some question can be answered easily by google. And even you will save time by doing so. If you always ask before searching on google, you will slowly irritate your teammates and won't be able to work independantly. Here I am pretty sure the official doc tells you which flag to use to disable this feature. If you come with a technical question, or something which lead to a discution, or anything with cannot be replied by a single line, I would be glad to help. Once again, apologize for being rude, wish you the best with Rust, Cheers,
\&gt; people trying to be helpful Again, [/u/Dlacreme](https://www.reddit.com/u/Dlacreme/) wasn't trying to be helpful. He wanted to punish people. This is what we mainly disagree about. You think using lmgtfy is constructive. That's ridiculous.
Please, let me know if you find how to.
No, I think telling you to “just google it directly” was them being constructive, since that’s a good bit of information for anyone asking your initial question (or any that can be answered with a single keyword search). The lmgtfy link was them drilling home the point. And yes, that _was_ flippant, though you’re leaping to an unsupportable conclusion by assuming that user is a sadist; in the entire tree of threads initiated by your post it’s only you who has been openly and obviously hostile to others.
Sorry, I mistakenly thought you were the OP from the other thread. --- Trying to answer anyway: &gt; What I asked was if our community is simply against stupid Evangelical promotion of Rust (not necessarily trolling) Most people here would probably be against that. &gt; or if it is against promoting Rust with facts in other communities. I don't know about others, but I personally find it unconstructive. If someone asks a C++ question on /r/cpp, there's not much point in telling them that Rust is the better language. Maybe they're using it for work, maybe they have to learn it for school, maybe for their specific problem Rust is actually the worse language (and that's quite often the case). If someone posts some news, say about the Lifetime profile. Again, there's no much use in telling everyone that Rust has a better, built-in borrow checker. Most people active on that channel will already know that. They'll probably downvote you, too. You may or may not convince someone to learn Rust, but be prepared for the downvotes from annoyed Redditors.
Thanks, I had already noticed. See my other reply.
receiving enums that don't name all bit patterns from FFI is a strong UB candidate. Implement TryFrom to parse the raw integer into your enum, and transport raw integers over FFI.
Thank you for letting me know that you wanted teach me a lesson. I don't appreciate your sorry-not-sorry statement though. Cheers.
Is treating the '0' character as EOF intentional?
Classic. Saying lmgtfy is offensive = initiating hostility In your book, people should've just shut up.
Fixed!
This doesn't seem relevant to r/Rust in particular, it might just be me but it feels like you take issue with the Reddit vote system in general and how people use it. You might feel more at home on the rust user forums where there isn't really a vote system and it's largely just the opinion and discourse
I'm glad you asked this, because the other post got locked and I've got Opnions(tm). My advice for you is to take downvotes less seriously. The number you see is not always the real score your comment got, sometimes people misclick and downvote (I've done that many time when scrolling through mobile reddit), I also downvote people who edit their posts to complain about downvotes as that is off topic. You got downvoted and you are now drawing conclusions about the human race, are you sure that's the best way to spend your energy?
I don't really mind.
This post isn't because of that thread; it's because that thread is reflective of the ongoing issue I've seen across many communities, like I explained in this post. I don't believe all my downvotes are people mistakenly misclicking. I think many people are just lazy and opinionated and a downvote / upvote is fast and easy, but they are only damaging their cause in doing so.
/r/playrust
Sigh. The hostility was the “I feel sorry” nonsense.
More /r/playrustservers I believe.
Even more interesting, there is no requirement that the null pointer actually be 0. Because the compiler knows dereferencing it is UB, it's allowed to put whatever bits make the most sense from an optimization perspective there
just what I needed, thanks!
Not really. &gt; 9. Please don't advertise your plugin, service, or discord server without approval.
You said using lmgtfy was constructive multiple times. Of course, I feel sorry for anyone who receives that kind of constructive criticism.
You are missing the point. I don't think all your downvotes were misclicking, what I'm saying is that you can't know why people downvoted you unless they tell you, drawing conclusions from just the number is useless. Like I said, I downvote people who complain about downvotes, how is that at all related to the grand problem of the human race not listening with an open mind? But I'll also be even clearer in what I think: You are wrong, this is not at all an issue in /r/rust, what happened to you is rare and definitely not worthy of a meta post.
For a while I would also downvote people who complain about downvotes, but now I do only under certain contexts. I think if you ask a legitimate question and haven't gotten any answer and are only being downvoted, it makes sense to bring it up because of the point of this post itself. Downvotes without any context / answer just kill any conversation or understanding about whatever the question was, and that is unfortunate.
Thank you!
Have an upvote. I just finished responding to this in my other comment to you. &gt; Like I said, I downvote people who complain about downvotes, how is that at all related to the grand problem of the human race not listening with an open mind? Because, like you said in the sentence before this, I have no idea of what reasons these people have for downvoting me unless they tell me. I also do not condone complaining about being downvoted just because of being downvoted. I do, however, take issue with people downvoting a legitimate question without offering any response or insight into why.
Typically it can't do that as you will likely have situation where pointer is either equals 0 or valid
Your opinions are valid, I agree that downvoting a legitimate question is bad and that usually happens a lot around reddit. It doesn't really happen on /r/rust though which the important part of what I'm saying. You were unlucky, that's all
For now, yes. I'm going to be refactoring it to use optionals very soon. My current strategy so far has been to stick to the book (written in go), then refactor to make thing more idiomatic once the tests are passing.
Building hackintosh (to run MacOS natively) and running MacOS in VirtualBox are 2 different things. What you are describing seems to be more related to the hackintosh. I first tried to run in MacOS in VB around 6 years go. I was able to use xcode and compile a simple app, if I remember correctly. Then I got Macbook and didn’t have have to deal with it any more.
I think it can be interesting to study the `Iterator` trait, especially if you audience already used it. `Iterator` covers Trait, associate type, generics and composition. You can even implement a (bad) version of Iterator, for example : [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=25aac0538b7577c906470175e31663b2](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=25aac0538b7577c906470175e31663b2) It might be a bit hard for first timers though...
I’m pretty sure I never even said it once, but please feel free to imagine that I did. Me, I feel sorry for anyone who can’t grow up.
No.
There are various different kinds of APIs, with different needs for calling them, but for a web API, you use an HTTP client crate like `reqwest` or `curl`. Of course, first, it's a good idea to search crates.io to see if anyone's written a higher-level wrapper for the API you want to use. I'm not sure if it's any good, but [this](https://crates.io/crates/github) would be a candidate for what you want.
for a rest api you could look at \`\`\`[reqwest](https://crates.io/crates/reqwest)\`\`\`
"I think telling you to “just google it directly” was them being constructive" No, it was not, especially after giving lmgtfy. "You were given constructive criticism" No, it wasn't constructive in any way. "people trying to be helpful" No, not really. His first link in lmgtfy didn't even have an accurate answer. &amp;#x200B; In fact, you were the first person who mentioned the word "constructive" and "helpful".
I agree! Bu on the other hand - this is the internet. And especially people who are into programming can be huge douches sometimes. Humans sadly aren't rational. If we were we'd have a lot less problems in the world.
Re-reading your question, you don't necessarily want the frames as PNG but in some format you can use for further processing. What would be the ideal format for you? You can easily have them as e.g. raw RGB or YUV frames (in whatever variant you want), OpenGL textures (tricky part is to integrate with whatever GL context you want to integrate with), PNG/JPG/etc frames passed to you directly or written to a file, ... If you can clarify then I'll make you a small example for that. Seems not very useful to do an example for something you don't actually need :) Also what's your status at this point?
Too long. Downvoted. /s
For `repr(Rust)`, if you transmute a byte array to a `T` you are relying on implementation-specific (NOT implementation-*defined*) behavior -- so this is always wrong, as field order can change any time. But if you use a deterministic `repr`, and if you get the layout right, this is okay. Also see the `FromBytes` trait from [this crate](https://doc.rust-lang.org/nightly/nomicon/what-unsafe-does.html).
Yes, you'll need to go through C for FFI. You'll probably need to do some extra allocations (so that every Rust value is on heap), because you C code won't know how large the values are. And since you have dynamic allocation, you must also expose a Rust function to free the value. See also https://www.youtube.com/watch?v=4t0I10eMoJU.
Another option to introduce the language is to write smaller and larger useful and fast command line tools for the development workflow or for some other purposes, log analysis and so forth.
There were two pieces of constructive criticism in their response: 1. You shouldn’t get in the habit of doing what you’re trying to do. 2. You should make use of Google: since the correct answer for your original question, as stated, was `#[allow(unused_imports)]`, which is able to be gleaned from the first item on a google search for “unused_imports” and the second on the link they provided, this _is_ constructive, and a lesson you _should_ learn... I’m glad they apologized for being flippant... your inability to accept that apology speaks loads to your emotional maturity. Your expanded question, how to allow unused_imports for an entire project, is indeed harder to find ... though that’s because it’s an even worse habit to get into. Regardless, the end of my interest has been reached.
I think this is related: [The Hard Parts of Open Source by Evan Czaplicki](https://www.youtube.com/watch?v=o_4EX4dPppA). It was posted within Rust community already, for anyone who missed it.
I down-voted that question. I didn't offer any response or insight into why because (a) it would have been of-topic meta-discussion or (b) it would have enabled a troll or (c) it would have taken a ton of effort and ultimately accomplish very little or (d) it would have violated community guidelines. And now you're here telling me I should have up-voted it because "up-voting things you disagree with promotes knowledge and understanding." Frankly, you are not owed any explanation. If you seriously want an answer to a question, ask it better. Explain what you are going to do with the answer. Explain why you can't find it yourself. Explain what lead you to the question in the first place.
No. All FFI in rust is unsafe because rustc can’t check external libraries for soundness. Safe wrapper code is written that covers almost all of the unsoundness but nothing prevents unsound code written in other languages from being unsafe.
FFI is unsafe. You can (and should) make safe wrappers over the imported functions, but raw FFI is unsafe, and that's not a bad thing. Safe Rust should be memory-safe, meaning that any memory unsafety should be isolated in `unsafe` code. So why is FFI risky? If you get a function import or type definition wrong, your program will exhibit UB and most likely crash. More so, the code you're calling might not be memory-safe (what if you call `mylib_free` twice on the same pointer?). So any FFI code should be marked as `unsafe` in order to uphold that invariant.
You might want to try tch which wraps PyTorch's C++ APIs: https://github.com/LaurentMazare/tch-rs
I would, too... I just heard about it in the Iris mattermost room. Let me see if I can find the link historically (or at least, evidence that I am losing my mind and made this whole thing up).
&gt; If you get a function import or type definition wrong, your program will exhibit UB and most likely crash. That is if you're very lucky. If you're not so lucky, it will be an exploitable security vulnerability that lets an attacker take over your machine simply by feeding specially crafted data to your program.
&gt; since the correct answer for your original question, as stated, was #[allow(unused_imports)] It was an incomplete answer. You need to put that in lib.rs. &gt; I’m glad they apologized for being flippant Lol, his sorry-not-sorry response is far from apologizing. Also, I'm sorry that your standard is so low to consider his answer "constructive". There you go, that's the illustration of how his apology sounds like.
That was it thanks!
For others, when you print, there are two formatting options for strings: println!("{}", x); // no backslashes println!("{:?}", x); // backslashes
If you're [looking for a way](https://github.com/djugei/treelike/blob/master/src/treelike.rs#L198) to iterate over a tree that is not binary, you can have a look at my code [here](https://github.com/Wulfsta/ketree/blob/master/src/ketree/tree.rs#L294). I believe this is the most space and time efficient way to do this.
&gt; it would have been off-topic meta-discussion How? My comment was a reply to someone and was related to what they said. &gt; it would have enabled a troll I'm not a troll. &gt; it would have taken a ton of effort and ultimately accomplish very little Then why downvote at all? If you don't have the energy to respond to the question then I don't think you should downvote it. &gt; it would have violated community guidelines How did my question violate community guidelines? &gt; Frankly, you are not owed any explanation This is a pretty conceited response, if you ask me. Nobody is "owed" anything, and if you had read this post at all you should see that I am saying you owe it to yourself to respond. If you care about something to downvote it then you are going against your own cause. &gt; If you seriously want an answer to a question, ask it better. I thought I had asked it perfectly clearly. This is not the kind of thing you search for on StackOverflow. Are we even talking about the same thing? Are you sure you responded to the right person?
when I am writing a rust lib and add #\[forbid\_unsafe\] to the crate and then load that library through ffi. Would it's be possible to check if the loaded rust lib has an unsafe block in it? If not it should be a logical thing to allow non unsafe loading of the lib. At least for rust - rust loading. Why am I wrong?:)
How would you check if compiled code has unsafe in it?
Dynamic loading has to be done through a raw, platform-specific C API. The compiler can't guarantee that you're using that API correctly. The *proper* way to do safe dynamic loading would be to write something comparable to rust-cpython's Rust-&gt;C-&gt;Python abstraction, where you write safe code and the library generates safe abstractions around the inherently unsafe dynamic loading and Rust-&gt;C-&gt;Rust FFI.
It's unused because type aliases don't enforce the bounds you put on type parameters. Writing a type alias like this: type ParsedInput&lt;'a, Item, Iter: Iterator&lt;Item=Item&gt;&gt; = (&amp;'a Iter,Item); Gives you this warning warning: bounds on generic parameters are not enforced in type aliases --&gt; src/lib.rs:3:34 | 3 | type ParsedInput&lt;'a, Item, Iter: Iterator&lt;Item=Item&gt;&gt; = | ^^^^^^^^^^^^^^^^^^^ | = note: #[warn(type_alias_bounds)] on by default = help: the bound will not be checked when the type alias is used, and should be removed Finished dev [unoptimized + debuginfo] target(s) in 0.35s
The simplest way of getting this to compile is to just add a PhantomData into the tuple. type ParsedInput&lt;'a, X, Input: Push&lt;X&gt;&gt; = (TokenSlice&lt;'a&gt;, Option&lt;Input&gt;, PhantomData&lt;X&gt;); At which point the compiler will warn about this: warning: bounds on generic parameters are not enforced in type aliases = help: the bound will not be checked when the type alias is used, and should be removed So, it appears that the compiler doesn't yet check these bounds, so the best approach is likely to just remove the bound completely for now, and enforce them where the `ParsedInput` type alias is used.
Did you implement the in-game programming language yourself?
I was actually wondering if you had meant `'0'` or `0 as char`. Seems like it was the latter and you've fixed a bug you didn't realize you had :)
You could typically move to a `struct`: struct ParsedInput&lt;'a, X, Input: Push&lt;X&gt;&gt;(TokenSlice&lt;'a&gt;, Option&lt;Input&gt;); And it still wouldn't pan out. I believe this is related to *variance*.
Can't agree with you more on this subject, but I'm seeing this behavior more and more all over the internet lately. Long gone are the dreams of what Internet could become.
Even if you're dynamically loading a safe Rust library, _since it's dynamic_ you could swap out that library after compilation for... anything.
I mean, there's also unsafe inside `Vec`. You're not actually expected to write this directly, instead the expectation is that you use an executor like tokio, which does this for you.
Once a library is compiled, there's no such thing as `unsafe`, or even Rust for that matter. At that point it is just binary executable data, you can't even know for sure if it was compiled from Rust or C (though if it has debug symbols a human can make a good guess). So at runtime, its not possible to know anything about the Rust code that produced the library, because the source code is gone and you only have machine instructions.
I don't have answers to any of these questions, however just to further demonstrate how weird this issue is: Marking the closure to be `move` allows the code to compile without the return statement. wrap_fn(move |_| path)(i) But, dropping just the semicolon from the return statement *stops* it from compiling and falls back to the exact same error. return wrap_fn(|_| path)(i)
It seems pretty wild to me to hand-roll ELF, Mach-O and ar parsers just for the sake of getting a binary from 2.4MiB to 0.5MiB. My laptop has a 128GB SSD, and this difference is not even noticeable. Shouldn't compatibility and reliability be the priority instead? I admit the build time changes are impressive, but these days software almost always comes precompiled and this will not dramatically change development workflow because incremental compilation will get it down to a couple of seconds anyway (unless you're using proc macros).
Interestingly, it compiles if you add move before closure.
I wasn't talking about you.
I thought there was some code in rustc that would randomize struct layout so this sort of thing wouldn't consistently work... or is that not actually true?
Yes I did, I designed it for the game. Lexer, parser, interpreter written in rust like the rest of the game.
I think you're underestimating how hard it is to formulate the right question.
&gt; I know I need to add more documentation. For a library like this what type of documentation should I include. Doc comments, examples, tutorial in the README, or all of the above? Why do you think you need to add more documentation? In what way would it be helpful? What kind of documentation would help with that?
I feel like how to use the library needs better explanation but maybe I'm being too hard on myself.
About parsing. https://iqlusion.blog/introducing-abscissa-rust-application-framework uses https://crates.io/crates/gumdrop . Might be a good compromise between spartan and bloated. :)
I've recently used [nalgebra](http://nalgebra.org/) for some matrix operations. It relies heavy on generics, so the documentation can be somewhat hard to read. But it might also help compiler to better optimize the code.
I'm doing this not to save space, but to remove bloat. It's like using electron for a simple text editor. I like VS Code, but does it really need 10x space/RAM compared to Sublime? `goblin` is a nice library, but I need like 5% of it. `serde` is an incredible piece of software, but do I need it to extract two fields from a JSON? I don't think so. This is a "we can just buy more servers"-kind of topic. Some people think that this is waste of time, some disagree.
Yes, I was using it before in `resvg`, but it takes 30sec to build on my machine. It's just too much.
The question I'm talking about is "[Are we against promoting Rust for those reasons or just against these kinds of worthless comments like "man up and use Rust](https://old.reddit.com/r/rust/comments/cfzftq/i_am_so_tired_of_seeing_this_shit_this_type_of/eudk2p0/)"?" The answer to that question is "no". It's so obviously no, one wonders why you're asking it at all. Did anybody say they were against promoting rust for reasons related to its purpose? Why would anybody say such a thing? What drove you to think that's a question that needs to be answered? Why would you expect the people of /r/rust to say anything but "no" to that question? &gt;How? My comment was a reply to someone and was related to what they said. That's arguable. I argue it was not. Apparently other people saw it that way too, or else why would you be down-voted? What is your explanation for this? Do you think good, relevant questions are just being down-voted all the time? &gt;I'm not a troll. You sound like one. So will I if I don't very precisely explain why I've down-voted everything I dislike. And that is tedious and not worth the effort most of the time. &gt;How did my question violate community guidelines? Because this discussion is getting more and more tedious, and it *will* end up violating the CoC if it continues carelessly. And what is the payoff? When is my effort here going to result in anything good happening? Call me cynical, but anyone with enough experience online will be able to predict which discussions to stay out of. You can't fault them for that. &gt;Then why downvote at all? Because I can? Because it's easy? Why do you even care? You're not owed an answer to this question either. &gt;If you don't have the energy to respond to the question then I don't think you should downvote it. The economics of this simply don't agree with you. It is easier to down-vote than to explain. &gt;This is a pretty conceited response, if you ask me. I didn't ask you. You asked for a response, I gave you one. I don't need you to police my morality. &gt;If you care about something to downvote it then you are going against your own cause. You don't know my cause. Or anybody else's, for that matter. I still don't need you to police my morality. For what it's worth, I don't need rust to be a popular or promoted language. I need it to be a good enough language, and I need it to work. That's not everyone's need... some people do need buy-in. But I make software for myself, so maybe stop with the broad strokes.
Thank you for the input, but pre- and post-order traversals are not a problem, just in-order is not very well-defined on trees with more then two children.
I'm not aware of any IRC channels, but there is a rust-dev and a rust-community discord to which you can find info about in the sidebar
Oh hey, [my old example](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=7bbe49d2ce91db42cd91c4645e01c4e1) still fails in the 2018 edition with NLL. I thought it was fixed :(
/r/playrust
Okay, this is when I am fine with downvoting: when people are just being dicks and are probably trolls themselves.
There is ##rust in the freenode network and #rust-offtopic/#rust in the oftc network.
One thing to keep in mind is that experienced C++ programmers are really good at spotting safety pitfalls so if you put up a slide with some buggy code that falls into one, don't be surprised if they catch it almost instantly... you kind of have to be that good if you want to work productively with the language. You are better off emphasizing that Rust frees you from the effort of worrying about and debugging safety issues in general and not focus too much on what the buggy C++ code would look like since it can feel kind of petty to focus on code that is so obviously wrong it wouldn't have written it in the first place. (Kind of like how with \`unsafe\` Rust you could make tons of short snippets with subtle bugs that would never happen because there's some simple safe alternative that does the exact same thing)
I can't make sense of borrow checker errors when using Y-combinator on a closure that takes mutable reference. // Taken from https://github.com/Stebalien/tool-rs/blob/85710a3b52014c0a9534c1300749f89970ff56c6/src/functor.rs#L28 pub fn fix&lt;A, B, F&gt;(f: F) -&gt; impl Fn(A) -&gt; B where F: Fn(&amp;dyn Fn(A)-&gt; B, A) -&gt; B { move |a: A| { let tmp_fn = |_: A| -&gt; B { unreachable!() }; let fun_holder = std::cell::Cell::new(&amp;tmp_fn as &amp;dyn Fn(A) -&gt; B); let fun = |a: A| { f(fun_holder.get(), a) }; fun_holder.set(&amp;fun as &amp;dyn Fn(A) -&gt; B); f(fun_holder.get(), a) } } fn main() { let mut cnt = 10; let rec = tool::prelude::fix(|rec, cnt: &amp;mut i32| { if *cnt &gt; 0 { *cnt -= 1; rec(cnt); rec(cnt); // error here } }); rec(&amp;mut cnt); } Produces the following error: error[E0499]: cannot borrow `*cnt` as mutable more than once at a time --&gt; src\main.rs:45:17 | 44 | rec(cnt); | --- first mutable borrow occurs here 45 | rec(cnt); // error here | --- ^^^ second mutable borrow occurs here | | | first borrow later used by call Why? `rec` has type `&amp;dyn std::ops::Fn(&amp;mut i32)`, it has nowhere to hold `&amp;mut i32`, how can second call to `rec` possibly use first borrow of `cnt`?
I think moving the compilation time from 71-&gt;7 seconds is pretty important for a tool like this, it greatly reduces the cost of installing it, improves first impressions, makes it easier to use it in modern CI pipelines that don't like binary inputs.
The important thing to realize is that you have to implement these traits for your own type. The only way that one of these traits could be implemented for a type is if the author of that type explicitly opted to implement them, so there's no way to use the traits to violate the invariants or privacy of a type whose author didn't want that to happen.
When I load that page, crates.io automatically gives me a docs.rs link next to the "repository" and "dependent crates" links. Does it show up for you?
You are probably looking for /r/playrust
i am but why downvote lol
So for the byteorder stuff, check out our [byteorder](https://docs.rs/zerocopy/0.2.6/zerocopy/byteorder/index.html) module. As for ergonomics in general, there's definitely room for improvement. I have some ideas that I'm just waiting to have time to implement, but I'd also love any suggestions! For the plugin freezing issues, it probably comes from the very large number of trait impls we have. We implement the three traits for `[T; N]` for a very large number of different `N` because we've had requests for that from people who need it. Const generics should allow us to do something like `impl&lt;T: FromBytes, const N: usize&gt; FromBytes for [T; N]` and significantly reduce compile times.
It can *send* pings now in addition to respond to them :P The more serious answer, though, is that we've spent the past 8 months doing a lot of internal improvements and implementing protocols that aren't actually exposed to the user (like IGMPv2 and MLD). So we've made a lot of progress, but so far none of it is actually user-visible. But it's all prerequisites for user-visible changes. E.g., with IGMPv2 and MLD implemented, we're a lot closer to supporting IPv4 and IPv6 multicast sockets.
500 LoC still seems like a lot, especially given it likely needs to be tested extensively. Do you fuzz it against `goblin` to see that they give the same results?
This is generally called HList. It is often implemented as `(T, REST)`, where `REST` is either `()` (terminator) or some other `(T, REST)` recursively.
Can someone comment on how this differs from Tokio and where one might choose one or the other?
Since discord is not free software, I'm afraid I can not use it
Cheers!
I’m really not... I’ve had to strive (and usually fail) at formulating the right question for more than forty years now. No doubt I shall continue to bork that one up reliably until entropy overtakes me. What I’m definitely not doing is overestimating how easy it is to never have to ask the wrong question when the breadcrumb is staring you in the face and you live in the fleeting moment when you can just ask a machine about it with a few keystrokes.
Providing binary artifacts achieves the same thing: it probably takes less time to set up too, and is even faster to install than the 7 (or 23) seconds of the new 0.8.
Ah sorry, I misread in-order as post-order.
Nice to see OTP-inspired process trees in Rust.
My sense is that you are either young or have some empathy issues from looking at your short term posting history. This is not an attack. I did not downvote your previous comments like on the one about rust devs shitting in a c++ post, but I can see why people did. I am not saying that other people are right in downvoting you either. If you are an experienced dev, you've been in the field long enough to have been told someone's else's language is superior. This is a forever repeating cycle because what is superior depends on one's needs. Some people are okay with poor performance if they consider the language easy to use, what being easy to use is subjective obviously. In comparison to specific languages like c++, Rust may be even undeniably superior but the fact is that humans write languages and not robots. As a human, I would feel extremely negative towards a language or community if I am discussing parts of a language I may use for my own job to further my understanding and someone else comes in to shit on it. It isn't helpful to suggest Rust because that wasn't the time or place for it. There are places where it's okay like if a dev is bitching about a particular feature in their language, then pointing out rust has a better solution or that the language developers might want to check out how rust handled it because they do x and y. Demonstrations where people write a program in one language and then another, that's a helpful way for people to see what they can get too. But **those are developers who are looking and are receptive to a better way, not everyone is or can afford to be **. There are devs who work in fields that will never make the switch or they are too busy to, it's not helpful for them no matter how superior anything is. What I described seems extremely obvious to a lot of people and it might be, if you have empathy and try to think about the perspective of others. This is why I think you are getting downvoted, you can say that you want this community to understand each other, but you are asking questions that show that you are not trying yourself to empathize, otherwise you would be able to answer them.
The purpose is different, Tokio wants to provide asynchronous runtime, while this one wants to provide persistent runtime. It is related, but not the same.
Have you reported this on Actix-web bug tracker yet? If not, please do.
Binary artifacts definitively take longer to set up, since the non-binary version is `cargo install cargo-bloat` while the binary version involves building the source and stashing the binary somewhere.
If it’s `#[repr(C)]` or similar, yes (`union`s or `mem::transmute`). If it’s `#[repr(Rust)]`, kind of (Rust layouts are unspecified and unlikely to be compatible between structs with multiple fields in general).
Yeah, cleaning up code to get rid of unused warnings is generally a good idea. Though sometimes I wish rustc would be just a little less *transitive* about unused warnings. Like I get that the body of an unused function is never run, but do you really have to list out every helper function called from within as also being unused (just because they aren't called anywhere else)?
Electron for a text editor is runtime overhead. It runs like... well, we all know what Atom runs like. Moreover, it's *noticeable* runtime overhead that actually gets in the way, not just something you need a microbenchmark to measure. It actually takes up a huge chunk of my RAM and everything. I'd expect a shared implementation to actually have better runtime characteristics than a hand-rolled one, as well as better compatibiltiy and correctness due to much wider testing.
Na, I can live without flying. I can't live without sweet cyberpunk upgrades.
Thanks for doing this, well done. I will have a further play with your rust code, but I can confirm it runs fine on my machine after a quick go. A question too, is it deliberate to have the middle ball ray tracing upside down?
I'd make an issue on github tbh.
Bloat - is a space wasted. I don't need a full-blown, heavily fuzzed goblin alternative, since I'm not parsing any random binaries. cargo always produce the same one. I'm not advocating rewritings all the stuff by yourself. I'm saying that people should choose their dependencies more wisely. &gt;Also, are you factoring in developer time to your calculations? This is just another "ram is cheap" argument.
Sorry I was a bit unclear: I'm comparing to the 3+ days for the optimisations in the original post (which make `cargo install` faster).
Literally my favorite part of OTP. I think any language used for work that needs guarantees should have this model.
Oops, makes sense and definitely the case.
&gt; I'm doing this not to save space, but to remove bloat. &gt; Bloat - is a space wasted. :) I think it's great that some people are willing to obsess over space and build times, and build alternative libraries that help with that. But I also expect most developers not to prioritize that, and I don't think either party is wrong.
I think you're both right. The thing is, regardless of whether this is "just" a disk space issue to a lot of folks, it will definitely impact usage. Just look at `regex`. It is (rightfully) perceived as a "heavyweight" dependency, and because of that, I've seen a lot of folks raise the bar for using `regex` only when it really gains them something. (That some might see this as a "good" thing because "regex is teh bad" is incidental.) `cargo-bloat` isn't the first thing to make `regex` optional; `env_logger` did it long ago too. Personally, I think this is entirely reasonable and prudent behavior. So if you're a crate author, then "decrease the size of the crate" or even "decrease the _perceived_ size of the crate" are things that likely will result in more folks using your stuff. So purely from a maintainer's perspective, regardless of whether their users are being purely rational beings or not, this is still something you might want to do if you want to increase the number of people using your crate. And sometimes, [people appear to have real constraints](https://github.com/rust-lang/regex/issues/583) with respect to size, although the precise details motivating their constraints are still a bit mysterious.
It's not a runtime overhead. It's mentality. And I'm against it. My parser is actually faster, since it does only what I need. But performance is not that important in this case.
The reference says that "The block of a function is conceptually wrapped in a block that binds the argument patterns and then returns the value of the function's block." If this is correct, and I understand it correctly, the function foo with an implicit return is equivalent to this: fn foo(i: &amp;str) -&gt; &amp;str { return { let path = "foo"; wrap\_fn(|\_| path)(i) }; } This version results in the same compilation error, and I think it makes it clearer why there is a difference; path is dropped before the return value has been evaluated.
What if I wrap your type in a type that implements this? e.g.: ``` #[derive(FromBytes)] struct MyMaliciousType { foo: YourTypeWithSecretField } ``` Is only allowed if `YourTypeWithSecretField` implements `FromBytes` explicitly? If so, then rad!!
Regardless regex, I don't think that this is bloat in case of cargo-bloat. Sorry if this is sounded like this. regex is actually a good example of a heavy dependency. Can I use a smaller one? Not really. Can I use a part of it? Not really. Can I rewrite it? Defenetly not! All I can do is too make it optional. I have a similar heavy library too - resvg. It's like twice as big as regex. But can I make it smaller? I'm trying, but you cannot go against the spec. You have to support everything. Otherwise it's pointless. In case of cargo-bloat I was able to remove a lot of bloat without losing any functionality, but I can't do the same in case of resvg.
Even if ffi weren’t unsafe, on Windows the mere act of loading a library causes code from that function to run, which can be anything and do anything.
You are looking for r/playrust, this is for [the programming language](https://rust-lang.org)
Aye, yeah, that's a good point. Although I still want to decrease its size. The linked issue in my last comment has two interesting avenues (optionally dropping Unicode support, optionally being less aggressive with inlining), although they didn't yield as big of gains as I had hoped. It is definitely possible to write a "lighter" regex implementation that sacrifices (potentially) both performance and features. I had been planning to do that while still depending on `regex-syntax`, but my exploration in that linked issue points to `regex-syntax` as a fairly significant contributor to the size and compilation time of the crate. (Just the parsing routine alone is something like 50KB.) So that kind of kills my motivation for a `regex-lite`, because I really do not want to rewrite the parser.
Is this inspired by Erlang supervision trees?
Thanks
Yep, that's right!
&gt; I was hesitant to even introduce Rust as most of the devs are Node.js guys Actually, that might make it easier to introduce Rust, assuming there's some C or C++ in use as well. People who aren't big fans of C or C++ might be happy to see anything that can replace those language for the cases requiring them.
I'm not sure what you mean by "path is dropped before the return value has been evaluated". The block will have evaluated to a value by the time return gets evaluated. In other words, how is this different than: fn foo(i: &amp;str) -&gt; bool { return { let path = "foo"; path.is_empty() }; } If `path` gets dropped before the return value gets evaluation it should fail too since you can't run `path.is_empty()` on it. But it compiles fine. I think what the reference tries to explain is how to think about pattern matching of the arguments. i.e fn foo((a, b): (u32, u32)) { println!("{} {}", a, b) } is equivalent to fn foo(_u: (u32, u32)) { let a = _u.0; let b = _u.1; return { println!("{} {}", a, b) } }
Just map and return tuples? ``` let tup: (Foo, Bar, Zui) = foo() .map(|f: Foo| (f, bar(f))) .map(|(f, b): (Foo, Bar)| (f, b, zui(b))); ``` You could make a data structure when using this for a specific thing. Maybe if you have a concrete example we can find a better way to handle this altogether.
You feel bad for his Juniors because he teaches them to be independent? K
Using lmgtfy is a good way to teach? K
For trivial stuff that the one asking could have found within 10min? Yes.
It's like you didn't even read how his lmgtf didn't solve my problem. And how I got an answer here in this Reddit thread. Smh.
Not the author, but I'm fairly sure the middle ball is a transparent refractive material, which is why the image through it appears upside down.
Because the people in this thread literally spelled the answer out for you. That's not teaching anyone anything...
Man, you need to read. I said I had seen the link and tried and it didn't work. The real answer here is to put that line in lib.rs, which is offered here in this thread. The lmgtf is offensive and doesn't help.
That is useful to know. Their tensor bindings look quite complete [https://docs.rs/tch/0.1.0/tch/struct.Tensor.html](https://docs.rs/tch/0.1.0/tch/struct.Tensor.html)
[this is what i have in my code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6b646104148e23b1a054280e53938b7a) and i tried to add * behind the lock and peers. but no chance. how can i fix it?
&gt; Man, you need to read. Funny. Are you talking to yourself? From the SO post from the lmgtfy: &gt; Add a crate-level allow attribute; notice the !: [...] The author even linked another answer for people who don't know what "crate-level" means. If you just put some effort into it and spend more than 2 seconds to _read_ you'll see following in the linked answer: &gt; [...] This attribute must be added to the top of your crate root, [...] The answer then goes on to explain what the root for a library, application, test, and example is. The answer was readily available. It just required some mental effort from your part. Stop making others do your work. Learn to Google.
So I think I know what the cause is. I'll try to remember to explain it when I'm back at my computer.
I'm working on [a tool](https://github.com/dragonrider7225/java_class_manipulation) to view and alter the contents of Java class files. In particular, I'm converting the imperative parser functions that I wrote before I learned about [nom](https://docs.rs/nom/5.0.0/nom/) into the declarative format that that package allows. Unfortunately, my implementation of the type descriptor parser practically requires that any attempt to parse a function or array type call the root parser, and this seems to cause a requirement that the type of the root parser be recursive.
Using nested \`use\` clause is much better to read overall, use that instead of multiple \`use\` clauses, if you need the own module, you can use \`self\` keyword &amp;#x200B; For the \`new\` constructor of \`Config\`, it would be better to receive 2 parameters instead of one list of arguments and return \`Self\`, instead of \`Result&lt;Self, str&gt;\` &amp;#x200B; Other than that, the other nice thing would be define pixels as a newtype, but that's not necessary, just a good practice overall
&gt; The author even linked another answer for people who don't know what "crate-level" means. I didn't know that meant to put the line in lib.rs. So, I was stuck. &gt; It just required some mental effort from your part. Oh, you meant I should have been magically unstuck by myself. What a helpful suggestion. &gt; Stop making others do your work. We can simply ignore the question instead of making an effort to offend people by posing an unhelpful lmgtfy link. Learn to be a decent human, please.
You... You just refuse to try reading, don't you? I already told you **that the linked answer tells you in which file to place the command**. Go to the linked answer and dare to tell me you still don't know. No wait, it was too much effort to click the link when you initially went, as well as when I linked it in my edit. I'LL COPY PASTE IT FOR YOU: &gt; [...] If you are creating * a library — the crate root will be a file called lib.rs [...] Again, just a little bit more effort from your part would be great. Not knowing is fine. Not wanting to know isn't.
Thanks for the feedback!
Actually, I don't see your SO link in my lmgtfy link. Here's my screenshot for proof: https://imgur.com/a/XQNdJCS So, what you said didn't apply at all. Not knowing is fine. True dat. Being condescending with lmgtfy isn't. Being a dick isn't okay either.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/pzfqLDy.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)
Is this doable with stable rust? Or do you need nightly for the specialization?
Why are you so stubbornly refusing to read? [Here](https://imgur.com/gallery/0SzAekF) is my comment telling you the *SO answer* has *another* answer *linked* which explains crate-level. Nowhere did I talk about the explanation coming from another lmgtfy link. [And when we look at the SO post we can see the link very clearly.](https://imgur.com/gallery/NJqS6En) And even then, if you don't know a term you, idk, CAN GOOGLE IT. Yes, freaky right? Just keep replying... Every comment keeps showing how you don't put any effort towards actually reading what is being said. It's as if you don't *want* to understand.
I may not agree with all the points you advocate but I greatly appreciate the effort you’ve put into optimization. I worry sometimes about the death of micro software universally (rather than only where it definitely is not a concern). For example, I am extremely bothered that rust applications compiled under Windows automatically have a dependency on the Visual C++ 2008 redistributable (dynamically linked by default although the option to statically link was later added). Rust implements its own version of basically all the functionality MSVC provides; the only reason there’s a dependency on MSVC is because it was modeled after the Linux approach where the kernel provides nothing and some form of libc is required. On Windows, that’s not the case: the Win32 API is more than sufficient on its own to develop entire applications (let alone libraries) against without needing a runtime dependency.
I already told you I didn't click on it. So, I was stuck. Then, I asked the question. What are you suggesting? Using a time machine to go back to click on the link. Wtf? We are discussing about whether or not lmgtfy is offensive. You think using lmgtfy is not in any way offensive. So, yeah, back to your first question. I feel sad for people who are taught with lmgtfy.
I wouldn't. This is "well known" behavior and has had quite a few duplicate issues about it.
Lmgtfy is not offensive when the answer is 2 clicks and a bit of effort away.
Reddit is also not free software.
I love the small 'fiction' at the beginning of the readme, I'll take the idea ! (人 •͈ᴗ•͈)
Struct layout does not involved randomization at this time. It is permitted to do so in the future.
We're just gonna agree to disagree. \&gt; 2 clicks and a bit of effort away. Apparently, you have absolutely no empathy. You just assume everyone will click on the right link every time. That's just ridiculous.
&gt;However, I have noticed something within our community that is reminiscent of other communities of people who have strong opinions on complex subjects: many of us react to questions and opinions we dislike immediately through dismissal / downvoting. I also don't like when people do this. But is it worse here than any other subreddit really? It seems like it's fairly fundamental to Reddit or other open platforms with a similar voting mechanism.
No, I don't assume at all that people magically click the right link. I assume you'll look around for at least 10-15min clicking on **every link** you can find that is vaguely connected to the topic, as well as Google keywords that you don't understand which you encounter along the way. If it had been hidden behind 5 consecutive links which could only be found by inputting the correct jargon in GitHub because Google somehow hadn't indexed it, then sure. Go ahead and ask. But this was 2 clicks on the very first links you encounter when coming from Google...
&gt; I assume you'll look around for at least 10-15min clicking on every link you can find that is vaguely connected to the topic &gt; If it had been hidden behind 5 consecutive links Those are arbitrary numbers. Why not 3? Why not 30? why not 7? Why not 9mins? why not 20 mins? Yes, I spent some time looking at other answers. Sadly, I didn't time how much time I spent looking around. Glad to learn you always time yourself when googling around. &gt; Go ahead and ask. That's exactly what I did. I felt I was stuck. So, I asked. Not everyone adheres to your absurd arbitrary numbers where we can only ask if we spend &gt;15 mins and the link must be hidden behind 5 consecutive links.
Yeah, those numbers are arbitrary. What it comes down to is that you don't give up after clicking 1 link and reading half a page. Which is close to what just have happened here because finding the answer to the OP question isn't that hard. I'm like a broken LP player here but: effort.
It’s actually funny, rust’s pattern matching makes adding argument support to an application without any external dependencies insanely pleasant, fast, and straightforward.
\&gt; What it comes down to is that you don't give up after clicking 1 link and reading half a page. I didn't give up. I clicked on other google results. I looked at other answers on that SO thread and other SO threads. It was just that I didn't click on that link about "crate-level". Your argument is essentially "I should have clicked on the right link".
Why not go with a graph data structure instead? Just create nodes on the go, and when you have a parent to assign them to, you make the new node if needed and connect the relevant children in your logic? If you later want to convert to some other data structure for a different purpose, then you'd have this graph version to work from.
You can use discord in your browser. Still not free software; but neither are most other websites.
I use cargo workspaces to create small libraries to avoid recompiling everything all the time. It seems more effective at avoiding compiling things on small changes than the compiler is normally
&gt;Use a custom fork of the crate with your changes applied And this isn't all that hard, since you can specify a git repo as a dependency in `Cargo.toml`. Just modify the code, commit that and push to a branch, PR it upstream, set the dependency of your other project to (temporarily) point to that branch, and hope the maintainer agrees and merges it so you can switch to the next released version.
Reddit was maybe once a place for debates but it certainly is not that now and this place is no different.
The problem is that triple backticks are only supported by "new" reddit so anyone using the old version or a client that uses the old version's formatting will see garbage. Supremely annoying on reddit's part.
Do you have any examples that show how this could be done?
Wrong rust sub my dude xD
true.
makes sense. thank you
that was too complicated to me to understand :)
makes sense. thank you
This release has gobbled up late nights and weekends for months, but no longer. I'm not afraid to say that I'm pretty darn proud of this version of cHTTP! The release notes also contain a link to my longer blog post if you want to read even more.
Sounds like a good alternative to actix. Just needs a bit of documentation ;). Also, you probably shouldn’t recommend adding the crate as a dependency with `*` as the version. Other than that, great project; I’ll follow the development. :)
You don't need to convert the bytes to a string first, you can just use [`from_slice`](https://docs.rs/serde_json/1.0.40/serde_json/fn.from_slice.html).
Why don't you just use the [from\_slice](https://docs.rs/serde_json/1.0.40/serde_json/fn.from_slice.html) function? Something like `let j = serde_json::from_slice(&amp;data);` But if you really want to convert a Vec of bytes into a string, you can just use the [String::from\_utf8](https://doc.rust-lang.org/std/string/struct.String.html#method.from_utf8) method.
Wait... I was going to say that at least Reddit is open source, but apparently they are not “anymore” (it’s been a few years but I still didn’t know that). Does anybody know why?
You can use [`ArcWake`](https://docs.rs/futures-preview/0.3.0-alpha.17/futures/task/trait.ArcWake.html) from the futures-preview crate, which makes it pretty easy.
Your code doesn't compile because it's incomplete. Can you extract a minimal example? Also, you seem to use the locked value after you drop the lock, which kinda' defeats the purpose of using one.
This "convention" is actually built into Cargo, and the reason why `cargo update` assumed it was safe to upgrade: https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#caret-requirements &gt; This compatibility convention is different from SemVer in the way it treats versions before 1.0.0. While SemVer says there is no compatibility before 1.0.0, Cargo considers `0.x.y` to be compatible with `0.x.z`, where `y ≥ z` and `x &gt; 0`.
All stable. "specialization" here means `impl MyList for ()` &amp; `impl&lt;T&gt; MyList for (T, R)`
What makes cHTTP different from reqwest?
[updated code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8018c1fcfe842c5514ee8da062e6a383) i've updated the playground code, i did drop the peers.lock() earlier and then in the data variable im trying to pass the the peers Arc&lt;Mutex&lt;Vec&lt;Peer&gt;&gt;&gt; but the problem seems about the serde serialization ?
Thanks, good point :-)
Hope you dont mind a friendly bumping. I am genuinly interested.
From the README, &gt; cHTTP uses libcurl under the hood to handle the HTTP protocol and networking.
Minor nitpick: the blog post has a sentence fragment "You already".
I too worry about that. People always say 'well i have enough space anyways who cares about 2mb on an executable' Well if you rewrote all the small tools in a standard linux distro in rust you would definitly care. Because thats probably a bump of 50% in install size. I agree that if you make applications that will be the main task of a server you can ignore that. But tools that will be used just momentarily should be as small as possible
Interesting enough, changing the return type of `wrap_fn` to just `F` is also making it compile, even though as far as I know the `impl Trait` syntax is just sugar for the evaluated return type, which should be `F`. I wonder if the implicit return is somehow changing the lifetimes the compiler is inferring for the return closure? IE in one case the inferred type signature of `wrap_fn` is equivalent to`&lt;'a, 'b, F: (&amp;'a str) -&gt; (&amp;'b str)&gt; wrap_fn(f : F) -&gt; F` but in the other one it suddenly becomes `&lt;'a, 'b, 'c, 'd, F: (&amp;'a str) -&gt; (&amp;'b str), G : (&amp;'c str) -&gt; &amp;'d str&gt; wrap_fn(f : F) -&gt; G`?
Your updated version is almost the same as the old one, missing `use`s and some type definitions. And it's still accessing `peers` without holding a lock. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9c5ec7153a788afd490aff1ad2a5ec80
Lol, I think it may be more graceful to look into attribute serialize_with or something like it. This attribute can be supplied by our NBT ser/de library. I will try this out today to see what would happen. I have updated my probable serde bug (or feature) issue to include relative code today. The inability to fetch outer struct name is a major block of my project, hope to solve it early, either by serde-rs team or raise my pull request.
All suggestions are great. Just wanted to say that sometimes in python, for performance reasons, lot of code is transformed to operate on matrices when simple loops in lower level languages would have been better in the first place (better meaning more straightforward, and easier on memory).
Oh thanks i just needed to add ```&amp;*``` to ```peers``` in the data var, the rest i had such as serialization derive and imports. But now i wonder why do i need to dereference it?
Working on a big file system for games.
The following doesn't compile: #[derive(Default, Clone)] struct Item; struct Vector { vec: Vec&lt;Item&gt; } impl Vector { pub fn get_mut(&amp;mut self, index: usize) -&gt; &amp;mut Item { match self.vec.get_mut(index) { Some(p) =&gt; return p, None =&gt; { self.vec.resize(index + 1, Default::default()); self.vec.get_mut(index).unwrap() } }; } } Error message: error[E0499]: cannot borrow `self.vec` as mutable more than once at a time --&gt; src/lib.rs:14:9 | 9 | pub fn get_mut(&amp;mut self, index: usize) -&gt; &amp;mut Item { | - let's call the lifetime of this reference `'1` 10 | match self.vec.get_mut(index) { | -------- first mutable borrow occurs here 11 | Some(p) =&gt; return p, | - returning this value requires that `self.vec` is borrowed for `'1` ... 14 | self.vec.resize(index + 1, Default::default()); | ^^^^^^^^ second mutable borrow occurs here why "returning this value requires that `self.vec` is borrowed for `'1`"? I'd assume that skipping `Some(p)` and entering `None` clause would release the borrow on `vec` due to NLL? Edition = 2018, rustc 1.36
I have a most marvelous proof that this margin is too narrow to contain...
Right on, thats I'd say the biggest one. A few other differences: - cHTTP uses the http crate as part of its public API, whereas request hides it in the implementation. - cHTTP has a lighter dependency tree. - cHTTP encourages the use of its free functions for making requests, which use a lazy shared client instance. - According to hearsay, cHTTP is faster...
My post was downvoted as hell for some unknown reason , then I choose to just shut up and be a quiet noob. sometimes I feel I am on twitch chat not a programming language subreddit. Some did answer in professional way help me understand it, but some just downvoted and use a tone like , how can u think of this, even there was some discussion on rust-internals. I just deleted the post to avoid projecting my personal experience into wider rust community.
Whoops, good catch! Just fixed.
Does it work without Rc?
Because from `lock` you get a `MutexGuard&lt;Vec&lt;Peer&gt;&gt;`, and you have to dereferennce it to get `&amp;Vec&lt;Peer&gt;&gt;`.
`Mutex` will give you `Sync`, not `Send`. If your value has thread affinity, it's unsafe to send it to another thread. It's not that `Mutex` requires the type to be `Send`, but it won't be `Send` itself otherwise. You might need to dedicate a thread for that value.
Well done with the optimizations! &amp;#x200B; I'm facing similar issues in one big (unfortunately closed-source) project, which currently needs 5 min to build on a decent machine. My 2 cents: \- dependencies hurts not only because of the build time. E.g. we were using rocket without default-features turned off, which required ring. I guess every1 knows how annoying ring yanking policy is, and we were not using it at all. (btw. with newer rust it is not that big deal but there was a 'bug' in cargo in the past) \- if you use nightly, some dependencies might switched already to newer rust and cargo complains that some feature is no more feature-gated. Or uses a feature that is not yet in your version of rust. &amp;#x200B; And things that I would disagree: &gt;It's just sad that people are spending a lot of time optimizing the \`rustc\` and then all this work is being neglected by such a simple thing. Come on - without rustc optimization it would be even worse. Great crates and features (e.g. proc macros) are there to help you. Rustc team is working hard to make it as free and pleasant to use as possible. &gt;\`serde-json\` -&gt; \`json\`, \`structopt\` -&gt; \`pico-args\` In the binary - sure. In the library, you must think about such changes twice as they may be harmful. If the target project already has serde-json (or structopt or any other), then you may be accidentally adding unnecessary bloat.
Is the complete code publicly available? It would be interesting to see some of it converted to idiomatic Rust and see where that leads.
Let's look at the Rc example - it shouldn't be used by more than one thread, but Mutex should provide adequate synchronization. So I'm still baffled why the compiler doesn't allow that. After all, it's not possible to use the value without the mutex.
TBH, I would probably just do: pub fn get_mut(&amp;mut self, index: usize) -&gt; &amp;mut Item { if self.vec.len() &lt; index { self.vec.resize(index + 1, Default::default()); } self.vec.get_mut(index).unwrap() } ... I'm not sure why your original code fails though.
I thought if i drop(lock) will dereference it too. Thanks for your helps :)
&gt; Right now I'm taking a simple mean of RGB channels to get the frame average color, but there's a better way to get average colors. I was a tad stumped on how to deal with summing numbers that large, however, and couldn't figure out how to best approach this in Rust. You convert them to float (`f32`). You can even implement [proper](https://en.wikipedia.org/wiki/SRGB#The_reverse_transformation) inverse gamma, as the root mean square thing is an approximation. It might be overkill, though.
Nope, Rc is *never* thread safe to send across threads, because there's no way to prevent you from racing between threads when you call clone(). Rc is pretty much the canonical example of a type that isn't `Send` even though it doesn't seem to contain any references. Rust is correctly preventing you from doing something unsafe. One alternative, if you are willing to use something like Rayon that gives you scoped threads, is to just dereference the Rc pointer and send a regular reference to the child thread. Then you don't have to worry about Rc not being thread safe, because you don't have the ability to clone it in the child thread.
Yeah, I've rewritten it about this way too. The original code is more of "easier to ask for forgiveness than permission" approach.
It's the right choice under the assumption that you want to remove unused code. This way, you can just delete everything it calls out. If it didn't report the helpers, you'd remove the main unused function, and then would have to iterator on a compile-edit cycle until the compiler stops giving you new unused warnings.
But Reddit allows you to use custom clients, for example I use a RedReader which is a free software. Discord doesn't allow that. And their web version is too low contrast, I cannot read any text without hurting my eyes and no option to change it.
Sharing \`Rc\` between threads can cause UB, and \`Mutex\` (Assuming restriction on \`!Send\` lifted) does not help in this case - after acquiring a lock you can clone reference, and now you have multiple unprotected \`Rc\`s in different threads.
Once you locked the Mutex you could clone out the Rc, then unlock the Mutex and clone the Rc a bunch more. The reference count would then change without being synchronized properly across the threads, thus you have a data race.
Ah, thanks. I thought it might be in Cargo but didn't want to assume or have time to do much research right then. I guess it would then be correct to say that the Cargo semantics of semver are stricter than the "official" semantics, and as such, releases should respect Cargo semantics.
&gt; They have inherited Bionic from Android, so Google did not make that choice. Wait, I may be unclear on the history here. Did Google buy Android initially, and not just start it from scratch?
From the example in the Readme: ``` let received_msg = msg.as_any().downcast_ref::&lt;String&gt;().unwrap(); ``` Can the messages be statically typed?
Ok, seems my example was not the best. My real use case is that I'm testing a web api where each request is dispatched on a thread pool. In testing, I wish to inject a mock service which is not Send into the request handler. In non-test environment, Rust would be absolutely correct to disallow that, but in a test I am absolutely sure only one thread will ever access the mock in the same time, but since it's not Send, I cannot pass it the the request handler. So I'm wondering is there a way to work around such situations, when I know the mutex is sufficient to synchronize access.
`Send` denotes the value can be transferred to another thread. The reason `Rc` cannot be sent across threads is that another `Rc` pointing to the same value in the first thread could remain, leading to unsynchronized access. Sure, this particular `Rc` would be under the Mutex and under control, but since `Rc` is also `Clone`, there is no way to guarantee instances outside the `Mutex` will exist, on both sides.
Is your issue that the request handler demands a Send bound? In that case, it sounds like an implementation detail if only one thread will access the mock at a time... it might be worth looking at the framework (assuming you're using one) to see if it has any existing solutions to this problem. I know that some Rust libraries will switch between Rc and Arc based on a flag, and there might be something along those lines available. You could also test it by keeping the request handler's data in a single thread and passing the stuff it needs to handle back and forth through channels (I use that solution a lot). You can even use a thread local to store global but thread-specific state. There are actually a lot of approaches that can work, it just sort of depends on your use case.
The trouble with your design is that the mutex would only guarantee synchronized access to `your_s.f` but not synchronized access to the `Rc`'s internal reference counter or wrapped data because you can easily clone that Rc and then have an Rc outside of your mutex that shares the reference counter and the data with the Rc wrapped in your mutex allowing you to create data races w.r.t. the reference counter.
Yes - the problem is that the handler demands Send. I'm using managed state in Rocket with mocks provided by Mockers which are not Send. It seems to be a case when something, which is not generally Send, is safe to share with another thread because of runtime guarantees. I though a simple mutex would solve such case.
To elaborate, the first one goes via the `Display` trait, the second one via `Debug`. Note that the `dbg!()` macro uses the latter version.
I think you're right, serde-with does look a *lot* nicer than wrapping stuff in special-case structs. The problem regarding the heterogeneousness of serde collections still stands, though. I think I have a rough idea on how to get around that, but I'm on mobile rn so I'll try it out later today if I have time. I too hope the bug gets fixed soon, but I'm curious what exactly do you need the flattening for? I mean as far as I'm aware we can replace the nested struct with its flattened fields for the time being, right?
It sounds like Mockers not having mocks that are Send is a known problem. Are you really attached to that framework, or could you switch to another? A couple of others do have Send. BTW, I'd advise against trying to reason about how tests are run with thread pools unless you are really familiar with the framework. Unless something changed, Rust's default test harness will happily run tests concurrently, so if you have something in a shared thread pool it might actually not be as safe as you hope. As for a Mutex solving things... a mutex basically lets you turn a shared reference into a unique one, from any thread with access to it. Unique references give you guarantees very similar to ownership, so what that means is that if it would be thread safe to transfer a value of a type from one thread to another, then it should be safe to access one through a mutex. But there are some types that it's not safe to transfer across threads. Mostly, they are all types that contain *references* to a type with interior mutability (like &amp;RefCell&lt;T&gt; or &amp;Cell&lt;T&gt; or whatever), since those types let you perform thread-unsafe mutation through a *shared* reference. A Mutex can't protect those types in the same way because shared references can be freely copied, so you could have pretty much just ignored the mutex and access the references anyway. Even though Rc doesn't *look* like a reference type, it's actually a pointer, and the thing behind the pointer is shared by all Rcs you clone and includes a reference count, which is updated in a thread-unsafe way through a shared pointer; so Rc also has interior mutability. It can be really tricky to figure out whether a type is thread-safe if you don't know its internals because of types like that, which is why Rust generally performs this reasoning automatically.
It's a weird question to ask. The answer depends very much on what aspect of the languages you look at. C++ and Rust are the same in some ways, especially relating to execution model: * meant to compile to native code * give control over memory usage patterns (flat type layouts, explicit allocation/deallocation, explicit separation of static storage, stack and heap) * work with a minimal runtime * use native threads * have stable addresses (no implicit moves) * not fully defined - some code may exhibit undefined behavior Given that Rust is designed to replace C++ for systems programming, I think these features are, in fact, *inevitable*. Rust used to have green threads and a bigger runtime, but those things were removed because they didn't fit the use cases that well after all. However, when it comes to language semantics and features, there are huge differences: * Polymorphism models are *very* different: Rust has traits and fat pointers, C++ has subclassing and embedded vptrs. Rust has language-integrated discriminated unions. * Error handling concepts are different: C++ has automatically propagating exceptions that are caught by type and are not part of function signatures; Rust has `Result` returns and a single untyped propagating exception for really bad things (panics) * C++ has late-checked templates that rely on syntactic matching; essentially they are AST substitutions with completely new name lookups every time. (Concepts are coming.) Rust has early-checked templates that use traits for name-based matching. * C++ has macros that work on a different syntactical level than the rest of the language, and are completely unaware of its scoping system. Rust has macros that work on the language's normal token stream, their names cannot collide with other Rust names, and they are hygienic, i.e. they interact with name lookup to prevent unexpected things. * Rust has affine types and destructive, bitcopy move semantics. C++ has copy semantics and non-destructive moves with custom code invoked on move. * Rust has the safe/unsafe distinction. * Rust has the borrow checker. These are massive differences, so I think to say that Rust is "C++ in disguise" is a conceptual error. It is taking the core execution model and saying that this execution model is embodied by the C++ language, so that any other language using this execution model is "just like C++ if you squint". But that is not true. Rust and C++ (and C, except for stack unwinding) share an execution model. But other than that, they are not all that similar.
There's a bit in the changelog about an agent thread: &gt;The background agent thread that manages active requests has received many changes and improvements and is now fully asynchronous This offers less latency when multiple parallel requests are active and increased overall performance. Does cHTTP always spawn a thread to handle connections? Is so, why and is it configurable?
Thanks for your help. I understand better now what Send represents. I also switched mock library and things seem to work.
Temporaries are dropped after their containing statement, and the tail expression of a block is considered part of the statement that contains the whole block. So temporaries in the final expression of a block are dropped after locals in the block. IOW path gets dropped before the closure that borrows it. See [Explicitly describe temporary drop order difference between `return expr;` and final block expression #452](https://github.com/rust-lang-nursery/reference/issues/452) and the many links there (in particular, [pnkfelix's comment here](https://github.com/rust-lang/rust/issues/21114#issuecomment-428373388)). I _think_ rustc is worried about drops because it can't see through the impl Trait in the return type of wrap_fn. If rustc knows that the type doesn't need to be dropped it should compile fine. But I'm not sure about this part.
I feel like this should only work if you move path into the closure
Thanks for your comments and suggestions. I am continuously adding some features and adding documentation(sigh, need to write a lot) after the initial release. Definitely put a concrete version to readme after I stabilize couple of things in my mind. (e.g. Macro based declaration)
Made some design considerations to ease the pain of statically typed approach. It comes with some other problems that I don't remember of during implementation phase. One of them was using unsafe block to replicate messages. Which I don't want and added at the root of the crate by saying ```#![forbid(unsafe_code)]```. These are the waters that I don't want to swim when I started making this project. But definitely I am open to suggestions and continuously thinking for alternative message injection.
The workaround is unsafe. If you UB will never happen just use unsafe to allow it. For example implementing Send manually in the type.
$$$ ?
If anything, goblin makes you pay for what you don’t use. You should open a bug report upstream.
I mean is it really lighter if you depend entirely in a huge lib like curl? I get that having less branches seem like a good idea, but if it has a single branch with hudreds of thousands of lines of code it doesn't seem much improvement.
I'm not entirely sure, but a closure has context which is where that &amp;mut reference could be held, perhaps the compiler doesn't have enough information to know it's not held?
That was a hastily made claim based on noting that moving path to outside the block makes the code compile. It is then very close to the original version with an explicit return. I think the key here is that the temporary closure returned from wrap\_fn has the lifetime of the enclosing return statement, whereas path, which the closure borrows, has that of the enclosed block. This is pretty much what the compiler says in the error message: "The temporary is part of an expression at the end of a block. Consider forcing this temporary to be dropped sooner, before the block's local variables are dropped."
If that’s a problem, they should just be dynamically linking libraries. Like, why on earth would you statically link a Regex library with dozens of binary in fuchsia?
Can we have more maths puns please.
Thanks for all the work on this. `cargo-release` made my crate releases so much easier (especially because I never got [semantic-rs](https://github.com/semantic-rs/semantic-rs) done).
Is it possible to combine it with Tokio runtime?
Dynamic loading is like a raw pointer.
Maybe because they don't want some of their "feature" to be available to the public. I am thinking of tracking, collecting the private data, etc.
What do you mean _vulkan dialect_? If you’re talking about SPIR-V, it can transpile _GLSL_ to _SPIR-V_, yes — even though, for doing so, it needs a dependency that uses a system library to do so.
Go’s deadlock detection is really nice. If you are using Rust, and all your Mutexes are parking_lock ones (if they aren’t, just open an issue in your dependencies), you can enable parking_lock deadlock_detection cargo feature. It does catch all deadlocks in my programs, and it has quiet good error messages for a library solution, but the error messages aren’t as good as Go’s.
you can show results for max-rss there, which shows max memory consumption
Because that's hard to do in Rust right now. I'm not even sure Cargo supports it.
That is true, but it's usually not a good idea to do that unless you have *very* tight control of every data type involved and its execution environment. For example, like I remembered later, Rust's test harness can run tests concurrently (it might even do so by default?), and it is really hard to know how that will interact with a handler that lives in a thread pool unless you know exactly how the thread pool is implemented and how the mock object is implemented. My experience has been that a very high percentage of the unsafe impls of Send and Sync are incorrect in some subtle way, even compared to other unsafe code (I just caught such a bug in my own code, too!). So I tend to try to look for other solutions first, especially if it's to solve a "UB will never happen because of how the type is used across a large codebase" scenario and not as part of an implementation of a tricky concurrent data structure or something.
Why not pass a byte slice and let the users deserialize it into whatever they like?
Since the closure is `Fn`, not `FnMut`, this context can only be populated when the closure is created. When it is created, `&amp;mut i32` doesn't even exist.
Of course, Im just tired of people saying hey I know better and rust is baddie for not allowing me do know better. If you know better use unsafe and make it work, it's possible. But you probably don't know better. The best way to know better is to fuck up because you didn't listen and having to handle the problems it caused. I have had my fair share of problems with C, if the rust compiler says I don't know better and I'm not doing something for performance reasons I will believe it and make it work. Safe rust also can do everything unsafe can (except ffi and intrinsics, which are rare among all crates).
This is usually solved by making those items public and then adding `#[doc(hidden)]`.
Let's say I'm declaring a trait that should be used by users of the library to provide an implementing type to another function. That function uses the trait's method, and ideally, depending on the error category, it either tries to cope with the error or returns with the error embedded in its own error struct. What should be the return types that its methods should be specified to return, and why ? trait Speaker { fn speak(&amp;self) -&gt; Option&lt;???&gt;; } A few ideas: * A `&amp;error::Error` which makes it very generic, but unfortunately the using code that will receive the error will know nothing about the error (if the Speaker had just a temporary error, a retry could work ! but if he's dead it will definitely not work) * A `enum SpeakError` with each variant describing one possible error condition. However this reduces the expressability of the possible errors, a PC speaker would like to indicate at which sample it failed for example, which could be useful. * A `struct SpeakError { kind: SpeakErrorKind, err: &amp;error::Error }` which would bring the benefits of both options, with `SpeakErrorKind` an enum * Or a `trait SpeakError : Error { fn kind(&amp;self) -&gt; SpeakErrorKind }` I would also want to know not only the error kind but also the instant it failed, so `fn failed_at(&amp;self) -&gt; u64` if it's a trait. What do you think ? PS: This is illustration code so there's probably an error somewhere (looking at you `struct`)
The situation here should improve considerably once const generics drop.
I've not found this to be the case in the rust subreddit.
Oh, my bad! Turns out it was an adblock glitch. The link is there.
What's the edition they are talking about shipping [here](https://github.com/rust-lang/rust/pull/53654#issuecomment-415864424)? I thought the next edition is 2021.
What's HFT?
It seems that an associated error type would be useful here, e.g. enum SpeakErrorKind {} trait Speaker { type Error: SpeakError; fn speak(&amp;self) -&gt; Option&lt;Self::Error&gt;; } trait SpeakError { fn failed_at(&amp;self) -&gt; u64; fn kind(&amp;self) -&gt; SpeakErrorKind; } This way users of the library can create their own error types, while ensuring that the library's own code can handle these errors.
What does that mean for users?
That seems like a good solution ! Thanks ! Have a nice day !
I'm almost certain that they are talking about the 2018 edition, which didn't ship until December of 2018, while this issue was both created and closed in August.
It also means you can get your nodejs guys to do some work on your systems level stuff, and you know that provided they didn't use unsafe, there won't be memory bugs. Worst case is they come back and say "the compiler won't let me do anything" in which case you've lost a few man hours rather than compromising the security of your application.
Anything against the hive-mind gets down voted to oblivion and people are hyper sensitive against making anyone feel bad because of criticism. Unless their opinion is against the hive mind, then it is quite fine to be a dick to the other person.
Imagine a type like `Arc&lt;Mutex&lt;Option&lt;T&gt;&gt;&gt;`. If you have one of those, you can call `.lock().unwrap().take()` to take ownership of the `T`. Essentially, sharing a reference to the `Mutex` (the `Sync` property) allows you to move its contents (the `Send` property). That's why `Mutex` generally requires `T: Send`. Notably though, `Mutex` does _not_ require `T: Sync`. (But `RwLock` does.)
I honestly have never seen this. If anything the rust community is the best at celebrating dissent of any community. Big decisions have been changed because of a comment by someone on a github issue. Google Aaron Turon's recent talk about open source governance to see a fuller exposition of the concerns involved.
This does make sense, looking at it from this point of view.
Instinctively, one would think it would not be possible to persuade everyone to use these 'base abstraction' crates, but I'm happy to say that a number of these have already been successful to a greater or lesser extent (futures, http, mint for 3d game vector layout). I hope this one enjoys the same success
&gt; Do not use `clap` for simple projects. Typicaly non-`clap`-based argument parsers fail at correctly accepting filepath arguments (which are common even in simple projects), making things broken for non-UTF8 filenames from the beginning.
I'm talking about reddit and this subreddit. Not about the entire rust community and governance.
According to the PR you linked to, since the result of the expression isn't bound to a variable, the borrowed path's lifetime ends when the expression returns. An explicit return probably does similar things to using a let binding manually.
Thanks for your blog post, I was not sure to properly understand how borrowing works. Now I understand :
I don't really engage in debates on reddit, I just use it to see any announcements. I use users.rust-lang.org, internals.rust-lang.org, and github issues for debate.
Yes, `clap` uses `env::args_os` and not `env::args` as many others. As long as you really need it, it's not a problem.
Thanks for both of your comments ! And yes, the material of the second big ball is reflective (glass-like) so the image appears upside-down.
ASCII-only regex is actually a very good feature for cargo-bloat, since method names are always ASCII (technically, you can use non-ASCII identifiers, but I never saw one Also, I think that performance is more important than binary size. At least in case of Rust.
I'm not sure it's possible. I can skip most of the data, because I don't need it. But `goblin` can't.
It is a good post. I am starting to use Rust, and I didn’t know about the meaning of “Copy” and “Clone” before reading the post. Thanks!
I think people just using a familiar/popular tool. I don't think that you have to use an external library to parse args in an example too.
&gt; Also, I think that performance is more important than binary size. At least in case of Rust. I don't think that matters. I'm not saying I'm _going to_ decrease `regex`'s size at the cost of performance, but rather, _may provide an option_ to so that consumers can choose their own trade off. It doesn't matter that this is Rust; performance isn't king in every use case.
&gt; Come on - without rustc optimization it would be even worse. `syn` compilation is just a waste of time. You can't fix it with a faster compiler. PS: I've actually switched from rocket to actix only because of nightly. I don't need a high-performance server, but fighting with nightly is too much for me.
After checking a project of mine: Rust std libs use Win32 heap and file APIs instead of the C runtime which is nice. I see CRT importing exception handling and memcpy, memmove, memcmp, memset, strlen functions... Pretty sure the std libs only require the exception handling and the rest are from libraries I've used. The last big CRT imports are math routines for trigonometric funcs. These imports look pretty dang important to me and not trivially replaceable.
As u/dpc_pw said, this thing is usually called HList. Take a look at [frunk](https://crates.io/crates/frunk), it provides a decent implementation.
No, I don't use clap because it's popular/familiar. clap _became_ popular/familiar _because_ it gets arg parsing right. There are a ton of subtle details about arg parsing that end users expect, and if you get it wrong, they file bugs. On top of that, failure modes are important to. Emitting sensible error messages is important, and clap does pretty well at that. Is there room for a smaller more minimal arg parsing library? Most likely, sure, but I'd personally stay away from it unless it gets the subtle details right like clap does. I use clap in examples because that's what my command line applications use, and I try to make examples representative of reality as much as I can.
High frequency trading
I [agree](https://llogiq.github.io/2019/02/27/tooling.html) that debugging async tasks isn't exactly straightforward – and Rust is not alone in this regard. At least we have crates to trace execution, which helps a bit to make sense of the tangle. I must admit that I haven't written too much async Rust code yet, so I lack some intuition, but I do wonder if we could create clippy lints against some common failure modes?
I wish people would stop reciting talking points and saying "C/C++ are bad, rust is good" and just work on proving it by writing good, useful projects. Companies don't want to use unproven technologies and the only way to improve Rust use and adoption is to cut away at the use cases for other lower level languages by making the appropriate tools, libraries and resources available.
Thanks for the suggestion!
This is fascinating to me: \&gt; The danger is that it's Rust's reputation on the line in people's perception if something goes wrong, rather than Actix's. I have no interest in using Actix, but it bothers me a lot if it means that we never know whether we're coding in the unsafe-but-looks-safe variant of Rust or Rust as designed. So it's undermining the integrity of Rust. It's interesting because I've never thought of someone being bothered by how I might use a programming language. Now you have me wondering, are there any FORTRAN users bothered I was trashing their reputation for speed by writing slow things. Are Rust users, if I were to ever write anything of prominence, going to be bothered by my contribution - would they rather my crappy coding ability hadn't joined the party at all? Also, perhaps we should work on correcting this misconception: \&gt; then see it's written in Rust, and they know that "Rust = safety"
As someone who is very interested in Rust and claims to be fairly good with C and C++, here are my thoughts on this article: - There's very little substance in this article. The words "C is unsafe" and "Rust provides stronger safety guarantees" are words that have been repeated ad nauseam. - NOTE: I am not claiming there's no truth in this. - Things like style guides, Valgrind, AddressSanitizer, proper use of what C++ calls RAII, and the experimental `-Wlifetime` do reduce the potential for bugs. - I'm not saying they reduce safety related bugs to 0, but they minimize them. - Something like MISRA-C, which defines a very strict subset and rules for writing C, coupled with a MISRA certificate would provide a good safety guarantee. For starters, no heap allocations means no leaks. - This is something I've never seen mentioned before. Has anyone ever attempted to compare MISRA-C with Rust? Correct me if I'm wrong, but I haven't heard of any safety critical Rust projects.
If you are writing an application you are the only user of, by all means, fill your SSD with whatever you want. If you are writing a library that has the potential to be used widely that's a different story. Will you pay for storage and build times for every developer using your library? How about the whole transitive closure of your library's reverse dependencies? You are pushing tiny costs on lots of people. Sometimes (tiny)\*(lots) is not tiny anymore. And it's possible that this product outweights additional development costs in some cases.
&gt; Has anyone ever attempted to compare MISRA-C with Rust? https://polysync.io/s/The-Challenge-of-Using-C-in-Safety-Critical-Applications.pdf They compare MISRA-C, static analyzers, and Rust, on four different sources of issues.
It's a good explanation, but it breaks down a little when you have multiple immutable borrows -- of the same value -- at once. You can't give your book to multiple people at the same time. But you can invite them, and their friends too, into your home, so they can read it, under the condition they'll be careful not to mess it up.
Thanks! Time to read.
In your opinion, is adding optional features the right way to go? Suppose in my project's dependency graph there are two occurrences of env\_logger, one with regex enabled and one without. This is increasingly likely as optional features proliferate: maybe some library developers didn't know about the feature, some didn't care, and some genuinely needed a unique feature set. Now I'm paying the price for regex anyway, but also I have to build two versions of env\_logger on top of that.
It would mean that you would need to compile openssl and curl yourself if you want to make a musl binary.
"lighter dependency" is different from "lighter".
The `RwLock` requires the contained type to be Sync? I think I saw that in the documentation at one point and thought it was a typo - can you explain that a bit? I would have thought `RwLock` would itself be implementing `Sync`.. why is `T` required to be `Sync`? Like.. does that mean I need to `RwLock&lt;Mutex&lt;T&gt;&gt;` ? Am I high lol?
In addition, it's best practice to make the accessible path involve some clearly implementation detail path (e.g. `macro_support`) and mark any item as semver exempt explicitly. Of course, it's _best_ if the macro expands to user-writable code, but that's not always easy nor even possible.
Started with 22 years old and I went "oh boy here we go with another 'experienced' guy fresh out of university," but your GitHub is absolutely stunning. 22 years old? When do you sleep?! Wish I was hiring for Rust, mate, best of luck.
Compiler does not know what `rec` could do with that reference - for example it could store it in a `Cell&lt;&amp;mut i32&gt;`, and so using `cnt` after first `rec(cnt)` call would be UB. I think in this case you wanted `rec` to have type `for&lt;'a&gt; &amp;dyn Fn(&amp;'a mut i32)`, but I'm not sure how to do that without making `fix` less general.
But is the tree lighter if it has a single branch weighting the same as a tree with 100 small branches?
Unfortunately, from a business perspective: A shipped program which makes the company money is 1000x worth a non-shipped program.
Thanks! Regarding sleep... I often don't. I think I'm just way too curious for my own good.
Sync means it is safe for multiple threads to have shared references to a value at once, which is exactly what RwLock allows you to do. Mutex only allows a single reader/writer at once
But isn't requiring `T` to be `Sync` meaning that in `RwLock&lt;T: Sync&gt;`, the `RwLock` isn't making `T` `Sync`? Ie, `T` must already by `Sync` for that to work, no?
Yeah, maybe
Instead of reciting the "safety" talking points, this is how to sell Rust: - Standardized tooling: No more CMake + Makefiles, or Ninja, or SCons, or whatever homegrown tooling you wrote to do builds, the language ships with a build tool. No more wasting days of time trying to understand the finer intricacies of CMake. - Simplified unit and integration testing: There's `#[test]` for embedded tests in code, doctests, and a standardized directory for integration tests. - Documentation generation: Super programmer X left, or trying to onboard new teammembers? Well, luckily you've been requiring doctests so when you use `cargo doc` you have example usages which must work. Oh yeah, and you just use a markdown flavor for writing docs. - Conditional compilation: Building targets for Windows-only or Linux-only? No need to do inheritance to change behavior at runtime based on the target. - Built-in benchmarking: How fast is this thing? Oh, btw, that's built-in as well. You shouldn't "sell" rust though. Practice writing Rust. You need a new command-line tool to do X at work? "Hey boss, give me 2 days to make a Rust instead of a Python 3 version. When it's done, you can all pass it around the office to have a look." Doing this on your own without supervision will go down very poorly and possibly maliciously, so make sure you get permission (send the request in email or slack) before you go about this. It'll be low risk, give other engineers the opportunity to actually see Rust in action, and maybe have them code review. - Rust + `clap` + `colored` to make a nice interface. - Show how short and simple it is to make all those command line options you need. - If it does any sort of substantial work, it'll be faster than a python version. Maybe stay late for a night or two to make a Python (or competing language) version. - Write up a comparison of various parts of the program which Rust made easier. Write which parts Rust made harder, or difficulties you had.
Yes, each and every client instance maintains exactly one agent thread. This is necessary in order to allow you run multiple requests concurrently without blocking the main thread. The agent thread runs an event loop in the background, and the client dynamically adds and removes requests from it while it runs. I suppose it may be possible to avoid spawning any threads if some sort of `execute()` method on the client simply blocked the current thread until all requests queued up finish. I'd want to hear a use case for that first though.
While the article mentions Rust only in passing, it raises some good points about the huge number of software vulnerabilities discovered recently and what the large-scale use of fuzzers might bring. &gt; Some numbers give an idea of the scale: as of January 2019, Google’s ClusterFuzz has found around 16,000 bugs in Chrome and around 11,000 bugs in over 160 open source projects integrated with OSS-Fuzz. OSS-Fuzz was launched at the end of 2016, I think. 16 000 bugs in Chrome -- assuming no duplicates -- is mind-boggling.
Does that actually happen though? AIUI, only one copy of `env_logger` will be built which contains all features enabled in your dependency graph.
PM me your resume. We have some backend work in rust that needs to be done if working on a [DAMS for schools](https://www.schoolbench.com.au/) seems interesting
Let's not fool around here, hyper is a pretty huge lib too. HTTP is a deceptively complex protocol, especially with 2+. And by default, a bundled version of libcurl is compiled and linked statically by default, with all protocols disabled except HTTP(S).
Another analogy would be that you put it on display (like put it in a museum or a display cabinet), many people can watch it, but nobody is allowed to touch it (or change it, otherwise they'd be obscuring other people's view by loitering in front of it ;-)).
Yeah, [about that](https://github.com/clap-rs/clap/blob/784524f7eb193e35f81082cc69454c8c21b948f7/src/osstringext.rs#L23-L32)... #[cfg(any(target_os = "windows", target_arch = "wasm32"))] impl OsStrExt3 for OsStr { fn from_bytes(b: &amp;[u8]) -&gt; &amp;Self { use std::mem; unsafe { mem::transmute(b) } } fn as_bytes(&amp;self) -&gt; &amp;[u8] { self.to_str().map(|s| s.as_bytes()).expect(INVALID_UTF8) } }
Hiring in the UK?
Try stackoverflow jobs mate. Stay away from the traditional sites and LinkedIn. I've seen a few rust interviews over here and you'd be surprised how many people are just flat out fucking clueless about the tool, but want experienced devs anyway.
With nom you can parse the data that you need, so it is possible.
It'd be remote work from the UK, as we're based in Australia
Thanks for the advice.
Goes for most stuff. My previous employer wanted to make apps but didn't have a clue about what to make..
I agree that `clap` is the right choice for something like ripgrep. But there are a lot of examples were you don't need an args parser at all. Like [this one](https://github.com/pcwalton/font-kit/blob/master/examples/fallback.rs). Do we really need clap to take 3 values from a vector?
True, but cHTTP wins in both departments: $ cargo bloat --example reqwest -nn5 File .text Size Crate Name 12.1% 86.5% 6.9MiB [37101 Others] 1.1% 7.6% 621.0KiB http http::header::name::parse_hdr 0.4% 2.6% 211.9KiB idna unicode_normalization::tables::compatibility_fully_decomposed 0.2% 1.5% 118.7KiB idna unicode_normalization::tables::canonical_fully_decomposed 0.1% 1.0% 81.8KiB idna unicode_normalization::tables::is_combining_mark 0.1% 0.8% 62.2KiB encoding_rs encoding_rs::gb18030::Gb18030Decoder::decode_to_utf8_raw 14.0% 100.0% 8.0MiB .text section size, the file size is 56.8MiB $ cargo bloat --example chttp -nn5 File .text Size Crate Name 8.4% 67.0% 1.4MiB [7844 Others] 3.7% 29.4% 621.0KiB http http::header::name::parse_hdr 0.2% 1.6% 33.7KiB [Unknown] vsetopt 0.1% 0.8% 17.9KiB chttp chttp::client::HttpClient::create_easy_handle 0.1% 0.6% 12.3KiB curl_sys Curl_http 0.1% 0.5% 10.7KiB libnghttp2_sys nghttp2_session_mem_recv 12.5% 100.0% 2.1MiB .text section size, the file size is 16.5MiB Maybe I'll publish more thorough results somewhere.
The guy that wrote that issue is complaining that if you build a whole operating system (Fuchsia) where you statically link everything then your system ends up bloated. I have zero idea how someone can conclude that the problem is “the regex crate” instead of “their whole architecture”. I mean, pretty much every other operating system dynamically links everything. They could reduce the size of the regex crate to zero, and their whole system would still be bloated.
Channels maybe? Or does that make this too close to actors.
you can also extract frames by letting ffmpeg decode to rawvideo to stdout and piping from
So?
I had actually taken a look at doing this! Ultimately I couldn't wrap my head around how to read binary data from the pipe in Rust (both the reading element and the decoding element). Any tips on how to approach it?
Yes. A single-versioned, well-vetted dependency is definitely "lighter" (at least in my head). &amp;#x200B; In the absence of strict definitions though, we can bikeshed this for hours.
Man you are amazing
Awesome, thanks! Made those changes.
[https://gitlab.com/cheako/hazel/blob/master/src/lib.rs#L91](https://gitlab.com/cheako/hazel/blob/master/src/lib.rs#L91) &amp;#x200B; I don't know if I'm just not doing this correctly. I loose part of self.window when I call run(), but I want to read my self.layer"s" in the event loop. I'm also looking to add functionality where the event handlers can add and remove layers, not sure how I'm going to accomplish that.
Power consumption is a very important topic in most embedded software these days. Its important even for grid connected applications as there are regulations within EU to decrease power consumption from many devices and I assume more will follow. I just published a git repo for a quickly hacked rust program to automate current consumption measurement (it will soon be a part of our CI tests): [https://github.com/bofh69/otii-measurement/](https://github.com/bofh69/otii-measurement/)
Oh! Just checked and you are correct. Very interesting. So cargo assumes that `env_logger = { features = ["regex"] }` dominates `env_logger = { features = [] }`. Even though there could be some code guarded by `#[cfg(not(feature = "regex"))]` in it somewhere. This means features shouldn't be used as general-purpose boolean flags, but only to add optional functionality that is backward-compatible. In other words, `env_logger = { features = ["regex"] }` must fulfill the contract of `env_logger = { features = [] }`. I like Rust more and more.
I did this in a project by creating an empty ImageBuffer and using read_exact on ChildStdio to read into the ImageBuffer (which has DerefMut to [u8])
So are you :)
&gt;30 I wonder what kind of project you usually work on for mere a 30 seconds to be too much. &amp;#x200B; Disclosure: Servo dev.
I am using VSCode with the Rust plugin (version 0.6.1) and when I use Ctrl+Shit+P and select "Run Task" there is no "Rust: cargo run". Anymore. I know this was removed, but then added back again later (see: https://github.com/rust-lang/rls-vscode/commit/ff119775bdd8760c94502036ec6af431e7f6fede) However I still cannot find "Cargo: rust run" in my tasks list. Has the update not been pushed yet or am I doing something wrong? (I am a beginner and I have a lot of little "projects" so I can try out different Rust features and setting up a task runner for every little test project I make is kind of a PITA. So I really really liked the built-in "Rust: cargo run" feature.)
Nice explanation! It matches my mental model of ownership and borrowing and the examples are nicely chosen. Props for explaining \`Copy\` as a "slip of paper". I've seen ownership tutorials either not touch the \`Copy\` at all or explain it as "moves and copies are the same and with move, but you just can't use original after move", which I find too low-level and not particularly helpful in building mental model. &amp;#x200B; I also like to extend this analogy of "books and pieces of papers" to references themselves: * A shared reference is just a \`Copy\` slip of paper with a note "there's a book at that address. Go ahead and take a look" * A mutable reference is an unforgeable certificate (with holograms and whatnot, so it's not \`Copy\`) with a note "there's a book at that address. You're the only one with access to it right now. You can do anything with it apart from moving it".