That would be awesome!
To be exact, /r/playrustservers (/r/playrust does not allow server ads).
Bulk syscalls are interesting- I've seen the same arguments used to justify asynchronous message passing. Another interesting option would be to allow pipelining syscalls or, potentially even more useful, passed messages (for example, [CapnProto's promise pipelining](https://capnproto.org/rpc.html)).
I use xargo in my launchpad-rs project for the Stellaris Launchpad. I've got heap, collections, UART, PWM and more so it's all doable if you can find the register definitions!
Very awesome work!!!
Yeah, something based in futures-rs and capnproto could be really awesome, specially with async/await/yield support in the language. Sounds similar to midori (http://joeduffyblog.com/2015/11/19/asynchronous-everything/).
The vision of userspace emulation sounds really interesting. &gt; **Userspace emulation** &gt; &gt; One thing we envision is being able to emulate other kernels in userspace, with a reasonable performance. We believe this is necessary to make Redox easier to adopt to your own computer without giving up certain platform-dependent software. &gt; &gt; The way we will achieve this is providing system calls for registering interrupts and system calls, such that the userspace can set up a fake kernel environment where the kernel binary can be mapped. I've been learning lately about the "lx-branded zones" in Illumos and the Linux ABI compatibility in FreeBSD. Emulating syscalls for other platforms seems like an incredibly useful feature. Are there other examples of this approach? Can anyone here speak to the pros and cons or potential pitfalls?
First of all, the first 16 bits are used for checksums, so it is only 112 bit, in fact. Still, you're right it is a lot, and it should be seen in the light of the alternative, 64 bit (- 16 bit checksum), which means that you can only address 281 tera bytes. While a personal computer will not hit this limit, it is not too far off to say it will be hit in the future. Furthermore, many large-scale servers has 512 or more TB available, making TFS unfit for those. In short, we want to be future proof, and the alternative, 64-bit isn't.
They're both correct. On is colloquial the other is a proper definition of the notation.
For another example of system call emulation, see the Windows Subsystem for Linux in Windows 10. 
I don't know how it works, but this sounds like its inspired by Swift, which has a similar feature. 99% sure any interpretation of C++ beyond reading type signatures is performed by clang.
Is that a hard limitation? Shouldn't temporaries still have a deterministic order of destruction?
Mhh... Sry but it feels like, that this is 100% unrealistic. :(
And you've nailed it perfectly. Now I completely get why declaring lifetimes is done, so that the new scope knows the original scope of the object and doesn't change it. But wait, I thought that using a reference already did that? So why would we ever want to name a scope explicitly? C++ doesn't even give us syntax for that so why does rust?
Your definition makes sense to me. The problem with `insert` is that you're trying to access the contents of your `Tree::Node` in a guard (`if s &lt; d`), which moves the entire `Node` (not just the contents) into the guard, and thus breaks the whole thing. The easiest way out of it is to move the checks into the `match` arm itself: https://is.gd/eu92gK Also note that you can't return `self`, or the borrow checker will complain for much the same reason. You can return a new `Node` with the same contents though.
one thing, it's probably too late to change now, but i wish you'd gone with the `[]` syntax instead of `&lt;&gt;` for generics. Nested `&lt;&gt;` looks terrible as u/mjoy points out below, things like this `PartialOrd&lt;Cell&lt;T&gt;&gt;` regularly appear in Rust code, and i've seen even worse things when people are doing stuff with multiple threads in particular (nesting of `&lt;&gt;` 3 or 4 levels deep)
In this case, you can just write `tree =&gt; tree`, since it's the last pattern. (If you don't want the catch-all behavior, you can write `x@pattern =&gt; x` instead) Edit: Now I see that you can't use this approach in the modified code, but I'm leaving the comment
I`ve got one question relating to TFS. Is your design based only on ZFS, or have you guys looked at hammer and hammer2 as well?
Getting multiple PWM timers to run concurrently in launchpad. I have an RGB rainbow wheel, but only in debug mode, not release :/
Wow, I didn't knew that Redox development is so intense! I hope I'll have time to look into it more closely some day. Keep up good work!
Using a reference does do that... but what happens when you pass two separate borrowed values with unique lifetimes? Then you need it. Also, C++ expects you to keep track of it on your own -- it should be in your design, or documentation, where your declared values have their destructors called. Rust handles it for you, and exposes syntax to get nitty gritty in the right moments.
You use `_` for "a single thing", and `..` for "whatever is left". So if you have `struct S { a : u32, b: u32 }` and do `let s = S { a: 5, b: 10 }`, then you can `match s` with `S { .. } =&gt;` and `S { a, .. } =&gt;` and even `S { a, b, .. } =&gt;`. Note that in the last case the `..` part can't match anything.
I don't know why they went with that, but _ ignoring one specific field and .. ignoring everything seems much more natural than your examples. _ looks like a blank in a form, while .. looks like an ellipsis. So probably human readability was the main factor. 
This probably falls way outside the mandate of keeping the IDE features 'basic' but what is the possibility of supporting step-debugging when crossing the C/C++ &lt;--&gt; Rust boundary? Or is this already supported and I'm just a moron?
&gt;but what happens when you pass two separate borrowed values with unique lifetimes? Then you need it. But why? Aren't borrowed values just references to a preexisting object? Then why does the new scope, let's say a function need to care about that? aren't the references themselves created within the scope of the function and thus they last the duration of the function and then are destroyed. But the original bindings were never changed so then why does the function need to know the original lifetimes of the two objects whose references were passed in? And even if they do can't the compiler just figure that out? I can see why that's a thing for structs because you don't want an object based on a structure to contain a reference to a non-existent object but why do that for functions? Also I still don't get what that extra syntax is trying to say to the compiler that it doesn't already know. I feel like I'm beating a dead horse here but reading some of these answers is just confusing me more. 
In addition to what /u/thiez said: `_` and `..` both exist for the same reason for which you would always make your matches be fully explicit (list all the variants explicitly). There’s probably a few of the reasons to do that; I can remember at least one from the top of my head: In the compiler we have a number of places where the enums are matched on. Some of these explicitly match on *all* the variants so that, when somebody added a new variant to a enum, the compiler would report an error pointing the developer to scrutinise the match for necessary changes as well. Since rustc is a very big project many people work on, such practice has helped us to avoid bugs. The similar reasoning applies to `_` and `..` in this case: you would use `_` rather than `..` so that when somebody added a field to a struct (or some such) the developers would be forced to scrutinise their matches.
why cant i see there how many votes for each feature ?
&gt;elision is usually defined as the removal of something, yet, in the context of rust lifetime tags, it means that the compiler will add them automatically in certain cases. In this case, the way to think about the use of the word elision is that the symbols have been removed from the source code. "Lifetime elision" is a feature that allows the programmer to elide lifetime annotations.
i foresee a day when the entire gamut of Linux OS code is ported on to Rust. :-)
jemalloc (the default allocator for Rust executables) does use a [separate arena per thread](https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919). I'm not sure if additional specialization would improve on this though.
Ah OK. If you read the first link I provided you'll see a picture of a slide of this year's Rust conference. There is one item on that slide that says: "Rust numerics / ML - Establish foundation ?" So the Rust team (and community) is aware and motivated to improve the numeric / scientific usefulness of Rust in the future. If you're not willing to invest time and learn Rust now at least I would suggest to keep an eye on it. Rust is a wonderful programming language with great tools and an awesome community!
&gt; There is an irq scheme that allows a driver to handle IRQs without putting the system into an infinite loop. In Linux, userspace drivers have no such facility and cannot handle interrupts. Linux userspace applications can use the UIO module to get a file descriptor that they can read interrupts from. What is Redox doing that UIO isn't?
Yes, but UIO does not allow handling an interrupt. In UIO, a small kernel driver that knows how to stop the device from producing more interrupts must be written. Once the device is told to stop interrupts, the userspace driver can read that an IRQ was handled, but cannot handle the IRQ itself. In Redox, the userspace driver will be notified immediately upon an IRQ, and is responsible for preventing the device from triggering more IRQs before sending an ack to the IRQ scheme. This removes the need for a small kernel driver. For information about this, from Linus Torvalds himself, see this: http://yarchive.net/comp/linux/userspace_io.html
Not really, outside of what is listed in this article. I am working on networking in the new kernel, to make it more robust and make it support timeouts and I/O multiplexing. My focus is to have package management soon, but we run into limitations with the current network stack - without timeouts, network operations that don't receive a response cannot be canceled. Ticki is working on TFS and ralloc. Someone who wants to help us could propose a roadmap.
&gt; Aren't borrowed values just references to a preexisting object? They are. &gt; aren't the references themselves created within the scope of the function and thus they last the duration of the function and then are destroyed. Not necessarily. There are a few ways that references can "escape" a function. For example: fn return_ref&lt;'a&gt;(in: &amp;'a i32) -&gt; &amp;'a i32 { in } &gt; so then why does the function need to know the original lifetimes of the two objects whose references were passed in? If it returns them or stores them somewhere, the compiler needs to know about that. The only way to represent that is with some kind of (possibly elided, but still *conceptually* there) lifetime variable. For example, say you had this code: let foo = 7i32; let bar = return_ref(&amp;foo); drop(foo); format!("{}", *bar); // WELP. Dangling pointer. Obviously, that shouldn't work. To make sure it doesn't work, the compiler needs to have some way to know that a borrow that's passed to return_ref lives for as long as return_ref's return value. Or in other words, that the first reference's *lifetime* is the same as the second's, conceptually. No matter what, the compiler has to be able to figure that those lifetimes are equivalent anyway, so we might as well spell it out. It's also important that Rust be able to type-check the *usage* of a fn using only its type signature and not its implementation; that way, the implementation can change without breaking all the downstream code. For another concrete example, let's look at *this* code: static a_word = 18i32; fn return_ref(_: &amp;i32) -&gt; &amp;'static i32 { &amp;a_word } let foo = 17i32; let bar = return_ref(&amp;foo); drop(foo); format!("{}", *bar); // Fine, bar isn't borrowing foo. &gt; what that extra syntax is trying to say to the compiler that it doesn't already know. Sometimes, the compiler won't even know for certain what the code is until after typechecking is done, because of traits. It will *only* have the function prototypes to work with, so it definitely needs lifetime annotations. &gt; I can see why that's a thing for structs because you don't want an object based on a structure to contain a reference to a non-existent object but why do that for functions? Aside from everything else, there's the fact that functions often take structs like those as parameters, or return them.
Well, Julia has an awesome console based on IPython Notebook with easy ways to make graphs oh the fly, from what I know there's nothing close to that in Rust. Wether that is a huge thing is subjective. IMO it is and would make me choose Julia, at least for early prototyping which I think gets a huge benefit from the immediate feedback of a console.
Most types have these traits, it'd only stuff like Rc that doesn't (even RefCell is Send). So you'd end up having a separate allocator heap for very few objects, and the savings may not outweigh the overhead.
I used Julia pretty heavily for a few years and was followed the language developer community pretty closely during that time. IMHO, Julia excels for academic work where you're interested in quickly proving/testing an idea enough to get some figures or determine that something doesn't work and then you can file that code away in some directory and never use it again. Building larger systems in Julia is definitely possible, it just becomes frustrating when your simulation code crashes at the end of a long run because of some easy bug that the compiler of a static language would have been able to catch ahead of time. I see Julia and Rust as complementary in the same way that Python and C++ are complementary: Python is great for small utilities, prototypes, and medium sized systems, but when you want to collaborate with more people/scale the problem sizes or hardware usage you generally would be better served with a statically typed language. And as far as the distributed computing story goes, last I checked (~ a year ago), Julia has good marketing on how easy it is to distribute work, but when you scratch below the surface you find the support pretty superficial. Eg: last I checked they were still working to get their runtime thread safe so they could properly support multi threaded applications (rather than multi-process ala Python). So I think Rust will rapidly shoot ahead here once Tokio/futures/rayon settles.
It depends on your problem. If you are working with very large matrices then Python with numpy can be almost as fast as Julia, because the matrix algorithms are implemented i c++. Rust also has matrix libraries, but I believe that some features are still work in progress. If your code has an inner loop that determines execution time then Rust is probably faster than Julia and Julia is probably faster than Python.
Are type level integers part of the plan?
Definitely.
Ok, that explains it then. An associated function is just fine for my needs, so I'll go that route. Thanks!
Heh. Sounds like you're two days too late! ;)
Context for the future, since this will be incomprehensible some months later: there were outages caused by [DDoS attack on DNS](http://krebsonsecurity.com/2016/10/ddos-on-dyn-impacts-twitter-spotify-reddit/) two days ago. By the way, this is not my work. :) I just discovered it.
I wonder how well this translates to actual usage. I would assume that most APIs (like libc) will approximately have a "one function call results in one syscall" mapping, in which case the underlying library does not have a chance to use bulk syscalls. So to get an advantage out of it the application author would probably have to put some manual work into it (which is rather unfortunate, as you'd have to break through a number of abstraction layers).
SSHFS mounts the network share locally. The application does not need to know that it is accessing files that aren't local.
&gt; In other words, “the layout and structure of a TwitterUser is malleable and subject to change at any time.” This does not match the nature of a serialization library, which usually wants you to control the structure of data entering and leaving your program. With that in mind, I changed my tactics to manually load each field whenever I needed to create one of these structs. FYI, `serde` has great for support for this. It allows you to ignore unknown fields and set default values for missing fields - see [Attributes](https://serde.rs/attributes.html) 
couldn't bulk syscalls be implemented as a compiler optimization?
&gt; EdgeDNS does its best to guarantee a maximum latency. If a response that needs to be refreshed doesn't get a response within a given time frame, EdgeDNS can directly respond with cached records in order to avoid breaking the latency guarantee. Might have saved users from being impacted by Dyn's outages.
For just mirroring the repositories you can use repository mirroring: https://docs.gitlab.com/ee/workflow/repository_mirroring.html
I had not known about argon2 - we could use that. **EDIT - We are now using argon2 in https://github.com/redox-os/userutils/** I have configured it to use 10 passes with a 64-bit OsRng seed.
We have an initfs to run drivers like the disk and filesystem driver in userspace. The clock driver is different because of performance - thrashing the TLB on every tick is unnecessary when the only thing that interrupt does is increment a number. ACPI is a case where we have forever been cursed by the complexity of x86. In order to bring up a secondary processor, it must be booted in real mode somewhere in low memory. This is a risky procedure if done incorrectly, so we do it as early as possible and insure there are no side effects before running userspace code.
I opened an issue about this hint here, since it's clearly misleading: https://github.com/rust-lang/rust/issues/37363 
In a somewhat related note, `HeapAlloc`, the standard heap allocator on Windows, it has an option to use an unsynchronized heap, which might be faster in single threaded situations.
The question mark (and `try!`) returns to the closure, not to the function outside of it. The error you're getting is the result of that - you're trying to throw an error to a function that returns u32. Here are two definitions of that function which work: fn digit_sum(n: u32) -&gt; Result&lt;u32, Error&gt; { n.to_string() .chars() .map(|x| x.to_digit(10).ok_or(|| Error::Digit)) .fold(Ok(0), |a, x| a.and_then(|a| x.map(|x| a + x))) } fn digit_sum(n: u32) -&gt; Result&lt;u32, Error&gt; { let mut sum = 0; for x in n.to_string().chars() { sum += x.to_digit(10).ok_or(Error::Digit)?; } Ok(sum) }
The problem using `try!()` or `?` within a closure is that it wants to do an early return, but "return" from within that closure only returns from that closure, not from your whole function. You might be able to take the `?` out of the map (so it returns the Result) then applying some extra logic in your fold closure to map into Ok results and keep around the first Err you encounter. Something like: fn digit_sum(n: u32) -&gt; Result&lt;u32, Error&gt; { n.clone() .to_string() .chars() .map(|x| x.to_digit(10).ok_or_else(|| Error::Digit)) .fold(Ok(0), |a, b| a.and_then(|x| b.map(|y| x + y))) } (also you don't need that first `clone()` there, the number's getting copied in anyway since it's Copy)
Are Redox capabilities "fake capabilities" like POSIX capabilities, or true capabilities?
Interesting, last time I tried that I needed to be in the github rust-lang org. [frewsxcv has set up mirroring for most of the rust-lang repos now](http://gitlab.com/rust-lang)! My offer to add/transfer the gitlab org to the core team still stands, yinz know where to find me ;)
I would like to create members of a struct through a macro like so: macro_rules! FooVtbl { ($ty:ident) =&gt; { pub foo: unsafe extern "system" fn(This: *mut $ty), } } pub struct HelloVtbl { FooVtbl!(Hello); } pub struct Hello { vtbl: &amp;'static HelloVtbl, } Basically I'm trying to wrangle with some FFI that uses internal vtables. To avoid mistakes of repeating the base class vtables, I'm trying to make it a macro which I can use whenever I need its vtable as part of another vtable. Is there any way to make this work?
I've been playing around a bit with the [ioctl crate](https://docs.rs/ioctl/0.3.3/ioctl/), and found it to be working very well. If you use this crate, you could translate a typical C ioctl to Rust like this. ioctl!(read SNDRV_CTL_IOCTL_CARD_INFO with 'U', 0x01; snd_ctl_card_info); #[repr(C)] pub struct snd_ctl_card_info { pub card: c_int, pub pad: c_int, pub id: [c_uchar; 16], /* ... more fields ... */ } And call the ioctl like this: let i: snd_ctl_card_info = unsafe { mem::uninitialized() }; let r = unsafe { SNDRV_CTL_IOCTL_CARD_INFO(self.fd, &amp;mut i) }; if r &lt; 0 { return Err(io::Error::from_raw_os_error(-r as i32)) } Btw, in case you get the struct wrong, you'll get -1 back from the kernel.
Full blown L4-style capabilities.
Might be possible, though I'm skeptical. First, you have to show that the syscalls commute (which is tough given that they are commonly IO related), and that combining them will actually improve things (as you're not just running them in parallel, you're always delaying further execution until all syscalls have finished, if I understood it correctly).
Nice!
http://stackoverflow.com/a/31612025/4237232 Differing lifetimes generate differing types. Rust _does_ infer many lifetimes (ellision) but in some places type declarations are necessary
It's probably out of scope but easily consuming blocklists to not resolve malware domains would be nice for a local cache.
Do you mean by having users use a local cache? I doubt this would have helped at the anycast resolving/routing level DynEct services were affected. I believe many mainstream operating systems do actually employ local dns caching resolvers, so maybe a better lifetime invalidation technique is in order to work around multi-hour long resolver outages.
Thank you! This is the answer I needed – a straightforward answer for a newbie. Now it's clear and I see that this distinction makes sense.
Well, I suppose a user *could* swap its OS resolver for this, but I was thinking of a larger scale; like ISPs, corporate networks, ...
Why don't you create a PR to Rust's BufReader instead? I'm currently running into the same problem where seeking completely discards the internal buffer, so a large buffer is unfortunate, as most of the contents are discarded, but a small buffer causes lots of syscalls, and especially if the file you are reading from is on a network drive, your performance is really bad due to all the latency overhead. So overall, your crate is perfect for my situation, but this should really be in the standard library.
I have a construct that works now: pub struct FooVtbl&lt;S&gt; { pub foo: unsafe extern "stdcall" fn(This: *mut S), } pub struct HelloVtbl&lt;S&gt; { pub FooVtbl: FooVtbl&lt;S&gt;, pub hello: unsafe extern "stdcall" fn(This: *mut S), } inherit!(HelloVtbl: FooVtbl); pub struct Hello { vtbl: &amp;'static HelloVtbl&lt;Hello&gt;, } The entire point is to have the correct type of `this` parameter in the inherited vtbl. It's not pretty but it'll work. Also abusing `Deref` to make the vtbl less painful to use: macro_rules! inherit { ($ty:ident : $base:ident) =&gt; { impl&lt;S&gt; ::std::ops::Deref for $ty&lt;S&gt; { type Target = $base&lt;S&gt;; fn deref(&amp;self) -&gt; &amp;$base&lt;S&gt; { &amp;self.$base } } } } 
You might be able to hack some pipelining into libc since file handles are opaque, but ideally you would just design the userspace API to be more amenable to it.
Note that a Copy and a move are no different in terms of performance. (The act of borrowing/passing a pointer is usually cheaper, of course.)
Yes but the higher level function could also benefit from that simple use case. It's like having differents shortcuts.
Would such a change be backwards compatible?
A lot of job searching websites allow to set alerts that will trigger email when a matching job is posted. (eg. indeed.com)
Wow! This is a really good idea. It looks like this code is used pretty often.
This is a really good idea. Added to the TODO list :)
This is awesome! You've even abstracted the libretro interface and made it idiomatic. Very cool stuff.
thanks hahaha 
And it should also be noted that although semantically, the data is moved, in the compiled code, very often LLVM or Rust itself can optimize the actual copying away. So moves don't necessarily generate any machine code.
These multiple ip addresses there are for a reason. They should be iterated over to find a first ip address that worked. (What would be most idiomatic way to do that, BTW?). Making standard library crippled by `to_socket_addrs` returning just one address is just a bad idea. Also, a lot of APIs already accept `ToSocketAddrs`, so one can do: `let s = TcpStream::connect("www.rust-lang.org:443")?`, so it's not even a problem. 
The default implementation discards the internal buffer on purpose to keep the position of the inner reader stable: &gt; Seeking always discards the internal buffer, even if the seek position would otherwise fall within it. This guarantees that calling .unwrap() immediately after a seek yields the underlying reader at the same position. Because of this I didn't implement the get_ref() and get_mut() methods. The only way to get the inner reader is to call into_inner() which synchronizes the position and consumes the BufReader, so this would break backwards compatibility.
The position isn't really stable though, because it doesn't get updated after reads does it? I don't see how that behaviour is useful, and it's not intuitive to me. If I wanted the seek to guarantee the position then I would unwrap then seek.
The std::io::BufReader cannot update its position after a seek because it doesn't know its absolute position. I think the incentive was to create a BufReader to buffer things, but still be able to access the underlying reader if you want to bypass it. But you can't have this flexibility and maximum seek performance, there already exists a [Github issue](https://github.com/rust-lang/rust/issues/31100) to solve this. The seek_bufread::BufReader implementation synchronizes the position if you access it via [into_inner()](https://github.com/gcarq/seek_bufread/blob/master/src/lib.rs#L134), until this point only the BufReader instance knows your correct position within the stream.
What kind of votes?
I'm still new to Rust, but the code looks pretty clean.
I personally feel `^` is better than `~` in pretty much every way, but really, I just wanted to hear your opinion. `~` isn't bad!
Thanks for explaining this to me. I'm probably biased and need to unlearn other languages first. It totally makes sense for the IPv4 / IPv6. You know what, it's easier to accept the cost of having to write something like this when we know the purpose.
&gt; `t.x` is an `i32`, which is a `Copy` type Why you said `i32` is a `Copy` type? and *how* did you know it? I've filed an issue proposing implements `Copy` for `i32` *explicitly*, several days ago: https://github.com/rust-lang/rust/issues/37295 
I agree that it would be nice to have the standard library be more explicit in its implementation, but the documentation does already mention this: https://doc.rust-lang.org/stable/book/ownership.html#copy-types
Hey, I have ~perfect vision and I also can't resolve blue lights from for away. It's real!
Congratulations!
I started writing a NES emulator to learn rust. I always enjoy seeing the different approaches and abstractions people come up with when writing their own. I remember the "aha!" moment I had when reading the sprocketnes source and finally understanding the addressing mode abstraction. Looking forward to digging into this and seeing what you came up with. 
As has been stated elsewhere, the correct solution would be to `.iter().find(..)` the first 'working' URL. What constitutes *working* is a matter of your URL usage, but the high level function can afford the additional complexity, because it likely would see much reuse (so the cost is amortized).
I think you're looking at this all wrong since this is a personal project, so the likely intent is for him to have the tool he's building as it doesn't exist. Additionally it's likely he's using it as a reason to learn Rust as well. Just because a similar tool already exists doesn't mean that a new tool shouldn't be built.
True, but this is still better than having a wrong checksum being accepted as being correct.
The third paragraph of my link starts with this line: &gt; All primitive types implement the Copy trait
Be aware that Julia still has so stable release, and makes no guarantees for compatibility between versions. I would not use it for anything "real" at this point.
No one propose changing what to_socket_addrs does. Op just want a new to_socket_addr which only parse a single ip?
&gt; It's not really a project that plays to Rust's strengths --- you would have a much easier and better time writing something like this in Ruby or Python instead. Once upon a time I started writing something like this in Ruby. And lert me tell you: you don't wanna do that! Rust gives you so many great things, it is perfectly fine for a tool like imag. &gt; Also, a tool like this can never hope to compete with something like org-mode anyway... imag is rather orthogonal to orgmode, actually. orgmode handles all the things for you, imag does not. imag gives you the ability to connect other tools, like taskwarrior and khal, khard and buku, etc etc (only that we are not there yet).
Great to see you progressing! I hope you have the stamina to keep going, wish you the best.
Thank you. Yes, this is for learning rust but also for solving my own problems. I'm a vim user and while I see orgmode and all the emacs stuff it is just not my universe (not wanting to start a holy war here). I prefer one tool for one job. imag is a way to combine these tools and do some data mining, possibly automatization, etc... 
I think there is a misunderstanding. The checksum is the checksum of the data, not of the pointer.
Cool project. More evidence that targeting embedded with Rust is a good idea and the code is approximately as readable and compact as I would expect equivalent C to be. I love coding C and assembly but I think my next embedded hobby project will be in Rust. My reason: a little more safety may lead to a few less bugs and that's extra important on embedded where debugging and patching are more painful!
&gt; One day, I would really love to read a post explaining how and why TFS differs from ZFS and Btrfs. I'd like to actually understand why ZFS uses so much RAM and alternative approaches, for example. I'm working on such a post :)
You're right. I was not aware of this exception. My apologies!
Nice work, OP. I hope anyone else considering a Rust-based emulator studies/borrows/steals your work in `libretro-backend` and `pinky-libretro`. Complying with the MIT/Apache License, of course! ;-) Thank you!!
[removed]
I'm glad you like it! I'll upload my libretro bindings to crates.io later today; I didn't do that originally since it's still missing some important features, but I guess it might still be useful even in its current state.
I was mildly concerned before doing it, but I’ve taken my prototype on several flights without any issue.
For me really it was all about having (as I’ve gotten used to) a strong type system with traits and sum types available. This made the calendar / time zones library much more pleasant to write than in C or C++, at least to me.
If you don’t wear glasses or other correction, maybe have a test. It took me a long time to admit to myself that I could use them.
...hopefully you won't have too many "wtf!" moments when reading my code. (: If you'll have any questions as to what I did (or did not) feel free to ask!
Me too, we should start a club! 
Rule #2 &gt; Constructive comments only.
It was the initial plan to have a new trait to support a single socket address. But since I know that is for IPv4 and IPv6 separation, it probably makes sense in some cases to have an iter for that.
Rust will catch the race condition on client_sock, yay!
Excellent work! I'm very interested in the bindings, and will definitely take a look and possibly use them in my emulator. I've been putting off libretro-related integration work because I didn't want to implement the bindings myself from scratch.
I once spent several days debugging overflow in embedded code. The error showed up in completely unrelated part of code (the overflow was in global static array and it overwritten other global variable) and was nightmare to find. The most ironic thing was that the buffer was actually ring buffer with error logs. (So debugging code caused bug.) This sort of thing wouldn't happen in Rust.
I think this it ships gcc and GNU ld only on Windows, there's no `.../bin` directory here on Linux, only `.../lib` (as of rustup.rs 0.6.3)
I've been wearing glasses for 8 years for the same issue, but I didn't think the blue/red light thing was common.
I think embedded needs it more than anything else. You have no options in that space currently. It's all C or some derivative. 
It makes the grammar unambiguous, IIRC.
I'm having trouble with lifetimes. My code is like this: pub struct Fieldset { pub q_variants: Vec&lt;(PathBuf, mime::Mime)&gt;, pub answer_audio: Option&lt;(PathBuf, mime::Mime)&gt;, pub answer_text: String, } for fieldset in &amp;data.3 { let a_audio = &amp;fieldset.answer_audio; let a_audio_default = a_audio.map( |path_mime| (path_mime.0.to_str().expect("this is an ascii path!"), Some(path_mime.1)) ).unwrap_or(("", None)); } let new_answer = NewAnswer { question_id: quiz.id, answer_text: &amp;fieldset.answer_text, answer_audio: a_audio_default.0 }; diesel::insert(&amp;new_answer) // and so on I'll need NewAnswer only for storing to database, so I'm not going to return it. From my understanding of stack, this should be an entirely safe operation to do: I'm trying to get `answer_audio` to be a a str slice to the `fieldset` struct, to which we have a reference that that lives at least the whole single loop iteration. However, the intermediate value (the slice) doesn't seem to survive beyond the closure that's being `map`ped. How do I solve this? The error message is like this: error[E0507]: cannot move out of borrowed content --&gt; src/lib.rs:335:31 | 335 | let a_audio_default = a_audio.map(|path_mime| (path_mime.0.to_str().expect("should be an ascii path!"), Some(path_mime.1))) | ^^^^^^^ cannot move out of borrowed content error: `path_mime.0` does not live long enough --&gt; src/lib.rs:335:56 | 335 | let a_audio_default = a_audio.map(|path_mime| (path_mime.0.to_str().expect("should be an ascii path!"), Some(path_mime.1))) | ^^^^^^^^^^^ - borrowed value only lives until here | | | does not live long enough ... 348 | } | - borrowed value needs to live until here
&gt; That's what he was pretty much saying. Red + green = yellow I think 500-560nm is pretty much just green: http://media.web.britannica.com/eb-media/02/96902-004-856CCB82.jpg
Disclaimer: I have no clue what I'm talking about I don't think the response strength really plays that big of a role for acuity as long as the receptors are sufficiently stimulated which I believe to be the case here. Instead I think the issue is more related to the distribution and density of different types of receptors. I found couple of pictures of receptor distribution in retina ([1](https://www.cis.rit.edu/people/faculty/montag/vandplite/images/chapter_9/mosaic.gif) and [2](http://i.stack.imgur.com/wIbcE.jpg)) which illustrate that we have significantly less receptors sensitive to blue especially in the critical central area.
Some time ago I collected these ideas: https://scribbles.pascalhertleif.de/things-to-rewrite-in-rust.html
That is interesting. I had expected the blue light to give the best resolution. https://en.wikipedia.org/wiki/Angular_resolution
It was actually this that made up my mind that porting or re implementing a linked list would probably not be a good idea....
ding ding ding (etc) I think we have a winner, no to find a binding for SDL....
Such an API should not exist ever. 99.9% of the time you must handle multiple addresses. If you're not will get a buggy, unreliable software. Such detail are exactly why I love Rust. Not because of the traits, generics, speed, etc.. It's because of well crafted APIs that guide developer's hand. Not everyone has to be network engineer, experienced in the matter and know why. Yet Rust will force you to the right thing - the wrong approach is inconvenient or even impossible. `ToSocketAddrs` is solving the problem for most APIs: you can pass it directly to code that can iterate over addresses, or iterate manually (since it implements `IntoIter`. I contrast it with languages like Python that prioritize readability, terseness, convenience and having a nice time, over reliability. Part of the reason why there's so much buggy Python code: it's very fast and easy to write buggy Python code. :)
This is the second part of our Doge API series. I published [the first part](https://www.reddit.com/r/rust/comments/55nt4f/how_to_implement_a_new_dom_api_for_servo/) few weeks ago. We hope this is helpful for the new Servo contributors! :D
Only if while the chainsaw is being used as a melee weapon it has a chance to dismember it's user.
Write a simple compiler/interpreter. If you want extra challenge/fun, write a simplified compiler for a subset of Rust. That will definitely teach you some Rust:)
Hey why return `f64:NAN` over `Option&lt;f64&gt;`?
I haven't gone through it yet, but this [tutorial](http://ticki.github.io/blog/making-terminal-applications-in-rust-with-termion/) on writing terminal apps in rust with termion looks fun. 
I came here to say this. Try to write an optimizing compiler (or interpreter) for brainfuck for example: the challenges will come naturally. And it's so fun! I think I'll never grow tired of this.
Is there any possible way to create an impl for `FromIterator` where the iterator must be clonable? I'm working with an FFI collection type which requires that I know the exact allocation amount ahead of time but by default you cannot clone the iterator: impl FromIterator&lt;i32&gt; for FFICollection { fn from_iter&lt;I: IntoIterator&lt;Item = i32&gt;&gt;(iter: I) -&gt; FFICollection where I::IntoIter: Clone { let iter = iter.into_iter(); // Have to know the length beforehand... let count = iter.clone().count(); let collection = FFICollection::new(count); // Before I can iterate over it for (i, el) in iter.enumerate() { collection.store(i, el); } collection } } Any attempt to sneak in a `Clone` requirement makes the rustc yell at me that this requirement was on the impl but not the corresponding trait method.
Try building an MVC framework in Rust. That's what I am working on. https://github.com/zpallin/iron_with_db
There's a number of reasons: 1. It keeps the API ergonomic. For most use cases that I see, the desired behavior would be to propagate the `NaN` until someone wishes to deal with it. It behaves similarly to `Option&lt;f64&gt;` without forcing any method wishing to propagate to have a `Option&lt;f64&gt;` in their signature 2. The more important reason is that `f64::NAN` is actually a valid result in numerical computing. What is the result of `∞ / -∞`? It's technically `NaN`, not `None`. In that sense, `f64::NAN` is a more correct answer than returning `None` Of course, I am always open to suggestions from the community. Otherwise I wouldn't be sharing it with you guys haha
Why not `method&lt;GenericType&gt;()` ala C#? I guess I'm curious about the underlying construct. Is it _really_ another module?
Pet peeve: using the term "zero-knowledge" incorrectly. I'm astonished that this uses rust-crypto, in allegedly a production-bound product. Are they going to pay for the audit?
Been intently following this. Dont think it is up to date with mainline, is it?
To clarify, this is a 56kb Windows executable that generates a full audiovisual presentation, realtime, with zero external media files. Written in Rust (minus the synth; the first of its kind to be done so in Rust afaik), produced with custom tooling (the visual tool is also Rust) over the course of about 2 weeks. Enjoy! :)
That's a bit more horrifying than it is funny...
Oh most definitely: prototyping makes sense in python. However, the inner me missing types, compiled time languages and the ability to have conditionals in graphs (yes you can with tf.cond, but it slows things down quite a bit). It would be nice to have the library be on par with the C++ impl though. 
The build of rustup that comes with clap-based generation of zsh, bash, and fish completions should be released any hour now. Thanks for the continual improvements, /u/Kbknapp.
Very interesting. Some blog post about creating it would be great too! What techniques were used to trim the file size? 
nicely said, my brain will happily accept that and be quiet now. :)
Totally agree and I was super enthusiastically following autumnai who built a DL lib from scratch in rust. Unfortunately they announced a month or two before TF and we're completely overshadowed. They shut down shortly thereafter :(
Isn't that Homomorphic encryption? Zero-knowledge [Poof], proving I have knowledge without giving you any of it is like the exact opposite.
I'll be doing a more or less extensive writeup tomorrow :) As for getting it down, the main bits were no_std, building with the i686 MSVC ABI and static-linking against the old VC6 runtime (which is system-standard since XP), and using an executable compressor which is quite good for this purpose (specifically kkrunchy: http://www.farbrausch.de/~fg/kkrunchy/). The tough part then becomes how we design our content creation tools to produce good content and basically not do a lot. :)
So normal encryption on some columns that you do need to do order or range search on?
How I'd imagine it, the standard library would add system calls to a buffer as their functions are called. When the program uses the values gotten from them, it would flush the system calls that were buffered. This would be able to group the open and read system calls, but I can't think of how to make it recognize that the heap allocated in the blog post example wasn't used until the read.
Two utilities are included: * `record` starts a recording session and logs all input to a file. * `replay` reads such a file and replays the input accordingly. Most of the work was already by the very cool pty-rs library, this only serializes the input and loads it for the replay. Unlike `script`, only the input is recorded here, along with the timings. The log file is also in a more readable format, helpful for debugging for instance. The main use-case I had in mind was reproducing bugs in some interactive applications: send the file, and anyone can replay exactly what happened. I'm sure people will find much smarter uses, like documentation or automation.
I really wish there was a standard json format for command line args(possibly print it to step it if env variable is set) so we wouldn't need such scripts and shells could fetch the information on the fly with scripts.
http://reddit.com/r/playrust
Very cool. The link for "the last issue" is broken: http://localhost:4000/2016/10/04/this-weeks-in-ruru-2/ instead of http://this-week-in-ruru.org/2016/10/04/this-weeks-in-ruru-2/
Congrats Jake :D
Certainly! There are some people discussing how to continue forward with Leaf in this issue: https://github.com/autumnai/leaf/issues/108
Hmm, recording and replaying *input*. So this is different from ttyrec/termrec which record TTY *output*. I was going to ask that you use their file format so you could play back recordings with things like [tty-player](http://tty-player.chrismorgan.info/), but that requires recording of output as well. Do you have any interest in supporting such a mode of operation? The way in which ttyrec et al. don’t record actual input has disappointed me. I’d really like the ability to use a hybrid as a part of documentation: the output recording being used in the documentation (via tty-player or similar), with the input recording being able to be rerun to update the output and warn concerning any diffs (normally ignoring timestamps). This would help with keeping things reproducible, updating documentation against things like rustc’s error format changes, &amp;c. Now all I want is something like this for Windows. Unsurprisingly, `cargo install record` fails in the crates `pty` and `termios`.
This is incredible. I don't think many scene-ers do anything in a language other than C or C++ when targeting these file size limits? Quite a breakthrough, to be honest. I've been wondering if it's even possible to do this kind of demo within those constraints in Rust.
Thanks, but an intermediate allocation makes me meh. Then again really it's a trade-off between running the iterator twice and an allocation. One is twice the cost of running the iterator vs amortized constant cost for the allocation. I've come to realize that maybe trying to box `FromIterator` in a spot it wasn't designed to, I can trivially create my own `IntoFFICollection` and then blanket impl it for all `T: IntoIterator&lt;Item = i32&gt; where T::IntoIter: Clone`. Using a prelude to automatically import the trait. Also why not a `ToFFICollection` that does the same but takes `&amp;self` since the `FFICollection` cannot reuse any allocation due to its design. Blanket impl'd for all `AsRef&lt;[i32]&gt;` and in the prelude. Now I've got all the convenience I desire and more. For good measure I also implemented your `FromIterator` using an intermediate `Vec` as you described. Perhaps a bit overkill but oh well...
Found this article: https://yawar.blogspot.cz/2016/10/the-birkana-hexadecimal-number-symbols.html Had to, just had to. :)
Ah yea, you would need a proper C FFI for this. Any idea when the backporting will start taking place? Let us know any outstanding items for the rust wrapper (maybe GitHub tickets?) . Would love to contribute. 
The Rust standard library does not have an equivalent of the aforementioned multi-threaded copy-on-write type ([`std::borrow::Cow`](https://doc.rust-lang.org/std/borrow/enum.Cow.html) is for the single thread only and checked by the compiler for the usage). The closest equivalent would be a library backed by [`std::sync::RwLock`](https://doc.rust-lang.org/std/sync/struct.RwLock.html) and [`std::sync::Arc`](https://doc.rust-lang.org/std/sync/struct.Arc.html), which fundamentally prevents this sort of bugs if themselves are correctly implemented. I do hope to see the individual audits for those primitive types.
And they said that Rust binaries are large... Congrats and keep up great work!
What happens if you do `type Generator = noise::Brownian2&lt;f64, fn(&amp;noise::PermutationTable, &amp;[f64; 2]) -&gt; f64 {noise::perlin2::&lt;f64&gt;}&gt;`?
Functionally yes, but would need some wrapper for an interface par with the single thread equivalent.
&gt; so I'm basically already vulnerable to a panoply of issues that will just never get fixed. Yeh, I've given up having root and a full Linux chroot on my phone and am now running copperheados, at least I can mostly trust my phone again.
\o/
Compile error. After -&gt; f64.
The `Arc` assumes that the data is heap-allocated, which I think is unlikely in a kernel. Additionally, `RwLock` itself contains a `Box&lt;sys::RWLock&gt;`, and neither `Box` nor `sys::RWLock` are guaranteed to exist inside a kernel. I suppose what I'm wondering is this; does the Dirty Cow vulnerability stem from an unsound implementation of the RW-lock or Cow primitives themselves? In that case, Rust wouldn't have helped. You can do unsound implementations in any language. But if, on the other hand, Dirty Cow stems from unsound *usage* of the existing sound primitives (which the C compiler couldn't see because of its weak type system), then Rustc probably would have caught it. Or if Dirty Cow stems from *not using* the existing primitives at all, but rather rolling your own half-baked implementation for performance/ergonomic reasons (for example due to the inability to compose a RW-lock and a Cow together cleanly, as in `RwLock&lt;Cow&lt;T&gt;&gt;`); then I'd venture that Rust also would have helped. I don't know though, and so far I haven't seen any good technical descriptions of Dirty Cow that don't require intimate knowledge of the Linux kernel.
Follow-up post here: https://www.reddit.com/r/rust/comments/59adt0/planetkit_week_2_a_first_attempt_at_making/ I made good on my promise of terrain, but failed to deliver hexagonal prism voxels. Maybe the bonus ocean will at least partly make up for that. :)
&gt; I think the best place to look would be in Redox to see how it does it. lets summon /u/jackpot51 &amp; /u/ticki_ ..
Yay, demoscene! I'm wondering, was it a really different experience working on this intro as opposed to doing it the traditional C++ way? It seems like on the one hand it would be more enjoyable writing an intro in Rust since you can still do lots of fiddly algorithmic size optimizations with less risk of introducing random memory corruptions. On the other hand, actually tuning the executable size may be more difficult.
For me it works fine in 1920x1080 but not in 3840x2160 where it only renders part of the scene.
Thanks. It worked. extern crate noise; extern crate rand; use noise::*; type Generator = noise::Brownian2&lt;f64, fn(&amp;noise::PermutationTable, &amp;[f64; 2]) -&gt; f64&gt;; fn t(){ let mut a: Vec&lt;Generator&gt; = Vec::new(); a.push( Brownian2::new( perlin2::&lt;f64&gt; as fn(&amp;noise::PermutationTable, &amp;[f64; 2]) -&gt; f64, 4).wavelength(32.0) ); } 
It should be pointed out that the [patch](https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=19be0eaffa3ac7d8eb6784ad9bdbc7d67ed8e619) is a change to the logic that sets flags on memory maps. Not the code modifying the maps. This bug is more akin to Apple's GOTO FAIL. A fault of programmer logic, not a failing of memory/pointer management. Rust doesn't have any defense mechanism against bad programmer logic.
This definitely seems like a good idea. I am wondering, though, why it uses its own folder rather than implementing the xdg-trash spec...but I'm not really familiar with the specifics of that spec, so I'm assuming there's a good reason. My biggest complaint is that (as far as I can tell) this will only work with filenames that are valid UTF-8. Considering `/` and `NULL` are the *only* invalid characters in a filename (on *nix, at least), I don't think this is a safe assumption. To change this, you'd want to use `value[s]_of_os` rather than `value[s]_of` from clap, and use `&amp;OsStr`s instead of `&amp;str`s. I'll admit that Rust's insistence on UTF-8 really does make handling arguments a pain at times, but I personally think it's best to do things "right."
&gt; Second, my device is older than six months, so I'm basically already vulnerable to a panoply of issues that will just never get fixed. This is why I stick with iOS, even if I dislike Apple's walled-garden.
Seems to be a solid garbage/trash/recycle tool. I wouldn't *advertise* it as an rm replacement or improvement tool. Having rm *shadow* mv has been considered an anti-pattern going back well into the 80's. Also breaking -r means a lot of system scripts will break. 
Damn, I saw that same article and was considering on making something like this as a rust learning project.
Similar bugs could occur. One major issue with SMP is TLB coherency. Two processors use the same page table and one of them frees a page. If the kernel does not send an IPI to the other processor to tell it to clear its TLB, it could access pages for other processes using the invalid TLB mapping. There are many similar hardware issues that could never be caught with Rust, and must be addressed by intelligent design. Dirtycow could not happen if the kernel uses Mutex or RwLock on absolutely all shared structures. The mistake dirtycow made was a missing lock, which could still happen in Rust. Take the ActivePageTable abstraction from Phil Opp - it allows, in safe code, any page table operation to be done from one processor and does not require locking or flushing or any IPI. While this is fine on a single processor system, without interrupts enabled - such a structure will inevitably lead to mistakes on an SMP system. Our previous kernel was rife with memory management bugs, leading to a need to rewrite the entire thing! **In Conclusion: Rust will not save you from all bugs - you need to be very cognizant of the state of the hardware when you are writing kernel code**
Thanks, this is really useful feedback. OsStr is definitely the right way to do things; not sure why I didn't look at it more other than wrangling between a bunch of types is a little hard when learning Rust. A few reasons as far as the spec goes, all opinions: I think defaults should cater to people who don't want to do any configuration, and /tmp is automatically cleaned up on (almost?) every system, saving some hassle in exchange for control. You can, of course, point the graveyard somewhere else. Other reasons include readability: I think having the trash mirror the filesystem itself is easier to parse than a bunch of files in one directory and another bunch of files in another directory. Also, compatibility with freedesktop isn't relevant to a lot of Unix (including Linux) systems, and I'm not sure that integrating with a graphical file manager is even desirable. The files I'm touching in Dolphin are very different from ones in a terminal. For two-way compatibility, I believe the undo feature would also need to read the entire trashinfo directory to find the last deleted one.
A multi-threaded `Cow` type wouldn't help here, this is an implementation of COW for pages managed by the memory manager; that's a pretty fundamental part of the kernel, not anything that you'd implement in a standard library. As /u/glaebhoerl points out, there is a possibility that you could use the type system to model a state machine and have the type system catch errors. I don't know enough about this particular domain to tell if that is realistic in this case or not. Honestly, for dealing with this sort of issue, I think that an seL4-style formally verified capability based microkernel is more likely to be fruitful for preventing this kind of issue than using Rust. But even formal verification has its limits; you have to ensure that the model you are verifying actually covers the kinds of behaviors that could cause vulnerabilities, so even formal verification is not a panacea.
https://hbr.org/video/5155033576001/why-better-technology-can-be-slower-to-take-off
`clap` has been a pleasure to use in my project. Thanks a bunch!
&gt; /tmp is automatically cleaned up on (almost?) every system Dangerous assumption. Many systems don't actually cleanup all files in /tmp (only during boot), because many files will live for a very long time, will not get touched but are still referenced and might get used in the future. &gt; Also, compatibility with freedesktop isn't relevant to a lot of Unix (including Linux) systems Freedesktop is effectively a sort of standards body. And like all standards one chooses to follow a standard or not. But following a standard is often preferable for Joe Average user, because distributions often have the more popular standards in mind when building how everything ties together. Especially the XDG related ones. And those get cleaned when somebody clears their trash as a bonus. But there are possibly better reasons to not move files to /tmp but inside their homedirs (for normal users at least): * File moves within the same filesystem are cheap. There is a big chance that /home is a different filesystem from / or /tmp. In that case the move is a copy+delete and you get all the corner cases of the other filesystems being full. * Home directories are often encrypted, some on the filesystem level and some on the storage level. Moving files to another part of the basic file hierarchy might possibly expose data that was meant to be kept confidential.
You can have a look at my code :)) it uses gtk instead! https://github.com/dhad05/GoL
Could you explain why rm shadowing mv is an anti-pattern? I can't see why it isn't just cautious. 
This is my second rust project. I saw someone else did the same thing (tokei) when I was about 80% done with this but I thought I'd finish it anyway. There's a lot of duplication in the counting code, but any feedback would be appreciated. 
Congrats! A question - most of the graphics are actually done within a pixel shader, right? Like the demos on Shadertoy. Do you generate this shader using Rust code? I'd love to read the source, but I suppose it's not open.
well, /u/BurntSushi released ripgrep a month or two ago...https://github.com/BurntSushi/ripgrep . (I'm noticing a pattern to these new tool names...). There is also the `parallel` implementation: https://github.com/mmstick/parallel Not to mention, the `coreutils` rewrite happening: https://github.com/uutils/coreutils
How about `-z` for `--zombify`. :)
No, this is polygon-based. The materials are pixel-shader based though, and we do deferred lighting, and there's a lot of post passes/shaders. But it's not "all one shader" like in Shadertoy; as convenient as that is, it's abysmal performance-wise (at least on my high-end laptops).
Interesting, like does it draw the bottom-left of the screen? Which GPU are you using? I has relatively heavy GPU mem requirements for all the post buffers/passes, but beyond that I'm not sure why it would fail in higher-res.
Haha, ikr? thanks! :D
Hey thanks! I had talked a bit about it on twitter at least; I don't really know of many sceners actually _using_ rust besides me except emoon/tbl, but the general consensus was that there was no reason it shouldn't be possible, just that nobody had done it. Frankly I just like using Rust more than C/C++ these days, so I wanted to give it a shot. Turns out it works just fine; it's easily as up-to-the-task as C++. The only thing that was worse with it was that compile/link settings weren't as transparent through Cargo when you have to dig deep as they were with VC++, and I had to do a lot of bindings by hand to make sure we only got what we needed and nothing included the standard lib under our noses. But for writing the actual code that does the actual stuff, it was lovely :)
Just built and compare tokei, cloc and loc and an internal repo that contains mostly TCL. loc is amazingly fast. I was already impressed by tokei's improvements, but loc takes it another level :) However, it seems to count slightly less lines than cloc and tokei. Here are the results for TCL: -------------------------------------------------------------------------------------- software files blank comment code total time -------------------------------------------------------------------------------------- cloc 11221 1835164 1078305 11459473 14372942 ~2m57s tokei 11296 1837099 1080238 11463368 14380705 ~13s loc 11296 1801423 1057508 11323881 14182812 ~0.8s edit: btw [here is the pr](https://github.com/cgag/loc/pull/3) for tcl ;) *update*: updated tokei time from 22s to 13s and cloc time from 3m39s to 2m57s. As explained in a comment below, results are not comparable if not run on a hot cache.
I have been doing writeups every week though while developing the tech on my [everyweeks site](http://everyweeks.com/). The intro was done in the last two weeks so not much there yet about that specifically, but I'll be writing a longer entry there in the next couple days for this week, when I'm done sleeping the party off. :)
I think there's an alias method on Arg you can use.
&gt; Proven correct algorithms can still fail. This is a failure of applying formal methods. They verified a *model* of an algorithm, but not an *implementation*, and there is **no** connection from the model to the implementation. This is what I've heard unenthusiastically described as "80s verification", and it's a huge problem repeated frequently (latest in Rust, by ticki's Hoare logic for MIR. not to disparage that work, it's important and hard and I'm happy to see it, but it's only the first step!)
My pleasure!
(not-a-dev here) Is cloc considered reliably verifiable? That is, its results are always right? If not is there some way to do so for these implementations and see what is most accurate? 
Also not exactly what you're asking for, but `clap` [supports using YAML](https://docs.rs/clap/2.16.1/struct.App.html#method.from_yaml). So it's theoretically possible for other arg parsers to *also* support YAML. Then there would just have to be some sort of consensus for the format. But it's a step.
Sorry I meant what the other reply was talking about that unix shells would be able to query binaries for cmdline arguments with an agreed upon api ala Powershell cmdlets. Not some sort of common cmdline format handling for argument parsers.
cloc has a command line option that strips out the comments from the files that it processes. If you do that, then compile the file again after stripping the comments and the result is the same, it gives you an automated way of checking if detecting the comments in the source code works (which is the hardest part).
It's hard to tell what is a right count in the first place. See for example [this comment](https://www.reddit.com/r/rust/comments/4bz04p/tokei_15_now_with_shebang_support/d1dt3gn/?st=iupqxy9p&amp;sh=43c356ee) from /u/theaaronpower, the author of tokei: // Counted as comment x = y; // Counted as Code. /* Counted as comment * comment * comment */ x = y * 2; /* Counted as code * counted as comment */ 1+2; // code Take this line: x = y; // Counted as Code. It's wrong to count it as a line of code because you ignore the comment. But it's wrong to count it as a line of code + a line of comment, because, well, there is only one line. I think in this example, tokei choices make sense, but I can't tell if it's "right".
Yes, I read it. Though my little example doesn't handle restoration (easy enough to do) or command line options (also easy enough to do), the shell version of this would be much, much smaller than what you've proposed. I'm not criticizing your work - it was probably a good learning experience. I am only pointing out that there are many tools in the toolbox and shell is often the least complex way to get things done. 
&gt; Rust doesn't have any defense mechanism against bad programmer logic. Well... it actually has some. Specifically, I'm with [glaebhoerl](https://www.reddit.com/r/rust/comments/599xo4/the_dirty_cow_vulnerability_could_it_would_it/d96yie8/) on the fact that leveraging the type system may have been able to prevent this bug. Rust can encode state-machines at the type level, preventing incorrect transitions and access to "past" states at compile-time (with zero run-time overhead). Of course, if you do not specify the state-machine correctly, it's buggy... so this is not foolproof.
Hmm, counting tcl style comments is the easiest type, so I'm surprised there's such a discrepancy. I'll have to look into that later. Thanks a bunch for the PR :). Are those all run on a warm cache? I haven't seen that much difference with tokei even on much larger amounts of code. 
&gt; It's wrong to count it as a line of code because you ignore the comment. I don't think it's wrong to count it as a line of code, it's what it is. It is *also* a line of comment, but you definitely can't count it as both (of as half lines), and comments would be less interesting. An alternative way to handle it would be an additional classifier for *comments on code lines*, but considering the way I use cloc/tokei/… is generally to count LOC I'd much rather count that as a line of code.
I tried to do character by character initially but found it be pretty hard to do. As for mmap, I found it significantly faster than using BufReader, and I don't know why. burntsushi found using an input buffer to be much faster than mmap (in a threaded context) in ripgrep, but it looks like he hand-rolled something. I hope to try something based on his work in the future).
What about making the location configurable? I personally like `/tmp/`, but if you have a configuration means figured out (since you're not targetting windows, `$XDG_CONFIG/rip` works), then you can make it a config parameter. Satisfy both parties.
There is such a state machine already, actually; check out the crate session_types, which enforces safe interthread communication via a state machine which is checked at compile time.
I asked him on Twitter he said "exactly".
What's the behavior if you undo a remove, but a new file was dropped there? For example, I'm running a daemon that logs to /mnt/mylog.log, and I rip it. The daemon is still running and starts a new file there. What happens if I undo? Personally I'd like it to error out in that case unless you give it -f for force, and maybe in force's case, create a new unique name in your graveyard for the file it's restoring over so it's not lost yet. Also, when it's verbose and printing the name of what it moved to where, I'd actually just like something that prints the end result file (just each new path delimited by newlines). If I remove it, I'd want the path to the graveyard file (one line per file) and if I restore it, I'd want the path that it was just restored to. This way it'd be easier to use the output in scripts because I'm most likely interested in the new file path. But yeah, I also don't like -r for anything but recursive, especially if this is meant as a rm replacement. I'd want to be able to alias rm to this and have the same interface but with an added undo option. This would confuse the shit out of me if I had to start using another program to rm where -r actually undos something. Also, what's the behavior if you try to rip your root dir? Or something like /proc? Or a parent directory that your graveyard is contained within? &gt;None that I can think of. I like -r because it's a little easier to type, but -u definitely wins on clarity. I'd like to accept both if I can figure out how to do that with clap. I honestly would very much rather it not use -r for that at all, not even as a duplicate option. First of all, no need to duplicate something like that. It only makes it less intuitive for people to adopt because you'll be struggling to figure out why a script uses a flag you're not used to and you see it works, and because it's just more to maintain. Also, -r is just used already for recursive and people will want to alias rm to this. If they're trying to delete a directory and end up accidentally restoring something (I guarantee people will alias it and mess up with this), it can be frustrating and really hurts usability. But seriously, if one way works, let it work that one way. Sometimes having two convenient ways to do the same things is way less convenient and way less intuitive. Have one good way to do it that always works and is obvious. I'd highly recommend making a debian package out of it and trying to push this upstream to debian and ubuntu repos if you want people to adopt it. Only once the CLI is 100% stable however. You'd never want to push it with the -r option and then later push a version with -u... That'd be painful. Either way, I'm sure people would love it. Also, my feature request would be to have some shred option that lets you overwrite it once from /dev/urandom, something that shreds everything in the graveyard. Not necessary, but if I want a full featured rm alternative I'd like optional shred capabilities for the graveyard. Overall though, thanks for making this! 
There are a couple of languages that can statically verify algorithms by embedding proves into the type system, like cog. They have to drop infinite loops and with them turing completeness, though, so they can't be used as general purpose languages. Overall you have to hit a balance between power and formal verification and for things like primitives you might want the power to do unsafe and hard to verify things for the sake of performance. In that case you really want to contain and test this section hard which rust's philosophy captures quite well.
I'd be interested to see what a full bash implementation of this is like, because I don't necessarily think you're wrong but I'm not *entirely* convinced you're right either. 
&gt; But don't hold your breath :) Too late, now you have to do it quickly before I die. 
To think that it takes a multiple of 56kB for YouTube per second...
Optionally compress the deleted files to save space? i.e write to a .graveyard.tar.xz file instead of a folder?
On today's episode of "Why the fuck does Windows do that?":
Disclaimer: I don't have much experience with Rust. I noticed on line 15 of `lib.rs` that you have this comment: // Why is it called partialEq? When I read up on the documentation for `partialEq` and `Eq`, I found just one difference. While both are transitive (a == b and b == c -&gt; a == c) and symmetric (a == b -&gt; b == a), `partialEq` does not guarantee the reflexive property (a == a). The specific reason in the documentation for leaving out the reflexive property is that for floating point numbers, `NaN` is defined by the IEEE standard to be `!= NaN`. However, in the struct that your comment references, I don't see any reason not to use `Eq`.
&gt; Dangerous assumption. Many systems don't actually cleanup all files in /tmp (only during boot), because many files will live for a very long time, will not get touched but are still referenced and might get used in the future. Ouch! Can you show me an example? Because by the spec it says that the data in /tmp should not be relied on! http://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/tmp.html &gt; For this reason people and programs must not assume that any files or directories in /tmp are preserved between invocations of the program. The reasoning behind this is for compliance with IEEE standard P1003.2 (POSIX, part 2). 
Maybe they tried to implement automatic cleaning at one point, but there was some enterprise that had software assuming it will only be cleaned up at controllable points in time, so we're stuck with this :p seems likely
Hi Jake 😊 I have to say I'm extremely impressed by this production, it takes a lot of commitment and follow-through spirit to pull off something like this, especially on the side of a full time job. I'm curious though, do you know roughly how much time it took you to finish this? When I'm working on personal projects I see a pattern where I tend to start obsessing about details that are unimportant. Do you have any techniques to avoid falling into those kind of traps, or is that just not a problem?
Cool, blake2 in hashmaps.
&gt; I'm astonished that this uses rust-crypto, in allegedly a production-bound product. Are they going to pay for the audit? [They seem to have bigger problems than that.](https://www.reddit.com/r/rust/comments/596r25/zeroknowledge_encryption_for_mysql_implemented_in/d978rul/)
I can't answer, I'm dead. 
Hey man! The visual tool I've been working on since march, more seriously since July after solskogen where our demo wasn't what I wanted it to be. The intro itself was 2 weeks on my end; that overlapped with a week of wobble's time and about the same for h0ffman although his timeline looked much different than ours as we wanted to have the music more or less done before starting visuals. Also I wrote the synth in 2012/2013 mostly so that was already done. Having done a lot of demoscene projects I think the most important thing there is deadlines. I almost always have a release party in mind, which is easy to select as I go to 2-3 a year. Especially in this scenario there was a lot of conscious thought going into time management generally, but at the same time two weeks (really more like the last week as the first one was still spent more on the tool than the intro, but as you know I took work off that week) was enough time that we didn't have to be very strict. It was actually a new experience to have short enough time that we had to be diligent but long enough time that I never felt rushed, and we got to play with a lot of ideas. There were a couple scenes that didn't make it in, for example. Anyways, the deadline thing means you have to prioritize and you have to do little bits here and there all the time. I don't really know any other tips, but the demoscene is really unique in that regard, and I've found it to be helpful for actually finishing stuff (mind you I've put out MANY prods that I'm not at all happy with. But they're done and I put them out!) I'd be happy to share more next week when I'm back in the office :)
No, it is my name utf-8 encoded that is represented there.
I'm not sure if OP is the author of the article, but `Segment` seems to be crying out for an `enum` to me. struct Segment { is_degenerate: bool, /* If true, only (p1x, p1y) are valid. If false, all are valid */ p1x: f64, p1y: f64, p2x: f64, p2y: f64, p3x: f64, p3y: f64, p4x: f64, p4y: f64 } relevant quote: &gt; This is where my lack of Rust idiomatic skills really starts to show. In C I put (cur_x, cur_y) in the (p1x, p1y) fields of the current segment, and since it is_degenerate, I'll know that the other p2/p3/p4 fields are not valid — and like any C programmer who wears sandals instead of steel-toed boots, I leave their memory uninitialized. Rust doesn't want me to have uninitialized values EVER, so I must fill a Segment structure and then push() it into our segments vector. If it were an enum, in the "tagged union" sense as he talked about in the article, an algebraic sum type, then he wouldn't have to initialize p[2-4][xy] in the degenerate case, and he wouldn't need an explicit bool there. Using his current design, [this is a shorter way to initialize the struct](https://is.gd/IjthuP). Duly note, deriving `Default` is necessary. I'm deriving `Debug` to make it easy to print the value of the struct. If he were to switch to an `enum`, [this is an example of what it could look like.](https://is.gd/wXvgeM) The benefits are immediate: the compiler will enforce at compile-time that you never access a degenerate segment as if it were a normal one, and you don't have to waste code or cpu time initializing things that aren't being used.
That would be great! I love poking around in projects like this, its a fun puzzle to solve.
That seems to be most of what happens with Windows. It's why we still have drive letters. Windows has nice backwards compatibility, and I love it for that, but that BC can be a pain in the ass.
This! I had to give up on Vala because the layer of indirection made memory bugs even harder to find and fix.
Awesome! Clap is really neat and I use it heavily in imag, cannot thank you enough for it!
yeah exactly, the synth and my previous intros have been "c-with-classes" for sure. It's very much the same problem set, just a different side of the coin :) Yeah the thing with conrod is, as promising as it is, it's just too early/immature to rely on for large projects. Qt is something I have experience with and I know works and scales, and has everything I'll ever need. Of course I would've loved to do it pure Rust (I did try Conrod and a couple other things before deciding on Qt) but it's just not there yet in terms of what I need to rely on.
I would also create `struct Point(f64, f64);` for easier work with points. Then whole thing could became just array of tuples.
Also worth mentioning (and perhaps this was obvious) but the goal here wasn't to do a 64k in Rust per say, but to do a cool tool and a 64k in general, and I just happened to try using Rust for it. Luckily I was more or less successful :)
Yes, very nice to see! Do you happen to know some projects that could benefit from this and are a good starting point for Rust beginners?
Neat. Google's new OS team is getting rust to work with their new OS. That is pretty awesome.
The main problem here is that std::string and CString are *not* the same type. std::basic_string&lt;char&gt; has absolutely no guarantees about its layout, and I can pretty much guarantee you that it does not match Rust's CString. You'll need to find an ABI-agnostic representation.
[This is coder543's 2nd example using Hauleth's suggestion](https://is.gd/JK8uOP)
With the increasing amount and variety of crates being published, it may be better to just make it an "interesting developments" section where mostly things are listed that are interesting for a wider audience. That way you're not constrained to crates and you can also list useful tools etc while you're not constrained by the large amount of narrow-audience or silly projects (like my [whitespace-rs](https://github.com/CensoredUsername/whitespace-rs)).
Correct. COW in "Dirty Cow" is not a Rust `Cow`. It's not a data structure. It's a mechanism in which two processes can share a part of their memory, as long as they don't modify it (which is common occurrence on `fork`). When the process will attempt to modify it, it will trap to kernel, and kernel will quietly, transparently substitute the read-only view with a writable-copy, so the trapped process can continue just like given part of memory was always writable. There was a race condition there, that would allow processes touch the data that did not belong to them. In similar way Rust won't protect people from race conditions when accessing files, sending network data, and so on - any other interactions with data outside of Rust process. Rust can only protect you wrong doing nasty stuff with data inside your process.
It definitely does. Using youtube on a 56kB/s connection would be pretty impossible
It is configurable, through a flag or environment variable. See the notes section of the README (I should make that more prominent).
A single character encodes one nybble, not one byte.
Well ... I found this problem sufficiently interesting that I took a whack at it myself. It's surprisingly hard to get this right: http://gitbucket.tundraware.com:8080/tundra/trm As of this writing, the code on the repo works reasonably well except: - It does not yet handle file/dirs with blanks in it - It is inconsistent on how it handles serial number suffixes (which is a cosmetic defect only). - It always assumes that directory moves or copies are recursive Still, it manages to do file/dir copies or moves (safe rm), has a test mode, allows you to decide whether to expand the top level symlinks or not, and supports multiple graveyards by means of CLI argument. It does all this in about 1/4 of Rust code I looked at. So at least some of the commentary above is reasonably justified. I make no claim this is perfect, only an interesting problem...
I liked this quote: &gt; We've gotten double free()s, wrong casts, and out-of-bounds memory accesses. Recently someone did fuzz-testing with some really pathological SVGs, and found interesting explosions in the library. That's the kind of 1970s bullshit that Rust prevents.
^(Ungh, the soliloquy)
Very true! I don't remember why I didn't use `Shell::variants()` I think because I wanted it to be alittle more obvious what I was doing. I was tired :P As far as getting the binary name, for the compile time completion generation I don't believe that will work. But for the runtime, yes you're correct. In fact for the runtime one clap doesn't actually *need* it because it already has that information, but in order to keep the example short and change as little as possible I just copy pasted :)
This is after Federico, one of the devs of librsvg, started looking at [porting parts of it to Rust](https://people.gnome.org/~federico/news-2016-10.html#25). Also see [this post](https://coaxion.net/blog/2016/05/writing-gstreamer-plugins-and-elements-in-rust/) by one of the main devs of GStreamer, the multimedia framework of GNOME. GNOME possibly porting libraries to Rust is a very nice development, and could have nice side effects for Rust as well. The GNOME project has a lot of low-level libraries that are widely used, even on other platforms. libxml2 comes to mind, which is used by the popular Ruby library [Nokogiri](http://www.nokogiri.org/) for parsing HTML/XML.
Yeah that's for runtime. I had added a completions subcommand to one of my tools and just copied and pasted as well. Is there an easier way to use clap's knowledge of the name instead of pulling it out of env? By the way clap is a wonderful library.
And [object shorthand!](https://github.com/rust-lang/rfcs/pull/1682)
Oh well there you go. Haha. Great utility. I was missing having a trash on Arch. 
Awesome.
thank you for the pointer and the advices
Thanks! Yes...and no. clap pulls it from [`env::args_os`](https://github.com/kbknapp/clap-rs/blob/01994467d5808903907012c26953ebde72594137/src/app/mod.rs#L1333-L1343). You *can* get the name this way...although it's bit hacky and not intended to be used this way: let mut app = App::new("test"); let res = app.get_matches_from_safe_borrow(env::args_os()); println!("Name: {:?}", app.p.meta.bin_name); The key is start the parsing (i.e. with one the `get_matches` family of functions, but do so in a way that doesn't consume the `App` struct.
Quote of the week? :)
 if has_first_segment { segment_num += 1; } else { has_first_segment = true; } This looks a lot like an Option&lt;usize&gt;. Using that, we could instead have this `if` be a more readable `match`. match segment_count { None =&gt; { segment_count = Some(0usize); } Some(ref mut segment_count) =&gt; { *segment_count += 1; } } It also enforces that we check that we have a segment count before we try indexing it.
The backporting is happening now, although so far I've been the main developer, and I've only been working on it in my off time. The project just moved from http://github.com/google/tensorflow-rust to http://github.com/tensorflow/rust, so I suspect the TensorFlow folks will be helping out, but I certainly don't want to put words in their mouth. Contributions are definitely welcome. The issues are tracked in https://github.com/tensorflow/rust/issues, and there's plenty to do that isn't tracked, yet.
This even affects C++ code with differing compilers and/or standard libraries! I propose to use `c_str`, this should give you something like a `CString` in Rust.
Idris has dependent types and is considered a general-purpose programming language by its authors.
Right! That's precisely what makes this a nice project, I think. Instead of shoehorning Rust into something, it was pretty much not-worse than doing it in C++. Although there were some restrictions and some hacking was required this was not any more terrible than the hacking that is required in *any* 64k intro :)
This is quite good. Nice to see our foundations getting safer with Rust's help.
Yeah, sorry, forgot to add that to the post. I actually tried that with the same results. What I find interesting is the fact that I actually wasn't expecting string to simply work, but the fact that it works inside the struct got me confused.
Also, what do you find confusing about modules?
There is the "Friends of Rust" page: https://www.rust-lang.org/en-US/friends.html Those companies actively are using Rust in production. Checking out their web pages would be a good start. Note that some of these companies say that they explicitly are not looking for "*just Rust*" developers but "*more general*" developers. And there is the "This week in Rust" page: https://this-week-in-rust.org/ Where job positions are also announced.
&gt; couldn't find something like .unwrap_or_panic!(&lt;error_message&gt;). But I guess that is not possible, because panic! is a macro You need to use `unwrap_or_else` like `.unwrap_or_else(|err| panic!(&lt;error_message&gt;))`.
&gt; edit: i'm terrible at formatting code on reddit Reddit does not support the "triple backtick" code block style, only 4-spaces indent.
I've removed this post since it violates rule 5. Feel free to re-submit this as a self-post, with some explanatory text about its relevance to Rust.
Now that non-zero discriminant enums get optimized I'm wondering how the discriminant is set for enums. Is it counting upwards starting at 0 or at 1 to have this optimisation by default?
Maidsafe is hiring too , the job title is 'Rust Engineer' !!! https://maidsafe.net/careers.html#rust_engineer
I've collected [a list of small project ideas](https://github.com/whostolemyhat/learning-projects) to work through. They start off really basic (guess random number, factorial etc) but I've found them pretty handy.
Thanks! Whenever you give it a test run I'd love to get your feedback/bug reports to make it better.
You're saying you want it to automatically start and stop the runtime for each function? One error I ran into while testing is that if you shut the runtime down then start it up again real quickly for another Haskell function on the next line was that it caused a conflict of sorts and the program stopped working. That being said I do like like this idea and it might be good to implement a Haskell trait for things like this. I'll open up an issue and see what can be done about it!
In all fairness, the jobs section in TWiR very rarely contains entries. It's worth to have a look at it (which I always do, just for curiosity), but one shouldn't expect to find something there.
No, you just have a persistent object representing the Haskell runtime, like how database connections are represented in Rust or C# (and, I assume, other languages too). You can pass that between functions or suchlike, or store it in a `lazy_static!` in order to get lazy instantiation and shutdown on program end.
There may be further notational refinements, but I think this problem is best solved at the presentation layer. Maybe use color-coding or superscripting to visually separate lifetime notations.
I see what your saying now. I'll look into it and see if it's reasonable and not much of a performance issue.
I read through it again and I didn't understand why they couldn't return () normally or if there's a break with a value return that instead. Was there some edge case I missed?
Since the `Haskell` struct is zero-sized, it does not exist at runtime. The speed is the same, the only difference is ergonomics (both positive and negative) and safety.
I was thinking more of the Runtime itself running for long periods of time. Having a way to turn it on and off automatically would be great.
As far as having my ear, you're more than welcome to file issues even if they're just questions on the github repo, or join the gitter chat room anytime! :) As far as using `get_matches_from_safe_borrow`, it's almost identical to using `get_matches` except it returns a `Result&lt;ArgMatches, clap::Error&gt;` instead of just exiting with an error message. It also doesn't consume the `App` struct, and allows specifying where to get the matches from (i.e. you could use some other iterator, or `Vec`, or array and aren't just limited to `env::args_os()`). This is actually exactly what [`racer` is doing when started in `daemon` mode.](https://github.com/phildawes/racer/blob/b165ed5e7048af2010cfb48a2b11452c3b51044c/src/bin/main.rs#L224-L242) Take note of the `AppSettings::NoBinaryName` which is mandatory unless you want to type the binary name with each embedded command, which I'm assuming you don't. The only difference for you, from `racer` would be the need to display the errors without exiting. Which can be done [like this](https://github.com/kbknapp/clap-rs/blob/01994467d5808903907012c26953ebde72594137/src/errors.rs#L399-L400) 
Aha, so I've seen this before; it's retina scaling. If you disable that (turn it to 1x) it should work fine. I'm not sure why this behaves the way it does; I've seen ways to fix in in directx but admittedly I'm not sure how to fix it in opengl. I'll have to look more into it, but at least that should be a workaround for now :)
It a shame that recursive bloc comments in Rust are not handled.
First and foremost, I find that web UIs are almost never satisfying for this kind of stuff. Startups come and go, and using a web-only hosted service just means vendor lock-in. When the ship starts sinking, all of my stuff is going to Davy Jones' locker. Web UIs are also only 90% as good as a native app in so many ways, and getting the extra 10% is a Herculean task that few companies have surmounted -- maybe a company called Herculus can actually get it done. Even ignoring the above, performance is just not cool, in general. You have a couple of options. The one most companies choose is that you have to upload all of your data to this foreign entity, which takes time and automatically takes the security of your data out of your hands. What if I don't want to wait all afternoon for this large dataset to get there? The other big option is that all of it is done locally on your computer, nothing is uploaded, which is honestly better for that service because they don't have to worry about or pay for customer data hosting, but few web services choose that route. The problem with this approach is that it locks the web service into using JavaScript for literally everything computationally. Even with the data being uploaded and stored on the backend, most companies would still just do the computation "for free" on their customers' processors just in-browser in JavaScript, but they at least have the option to accelerate some computations on their backend, if they so chose. JavaScript engines are surprisingly fast these days, but you're still generally talking about single threaded execution. In this case, a single thread of a JIT executing an interpreter that will slowly crawl through your data to give you results. For all of its blandness, at least Excel is fast. LibreOffice even does some GPGPU acceleration of computations in certain environments where it is beneficial. If I want fast computation, I can easily throw something together in Python using numpy, and numpy is blazingly fast. PyPy supports numpy these days, I believe, so what little Python code I would have would go super fast. Hopefully in the near future, Rust will offer nice mathematical libraries like numpy, and that would be a far better solution than using Python, in my eyes. So, I respect attempting to innovate in the space that you're targeting, and I wish you the best of luck, but I'm probably not in your target market. If I were entering this market, it would be cool to have a native, desktop GUI dataflow environment that lets you build a graph transforming your data until it looks right, operating as an interpreter over a very small sample of your data. Once you're satisfied, it could generate C or Rust or something, ram it through the compiler, and process large datasets very quickly. It would keep this executable around in kind of a cached fashion in case the same computation needs to be done again with no changes, to avoid recompiling. Ease of use, speed, offline convenience, and the packaged software guarantee that you'll still be able to use it in 10 years if you need to, even if the company that made it sank into the Mariana trench.
The [`Vec` docs](https://doc.rust-lang.org/std/vec/struct.Vec.html) are surprisingly detailed about this sort of thing: &gt; Due to its incredibly fundamental nature, Vec makes a lot of guarantees about its design. This ensures that it's as low-overhead as possible in the general case, and can be correctly manipulated in primitive ways by unsafe code. &gt; ... &gt; Vec will never automatically shrink itself, even if completely empty. This ensures no unnecessary allocations or deallocations occur. Emptying a Vec and then filling it back up to the same `len()` should incur no calls to the allocator. If you wish to free up unused memory, use `shrink_to_fit`. &gt; ... &gt; `push` and `insert` will never (re)allocate if the reported capacity is sufficient. `push` and `insert` _will_ (re)allocate if `len() == capacity()`. That is, the reported capacity is completely accurate, and can be relied on. It can even be used to manually free the memory allocated by a Vec if desired. Bulk insertion methods _may_ reallocate, even when not necessary.
Almost certainly is a stack overflow.
`json-rust` author here. A lot of good edge cases there, will be adding them to the tests. The most critical issue here is stack overflow on (very) deeply nested structures. It will take some time before I get time to fix it, but [it's on my list](https://github.com/maciejhirsz/json-rust/issues/93). I was quite surprised that parsing digits after a period wasn't already covered. As the author correctly guesses that JSON_Checker is an influence here, although I don't see a test that would require `[1.]` to pass the parser as valid JSON. In either case, it should be trivial to fix. The two things that are most puzzling to me is panic on unicode identifiers and errors on parsing utf-16. The former because I can't seem to be able to reproduce it, the latter because `json-rust` can only parse `&amp;str`, which is to say that it can only parse utf-8 and any other encoding would first have to be converted to utf-8. The integrity of the encoding should be guaranteed by the Rust type system, unless unsafe code is invoked to create the string, in which case panic is quite fine. Edit: rolled out 0.10.3 with integer overflow for large exponents and the edge case for number parsing fixed. Stack overflow has to wait for a free weekend. Edit: all crashes/panics should be fixed now with 0.11.0
correct :)
Do you have an example? I would expect nested comments to be counted fine. edit: nevermind, thinking more, I'm pretty sure they're broken
For `start` and `deallocate`, take a look at `Box::into_raw` and `Box::from_raw`. As it is now, you are returning a pointer to stack-allocated data in `start`.
&gt;Would you agree that a server-client architecture can also result in good user experience regarding computation speed and reactivity of the whole app? This is bike shedding. No customer has had this issue, so why are you solving it? Maybe a Client/Server solution makes sense down the road. But to drive adoption this just creates another hurdle for user.
This is really cool, I like it. Since you seem to have a higher-order functional language in there *already*, you should check out some of the inductive program synthesis ("learn from example") work that MSR published and that ships in Excel. Definitely future tech, but it'd be neat ;)
From a quick look in the code, it seem that comment lines are counted the same way in Rust than in C. But C does not support nested comments : the comment block always end at the first `*/`. For example, in this code, the third line is a comment in Rust but not in C : /*1 /*2*/ 3*/ 
omg bstrie you're awesome.
Thanks, this should help when I get time to write a prototype.
Great work done there.
So cool omg
[Here is the graph of serde_json results.](https://github.com/nst/JSONTestSuite/pull/3#issuecomment-256429294) The only thing we feel the need to address is stack overflow. Beyond that, the two other "failures" are UTF-16 which I am not interested in supporting and large exponents which I think is mistakenly in the "y" category when really it is implementation-defined. I [reported the inconsistency](https://github.com/nst/JSONTestSuite/issues/4).
&gt; What's the behavior if you undo a remove, but a new file was dropped there? The same mechanic as removing a file with the same path twice: the newer file is renamed to `filename~1`. &gt; Also, what's the behavior if you try to rip your root dir? It'll panic, since it tries to create the parent directory of the target first. &gt; Or something like /proc? Undefined but it seems to just throw errors for me. &gt; Or a parent directory that your graveyard is contained within? It keeps making directories and then fails very loudly and hilariously when the filename length limit is exceeded, then cleans up. Probably worth throwing an error for this. &gt; I honestly would very much rather it not use -r for that at all, not even as a duplicate option. I decided to drop -r completely and use -u instead :) &gt; Also, my feature request would be to have some shred option that lets you overwrite it once from /dev/urandom, something that shreds everything in the graveyard. Not necessary, but if I want a full featured rm alternative I'd like optional shred capabilities for the graveyard. Overall though, thanks for making this! Interesting idea, although if the graveyard is on a different filesystem I think the data would still be recoverable on the original partition? Thanks for the detailed feedback!
Oh, I see. I was trying that function without |err|. Makes sense, thank you! 
I think [this](http://research.microsoft.com/en-us/um/people/sumitg/pubs/sigmod14.pdf) is the paper.
Relevant serde stack overflow issue: https://github.com/serde-rs/serde/issues/82
How do I turn Trait type fields into Generic Parameters? I have a trait object that behaves mostly an iterator. It maps a list to a list. And I'm trying to turn it fully into an iterator. The issue is I'm defining my input as a Trait Object, so it's typing parameters are variables, while the iterator class requires a generic parameter.
It's not. These are the ones I was thinking of: - http://research.microsoft.com/en-us/um/people/sumitg/pubs/ip-cacm15.pdf - http://research.microsoft.com/en-us/um/people/sumitg/pubs/oopsla15-pbe.pdf - http://research.microsoft.com/en-us/um/people/sumitg/pubs/pldi11-inverse-synthesis.pdf - http://research.microsoft.com/en-us/um/people/sumitg/pubs/oopsla10_synthesis.pdf
Hm, right. The enum repr came before the nonzero optimization so starting with 1 and 0 made the same amount of sense at the time. Feel free to open an rfc to change this :)
Not having ever used WebGL, I can't do much except point you to the interface that shows what methods we have ostensibly implemented so far: https://dxr.mozilla.org/servo/source/components/script/dom/webidls/WebGLRenderingContext.webidl There are several open PRs adding additional correctness fixes and missing APIs, too. We've got an [issue](https://github.com/servo/servo/issues/10209) tracking all of the outstanding WebGL 1.0 APIs if anybody would like to help!
Is there an example of how to use the streaming API, e.g. from a File? I'm having trouble making my code compile and my google-fu failed as well
I've loaded a bitmap into an `sdl2::surface::Surface`. How do I get at the value of a pixel in this surface? 
Your terminology is pretty confusing here (not your fault... trait objects are also confusing). Can you show us some code so we can see where the gaps are?
I'm just reading the docs here, but it looks like you should call `without_lock` to get a slice of pixels.
On the off chance you're unfamiliar with it, the last product I ran into in this space is Resolver One. I really liked the product but they never got enough traction and wound up shutting down.
Actually solved it I didn't have to specify the Trait subtypes. Basically I was doing something like this trait Thing { type A: SomeTrait; .... omitted } struct AThing&lt; I:Thing, X: TotallyDifferent&gt;{ data: Vec&lt;I::A&gt;, ... omitted } 
I already planned to implement `StreamOnce` for my struct (which implements Read), but I was 100% sure that Streaming is supported and I'm just unable to figure it out :) Thanks for super-fast response, and for the library itself.
There's also a segfault in "n_structure_open_array_object.json", at least on my machine.
If I make a sea urchin out of nails we could put it next to one of edunham's plushies and reenact that image in real life. :)
No, because then you can synthesise an instance of `Haskell` without using `fn start(...)` (as explained in the comment).
Really impressive material. I can tell you put a lot of love into it. Thanks for sharing.
Ooh I always wanted to build a statically spreadsheet like tool, if only I was skilled enough. Does it do units of measure?
`pub extern fn ...`
Doesn't seem to work here.
How can I statically link a library in Windows? I have a `foo.lib` file and the following code in my `build.rs` file: fn main() { println!("cargo:rustc-link-search=native=C:\\lib\\x86"); println!("cargo:rustc-link-lib=static=foo") } But the `.exe` file still requires `foo.dll`. I'm not experienced with external libraries, is this a mistake with my setup or is `foo.lib` the problem? My goal here is to hide the dependency, if statically linking `foo` is impossible, is there an alternative? 
I guess the only concern is how easy it would be for a third party to convert UTF-16 to UTF-8 on the fly. That doesn't seem too difficult to me, so it's better solved by the user if they want anything besides UTF-8.
&gt; Any libraries doing this need to be fixed to avoid unchecked stack growth as a matter of urgency. This could be easier if we had opt-in tail call optimization with returning with `become` instead of `return`. There is the issue of when to run the destructors, but running immediately before the `become` (instead of after, like `return`) seems like the right behavior. Instead, one has to refactor the code to not depend on recursion, which can sometimes lead to it being harder to understand. In C, such tradeoff is common.
`key.0`, or if you want to cast it to another type, `SecretKey(public_key.0)` They are just tuple structs, look at the implementation here: https://github.com/dnaq/sodiumoxide/blob/master/src/newtype_macros.rs#L204 Documentation on tuple structs: https://doc.rust-lang.org/book/structs.html#tuple-structs
With the Rust Language Server is in it's [pre-alpha stage](https://github.com/jonathandturner/rls), and Rust compilation times are a work in progress, I'd recommend being forgiving with expectations. As both the Rust Compiler gets more efficient with partial compilation and Rust Language Server becomes more stable, on-the-fly syntax checking becomes feasible. If you have a few minutes, take a look at the [roadmap for Rust in 2017](https://github.com/aturon/rfcs/blob/roadmap-2017/text/0000-roadmap-2017.md). 
It is written in 2014 against 0.10 / 0.11 instead of 1.0 (May 2015) and lots of details were locked down fairly late in the run up to 1.0. Most of the information is correct but when skimming I see that there's still references to GC, which I thought was out of the language by that point. The guide mentions macros but macros were only partially stabilized. Pattern matching as shown in the article works but procedural macros require using the nightly distribution and flipping a flag. There could be more, I didn't look that hard. Seems like a reasonable way to get your bearings if you're so inclined but I think the Rust Book (or the [wip new version](http://rust-lang.github.io/book/)) and Rust By Example are better sources for learning. I'll also mention that Rust is not a particularly functional language. Most code winds up being a mix of sequence transformation with HoF and combinator chaining and the type system conveniences you're used to paired up with imperative algorithms using mostly immutable local bindings. I think the ability to return sequences (impl Trait) should bring out more functional-style libraries.
thanks a lot for taking the time to do the review, I'll just stick to the Rust Book in that case. thanks for the mention of impl Trait and how Rust is generally written, I've been trying to get my head around idiomatic rust (I'm coming from Scala and Haskell).
You might find my first rust project interesting if you're coming from an FP background. I took the Ocaml code from the PLzoo for a prolog interpreter and rewrote it in rust. I really didn't have to change things very much. A lot of ML maps nicely on to rust concepts/standard library. I encourage you to checkout the original and compare it with my translation. * original: http://plzoo.andrej.com/language/miniprolog.html * my version: https://github.com/dagit/rust-prolog
One caveat I just noticed that the author has been updating the original. So it's possible you'll encounter some version skew unless you can find the code from last year.
Thanks! Will look into it.
It doesn't, yet. However units of measure would be a really nice feature. Especially, given how smooth units would fit into the concept of the language as it is so far. At some point you literally won't be able to compare apples to pears (or add Euro to Yen) :)
I would love to jump ship to Rust one day. I am a .NET developer by day though and I am concerned my lack of production quality *nix skills will be a big barrier for me. I am glad to see Rust positions available now. It gives me something to aim for!
&gt; you're still susceptible to out-of-memory conditions if you let that stack grow too tall. You run out of memory before reaching that condition if you parse in a while loop.
Ah, I didn't think to check the dependencies of my dependency. You're right, `nickel_postgres` required an older version of `nickel` - I updated the version required and my project built without any further changes needed. Thanks!
Surely you can limit the input size even if you're using the call stack as your parser stack?
I'm going to look into it, thanks.
If anything, I *want* to be able to add Euros to Yens, but I also want the conversion done automatically, even if I have to say how it's done myself.
I wouldn't mind it being counted as both a line of code and a line of comments.
Haha, considering "or else" a threat instead of a conditional makes me chuckle. Unwrap it NOW, OR ELSE!!!!!
this is damn cool
Congraz on being the first to point out how Airtable is an important competitor! From what I can tell by now, Airtable doesn't support arbitrary computations on the contents of a cell. E.g. you can put a list into a cell, but you can't run a function that filters the list. That might sound like nitpicking, and indeed Airtable is a great tool and they are already *pretty* mature with what they do. However, it seems that they really focus on being this app-kind-of-thing. I want something that doesn't limit me in terms of programming, ever. EDIT: Oh, and I like your analogy with Elm. If Elm aims to be a convenient, less complex way of enjoying the feats of functional programming in the UI context, maybe Herculus could become a convenient way of enjoying FP in the context of data handling.
Sure, that too!
Yeah, but I don't think that's really a problem. The statistics I'm interested in are "how much code is there" and "how many comments are there". I don't need that to add up to the total number of lines. If you need to compute a ratio, well just count the number of hybrid lines as well and report that.
Nice! Can't have enough usable error messages! ;) Is the colored diff feature for "required/expected" messages planned for rustc?
I am so confused by this.
It seems like this business would be better off with an Apache Kafka expert than a rust expert. I am neither but maybe talking to someone that knows a bit about both would be beneficial. https://github.com/spicavigo/kafka-rust 
Same here :)
Why `extern` though? That just changes the function to use the C ABI.
I came here to say the exact same thing. I think we would all benefit greatly from this!
Yeah, it can also be read in way which implies the individual will take the role as the senior rust developer at the company, meaning a position of authority. It's not just something you are in your abilities with the specific language but how developed you are in other faculties. 
extern tells the compiler "hey, somebody might link to my library later and call this function". 
Sure. In GDB 7.11.1 it looks like this: $1 = Vec&lt;i32&gt;(len: 3, cap: 3) = {1, 2, 3}
I didn't try the annotation, but putting `--crate-type lib -C opt-level=3` into the arguments field _does_ make the crate type `lib`. Then one can just mark the desired functions `pub`, like mentioned above.
I don't know the details but from what I've seen long time ago, I felt like simple parser would be just like other parser. Isn't this true?
No, that's what `pub` does
How can I use associative types to declare `Fn,FnMut,FnOnce` I'm trying to build an abstract LL(k) parser. The rough signature trait Foo { type Input; type Output; //methods omitted } impl&lt;T: Foo&gt; FnMut(T::Input)-&gt;Option&lt;T::Output&gt; for T { fn call_mut(&amp;mut self, arg: T::Input) -&gt; Option&lt;T::Output&gt; { //body omitted } } Fails. 
Is there a right or preferred way to validate path to prevent a path injection? I get the filename from user. That is appended to the directory path, but I want to accept only paths that point to the directory itself, or subdirectories.
I think there's support for conversion in Rust by creating some sort of Iterator. (I've used it but I don't remember where it came from.) It's very easy.
But pub is for in-rust compilation, which is always static, so the compiler can still remove it. Extern means the function may be called without the compiler's knowledge so it isn't allowed to completely remove the symbol.
Programs written in the Rust Programming Language always run as fast as possible, however you may want to try asking again over in /r/playrust.
Which in turn means that `pub`is what stops the compiler from removing the function. While an `extern fn foo()` (without `pub`) may still be removed by the compiler, because it's not externally visible.
Because I just waved a dead chicken at the code until it worked, and didn't think about it too much :p
cc /u/nasa42 for twir
Another week of [`cage` hacking](http://blog.faraday.io/announcing-cage-develop-and-deploy-complex-docker-applications/). This time I'm trying to get it to talk directly to the Docker daemon to get container status, which means parsing JSON. And this means cryptic error messages from Rust serialization libraries. It turns out that there are two steps we can take to address this: - "Rewind time" using `rr`, starting from the crash and looking for the last couple of calls to certain deserialization functions. - Use `error-chain` to wrap cryptic errors with as much information as possible (and use `rustc` to enforce this wrapping at compile time). I thought this was interesting, so I wrote it up for the Rust community!
Oh yeah, that makes sense; no need to use `pub` for an `extern`'ed callback passed to a C function. Although, I couldn't find the answer to this specific question in the docs :/
&gt; rust is now going mainstream. I think Rust has critical mass to not die if Mozilla drops it but is nowhere close to going mainstream. It's approaching business-acceptable levels (think Clojure) where you can get a job in the language if you look but it's not really mainstream. I think Rust has the potential to go mainstream, particularly with ease of use and adoption being the team's primary focus for 2017 but it's at least 3-5 years out. I was in the Python, Node, and React communities before they went mainstream. The way you can tell is that before a community goes mainstream, you can pretty much keep up with what everybody's doing if you read the central forum (users.rust-lang and /r/rust in the case of Rust). New people come in and produce surprisingly good projects but the community is comprehensible. When a language goes mainstream, there's a flood of new projects coming in. The quality will vary and will overall be lower than the early adopters. It becomes impossible to keep track of everything and you start seeing duplicate libraries for mainstream needs. Alternative intros and tutorials get written as people introduce the language to their workplace and aren't quite happy with what's already out there or they want to make a name for themselves in the language because it's beneficial for their career. That's pretty much the signal, after that you'll see companies of increasing size and conservative tendencies announcing they're adopting and then you start seeing junior devs with it listed as their main skill set.
It's awesome that Elm (maybe clang before it?) started this trend of making error messages actually usable and friendly!
Fun fact: the "R" originally stood for "resplendent." I have no comment on whether it's a coincidence that it's also my first initial.
Very exciting.
manishearth, llogiq, autorun,tomaka,sfacker,sgriff,...
Removing this post, since it violates Rule #5 - it does not appear to be written in Rust, or have any specific relation to Rust other than having strict typing.
It was also a pretty awesome TV show.
There is consensus that abusing the nonzero optimization is bad and we should instead further expand to general "niche filling". I took a look a week ago and it's even easier than I thought to expand the current (zero-only) niche-finding algorithm, and I'll gladly mentor someone (or do it myself in a month or two).
Nicely done! One issue on the subject of memory safety- it is totally possible (and explicitly "safe") to leak memory. For example, creating a reference cycle or even just calling `mem::forget` on a `Box`.
this is a great example how debuggers can be helpful in isolating an error over a complex surface area.
Most regular expression engines are more powerful than regular languages.
This is the best tl;dr I could make, [original](https://medium.com/mozilla-tech/a-quantum-leap-for-the-web-a3b7174b3c12) reduced by 87%. (I'm a bot) ***** &gt; Quantum is our effort to develop Mozilla&amp;#039;s next-generation web engine and start delivering major improvements to users by the end of 2017. &gt; Project Quantum is about developing a next-generation engine that will meet the demands of tomorrow&amp;#039;s web by taking full advantage of all the processing power in your modern devices. &gt; Quantum starts from Gecko, and replaces major engine components that will benefit most from parallelization, or from offloading to the GPU. One key part of our strategy is to incorporate groundbreaking components of Servo, an independent, community-based web engine sponsored by Mozilla. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/59p7wm/a_quantum_leap_for_the_web_contains_updates_on/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ "Version 1.65, ~11352 tl;drs so far.") | [Theory](http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/) | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr "PM's and comments are monitored, constructive feedback is welcome.") | *Top* *keywords*: **Quantum**^#1 **web**^#2 **engine**^#3 **more**^#4 **components**^#5
Man, it bugs me too. But users will be users.. 
I have used reverse debugging in the past to debug an issue with an unfamiliar code base. The last time I did it, I was using GDB's native reverse debugging functionality; but that is painfully slow. I had to limit the size of my inputs substantially to get the program to run quickly enough to be usable and reproduce the bug, and luckily I was able to reproduce it with limited inputs. At that time, `rr` existed but was 32 bit only, while I was debugging this on a 64 bit system. But even being that slow and having to cut down the input size to compensate, reverse debugging was a much easier way to track down a problem in an unfamiliar code base than regular debugging. Look forward to using `rr` the next time I have to debug such an issue.
There are 3 factors at play: The first is that you control exactly the size of what you put on the heap, whereas the stack is more mysterious: - a library function has no control over the amount of stack still available. - the stack generally retain *more* information than strictly necessary (space for variables no longer necessary or that are not yet in use, space for spilling registers, ...) The second factor is that generally speaking, you have much more heap space available than stack space. A typical linux stack size is 8 MB, whereas it's easy to have a few GBs of heap space. The third factor, you nailed: &gt; If you have a fixed limit Many times, you will have a *configurable* limit, with a reasonable default: most people do not have to twiddle with it, but if you ever run out you can print an error message telling people how to increase the limit. If you use the heap, just this flag is enough to get you going. If you use the stack, you may also need to explain people how to tune their stack size, which is platform specific and may require elevated privilege. --- So in short, using the heap is space efficient and easily tunable.
Senior Rust engineer with 10 years of experience. /s
Dotty is pretty freaking awesome...formally proven as sound, and extremely powerful type system, but far more simple and fast than scalac is today. I'm a huge fan of Scala as a language, however the JVM as a target makes me sad when I want to do anything that isn't server programming. It's such a shame, cause I think Scala could possibly be the best application programming language in existence if it wasn't so married to the JVM. Dotty helps get rid of some of the hard JVM coupling and obscure/unneeded Scala features, making projects like ScalaJS and Scala Native much more tenable. It's my personal dream of a project to take Dotty, get rid of the crufty parts of the Scala language that only exist due to the limitations of the JVM as a platform (abstract classes vs traits, reflection, and nullable types come to mind), and then compile it down to MIR. Then find a way to build a [co-effect system](http://tomasp.net/blog/2014/why-coeffects-matter/) using scala's awesome implicits, and a super awesome rust-specific FFI (embed Rust as a drop-down language?). Application level programming nirvana. 
The eventual goal is nebulous. Quantum incrementally brings Servo code into Firefox. There may be Firefox components that never get replaced with Servo code. Quantum also covers projects which are incorporating Servo's ideas (but not code) into Firefox, or even things unrelated to Servo. I think ultimately Firefox would have many Servo components, but also a lot of its own stuff, and a fully Servo-based engine (if it happens) would be a separate thing. Pretty far off though.
Oh boy...
(At the same time, this is very hard to do by _accident_ in safe rust)
In 2025, Apple will just adopt Servo in much the same way they once adopted KHTML.
I dunno. I work with scala daily, and while it can be beautifully terse, I'm not particularly happy working with it.
_some_ of Servo's features, not necessarily all of them. In many cases it might make more sense to rewrite a Gecko component in Rust or not touch it at all. Gecko is much larger than Servo, and does many things Servo doesn't. Nor does it have the same architecture -- while it may make sense to switch to servo's architecture in some cases, this won't be all of them. Things like Servo's DOM probably won't make it into Gecko (though at some point it may be possible to write DOM interfaces in Rust in gecko). Remember that there's also a safety cost to doing the FFI between Rust and a mostly-safe C++ (i.e. being used with best practices), and if the FFI API surface is large enough for a conversion it may make more sense to just leave it as is. I think the DOM is one of these; there's far too much code from all over the place doing arbitrary things with the DOM internals.
I've started submitting some [pull requests](https://github.com/erickt/rust-zmq/pulls/rotty) to rust-zmq lately and plan on starting on zmq integration to [tokio](https://medium.com/@carllerche/announcing-tokio-df6bb4ddb34).
I want this to be true.
Now everyone impatient to know when this will get deployed will be asking "why haven't I leaped yet?!?".
Yes and no :). I think it will be a case by case basis depending on existing code/libraries.
Maybe take a look at Ferris' live coding videos? he codes a Nintendo 64 emulator from scratch. There's 12 videos and they're a few hours long each https://www.youtube.com/watch?v=Fsi9HPcyrU8&amp;index=1&amp;list=PL-sXmdrqqYYcznDg4xwAJWQgNL2gRray2
I think the current "Servo ideas" ones are all in C++ (Quantum DOM is the main one, though that's a mix of servo ideas and other things). Remember that writing a component in Rust has a safety cost at the FFI boundary. C++ itself can be pretty safe if you use it right (not at the level of Rust, but still), but translating C++ idioms to Rust across the FFI boundary is prone to mistakes and can lead to unsafety. I've been doing work in stylo to make this safer, but it's not always possible. This cost depends on the kind of component. Something with a clean abstraction boundary is easy to replace with Rust -- but in this case we could just as easily replace it with Servo's code. Something that's more horizontal/architectural (e.g. quantum DOM) is harder to replace with Rust or Servo code. So most of the things that could be written with Rust would probably be replaced with Servo code anyway (unless Servo doesn't have this code, in which case Gecko would use it first and Servo would later -- this happened with mp4parse). Patrick talks a bit about Servo's analogue of Quantum DOM and why Gecko needs its own [here](https://news.ycombinator.com/item?id=12809625) But it's possible that a Servo idea would end up being implemented independently in Rust for Gecko. Less likely though.
graydon :-p
This is a very good point.
Making it possible to write new DOM components in gecko is definitely a goal (I at least) have, and bringing over Servo's DOM wholesale is not, as least for now. That way we can get the benefits of rust's safety and productivity without compromising web compatibility and taking on tons of risk. 
And that's fine, but then it's no longer a regex. Even so, I'd love to see a regular expression engine that can accept valid JSON, and the expression that enables it to do so.
What helped me get started was porting an existing little project of mine to Rust. In my case, a screenshot utility that uses XCB with the SHM extension (most screenshot tools go right for x11 instead of using XCB; "the modern way"). I got it working just fine in two days or so and learned a ton! I'm still a total newbie but what's interesting is that after a few days I haven't found myself "fighting with the borrow checker" much at all. In fact, that phase probably only lasted a couple hours. I struggle much more with when and where to use structs/arrays/types/vectors, converting various types/structs into other forms that popular libraries like, how to properly call out to C (a language I don't know very well at all), and I really have no clue what `T` is supposed to represent, how to use lifetimes (or even why they exist/matter), or many other things that are *assumed* to be known in all the various HOWTOs and documentation. It seems like every Rust doc or tutorial starts with the premise that the reader is intimately familiar with C, pointers, the heap/stack, and particularly all the apparent nonsense that exists in the world of C. As someone coming from the world of Python and JavaScript it's not very helpful. What's funny is that people will recommend learning computer science stuff like algorithms, advanced data structures, etc which of course are all taught in C.
Oh, and I should mention: This crate was *heavily* inspired (right down to the name) by [ActiveState's `appdirs` library](https://github.com/ActiveState/appdirs) for Python. My Rust version is less opinionated, though (e.g. won't append `\Cache`to the data directory on Windows for cache data).
Thank you, kind person, that is exactly what I needed.
Nice work. I will be using this at some point!
I first recommend [the book on Error handling](https://doc.rust-lang.org/book/error-handling.html) to have you learn about `try!` and `unwrap`. However, since `try!` only works for `Result` and no other structs, there are also existing macros to work around these limitations, e g my own [inner](https://docs.rs/inner/0.1.1/inner/) crate. 
Your final example doesn't typecheck. I assume you were trying to emulate monadic do notation: some_func().and_then(|x| some_func2().and_then(|y| some_func3().and_then(|z| use_some(x, y, z) )));
Do they support parsing context-free languages?
Yep, that was my thinking.
Awesome, let me know if you run into any bugs or ergonomic issues :)
Thanks! My pleasure!
For anybody looking for a general way of chaining `if-lets` and `if`s where there's no `else` clause, there's [this macro](https://github.com/Manishearth/rust-clippy/blob/master/clippy_lints/src/utils/mod.rs#L34) in Clippy.
Hey, can you check if the segfault still happens on 0.11.0?
I suggest adding a "null" implementation (that returns `NotSupportred` every time) for platforms other than Windows, Linux and MacOS. This would avoid compilation errors when you compile for Emscripten or iOS for example.
I wonder if the planned C++ integration might help some of that, I wonder if it would be possible to have drop types treated as destructors and used with raii in C++.
Obviously, for questions, you can also ask me here.
Yeah, that might. bindgen already can generate methods and it shouldn't be too hard to make destructors. Right now stylo doesn't try this because name mangling is not the same across platforms (so we have to generate bindings for each platform -- we plan to do this eventuqlly though), and our rustc still has inline drop flags iirc.
Sure, but the version that /u/Quxxy presents doesn't introduce huge amounts of nesting, and I imagine it uses less stack space (although when LLVM is done optimizing, who can tell?).
Yeah that's what I want. Or generally that's what the retain method could provide, but no one thought of that, so it's an unfortunate oversight in the API :/
It would be great if Rust tooling would use that. We should finally force proper locations for all configuration files…
Nothing would honor me more. But I think it's a bit late, now. ;)
What errata specifically? I didn't adopt any of their "opinionated" features (e.g. appending `\Cache` to cache path on Windows). I also chose not to support "problematic" features (e.g. non-user-specific program data fails with a permissions error on Windows Vista, so I chose not to support shared data on Windows.)
Would it make sense to add the field name to rustc_serialize's ExpectedError? This whole debugging session would have been unnecessary if ExpectedError("Object", "null") would have been ExpectedError("Volumes", "Object", "null"). As we need the field name anyway in that part of the code, we this should only occur an allocation cost when the ExpectedError is constructed. This is still not perfect, e.g. if you have a structures with many repeating key name. Something like ExpectedError("*ContainerInfo.Config*.Volumes", "Object", "null") would be even better, but that would probably occur a much higher runtime cost.
&gt; Would it make sense to add the field name to rustc_serialize's ExpectedError? This whole debugging session would have been unnecessary if ExpectedError("Object", "null") would have been ExpectedError("Volumes", "Object", "null"). This would be a huge improvement, yes! Do you think the maintainers would be interested in a PR? serde_yaml, at least, tends to have similarly cryptic errors, and that is really hurting `cage`'s usability as well.
I'll take another look. I cross-referenced most (if not all) of the directories there with the official platform documentation, so I *think* I got everything right...
Regarding the Linux part: You are a saint. Thank you very much for doing things the right way in the first place. I still hope for a day when I will have no dotfiles besides `.config`, `.cache` and `.local` in my home folder.
So is it basically just a hackathon? Is there anything different compared to those besides the time zones and using Rust?
I think the main downside to giving the closure an &amp;mut is that you probably already have a lot of predicate functions defined in other places, and those will usually take a shared reference. You'd need to wrap all of those in a closure just to downcast the &amp;mut to an &amp;. It would be interesting if a fn(&amp;T) was able to coerce into a fn(&amp;mut T) though. Are there any fundamental reasons why it can't?
Rekt!
I'd like to remind everyone of our "No zealotry" rule. Let's keep discussion primarily objective, back up opinions with code, and try to remain calm and level-headed :)
I think I'm going to refer to my program's runtime as play time from now on, haha. Love this EL5 write-up, haha.
[Not replying to anyone in particular, I just picked a comment towards the top of the thread.] This thread is getting a little heated, I'd appreciate it if we could all take a step back and reflect for a moment. Differences of opinion are great (and I thoroughly encourage them), but let's keep the discussion on-topic, and not resort to personal insults.
filter/map/collect?
If `x` is `Option&lt;T&gt;` definitely use `.and_then()` Edit: Same thing if `x` is `Result&lt;T, E&gt;`.
Given that retain is already going to have to shuffle elements around, I figured the difference between that and a new vec at all shouldn't be much, though maybe that's incorrect.
What is the byte order of your proposed `as_bytes` method? Little endian or big endian? Just use the [`byteorder`](https://crates.io/crates/byteorder) library. These functions actually used to be in `std`, but we cut them out in the run up to 1.0 (along with lots of other stuff).
The only thing that enrages me more about Linux than the crazy blending of user data, app settings and cached data in my home directory, is when people don't have a problem with it and tell me that /home is supposed to work that way. It seems to be a popular opinion, and I don't get it.
&gt; What is the byte order of your proposed as_bytes method? Native of course. (Because it should be implemented with `unsafe` `transmute` of reference.) And yes, I'm aware that it might be incompatible if someone did `writer.write(foo.as_bytes())` where `writer` is connection to other machine with different byte order. However, there are obvious use compatible cases: pipes, unix sockets etc. Edit: I don't see how I could use it with byteorder. An example would be helpful.
Now I know to not comment and slowly walk away :)
Check out these [docs](http://burntsushi.net/rustdoc/byteorder/trait.ByteOrder.html). You should be able to do something like this: let mut buf = [0; 4]; NativeEndian::write_u32(&amp;mut buf, 1234);
Thanks for following XDG Base Directory specification. I never liked when some app creates additional files/directories directly in my home dir (cargo…). I have some suggestions: - Only first path is returned when requesting SharedData and SharedConfig. For example on my system SharedData returns only `/home/arvamer/.local/share/flatpak/exports/share/` when `/usr/share` and `/usr/local/share` would be usually more useful for apps not installed using flatpak - It would be nice if you had in docs table with root directories of each `AppDataType` for each platform. - You could also add tmp dir (or runtime dir using XDG terminology)
As stated on the page: yes. Feel free to put yourself in as a project, even if you cannot participate.
&gt;Native of course. (Because it should be implemented with unsafe transmute of reference.) I'll likely get downvoted for this, but if fn to_bytes_native_endianess(x: u32) -&gt; [u8;4] { unsafe{ ::std::mem::transmute( u32 ) } } Does what you want it to do you honestly should use it. The type system escape hatches exist for a reason. Unsafe code can be perfectly predictable, and *safe* in the context of C/C++ code. If you want to avoid the messiness of cross platforms then use the `#[cfg(target_endian = "little/big")]` then when somebody comes along to build on another platform they get a compiler error rather then quietly broken code. :.:.: Yes `byteorder` crate is a better fix, but not everything needs to be cross platform and 100% safe. 
Awesome! I'll open up some easy issues in my crates people can jump into then and list them.
It's quite [recent news](https://www.reddit.com/r/rust/comments/583hst/facebook_is_writing_a_mercurial_server_in_rust/).
I used something similar except with references (because I wanted to read_exact directly into struct field). I know that such code is safe. I'm just surprised why it isn't already in standard library because I feel it might be very common. &gt; needs to be cross platform and 100% safe I believe everything should be 100% safe. What's the point of program if it's incorrect? Regarding platform-dependency, writing native-ordered bytes to Unix socket or pipe is clearly, obviously platform-independent.
&gt; FWIW, I don't think that's obvious at all. I wrote _directly_ and I mentioned references. Is there a way to get reference to `u32` with different than native endianess? Obviously there isn't. Intuitively I think that `read_u32&lt;R: Read&gt;(&amp;mut R) -&gt; u32;` is less efficient than `read_u32&lt;R: Read&gt;(&amp;mut R, &amp;mut u32) -&gt; io::Result&lt;()&gt;` if you want to read directly int field of struct (because there are instructions to copy the value) but that might get optimized by compiler - I'm not sure.
I'm surprised, you are the third person who suggested doing write instead of read...
&gt; There is nothing unsafe when converting u32 to [u8, 32] because same thing can be achieved using safe. (Similarly mem::forget is safe because it can be simulated by making reference cycle.) It's implementation dependent, that's what is unsafe. Edit: looking at to/from_le/be, this doesn't seem to be a *great* reason, but at least those are explicit. &gt; The example you provided is exactly opposite of what I wanted: I wanted to read u32 directly into existing structure and I'm sure that ordering is correct, because it comes from Unix socket. (And I know that program on the other end is writing it natively.) Oh, oops. Also, since you're sourcing it from a `Read`, this'll be a lot better with `byteorder`: use byteorder::{BigEndian, ReadBytesExt}; let number: u32 = try!(socket.read_u32::&lt;BigEndian&gt;());
I also have lots of headaches with `"cargo:rustc-link-lib=static=..."`. I don't understand what it does. Instead what does work is using the `links = "foo"` in your Cargo.toml as seen [here](http://doc.crates.io/build-script.html#the-links-manifest-key). Then just drop that line (but keep the `"cargo:rustc-link-search=native=..."`). Also make sure that `foo.lib` really is a static lib, on windows you link with special .lib files even if they're linked dynamically.
The OP kinda has a point, it'd be nice if you could safely convert into bytes and the standard library already has functions for converting to/from big endian/little endian result = u32::from_be(num).as_bytes();
&gt; I wrote directly and I mentioned references. Is there a way to get reference to u32 with different than native endianess? Obviously there isn't. No, I'm saying that I don't think it's obvious that an `as_bytes` method on `u32` returns its native byte order. It's unclear to me. I wasn't referring to your description. Sorry. &gt; Intuitively I think that read_u32&lt;R: Read&gt;(&amp;mut R) -&gt; u32; is less efficient than read_u32&lt;R: Read&gt;(&amp;mut R, &amp;mut u32) -&gt; io::Result&lt;()&gt; if you want to read directly int field of struct (because there are instructions to copy the value) but that might get optimized by compiler - I'm not sure. That isn't the example I linked though. You can use byteorder independently of `io::Read`/`io::Write` with the `ByteOrder` trait directly. Maybe it would help if you included a complete code sample of the problem you're trying to solve. It's not *at all* clear to me why the `byteorder` crate is insufficient for your use case.
Hahaha! You're welcome.
&gt; at the time this project was still under the wraps So much for Mozilla being a community…
Awesome. The end of my hiatus is due end of November, but perhaps I can make an exception for this...
Oh wow, awesome! Send me a link if it's public :)
I don't think using byteorder and a few bitwise operations will be slower than what you are suggesting. Casting to a byte array is all well and good but at some point you will have to get the values out to compare them or do whatever operation you want and then you will have gained nothing and probably even lost something if you get multiple values out that way.
Update: apparently it works OK with nightly `rust-gdb`, it's just stable that has problems (which, TBH, could be expected, as GDB 7.12 is quite new).
See http://manishearth.github.io/blog/2016/08/18/gc-support-in-rust-api-design/ We're specifically looking into adding hooks for GCs that let a GC query for live GC objects. Servo itself uses a set of lints to make the "two kinds of GC pointers" thing work. But eventually we'd like to move over the proposed GC hooks.
I don't think it should exist without a qualifier. to_bytes_le or to_bytes_be, on the other hand, would be acceptable to me. The endians should not be inferred. Doing so is what makes code unsafe and platform incompatible. transmute should be used when you really want to do that.
This was really interesting and well-written. But why is reverse debugging required? It seems to me you'd grep rustc-serialize for "ExpectedError" and break on the function that prints it, then walk up the stack.
transmute x, not the type u32
This is to a huge extend the work of edunham. We're happily taking pull requests https://github.com/rust-community/rust-community.github.io and here https://github.com/rust-community/resources
&gt; The endians should not be inferred. Doing so is what makes code unsafe and platform incompatible. I think that's already the case in `to_le` and `to_be`, but I agree with you since it's a ton easier to accidentally break things on little endian platforms by not calling `to_be`.
TLDR: Rust code is 3x faster than go code! :)
Highly recommend running your program in a profiler such as valgrind in combination with http://kcachegrind.sourceforge.net/html/Home.html Or possibly alternatively or in combination with some form of sampling profiler and flame graph visualization such as http://blog.adamperry.me/rust/2016/07/24/profiling-rust-perf-flamegraph/ or https://github.com/llogiq/flamer Hyper without much effort pushes ~500K req/s on my core i7 4770K without any tuning... and Iron last I checked was around 200K req/s for the same machine https://github.com/iron/iron/pull/392 https://github.com/hyperium/hyper/pull/822
By the way, the [unicode-segmentation](https://github.com/unicode-rs/unicode-segmentation) crate provides a tokenizer that correctly skips over whitespace and punctuation.
The problem is that the error is created somewhere down in the serializer library, then the stack is unwound, and _finally_ the error is printed from `main`. If you don't use a backtrace-compatible library like `error-chain`, Rust makes it very hard to find the original source of an error. Sometimes, if the error is constructed using a `new` function, you can break on that. But reverse debugging is ridiculously easy once you get the hang of it, and it allows you to rewind backward from almost any kind of crash or unexpected exit. Now that I've done it once, I can track down similar errors in under a minute. So it's a really useful and general technique for frustrating bugs.
See [`tantivy`](https://crates.io/crates/tantivy)
Neat! I'm not familiar with the `arrayvec` crate, but is there some benefit it's giving over a `Cow&lt;'a, str&gt;`?
As I pointed out it is not raw performance that is the problem. It is the fact that I need to be able to have thousands of concurrent connections. Thanks for pointing out the profiler, though.
That's a great post!
I'm a beginner too. To avoid chaining, I've been using: let v1 = some_func1().ok_or("error 1")?; let v2 = some_func2().ok_or("error 2")?; let v3 = some_func3().ok_or("error 3")?.clone(); // just to show that this works `error-chain` will make this type-check without a hassle. And I get to use meaningful variable names (and error messages if needed) at each step. The lack of `Carrier` impl for `Option` makes this pattern preferable for me, even when there are no real errors to care about.
Cool article. Lucene solves the Heap allocation problem by reusing the same buffer... If the TokenFilter requires to remember some previous buffer (for instance for something creating index-time query expansion) then the TokenFilter is in charge of handling its own pool of tokens. If I may ask, why bleve and not Lucene ? I am not trolling, I am implementing a [search engine in Rust myself](https://github.com/fulmicoton/tantivy/).
Could someone give me the five-second pitch for this website? It's not evident what use-case this serves that isn't already served by [rust-lang.org](https://www.rust-lang.org).
Yeah, that's pretty much what I have now, but `assert_eq` in a unit test is just less strong than a build break. Also it only covers the cases of `Foo` in the unit test. Maybe it works for `i32`, but breaks for some wacky custom FFI type someone else uses it for. Though I realize that's a moot point if the language actually does guarantee they're the same size/layout/etc.
Does this have any concept of folders like S3? Having this combined with locking that is granular to a folder could be really useful I think. At least we use this folder interface on S3 all the time, though I'm sure that and this have different use cases.
I am also a bit confused. Is this more a place for "casual" rust user working with rust in contrast to people working on rust? Or to help building communitys outside of "core" rust (like a servo community if there wasn't already one) I am trying but I don't get it, sry.
Or: code optimized after careful analysis is faster than sloppy code. It's hard to tell.
Most meaningful project name ever. Would steal 10/10.
nice, I haven't heard of that crate - definitely going to check it out!
It is probably full of unsafe blocks but I think it is important to understand that you need to start somewhere but that does not represent theoretical limitations. It is possible that the compiler can be much smarter and eventually it will detect patterns and convert unsafe code to safe code. This is even mentioned in the article.
apart from corrode, finding orphaned but still used c projects to port to rust is a brilliant idea.
Great to see a page dedicated to community. I am bit not sure about submitting pull requests, because the site does not look clearly thought out. It would be helpful to have some kind of vision written somewhere, as well as common use cases this site should solve. This would help any potential contributors to understand more clearly if their pull request matches site goals. As an example, "Resources, Team, Conduct" links at the top look like navigation. However, clicking on any of them makes them disappear or be replaced with something else. Solution here largely depends on the site goals and can be very different :)
Easier to support arbitrary nesting and dynamic locking, I'd guess.
I'm afraid going to Cologne is still not feasible for me, but I can chime in via IRC.
This is a VERY cool project. I'll be tracking it eagerly!
Actually, `unsafe` Rust might very well be safer than C, if only because you get rid of undefined behavior on arithmetic operations, pointer casts (`-fno-strict-aliasing`), etc... That being said, I do think there is a risk for undefined behavior when multiple different mutable pointers modify the same value concurrently. If anybody with more experience could chime in... (/u/Gankro ?)
Hehe, for posterity, as Federico mentioned in the PR, GNOME always used its own infrastructure and GitHub is only a mirror, so always remember to ping GNOME maintainers or they may not see Pull Requests done on GitHub. :)
&gt; It's implementation dependent, that's what is unsafe. Just because it has different byte ordering doesn't make it unsafe. At worst incorrect in some cases. (There is tons of possibly incorrect behavior already.) Do you know about "scopd thread fiasco?" It was that there existed something called scoped thread which was later found unsound because it relied on destructors running. `mem::forget()` was considered unsafe at that time. When someone found out it's actually possible to simulate `mem::forget()` using only safe code (via reference cycle), the scoped thread was deprecated and `mem::forget()` became safe. Same thing with this case. It's easy to simulate the "unsafe" behavior with safe code (`let x: u32 = arr[0] as u32 | arr[1] as u32 &lt;&lt; 8 | arr[2] as u32 &lt;&lt; 16 | arr[3] as u32 &lt;&lt; 24`)
How I can communicate between PowerPC and MacBook using Unix sockets? The last time I researched Unix sockets, they were only able to communicate within same machine... And if you communicate between different machines, then you should be checking your inputs already. That's exactly what heartbleed was. Thanks to Rust, if you forget to check, your process will panic. If you consider this unsafe, then whole Rust is unsafe already. Rust isn't silver bullet to protect you against all bugs. And even if it was, why there is only `File` type and no `RoFile` and `WoFile`? The type system could allow you to safely create `RoFile` and never accidentally try to write to it. Similarly, why there is a `binary_search()` method on `Vec` even if there is no guarantee that `Vec` is not sorted? Do you see it? Many things in Rust already allow you to do incorrect behavior and nobody complains.
I want bytes of `u32` to be accessible as `&amp;mut [u8]`, because that's what `read()` need. If you read carefully, when I want to read into that `u32`, I could do `stdin.read(my_number.as_native_bytes_mut())`. It's the fastest way and also boilerplate-less way.
&gt; No, I'm saying that I don't think it's obvious that an `as_bytes` method on `u32` returns its native byte order. Ok, I admit that better name for those methods would be `as_native_bytes()` and `as_native_bytes_mut()`. That would be more clear wouldn't it? &gt; Maybe it would help if you included a complete code sample of the problem you're trying to solve. It's not much problem, more it's an amusement that such thing is missing in standard library. The problem I was solving was that I had to read `u32` from Unix socket. That `u32` was sent by other process in native endianess. (Nothing to worry about since Unix socket ensures the sending program will be on the same machine.) I didn't want to introduce another dependency for such trivial task. (Also because company I work for is reluctant to introducing dependencies.) So finally I ended up with my own `AsBytes` trait `impl`d for `u32` with those two methods. However, I was thinking whether I missed something in standard library because I couldn't believe it isn't there. Is that more clear now?
Under the current impl that would require a Hashmap where you can lock individual keys (while still being lockless generally). I don't know of any that has those.
&gt; I want bytes of u32 to be accessible as &amp;mut [u8], because that's what read() need. The examples you've been given with `byteorder` are not incompatible with this requirement, so I'm not sure what the issue is? &gt; If you read carefully What am I supposed to read? I'm still having a hard time understanding the problem you're trying to solve. Given how many folks have responded with answers you find unhelpful, I'm willing to bet that I'm not alone. I don't know how to move forward without seeing a more complete code sample from you. &gt; It's the fastest way Really? Are you sure? Is there a benchmark for that? (See other posts in this thread where folks assumed byteorder was "slow," when it is in fact not.)
Thank you for finding out for me that optimizer is that good!
By fastest I meant: "I don't believe there is something faster." Seems like byteorder is equal. Good to know.
I read it as "this is a place collecting resources and best practices for teaching Rust to other people, as well as centralizing avenues for interacting with other Rust users".
On the other hand, Rust makes it easier to write fast code than Go. For example, Go uses copy by default and you have to go out of your way to avoid copies. In Rust, the natural way to code things is also generally the fast way. Go tends to have multiple syntaxes for doing everything, only one of which is efficient. Also, monomorphization in Go requires manually generating copies of your code using an external system, which is very ugly and rarely done. And that's ignoring all the optimizations that the lifetime/ownership system allow which are simply impossible in Go no matter what you do. That being said, algorithms &gt; microoptimizations. If you use an inefficient algorithm, it will be slow in any language.
All of the Rust source code is available on GitHub. I don't remember it ever having sound effects or frames per second, though. (really, this is the wrong subreddit. we write code here, we don't /r/playrust)
I have written such a program before, what I found was that often I needed to add some offset as well as multiply all times by some number (if the fps are off by a tiny amount). Perhaps you'd like to include a scaling feature as well. 
For `winapi` I went with a relatively simple approach to binding COM interfaces. I don't write any custom traits, I just provide the raw interface with inherent methods, along with `Deref` for inheritance, all handled through a macro. For example, I define interfaces like this: RIDL!{interface ID3D11Resource(ID3D11ResourceVtbl): ID3D11DeviceChild(ID3D11DeviceChildVtbl) { fn GetType(&amp;mut self, pResourceDimension: *mut D3D11_RESOURCE_DIMENSION) -&gt; (), fn SetEvictionPriority(&amp;mut self, EvictionPriority: UINT) -&gt; (), fn GetEvictionPriority(&amp;mut self) -&gt; UINT }} Then given a `foo: &amp;mut ID3D11Resource` I can invoke methods as simple as `foo.GetEvictionPriority()` as well as invoking inherited methods such as `foo.AddRef()`. No need for a `com_call!` the way you do. To avoid manual management of refcounting, I've written my own [`ComPtr`](https://github.com/retep998/wio-rs/blob/master/src/com.rs), but certainly someone could write their own. My approach doesn't provide any sort of safe wrappers for the interfaces, but it is fairly simple for someone to wrap a `ComPtr&lt;IFoo&gt;` in their own struct and provide an idiomatic Rust interface. WBEM is definitely in the Windows SDK, so eventually `winapi` will provide those COM interfaces. I just haven't gotten around to it myself because Windows API is friggin massive and bindgen is nowhere near good enough yet so I'm stuck doing stuff by hand. PRs are welcome though.
Given that Firefox is considering the integration of Pdfium, I wonder if anyone has begun implementing a PDF renderer in pure Rust as a less risky alternative. Even a limited feature set implementation like pdf.js would be a great boon, but one of the motivations to use Pdfium is features like pdf forms. PDF has a (very long) spec and multiple open source full featured implementations, so it seems like a more feasible goal than trying to recreate Flash. I cannot be the first one to have thought of a pure Rust PDF engine.
Thanks for the reply. I'm really interested in writing code where I can have Rust help me out. I'm not happy with just a simple dump of the raw structs. I wrote the traits first as they helped me understand the relationships between the various typeclasses (vtbls, interfaces, classes, and their idiomatic rust wrappers). Rust is so awesome ._. They also help preventing errors when screwing up the macros, eg passing a vtbl type where an interface type was expected in the macro results in a compile time error. I like how we both came to the same macro structure: `IInterface(IInterfaceVtbl): IBase(IBaseVtbl)` :D I am highly skeptical of using `&amp;mut self` however, since they really accept pointers and nobody really cares about `const` in C. It just feels wrong to use `&amp;mut self` so lightly. On top of that they are really ref counted (through `IUnknown`) and Rust has its way of modelling types like this, eg `Rc&lt;T&gt;` which uses const references. So a more appropriate signature would be `&amp;self`. I leave that in the open and just go with w/e is defined in the C headers, which is usually `*mut`. These are allowed to alias so that's fine. All `com_call!` does is ensure the same `This` pointer is used for getting the vtbl and passing it as the `This` pointer. Highly unsafe and incorrect things may happen if you don't. As it derefs raw pointers it requires an unsafe block anyway. You bypass this issue by having the raw bindings enforce this, though I disagree with using `&amp;mut self`. I've seen other crates use the same pattern, where `ComPtr` is a struct, but I just couldn't make that work elegantly. My solution turns it into a trait which represents the idiomatic Rust wrapper for the underlying interface. About WBEM: I've also written a nice idiomatic wrapper for [`BSTR`](https://github.com/CasualX/com-rs/tree/master/bstr) (no docs online atm). Provides a borrowed `&amp;BStr`, system allocated `BString` and array backed `BArray` (really not going to pay an allocation cost for what are bstr literals, in theory a compiler may fully optimize the encoding to wide chars and put the result in `.rdata`). Currently working on making a nice idiomatic wrapper for `VARIANT`.
Technically yes, tantivy could probably be integrated with another database (SQL, NoSQL, etc.), but the way to do it would require a bit of thinking. Especially, integrating tantivy commit system with the database journal, and the place tantivy data is stored would require a bit of thinking. I'd be glad to help when such a use case comes.
I uploaded my idiomatic `BSTR` wrapper [here](https://casualx.github.io/docs/com-rs/0.1.0/bstr/index.html).
I've been thinking about this project for a few days now, and I'm incredibly excited at the prospect. Because it's a little complex to visualize, here's my simplified understanding of how it all fits together: * WASM source code arrives in the browser * Spidermonkey ahead-of-time compiles it to Cretonne IR (henceforth CIR) * Cretonne (the backend, not the IR) performs some optimizations (with far different constraints to LLVM, most importantly in that its focus on low latency means a much more specific and less speculative set of potential optimization passes and its focus on security means that none of its passes will attempt to exploit UB) and then converts the CIR into native code Alternatively: * Javascript source code arrives in the browser * Spidermonkey interprets the JS as usual, but when JIT kicks in it converts Javascript to CIR * Cretonne does its thing What this thread is proposing is the following: * rustc does its usual dance up through MIR * Instead of translating MIR to LLVM IR, MIR can be translated to CIR * Creteonne (modified here to produce static libraries) does its thing Advantages to Cretonne: * Being designed for a JIT use case means it has extreme latency requirements, which should be very, very good for compile times (proof that a dedicated backend for low latency is a worthwhile endeavor is that everyone else who has tried to use LLVM for JIT seems to have either abandoned it (Python, Webkit) or sweats blood for it (Julia)) * Designed to minimize undefined behavior, which would address some of our most pernicious LLVM-related unsoundness holes * Already written in Rust, so would work towards a Rust compiler with no foreign dependencies (LLVM is the largest, but not the only, non-Rust code that rustc uses) Disadvantages: * Nowhere near the number of targets that LLVM provides (the big three would be supported, I presume) * Generated code will almost certainly not be as good as LLVM, due to the deliberately reduced quantity of optimizations The ultimate idea is that Rust could provide Cretonne as an alternative backend for its tier-1 targets, and would use it by default for debug mode while retaining LLVM for use in release mode. See also http://cretonne.readthedocs.io/en/latest/compare-llvm.html
Great! I guess you have seen the [winrt](https://crates.io/crates/winrt) crate? It also contains some COM stuff, including a [BSTR wrapper](https://docs.rs/winrt/0.1.0/i686-pc-windows-msvc/winrt/struct.BStr.html). But since Windows Runtime is an extension of COM and uses its own string type (HSTRING), BSTR is only needed in some special cases there. I'm probably going to remove that and instead refer to your crate then (when you have uploaded it to crates.io, which seems to be not yet the case)!
Abstracting the back end sounds good for robustness and future-proofness.
&gt; However, if you can't add a move-aware type, then you can't write an ergonomic, pluggable, precise garbage collection, because pointers can't tell the GC if they've been emplaced somewhere. Every problem can be solved with one more level of indirection? I am thinking that a double-indirection scheme could work quite well. That is, instead of having a pointer directly, you have a handle to a pointer. This is what Rust uses under the scenes for `Mutex` for example, because native mutexes cannot be moved, so instead Rust heap allocates them and you can then move the `Mutex` type around as much as you desire. While the double-dereference is slightly annoying from a performance point of view, it would also allow inner pointers. Many GC'ed languages force you to have indirection everywhere, which has a cost of its own. For example, in Java `[T]` is an array of pointers to `T` and a `class` with a `T` and `U` objects only contains pointers to these objects. On the other hand, if you have the ability to hand out inner pointers, you can have `[T]` directly contains the instances and the `class` directly contain the instances of `T` and `U`. Your `Gc&lt;T&gt;` handle would then point to a record which has: - a `*mut T`, pointing directly to `T` - a `*mut ()`, pointing to the outermost owner of this `T`; it may the be `T` itself - probably some GC-specific fields (for marking, etc...) So, while `Gc&lt;T&gt;` has an indirection, it however allows taking pointers inside value types, which themselves reduce the number of indirections. As for implementing a moving collector, I would expect `Gc&lt;T&gt;` to behave like a `RefCell&lt;T&gt;`: it does not implement `Deref` or `DerefMut` itself but instead returns a guard object which does. This guard object, while alive, would pin the object. It is necessary to avoid concurrent mutations anyway. What do you think? *Note: I would implement `Gc&lt;T&gt;` as `usize` and have it index into an array of such records; thus avoiding double heap allocations. It also sounds cache-friendly... but intuition does not necessarily yield positive results.*
What if I don't?
&gt; Do you know about "scopd thread fiasco?" Yes, I do, if only in retrospect. This is different. No code is relying on the assumption that `mem::transmute(byte_arr, num)` is unsafe.
Yeah, except it's not dangerous to existing safe code.
[Here](https://doc.rust-lang.org/book/references-and-borrowing.html#mut-references) in the book. [Here](https://doc.rust-lang.org/reference.html#unary-operator-expressions) in the reference. It means "the thing this reference is pointing at". It's the same notation as in C. You could also do match result { &amp;Ok(ref items) =&gt; ... &amp;Err(ref why) =&gt; ... } but it's more code, so most people do it the first way.
What is not dangerous to existing safe code?
Nice Pumpkin!
Thanks for the huge write-up. Will take time to digest!
I figured the one on rust-lang.org was the official one. Besides, I figure it would be nicer if there was more contrast between the cog and the hands, because they kinda blur together. But I don't really like the hands.
I think that any PR that improves error messages would be greatly appreciated by the larger community - let alone the maintainers!
If it's of any use to you, my [substudy](https://github.com/emk/substudy) tool has peg-based *.srt parser [here](https://github.com/emk/substudy/blob/master/src/grammar.rustpeg) and [here](https://github.com/emk/substudy/blob/master/src/srt.rs). There might be some code you can re-use.
Rust as a jitted scripting language here we come!
Cool! Now I can `rustup update &amp;&amp; cargo update` (edit: `-a`)
Well, `cargo install-update -a`, because `cargo update` is a `cargo` builtin for updating deps in `Cargo.lock`, but yes, that's roughly it.
I thought of the same thing when I first looked at Corrode, but it turns out that this is infeasible because [libclang's C bindings, which Rust then binds to, are a bit... partial](https://github.com/jameysharp/corrode/issues/50#issuecomment-236096187).
Nice, thank you for this. This is really something I started to miss. There is one feature I think is missing: an option to list packages that need an update, but without updating them. 
You appear to completely ignore `$HOME/.local/share` (I can never remember the exact XDG variable names without looking them up, but I think the variable which falls back to that is `XDG_DATA_HOME`). You really don't want to do that. I had to dig through mailing lists to find a proper explanation of the intent behind the config/data split, but it turns out it's like this: * `.config` is for configuration which may be machine-specific and, while being a pain to rebuild, is replaceable. It's also expected to generally be small files. * `.local/share` is for irreplaceable, machine-agnostic stuff, like user data in tools which don't use Open/Save dialogs. (eg. mail clients, BasKet Note Pads, etc.). It's expected that these files may grow quite large. In other words, your design forces programs to put all data in the closest Linux analogue to the non-cache stuff stored in the non-roaming portion of a Windows user profile.
I think writing unsafe one-liner is the right thing to do. Having seen a couple of "real-world" Rust projects, it's common for each project to have its own special layer of unsafe casts/reads/writes for dealing with proprietary/binary data, and probably some buffer utilities to make them ergonomic. 
Does `cargo install-update -a` update `cargo-update` itself?
It'll try, for it does not discriminate, but it'll fail horribly on Windooze (obviously) and might work on Linux (IIRC you can replace the executable even if it's currently running there).
You are correct that `$XDG_DATA_HOME` falls back to `$HOME/.local/share`. I actually do [use it in `app_dirs`](https://github.com/AndyBarron/app-dirs-rs/blob/a0bae/src/imp/platform/unix.rs#L15), and the `xdg` crate [correctly falls back to `$HOME/.local/share`](https://github.com/whitequark/rust-xdg/blob/6da8930/src/xdg.rs#L242-L244) if `$XDG_DATA_HOME` isn't specified. Isn't that the intended behavior? (I could have messed up the docs somewhere. They were admittedly thrown together hastily; I've got [a GitHub issue](https://github.com/AndyBarron/app-dirs-rs/issues/11) to make a proper table of directories for each platform.)
[💙](https://twitter.com/garblefart/status/791343684268728320)
Ahh, on second reading, I misinterpreted the API. Sorry about that. I can only blame lack of sleep mixed with the unfortunate formatting and low-contrast comment color scheme [here](https://docs.rs/app_dirs/1.1.0/app_dirs/). (ie. I was so focused on not losing my place that I completely missed the enum and mistook the use of `.config` in one example and `.cache` in the other as proof that you were demonstrating "the two different places this crate abstracts", similar to how SDL 2.0 only abstracts one of those locations via `SDL_GetPrefPath(org, app)`.) **EDIT:** This use of whitespace would help the "unfortunate formatting" issue since it'd make the distinction between top-level and "word-wrapped" lines more clear: // Windows: "%APPDATA%\SuperDev\CoolApp" // (e.g.: "C:\Users\Rusty\AppData\Roaming\SuperDev\CoolApp") // macOS : "$HOME/Library/Application Support/CoolApp" // (e.g.: "/Users/Rusty/Library/Application Support/CoolApp") // *nix : "$HOME/.config/CoolApp" (or "$XDG_CONFIG_HOME/CoolApp", if defined) // (e.g.: "/home/rusty/.config/CoolApp")
That'd certainly be doable, but it'd also result in something completely different from what Corrode aims to be. Corrode aims to preserve the structure of the original C as exactly as possible, so that a human can take over porting after the "simple" part (ha!) is done. Perhaps a better option might be writing a Corrode-like translator in C++ (to use libclang directly), but then you lose sum types, etc.
You might consider using time in milliseconds stored in a u64 rather than time in seconds stored in a f64. A millisecond of rounding here or there probably won't matter, but it's a good habit to get into.
Just like `#[macro_use(...)]` you can use `#[macro_reexport(...)]`. This is unstable however.
Yep, there is [cargo-modules](https://github.com/regexident/cargo-modules).
Oh... So I looked up the feature tracking and it seems like it's set to be removed. Apparently, macros are going to just be reexported automatically at some point via pub use, or there is going to be some similar functionality for it... But if it's unstable, then I'll avoid using it. Do you know if there is an alternative other than explicitly defining these macros in the end-crate (C in the example)?
I think cargo is not meant to be a package manager. It's more of a rust make. You see make install but not make update.
This project is really cool man! I like how you talked about the different architectures you used. :) What resources did you use to learn how to make a game? To learn Rust? I've only read a little bit but making a smallish game with Rust is my goal. 
I think struct size can change. When we had drop flags, if `Foo&lt;T&gt;` implemented Drop then `Foo&lt;T&gt;(T)` would be more like `Foo&lt;T&gt;(T, bool)`. Although in that case `&amp;Foo&lt;T&gt;` would not invoke drop and would be ok. But the compiler writers reserve the right to to change struct layout. You should at least throw in: fn fooify&lt;'a, T&gt;(b: &amp;'a T) -&gt; &amp;'a Foo&lt;T&gt; { let ptr = b as *const _ as *const Foo&lt;T&gt;; unsafe { assert_eq!(b as *const T, &amp;(ptr.0) as *const T); &amp;*ptr } } Edit: Or use: #[repr(C)] struct Foo&lt;T&gt;(T); Which has a well defined size and layout.
Cool, it let me know about specs which I wouldn't have known about otherwise. Might be useful for me eventually. Btw in the top of the article you say the project is abandoned, in the bottom you define some next steps. So it's hard to know whether you're going to keep working on it or not.
I suggested it to avoid the problems mentioned (incomplete C API, insufficient support of language standards in language-c Haskell library) and consume the tree in a layer where it's pre-parsed, but maybe that means we're missing information because it's too much llvm ir and less human C syntax. libclang can still be used in C++ with Haskell and I'd imagine it'd be easier than extending language-c to support all the things libclang's C++ API does.
You could use the [`owning-ref`](https://github.com/Kimundi/owning-ref-rs) crate to return an `&amp;str` (created by `trim` in this case) that "carries" its owned string with it, to get the best of both worlds. It would be suuuper overkill here, but it's nice that it's an option :)
Regarding timestamps, you *probably* want the [`chrono`](https://crates.io/crates/chrono) crate. `Instant` and `Duration` are only meaningful relative to themselves.
&gt; I had issues for cross-compiling portaudio from linux to windows so I deciding to use only rust dependencies. I used rusttype instead of freetype and rodio instead of portaudio. (rodio author here) Nice to see someone who is using my crate! When it comes to sound, people usually suggest portaudio or SDL without even taking a look at my crate. Note however that it doesn't support Android or Emscripten. It will still compile, but you will get a runtime error. Android shouldn't be too hard to add, but when it comes to Emscripten unfortunately the WebAudio API is too high-level to be made compatible. &gt; I had some difficulties to use Rodio because I didn't find any example that correspond to my usecase (interactive sounds). However I implemented it in a crate named baal still very unstable. The purpose of rodio is to be high-level and user-friendly, which means that it should cover any non-weird usage. I have taken a look at baal, and most of this stuff could be taken upstream. 
yes! definitely! And I don't care how messy the source is :) I'm also interested in the exact linking options to get the size down. I'm planning to do something for Revision 2017 in Rust. (Btw, I'm also looking for collaborators :)
See my comment on issue [#12](https://github.com/AndyBarron/app-dirs-rs/issues/12). But after reading about [Flatpak directory structure](https://github.com/flatpak/flatpak/wiki/Filesystem) it looks like it modify `$XDG_DATA_DIRS` to allow other applications to find .desktop files, installed apps' icons, etc. In this case returning all paths is necessary (edit: but it's Linux specific use case).
I used the Rust Book and Rust-by-example to learn rust. to make a game : * [arewegameyet](http://arewegameyet.com/) at the time it didn't exist but it is cool, * [amethyst](https://www.amethyst.rs/) was very inspiring to me even if I prefer create my own *engine* which is based on glium (opengl) + rodio (audio) + gilrs (gamepad) * [games in Piston](https://github.com/PistonDevelopers/piston/wiki/Games-Made-With-Piston) where I discover lazy_static. 
thanks! i'll read it
Judging from the path to emcc, you're running version 1.35 of emscripten instead of the incoming branch. This is fixed with `emsdk install sdk-incoming-64bit` and `emsdk activate sdk-incoming-64bit` like the guide mentions. 
Cargo is a lot more than make. It handles updates for libraries. Why not for binaries as well?
jemalloc, libbacktrace (IIRC), libc (duh), and probably some random assembly snippets.
Okay so I first started writing an srt time adjuster because I had subtitles that didn't match some video. At first I thought it was just a problem with offset, so I added/subtracted some value from all the times and hoped it would work. At the start of the video everything would be fine, but towards the end the subtitles would be off by seconds or even minutes. So it turned out that the video was playing at the wrong number of frames per second (or perhaps my video was correct and the video of the one who created the subtitles was incorrect). You wouldn't notice when you were watching without subtitles, because playing a video 1% faster or slower isn't something that humans notice. But it makes a huge difference when it's a two hour movie, because a 1% difference between the subtitles and the video translates into a 1.2 minute difference towards the end of the movie. In the end I had a tool where I would input four timestamps: &lt;start of some phrase in the video at point A&gt; &lt;start of the same phrase in the subtitles&gt; &lt;start of some phrase in the video at point B&gt; &lt;start of the same phrase in the subtitles&gt;. If you pick A near the beginning of the movie, and B near the end, then you can easily calculate an accurate offset and scalar for all the timestamps in the srt file.
This is already happening with rustc being written in Rust :) The first step of building rustc is downloading pre-compiled binaries for a previous version of rustc. This leads to fun things like ["When a string contains `\` followed by `n` insert a newline, which in Rust is spelled `\n`."](https://github.com/rust-lang/rust/blob/ef6f74340762f145f780aeb1b549030bd84c5beb/src/libsyntax/parse/mod.rs#L303) But nowhere in the compiler source is it written that `\n` is byte 0x0A !
Not too sure about the hands myself, to be honest. My first thought about seeing the picture was to instinctively retract my own hands as if they were going to be scraped by the cog :/
To me this talk about using Cretonne for rustc seems premature, looking at the current state of Cretonne ("Cretonne is a work in progress, and it can't do much of anything at the moment"). Maybe I'm overestimating the work, but seems like even experimental rustc support would happen earliest somewhere in 2018.
Thanks, I was accidentally using the command from the SDK install instructions. I deleted the install and used a fresh zip extraction. Then I ran the correct command in the VS dev console but I got errors: http://dpaste.com/2K52NBF#line-34 For the record, cmake could always find the compiler before when I used it for C libs to generate MSVC projects. So why isn't it working here?
http://kripken.github.io/emscripten-site/docs/getting_started/getting_started_with_emscripten_and_vs2010.html &gt; Visual Studio 2011 and 2012 are not supported. 
You're asking the choir if they believe in god.
and what answer is that in a non-figure of speech manner
I presume, you're saying yes for me to replace C++ with Rust. But more replies gives me more motivation and reasoning so i shall wait.
I come from System based programming mainly, i tried Web based but never enjoyed it. I'm passionate about this and people who take time to write as much as you have means a lot. Thank you.
I see, well i don't mean settle as in just learn Rust and be done. I do intend to learn more than 1, 2 even 4 languages. Since I know, a true programmer knows more than one language.
It's a bit sad to see the news about something being abandoned... For the code, you should never need to do stuff like `.with::&lt;PhysicState&gt;(PhysicState::new(pos))`. Why not just `with(PhysicsState::new(pos))`?
If C and C++ are the languages you are the most familiar with, I think Rust can be a good choice. Coming from this background I'd think it can even be a way to have an introduction to some concepts of functional programming that feels more "gentle" than e.g. Haskell (at least that how I felt it). Since the major difficulty in learning Rust is (imo) the memory management, borrow checker and all that stuff, if you already know the basis from C(++) it shouldn't be that hard (and while the borrow checker can be annoying, I think it's actually a good tool to understand those concepts better for later programming in languages such as C/C++). So, yeah, I think it could be a good choice, unless you love object oriented programming (which Rust doesn't really have).
now you've said that I don't know why I ever write with the explicit type ...
Well, this is what webrender does at the end. Output bitmaps.
I'd say you'd have to try it, I like the lack of garbage collection, and coping with the compiler hasn't been (yet) as hard as all the doc's make it seem - but then I've really not done more than scratch the surface as yet... but yeah, you defiantly have to try it for yourself... (with some kind of concrete project)
Think I'll give it a go. I do like memory management. And no garbage collection. I'm very fond of freedom. It's why I don't like engines such as unity or unreal even game maker. 
This sounds great. I could host a space in NYC. Would there be any interest in that, even if it's outside of the time zone range?
Awesome. I'm impressed how much time &amp; effort goes into *production* (as opposed to just hacking stuff together as we did in my days) – and it shows.
I highly recommend using WebRender. We even had a proof of concept port of pdf.js to use WR as the backend and it worked great.
Once you're offering to install things, you need to commit to updating them. Anything else is irresponsible.
You were probably looking for /r/playrust.
&gt; When it comes to sound, people usually suggest portaudio or SDL without even taking a look at my crate. Sadly in open source world there is no alternative to OpenAL-soft if you want 3D audio with fancy effects and HRTF. IMO kcat outstanding work on library is a bit wasted by OpenAL API.
You ought to be aware that you have to understand a lot of things to use rust effectively. It mixes imperative with functional concepts and you always have to keep lifetimes at the back of your mind. I really like rust exactly because of these things but it also means that it might be more difficult to get started with than, say, c or python. Learning some variety of languages can be really helpful to approach problems from different perspectives. I am really glad that I used both haskell and c for a while, for instance. That said when starting out with programming it probably is best to stick with one language until you are comfortable. Basically everything apart from syntax will transfer between most languages anyway. If rust is the language you stick with for a while that is great but that decision probably won't make or break your learning process. Finally I can really recommend exercism.io to get comfortable with a language. The problems are all overseable enough to focus on the implementation details and the constant feedback and examples really help.
That's cool. To learn rust I'm building an id3 reader from scratch. It's not too challenging so far and will help you learn some low level stuff
[Reffers](https://github.com/diwic/reffers-rs) is another useful crate along similar lines.
Ty
If you check out the gallery, you'll see that I used a flashlight and a metal Ferris that /u/kibwen made to get the design onto the pumpkin, haha :3
YESSSS also let it be known that creating Ferris out of Ferrises has already been done!! http://imgur.com/a/4fnjg
Ah right, I guess in some cases avoiding that explicit lifetime would make things easier, but since your sample has a lifetime binding available it could be less of an issue to use lifetimes right down to the `Token`. I should spend some time with `arrayvec` too.
Right, that's what I read. And there's the fear that by doing any work on expanding the `$crate variable`, then they'll essentially worsen the already fragile `macro_rules!`. Apparently, they're working on some sort of alternative to `macro_rules!` that'll actually be stable? Dunno, but I hope so. :/
Not sure whether you've come across corrode, but it might help you automate the process somewhat: http://jamey.thesharps.us/2016/07/translating-c-to-rust-and-how-you-can.html
In the future, glance through a subreddit's front page at least once before posting to it. If you don't understand the posts then it's probably not on the topic you expect. (Rust the programming language predates Rust the game, so /r/rust was taken by the language first).
It mighty be worth mentioning the existence of https://github.com/Hoverbear/raft-rs to avoid confusion.
[`llvm-safe`](https://github.com/gereeter/llvm-safe) is my attempt at safe bindings to LLVM. At this point it is really more of a personal project to be used in a compiler/language I'm working on, so I can't promise that it will suit your needs, and it certainly isn't close to complete - I've been just adding things as I need them. Similarly, I haven't put much effort into documentation. For this reason, I also haven't published on crates.io, though I'd be happy to if there is interest. With all those disclaimers out of the way, `llvm-safe` has a number of nice properties: - It is completely zero-cost. - It actually enforces a bunch of finicky assumptions that LLVM makes. For example, it prevents mixing values between different functions and calling functions from different modules.
oh...Thanks :P 
Bad idea: /// TODO. Or, in some ways worse: /// Adds an item. fn add(&amp;mut self, item: T) { ... } 
If nothing else, this would cause issues for the many existing crates without documentation, who would likely be pretty upset at the sudden requirement. Beyond that, I don't know that a hard rule will get good documentation. The missing docs lint can't check quality, and quality only comes when the crate maintainers really care about making it happen.
Are there any rustaceans with access to atomic force microscopes? Can we have a Ferris made from individual iron atoms or something?
I used llvm-rs for a while, then gave up and rewrote everything with unsafe blocks calling the c API directly. Llvm is finicky and it seems like it would be pretty difficult to encode all the important properties of the API in some wrapper, so i ended up having more trouble checking for the behavior I wanted and the guarantees I wanted with a wrapper than with unsafe calls. I haven't looked at llvm-safe though. 
On the opposite end of the spectrum, take a look at [my most recent work](http://www.starhop.com/library/images/photos/crab-nebula.jpg).
I generally agree with the other comments here, and I'd like to throw in an alternative suggestion, too: focus on trying to help people write good documentation where it's lacking instead. Not everyone is good at writing documentation, or has the time to do it well, so finding ways to help people write good docs is probably going to be more fruitful than telling them off for failing to do it themselves. This could make up part of another idea I've been toying with recently: a different spin on "crate of the week". Either the Rust subreddit or the Rust community more broadly could have a "random acts of contribution" system, whereby a project gets chosen at random each week to receive focus from the community. This could start with popular library crates, or crates that someone nominates as needing a particular kind of love, and then move to a more automatic system. It'd probably be best to get advance consent from project authors; I imagine not everyone would appreciate a swarm of overly-helpful Rustaceans landing on their doorstep overnight. :) Over time we could build a checklist of suggested helpful activities. I'm imagining that if I want to do a tiny little thing to help out the Rust community but I'm having trouble deciding how to spend my spare hour, then I'd be able to check some page to find what the current "project of the week" is, skim down the suggested tasks to find one that I could reasonably do, and then go off and do it. Examples might be: - Review subset of documentation for misleading information or typos. - Find a function or module that could benefit from documentation, or more comprehensive documentation, and update it. - Update dependencies. - Run rustfmt. - Run clippy. - Improve the README to better communicate what the project is, and who might be interested in it (according to yet another checklist). 
I don't agree with the quote &amp; didn't know other people felt that way. The impl shown is poor style (5 does not have an area of 5), but there are perfectly valid traits to implement on primitive types.
Such is life. I very much appreciate the excellent Windows support from Rust (one major issue is less than stellar PDB support, but LLVM is at fault here).
My understanding: * Ready: http://stackoverflow.com/questions/39942263/how-to-handle-errors-in-mio/40272111#40272111 * PollOpt is just like a bitmask so all `is_*` just check if a given bit is set * edge vs level: http://stackoverflow.com/questions/1966863/level-vs-edge-trigger-network-event-mechanisms * oneshot, you need to reregister every time it was triggered * urgent - I'm guessing, will be delivered as first one when multiple events are returned from one `Poll::poll`? * all/empty - all bits set, all bit empty? I used to set `O_NONBLOCK` manually: https://github.com/dpc/colerr/blob/master/src/main.rs#L59
As with the others here, I don't agree with that line. The rules around coherence mean that there's little harm one can do with implementing new methods on primitive types.
I have never heard of that, the orphan rules mean that there is essentially no reason to not implement a trait if there is a meaningful definition for it for a type.
It's funny you say that about Haskell, I tried to get into Haskell and didn't really like it or see the appeal, but after learning Rust I started to notice it being mentioned often around here and in blog posts about it, gave it another shot and instantly fell in love. Although now I know what I'm missing when it comes to HKTs, which is a shame.
TL/DR: Because newtypes. If you have a *special case* of ints or strings, that you want to implement a trait for, then that special case should be wrapped in a newtype, e.g. `struct Area(u64)` or `struct DatabaseId&lt;'a&gt;(&amp;'a str)`. You can then implement your trait on that newtype. The primitive type itself should only represent the most general case, so you should only implement a trait for `i32` if every single `i32` in every Rust program ever written could have use of that trait. And to be honest, if such a trait exists, then that trait belongs in the standard library or the `num` crate anyway. Well, that's the theory anyway. I have implemented traits for primitives too, since it can be quite practical. But if I were writing a crate for others to use, I can't really imagine a case where I wouldn't use a newtype instead. 
 if you could just compile anyStruct.anyMethod() and rust would panic if anyStruct didn't have an anyMethod, then traits wouldn't be needed at all ? dynamic (late binding) vs static (static dispatch) the point of rust existing is to reduce the risk of stuff crashing at runtime (while doing system-level programming), thus static type checked dispatching is being favored. if you don't mind the occasional runtime crashes much there is almost no reason to use rust, smalltalk/clojure/ruby etc. would do a better job for the problems you're dealing with. if you want full late-binding OO (a-la-smalltalk), then you lose the systems programming aspect of rust, (you need to box everything, maintain runtime types, heavy use of GC etc.). The closest you could get of system-ish real-OO-ish might be CLISP with CLOS but i don't know much about it. ------------------------------- on a more *programmer aspect*. the traits documents the points of extension of a library (and also help your IDE give you better feedback). through traits it gets easier to integrate libraries together and have (a little bit...) more certitude that things won't go south at every single update.
It's in the book: https://doc.rust-lang.org/book/structs.html. Maybe also look at https://aturon.github.io/features/types/newtype.html, but there's an awful lot of FIXME's in there.
There's a huge problem with newtypes, you can't really use them with containers of T without transmuting your container to a container of Newtype(T) or completely reconstructing your container, and wasting a lot of performance. So I think it's absolutely reasonable to implement your traits on T directly. Unfortunately that's not always possible (if you didn't define T or the Trait in your crate). In that case Rust doesn't provide a good solution at the moment unfortunately :/
You might be interested in /r/DailyProgrammer, if you're not already on there :)
I don't get it. What if your trait applies (among other types) to numbers in general?
&gt; What if your trait applies (among other types) to numbers in general? Then implement it on numbers directly? (The GP started with, "If you have a *special case* ...")
I've just been putting `&amp;`s in front of my match arms, never occurred to me you could do that! All those wasted keystrokes...
I'm writing a VGA driver. The VGA spec uses a pair of u8s, and technically every single u16 (2xu8) is a valid VGA element. However, I'm not implementing VGA methods on u8 or u16; I'm making new types that are strictly around them, and implementing methods on those. It winds up all coming out to the same ASM, but it's to tell you and the compiler why you're doing what you're doing, and to maintain *semantic* cleanliness. 
In [x1b](https://github.com/serprex/x1b/blob/master/src/x1b.rs#L82) I implement the RGB trait for () &amp; (u8, u8, u8) but opted to wrap a u8 for 256 colors. The last one has 3 distinct regions of colors (0..16 backwards compat with 16 color, 17..232 base-6 RGB, 232..256 24 shades of gray)
&gt; while &amp;self to *mut $interface is dangerous and unsafe. The "safe" version of going from &amp;self to *mut $interface is to put the $interface inside an `UnsafeCell`. Maybe that's what needs to be done here?
Rust's traits are much more powerful than interfaces. What you're suggesting is more akin to Go (though they have some static checking) The type information can be used to implement [mixed type containers with full information at compiletime](http://nercury.github.io/rust/interesting/2015/12/12/typed-arrays.html) Does your object oriented coding even powerful enough to [brainfuck](http://pastie.org/9757227)? I guess what I'm trying to say is that traits are there for the compiler to be there for you (at no runtime cost to boot) If you're itching for more OOP dynamicness, consider something like [specs](https://github.com/slide-rs/specs)
I don't I have all the anwers, but I can give some additional info at least: 1) I've found `PhantomData&lt;&amp;'static T&gt;` as the least intrusive one so far, it does not add any additional lifetimes, nor ownership. 2) PhantomData is also used for trait bounds. That is, `struct Foo(i32)` can be sent between threads, but `struct Foo(i32, PhantomData&lt;Rc&lt;String&gt;&gt;)` can not, because the struct no longer implements `Send` (`Rc` explicitly bans `Send`). 
Is there a Markdown _generator_ somewhere too? 
Is this syntax compatible with ReST? I prefer that format and having an ASCII diagram prettifier like this supported by that format would be awesome.
I think that he meant that the compiler would panic at compile time if `anyStruct.anyMethod()` didn't exist, not that Rust would panic at runtime.
Nope. Totally cannot be done. `$interface` is an opaque type, with an unknown size and unknown contents, only the first field, the pointer to the vtable, is known. As a result, it must always be worked with behind a pointer and Rust can never ever work with it by value, meaning `UnsafeCell` is out of the question. However, I have been considering another solution. If I wrap `*mut $interface` in some sort of `Com&lt;$interface&gt;` wrapper and impl the inherent methods on _that_, then I'd always work with the interface behind a raw pointer, while also being able to have the inherent methods take `&amp;self`. I'd also be able to provide convenience stuff like `Drop` and `Clone` on the wrapper. Although then I'd also want to provide a better version of `QueryInterface` which means I'd need to have a trait that all interfaces implement which provides their IID.
&gt; When I wrote it, I remembered writing stuff like Rust is surprisingly expressive, which got a really, really bad reception. People really don't like putting DSL-like methods on primitive types. I'm not surprised by this, but I like `2.days().ago()`. :-)
This is pretty cool. Maybe if this project evolves steadily for a couple years people might consider translating non-abandoned projects in order to improve safety and maintainability (glibc for example). But that would require whole other level of stability, completeness, correctness, and commitment. But who knows. Great software tend to have those, and this sounds like a great piece of software.
Good suggestion; updated the readme.
Thanks, fair point. I wrote this more for my own edification than with the intent for it to become a general purpose Raft library. I'll try to direct it that way over time, but I'm fine with the initial release being self-contained, so to speak.
how does one convert: * (from) std::env::Args * (to) Vec&lt;&amp;str&gt; or &amp;[&amp;str]? I am just trying to pass arguments to child process...
I don't see how that would provide anything different from what traits currently provide, other than drastically inflating compilation times since you'd have to perform a global program analysis on every generic function call.
That does seem like a valid use case then - the documentation probably should be clearer.
&gt;The impl shown is poor style (5 does not have an area of 5), but there are perfectly valid traits to implement on primitive types. Even the standard library has some questionable methods on primitives. For example `f32::to_degrees()` - how do I know that this number was in radians to begin with? 
I was already experimenting with asm.js and this will be so much better. I can't wait for browser APIs to become available to wasm directly!
No problem. Had the same question. I was hoping that this would be a replacement to pulldown-cmark. I think pulldown-cmark does the job spectacularly but it's lack of maintenance is a little concerning to me. Then again, maybe it doesn't need it!
I don't really find that questionable, so perhaps you sit on the other side of the fence from me on this. :-) The degree to which these types can be said to carry meaning (in contrast to information) is very ambiguous.
Not that I know of, but you could potentially start with [bincode](https://github.com/TyOverby/bincode) and use [leb128](https://crates.io/crates/leb128) for your variable-length integers.
That sounds really useful. I've got no idea if one exists but I totally would use that.
Protobufs are pretty compact if you can deal with the added complexity. [general info about protobufs](https://developers.google.com/protocol-buffers/) | [rust implementation](https://github.com/stepancheg/rust-protobuf).
Thanks. But damn, all those derefs and borrows :)
Cool, thanks for the insights. Yeah, I'd love to hear more about this. I read your writeup, which was great, but it would be really cool to see the tool in action too. Also this inspired me to actually write some rust code this weekend, so got a few more instructions implemented for my gameboy emulator (learning project). I really, really like it, and think there's a good chance I'll fall in love with this language. 
&gt; let mut file = File::open(args[0].to_string()).unwrap(); &gt; let file_metadata = file.metadata().unwrap(); gives me a FileType but I can't see a route to putting that as String. Is there a simple option for converting FileType to [mime::Mime](https://crates.io/crates/mime) or a String type? The other end of a [request](https://crates.io/crates/request)::post that follows, I wonder is wanting something mapped to nodejs/mime/1.3.4
What ever happened to that Asm.js WASM-&gt;Asm.js compiler? Does that still exist as a thing? I thought that was supposed to be the bridge between old and new browsers supporting WASM.
The author said he'd be more willing to make changes once CommonMark is 1.0, so he's not playing catch-up with a spec that keeps changing out from under him. 
`FileType` implements `Debug`, so you can do `format!("{:?}", file_type")` to get a `String`.
Check this post out: https://users.rust-lang.org/t/compiling-to-the-web-with-rust-and-emscripten/7627
Oh, I was trying the demo just minutes before, read all the non-goals, the comparison to persona and all the things I saw, but I didn't realise the broker was in Rust until I came back to reddit and saw it on this sub. Good work. I'm interested to see what comes out of this :)
Oh, great. I did not know that. Seems I made a silly, premature assumption.
hmm.. so that does work as String but gives not anything like the Content-Type I was expecting. &gt; file_type: "FileType(FileType { mode: 33188 })" response for both a .txt and .jpg
It's fun how people sometimes talk about how Rust's lack of OOP lacks the ability to implement a GUI API, yet here we are
Some more commentary on Phoronix: https://www.phoronix.com/forums/forum/phoronix/latest-phoronix-articles/908188-should-gnome-begin-replacing-more-c-code-with-rust Though it's not too constructive, some people saying "Yay!" and others saying boo, gnome!
[What do you think about this?](http://gamedev.stackexchange.com/questions/16644/what-are-the-best-ways-to-serialize-and-unserialize-network-messages-for-c-c-m#comment25780_16788) (and the replies to that) Also I don't really care about versioning because server and client will always use the same protocol version.
metadata is filesystem-oriented, that is: file, directory, link... Mime is about file content, usually when exchanging files (mail). You can't get the mime type of a file that way. Only thing you can do is guess it from its content (see the `file` command on Linux, or this rust library: https://github.com/abonander/mime_guess). You can also try to guess it by the file's extension, but it can be spoofed easily.
Why?
This looks promising! I've been hoping something like this would appear for a while. Thanks for posting.
The more I think about it the more I think that `f32::to_degrees()` is no better than `f32::area()`.
Please, be constructive.
Every few months, WebAssembly crosses my mind again and, with cautious optimism, I check their website to see if it's close to being an implemented thing yet. Still a little too bleeding-edge for me, but we sure are getting closer!
I don't think anyone has *ever* thought Rust can't do GUI. It can, it's just a huge PITA relative to almost every other contemporary, mainstream language. From my limited experience thus far, I think it's more that Rust doesn't have good tools to replace the tools OOP gives you. For example, you can't implement methods on `Rc&lt;Self&gt;`, so it's a *huge* pain in the backside to do anything with object graphs. There's no fine-grained behavioural inheritance: I can't define "base" functionality and then override individual components without a crapton of boilerplate. I think "OOP" is a red herring: I believe it's fundamentally about the mechanical tools OOP gives you, not OOP itself. **Edit**: and before someone *inevitably* says it: *yes* you can work around these limitations. The issue is that it takes significantly more effort to do this in Rust than in (laundry list of contemporary mainstream languages).
I would like to hear more if you can expand on that 
Disagreeing with something doesn't mean that what you disagree with is not constructive. Your comment is not constructive. It is, in fact, highly insulting towards me. What I've stated is a widely established computer science fact.
What's there to expand? It should be common knowledge. Here's a hint: cache misses, cache misses everywhere.
On the other hand it's a (start of) a discussion about using Rust to replace C, which isn't exactly well known for its great support of OOP either, so the bar isn't really that high ^^ 
ReST? you mean rest api? I don't know any Rest associated with diagrams. If it there is, then it is using a bad name since Rest commonly refers to the http rest api.
Not who you are responding to, but there has a been a huge shift towards stateless components in javascript (redux + react for example). The amount of side effects that occur with OOP and similar practices becomes untenable when dealing with UI state. I agree with him that OOP is not good for UI work, but probably for different reasons (not at all a performance issue).
There is a way to implement methods on types wrapped in `Rc`. The GTK-rs wrapper actually does this.
&gt; After you finish the emsdk activate step, you have to manually add the emsdk_portable/emscripten/incoming folder to your $PATH On MacOS, I needed this additional instruction from lower in that thread.
*Deep breath.* &gt; The issue is that it takes significantly more effort to do this in Rust than in (laundry list of contemporary mainstream languages).
I wouldn't say that it takes significantly more effort to create methods for types inside `Rc`. It's no more difficult than any other type.
GNOME adopting rust is an amazing possibility. I might be willing to contribute to a GObject binding generator. Has anyone planned out how one should work, and how do the existing ones work? Does GObject have an interface definition language?
That's just outright not true. You can get around it, *yes*, but that involves defining a trait for every type that's supposed to only be used inside an `Rc`, which means specifying every method twice *and* needing to import both the type and the associated trait everywhere, *which is significantly more effort than you would need in another language.* I have *agonised* over this. Rust *does not* have a good solution here: it's a choice between wonkiness on the user's side (extension traits getting everywhere like a virulent pox), or on the implementation side (needing reflexive objects to go from `&amp;T` back to canonical `Rc&lt;T&gt;`).
Wait, so you *already* posted this to /r/playrust, and decided to spam a totally unrelated subreddit anyway?
I sometimes think OO is poorly named. What really differentiates rust from C++/Java style OO is how behavior is inherited and how data and code are composed and abstracted. In essence you still have data "objects" that you make calls to, that you can use to represent real world objects. My gripe with Java was always the mess that inheritance eventually caused growing code bases. In addition to just other things relating to that object system. I've always been more of a C guy with interest in functional programming. Rust basically hits most of my interests. It's not OO in the traditional sense sure, and I love it exactly for that. But you can still represent everything that you want. And now you don't have mutable state hell to deal with.
You are looking for /r/playrust.
The purpose of my comment is not to provide a 'reasonable explanation'. This is not the time or the place for such a discussion. The purpose of my comment is merely to be a simple comment. I am not here to educate you on computer science, but to iterate that OOP is not the be all solution that many people make it out to be. The reality is quite different, in that OOP codebases are rife with redundancy and performance complications. For each method that you implement for a class, you increase the amount of cache misses exponentially. AAA game engines struggle immensely with the fact that their C++ code is largely OOP, and a significant portion of CPU time is wasted dealing with cache misses, especially if you're using an AMD processor which does not feature large caches. You may not experience much performance difference with smaller applications that are written with OOP, but the larger it becomes, as in a GUI API with an increasing amount of functions, the greater the occurrence of cache misses. In the end, GUI's written without OOP will have much less cache misses.
Thank you so much for this comprehensive answer! The legend of the Rust community's hospitality is true. From your response and what little I know of Rust so far, I take it if I can get to stage 1 I can run a proper "Hello World!" on my target? A few major questions, 1. you mentioned using `cargo-build` to build `core` crate and `std` crate. How do I go about doing that? Is there a `make` option or should I do something like [this](http://stackoverflow.com/questions/28031806/cannot-link-against-core-library-when-cross-compiling)? 2. Once I have `core` and `std`. How do I incorporate these libraries into `rustc-stage1`? 3. I assume `configure`'s option `--target` is the triple rustc feeds to the LLVM backend? So it should be the same as the existing triple on LLVM for my target? 4. What's the different between `configure` options `--host` vs `--build`? Sorry if I asked previously answered questions, you can simply tell me where to look for the answer if responding is too much work. And thank you once again for your lengthy reply! 
To my knowledge, you would have to either destructure the tuple, like so: ``` let (a, b, c) = old_tuple; let new_tuple = (a, b, c, new_value); ``` ... or index it, like so: ``` let new_tuple = (old.0, old.1, new_value); ``` 
That's kind of what I was afraid of. I think it might be good for Rust to expand its tuple story around things like this, especially since features like [`unboxed_closures`](https://github.com/rust-lang/rust/issues/29625) seem to be looking to tuples as a solution for variadic generics. Looks like there's [an RFC](https://github.com/rust-lang/rfcs/pull/1582) for a similar feature.
Yes! :) We'd love to have you!
I [once added i686-linux-android support](https://github.com/rust-lang/rust/pull/27957) to rustc. Basically if your target triple is officially supported in recent LLVM versions, the only thing you need is to add some platform dependent definitions to libstd (and maybe liblibc etc). `--build` is the platform on which a prebuilt compiler *builds* your cross-compiler (rustc). `--host` is the platform that will be used to *run* your cross-compiler. `--target` is the platform that runs your cross-compiler's output. `configure` by default has`build ?= current-machine; host ?= build; target ?= host`. So in your case you just need to set the target to be your new platform's triple.
Does gnome run on any platforms not supported by rust?
Which is, for example, what Alan Kay would say. OOP in pre Smalltalk-80 was all about async messages
You could use nested tuples with a helper macro, like this: macro_rules! tup { ($head:tt) =&gt; ($head); ($head:tt $(, $tail:tt)*) =&gt; ( ($head, tup!($($tail),*)) ); } fn doopy(args: tup!(f32, f64, i8)) { let tup!(a, b, c) = args; println!("{}, {}, {}", a, b, c); } fn main() { let vals = tup!(3.4, 2.2, 7); doopy(vals); assert_eq!((3.4, (2.2, 7)), vals); } You'd want to improve the macro, though, as that one will accept only single token trees. It won't work with something like `&amp;str` or `6*2`, for example. But, if you do it this way, then you can expand a tuple with `let new = (val, old);`
I've always found that sort of Ruby-esque "monkey-patch the world into primitive types to follow natural english" to be unappealing. ...however, given that Rust is a compiled language with a powerful optimizer, one of my main reasons for hating it (the potential overhead) is gone. I do still think it's ugly though. In my opinion, that kind of "massage the syntax to look like natural language" results in leaky abstractions where you eventually bump up against the limits of the trick used to implement the DSL and then start to lose your certainty that your language intuition is correct.
now i get what you mean, thanks!
GNOME only runs on Linux, due to systemd dependency. Of course, there may be architectures that GNOME does support, but Rust doesn't.
I'm not entirely clear which platforms GNOME is supported on and [this page regarding GLib](https://wiki.gnome.org/Projects/GLib/SupportedPlatforms) is unclear whether it's listing "supported now" or "want to support" entries. However: * "Debian on Hurd" seems to be the only GLib OS entry not on the Rust [platform support](https://doc.rust-lang.org/book/getting-started.html) list. * That list for GLib claims they'll only support what they can test on, which means that Rust's support for targeting i686, x86_64, all major ARM variants, PPC 32/64/64LE, and MIPS in both endiannesses should be enough.) (Conversely, that GLib page doesn't list support for iOS and Bitrig while Rust does.) That said, Wikipedia claims that they only target Unix-like systems running X11 and Wayland and I remember hearing that part of GNOME depends on systemd APIs. (systemd intentionally only supports Linux so they can depend on APIs like [cgroups](https://en.wikipedia.org/wiki/Cgroups)) Also, given how much less portable things like the GNOME control panel would **inherently** be than individual user applications with no need to manipulate platform-specific APIs, I doubt they enforce the same standard of portability for all packages.
&gt; people don't notice it when there are delays of up to a few dozen milliseconds So, a few seconds? I think I'll notice that delay :D
This is absolutely not true. GNOME runs on [OpenBSD](http://cvsweb.openbsd.org/cgi-bin/cvsweb/ports/x11/gnome/#dirlist) and [FreeBSD](http://www.freshports.org/x11/gnome3/) for example.
Yeah there's a German word for it as well, looked it up after your previous answer cause I was confused \^\^
Sure, its not an area we can focus on, but we won't block anyone from participating and support them as well as we can :). \o/
I wonder how useful it will be to run wasm on the server side as well as the browser. Whatever wasm-rooted ecosystem you use on the browser could also be used on the server. Although, anything that can compile to wasm shouldn't be hard to compile to native, so maybe it's not necessary on the server. Regardless, I'd really love to see wasm become the "fixed" version of the JVM for cross platform development.
That would make a lot of sense on IoT platforms.
GLib is just a standard library used by GNOME (but can be used by other unrelated projects too) comparable to STL in C++ or Rust standard library. It doesn't do anything with GUI (in fact, it was non-GUI parts extracted from GTK+). As such, whatever it supports is not what GNOME desktop environment supports.
`qt quick controls` does look like native'ish, is it not? Yes it is not 100% as if you really code with wpf, cocoa .. but i would – at leas hope – 95'ish% of users couldn't tell
It's completely independent of the OS's widget styling in the same way that something like Electron+Bootstrap would be and the provided styles are designed to fit in on smartphones and tablets more than desktops. It only *just* gained some form of support for reading and mimicking the OS's color scheme so users won't get upset about your application being the lone dark-on-light or light-on-dark application in a desktop configured for the opposite. Maybe I'm just especially picky, but I try to avoid such "special snowflake" applications unless there really is no suitable alternative. (I find their distinctiveness distracts me from the content I'm supposed to be focusing on.) **EDIT:** Now that I think about it, I think I remember something about Qt Quick Controls 1 trying to replicate QWidget's ability to match the system theme, but they threw that out in Qt Quick Controls 2 because the OS APIs are apparently incompatible with Qt Quick Controls 2's scene-graph architecture.
That's what you should expect from a forum where most people are not programmers.
It is probably more readable to use conversion methods. let args = args.iter().map(|s| s.as_str()).collect(); // or map(String::as_str)
Let's hope they'll contribute on gtk-rs now. :D
you cant edit the title and the question should've been the title
&gt; but they threw that out in Qt Quick Controls 2 Oh, i was not aware of this! I guess i never touched QML really since `Qt Quick Controls` "1" as i had no project that needs a Desktop-GUI since then.
Hey mmstick. This is the worst part of the Rust community. You'll notice that Mozilla's policy regarding safe spaces in in full effect here. I recommend avoiding this part of the internet and maybe come check us out on matrix, far away from Mozillas bullshit. You're right, that you can say anything you want, and that the person who's boohooing over it is being less constructive than you. However since "safe spaces" take precedence here your opinion means nothing and the bandwidth you used makes you literally Hitler. They could have just downvoted but everybody who has feelings here is a mod. Here comes Manish about how unreasonable I am, and how his feelings are hurt, if you keep it up long enough they'll come lock the thread and there's an 80% chance a new maymay will be formed. 
Cheers, still got a bit of a way to go, before most of the needed components, documentation and examples are in place. Then it can be used in anger 
Here's their feature comparison chart: https://doc.qt.io/qt-5/qtquickcontrols2-differences.html#feature-comparison-table ...though, for some reason, they neglected to include rows explaining the advantages Controls 2 has over Controls 1, so that chart makes it look like Controls 2 is either equal or inferior rather than aiming for a different niche.
Faster than C? Am I reading the chart right? "Throughput Compared to Native" The web assembly speed for 'skinning' is faster than the 'clang -O2' speed. Is this an error? How? 
https://en.wikipedia.org/wiki/Angular_unit Radians and degrees aren't the only ways of measuring angles. Sure, they're the only ones in popular use today, but why would you bake that into a language that will be in use for a long time? What if other methods of angle measurement become popular in the future - won't that be confusing for people using Rust? Plus, there's the fact that floats don't need to know about angles at all, and thus shouldn't.
TracingJIT's are a powerful optimization tool. The real strength lies in branch optimization and Instruction Cache layout. So your never making long jumps. Basically Profile Guided optimization is a massive win even for C/Rust. That being said the LLVM exposes the tools to do this with any LLVM-language. [There are demos on how to do this in Rust](https://github.com/Geal/pgo-rust) which demonstrate MASSIVE gains over native C/Rust. There is even [an RFC to add PGO into native rust](https://github.com/rust-lang/rfcs/issues/1220).
*This* is the subthread you pick to troll about Rust's CoC? A throwaway OOP flame met by requests for more constructive/descriptive followup? Talk about a fragile psyche needing a safe space...
&gt; I am sorry I can not be too specific on the target due to corporate policy. &gt; Violation that puts myself and this project in danger. That's OK. I understand. But it sounds you'll have to maintain a fork of rust-lang/rust and rust-lang/libc. &gt; Linker is Windows only. You can set the linker in the target specification, either in the `.json` file or in the `.rs` file (in `src/librustc_back/target`). Otherwise, you'll have to set it in a `.cargo/config` file under the `target.$triple.linker` key. &gt; you mentioned using cargo-build to build core crate and std crate. For core, you can use Cargo directly: $ git clone --depth 1 https://github.com/rust-lang/rust $ cd rust/src/libcore $ cargo build --target $triple You can do the same for std; it won't fully build due to bugs but it should still tell you what needs to be fixed in e.g. libc. These two can be done with a target specification file, the `.json` file. To actually cross compile `std` for your target, you'll have to use rustbuild: $ git clone --depth 1 https://github.com/rust-lang/rust $ mkdir build $ ../rust/configure --enable-rustbuild --target=$triple # magic, undocumented Python incantation :-) # (`make` works too but takes a LOT longer) $ python ../src/bootstrap/bootstrap.py --stage 1 --step libstd-link --target $triple But at that point you'll need to have the target in tree (a `.rs` file in `src/librustc_back/target`). Although that command cross compiles `std` correctly (the `.rlib`s) it doesn't build a proper "sysroot", a directory layout that `rustc` uses to cross compile. So, you can't use those artifacts to build `std` programs. A full `make` command does build a proper sysroot that you can use to cross compile; IIRC, the sysroot will be in `build/x86_64-unknown-linux-gnu/stage2` (the triple is that directory is the triple of the HOST not the TARGET's). &gt; Once I have core and std. How do I incorporate these libraries into &gt; rustc-stage1? `rustc-stage1` doesn't include `libstd.rlib` cross compiled for the target. As I mentioned above, you'll need a full `make` to get a proper sysroot with the cross compiled `.rlib`s. &gt; I assume configure's option --target is the triple rustc feeds to the LLVM &gt; backend? So it should be the same as the existing triple on LLVM for my &gt; target? No, that triple, the one you pass to `configure`'s `--target`, must match the triple you added in tree (in `src/librustc_back/target`). The LLVM triple is in the target specification; it's the `llvm-target` field of the target specification to be precise. So, at the end, you'll have a `x86_64-A-B-C.rs` file in `src/librustc_back/target` with its `Target.llvm_target` field set to `"x86_64-D-E-F"`, the LLVM triple you use with `clang`. &gt; What's the different between configure options --host vs --build? Not really sure. You only ever use `--target` or `--host`. `--target=$triple` cross compiles `std` for `$triple`, and `--host=$triple` cross compiles `rustc` for `$triple`. &gt; you can simply tell me where to look for the answer if responding is too much &gt; work. We don't have much (any) written information about this "arcana" :-/.
Urgh, *Gnome*. The US International keyboard layout in Gnome has been broken for more than ten years. Gnome's Bugzilla is currently down, but this is bug has been part of Gnome for at least a decade and it is still regularly revisited. Not just on the Gnome bug tracker, but also on the bug trackers of downstream users of GTK+ like Ubuntu and Hexchat. Getting keyboard layouts right is important; otherwise, a number of potential users will actively avoid your system because it's a constant pain in the ass for them. The fact that this bug is not getting fixed could be due to many reasons - the keyboard input component of the system could be abandonware, or maybe mismanagement prevents any fix from landing. Maybe it's WONTFIX. I can't remember off the top of my head, and again the tracker is down. In any case, I would not put my time or effort in a software project with these kinds of outcomes.
That's the look the developer gave it. When/if Rust gets an actual branding policy, it'll move to that.
No, REST is what you're thinking of. I'm speaking of ReST, restructured text. It's another markup language for text more similar to asciidoc in that it has a formal spec and supports a lot more types of markup than markdown. Most notably the Go and Python docs are all in ReST and use Sphinx to generate HTML docs. I was just curious if the diagram support could be torn out and used with a ReST parser.
You probably meant to post this in /r/playrust. This subreddit is about the programming language [Rust](https://www.rust-lang.org/en-US/).
I find [this view](https://github.com/GNOME/librsvg/compare/rustification) particularly illuminating. Couldn't figure out how to get something similar on git.gnome.org.
I was going to post that emcc needs to be on your path, but then I read your post more carefully and saw that you already did that. Double check? Other than that, I don't know. That's the only problem I ran into, but I'm on MacOS.
Explodey thing: When using asm2wasm I get the following error with glutin: HEAPU8 Assertion failed: (mappedGlobals.find(name) != mappedGlobals.end() ? true : (std::cerr &lt;&lt; name.str &lt;&lt; '\n', false)), function operator(), file /Users/steve/.emscripten_ports/binaryen/binaryen-version_18/src/asm2wasm.h, line 1331. Regular asm.js works just fine. Also, asm2wasm works fine on my little vdom experiment. I'm using the latest incoming branch of emscripten/rust nightly. Anyone else run into this or have a direction for investigation? My only guess is that HEAPU8 is for some reason not getting pushed into mappedGlobals in asm2wasm but it isn't clear to me why this is only tripping when I use glutin.
Nobody said they weren't a "consistent member of the community". This whole exchange is mmstick making a short throwaway comment about OOP, people asking for more explanation, mmstick spending more time explaining why they don't want to explain than an explanation would have taken, and you out of nowhere pretending this has something to do w/ Mozilla and 'safe spaces'.
Ha! One of the most common places you see "dozen" these days is buying eggs at the store, which come by the dozen. I can't imagine buying 1,000 eggs!
Of course, as always, the other explanation is that they didn't compile with `--release`.
I thought about that, but the issue is that I then have to have an un-nester in order to flatten the tuple into the `Args` type parameter for the `Fn` traits.
It's still very much in the try-fail-retry phase and as such is an incoherent single-module mess right now, but you're welcome to have a look: https://github.com/steveorsomethin/vdom-experiment The way styles, children, siblings work was heavily inspired by the way uniforms are handled in glium. While I can statically create arbitrary sets of descriptors and their component representations, the deep generic types absolutely crush the compiler past a certain point so I don't think it's going to work. I've been trying specialized tuples-as-child lists instead and it's proving to be simpler and much gentler on rustc but it isn't ready to commit yet. Also, the deep type signatures absolutely require a macro in order to have a handle to a known type for FFI without dynamic dispatch, but I also don't think it's going to be worth it. The macro simply makes things too inflexible IMO and I'd like a less magical solution. Dynamic children are also going to be necessary, though in my experience with react the vast majority of the scene is stable, so there's something to the static/tuple approach. Enums would be an option, but not with the horrific generic types I'm creating. Boxing + dynamic dispatch is probably going to be necessary, if uncommon. For events I was going to start with pushing into a channel and see if try_recv in whatever analog to ReactCompositeComponent would be adequate for a POC. One bit of good news is that in a test where I had a small pile of divs with styles no-op diffing, react (prod) was 1.2ms cold, 0.4ms hot. The experiment was &lt;=0.005ms when it registered at all. Of course, anything that does get through to the DOM costs multiple milliseconds in both.
It does, anywhere else on the internet it would have been ignored, or downvoted, instead somebody needs to attack the thought an individual has, as if bandwidth is a precious resource. This conversation is over.
Is `RefCell` kind of an anti-pattern when patterned with`ThreadLocalKey` ? I really can't think of a situation where you are going to end up aliasing a thread local key pointer. Especially if the current closure system is followed. As only one closure can have access at once acquiring a `RefCell` to do any mutability seems to add undo overhead.
Which is what `Deref` is for? The problem is that you cannot access the `Rc` itself and clone it from such methods.
The closest I can think of is msgpack but it's not as extreme as what are you looking for 
I would just like to see a few of the RFCs (like Async IO and yield) be settled before taking on the large parts of GNOME or similar projects. I've seen the value of these features in other languages like Python, and it would be nice (but not necessary) to have them in place before tackling such a goal
These are good points, but I wonder how quickly they would need these features. I bet they could find a years worth of low hanging fruit to tackle first (to mix a few metaphors). On a side note, yield would be useful for the work I'm doing. Unity implements animations using coroutines and I want to steal that idea. So I'm very hopeful that gets added. I saw that here are some coroutine libraries for Rust but as far as I can tell, they use threading which is not great for what I wanted to do.
Asking for an explanation != "attacking the thought", it's seeking to understand the thought. And its still unclear how this has anything at all to do w/ Mozilla policy.
It sort of looks vaguely promising, but I'm not sure what it is supposed to do. If you want also reach developers that are not experts in micorservices (like me ;-) ) maybe it's a good idea to provide an example? It feels like the Readme is too complex for me (and thus the general developer audience).
Also accessibility, which is something *many* apps that don't use platform-native toolkits get wrong.
Yes, we're in the process of developing our website, that'll be the example and it'll be well documented. Also I'm looking at documentation in markdown. All this and more is needed before we stabilize on 1.0, which is coming soon. I put this up now to start getting feedback! Thanks! What it's supposed to do: automate a whole bunch of things which make microservice deployments and developments complex and hard to do.
We're part of a larger lighting art collective known as Radiant Atmospheres. It's a bit of an umbrella organization with a shared warehouse space where we store all of our equipment. My subgroup is called Imaginary Photons, and is primarily a collaboration between myself and one other individual. There's a documentary being made about RA: teaser reel: https://vimeo.com/96877184 www.radiantatmospheresmovie.com/stills/ our web site, perennially out of date: www.radiantatmospheres.com
Why is native look so important? Nothing on Windows looks native. Not even Microsofts products like Office or VS. Photoshop or pretty much any other expensive software has custom widgets. At this point I'm not even sure what the native look on Windows looks like.
&gt; mmstick spending more time explaining why they don't want to explain than an explanation would have taken FWIW I think this is an uncharitable characterization; you don't know how complicated that explanation is. I have heard similar things about OOP in the past (sadly, I don't know the full details of this) so I don't think that mmstick is being needlessly disparaging here; and they're free to not spend the time to provide an explanation (but, like I said in my comment, they're likely to be ignored).
How much does Rust evaluate at runtime? It seems like between the ownership system and lifetimes it should be able to do quite a lot. I'm imagining that pretty much everything that doesn't require/depend on any sort of input from outside the program, or perform any sort of output to outside the program, should be doable at compile time. Presumably simple expressions involving only literals, like 1 + 2, are evaluated at compile time. But would something like 5.pow(5) be evaluated at compile time? In the function there would be a temporary variable, but all input is known at compile time, and presumably there wouldn't be any side effects within in the function (all memory allocation would be stack). I know this is definitely possible considering that C++ does it with constexpr functions, but googling about such things in Rust just lead me to old discussions about eventually implementing this in Rust. But going even further Rust should be able to evaluate functions at compile time that take immutable references to things that can be evaluated at compile time. Or maybe even create, initialize, pass around and eventually drop data structures so long as their lifetime is limited to places that could be evaluated at compile time. To express what I'm thinking. https://is.gd/9RQ8Uo That example comes from [this comment](https://www.reddit.com/r/programming/comments/5ai3cz/thoughts_on_dx_gnome_and_rust/d9h3mdo/), and I was thinking about compile time evaluation at the time, so it got me thinking.
Except for the last GTK 3.X version and a few issues on docs, it shouldn't remain that much... What is missing for you?
I think I misunderstood some of the things I read on twitter and elsewhere. It seems like the biggest piece missing is a tool to extract GIR definitions from Rust source such as exists for C. Is anyone already working on that?
&gt; There is no reason not to invite somebody whom I have decided needs an invite. _This is not the place to do this_. I didn't say you shouldn't. I said _not here_. PM people all you want. And I wasn't talking about the invitation anyway, I was talking about the rest of your comment. People are free to express themselves however they feel _in their own spaces_. This community has rules -- I'm not the one who decided on them, the community did, but we have rules. I left a mod comment giving explicit approval because it would be easy to misconstrue the community's reaction as saying that such comments are against the rules. We've had people in the past think that the rules are stricter than what they really are (and thus be extremely guarded in their discussion), so I was just clarifying this preemptively.
&gt; "Debian on Hurd" seems to be the only GLib OS entry not on the Rust platform support list. I know someone working on porting Rust to Hurd...
Thanks for the suggestion! I combined bincode and leb128, the result is [mincode](https://github.com/Boscop/mincode). It uses leb128 for all integer types, also vec length, enum tags etc. It also has different options for encoding floats: Floats can be encoded in their original precision, half precision (f16), always f32 or at half of their original precision. I also added serialization for bitvectors and added a lot of tests to check everything. All tests pass. Criticism welcome! :)
I clicked through to the comments out of sheer curiosity about whether or not this was the right reddit.
Why yes, you may. But I couples be ironic and say no ;)
&gt; QWidget API isn't exactly trivial to write Rust bindings for because it expects subclassing and C++ doesn't expose a standard ABI. Qt requiring inheritance to implement certain features is one of the things that always frustrated me about it. I guess starting with GTK spoiled me in that regard.
If adding a few dozen milliseconds makes you cross some threshold, it noticeably slows down the application, it's perception at least. See http://cogsci.stackexchange.com/questions/1664/what-is-the-threshold-where-actions-are-perceived-as-instant for more...
This looks solid, are you developing anything right now using his api?
I prefer the second one because it's cleaner. If performance matters for this code, then consider reusing the `user_input` buffer for multiple `read_line` calls. For example, you could pass the buffer as a parameter to `read_input`, and then it would only need to return `&amp;str`.
By "an implemented thing" I mean it in the broader sense that there's a critical mass of infrastructure built up around it such that I don't have to venture into uncharted territory in order to try to write a simple web app in Rust. Once there are a few tutorials out there to walk me through it, and the stack is demonstrated to be somewhat stable, I'll be all set.
Because Rust doesn't have a stable ABI, doing so directly wouldn't make sense. But, if we focus on an easy way to expose (stable, robust, useful) C APIs, then GIR definitions could be generated from that. Even through a Rust extern -&gt; C header -&gt; GIR process.
Yes, but it isn't open sourced (at least for now). I implemented an abstraction for different "scenes" (a.k.a. game states, like main gameplay, menu, etc.) to make it a bit more ergonomic. I would like to eventually open source that bit, but it's still got a ways to go (messy API, probably too much dynamic dispatch to be performant). One of the coolest things I pulled off was integrating `piston_window` with [`hlua`](https://crates.io/crates/hlua), which is a set of Lua bindings for Rust. Unfortunately, `hlua` is pretty limited in what types can cross the Rust/Lua FFI boundary, so the game objects aren't fully dynamic or linked to Lua at runtime. But I do have it so that you can set up a scene with pure Lua -- sure beats recompiling every time!!
In this installation we used four. The server pushes snapshots to the slaves over a 0mq pub/sub network. We use the 0mq topic subscription system to map a numeric topic to a virtual video feed, so each slave is only delivered the messages corresponding to the virtual feed they are listening to. In this install we used two virtual video streams mirrored to two projectors each. Just running one of these things requires a lot of creative energy (it is very much an improvisational performance), so two video streams is already a lot for one operator to handle.
I use a mix of Qt and GTK+ 2.x since `QGtkStyle` provides a comfortably reliable way for them to look identical. It was certainly a hassle, however, to find a Clearlooks-like Tk theme for the one ugly app I haven't yet found a suitable replacement for. (`git gui`)
`f32` is both radians and degrees: they are both notations for a dimensionless ratio. Whether you're using radians or degrees is a difference of a scaling factor. Likewise, you could make the argument that `*2` is a problem because it introduces a scaling factor; how do you know the number wasn't already scaled by two? If you do it twice, you get `*4`, which may be wrong.
I was thinking that it could generate a shim which exposes C wrappers for rust functions, but I'm not sure how well that would work.
&gt;You can do the same for std; it won't fully build due to bugs but it should still tell you what needs to be fixed in e.g. libc. Hit the nail on the head. This morning I got `rust/src/libcore` to build in under an hour. I spent the next 9 hours trying to get `rust/src/libstd` to build. I tried: 1. Using flag `--llvm-root` to point to our local branch of llvm compiler. 2. Building `core` and `std` to llvm-ir then feeding these `.ll` files to our llvm compiler. 3. Building a native rustc on windows, then replacing the entire `llvm` inside `rust/src/bootstrap/` with our own llvm. No matter what I do, I keep on getting vague errors suggesting the linker is missing libc symbols. Adding `--verbose` does not help much. My understanding is that `src/rustc/std_shim` is not getting linked to our target's `libc`. Parallel to that, I also tried creating my own `my_target.rs` base off of `src/librustc_back/target/x86_64_unknown_freebsd.rs`. But `configure --enable-rustbuild --target=my_target_triple` would fail due to rust not know what my triple is. Perhaps I need to cargo build librustc_back first? Currently I am still scratching my head, without being able to build `libstd` and without `configure` recognizing my triple, I don't see how I can hack a path forward.
1000 times yes :)
From the same author: https://blogs.gnome.org/despinosa/2016/11/01/rust-and-gobject/
If I have to design program to be able to work with such edge-cases, I may never finish it.
It's cool that gnome is thinking about using Rust, but I really hope we don't have to eavesdrop on their whole decision process here on this sub. 
See below. The idea is that you would use `buffer` multiple times when reading lots of lines, so you would only do one allocation in total, instead of an allocation per line. If you don't need to read lots of lines, then the performance probably doesn't matter. use std::io; fn main() { let mut buffer = String::new(); println!("Hi, What is your name?"); let name = read_input(&amp;mut buffer); println!("Hello {}! Nice to meet you!", name); } fn read_input(buffer: &amp;mut String) -&gt; &amp;str { io::stdin().read_line(buffer) .expect("Failed to read line!"); buffer.trim() } 
Thanks a lot for the explanation :)
Mostly less work than writing an entire UI library. Also react's model of a web version and native version works really nicely and allows one to use actual native UI components one each platform while reusing most of the code. 
Thanks man! 
Uh oh, too many good quotes this week! I've added this to [the thread](https://users.rust-lang.org/t/twir-quote-of-the-week/328/314) to pickup in future.
Speak for yourself. I find it interesting but don't have time to go searching for this sort of thing myself.
I personally couldn't stand `piston_window`, but maybe I need to revisit it. Obtuse is an understatement. Your mileage may vary though, I thought the same about Iron but it seems to be doing other people very well. I used the Rust SDL2 wrapper and was never happier. Have you looked at [ArcadeRS](http://jadpole.github.io/arcaders/arcaders-1-0)? It uses SDL2.
Have you tried: [target.x86_64-pc-windows-gnu] rustflags = [ "-C", "link-arg=-Wl,--subsystem,windows", ] in a project local `.cargo/config`? It, the `.cargo/config`, won't "stick" to your project though. As in it won't affect crates that depend on yours. Would [this RFC](https://github.com/rust-lang/rfcs/pull/1665) help? It has the words "windows" and "subsystem" in it and has been recently accepted. (I haven't read it or know much about Windows so *I* can't tell) EDIT Ah, but this passes those flags to all the crates for all the profiles, not just "release". AFAIK, there's no way to have per profile rustflags.
To use a different LLVM you can do two things: - `--llvm-root` to point to an *already compiled* LLVM. The argument to this flag is usually `/usr`. - Change the LLVM submodule to point to a different repository. **NOTE** You must commit this (submodule) change or the build system will revert it. The build system always reverts any change within submodules to make the submodules' contents match the submodule commit hash stored in HEAD. For libc, you'll also have to change the submodule. Commit the change! &gt; No matter what I do, I keep on getting vague errors suggesting the linker is missing libc symbols. I'd suggest checking that right linker and linker flags (`-L`) are being used. When linking (through `rustc`) fails, the error message contains the full linker command. If it doesn't you can pass `-Z print-link-args` to `rustc`. &gt; My understanding is that src/rustc/std_shim is not getting linked to our target's libc. Hmm, Rust `.rlib`s don't contain a copy any defined/global symbols that shared libraries expose; they only contain undefined symbols and carry a "link to this library (`-lfoo`)" message in their metadata. So if you are getting those errors using the `.ll` approach, it makes sense because that bitcode doesn't contain Rust metadata. I'd suggest here using `nm` to check what undefined symbols `libstd.rlib` contains and what global symbols you target `libc.so` exposes. If those don't match, review the `extern` blocks in `src/libstd`, perhaps your target libc.so has different names for the same functions that a normal "x86_64" libc.so does and you have to change the name of the functions inside the extern blocks. &gt; But configure --enable-rustbuild --target=my_target_triple would fail due to rust not know what my triple is. Oh, sorry. I forgot to mention. You have to create an empty `$triple.mk` file in the `mk/cfg` directory or `configure` won't work. Something like the s390x-unknown-linux-gnu.mk file in [this PR](https://github.com/rust-lang/rust/pull/36028/files). (This is some nonsense inherited from the old Makefile based build system; the new system, rustbuild, doesn't use Makefiles at all but `configure` still demands them :-/)
Wrap your existing crate in another crate that uses a `build.rs` directive to generate the *subcrate's* Cargo.toml? Within the build.rs file you can use conditional compilation. This is a really hacky solution :| 
Yeah, composition via the familiar react-like API was going to be the next step before I ran into the generic-pocalypse. I had a hard time deciding if react or virtual-dom would be a better fit for rust. With the react model, effects are applied incrementally and I don't need to emit a full descriptor tree every render. With virtual-dom, I believe if you wanted to re-use or memoize parts of the scene that haven't changed you'd need to move the previous descriptors or resort to something like Rc. Anyway I won't derail this thread too much more. Excited to see what you think of, hit me up on PM or github if you have any ideas.
what you want is https://github.com/rust-lang/rust/pull/37501
I guess ndarray has one trait that you want to have, (`ShapeBuilder`) which adds some extra methods on tuples used for more advanced options (strided shapes). I'll keep your thoughts in mind, since I'm tempted to expand the prelude all the time, and also I could think about how to remake the shape builder-using part into using more concrete types and not overload tuples. But the thoughts have not really addressed what you'd do if you had a relatively large amount of basic types and functions that you wanted to use, a lot. When every module in a project wants to use `Array1, Array2, ArrayView1, ArrayView2, ArrayViewMut1, ArrayViewMut2` and so on then a prelude is very convenient.
You're tangling up a few different aspects: * Rust's borrowing and lifetime system is evaluated entirely at compile time. * That said, if some lifetime and borrowing pattern cannot be expressed there's an escape hatch where the borrowck is evaluated at runtime through types like `Cell`, `RefCell`, `UnsafeCell` for single-threaded and `Mutex`, `RwLock` for multi-threaded support. * Evaluating expressions which happen to only depend on const inputs is a job of the optimizer, specifically constant folding. It may or may not optimize. * The guarantee of const expr evaluation support is very limited at the moment, see `const fn`. This is separate from the previous as forces additional constraints on the type system. In your specific case I'm pretty sure you don't get your string const evaluated (even `const fn` can't really do that). If you're really worried about perf here's what I'd do: 1. Create an `Indentation` struct, holding the number of spaces to indent for. 2. Implement `fmt::Display` for it. 3. In there you just write a loop where you `write!(f, " ")`. 4. If you don't want to write a single space at the time (it's probably `BufWriter` which does buffering itself anyway) just create a fixed size `[u8; 16]` or something and fill it with 32 (space) then cast that unsafely to `&amp;str` through `from_utf8_unchecked` and write that at once. 5. Now simply `println!("{}Hello World!", Indentation::new(4));` That should do the trick :) EDIT: Depending on what you want, the formatting system has alignment options which may be better suited. 2DIT: My suggestion on the [playground](https://play.rust-lang.org/?gist=4b3f0a1499325796543963058611c357&amp;version=nightly&amp;backtrace=0).
Can you please re-phrase what you are thinking?
&gt; That the first concrete progress I made after quite a few hours of frustration. Cross compiling C programs is fun, right? :-) Oh, those lovely linker errors. &gt; Use rustup to get a mips-unknown-linux-musl compiler &gt; appears to be mips-unknown-linux-uclibc. I can tell you this won't work because those are two different targets and `mips-unknown-linux-musl` produces *dynamically* linked binaries. (This musl target doesn't produce statically linked binaries because libunwind doesn't support MIPS and we use libunwind when we "statically link libc.a to libstd.rlib") --- So, the ingredients for cross compiling a Rust program are - A linker / C toolchain. You can use one of OpenWRT SDKs (this is an OpenWRT device, right?) that are available as binary releases [here](https://downloads.openwrt.org/). - Cross compiled standard crates. You can't get these from `rustup` because there are no binary releases for the mips-uclibc target (\*). You'll have to cross compile those crates yourself. The steps are: Grab the rust-lang/rust repo. `git checkout` it at the same commit hash as your `rustc` (see `rustc -Vv`). `configure --enable-rustbuild --target=mips-unknown-linux-uclibc &amp;&amp; make`. You'll have to supply a C compiler to the build system and you do that via an env variable: `CC_mips_unknown_linux_uclibc=/path/to/mips-linux-openwrt-gcc`. (\*) The reason we don't have binary releases of std for the mips-uclibc target is that the `libc` crate hasn't been verified to work with this target. So if you manage to build a std program for this target and it crashes when you run it then you at least know that the source of the problem was very likely the `libc` crate. --- If want to take the "meta" build system approach, AKA buildroot, yocto, openembedded, etc., then the [meta-rust](https://github.com/meta-rust/meta-rust) project may be of help. Or may not. I haven't actually used it before.
I can second this. At least from a beginner programmers perspective, getting up to speed with SDL2 wasn't that bad. Although I'd rather work with Piston at this point I think. There were bugs with Piston and the ArcadeRS walkthrough was fun to do. Recommend it for beginners. :-)
So, actually you don't need to build the rust-lang/rust at the exact same commit as your `rustc` because you'll be bootstrapping a new compiler as well. After `make` succeeds, you can use `rustup` to have it use the "stage2" compiler that `make` produced: $ rustup toolchain link stage2 build/x86_64-unknown-linux-gnu/stage2 $ rustup default stage2 $ rustc -V rustc 1.14.0-dev (...) `dev` indicates this is a bootstrapped compiler. After you do that, then yes you can just use `cargo build --target mips-unknown-linux-uclibc` *but* you must first tell Cargo to use the right linker with: # ~/.cargo/config [target.mips-unknown-linux-uclibc] linker = "/path/to/mips-linux-openwrt-gcc" &gt; Since I have a working gcc from buildroot Yes, certainly. Just change the CC_mips_unknown_linux_uclibc env variable to point to that `gcc` before you call `make`. &gt; the device is this one [This](https://wiki.openwrt.org/toh/buffalo/wzr-600dhp) seems to be the OpenWRT wiki page of that device. If that's true, then [this page](https://downloads.openwrt.org/chaos_calmer/15.05.1/ar71xx/generic/) contains the SDK.
I'd suggest you look around the source code for [amethyst](https://github.com/amethyst/amethyst). Its very clear and well documented..it could provide some inspiration.
See also the discussion on the [internals forum](https://internals.rust-lang.org/t/blog-post-series-alternative-type-constructors-and-hkt/4300/1)
Maybe I was missing the feature gate? I definitely got errors in 1.13 trying to use it. RFC 1628 ends with a comment, "Removing this from FCP -..." I took that to mean it's not being actively pursued.
If you use a feed reader, you can get a taste of general GNOME development by subscribing to planet.gnome.org. All of these Rust-related posts have shown up there too. I would love to see something like planet.rust-lang.org too! I subscribe to folks' blogs as I find them, but an aggregate feed would be really nice.
&gt; I'm not sure the Rust communities stance on it, but I really do not the use of prelude here. You don't have to use them, so I guess it does not hurt to have them? However, I would prefer the example to use explicit imports instead.
I was actually convinced of the utility of a prelude while writing the library, since I tended to have 10-ish imports for `ndarray` in most of the interesting files. &gt; But when libraries use them in their examples, it basically enforces their use IMO. That's actually a very good point. I don't think agree with /u/vks_ that it doesn't hurt to have a prelude, but I think you're right in that library examples shouldn't depend on them. I'll still mention the prelude, but I'll probably change the examples to use explicit imports.
Has anyone gotten Rust to work successfully in Visual Studio Code on Windows 10? I'm running: VSCode 1.6.1 Shell 1.3.7 Render 52.0.2743.82 Node 6.5.0 and have installed the RustyCode plugin (0.19.1) as well as the Native Debug Plugin (0.12.2) as well as the Rust Windows MSVC ABI .msi (1.12.1) and am trying to get a simple "Hello World" debugger to work. When I run the debugger nothing happens; although I get the following warnings to show here: Code-Debug WARNING: Utility Command Server: Error in command socket Error: listen EACCES C:\Users\usernamehere\AppData\Local\Temp\code-debug-sockets\Debug-Instance-ldeq Code-Debug WARNING: The examine memory location command won't work But I think these are warnings? This should be unrelated to actually running, correct?
I'd like to see a more general way of creating new idents that doesn't require compiler plugins. When I've needed new idents, I've wanted to do more than concat existing ones. For example, I've wanted to convert snake case to camel case, or append a suffix.
The weeks are really going by, 82 for Servo and 154 for Rust.
Thanks. I've tried running Visual Studio with VisualRust and that works wonderfully until I have to add in something to a Cargo.toml; which left me scratching my head trying to figure out how to do that from within Visual Studio (since I couldn't find an actual file.) Hence I switched to trying Visual Studio Code since there was promise of debugging but running the code nothing actually happens in VSC. I've given up as well trying to make the debugger work this morning. I'm also playing around with Atom Editor + a console window for any cargo commands as well for my own self learning. I just started reading about Rust about a few days ago and decided to work through some of hte examples in the book.
&gt; Speak for yourself. FWIW, meadowfire did say "I really hope..."
Thank you so much, I was banging my head against the wall for hours! The sad part is I even tried weak refs, but not this way (which makes way more sense!) Thanks again!
Where?
The proposed design seems to allow for that. One idea mentioned was that new platforms could start with a template PAL where every function just panics, and from there you fill out proper implementations of the functionality you want.
Empathically no, at least for microbenchmarks. Macrobenchmarks (measured in seconds) are probably mostly OK but take a long time to get a stable result. By the way, using [bencher](https://github.com/bluss/bencher) enables benchmarks on stable.
You want /r/playrust
Any existing script to run `benchcmp` iteratively through last N items of git project history?
That link is a 404. 
Slightly more idiomatic: fn main() { let client = Arc::new(stuff); let ping_client = Arc::downgrade(client.clone()); thread::spawn(move || { while let Some(client) = ping_client.upgrade() { // ping stuff here } // client fell out of scope in main } }
I'm not so sure it's a good idea to do something as rash as failing a build automatically, since time based tests are notoriously flaky. However, it does feel like a good idea to have them available for at least a human to inspect them to see if anything fishy is going on. That said, I have a few crates that run benchmarks in travis, but I don't think I ever actually look at them. If I think a benchmark might be affected, I always pull in the change and do the comparison locally.
Did you consider using a library like `nom` or any of the other parser libraries before writing this from scratch? Your parser would be zero-copy in that case too.
This is perfect! Looks like it's landing soon, too. I can wait :)
Thankfully, it looks like there'll be [an official solution](https://github.com/rust-lang/rust/issues/37499) very soon.
One of the ideas is to have an example_pal. This would implement everything as stub functions that all panic. You'd just implement what you need and leave the rest. Though I don't see how much utility there really is in that. It makes creating a new *_pal super easy, but this should be a one-time cost that hopefully the community and the project will do a good job of covering. So while this is definitely ideal, I wonder if it's worth the effort given the return.
code is on github: https://github.com/generalelectrix/pytunnel/tree/master/tunnelclient Not really useful for general applications.
Here's one technique that might be useful. If your client is a loop, you can simply keep a "time since last message sent" variable. Then in the loop you check if this value ever goes over a certain threshold, and if so, send a heard beat message (where every message sent resets the variable). This means that when you are sending other messages, no heart beats need to be sent. Then on the server, you have a "time since last message received" variable. If this ever goes above a certain value, you can assume the client has disconnected.
I think that's where scenarios would come in if those become a thing. Someone in the internals thread described it kinda like this: Think of the PAL as a "horizontal" component that links libstd to the underlying platform, and then think of scenarios as a "vertical" component that slices away certain chunks of libstd that your platform can't or won't support.
I find it incredibly frustrating when they're used in examples. It makes it really hard to learn how to use a library when you look at a short example and have no idea where anything is coming from.
I think a better approach for that is to do something like `use ndarray as nd;` and then `nd::whatever` when you use it. It makes it both concise and clear.
dude this is soooo syntactically noisy and ugly,omg let mut m = arr2(&amp;[[1.0 as f32, 2.0], [-2.0, 1.0]]); let r = Eigen::compute_mut(&amp;mut m, false, true); assert!(r.is_ok()); let r = r.unwrap(); let true_evs = Array::from_vec(vec![c32::new(1.0, 2.0), c32::new(1.0, -2.0)]);
You want /r/playrust
Typo? fn list(v: &amp;List&lt;u32&gt;) { let mut iter = list.iter(); let value = iter.next(); ... } Should that be this? fn list(v: &amp;List&lt;u32&gt;) { let mut iter = v.iter(); let value = iter.next(); ... } 
Not for me, as I need stuff like disabling the red zone or landing pads.
&gt; The result? an application with predictable CPU and RAM usage. Typically, the RAM usage graphs will be flat, compared to the sawtooth graphs with garbage collectors. Predictability is a key feature for stable production systems: you can make more assumptions about the runtime behaviour and plan for resource usage. One can argue that a sawtooth graph is also predictable so long that it always retains that behavior. Flat vs. sawtooth is a different topic.
Is it possible to create my own facade? I have a bunch of loosly related concepts, each of which I've put in their own crate to ease development. However the fact that they're all in their own crate is a detail, I wish to combine them all in a facade crate which just reexport the individual smaller crates. I would like it to be like std, where the docs are basically duplicated in the facade without any reference to the fact that they used to be smaller crates. Is this possible? Is such a crate publishable on crates.io? My alternative was to just use a build script to c&amp;p the individual crate contents in one bigger one but that feels like a hack even though I wish to achieve that exact effect.
the sawtooth graph is heavily dependent on external factors such as, for a web server, the number of concurrent connections or how heavy some requests are. The peaks of the graph are also when the program is the most vulnerable (from the point of view of reliability): high memory usage, tasks will soon be interrupted for an indefinite time. I can plan the resource usage for this behaviour, but if I can do without it essentially for free, why wouldn't I?
Yea figured that out lol
I'm trying to play around/explore with the combine crate to parse an expression to a member of an enum (p.s. I know about combine-language but I'm trying to explore combine first). http://pastebin.com/S535iiN5 integer .or(symbol) .or(array.map(Expr::ArrayLiteral)) .skip(spaces()) .parse_stream(input) for some reason it seems to be only matching integer or first or func, I thought it should match the first or it doesn't Err on, thats what the docs/examples seem to imply, is that wrong?
You could consider using the entity-component-system architecture instead, for example using the specs crate.
I think most of want you want are covered by traits. See: [The Book](https://doc.rust-lang.org/book/traits.html) and [Rust by Example](http://rustbyexample.com/generics/gen_trait.html). The gist of it is however that instead of inheriting an interface you can implement traits on your objects and then create generic functions which require specific traits.
It sure does! As an example, here is a small screenshot of /u/steveklabnik1 using `rustup` &amp; `rustc` to compile rust to wasm and asmjs. The `rustc` step you see could easily be replaced by a `cargo` project using the `cargo rustc` command. https://twitter.com/steveklabnik/status/786350257344880641 For accessing the DOM from Rust code, using the `webplatform` crate is your best bet: https://github.com/tcr/rust-webplatform
But under varying load, then a program that does not rely on GC is also non-predictable, correct?
Thanks for the gentle introduction. Looking forward to the next part.
It's not about presuming to speak for others. It's simply that, just like writing to your representative in government, it's assumed that the proportion of those who speak up will be somewhat representative of the much larger proportion of those who don't speak up. Since Reddit has voting, your post and my reply serve as obvious places to collect agreeing votes as an alternative to a flood of "I agree" replies.
An aside, but I have to say respect to that Final Fantasy 7 logo at the top of the blog post.
There's a good sample of webplatform's use here too: https://github.com/tcr/rust-todomvc
Yes it's possible, and yes you can publish it. The key is `pub use`.
In Rust it should mostly change proportionally and the difference with GC is that it could switch algorithm on changing load which makes it less predictable.
Is there any way to get the output javascript down in size? The example given at: http://timryan.org/rust-todomvc/ weighs in at 1.4MB gzipped.
Currently the underlying emscripten compiler is invoked without passing optimization flags, that's why the resulting JavaScript file is so huge. Passing `-O2` brings down that JavaScript file to 656K (188K gzipped). This will be [fixed eventually](https://github.com/rust-lang/rust/issues/36899)
i also wonder if running it through the closure compiler at the end would help...
No. /r/playrustservers. /r/playrust doesn't want server announcements either.
Thanks for the feedback. &gt; For example, what does Eigen::compute_mut do with the matrix that requires it to be mutably borrowed? It seems to me like it reuses the matrix's memory and leaves it in a garbage state, and in that case it should take ownership of it instead of borrowing it. I agree wholeheartedly. I actually got bit myself by this when writing tests; it's a LAPACK-ism that the output is usually communicated by overwriting the input, or that the input is used as workspace. I don't think that should leak into `linxal`. The `SolveLinear` and `LeastSquares` traits use `*_into` functions instead, which I think is better. I'll soon be changing the other traits to match. &gt; Taking plain bools as flags to a function is pretty hard to read; and subsequently returning Some(v) vs None based solely on whether those flags are true or false will cause every call site to have quite a bit of boilerplate. I'd prefer separate functions for those cases, ... I'm not sure what the right answer is here. I thought about defining `Neither/Left/Right/Both` enums for the `SVD` trait, for instance, or using separate functions for each combination (and having different return types for each of the functions, but... bleh). My first thought is that that would be too verbose of an API, but maybe that's a better tradeoff. *EDIT:* &gt; or returning a lazy object that computes the eigenvectors only if they are actually requested. I hadn't considered that approach. Unfortunately, you can't compute the eigenvalues and later compute the eigenvalues with LAPACK API (AFAIK). You have to do a bunch of copying if you compute the values now and the vectors later, so I'd rather the user specify in advance which they will anticipate needing. 
The example is a bit more verbose than you would expect to see in practice. Besides shortening `1.0 as f32` as /u/llogiq mentioned, I don't see how you can make a matrix declaration much shorter. /u/two_pence mentioned the `(..., false, true)` issue, which I think is a valid point. In practice, you wouldn't need to call `.is_ok()` before using the result. The `Array::from_vec` is actually unnecessary, that can be shortened with an `arr1`. I'll make that change in the example. The `c32` type is an alias for `Complex&lt;f32&gt;`, directly from the `num_complex` trait. `c32::new` is the shortest way to construct a number, I think. I could define traits on the `ndarray`s themselves, so Eigen::compute_mut(&amp;mut m, ...) will look more like m.svd_mut(...) That might be a better approach. I'll have to experiment.
Some things can be done by implementing the function that you don't want to duplicate by having it access the object via other functions, e.g. using getters and setters.
So what I'm seeing locally is not representative of how it'll look like when published on crates.io? I am using `pub extern crate $crate` for all the crates, their dependencies are local paths (in the same git repo). When I run `cargo doc --open` locally and view the result, it has documented all the crates separately. In the docs I see a bunch of `extern crate $crate` where `$crate` links to their respective crate docs. When I create a new crate with the facade as dependency, I see it compiling all the separate crates (perhaps this is expected?). Will users of the library see this too? EDIT: I tried to `extern crate $crate as __imp_$crate; pub mod $crate { pub use __imp_$crate::*; }` for all crates but this still tries to link to extern crate docs instead of providing them inline like std does.
...so a function with the instance as a parameter as opposed to a method, is that what you mean?
&gt; GC being non-deterministic is not a very controversial statement. True, but I think one thing that people often miss is that the RC is a form of GC... and is *in general* just as unpredictable as other strategies. I guess it's still *technically* deterministic in that reclamation *will* happen when destroying the last reference, but a) the amount of work may be unbounded, and b) when you cannot really predict which reference that is, it doesn't really make much difference. Now, in a typical request/response server-type application written in C++/Rust you can _usually_ just keep a lot of state on the stack since it's likely to be request-specific, but I think there are indications the web, at least, is actually moving slightly away from this model (HTTP 2.x server push and multiplexing, etc.) and it's pretty much unknowable what's going to happen. I don't have much experience with Rust, so it's also unclear to me how much (scoped/unique) heap allocation will be necessary for such a server, but I'm guessing it's also non-trivial. Here, I think, some types of GC may actually have an (overall) efficiency/throughput advantage in that heap allocation may as simple as a pointer bump. There's also the issue of fragmentation when you do have heap allocation without the freedom to just move memory around. Obviously, if you can guarantee that everything stays on the stack then you're good, but that's true of any runtime/language. Some languages just make that easier (to enforce) than others :). **In short: It's complicated :). Summing up the situation as "non-GC/RC is better than other-GC" is overly simplistic in my opinion.**
Shouldn't fn floatify_family&lt;F&gt;(ints: &amp;F::Collection&lt;i32&gt;) -&gt; F::Collection&lt;f32&gt; where F: CollectionFamily be fn floatify_family&lt;F&gt;(ints: &amp;F::Member&lt;i32&gt;) -&gt; F::Member&lt;f32&gt; where F: CollectionFamily ?
Detect regressions and file bugs automatically. Chromium [does this](https://chromeperf.appspot.com/group_report?keys=agxzfmNocm9tZXBlcmZyFAsSB0Fub21hbHkYgICg_cDD4wkM), although it has dedicated bots that run the benchmarks.
If you're only doing a single layer of inheritance, you can get a similar result using a generic wrapper struct Entity&lt;B: Behavior&gt; { pos: Matrix, behavior: B, } impl Entity { pub fn draw(&amp;self, canvas: &amp;mut Canvas) { self.behavior.draw(canvas.transform(self.pos)) } pub fn update(&amp;mut self) { self.behavior.update(&amp;self.pos) } } trait Behavior { fn update(&amp;mut self, &amp;Matrix); }
RC? In composition class I learned that it's good form to define your abbreviations at the outset (eg. Rent Control (RC)) so the reader can understand what you're talking about. Given the context, did you mean "Rust Compiler (RC)"?
&gt; we can’t actually infer the of the family! Missing 'type' &gt; type Iter: Iterator&lt;Item=Item&gt;; =T
I don't have time for a point-by-point, obviously, but... (EDIT: I should also say... I'm not sure we're even disagreeing about any *facts* under consideration, perhaps only the interpretation of said facts or what lesson we should take from them.) &gt; As well as incremental reduction of fragmentation. That's just good malloc design. Well, except it's an *unsolvable* problem if you can't move memory[1]. There *will* be pathological situations where you can end up unable to allocate[2] (due to the inability to arbitrarily move memory). My main point here is that you're talking about a "good malloc implementation" and others are talking about a "good GC implementation". Each has advantages and disadvantages and there's just no **simple** answer for "what's best?". I'm just arguing against this simplistic thinking that "GC bad" and (for that matter) "GC good". You need to figure out what context your code is going to run in, etc. etc. I'm satisfied with the answer "it's complicated, let's go from there and experiment", while everybody else seems to want to pick a "winner". I'd actually love to see a good peer-reviewed unbiased survey of this whole area, but I suspect it's entirely impractical to actually go through all the nuances. [1] EDIT: Well, alright, I guess you could just restrict the language's semantics to disallow dynamic allocation, but if you do that, then people will just invent a way to do dynamic allocation on top of your non-dynamic allocation and you're back where you started. Besides, the only place I've ever even *heard* of that has been able to avoid this is some type of space probe. [2] Yes, this happened. No overcommit -- that might have rescued us, but we didn't have it because "someone-not-me" was worried about "magic".
&gt; fn floatify_family&lt;C&gt;(ints: &amp;C) -&gt; C::Family::Member&lt;f32&gt; &gt; where C: Collection&lt;i32&gt; It is nice to see how powerful associated type constructors are, but is this still readable? And perhaps even more important, how would API documentation work for the related traits? To give an example, take `File::open`: fn open&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;File&gt; This is really useful, and it especially simplifies call sites. But in my opinion it is also harder to read and grasp than simply fn open(path: &amp;Path) -&gt; Result&lt;File&gt; I have a feeling that associated type constructors could skew things even more towards “clear and readable at the call site, but noisy and full of indirection in the definition”, but I have to admit that I have not thought about it thoroughly.
Where you write &gt; Linking collections and families &gt; &gt; To make inference work, then, we really need a “backlink” from Collection to CollectionFamily. This lets us go from a specific collection type to its family: I believe this is just injectivity. You want "trait families" to be injective, which would create an "automatic" back-link without having to place an additional "back link" in your type. You probably want injectivity by default, I'm not sure where you would _not_ want it to be injective.
(EDIT: Sorry, I'm rambling a bit...) Yes, but again... RC-is-GC :) It doesn't afford much tuning, but happens to be (often?) used in a pattern which is relatively easy to optimize at runtime. Of course if you go *only* static/stack allocation for everything, then you're golden -- everything is an increment/decrement. I realize you didn't explicitly mention RC, but an issue here is that e.g. Rust (not to pick on Rust per se, almost all languages do this) allows any old little subroutine to do a *lot* of stuff memory-wise, but the caller might not have any idea. There's simply no way to (statically) constrain the subroutine. If you want control -- *that's* what you want, I think. Aside: I found Andrei's talk about allocators very interesting: https://www.youtube.com/watch?v=LIb3L4vKZ7U (but I'm guessing you've already seen it :)) My general thought on this really amount to: If you REALLY want predictability you need a language which can **statically* give you the "i-deallocate-everything-allocated-in-this-frame-before-the-next-frame" (substitute "tick" or whatever for "frame") and/or "no-dynamic-allocation-inside-a-frame" and/or ... (Basically statically type-checked "regions", but... more + better :))
ok, so, I don't want to add oil on the fire here (even though this is a good thread and I want to read more), but when I talk about the stability I can get with Rust, I wen a bit further than not using GC. I'll soon release some stuff where I put a hard bound on a server's resource usage and can actually predict very reliably how much memory will be used. As an example, by preallocating large pools of objects or buffers, you avoid a bit of the unpredictability of fragmentation (and the speed bump of frequent allocations and deallocations). It is something that you can do in other languages, but Rust makes it particularly easy to do.
I was wondering why a two week old tweet got popular all of a sudden.
The actually ideas include much more, and hopefully I'll have time to work on new mockups before the end of the weekend. Ideas from Erik Vesteraas are very impressive, but not possible with the current prototype. See the links he posted here https://internals.rust-lang.org/t/borrow-visualizer-for-the-rust-language-service/4187/26?u=nashenas88
Really not sure what this is supposed to be, but I'm fairly certain you're in the wrong subreddit
I often get asked "Who is using rust?" and while I can rattle off some names (can't like to the friends of rust page in a conversation) that people will recognize, ultimately, I'd like to see companies discuss it more. They're obviously not obligated to, but for a lot of people I talk to they believe that rust is niche, or even still unstable - essentially that it is not production ready. Having companies talking about rust would really go a long way. When I say "Dropbox and Chef use Rust" peopl ewill often say "Oh, really? Maybe I should take a look". I really can't understate the reaction when people find out that companies they've heard of are using Rust. The note about async io is also something that resonates with me. Glad to see progress made here.
&gt; Now that we have impl specialization does it make sense to have a lot more trait only crates? If there are relevant impls for std types and primitives, that crate needs to contain them to avoid orphan issues. The [futures](https://crates.io/crates/futures) crate is essentially an example of this. It contains a lot of types, but they're implementations of the futures combinators that are part of its trait definitions. Most of the things you'd want to do with futures requires an asynchronous runtime implemented on top of it, which tokio is an example of. &gt; Is there a way to make this a zero cost abstraction using generics? Even if we use default implementations? Absolutely yes. Generics do not have a runtime cost, even with specialization. They are always resolved to a single impl at compile time, which can be optimized just like the non-generic version would be.
Great! Andrei has had some pretty amazing *really* practical insights. (I agree that the first section is pretty C++-focused, and admittedly a bit negative, but AFAIK it was all pretty tongue-in-cheek. AFAICT the "famouses" in C++ mostly know each other, so they don't shy away from abrasive language like you might expect as an outsider.)
Yes, indeed. Another bit of complication! I'll defer to you on the practicalities of Rust, but I just want to implore people to just consider more context when considering their language... **other than "GC" vs. "no-GC"**. How many *ACTUAL* servers need absolute guarantees on max latency? Very few... but everybody seems to be chasing "async" or "no-GC" when that's the absolute *least* of their worries. If your server needs to talk to a remote PostgreSQL to produce an answer, you'll incur some latency regardless of whatever else happens (GC or whatever)... so again: it's complicated. IME such latency outdoes any kind of GC/whatever latency you might have. If all you're doing is "compute", then great, but if you're talking to a backend (database, whatever) or two, then you've already spent those milliseconds anyway. As a (former) C++ programmer, I *completely* understand why Mozilla invented Rust even it was *just* to get a better language for implementing security-critical, soft-real-time software, but I'm going to guess that most of the browser UI is *still* going to be JS... and there's nothing wrong with that! 
Looks like atom.
Yes. It was the first editor that was somewhat easy to implement this in.
Ncurses is probably what you want. It provides a virtual frame buffer for your terminal, with support for overlapping windows.
Well, depends a lot on how you're GCing. It used to be quite a big issue when people were using young versions of Go with, say, half a second here and there kind of latency. The follow is really simple and you clearly know it already, but I'll say it anyway because I am trying **really hard** to procrastinate on the Communist Party Case doctrine. Very few people are chasing either soft or hard real time, you're right. Most couldn't care less; they want to say, at the strict end of the scale, that '99% of our requests complete in X seconds'. But the way to deliver this isn't usually by guaranteeing one machine's performance, it's by scaling *before* that one machine gets choked up. Thus, the absolute predictability of a given request latency is not nearly as important as the more rough predictability of a system as a whole. The author in this case wanted to say with some amount of certainty how their application would break down, as it were, with too many connections, so they would know when to scale it. Huge generalisation that is nonetheless mostly true: with non-GC, the plot of memory used vs requests in flight stays fairly linear near the maximum, whereas with GC, that part of the graph gets hella swirly, hella early. (Pardon my french.) This means you can (a) know when a machine isn't going to cut it more accurately; and (b) get more reliable capacity per machine under load. So, yes, "it's complicated", but you _can_ simplify the GC/non-GC arguments enough to draw a working conclusion like this one for your particular circumstances, and factor it into your broader analysis of what your system has to do.
Wouldn't that require some additional changes to the current type/trait structure? It makes sense that you could get `Vec` from `Vec&lt;i32&gt;`, but to my understanding `Vec` isn't a type in Rust, so there's no machinery for getting from `Vec&lt;i32&gt;` to `Vec`. This could change through the addition of more "traditional" HKTs, but the current system requires that there be some other type, `VecFamily`, that identifies `Vec`. Injectivity doesn't seem to help then, because `Vec` and `VecFamily` aren't related through any special machinery without the addition of an associated type parameter such as `Family` in the article.
&gt; They're obviously not obligated to, but for a lot of people I talk to they believe that rust is niche, or even still unstable - essentially that it is not production ready. Most people who say that imply "Rust is niche/unstable ... when writing a web server/backend". And for this, it is mostly true. 
I also forgot to add "party with a friendly player on my server".
Really?! The quality of Rust support on VSCode is the only reason why I allow a webapp disguised as native on my computer. Which native IDE offers better support than VSCode?
Without using [`try`](https://docs.rs/combine/2.0.0/combine/fn.try.html) combinator, [combine is limited to create LL(1) parsers.](https://docs.rs/combine/2.0.0/combine/#overview) In other words, it can only look-ahead a next single element in the stream by default. In your example, `symbol` _consumes_ `#` and probes whether the next character is `"`. Try `integer.or(try(symbol)).or ...`.
They're like a travelling subreddit hermit, each refuge they knock on the door of solemnly turns them away.
thanks that looks like a good start
Also, "Weld railroad track segments."
Maybe you know, is rustfmt working in VSC now?
I like the IntelliJ IDEA Rust plugin. The authors are very active and responsive as well.
It is possible to call into the compiled code. Currently this still requires a binary (with a main method). See [my minimal example on how to do that](http://www.hellorust.com/emscripten/demos/04-call-into-lib/)
I found that trying to build the rust compiler/standard lib still presented a few roadblocks. I had to add a .mk file and a .rs file for the unrecognized platform triple and I still wasn't able to get the compiler to build. At this point I stopped and looked at the big picture and considered my options again. I could have: * Kept pushing through to produce a rust compiler for the device. Problem: there was a good chance that that binaries would not have worked. Or worse, they might have appeared to work but have exhibited flaky behaviors later, which is *not* why I want to use Rust for my project. * Bought a new device. I might have done this if I could have located a router under $100 that had an x86 chip and plenty of RAM/flash and a working OpenWRT distro for it. I didn't see anything like that. * Flash the device with a disto natively based on musl. So I thought it over and realized that: * I bought that particular router because it was *designed* to be flashed with new ROMs, so I should consider doing this. * Trunk of OpenWRT and now LEDE both use musl by default. I was worried that using trunk might be a problem. So I downloaded a base LEDE image for my device and the associated toolchain. * I verified that I could at least produce binaries with the Rust compiler and the pre-built LEDE toolchain for my device. * I flashed the router with LEDE and installed the web config. * I pushed my binary to the device via ssh/scp and ran it. It said "hello world!". Win! This is clearly the best option for me overall as I have supported (albeit trunk) image for the device, a working toolchain built with a vendor's expertise, and a tier 2 supported compiler for Rust. 
&gt; therefore, you cannot model a Collection trait today in Rust, at least not in a nice way. There are some tricks I didn’t cover. =) As a person new to Rust, I'd be interested in learning about those tricks. 
Just released version 0.1 on crates.io. Some demos are available on the repository: the flow past a cylinder and the poiseuille flow.
Sorry for the noob question, but what is it specifically about specialization that makes this possible now, when it wasn't before? I (think) I understand specialization, at least on a shallow level, and I'm not seeing the link here. But I am probably missing something in my understanding.
Thank you! I have been following your demo/examples this week. That's really helpful to me.
Function calls in JavaScript are not really opaque because IonMonkey can do inlining, which often allows for more optimizations to be applied.
I wrote a plotting utility in pre-1.0 rust a while back: https://github.com/jswrenn/fireplace I'm working on a rewrite that uses braille characters. I've [thrown the essential parts into a gist](https://gist.github.com/jswrenn/ee1238a62eb7251a9c1297670c0e5bd3), if you'd like to play with it.
&gt; I had to add a .mk file and a .rs file for the unrecognized platform triple Why, though? `mips-unknown-linux-uclibc` is already in tree. &gt; I pushed my binary to the device via ssh/scp and ran it. It said "hello world!". Win! :+1:. Yeah, I was going to suggest using trunk and the mips-musl target but ... some people don't react positively to the suggestion as they associate trunk / nightly with not stable, not ready for production, not serious, etc. so I hesitated. I hope that OpenWRT/LEDE release a stable version based on musl soon then more people will be willing to use the mips-musl target.
I'd like to chunk a vector of numbers, starting from the last position, keeping both the chunks themselves and the elements in the chunks in their original left-to-right order: [1, 3, 2, 6, 5, 4, 9, 1, 5, 4] becomes [1], [3, 2, 6], [5, 4, 9], [1, 5, 4] Right now I'm doing this, using itertools chunks() let digits = vec![1, 3, 2, 6, 5, 4, 9, 1, 5, 4]; let chunks = &amp;digits.chunks(3) .collect::&lt;Vec&lt;_&gt;&gt;() .iter() .map(|e| e.iter().rev().collect::&lt;Vec&lt;_&gt;&gt;()) .collect::&lt;Vec&lt;_&gt;&gt;(); let chunks = chunks.iter().rev().collect::&lt;Vec&lt;_&gt;&gt;(); It works but I'm wondering if there is a better way? Just doesn't look great. Thanks!
VSC has always been unusable for me because I can't get clippy integration as in Atom.
How portable is regular Rust code to the new platform? Any specific things that makes a program unportable to it?
There's clippy integration in atom!? How do I get all of this setup?
Because (most of) the standard library requires a kernel (or a libc, which in turn requires a kernel) to actually work. There is a WIP port of libstd to the Redox kernel, but it's intended for userspace apps.
Is there some reason not to ship the rust binary and a copy of the musl libc in a non standard location? You can also in many cases use the ld-linux.so as a type of wrapper to switch the default libc for a process. Try running ld-linux.so --help on your router.
Check out [this thread](https://www.reddit.com/r/rust/comments/5as9gy/refactoring_std_for_ultimate_portability/) from yesterday, there's ongoing discussion about the portability of the standard library.
Maybe I'm setting it up wrong. I can't get my rust shit to work at all. My Golang plugins work wonderfully
In a broader sense, a standard library's job is to take the abstractions provided by multiple operating systems and provide a unified set of abstractions on top. this isn't _strictly_ true, but it's the common case. More specifically in Rust's case, libcore requires no underlying OS, and libstd builds on that by providing useful stuff on top of it + what the operating system gives you. So libstd makes sense for userland, and libcore makes sense for kernel stuff.
Not quite Wellington, but I'm always keen to meet up with others for hacking
&gt; It should be pointed out that C++ loses a lot of features once you no longer have an OS. Surely that list is very wrong. I've done most of that stuff freestanding. Including STL. You do need some runtime support, but ~none of it cares about having an OS.
I agree with you, but think that a lot of things could be solved with separate improvements. For example abstract types could simplify your function call by making fn open&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;File&gt; into fn open(path: @AsRef&lt;Path&gt;) -&gt; Result&lt;File&gt; Which is far more readable. The example you gave could be cleaned up into something like: fn floatify_family&lt;C: Collection&lt;i32&gt;&gt;(ints: &amp;C) -&gt; C::Family::Member&lt;f32&gt; An even cooler improvement would be the above extension of abstract types into function input and allow the return type of a function to access the parameters so you could have something like: fn floatify_family(ints: &amp;@Collection&lt;i32&gt;) -&gt; ints::Family::Member&lt;f32&gt; The point is that, sugar code for readability can be done easily. The question is how to expose the feature in a way that this can be done in a way that isn't too painful.
Having supervision in an MCU with a base-and-bound MPU or similar RTOS context is really a lot different than an actual userspace. None of the OS services most people are accustomed to are present.
I've used Dropbox as a hammer answer to this question too: - "Do you store your data on Dropbox?" - "Yeah..." - "Well, their storage servers are written in Rust, so you're trusting it already."
You don't need an OS for an allocator. I do a lot of work with PIC microcontrollers and you can use malloc() and free() just fine on those if you specify a heap size during the build process. Of course, with those systems you generally avoid this if at all possible.
This is provided through a runtime (which is automatically linked). The microcontroller runs more than just your code. It's more accurate to say it requires a runtime. 
I am trying to implement a Trait called Shape, which has a method called intersect (along with others), that takes in another shape and returns a bool. I have two structs, a rectangle, and a circle, both of which implement Shape. A rectangle should be able to determine if intersects with either another rectangle or another circle. A circle should have the same capabilities. Unfortunately I am running into an issue of duplicate definition when I try to implement the methods, sample code here: https://is.gd/BT1LHY I don't think there is method overloading in rust, so apart from having a method on the trait for each possible shape (i.e., intersect_with_circle, intersect_with_rectangle, intersect_with_triangle, etc). Is there a more "rusty" way of doing something similar to this? I experimented with having a separate trait for the 'Intersect' method alone, and have each struct implement it as needed but it seems very verbose. Now each shape has to implement this extra Trait for each shape that it supports intersection with. 
I hope I can make it to the cologne one - I want to pick up rust again and finally do something useful with it. where is it? I assume the C4 as usual? :)
We haven't officially announced anything yet, but it's very likely at the C4. Looking forward to seeing you there! :)
By "touches threading" do you mean just stuff like spawning threads and accessing thread local storage or do you mean any thread safe primitive like Arc, Locks, Channels, etc? Do the latter not work at all or is their thread safety specific code just a noop?
I'm in the process of starting a game studio. I may end up using an existing game engine like Unity, but right now I'm exploring writing stuff from scratch and I'm using Rust for that. Once the company paperwork is registered and I have a website, I'll be quite happy to list Rust as a language we proudly use.
I understand how it works, I'm aware there's a runtime. My point is that there isn't an "OS" in the conventional sense. There's no networking, storage, files, multiple processes, nothing of the sort. But you can still do dynamic memory management.
Not terribly interesting but I thought it might be helpful to some people who haven't yet played around with `Future-rs`.
[removed]
I used to use makefiles as a place to save commands I needed to rerun frequently, but I got tired of make's idiosyncrasies and wrote a command runner in rust that uses a simple, expressive syntax similar to make's. I find it to be enormously helpful, both because it saves typing and because it saves trying to remember what commands do what for a particular project. I encourage you to check it out! If you have a feature request or an issue with it, please let me know 🙇 Edit: Some other notes: The code isn't very well commented, but it contains a hand written tokenizer and recursive descent parser, as well as a description of the grammar in grammar.md. The tokenizer is a little gross because it is slightly context sensitive, but the parser is very nice, and allows producing really good error messages.
Yes you can do that with trait implementations, it's standard practice. That is how the From/Into traits are implemented [in the standard library](https://github.com/rust-lang/rust/blob/3fba503bf50b4a83dbc20e002b1e1e2c00fe1054/src/libcore/convert.rs#L269). For example: impl&lt;T, U&gt; Into&lt;U&gt; for T where U: From&lt;T&gt; { ... }
Could you elaborate on these make idiosyncrasies?
Heyo! Yeah, definitely. So one thing is that by default, if a recipe has no dependencies and a file with the same name exists, make won't run it. So for example, if you have a makefile that looks like this: test: ./test and you do `make test` it won't run it, because it sees the file 'test' and assumes that the recipe is up to date and nothing needs to be done. The solution to this is to add a .PHONY line in your makefile: test: ./test .PHONY: test Which will ensure that the recipe is always run, even if make considers it up to date. Other things too, like '=' vs ':=' assignments, a lot of weird escaping rules, only allowing tabs to indent recipe bodies, using '$' as an escape character, so you have to do '$$' whenever you want to use a shell variable in a recipe, and probably other things I'm forgetting. Also, make has really terrible error messages, which is one of the things that I tried to improve with just. Make will usually say something like "unexpected end of input" whereas just will underline the token where things went wrong, and hopefully tell you what it was expecting. EDIT: Also, another thing is the lack of portability between different versions of make. GNU make and BSD, for example, are so different that it's very hard to write a makefile that works for both.
+1 for coeffects. It's the good stuff.
idk, I ported the stdlib into Wind Waker (yes, a 14 year old game) where I neither have an OS nor libc available to me and it wasn't that much effort. I don't have stdin or network support, since the game doesn't support those, but everything else works just fine and wasn't hard to implement either.
Imagine in Python, you have something like: class Thing: parent = None child = None def set_child(self, child): child.parent = self self.child = child You can't do that directly in Rust. struct Thing { pub parent: Weak&lt;RefCell&lt;Thing&gt;&gt;, pub child: Rc&lt;RefCell&lt;Thing&gt;&gt;, } impl Thing { pub fn set_child(&amp;mut self, child: Rc&lt;RefCell&lt;Thing&gt;&gt;) { child.borrow_mut().parent = ... // Wait... I need Rc&lt;RefCell&lt;Self&gt;&gt;, but I only have // &amp;mut Self. Uhh... } } So instead, you could do this: pub trait ThingExt { fn set_child(&amp;self, child: Rc&lt;RefCell&lt;Thing&gt;&gt;); } impl ThingExt for Rc&lt;RefCell&lt;Thing&gt;&gt; { fn set_child(&amp;self, child: Rc&lt;RefCell&lt;Thing&gt;&gt;) { child.borrow_mut().parent = Rc::downgrade(self); self.borrow_mut().child = child; } } Except, now, many of the methods that *should* be on `Thing` are on an extension trait instead that you have to use *everywhere*. That, or you have something inside each `Thing` that contains a `Weak&lt;RefCell&lt;T&gt;&gt;` back to the owning `Thing`... although now everyone implementing types that have to participate in the graph have to remember to implement all this internally (which comes back to not being able to cleanly mixing in base functionality).
Thanks for pointing that out, I updated the blog post.
I think the most ridiculous thing is that you end up using something like automake or cmake so you don't have to work with make, so you can literally make make. makefiles came around to make it easier to compile programs, and then it became so hard to write them that people made programs to make makefiles. And I still have to look up cmake stuff every time I work with it... Thank you for making `just`. The rust ecosystem is really starting to look great. It seems like it's not only building towards a rich ecosystem, but a *right* one where everything actually makes sense and avoids previous mistakes from other programming environments.
I have pity on Rust's type checker.
I really appreciate your thoughts on the library side of Rust. As a red stapler guy who works for a large corporation and have tried (and failed) to port Rust onto our llvm compiler, I'd just like to give my experience. So a bit background, we run x86 on a derived bsd ish os. we have a a llvm triple but our compiler is maintained as a parallel private branch to the upstream llvm. I am not the first guy to have tried to port Rust to our platform, the last guy build a libstd but run into problems interfacing Rust with our own compilerRT. Since he wrote nothing down and quit, I am starting fresh with no knowledge of Rust. I got a lot of help from this sub so I am very greatful of the rust community. This is meant as constructive criticism. So if anyone takes offense, it is probably due to my own ignorance. 1. Building Rust on Windows is really difficult. The GNU way failed because of directory formats conflict. Cygwin Python interferes with the version of Python Rust tries to use. Rust uses MSYS2 which seems me to be much harder to use. The visual studio way apparently work. I know Windows is a shitty development platform, but given we run a proprietary linker on Windows I am stuck. 2. Rust build wraps around LLVM three times over, needs its own library and apparently interacts with Git and llvm compilerRT. As a guy who primary does work on clang, I had mistakenly hoped Rust would sit neatly on top of llvm. This is not a criticism on the rust ecosystem. But given that rustc generates LLVM IR and llvm BC, I was hoping for a more modular build experience. I would love to have a more granular build switch. 2. Building the libstd is really really difficult. Error message is cryptic. I know the problem is in the libc shim. But I can never figure our the cause of the linker failure. I don't really have a solution to this as bootstrapping is inherently difficult. I would love to have a bootstraping switch that stops at the shim and logs the interaction between rustc and llvm in glorious detail.
Neat. Does it figure out which recipes need to be rebuilt as well, like make?
You're very very welcome! ^__^ I actually really like make for when I have some dependency graph of inputs, commands, and outputs, but which for some reason isn't a good match for another build system. Like, for example I'm building documentation, or running some I've written that munges some big file. The problem is that for a long time make was the only game in town, so it got stretched waaaaaaaaay beyond its limits.
That C++ list is just plain wrong. Have you ever done bare metal development in C++? I did, and there are compilers which support the complete C++ standard in bare metal, the only thing preventing their use is how much memory you are allowed to use. A language runtime is also an operating system. That OSDev in C++ link could surely get some updates. 
&gt; libc, which in turn requires a kernel Only if you are talking about GCC libc. There are C compilers for bare metal programming, with support for their own libc.
I don't think that will ever happen in Rust, because then you would have duplicate function definitions. Not that I dislike the feature in Haskell, but I think it would needlessly complicate the language, because it's yet another thing to learn for newcomers.
I would argue it makes it simpler, but our experiences may just be too different to agree on that :).
This is pretty much what we do for a lot of our administration work. Automation systems such as ansible basically fall back on shell scripts anyhow once you have to go beyond their normal limits. A well documented, simply written she'll script is a good self-documenting way to do things.
Hm, haven't tried ansible myself yet, but I do use salt, and for its use case I actually like it far better than shell scripts. I do remember the puppet stuff we had before that was 80% shell scripts too though.
The TLS story for Rust HTTP clients is still being fleshed out. 
It certainly permits recursion, but this grows the stack. Tail-call optimization would allow you to, under specific circumstances, avoid growing the stack by treating the tail call (literally, the last call in the function) as the continuation of a loop. Thus, you can recur as deep as you want, and you won't blow the stack.
Note that this subreddit is for [Rust the programming language](https://www.rust-lang.org). You probably want [/r/playrust](https://www.reddit.com/r/playrust/).
Thunderbird doesn't and, even if it did, I don't trust Bayesian filters. (I do deterministic spam handling by using a forest of e-mail aliases which act as revokable API tokens) ...plus, I'm planning to replace Thunderbird with a homegrown thing with a much more streamlined UX and I don't feel like adding Bayesian filtering to that either.
[removed]
I made this because I needed coverage for rust, and tried using travis-cargo, but it's unfortunately not working with newer version of cargo. When I found out it used stdout/stderr, I figured there ought to be a better way to do this using cargo as a crate directly. Turns out, this isn't such a great idea, because different versions of cargo won't play well with each other, leading to the coverage step rebuilding everything. This could be fixed by having multiple version of cargo-travis for each version of cargo, but cargo's core changes so much it's a pain. I wonder if anyone has a good idea of how to fix this ? Having a stable API for the currently installed version of cargo would be great for building tooling.
I completely agree, OP. I love this feature of ML languages and wish that it was included in every language I use.
What was the problem with `travis-cargo` and newer cargo versions? 
TCO/TCE which isn't supported right now, meaning you cannot write tail recursive functions and expect them to be space efficient.
Oh, right... Thank you!
Rustup also has a hyper backend but I don't believe it's enabled by default right now.
The scoped thread pool crates should probably impl the Executor trait.
To avoid dependency hell obviously. The more relevant question is why does it use curl at all? If you've ever used libcurl the code-stench is unbearable. This isn't going to be the last vulnerability in it. Doesn't Rust itself have pretty good support for HTTP requests (which I assume is what it is used for)? Edit: Nm according to the comment below TLS support isn't great yet.
I'm not sure, I haven't used Mach! Does Mach let you put arbitrary commands into a file, or does it just interact with mozilla's build system?
The above script is missing many features of just. If you check out the readme and give it a shot, I'm sure you'll find it useful `^__^` Also, using make would be better than the above script, since it allows running multiple recipes, printing commands as they run, and stopping at the first command that fails.
Update: it does since [`v0.4.1`](https://github.com/nabijaczleweli/cargo-update/releases/tag/v0.4.1)
It can be extended with arbitrary Python code.
Awesome!
Huh, I thought so, but that looks like it's changed since I last looked at it. And it looks like CpuPool doesn't impl it either.
Are there instructions for installing and setting up mach in a new project? I'd like to check it out, but I can't figure out how to install it, or how to configure it with new commands once installed. It looks like mach integrates with the mozilla build system. Is mach used/useful outside of projects that use the mozilla build system? 
Rust did think about it, as far as I know, but how it would interact with the borrow checker is kind of an unknown. 
Yeah, that sounds like the kind of complexity you could base a doctoral thesis on.
Servo uses it (with Cargo, natch, rather than the Mozilla build system). The [python](https://github.com/servo/servo/tree/master/python) folder has the implementation details, along with the files at the root of the repo. The Mozilla Build System stuff is just some commands that are defined for Mach, AFAIK.
The issue is with destructors. With normal (stack-growing) function calls, any local variables are dropped *after* the call. But with a tail call, we have to drop these variables *before* the call instead. See the [FAQ](https://www.rust-lang.org/en-US/faq.html#does-rust-do-tail-call-optimization).
Why didn't you try to fix travis-cargo instead of writing your own?
Two reasons. First, fixes already exists, but the owner of the package never merged any PR. https://github.com/huonw/travis-cargo/pull/61 and https://github.com/huonw/travis-cargo/pull/55 both fix the problem. Second, I wanted to try the approach of using cargo as a crate directly, as written on the repo's README. travis-cargo is written in python and scraps stdout to do its business, meaning it's prone to breakage at every cargo update. I figured writing my own with a different approach would be worthwhile. Using cargo directly has the advantage of being more resilient.
&gt; To avoid dependency hell obviously. That's what packages (rpm, deb, dmg, msi) and package managers (apt, dnf, brew) are for. &gt; Doesn't Rust itself have pretty good support for HTTP requests (which I assume is what it is used for)? This is a valid question. Rust could use openssl and send it's own HTTP requests.
curl seems to be working everywhere already. The versions of libcurl provided by OSX and Linux distributions shouldn't vary greatly. For Windows, projects simply bundle all dependencies into a single MSI package.
Easy fix. Just move "let path;" after the "let path_buf =" statement. path_buf needs to outlive path due to scoping requirements. 
u/machinationofclay has the fix, but to be honest I am stumped as to what the problem is. Either way, this is in my eyes a nicer way of writing it (sorry, couldn't help myself :P ): https://is.gd/QLVP6X fn change_dir(args: &amp;Vec&lt;&amp;str&gt;) { let path_buf = env::home_dir().unwrap(); let path = match args.len() { 0 =&gt; path_buf.as_path(), _ =&gt; Path::new(&amp;args[0]), }; env::set_current_dir(&amp;path).is_ok(); }
There is also a magic variable called `$crate` that expands to the absolute crate name where the macro was defined. This allows you to write absolute paths to things in your crate, without worrying about your crate name.
From what I understand, `macro_rules!` wasn't really ready when 1.0 came around, but was the most stable form of macros available. The plan is to add them to the regular `use` statements, but there are some kinks that need to be worked out. All macros are expanded after tokenization (which is why macro calls must have balanced braces). `macro_rules!` are also only a specific type of macro, and at some point in the future a second interface (probably `macro!`) will be created that takes a TokenStream, and returns a new TokenStream.
Things are destroyed in the reverse order of creation, so in the current code, there'd be a moment where path is dangling.
I am just starting to learn rust, so I am really not familiar with idiomatic style of writing code yet. Your code looks wayyy better. Thanks!
Thanks, I need to learn the borrower and lifetime concept thoroughly. I only have a vague idea of what it is (the one in C/C++). 
I am getting this error. Any ideas? error[E0277]: the trait bound `(): std::convert::AsRef&lt;std::path::Path&gt;` is not satisfied --&gt; src/main.rs:14:3 | 14 | env::set_current_dir(&amp;path).is_ok(); | ^^^^^^^^^^^^^^^^^^^^ trait `(): std::convert::AsRef&lt;std::path::Path&gt;` not satisfied | = note: required because of the requirements on the impl of `std::convert::AsRef&lt;std::path::Path&gt;` for `&amp;()` = note: required by `std::env::set_current_dir` 
You used ; somewhere you shouldn't.
&gt; Could you clarify what you mean? As far as I can interpret, the link shows that curl-sys is literally already acknowledging this: it uses the system version on those platforms. You originally said "The vendoring is so the package works everywhere", which I interpreted as implying that you cannot always rely on the system's version of libcurl to match the ABI you compiled against. This is a fairly common argument made in favor of vendoring everything, either as a statically compiled "fat" binary or monolithic package (vagrant does this). In reality, this is rarely an issue as OSes and package maintainers ensure the ABI only changes on major OS releases. &gt; How is this actually different to what curl-sys does, in practice? In fact, it is almost exactly what curl-sys does: compiles it and links it into the binary, resulting it ending up in the MSI. Either way, it seems like any interpretation of what you propose requires releasing new artifacts when curl needs to be updated. I guess the only difference is you keep libcurl out of the repository and source code. Also, I believe it's possible to install libcurl as a separate DLL which the Windows binary can then load.
Setting up auto scaling is a bit involved on AWS, but it can be done. To handle higher traffic, you'd probably want to allocate some machines to be used in anticipation, and then based on certain triggers in AWS, you could have it increase the size. I would google an ECS cluster with auto scaling tutorial for AWS. Decide what size machines you want, and you can deploy easily in a dockerized image. If you have the processing and the web server all in one program, then each machine needs a port allocated, and the AWS load balancer will need that port ahead of time, so you can't multiplex workers on one machine. If you go with a worker, master structure, you'd probably do well with a few (2-3) front end servers (maybe even just one tbh), and then an auto scaling CPU worker pool on ECS communicating through a message queue, or what have you. Perhaps using SQS, but you'd need a place to store results, so what I typically do is something like celery where I pass a unique ID, a payload, and a method name (and a ttl for redis results so that it vacuums itself), so that you could use two channels, one for publishing new work (I.e "jobs"), and one for results (i.e. "Results"), and pass in a unique job id, like a UUID, that you can use to track the job results when they finish (and perhaps a progress key if you want to be fancy). For such a simple workflow, this should be quick to set up and sufficient for your use case. Allocate enough ram for redis to handle your maximum concurrent result set based on projected traffic. Finally you deploy them both, and use AWS auto scaling group. If you move your dns name servers to route 53, then redirecting to the load balancer CNAME is very easy. Source: I work at a startup and set up this infrastructure for us. I used terraform to assist in the set up for the infrastructure, and can help if you want. I was going to make this into a blog for our company one day.
Here's my version: fn change_dir(args: &amp;[&amp;str]) -&gt; Result&lt;(), io::Error&gt; { let path_buf; let path = if args.is_empty() { path_buf = try!(env::home_dir().ok_or_else(|| io::Error::new(io::ErrorKind::Other, "Home directory not known"))); path_buf.as_path() } else { Path::new(&amp;args[0]) }; env::set_current_dir(&amp;path) } 1) Notice how path_buf is only calculated when it's value is needed. 2) The function now takes an `&amp;[&amp;str]` instead of a `&amp;Vec&lt;&amp;str&gt;` as this is more flexible. A `&amp;Vec&lt;T&gt;` automatically Derefs to `&amp;[T]`. 3) Proper error handling - this function now returns an error in case it fails. The caller can then choose to handle this appropriately, instead of potentially continuing in the wrong directory. If this is too much for you right now, at least change `is_ok()` to `unwrap()` so that the program panics instead of potentially continuing, potentially doing dangerous operations in the wrong directory. Side note: in case you really want to ignore whether set_current_dir succeeds or not, the most common way to write that is: let _ = env::set_current_dir(&amp;path); ...but even that is relatively uncommon, given that people usually don't want to ignore errors.
Forgive my ignorance, but how is this different from optional dependencies?
You would only have to opt into the optional dependency once, instead of enabling it for each of the dependent crates.
First of all, disclaimer, absolute Rust noob. I also know next to nothing about SSL/TLS, if that wasn't clear :D This client I'm writing is my first foray into both of those things. &gt; why are you even using TLS at that point!? I think most people who use the auto generated certificates don't really care about it being secure at all, but the mumble protocol uses TLS. Case in point: The official, default mumble client will prompt you if you're connecting to a self-signed/untrusted server, but happily let you do. A popular library for murmur clients, mumble-ruby, [uses SSL_VERIFY_NONE by default with no option to turn it on!](https://github.com/mattvperry/mumble-ruby/blob/master/lib/mumble-ruby/connection.rb#L16) To be clear, that is NEVER the behavior I want, but people who build clients on top of mumble-rs (what I'm working on) would expect it to work the same way, I think. Or at least have an option to turn off verification, like the official client. That being said, I'm willing to say "tough shit, that's horribly insecure, let's encrypt is free", and that's probably what I'll do :) &gt; but a separate connect method that doesn't take a hostname is something that could be added That would be helpful, because I think a lot of people host servers without a domain name, and just give out the IP for connecting. So, they'd still have to get a trusted cert, but at least they wouldn't also need to get a hostname. Although, is it even possible to get a cert without a hostname / Can you get a trusted cert with just an IP address? If not, then it's a moot point I guess. &gt;It'd probably wind up with a hideous name [..] to try to make it a bit painful to use :) Understood :D &gt;First though, it'd probably be worth checking to see if the certificate does have a CN or SAN. Will do! I still have a lot more reading to do to make sure I do this all correctly, and I'll investigate that as well. Thanks for being awesome with this follow up, and you also answered my question in a thread the other day.
hey i just saw you in r/Atlanta :) i would suggest getting it to run in docker, then using AWS elastic beanstalk. it does all the grunt work of auto-scaling, load balancing, and zero downtime deploys for you. let me know if you want some guidance!
String vs str : https://medium.com/@jimmco/strings-in-rust-8cc9ea07560b#.2f9lfgrk2 Error handling: https://doc.rust-lang.org/book/error-handling.html Ownership : https://youtu.be/GbWECt0M3CI?t=885 Closure : https://gist.github.com/dumindu/b1a0c75030404d6c75e2c6e6f9e27c38 Also http://cis198-2016s.github.io/schedule/ https://medium.com/learning-rust might help you to learn things quickly
TLS does two things: encryption and authentication. Sometimes, people only want encryption (e.g. because they don't have a domain name and a trusted certificate). Sometimes, people need to access sites that don't have a trusted certificate (e.g. the railway ticket service site of China). Or people just don't want to add root certificates for things like occasional mitm testing, or access a site with a just-expired certificate.
I've spent 4 hours yesterday trying to get Hyper to compile on a Windows 10 machine. Hopefully this will help.
I would personally prefer this: fn change_dir&lt;'a, P: 'a + AsRef&lt;Path&gt;, D: Into&lt;Option&lt;&amp;'a P&gt;&gt;&gt;(dir: D) -&gt; Result&lt;(), io::Error&gt; { let path = try!(dir.into() .map(AsRef::as_ref) .map(borrow::Cow::Borrowed) .or_else(|| env::home_dir().map(borrow::Cow::Owned)) .ok_or(io::Error::new(io::ErrorKind::Other, "Home directory not known"))); env::set_current_dir(&amp;path) } The interface states the intent of optional argument more clearly (using option) and the fact that argument should be path (allowing any reference convertible to `&amp;Path`). The code is also somewhat shorter and might be more readable. Examples of calling the function: change_dir("/a/b/c").unwrap(); // Changes dir to /a/b/c; requires Rust 1.12 or newer change_dir(None).unwrap(); // Changes to home dir change_dir(my_vec.iter().next()).unwrap(); // Same behavior as OP's function. If you worry about performance, I guess compiler will optimize it enough. To improve it even more I'd use new Error type, so the `Err` could be inspected.
Windows and Mac don't have package managers, and they are not a great solution on Linux either. There are so many and they are never up to date. If I want the latest version of Rust that was released yesterday I can't get it from apt.
This is a follow-up to https://www.reddit.com/r/rust/comments/59adt0/planetkit_week_2_a_first_attempt_at_making/. As before, you can find the code on GitHub here: https://github.com/jeffparsons/planetkit. I'm pushing code as I go, so if you're interested you can also follow along there! 
Haha, small world! :) My post was removed from /r/atlanta the mods shortly after I posted it, but when they realized I was from Atlanta they said it'd be okay to re-post it as long as I made mention of the fact. I made several changes to my app that I posted in my response to binkarus, which leaves only the wav generation functionality in the Rust app. I'll have to figure out ECS or elastic beanstalk today. I don't have much experience with Docker or deploy ops in general, so I might shoot you a question or two. :) Totally off topic: do you know of any local Rust groups or meetups? 
Personally I'm biased, but I think [packaging your app for Sandstorm](https://sandstorm.io/developer) could solve many of your problems. Then you wouldn't need to worry about scaling, because each of your users would run their own instance on their own Sandstorm server. To allow people quickly try out the app on [our shared hosting](https://oasis.sandstorm.io/), you could use our [app demo](https://docs.sandstorm.io/en/latest/administering/demo/#app-demos) feature, which would make a link like https://oasis.sandstorm.io/appdemo/n0y5gfc98m6atyj3k5nyaxtz8x4yxrh2vz8c47m3xfysnn5xgs90 that you could share.
&gt; Encryption can prevent this. Really? In the absence of certificate it's trivial for the ISP to MITM and therefore inject advertisements/redict users even if the traffic is encrypted between the user and the ISP (and by the way, there's no guarantee they even bother to encrypt between the ISP and the site you are looking to contact, so your traffic may very well be in the clear). If you do not trust your ISP to be well behave, then use authentication or only expose traffic that you do not care about (such as checking reddit! :p).
I'm not sure I follow. I'm trying to scale a single expensive endpoint (speech synthesis) to 500 - 1,000 queries per second. I'm not spinning up instances on a per-user basis. The endpoint is exposed to the entire web at large.
&gt; feature flag rigmarole :D !
The trait is defined incorrectly - the get method should take `&amp;'a self`
I meant in c++ you don't have to worry about the order in which you declare variables. 
Thanks for your reply. This idea is also posted by [Pavel on SO](http://stackoverflow.com/a/40449685/1184354); howeve the method may return something with a different lifespan, and I think `&amp;self` should not take `'a`; I also tried `get&lt;'b&gt;(&amp;'b self) -&gt; &amp;'a u8` but it doesn't work either. For example `data` in `U8Ref` may outlive the `U8Ref` object.
AFAIK, in C++, if you do something like this: OnDestroyDumpVector&lt;int&gt; dumper; vector&lt;int&gt; vec; if (x) { vec = generate_vector(); dumper.set_vector(&amp;vec); } Then compiler will let you do it but you've introduced a use-after-free bug.
There is a way to "just connect" - you just use `SslContext` and `Ssl` directly.
That seems like a situation where you'd want to use `SslContext` and `Ssl` directly and stick with their defaults - you don't care about the identity the server's presenting or if the connection ends up choosing some awful cipher over SSLv3, so it seems like `SslConnector` wouldn't really be buying you anything.
At the end of be function, won't there be a time where the vector is freed, but the pointer is still alive? That's my understanding, though I'm not always great with C++ edge cases.
You're conflating entity authentication (signing handshakes with certificates) and message authentication (MACs, AEADs). Most attacks on unauthenticated encryption relate to the latter. When you don't authenticate your counterparty, however, you set yourself up for much simpler attacks, where the attacker trivially impersonates the other party.