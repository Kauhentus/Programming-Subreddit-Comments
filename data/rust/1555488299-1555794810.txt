To be fair "Why did you expect it to? [...], it's just a bug in your logic" is the same logic thrown around when you segfault in C. Maybe someday most languages will detect it at compile time. But first somebody needs to demonstrate a method that is: generic, easy to implement, and easy/worthwhile to use.
FWIW, I think this is educational, but not really how NLL work. NLL didn't change when values are dropped, it really only changed when values where considered borrowed. Values are still always dropped at the end of their scope. That also means whether a type implements `Drop` affects NLL. Besides that you can't actually drop a reference like that, since it implements `Copy`. I.e. this will drop a copy and keep the original reference around.
there is also [cargo xbuild](https://github.com/rust-osdev/cargo-xbuild), the successor to xargo.
&gt; Having a code coverage of 100% on foo means that your test case explore all the branches in the code of foo: Having 100% **branch** coverage means that. "Code coverage" can and often does also refer to statement coverage.
I'm coding up a "Chess" AI for a variant on chess called "Four Kings one War" which has a 16x16 board, 64 pieces on the board and a lot of complexity. The ai\_4k1w.dll compiled in rust is invoked from the existing game in Unity and can compute 1,000,000 boards in a few seconds using just one thread. &amp;#x200B; Today I added En-passant rules for the AI, I also managed to have the AI beat the inventor of the game over several matches. He's stoked to be adding it to the game. &amp;#x200B; [https://fourkingsonewar.com/](https://fourkingsonewar.com/) &amp;#x200B; I'm loving rust so far. I've found it extremely painless for both this and my own personal game work. It is rock solid, absolutely trivial to set up a development environment and get code compiling and a joy to work with.
ML is mostly about exploration. Once you reach the point of exploitation with an ML application, you usually have enough resources and experience to reimplement from scratch anyway. I use rust heavily in ML for developing core libraries and production performance bottlenecks, but it isn't the right tool for the exploration part of ML in the same way Python, R, or Julia are, just as they aren't the right tool for the production/core library part (apart from Julia for certain niches).
First of all, that example only has two levels of iterators, not infinitely many. Second, you can have an iterator whose element type is itself, though I don't see the point: struct Foo; impl std::iter::Iterator for Foo { type Item = Foo; fn next(&amp;mut self) -&gt; Option&lt;Foo&gt; { Some(Foo) } } Third, I don't see how currying would even help with that.
This was amazing, please make more! :)
I'm not saying "why did you expect it to?" because I think it's impossible, or a bad idea - I'm just saying that because Rust in its current state doesn't really detect this sort of thing, or even try to, or even claim to try to
What's the rationale behind the closures' syntax? &amp;#x200B; I mean, the syntax \`|x| x + 1\` is weird, where does it come from? Something like \`fn(x) x + 1\` would have been more "logic", doesn't it?
If you dont use \`\_first\` again, the compiler can effective mark the \` \_first\` dead, and it will no longer prevent you \`push\`ing into the original vector.
There are two standards for math API libraries – BLAS and Lapack. Between them these are to maths what OpenGL is to graphics. Vendors make their own compatible implementations of these library APIs: the Intel has the MKL, and even NVidia has CuBLAS. There are also may open-source implementations, like GotoBLAS and Atlas. Numpy wraps whichever BLAS library it finds on your machine. The features it offers are fairly bare-bones. As soon as you get into any decent sort of math – machine learning in my case – you need some of the features in Lapack which Scipy wraps and (significantly) augments. I would expect Numpy to be as fast or faster than ndarry. Some of the BLAS implementations it wraps like GotoBLAS are super-mature and optimised, with chunks of handcrafted assembly. Ndarray it seems has experimental support to delegate to native BLAS which may help. For your purposes, you need to consider what your project needs to deliver. If it is a novel implementation of an existing machine-learning method, then Rust is great. If it is a broader project that uses machine learning tools, choosing Python maximises your chances of success.
Not sure the `crt` is that clear either (I couldn't tell you what is means before I looked it up right now). In the spirit of not abbreviating perhaps `async-runtime` is even better?
I used xargo, seems to work reasonably well, even though it is in maintenance mode. I had to change the dependency from collections -&gt; alloc , to get Vec support. ( Documentation is not updated )
I measured the size from the size of a custom image that I use for the home grown boot-loader. It should accurately reflect the size of code &amp; data segments that the linker keeps. I did have some problems getting each function in ts own section, so linker gc was not optimal.
You can try https://github.com/passcod/cargo-watch or https://github.com/watchexec/watchexec. I'm not sure what's the difference between them.
&gt; That also means whether a type implements Drop affects NLL I think you meant to say that it does *not* affect NLL, right? If not, I'm missing something. I already knew that NLL didn't affect when drops occurred, but that to me implied the opposite of what you say here. Does implementing `Drop` extend the lifetime to end of scope?
Your parent mentions a warning suppression, not a compilation error.
Even for your use case, you could name each pin etc. :)
What is the time cost for \`Rc\` and \`Arc\`? can we use it more frequently where we use \`Box\`?
Thanks, I will give that a go also
rust?
It's simple enough for a known number of arguments. I wrote an implementation for `curry2!` [here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b1db91d05c408d38fb1a49e0265a15e4). I don't know enough macro black magic to write one that's general over arbitrary arity. I'm not even sure it's possible.
Could you try running [cargo-bloat](https://github.com/RazrFalcon/cargo-bloat) on the resulting elf file, and post the output somewhere? Preferably with complete results, e.g. "cargo bloat --release -n 0"? I haven't attempted to use `alloc` with embedded yet, so I don't know where that size is coming from. You can also look at [`alloc-cortex-m`](https://github.com/rust-embedded/alloc-cortex-m) if the majority of the bloat is coming from the allocator, and you can also try a few [profile override tricks](https://github.com/ferrous-systems/internet-of-streams/blob/master/Cargo.toml#L16-L21) to improve the LTO performance, if you are producing a binary, rather than a library.
There is &lt;https://lib.rs/&gt; (former crates.rs) which is an alternative repository to crates.io, maybe it has some resources.
No, ? does not cause a panic.
I've not followed the async progress at all. Will async in the future be possible to use like [protothreads](http://dunke) in C for resource constraint devices? Protothreads uses clever tricks with macros to make functions be async, but local variables doesn't work correctly because of it.
is there any way to deploy that game in web via wasm?
That's pretty good
Why do the bindings you wrote for Bluetooth stuff *must* live in winapi itself? Couldn't you maintain them in a separate crate until they get upstreamed?
/r/playrust
I love JetBrains, they really have their shit together.
Yes... Why?
Thanks. The way this was being presented is that we'd have an async/await main, and everything async/await below that. I suppose the plumbing between components could be channels, so every async function works like a little message-event handling loop. That might be one way, although that would be a lot of channels. Or actors underneath might be another way. Anyway I'm just curious (as everyone is probably) about how to code stuff in this new async/await world, especially regarding how this will interact with the borrow checker and other unique Rust features. (I've done loads of coroutine stuff in Lua, but that has shared mutable state, so with Rust it's going to be different.)
It would be way more correct to use a `unborrow(x)` or `drop_borrow(x)` or something like that instead of `drop` in the examples (otherwise they can be misinterpreted as `drop == std::mem::drop` which would be incorrect).
Basic question: So I asked this in Stack Overflow but they don't allow really broad questions. &amp;#x200B; Im basically stuck on how to get an environment set up for coding. My plan is to use IntelliJ IDEA on a Windows 10. At one point i downloaded Visual Studio but I uninstalled it. For some reason I also uninstalled Atom. Could you point me to a resource that can address this concern?
Long time lurker here. Would a function that looks like this: fn takes_and_gives_back(foo: MyType) -&gt; MyType { Where `foo` is simply modified and then returned, be unidiomatic? I say this because I'm creating a tree recursively where the values of the child nodes are calculated based on their parent, and right now I have some ugly lines like this: create_children(&amp;mut left, depth - 1); root.left = Some(Rc::new(left)); create_children(&amp;mut right, depth - 1); root.right = Some(Rc::new(right)); Where `create_children` is the recursive func, that would look much better (IMO) if I just did something like: root.left = Some(Rc::new( create_children(left) ))
Really good walkthrough!!
Yes. If you have type strict Foo&lt;'a&gt; { &amp;'a i32 }; and you borrow like this let mut v = vec![1]; let foo = Foo { &amp;v[0] }; v.push(2); the code compiles in Rust 2018 because NLL assumes borrowing ends before 3rd line. But if you add impl&lt;'a&gt; Drop for Foo&lt;'a&gt; { fn drop(&amp;mut self) {} } the snippet above suddenly stops compiling because `foo` is **used** at the scope end by dropping mechanism and thus borrowing ends only there. Yet. If you force dropping like this let mut v = vec![1]; let foo = Foo { &amp;v[0] }; drop(foo); v.push(2); it starts compiling again, thanks to NLL because borrowing ends on 3rd line now. In Rust 2015 you couldn't, for example, lock mutex, use it, drop lock and reuse mutex object without putting lock into nested scope.
&gt; drop == std::mem::drop https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8261c0ddf8adfbfe10610a7b07516938
I am working on the frontend for a simple messaging project. I am reading input using io::stdin().lock().readline(). The messages received are printed to the console using println!(). The problem is that when a message is received while a new one is being written, it is appended to the current line. Even though this is only visually and the received message isn't appended to the one being written, this looks a bit unpleasing. Is it possible to keep the input line fixed at the bottom of the console and have all the other messages printed above it?
async-rt works as well
Then the examples are incorrect, because the drop happen at the end of the scope in LIFO order.
It's still incorrect, because `drop` just takes value and does nothing, letting value be dropped implicitly. It should be `drop_in_place`
Try asking that in Stack Overflow. They usually handle coding questions pretty quickly. &amp;#x200B; By the way, I can't answer this, I'm sorry. I am brand new to Rust.
I think you're right that the error handling isn't ideal here. Because when there's an error for just one stream, you want to just abort that one stream, not the whole listener loop. As others said, it's a graceful error return though, not a panic.
&gt; Just like 20 minutes ago I downloaded an app to boot Linux in a USB (Etcher) and the app's weight was +100 MB, and I'm pretty sure almost all that weight is from the electron UI Considering how literally all that app is “dd if=image of=/dev/usbthingie” I say you’re being generous.
You can store the position of the data: https://docs.rs/tar/0.4.22/tar/struct.Entry.html#method.raw_file_position.
I think using the system provided webview largely defeats the point of Electron because you end up needing to test against each platform individually so making something actually cross platform ends up being a giant pain in the ass. Especially for people who don't own Macs and have no way of testing against Safari (MSHTML is kind of terrible but they at least provide VMs to test against it for non-Windows users).
I was talking about the drop order in general. Which kind of drop glue gets generated, if any at all, depends on the values being dropped and the control flow graph of the function.
\&gt;just curious, why would you use Rust with an embedded browser If your APP eats away some like 2-4 Gb Ram, one more GB for browser is not an issue. Besides, is there really a choice for writing cross-platform complicated GUIs in reasonable time?
hotel?
oh ok
r#wenn ;)
that's the spirit!
This is a result of `tokio`, which `actix-web` uses, forcing all futures to have error types of `()` to indicate that errors are handled. See the comments in this [`tokio` example code](https://tokio.rs/docs/getting-started/hello-world/#creating-the-stream).
I'd first make sure everything you need is there between the following crates: ndarray, ndarray-linalg, and ndarray-stats. If everything is there they should be close in performance at the very least since all of the blas and lapack libraries should be the same. I'd also ask this question over on the discord science and ai channel, since I know several people on there have extensive experience with both ML and ndarray.
With the pace of development on their Rust plugin, I have a dream that it'll follow their Go plugin and go from being a JetBrains made plugin to its own full blown IDE.
You could also try mem mapping the file.
I personally suggest vscode to educators. It's a free open source extendable ide/text editor that won't lock their students and teachers into a paid ecosystem.
Yup. Just have an embedded web app inside your process and access it from your browser of choice. It will have much less overhead, at least on Windows. If you run Slack, Discord, Spotify and whatever else you’ll see each of them spawning lots of browser-like processes that eat huge amounts of ram. I’d call that a lesser evil.
Did he try to drop his CV in a job board with the mention "Rust developer"? That's the fastest way to find a job, IMO. Some service companies will try to sell him to a customer, if there are any.
Although it's not directly related to your question, if you don't need access to all files simultaneously it's better to avoid loading all files in to memory at the same time.
This is how I'm developing a rust/web-view app: * Rust backend via GraphQL (Juniper) * I can test and interact with the Rust backend with typical GraphQL APIs * TypeScript/React/Apollo frontend I created my own Apollo "link" that just uses the web-view related means of communications, so that there are no "real" network requests.
Cool tutorial. Got some TIL moments from there aswell
it sounds great, just don't ever step off the happy path, lest you plummet to your (performance) death. also, numpy (etc.) is calling fast code, but calling it from python entails a LOT of overhead. in my experience it's difficult to write a slower rust program, assuming basic competence. the big cost of rust is development time, which makes it unwieldy for data exploration.
If only it didn't suck. It breaks all the time and often everything freezes for minutes.
# &gt; Shell completions for Cargo Yay, this will be a nice quality-of-life improvement!
Pinging /u/nasa42 again to make sure I get an answer... :)
I’ve used Matlab and Python a lot in the last 15 years. Both have the unhappy feature that the runtime can be proportional to the number of lines of code (though I’ve heard Matlab has a JIT now). However if you take care to vectorise your code (ie use matrix algebra instead of for-loops and list-comprehensions), and use the tools in their recommended way, they are incredibly fast once you start dealing with meaningfully large datasets. At scale, if you know what you’re doing, the interpreter overhead just becomes a constant noise factor in the overall runtime. I could see a case where computationally intense feature extraction from large files might be faster in Rust. But most of the scientific Python stack is ultimately written in assembly, FORTRAN and C (occasionally generated via Cython) and has been continually fine-tunes by an enormous body of developers over a decade.
Your name is suspiciously pertinent for this post...
They truly great thing about VSCode is that it is open source. You can file a bug or a pull request and it will only get better over time.
Ah, I didn't see this one. It is still a bit annoying to keep track of positions and sizes ... but you got me an idea.
...until the next nightly update.
Both IntelliJ IDEA and the Rust plugin are free and open source as well: https://github.com/JetBrains/intellij-community https://github.com/intellij-rust/intellij-rust
You're right! and with @WellMakeItSomehow answer, I realized that I could probably store directly the `Entry` obtained in the iterator. Initially, I was afraid by the `Archive::entries()` doc saying: &gt;Note that care must be taken to consider each entry within an archive in sequence. If entries are processed out of sequence (from what the iterator returns), then the contents read for each entry may be corrupted. But I may have misunderstood this warning. I just tried something where I kept the `Entry` in the hashmap. Then later read each entry (part of the tar file) only when needed as you suggest. I think if I'm careful to read only once each entry, I shouldn't have any issue. The following code seems to run without issue: fn run(archive_path: &amp;str) -&gt; Result&lt;(), std::io::Error&gt; { let archive_file = File::open(archive_path)?; let mut archive = tar::Archive::new(archive_file); // Create a hashmap with the content. let mut data = HashMap::new(); for file in archive.entries()? { // Check for an I/O error. let file = file?; // Insert the file into the hashmap with its name as key. let file_path = file.header().path()?.to_str().expect("oops").to_owned(); data.insert(file_path, file); } for file in data.values_mut() { let mut buffer = Vec::with_capacity(file.header().size()? as usize); file.read_to_end(&amp;mut buffer)?; println!("file size: {}", file.header().size()?); } // Sleep to have time to observe memory consumption. std::thread::sleep(std::time::Duration::from_secs(10)); Ok(()) }
Tbf most of the libraries are written in C++
FWIW, I find the inverse of `copy_into` to be more intuitive for a channel/stream/socket API. E.g. this: writer.write_from(reader) rather than reader.copy_into(writer)
Are there any examples of linux kernel modules built-in Rust? I'm expecting there's going to be a lot of unsafe code referring to kernel code, so would it even make sense to use Rust?
Nothing unidiomatic about that, IMO.
It comes from Ruby and Smalltalk. fn in a similar way to that is already used for function pointers.
The standard library will include the API for an executor, but won’t provide any implementations. You’ll need some sort of external crate.
Does it detect low performance nudity too?
Hum, actually when processing the actual image files in another order (not the normal sequence as in the above `data.values_mut()`) It crashed :(. So I guess I did understood correctly the warning the first time XD
I also speak from deep of experience in both languages, doing intense numerical work with large datasets. I just take issue with the idea that it's "incredibly" fast. Blas is fast, but what kind of idiot isn't calling Blas when appropriate? Ndarray + Blas is as simple as `features = ["blas"]`. Opening a 10-20gb data file in python is *painful* - and you better have lots and lots of memory. Anything that's custom (i.e., you can't call an existing numpy function) will be horrendously slow. I'm not saying it doesn't have its place. I prototype models in python, it would be extremely onerous to do that work in rust. But, like, have some standards! Numpy performance is just not terrible, as long as you never venture off the happy path.
We organize RustLab in Florence, Italy: [https://www.rustlab.it/](https://www.rustlab.it/)
Also https://github.com/rust-unofficial/awesome-rust. However, both lib.rs and awesome-rust can contain yanked crates, plus IIRC the latter also contains projects not published on crates.io or other registries.
It might be worth enabling [this libstd feature](https://github.com/rust-lang/rust/blob/master/src/libstd/Cargo.toml#L59-L60) via xargo if panic formatting messages are what's causing your problem
[`exa --tree` looks like it](https://the.exa.website/features/tree-view) might be [*nearly* what you want.](https://the.exa.website/features/filtering)
I've done something like this before (seems very similar, I was just precomputing a bunch of costly features and it had to be in python, rip would've used akka/scala) but to avoid all the forking and spawning and crud, I used \`multiprocessing.Pool\`. Afaik you can only use \`Pool.map\` to map a single function onto data so to work around this, I took each function I needed to call and its args and wrapped them all up in lambdas that just take nothing and call it with the args and returned, and just mapped Pool.mapped the list of lambdas onto a list of empty tuples. End the end, it may've been the harder option but I got to barely deal with python's shitty multiprocessing bits.
Don't engage with this account, which is a sockpuppet for /u/monkey-go-code 's trolling.
Try storing the offsets and lengths instead.
This is my only account.
More like nightmare. Mixing rust and C/C++ is a dream in CLion right now, I don't want to give that up.
I'm surprised I had to scroll all the way to the bottom of the thread to find this response while everyone else is talking about non-lexical lifetimes, which is not the root cause of the issue.
Yeah numpy's and matlab's data readers are pretty slow ... I'm actually surprised how easy it was to write an equivalent crate to numpy's loadtxt that just puts it to shame in terms of speed ... well maybe easy for someone more familiar with text parsing I had some learning to do. I'd also like to add that Rust can just as easily call those optimized libraries with the right bindings. We're just still building up the libraries/crates that bind to those libraries.
This might be a bug in the standard library. If you can reproduce it with a clean install of Rust, open an issue on GitHub for it
Must be a `RwLock&lt;Blog&gt;`
I haven't really been keeping track of the async/await discussions, but it sounds like a fundamental change in borrowing and lifetimes. Is there a good reference where I can catch up? Is anyone worried about it?
Sometimes the runtime of the preprocessor can be a hindrance to your exploration. We had a Python preprocessor that took literally a week to run (originally designed for a smaller dataset). I recently rewrote it in Java using Beam and it runs in literally 20 minutes now. It's sort of a generic tool over a range of problems, so less time preprocessing means more time spent exploring actual ML. I think Rust could potentially be useful in that niche.
Would you recommend rocket as the best option for services in a 'micro-service' architecture? Right now where I work we're running node/express services. Probably less than 100 services (each one running several instances), but not by a lot. I'm thinking of putting together a proposal to look at rust.
I've been checking https://areweasyncyet.rs periodically. Not sure whether there's a newsletter specifically for it, but it does come up often enough in This Week In Rust to consistently remind me to give that site a visit.
[https://doc.rust-lang.org/book/ch09-03-to-panic-or-not-to-panic.html](https://doc.rust-lang.org/book/ch09-03-to-panic-or-not-to-panic.html) &amp;#x200B; The impl of guess in this chatper should be exactly what you're looknig for.
But "rt" can often mean "real time" as well. Naming things is hard!
That's a very good point, thanks, hadn't thought of it.
Yeah, this like make library and calling it “library”. Or publishing a crate called “crate”.
Try /r/socialist_programmers Or any socialist sub, there probably will be someone with coop experience or at least with sources to study. Im also heavily interested in making a programming coop, but havent stopped to study how it would work.
Good idea, [here](https://www.reddit.com/r/socialistprogrammers/comments/be8nq3/how_to_best_set_up_a_socialist_programming_coop/) I posted it.
Gentle suggestion to make sure you use one of the A- variants of the GPL license, since this will be running on servers, not on clients. Since people running software on their own servers, they're not "distributing" it, and so don't have to provide source to users. The A- variants fix this. Here's the Affero variant of GPLv3: https://en.wikipedia.org/wiki/GNU_Affero_General_Public_License
Maybe you should use more time reading the subreddit description before you post. This one is about the Rust programming language, not the game.
Wrong subreddit my dude
Upvote for AGPL, best license ever.
Totally agree, this uses the [AGPL](https://github.com/dessalines/lemmy/blob/master/LICENSE).
Hey guys just started new server Rustanonymous is the name! Enjoy
[fd](https://github.com/sharkdp/fd) isn't really _tree_, but it shows a recursive list of files while not showing hidden and gitignore'd files by default.
/r/playrustservers
/r/playrust
Thanks! I'm already using `fd` but looking for a tree-like output. I _suppose_ I could write a script that formats `fd`'s output if I really wanted to.
&gt; not working with actual unordered processing code So one thing worth mentioning is a `tar` archive literally means **T**ape **AR**chive. It is a continuous stream of data, which assumes it'll be read from start to end every time it is accessed. The idea is you can use Buffered IO and only load each section into memory as needed. --- For indexing, and searching a `tar`. You'll likely want to read the entire archive, and build a `HashMap&lt;String,u64&gt;` of `path` and `offset` data (assume it isn't compressed). Then search the `HashMap` Alternatively, if you know what you are looking for head of time, you can `filter` the `Entries` directly while reading. [personal example](https://github.com/valarauca/car/blob/master/car_cli/src/extract.rs)
&gt;stabilize the `alloc` crate Woot, woot!
This is very close to arenas, but not quite. I have an implementation of such a type here: [https://github.com/mtak-/swym/blob/master/src/internal/alloc/dyn\_vec.rs](https://github.com/mtak-/swym/blob/master/src/internal/alloc/dyn_vec.rs). The main thing I punted on was supporting overaligned types - I didn't actually need that for my use case.
Maybe you can't do this for some other reason, but it sounds like using another archive format may work better. For instance, I believe you can access files in a zip archive in an unordered fashion without much effort. That said I haven't used anything like this in rust, so I can't comment on a good library to use.
I see some references to `vectored` reads and writes, what are their purpose?
 Even though I think both products are great, I have absolutely never seen vscode freeze. And breaks all the time? I don't even understand what you mean by that. RLS breaks? What breaks? VSCode is just a shell that other things are loaded into. I'm fine with someone liking intellij more than VSCode, that's why we have different products so people can have different opinions, but don't lie about it.
Either rocket or actix web. Rocket is imo currently much simpler and more mature and refined. Rocket uses classic sync functions as handlers. Actix uses async and the actor models which is nice but both actix and async is a bit immature imo. Right now I would say rust. Probsbly actix-web from early 2020 forward
You'll still be able to do everything with the Rust plugin in CLion. It'd work similarly to how IDEA/PyCharm work today: the dedicated IDE is just a stripped down version of the main IDE that comes with that plugin default, but e.g. IDEA + the JetBrains IDE has all the capability of the python plugin, which is what powers PyCharm. &amp;#x200B; TL;DR "IntelliJ Oxide" would be CLion with the Rust plugin but without the C/C++ plugin. (And probably focus on Cargo support rather than requiring Make to function.)
Thanks. I appreciate it.
"Vectored" IO scatters reads and gathers writes. This means you can give it a list of buffers to use, instead of just a single one. This interacts better with some custom allocation schemes that want to reuse buffers as much as possible, even though the required read and write sizes vary wildly over time.
You're welcome!
Ok thanks! I managed to do it like you say: struct FileEntry { offset: u64, length: u64, } fn get_buffer&lt;R: Read + Seek&gt;( name: &amp;str, file: &amp;mut R, entries: &amp;HashMap&lt;String, FileEntry&gt;, ) -&gt; Result&lt;Vec&lt;u8&gt;, std::io::Error&gt; { let entry = entries.get(name).expect("Entry is not in archive"); read_file_entry(entry, file) } fn read_file_entry&lt;R: Read + Seek&gt;( entry: &amp;FileEntry, file: &amp;mut R, ) -&gt; Result&lt;Vec&lt;u8&gt;, std::io::Error&gt; { let mut buffer = vec![0; entry.length as usize]; file.seek(SeekFrom::Start(entry.offset))?; file.read_exact(&amp;mut buffer)?; Ok(buffer) }
Yep, I eventually [did exactly that](https://www.reddit.com/r/rust/comments/be7gg5/memory_efficient_way_of_storing_tar_archive_data/el4b54j?utm_source=share&amp;utm_medium=web2x) :)
Can you create the tar archive such that files are stored in the order you need to process them?
We (TrendMiner, Hasselt) have been using a small program written in Rust for 2 years now. We're a Java shop in general, but are using other languages where it makes sense. This part (an NSS plugin) does not see much actual development though, since it just works... No other Rust work on the horizon right now. I'm not aware of other companies in the area that use Rust and neither have I had to interview people who had Rust experience or even listed it on their resumes, which of course does not help in promoting more usage of Rust. So if you cannot find a real Rust job, I would suggest to join a company that is open-minded about things like this and be sure to suggest Rust when there is a a clear case for using it to solve a problem. If the thing you're writing is core to the company, the chances of it sticking and being used for further development would increase.
 struct FileEntry { offset: u64, length: u64, } AKA `[u8]` :-). ZIP archives would work a bit better since they're random-access, but it's the same thing in the end, and it's not like you'd get anything from compression. Do you need to process the files in that specific order?
This is an OS question, not really a rust question. Assuming you are on Linux or something sufficiently similar, the answer probably involves turning off line buffering and input echo, and dealing with the output terminal directly instead of as a `Write`. There are crates to do those things but I'm not sure which are current.
Basically \^\^. Zip doesn't bring much here since the archives are basically 99.9% png images and 0.1% txt files. And one specific txt file inside the archive gives me the processing order of the images, which is important since images are from a video stream.
just published my first Rust project, a [radio link simulator](https://github.com/PTScientists/link-simulator) for development and test of satellite communication links
Don't try to get an ide set up if you're totally new to programming; it will hide the essentials from you meaning you'll have to go back and re-learn them later. You're basically already running into the hidden-essentials issue it sounds like. Just a text editor is all you need. (I wouldn't exactly recommend notepad but something simple like notepad++ or sublime is sufficient.) Use `rustup` to install rust; instructions are on https://rustup.rs. You can run the tools rustup installs from PowerShell on Windows. Read the rust book (won't even try to link it because maintainers apparently don't make any effort to avoid link rot) to learn about cargo.
Just sort them when creating the archive :-).
I don't have this "tar-fu" level ahah. And more seriously, other users of the app should be able to just `tar -cvf *` their dataset folder and it should just work*
They don't want to hear about servers either, and send folks to /r/playrustservers
That's fantastic! This is MIT-licensed, so I can use this as a base. Thanks!
You could take a look at [tree-rs](https://github.com/sighol/tree-rs) (I am the author). However, It does not support ignore files. There is also [treeify](https://github.com/dzamlo/treeify). You can pipe output from fd into treeify and display a tree.
I'm starting to use generics, but am stuck on something. I have a function which I want to return a struct which implements \`MyTrait\`, so I have the return type of that function set to \`impl MyTrait\`. The function body is a \`match\` expression. Each arm of \`match\` will return a struct which does implement \`MyTrait\`, but it is still yelling at me about each match arm being a different type. How should I do this?
What is the difference between `fn foo() -&gt; impl MyTrait` and `fn foo() -&gt; T where T: MyTrait`?
I am having problems running cargo bloat, since the project is a static library, and I can't use the elf file(s) as input. As I mention initially, I suspect that I have unwittingly pulled in core::fmt - I will see if I can unravel the dependencies.
Derive macros are permitted to emit macro\_rules, so you'll need to shim everything through a hidden derive macro. For an example of this see the derive in [`linkme`](https://github.com/dtolnay/linkme).
When you return `impl MyTrait`, your function gets to decide what specific type you're returning. When you return `T`, the caller gets to pick what T that is: ``` fn foo&lt;T&gt;() -&gt; T where T: MyTrait { // ... } let x: SomeImplementation = foo(); let y: OtherImplementation = foo(); ```
You can't do it with impl Trait (which has to resolve to a single type, not multiple alternatives), but you can return trait objects: `Box&lt;dyn MyTrait&gt;`
It also lowers the syscall overhead as you can send multiple operations at once.
If the visit order is fixed you'll get best performance by ordering the tarball correctly. If you really need random access use a randomly accessible archive.
Ah, so `impl MyTrait` means "this function isn't sure which type it will return, but it will return a concrete type that can't be coerced into anything else" and `T where T: MyTrait` says "let the caller coerce it into something else as long as that something else implements MyTrait"?
&gt; so impl MyTrait means "this function isn't sure which type it will return, The function knows exactly what type it will return - it just isn't going to tell the caller. &gt; "let the caller coerce it into something else as long as that something else implements MyTrait" Sort of, but there's no coercion going on in the second case. The first call that returns `x` is calling a function that returns exactly the type `SomeImplementation`, and the second call that returns `y` is calling a function that returns exactly the type `OtherImplementation`.
Actually `impl Trait` in return position hides the type from the caller, which allows to restrict the API of the return type, without requiring either boxing or dynamic dispatch, which would both have a runtime cost. The compiler still knows and monomophizes the return type.
Your problem is with your implementation of the trait - instead of introducing new type variables (which cannot be inferred) you should add your trait bounds like this: impl&lt;F: Send + 'static + Future&gt; AutoRuntime for F where &lt;F as Future&gt;::Item: Send + 'static, &lt;F as Future&gt;::Error: Send + 'static { ... }
VSCode has never frozen for me in the past 3 years. Can't say the same about Intellij.
Qt
Oh, it was so simple! Thanks, now it is perfect!
That is what web developers do. I think. It should not be a problem if you dont use dark apis And MacOS uses the same webview gtk uses
Ah yeah, when you make a staticlib, it's going to pull in the world and all of your dependencies. It's up to your final compiler/linker to drop unused sections, because otherwise Rust can't really tell what is and isn't used. There is some kind of open issue for that, but I don't have the link handy.
Glad you're going to experiment on this
Pandas can read in 2.1GB of data in 52sec if it’s stored in CSV or 2sec if it’s stored as a Parquet file. Benchmarks: https://uwekorn.com/2019/01/27/data-science-io-a-baseline-benchmark.html As I said in my original comment, if you’re doing bulky feature extraction on unstructured data, other languages may work better. E.g. I once wrote a custom Twitter tokeniser in Java (so I could use Lucene) that wrote the features out to a Numpy file which I could load into Python. It was fine. Also, for huge datasets, there’s Pyspark and MLlib, though the new [Pyspark UDF decorator](https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html) alliés you to mix Numpy and PySpark with minimal marshalling issues. Python may well have failed for your use case. However Python/Numpy/Scipy/Scikit-Learn/Pandas/PySpark can be made to work well in many other cases. It offers acceptable performance and great productivity. And if you need the fill in gaps in performance there’s Numba or Cython: the latter of which I’ve used.
A friend of mine projects to bring rust in her startup. I'm forwarding her the thread..
`tar` adds the entries in the order from the command line. If you use `*`, that's going to be expanded by the shell, and the resulting list should be sorted alphabetically (depending on your locale, but that's probably irrelevant here). You mentioned WASM, is your app running in the browser? Does the user provide that archive? It might be better to support drag-and-drop to the browser window, which would be much more efficient as you wouldn't need to store more than one image in memory.
Working on a metric storage system. Like graphite/ganglia. I doubt it will come to fruition but I’m learning loads. Right now I’m working on the on-disk format. I’ve previously on a semi-related project gotten a statsd parser written in nom. If this goes further I can bring that into this project to build a more complete (in terms of my project) metrics ecosystem.
Underaligned types (`&lt; mem::size_of::&lt;usize&gt;()`) may not work either, as I'm pretty sure I always force usize alignment.
I upgraded my Rust port of the `d` documentation generator ['docket'](https://github.com/iwillspeak/docket) to use the latest version of Pulldown-cmark. Took a bit of tweaking as the latest version switched how it tokenises `[TOC]` which my code recognised to replace with a tree of contents. As part of these changes I made first use of Azure DevOps pipelines for CI on a Rust project. Turned out to be pretty simple to get set up [using the rust docker container](https://github.com/iwillspeak/docket/blob/master/azure-pipelines.yml#L3) for building.
Nice! If you haven't found it already I recommend Bob Nystrom's ["Crafting Interpreters"](http://craftinginterpreters.com/) as a hands-on introduction to language development.
I once replicated some of the benchmarks present in numpy repository to ndarray. I found almost near identical performance in both. Ndarray used less memory compared to numpy in some cases. It might be due to some overhead associated with calling C code from python. I was really impressed with the performance of ndarray considering how much effort has gone into numpy. In my benchmark, both numpy and ndarray had openblas as backend. It must be before some 8 months. Not sure whether ndarray improved after that.
It sounds like what you are looking for is type state analysis, which used to be a feature in Rust but was dropped before 1.0. You can mimic it with some of the building blocks in Rust's type system, though: https://pcwalton.github.io/2012/12/26/typestate-is-dead.html
&gt; but it sounds like a fundamental change in borrowing and lifetimes It isn't. Rust's type system is already powerful enough to express pin, and there are a variety of compilation strategies to regular rust lifetimes. https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md#the-expansion-of-await
The short answer: don't worry about it. The long answer: it depends. On algorithms, hardware, etc. If your algorithm clones an `Arc` **a lot** then you might notice a difference compared to `Rc` or `Box`. If your algorithm creates (and/or destroys) boxes or arcs **a lot** then you might notice a performance difference compared to keeping things on the stack. But unless you're making microbenchmarks, the rule of thumb is that you won't notice any difference. And I suppose you are not, because if you were, you would have made a few instead of asking this question 🙂
[Zip supports uncompressed archives](https://superuser.com/questions/411394/zip-files-without-compression).
Good to know (the file order)! No wasm yet, it's my goal \^\^ to be able to run those algorithms in browsers. We cannot Drag and Drop folders, only files. The directory structure of the dataset is somewhat predetermined, to be compatible with some evaluation scripts, and contains subfolders so the simplest way to support wasm is in my mind to be able to work with an archive. In case you're curious, the aforementioned work is a research project ([https://github.com/mpizenberg/visual-odometry-rs](https://github.com/mpizenberg/visual-odometry-rs)). I'm a bit tired of research work never being accessible (both in terms of paper availability, and easy code reproducibility) so I'm trying to make it easier for people to reuse and/or simply test the code.
This is the third arewexyet sites I've seen for rust, is there a list of them somewhere?
Thanks for the link, that sounds quite interesting.
That link doesn't point to anything.
Ah, I didn't know that \^\^. I'm probably not going to invest time in multiple archive formats but out of curiosity (maybe for later), is there a reference crate for zip and such?
In the case of returning `impl MyTrait` is it correct to say all code paths in the function must return the same concrete type?
Yep!
Does this count as an index? :p http://imgur.com/a/HZGQc3N
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/qP8Go8t.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20el4ycdw)
Good bot
^thanks ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)
Maybe, but it will probably take a lot of work! The library the video uses is [tcod-rs][tcod] and that's just Rust bindings for a C++ library called [libtcod]. And that in turn relies on [SDL 2][sdl]. It is possible to compile C++ to webassembly and I believe emscripten is able to work with SDL. So in theory, you should be able to use the `wasm32-unknown-emscripten` target and build tcod-rs and your program. However, I'm not aware of anyone actually getting that far or what issues it might entail. I'd start with just trying to get libtcod to work with emscripten. Once you get that, you can try building tcod-rs (possibly having to modify the [tcod-sys' build.rs script][build]). I've seen this thread where someone tried to do the first step and didn't get very far: https://users.rust-lang.org/t/compiling-to-wasm32-with-emscripten-an-app-that-uses-a-c-library/20161/2 So I've no idea how much work would any of this be. However, if you or someone else does manage to get this working, I would be delighted to merge it to tcod-rs! [tcod]: https://github.com/tomassedovic/tcod-rs [libtcod]: https://bitbucket.org/libtcod/libtcod [sdl]: https://www.libsdl.org/ [build]: https://github.com/tomassedovic/tcod-rs/blob/master/tcod_sys/build.rs
Thanks. I'm going through this in detail to make sure I understand it. It uses nightly features that don't show any sign of being stabilised. So Rust doesn't seem ready to support this kind of thing officially in stable yet. So the choice is to make a nightly-only crate which stays in limbo indefinitely, or do a hack with some runtime checks to fail ASAP if anything changes in Rust core. I guess this is why no-one has made a crate yet. I will think some more.
You're welcome! https://i.imgur.com/Q5NnBt9.png?fb
I'm crying right now
You could do something similar with quicksilver, here's a roguelike template for it https://github.com/tomassedovic/quicksilver-roguelike
if we weren't ready to scrap code, then we wouldn't be here ;)
What happened, are you okay?
have you thought about not using Gluster?
I don't think we have gluster hard coded in there anywhere? This supports anything that serves NFS. Netapp/Gluster/ etc all should work.
ah. my misunderstanding. thanks for clarifying.
You also post over https://community.coops.tech
But that might also mean that **the plugin is removed**, so you can't use it for free in IntelliJ Community, but have to buy the Rust IDE.
"IntelliJ Oxide" -&gt; "IntelliJ OxIDE" :-)
Hey you got a good guide to set this stuff up? Or a resource to learn it
Yep, `cargo watch -cs 'cargo check &amp;&amp; cargo test -- --nocapture'` is a good one
There's some infrastructure to write kernel modules here: https://github.com/alex/linux-kernel-module-rust
It would probably be better for the location arguments to take `T: Into&lt;PathBuf&gt;`, then call location.into() to produce a PathBuf. That would allow a wider variety of arguments, including some that cannot always be represented by &amp;str such as OsStr.
I will PM you my email - please send his email and some relevant information to me. I would then be glad to set up a call with your friend and gather some more information as well as give information on the opportunity we're offering. Thanks!
You might want to look at https://opencollective.com/
Ah yes that's a great idea. Thanks!
I wanted to try this; the VS Code plugin works well. However, since I'm not familiar with Erlang or Rebar3, I didn't know how to setup a "Hello World" project, so I copied the `example-url-shortener` repo, ran it with `rebar3 shell`, and got this error: ===&gt; Verifying dependencies... ===&gt; Fetching elli ({pkg,&lt;&lt;"elli"&gt;&gt;,&lt;&lt;"3.2.0"&gt;&gt;}) ===&gt; Version cached at /home/ludwig/.cache/rebar3/hex/hexpm/packages/elli-3.2.0.tar is up to date, reusing it ===&gt; Fetching gleam_experimental_elli ({git, "https://github.com/gleam-lang/gleam_experimental_elli", {ref, "ea3e87a8e7fddfc2505260a48940c93c184255ac"}}) ===&gt; Fetching gleam_experimental_stdlib ({pkg, &lt;&lt;"gleam_experimental_stdlib"&gt;&gt;, &lt;&lt;"0.1.1"&gt;&gt;}) ===&gt; Version cached at /home/ludwig/.cache/rebar3/hex/hexpm/packages/gleam_experimental_stdlib-0.1.1.tar is up to date, reusing it ===&gt; Compiling gleam_experimental_stdlib sh: Zeile 0: exec: gleam: Nicht gefunden. ===&gt; Hook for compile failed! The second-to-last line translates to "**sh: Line 0: exec: gleam: Not found.**" Maybe I did something wrong?
There's still no stable way to split a `*const dyn Trait` into a vtable and data pointer, and put it back together. Well, you can transmute to `[*const (); 2]`, but that's not guaranteed to work in the future. There also is no way to pass unsized values to a function without using `Box`.
The first point, yes that makes sense. I would have to fix up the code if anything changed, and fail ASAP at runtime if something didn't look right, which is not at all ideal. The second point, I think you can pass an unsized value by making the type a parameter, e.g. `fn defer&lt;F&gt;(&amp;mut self, cb: F) where F: FnOnce() + 'static` to take one example.
there's [this](https://wiki.mozilla.org/Areweyet) which you may find helpful.
Oh this is perfect, thanks
Looks dope, thanks!
Oh shit that's awesome. That removes a ton of boilerplate for really simple Iterators or functions that are best expressed as such. fn magic (w : f32) -&gt; impl Iterator&lt;Item: f32&gt; { let mut x0 = w.sin(); let mut x1 = 0.0; let b = 2.0 * w.cos(); from_fn(|| move { let xn = b * x0 - x1; x1 = x0; x0 = xn Some(xn) }) } That's a sine wave oscillator for example
Thanks for drawing attention to it - I had overlooked it!
And abbreviating something that's really used as a crate name is not worth the confusion!
Can you talk about the motivation for this tool?
Note that the sister function \`successors\` could also be useful for your case of generating a sequence -- particularly if you want to use a check to add and not a normal addition. Another important difference between the two functions is that \`from\_fn\` doesn't implement \`FusedIterator\` -- which can be important for some optimizations. In short, make sure you know the guarantees of what you're using for you get carried away!
The generated assembly for [a simple example](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;code=static%20mut%20value%3A%20i32%20%3D%203%3B%0A%0Apub%20fn%20change(new%3A%20i32\)%20-%3E%20i32%20%7B%0A%20%20%20%20unsafe%20%7B%0A%20%20%20%20%20%20%20%20let%20old%20%3D%20value%3B%0A%20%20%20%20%20%20%20%20value%20%3D%20new%3B%0A%20%20%20%20%20%20%20%20old%0A%20%20%20%20%7D%0A%7D) has the static variable being accessed with an offset from `%rip`, so it's position-independent.
&gt; Saving and Loading data is rather simple, so why are databases so complicated and bloated? This line screams [Dunning-Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) to me and I wouldn't feel safe trusting my data to this as a result. Without going into the massive pile of things covered by SQLite's test suite, here are some reasons databases are "so complicated and bloated": 1. Most importantly, [ACID-compliance](https://en.wikipedia.org/wiki/ACID_(computer_science)) in the face of decades of hard-won discoveries about how OSes sacrifice reliability in the name of performance. 2. Allowing many users to safely *read and modify* the same data at the same time. ([MVCC](https://en.wikipedia.org/wiki/Multiversion_concurrency_control) is one way to accomplish that.) 3. Support for on-line updates to the schema and indexes to account for changing needs in a system where every second it's offline could cost you a fortune. 4. Replication, for redundancy and scaling. SQLite is certainly simpler, being an embedded database rather than a server, but guaranteeing point 1 (ACID) is a lot harder than it seems at first and I'm sure there are much faster approaches than yours if I'm just doing a cache. (And if I *am* storing data which can't be regenerated, I'll go with SQLite since it's the one that's tested thoroughly enough that it winds up in avionics.)
This information is helpful. Thank you for the clarifying points.
See https://guiand.xyz/blog-posts/unboxed-trait-objects.html
Awesome! That is a great use case.
Okay thanks, but I have no idea what a text editor is or how to get it set up for myself. I want a nice free one as well.
The points you bring are perfectly valid. But there are some things I'd like to address. &gt;This line screams [Dunning-Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) to me and I wouldn't feel safe trusting my data to this as a result. I was more talking about the complexity of use by the one implementing the database in an application, not necessarily the database backend itself. Which correct me of I'm wrong, it sounds like you're referring to. &gt;Allowing many users to safely *read and modify* the same data at the same time. ([MVCC](https://en.wikipedia.org/wiki/Multiversion_concurrency_control) is one way to accomplish that.) It's great that you do bring this up because I haven't actually thoroughly thought it out. In my test cases and usages it hasn't been asynchronous access. Which is why I haven't put emphasis on this. I should probably switch to a more concurrent model with either mutex locks or MVCC as mentioned. &gt;Support for on-line updates to the schema and indexes to account for changing needs in a system where every second it's offline could cost you a fortune. The reason I created sfsdb was because I saw a hole between simple file read/writing, and huge database framework that take over the application. The issue described is generally more a problem with the intended consumers of the more framework-like databases, and not this. Although with support for managing the database using closures, you could achieve something like this.
Hi, [Tock OS](https://www.tockos.org/) has a very similar (identical?) problem. I've been working on Rust app support for Tock. First question: are your binaries moving around as a whole (e.g. loaded into RAM) or does their read-write address space move around relative to their read-only address space? Tock does the latter, as executables are executed out of flash while read-write data is located in RAM. There is a description of how Tock's C apps work [here](https://www.tockos.org/blog/2016/dynamic-loading/) -- but LLVM does not support the necessary relocation model so currently Rust apps cannot be dynamically positioned like C apps can. If everything is loaded into RAM, you have a number of options. Generally, you'll want some form of dynamic linker to fix things up. The easiest option is probably to use position-independent code (this may be the default), in which case you'll probably get a relatively small set of relocation types. Unfortunately, the implementation if your linker will need to be custom for your architecture. I'm happy to talk about it further -- PM me if you'd like to talk over the phone and/or video call. I am on vacation through the next weekend so I may not be responsive but I can try to set up a call to discuss it.
Looks good! One of the suggestions I have for [your code](https://github.com/mzhong1/File-Forklift/blob/ba8374d7713ae996a0b5d50d422f97ca02f74638/src/tables.rs#L518 is: ``` pub fn current_time() -&gt; NaiveDateTime { let now = Utc::now(); NaiveDateTime::from_timestamp(now.timestamp(), now.timestamp_subsec_nanos()) } ``` Can be ``` pub fn current_time() -&gt; NaiveDateTime { Utc::now().naive_utc() } ``` Or `naive_local()` if you are returning the local time
It seems like this: [https://docs.rs/termion/1.5.1/termion/fn.async\_stdin.html](https://docs.rs/termion/1.5.1/termion/fn.async_stdin.html) is exactly what you want? I did something similar with [https://github.com/robbieh/dasblinkenping](https://github.com/robbieh/dasblinkenping) (sorry, it's new, and I'm sorta-new to Rust). I just pass the Keys on through an MPSC channel back to the main thread.
I don't have time to type up more at the moment, but I recently discovered that `#[derive(Debug)]` tends to bloat binaries significantly. I definitely noticed tons of UTF-8 manipulation code pulled in as a result. You'll need to somehow convince the compiler that you are not using any of the `#[derive(Debug)]` derivations so they're optimized away (you are using LTO, correct?). I don't know if you can do that without forgoing `Vec` entirely. In particular, watch out for Options and Results, and I think unwrap() can use Debug.
Yeah. I haven't tested it out yet, but it looks like it'll work as a very close approximation of how I like to use generators in Python.
And for completeness: https://doc.rust-lang.org/std/iter/trait.FusedIterator.html
Ahh. The way you described it made it sound like you were comparing yourself to client-server database engines, given that SQLite occupies the niche you're now describing and isn't really that complicated to use. For the line I quoted, I'd suggest one of these alternatives: * Saving and Loading data is rather simple, so why is putting it in a database so complicated? * Saving and Loading data is rather simple, so why is using a database so complicated and bloated? * etc. Even then, though, I'd argue that "Saving and Loading data is rather simple" is a misleading statement. It's rather simple if you don't actually want to guarantee that you'll be able to read what you saved in real-world situations. I've used various simple data stores and I've managed to corrupt everything except SQLite by doing seemingly harmless things with them. I actually managed to corrupt what I wrote into Python's BerkeleyDB bindings on my first try, just by hitting Ctrl+C.
Just FYI, for you or anyone else who sees this: OpenWL now supports creating plugin-friendly windows on Windows and Mac. On Windows the HWND gets nested in the host's provided HWND, on Mac the internal NSView is shared with the host. I only tested with VSTHost (VST2) and AULab (AU2). TODO: Linux LV2, verifying that the same approach works with VST3/AU3.
What I don't like about sqlite is that it doesn't feel native to the language (in this case rust). for example; in sqlite you would query the database using strings of code in an entirely different language, while in sfsdb you use closures. Sfsdb in Rust takes advantage of what rust is good at. Such as DOP. While SQLite more feels like an entirely different system you communicate to from rust
Some functions for converting cartessian to spherical coordinates and the other way around. I didn't end up using it, so published it in a gist in case somebody need it: [https://gist.github.com/theypsilon/f09305889e1fd5aa182999af3bad10b9](https://gist.github.com/theypsilon/f09305889e1fd5aa182999af3bad10b9)
Alternatively, a simple enum iterator, provided it implements Copy fn iter_from (&amp;self) -&gt; impl Iterator&lt;Item = StandardEnum&gt; { let mut v = *self; from_fn(|| move { v = match v { StandardEnum::A =&gt; StandardEnum::B, StandardEnum::B =&gt; StandardEnum::C, StandardEnum::C =&gt; StandardEnum::D, StandardEnum::D =&gt; StandardEnum::E, StandardEnum::E =&gt; None, } v }) } fn iter() -&gt; impl Iterator&lt;Item = StandardEnum&gt; { StandardEnum::A.iter_from() }
Yeah I'm much more familiar with Go, so I assume you'd be able to set things up similarly. Since Go doesn't have generics, I tend to write a package as a wrapper for an event loop. The external interface is just a threadsafe wrapper that forwards "messages" into the inner event loop over a command channel, and will do setup for the inner loop struct when I call Start(). The messages themselves contain a command enum define, args if necessary, and a reply channel that I then listen to. I tend to call these things "Engines". It's sort of a half-assed erlang GenServer pattern, except with the external interface instead of an inbox full of messages.
Thanks. This takes more space than mtak-'s solution above, because it allows random access (which some people might need, but I don't). Also, to get the vtable, instead of using nightly features it makes assumptions about fat pointer layout that Rust doesn't guarantee. (Same issue as discussed above.) It seems likely that this is the best we can do on stable, though.
You should definitely look at [`treeify`](https://crates.io/crates/treeify) for that. :) I use it fairly frequently with `fd`.
This is great! Feel almost as have generators, and is easy to use!
A simple hack may be just turning the result of find into a Vec with collect. Then let rayon do the parallel map on that Vec. Not nearly as suave, but could get the job done.
It occurs to me that this is likely to be the sort of thing that seems small/minor, doesn't get much attention at first, and probably will be taken for granted by most... but actually quite significantly contributes to the general ergonomics of Rust, and makes it a pleasing thing to use.
You know? I think I finally am. Yeah. Yeah, I'm okay. I am okay. Okay.
VS Code or Sublime are my favorites. VS Code is kind of an ide as it allows extensions and such. There's a popular rust extension that gives you autocomplete and such. Also, there's a terminal built right in so you can compile/run right from the same editor.
That is a point I considered too. The ideal situation of course is too have them incorporated; alternatively I'd create a repo based on the subset of my changes in the fork, but as I mentioned before those have downsides too such as potential confusion between why there is a *winapi* and a *winapi_bth* (once *winapi* incorporates the changes). A side note; my initial believe was that there was a way to incorporate a local copy of a crate inside another crate that you can reference when published. As it turns out you need to publish that local crate too. Knowing that, the only way forward I see is to publish my bindings separately, as you said, or wait for the maintainer to merge the PR.
I did not offer him money, but instead offered to help him review some other PRs to reduce his workload - if he deemed me capable of following his style guidelines i.e. I personally felt that to be more in the spirit of open-source collaboration, than paying to get something done.
Happy cake day!
Thanks!
\&gt;much better writers &amp;#x200B; lol care to name \*any\*?
Using `successors` you can write the equivalent Fibbonacci generator even more succinctly. ~~~ fn fib_sequence() -&gt; impl Iterator&lt;Item = u64&gt; { successors( Some((0,1)), |(prev, current)| { Some((*current, *current+*prev)) } ) .map( |(_,current)| current ) } ~~~
Have you tried using \`find\_map\`? &amp;#x200B; fn main() { let v = vec!\[ Err("I am an error"), Err("I am an error"), Err("I am an error"), Err("I am an error"), Ok("First real value"), Err("I am an error"), Err("I am an error"), Err("I am an error"), \]; if let Some(s) = v.into\_iter().find\_map(Result::ok) { println!("I found \\"{}\\"", s); } } &amp;#x200B; https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=073b8a39df8831ea2df1051f8680f868
A multi threaded renderer (w/ winit + gfx-hal)! Got stuck trying to figure out how macros work for the first time. Hopefully, will be done by the end of today, at least.
Been tearing my hair out for a while trying to find some documentation on how to properly export/use macros. I'm trying to define a macro in my lib.rs and use it in the main.rs but I have no idea how to do it. The resources I find don't seem to be helping much about that either, so I figured I come to reddit. &amp;#x200B; Basically, I'm trying to define a macro and use it in the same crate. How/is this possible?
I totally agree with you. I wanted to posted about `from_fn` because it is a more general case. This is a great use of `successors`. Personally, I would format your function like this: ``` fn fib_sequence() -&gt; impl Iterator&lt;Item = u64&gt; { successors(Some((0, 1)), |&amp;(prev, current)| { Some((current, current + prev)) }) .map(|(_, current)| current) } ``` I like the use of the tuple and the immutable values.
&gt;successors Thanks for sharing! I didn't know about successors!!
That *is* a common complaint about SQL-based databases. They accomplish language portability by feeling equally foreign in all languages. Personally, I'm willing to accept some discomfort in exchange for being able to trust my infrastructure more. (eg. I recently discovered that rust-cpython **may** (just "may") not be free of an inducement to undefined behaviour present in PyO3, so I've decided to use it more as a prototyping aid and, once the overall design settles down, I'm planning to rip it out of my PyQt+rust-cpython projects and switch to some kind of subprocess-and-named-pipe FFI.)
There's https://github.com/faern/rips/tree/master/packets which looks pretty decent from a glance. I also watched this talk recently which introduces a relevant project: https://www.youtube.com/watch?v=UfMOOxOGCmA, [but it's not really aimed](https://fuchsia.googlesource.com/garnet/+/refs/changes/50/210750/10/bin/recovery_netstack/core/src/wire) a public consumption (yet?).
Haskell has an interesting function matching syntax that adds in some local names: capital all@(x:xs) = "The first letter of " ++ all ++ " is " ++ [x] I recently had a really hairy piece of match code that worked on an `enum` that was a little verbose, but then wanted to use the matched value further in an expression inside the branch. Does Rust have something similar to the `@(x:xs)` idea? I have a vague feeling that it has been described in the Rust book in passing but I can't for the life of me find it. :) I could just straight out use the enum value from the HashMap look up that the branch eventually does, but I was hoping that keep the compiler-assist in play to let me know when I haven't handled all the cases instead of having a default action during run-time.
You can destructure enums in match arms. If you had a List enum with variants Nil and Cons(x, xs), you could get the head from a list as: fn safe_head(L : List char) -&gt; Option&lt;char&gt; { match L { List::Cons(hd, tl) =&gt; Some(hd), _ =&gt; None } } If that's not what you were talking about, one of the later chapters has a reference for pattern syntax https://doc.rust-lang.org/book/ch18-03-pattern-syntax.html
[@ bindings? ](https://doc.rust-lang.org/book/ch18-03-pattern-syntax.html)
Aha! What I have in my type can't be destructured in this way because is does not have any other data. Quoting from the link on pattern-syntax: &gt; For enum variants without any data, like Message::Quit, we can’t destructure the value any further. We can only match on the literal Message::Quit value, and no variables are in that pattern. At least I know that I wasn't leaving something on the table for refactoring.
With a macro_rules! macro, you might just need to annotate it with the #[macro_export] attribute if you haven't already. For proc macros, AFAIK you still can't define and use them within the same crate, which there's a legit reason for that was explained to me once and has to do with compilation, but I can't remember the details.
Is there any way to use/open an enum's namespace in the same module it's defined for a scope larger than a function? Writing out Enum::Variant(_) =&gt; every time I want to match, or starting every function with use Enum::*; is bumming me out.
Tried to shoehorn it into where that seemed logical and it fails to parse. I commented it out in the sample below: ``` match evaluation { StudyEvaluation::Unreviewed /* @ u // but this doesn't grok */ =&gt; { let delta = config[&amp;StudyEvaluation::Unreviewed /* &amp;u */ ]; self.confidence.change(delta); } // rest of my match elided... ```
Can you expand on rust-cpython?
I made a `VecOfDst&lt;DST: ?Sized&gt;` type: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=bbeecccc025f5a7a0ad06086678e13f3 as part of writing up the Motivation section of the Pointer metadata RFC https://github.com/rust-lang/rfcs/pull/2580. This provides iteration but not random access indexing. It supports arbitrary alignment. It requires Nightly, but you can port it to Stable today if you hard-code a given trait. (The RFC, if accepted and implemented, would allow the generic library to be defined in Stable Rust.)
If the types are `Send`, try https://docs.rs/rayon/1.0.3/rayon/iter/trait.ParallelBridge.html#tymethod.par_bridge.
&gt; That is a common complaint about SQL-based databases. They accomplish language portability by feeling equally foreign in all languages. Besides the existence of ORMs which you mention, SQL can be extremely powerful, especially when you index your table appropriately. For querying, SQL is more expressive than your favourite general-purpose language. I've seen a lot of apps basically retrieving a couple of database tables in full just to perform some aggregations that the developers either didn't know how to express in SQL, and their ORM wasn't able to generate.
It's the other way around, i e `u @ StudyEvaluation::Unreviewed`, not `StudyEvaluation::Unreviewed @ u`.
Just put the `use Enum::*` outside the function, like this: #[derive(Debug)] enum Rusts { Mold, Yeast, Funghi, } use Rusts::*; fn main() { match Mold { Yeast =&gt; unimplemented!(), u @ _ =&gt; println!("{:?}", u), } }
So if I understand correctly, the idea is to read different files from multiple machines at once to improve throughput? &gt; Samba does not support multithreading. Didn't this change with Multichannel support?
That first benchmark is likely getting optimised to nothing, removing the function calls/iteration, since 27 picoseconds is very *very* few cycles (less than 1).
As long as a location is mentioned on the meetup page, I won't mind including it.
You're totally right. I apologize. I ran it again with Criterion's \`black\_box\` and got slightly longer times (roughly 480 picoseconds). Does that sound more reasonable?
I tried playing around with this over the weekend, but was too stupid to figure out the borrow checker. I'll have to take a look later this weekend.
Thanks! Yet another reddit bug. Should work now.
Thanks!
After reading the readme I have no idea what this does.
This seems cool but can you / anyone elaborate a bit on why exactly? What would a common use-case be for this? Just to cut back on the verbosity of iterators or is there more to it?
 Basically, yeah (verbosity). Means you're much more likely to create them, which leads to superior code quality and a more maintainable codebase (iterators are much easier to compose than alternatives, and to debug).
That's exactly what prevents me from going to a full bazel build setup. Languages are so ingrained in their environments (e.g., Cargo for Rust, Webpack for the JS/TS world) that it's a challenge to match the dev experience with a "non-standard" build system. Let us know if you manage to get a smooth flow.
We (https://mototomo.io, Brussels) are using Rust along with Typescript, Rails and Swift. We are not expanding the team yet but I'll let you know if that changes.
That’s really interesting. I like the idea of passing iterators around as opposed to materialized arrays. Thanks for that!
[https://twitter.com/AmethystEngine/status/1118770896569819137](https://twitter.com/AmethystEngine/status/1118770896569819137)
Hi All. How does one set a cookie using reqwest to a request (and possibly reuse it?)? I looked at the documentation - but I didn't find anything obvious about how to set it.
I asked this same question a while ago here on this subreddit (but not as a separate post but as a comment to a post ) [Post](https://www.reddit.com/r/rust/comments/74rbgl/what_new_rust_libraries_would_people_like_to_see/do0p3ai?utm_source=share&amp;utm_medium=web2x)
Is it a key-value store ? How does it handle concurrent access ? crashes ? power failures ?
Yeah, successors is super useful for IDE stuf: https://github.com/rust-analyzer/rust-analyzer/search?q=successors&amp;unscoped_q=successors In particular, I believe [this](https://github.com/rust-analyzer/rowan/blob/11b085ef278e46286ff2d16262b0d6fd57628c9f/src/algo.rs#L119) function was the reason i’ve tried to help to bring successors to itertools/std (the actual impl is by SimonSapin, not me).
The readme is seriously lacking. From the doc it doesn't look like a database at all but like a rudimentary key-value store.
Amazing, that could be the case where Amethyst can shine.
Apparently I alrwdy know how to use it. I really don't, even after reading the readme.
Congrats to everyone! The community is awesome and the project is definitely deserving of this. Excited to see the progress that can still be made.
Shameless plug: rust-analyzer has code for supporting non Cargo-based projects https://github.com/rust-analyzer/rust-analyzer/pull/939. I am not sure how well it works in the wild, I don’t use it myself and I don’t know if anyone does.
Yes, but I have to take care of the binary size first.
I sent a mail to a company asking if they need a Rust developer. While they mainly use Java, they were positive to the idea of doing some things in Rust, and in further meetings they identified several possible projects that could be done in the language. The expectation is that I should get to work about 50% with Rust, and I am happy with that. So my advice, if you would be okay with possibly not working 100% with Rust, is to apply to any (open-minded) company as a Rust developer rather than looking for one that is already using the language.
Is it possible to generate a Cargo.toml file using Bazel for the sole purpose of enabling IDEs?
For IntelliJ specifically, this should work the other way around: IntelliJRust should export some kind of RustProjectModelProvider extension point, which could be used by something like rust-bazel plugin to teach IDE about the project model. That shouldn’t too be hard to implement, it’s just no one has done this so far.
How does it perform against a fibn without Iterator?
As someone who was waiting for Generators, how is that really different? What would Generators let me express that this wouldn't?
I follow the evolution of Amethyst through your forums. I know you are working in the integration of Rendy, and exploring ideas with the editor tools, scripting language and UI. WebAssembly support its an overkill feature. This is a good new, Im looking forward to see how nice Amethyst can be in the future.
Which is also exactly the way it works in Haskell...
Corecursion all the way up! :)
Europe is much more conservative when it comes to adoption of new technologies. I'm a node developer and even for node there's very few jobs outside of the UK in Europe. Belgium is a very small country so in general theres not that many jobs. People here might downvote me, but if he is looking for a job as a Rust developer, especially as a recent grad then he is doing it wrong. He should look for a developer role, not a Rust developer role. He can pick up basically any language on the job and as there's a shortage of developers many companies will be willing to hire him without being good at the tech stack they use. But waiting for a job specifically in Rust will probably mean he will be unemployed for a long while.
I don't know of any, but I am interested to know as well :-).
Why do you think webassembly support is overkill?
If you already filter (or just append an additional `filter` to your chain) you can just use `next()` to get the first entry.
Did you claim the entire KULeuven for yourself, u/KULeuven?
YES. I find creating your own struct implementing Iterator to be quite cumbersome for simpler things.
If someone wants something actually usable, fast and with a simple API, sled is awesome!
nice! This is going in the toolbox.
At [Barco](https://www.barco.com/en/) (Kortrijk, BE), we are using Rust in our products and are looking for people to extend the team. PM for more info!
Congratulations! I really look forward to WASM games!
People are downvoting you because node jobs are all there seems to be right now.. also in Europe.
I didn't choose the right word. I thougth that the meaning of overkill was different. What I wanted to express is that Webassembly support will be a great addition. It's important to target all the platforms and in the coming years I think that Rust will be tier 1 for Webassembly. So, sorry for confusing you, since my english isn't the best I ended up writting the opposite of what I wanted to. Thanks for pointing it out.
Yep, that's probably an easier way to do it. The benefit of using libtcod is that it's giving you a lot more than just rendering: field of view, path finding, noise, random generation, bsp... It's awesome if you've got a traditional-ish roguelike in your head and don't want to deal with be researching all of the tech. But: you may not actually need all that in your game. And what you do need can be put together with additional crates. If/when I get to write another roguelike, I'll almost certainly go with Quicksilver because of the crossplatform+wasm aspect and greater control over the graphics (i.e. not being bound to the cell grid, the ability to keep the map tiles square and the text readable, etc.).
See this comment: https://www.reddit.com/r/rust/comments/azit15/i_made_a_super_simple_example_guide_of_how_to/ei8fbd6/?context=3
If i'm not mistaken, when running a program the OS should allocate a memory block for it. That block would allocate memory sectors for the heap and the stack. I assume globals probably can be detected at compile time and have their memory allocated at startup as well.
Oh, that explains why it seems alien in a C-like syntax. Thanks for your answer.
Don't apologise for your English. It's not a good language. it just happened to have a very powerful Navy behind it for a few hundred years.
You're English is excellent. I completely agree with you, WebAssembly support is an exciting feature.
I wonder if a `hint_size(Some(n))` iterator extension method would be useful now that `from_fn` is a thing.
Then check out the examples
I guess it could use a "usage" section for those who don't dive into examples to sum it up
Nice piece! &gt; One possible improvement might be to make the opposite assumption: that these lifetimes are all the same. I've had the same thought. The problem is that it's difficult to know if that really is a more common case. Searching through existing code doesn't give much because that code is written by developers under the assumption of how it is already. I've seen a lot of code (especially on Stackoverflow), where developers "fix" a borrow error by introducing a lifetime variable and applying it to every reference in sight, so all references have the same lifetime. This might seem to support your idea, but actually this approach produces very constrained lifetimes, so code isn't as flexible as it could be, which leads to other problems when you try to use it elsewhere. The current default is as flexible as possible, letting users add constraints if they need to. I'm not saying this is definitely better, but it's not so clear cut if your suggestion would be an improvement. &gt; The basic idea is that threads are spawned within a concurrency nursery, a different kind of structured control flow block. At the end of the block, all spawned threads are joined back together. Is this different from Crossbeam's [scoped threads](https://docs.rs/crossbeam/0.7.1/crossbeam/fn.scope.html)? On the surface at least, it seems to achieve the same goal.
No, that's not quite enough; it's still on the order of a single cycle, which suggests it may be being folded to a constant at compile time. You may need to use `black_box` on both the input and the output.
Putting aside whether this is a good database and whether it can handle edge cases such as power failure I think one part of the design is really bad for its longevity: The fact that it needs to be rewritten in other languages. The simple fact that you can't have clients in multiple languages for the same "database" means that different implementations will either split at some point or the development will just die more quickly than ordinary.
Think of `impl SomeTrait` as a placeholder for a type we use instead because either we don't want to or we cannot name the actual type that is returned. It doesn't require any generics: fn squares() -&gt; impl Iterator&lt;Item = i32&gt; { (1..=10).map(|x| x*x) } This example shows the motivation for wanting such a feature. Would you know the name of the actual return type? The closest we can get to its name is `std::iter::Map&lt;std::ops::RangeInclusive&lt;i32&gt;,_&gt;` where `_` is a placeholder I picked for the closure's (`|x| x*x`) type. But ... this closure's type doesn't have a name! So, we can't actually fill this blank. As someone who calls this function, you only know that you get something which implements `Iterator&lt;Item = i32&gt;`. You can ask the compiler for its size and use its iterator interface. You hold something in your hands you can't name. But there is no overhead involved. Specifically, this *does not* involve any indirection or boxing. It's just a value with an anonymous type. And as far as type checking goes, the compiler lets you do only those things to this value which have been promised to work (iterator) even though the compiler knows exactly what else this type can and cannot do. fn main() { let s = sequence(); println!("size of iterator in bytes: {}", mem::size_of_val(&amp;s)); let v: Vec&lt;_&gt; = s.collect(); println!("sequence: {:?}", v); }
Coincidentally, I made [this PR](https://github.com/bluss/rust-itertools/pull/341) last week!
You actually will be able to use the same database from the rust, and the experimental Go version. This is of course a matter of opinion but I think the greatest flaw of things like SQL is that it often isn't implemented from scratch for each language, making it feel as an entirely different system you interact with from your codebase, instead of a part of your codebase itself.
I'm actually kind of surprised it still exists at all. I just assumed it was absorbed into the WASM target or something.
this is the wrong subreddit, try r/playrust
I was actually quite Sunrise that rust didnt have this before since, I used the eqivalent in Scala quite frequently
&gt; this approach produces very constrained lifetimes, so code isn't as flexible as it could be I had wondered if this might be a downside. I really don't know either whether it would be an improvement. My current plan is to try it the way I suggest and see what the ripple impact might be on whether it reduces annotations and if it worsens polymorphism. One nice thing about building your own language is you get to play with possibilities and see what happens as a result. &gt; Is this different from Crossbeam's scoped threads? You are the second to suggest that Rust can already do this, with Rayon being cited as another example. From a brief examination, I am now inclined to believe it can. The principle is the same in all three situations: borrowed references become passable when threads have a delimited, and smaller lifetime. As I mentioned in [my reply to the other post](https://www.reddit.com/r/ProgrammingLanguages/comments/beivdv/the_power_of_lifetimes_cyclone_rust_and_beyond/el6bp83?utm_source=share&amp;utm_medium=web2x), I am curious to know how this is being handled under the covers by Rust. Is the Rust borrow checker doing a lifetime check on threads, or is there some other mechanism at play? In any case, I clearly must have misunderstood something I read in Rust documentation a couple of years ago. Thank you for your kind and helpful feedback.
I mean compared to Java or .NET jobs they are a super minority in Europe. I would definitely not say "node jobs are all there seems to be right now".
Your English is perfectly understandable to me! Don't fret about that :)
You're organizing people around a social media endeavor, using Rust as the tool to accomplish it. Consequently, your coop would be something along the lines of a social media coop. Good on you for planting your flag and making something that people can organize around. Good luck!
Thanks! So is that what I need to use for my return type? The function I'm trying to create will take an input that I know the type of (basically a string) and then convert that string to a struct and return that struct. All of the structs implement the same type. It could return FirstType or Second type, etc.
First of all, awesome job! I'm currently using the Annoy model quite a lot and I was wondering if you have any idea of the performance between the two? Otherwise I'll definitely investigate it.
Instead of `u @ _ =&gt; …` you can just write `u =&gt; …`.
Yes
They are absolutely not a super minority. I have a Rust job and most misguided job offers I receive are about node.
[`process_results`](https://docs.rs/itertools/0.7.5/itertools/fn.process_results.html) might be useful as long as the iterator is returning Results. It passes all the Ok values to a closure until it encounters an Err, then bubbles up that error.
That's incredible news. I was waiting for this to happen honestly to start using amethyst.
Are you crazy? I might believe that there are a slight percentage more Java and even .NET jobs. But in no way shape or form are javascript/node jobs a super minority. You don't even have to try to find a javascript job, they almost literally grow on trees.
Yes
Thanks! I'll experiment with this. If you need any more motivation for your RFC, my use case is for a very minimal single-threaded actor runtime, where I'd like to make queuing a call and later executing it as efficient as possible, because there will be a lot of these calls.
Hey now, no reason to hate on English. Also, most would be shocked to hear it has a relatively high information rate: https://www.realclearscience.com/blog/2015/06/whats_the_most_efficient_language.html
Yes
This is very interesting. I'm very interested right now in porting/releasing a game for web - but I HATE JavaScript and really enjoy lower level statically typed languages, and the game is a bit complex, so WebAssembly seems like a great (maybe the only) fit. I like Rust, but Quicksilver seemed like the only option, and I just ran into too many roadblocks and decided it's too much of a headache to be working in both a language + framework that are so new. So I switched to C++/SDL2, which seems good so far. Anyway, how does Amethyst compare to Quicksilver in maturity? And when would we expect complete/robust WASM functionality?
So this creates one file per key? It might be good to add a disclaimer in the README to explain that...
Yes
Given that we already have generic iterators over arrays and vectors, what is the use case for custom iterators over arrays/vectors of some arbitrary item? Coming from old-style C++ (I only just convinced my boss to update to C++11), I am really new to the whole concept.
No, this is not suitable in your case. The type remains nameless but it's still a single type. The compiler figures out what type you mean by analyzing the function. It looks for a single type. If you want to return something of a type that depends on runtime information, this requires some kind of runtime polymorphism which usually involves an additional layer of indirection (reference, pointer, box, etc). For example, you can make a `Box&lt;dyn MyTrait&gt;` refer to an object of any type that implements `MyTrait`. To put it differently, *runtime* polymorphism allows the *dynamic* type to be different from the *static* type. The *static* type is the type information known at compile-time. The *dynamic* type is something that's not necessarily known at compile-time. It's a runtime property. So, a reference of type `&amp;dyn Display` refers to something we can display but we don't need to know at compile-time to what dynamic type it refers to at runtime. Working with such an object requires dynamic dispatch which is why we use `dyn` in there to make this clear. Type placeholders like `impl MyTrait` are purely a compile-time thing. It's just about *not* naming the concrete type. But there *is* a single concrete type which is *known at compile-time*. It just doesn't have to have a name.
Yes.
What generators give you is the opportunity to do different things. Example: fn gen() yield u32 { yield 2; yield 3; yield 5; for i in (10..15) { yield i; } yield 143; } If all you do is mutate a state to get a new value, then `from_fn` is what you want. If all you do is apply a transition to the previous value, then `successors` is what you want. In more complicated cases where you need a state machine, then you need a generator (or a manual state machine).
I thought this article was a bit unintentionally provocative with how it shows that it's very easy for amateurs to get discouraged from attempting to hand out multiple references to what is 'simply' a record. IMO, it's not surprising most people just reach for clone() when they need those instead of complex reference types like `RwLock&lt;Arc&lt;struct&gt;&gt;`.
What about IE6?
It is possible, and it has been half done a couple of times https://github.com/bazelbuild/rules_rust/issues/71 https://github.com/bazelbuild/rules_rust/issues/95
Do you think that's better than having bazel generate Cargo.toml?
I have been handwriting the Cargo.toml to match BUILD files.. but they are definitely able to be generated. There was some discussion about this in rules_rust
This is a subreddit for the rust programming language. Go to /r/playrust for the video game subreddit.
Is there a way to match on an enum variant without spelling out the enum's name explicitly? Ie is there a way to omit "MyEnum" in the following? ```rust match my_enum { MyEnum::A(x) =&gt; {}, MyEnum::B(x) =&gt; {}, } ``` I reckon Rust _should_ be able to infer the enum I am matching on anyway.
hmm, the first thing that comes to mind is that this wouldn't let you yield mid-function like python generators would
Well i guess YMMV, there's a lot of JS jobs but they are mostly front end at least in my experience. When I was looking for a job through talent.io I got a lot of offers from the UK for node, but in all other European countries I got Java or Rails ones, literally 0 Node interview requests outside of the UK.
I'm sure that, as with all software, there will be bugs.
yes
I'm a bit late to the party bu here's [my solution](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8a48abf018bf617eb15a59c95f958cb7). It has the same semantics as Haskell, that is, it does not evaluate any part of the list strictly. This also means I need to make a custom Thunk and List class. It's similar to the code by u/boomshroom with a few differences: * There is no unsafe code * calling `prod` creates a thunk rather than actually executing the code. We only execute the code once we need to print the values. * This should work fine for infinite lists. * Thunks are not parameterized by their function, so from an outsiders perspective, any Thunk that generates a value of type T has exactly the same type. Some remarks * Thunks are a monad (I think) * `pure(x)` is `[x]` * `concatMap` is `bind` * `concat` is `join` This was actually a really great learning exercise.
Gotcha. Thank you very much. I really appreciate it.
Site seems to be dead
I think English is an excellent language. There are some issues with pronunciation, but in written form it's simpler than most other languages out there. You don't have to think a lot about conjugation of verbs depending on the grammatical person, and you don't have to think about the gender of the words. Also the 26 letter alphabet is a pretty good size when working with computers.
Clients can feel natural for the language. You don't need to reimplement the whole database just to make it feel natural. Slap a unix socket with a simple text on top and write whatever clients you want.
So, I just encountered a bug in my implementation yesterday that was causing it to work for small datasets but broke down at larger ones. When I tried to fix it I actually reached the type name length in Rust (the automatically generated names from closures appearing in combinator sequences and such). I haven't been able to resolve this yet and I am blocked by the name mangling v2 refactor in Rust. I can give you an update right after I am able to resolve the issue.
yes
I can see that you're trying to encourage initializing new immutable values by using `RwLock&lt;Arc&lt;Config&gt;&gt;`, but set up like this, it requires an allocation every time you want to update a single field. I find using Arc is mostly useful if you have a very large structure where several copies of a single instance are being used around the instance, or if you specifically want to mutate a value and have the change visible from other threads. In this case, I'd probably just use `RefCell&lt;Config&gt;` or even `Cell&lt;Config&gt;` since the allocation just seems superfluous.
There is some relatively new documentation on the two ways to export macros here: https://doc.rust-lang.org/nightly/reference/macros-by-example.html#scoping-exporting-and-importing If you have two separate crates (lib and bin), then you'll probably want to use `#[macro_export]` on the macro and then in the crate you want to use it have `use mylib::mymacro;` to import it.
Guess, we couldn't target that browser anymore. Question is, is IE6 support is worth all the resources the compiler team does have to spend to support asmjs.
I'm confused about returning `Box&lt;dyn My trait&gt;`. So far my return types have been, well, types. It seems weird to return a pointer to a trait. I thought pointers we're for referencing objects like structs or vectors. Traits aren't objects though, are they? I always thought they were on the level of types where they weren't actually objects that can be referenced or manipulated. I can't clone a trait, can I?
My usage of unsafe was mostly because I wanted thread safety without unlocking on every read, and because Rust could really use some support for atomic enums. It would not have been hard for me to avoid unsafe of I want working with those objectives. It does now occur to me that Rust has default route parameters, so I could have made it `Thunk&lt;T, F=Box&lt;dyn FnOnce()-&gt;T&gt;&gt;` and provided fairly simple conversions to box the function.
Iterators in Rust aren’t really like iterators in C++. Rust’s iterators can express iteration over sequences that don’t come from a collection at all; the closer analog are C++20’s new *ranges* (if you’re familiar with them).
Noob question: How bad/much slower are clones? I do it all the time, but I never benchmark any of my stuff. How much slower does it make my app on average? Is it 10%? 2%? 0.6%? 0.001%? ...?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/u_aunpyz] [I'm excited about std::iter::from\_fn](https://www.reddit.com/r/u_aunpyz/comments/bemco9/im_excited_about_stditerfrom_fn/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Yes, although, as mentioned in the thread, a more lightweight standalone wasm to asmjs converter would be a cool way to still support older browsers.
Unfortunately no. I see how iterators in Rust are useful for things like mathematical sequences. I suppose that they could be used for random generation as well. Could you use Rust iterators to transform a byte slice into a known data structure?
Yes! The [`collect`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect) method (and supporting functionality in `FromIterator`) is available for exactly that purpose.
There is an error in this article, `thread_local` is distinct for each thread, so if you were trying to modify the configuration from one thread, and then access that in another thread, that other thread wouldn't see the changes. If this is intended, I would go with `RefCell&lt;Config&gt;` instead. If this is unintended, I would go with `lazy_static!` storing `RwLock&lt;Config&gt;`.
I understand that, but if it allows me to run arbitrary code paths then I can just redirect the execution flow wherever I want everytime, as every time it gets to the end I see it as a 'yield'
But is that a question of ergonomics or is this something I couldn't express with from\_fn? Because like I answered to another person it looks to me that if I can arbitrarly specify any code paths I could get arround the state problem by passing the state as parameter every time.
it depends on the system. clone() allocates memory. In best case scenario allocator has available block of required size, worst case is that system has no memory, reaches for disk or kills random processes. Avg is somewhere in between, but run your own benchmark to figure out where exactly. RwLock etc. isn't free either.
How does this compare to using [iterate](https://docs.rs/itertools/0.7.5/itertools/fn.iterate.html) or [unfold](https://docs.rs/itertools/0.7.5/itertools/fn.unfold.html) from itertools? Seems very similar
Yes this is what I was thinking of, I've looked into Intellij-Rust a bit, but haven't had time to really think this through. It might be a lot of work, and I don't have that endurance for non-work coding.
I think these things are great concepts to work with, except that I’m wary about using indices as pointer-replacements. They work around the borrow checker only so that you have to implement these things all by yourself. You might be able to skip a few things because you (allegedly) know more about your code than it does, but it’s a dangerous source of bugs.
I think so: *if* you already have requirement that rust code should be build by Basel, the it’s just more direct to feed info about project system directly to IntelliJ than going via Cargo, losing Bazel specific info along the way.
Ah this is interesting, I'll take a further look.
Excellent piece. Extending lifetime from borrowed references to threads sounds like a genius idea. However, I say sounds because obviously I don't know the full scope of it's reprecussions.
It depends heavily on the type. Generally, expect worse when you have vectors inside, unless the 'clone' is just a RC or Arc counter bump.
Sure, but you have done that before by implementing the `Iterator` trait. In my mind, the attraction of Generators is that they abstract the state machine...um...machinery and make the code read more like it's using standard control flow
So in normal useage a trait is indeed a type-level construct that doesn't actually exist at runtime. However, you can use a trait to define an actual type called a "trait object", and this is what the `dyn Trait` syntax refers to.
Wow, I was reading that syntax "backwards" for quite a while. This works for me now.
I'm currently trying that, but it's only good for a single target. I don't think `cargo-raze` isn't intended to support workspaces, so if you have multiple targets, I think keeping bazel in sync with Cargo gets tricky.
These are useful links thanks!
Ergonomics. The whole point of yield/await is to make creating those 'linear' state machines easier and more readable (and thus less buggy). This is not to be underestimated! The simplification is often extraordinary and very user friendly (which attracts more coders as they don't get intimidated by the state machine and saving and restoring of 'scratch' arguments on the resume).
 let res = client.get("http://www.example.com") .header(reqwest::header::COOKIE, "I'm a cookie!") .send()?;
IMHO, SQL couples the syntax and semantics too tightly. It's designed to be written by humans and is too difficult and error prone to write programatically. It would have been better if SQL was some kind of low-level machine-readable language instead. Something like a lisp for specifying relational operations. Then each you could more easily specify the queries however they like, including using plain SQL as done today and then translate it to the low-level API.
Use the [reqwest::header::SET\_COOKIE](https://docs.rs/reqwest/0.9.15/reqwest/header/constant.SET_COOKIE.html) header. You may also want to use [reqwest::ClientBuilder::cookie\_store](https://docs.rs/reqwest/0.9.15/reqwest/struct.ClientBuilder.html#method.cookie_store) so that you persistently store cookies that you receive.
My understanding of the example was that the thread local variable was shared by cloning the inner Arc and passing the clone to another thread.
Whenever you always return `Some(x)` from `from_fn`, you can always use `repeat_with` instead: ```rust use core::{mem::replace, iter::repeat_with}; fn magic(w: f32) -&gt; impl Iterator&lt;Item = f32&gt; { let mut x0 = w.sin(); let mut x1 = 0.0; let b = 2.0 * w.cos(); repeat_with(move || { let xn = b * x0 - replace(&amp;mut x1, x0); replace(&amp;mut x0, xn) }) } ```
Assuming you're using a standard TERMINFO terminal, you can use a library like [termion](https://docs.rs/termion/1.5.1/termion/) to give you more fine-grained control of the terminal or a library like [tui](https://github.com/fdehau/tui-rs) to create terminal interfaces.
Yes. I appreciate that some folks still use IE6 for whatever reason, but we can't continue spending dev cycles supporting these folks forever. Most mainstream websites, including Google started dropping support for IE 6 10 \_years\_ ago. Today less than 1% of users use it.
You're always teaching me new things on here. I appreciate it.
I have done that, and now they both run about 15 ns. I really appreciate the feedback. I am learning, although publicly haha.
&gt;clone() allocates memory Not necessarily, cloning Rc/Arc is just a manipulation of the counter. The cost of cloning depends on what you do with the clones and what types you're cloning: * Cloning `Rc` is basically free * Cloning `Arc` shouldn't be visible, unless you do it in a very hot function/loop * Cloning of specialized persistent data structures is usually the cost of cloning `Rc` or `Arc`. * Cloning of anything else (strings/collections, etc.): * If you're going to read most of the cloned structure afterwards anyway, you're fine. Cloning in this case can slow you down by max \~2× (but I guess usually a few percent or less). * If you're eg. cloning e HashSet, just to call a single `get` on it and then throw it away, they the clones would slow down your code a lot. In such a case, use `Rc` or `Arc`. u/boomba, ↑
If you mean just a function \`fibn(n: u128) -&gt; u128\` that returns the nth fibonacci, I just tried it with a benchmark and it rand in exactly the same time. But the function, \`fibn\` does not get you nearly as much functionality as the iterator does. The iterator is not restricted to using only the \`nth()\` method.
Thanks, after your comment I tried Zeal and really liked it. Some stuff don't seem to work off-line (I assume there is some javascript shenanigans in the docs) but otherwise it is a huge improvement over using the browser.
Thank you for your response, it was very informative. We are planning on loading everything in RAM since that seems the easiest. I did some more googling last night and came across the [relocation model](https://doc.rust-lang.org/rustc/codegen-options/index.html#relocation-model) compiler flag set to pic. Do you have any experience working with it? Instead of using having a global offset table like I've seen with other position independent code implementations, it instead it has a table of offsets in the middle of the text and uses the PC as an offset. For example, the following code ```Rust use core::panic::PanicInfo; static mut value: i32 = 3; static mut VAL2: i32 = 4; pub fn change(new: i32) -&gt; i32 { unsafe { let old = value; value = new; VAL2 = old; VAL2 } } ``` Generates the following assembly ```ASM Disassembly of section .text: 0000000000011000 pie::change::h6975ae8f74c8e3dd: ; pub fn change(new: i32) -&gt; i32 { 11000: 83 b0 sub sp, #12 11002: 01 46 mov r1, r0 11004: 01 90 str r0, [sp, #4] ; let old = value; 11006: 07 48 ldr r0, [pc, #28] 11008: 78 44 add r0, pc 1100a: 02 68 ldr r2, [r0] 1100c: 02 92 str r2, [sp, #8] ; value = new; 1100e: 01 9a ldr r2, [sp, #4] 11010: 02 60 str r2, [r0] ; VAL2 = old; 11012: 02 98 ldr r0, [sp, #8] 11014: 04 4a ldr r2, [pc, #16] 11016: 7a 44 add r2, pc 11018: 10 60 str r0, [r2] ; VAL2 1101a: 10 68 ldr r0, [r2] ; } 1101c: 00 91 str r1, [sp] 1101e: 03 b0 add sp, #12 11020: 70 47 bx lr 11022: 00 bf nop 0000000000011024 $d.1: 11024: f4 0f 00 00 .word 0x00000ff4 11028: ea 0f 00 00 .word 0x00000fea ``` Do you think this will provide the functionality I want?
Methods have access to every member of `self`, so ideally you should be able to just do `println!("{}", self.a);` inside of the `bar` method.
Could you give an working example in [playpen](https://play.rust-lang.org/)? Without actual code, we could only guess what fit into your scenario.
Not every iterator can be parallelized. first collecting and then executing will do the trick. Other options are: If you want the processing (i.e. the map function) of what you find to be run by rayon you can use [this](https://docs.rs/rayon/1.0.3/rayon/iter/trait.ParallelBridge.html) If you want `find` to be parallized you have to reimplement [this](https://docs.rs/select/0.4.2/src/select/document.rs.html#149-162) piece of code from select.rs using rayon
No, absolutely not. This is one of those things that I really don't like about Rust's wasm ecosystem right now is that it absolutely does not care about any other use case that is not wasm-unknown + wasm-bindgen. It is extremely frustrating that everything else is constantly breaking and now even considered to be thrown out completely. One of these use cases is targeting IE11 (and possibly IE10), which is a real requirement that is still necessary nowadays. And no, there still is no good polyfill / converter, unless you want to emit 500+ MiB of JS or want impractically slow polyfills. Fortunately the emscripten people are also dropping fastcomp (which is their asmjs compiler) and are replacing it with wasm2js which is now very actively maintained, but until that is actually properly working, I would very much advice against removing the asmjs target. Maybe js-unknown-unknown could become an experimental target that uses wasm2js in order to experiment switching over those use cases over time.
Yeah the motivation for this was rsync'ing filesystems that have many millions of files or close to PB size can take weeks to months to migrate. It's far too slow. The other issue is that enterprise file servers and storage clusters usually have a lot more network bandwidth than any single client has. To get around this the tool we built goes parallel with many machines all collaborating together to move the filesystem. We pool network bandwidth and threads to push the file server as hard as possible.
Good point. Want to put in a quick PR? If not I can do it
If this is on an inherent method or similar (e.g. `impl MyEnum` or `impl Trait for MyEnum`), you can use `Self` instead of `MyEnum`, but I think that's still unstable. Otherwise, `use MyEnum::*` is pretty much what you can do.
https://coder.com Have you looked at this. Maybe it can be used with Rust
Nobody is seriously talking about IE6. (The other comment in this thread that mentioned IE6 was a joke.) asm.js is also needed to support IE11, and some others like UC Browser.
Welcome!
&gt; Is this different from Crossbeam's scoped threads? On the surface at least, it seems to achieve the same goal. Crossbeam scopes are an essential building block for efficient managed threads in Rust: they give threads and their enclosed data a lifetime. However, this is neither necessary nor sufficient: Erlang supervisors meet the requirements and have no shared data between processes. The essential piece is that you also need a control structure, like Rayon `scope` or `tokio` threadpool to manage errors and cancellation. Further more the article makes the claim that you should should only spawn "thread nurseries" from an existing one. This is supported by Rayon, but ironically lifetime rules make it difficult to pass the nurseries around ergonomically so I haven't seen many with scoping more than a couple levels deep. Also having a raw `thread::spawn` construct violates the spirit requirements of the article, but that would be counter to Rust's goals so we should let that slide.
What is the purpose of ``` type Item = String; type Error = (); ``` in trait implementations? I get that it works kind of like an alias, but I don't understand the reason this is needed. Why wouldn't we just return a `Result&lt;String, ()&gt;`?
These are “associated types”, and they’re part of the interface of the trait. To implement a trait that has associated types, you need to tell the compiler which types you’re using. More can be found in the book. (That is, this is *not* the top-level type alias construct)
Awesome. Thanks for the explanation!!
It can be done this way, but then what's the point in making it essentially global. See https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=37f5c8426488e6fe6cf7a34478623c52 by the way.
It doesn't. It just writes the each value to a file named after the key.
I think the point is that you can orphan the old config and replace the source so that the next time people go to get the config they get the new version and eventually all of the Arcs for the old config get dropped.
I'm trying to implement the simplest Future according to Tokio docs (simpler what they have) and it isn't working for some reason. Could someone explain why? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0f027917b459c9ce3cb951c50ae543d3
That's orthogonal. If yield is implemented, it absolutely could.
Live for me.
&gt; in sqlite you would query the database using strings of code in an entirely different language, while in sfsdb you use closures. Sfsdb in Rust takes advantage of what rust is good at. Such as DOP. While SQLite more feels like an entirely different system you communicate to from rust This is the object relational impedance mismatch. It's unavoidable for any real relational data system. Unless you actually model the relations correctly. But then you're actually just writing the database engine again.
It just has poor type safety compared to Latin or Lithuanian
ah ok. thank you
Thanks for your suggestion. I've tried Coder before, made a free account back when it was possible. It can definitely be used with Rust, but: - it sometimes takes over 60 seconds to load - it requires more reliable connection than Cloudy does - it requires downloading 2.5MB of JS to start when cached, 12MB otherwise - their free plan only offers 2GB of RAM (out of which Coder server takes 1) and 3GB of HDD, so you need to self-host on your machine (VPS) anyway - it's not IDE-independent - since it's running in browser, some VSCode features/plugins are unavailable - and I'm not talking about "Open with default app" and "Open with default browser": though Ctrl+R to switch to recently used folders should work, it doesn't - if you are developing GUI program, or hardware driver, you want to run output binaries on your local machine. It's not that easy to download files off Coder, while it's just `cloudy get path/to/files` - Coder doesn't solve other problem I had, which is processing huge files with GIMP and ffmpeg (16GB+ of RAM required), installing x2go or vnc server manually every time is annoying So, as a power user, in the end you would be running your own VPS, rsync-ing to it to get your files (you would probably write script to automate these 2 things, hmm...), while running Coder on it, getting experience sub-par to running VSCode locally. I'm not saying Coder is not a good product, for large web-dev projects it's probably enough (and it may be godsend in large organizations, where someone would otherwise have to help newcomers install IDE &amp; toolchains). For my Rust projects however, it's not what I needed.
**Very** depends on what you are doing and what you are cloning. I work on cargos resolver, witch needs to clone all of its state once per dependency. In this [PR](https://github.com/rust-lang/cargo/pull/5132) I removed one call to clone in some cases in the hottest part of the loop. I don't know the perf difference, but it was [reported](https://github.com/rust-lang/cargo/pull/5044#issuecomment-370816600) because it was dramatically slowing down building rustc. In this [PR](https://github.com/rust-lang/cargo/pull/5118) I got a **+18%** improvement by using a `RC&lt;Vec&lt;_&gt;&gt;` instead of a plane `Vec&lt;_&gt;`. In this [PR](https://github.com/rust-lang/cargo/pull/5147) I got a **56%** improvement by using a single hashmap instead of nested hashmaps. So if you are having performance problems and you have profiled to find the slow functions, then clones can be a big deal.
So something like this: struct Settings { filename: String, // ... } impl Settings { fn save(&amp;mut self, filename : &amp;str) { if filename == "" { filename = &amp; self.filename; } println!("Saving to {}", filename); // ... } } fn main() { let mut foo = Settings { filename: String::from("aaa") }; foo.save("file1.txt"); foo.save(""); // is this okay? } I changed all names to better reflect my actual code. As you see, it's not really that much different. Anyway, this gives me another error: error[E0623]: lifetime mismatch --&gt; src/main.rs:9:34 | 8 | fn save(&amp;mut self, filename : &amp;str) { | --------- ---- | | | these two types are declared with different lifetimes... 9 | if filename == "" { filename = &amp; self.filename; } | ^^^^^^^^^^^^^^^ ...but data from `self` flows into `filename` here
Yeah exactly, that means we've got zero overhead abstractions, which is awesome! Thanks :)
Good job, congrats!
I hadn't thought English was bad until I had had the chance to consider past tense. (Realizing lately some advantages to conjugations in other languages .. ;) But I think where English is the worst is in consistency of pronunciation vs spelling. Further I'm told one of the most difficult things is all our 'direction'-modifiers that are mostly a matter of memorization. (Put on, put down, pull over, push over, drop in, drop out, in/out/over/on/onto/into/up/down/over/under, etc..) and that's not counting colloquial speech. I think you're right about having a good ratio of characters, lack of accents, tenses, etc., but English certainly lacks a certain internal consistency that makes it not such a good 'compression' when you take into account that it requires a sizeable look-up table, whereas languages that stick more strictly to rules I think are generally easier to learn.
Most of languages in Southeast Asia don't even have a thing called "conjufation" or "gender of word".
I'm just trying to understand this better. The alternative to the asm.js backend is to use webassembly, right? https://caniuse.com/#feat=wasm
Very interesting. I’ll have to look into it. Thanks!!
I'm trying to route the output of a function to the `stdin` of a `Command`, but everything I've read suggests I have to give the `Command` the data through `stdin` *after* it's `spawn()`'ed. I suspect the command finishes very quickly once `spawn()`'ed. I've tried using `os_pipe` but I think I must be doing something wrong. This is what I want to do: let pipe = pipe::new() // imaginary rust function, this type must implement Write let encoder = Encoder::new(pipe) // creates Encoder that writes to pipe encoder.encode(&amp;data, x, y, format) // encode data, write it to pipe Command::new("cat -").stdin(pipe).spawn().unwrap() // call some command with data from Encoder I want the effect to be identical to $ cat - &lt; /some/file.txt
Using indices is a horrible way to circumvent the borrow-checker. In fact, I can't think of any worse method a sane person would use. Using array/vector indices is obviously worse than using typed pointers because you lose type safety. It's also perhaps less obviously *worse than using void pointers* because when manipulating indices there's nothing to prevent you from using your index in the wrong structure, even if the structure contains the same type of stuff.
&gt;If your future isn’t a TryFuture yet, you can quickly make it one using the `unit_error` combinator which wraps the output in a `Result&lt;T, ()&gt;`. I wonder if it might be better to set the error type to `std::convert::Infalliable`. This way the fact that the `Future` can't fail is preserved in the type system. If you're fine being chained to nightly, you could also cut to the chase and use the never type directly a la `Result&lt;T, !&gt;`.
Easiest solution is to forego references and just clone your strings: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3a6fa1fce078beb6253e86a3f5b0b368 However, I kind of feel like your API is mixing separate concerns and that's where the problems are coming from. If the `Settings` struct is keeping track of where it wants to be saved, perhaps the actions of updating this path and saving to the path should be separated like this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=273b81c2b77f2f2730e66c26b594f0ea
Yes, but I think their writing is less suitable for computers, and pronunciation is usually even more complicated. And I heard (don't really know a lot about it though) that the tenses are quite complicated as wel.
I thought this could be relevant as development of the rust language/compiler has traditionally struggled with the long merge times with Bors.
There's more discussion on Hacker News: [https://news.ycombinator.com/item?id=19692820](https://news.ycombinator.com/item?id=19692820)
Unfortunately, many futures 0.1 functions expect a unit error. It's probably possible to make it generic and output any type requested, though the never type already coerces like that.
Does that include fish-shell?
The thread starts talking about npm, but Cargo.toml was added to the plugin recently. Needs polish, but works properly, I figured maybe others find this useful as well.
Ale co ma tam być po polsku? --- Sorry, couldn't stop myself.
Yea, the conjugation of the tenses is pretty bad, since there isn't a consistent system for it.
There are libraries for generational indexes that sort of combine the best of the two approaches &amp;#x200B; [https://github.com/fitzgen/generational-arena](https://github.com/fitzgen/generational-arena)
This looks great! One thing that comes to mind immediately is that I'd like a version of the `async` macro which accepts either 0.1 or 0.3 future, to avoid some of the `compat()` calls. I think if I ended up using Futures quite heavily I'd probably write helpers to try and minimise the number of explicit `compat`s I'd need to use where possible, but I understand why that isn't done here.
Why isn't there a trait for arbitrary hashmap or vector implementations so code could accept M: HashMap rather than a concrete hashmap from stdlib or a crate?
There is actually a `never_error` method as well (I think just on master, not yet released), but as boomshroom mentions: on futures 0.1 the standard was to use `Future&lt;Error = ()&gt;` and document that it shouldn’t ever produce an error value.
Looking at the changes in [the PR link](https://github.com/rust-lang/rustup.rs/pull/1646/files), looks like only `zsh` and `bash`. If you're interested, I bet it would be easy to add! :)
[It would require higher-kinded types, which aren't a part of the language yet.](https://www.reddit.com/r/rust/comments/83q25s/why_no_traits_for_collections_in_rust/dvjrp7d?utm_source=share&amp;utm_medium=web2x)
Nobody supports IE10 / IE11 for fun, so maybe more funding is needed?
Tokio w/ the async-await feature flag does this.
Does it prevent traits like GetItem, SetItem from existing?
I would use (and am using) actix-web `0.7` at least until the new iteration reaches beta. You can get the async version working like this (your `students::read` handler): pub fn read(request: &amp;HttpRequest&lt;State&gt;) -&gt; Box&lt;Future&lt;Item=Json&lt;Vec&lt;Student&gt;&gt;, Error=actix_web::Error&gt;&gt; { request.state().db .send(ReadRequest{}) .from_err() .and_then(|res| res.map(Json).map_err(actix_web::error::ErrorInternalServerError) ) .responder() } And then switch the `Route::f` for this handler in `main` to `Route::a`. In general, it looks good! I would suggest trying to remove as many `expects` as possible. actix-web makes it pretty easy to return a result.
Holy Crab! Thank you very much for this well written tutorial! This is pure fun!
Cheers! I too don't know the full scope of its repercussions, but I am excited to play with it and learn.
You should thank [Bodil](https://twitter.com/bodil), the author of this post, she's an amazing lecturer and also the author of [im-rs](https://github.com/bodil/im-rs) and [typed-html](https://github.com/bodil/typed-html)!
Pretty sure you're looking for r/playrust or r/playrustservers :) this sub has nothing to do with the game
Experienced Rustaceans - what is your working relationship and/or workflow with regards to Rust/crate documentation? In my experience in other ecosystems, I've become extremely reliant on Kapeli's [Dash](https://kapeli.com/dash) app, which only offers documentation for the stdlib and many of the links are iffy/broken after the newer edition of TRPL landed on the site. I'm vaguely aware of `cargo doc --open` but haven't really acclimated to it yet, since I have relatively sparse opportunities to write Rust - I'm full-time Elixir at my day job and on most side projects right now. Is there an even-better option I should be aware of?
I will. Thanks for sharing
If I understand what you're trying to do correctly: let child = Command::new("cat") .arg("/dev/stdin") .stdin(Stdio::piped()) .spawn()?; let mut child_stdin = child.stdin.unwrap(); writeln!(child_stdin, "Hello, world!")?; `child_stdin` implements `Write` here so you can use it with `Encoder` or whatever else you want to do with it.
Wonderful writeup. It must have taken a long time to put together, and it's so perfectly iterative. I really appreciated the fact that the examples hit the type limit. I also think it's the first time I've read a readable description of what a `Monad` is. FINALLY! My only minor suggestion would be to rename `whitespace_wrap` to `trim` :)
 Neat, just curious is it worth it to use it over RLS now or should we wait? Also, i see you can install it into vscode, is there a version installable for vscode-insiders? I can only use insiders for a few new things coming out, but I would like to give it a try.
Does the process not run as soon as `spawn()` is called? The program I call outputs `Could not open directory: /dev/stdin` and `encoder()` errors with `Custom { kind: Other, error: StringError("broken pipe") }`, which leads be to believe it checks `stdin` before `encoder()` is done (or even called).
Today we had a language team meeting. Among other things we did some triage, discussed drop order in \`async fn\`s for unused arguments, and assorted other things.
Isn't "ergonomics" a current goal of rust development?
Sure there are 26 letters but there are 11 different ways to spell the sound 'i:' ("ee").
Thanks for that. I actually downloaded VS Code and the rust rls extension with it; could you tell me a good guide on getting started from there?
I suppose the rationale is that you could have a single thunk parameterized by `T` and `F`, but any collection of thunks may all have different functions. I figured I'd just fix it at the thunk level rather than the collection level. But you comments and implementation are pretty interesting to read and I learned a lot!
Crikey. I swear this was like the first thing I tried and RLS threw a red squiggly, but there must have been something else wrong with it because this definitely works. Thank you for restoring my sanity.
https://docs.rs is my automatic goto for crate documentation. It's maintained by the official Rustdoc team and an indispensable community resource. You can just navigate to `docs.rs/&lt;crate_name&gt;` and it'll give you the docs for the latest version, or any number of previous releases at your choosing (not sure how far it goes back, it's probably documented somewhere). Besides `cargo doc --open`, there's not really any solution I know of for _offline_ docs of crates. Theoretically you could have a program which compiles documentation for every crate in your local Cargo cache but I don't think anyone's implemented that yet. If you installed Rust via Rustup then you already have on your machine the stdlib documentation and TRPL (as well as Rust by Example, the Rustonomicon, Cargo and Unstable "books" as well as several others; kinda bloats the distribution actually) for the release you're using. `rustup doc` will open the same index in your default browser as the one at https://doc.rust-lang.org but all the links point to your local install.
In languages where immutability is idiomatic (debatable when it comes to Rust), creating a copy of some structure with a slight change then destroying the original is an extremely common pattern. A properly implemented memory allocator will let you coast through this with barely a change in amortized run time. As the total amount of committed memory remains the same at the end of the operation, it really doesn't matter how much memory is allocated and then de-allocated. Not sure about Rust implementations. Arguably, introducing immutability has a tendency to decrease the overall amount of wasteful allocations in typical messy codebases by removing defensive cloning. The elimination of defensive clones also helps keeping semantic equality to the strict minimum, saving on inefficient equality tests often plaguing very hot code sections.
The rust version shouldn't be any slower than the bash version, however, if encode() takes a long time then there will be a long time between spawning the process and feeding it stdin. I'm assuming the program that you're spawning does a non-blocking read on stdin right after it's spawned? `cat` blocks on it's read so the delay shouldn't be an issue for it. You could try encoding your data into a buffer before you spawn the process, and then just copy the buffer into stdin right after.
If those are functions that operate uniformly on arbitrary collections, then yes HKT/GAT is the blocker.
I wonder why it wasn't just named GPL v4. If we went from GPL v2 to v3 because of tivoization, wouldn't it make sense to jump to v4 because of cloud computing?
&gt; The latter approach via an OpenGL window would be vastly slower than something like Electron. I'm highly skeptical as to how that could ever be the case.
Not performance-wise, implementation-wise.
Lol, after looking in this sub for a few minutes I realized that this isn’t the game and I have no clue what it was
I love parser combinators, and I'm stoked people are writing about them. Thanks for the great article! I've played around a lot with parser combinators in Rust myself, and I have found that instead of fn parse(&amp;self, input: &amp;'a str) -&gt; Result&lt;(&amp;'a str, Output), &amp;'a str&gt; everything gets simpler and more composable if you use fn parse(&amp;self, input: &amp;mut &amp;str) -&gt; Option&lt;Output&gt; which is essentially the same thing, but the types are simpler. I know that `&amp;mut &amp;str` looks a bit weird, but that becomes a non-issue once you abstract over the input type, too, and you end up with something like Fn(&amp;mut Input) -&gt; Option&lt;Output&gt; which has the additional benefit that you can support other inputs types such as `&amp;[u8]`. Another (minor) difference between this `Parser` trait and mine is that I think `Output` makes more sense as an associated type than as a generic type parameter. Making it an associated type is in line with some standard library traits such as `Add`, `Mul`, etc, but also the `Fn` traits – they all have an associated type called `Output`. The parser from this article can be implemented for a specific type multiple times with different `Output` types, which probably isn't something you ever want to do. Making it an associated type also means that you don't have to name that type if you don't care about it, such as the output type of the second argument of the `left` combinator, which reduces the amount of boilerplate for some combinators. I'm also not super stoked about `BoxedParser` – it's crazy how well the compiler manages to optimize parsers that aren't boxed, thanks to Rust's zero-cost abstractions, and preventing these optimizations really ruins part of the fun for me. :P I also ran into unacceptably long compilation times initially, but I think that all got resolved once I started returning concrete types from all methods (e.g. returning a `Map` instance from `map` instead of `impl Parser`). So that might be something to try out. Regardless, this is a fantastic article and I hope it makes more people fall in love with parser combinators.
For flat structures, that is absolutely the case with Rust, but remember that it's a systems language first, and a functional language second. Because of this, idiomatic Rust really only allocates when it needs to. For all you know, this code may end up running on a microcontroller where the mere existence of a heap is a luxury you can't afford. Plus, if it's immutable, who cares that it's on the heap? In Rust, memory management is so important that the language and standard library contain no fewer than 8 different pointer types, 3 of which are specifically to support mutability. Add on the fact that 3rd party crates add numerous other ways to manage memory like types of garbage collectors and arenas and you can see that this is a really big deal for Rust. About equality tests, Rust's standard library always uses structural equality except in the case of raw (unsafe) pointers because they can't be safely dereferenced. Other than that, the aforementioned pointer types often have a pointer equality test exposed as a method. Defensive cloning really isn't that common in idiomatic Rust code since the compiler prevents you from mutating data of someone else is still looking at it. In the end, cloning really only happens if you need the previous value to still be accessible, and if you consume said value, you already know that you're the only one with access to it.
It's interesting what (generally problematic) patterns people bring to rust, which don't play well with the borrow checker. Eventually you bend your will to it, then you realize the new patterns are actually pretty great! Borrowck morphs from an annoying nag to the angelic wife of Clint Eastwood's character in *Unforgiven*. But, why would you ever make a configuration object thread local AND mutable? I've always thought of config as global and static, just as a concept.
I don't know for sure, but I imagine it's the same reason that `main()` used to only be able to return `()`. Semantically it doesn't make sense for anything else to be returned because the computation is over with. `tokio::run` also doesn't return anything, so the value of result in your example will always be `()`. If you want to use the value inside the future you could [do something like this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=28f2e5352423ddacf99577f812a400a4).
Don’t quote me, but I think that was a big focus like 2 years ago. Not that it’s not always important and considered, but this year the focus is more on stability.
&gt; Don't quote me, COME AT ME BRO!!! (Ah I see. There's certainly some rough edges that I think they should continue to look at.)
Great to see this transparency.
Go Terminal &gt; New Terminal cd to the location where you want the project to be then 'cargo new name_of_application' It'll generate you a main.rs file a cargo.toml file and everything you need to get started and coding.
Rust is free
Uhhh.... buddy. Rust is $35 USD.
No it's free and open source. Install instructions here https://www.rust-lang.org/tools/install
Ohhhh shiiiit. I'm stupid thanks.
r/rustgame
Thanks for the suggestions everyone!
Just the reddit username ;-)
After further investigation this is also a problem when piping data to the command via the shell, but not redirecting data to it...
A fund to provide Lang team members microphones would be helpful, though.
Oxygengine - crate to make ECS based games for Web (other backends will be added later, for now it uses only web backend) :D Demo here: [https://github.com/PsichiX/Oxygengine/tree/master/demos/hello-world](https://github.com/PsichiX/Oxygengine/tree/master/demos/hello-world)
So, I implemented it this using `&amp;mut &amp;str` (I thought it was interesting, and wanted to try it, thanks for the idea) and without using `BoxedParser` (because that bothered me too), but kept the `impl Parser` stuff because the types were simply too annoying and large to type out. This got the build times to be under 5s for me, even with release mode. I think the problem is that `impl ...` doesn't play well with lifetimes, and so removing the lifetime parameter on `Parser` made the compilations faster.
This is the subreddit for the Rust programming language. You're looking for /r/playrustservers
I believe that some 0.1 futures, like the ones in \`tokio-timer\` are not 0.3 compatible even with the compat layer. I think maybe it worth a notice in the article.
Earmarking to look at later! Glad someone found it useful. ;)
You want Ar/playrust ... this subreddit has nothing to do with the game.
wait u mean this is a legit server for RUST and not Rust ? wtf
The full example would be very helpful, but I simply suggest to make sure you provide a valid data to your struct. You could test and provide a default value in the 'constructor' (aka new method) of your struct or right before you call the constructor.
&gt; Is the Rust borrow checker doing a lifetime check on threads, or is there some other mechanism at play? Rust knows nothing at all about threads. Scoped threads appear, to the borrow checker, just like any other object. The important part is the lifetime system, which is general enough that thread APIs can express the necessary requirements. &gt; “Unsafe” magic then resets a passed closure’s lifetime to ‘static. Although a cleaner architectural approach might be preferred, this definitely gets the job done. This is only done because Crossbeam is piggybacking on the standard library's thread API, which has its own (in this case redundant) lifetime annotations. The *actual* "unsafe magic" is in interfacing with the OS, which is always going to have to be a kind of assertion to the compiler that it's safe- except in obscure cases where you're compiling your OS with your program.
i think you are correct but it is possible that coming to rust first might be less weird than coming to it after being familiar with non borrow checked languages.
This is a server for the Rust Programming Language
idk what that is
It’s a language in which people tell computers what to do. For the subreddit about the game Rust, please see r/playrust
I agree that it's an advanced language, although I disagree with the desire to change that. One thing Rust is very good at is front-loading the thinking of programming. More time thinking about how to get the thing done and less time thinking about how to fix problems. The trick is, new programmers just haven't developed the skills of that kind of thought. Sure, they need to eventually, but it's not clear that forcing them to learn all the things at the same time is a good strategy. I always recommend people start with either Python for no other reason than it minimizes the number of completely different things that have to be learned at the same time. Then once someone has a handle on basic imperative programming, then they can move on to functional programming, and then types, and then concurrency... and then once they have all that, then they're ready to start on Rust.
ik i found it i just thought this was also for that lol
Hum... I am not sure about this. When you are familiar with C or C++ you will have hard time trying to compile your code, because you know what you are doing is good, but Rust forces you to do it 'its way'. So you have to learn how to use Rust, but the concept of memory, lifetime, references etc... are clear and you know what Rust is doing and why it doesn't want to compile. Buf if you learn Rust as a first language, you don't know what's really happening. You don't understand what's the difference between references and values, why mutable var is not always safe, etc... so instead of trying to understand what's happening, you will learn specific pattern to handle specific situation. Just my opiniont though
I very rarely struggle with the borrow checker, but not because I'm particularly smart or good at Rust. I think there's a style or a subset of Rust that doesn't involve getting tangled up in lifetime problems, and that if those things were taught as advice to beginners, the language would probably be quite tractable. Certainly at least as tractable as C++, which is taught to beginners often. Keep in mind with all these comparisons that people are taught C++ as a first language in school- a language with undefined behavior scattered everywhere- and they manage to survive. I often try to tell people learning Rust these two things, especially if they're new to programming too: 1. Avoid putting references in structs. Prefer owned values or `Rc`/`Arc`. Even if it's possible to make the code work, all the explicit lifetimes get nasty. 2. Don't fear `.clone()`. A lot of people rightly associate Rust with speed and `.clone()` feels like you're sacrificing the reason you're using this language just to make code compile. The trick is to know when cloning has no measurable perf cost.
Hey u/findingo you should definitely check out the Rust WebAssembly Working Group! Lots of exciting things happening in the WG right now. Team repo is here: https://github.com/rustwasm/team We’ve been doing a lot of work on the Gloo project. Lots to be done there as well. Personally, I’ve been putting together some high-level APIs for the WebSocket system. Check it out: https://github.com/rustwasm/gloo What sort of things are you looking to get into???
You *always* need to know what's happening. Even in Java, you should know the difference between a primitive type and an Object, you must understand references, the stack, the heap and something about garbage collection. Automatic memory management doesn't mean that memory becomes irrelevant. I had no problems learning these things in Java and later applying my knowledge in C and in Rust. Learning C might help you better understand memory management, but it isn't necessary.
In my experience, having spent many years writing in a good number of different languages (C++,Go,Swift,Python,JS), you go through a series of comprehension phases. After a month of intent and follow through, you’ll be good. I’ve been writing Rust for a few years now, built lots of microservices with it, and every once in a while I will still need to pause to really think about the data types and ownership paradigms which will best solve the problem, but usually I find myself so relieved by the compiler. So many problems avoided with such little effort. So many maintenance issues I will never have to worry about. Big payoffs, by my analysis.
Hey, btw there is some work starting in the Amethyst community to get WASM supported. Given that your project is also ECS based, might be some good cross pollination potential. Are you using specs ECS or your own custom impl? Also, are you using wasm-bindgen at all???
So, I checked, looks like you are using specs &amp; wasm-bindgen! Sweet. I’ll make sure to keep this around for reference.
Thank you! Great work! I've not found any other example that has handled the database by putting it in the state. I think it's really elegant.
Agreed. But it’s so much better than 2015-2016. What seems to be really holding companies back from using rust isn’t ergonomics, but stability and robustness. At least according to the blogposts I’ve read xD.
Spotty auto complete holds me back at the moment :(
"Why can't I do this?","Why won't the borrow checker let me do this?". These are probably the 2 questions that make the reputation of Rust as a hard language. However, would you ask those questions if Rust was your first and only language? Maybe what makes Rust hard is people trying to do things "the way they always did in other languages". What's hard is to break habits.
Thanks. The 1.0 syntax looks much cleaner. Can't wait. Can I use the `with_async` method to get async in the other handlers as well?
\&gt; When you keep piling on modern IDE features like code indexing, Git diffing, linting, background compilation etc. that do all sorts of stuff in the background while you work, these editors end up getting sluggish because of the cumulative weight of all those operations in a language that doesn't really scale all that well. &amp;#x200B; Sublime Text, even while running LSP (tested both with ccls and rls) is far faster than any other editor I've used. I recently bought a license because I have been cracking the damn program for years and feel bad that they are getting replaced by vscode for a lot of people now, even though Sublime is still better and popularized multiple carets in the first place.
I agree. Look at TeamSpeak and Mumble vs. Discord (both of them are better than Discord except for the friend adding / spying functionality Discord provides). Second best example I can think of is Sublime Text vs. VS Code. Again the native solution with a far smaller team wins. It's almost as if people figured out how to do things properly a long time ago.
Of course you should. But you live in a sweet world of dreams if you think most of the developers now what they are doing. I am living in SEA where schools teach how to use a language, not what's happening at compilation or running time.
I'd go the other way around - use `for _ in range` to count my matches, and then explicitly error out if the parser fails.
There is someone using the menu bar :)
&gt; Scoped threads appear, to the borrow checker, just like any other object. Aye, this is exactly how I would want it to be. Thanks! &gt; The actual "unsafe magic" is in interfacing with the OS That too makes sense.
This doesn't work. For example, if the range is `(5..=6)`, the combinator should match its target exactly 5 or 6 times. &amp;#x200B; Invoking the code, `for _ in 5..=6` still runs the loop only **2 times** total: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=283783b34b99fd6c6431106d404bbb1f
How does it compare putting a sql pool in the state vs using actors?
Yeah, you need to make a second range here to get the minimum number of items. Something like this: for _ in 0..r.start_bound() { let next, result = parser(new_input)?; results.push(result); } for _ in r { if let Ok((next, result)) = parser(new_input) { results.push(result); } else { return results; } } return results;
Rust solves a lot of problems that nonprogrammers never had, though. Beginners should learn about loops, ifs and functions. I don't think hitting them with memory management, macros and the pitfalls of concurrency is a good thing to do.
if you don't have written the game in rust, you are in the wrong sub.. and even then the question is a bit unspecific..
A beginner might need other tradeoffs, though.
You made me do - https://github.com/projectfluent/fluent-rs/commit/934dd7795015d7c5e2981884c51378c16b47c5ef Hope you're happy now. j.k. Seriously, thank you :)
You can also use a polyfill, or maybe the `wasm2js` tool.
Haha, still happy. Looks like nice changes to me.
I feel like you could still get yourself into trouble with this. &amp;#x200B; 1) \`0..r.start\_bound()\` is not valid syntax. 2) Your start bound could very well be \`Unbounded\`.
This would be like saying that Python is a hard language because beginners would not understand metaclasses. While your remark is true as for the memory management (and I think the book does an excellent job at explaining this, even for a beginner), macros can be used without understanding what's happening behind the curtain (that's my case, never understood how to write those Elvish things, I still use them a lot), and concurrency is a feature, one might not need it, and I think concurrency is hard to grasp anyway, not Rust's concurrency specifically.
I know it's not literally valid syntax, yeah. If your `start_bound` is `Unbounded`, you can just set it to 0.
Actually it is great for new programmers and move to c or c++. rust compiler will teach you what is safe and what is not. learning rust thought me a lot about safety.
With respect to documentation issue, I don't know how the actix doc is structured exactly but note that running `cargo doc [--open]` will give you the documentation for your own package *and all of its direct dependencies at the versions you're using*. Not only does it avoid network round-trips, it avoids the "oh damn I've been trying to write stuff for an API/version I'm not using" after hours of hair-pulling. Frustratingly `cargo doc` doesn't include the stdlib, that's a separate `rustup doc` away.
The issue here is that `tokio-timer`’s futures rely on more global state than just the futures 0.1 task system, specifically a `Timer` configured with [`tokio_timer::with_default`](https://docs.rs/tokio-timer/0.2.10/tokio_timer/fn.with_default.html). At the moment the only executor that does so is the one provided by Tokio, but I believe that it would be possible to set this up with a futures 0.3 native executor and use the timers on it. (This has been mentioned elsewhere as well, so I’ll look at adding a description of this to the post).
Okay, I feel like this would break on the cases: `(..=0)`, `(0..=0)`, `(..1)`, `(0..1)` All of which should parse **0** patterns, but would run exactly **1** time in the context of `for _ in range` if we set `Unbounded` into 0.
I think I can’t compare it with RLS both because I haven’t used RLS extenively myself and because I am biased :) But I’ll be extremely curious to here what others think about it. The plugin should work with insiders just fine. The only potential problem is that we call `code` binary for installation and if yours is named differently, it will fail. But you can install extension manually from vscx.
The examples where your right bound is 1 are fine, because they will skip the first loop and then run the second one, which should be fine. The examples where the right bound is `=0` are a problem, yeah. I guess you could solve it by normalizing both bounds and not just the left one?
I agree with you about normalizing both bounds, but the two bounds are the same: `Included(&amp;0) == Excluded(&amp;1)` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e0f53efd7de9cb6480c9c1326edb398a
I found that having some C/C++ experience made me less likely to give up. I had already spent plenty of time getting segfaults, so I appreciated that the borrow checker was figuring those out at compile time.
Thank you for your response u/doddzilla. &amp;#x200B; I've been exploring wasm-bindgen, web-sys, js-sys, stdweb, dodrio, typed-html. it seems everyone is working separately. I have just looked at gloo's PRs and issues, a lot of discussions there. I want to use wasm in webapp &amp;#x200B; I have zero experience working for open source, but I'm willing to contribute. I think I'll spend more time learning the gloo project
Oh yeah, I see the problem now - it's not the right bound, it's the left - `0` being there still gives us one iteration, but for the parser combinator case it actually shouldn't give any. You can probably hack around it by shifting it right by 1, but that's also pretty messy.
You mean to post in /r/playrust
Yikes, just 85% global support. Definitely not time.
I really appreciate your insights. It sounds like you're comfortable with the material, but maybe did not implement a solution yourself. If you wanted to implement one, I would love to see what you come up with (or post it if you have already done it).
raw indices bad, typed handle based accessors good. A handle shouldn't tell you what it is internally (index, hash key, etc). It should be typed so that you can't use one handle in one place and again in another incorrect place (typed), and it should allow you to do all kinds of hidden optimization and safety checks using it (but that may be hidden as an internal detail to the user). &amp;#x200B; Conceptually a handle should be like a pointer with all kinds of smart and protected things inside without pointer arithmetic. It's just more work than a simple index, and that's the rub. It takes work to do correctly.
Depends on the class you take - introductory programming courses of course will skirt by more advanced topics and instead focus on the user experience and achieving goals/feeling accomplished. Typically memory management and lower level details are offloaded into C &amp; Assembly courses where it makes more sense to play around with those kinds of concepts. I would expect something similar if there were an Intro to Rust course - probably most of the class would be about the ownership model and generic data structures and less about unsafe and bitwise interactions. Also I think most classes in the Seattle are will be about Web Development or Data Science, so literally nothing about memory management is needed to get started, just that objects are objects and data frames are built from CSVs if you know the proper magic rites :).
I know that this was the kind of stuff you would see when structured programming first became a thing. How there were all kinds of patterns and tricks that couldn't be done like it could be in assembly. How there were significant new paradigms and upfront learning costs that came with structured programming that weren't in assembly and so it was a barrier to entry. &amp;#x200B; It's not what people are used to and there are not nearly as many good teaching aids. This doesn't make it 'advanced user's only', just 'difficult now'.
You are right about writing, because half of them don't use Latin alphabet. Pronunciation is easy because they don't have many final consonant. The fact is that, people in SEA find difficulty pronouncing English, because of those consonant. Ah, but many of their languages are tonal. This may be difficult to Westerner. Tense is the easiest thing in these languages because they don't have verb conjugate. They don't have things like "present parti...". They only have "past", "future" tenses and just add one more word before the verb to indicate the tense.
Had to use google translate + some guess work, but totally worth it.
Little out of topic, but you can give a try rls 2: https://github.com/rust-analyzer/rust-analyzer
yeah! I only wish I could use the `locales.iter()` in the `ResourceManager::get_bundles`, but I failed to figure out why the parser complains about the lifetimes. Oh well, it still looks better! :)
it's definitely not the easiest language to learn, but c++ beyond basics isn't either. I'd say the barrier people hit learning a language, that is the barrier between being able to write simple programs to being able to program advanced stuff with a language comes much earlier. In rust if you climbed over that barrier, the borrow-checker, lifetimes, maybe impl of traits for non crate structs etc. it's like any other language. I only spent a few days then hit that wall, then left rust for a few months came back hit that wall again and did that several times. Then it clicked and since then it's very easy to identify deadlocks and fix them, what previously meant I don't know how to fix that. So all in all it took me a few months spread over three years or so, with long pauses in between where I did not touch rust at all. I am not working as a software developer, but if I can learn it, committed people can do it too. There's still lots of things I never tried. For instance never used a token tree in a macro and there are so many things, but I am confident that it's not difficult to understand and use when I need it, because I have jumped over that barrier.
This was a fantastic introduction to parser combinators. I've used
So I've tried to actually make it work and [this is what I ended up with](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b62a3ca67ff118a696e557519eb2bf01). You can replace the `while` loops with `for` loops as I originally suggested, but I kind of feel like it reads better with `while` loops, semantically (though it probably doesn't get as optimized as the `for` version would have been).
&gt;`.clone()` feels like you're sacrificing the reason you're using this language just to make code compile. The trick is to know when cloning has no measurable perf cost. Would you mind expanding on this a bit and giving an example? I sort of had the same thought the other day, but I don't have a strong CS background, so it was more of a feeling that I couldn't really explain properly (if that makes any sense).
I guess I assumed that this stuff supercedes the async-await bits in tokio, so I wonder when it's best to use this stuff, when tokio, and when both? The tokio stuff has the advantage of batting the async aware methods directly onto things and hiding most (all?) uses of compact, but this stuff is more general and doesn't require tokio, which makes a lot of sense.
Hi. Anyone tell me how to build it in window, pls. I got error with cmake gmpxx\_include\_dir not found. Thank in advance
Yeah nothing unsolvable. Just very inconvenient.
I can't believe I just spent 20 minutes of my life watching that. Wow. And here I thought I was beginning to understand Rust.
Still on my list, I assume it's worth it?
This looks like a good step towards building a general async foundation that we can build things from without coupling them to a given implementation. Id assume that in order for this to take off, libraries like Hyper would have to move to using Runtime rather than directly using Tokio, or is it easy to just use both as it stands (at the cost I guess of having more than one executor/reactor/etc)?
`fn main() {` `let mut m: [[u8; 16]; 9] = [[0; 16]; 9];` `m = four(m);` `println!("{}", m[5][5]);` `}` `fn four(mut m: [[u8; 16]; 9]) -&gt; [[u8; 16]; 9] {` `for i in 0..15 {` `m[i][5] = 4;` `}` `m` `}` &amp;#x200B; What is wrong? How am I supposed to access arrays with index variables??
One way to keep the public API identical to your example is to split `self` into disjoint borrows: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=762cf877fccd5542bcede51560286780 https://doc.rust-lang.org/nomicon/borrow-splitting.html
`m[i][5] = 4;` should be `m[5][i] = 4;` You list indices left to right from the outermost
Like in most schools nowadays. Rust also help those who don't understand that not firing a bullet in their foot when working on production grade apps. Like in other languages you have several levels of code quality you can acheive. In other languages it's measured by correctness and speed (among others), rust lowers the amount of uncorrectness you have at your disposal by a certain degree, and speed by another. Using a garbage collected language do not offers guarantee either, though it helps newcomers up to a certain degree. Though, I prefer working with one educated programmer than with 2 people that keep me investigating about leakage or core dumps. Understanding the borrow checker feels complicated, but it's not once you get the idea. Though, for someone not interested about thinking the architecture of the soft he works on, I can understand it's a blocking issue.
Hey, I'm interested in hearing a bit more about your concerns. &gt; everything else is constantly breaking Can you elaborate a bit more? Have you found the emscripten targets unstable? &gt; wasm2js which is now very actively maintained, but until that is actually properly working Have you found that wasm2js is not mature enough to work as a replacement for direct-to-asmjs compilation? Thanks!
Thanks! Holy cow though, it takes a while: https://i.imgur.com/OvSYR6P.png
I disagree with this. In fact, I think that Rust is incredibly beginner friendly precisely because it nudges (forces) you to get the basics right. See, I'm a mathematician and programming (for now) is my hobby, not my job. And I've felt drawn to Rust because of how strict it is. (Plus the compiler error messages are best in class. They actually help you to figure out what's going on and fix it -- even with no prior experience and no external help.)
&gt;Thanks for this. I need to dig into this when i have a bit more time and see what it is doing to get all its data. I wonder if it calculates anything interesting not directly provided by [crates.io](https://crates.io). hmm...
Yeah it's extracting and building all the documentation locally so if you have a lot of dependencies… it can take a while.
I think you're view of software development is to narrow. The average person in a software development careers probably knows less then people browsing programming forums. With that said, I would encourage anybody considering Java, C , C++ , C#, to choose Rust for the value of what you learn (job prospects doing Rust are a different story). Anybody considering Js, Python, Haskell, VBscript, Lua , etc. can probably get their particular job done just fine without understanding why a borrow checker is a nice thing. So the question should probably be: What is your first program going to achieve and why?
I just added instructions to make rust-analyzer work with Sublime Text 3 by the way! [https://github.com/rust-analyzer/rust-analyzer/pull/1167](https://github.com/rust-analyzer/rust-analyzer/pull/1167)
&gt;Anyway, how does Amethyst compare to Quicksilver in maturity? I can't speak for Quicksilver in great detail as I haven't used it much. It is very focused on 2D games, whereas Amethyst supports both 3D and 2D. Without knowing what roadblocks you hit, or what features you need, I can't say if you'd encounter them in Amethyst as well or not. If you are comfortable with C++ and SDL2, I think you could work with Amethyst; our 2D functionality is fairly low level at the moment. &gt;And when would we expect complete/robust WASM functionality? We start work on May 1st, and go the end of summer.
But how do you handle error messages in your simplified `parse` function?
Wouldn't that be rather slow on windows?
Are you thinking of Windows Defender? Maybe, I don't know, but I think it's got bigger issues than being slow: no transactions, no support for concurrency, being slow when you try to update large documents, making the OS unhappy when you have a lot of objects, and so on. I actually tested it against SQLite. They're about as fast for the 1 000 inserts in the example, but SQLite is much faster with 1 000 000 rows.
rust?
You'd overcome borrow checker struggles in several weeks at most, I think, depending on what you do. Several weeks compared to decades of programming is barely noticeable.
Rust
I have said it before and will say it again: They released too early. I don't know how that could have been fixed anymore. The problem isn't only the borrow checker, it's a lot more, just like you recognized.
clone makes a copy of a value. Copy something large or copy n times for n calls.
&gt; This would be like saying that Python is a hard language because beginners would not understand metaclasses. I've never encountered metaclasses in Python. Have you never had to do memory management in rust?
That's a cool project. I noticed a small issue wrt. panning: if you drag the map and release the mouse cursor, it will keep moving due to inertia. But if you pan again before it stops, it will conflict with the movement caused by inertia.
So I tried to install rust-analyzer via [AUR/rust-analyzer-git](https://aur.archlinux.org/packages/rust-analyzer-git/). The problem is, I cannot compile it: The compiler used 100% of my RAM (8GB btw) and froze my computer for hours until I gave up and force shutdown. My question is: * Is there a way to successfully compile it in my computer? * The repo seems to have Travis CI set up with a `deploy` section. But I find no prebuilt binary.
The fact that Rust requires higher mental capacities, doesn't make it advanced. It certainly is difficult to learn, but there is nothing complex about Rust per se. People should stop comparing it with any language other than C++
I also used Arch Linux. I just clone repo and do `cargo install-code` according to instruction, no need root, so there is no need of package manager. And rust-analyzer have new features every day, so it would be sad rebuild it from scratch every time.
Yes, you should be able to use `with_async_config` for the other handlers in the same way. One other note: don't store passwords in plain text. You could use [`bcrypt`](https://crates.io/crates/bcrypt) or [`scrypt`](https://crates.io/crates/scrypt) for basic password hashing.
The thing is in Java you really don't need to know any of that, you could have a reasonable, average career and never know. Many people do. Alternatively maybe you just get used to many many concepts in programming before having to deal with the details of memory, and maybe that is much easier. When I was a kid I did some C and C++ but pretty much everything was stack based and we didn't get into those details much.
For people using VS Code: https://marketplace.visualstudio.com/items?itemName=serayuzgur.crates.
Only problem with starting with python is people might then keep using it in production wasting electricity =)
Great with the async config, but I don't care about the passwords or security. The login and password are auto-filled anyway in the login: https://dziennik.netlify.com
&gt; because you know what you are doing is good, but Rust forces you to do it 'its way'. Right, but because you come from C and C++, you have all the tools to quickly understand *why* rust is asking these things of you.
Sure the many things I think rust is a blessing many beginner programmers would not appreciate. I like not having to deal with runtime errors which rusts compiler prevents upfront. I like that rust stops me from being lazy when I just want to just "quickly" fix or refactor something and do not think about it and the compiler comes along and stops me in my tracks of what the hell I am trying to do right now or even shows me that I missed something during a refactor. These things just slip easily through other languages and introduce bugs I have to deal with later on.
To add on that, I feel there is some expectation that "because low-level speed" `Rc&lt;RefCell&lt;_&gt;&gt;`, `Arc&lt;Mutex&lt;_&gt;&gt;` and trait objects should be used only as a last resort. Tbh I believe in many cases this kind of thinking falls into the "premature optimization" side. Many uses don't require the absolute performance that drives you away from `Rc&lt;RefCell&lt;_&gt;&gt;`, and using them can often make the code incredibly simpler.
How does it compare to rls ? Is there a features table somewhere ?
It's a system programming language, so yes.
I was wondering why the Parser trait isn't defined like this: trait Parser { type Output; fn parse&lt;'a&gt;(&amp;self, input: &amp;'a str) -&gt; ParseResult&lt;'a, Self::Output&gt;; } I then used HRTB to implement the trait for `Fn(&amp;'a str) -&gt; ParseResult&lt;'a, Output&gt;`. But when trying this I ran into issues with implementing map and pair. It only seems to work, if I explicitly specify the type for the closures before returning them (using `#![feature(impl_trait_in_bindings)]`. Is there a better way to do this? https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=ca49e79bd73fd9d5ce3ca99a7815c427
Thanks for the find. The dragging state handling could use some more work, it's been slowly getting messy during implementation.
When runtime speed and runtime correctness are both at a premium, Rust is definitely a good choice. It may also be a good choice when just one of those two things is at a premium.
[mp4 link](https://preview.redd.it/z4zqx65tw7t21.gif?format=mp4&amp;s=a21097d416107aa146b840812523fe2b3304751a) --- This mp4 version is 89.2% smaller than the gif (899.33 KB vs 8.14 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
Url: [https://gauger.io/contrib](https://gauger.io/contrib) (mobile friendly) GitHub: [https://github.com/devgg/contrib](https://github.com/devgg/contrib)
I guess that makes sense since drop is for resource management not just memory management
Here's my anecdote: I remember struggling with borrow checker back when Rust was still in 1.1 or so. That was before NLL! I almost quit Rust because I never managed to compile a single program. I continued to develop on C++, as it was less picky on these stuff and compiled programs nicely, but it was sometime later that I realized one thing: the compile errors were turned into runtime errors in C++! Segfaults were everywhere and these wreak havoc. Both are *equally* strenuous on the programmer, but people tend to be biased towards C++ being easier because they see their programs compile. (Also, I found my programs experiencing less segfaults these days, since I've gotten used to Rust. So that's a bonus.)
And panic hooks are called before unwinding.
Agreed.
Care to elaborate? OP only mentions borrow checking pains. Quite a bit has been improved since release from lifetime elision to recent Non Lexical Lifetimes.
Spent 30 minutes trying it ; from what I read, I'm guessing that it's not meant to replace the RLS just yet, but rather provide a different approach on IDE support for Rust, and then (in the *not-so-*distant future) use the benefits of said approach to integrate into the RLS. For now it's a plugin to install to your IDE just like the RLS, implemented features are working fine : * code actions are cool (inlining local variables, match arm completions, ...), * document and workspace symbols are working perfectly &amp;#x200B; Here is the [list of features](https://github.com/rust-analyzer/rust-analyzer/blob/master/docs/user/features.md).
Wrong sub, go to /r/playrust.
Anything you'd write in Go, Java (and soon JavaScript/TypeScript). Rust is an extremely productive language because reuse is so strong (first thanks to the very strong typing system + borrow checker, second to Cargo and crates.io). I guess this might read as zealotry, but I write exclusively Rust professionally after 10+ year writing in various other languages and mainly Java. After the initial learning curve (steep or not depending on your programming background), I would find it hard to downgrade to most other languages. Rust just takes so much of the cognitive load with its type system (something I found true when programming in Ocaml as well), but also makes trade-offs explicit (e.g, no implicit conversions or preventing a large object graph from being GC'd) which helps making the right design decisions. And you can write performant code (e.g, with references to stack allocated values) without depending on external optimization processes (like escape analysis) and without worrying about memory safety. As you mentioned, that also applies to concurrent programming, even in trickier programming models like mixing M:N threading, channels, and so on. Rust shines as a language that lets you focus on modeling your problem -- with modern language constructs (enums, generics, traits, etc), because the rest is taken care of for you by the compiler.
Better training materials, and continued improvements to the already awesome error messages will help people get into Rust and understand what's going on.
Awesome!
How do I `run` rust in VSCode? - On the commandline, I run `cargo run` which works fine. - If I run: **set default build** all I can choose is: check, build, clean, test I tried `task runner`, but then it **loses all color information in debug output** I've been searching, but the results seem to be for an older version of rust.
I have a trait with bounds that say that this trait relies on another trait with associated type, and a bound on that associated type. When I use such a trait, compiler says that the required bound on the associated type is not implemented. [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=557fc820b78e46a55700813fb684bba7) This seems strange to me, since trait definition requires the bound to be implemented. Is this a bug or do I misunderstand smth?
Source code on reddit gets messed up if you use \`\` to show multi-line code. Instead, simply indent your code block by one tab. (Easy to do before you hit copy in your editor)
&gt; Js, Python, Haskell, VBscript, Lua This is the strangest collection of languages I've ever seen grouped together.
The original article also does zero error handling. It uses `Result::Err` to give back the original input. So u/tim_vermeulen isn't changing anything. If anything it makes it easier to embed error messages into his method by changing from `Option` to `Result` and using `Result::Err` to give the error message.
Repost of https://www.reddit.com/r/rust/comments/bepi63/learning_parser_combinators_with_rust
I really haven't been following this and happily using futures 0.1. So, a couple of questions if anyone is game: 1) Tangibly, what's the difference between 0.1 and 0.3? It is significantly and tangibly different to the difference between \`Future&lt;Item=X, Error=Y&gt;\` and \`Future&lt;Output=X&gt;\`? 2) The main take away I have from this post is: &gt; The compatibility layer makes it possible to run std futures on executors built for futures@0.1. This makes it for instance possible to run futures created via async/await! on Tokio’s executor. ^ Why is this necessary? Can't we just have a native 0.3 / std::Future executor? Shouldn't it be the *other* way around, with a native 0.3 executor and 0.1 comp layer to run old futures in the new runtime? Did I miss something? Is there a 0.3 executor (ie. not tokio) I can use? 3) Everything is still unstable right? Why bother now more than before?
Come on. Just look at my history. I have complained about Rust lots of times. And without any serious reply.
30 years of programming experience, mainly C, Java and Python. I’ll make the observation that, in general, Rust is a very approachable language with good library support for a lot of common tasks. I don’t think it is an advanced users language, I do think it’s a language that expresses strong opinions about how you should write your code, although arguably no more than, say, Java does. There are two things about Rust that I have found make you think more than other languages: - Immutable method invocations interacting painfully with mutable invocations in loops - Lifetime references within related structures. You can often address the former with judicious use of Drop to lose the immutable reference and take a mutable reference to update state. I don’t have a good answer to the second problem, but Arc/Rc is an ok answer and I am confident I’ll get better at solving those problems as my knowledge of Rust grows. I really like the fact that when a program compiles there is much less debugging than with other languages. That is a massive win and you don’t need to be an advanced user to appreciate that.
Video games.
I've seen `vec!["one", "two"]` (square brackets) used as the standard syntax, but I noticed that `vec!("one", "two")` also works. Why is that?
Good luck convincing the US government to rewrite all their internal web stuff, training materials, etc to not require IE.
No one is going to dig through your hundreds of pcj comments to have a discussion with you. If you want a serious reply, you need to do us the courtesy of posting a serious comment.
I often do a 'clone first, benchmark later' first pass at projects. I use owned values everywhere, clone everywhere. At this point optimization is largely a matter of grepping for common allocation patterns eg: usage Vec, String, and .clone(). Hacking references in after that first pass isn't usually that hard for me and I can move way faster if I know that I can always go back and make it faster fairly easily.
I don't know. I know the rules of borrowing, I know when a variable goes out of scope because the rules are described in the book, I know move/copy/clone behavior, but I don't feel like I'm doing memory management. I'm just applying concepts I have been taught by the book.
Meaning you should use a \`curses\` facility for printing to the main buffer instead of printing to the alternate buffer at time of panic? :)
`vec!` is a [macro](https://doc.rust-lang.org/book/ch19-06-macros.html), and macros can be invoked three different ways: * `macro!()`, used for function-like macros like `println!()` * `macro![]`, used for macros that initialize containers like `vec![]` * `macro!{}`, used for block-level DSL macros like [horrorshow's html](https://docs.rs/horrorshow/0.6.6/horrorshow/) These are a matter of personal preference though and you can use whichever style you think is best when calling the macro. So `vec!["one", "two"]`, `vec("one", "two")`, and `vec { "one", "two" }` all work.
&gt; (and soon JavaScript/TypeScript) Can you elaborate? Is this referring to WASM or something else? Just wondering because I'm a JS developer who is interested in Rust just at "ooh that's neat" level and have been poking around a bit, but haven't built anything substantial yet.
I like it
Wait, there's another Gauger? And they do rust!!! Bro!
I think the compiler just isn't smart enough to determine that because of the trait bounds in `Foo` that if a type implements `Foo` then `Foo::Associated` must implement clone. [If you add a trait bound to foo() it compiles](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=240bdb6484649c01ec84a4197cd377ad)
Managed to track down the issue using your suggestions. I was not using buffered input/output but I was writing a lot of small amounts of data. Fixed that and my tests have gone from 40 minutes each to 20 seconds! Thanks again for your help.
Would you mind pointing me in the direction of the tickets you've filed? I'm interested in hearing what the criticisms are in order to actually know wether we're aware of them. The team strives to listen extensively to the community and pays close attention to the issue tracker.
&gt;it’s totally possible to write an operating system in Rust but not in Go (unless you strip away all of the useful features of the language to get rid of the runtime). I can confirm that writing an OS is easier in Rust than Go. That said none of my Rust kernels have surpassed my Go one. :P
/me sighs and fights back tears You're not wrong.
You can use Rust on systems with very limited resources, e.g. embedded systems. You can also use Rust in applications where performance is crucial, e.g. a regex engine, database, codec, file compression tool, compiler, emulator, cryptographic tool, etc. But you can also use Rust everywhere else. Rust is often used on web servers, in WASM applications and in games. Because of procedural macros, library authors are able to make very powerful and intuitive APIs. A good example of this is [Rocket](https://rocket.rs/). In areas where the ecosystem isn't so advanced yet, using Rust is entirely possible, but using a more mature language might be better in some cases.
If you like clap, you're gonna love [structopt](https://crates.io/crates/structopt). Give it a try! I also second the rayon suggestion. Coming from Java, it makes me feel right at home. 😎
Hi, Yes I'm referring to WASM. IMO JS/TypeScript were reasonable ways to run in the browser (other languages 'transpiling' to JS sounded like a headache to me). With WASM as a first-class citizen in browsers, and as a first-class target for Rust, I believe that in a few years when it matures enough, Rust will be a valid alternative to JavaScript even for building web apps. Of course it's already possible to do that now, but I feel like it is a bit early.
That's "`jemalloc`". :)
Fixed thanks!
Nice! I appreciate the time you took to put that together. Thank you for collaborating with me on thinking of alternatives.
Is this why all java apps I find in the wild run on minimum 1GB ram idle?
I'm actually curious if there's a good way to unify the two parts now. The ones I could think of all make the code harder to read.
`task.state` implicitly returns the field by value even if `task` is borrowed. A simple fix would be `(&amp;task.state).into()`. Aside from that, typically the way to convert a type to a textual format, it's done using either `std::fmt::Display` or `std::string::ToString`, the latter of which is implicitly implemented for users of the former, and both take their reciever by reference, so `task.state.to_string()` would work as is. There's also the `serde` crate for serializing data, but it's more for maintaining structure for later reading rather than printing user friendly output.
How did you manage to find a job writing rust? I'm pretty close to graduating from University Andy it would be a dream to find a company where I could write in rust
"Submit to rust" nice subliminal messaging :)
Good read, curious to learn more about prop testing now.
If your struct has a preferred textual representation then [`Display`](https://doc.rust-lang.org/std/fmt/trait.Display.html) is probably more appropriate than `From`: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6391654afe3bd0ad1662e2229e2212f0
&gt; How does it compare to rls ? Is there a features table somewhere ? I don't bother to compare. `rls` just don't work with my projects, it is too slow. So all of `rls`'s features is just waste.
No, the reason for that is the JVM just allocates a big chunk so it can expand the programmers running in the JVM as needed. The actual program isn't using that much. Java has a bad rap in a lot of our brains for 1990s desktop apps that felt sluggish, but that was partyl because the 1990s JVM wasn't as good as now, and partly because swing wasn't a great GUI library. &amp;#x200B; The JVM actually does a really good job of making naive code run very well.
Thank you for this comment! It confirms my suspicion that a language with implicit copy everywhere is a good idea:) What you are doing in the second phase is something that the compiler should be doing. I just want an insanely straightforward code, without references and maybe the ability to ask the compiler how the optimization step ended up doing. An IDE integrated visualization for the copies that remained in the code after optimization would be enough. I'd just iterate over them and decide whether I'm satisfied with those copies and alter my design if not.
Well the easiest example of when a `.clone()` is performant is when the type in question is `Copy`. If a type can be cloned by simply copying bytes that's generally very performant. It gets a bit more in-depth for types that are not `Copy`, though, because ultimately the cost of a `.clone()` then depends on the nature of what 'cloning' means to that type. An `std::rc::Rc` is not `Copy`, but it is cheap to clone. Why? Because when you want to make a clone of the `Rc` you can't just copy the bytes - the whole point of an `Rc` is that it counts how many of itself are currently alive. The `.clone()`, though, has a simple job: add one to the internal counter to represent the newly created reference returned by the `.clone()`. Adding 1 to a counter is a cheap operation at the CPU level. A `std::sync::Arc`, though, is *atomically* reference counted, and in order to understand precisely why that makes cloning it and *atomically* updating its counter much more expensive performance-wise means you need to learn about atomicity of instructions. A lot of the time deciding how much of an impact (if any) a `.clone()` has comes down to having to know the implementation details of the type. That being said, though, a one-off (or recurring but infrequent) clone is almost always fine performance-wise. Even if a clone took 50ms (an eternity in CPU time) odds are good that if you only need to do one clone once at program startup or something like that nobody would notice that extra startup time and call it a problem. Meanwhile a somewhat cheap clone, but one that's being done hundreds, thousands or more times a second when the program's got a lot to do can end up adding a significant overhead compared to dealing with a solution that uses lifetimed references.
Oh interesting that I never got to see that implicit try to pass by value before. As for the Display implementation I'll have to see if that will be the better trait once I get the rest up to dateish. Well thanks so far ^^
\&gt; the compile errors were all runtime errors in C++! I remember with fondness that one time stack corruption in C++ caused phantom crashes far down the line and I spent hours trying to understand why the part of program that looked absolutely correct kept crashing. Not. I hated that.
I wouldn't call WASM a _first class browser citizen_, at least not in the same way as JavaScript. All the web APIs are made for JavaScript, and somewhat clunky to use directly from WASM. A WASM language may never _replace_ JavaScript. For the foreseeable future, JavaScript is in the best position to cleanly glue UI elements together, especially with a framework like React. Rust is useful for heavy processing, or complex business logic. There is little benefit to writing basic querySelectors and event handlers in Rust. As @alexcrichton said: &gt; [Adoption of WebAssembly and Rust on the web will critically rely on not replacing JS but rather augmenting JS and the existing ecosystem.](https://github.com/rustwasm/team/issues/226#issuecomment-417801729)
And then what?
&gt;Would you mind pointing me in the direction of the tickets you've filed? I haven't one. But I will give you a couple of directions: 1. The right arrow. It's only useful in a functional language. But in an other language it makes zero sense. 2. The countless of times that people have to write the package::method::crap. Just look at Go, for whatever sake. There you have both a proper import and zero package::method::crap. 3. Why does a line have to end with a ";" ? Beats me. &amp;#x200B; And I can go on for a while.
My brother is named Andi actually :D
&gt; If you like clap, you're gonna love structopt. Give it a try! I love it and would definitely recommend trying it, but I've had people tell me they disliked the declarative type-annotated nature of structopt, so YMMV.
It might be possible to arrange an early endwin(), or display an error via curses using https://doc.rust-lang.org/std/panic/fn.set_hook.html
To create a custom registry, can't you just fork [crates.io](https://github.com/rust-lang/crates.io)? Has anyone tried this out? Also, [ship.rs](https://ship.rs) states: &gt;Mix Crates &gt; &gt;Your private crates play nicely with open source crates, unlike crates hosted with crates.io. However, I read on the Rust Blog that crates in custom registries can depend on [crates.io](https://crates.io), so I don't understand what this is about.
Yeah i realized that when reading the post.. Sorry for the noise
It seems related to this: https://github.com/rust-lang/rust/issues/58956
Small question regarding match expressions: I'm writing an interpreter and thus have different pieces of grammar I need to match. I'm currently doing this manually, which works but maybe it can be a bit beautified. Lets say I have a grammar `term: factor ((Mul | Div | IntegerDiv) factor)*`. My current corresponding code is fn term(&amp;mut self) -&gt; Node { let mut node = self.factor(); loop { let node_type = match self.current_token.clone() { tok @ Token::Mul | tok @ Token::Div | tok @ Token::IntegerDiv =&gt; { self.eat(tok.clone()); NodeType::BinOp(tok) }, _ =&gt; break, }; node = Node { node_type, left: Some(Box::new(node)), right: Some(Box::new(self.factor())), }; } node } Is there a way to make this whole thing(with all the other grammars) work as a giant match expression? So that I actually have something like: match tokenstring { term @ factor ((Token::Mul | Token::Div | Token::IntegerDiv) factor)* =&gt; // do stuff that needs to be done with terms _ =&gt; // handle other cases } &amp;#x200B; So I kinda want regex's but for all my different enums etc. rather than strings.
`reqwest` is great, but it's worth noting it's not full-featured... e.g, try working with cookies and you'll quickly find yourself massaging http headers yourself. IIRC there's ongoing work to make that better, though, so there's that.
Hmm, could be. I'm not using any unstable features though. I did change some of my code to use impl trait arguments so maybe it has something to do with that
&gt; To create a custom registry, can't you just fork crates.io? Has anyone tried this out? The devil's in the details! I'd doubt it's as simple as this, given that setting up a [read-only mirror](https://github.com/rust-lang/crates.io/blob/master/docs/MIRROR.md) isn't currently stable. I'm assuming that setting up a full fork is, at most, a WIP. &gt; Your private crates play nicely with open source crates, unlike crates hosted with crates.io. I think that the problem isn't custom registries depending on Crates.io, but the other way around.
&gt;I think that the problem isn't custom registries depending on Crates.io, but the other way around. Crates on [crates.io](https://crates.io) are **open-source**, so it's a good thing they can't depend on closed-source crates. Or am I missing something?
Anyone who knows how to use nalgebra: How do you create a matrix filled with a constant without a secondary call to fill?
For question 1, it's calling `From&lt;TaskState&gt;` in main as well. Borrowck cannot change inferred types, so it's always going to pick `From&lt;TaskState&gt;`. But I'm baffled as to what you're trying to achieve: if you don't want `TaskState` to be converted, then get rid of the `From&lt;TaskState&gt;` impl. That seems really easy compared to whatever else you're trying.
Well, it depends on who you are. If one is determined to stay in the open-source world, I would agree! I love that Crates.io is open-source first. :) That said, I'm currently using Rust at a shop that WANTS to open-source stuff, but right now the team isn't at a point that it's a priority. Being able to seamlessly use a private registry would be really nice!
But that is just a branding enabler feature! Wee/Wii, Googol/Google, Lift/Lyft, etc.
Dude, this is phenomenal!
is the an alternative you'd recommend instead?
I personally use it where I previously would've used Python/Ruby/Bash to write "small" scripts that do something useful, I haven't really upgraded to writing anything large with it yet but even for smaller programs Rust is awesome. Package management similar to Node easily allows you to pull in useful packages, compiles to a single binary (and with `musl` to a static binary) that runs on Windows, macOS and Linux, a fantastic type system, awesome concurrency and once you grok the borrow checker things really fly. I've written a few utilities, one that fetches `.gitignore` templates, one that fetches and downloads competitive programming problems etc, things that previously I'd do in Python.
Not at the moment, no (although if you're using Actix in your project, it has a pretty decent HTTP client in there). My issue was more with the specific wording using in the article is all.
So I spoke with Bodil about it on twitter. She said that there is really not much magic, but she did provide me her solution: [https://github.com/bodil/vgtk/blob/proc-macro/macros/src/combo/combinators.rs#L349-L374](https://github.com/bodil/vgtk/blob/proc-macro/macros/src/combo/combinators.rs#L349-L374) &amp;#x200B; I think it is really elegant, the way that she has different combinators, such as \`any\`, \`up\_to\`, \`at\_least\`, \`exactly\`, \`between\`. I imagine I will flesh those out more when I complete the tutorial, but I think the solution is very readable.
“You need to enable JavaScript to run this app” -_- My only complaint, looks cool!
Her `between` solution is actually surprisingly similar to what I suggested :) Also, nice catch on the fact that the lower bound can't be exclusive - I was wondering if that's the case, but decided to play it safe.
1. This is your personal opinion, not a criticism. Moreover, you are objectively wrong that it makes zero sense. It may not make as much sense as in a functional programming language, but it does make perfectly good sense in any language. 2. Is this really any different form languages like Java and C#? 3. Is this really any different from any systems language currently in existence? (C, C++, JavaScript (for minimizers), C#, Java)...
&gt; What you are doing in the second phase is something that the compiler should be doing. I don't think compilers are particularly good at eliding allocations. Like, yes, I would like the compiler to optimize all of the code in an ideal way but it's not really how it works.
For now, these APIs are designed for JavaScript, and you hear people involved say it's not meant to replace JavaScript. I'm curious to see how things will unfold, but I wouldn't surprised if, say in 10 years, all Web APIs have a 'native' WASM/WASI interface (or two, one for GC'd languages the other not)
The job found me. In general, I think there are Rust jobs out there, but maybe they're targeting senior devs?
1. It doesn't in Go. 2. It doesn't in Go. 3. It doesn't in Go. Here, from a language that exist only a couple of years old, I would have assumed that they would have looked at least in what makes it the best, not for what is existing today, and they simply didn't do their work.
Okay, this listicle is not entirely without merit, but can we stop the stupid title? To quote [Hacker News Guidelines](https://news.ycombinator.com/newsguidelines.html): &gt; If the original title begins with a number or number + gratuitous adjective, we'd appreciate it if you'd crop it. E.g. translate "10 Ways To Do X" to "How To Do X," and "14 Amazing Ys" to "Ys." Exception: when the number is meaningful, e.g. "The 5 Platonic Solids."
Knowing C#, C (could probably make something work with C++ but not idiomatic), Python (,...) and currently learning Rust I've chosen Python for my finals project that's now running in production and would do it again in a hearbeat. What good reasons speak against using python in production would you say?
I really like the simplicity of using [docopt](https://crates.io/crates/docopt) if you have a really simple set of arguments. Even though it won't have any "future evolution", it seems maintained still and I don't see the need for evolution in a command line argument parsing library personally.
This has been true for a long time, but reqwest 0.9.14 added cookie support.
I personally find \`Rc&lt;RefCell&lt;T&gt;&gt;\` to complicate code more than simplify it; YMMV. :)
&gt;It confirms my suspicion that a language with implicit copy everywhere is a good idea:) It might be a good idea at first, but then you get stuff like "25,000 strings allocated every time you press a key" [https://groups.google.com/a/chromium.org/forum/#!msg/chromium-dev/EUqoIz2iFU4/kPZ5ZK0K3gEJ](https://groups.google.com/a/chromium.org/forum/#!msg/chromium-dev/EUqoIz2iFU4/kPZ5ZK0K3gEJ)
This was great! One thing: you never explicitly say to switch `parent_element()` with `open_element()` in `element`.
ICE(internal compiler error) is always a bug (usually in the compiler, sometimes in compiler plugins such as procedural macros), so as long as it is reproducible, you should always report it. Don't worry about how helpful it will be. Rust developers in general consider all ICEs seriously.
The book has chapters on implementing a basic multithreaded webserver. Id start with those
The language features are instantaneous once the workspace is loaded (takes a few seconds for my machine to load the rust-analyzer sources). It is a bit of a memory hog but very fast and works well as a daily driver in vscode. It lacks a few things like full name resolution for traits and some macro support though that has come really far in the last few days. I highly recommend just installing from the master branch and disabling the built-in rls extension and seeing how it goes. If you have `cargo-watch` installed it's REALLY nice. Features: https://github.com/rust-analyzer/rust-analyzer/blob/master/docs/user/features.md Language Server Protocol: https://github.com/rust-analyzer/rust-analyzer/blob/master/docs/dev/lsp-features.md
Well it's 2019, and Jenkins, GoCD are 2 of the biggest java apps that come to mind that require &gt; 1GB RAM just running idle, this is just the server, not any agents. Meanwhile similar apps written in go take &lt; 10MB RAM. For lots of big companies that don't care how much ram an app uses it doesn't make a difference, but for lots of small companies and individuals it does. This is currently the primary reason I stay away from running any java systems. I don't care if the actual app inside the jvm isn't using all of it, when from my perspective the process has allocated that much ram that's all I care about, as it means it's preventing other processes from using the much needed ram.
Thank you, but I've already read the book and am seraching for something more advanced.
Ah! That slipped by me, apparently got out this month. Thanks for the correction, super useful to know.
Why does this default to js?
The sequence of events goes like this: - Your code detects an error condition and passes control to code generated by the `panic!` macro. - The panic payload is constructed (the `panic!` macro can also generate formatting code like `println!` and `write!` and friends), boxed, and packaged within the struct `std::panic::PanicInfo`. - A thread-local flag is set and can be tested with `std::thread::panicking()`. - The panic hook is called with the `PanicInfo`. The default hook prints some diagnostics on standard error stream, including a backtrace if `RUST_BACKTRACE` is set in the environment. Other platforms may behave differently. - Next the panic handling code needs to clean up. It may abort (similar to `std::process::abort` if not exactly the same) or `std::panic::resume_unwind`. - If it unwinds, *only the boxed payload* is preserved. The location information is no longer accessible. Unwinding will prevent a backtrace from being generated. - `resume_unwind` initiates some platform-specific magic, typically using llvm's mechanisms for C++. - This magic causes values on the stack to be dropped in the reverse order of creation. The thread's panicking flag is set so a second panic during drop will cause an abort instead. - When/if the magic is finished, the thread's stack has been unwound as far as the most recent `catch_unwind`, which clears the panicking flag and returns `Err(payload)`. - If the thread can continue from that point it does. Otherwise there's an opportunity to do whatever cleanup is necessary (typically crossing FFI) and `resume_unwind` will be called again. - If an FFI call would be unwound the behavior is undefined. Newest versions of the compiler attempt to generate code which crashes. - If the main thread unwinds to the beginning of its stack, the entire process exits with an error code, typically 101. - If a spawned thread is unwound to the beginning of its stack, that thread exits. `JoinHandle::join()` returns `Err(box payload)`. For the purpose of optimizing, you can assume that `catch_unwind` is fast - about the same as an FFI call - but actually panicking/unwinding with `resume_unwind` may be about as slow as I/O. I think the best way to handle that situation is to change the drop hook. The default behavior of reporting the panic to the terminal is not suitable when the terminal is in alternate-screenbuffer mode, which curses sets. Since the mode of the terminal and the panic hook are global state, the `main` application crate should have responsibility for setting them. However you can and should, if building a crate for curses, expose a recommended panic hook and/or components which the `main` crate needs to implement a useful one. [One option is `log-panics`](https://github.com/sfackler/rust-log-panics), or something else. Like everything that uses the `log` facade, actual applications will need to choose a logging backend. A curses crate could offer a way to redirect logging to a file and/or dump critical errors to the standard console buffer.
These kinds of posts are the sign that Rust has truly hit the mainstream as a language, babybeeee
Your examples could be cleaner by taking advantage of "\`?\` in main", e.g. \`fn main() -&gt; Result&lt;(), dyn std::error::Error&gt;\`. This would mean you could just use \`?\` in your Serde examples instead of \`unwrap\`. &amp;#x200B; Also, please don't give code examples as images, it's just annoying for anyone going through the article who wants to try the code out themselves, especially when the example is a beyond a couple lines. I do sympathise with the lost prettiness though, however that is easily fixed with some creative CSS (which albeit is probably not available on Medium).
Well if your gold standard is Go then I would suggest programming in Go!
This is just perfect. I was looking for something to validate Azure JWT with their public JWK set. Thanks!
One thing I found great while learning about parallelism with Rust is that many problems that arise from threading become compile time issues instead of undefined behavior. Because of that, I found it a lot easier to experiment with threading and be confident of what I've written. If I had to suggest a book besides the official I would suggest the Rust book by O'Reilly. It has some nice sections on concurrency.
If a trait has type parameters, then you can implement that trait multiple times with different actual parameters. For example, `Vec&lt;T&gt;` implements both `Borrow&lt;Vec&lt;T&gt;&gt;` and `Borrow&lt;[T]&gt;`. If a trait has an abstract associated type, then whenever you want to implement it you must define what that type is. `Deref` can only be implemented once for a type. Thus if you say `&lt;Vec&lt;T&gt; as Deref&gt;::Target`, that can only refer to `[T]`. Because of this `DerefMut` must have the same target type as `Deref` does. That makes custom pointer types *much* easier to understand but it wouldn't be possible without associated types. And because they're easier to understand it's also easier for the compiler to figure out what types you're trying to work with. There's a trade-off between flexibility and ease-of-use. The convention with iterators is that they are like pointers - pointers can only point at the one type of thing they point at. Iterators can only return the one kind of thing they return. I'm guessing you're looking at futures or streams, and they follow the same convention. If they didn't then you may have to give the compiler explicit type hints more often. (I'm not too good at predicting when you'll run into those problems. API design is hard.)
1.0alpha +1 * you don’t need AppState, you can store addr directly * in middlewares future could be Either&lt;FutureResult, S::Future&gt;
That's in fact exactly what I wrote it for! :)
A nice list but, at the moment, PyO3 has a [flawed design](https://www.reddit.com/r/rust/comments/azit15/i_made_a_super_simple_example_guide_of_how_to/ei89s8e/?context=3) which invokes undefined behaviour.
I started rolling my own based on the existing JWT crates and found your crate name rather amusing (but quite descriptive) :) Thanks for sharing!
Of course I am, but I was only trying to mention the why, which is being ignored once again.
This is super helpful. Thank you very much. I've updated the first two, tomorrow will take a look at the 3rd.
Pointers to `dyn Trait` can be broken down into two fields. One is a pointer to the actual value. Its concrete type is hidden, so you can't do anything with it directly. The other is a pointer to a table of functions which implement the trait for the hidden type. This table also contains housekeeping attributes for the type: its size and memory alignment and drop procedure. (Accessed with `std::mem::{size_of_val, align_of_val, drop_in_place}`) It's called the "vtable" like similar structures used by C++ and other languages. So you *are* pointing to an object (object = "a string of bytes, located in virtual memory, interpreted according to the syntax and semantics of a concrete type"). The difference is that the pointer types you've seen so far promise that the target has a specific concrete type. `&amp;u16` always points to `u16`. The pointer types to "dyn Trait" only promise that the value belongs to a type that implements `Trait` and that the implementation can be found at runtime.
Thanks, that looks like the cause. I just checked, and I have 402 symbols related to core::format Debug. My initial thought is that it should be possible to eliminate the whole Debug trait for embedded ?
Thank you for this wonderful language. From bottom of my heart
&gt;flawed design Thanks! Added a note.
Oof, that'll do it. It's also worth posting your code for independent review (when possible).
1. Define an enum which wraps all possible structs returned by your function. 2. Implement `MyTrait` for that enum with boilerplate that delegates everything to the underlying structs. 3. Wrap the structs before passing them out of the `match` statement. Now it works. You're only returning one type (the enum) so `match`/`if`-`else` and the function (multiple `return`?) can pass type-check. Anything that calls that function will only interact with the enum through the interface of `MyTrait`, so it'll never notice the enum. You can even define the enum within the function body; I wouldn't because it's messy. I'm a little surprised that the compiler doesn't do this automatically. It's a common enough question for sure. The biggest downside I see is that it complicates how `match` is analyzed by the compiler - it may imply a new type every time it's used and that's kinda scary.
&gt;structopt Fantastic!
Python may have been the best choice for you, I just wish the state of the programming tools world was such that there was a language+ecosystem as nice to use as Python, without the inefficiency. The inefficiency isn't necessary to have the nice to use properties.
You can change the amount of memory the JVM will allocate up front if you want: https://stackoverflow.com/questions/1493913/how-to-set-the-maximum-memory-usage-for-jvm
&gt; (any possible rust-cpython) I get the impression that this is a typo of "and possibly rust-cpython"
Yep, that definetly would be great. I think PyPy coming to Python 3 will be a huge step forward (JIT-compiled Python - aww yes). I don't know how Jython and IronPython perform, but they shouldn't be much worse than Java and C# I think.
What does this have to do with the Rust programming language?
oh boy sticky fingers! thanks and fixed!
1. Large Python projects are hard to maintain and refactor (same goes for all languages with dynamic typing). 2. GIL ruins concurrent stuff (unless you go all out and use processes, but you will get performance overhead anyway) 3. It is just slow I would only use Python for: a. Prototyping b. Quick DevOps scripts c. Data Science projects d. Teaching programming But in the end it is a choice of developers - if you really enjoy it..
rust is the new javascript 😎
Only somewhat apropos, but Redox has a microkernel + device-server architecture ("Minix meets Plan 9" perhaps), both written in Rust. One of the characteristics of well-written low level code is that you *can't* have a lot of complexity in play at once - not without things breaking. This is true whether or not you have `unsafe` explicitly marked in the language. A working kernel will have a little bit that does context switching, little bits that modify page tables, little bits that manage interrupt context, etc. etc. It should be possible to understand each of those tasks within a compact module. Those modules *will* require `unsafe` and often raw assembly, but they can't run on for thousands (or even hundreds) of lines before they establish the normal invariants necessary for safe code. Rust makes that programming task - encapsulating "architecture-specific" code - a bit more explicit. Otherwise it's not fundamentally different from C. The advantage is that you can then write the vast majority of the kernel in safe code and benefit from type and lifetime checking which are much more powerful than C. You don't need unsafety to decide which task to schedule next, which pages to swap out, etc.
I chose it because: 1. It had to be developed in a really short time 2. Desktop UI-App / performance is of no concern (as long as it's not absolutely terrible and there are noticeable lags) 3. Cross platform development is a breeze 4. Never done any computer vision stuff with another language 5. Only semi-relevant: The project will serve as a learning platform for future devs in the company (they didn't have anything with Python up until now and want them to learn the language) Concurrency with threads is a great tool even with the GIL (used it a lot in this project) - though there are versions of python out there without the GIL (maybe even libraries for CPython - Qt for example has QThreads which maybe aren't restricted by the GIL? I honestly never needed it)
Example? Sure. Here's some places you should expect clones to be fine * A line that runs once at program initialization or shutdown * Clones of vectors or strings that are usually small- not only do most memory allocators have a very fast small-object allocator but there are small-size-optimized versions of these data structures on crates.io that can be added later with little effort. * Cloning an `Arc` or `Rc` is uncommonly free, enough that I've seen it advised to write them as `let my_name = Rc::clone(&amp;name)` to be absolutely clear to the reader that optimizing away this clone is the tiniest of gains. * Internal startup code, such as before launching a thread or running a big loop that may or may not want to take ownership of a value at some point is often a fine place to clone smaller values It woudl almost be easier to offer the opposite advice: Clone liberally, except on large containers. Withoutboats has complained about Rust's probably-misplaced syntactic salt before: https://twitter.com/withoutboats/status/931342897751851008 Profiling Rust is quite easy with `perf`, and if you care at all about performance you should get used to it. `perf record --call-graph dwarf target/cratename/release` then `perf report`. Just be careful of overloading perf if your program runs too long. If that happens, make a smaller test program. You can also use frame pointers for profiling, but they're less helpful.
I think it was mentioned as the most used language on the stack overflow developer survey. So slightly better than random 😄
Anyone unfamiliar with borrowing as a concept will struggle with the borrow checker, regardless of prior programming experience. Just as anyone unfamiliar with programming will struggle with programming. You can very well learn borrowing as you learn to program. Easier to start with good habits than to learn bad habits that will later need to be removed.
and if you want to deserialize your env vars, [check out envy](https://github.com/softprops/envy) not the author, just a fan
I'm calling /rustjerk
Not sure exactly what your saying here but I think I got this: 1. Open up the terminal of your choice (I will choose the cmd or Command Prompt on Windows) 2. cd to... where? How do I say which location I want it to bein and how would I access that location? 3. type cargo new name_of_application , where name_of_application is basically the name for your project 4. It'll generate these files, but how do I access these files then?
Sorry, I didn’t realize you weren’t familiar with console commands. 1. VS Code has a built in terminal, you can access it from Terminal &gt; New Terminal, but you can use cmd if you do prefer. 2. The command is cd short for ‘change directory’. So to access your “My Documents” folder for example you’d just type cd C:\Users\&lt;your computer name&gt;\Documents. note if the directory path you want to access contains any spaces you have to put quotes around the entire path. Also hint use the tab key to autofill. 3. Yes 4. They’re generated in the directory you cd’ed to. If you use VS Code you can open the project folder you just created, and voila, you can open up main.rs and start coding!
For anyone familiar with Rayon, is using it behind a web server a bad idea? Eg, I'm used to languages with green threads and am not accustomed to spinning up real threads for this type of work. Is calling a Rayon workload from a multi-threaded web server like Rocket a bad idea? What happens if I run out of threads? Might I block incoming web requests/etc?
I regret to inform you that you are on the Rust subreddit
Thank you.
Can you elaborate on `Arc&lt;Mutex&lt;_&gt;&gt;` being a last resort? Eg if you have a web app that mutable shares `_`, isn't a sendable, thread safe mutable var the only way to do that? I get that there are times where you can try to do what is effectively copy on write style data structures, but I feel like that's a bit atypical. Am I missing something here?
Great, but now I'm stuck at the last step. Here's what has happened so far: &amp;#x200B; 1. I was able to open up a new terminal through *Terminal -&gt; New Terminal.* But I think I pretty much am lost here. I created a folder called "*My Documents*", created a new binary with *cargo new rust\_program*, but then when I clicked into My Documents in File Explorer, there wasn't anything. Then I deleted that folder in the File Explorer, and created a new one called *Rust Programming*, and then into the terminal typed *"Rust Programming"* to access that directory. But when I typed into the terminal *"My Documents"*, it went into the folder as if it actually existed! So I am really confused.
Rust does wonders as a systems language for one big reason: it's both safe and painless to use large static (i.e. global) structures, which naturally need to be mutable. In C, it's painless but somewhat unsafe. I wasn't really talking about that use case, where lifetimes and ownership are barely relevant anyway. It's not natural at all to e.g. write an OS with a strong focus on immutability. Fair point about defensive cloning (though it seems that's what many newbies will end up doing anyway if they get fed up fighting the borrow checker). About equality, structural (semantic) equality is famously difficult to implement right, and very frequently it will need to change in non-trivial ways as the program evolves. It's also obviously slower than referential equality. It makes sense for many objects to support semantic equality, but it doesn't make a lot of sense for Rust sets and maps to *always* default to using semantic equality when referential equality is what you need in most cases. Perhaps most importantly, any semantic equality implementation of any even slightly complicated type *will* defy the expectations of a portion of readers, no matter which compromise you choose. Semantic equality is useful in cases that are typically non-programmatic and very explicit, such as building a test case for a function which generates a complex data-structure by writing out the expected result literally then checking that the expected and effective are "the same" semantically.
https://medium.com/@orbitalK/why-the-machine-b9803a77fa29 Going to get tired of posting this all the time, but learning the stack discipline habit that the compiler will demand makes it really easy to visualize why multithreaded programming has only a narrow set of concepts to nail down and start building on top of.
My favorite part was "the scream" and Felix losing it :D
https://medium.com/@orbitalK/why-the-machine-b9803a77fa29 I wrote this specifically for being able to comprehend the borrow checker's pathology, stack discipline, for programmers not recently exposed to such work. In terms of having the option to approach CS very abstractly or to always just build it on top of drop dead simple* structures like execution stacks, Rust actually is quite approachable. I think languages that demand high abstractions but expose almost no machine details can be very difficult in spite of not appearing to carry a lot of weight in terms of needing you to understand the execution mechanics or their own runtime. Java might not be "advanced" but, Producer Extends Consumer Super is not exactly light reading the first time around. *_Abstractly. They are magical assembly runtimes with mystifying behaviors if you peak below the assembly execution_
Why gif? Are you on a Mac? Do Macs have default software which generate gifs from screen captures? I ask because I have been a life long Windows/Linux user and I have never seen any tools which produce gif as their output.
You're missing a `$` in `$(arg:tt)*`. It should be `$($arg:tt)*`.
`tt` consumes a "[token tree](https://doc.rust-lang.org/proc_macro/enum.TokenTree.html)" which is either a single token, or something of the form `(tokens)`, `{tokens}`, or `[tokens]`, where there can be any number of tokens inside the delimiters. Thus, aside from the delimiter case, a non-repeated `tt` can only consume a single token. `"HELLO"` is one token, and a comma is another token.
Can you elaborate on the second point? I was trying to find a good explanation when should or shouldn't use `clone()` and `Clone` vs `Copy` but I never found a good one.
There is a limit to the number of threads a program can create which you can configure. However, if you spin up, say 8 threads to process some data in parallel when someone calls your API (because you have 8 cores in this example), and you get a sudden influx of traffic because your API is exposed to the internet, you risk crashing your program. Here's a quick example :) https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=88d0ae54f00b3ef4471678118ce183eb
Perhaps the solution is to not use Medium...
This is a follow up post on my real time CLI Software Rasterizer, written in rust. It's named sloth, because its pretty slow due to its software-rendering nature. Before, the framebuffer was composed of a vector of &lt;u8s&gt; that were then combined into a &lt;str&gt; and printed to the screen without any ANSI escape codes. Now, the framebuffer is a vector of Strings, which means the full extent of termion can be applied to each pixel. This may be slower, and require some more memory, but it is only variable with screen size which for a standard TTY is small anyways. From this, I used MTL loading in tobj to implement colors! Try it out yourself on the development branch over on github. [https://github.com/ecumene-software/rust-sloth/tree/colors-rework](https://github.com/ecumene-software/rust-sloth/tree/colors-rework) In the future, I plan to implement multithreaded horizontal strips to hopefully improve performance, as in my WSL terminal when there is a high performance load the screen flickers. As well as FBX support for skeletal animation, multiple lights, and more functional command line options.
My experience with Rust is that package managers usually manage to screw up operating cargo spectacularly. Until the situation improves (which it shows no signs of) I'd `git clone` and `cargo install` everything manually. I get that it's a bit of a bummer that your AUR helper can't update the things but at this point I don't trust them.
This look awesome, keep up the good work. Hopefully, I will have enough time to test it some time.
Ah! This helps a lot, thank you.
Do you know of a good resource to get a better understanding on how to manage threads like this? Eg, I'd like to use Rayon from a web server but the last thing I want to do is introduce undefined behavior.
I would always derive `Copy` on a type that's 8 bytes or less, because your options when calling a function are to pass the value or pass a pointer (Rust references are restricted wrappers around pointers). If the thing is smaller than a pointer there's less operations, and many optimizers do a better job given values instead of pointers. Prefer pass by move when possible. But sometimes you don't want to consume a value, so in those cases where you don't have a `Copy` type, pass by reference. If that creates a lifetime issue, `.clone()` it if possible at the call site. As a personal habit I profile nearly all of my code which provides me the leverage to clean up excessive cloning. Measurement and experimentation is _the only way_ to know what makes code slow. With even decent profiling, you can answer questions like: "Given that multiple threads need to read the data stored in a Vec, should I clone the Vec or put it in an Arc?"
Is it generally impossible to define what data is passed along the graph? Normally for this idiom you'd have a trait object that defines how each node is constructed and connected in the graph, and a callback that takes a context as an argument for modifying before passing the context to the next node(s) of the graph. Generally you'd define what the context is supposed to contain. Ideally nodes would have no knowledge of one another's existence.
 ,@@@@@@@@@@,,@@@@@@@% .#&amp;@@@&amp;&amp;.,@@@@@@@@@@, %@@@@@@%* ,@@@% .#&amp;@@@&amp;&amp;. *&amp;@@@@&amp;( ,@@@@@@@% %@@@@@, ,@@, 3 ,@@, ,@@, ,@@/ ./. ,@@, %@% ,&amp;@# .&amp;@&amp;@@( .@@/ ./. #@&amp;. .,/ ,@@, %@% *&amp;@&amp;. ,@@, ,@@, ,@@&amp;%%%%. .&amp;@@/, ,@@, %@% ,&amp;@# %@&amp; /@@, .&amp;@@/, (@@&amp;%(*. ,@@&amp;%%%%. %@% &amp;@# ,@@, ,@@, ,@@/,,,, ./#&amp;@@@( ,@@, %@@@@@@%* /@@, #@&amp;. ./#&amp;@@@( *(%&amp;@@&amp;. ,@@/,,,, %@% &amp;@# .&amp;&amp;. ,@@, ,@@, ./, .&amp;@# ,@@, %@% ,@@@@@@@@@% ./. .&amp;@# /*. /@@. ,@@, %@% *&amp;@&amp;. ,, ,@@, ,@@@@@@@% .#&amp;@@@@&amp;/ ,@@, %@% .&amp;@# ,@@/.#&amp;@@@@&amp;/ /%&amp;@@@@. ,@@@@@@@% %@@@@@. ,@@, ,*************,,*/(((((//,,*(#%%%%%%%%%%%%%%%#(*,,,****************************************************,*/(((((((((/((((////****/((##%%%%%% ,*************,,//((((((//,,*(%%%%%%%%%%%%%%%%%##/*****************************************************,,*/(///(//////****//((##%%%%%%%%%%% ,************,,*/(((((((//***/#%%%%%%%%%%%%%%%%%%%#(/***************************************************,*//////////*//((#%%%%%%%%%%%%%%%%% ,***********,,*////////////***/##%%%%%%%%%%%%%%%%%%%##(*,***********************************************,,*////////(###%%%%%%%%%%%%%%%%%%%% ,**********,,,*/*******//////**/(#%%%%%%%%%%%%%%%%%%%%%#(/**********************************************,,,***/(##%%%%%%%%%%%%%%%%%%%%%%%%% ,*********,,,,*************///***/(#%%%%%%%%%%%%%%%%%%%%%%#(/***********************************,****,****/((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%# ,*********,,,***************//****/(##%%%%%%%%%%%%%%%%%%%%%%##//**************//////////////////////((#####%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#( ,********,,,,***********************/(#%%%%%%%%%%%%%%%%%%%%%%%##################%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/ ,*******,..,***********************,,*/##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###((// ,*******,.,,***********************,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(//**// ,******,.,,,************************,,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//******* ,*****,,,,,********,***,,,,,,,,,,,,*,,,,,,*/(######%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/********** ,*****,..,*******,,,,,,,,,,,,,,,,,,,,,,*,,,,*///((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###(/************ ,*****,,,*******,,,,,*,,,,,,,,,,,,,,,,,****,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#######(//************** ,****,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,**,,,/(%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#((//****************** ,***,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..,,,,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/******************* ,**,,.,,,,,,,,,,,,,,,,,,,,,,,,,,.......,,,,,,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#####%%%%%%%%%%%%%%%%#(/****************** ,**,..,,,,,,,,,,,,,,,,,,,,,,,,,......,,,*,,,*(#%%%%%%%%##(((/(##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(((/*/((#%%%%%%%%%%%%%%#(/***************** ,*,..,,,,,,,,,,,,,,,,,,,,,,,,,,,.....,,**,,*/#%%%%%%%##((((*,**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((##/,,,*(#%%%%%%%%%%%%%%#(***************** .*,.,,,**,,,,,,,,,,,,,,,,,,,,,,,,,,*****,,,/(%%%%%%%%#(//(#/,..*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//(#/,..,/(#%%%%%%%%%%%%%%#/*****/////////// .,..,,,,,,,,,,,,,,,,,,,,,,,,,,*,,*******,,,(#%%%%%%%%#(*,,,....,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(*,,,....,/(#%%%%%%%%%%%%%%#(*,**//////////// .,..,,,,,,,,,...........,,,,,,*,********,,*(#%%%%%%%%%#(/*,,...,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,..,*/##%%%%%%%%%%%%%%%#(***//////////// ...,,,,,,,................,,*,**********,,/#%%%%%%%%%%%%#((////((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((///(#%%%%%%%%%%%%%%%%%%(/**//////////// ..,,,,,,.................,,,**********,,*(#%%%%%%%%%%%%%%%%%%#%%%%%%%%#((///((#%%%%%%%%%%%%%%%%%%%%%#%%%%%%%%%%%%%%%%%%%%%#/**//////////// .,,,,,,,,.................,,***********,,/(####%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*//////////// .,***,,,,,,..............,,,**********,..,***//((##%%%%%%%%%%%%%%%%%%%%%%%##((##%%%%%%%%%%%%%%%%%%%%%%%%%##(((((((((###%%%%%#/**/////////// .*****,,,,,,,,,,,,,,,,,,,*************,..,*******/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##///*//////((#%%%%%#(**/////////// .****************/******/***////*****,.,*///////**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(////////////(#%%%%%#/**////////// .***********************/////*******,..,*//////////(#%%%%%%%%%%%%%%%%%%%%##########%%%%%%%%%%%%%%%%%%%%#(///////////*/(#%%%%%#(***///////// .************************///********,..,*//////////#%%%%%%%%%%%%%%%%%%#(//*****///(((##%%%%%%%%%%%%%%%%#(///////////**/##%%%%##/***//////// .***********************************,.,,***///////(#%%%%%%%%%%%%%%%%#(/*,,,*//((((////(#%%%%%%%%%%%%%%%#((////////////(#%%%%%%#(*********// ,***********,,,*,,*,,**************,,,*//******//(#%%%%%%%%%%%%%%%%%#(*,,*/(((#####(((((#%%%%%%%%%%%%%%%##///////////(#%%%%%%%%#(***/////// ,*************,,**,,,************,,,,,/(##((((####%%%%%%%%%%%%%%%%%%%(/**/(((#((((#((//(#%%%%%%%%%%%%%%%%%#(((((((((##%%%%%%%%%%#/**/////// ,******************************,,,,,,,*(#%#%%%%%%%%%%%%%%%%%%%%%%%%%%#(**/((#(#(((#((//(#%%%%%%%%%%%%%%%%%%%%%%%#%#%%%%%%%%%%%%%#(**/////// ,*************,**************,****,,,,,/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*/((((#((((///(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(/*/////// ,*************************************,*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(////////////(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#/**/////* ,******////****///////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%####(((((((###%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(******** .,*,****///////////////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/******* .,,,,*****//////////////////////////*******(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(******* .,,,,,,***********/////////////////********/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(*******
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/amethyst] [Evolution Island: Amethyst showcase game looking for collaborators](https://www.reddit.com/r/Amethyst/comments/bf65us/evolution_island_amethyst_showcase_game_looking/) - [/r/rust_gamedev] [Evolution Island: Amethyst showcase game looking for collaborators](https://www.reddit.com/r/rust_gamedev/comments/bf65q7/evolution_island_amethyst_showcase_game_looking/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Not off the top of my head - I think that a good place to start would be with the differences between OS Threads and Green Threads. Something easy to find would be to run `man ulimit` on your Linux/macOS machine (or google it) to get an idea of what kinds of limits might be imposed on a running program.
So, I think your biggest issue here is that you don't really understand command lines. Please know that at any time you can type help into the command line to give you a breakdown of the possible commands that are available. Let's go back and figure this out. The command line is exactly what you see in file explorer except without the fancy gui and "folders" and such. So, as an exercise, open up both a command line and a file explorer to the C drive (type 'cd C:\' in the command line). Now type 'dir' into the command line and you should be able to see everything that's in the folder listed out. Compare that to your file explorer, it should show the same things just in a different way. Hopefully things are starting to make sense, now to open one of those folders on the C drive in the command line, you just use the cd command and start typing the name of the folder you want and hit tab until it autofills to the correct one. It should cycle through alphabetically, so if you have two folders like "Some Folder" and "Some Directory" it should autofill to "Some Directory" then "Some Folder" then back again. Now back to your issue. The path in the start of the command line (before you type) is the current directory where you're working in. Notice when you cd into a different directory the path changes. So, if you typed cargo new into the wrong directory, it's likely that you accidentally created a new project folder in a directory that you didn't want one in. So, in short, that folder is wherever you created it. Let's make it simple do the following commands: cd C:\ mkdir "Rust Programming" cd "C:\Rust Programming" cargo new rust_program mkdir = Make Directory. Now open up your file explorer and go to the C drive. Click on the Rust Programming folder, and there should be the rust_program project folder in there. Next VS Code allows you to open up any folder and it'll list out the tree of files and folders so you can open them and view/open/edit the files without using the command line or the file explorer.
One of the [goals for this year](https://github.com/rust-lang/rfcs/blob/master/text/2657-roadmap-2019.md) (under the compiler section) is better IDE integration with the compiler, which should definitely help.
Hey! I'm one of the devs working on this project and the current repo maintainer. Just passing by to say that any interested devs may feel free to direct message me on Discord or ping me in the Amethyst Discord channel. While I have been inactive due being guiltily-but-productively busy with my thesis (which is going great!), I'm always checking the forums, Discord and often am available on weekends for exchanging ideas, do code reviews or help clear up any questions about the current code. &amp;#x200B; Anyway, feel free to hit me up! @khskarl on Discord and GitHub.
How is Rust better for making games? Like is harder to put cheats on games? Or what is it? Noob question. Thanks.
The problem is that your "why" is unconvincing. Having a reason is one thing, but it needs to be a convincing reason to change anyone's opinion. I could say that we should all program in J because its better, that's not going to make anyone program in J. Rust should be compared to the greater community of programming languages. It is interested in pulling people from those crowds, not just Go. Moreover, language design is such a massively diverse design space that to latch on to Go as "having done it right" is great and all but would not convince anyone asides from those that really like Go. tl;dr your arguments are lacking substance.
Yeah, I'll keep the lights on, but I don't use the library myself any more (in new applications), so there isn't much dogfooding going on. It has at least two fairly important deficiencies at the moment. Firstly, clap is going to be much faster, since docopt internally uses a backtracking-like algorithm to match arguments with the usage. Maybe docopt could be made faster, but I never devoted time to it. Secondly, docopt only supports `String` arguments, which means it can never work with all possible file paths on Unix (or Windows). This could be fixed, but just requires internal refactoring that I don't plan on doing.
maybe you are confused about this but im just confused why you are asking this question in a thread about a ASCII art generator project. maybe the real question is do you know what you are doing enough that if someone answers your questions for you will truly learn? get off reddit , go medidate and next time you do stuff think about it very very clearly. once you achieve this go learn, read and try it yourself you should be a much better guy that can answer your own questions
A list of accredited registrars on RNIDS (Serbian National Internet Domain Registry): [https://www.rnids.rs/en/registrars/list-accredited-registrars](https://www.rnids.rs/en/registrars/list-accredited-registrars) &amp;#x200B; Comparing the list and a handful of rust websites with a [WHOIS](https://www.rnids.rs/en/whois/) lookup: * [diesel.rs](https://diesel.rs) uses [Beotel](https://www.beotel.rs/hosting/domeni) * [docs.rs](https://docs.rs) uses [ninet](https://www2.ninet.rs/en) * [areweasyncyet.rs](https://areweasyncyet.rs) uses [ISTanCo](https://www.istanco.rs/)
&gt;and then (in the not-so-distant future) use the benefits of said approach to integrate into the RLS. I don't think that's true. I think it's definitely meant to be a separate / new thing, as it pretty much implements everything from the ground up. The biggest difference (key for performace) is that it includes a hand-rolled parser and does not rely directly on `rustc` at all (no waiting for it to build your project or anything like that.)
I don't do low-level things with Rust, I use it where existing solutions aren't fast enough for me. My pet project on this front is https://github.com/saethlin/loadtxt, which I use as a replacement for `numpy.loadtxt` because I have to work with C codebases that emit very large (~1 GB) text files. I'm also on an HPC system so my dev environment is two Xeon Gold CPUs. In such an environment you _really_ want to share memory so Rust is a great fit because both the language and its libraries are designed for taking advantage of the compute resources I have available to me.
Dude STFU. Have a nice day tho.
You're getting downvoted because the question is at least mildly out-of-place. But Rust is superior for making games **in some ways** for the same reasons it is superior for ANY systems programming. Its static-analysis means it's much harder for a programmer to create memory bugs, if they're not writing "unsafe" code (unsafe is a keyword in rust). It won't save you from a vast variety of cheats, man in the middle attacks, decompiling/modifying byte/machine-code, etc. Client code that you ship to another human being is not to be trusted, even if it started out as your code, and no matter what language you initially wrote it in. Is that helpful?
Is there a good example of handling pagination with reqwest. Asking specifically for use with the GitHub api
I use ninet for serde.rs. No complaints. I pay them 29 €/year.
I really like https://rocket.rs . Would love to learn actix but rocket was so easy coming from a node background and worked well for my use case
Thanks.
Lol this is such a condescending non-answer.
I'm so going to Bogart this concept into E-Nguyen as a post-process
You should share Suzanne over in r/blender if you haven't already
I always tell people to read the book and actually do the sample problems in it. Rust is very painful to learn by just writing code and searching stackoverflow when you get stuck.
Would it not be possible to use the GPU and/or SIMD to speed up both this project and something like https://github.com/daleroberts/tv?
 GPU processing would be faster, but it would have a higher overhead and be less lightweight. The only time I could see sloth being used is in a scenario where one does not have a GPU, and would like to visually see a 3D file. By using the GPU you kinda defeat this purpose. Disregarding practical uses, it absolutely could be hooked to an OpenGL framebuffer because you can read pixels from vram, but it's just costly performance wise as you're reading every single one. It would be fast as hell, too. Speaking purely on performance, there may be diminishing returns as generally everyone's terminal window has a similar text-range (maybe 100-1000 characters wide), so what one might think will speed things up could add so much overhead just rasterizing on the CPU could be faster. Plus, you would have to change the name from sloth to something else because it's named after its slow software rasterizer (TOTALLY the most important point imo).
I was certainly thinking that, but decided not to bring that tired argument up. Looks like you've done that for me anyway.
Ah, I had no idea the lifetime is what's (likely) causing it, thanks! &gt;but kept the `impl Parser` stuff because the types were simply too annoying and large to type out Just to be clear, as an example, I have a `Map` type that is generic over the original parser and the transform closure, so with this approach the types are very easy to type out. But it does involve writing some boilerplate, so I guess there's a trade-off there. Either way, trait methods can't return `impl Parser`, so writing dedicated types for each combinator was my only choice.
Have a look at rust's crossbeam crate: https://stjepang.github.io/2019/01/29/lock-free-rust-crossbeam-in-2019.html and c++ cpp-taskflow https://cpp-taskflow.github.io/#/ https://github.com/cpp-taskflow/cpp-taskflow
error\[E0583\]: file not found for module \`inputs\` \--&gt; src/main.rs:14:9 | 14 | pub mod inputs; | \^\^\^\^\^\^ |
&gt; For anyone familiar with Rayon, is using it behind a web server a bad idea? I'm not intimately familar with rayon - if you read [this post](http://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/) and watch [this talk](https://youtu.be/gof_OEv71Aw) you'll know as much as I do - but this doesn't seem like a bad idea at all. &gt; I'm used to languages with green threads and am not accustomed to spinning up real threads for this type of work. Spawning a new threadpool to handle every request would be a bad idea, yes. Fortunately, Rayon uses [a single threadpool](https://github.com/rayon-rs/rayon/blob/047ea91e6450d923ff769179de94a15fcdf7e6aa/rayon-core/src/registry.rs#L53) for all jobs by default. The particular way Rayon sets up its ThreadPool means you pay for setting up threads once when you first use a Rayon parallel iterator, and after that it reuses the same threads. &gt; Is calling a Rayon workload from a multi-threaded web server like Rocket a bad idea? Given that every popular web server in Rust is multithreaded, I'd hope not. :) [Rayon creates one thread per core](https://github.com/rayon-rs/rayon/blob/047ea91e6450d923ff769179de94a15fcdf7e6aa/rayon-core/src/lib.rs#L221) by default, and [Rocket creates two per core](https://github.com/SergioBenitez/Rocket/blob/7ab1c427b54373fe69c4e9df526aeaf5d1d2eed6/core/lib/src/config/config.rs#L218). Having three threads per core shouldn't cause any catastrophic problems; at worst, each core switching between multiple threads means you'll pay for context switches and more cache misses, but those only affect performance. &gt; What happens if I run out of threads? Might I block incoming web requests/etc? You'll be hard-pressed to run out of threads in this situation. If you created a new threadpool per request, you'd run into trouble, but (3 \* cores) threads is no problem - my phone, which reports 8 cores, can spawn 80 threads with only minor issues. (The UI locks up while the program is running if I spawn more than 7 threads, but .
I love this. When I first started learning C++ in the early 2000’s and just had an 80x25 character output with 16 foreground and background colors available I decided I would rather figure out how to use the text characters as pixels than let the rendering logic sit behind some mysterious 3D API. Pretty sure I still have that spinning lit textured text console cube sitting around somewhere. At one point I was building a database (or a high dimensional vornoi diagram) of mappings between colors and colored characters based on the ratio of foreground pixels. Though I know that folks in the demo scene took it a lot farther than I did!
I must be doing something completely wrong. I cloned rust repo locally. I navigate to this rust folder. I type `cargo build`. I get: ``` error: failed to read `&lt;fakepathto&gt;/rust/src/tools/clippy/Cargo.toml` Caused by: No such file or directory (os error 2) ``` Sure enough, the clippy folder is empty. Any help appreciated! Thanks.
I appreciate your innovacity C:
Coolest thing I've seen today
Is it expensive to repeat this multiple times in the same loop? window.draw_2d(&amp;e, |c, g| { rectangle(...); }); piston\_window
Hah, it's still up. http://entropygames.net/files/shared/textconsole.zip
...and windows 10 thinks all those old applications are all viruses! That's what I get for using windows.h.
This is sick AF! I just ran some of the examples (compiled without a problem, which is also great). Christ on a bike it's slow if you don't compile with .\`--release\`, but it's so much faster with the production optimizations on. Maybe that's obvious to most people but I've never had a Rust executable demonstrate such a profound difference as this. I really really love this project.
&gt; Having a reason is one thing, but it needs to be a convincing reason to change anyone's opinion. And that is the reason we are having this right arrow, this crappy :: and line endings with ; that is so annoying. And I can think of a dozen items more if you are giving me time. But it is thanks to guys like you who need to be convinced instead of guys who are actually doing it and make the world better instead of worse.
I'm confused by this comment. Rayon manages a global threadpool with a fixed number of threads. It doesn't spawn a new thread when you ask it to parallelize some work. (If it did, that would defeat the entire performance benefit of using Rayon, since spawning an OS thread isn't cheap.)
Yeah no kidding. “Intelligently finds inputs that break your code.” If only all of my projects could have this feature. Then I wouldn’t have to convince people that unit testing is important.
Are you familiar with the OpenMaya interface and creating nodes with it? It's actually a pretty well designed API for a node graph and would be pretty transferable to rust concepts. I'd try and just emulate that API and system for sending data to nodes. Imho your evaluation engine should always know the types of your plugs and then just write their data to a data block. That data block gets passed between nodes just like in Maya, and querying a plug from it gives you the pointer to the data. Then you just have to trust the third party node to cast that pointer to the right type.
Oh dang, does it? I've been wrong in my understanding about Rayon all along :(
I used istanco for a while and it worked well
Let me inform you that I am not.
Assuming you're trying to build [https://github.com/rust-lang/rust](https://github.com/rust-lang/rust) `rust/src/tools/clippy` is a [git submodule](https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjA4pTh9d3hAhXxQd8KHeu8AM0QFjAAegQIABAB&amp;url=https%3A%2F%2Fgit-scm.com%2Fbook%2Fen%2Fv2%2FGit-Tools-Submodules&amp;usg=AOvVaw2Z1IcMzfGul-EouSqqX_G9). Normally if a project contained submodules you would initialize all of the submodules with git before trying to build it, however, the rust build script [`x.py`](https://x.py) will do this for you when building the compiler: $ ./x.py build For more info see [this chapter of the rustc book](https://rust-lang.github.io/rustc-guide/how-to-build-and-run.html).
Is C++ really taught as a first language that much anymore? The AP test for high school CSS switched to Java in the late 90s or early 00s. By the time I started uni in the early 00s, Java was the language of choice. I hear tell it's Python now. Who's teaching C++ as a first language these days?
Wait, so you're saying the world is a worse place because people use Rust instead of Go?
&gt; the last thing I want to do is introduce undefined behavior I believe the parent comment misunderstood Rayon a bit. Using Rayon doesn't spawn threads willy nilly, so you don't have to worry about running out of them. Also it might be worth clarifying that a "resource temporarily unavailable" panic isn't undefined behavior; it's a crash, yes, but not a memory vulnerability than an attacker could exploit or anything like that. That said, Rayon isn't ideally suited to parallelizing requests for a webserver. It's intended for _data parallelism_ specifically, that is, situations where you have all the data you need and just need to run some computation on it as quickly as you can. But that's not really the case in a webserver. You'll often be blocking on IO, waiting to send or receive more bytes over the network. If you do that inside the Rayon threadpool, you'll end up blocking all the treads in the pool, and your performance won't be great. See this warning: https://docs.rs/rayon/0.9.0/rayon/fn.join.html#warning-about-blocking-io However, if you're using a web framework that's already taking care of parallelizing requests for you, and you just need Rayon to help you parallelize some computation within a request, that could be a very good fit.
No worries, take a look here: https://github.com/rayon-rs/rayon/blob/master/FAQ.md
If we're looking at extreme minimalism, the various lang items could be reduced to *less* than nothing with `core::hint::unreachable_unchecked()` which is undefined behavior to run. Since you're using `no_core`, you should probably to able to redeclare it as `extern "rust-intrinsic" { pub fn unreachable() -&gt; ! }`. This way, the compiler won't even bother adding a return instruction even if it doesn't have an infinite loop.
Is this still Rust? Haha
We defefinitelly want, long term, just a single codebase which can be both a batch compiler and an interactive language server. So, long-term, rls, rust-analyzer, rustc should should be merged. That is a very distant future at this point however.
I can't give you any names but I'm on a reasonably large programming Discord server (&gt;18,000 members) and the inflow of people being taught C++ as a first language seems about the same as it was 4 years ago. That's all _very_ anecdotal, but it's definitely still happening.
Yup, that's basically the design I have in mind. But, the data that it passes around is defined at runtime. So, the graph doesn't know about mesh data until the mesh data plugin is loaded.
Dunno if you fixed it, but that coredump should actually be super helpful. https://stackoverflow.com/questions/5115613/core-dump-file-analysis Basically, [find](https://stackoverflow.com/questions/2065912/core-dumped-but-core-file-is-not-in-the-current-directory) where it was dumped inside docker. Copy it out and run `rust-gdb` with it, instead of normal gdb, with how that stack overflow post says how you debug a core dump. Then, you should be able to get a stack trace to find what dependency has the issue and where the unsafe code is that might cause it. It kinda sucks, because the bug only happens after awhile, so it's probably not going to be an easy free to fix. But, using rust-gdb on that coredump should get you started.
It is the most simple, but yet very informative explanation I have ever seen.
Although I agree, that autocomplete for rust is non the best, but I was using TabNine lately, and I was pretty satisfied.
That sounds like a job for either a dynamically typed language or serialization protocol like JSON.
Yup, Maya is generally my bread and butter for work. I'm borrowing some ideas from Maya, but mostly looking into applications such as Houdini, Katana, Gaffer, and Nuke, because (to me) nodes in Maya feel like the refer to the object, whereas the other applications refer to the changes to the state of the world. I personally like the second option, because it should make cases such as swapping geometry in a rig easier (fingers crossed). However, I realize this may make things more complicated when it comes to things such as "subdivide only one mesh rather than all the meshes". As for the plugs, I still have to decide if the data type is known at runtime or compile time. At the very least, I would have to have types that support animation (ints, floats, etc), and probably string types. Right now the rough idea is the plugs are functions that get evaluated. They may be a constant value, animation graph, or some arbitrary function. Passing data around will probably look something like this: A node's evaluation function will take a context object and get all of the state that is passed into it. It then decides if it is going to modify the data, clone it, modify it, then pass it back to the context as the output of the data. Or if it is creating new data such as a mesh generator, then just pass the data to the output.
I think it can be done with a statically typed language, but it would mean having to pass void pointers around and let the evaluation function handle dereferencing. So, there's going to likely be some unsafe code, but at least it is close to where the data is going to be manipulated.
I think you better read the entire thread that I wrote.
If it's just data you can put it into an enum variant, check out how serde_json does it, very straightforward. You can also add a function variant that contains a `Box&lt;dyn Fn(Var) -&gt; Var&gt;` (or something similar), to contain methods in the data. But that's more or less a dynamic type system and interpreter just implemented in Rust.
I did, I think you should work on your honest communication with others, and maybe tone down the dogma a little bit.
How does it differ from `futures-timer`?
&gt; futures-timer It is different in a way that it allows user to supply own `Timer` for all primitives like `Delay`
Cool beans! I'm getting similar sizes (8432 bytes) without unstable features and with less code. I wonder what makes the bulk of those bytes – haven't looked at the assembly. #![no_std] #![no_main] #[panic_handler] fn panic(_info: &amp;core::panic::PanicInfo) -&gt; ! { loop {} } #[link(name = "c")] extern "C" { fn write(fd: i32, buf: *const i8, count: usize) -&gt; isize; } #[no_mangle] pub extern "C" fn main() -&gt; isize { unsafe { write(1, b"Hello, World!\n" as *const u8 as *const i8, 14) }; 0 }
Actix is very similar to rocket, especially the upcoming 1.0 version. It lacks a little bit behind in the "easy database configuration" department with a little more boilerplate but having good websocket Support is more important to me. Have a good day!
No. I don't think so.
😳😳 That's odd.. I'll look into that later!
Can you give an example of buggy highlighting from RLS?
Fixed**
Hey all! I made a thing I thought I'd share, a `#[struct_layout::explicit]` proc-macro attribute inspired by C#'s `[StructLayout]`!
Good luck, anethyst really needs showcases! I am not into 2D gamedev myself, but the second you need help with a 3D showcase, I'd be up for it!
The code is a mess unfortunately. It's academic code and also the first thing I wrote in Rust so full of bad practices. The next project will be a complete refactor and solve a more general problem so should improve a bunch then. Would be less embarrasing for people to read it after that.
Not from RLS. RLS itself doesn't provide syntax highlighting. It's bundled in VS Code. Here's the example: [https://i.imgur.com/QrrnGD5.png](https://i.imgur.com/QrrnGD5.png)
When your code breaks at 3am, and you have fix it, after a panicked session of frantic debugging, you find the issue and feel like an total idiot, you realise this would have never compiled in a static language. Repeat a few times, and you get the picture
The code runs on one machine and nobody will ever use it at 3am - I think it'll be fine ;)
Strangely enough, VS Code actually uses the syntax from [an Atom extension](https://github.com/zargony/atom-language-rust) for Rust highlighting. However, Atom itself now has a different highlighter built-in, so it's not really used there any more. Due to this, plus the fact that the auther of the extension is too busy, the syntax hasn't really been developed that much lately. [There's an issue open on their GitHub looking for maintainers](https://github.com/zargony/atom-language-rust/issues/144) - contributing there would probably be the most direct way of improving VS Code's highlighting.
I never noticed your comments with a link to this article, and considering that others haven't as well, wy not take this as reason not to tire of sharing it? It's a good post!
Check out [Rust Analyzer](https://github.com/rust-analyzer/rust-analyzer). It is still in development, but it's already quite good and it supports proper syntax highlighting.
I was hoping for a post about consensus protocols, but this turned out to be more the social kind of consensus :)
What does this have to do with Rust?
&gt; It's intended for data parallelism specifically, that is, situations where you have all the data you need and just need to run some computation on it as quickly as you can. But that's not really the case in a webserver. For clarity, what I'm dealing with is a web server we wrote at work that handles ~hundreds of millions of lines from a cache, per web request. It's a very specific application that basically crunches rows of data from memory. The amount of IO _(once the dataset is cached)_ is minimal by comparison, thankfully. &gt; However, if you're using a web framework that's already taking care of parallelizing requests for you, and you just need Rayon to help you parallelize some computation within a request, that could be a very good fit. Yup, I think that is exactly it. My next concern would be figuring out _how_ I can parallelize, as some data points are expected to be calculated in order, others not. Will be curious to experiment. Thanks!
Even better, make your starting point `_start` rather than `main` (which is called by libc rather than the actual executable starting point) and implement `write` and `exit` functions using syscalls (requires inline assembly for x86), so you don't depend on the C standard library as well
It seems like statically linking to libc would be a benefit in this case since it would make the exe smaller. It's also why C exes on Linux are around 9Kb for a simple hello world.
I agree with your points regarding trait objects and `Arc&lt;Mutex&lt;_&gt;&gt;`, but `Rc&lt;RefCell&lt;_&gt;&gt;` is somewhat different. `RefCell` feels like a copout because it moves the borrowing checks to run time where they don't really belong, not because they affect performance, but because they affect reliability. What good is it to claim that a Rust program that doesn't use `unsafe` is crash-proof if the code is fraught with panics potentially introduced by every call to `RefCell::borrow` and `borrow_mut`? Sure, a programmer understands the difference between a panic and a hard crash caused by undefined behavior, but for the end user the end result is the same - a bug went undetected at compile time and failed at run time instead. That is one of the things Rust was explicitly designed to prevent, and `RefCell` (introduced without care) is a step in the wrong direction.
Still requires rustup and nightly :(
You're right :-). It looks a little different for me, but it's indeed not great. I even tried `rust-analyzer`'s highlighting mode, but it's not any better.
The issue is that there's no stable ABI for Rust dynamic libraries. There was some work towards one, but it's pretty far from completion. Also, updating a _library_ will generally not require the users to "recompile all packages", but updating the compiler will. Also, Rust applications generally lock all of their dependencies to a fixed version (and that's actually not a bad thing!).
Thank you.
A locked mutex forces all threads that need the shared resource to wait. Even if your thread holds the mutex "only briefly", it could be descheduled by the OS *while holding the mutex*, in which case all threads that needs the same resource are forced to wait for the original to be scheduled again and release the mutex. The solution is to use higher level abstractions implemented by experts using lock-free data structures. For example, [crossbeam channels](https://docs.rs/crossbeam-channel/0.3.8/crossbeam_channel/) provide extremely efficient communication among threads, and [rayon](https://github.com/rayon-rs/rayon) implements streaming and fork-join parallelism using a thread pool and a work-stealing queue. Ideally, those are the kinds of abstractions one should turn to first when considering multi-threaded programming.
Sure it become necessary to recompile. Imagine there's a reliability issue in the libc – so Debian etc. distribute an update. All the userspace applications just link dynamically against the new library. If all your crates are linked statically, you (or the guy maintaining a package) have to re-link (== compile) your programs against the updated static library. There is no other way.
Are you talking about a situation where libraries are linked dynamically or statically? If you're using dynamic linking, you can generally update the dynamic bits without breaking the ABI, as long as you use the same compiler. If you're using static linking, you do have to recompile everything.
That would be the best if Rust team takes over it IMO. Alternatively, making a new one from scratch as a new extension also makes sense. I even tried to do it, but TextMate grammar rules stopped me.
Does there need to be a loop around the write call, to make sure it writes all the bytes?
Sadly it didn't work for me. Buggy syntax highlighting's still there.
&gt; My next concern would be figuring out how I can parallelize, as some data points are expected to be calculated in order, others not. If there's a natural way to express your computation recursively, the rayon::join API can be a really easy way to parallelize it. Any recursive steps you can do in parallel get joined, but anything where you need the result you can just write the usual way.
How familiar are you with those other applications at an API level and as a user? I'm curious what your take aways are doing complex rigs with each of them. It's quite a bit harder to implement things the way they did while still being flexible and performant. Houdini and nuke for example are typed as well but at a higher level. In houdini you're typed by the opnet you're in. Nuke and katana both do strong typing between dimension types (ie you can't mix 3d and 2d nodes without a conversion in between) and nukes evaluation manager has to jump through hoops to concatenate similar operations like transforms and color ops. Compile time versus runtime is an interesting debate, do you intend to have a UI at some point? How quick would changes be to changes in the UI? Would you even be able to do type safety if you're just modifying them as generic contexts? Do you intend to be able to parallelize your graph at all? It gets a lot trickier with world contexts though not insurmountable. Overall it's a very with endeavor. I'd start backwards though and go from the kind of uses and plot out the data flow, to then arrive at implementation details.
Have you tried to enable the `rust-analyzer.highlightingOn`? Although it is experimental, but it is based on actual syntax parsing.
Of course. I don't know what's wrong.
I assume you mean dynamically linking libc, or statially linking to an embeddable libc like musl? Ultimately, dynamically linking to libc will have a similar size impact to implementing libc functions with raw system calls (which only take a few lines of inline assembly) versus some . The main advantage of linking to libc is that the implementations have user-space wrappers over raw system calls to ensure correctness and debuggability. On the other had, embedding these functions as part of a static binary instead of relying on libc a la Go has a huge advantage of binary compatability across OS distributions.
Why do you use a C main instead of the standard Rust main?
Dynamic linking, yes.
Yes this is a serious problem, but it's not easy to fix.
I recently discussed this with some folks as well. The amount of code that is monomorphised at the final call site also factors in how effective sharing a dynamic library is.
Both implementations of `Chooser::choose need to have the same lifetimes, because lifetimes only exist at compile-time. I modified it so that both `self` and `other` are constrained to the `'a` lifetime, meaning `'a` becomes the intersecting lifetime of `self` and `other`. I also had to make first and second references for some reason, I'm not entirely sure why https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5f85abd5db257948b347de82d213fa71
Might be worth digging into libaa to see the tricks they play. There is an awesome demo of what they could do with it: [https://www.youtube.com/watch?v=FLlDt\_4EGX4](https://www.youtube.com/watch?v=FLlDt_4EGX4)
&gt; What good is it to claim that a Rust program that doesn't use `unsafe` is crash-proof if the code is fraught with panics potentially introduced by every call to `RefCell::borrow` and `borrow_mut`? I don't think anyone claimed that not using `unsafe` made a program crash-proof. Rather it ensures absence of undefined behavior. This is quite different IMO. A panic is a well-identified crash with a stack-trace to guide you. Compared with a segfault triggered because some unrelated part of the program once wrote at the wrong place some time ago, I find it quite better.
As long as you're developing open-source software for use by other programmers, then... this isn't really a big issue, speaking from my own experience. You just don't use dynamic libraries and that's usually fine. The time it gets annoying is mostly when you want to make binary plug-ins in Rust.
Nice, but it doesn't help me when I am trying to use rust in an embedded setting. As soon as you try to move beyond C level of abstractions, and want to use things like Vec - the standard library pulls in hundreds of K of code with std::fmt Debug, and utf8 manipulation code that you neither want, need or necessarily have room for in flash memory.
Sure, it would be ideal if the core rust team had infinite time and energy.
Is there a way for me to iterate over a collection of different types?
I've since tried to tackle point 3 at [https://github.com/nlopes/avro-schema-registry/commit/b78c58695ad6d3976af121f683e6e9c438221cb5](https://github.com/nlopes/avro-schema-registry/commit/b78c58695ad6d3976af121f683e6e9c438221cb5) &amp;#x200B; Is this what you had in mind @fafhrd91?
Interesting! I tried it like that before, but with my main function being got greeted with let a = first.choose(&amp;second); error[E0597]: `first` does not live long enough --&gt; src/main.rs:26:13 | 26 | let a = first.choose(&amp;second); | ^^^^^---------------- | | | borrowed value does not live long enough | argument requires that `first` is borrowed for `'static` &amp;#x200B; fn main() { let first = First {}; let second = Second {}; let a = first.choose(&amp;second); let b = second.choose(&amp;first); println!("{:?} {:?}", a.type_id(), b.type_id()); }
I didn't realize that Go used the syscalls directly. They do list glibc as a requirement. Maybe they use it for something other than syscalls?
You could definitely use something like OpenCL to create a portable implementation that works across cpu + gpu
I was hoping Alice In Chains :(
Rust-analyzer supports only pretty basic highlighting at the moment. It could do much better, but, unfortunately, neither LSP no VSCode have fasilities to implement proper highlighting (as opposed to colorization via a bunch of regexes). The bits of highlighting that exist are a giant, horrrible hack which I’v added for my personal use :-)
No, I'm not entirely sure what that's about, like I said, I had to make them references, like \`first = &amp;First{}\` and \`second = &amp;Second{}\` in order for it to compile.
If I could give gold, on god I'd give gold. After so long, I was finally able to open up the main.rs file and have highlighted syntax come up with the classic fn main() { println!("Hello, world!"); } come up. So now my next step is which most basic things I should learn about VSCode. Example is how do I run the program, or if I need to know anything else about VSCode at this point.
Alright; hopefully, someone else will chime in!
Very cool! It is very strange because I'd just written a similar color changer (no 3D). It was like 2 days ago..
I tried to use the Rust standard main, but with `no_std` enabled, it appears to require it to be annotated with `#[start]`. That, in turn, requires a unstable feature.
&gt; I wanted to avoid using Mutex but because the Parquet execution plan creates threads, I need to pass channels between threads, and the mpsc::Sender trait does not support this. `crossbeam_channel`'s `Sender` is `Send` and `Sync`, would that help here?
Haha thanks. I kind of feel like a broken record just shilling his own post over and over, but there's definitely a pattern to the issues that show up, so I'm kind of trapped.
Thanks for the crossbeam suggestion. I will check it out. The logical plan will be optimized before being converted to a physical plan, so that only the necessary columns are loaded.
I believe Go depends on libc for cgo support, but the go standard library doesn't depend on libc and statically compiles with the binary by default. IIRC, if you disable cgo, a go app can potentially have no binary dependencies, making it useful for running on arbitrary linux distros, particularly lightweight musl-based containers like alpine.
The approach that I believe SQL Server (which I was familiar with in another life) takes is to have most operators be single-threaded. There are a couple of special operators for parallelism that distribute batches, gather the results, or redistribute them in a different way. I found https://www.red-gate.com/simple-talk/sql/learn-sql-server/understanding-and-using-parallelism-in-sql-server/, which explains it better than I could. Maybe it's worth exploring that approach instead of "baking in" the threading in every operator.
Thanks. That looks like a great article. I'm reading it now. The current PoC only starts one top level thread per partition and then operations such as projection and selection are single threaded. The [FilterExec.next](https://FilterExec.next)() just delegates to its input, for example. It doesn't start any threads. The only reason I have extra threads right now is because I had to create the ParquetFile in separate threads because that parquet lib doesn't implement Send + Sync. I don't know if there is a better solution to that problem.
The memory footprint and the updatability are issues
Yes
It's requiring a 'static bound because of the call to `type_id`. All of the functions on `Any` require that the type is 'static.
I think you misunderstood what K900_ was trying to say, so let me rephrase it. The Rust ABI is not stable: each and every Rust compiler may choose its own ABI, and its own rules. The rustc compiler does not guarantee ABI compatibility for one release to another, nor from one set of flags to another; it does, however, guarantee that if you recompile a dynamic library with the same compiler and same set of flags, you end up with the same ABI. The consequence for the use of dynamic linking is that dynamic linking is only usable with rustc if you are in control of: - The version of the compiler. - The set of flags provided by a compiler. This is generally the case for a distribution, and therefore a distribution could swap Rust dynamic libraries... providing that the authors of said libraries have been very careful with the API they expose. --- The main issue with dynamic linking in C++, D, Rust, and any other "native" language which compiles generics to monomorphized instances, is that generic code is **inlined in the caller library**. Dynamic Linking and Inlining do NOT work well together. At all. Any change in an inline API function is NOT reflected when switching only the dynamic library; the caller library must be recompiled, as if static linking had been used. This means, in turn, that upgrading "only" a single dynamic library following a change requires that the change be *tucked away* in a non-inlined function. As a result, in order to make a library Dynamic Linking Friendly, it should either expose no inlinable functions (including generic functions), or only expose very simple ones which are unlikely to require a change (such as pass-through functions). It's possible, but constrains the design and may compromise efficiency. --- And thus we come to the advice of giving such library a C ABI: - No ABI issue: the mangled name no longer depends on compiler version or set of flags, but is dictated by the code. - No generic issue: C has no generic. - Still potential inline issues: use `#[inline(never)]`, and pray.
Welcome to 2019 lol
What if I want to have 10 args?
First question: what is the collection of different types you have, and how did you get it in the first place? The answer to your question depends on the specific details of the collection of different types in question.
To be honest, most of my work is with the Maya API. Although, I've had a chance to talk to people that know the applications a lot better than me, and it seems the direction I'm planning to go is valid. There may be a UI. First thing I'd want to do is get a working version done and see if the studio I work for is interested in running with it. But more realistically, I'd probably write the graph engine, and hook it into Blender so I get Blender's interface for free. Not sure if I understand the changes to changes in the UI question. I think that the type safety would have to be handled in the nodes' execute method. But, I was talking with some people one (one of?) the Rust Discord channels, and one suggestion is to have the graph itself have a signature like `Graph&lt;T&gt;`, and make the implementation something like `Graph&lt;Box&lt;dyn DataContainer&gt;&gt;`. So if we want to have everything strongly typed, that's still an option. The main reason why I want this to have the nodes and types defined at Runtime is so if developers use this, then they don't need to worry about working in managing their own copy of the library, or work in Rust. Yup, I'm probably not going to parallelize it on my first pass, but it will be. This is why the data is passed immutably between nodes. Thanks for the feedback. I think I have some use cases sketched out, but I'll probably go back and give it a second pass. There's still plenty of questions that I have to answer such as if someone were to use this to make a rig, what would the rigging interface look like?
Under what kind of use cases would you need to resort to Vec in an embedded setting? What kind of inputs or data are you working with where you don't know the size or can't allocate a sufficient buffer for beforehand, and therefore had to dynamically allocate from the heap? I'm currently learning about embedded programming in Rust, so apologies for my ignorance.
It's probably my morning brain, but I don't think I completely understand what you're saying. Mind writing up a code snippet?
then you are free to implement the missing ones and make a pull request :) i figured not many api endpoints have that many arguments anyway, so i stopped at 10
&gt;I don't think anyone claimed that not using `unsafe` made a program crash-proof. Rather it ensures absence of undefined behavior. This is quite different IMO. No argument here, I agree that a panic is much nicer than undefined behavior. My point was that the difference is unlikely to matter to the end user. From the user's perspective both result in a crash, and the nice stack trace will not alleviate the fact that their Firefox (or whatever) has crashed. The borrow checker, on the other hand, is designed to prevent memory errors *at compile time*. If moving those checks to run time causes a bad gut feeling, the gut is not wrong.
I have several different structs, and then a Plugin struct which is a tuple. So, it is like `Plugin(HttpPoller::new(), tx)`. Each different struct implements Stream and Plugin implements Future. I want to iterate over a vector of all of my Plugins and run them all.
Embedded programming covers a wide range of applications, from simple light switch controls to almost Unix type applications. One project I am working on handles Ethernet with multiple TCP/IP connections (LWIP https://savannah.nongnu.org/projects/lwip/ ) where there are some queues of varying size, as well as buffered writing to SD memory card. There is also communication with other serial devices ( SPI, I2C, and single wire ) - having a Vec&lt;u8&gt; representation of the serial messages can be useful. But I would also like to have Vec of (Boxed) trait objects for things such as publish subscribe patterns. Currently I can't fit any of this in because of things that derive(Debug) pulls in.
&gt; it does, however, guarantee that if you recompile a dynamic library with the same compiler and same set of flags, you end up with the same ABI. Is that new? This would include deterministic struct layout, for example, which would be great news (I thought any guarantees about this were being held back, though). For me this is the main "dynamic library w/o C ABI" pain point; that .. it is all undefined behavior without consistent type layouts.
Thinking crazy... this not show how must be the final solution for rust? Mirror how is done to expose C: &amp;#x200B; \- Mark functions/type as "extern rust" or similar. This will make the give the same as No ABI/No generic and disable inlining \- Help to clearly delimit what is the API boundary
My point is that this might not me the most ergonomic design. You were asking for feedback, not for contributors as far as I can recall.
Can't you just make a collection of Plugins in that case?
&gt;I often do a 'clone first, benchmark later' first pass at projects. I use owned values everywhere, clone everywhere. This approach works for you because you know what you are doing. Rust beginners, on the other hand, shouldn't try to emulate it too early in their learning. Taken literally, it can lead to code like in [this StackOverflow question](https://stackoverflow.com/q/46388977/1600898) where the poster cloned the entire hash table on each access - and the hash table was supposed to be a cache to speed things up! True, one should not be afraid of cloning a piece of data where it matters, but inserting clones to appease the compiler without understanding the nature of what is being cloned is dangerous.
Great to see your progress. I hope to get there someday with my own lib ;) \---- This caught my attention: &gt; I’m now wondering if I can also use it to allow me to somehow pass the ParquetFile between threads Why? I think is simple to pass the PLAN (resolved per thread), execute the plan in *each ParquetFile thread* and return back the data? In my mind, is more easy to move AST/plain data than resources (like files or db connections). &amp;#x200B; \---- &amp;#x200B; With relation to this, I wonder how good for this kind of library is to apply the [LMAX disruptor](https://martinfowler.com/articles/lmax.html). Put a ring buffer to mediate, and pass messages between workers. The good about this design is that read and writers are not blocked, is easy to scale up or down the task manager and allow to PIN the workers to threads. So, no worries about how move things across them!
Nice! This project seems quite similar to my software rendering crate, \[\`euc\`\]([https://github.com/zesterer/euc](https://github.com/zesterer/euc)). Perhaps we could collaborate on some things?
I'm pretty sure that's the case for essentially every platform other than Linux.
The inner types are still different though so it doesn't work
I was going to write a pipeline for mine, but writing software shaders made my head hurt. Looks like you've got that figured out! I might make a sloth-euc fork and try implementing your pipeline sometime, as of now there are a few new projects I'm considering
It would be cool to see whether we can integrate both systems in a way that plays to the strength of both projects.
Could somebody explain why do I need to write ```PhantomData&lt;T&gt;``` here? Why is not ```T``` considered "used" in ```Bar```? ```rust struct Foo&lt;T, Bar: Fn(T)&gt; { bar: Bar, _t: std::marker::PhantomData&lt;T&gt;, } ```
I'm not sure about "always." You can successfully build a web application in something like Ruby or Python without knowing most of that. Not to say that web developers shouldn't learn about those details, but it's not necessary.
I think it would probably be good to at least mess around with the node graphs in the other apps to see what pros and cons their systems have. Even if not at an API level, it will at least be good research from the point of view of usability. The reason I was asking about the UI was because you mentioned you weren't sure about compile time vs run time. If you had a UI for your nodes, or even just a human editable file that defined the graph, will that be evaluated at runtime? If you tried to do a lot of the safety at compile time, it would mean you either need your graph users to code, or the UI would need to generate code to compile, and there's an associate delay in the feedback loop to the user. The strongly typed aspect of it can only apply if you're sticking to just rust nodes. If you go across the CFFI. the node on the other end has to bear the responsibility for the most part. Even if you're not parallelizing it, it's more than immutability when it comes to graph evaluation. It would be good to think about scheduling constraints from the get go even if you don't implement it just yet. For example, what if a node's output is connected to two other nodes. Those two can be run in parallel but do you copy the whole context between threads? What is the size of that context? Anyway just some things to consider. The basic outline of everything you're saying sounds good, but I think you might need to flesh it out a bit more with a few different use cases, and just get some hands on time with the other node based apps. A lot of these questions are also heavily performance graph oriented, which may not be the space you're trying to provide in. A lot of VFX things like pipelines and rig build graphs don't need to be highly performant, but can still be expressed in a graph. Not that your design would be slow or not, but every decision will have a requisite compromise in speed versus complexity. There are also some good DigiPro/SIGGRAPH presentations that are good for seeing how you can make optimal graphs. Specifically the libEE digipro presentations from Dreamworks ( https://dl.acm.org/citation.cfm?id=3233085.3233089 ) and the Presto graph presentation ( http://www.multithreadingandvfx.org/course_notes/2017/florian_presentation_2017.pdf )
Jython and IronPython are not only worse than Java and C# respectively, but in many areas have a hard time catching with CPython, especially where CPython is helped by C extensions. It turns out that the kinds of optimizations that a classical JIT performs doesn't help with the highly dynamic code required by a run-time implementing the Python semantics. To optimize for that level of dynamicity, you need either a JIT that understands the scripting language (like V8 for JavaScript), or a JIT tailored to observe the interpreter of the high-level language and emit native code that implements the code the interpreter was running (the approach taken by PyPy). See [this paper](https://bitbucket.org/pypy/extradoc/raw/tip/talk/icooolps2009/bolz-tracing-jit.pdf) for details on PyPy.
Man you have no idea how much I've struggled trying to get perf to run in a Docker container (can't install perf on my NAS to identify bottlenecks in my code, but NAS comes with Docker).
That's great! I hadn't really figured out how to make Rust panic on abort, so I just stubbed in a panic handler. Also, would `#![no_core]` really make a difference here?
Huh, didn't know that. Thanks for the heads up and the paper.
Because `T` might contain a lifetime and a function of `T` would be (hopefully I get this right) covariant over this lifetime, whereas a `T` would be contravariant over the lifetime. Given both, any contained lifetime would have to be deemed invariant.
Would you mind explaining how the extension you linked is used in vs-code? I checked the rls-vscode repo and couldn't find any references to that extension. I'm interested in working on improving the Rust support for VS Code, but I want to make sure that I'm working from the right place.
how can I make it more ergonomic?
&gt; Then once someone has a handle on basic imperative programming, then they can move on to functional programming, and then types, and then concurrency... One nice thing about Python from a learning perspective is it actually has all of those things, even if it's not the best at any of them. Python to Rust is probably a good sequence of languages to learn actually, since they cover a pretty wide gamut of programming styles and features. Plus, you can create modules for Python using Rust. ([Milksnake](https://github.com/getsentry/milksnake) is apparently the way to go for this.)
Godbolt of an improved version, incorporating suggestions from u/GolDDranks, u/dangerbird2 and u/boomshroom (linux only, haha platform specific): https://godbolt.org/z/ZVzNmT My C code for comparison: main() { puts("Hello, World!"); }
&gt;Worse, I think the current process often starts with a particular solution. This encourages people to react to that solution. The RFC author, then, is naturally prone to be defensive and to defend their proposal. We are right away kicking things off with an “A or B” mindset, where ideas belong to people, rather than the process. I think ‘disarming’ the attachment of people to specific ideas, and instead trying to focus everyone’s attention on the problem space as a whole, is crucial. This is something I've noticed again and again in community run projects - person A proposes an idea, but really wants people to spitball around the problem, person B turns up and points out a minor flaw in the idea of person A's proposal as if it were a critical failing, and it turns into a shitfest when person A gets defensive The std-proposals group for c++ was notorious for this. I think part of this involves heavily managing and curating the community - you need to weed out people who are aggressive and not helpful, but many communities fail to do this because they haven't specifically done anything transgressive of whatever fixed set of rules there inevitably are At the same time I also think you need very clear guidelines on participation, to remind people of exactly what the purpose of everything is. Its a fundamentally cooperative process where people are trying to solve a problem, not a place to shit on things you don't like Its difficult because I suspect that on the internet its one of the most human responses to spotting a flaw in a proposal to go THIS IS SHIT LMAO - although it is very occasionally appropriate in extremely limited circumstances (see c++ graphics) This is why, as much as people love linus (and its extremely refreshing that he's changed), his approach to problem solving could be extremely counterproductive. Instead of approaching a problem to be solved, it was shutting down a discussion and driving out people who actually wanted to help. People who supported that kind of behaviour were actively shooting themselves in the foot. It didn't promote better results, but actively stifled progress Rust seems to have managed to avoid a lot of this so far which is nice, it would seem to be a good model for collaborative development (or at least, better than other approaches). I'll be interested to see if they can keep it going though - c++ has a problem in that its near impossible to actually make proposals to the language - partly because its a complex beast, but partly because everything is done in such a formal inaccessible way behind closed doors
The syntax is bundled with VS Code itself - the RLS plugin doesn't provide any kind of highlighting.
Nice handy crate, i found that in your codegen module, instead of `panic`, you could use [`to_compile_error`] to report error nicely.
&gt; to_compile_error https://docs.rs/syn/0.15.26/syn/struct.Error.html#method.to_compile_error
That guy's just a troll, just report using the correct '/r/rust rules' section he's violating. **The worst thing you can do to a troll is to ignore them.** &amp;nbsp; I second krelin's post. Treat anything inputted by users as potentially dangerous. If they are using a web-client to communicate to your program -- assume users are editing the HTML and Javascript. Client-side javascript validation is useful to give the user a better experience when filling out forms. But you must validate input server-side before using it. SQL injections are dangerous. If you're using plain-text to generate queries, you're vulnerable. If you're not using a library to **auto-paramatize / escape inputs** -- a simple login form could end up running a SQL query the attacker crafts. It could steal passwords, it could delete your entire DB. If you're running a web server, make sure to **validate inputs** and to **escape** any fields from a user. Say you have a user account profile screen. You'd expect a user to enter a text description. But what if the user sets their profile to description = "&lt;script&gt;alert('bad news');&lt;/script&gt;" Now, when the server renders the description, it's running javascript that came from the client -- not you. This example shows a dialog box. But, what if they instead write a script that forwards user data to their own server? I've seen this exact bug in Mobile twitter clients. They didn't sanitize input. The one I remember was harmless, but it broke twitter until that app was patched. In python there's [MarkupSafe](https://pypi.org/project/MarkupSafe/) to deal with unsafe text -- I don't know the rust Ecosystem good enough to recommend an equivalent library.
Thanks! The game is designed to be render-agnostic, so we’d like to make a 3D version eventually. I could tell you more about what might look like if we can continue this on community.amethyst.rs so it gets properly recorded.
You are right! Doing it without `Any` does work without `'static` lifetimes: [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e2f2c407d45821622e797b8b7b6eea64). I had to add explicit type\_of() method to the trait though. One more thing: do you know why it worked [in the code snippet](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5f85abd5db257948b347de82d213fa71) by /u/AngusMcBurger without specifying `'static`?
Yeah, the only one I really haven't played around with much is Houdini. I'll have to see about picking up a trial copy. I was planning on having the graph built and evaluated at runtime. Also I'm expecting artists should be able to work with this. I was thinking about having the graph get compiled at runtime, like with OSL, but my concern is we lose flexibility. So, I'm most likely going to have to sacrifice some type safety. You're right, I have to think about scheduling and passing the data around. One idea I was toying with is each data container can have child data containers (for example, in the case of scene graphs and child meshes). And when everything starts to get passed around, then anything that gets passed around will be partially or completely copied based on if something gets modified or not. Not sure if it's a good idea. I'd like the graph evaluation to be fast (at least fast enough for realtime playback of complicated rigs). What I may do is start with having this as a pure "simple" graph evaluation system without the plugins, and all data types/nodes/etc will have to be defined at compile time, so the compiler can optimize everything it can. Also, I may have skimmed those papers, but I'll read them again. Thanks again!
I would consider using `type Args = Vec&lt;String&gt;` to replace `Args`, then replace `args: T` in the `new` method with `args: &amp;[T]`. I'm no expert and my way may not be the idiomatic way, but it would allow for an arbitrary number of arguments and be a lot less code.
Is there a way to have a rust trait which defines two possible functions, either one of which (but not both) can be implemented by an implementation?
Can you have an enum of plugin types? Playground example: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=13a090e50efd8b9e0e61c9c135374a98
I don’t see it mentioned in this thread, have you tried [alacritty](https://github.com/jwilm/alacritty)? There are tricks to get Linux terminals to run with a gui in WSL so you aren’t stuck with Windows’ not great cmd experience.
Are you sure you have navigated to the right Rust folder? A Rust project is defined by a Cargo.toml. If you don't have a Cargo.toml in the folder you have navigated into, `cargo build` will error out as you mentioned.
It is my understanding, at least. Given the experiments to have reproducible builds with rustc, I would expect indeed a stable struct layout given a fixed version of rustc and fixed set of flags.
The formatting for your code has messed up. You'll have to either reformat it (see "formatting help" link for reddit, which appears when you are making), or just share share through a paste link through https://paste.rs/?
I am currently developing [abi\_stable](https://github.com/rodrimati1992/abi_stable_crates) to fix the "I don't want to recompile my users if the implementation changes in an ABI compatible way" usecase. To do this I had to add type-checking at runtime. Here are the caveats: * It's not in a state that other people should rely on right now,that would be at least after 0.3 is released. * I had to re-implement most standard library types exposed in the dynamic library. * It does not allow dynamic libraries to expose generic functions(they can only be generic on lifetimes). * The types you can expose in public functions are limited in that they have to have a stable layout or be opaque.
My goal was to make a function that takes everything that is `Display + Sized`. Unfortunately, I had to use Strings on the way there. Is there another way of achieving this? And what is the more efficient version at runtime?
Thanks for clarifying. Sooo after all, what is the recommendation for users at the moment; use static libraries (crates) as long as the memory footprint doesn't become too big?
Rust is 'avoiding it' precisely because it has a vigorously enforced code of conduct and has had it from day one. C++ *has* to work behind doors, because if they tried open development it would be a complete disaster of ego and misplaced testosterone. In my experience, people with too much aggressiveness to be healthy look at a code of conduct and go 'SJW snowflakes' and self select out (and badmouth the project ofc, because they're horrible people) but if they're already in, look out for the self-destructive comet, especially if it's open source, ie: 'not a job'.
Installing it now, thanks for the recommendation!!
When it comes to distributed query execution, I will be adopting the approach you suggest - passing a **logical plan** to a node and expect a stream of data back. I had at one point started going down this path with the physical plan too but had rejected this approach and I can't remember why. Thanks ... I will try this approach again and see where I get to.
By moving the 'static bound to Chooser you can use your main [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8528d67661bba80d133241fad02cbb9c)
Neat! Didn't know https://paste.rs/ existed, and in Rocket too!
Is this tightly coupled with termion or could it be made to work with something like crossterm as well?
I thought this might be related to remacs somehow, but this is actual rust for real Emacs. Good stuff!
I can, but it would be hard because there are about 60 plugin types. That would be a huge enum. I thought generics would be better because of that.
That's cool, I didn't know about this syntax. Thought lifetimes always have to be inside &lt;&gt; or follow &amp;. Thanks for the tip!
Not at all, the entire thing is very lightweight. I could certainly port it to whatever terminal library. The only funky thing would be the ANSI escape characters that termion makes easy for you
There's no one-size fits all, really. Personally, I prefer using static libraries for multiple reasons: 1. Simplicity: one binary, no dependency. Easy to deploy and move around. No dependency hell. 2. Performance: by design, LTO doesn't work across DLL boundaries. The main advantage of dynamic linking really is the ability to substitute one version for another; which only really matters for distributions, to patch users' machine with minimal bandwidth. I am personally developing for servers, with a single application running on the server, so there's no advantage to dynamic linking in my cases: neither patching nor memory savings.
I think what it happening is that `a` and `b.type_id()` require the returned `&amp;Chooser` to be `'static` but `Chooser` isn't `'static` so it will assume `&amp;Chooser` is, which translate to `&amp;'static Chooser`. And since you told the compiler `first`, `second` and the returned `Chooser` must exist in the same lifetime, `first` and `second` will have to be `&amp;'static` too. It works when you initialize with reference because, it will be `'static` that's why you can make `&amp;'static str` for example. So `let first = &amp;First {}` is actually `let first: &amp;'static First = &amp;First {}`. I hope I'm somewhat understandable, tell me if I'm not =)
link?
I think you should be able to just do `Vec&lt;T&gt;` `where T: Display`. According to the documentation, [all type parameters implicitly have the `Sized` bound](https://doc.rust-lang.org/std/marker/trait.Sized.html). Creating a `String` at runtime is an allocation in addition to creating the `Vec`. There's not an easy way around those allocations with anything of a variable length. If you know ahead of time that you'll never have more than X arguments, and each argument may never be more than Y bytes long, then you could optimize by defining a fixed-sized two-dimensional array `[[char; Y]; X]` (where X and Y are known at compile-time). It's kind of ugly, and I don't think format would work for this approach (since formatting needs some allocation of its own, because its output isn't known until runtime).
I remember the reason now. The approach you suggest works if I am just returning final data (RecordBatch implements Sync and Send so can easily be passed between threads). It doesn't currently work if I want to pass an Iterator between threads because some of the underlying types weren't designed with this use case in mind. In [https://github.com/andygrove/datafusion-benchmarks](https://github.com/andygrove/datafusion-benchmarks) I am performing aggregate queries by creating a separate context in each thread and executing aggregate queries in parallel across partitions, combining the results, and then performing another aggregate query on those results. This works because the final data from each aggregate query is tiny (10 rows).
Oh no! Is your Docker setup FROM the official Rust image?
I didn't know that initializing with references invokes `'static` lifetime; I expected them to get dropped in the end of the block as usual. I think this piece of information clarified the last bit of confusion I had with this code; thanks a bunch!
what memory footprint? the RAM footprint is the same or better unless you're running several different rust applications that hypothetically would have shared dependencies via dynamic linking. Dynamic linking increases the memory footprint of a single application because the optimizations are much weaker, and the library can't be in the same pages of memory. if you're talking about the disk size, when has 5 or 6 megabytes been an issue for any computer in the last 15 years? The many downsides of dynamic linking generally outweigh the benefit of saving a bare handful of megabytes, except in the specific case where a Linux distro has hundreds of command line utilities that all happen to be compiled at the same time, with the same libraries, flags, and targets.
 I'd just like to interject for a moment. What you're referring to as Linux, is in fact, GNU/Linux, or as I've recently taken to calling it, GNU plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities and vital system components comprising a full OS as defined by POSIX. Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called "Linux", and many of its users are not aware that it is basically the GNU system, developed by the GNU Project. There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine's resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called "Linux" distributions are really distributions of GNU/Linux.
Meanwhile Fuchsia is in the process of moving [away from unix](https://github.com/rust-lang/rust/issues/58590) as a target family. I can't say I understand the tradeoffs well enough, but it might be relevant background.
It only works for one color scheme (I think zenburn). For other color schemes it can produce weird colors.
What about compile-times? The reason I started developing [abi\_stable](https://github.com/rodrimati1992/abi_stable_crates) for making rust dynamically linked libraries was a desire to improve compile-times of some of my local projects(crates I don't put on github).
wow - that is amazing
Interesting discussion, I'm really noob but AFAIU with Unix support one day may be possible to have gnu/redox instead of gnu/Linux, and that could be super cool. I would totally dualboot redox :)
Take it to /r/playrust
&gt; Rust is 'avoiding it' precisely because it has a vigorously enforced code of conduct and has had it from day one. This helps but is insufficient- "many communities fail to do this because they haven't specifically done anything transgressive of whatever fixed set of rules there inevitably are." RFC threads and internals threads are full of this kind of argument over specific proposals rather than the more useful mapping of the space. People point out downsides as if they're showstoppers rather than design choices, then people get defensive when trying to improve their idea, etc.
\`chunks\_mut\` and \`swap\` looks helpful! Here's a [playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=940968f3d0e7047a696cc78f244e5e7b).
Just type cargo run in the terminal when you’re cd’ed to the directory that has your main.rs file
Alright, I maybe got a little too greedy trying to do it in one line without using loops. &amp;#x200B; Thanks !
Sounds like a win.
How is this related to Rust(rule 5 of this subreddit)?
You can if you want to `slice.chunks_mut(2).for_each(|chunk| chunk.swap(0, 1))`
Can't the same principles apply? It's really hard to do social consensus. Actually the biggest proponents of social consensus ended-up rejecting it for some other kind of direct-democracy. So I see the debate about how to make it work needing the same principles.
Can you or someone else record a gif/mp4 of it?
Maybe receive impl Iterator&lt;impl Display&gt;? Because that would allow for generic arrays and stack-based strings or any kind of crazy datastructure you want to use.
Note that this doesn't change the unix-ness of Redox OS; it merely utilizes the existing unix-ness of it to eliminate a lot of the special redox code in libstd and other crates.
Are plugins used this way reliably sandboxed?