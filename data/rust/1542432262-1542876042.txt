Thanks!
I've had this bug just recently too and someone in Discord had it as well. So I'm pretty sure this is a new cargo bug. I don't know if it's reported yet though.
Note that procedural macros aren't what you'd use most of the time. Instead, you'd use normal macros, which are stable and far easier to write. You'd generally only want procedural macros in one of the following cases: - Your macro involves more complex logic than a simple syntactic transformation. - You want more flexibility with the kind of syntax your macro can use. - You want to provide better error messages.
I give you one free [Rust](https://www.rust-lang.org/en-US/install.html), keep your Steam games.
Hi Michael! Does one need to bring his own laptop to participate in workshops on Sunday?
Thanks for letting know
On that front, one of C++'s greatest competitive strengths is also its greatest weakness... the approach it took to maintaining compatibility with C makes it incredibly difficult (and not yet attained) for C++ to offer the degree of compile-time mistake-catching capability of a language like Rust. Rust isn't the first language to try to be a safer C or C++... it's just the first one to gather sufficient interest. Heck, it actually took inspiration from one of the predecessors that never took off: a safer dialect of C named [Cyclone](https://en.wikipedia.org/wiki/Cyclone_(programming_language)).
I haven't used Rust specifically for this kind of task (my projects are best suited to [Django](https://www.djangoproject.com/)) but have you tried running your project under a profiler to see where it's spending its time? That's always one of the first things I do in *any* language when performance is an issue.
I agree, but I think people who haven't been exposed to well-written, modern C++ have an exaggerated idea of how unsafe it is. I work in HFT, write C++ every day, as do most of my colleagues, and it's really rare to see a bug in production caused by the kind of error that Rust protects against. To be fair though the code doesn't have to deal with malicious user inputs.
Quick addition, I noticed that something I wrote was kinda wrong: &gt; Rather than fibs.get(fibs.len() - 2).unwrap(), it's simpler to just write fibs[fibs.len()-2]. The behavior is the same, in that both will panic if the vec is too short. That isn't 100% accurate. They are the same, but what will happen with a vector with &lt;2 elements is that the subtraction will negative-overflow. That itself causes a panic in debug mode, but in release mode it will wrap, and you'll try to get the (usize::max_value()-1)th element from the vec. That will cause a panic too if it exceeds the length of the list. Which 99.999% of the time it will. But in some circumstances on a 32-bit or 16-bit machine it might conceivably be a valid element in a giant list or a memory mapped file or something, especially if you subtract something much larger than 2.
&gt; To be fair though the code doesn't have to deal with malicious user inputs. That *does* make a huge difference.
Av?
Yes i think that also can be a case be we don't really have async postgresql db driver which i can properly clone and pass between threads (am i wrong?). if there is any would be great to see an example how it could be used warp.
Yes i think you are right will need to do some perf stuff ;) Thanks. &amp;#x200B;
&gt; Is it possible to say with certainty that if you do trigger undefined behavior, it will be detected? (eventually, not necessarily today) That is the goal. It is not clear whether this is possible. One obstacle here is non-determinism: Certain undefined behavior might only arise in some, but not all possible executions of a program; miri will likely not be able to exhaustively explore all possible executions. Two examples of non-determinism are concurrency (miri currently just doesn't let you spawn a thread), and the non-determinism of the allocator when it picks a location as the base address for an allocation (miri currently keeps the base address "abstract" which means it does not have to make a choice, but also some pointer-manipulating operations cannot be supported). I imagine miri might one day support a very crude form of concurrency, but it will not explore all possible interleavings -- so it will not detect all possible UB (in particular, it will not detect data races, but concurrency can also lead to non-determinism in the values a valid program observes when it has race conditions [NOT data races!] on `AtomicUsize`, and if only some of the possible outcomes of these race conditions lead to UB, miri will still miss them). miri might also one day choose a concrete base address to allow more pointer-manipulating operations, but then if the program happens to work with this choice of base address, that does not imply it will work with all possible choices. Non-determinism aside, I hope we can eventually define Undefined Behavior in Rust precisely enough that it can actually be faithfully checked on any given execution. Then we will be able to answer your question with "yes". This will involve lots of work, also on the side of the LLVM IR (because that's our compilation target), which means this interacts with Undefined Behavior in C -- but there are several people working on understanding UB in C/LLVM better, so I think it is realistic that we will get there eventually. :)
Not a stupid question at all. :) Yes, it does accept more code: For example, it accepts all the unsafe code in `RefCell` (well, the parts I have executed, and the intention surely is that it accepts all the rest as well). Basically, it should accept all unsafe code that is actually "legal", because it *defines* which unsafe code is "legal".
Interesting example, thanks! I will investigate.
They exclusively use a Result type afaik. So like Rust, except there's no panic!
Dude, Sorry to sound rude but the problem here is that you don't have a clear model of performance in modern io bound web services. No amount of quick tutorial or blog post will make you better at this, however just few minutes of deep studying will make you understand it. I am not going to explain it to you because I don't have the time and because I am on my phone but those are stuff that you should already know. To point you on the right direction I would suggest to repeat the benchmark and this time observe the CPU utilisation. Just run htop. (Htop will also show the amount of CPU used by wrk, not sure if there is a way to filter it out.) You will see that the rust program barely use the CPU and it is mostly waiting on IO. Try to change the pool size and see what benefits are there, if any. 
I am not sure if understand it correctly i have 10 connection in the pool already, if i increase connections i will have better performance but the problem is that node and rust have the same amount of connections but for some reason it performs worse
Cool, interesting to see another approach.
Like the sibling-comment says, their usage of `Result` is basically the same. The difference is that `Rust` has panics. Elm has something called `Debug.crash` which can be used like Rust's `panic!()`. However the core team did not want that, and it was removed in release builds in Elm 0.19.
Yep, but compiler plugins work on the entire AST, so they can do stuff without needing an explicit call. 
Thank you i am going to check it out :)
The problem in all of these cases is that you end up with "abnormal" references that have a "wrong" tag. But I think we can leave `HashMap` out of the equation, right? Your `&amp;mut` case is most probably unsound because `&amp;mut` is invariant. So you could end up inserting an `&amp;mut Foo` into the map, and then your borrow ends and someone reads it as `Box&lt;Foo&gt;` -- clearly bad. For the owned case, you'll end up with shared references that have a unique tag, which will get fixed on the first reborrow, so this should work. `Box` doesn't really have any special tag currently, but maybe it should get treated like a unique reference? Then your `&amp;HashMap` example would also be just transmuting `&amp;mut` to `&amp;`, which again should be fine.
Feel free to follow up on this! Also check the connections on the DB side, how many concurrent DB connection are you using on each scenario?
Default for Rust pool is 10, Node.js 1 is using 10 as well and Node.js 2 uses 10 for each core so about 80 (that is the reason in huge difference) the main compassing should be between Node .js 1st and Rust which is 290 / 113, but node uses only single core.
Ooh, I see, thanks. Interesting.
Does Linux look like windows just because they support windows drivers? No, you have a wrapper. Did AMDGPU want to use a very much windows driver and a wrapper? Yes, but Linus said no because it's a mess. Redox could really use sucha wrapper mess to make it runnable at all, and then focus on implementing native drivers.
Yes you are right if i run db locally rust performs much better then node. Also i have some weird issue with tokio blocking where if i add println!() in my code it reduces latency much more. I have [Old redit post](https://www.reddit.com/r/rust/comments/9ulbj3/weird_rust_hyper_async_behaviour_why/) (have seen it only on some linux distros, mac does not have this issue and windows not sure). Thanks for your tips and explaining how it is actually works.
thanks a ton! - I actually found a way to make it work: &amp;#x200B; use crossbeam::thread::Scope; fn my_scope&lt;'a&gt;(array: &amp;'a [i32]) { let myfn = |scope: &amp;Scope&lt;'a&gt;| { for i in array { scope.spawn(move |_| { println!("element: {}", i); }); } }; crossbeam::scope(myfn); } fn main(){ let array = [1, 2, 3]; my_scope(&amp;array); } &amp;#x200B;
SDL2 might give you some trouble with getting the "right" window behavior. You want something that will let you create a transparent, undecorated window, and then have that window stick to just above the desktop in the z-order. That will definitely require platform specific code in some way. You can still render it with OpenGL though.
`println` is going to cause everything to have to serialize on one resource: your standard output. It's locked on a mutex so that only one thread can use it at a time, and others wait for it. You'll probably want to use [`log`](https://crates.io/crates/log) and some asynchronous logging backend.
They should just add it under a cfg flag
Thanks for clearing this out :) &amp;#x200B;
Wait! You still haven't uncovered the whole issue! So what? We use rust only when the DB is local? Why that? What changes if you use a local db? What if I want to reach the same performance on a not local db?
I improved the code, documentation and examples a bit and published it as a crate. And it works on stable now. [https://github.com/Phaiax/gtk-rs-state](https://github.com/Phaiax/gtk-rs-state) [https://crates.io/crates/gtk-fnonce-on-eventloop](https://crates.io/crates/gtk-fnonce-on-eventloop) The readme contains a graphic that hopefully explains your questions. The idle\_add() is hidden in the code generated by the macro.
Yes, i know that i have not found actual reason yet, that what i am trying to do :) What i have found for now is that connection on DB are open but not all of them used at the same time, while benchmarking rust is using about 1 - 2 connections and all other are idle. Node is also not using all connections 2 or 3. 
I am not sure why it doesn't use all the connections actually, on the local or on the remote case? Try to run slower queries (put a sleep on the SQL following the postgres syntax pg_sleep(n) will sleep for n second before to return, n=1 should be sufficient). This should be enough to saturate the connection pool. Then, how many threads are you using on the rust version? ;)
No no, I don't use reddit much and I made a few times the mistake to post something where it doesn't belong because I didn't read properly the description or check the existing posts... human mistake. Unless /rust is renamed to /rustlang or something, it won't work. &amp;#x200B; The game is quite new (2018) and the player base is quite big. I think the confusion will last for a very long time... &amp;#x200B; [https://steamcharts.com/app/252490](https://steamcharts.com/app/252490)
Tell that to Bryan Cantrill lol
Local and remote both. &amp;#x200B; About threads i am using only what is provided by tokio (warp) i would assume it creates many threads so can not say that.
&gt;This question comes up so often, and there appears to be a lot of confusion around it. The choice is very rarely between "panic or Result," so phrasing an answer in terms of "use Result instead of panic" is a bit off. Panicking and Results solve two different problems. Actually it is good (and even fantastic) that the question is raised so often. One thing I love with Rust is that it teaches me (and sometimes force me) to write better code. If, like me, you come from languages like Python or Ruby, you know that exceptions are often badly used or they are simply ignored. It's really a good thing to question how to handle it.
Dig deeper is documented how many threads you are using! How many rps on the local scenario? What the average latency? Average no 50 percentile.
Sorry, only remote uses one or two connections and local one is using all of them without any timeout.
You are not connecting to pg correctly, you are doing synchronous IO in rust, so ofc it's gonna suck. Look at how actix does it in the techempower benchmarks, where it actually has the best performance among all frameworks for database updates https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=ph&amp;test=update Just check out the techempower github and see how they did and it should give you some clue.
Ok from warp docs it seems \`run\` function runs server on the current thread only, local rps is about 2500 - 3500. Latency depends on number of connections. 
Careful, the real logic happen inside tokio_threadpool::blocking :) Out of curiosity the node without cluster in a local environment how many rps sustains?
You could do all I/O in a synchronous actor in Actix. Synchronous actors run on a thread-pool, so you can receive request / setuid / do I/O / setuid back / return response. Note that the libc setuid() does a setuid of all threads in the process. Linux can do setuid per-thread, but you will have to use the raw syscall.
Ohhhhh, node gives at about 2886
I don’t think rust can realistically work on 16bit architectures.
&gt; But the compiler knows what architecture it’s compiling for. There’s no need to support 16bit architectures when you’re compiling for 64bit. It's a debated issue. The problem here is a potential ecosystem split: if a library uses a conversion from `u32` to `usize` because it "just works" on the tested platforms, then this library is unusable on 16 bits platforms, and any library that depends on it is likely unusable as well. This is similar to `#[no_std]`, except unwittingly, which is admittedly worse. On the other hand, while using `TryFrom` requires a bit more typing, on platforms where the conversion always succeeds all the checks and panics should be optimized away, so that there should be no run time penalty.
It's probably not a large factor, but one thing I noticed is that you're using a (presumedly server side) prepared statement in your Rust code, but a plain statement in your JS code. And the prepared statement is used only once before it is released. So for each insert, your JS code does one thing, it just sends the insert statement. But your Rust code does three things. Prepare the query on the server, execute it, and then free it. Especially with a remote DB server, that will negatively affect performance. Unfortunately, from a quick glance, there seems to be no public function in the postgres crate that performs a plain statement. batch_execute with a single statement seems to be the closest option. But you could go with prepare_cached instead, which will prepare the statement only once per connection, which should at least kill two roundtrips to the database server per request, improving the response latency even after you switched to asynchronous database handling.
Eh, the reason it's "limited" (I don't even really know in which ways) right now is that there's only like one person working on it. I've mostly seen these 32-bit assuming `as usize` casts in crates that legitimately will only work on at least 32-bit systems, and for everything else there's [multiple](https://rust-lang-nursery.github.io/rust-clippy/master/index.html#cast_possible_truncation) Clippy [lints](https://rust-lang-nursery.github.io/rust-clippy/master/index.html#cast_possible_wrap) that make finding them rather easy. It's unlikely you'll ever want to use non-`no_std` crates on that architecture and keeping a useful subset of `no_std` crates 16-bit compatible doesn't seem too hard to me.
Awesome, I'll check it out!
&gt; That's in a way where I wonder if it wouldn't be permissible to make another exception to the rules around platforms &lt;32bit that do not require TryInto to be used for such conversions. IIRC this used to be the plan. You'd also get a "compatibility lint" you can configure to warn when you use an impl that won't be available / won't do what you want on 16-bit systems. Seems like that remained vaporware though.
FYI, whilst Node is required, you _will_ be able to use the built-in npm virtually anywhere that Yarn is used. All you practically lose is the pre-provided Yarn-format lockfile.
What is an idiomatic way to convert something that has `as_str() -&gt; &amp;'static str` method into `Cow&lt;'static, str&gt;`? Currently I always have to write `.as_str().into()`. Should I add `fn cow(&amp;self) -&gt; Cow&lt;'static, str&gt;` method? Or implement From, or maybe something else?
&gt; change the grammar file to be able to writ Rust code that “generates values” – constant values, lambdas, etc.– directly next to the rules LALRPOP [does something like this](https://github.com/lalrpop/lalrpop/blob/master/doc/calculator/src/calculator6.lalrpop) - you can give rules what are effectively return types, and then write code to generate those types when a rule is matched. 
The master branch has async support (or so I've read). You might be able to point at a recent passing commit of the postgres driver and support for it.
Postgres has async support in the master branch of tokio-postgres. Source: https://www.reddit.com/r/rust/comments/9xd6cs/dbi_a_procmacro_based_database_interface_inspired/
Hi! That's correct.
Of course. The Rust repo vendors a lot of stuff that's still available outside of rustc.
i mean the size of the thread pool that blocks on pgsql. but apparently there is async support somewhere but use that :p
That makes sense, thanks!
&gt; I think it will likely always end up as limited. Well, support for an embedded platform like that typically is limited pretty much by definition and that's ok. I don't believe you can use _any_ C/C++ library on MSP430 either. 
I don't think it's reported, please do! We will take it seriously and try to track it down.
If the try_from followed by unwrap panics at runtime on a 16 bit platform, how is that better than having a compile time error saying "function foo assumes usize &gt;= 32 bits but you're compiling for a 16-bit platform"? Would you expect the library author to return an Option in such a situation?
Linux modules link with the kernel though. Although I have made a module before, I can't say I have really ever been significantly involved in the community, but my understanding is that, because the data types modules use are so intertwined with the kernel, you pretty much would need to have a Linux kernel to have kernel modules. Often times in the kernel I also saw linked lists embedded inside structs and pointers to other structs from those, making everything sort of tangled together. Plus, if you call anything, you have to link to that and have the same signature. I don't think creating a wrapper around Linux kernel modules is really possible without basically having the same architecture as Linux for these reasons.
They're using the sync support in tokio, nothing wrong with that. Sync db calls should be a few orders of magnitude faster than the results they're getting so there's definitely something wrong here.
Awesome. Always wanted to know how to do this (in general). And it even looks like a beginner-friendly project. Very nice!
It's likely that the db finishes each request before the next one comes in so R2D2 will just reuse the same connection. &amp;#x200B; This also suggests that mucking about with the threadpool won't help. They should be able to beat the node result even with a single thread.
&gt; Would you expect the library author to return an Option in such a situation? Yes. It may be that the library author may decide to systematically unwrap, not seeing the point of covering the 16 bits usecase, and that is their prerogative. However, much like `str` and `String` make you aware of the intricacies of Unicode, the use of `TryFrom` lures the author into *consciously* deciding whether to handle the case or not. And even if they do not *right now*, it's just a matter of searching for occurrences of `unwrap` and `expect` to later find the call sites which need to be adapted.
The csv example looks amazing. I wrote a sql-like grammar with domain-specific shortcuts with pest and had the same experience: defining the grammar is awesome, but matching/handling the parsed types in rust was a chore. Will definitely be watching to see how this develops!
Can you also put the max/min memory usage of both? iirc node alone adds like 10mb of memory itself, and will be cool too to se the memory usage of both implementations also, because I think memory is also one factor when having a webserver. This is a bit off topic and not to related to the subject, but with a server of 1gb you can have a super low traffic site running mariadb (mysql) and rails, both of them uses 800mb when idle. I know that rails alone uses 500mb aprox. but also isn’t fair to compare too much rails because is a full featured framework, but you could try to build one with rocket (iirc is the name of one popular rust backend) and with node maybe expressjs (don’t know if there’s another popular option, few years I didn’t check node, maybe sails too). PD: didn’t read the code you used in both implementations bcs im on mobile, but wanted to ask about memory usage.
I did notice a slow-down on the site a few minutes ago, but it seems to be cleared up now. Are you able to access the site now? If not, what is the error? Is it a 404, just timing out, etc? Can you reach the [home page](https://www.joshmcguigan.com/)?
Yeah, it may be safe, but it isn’t really Elm Architecture without immutability. Half the point of doing Elm or Redux in the first place is so that implementing undo is a one-liner. (And by undo I mean not just undo buttons, but effects with retries, error recovery, time travel debugging, etc.) Also, you shouldn’t be designing APIs around panic recovery. You should just exit the code on panic. Continuing on with just half an execution of update() done is way more unsafe; imagine panicking inside an unsafe block without the whole transaction done. You panic if you simply cannot continue, with good reason.
Oh is now available. Thanx 
Procedural macros are also stable now. :)
I'm having trouble understanding the context of this document. is this a general API for streams to implement? does tokio do this?
There are actually some scenarios where non-macros would be desirable too. In Amethyst, for example, there are custom derive macros that depend on certain types being imported in order to compile correctly after expansion.
Using `tokio_threadpool::blocking` puts the blocking DB query in a 'blocking' thread, accomplishing the same goal as having a bunch of sync workers, but without the message passing overhead.
`warp::serve().run()` is using `tokio::run()`, which uses default runtime options. It's also possible to configure a runtime and spawn the warp server instead of calling `run`. The [runtime builder docs](https://docs.rs/tokio/0.1.12/tokio/runtime/struct.Builder.html) show the default values in the method descriptions.
Last I checked the best option was criterion-plot, and it's not very well documented.
They should have leveraged the borrow checker
Base Node memory is closer to 100MB I believe, although my numbers might be out of date.
&gt; D isn't safe , so this sounds like exageration `@safe` D is, and even `@system` D is safer than C or C++ by default. It isn't and can't be exaggeration given my experience in writing C, C++, and D in production. Those bugs don't happen. &gt; totally different execution model- relies on a GC and has its own complexities when you need state/side effects. How is that relevant to me stating that Haskell doesn't suffer from the same kinds of bugs? &gt; it might be that C/C++ just dont suit you They don't, due to all the aforementioned problems. &gt; The bugs it eliminates are trivialities, easy to track down Not in my experience. &gt; I'm spending just as long debugging (there's more that can go wrong in a program than plain memory errors) Yes, which is why I'd prefer to limit my debugging to the non-memory errors instead of staring at stack traces all day only to realise that the stack was smashed. There's enough work to do, I don't need to spend even more time on mistakes the computer can catch/avoid for me. 
&gt; there are still bugs in rust programs Of course there are still bugs, I never claimed otherwise. What I _am_ claiming is that writing code in Rust (and many, many other languages) reduces the number of bugs and therefore my general frustration. &gt; correct code just takes longer to write.. In C or C++? Yes, it takes longer. A lot longer. &gt; its not magic. Nothing is magic in programming.
Hi there, this is the wrong sub, you're probably looking for /r/playrust 
&gt; The game is quite new (2018) and the player base is quite big Maybe they should’ve checked for subreddit availability before choosing that name ;) 
Rust noob here as well, but I'm curious about what you mean by "I can't look at it without tears." My first question to you is, **what are the things you find worst about your code?** I feel you have a much more negative assessment of your own code than it deserves. I find your variable names and logic quite readable. Maybe you just want to find more elegant / concise ways to express the same logic, avoid redundant match blocks, or something else? (Someone else may be able to point out why I'm wrong, but) for me, I think of `String` vs `&amp;str` in Rust as somewhat analogous to C++'s `std::string` vs `char*`. To me, as a Rust API consideration, both `String` and `&amp;str` imply a sequence of characters, but `String` emphasizes that it owns its own memory, while `&amp;str` emphasizes that it is pointing into and dependent on existing memory. As such, it's very hard to return a `&amp;str` if you are allocating new text inside your method. I think the fact you are taking in a `&amp;str` and returning a `String` is fine; see also [this answer](https://www.reddit.com/r/rust/comments/7megb9/returning_a_string_from_a_function_string_or_str/drtbaur). As for lifetimes / ownership, these are tricky concepts. Don't try to force it - it will click eventually (and then you may find yourself sweating when you read tricky code in other languages that doesn't know how to express these concepts explicitly). As a new Rust dev, I'd say maybe try to always be overly aggressive about owning your own memory as much as possible at first, and then slowly figure out how to make this function or that struct more efficient by embracing lifetimes in simple scenarios.
Leaving a comment saying you're seeing it as well, along with any relevant information.
&gt;It might be coincidentally possible to memoize work between invocations of a proc macro by (ab)using thread local storage, Oh, it is
Have you tried wrapping the transfer in a block? ``` fn http_get_to_vec(url: &amp;String) { let mut dst = Vec::new(); let mut easy = Easy::new(); easy.url(url).unwrap(); { let mut transfer = easy.transfer(); transfer.write_function(|data| { dst.extend_from_slice(data); Ok(data.len()) }).unwrap(); transfer.perform().unwrap(); } println!("Vec len = {}", dst.len()); } ```
You're much too hard on yourself, the code was not nearly as bad as you say :) Here is my take on it: https://gist.github.com/DenialAdams/06d6a8c841c7e328ce986a299f786ead I moved the string processing that is unrelated to the piglatin logic (trimming the string) to the call site, as I think it's clearer to leave that logic out of piglatinize. I also chose to have piglatinize take an `&amp;mut String` - this way piglatinize does no allocations and leaves the memory management up to the caller. Related to that, by using remove(0) instead of slicing from [1..], we avoid a panic if the input starts with an emoji or another multi-byte UTF-8 character, and we don't need to allocate a new string from the slice. 
Oh, really? I thought proc_macro was stabilized but there was another unstable hurdle blocking their actual use. Has that situation changed?
Don't answer to people that do not read sidebar/rules and subreddit description. They will learn they have to do some research before posting :)
Can you elaborate on this intern project? Are there paid positions to formalize this specification in an ITP?
You don't have a sidebar on the app. 
That worked perfectly! I'm not sure I fully understand how wrapping effects mutability. What changed by wrapping that block? 
&gt; How is that relevant to me stating that Haskell doesn't suffer from the same kinds of bugs? because it's not a fair comparison: haskell can't target the same niches as C (without extreme contortion). "a saloon is more comfortable than an F1 car", "an 18wheeler truck can carry more than a bicycle" etc .these are all designed for different things.
I took a stab at [tweaking your code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=351fa6e3758acd6405c126a2cb5ea1f6), but it didn't change that much. What do you think?
Very nice. I added it a DFIR data visualization list: [https://www.dfir.training/tools/data-visualization/1056-gephi](https://www.dfir.training/tools/data-visualization/1056-gephi). 
It seems that default type parameters are only used in types, and completely ignored in paths. Stuff like `fn foo(x: Foo) { ... }` uses `Foo` in type context, and properly defaults to `Foo&lt;u64&gt;`. However, `Foo::new` is a path, just like `some_crate::some_module::SomeType::static_fn` would be a path. `&lt;Foo&gt;::new()` once again uses `Foo` in type context, and thus works.
It limits the scope of the mutable borrow in the closure. Because the closure only lives until the end of the block, the borrow it takes can also only live that long; that prevents it from clashing with the immutable borrow needed to use `len()`.
I would maybe try the following: transfer.write_function(|data| { let len = data.len(); dst.append(data); // consumes `data`, much faster since data is not copied. Ok(len) }).unwrap(); 
This was my first attempt at procedural macros, but I am pleased with how it came out. If you notice anything that could be improved, let me know!
I can understand your frustration, but I think being actively helpful is more in keeping with the spirit of the the Rust Code of Conduct. 
Before I clicked I actually thought they had found a bug in rustc about variable shadowing inside nested scopes. 
So should I look into putting it in a `Box`? Or perhaps have a "Node-allocator" on the `struct Pratt`? The second option seems viable to me, as any `Node`s it manufacturers will live as long as `Pratt`, correct?
Just to be sure remove the database and make these just "hello world" programs. If you are running them on OSX try something else, for reasons I've never figured out, OSX sometimes performs very badly on networking benchmarks.
This matches how I think too. It’s rare (at least, I’d think it would be) to even see returning references unless the function is purely plucking something out internally. Doing any kind of processing will typically result into having to turn it into a String due tot the ownership constraints. Would second the “aggressive” aspect. When I started off, I literally cloned everything to get my programs to compile. Only once it worked did I go back and try remove the clones; this forced understanding of ownership but in such a way that it was usually only related to a few lines of code at a time rather than the entire project. Of course, ownership is still “hard” sometimes though; it’s why design is more important in Rust rather than a language such as (e.g.) JavaScript. 
A fascinating naming story for my open source classes. GL under the new name! 
Does that matter? The database pool is smaller, so the larger number of back-up threads in Tokio just means that the requests queue up until it's full.
Some generic feedback: 1. Clean up and try to use as little mutability as possible, specifically your handling of the first character is confusing. 2. I don't know if you're familiar with C++, but as others have said think of them as `std::string` and `char *`. 3. `read_line()` includes the `\n`, so you want to call `trim()` on it. You can clean it up pretty nicely. Otherwise you totally nerdsniped me into seeing how I'd go about implementing a clean version. Now let me note that I took a completely different approach, so it doesn't resemble your code at all anymore, nor does it do much to help with ownership/string/vector. [If you want to see it anyways...](https://gist.github.com/RaphaelAddile/d5fee90842d592e3ed3cd00652c98530)
I am not sure neither! However what I noticed is that on average the request take 1 second of latency, there are 100 threads, and it complete 113 RPS (that with a small of pileup fits perfectly in the model). We should know the ping time between the server and the db, how many round trips the code is actually doing and then we could investigate further. The pool anyway is underused, I am not sure why...
I remember how bad my piglatin program was and how hard I found it when I started. 
That gives me the following error: &gt; expected type `&amp;mut std::vec::Vec&lt;_&gt;` found type `&amp;mut &amp;[u8] concerning: &gt; dst.append(&amp;mut data); But you have the right idea. I don't need the data copied. I'll look into it and see how to correct that error.
I appreciate the pointer. Looking into nll lead me to find a lot of useful articles about compiler flags I can use to track down borrow-checker related errors. And yes, it compile with nll enabled. Thanks!
Hi everyone! I think I'm having a conceptual difficulty with lifetimes, or perhaps with how structs and their instances work. Here's the short version: I have pub struct Parser&lt;'a&gt; { chars: Chars&lt;'a&gt;, buf: String, } and it yields tokens that it builds by iterating through `chars`, pushing characters to `buf`, and returning `buf` (or a copy thereof?) when it deems a token is "completed". But it may reach the end of `chars` without having completed the token it's building, in which case I'd like for it to restore `chars` using `buf` with self.chars = self.buf.chars(); in a function taking `&amp;mut self`, and attempt to build the token differently. Unfortunately, I'm told that a lifetime cannot be inferred because—if I understand correctly—my reference to `self` has an associated lifetime that limits the lifetime of this new `Chars`, but this `Chars` must also live as long as the `'a` associated with `Parser`, and these requirements conflict. This doesn't make complete sense to me, since I feel that a reference to `self`—which is an instance of `Parser`—should by definition have the same lifetime as the one I've defined as associated with the `struct`. I'd like to know where my gap in understanding is. [Here's the long version](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=2e9891bc28b03e7143cf4205a05e3fd9). Here's the error itself: error[E0495]: cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements --&gt; src/main.rs:33:39 | 33 | self.chars = self.buf.chars(); | ^^^^^ | note: first, the lifetime cannot outlive the anonymous lifetime #1 defined on the method body at 20:5... --&gt; src/main.rs:20:5 | 20 | / fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { ... | 37 | | } | |_____^ note: ...so that reference does not outlive borrowed content --&gt; src/main.rs:33:30 | 33 | self.chars = self.buf.chars(); | ^^^^^^^^ note: but, the lifetime must be valid for the lifetime 'a as defined on the impl at 17:6... --&gt; src/main.rs:17:6 | 17 | impl&lt;'a&gt; Iterator for Parser&lt;'a&gt; { | ^^ = note: ...so that the expression is assignable: expected std::str::Chars&lt;'a&gt; found std::str::Chars&lt;'_&gt;
Oh, that's awesome! Thanks a lot.
/u/goriunovd I tried the test in your older post. I got: $ wrk -t4 -c2000 -d10s --latency http://127.0.0.1:3000 Running 10s test @ http://127.0.0.1:3000 4 threads and 2000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 1.09s 354.40ms 2.00s 69.01% Req/Sec 184.04 55.36 404.00 71.07% Latency Distribution 50% 1.12s 75% 1.33s 90% 1.56s 99% 1.80s 7241 requests in 10.01s, 806.13KB read Socket errors: connect 983, read 0, write 0, timeout 391 Requests/sec: 723.73 Transfer/sec: 80.57KB and 739 rps with the `println!` uncommented, which isn't significantly better. I was wondering whether it's related to the Code terminal. I tried from Code (with a longer test of 100s) and I got 546 rps and 541 rps, so I can't reproduce that specific result of yours. Note that my DB server is over a WiFi network, and very slow, so there's that. There's two things I'd like to try: make a pool of threads and send the posts over a Crossbeam channel, and use the single-threaded run-time. But not tonight.
nll should be enabled by default on stable soon, with Rust 2018 almost out, so you shouldn't really need to worry too much about compiler flags. I'm really happy that this class of errors is going to go away soon. It's a pain to a lot of people.
Happened across this today and now I'm curious! Does it perhaps have some kind of planned use with regards to `rustc`? If anyone has any additional information on what's going on in there I'd be quite interested to hear it.
Closest category I could find, and where I think someone will be able to find it as well.
Wow, I had no idea Zola compares so well to Hugo features-wise! Really looking forward to trying this out with my next static site project.
Is there any fundamental difference between a LRU cache and simple memoisation?
Makes sense! I appreciate it.
&gt;A LRU cache is simply a data structure that can be used to implement memoisation among, other things. This macro is ultimately performing memoisation, though using a specific eviction strategy.
Short story: you cannot have struct fields borrow other fields of the same struct. If you try to do that, you will either get something like your current error, or you will be unable to move or modify the struct for the rest of its lifetime (making it almost useless). Now here's why your current case cannot work: if you explicitly write out elided lifetime on `next`, you get an error that makes quite a lot of sense: error[E0495]: cannot infer an appropriate lifetime ... 33 | self.chars = self.buf.chars(); | ^^^^^ note: first, the lifetime cannot outlive the lifetime 'b 20 | fn next&lt;'b&gt;(&amp;'b mut self) -&gt; Option&lt;Self::Item&gt; { | ^^ You only have a reference to `self` with lifetime `'b`, so you known that `self`, and thus `self.buf` will only be guaranteed to be valid for lifetime `'b`, and so `self.buf.chars()` cannot outlive that. note: ...so that reference does not outlive borrowed content 33 | self.chars = self.buf.chars(); | ^^^^^^^^ note: but, the lifetime must be valid for the lifetime 'a 17 | impl&lt;'a&gt; Iterator for Parser&lt;'a&gt; { | ^^ But you try to assign that to `self.chars`, which has lifetime `'a`. So for this to be valid, `'b` would have to outlive `'a`, but there's nothing in the signature that requires that, so the compiler can only complain. If this compiled, then the user of `Parser` could: 1. Construct a new parser that uses some `'static` string. 2. Make parser's `chars` borrow the same parser's `buf`. 3. Deconstruct the parser, obtaining a string `buf`, and `chars` iterator that has `'static` lifetime, but borrows `buf`. 4. Destroy `buf`. 5. Use `chars` to summon nasal demons.
I have created new runtime with 1000 blocking and no changes in bench still 112 rps: let server = warp::serve(warp::get2().and(index_load)).bind(([0, 0, 0, 0], PORT)); let mut thread_pool = tokio_threadpool::Builder::new(); thread_pool .pool_size(4) .max_blocking(1000) .name_prefix("helllo-world-"); let mut runtime = tokio::runtime::Builder::new() .threadpool_builder(thread_pool) .build() .unwrap(); runtime.spawn(server); runtime.shutdown_on_idle().wait().unwrap(); &amp;#x200B;
Thanks will try that out :)
I’ve been wondering this too. No conclusions yet.
Your question is a bit hard to understand, but I *think* that you want to store a ```&amp;mut Iterator&lt;Item=Scalar&gt;```. That is a trait object, so you can store any trait in there that implements ```Iterator&lt;Item=Scalar&gt;``` (i.e. any iterator that produces a Scalar) at the cost of dynamic dispatch: Any call to that object will first go through a virtual function table.
&gt; Wow, I had no idea Zola compares so well to Hugo features-wise! The issue for the name change actually says "Downside is Hugo is also a french writer", but I assumed it was a deliberate, playful choice. Seems like an upside to me.
Just to make sure, you aren't bench marking on OSX right? I don't know why but there is something crippled about the networking of OSX, maybe its so they can sell OSX server.
Nowadays you cannot name anything after most common words or names, somewhere out there is a company or product with the same name that potentially will confuse you. I've started considering naming my projects in Norwegian, but that only fixes it for people who do not speak it.
It could not only run on 16-bit architectures but also even make `u32` and other not-normally-present primitives available by simply representing those types as compositions of other smaller types, assuming that's not out of the question for some reason.
So now your argument is "well if C++ static analyzers blatantly copy rust and bolt on some sort of lifetime information, and then people rewrite the whole project to *use* that lifetime information, it might be as good as rust? Except for all the nice syntax." At that point it'd be easier to just rewrite it in rust! And much nicer too, since rust *elides* lifetimes. you don't need to spell it out. But this bolt on lifetime thing wouldnt have that benefit, so you'd have to bolt them on everywhere. And if you're not using them everywhere, then you have the same problems as before anyway!
I see above that TryFrom can convert, if the compiler knows it will always succeed then it should be able to optimize those checks out as well.
That reference cannot be returned from the function because the referent is defined within its scope. If you need to move a reference out of the function scope, you should consider using `Box`. I can tell you that when I was writing a compiler in Rust, I decided to just use `Box` for everything. It made my life extremely simple. Another thing you could do is use your `Pratt` struct to allocate `Node`s that are owned by the struct instance, or you find a way to move your `Node`s into the `Pratt` struct and then reference them from there. However, managing the lifetimes for either of these solutions seems much harder than simply using `Box`, though it might be a nice deep dive into lifetimes to avoid it.
C should be a official target support, it's probably way harder but it would immediately solve a lot of problems in the embedded area (of course the ideal situation is having direct targets, but they can take some time and you have to handle them individually).
I mean, how turn: let walk= something.iter() .map(..) .filter(..) .etc(..) //LAST STEP .map(|x| Scalar::String(x)) into fn adapter(...) -&gt; Iterator&lt;Item=Scalar&gt; 
Yay :) Just to show the performance improvements aren't just for large sites, here's build time on my little 28-page personal site: * 0.4.1: 1.4s * 0.5.0: 222ms Syntax highlighting initialization's gone from serialized O(threads) to O(1), so if you use that and have a lot of cores, you should see a pleasant improvement.
I try this but can't figure how pass it: struct Cursor&lt;I&gt; where I: Iterator&lt;Item=Scalar&gt; { pub walk: I } let lines = BufReader::new(file).lines() .map(|x| x.unwrap()) .map(|x| Scalar::String(x)); Cursor { walk: lines ???? ^^^^^ expected type parameter, found struct `std::iter::Map` }
&gt; At that point it'd be easier to just rewrite it in rust! 2 reasons not to * accumulated *instinct* (intuition which once built up works faster than logic): there are many more programmers who 'get' C++ syntax already. There is a cost to switching. * having C++ sourcebases in established products. (my real world acquaintances are stuck doing real work in C++ because they're tied to C++ libraries, using those from rust would be utterly horrible.. it's of no use to them) &gt;&gt; And much nicer too, since rust elides lifetimes. you don't need to spell it out. gee, i never thought of that, by suggesting a default first.
You can override the system allocator globally, but I don't think there's any way in the standard library to specify one on a per-object basis. There's probably a crate that would let you do that, but I can't seem to find one. There are arena allocators that can be used for pooling. If you have an allocator, you can make your own collection types that use it. An example would be: #![feature(allocator_api)] use std::alloc::{Alloc, AllocErr}; use std::ptr::NonNull; use std::sync::Mutex; struct MyBox&lt;'a, T: ?Sized, A: 'a&gt; { p: NonNull&lt;T&gt;, alloc: &amp;'a Mutex&lt;A&gt;, } impl &lt;'a, T, A: 'a + Alloc&gt; MyBox&lt;'a, T, A&gt; { fn new(v: T, alloc: &amp;'a Mutex&lt;Alloc&gt;) -&gt; Result&lt;Self, AllocErr&gt; { let p = alloc.lock().alloc_one()?; Ok(MyBox { p, alloc }) } } /// Make sure to deallocate impl &lt;'a, T: ?Sized, A: 'a + Alloc&gt; Drop for MyBox&lt;'a, T, A&gt; { fn drop(&amp;mut self) { self.alloc.lock().dealloc_one(self.p); } } /// Equivalent implementation for DerefMut, AsRef, and AsMut impl &lt;'a, T: ?Sized, A: 'a + Alloc&gt; Deref for MyBox&lt;'a, T, A&gt; { type Target = T; fn drop(&amp;mut self) -&gt; &amp;T { unsafe { self.p.as_ref() } } }
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=2c64ba0b43ea93d59625814c33d7c044
`fn adapter(...) -&gt; impl Iterator&lt;Item = Scalar&gt;`
I understand, I do not currently have a concrete example I was mostly looking for general tips and guidelines (If I've missed something obvious) which I feel I have gotten in this thread :) Thanks for your willingness to help more concretely though!
They are there to remember us that when they cease to exist because bot delete them instantly without false positives rust will be ready for **everything**
Hey that broke my build, can you please undo that change?
Probably not. After a certain point the hard part becomes correctly parsing the user input rather than actually implementing the functionality, and I'm just not as interested in that part. The [rush](https://github.com/psinghal20/rush) shell is a similar project, which chose different features to implement, so you might be interested in checking that out. 
Playing around with `alsa` crate, I've tried at some point to cast a `i16` to `f32`. Clippy complained that the conversion via `as` might be lossy, and recommended to use `f32::from` instead. I did just that, but I have some doubts: how does using `from` fix it? It doesn't panic where `as` would lose data, does it? That would be messy.
Very cool, thanks for the link. That's a good point about not adding much more complexity, I'd understand wanting to be done with the project.
The cursor will provide some metadata. I already forgot about impl. I will see if this is enough...
The `from` implementation for `i16 -&gt; f32` [https://doc.rust-lang.org/src/core/num/mod.rs.html#5210-5215](just calls `as`). IIRC, the reason it's linted against is that if the type is later changed from an `i16` to something like an `i32`, the `as` version will be lossy silently, whereas the `from` version will not compile as `From&lt;i32&gt;` isn't implemented.
Thanks for the reply. I'll investigate using Box's. As an aside, what compiler did you write in Rust? I keep trying to complete mine, but it seems like one of those projects I might never have time to complete
Can you share a git repo with all the project?
(╯°□°）╯︵ ┻━┻ I did see that site but didn't go much further after seeing it was a wedding site. It should be fine though, the intersection of people using SSG and Americans using a wedding site builder should be fairly small. 
Makes sense. Thanks!
&gt; And even if they do not right now, it's just a matter of searching for occurrences of unwrap and expect to later find the call sites which need to be adapted. It’s also trivial to go through compiler errors and fix them while compiling for 16bit.
That's a good idea! I've done little with thread local things, but that'd avoid the issue of needing a recursive mutex, and would avoid the overhead. I'll give it a go.
I was in a compilers class a year ago where we had a language spec we had to implement. It was basically a subset of Python 2 syntax. The Prof. was chill with me and my partner using Rust, so we did that. It never quite worked right, but yeah. That language sucked to implement, and it required linking a static C library to provide most of the "pythonic" functionality, so neither of us wanted to bother completing it after the class.
&gt; &gt; &gt; LRU is about what to do when your cache becomes too small. Typo: LRU is about what to do when your cache becomes too large*
Pest is built on top of the ideal that parsing should be "pure" and actionless. A _big_ issue I've had with ANTLR is that while it offers an interpreter, said interpreter never works for any real grammar because any real grammar has semantic actions in it. Another wrinkle is that a parse tree isn't an (abstract) syntax tree. Maybe I'm biased; I have a very idealistic opinion and will probably end up with at least five different representations in my pipeline (source -&gt; Lossless Syntax Tree -&gt; Abstract Syntax Tree (view into LST?) -&gt; High-level Intermediate Representation (basically desugaring and representation independence) -&gt; Mid-level IR -&gt; Codegen IR) before I'm truly happy, which necessitates a bit of repetition, but because (ideally) these representations are not very coupled. But imho, your parse tree and your actual syntax tree are two separate concerns. Pest is only concerned with the parse tree atm, though it definitely could be more typed. ----- As for pest-in-public-API: I definitely agree, and consider the appearance of pest/from-pest in the API of Nafi a bug. Unfortunately, I don't think it's possible to hide until we get crate-scoped implementation. It does sound like LALRPOP offers exactly what you want, though!
Pest is built on the ideal of "pure" parsing without transformation. I wrote a bit more on your part two. TL;DR semantic actions break the model that pest wants to present. And yes, pest-ast is a second processing pass on the untyped tree that pest generates. This is because I at least see the parse tree and syntax tree as distinct problem spaces.
It seems that instead of having builtins, the shell should instead open a pipe to the program through which that program controls the shell, either on one time basis or an ongoing one (so all subsequent commands are run in the context of that command - it could modify and/or re-route the stdin, stdout, stderr, etc). This eliminates the partitioning of its functioning. It also opens up neat possibilities of how shells might operate. Is this an existing concept? I'd be surprised if it wasn't.
It seems that instead of having builtins, the shell should instead open a pipe to the program through which that program controls the shell, either on one time basis or an ongoing one (so all subsequent commands are run in the context of that command - it could modify and/or re-route the stdin, stdout, stderr, etc). This eliminates the partitioning of its functioning, meaning *all* shell commands are just programs and can be added to at will. It also opens up neat possibilities of how shells might operate. Is this an existing concept? I'd be surprised if it wasn't.
Don’t you think it could be cool to directly give the power to people to lift a pure Rust function inside the grammar directly in order to yield a more-typed token tree? The functions are still pure.
That could lead to silent SemVer violations. For instance, suppose that this works: ``` fn size(base: usize) -&gt; usize { usize + 1 } // In a future world with value generics let arr: Array&lt;i16, size(10)&gt; = Default::default(); ``` If, in a future release, `size` is made to be no longer `const`, then this code will break. `const` is a bit like a marker trait for functions; it's a promise that this function will always be `const`.
This was one of the things that surprised me as well. The link below does a good job explaining why `cd` must be a built in. https://unix.stackexchange.com/questions/38808/why-is-cd-not-a-program/38809#38809
This would be kind of like having a `NotCopy` trait, though. Consider that generally an `fn` can always be made into a `const fn` without breaking anything, but the reverse is not possible. Rust generally has a model where you add behavior constraints to something (usually in the form of traits like `Send` or `Copy`); `const` is consistent with this model.
This is a very good question and something that could serve to be a part of an official link for beginners. Also, I haven't read a lot but the little I read (and from others' claims) ripgrep is probably a good code base. But please don't go by my word. /u/steveklabnik1 sorry for bothering you but do you feel that this is something you'd like to make an official list of? I know I would be very benefitted
I always love how high quality these streams are-- always super relaxing and informative!
That sounds promising for those actors that need it. I hadn't seen that yet.
I'd have to defer to u/dragostis for this; he's still the project lead. I've got autonomy in pest-ast but he's still the main driver for pest proper. (That said, if I were to go and build a mode for pest that emits a typed view into the parse tree it'd probably be accepted.) The problem with embedding semantic actions, though, is that interpretation becomes impossible. ANTLR has the exact same problem; they offer an interpreter that breaks on any decently real grammar because it doensn't run semantic actions. For example, the pest.rs editor becomes a lot more difficult to do. And also you end up with horrible compile errors if your code isn't good; the span pointed to for all problems would be the `#[derive(Parser)]` and not any of the code in your `.pest` file. Personally, I think separating the behavior from the declarative grammar is desirable, though there's definitely a lot that we could do to make this easier.
Serious props on the rename, I know some would be too stubborn to do so. I think it was a critically smart decision. Love what you're doing, can't wait to pick my blog back up soon and get it generating with Zola! :D
Why the name change, as someone out of the loop? 
This is a great question and common to many languages. Everyone knows about the headline projects in a language, like Docker in Go or Parity and Servo in Rust, and you can always look at those- but they are massive and frankly too complex to casually try to understand. There should be some projects that serve as good examples for people to digest. Maybe a key value database like BoltDB in Rust could be a good candidate project
There is a tracking issue for this. It hasn't landed in nightly yet, but work continues: https://github.com/rust-lang/rust/issues/42774
You probably want r/playrust
Thank you again. Using Rc seems to work. From my impression, if we use Rc everywhere, then it will roughly work like coding in Java. The code is somewhat verbose but probably more flexible. I have a follow-up question. Does this mean, when in doubt, we should just use Rc? Using lifetime with Box is very complex and difficult to change, it seems. &amp;#x200B;
Not sure the styles will be up-to-date (esp for Rust 2018) but last year's libz blitz might have some good crates to look at along with the resulting style guide: https://internals.rust-lang.org/t/rust-libz-blitz/5184 
Devil's advocate - what is the reason to use futures here at all, and all the dependencies you need to get it working? 
And headline doesn't necessarily mean well written ... Just the idea is great and took off
Oh, no reason at all. I just wanted to compare how it is to work with asynchronous IO in Rust compared to C/C++ and how it is to program with it. 
Alright, so I made some adjustments based on your feedback and some of the other comments. I've got this, but it still won't compile: if commands[0] == "add" { match employees.entry(department) { VacantEntry =&gt; employees.entry(department).or_insert(vec![name]), OccupiedEntry =&gt; OccupiedEntry.get_mut().push(name) } } Error reads: warning: unused import: `std::collections::hash_map::OccupiedEntry` --&gt; src/main.rs:2:5 | 2 | use std::collections::hash_map::OccupiedEntry; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: #[warn(unused_imports)] on by default error[E0599]: no method named `get_mut` found for type `std::collections::hash_map::Entry&lt;'_, &amp;str, std::vec::Vec&lt;&amp;str&gt;&gt;` in the current scope --&gt; src/main.rs:31:44 | 31 | OccupiedEntry =&gt; OccupiedEntry.get_mut().push(name) | ^^^^^^^ Am I doing my imports wrong? I'm still new to the language, and honestly, I'm mostly guessing at the syntax in the arm statement. Hope I'm not too far off though.
Yes I have. I should probably have cross-posted instead.
The way I described isn't actually incompatible with the reasoning described here, though - it would function as a decorator, rewriting the communicated current directory.
I think this purse is safe.
The sound of that keyboard is seriously chilling me out. What is it?
That's fair. I wrote this to learn about how the shell works, and the parsing isn't really the interesting part to me so I avoided it. 
Never mind- areweideyet has it
The Filco Majestouch Ninja Tenkeyless: https://www.diatec.co.jp/en/det.php?prod_c=775
You are super close! The OccupiedEntry and VacantEntry variants are like the Some variant of the Option enum in that they carry a value with them. You want to change your code so you match VacantEntry(entry) and then you can do entry.insert(vec![name]) in that match arm. Ditto for the OccupiedEntry(entry) and then you can do entry.get_mut. The error message you are getting hints at that, it is saying that you are trying to do a get_mut on an Entry when it is only OccupiedEntry that had the get_mut method. I believe the import warnings will disappear when you make the changes above as well. Good luck!
Ahh that's actually one of my favorite sounding boards, I have one myself in Browns (not the Ninja, but I have aftermarket keycaps). Great video!
This is how my PEG parser generator, [rust-peg](https://github.com/kevinmehall/rust-peg/) works. Rules have a return value that is computed by Rust expressions embedded in the grammar. For instance, for a simple arithmetic expression grammar, the parser can [compute the value directly](https://github.com/kevinmehall/rust-peg/blob/0.5/peg-syntax-ext/tests/test_arithmetic.rs) or [return an AST data structure](https://github.com/kevinmehall/rust-peg/blob/0.5/peg-syntax-ext/tests/test_arithmetic_ast.rs). Note: The `master` branch is in the middle of a redesign now that procedural macros are stable, so look at the `0.5` branch or the version on crates.io for a version that works `build.rs` script.
In `::lru_cache`, by including the leading colons, we are instructing Rust to start looking from the root level (i.e. where you'd declare `extern crate lru_cache`) instead of looking from wherever nested module hierarchy the current function is in. &gt; why is it necessary to unwrap the cache as mut to grab a reference? We declare the cache as an `Option&lt;LruCache&gt;`. Option has a method called `as_mut`, which looks like: ``` impl&lt;T&gt; Option&lt;T&gt; { fn as_mut(&amp;mut self) -&gt; Option&lt;&amp;mut T&gt;; } ``` So if the Option is a `Some` (it has something), it will be transformed into a mutable reference of said thing. Then we `unwrap` that transformed Option (which basically assumes the cache exists and that we can successfully grab a mutable reference). Then we have a `&amp;mut T` or `&amp;mut LruCache`, which we can modify.
#SAVED!!! 
I'll answer everyone in this post, I hope it's okay :) &gt; Maybe you just want to find more elegant / concise ways to express the same logic, avoid redundant match blocks That was pretty much my main qualm with my initial code. I tend to think of Rust as a kind of Haskell masquerading as C++ (maybe not the best metaphor, but I tend to see a lot of Rust code written in a functional style). I felt that my code looked way too much like C/C++, except even worse cause you can't index Strings. In Haskell, I would write the `is_vowel_initial` function like this: is_vowel_initial :: String -&gt; Bool is_vowel_initial word = (head word) `elem` "aiueo" Instead of a for-loop like I did in Rust. I'm just not familiar enough with the standard library to find these functions I guess :) Googling doesn't seem to help as much with Rust as with other languages, probably cause it's just so new, and also cause I'm so new to it :) I see how you handled it, and it's exactly what I was hoping for. Pretty much a Rust translation of the Haskell code above, minus the `head`: fn is_consonant(c: char) -&gt; bool { !String::from("aeiou").contains(c) } And you used `s.chars().next().unwrap()` instead of my bulky funtion with pattern matches, that's what I wanted to write too, if I had known how XD. Or use u/Flandoo's `remove()` instead, that's also a lot simpler. Also both u/Flandoo and u/RaphaelAddile used `trim()` to strip the final `\n` from the input, again, so much simpler and more elegant. u/RaphaelAddile I like the way you wrote it, although the logic is a little different in yours, but also very useful for me to study. Thank you all for taking the time to comment and correct my code! ------- &gt;I think of String vs &amp;str in Rust as somewhat analogous to C++'s std::string vs char*. To me, as a Rust API consideration, both String and &amp;str imply a sequence of characters, but String emphasizes that it owns its own memory, while &amp;str emphasizes that it is pointing into and dependent on existing memory. As such, it's very hard to return a &amp;str if you are allocating new text inside your method. I understand how String and &amp;str work as data structures, but it's difficult to keep all of the ownership details in my head at the same time. I get confused and make silly mistakes, but then again, from what I understand, that's the way people usually learn Rust :) 
but then the cd "program" only exists to call back into the shell builtin, so whats the point?
Re-implementing the collection types isn’t really a trivial task. I want to avoid that if I can :) Can the system allocator be overrided on a per-module/crate basis, or does it need to be for the whole application?
Interesting. What use-cases would require terminating the application on allocation or deallocation?
There wouldn't be any builtin anymore - that's the point
quite late but there are now tools for generating wasm from Haskell
I really enjoyed the [ripgrep code review](https://blog.mbrt.it/2016-12-01-ripgrep-code-review/). I think [BurntSushi](https://github.com/BurntSushi) is regarded as producing high quality, practical rust. 
And .. there's a crate for this: shlex
I've been doing the same, although mostly because I'm just lazy and not because I want to avoid name conflicts.
Have you tried reading the [book](https://doc.rust-lang.org/book/)?
Am I using the wrong version of Rust? pwarren@hollis:~/Projects/rs_sh$ rustc --version rustc 1.30.1 (1433507eb 2018-11-07) The first step errors out with a "can't find stdin(), I fixed that by doing std::io::stdin() but then the Command module dosn't seem to exist, and std::process::Command expects a type, not a string :(
Do people usually write their own themes? When I was looking for a static site generator, the selection of themes was pretty much the only factor. 
I would think looking at the source code of parts of the standard library would fit the bill. Also clippy tends to push you into best practices but that's not what you asked. 
Yes exactly. In obstruction freedom, a running thread may hinder overall progress (but only if other threads are running). In lock freedom a running thread cannot hinder overall progress. Super short version: Wait-free: all N of N threads complete in bounded steps Lock-free: &gt;=1 of N threads complete in bounded steps Obstruction-free: if only one thread running, it completes in bounded steps It's mainly the names that make if confusing because even obstruction-free systems can't hold locks.
Here are other frontend libraries relying on wasm-bindgen in rust: https://github.com/utkarshkukreti/draco https://github.com/csharad/ruukh/ You might find inspiration in those. 
Yes, a big part of the speed improvement is thanks to your work!
I always do write my own templates but I am pretty sure I am in the minority.
I think the main issue in rust pg library (or pool) as it is not releasing connection (or really slow at req, res)
Personally I use `Rc` quite rarely, especially in combination with `Cell`/`RefCell`. Shared mutable state is hard to reason about so I try to avoid that. Might be a personal preference - I used functional languages quite a bit before using Rust, so not being to share mutable references never felt too restrictive for me.
Thanks for the video was searching for an explanation of async and tokio this past week!
&gt; But assumptions like that are where it all falls apart. no you'd just verify where it doesn't hold your checker starts out *assuming it's supposed to be the shortest lifetime*, then it tells you where that assumption breaks down. Then you have 2 choices:- * accept that part reported as Unsafe (remember this could be visualisation rather than annotation) * put the lifetimes in you then gradually reduce the amount of unsafe, whilst at every point having a working project.. instead of having to drop all your mature tools, libraries, and accumulated experience with an "all or nothing" leap. 
Just read the second edition of the book which you can find [here](https://doc.rust-lang.org/book/second-edition/index.html) Also follow this subreddit.
Yes local works alright ( would say the same on node and rust may be rust slightly better) only remote one is very slow that is very weird. 
It's probably just for tests, to ensure that no allocation/deallocation happens in critical sections, as it can destroy performance and is quite easy to miss (especially when calling functions from other crates).
I think I get what you are saying. But if I'm understanding correctly, the shell would basically replace each built-in with and API hook for that built-in. And the code behind that API hook would probably look similar to the current implementation of the built-in. That said, there is definitely a lot of room for innovation in the shell/terminal emulator space, so if you get around to implementing a prototype I'd be interested in seeing it. 
I actually did look at [conch-parser](https://github.com/ipetkov/conch-parser), which seems to be a rather complete shell command parser. If I were trying to write a real shell replacement I'd probably look there to start. &gt; Please note that this was a learning project for me, and in cases where there was a trade-off between simplicity and robustness I most often chose simplicity. This line in the blog is two sentences below the snippet quoted by /u/LordOfDemise.
The playground link below is the complete (with imports) version of the code from the first step in the blog post. I am able to run it using `1.30.1`. I considered including playground links for each step of the code, but stopped when I realized you couldn't actually run this type of code in the playground because the playground doesn't allow interactive, long running processes. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=e306b289a2400cadd55103e097879eed The final version of the code is [available on GitHub](https://github.com/JoshMcguigan/bubble-shell).
Great video. A bit off topic, but maybe you could use smaller and pressure sensitive paint brushes when drawing stuff. It would probably make the text more readable. For example, in Khan Academy math videos, they use drawing boards exclusively and their drawings are super good looking and text is easily readable.
thanks. awesome.
It looks very nice. I only stick to another static site generator because of the lack of internationalisation. Great job anyway !
rusty humor and jest
Can I highjack this thread to understand the point of TLS ? Is this primarily because you are in a situation where you don't have or don't want to have different processes ? Or is this to have slightly cleaner global variables that cannot be mixed in global name space ? I slightly understand their usage but I don't see the killer application. 
It’s true I dislike the macros, but so far `nom` has made the job… until I wanted to share the grammar between the `glsl` crate and `glsl-quasiquote`. The current `glsl-quasiquote` crate uses `glsl`’s grammar by using its public interface, and this causes problem for variable interpolation. In order to implement that feature, I need to slightly modify the grammar to authorize some rules (identifiers, typenames, etc.) to accept some patterns, like `$x` or `{ x }`. Doing that with `nom` is terrible. I didn’t know `combine`! I’ll have a look, thousands thanks! :)
Interesting. What kind of parser is `rust-peg`?
have you seen the old william latham 'evolutionary art' stuff? maybe you're heading in that direction?
&gt; It seems that the two languages can coexist. SPARK remains very well-suited for safety-critical embedded applications, while Rust looks like a good fit for the IT domain. Generic embedded applications may lean on one side or the other, depending on various factors. Both languages bring interesting ideas to the table—and both suffer from shortcomings. **Perhaps there’s room for cross-fertilization.** I think that one obvious, if expensive, avenue of cross-fertilization is to develop a system of annotations for Rust functions which would describe pre-conditions, invariants and post-conditions, then have a static analysis plugin run as part of compilation to verify that the implementations match these specifications. This would make Rust suitable for situations where such static verification of a program's properties are either necessary or highly desirable.
I must confess I don't have a concrete example for usage of this. But, yes, you can imagine situations where you don't want to access global variables. Or you want a different variable per structure. As a concrete example, I have used this TLS to write a type that 'solves' the ABA problem. This type has a per-thread per-structure garbage list. But this is a library and not an application. I also remember a guy asking for per-object thread-local in a [Rust forum](https://users.rust-lang.org/t/per-thread-per-object-storage-thread-local-but-not-static/19538). 
I think we can disambiguate fairly easily with “Zola blog generator” as a search phrase.
Request context is one example. Finagle is a good example of this: every request has a context that includes a zipkin trace id which is propagated to every thread working on it (this is complicated because finagle makes heavy use of futures, and understandably, does not use a thread-per-request model for scalability reasons.) Another example is where resources are inherently thread-local. My memory is vague, but Netty used to have a thread-local that held super-thread buffer pool. Network operations would use this local pool to use/release memory blocks, which is dramatically cheaper than using a process-wide pool.
Yeah 
I'm following the Mozilla WebGL Tutorial [https://developer.mozilla.org/en-US/docs/Web/API/WebGL\_API/Tutorial/Adding\_2D\_content\_to\_a\_WebGL\_context](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context) in tandem with the wasm-bindgen examples [https://rustwasm.github.io/wasm-bindgen/examples/webgl.html](https://rustwasm.github.io/wasm-bindgen/examples/webgl.html) and I am at the point where I am suppose to send my vertex data to a buffer in WebGL but since I am using Rust WASM there has to be some workaround, I do no understand the workaround. I have worked with OpenGL before so I understand how buffers work, its the WASM specific stuff I need help with. If someone could comment every line of this code with whats happening and why its done I would be very happy. let vertices: [f32; 9] = [-0.7, -0.7, 0.0, 0.7, -0.7, 0.0, 0.0, 0.7, 0.0]; let memory_buffer = wasm_bindgen::memory().dyn_into::&lt;WebAssembly::Memory&gt;()?.buffer(); let vertices_location = vertices.as_ptr() as u32 / 4; let vert_array = js_sys::Float32Array::new(&amp;memory_buffer).subarray( vertices_location, vertices_location + vertices.len() as u32, ); let buffer = context.create_buffer().ok_or("failed to create buffer")?; context.bind_buffer(WebGlRenderingContext::ARRAY_BUFFER, Some(&amp;buffer)); context.buffer_data_with_array_buffer_view( WebGlRenderingContext::ARRAY_BUFFER, &amp;vert_array, WebGlRenderingContext::STATIC_DRAW, ); &amp;#x200B;
Have you looked at the thread_local crate? It is very similar to what you have written. (Disclaimer: I am the author)
LRU is simply a policy for evicting entries in a bounded cache. It's pretty much orthogonal to memoisation: you can memoise to an LRU cache.
You want to write `iter_mut()` instead of `iter()`.
This was an outstanding stream. Thank you so much for doing this. This is the first time I've seen someone explain the full runtime/execution flow and all the moving parts involved. I've seen quite a bit of material on Futures and async in general in various languages and it seems most talks always take it for granted that people know the whys and hows of a reactor pattern and focus only on the usage of Futures leaving the rest feeling like magic. The part I would have like to see a bit more is how would we deal with CPU intensive work int he context of futures (e.g. we shouldn't block the event loop threads, so where should we do the CPU work and how do we structure such a thing?) &amp;#x200B; Anyways, keep up the good work!
This `iter_mut` thing has the looks of a workaround. Is it possible that there, in a future version of the language, will be a more natural syntax for it?
You can also write `v`, `&amp;v`, `&amp;mut v`.
Prove it. Not being adversarial, I'm just saying there are certifications in place. The first question any project manager is going to ask when you bring up anything new is "Is it certified for ....". - US RTCA DO-178C North American Avionics Software - IEC 62304 - Medical Device Software - ISO 26262 - Road Vehicles Functional Safety - EN 50128, Railway Industry Specific - Software (Communications, Signaling &amp; Processing systems) safety review Talking up how safe Rust is won't move the needle. Right now is 'heads down full throttle to certification' time. Perhaps a steering team to chop down the full language to a functional safety subset. ADA even got itself a US Military Specification: MIL-STD-1815.
In addition, the only reason the cache is in an Option&lt;\_&gt; to begin with is that rust doesn't let you do complex initialization of statics. In order to perform the initialization we defer until the first call of the function, which then constructs it for all future invocations to use.
`Read` provides [`chain`](https://doc.rust-lang.org/std/io/trait.Read.html#method.chain) method, which concatenates two readers. So you can chain two file readers into one, and then wrap the whole thing into a single `BufReader`.
Always thought design by contract was a good idea.
Although it is the most important part of a shell. Parsing accounts for 40% of the Ion shell's source code.
[https://github.com/nrc/libhoare](https://github.com/nrc/libhoare)
Thanks!
To expand on this: any type where `&amp;T: IntoIterator&lt;Item=&amp;U&gt;` or `&amp;mut T: IntoIterator&lt;Item=&amp;mut U&gt;` can have the respective `&amp;T` reference iterated over with simple `for` loop syntax. The `.iter()` and `.iter_mut()` methods are simply ways to explicitly get those iterators. It would be nice if they could be generalized into trait methods instead of direct methods on concrete types like slices.
The brush is already pressure sensitive, but I'm pretty new to drawing boards, so probably don't quite know how to use that to my advantage yet. A smaller paint brush is probably a good idea regardless though! That said, I think the text is relatively unimportant in these diagrams as I'm already saying out loud what I write down. Duly noted though!
You are in a programming language subreddit, try r/playrust. 
(From April 2017)
Oh crud thanks. Removing the post now
Nice! In the past I made a few postgresql extensions on windows in C for a few things and I always wondered how difficult it was to do them in Rust.
It's a nice library, however: - it is about dynamic checks, - which are only executed in Debug. That being said, it could provide the basis for the annotations which a plugin would use.
I'd love to have feedback on https://github.com/getzola/zola/pull/111 The more eyes on it the better!
&gt; Prove it. It's in the works :) For example, Ralf Jung from the Rust Belt project just posted his progress on the Stacked Borrows idea, which establishes a model to prove the "borrow checking" part of Rust works as intended, and even extends it to `unsafe` code. With hope, next year a formal proof will be developed. Beyond memory safety and type safety, there's also a [Formal Verification WG](https://internals.rust-lang.org/t/announcing-the-formal-verification-working-group/7240) in which notably Gallois (an embedded company) participates. I would expect something along the lines of SPARK or FRAMA-C to pop up for static verification of Rust programs. --- &gt; Not being adversarial, I'm just saying there are certifications in place. I am not too familiar with certifications, the only one I ever had to comply with being PCI-DSS (credit card number processing), which is far from being as rigorous. My understanding, however, was that certifications would not only certify the language, but also its implementation; that is: - rustc, - LLVM, - part of `core` and `std`. Therefore, it seems to me that it would be best to agree on a version to certify for all certifications beforehand, rather than have 2 or 3 versions each with a subset of the certifications... which makes me think a LTS would be a great rallying point.
I’d love to see more options for avionics such as Rust, but it’s a tough sell for projects until there are some mature code coverage tools, a certifiable library, and acceptance by the major players (Boeing, Airbus, military, etc). I like Ada but there is some resistance because some see it as too obscure / hard to find people with those skills.
Updated to now support multiple threaded access via TLS!
Great stream as usual! Looking forward to the next one.
The easiest approach is to iterate over indexes to the vector insteads of references. This way you don´t need mutable references to two separate elements of the vector (Which is needed for insertion sort) https://codereview.stackexchange.com/questions/141946/insertion-sort-in-rust Alternatively you can probably use `split_mut_at` but that is more complicated https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut
You as a programmer? Probably not, your gut is going give you better answers. &amp;#x200B; But lawyers, policy makers and other people like that have experience in different areas and their gut feeling doesn't apply here. They don't have a way to tell between „An experimental PoC one student wrote over the weekend“ and „Something meant seriously, a lot of people looked at it and they all kind of agree it is as correct as anything can reasonably get“. So, having an \*expensive\* lot of people to sign a certification at least proves the part that someone meant it seriously enough to pay the money and that a lot of people looked at it.
Any way to generate pages based off a database? I want to generate a few thousand pages with the same template but differing data on each page. It would be nice to be able to generate that without having to generate the markup for each page on the filesystem each time.
You can write either `for i in &amp;mut v` or `for i in v.iter_mut()`. They are equivalent.
Speaking about iec62304, that I use regularly at work, you can not really certify a programming language using it. This is more about the specific usage of the medical device, what are the mitigation in place in case of software failure. But there is no cookie cutter answer for things going from thermometer to pacemaker. And this takes the whole system into account, i.e what are the hardware or manufacturing process to make sure the device is safe. So this is much broader than a programming language. However it won't probably hurt your case mentioning that your software might not experience some race condition or out of bound access by design.
I don't have a remote db right now to test. I want to dig deeper on this anyway, so hopefully I will be able to have a look into this...
One thing wasn’t clear to me about the SPARK prover: is it using dependent types to do the proving? Is there any restriction on when or how the static analysis works? I did some googling and still wasn’t sure.
1. Iteration over a receiver stops when all messages have been processed, and all senders are dropped. There are two copies of the sender, with each spawned thread owning one of them. When a thread exits it drops its sender (because it goes out of scope), and that's when the receiver knows to stop iterating. If you added another statement `let tx2 = mpsc::Sender::clone(&amp;tx);` at the start, then there would be a third sender kept alive in the main thread, and the `for` loop would forever keep waiting for another message. 2. You cannot just say `clone` because there's no such function in scope - you need either to specify the type (`mpsc::Sender::clone`) or the trait it comes from (`Clone::clone`). Also, it takes parameter by reference, so you need to do `Clone::clone(&amp;tx)` instead of `Clone::clone(tx)`. Although the idiomatic way to call it would be simply `tx.clone()`.
PEG-style grammar, generates Rust code implementing a recursive descent parser with precedence-climbing for operator parsing.
as much as I know it would cause potential issues, it is the one feature i most miss from rust. le sigh.
1. So the receiver just knows how many transmitters there are and when they "ran out of stuff to send". Understood. Thanks for clearing that up! 2. Ahhh of course `tx.clone()` is what I meant to say. (I corrected it in the original post). So is using `tx.clone()` the same thing as `mpsc::Sender::clone(&amp;tx);` ?
Ah right, I forgot tokio added the internal threadpool. Thanks!
Yes, in this case all of `mpsc::Sender::clone(&amp;tx)`, `tx.clone()`, `Clone::clone(&amp;tx)`, and `&lt;mpsc::Sender as Clone&gt;::clone(&amp;tx)` are equivalent. If `mpsc::Sender` had a function `clone` defined on it (that would not be a part of `Clone` implementation), then the first two would call that. The latter two will always call `clone` from `mpsc::Sender`'s implementation of `Clone`,
s, n, tz, tx, ty? I am not liking those function names. I get it and why, but ewww.
"Your scientists were so preoccupied with whether they could, they didn't stop to think if they should." Just joking obviously.
Lol yeah they are terse. You are going to write them so much when using this library though; they need to be short. And they also stick to the names used in [EisenScript](https://after12am.github.io/eisenscript/docs/reference/translation.html) which this is intended to replace. Internally I actually have [fully descriptive names](https://github.com/turnage/immense/blob/master/src/rule/transforms.rs#L428) which I plan to export when I work out how I'll accept raw matrix transforms.
No. “Function overloading” is when you can have two functions of the same name with different type signatures, and the proper function is dispatched based on the types of the argument passed to it.
Working on just the local version I start to believe that you simply put too much load into the application. Can you repeat the remote benchmark with a reasonable number of connections to the rust web server? Like 100 and not 1000? Also, if you post results post the whole output of wrk, I am not sure how to interpreter the timeout. I believe those are not counted on the final rps, but I can't find any documentation for this claim. Also, I see that increasing the number of connection to the database I see an almost linear increase of performance (10 connections 400 rps, 100 connections 4000 rps). I start to believe that in your configuration (10 connections to the db and a 1000 connections to the server) you are just testing the performance of PG However I still not sure why there is this performance difference. You said somewhere that there are few connections open to pg, like 2-3, how do you measure that? The rust version just open as many as I told him to open. Checked with `SELECT sum(numbackends) FROM pg_stat_database;` 
The mutability is part of the type signature, and that’s important, so it can’t.
How popular is Rust at MIT?
Have you thought about doing it without WASM? So instead, e.g. generate a cdylib Rust library and generating PHP wrapper code for it via proc\_macros? I've done a [PoC for something similar in Java](https://github.com/hobofan/jnigen) (but sadly haven't found the time yet to clean it up), and it wasn't that complex, so I'd wager it might be simpler than getting WASM involved.
I still think Haskell is more approachable for the tasks like these.
Thank you for this. Watched it through and i thought it was a very good explanation on how everything works with Futures and async/await. Both useful and interesting. Also very useful for any language working with Futures and async/await. 
A lot less useful though. I am also exploring compiling to wasm for python currently because distributing native modules is such a crazy world. 
Neat! Looks like a graph API all right. One comment: Since you expose [Edge](https://github.com/SilensAngelusNex/pgraph/blob/83b7c2fe554f3bdd5c754cb1c15e649c73f3fcd4/src/lib.rs#L17) as a first-class type in the interface, I would maybe expect the public methods to be named 'g.add\_edge(v1, v2)' or 'v1.add\_edge\_to(v2)', etc. The method named 'v.connect(..)' does not make it obvious what happens if there's already an edge between the two vertices.
Usually personally what I like to do is to find a crate/tools I will use the most and then I look into it. For instance I liked to read [crossbeam](https://github.com/crossbeam-rs/crossbeam) which is not that huge and you can learn a few design pattern in it. And then after that I checked how a crate they use named [parking_lot](https://github.com/Amanieu/parking_lot) is done. And I repeat. I liked to read : * [crossbeam](https://github.com/crossbeam-rs/crossbeam) * [serde](https://github.com/serde-rs/serde) * [actix](https://github.com/actix/actix) * [rusoto](https://github.com/rusoto/rusoto) * [rocket](https://github.com/SergioBenitez/Rocket) * [linkerd2-proxy](https://github.com/linkerd/linkerd2-proxy) or also named Conduit before. Also I didn't check that yet but [hyper](https://github.com/hyperium/hyper) and [tokio](https://github.com/tokio-rs/tokio) should be cool. For embed software you can see: * [embedded-hal](https://docs.rs/embedded-hal/0.2.2/embedded_hal/) is the standard * [l3gd20](https://github.com/japaric/l3gd20) to see an example of an implementation on the hardware side. You can skip those if you are not interested in embed software but if you are curious you can at least read [this post](http://blog.japaric.io/brave-new-io/) and see how Good Rust is even for embed software. Hope all that helps!
Or adapt Rust's borrow checker to SPARK. Which is already being done.
If you are using this, you are already using a native module (the one that reads and executes the wasm), though, so I'm not sure if that is that big of an argument. Sure for the N:M language interop problem WASM is potentially a good solution, but for the special case of Rust inside X, WASM might be overkill.
Sure; of course this being r/rust I'm slightly more concerned about enhancing Rust ;)
Seeing as it is r/rust, and not r/jazz, it's expected that posts relate to Rust and, even better, than they *explain* how they relate. In the future, I advise you to make this more explicit. For those who wonder, apparently the Jazz interpreter (?) is written in Rust.
Who names these things? That is the least intuitive name ever IMO.
But i only need one.
Thanks for taking a look! I can't add `v1.add_edge_to(v2)` to the API (`v1` doesn't have the information to determine whether or not `v2` is in the same graph), but renaming `connect` to `add_edge` makes sense. Do you think that `add_edge` makes it clearer that the edge will be overwritten if it already exists?
I don't understand. The goal is to be able to run WASM in PHP. Instead of writing a WASM interpreter in PHP from scratch, I use a PHP extension that talks to a Rust library that uses `wasmi` (next stop is Cranelift).
Link to previous announcement thread: https://www.reddit.com/r/rust/comments/9x5uvk/advancedresearch_releases_a_generic_linear_solver/ The new generic linear solver allows efficient automated theorem proving with Rust enums, taking advantage of precise control of inference rules and the performance of hard-coded inference rules. We did not have an example showing a more advanced case of theorem proving, so I thought the magic square would be a good fit. However, it took a while to figure out how to solve it with a linear solver, since I'm accustomed to thinking in terms of backtracking. It turned out to be not that hard, and the linear solver is much better than a backtracking algorithm, since it can give feedback on alternatives ways even before it found a concrete solution.
The goal is to run WASM only. The WASM binaries can represent any programs (Rust, C, C++, C#, Go probably), it does not matter :-).
Is the `README.md` helpful? If not, then it's an error that must be fixed :-).
Oh, you want clients to be able to send wasm to you to run? &amp;#x200B; Then I understand why you are passing the wasm from php to rust, but why aren't you passing it directly to rust? Rust is compatible with the cffi, so why do you need a C layer in between?
The WASM binary does not necessarily come from a client. It can land on the server. PHP cannot talk to Rust directly, hence the extension (written in C).
 // snip pub fn do_stuff() { println!("Starting to do stuff"); thread::sleep(Duration::from_secs(2)); println!("Done doing stuff"); } let headerbar_clone = headerbar.clone(); button3.connect_clicked(move |_| { println!("Doing stuff"); gtk::idle_add(do_stuff()); println!("Finished"); }); This code gives this error: error[E0277]: expected a `std::ops::FnMut&lt;()&gt;` closure, found `()` --&gt; src/gui.rs:80:9 | 80 | gtk::idle_add(do_stuff()); | ^^^^^^^^^^^^^ expected an `FnMut&lt;()&gt;` closure, found `()` | = help: the trait `std::ops::FnMut&lt;()&gt;` is not implemented for `()` = note: wrap the `()` in a closure with no arguments: `|| { /* code */ } = note: required by `gui::gtk::idle_add` error: aborting due to previous error For more information about this error, try `rustc --explain E0277`. error: Could not compile `gtktest`. Let us look at the docs: [https://gtk-rs.org/docs/gtk/fn.idle\_add.html](https://gtk-rs.org/docs/gtk/fn.idle_add.html) pub fn idle_add&lt;F&gt;(func: F) -&gt; SourceId So it takes a function as the parameter. But why is it not working? Why is the error message talking about closures? I am so confused? What do I need to change to make it work and why? What's the topic I need to google to understand this? So confusing.
&gt; Before Rust, I didn’t contribute much code to projects over the Internet. Not that I wouldn’t like opensource or that I wouldn’t want to help out, I just somehow never found a project I’d like to fully join and keep working on. &gt; I now contribute much more code than previously, I just do it across a very wide range of projects. I call these a passerby contributions ‒ I walk by a library, try to use it for something and discover a papercut. An hour or two later, I’m opening a pull request to the crate. This is basically exactly my experience too. I hadn’t really considered why this was aside from my enthusiasm for the language but the reasons outlined in the post certainly are part of it. Especially the small crates and good tooling that make it easy to orient yourself, build the code and made changes quickly. 
Maybe you could get things started with an entry for [The Rust Programming Language ](https://doc.rust-lang.org/book/2018-edition/index.html) to show an example of the sort of posts you would like. 
Proud owner of a \[Majestouch Minila Air\]([https://mechanicalkeyboards.com/shop/index.php?l=product\_detail&amp;p=3656](https://mechanicalkeyboards.com/shop/index.php?l=product_detail&amp;p=3656)) here, best keyboard for couch coding I've ever had the pleasure to use &lt;3
It can be nice to have some things abstracted into a framework. For example, your logger may use request data stored in the TL to prepend useful information to log messages (including request-level info). You can have a generic request timer that knows that every request has a TL with a trace id.
Not sure who invented this specific term but it is what everyone calls it.
Are there any editor plugins/themes that respect the color coding used in the documentation generated by cargo doc (IE traits are purple, structs are red, functions gold, etc)? I've found that to be immensely helpful in making a screen full of text more manageable, but I haven't been able to find anything about any rust-specific styles or plugins to get editors to follow that convention.
`do_stuff` must have return type `gui::gtk::Continue` if you want to pass it to `gtk::idle_add`.
I’m not aware of any.
what is ecs?
This PHP FFI extension already, http://pecl.php.net/package/ffi, but it is abandonned. There is also https://github.com/dstogov/php-ffi by Dimitry Stogov, but I've never tried it. The PHP extension is small so far, and we need to implement stuff like Array View to read from and write into the WASM memory, things that are hard to do with only FFI because it implies many type manipulations. So without any FFI support in PHP, having a PHP extension (written in C) is necessary.
Excellent work! Thanks for sharing!
True, it's not specifically a 'language' but more a full language toolchain (as others have mentioned). 
&gt;Do you think that add_edge makes it clearer that the edge will be overwritten if it already exists? Well to me it would kind of imply the opposite: that an edge will be added, or Err() produced. One might call it `ensure_edge(...)`, but that seems kind of unwieldy. When things are hard to name it can be a clue that the underlying concept is messy, or it's at least something that needs to be explained in the docs. (Also, I've found that not supporting multiple edges between one pair of nodes can make things harder for some graph algorithms, particularly those having data attached to the edges.)
Hmm ok. Well now I changed it so it returns `gtk::Continue(true)`, but it sill blocks my GUI. I don't get it. I thought idle_add() should be used for async-ing the GTK GUI. Hmm I guess I need to hire someone from odesk or something. I'm really absolutely lost. Async GTK is so ridiculously hard/complicated. But thanks for your help!
 cache.with(|c| { let mut cache_ref = unsafe { &amp;mut *c.get() }; let cloned_args = (x.clone(),); let stored_result = cache_ref.get_mut(&amp;cloned_args); if let Some(stored_result) = stored_result { stored_result.clone() } else { let ret = __lru_base_fib(x); cache_ref.insert(cloned_args, ret); ret } }) This clone seems only necessary in `else` branch.
https://learning-rust.github.io/docs/b5.impls_and_traits.html might be helpful. 
[Entity Component System](https://en.wikipedia.org/wiki/Entity%E2%80%93component%E2%80%93system) 
capnp is a tool for constructing new protocols, or interoperating with existing capnp-based systems; it is not a tool for interoperating with non-capnp systems.
Is there any support for generating data other than .obj files? For example, it would be nice to generate GPU-friendly vertex and index buffers directly, or better yet expose some sort of iterators that can be used to generate whatever structure someone might want.
At the moment no, but I currently provide an iterator over an opaque type called OutputMesh, which I imagine in the future could implement Into for a variety of useful output representations.
Thanks this is really useful 
Great idea, I’m all for bridging different languages, this certainly will help us devs to get some real stuff done in the future.
The embedded-wg currently has a survey open for a 2019 wishlist and one of the requests is [certification](https://github.com/rust-embedded/wg/issues/256#issuecomment-438889322).
Thanks for explaining, I was under the impression that I can use protobufs to describe my messages and auto-generate the code that turns my message structs into bytes and back.
Thanks for sharing your project. You may want to checkout [oursh](https://github.com/nixpulvis/oursh), which has similar goals. 
This is a really great overview to futures and how rust handles them. I'm pretty new to this whole idea of asynchronous programming, and this stream makes me fascinated about the subject. Are there any other resources you recommend on this kind of thing in general and more specifically the inner workings of the executor or reactor mentioned?
I'd argue python is a bit more segmented than that. There's venv, virtualenv, some projects just expect you to install things globally with pip, and none of these help with having a consistent way to run tests like `cargo test` does. My experience contributing to rust projects has been much nicer than contributing to python ones because of this. Even though python has similar tools, there's nowhere near the ecosystem coherency that rust has.
Could you possibly include the imports in the gists on your page? It's a very useful and nice tutorial you've built, but as a beginner it threw me trying to work out what the imports were. (I know you include a link to the Github repository but as far as I can see, that's only in the conclusion, so I spent a few confused minutes trying to compile the gists as-is, before I saw there was a link to the finished article).
The standard library
What brilliant and handsome user put that in there?
You're getting a mutable borrow of v when you call v.iter_mut(), but but you don't need that (you're not mutating *e). You can just loop over the indexes of the vector instead.
Glad you found it interesting! The (still under construction) Tokio documentation section on "going deeper" (futures, async execution, etc.) is pretty good and getting better! https://tokio.rs/docs/going-deeper/futures/
Within the research community you mean? It's starting to take root in a couple of different labs, and there have been some recent papers that use it, but it's still nowhere near as popular as C or Python (depending on the field) :)
I think the function body is equivalent to the following, which doesn't seem to do very much for i in 0 .. v.len() { for j in (0 ..= i).rev() { if v[j] &lt;= v[i] { break; } v[j+1] = v[j]; } }
You can use either capnproto or protobuf to describe what fields your messages contain, but not how those fields map into bytes on the wire. For example, Text in capnproto is always [length-prefixed](https://capnproto.org/encoding.html#lists) using offset pointers into the message's data section. The capnproto encoder is designed to pair with the capnproto decoder. You can't use one without the other. If you use a different encoding system (as it looks like you're doing), you will indeed need to write custom conversion code.
 &gt; Second, Rust have relatively consistent conventions. Most things don’t digress from the std style much. If you want to make life easier for contributors (and users of your API too), stick to it. There are even style guidelines. Might be worth pointing out that Rustc actually checks styling conventions too: constants are all caps, function names are snake case, and so on. And so far I have found no project that deviates from *that* standard (except possibly for C FFI). I find that these helps a lot with consistency across different Rust projects, compared to various C repositories I've seen over the years. As for the guidelines you linked, I think [this style guide](https://github.com/rust-lang-nursery/fmt-rfcs/blob/master/guide/guide.md) is less abandoned? But it sure is confusing if there's more than one. 
Here are some rust translations of the pseudocode on wikipedia which it looks like your code is based on. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=cae68aad568698f6f7a9cc22f466b6aa
Excellent city choice :-]
I have a quick question: does anyone know how Zola (great new name!) with the book theme compares to mdbook? Currently I’m using a combination of Jekyll and mdbook for my site, but I would consider switching over to all Zola, as mdbook seems to be getting more buggy over time...
PHP user-land cannot talk FFI. So we need a PHP extension to bind PHP userland to Rust (through FFI). This is how it works :-).
Still not clear what it is I need to do. Could you show me a code example?
Link seems to be broken
Writing a serializer in Serde is a possibility, but could perhaps be complex for someone fairly new to Rust. Maybe writing a macro could be an option? The macro would take field name and field types as input and generate both a struct, and a trait implementation for serializing.
The internals section on the Tokio site goes into detail about this: https://tokio.rs/docs/internals/intro/
/r/playrust.
Good stuff 
Your php extension could be in rust too as it can support FFIs expecting c calling semantics.
If you're expecting some people to make an edge type that they want to mutate, try also copying Map's Entry API.
Hoo, that's an entire different project to write “API bindings” from Rust to Zend Engine/PHP. It's utterly different and very complex. It's also likely to break at anytime since Zend Engine keeps the compatibility through C macros, but the internal API changes very often. I would never recommend to do that :-).
https://blog.guillaume-gomez.fr/articles/2018-11-19+GNOME%2BRust+Hackfest+in+Thessaloniki works here
Someone actually made this like two years ago, but not sure what happened to it though or how to even find it.
I think being able to visualize lifetimes/borrows would be a wonderful teaching aide! 
I'm working with openapi yaml files using [the Openapi crate](https://github.com/softprops/openapi) .These files can have references to other pieces of the file. Resolving the reference is basically copy/paste the referenced object in the place referencing it. I want to pass through the structure and resolve all the references. This is a very nested structure. As an example. definitions: Country: properties: regions: items: $ref: '#/definitions/Region This is modeled as a bunch of Opion&lt;BTreeMap&lt;String, SomeOtherStructure&gt;&gt; Ideally I can iterate and modify in place. But I can't make it work. Probably is illegal in Rust. I've tried copying in other structure but BTreeMap does not implement IndexMut it seems and it is complicated. Any other idea?
That's a link to `tokio_threadpool::blocking`, are you saying it's being moved into the `tokio` crate?
I'm even less sure of what this would look like after nll. Before nll, lifetimes were pretty much scope based. Now? Well, they're call non-lexical lifetimes for a reason. I do really want this though.
Just like this? [https://pic2.zhimg.com/v2-b7bdc8a3a010ad92012199af2750cc72\_1200x500.jpg](https://pic2.zhimg.com/v2-b7bdc8a3a010ad92012199af2750cc72_1200x500.jpg) I noticed it is atom, but I haven't find any plugin like this. 
Relevant Hacker News submission where I found this: https://news.ycombinator.com/item?id=18480324
403 forbidden
The fact that the other party uses a binary format doesn't mean you can use any binary format. You have to use the same one.
It's a very early implementation for this purpose. I should make it more strong, with: * make it a real rust crate, can be simply imported; * library usage of bindgen, to run smoothly on every platform; * implementatios of all the postgresql functional macros, that bindgen can not generate([see this](https://github.com/rust-lang-nursery/rust-bindgen/issues/753)); For those utility methods used in stored procedures, I think it should be an independent crate.
During the last few weeks I: - started [@rust_gamedev](http://twitter.com/rust_gamedev) twitter account in an attempt to create some central point for #rustlang #gamedev stuff on twitter; - implemented the first iteration of a campaign mode for [Zemeroth game](https://github.com/ozkriff/zemeroth): https://i.imgur.com/nq232os.png - [gave a presentation about Zemeroth project at 8th Indie-StandUp](https://twitter.com/ozkriff/status/1058359693503070208); - wrote [a second monthly report (in Russian) about rust ecosystem](https://habr.com/post/429038/);
it might just be me, but I get a 403 forbidden error when I open that image (from Australia)
I've been failing miserably at saving files with their file extension intact with a Http.Post request in [Rocket.rs](https://Rocket.rs). There are no examples of this in the framework documentation and every example on GitHub that involves a Post request saves the file to disk without the file extension, in Pastebin fashion. Why is it so hard? :( [Post("/", Data = "&lt;Data&gt;")] fn upload_image(data: Data) -&gt; io::Result&lt;String&gt; { let id = "somefile"; let filename = format!("upload{sep}{id}", sep = MAIN_SEPARATOR, id = id); let path = Path::new(&amp;filename); data.stream_to_file(path)?; Ok(url) } &amp;#x200B;
The error is occurring when cargo tries to build one of vulkano's dependencies, `shaderc-rs`, which is used to compile shaders from glsl to spirv. I noticed that your building this in a directory that has a parent directory containing spaces. You can see in this `/usr/bin/ar: Can't open output archive /media/tim/tmp-Linux` your path is truncated at the space. I'm able to reproduce the error, so I will file an issue on the `shaderc-rs` issue tracker for you, in the mean time you may be able to work around the issue by removing the spaces from that directory.
[Re-uploaded](https://i.imgur.com/zYkjfMe.jpg)
You know, I knew that I wasn't supposed to use spaces in my directory names, but I'd never have thought that'd be the issue. Thanks! That sorted me out.
I think that this is a mockup image from some previous discussion of this idea.
Yeah, this one works. The original one still not for me. I’m using the Apollo-App on iOS.
There's also Pipenv, which is quite neat (but adds to the fragmentation).
Getting Chapter 3 put together on the book for [programming rust gba](https://github.com/rust-console/gba)
&gt;Text nodes must be quoted, because there's only so much Rust's tokeniser can handle outside string literals. So, instead of &lt;p&gt;Hello&lt;/p&gt;, you need to write &lt;p&gt;"Hello"&lt;/p&gt; I'm currently shopping around for an HTML crate and keep asking myself this: if you have to add even more verbosity, why stick with HTML? How about just simply `(p "Hello")` ?
I can't speak for Ruby or PHP. But I can talk about Perl, Python, C, C++/Qt/Kde… And even in the python, you'd find projects with autotools, custom setup scripts that use nobody-knows-what inside… I guess there's also a difference between using it for doing webservers (where you're expected to use virtualenv) and desktop applications (where you certainly are not). &amp;#x200B; A community describing itself as friendly and actually feeling the friendliness is different. As it is said, even Unix itself is user friendly, it just chooses its friends.
It might be less abandoned, but this one talks more about where to write how many spaces than eg. naming of conversion methods. I think both is important, but the spaces a bit less so.
Original submission to `r/vim` [here](https://www.reddit.com/r/vim/comments/9y8lr5/faster_devicon_file_preview_with_fzf/). What I found somewhwat interesting is that the tool itself does very little: It basically looks up something in a `HashMap`, and returns it. Still the performance benefit seems to be there (over bash, mind you), even though the HM has to be constructed on each binary start. Is there a better way to do this? Maybe make a static array and then use `HashMap::from_iter`? Anyways, I found it nice that rust is used somewhat "casually" to solve a problem that's easy to do in bash, but didn't quite perform.
The examples in your README are pretty close to the level of `mio` in terms of API. Is there a `differences between mio` section?
I'm hoping to get some work done on [rust-rst](https://github.com/flying-sheep/rust-rst), an incomplete parser and not-yet-renderer for reStructuredText. There was a version of the grammar with a complete but incorrect parser that handled indentation wrong, but with my [PR for the pest parser library](https://github.com/pest-parser/pest/pull/334) I can parse it correctly (mostly) 
&gt; custom setup scripts that use nobody-knows-what inside… To be fair, Rust has `build.rs` scripts as well, that can run arbitrary code during the build process. (which AFAIK, is the currently recommended way to link with C libraries via pkg_config, so there are plenty of them.)
Bingo, that's where they moved :-). I guess I should update the post with this one so at least I can find it next time.
I am writing an id implementation based on [Using rational numbers to key nested sets](https://arxiv.org/abs/0806.3115) and a modified form of [An order preserving finite binary encoding of the rationals](https://www.researchgate.net/publication/261204300_An_order_preserving_finite_binary_encoding_of_the_rationals) for use in sled. The former because it doesn't support buckets, and the latter because it doesn't support custom comparison operators. Optimizing it has been fun and a great learning experience, but i don't want to look at any bitwise for a long time after this.
I would be _great_ to have a slim-lang parser https://github.com/slim-template/slim
It's probably more useful post NLL, as now it's way less obvious what the lifetimes are. 
Because you can still fiddle around with HTML in the browsers devtools and then copy paste it into your Rust code. Because there is a shitload of HTML sitting around in legacy webservers (waiting to be rewritten in Rust ;) ). Because all existing UI frameworks show you examples in HTML and not in syntax XYZ. &amp;#x200B; React JSX is also not 1:1 HTML (class != classname) and it is having tremendous success with it, because all things considered, it's still very easy to learned compared to a complete custom syntax.
Or Haml, or any other template language with a similar style
Looking great! It's a bit difficult to compare crates of rather different maturity, so **assuming pgraph had all the features you have planned for it, how would it distinguish itself from petgraph?** What are their respective strengths/unique features, what are their weaknesses? It might also be helpful for potential users to add a brief comparison with existing graph crates (e.g. petgraph) to README, too.
Jetbrains makes a good job everytime. At work, I use Rider for the C#, and I also couldn't really use anything else.
You might be interested in [Maud](https://maud.lambda.xyz/). One of its design principles is to favor consistency with Rust syntax over consistency with HTML. (Full disclosure: I'm the author of Maud.)
Just to be clear: I was never talking about usage numbers. I was talking development, and improvement of the language itself. And using SO+Google search stats as a metric for language usage? Really? "A lot of people don't understand X. It must be picking up speed."
I don't know if it counts as avionics in your book, but there is a whole lot of non safety critical computer stuff in aviation where we could use rust today. For example, my current flight computer for paragliding is xcsoar installed on an ebook reader with a self build vario screwed on, and thats totally fine legally. So, before rust runs on the critical systems on an airliner, there is a whole lot of space to explore to get into the space gradually.
Since I was one of the [commenters](https://www.reddit.com/r/rust/comments/94j3gg/gutenberg_040_is_out/e3n7hji) on the name, I just wanted to add my commendation of the new name. I like!
Short answer: No such section, no. Long answer: There is a lot of Mio boilerplate at the moment, but the plan is to abstract that away. I want an API that is easy to get started with but doesn't limit the use cases. 
What's NLL?
Non Lexical Lifetimes, the new algorithm for the borrow checker. http://smallcultfollowing.com/babysteps/blog/2017/07/11/non-lexical-lifetimes-draft-rfc-and-prototype-available/
Non lexical lifetimes
I just thought they reapplied the color change for the language indicator on github for rust
My current personal site is using Zola. It has been very easy to use, apart from some shady data usage stuff when making relations to sections and pages. All in all, I was able to convert my old WordPress site/theme into Zola during a single evening. Data migration took another evening.
Are you talking about differing content or differing metadata/layout/design?
In an effort to support people who can't afford a ticket to the conference, we issue free tickets sponsored by the community. You can apply [here](https://michaelpankov.typeform.com/to/rwmBKG). First batch will be given out by November, 26. [https://michaelpankov.typeform.com/to/rwmBKG](https://michaelpankov.typeform.com/to/rwmBKG)
it still feels a bit too low level. Here are a few things that could be handled by this library: * The \`TcpListener\` could return a \`TcpStream\` that's already registered * having the \`Sessions\` handle reads and writes feels a bit backward. You could have one object that's interested in events from multiple sockets. And they might not want to handle the event right when it's available. Example: one client session with a \`TcpStream\` for the client, and another \`TcpStream\` for a database connection. It might want to have both the DB socket readable and the client socket writable, while it's streaming data from one to the next. In sozu, I separate the event handling from the protocol execution: [https://github.com/sozu-proxy/sozu/blob/master/lib/src/http.rs#L488-L521](https://github.com/sozu-proxy/sozu/blob/master/lib/src/http.rs#L488-L521) * a part that's typically annoying to handle is keeping around sessions or sockets that can still work. Like, you read from socket 1 and write the data to socket 2, but socket 2 returns \`WouldBlock\`, so you would have to wait for the event loop to tell you that socket 2 is writable again. But in the meantime, socket 1 still has data, and would not receive any new event (since we use epoll in edge mode). So the event loop should keep track of the sockets that are still ready to do stuff from the previous loop passes Small nitpick: since you already store an "interest" field with your sockets, you could register them only once in edge with all the interests, avoid oneshot (so you don't need to reregister every time), and in each loop execution, see how interest and readiness match. As an example, after reading from the \`TcpStream\` for your client, you want to answer, so you set the "writable" interest, and since it probably already has is in its readiness, you can write to the socket immediately instead of reregistering and waiting for the next loop pass. Reregistering the sockets all the time was a big performance issue in older versions of sozu.
I'm not sure if highlighting all borrows is a good idea, but highlighting the borrow under cursor, or what is causing a error does make sense. Though, is the borrow checker that confusing? Once you get used to it you would quickly understand what has to be changed to resolve the errors.
Maybe [Message Pack](https://msgpack.org/) is what you need? It's like JSON but in binary, and there are rust parsers.
REST/HTTP is just a frontend to your data, similar to how HTML is used to render data on a regular web page. ECS is a means of handling data and data manipulation, and strapping REST over that is either a good or a bad idea, depending on how you can model your REST resources against the ECS data model. In the end you need to consider the whole thing at a glance: does ECS make any sense for the business domain and data model, and what types of ports/adapters (API, GUI, TUI, DB, etc.) are required to access and manipulate the domain data. If your business domain works akin to a game engine with constant change, data and events flying around all the time, with replication being a big requirement (where ECS has been proven to be an OK solution I guess), then yes, maybe ECS could work for the business logic implementation. Making a web service (that runs using a HTTP request/response cycle) with ECS seems a bit counter-intuitive to me, though I guess the closest thing "in web architecture terms" is event-sourcing and CQRS architecture or similar with different kinds of APIs slapped on. Apart from REST, you could try using ECS with WebSockets and a RPC API or similar, in case "realtime" is something you're after.
Slight danger of non-additive feature flags in the blog post, but very nicely explained.
I've been integrating new types (thank god for macros) into [orion](https://github.com/brycx/orion), which have become a major usability improvement. Both in preventing misuse but also for things like random generation of keys. With std it'll be a matter of just calling a `generate()` function on a given key type, without the user having to know what key-sizes are recommended, etc. I have also been reworking the high-level API, after some feedback, so it feels much more like libsodium now. And lastly I've been working on improving the already public types, so as to keep more in line with the Rust API guidelines. I'll probably spend most of this week testing and polishing the documentation. All this will be included in the v0.10 release, which I aim to get done mid/late this week.
This is very cool! Is it correct to say that if we need to stabilize a significant portion of procedural macro, we need to stabilize a portion of compiler internal APIs? If so, how do we determine the API surface, and will it impact future compiler improvements?
I don't think r/jazz would appreciate it. I suggest the OP should claim r/playjazz.
Thanks, it looked wrong to me too! I'll try to submit a bug for the CLion plugin if they have a public project.
Given that we've already sunk some complexity cost into what can be described as const-value dependent types with RFC 2000 (const generics) I think that the natural continuation is to break the runtime barrier and add runtime-value dependent types (or just "dependent types") to the language itself (no external tooling needed) as well as some refinement typing sugar (e.g. `{ x: T | p(x) }` on top for the sake of ergonomics. This might also fit well in with the idea of dependent lifetimes such as noted in [Things Rust doesn't do well](https://medium.com/@GolDDranks/things-rust-doesnt-let-you-do-draft-f596a3c740a5). My experience with design-by-contract languages has not been all that good; I especially felt that writing in Dafny was an uncomfortable experience.
No, I don't even know that website :D
Note: I don't know how to integrate traits and async/await. You'll have to fix up those parts. You'd have a Worker that is generic over some message handler. struct Worker&lt;Handler: MessageHandler&gt; { // channel endpoints here handler: Handler, } The MessageHandler trait contains the handle method and a way to get the initial version: trait MessageHandler { type State; fn new(initial_state: Self::State) -&gt; Self; async fn handle(&amp;mut self, msg: Message) -&gt; Result&lt;Message, Error&gt;; } The Worker impl contains the boilerplate: pub fn new(initial_state: Handler::State) -&gt; Self { let (tx, rx) = mpsc::unbounded(); Worker { incoming: rx, my_addr: tx, handler: Handler::new(initial_state), } } pub async fn run(mut self) { loop { let (msg, ret_addr) = await!(self.incoming.next()).unwrap(); let ret_msg = await!(self.handler.handle(msg)); ret_addr.send(ret_msg); } } And a handler impl contains the actual logic: struct StockWorker { max_seen_price: u64, } impl MessageHandler for StockWorker { type State = u64; fn new(max_seen_price: u64) -&gt; Self { StockWorker { max_seen_price } } async fn handle(&amp;mut self, msg: Message) -&gt; Result&lt;Message, Error&gt; { match msg { Message::RequestStockPrice =&gt; { let p = 100; // let p = await!(get_stock_price_from_net()); if p &gt; self.max_seen_price { self.max_seen_price = p; } Ok(Message::Response(p)) }, Message::RequestExecuteStockTrade =&gt; { let profit = 6; // let profit = await!(do_the_trade_from_net()); Ok(Message::Response(profit)) }, _ =&gt; panic!(), } } } 
Thanks for the feedback, really appreciate it. Some good points. I'll do a version without oneshot and see how it performs, and I'm going to rethink some of the choices made based on your feedback. It's clear it's still too low level from the comments so far. Thanks 
There are multiple levels on which this is inappropriate on this subreddit.
&gt; Once you get used to it And this is what is being addressed: getting new learners to understand what's going on without having to trial-and-error mental models of the borrow-checker based on blind grasping and reading and interpreting error messages.
That's a weird-ass political compass.
An alternate explanation is "More people are interested in learning X, it must be gaining in popularity". I'm not interested in playing whacamole with the goalposts around your definition of "picking up speed". That being said, `clang`'s monthly commits have been [declining for years](https://i.imgur.com/O5tdxtD.png), and `gcc` has [been stagnant](https://i.imgur.com/er1vPjL.png). The raw data I used from git logs (collated by month) can be found [here](https://pastebin.com/bXnQh2Xq). For "improvements of the language itself", that's hardly worth arguing about as it's entirely subjective. 
Hi guys! Picked a ,,The Book'' today and installed rust using the sh script on the website. However, when I try to compile the ,, Hello World'' program, I get an error saying: `error: linker `cc` not found | = note: No such file or directory (os error 2) error: aborting due to previous error ' Hope you guys can help me out!
&gt; regular acyclic tree As opposed to all those cyclic trees out there :P
I know in general isn’t required any complicated system for REST API, most of them are just a few lines of code. The think is I was trying to se how could it work as a pet project and see the implications, saying that ECS in general is better for long/complex tasks that can be split up and run in parallel. Also was interested a time ago into actor model systems, never get deep into it, because didn’t find any real usage in my job/hobby projects, and ECS is something I interested in for game development, but because I’ve more experience with web dev wanted to do some sort of learning experiment. Will try to approach as you pointed out and see what monster comes alive from that :)
I'll do that. Thanks for the feedback. It makes sense.
Yeah, same with C#, that's actually the reason I still can't feel at home with Rust -- it just doesn't have good IDE experience. Having incomplete and sometimes even incorrect intellisense. I know the reason is absence of compiler support for such thing. Therefore I insist that we push this feature as a priority for the 2019 rust milestone!
I never thought about it much before, but the part about community does make a big difference. Out of the dozen or so Rust crates I've contributed to, I've only had one negative experience which was with Servo, so I just don't contribute to that project anymore. Compare that to the dozens upon dozens of negative experiences researching and trying to fix bugs in Java libraries... Pivotal (the company behind Spring) employees in particular seem to lack any modicum of professionalism on Github.
This is the site trying to prevent people from linking to images on their site. You can get around it by putting the cursor in the address bar and pressing enter. This will reload the page with no referrer address.
Sadly, there's a huge amount of work to get to a good IDE experience. 
Unless I'm understanding the `petgraph` documentation incorrectly, the designed-for use pattern is having one graph that gets mutated over the course of your program. For `pgraph`, most changes made to a graph will actually copy the graph and return a new, modified one. The copy is cheap (time *and* space) because of the structural sharing that `rpds` gives me. [Here's a cppCon talk on the topic.](https://www.youtube.com/watch?v=sPhpelUfu8Q) Long story short, if you need a graph to use for one, specific, delimited part of your program, `petgraph` is going to have less overhead than `pgraph`. However, if you have a long lived graph and you want to be able to traverse previous states of the graph, or you need have multiple threads reading the graph (for drawing, maybe?) while its another thread is modifying if for the next time step, the `pgraph` is going to make the clones you need very cheaply.
It was a big part of 2018, and the language server has come a long way this year. It just takes time, it's not that nobody is pushing it as a priority. 
That would explain why I can see it on my Reddit app but not on my PC browser...I'll keep that in mind for next time
Being new to it myself, the concept is strange. I'm starting to follow it, but something like this would be great.
One thing that's really cool about Rust is you don't need a compiler (like JSX) for this. It's using a procedural macro, so the Rust parser only sees the result of the macro. Basically, with Rust, you can import syntax like this much like you'd import a library in other languages.
Even better, we love this kind of thing over in /r/programminglanguages.
It's more that I have a list of projects that I go to when Derek (my PhD advisor) asks me for something an intern could do, and this is on the list.^^ Derek also mentioned he might have a candidate for this particular project already, I am not sure what the latest status is here. But in general, as part of the [RustBelt project](https://plv.mpi-sws.org/rustbelt/), we have paid PhD and intern positions to do Rust-related work in Coq (maybe also in another ITP, but all our stuff is in Coq so that would be strongly preferred).
If you work with HTML day to day, it's typically much nicer to use a template language which is as close as possible. Like JSX. There is also a lot of value in just copying an already popular approach.
If you have the wrong nightly, it won't even build, and if you changed the nightly since building, it will not start. So there'd have to be a wrapper using only stable Rust to do that check. Might be possible, not sure. `cargo miri` might not even need nightly itself, it just spawns `miri` as a separate process, so maybe `cargo miri` could be that wrapper. However, our current plan is to make "miri-preview" a component that you can install via rustup. That's even more convenient, and the dev-tools team has said they are open to this idea. :) We "just" need to automate the libstd building with xargo a bit more for that, which I hope to do this month.
I've been writing [an SDK for the PlayStation 2](https://github.com/ZirconiumX/prussia) from scratch. I'm almost at the stage of drawing my first triangle! I've also been goaded into writing a barebones PS2 BIOS so you don't need to dump your PS2's BIOS. This should make emulation start a bit faster, but also reduce the cost of developing for the PS2.
Ran into similar with Jade/Pug. Copy-paste had it's advantages. In the end though, I still often would convert the HTML to Pug with an online tool and massage it into my existing Pug code. In JavaScript, management of HTML code was easier with minimal time investment for Pug. I'm unsure how you could do similar in Rust though. I tried other HTML templating languages for JS and would near always drop them for some reason or another. Pug's the only one that stuck. That said, I would like to see Pug parsing made available to Rust.
Persistent data structures are great, indeed. Thanks for the comparison!
I loved it— thank you for streaming! I've followed you on Twitch so hopefully will catch you live next time. Have you built anything with tokio on stream? 
&gt; I was thinking the transmute more specifically would be from &amp;'a mut HashMap&lt;i32, Box&lt;Foo&gt;&gt; to &amp;'a mut HashMap&lt;i32, &amp;'a mut Foo&gt; -- as were you, right? (There not being much other choice?) Hm, didn't think much about lifetimes as they do not matter for UB. They do matter for what the client can do with the `HashMap` though, of course. But yeah, even if the lifetimes are the same, if the client has something at a longer lifetime that'd break it. (For example, `&amp;mut Box::leak(Box::new((1, 2))).1` -- this has type `&amp;'static mut i32` but you better don't transmute it to a `Box`.) &gt; I have a hard time thinking through whether or not the borrow checker would reject the "insert some other &amp;mut" The following breaks your transmute: ```rust fn counterexample(x: &amp;mut HashMap&lt;i32, Box&lt;i32&gt;&gt;) { let x = your_transmute(x); let evil = &amp;mut Box::leak(Box::new((1, 2))).1; x.insert(1337, evil); } ``` &gt; would this "special tag" for Box have to exploit the compiler's special knowledge of Box? Yes, that is precisely what I did now. &gt; Could it work with a re-implementation (as far as possible) of Box using unsafe library code? Does it imply the latter would have to be defined in a particular way for it to be sound? Hm... one *could* maybe use `&amp;'static mut T`. I am not sure if I want to recommend that, it violates some other principles I want to uphold, but I think in the current model it would work (because lifetimes don't matter). &gt; On a possibly unrelated tangent, but since this reminded me... there was some brainstorming a while ago about allowing "self-referential structs" to be expressed in safe code I think the part you mentioned is not the interesting part about self-referential structs. In ``` struct Foo { x: i32, y: &amp;i32, // points to x! } ``` the interesting field is not `y` but `x`! For why we "just" have the problem of not having the right lifetime, so we have to lie and use `'static`, but that's not the worst of it. For `x`, we are entirely not even saying that it is currently borrowed! We'd want something like ``` struct Foo { exists&lt;'a&gt; x: Borrowed_for&lt;'a, i32&gt;, y: &amp;'a i32, } ``` to tie the two together, and the `Borrowed_for` is what IMO is most critical with these proposals. But you *did* remind me that I should test Stacked Borrows with self-referential generators...
The IntelliJ Rust plugin works very well. Better than RLS.
visualising the borrow checker would be nice, but the community should probably focus on getting the core IDE features - and compile times - as good as possible. regarding interactive visualisation, imagine leveraging the type inference for something like haskell holes.. 
Don't forget /r/jazzjerk
Yes rls integration with vscode still seems to break all the time and is buggy af, two years after the 'year of the developer' push.
Except for it's non standard formatting and slower than eclipse sometimes.
Reindexing. Reindexing. Reindexing... Their Scala editor has been pretty bad though...
I'm on phone so don't want to look but be5invis on github has a repo which has font for source icons too if I remember correctly. 
Hey thanks for the crosspost! Re: The HP being initialized at every binary start. Ya this is something I thought about and being very new to Rust I wasn't sure the most appropriate way to solve this. I found lazy_static almost immediately and just kinda ran with it. I also looked into PHF (https://github.com/sfackler/rust-phf) but that required an extra build step that I didn't feel like adding. Anyways I would love to know if there is a more performant way to do this, or just a way that feels most Rust-like! e) Ya you're right they aren't really a 1-1 comparison! Maybe I'll give the Rust one a but more beef and run the comparisons again! (Though I fully expect it to still blow bash and vimscript out of the water lol)
What do you mean by "source icons"? Would always be down to add more fun icons to my setup! I'm currently using a NerdFont patched font for this: https://github.com/ryanoasis/nerd-fonts I'm currently using the patched Hack font for my terminal Ooh unless you mean for my blog, and then yaaa. I thought about trying to add a patched NerdFont there too but didn't get to it this weekend! Thanks for the reminder! 
I'm not sure what the target audience of this post is, but if it's not just notes for your own consumption, please do a double-check before publishing. A lot of code in there will not compile, and also some info in the prose is wrong (e.g. integer literals not allowing for a `u8` suffix). There is also a few conceptual inaccuracies (e.g. around tuples) but these are much more nuanced.
I have also IntelliJ IDE and VS Code. Both sometimes mark something as "wrong" when the compiler say otherwise. Remember, the compiler is the actual "source of truth". IDEs/Editor plugins sometimes get stuck in a wrong advice (I have this behaviour on me on almost all IDEs/editors I have used, but much more in recent times). So, as long the compiler say is fine, then is fine.
It means a lifetime ends at the last place it is used instead of at the end of scope.
What operating system are you on? If you type `which cc` in a terminal, what does it say?
You are looking for r/playrust.
I'm afraid this let v2:vec&lt;i32&gt; = []; does not compile: the capitalization of `vec` is off. and `[]` is an empty array which is different than a vector. Nor will it produce the same result as `let v = vec![];` - a compiler might infer a different type than `i32` for `v`, depending on how you use it elsewhere in the code.
Yes indeed! In fact, many of [my past streams](https://www.youtube.com/channel/UC_iD0xppBwwsrM9DegC5cQQ/videos) have built stuff using tokio. [This video](https://www.youtube.com/watch?v=mMuk8Rn9HBg) might be a good place to start.
I think this is heavily driven by the language. Some languages prioritise ease of compiler analysis. Some... don't. There were already multiple highly-competent Java IDEs by around 1999, despite pretty much all development having started from scratch. I'm really hoping the Rust IDE support gets up to a good level, but TBH having a slow compiler does tend to correlate with poor support.
Very nice, but it's unfortunately not what I need, I'm going to have to write my own serializers in my case.
How do I document generic type? For example, it seems like I can't do this: pub struct Tally&lt;T, C = u64&gt; where /// Candidate type. T: Eq + Clone + Hash, /// Count type. `u64` is recommended, but can be modified to use a /// different type for counting votes (eg `f64` for fractional vote weights). C: Copy + PartialOrd + AddAssign + Num + NumCast, { running_total: HashMap&lt;T, C&gt;, num_winners: u32 }
Damn, how did we not hear about this? Can you guys post to https://skgtech.io/ next time? I'm sure plenty of people would have liked to attend.
I haven't used mdbook so not 100% sure about the differences except that mdbook has Rust playground built-in. For the book theme to work, I would recommend copying the templates + sass into your project rather than using it as a theme if you are planning to have a mixed site.
I'm pretty sure I've seen a proof of concept of exactly this actually working in an editor some time (maybe two years) ago. What happened to that?
Not that GUIs don't have their advantages, but this particular feature can work just fine in a TUI IDE.
Rust icon, cop icon, Java icon 
Scala is a great language too. Held back by a lack of decent ide. I don't want to be a doomer but rust needs and ide if it wants to be a massively used language. And I say this as a vim fanatic. 
I'd probably make a type for that, e.g. /// Count type. `u64` is recommended, ..... pub type TallyCount = Copy + PartialOrd + AddAssign + Num + NumCast; And then make my struct/type's where clause use that type. 
Does anyone use rust-lldb? I'm trying to get a tuple of of u8s to print out in hex. Currently, it's interpreting whether the u8s are valid ASCII and if so, printing out chars.
I had the same issue over a year ago with Avast antivirus on Windows. The same file and also some other exe file from llvm (or lldb?) were detected as malware.
Hi all, Are there any examples of testing Rust entirely offline, no proxy, no VC++ build tools? Alternatively, does anyone know a fix for the libcurl issue when using HTTPS_PROXY environment variable? &gt; A requested feature, protocol or option was not found built-in in this libcurl due to a build-time decision
We posted it on reddit. Also, we can't really post on every websites of the world (even less if we don't know about it)...
&gt; But yeah, even if the lifetimes are the same, if the client has something at a longer lifetime that'd break it. Waait... isn't the point that `&amp;mut` lifetimes are invariant so you need something with the *same* lifetime? Am I misunderstanding what invariant means? Or wait -- is the confusion I have fallen into that `&amp;mut` has both a lifetime parameter and a type parameter, and it is *covariant* in the one and invariant only in the other? &gt; Yes, that is precisely what I did now. (While this is much better than nothing, needless to say I think the use case for doing this with library-defined smart pointers also exists...) &gt; but I think in the current model it would work (because lifetimes don't matter) Ah I see. I remembered some similar-sounding soundness issues having come up in the past of "lying with lifetimes" (I think it was w.r.t. `Ref`/`RefMut`), but apparently that must have been under the *previous* model. &gt; For x, we are entirely not even saying that it is currently borrowed! Yes, this question was bothering me which is why I chose to just link to the existing threads instead of trying to give an example myself. :-) I think most of the examples other people have given employ some kind of punning between the field name and the lifetime, so that by re-using the name of the field you also indicate that it is borrowed for that lifetime. But of course this is not "fully general". But for expressing `Box` in this is way I think it doesn't matter, since the thing that is borrowed-from is not another member of `Box` but the heap allocation itself. Incidentally... I just yesterday got around to looking at the "Linear Regions Are All You Need" [paper](http://www.cs.cornell.edu/people/fluet/research/substruct-regions/) (which has been in a tab for some time:) and it sounds like they in fact express things in some way that's similar to this: &gt; Unique pointers are essentially lightweight, dynamic regions that hold exactly one object. To ensure soundness, both dynamic regions and unique pointers depend upon a notion of linear capabilities which must be carefully threaded through a program. To alleviate this tedium, Cyclone provides convenient mechanisms to temporarily “open” a dynamic region or unique pointer and treat it as if it were in a freshly allocated, lexically-scoped region. Sure sounds a lot like "opening" an existential lifetime...
I think this answer could be useful to you: https://stackoverflow.com/questions/47221811/cargo-ssl-download-error-behind-proxy-on-windows I'd also open an issue for Cargo. 
Check out this role in San Francisco: [https://blockchain.works-hub.com/jobs/rust-engineer-in-san-francisco-united-states-of-america-3a18b](https://blockchain.works-hub.com/jobs/rust-engineer-in-san-francisco-united-states-of-america-3a18b)
Currently on GalliumOS, a Linux distro for chromebooks. `which cc` returns nothing.
Technically it's a bug in the software if it breaks when the path includes spaces, but of course you can work around it by removing the spaces.
Is there a chance of a macro interface that takes any string or file as input and outputs an AST? It would remove the current syntax limitations.
\`type\` is basically an alias, and will work as you would expect for substitution.
Like others have said, you will likely have to do all the serialization yourself. There is a utility crate I've used before called [bitfield](https://github.com/dzamlo/rust-bitfield) that helps out a bit with the bitwise operations. I included an example below. For deserialization [nom](https://github.com/Geal/nom) is good at bitwise parsing. It has a bit of a learning curve but once you get it down you can make some very powerful network parsing functions. #[macro_use] extern crate bitfield; use bitfield::{Bit,BitRange}; bitfield!{ struct MyNetworkStructHeaderBits(MSB0 [u8]); } struct MyNetworkStructHeader { field_1: u8, //2b flag_1: bool, //1b flag_2: bool, //1b flag_3: bool, //1b flag_4: bool, //1b field_2: u8, //2b optional_field_3: Option&lt;u8&gt;, //8b or None payload_length: u16, //16b } fn create_my_network_struct_header(user_payload: &amp;[u8]) -&gt; MyNetworkStructHeader { // create an arbitrarily valued header and return it let header = MyNetworkStructHeader { field_1: 0, flag_1: true, flag_2: true, flag_3: false, flag_4: false, field_2: 2, optional_field_3: None, payload_length: user_payload.len() as u16, }; header } fn pack_my_network_struct(header: &amp;MyNetworkStructHeader, payload: &amp;[u8]) -&gt; Vec&lt;u8&gt; { let mut ns_bits = MyNetworkStructHeaderBits([0; 4]); // our header is max 4 bytes long ns_bits.set_bit_range(1, 0, header.field_1); ns_bits.set_bit(2, header.flag_1); ns_bits.set_bit(3, header.flag_2); ns_bits.set_bit(4, header.flag_3); ns_bits.set_bit(5, header.flag_4); ns_bits.set_bit_range(7, 6, header.field_2); let mut bit_pos = 8; // now we need to keep track of where we are for the optional parts of our header if let Some(val) = header.optional_field_3 { ns_bits.set_bit_range(bit_pos+7, bit_pos, val); bit_pos += 8; } // set the length bits ns_bits.set_bit_range(bit_pos+15, bit_pos, header.payload_length); bit_pos += 16; // now throw it all into a new vec let mut final_payload = ns_bits.0[..(bit_pos/8)].to_vec(); // and then attach our payload final_payload.extend_from_slice(&amp;payload); final_payload } fn main() { let payload_vec: Vec&lt;u8&gt; = vec![1, 2, 3, 4]; let mut network_header = create_my_network_struct_header(&amp;payload_vec); let packed_struct_no_option = pack_my_network_struct(&amp;network_header, &amp;payload_vec); assert!(packed_struct_no_option.len() == 7); println!("No option: {:?}", packed_struct_no_option); network_header.optional_field_3 = Some(42); let packed_struct_with_option = pack_my_network_struct(&amp;network_header, &amp;payload_vec); assert!(packed_struct_with_option.len() == 8); println!("With option: {:?}", packed_struct_with_option); } 
[Nice catch](https://phaazon.net/media/uploads/gravity_dog.jpg).
Indeed :) And r/compilers would appreciate any "innovative" compiler or interpreter strategy created for the purpose.
https://github.com/lark-exploration/lark/blob/master/samples/challenge1.lark it looks like a new programming language, I doubt it has anything to do with Rust beyond the fact that it uses Rust.
Ah, I assumed the issue was with cargo since the build of libcurl used in rustup (supposedly) supports proxies: https://github.com/rust-lang-nursery/rustup.rs#working-with-network-proxies. Can you try using a lowercase environment variable? It might make a difference in the mingw environment... There are also the standalone installers, which may work for you: https://www.rust-lang.org/en-US/other-installers.html#standalone As mentioned they "come with rustc, cargo, rustdoc, the standard library, and the standard documentation". This is "the full system", i.e. what is installed by default by rustup. For extra things, like tools (rustfmt-preview) and cross-compile-targets you can try downloading manually from https://static.rust-lang.org/dist/index.html, but I haven't done this before so I can't help much.
Oh gotcha! Awesome, I'll look into adding support for more icons sometime soon! 
Macros is one of those things in rust I haven't ventured into yet; they are a little intimidating. Any recommendations for learning resources (other than the rust book)?
&gt; The RLS is a big strike against the whole 'rust is reliability' talking point. &gt; hehe depends if it crashes, or *panics* rust only promises that it won't allow dangerous memory corruption, not that the programs will always work.
That is definitely an interesting idea! I'm my use case I usually have between couple dozens and tens of thousands of files to loop through, in a single executable call. I assume that for the smaller set sizes a binary search would be faster! I wonder if for my larger directories, the hash map will be faster since the constant time lookup for that many files may beat out the one-time initialization penalty. I wonder if lazyily filling the HM with just the extensions that were used (and having it act as a cache would he a good mix of both) That way if you are looking up the same symbol you get the HM speed, but don't have to pay the full instantiation penalty for small lists! 
Actually, I have the opposite opinion. Dependent types would significantly add to the complexity of the type system, complexity which would likely surface in part of `core` or `std` if they are intended to be used in domains where static verification is necessary. Unfortunately, this burden of interface would then impact *every* user, when most users are not in fact interested by static verification. Now, this is Rust, so someone may come up with an idea to make it possible to have a two-layers language depending on whether static verification is intended or not or otherwise have a way of painlessly using dependent types, etc... In the absence of such innovation, however, an annotation-based method supporting *external* annotation has 2 benefits: 1. Casual users are not impacted, at all, by the compilation checks. They may choose to opt-in into the run-time checks (for example in Debug builds). 2. Using external annotations, a 3rd-party dependency API can be *enriched*, allowing the use of 3rd-party dependencies for which the author didn't provide annotation suitable for the (current) plugin. The latter point, notably, allows multiple plugins to use various annotation systems without having to clutter the code to support *all* annotation systems; or even if a single annotation system, allows working around the limitations of one particular plugin. I find it a more pragmatic approach. I will also admit having never used such a system before ;)
Can you post the source for prompt_password_stderr? 
The problem is that when you call `cat data.txt | your_program`, `stdin` is not connected to the terminal anymore - it's _only_ fed with `data.txt`, and your input doesn't get there. What you _can_ do is instead, read `/dev/tty`. This file always represent the input/output of the actual terminal, not the stdio pipes.
Asked last week but got no love. I'll try again. I'm working with openapi yaml files using [the Openapi crate](https://github.com/softprops/openapi). In the content you can use a $ref key as the example below to indicate that you want to use the definition/param of somewhere else in the file. Resolving the reference is basically copy/paste the referenced piece in the place where is being referenced. I want to resolve all the references first, then later work with the result so I do not need to be resolving everywhere in my code. This is a very nested structure. As an example. definitions: Country: properties: regions: items: $ref: '#/definitions/Region This is modeled as a bunch of Option&lt;BTreeMap&lt;String, SomeOtherStructure&gt;&gt; Ideally I can iterate and modify in place. But I can't make it work. Probably is illegal in Rust. I've tried copying it first to other structure but BTreeMap does not implement IndexMut so to me is difficult also to accomplish. I don't care if the process it is inefficient. Any other idea?
EOF isn't really a character, it's a way to indicate that there is nothing left to read. So by definition, if you reach the end of the stream there can never be anything afterwards?
"unexpected end of file" is the full error message. rpassword is from [crates.io](https://crates.io). The function I am using above can be found [here](https://github.com/conradkdotcom/rpassword/blob/0f53841d6bab225b36b635cab9d5c8bb3cb9619f/src/lib.rs#L73).
Cool, I was looking at Maud the other day. I was wondering if it can be used with async/await syntax?
Finally getting [graphql-client-web](https://github.com/graphql-rust/graphql-client/pull/174) merged, and release a 0.6.0 of graphql-client at the same time.
In your example, are you meaning for id to be the file path given by the upload? 
Honestly using Vim I've found RLS to be pretty reliable (I use Deoplete + Language Server Client). Maybe the client is just really buggy? Try using a normal language server client, which RLS should be conformant to.
Note that `rpassword` has this option already, it is called `read_password_from_tty`.
*Getting* drive-by contributions is also quite nice, even if it's just a one-character typo fix in documentation. Someone out there uses your crate and cares about it enough to nitpick, huzzah!
/r/playrust
Rust Script Xml?
Why not both? The community is a finite size, sure, but the people who optimize compiler performance and the people who make shiny IDE plugins aren't necessarily the same.
I now configured CodeLLDB to use `rust-lldb`. However, I still cannot step into std - vscode looks for the stdlib code in my crate root: * When using stable, it looks for the file (for example) `$CRATE_ROOT/libcore/cell.rs` * When using nightly, it looks for the file `$CRATE_ROOT/$GITID/libcore/cell.rs` (where $GITID is probably the commit id of the build) The most annoying thing is that I need to adjust the sourceMap configuration every time I update nightly.
Are you aware of the BTreeMap::get_mut method? That's very similar to what IndexMut would do, except that you have to handle the possibility that there is no element for your key.
Well, I've got lots of stuff like parenmatching and autocomplete and such, but it never worked quite as well as something like Intellisense. Also, GUI debugging is just this much nicer than GDB, and that's a hill I'll probably die on.
I'm trying to write a function that accepts an Iterator over Items that implement Deref to a `str`. For example, I'd like my function to accept the following input let a: Vec&lt;&amp;str&gt; = // . . . let b: Vec&lt;String&gt; = // . . . my_func(a.iter()) my_func(b.iter()) Unfortunately, I can't seem to get the signature right. I feel like it should be something akin to this fn my_func&lt;S, I&gt;(iter: I) where S: Deref&lt;Target = str&gt;, I: Iterator&lt;Item impl S&gt; { // . . . } Obviously, the above doesn't work. I'd really appreciate any feedback on the correct syntax, or if there's a better api I should be striving for. Thanks!
Short and sweet.
got it
Oh man, that was dumb of me, haha. Maybe RMX -- Rust Macro XML.
Fair enough, I was giving you the main tech website for Thessaloniki, if you're running a closed event or whatever, feel free to ignore me.
That was a really interesting talk. Thanks for the link! `petgraph` also provides [algorithms](https://docs.rs/petgraph/0.4.13/petgraph/algo/index.html) that are (or are going to be) generic over implementation of the graph, as long as it impls the correct [traits](https://docs.rs/petgraph/0.4.13/petgraph/visit/index.html). Maybe you could use that to share work. Why `rdbs` instead of `[im](https://crates.io/crates/im)`? Do you have opinions on the differences?
Making a [game](https://github.com/yaahallo/gameoff) for the github november gameoff challenge as an excuse to play with amethyst and see how close we are to game yet. Incidentally, this project has been very successful for getting my friends to sit down and learn rust, far better than any of my previous attempts at evangelizing. 
Interesting! Well it sounds like there is only one way to get to the bottom of this! Adding it to my list of future blog post ideas! 
I would have expected it to be `&lt;Item=S&gt;` because S would be a concrete type with a constraint that it implements the Deref trait for str.
yea I'm having trouble getting it to work too, mb.
Why is it so slow and how do we make it faster? And how can assembler code in rust be slower than elsewhere? Sorry for being a noob.
Awesome, thanks! Here's the working example with async as well in case it helps anyone else :) [https://gist.github.com/arya1x/d1207a39bf1eb1bdf0702742304b96a5](https://gist.github.com/arya1x/d1207a39bf1eb1bdf0702742304b96a5)
There's an action to run rustfmt. Would be nice to have the option to run it with the standard bind though. It definitely gets slow, especially when you have a lot of dependencies, but last time I tried RLS, it simply didn't provide all the available completions and if it was any faster than the IntelliJ, it was only by a small margin.
Yeah, that will currently fit my use case. Ideally though, like I'd like to be able to use `a` or `b` after calling `my_func()`, and to my knowledge I can't get that to work with `into_iter()`.
Yeah, with NLL a single borrow can end in several places. For example if there are multiple if/else or match branches that use it.
There are currently two different flavors of macros: "normal" macro\_rules macros and procedural macros which are programs running in the compiler that consume and output rust code. In both cases, the way I've best learned is reading what other people have written, and then writing my own using them for reference. For macro\_rules macros, there are a few good introductions out there. Beyond the book there are tutorials such as [https://medium.com/@phoomparin/a-beginners-guide-to-rust-macros-5c75594498f1](https://medium.com/@phoomparin/a-beginners-guide-to-rust-macros-5c75594498f1) and [https://danielkeep.github.io/quick-intro-to-macros.html](https://danielkeep.github.io/quick-intro-to-macros.html). Macro\_rules macros are more limited than procedural macros in what they can do, but are generally easier to implement. &amp;#x200B; For procedural macros, they only recently have stabilized in the general form and there aren't that many resources out there for them. The majority of procedural macros utilize the \`syn\` crate to parse rust code to an AST, then turn it back into a TokenStream. I made this crate by looking at the syn example, then just reading the crate documentation and making heavy use of debug printing. &amp;#x200B; Also, \`cargo rustc --test ref\_return -- -Zunstable-options --pretty=expanded\` is your friend for examining what code a macro expands into. This would have been much harder without that ability. &amp;#x200B; &amp;#x200B;
Did you use the `--release` option to build a release-quality binary for your tests? Rust doesn't optimize anything unless `--release` is passed to `cargo build`
You're a lifesaver. I had a played around with adding borrows but I've never seen the `&lt;'a, S: 'a, I&gt;` syntax before. Mucho gratzi!
&gt; but it never worked quite as well as something like Intellisense True, but there's no reason why that couldn't be implemented in a TUI editor. &gt; GUI debugging is just this much nicer than GDB This can also be done in TUI editors. Debugging with GDB within emacs (that's actually the only thing I use it for) is a breeze, and not any harder to do than within the GUI IDEs I tried.
late reply: IDK maybe I've spent too much _time_ with the borrow checker, but the visualization is just making lexiconal scope more apparent. Which is already blatantly apparent in the `{ }` structure of functions, and match statements. While I welcome newer approaches to teach the topic, I've found approaches which also don't teach writing smaller easier to test functions kind of fail. The borrow checker requires a large re-orientation of developer thinking, and code organization. Often I find it is easiest to start with how callers, and callees interact then building up from there as the borrow checker mostly enforces you can't returned borrowed data _up_ the call stack, and errors _within_ a single function's body mostly come down to writing monolithic methods (which is a commonly encouraged industry anti-pattern). 
&gt; Have you considered supporting additional syntaxes like haml or slim? Haml and Slim use indentation for nesting, which cannot be implemented in Rust macros as the compiler doesn't include whitespace in the token stream. I did refer to them for inspiration though! &gt; Do you support including from files? You can use modules – it's Rust, after all!
That's pretty reasonable for a package manager.
Consider using a lazy static for that.
Ahhh ok. I thought it was the exact same assembler code that was used elsewhere as well. Thanks!
I was not aware, my plan is something like let definitions = self.spec.definitions.clone(); for (name, schema) in self.spec.definitions { for (property\_name, property\_schema) in schema.properties { for (item\_name, item\_schema) in property\_schema.items { if schema.ref\_path.is\_some() { definitions.get\_mut(name).unwrap().get\_mut(property\_name).unwrap().get\_mut(item\_name).unwrap() = &lt;resolve reference&gt; } } } } Which seems super ugly to me. Any better ideas?
And a competitor, poetry.
This may be a dumb question, but I’m curious as to why we don’t require some sort of signing for packages (or make it optional) so we can more easily verify who publishes these crates. I know NPM had some issues with popular packages essentially being hijacked
If you iterate over `some_map.iter_mut()`, you will already have mutable references to the values, so there won't be any need to call `get_mut` in that case. Are you familiar with the `.iter()` vs `.iter_mut()`, vs `.into_iter()` distinction that shows up in most collections? If not, it might be worth re-reading [some chapters of The Book](https://doc.rust-lang.org/book/second-edition/ch13-02-iterators.html). As far as what `&lt;resolve reference&gt;` should do, my guess would be to do a first pass with `.iter()` over all your definitions, where you assemble a separate "references map". Then in a second pass with `.iter_mut()`, you can fill in all the references using that map. Presumably most of the time you're dealing with small-ish files, and using some secondary storage is no big deal, but if that's not true...then you have an interesting problem on your hands :)
Differing content, as in title, statistics based off the title etc. I know hugo has a data source thing where json can be input and it renders based off that.
It's not, it was open and it's sad that some locals have missed it... It's really hard to reach everyone. I hope we'll be able to see you in any future event!
Why not require signed crates and secure second factor authentication? 
A proc macro does not currently offer a way to recover the raw string behind the token tree. It’s a limitation for several tools i tried to make. Here, it means you cannot properly parse macros whose input have significant whitespace. Ideally, a Span should have a .as_raw_str() for that use case.
Ahh I see. Thanks!
anybody aware of a simple workaround for this "bug": [https://github.com/rust-lang/cargo/issues/1197](https://github.com/rust-lang/cargo/issues/1197)
I vote for /r/writejazz for maximum ambiguity.
It’s very complicated. There’s a ton of options. Balancing with user experience is hard. Signing alone is not enough to accomplish that goal. This has been under discussion for years with no clear path forward.
Mostly that nobody has written an RFC for it, and we're already swamped for time
&gt;MT7697 Thank you for the help. I looked into the 7688, but at $15 and the raspberry pi zero W at $10 it's a hard sell. The reason I didn't go for a Pi zero w and was looking at the Air602 is that I will use a bunch of those just to collect data from sensors and send over wifi or receive data and active a relay. A board running Linux seems overkill for that. &amp;#x200B;
I was playing around with something similar, trying to emulate a more Rust-y syntax. It is only an experiment as of now, called [htmlfn](https://github.com/partim/htmlfn). The structure looks something like [this example](https://github.com/partim/htmlfn/blob/master/examples/helloworld.rs). It gets away with a surprisingly small amount of code: just one trait and three declarative macros.
Try: $ sudo apt-get install build-essential
A while ago I had a case where it flagged "use of moved value" because I used a variable twice... for a `Copy` type. Of course it compiled.
Thinking about how to implement UDT support for Variants/safearrays in my crate: [oaidl](https://crates.io/crates/oaidl). Considering using the recently stabilized proc_macro_attribute to codegen the wrapper functionality. 
I am working on type\_level\_values. Today I fixed some things (mostly lifetimes and match ergonomics stuff) for the library to work back to Rust 1.20,and changed how I reexport private items to get around a (reported) nightly ICE. Later in the week I'll be working on adding more defaulted collection methods,starting with filter\_map/FilterMapOp. Would welcome any help with the open issues,especially the type\_fn2 one (haven't started writing about code for that issue),since that one can be done with almost no knowledge about the rest of the library .
Opt-in signing with user-managed keys and grace times for key changes should at least help against high-profile account takeovers.
I'll take a deeper look into `petgraph`, if I can leverage their algorithms, that would be fantastic. I used `rpds` mostly because I saw it first. (I think I just googled "rust persistent data structures." Surprise, surprise, `rpds` came up first.) I think it would be pretty trivial to switch between them but I don't know of any particular compelling reason to do so. If someone has one, I'd be happy to hear it.
I'm working on a fast pure rust implementation of machine-learning tree methods. The long-term objective is to be as complete as Xgboost/Lightgmb. Right now I have a fast implementation of random forest for regression with the handling of missing values. There are so many tricks not documented, it's impressive how complex it is compared to the texbook algorithm.
A procedural macro does `TokenStream -&gt; TokenStream`. To allow for generic syntax such as jsx as input, you'd like `String -&gt; TokenStream`. Then you can use a custom syntax that is not limited to the Rust token syntax. `typed-html` uses `&lt;p&gt;"hello"&lt;/p&gt;` because of this limitation. 
The best way I have found to learn proc macros is to look at examples (there's one in the syn crate), and to read the syn crate documentation as you try to implement things. Also debug printing the output of various syn commands helps tremendously, as does printing the expanded code. As for your other question: proc macros are unhygienic. You may import the other crate in the proc macro's crate to use in the code you write, but the output of your proc macro does not have to only include things known to the proc macro. Self-promotion, but I just created my first proc macro a few days ago [lru-cache-macro](https://github.com/tylerreisinger/lru-cache-macro) that could serve as an example of how one could implement an intermediate-complexity proc macro.
I'm not a proc\_macro expert by any means, and I don't know of any great individual resource, but here are some suggestions: Read the source for a smallish/manageable project using proc\_macros, like [https://github.com/JelteF/derive\_more](https://github.com/JelteF/derive_more). I'm not affiliated with that crate at all, and don't even know if it is good/model code, but it really helped me think about what I want to do with these token streams. Do a lot of panicking on the debug output of a `syn` container. Start with `panic!("{:#?}", parse_macro_input!(item as Item));` to see what you have to work with. You can also panic on your `quote` output to make sure it looks good. Also, for your related question: use the `serde_derive` impl-in-dummy-const hack!: [https://github.com/serde-rs/serde/blob/master/serde\_derive/src/ser.rs#L65](https://github.com/serde-rs/serde/blob/master/serde_derive/src/ser.rs#L65). Doing so lets you bring your parent crate into scope without having to worry about your users renaming your crate. &amp;#x200B; &amp;#x200B;
Thanks for those examples! Re unhygienic: I receive the following error: `error: cyclic package dependency: package `framework v0.1.0 (C:\Users\david\code\wasm-framework)` depends on itself.` when placing the parent and macro packages in each other's cargo.toml as dependencies.
I kind of agree. When I was starting out programming (pre-college a decade ago...) Eclipse was a gateway drug to programming. I wasn't *afraid* of the console, just utterly incompetent. I'm a vim and emacs user now, but knowing younger me I can see why an IDE that let's you install everything you need with a couple of "next" button presses could help drive adoption. C and C++ weren't like this but that's when programming was all Punch cards and terminals. Looking mostly from the outside I think there's enough interest in the safety of Rust over C and C++ to prevent doom. And also that there's enough of the language in flux that creating tooling is a moving Target (but that's an uninformed view).
yeah, smallish files. Thanks so much. Will experiment!
As a compiler writer, your moving target point doesn't apply since 1.0
I’m using Pest, which includes grammar files with a (procedural macro? A #[] declaration, not sure the name); when the grammar alone is changed Cargo does not recompile the library, nor the source of anything that depends on it. I’d like Cargo to do this - and I’d rather not have to write a build script just for that purpose. How would I go about this?
I submitted fixes to the Close Captioning of [this rustfest talk](https://www.youtube.com/watch?v=11Bme1xw0ag) about two month ago (Youtube auto generated ones were highly confused by the name of the library). It seem to not have been reviewed/accepted. Is there anyone to ping ? Not that I'm in a hurry but more thinking that owner of the youtube channel don't particularly pay attention to notification but accessibility is important...
Wrong subreddit. you want /r/playrust
We're no longer living in the 90s. Breaking in the presence of spaces in file names is a pretty embarrassing bug of the software, not your fault.
This is probably the 'new complicated but useful thing attracts professionals first' effect.
I think rust's clarity on first read is its unappreciated superpower. I've never been able to read other people's code so easily. Totally agree with the author on that - great post. 
Well, at the very least I'm happy to have helped in the process of debugging a Rust library! I'm pretty terrible with some of the more advanced libraries like Vulkanos -- I'm a second year CS student -- so I tend to generally assume that I've done something wrong, and that assumption is usually a safe one.
I really like that Idea! Any reasons why not requiring it from now on? Anyone publishing a crate should have a valid email address anyway. 
I was thinking a build script check of rust version to make sure it matches the version miri was released for, and also a runtime check at start to make sure that the version of rust used to launch it matches the one it's compiled for. I don't see why a stable wrapper would be needed anywhere? But a miri-preview component would be great and much easier to manage.
huh, I started using vulkano as a second year CS student, now i'm a fourth year CS student. Keep at it.
You always want to phase in a change like this. Especially in this case, since it's requiring authors to do something (verify the address) which wasn't even possible before.
Hey, this could be useful for contacting crate publishers who don't respond to the forms of contact they list in their readmes!
Start by reading this issue from 2014: https://github.com/rust-lang/crates.io/issues/75
Using `for e in v.iter() {}` you iterate over the values o `v` with immutable reference, that mean you cannot change it's value. Using `for e in v.iter_mut() {}` you iterate over the values o `v` with mutable reference, that mean you CAN change it's value. You could change it's value in the range loop because you `v` is mutable and you probably accessing it's values using `v[i]`.
Just a research project. Hoping some of the ideas are useful down the road. If they are, hope to write about them/turn into RFCs/etc.
Full disclosure, cargo maintainer focusing on dependency resolution. Cargo defines a semver compatible range for each dependency. You will build only 1 version of a crate for each semver compatible range. All `1.x.y` version are semver compatible. So from your example, `1.0.3`, `1.2.3`, `1.1.0` and `1.2.1` are all compatible, cargo will pick 1 version to build. Presumably the newest version that is compatible with all the requirements of your dependencies. If you had let's say a transitive dependency on `winapi = "0.2"` and a separate transitive dependency on `winapi = "0.3"` then cargo will bild both of them, as `0.2.x` and `0.3.y` are not semver compatible. (detailed definition elided.) &gt; These could all use the same version but they were set to a hard version by their individual devs and there isn't a way for me to change that. If there `Cargo.toml` has `serde = "1.2.3"` cargo will interpret that as `^` (larger but still semver compatible with) meaning that all of your example transitive dependencies will be coalesced to newest version of serde `1.x`. It is rare and generally frowned upon, but the devs *can* hard pin a version requirement with `serde = "=1.2.3"`, if you have transitive requirements pind to two different semver compatible versions, then cargo will error. (details of other syntaxes, and backtracking resolution elided.) Also you can look in the `Cargo.lock` for the full list of transitive dependencies cargo picked. Was that helpful? What else would you like more details on?
please dont
Note: `1..v.len()` doesn't give you the indices of a vector; `0..v.len()` does.
I'll allow it.
Motivated by u/fitzgen and his usage of the Z3 bindings, I'm getting back to improving them: https://github.com/prove-rs/z3.rs I've also been submitting a number of minor improvements back upstream as well. I'd love to hear from people that are interested in using the Z3 bindings to guide further work on them.
I don't think I am. I'm not suggesting it would be simple or easy or fast to do. I'm saying "naive assembly" in the sense that it's only something that's going to work, not something that's optimized or efficient in any way, just quick to generate.
I think what you're trying to do is '''cargo doc''' no rustup.
Proc macros return proc_macro::TokenStream, which for example can be created with the quote! macro. The contents of the quote! macro is evaluated in the calling scope, so you can do quote!(outercrate::foo()) even though your macro crate doesn't know about outercrate. Have outercrate re-export the macro for maximum convenience, too.
Try adding an empty build script, just `fn main() {}`. When a build script is present, Cargo is conservative and treats every file within the project directory as a potential source file by default, unless the build script prints explicit `rerun-if-changed` directives.
Did you have a look at: https://github.com/vulkano-rs/vulkano/tree/master/examples/src/bin/image ? What's also very nice is: https://github.com/bwasty/vulkan-tutorial-rs
If you mean if the `html!` macro can be called within an async function, then yes. Maud will return a buffer containing the rendered HTML; what you do with that is up to you. Some users have requested the ability to [stream the response as it is generated](https://github.com/lfairy/maud/issues/149), but I'm not a fan of that approach for the reasons I outline on that issue.
This is being added in [rust-lang/rust#55780](https://github.com/rust-lang/rust/pull/55780).
This is haunting.
&gt;The problem is that when you call `cat data.txt | your_program`, `stdin` is not connected to the terminal anymore - it's _only_ fed with `data.txt`, and your input doesn't get there. Couldn't you do: cat data.txt - | your_program to connect stdin after giving data.txt as input? Or am I misunderstanding the problem?
Right, it sounds so easy. But even "naive assembly" is surprisingly difficult to generate, even the most asinine direct translation. You still have to do register assignment, and register assignment on x86 is decidedly non-trivial, because there are relatively few registers to work with (even on x64), and many operations have constrains on which registers to use (e.g. shift instructions *must* use the CL register). You still have to respect calling conventions to and from native code, because many parts of the runtime are implemented as calls into libc or similar libraries. You still have to correctly maintain stack invariants, including emitting correct function prologs and epilogs on platforms that use instruction decoding to implement unwinding. You may also have to emit unwinding descriptor tables. You still have to handle unwinding and drop() call insertion. You still have to implement *all sorts of things*. It's a complex environment. I'm not trying to pull rank, but I've implemented and contributed to a number of compilers, including compilers that were ostensibly very focused (i.e. trying to do one specific set of things), and even those were surprisingly complicated. These are non-trivial undertakings. Yes, it can of course be done. But it's not to be underestimated.
Due to holiday travel I'll have a long time to work on an audio driver API. The end goal is "easy things are easy, complex things are possible" with as low latency as possible. The end goal would be a cross-platform means of interacting with the standard driver APIs and being able to build abstractions on top of it, with as little overhead and hidden allocations as possible to ensure maximum latency. One philosophical question I'm debating is how different driver features are exposed to someone consuming the library. WASAPI is really the wrench in the gears here, since the API is completely sideways in terms of features (sample rate is fixed, yet default input/output devices can have different sample rates, and buffer sizes are exposed in increments of 100ns, not a number of samples!). I don't know if all features should be exposed, or optional features on particular platforms should throw compilation errors, and if that's the case how best to leverage Rust's current semantics for doing so. 
I'm building a \[fixed-size VecDeque\]([https://docs.rs/fixed-vec-deque](https://docs.rs/fixed-vec-deque)) implementation, for use in games mostly. E.g. scenarios where you want to spawn entities every frame, but you don't mind having an upper limit and you'd like to minimize memory pressure. I've also started more actively try to contribute to \[Amethyst\]([https://github.com/amethyst/amethyst](https://github.com/amethyst/amethyst)). A game engine with exceedingly high potential due to it being fundamentally based on a high performance, multi-threaded ECS. \[I held a presentation last week\]([https://docs.google.com/presentation/d/1hvbvhih-Uui9OcX98epW\_D93vWqu2ey8YQxRM8FErS8/edit?usp=sharing](https://docs.google.com/presentation/d/1hvbvhih-Uui9OcX98epW_D93vWqu2ey8YQxRM8FErS8/edit?usp=sharing)) where I talked about me \[taking it for a spin in an asteroids clone\]([https://github.com/udoprog/asteroids-amethyst](https://github.com/udoprog/asteroids-amethyst)).
On vacation this week, so I'm getting back to working on my game. I've started the week by replacing my hand-written text rendering code with the excellent \[glyph-brush\]([https://github.com/alexheretic/glyph-brush](https://github.com/alexheretic/glyph-brush)) crate--just took me \[a couple of months\]([https://www.reddit.com/r/rust\_gamedev/comments/9dv9bz/glyph\_brush\_fast\_ttf\_drawing\_for\_any\_render\_api/e5k6g08](https://www.reddit.com/r/rust_gamedev/comments/9dv9bz/glyph_brush_fast_ttf_drawing_for_any_render_api/e5k6g08)) to get to it. It's a big win: more features and less code to maintain on my end! &amp;#x200B; From here I'm going back to getting some simple "scripting" in my game, a top-down 2D action game inspired by Hyper Light Drifter and The Binding of Isaac. For now I'm looking at a simple approach similar to \[this blog post\]([https://azriel.im/will/2018/10/12/again/](https://azriel.im/will/2018/10/12/again/)), basically using a data file to describe the hit and reaction boxes for each animation frame. I hope to do a bit more, including damage and other information in there. I imagine I'll eventually need to switch from data files to something with support for simple logic, but I hope this will get me going!
 “if you have transitive requirements pinned to two different semver compatible versions, then cargo will error. “ Is there a reason why Cargo won’t just build both versions of the transitive requirement in this case? 
Still, it'd probably get a more enthusiastic reaction in /r/rustjerk/
Ok, I've tried with iter\_mut() but obviously I don't know my rust. This amazing code will fail. : for (_name, mut schema) in definitions.iter_mut() { if schema.ref_path.is_some() { let definition_name = schema.ref_path.as_ref().unwrap(); schema = &amp;mut def_clone[&amp;Spec::json_ref_name(&amp;definition_name)].clone(); } if schema.properties.is_some() { let mut properties = schema.properties.as_mut().unwrap(); for (_property_name, mut property_schema) in properties.iter_mut() { if property_schema.ref_path.is_some() { let definition_name = property_schema.ref_path.as_ref().unwrap(); property_schema = &amp;mut def_clone[&amp;Spec::json_ref_name(&amp;definition_name)].clone(); } } } if schema.items.is_some() { let mut items_schema = schema.items.as_mut().unwrap(); if items_schema.ref_path.is_some() { let definition_name = items_schema.ref_path.as_ref().unwrap(); items_schema = &amp;mut Box::new(def_clone[&amp;Spec::json_ref_name(&amp;definition_name)].clone()); } } } I think the `schema = &amp;mut def_clone[&amp;Spec::json_ref_name(&amp;definition_name)].clone();` line makes it think that schema is used to temporaly store a value but it does not store it in the value from definitions I get a "creates a temporary which is freed while still in use" error.
Beautiful renders!
I rewrote [flamer](https://github.com/llogiq/flamer) and [overflower](https://github.com/llogiq/overflower) (look in the `proc_macro_attribute` branch) and [blogged](https://llogiq.github.io/2018/11/10/proc-macro.html) about the experience.
For an example of a very fast hash implementation in Rust, see [`blake2b_simd`](https://github.com/oconnor663/blake2b_simd). (Full disclosure, my crate.)
Sorry for offtopic question, but maybe you know if there are any plans to separate build-dependencies from regular dependencies? Right now it's not possible to select different feature flags for some crate that is listed both in dependencies and build-dependencies.
With every toolchain you download via rustup the docs get downloaded and built too. So there is no need to add them again. Just run `rustup docs` and it should open them in your browser.
Borrow checker_irl
Even that is a high-level sketch of a design and not an actual design. Even within that space there’s a bunch of options.
Using indices can have bound checking overhead. Use the reference iters when you can for safety and performance. Remember you can use enumerate if you need both the reference and the index.
You seem to be having repeated problems with fundamental issues. What Rust teaching material are you following ? The Rust Programming Language ? Rust by Example ? 
The OS behind it is https://discourse.org
I am started reading "rust programming language ". Most of the concepts in rust i read through. But when i code its not coming to my head.. Now started solving some problems/algorithms with rust. When i started coding the problems,looks like books reading knowledge is not sufficient for me. Am struggling with fundamentals itself. Sorry for asking questions frequently.. I will try to a little more homework. Anyhelp on some books and beginers online tutorial i can start with..(i dont want keep reading the concepts..rather want to code something in rust)
How to delete someone else's post
Although living here since more than 3 years now, I didn't know about that website. Thanks a lot! If I had know about it, I would've added the event there. Next time.
Thanks
Did you install it through your package manager? Try removing rust thst way. Otherwise you can use sudo probably to uninstall it, just put it in front of rustup I think. Normally rust installs into your user directory, not the system ones. So I'm inclined to think you installed it via your package manager.
`rustup` by default operates in your home directory, so it makes sense that uninstalling it won't install a (separate?) global rust install. I haven't ever had rust installed in `/usr/`, but looking at some [old documentation from before rustup existed](https://doc.rust-lang.org/1.0.0/book/installing-rust.html#uninstalling), maybe something like this could work? sudo /usr/lib/rustlib/uninstall.sh ----- For a surefast solution, though, it depends on how you installed rust. I'm 90% this install wasn't using `rustup`, since unless you've explicitly configured it otherwise it will install to `~/.rustup/`. If you installed with a package manager like `apt`,`zypper`,etc. that package manager should be able to uninstall it. If you manually used a standalone installer, like `rust-xxx-x86_64-unknown-linux-gnu.tar.gz`, then it should have installed an `uninstall.sh` somewhere in the lib directory near where rustc is installed. If neither of those is your situation, could you possibly provide more information?
It should, unless they link to a native library.
&gt; When i started coding the problems,looks like books reading knowledge is not sufficient for me. Am struggling with fundamentals itself. So maybe the Rust Programming Language is not working for you. Have you tried going through Rust by Example? Or maybe you can benefit from http://intorust.com/ , which is a series of screen casts that goes over the fundamental concepts. 
Looks like, heres one issue on it but it links to others. https://github.com/rust-lang/cargo/issues/5730
Nice username you've got there
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [I'll just leave this here](https://www.reddit.com/r/rustjerk/comments/9yqzn6/ill_just_leave_this_here/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Huh, odd. You can also join the Slack channel, pretty much all of the tech meetups organize through that (eg the Python meetup I'm hosting on Friday). You can an invite from the site. 
Interesting. https://github.com/swc-project/swc seems to mean it's based on Babel and closure ? Is that right ? Can you tell us more about the goal and context ?
No problem! It looked pretty good to me. Maybe a few places you could simplify a match. I did want to say that many rust programmers will refer to ourselves as rustaceans.
It's rust port of babel and closure compiler where both features transcompiling new-generation javascript to old-days javascript. &amp;#x200B; It's goal is to replace babel. Main benefit of swc over babel would be performance. Webpack with babel-loader disturbs edit-save-refresh cycle because it's slow. You can try it with create-react-app. Even on a fresh project, recompiling takes almost a second and got worse as project get bigger. &amp;#x200B; &amp;#x200B; &amp;#x200B;
[(\/) ๑⚈ Ό ⚈๑ (\/)](https://i.imgur.com/eAUQNJ7.png)
I just found this code: let email = SimpleSendableEmail::new( "user@localhost".to_string(), &amp;["root@localhost".to_string()], "message_id".to_string(), "Hello world".to_string(), ).unwrap(); What is the third line about exactly? I guess this is supposed to be an array of Strings holding only one String? That's what the square brackets mean, correct? But why do I need to send all the others Strings directly and the array via an reference? What's the logic behind this?
You can't do that. The type of variable length arrays (and a fixed length would be very inflexible for the caller) is [T], which is unsized - its size is runtime-dependant. Unsized values can, for the most part, only be stored behind some kind of redirection, for example a reference (borrowed) or a Box (owned). 
As far as I can remember I installed it via the official doc back then. I think it was curl -L https://static.rust-lang.org/rustup.sh | sudo sh
Running \`sudo /usr/lib/rustlib/uninstall.sh\` gives: \`sudo: /usr/lib/rustlib/uninstall.sh: command not found\` &amp;#x200B; &amp;#x200B;
Just added an `OrthographicCamera`: [commit ](https://github.com/wahn/rs_pbrt/commit/dffa1a280e28b517473384e80d68532c9083ef2d) And the docs: [orthographic-camera](https://www.janwalter.org/doc/rust/pbrt/cameras/index.html#orthographic-camera) 
Sorry, but I didn't understand anything you just said. :-( Let's please try this in ELI5 language: 1. The squarebrackets mean that what is being passed here is an array containing 1 String, correct? 2. If it is an array. That makes even less sense to me. An array is of fixed lenght, correct? 3. I guess this field is supposed to be the "TO" email adresses. Meaning the number will be different. Sometimes I only send the email to 1 person, sometimes to 5 persons. 4. If 1 and 2 and 3 are all correct, then how can this be? Should we be using a Vec here?
Note that if you are on Debian-derived distributions, the package name is rustc, not rust.
1. A reference to an array, yes. 2. Rust has the types [T; n] and [T]. The first one is a fixed-length array, the second one is a variable length (and thus runtime-sized) array. 3. Which is why you wouldn't want a fixed length array, exactly. 4. You could use a Vec, yes, but it would impose additional burden on the caller. A reference to a Vec&lt;T&gt; can "decay" (it's called deref-coercion) to a &amp;[T], so taking &amp;[T] as parameter type is the most flexible for the caller.
Ah, darn, hm. Can you poke around in `/usr/lib`, `/usr/share/lib` and `/usr/local/lib` to see if any rust-related directories have an `uninstall.sh` script in them that might be it? Or maybe - what version of rustc do you have installed? You can find it with `rustc --version` and it could give us a better clue as to what version of rustup was used to install it.
OS, I think it means not what you think it means
Thank you! it worked!
/r/playrust
OK so you're obviously a much better Rust programmer than me, but are you 100% sure that there are variable-size arrays? I thought only Vecs ca do that. I just looked it up in the TRPL and it says so too. https://doc.rust-lang.org/book/2018-edition/ch03-02-data-types.html#the-array-type What am I misunderstanding?
No I can not agree with you. The community of r/rust is very kind and helpful. Don't know about r/playrust though... 
sorry! going over there now.
I think it has something to do with their reading disability. We get them here daily. They can't even spot the correct subreddit. They see this subreddit, the colors don't match, the logo is nowhere close to the Rust game logo, yet they still think: "Ahhhhh this must be the correct subreddit!" ;-)
I strongly disagree. As someone who used nothing but C for years (at least professionally) before trying Rust, the borrow checker completely blows up one of the foundational properties of a bracketed language. Now, I'm a bit fore flexible than my peers, but I work with some guys who have been programming in C and assembly for their entire 25+ year careers, and they aren't the kind of people who are going to waste time fighting with the borrow checker- they're just gonna go back to C. Now, a lot of these guys also love their Visual Studio and/or Eclipse, and if a similar IDE could illustrate the borrow checker's behavior, then they might be open to trying Rust.
How about markdown, but as a web protocol
Ahh ok. Array slice. I understand that concept. 1. So line three is basically the first time I created this array? Like a string slice? Meaning there is no explicit "let myarray = ..." and so on? Correct? 2. Also I just found and checked the docs to help me understand: https://docs.rs/lettre/0.7.0/lettre/struct.SimpleSendableEmail.html Now I'm even more confused. So it is actually taking in a Vec? Or is this an example of this decay-stuff you were talking about earlier? Or are the docs just outdated? 
1. Yes. I guess technically it doesn't make sense to take a reference of a value that is never stored explicitly, but I think it's very ergonomical that it works this way. 2. You're looking at old docs. This is the (current) newest version: https://docs.rs/lettre/0.8.3/lettre/struct.SimpleSendableEmail.html
Ah yes of course. I should have spotted this. OK so I'm very close to understanding this. It's interesting that the author of lettre actually had used a Vec and then transfered to a reference to a list of Strings. So one last question and again an ELI5 phrasing: Since vectors (sometimes?) have this "decay problem" there are times when it is better to just use a reference to an array of Strings instead of a Vec? Would that be phrased correctly?
&gt;some things are just confusing Being a noob in regards to the Rust programming language I fully agree!! :-)
It's not a problem, it's a feature! The decay I was talking about can come in very handy: Instead of passing the &amp;[...] in the original code, you can also do this: let to_vector = vec!["foo@bar.com".to_string()]; // Creates a Vec&lt;String&gt; let email = SimpleSendableEmail::new( "user@localhost".to_string(), &amp;to_vector, "message_id".to_string(), "Hello world".to_string(), ).unwrap(); Because a &amp;Vec&lt;T&gt; can be deref-coerced into &amp;[T], which is really just a big word for "can be used instead of". While you should almost never have a function take a &amp;Vec&lt;T&gt; (because &amp;[T] is more general), taking a Vec&lt;T&gt; may be reasonable when full ownership is required, e.g. when storing the values (the SimpleSendableEmail likely stores the receiver list), because they would need to be cloned otherwise. So in this case it was a trade-off between usability (passing all types that "decay" to a &amp;[String]) and performance (having to clone the strings in the new-function).
To all you just wrote: "Ahhhhhhhh ok that makes sense!" :-) I thought this had some underlying memory/performance reasoning. Thanks so much for explaining! I have actually fully understood this now. 
It's not a trait object it's a generic. Trait object would be Cursor&lt;'a&gt; { walk: &amp;'a Iterator&lt;Item = Scalar&gt; } With that you lose the hability to call the combinators like `filter`, `map`… and can only use `next`
Fyi the links to CONTRIBUTING.md and ARCHITECTURE.md at the bottom of the Github page are both broken.
I'll *borrow* this 
There's no (good) way to do that. What you can do is implement a single function, `map_addr` which contains the complex logic, and only borrows &amp;self, which just translates the address into an array index, and then have `map` and `map_mut` functions just use the returned array index.
I know it's not Operating System. I am a PM for lord's sake. 
fyi, borrowing this for my mastodon instance
Oh, and it's a WIP, but you can see a fairly non-trivial proc macro here [here](https://github.com/rbalicki2/smithy/blob/master/packages/smd_macro/src/lib.rs) with it's use [here](https://github.com/rbalicki2/smithy/blob/master/packages/smd_tests/src/lib.rs)
Except the mod comment nobody has hinted on this.. I wonder if people got it really?
Author of the original blogpost here: Thanks, that looks interesting. Although I really wanted to avoid null at all cost. And regarding auto-boxing the values - sure, Rust stands out from the other three significantly.
I might give Idris a try then!
I thought I was in /r/rustjerk tbh
Here's the original `map` fn map_as_mut(&amp;mut self, addr: u16) -&gt; &amp;mut u8 { unsafe { match addr { 0x0000...0x1fff =&gt; self.ram.get_unchecked_mut(addr as usize % RAM_CAPACITY), 0x8000...0xFFFF =&gt; self.rom.get_unchecked_mut(addr as usize % ROM_CAPACITY), _ =&gt; panic!("Mapper not implemented for address 0x{:x}", addr) } } } It can return a reference to two difference arrays and potentially others after I implemented more mapper, ppu, input and such. They're all read and writtern from memory on the NES, but the actual source are multiple.
Citing from that very page: * Transmuting an &amp; to &amp;mut is UB * Transmuting an &amp; to &amp;mut is always UB * No you can't do it * No you're not special
If we allow duplication more we get less resolver errors and more `Expected 'Regexp' got type 'Regexp' did you mean 'Regexp'` (when you try and use the correct type from a slightly different version of the library) errors. There are communities that let only *one* version by each name (Python); there are communities that don't worry about version conflicts (Npn and Ruby I think). The cargo team tried a compromise of this "semver compatible range" thing. So far it works pretty well, tho we are not against discussing tweeking it sum. There is an [RFC](https://github.com/rust-lang/rfcs/pull/1977) accepted, that I am working on implementing that tweeks it to make more things have to match. Once that is implemented and widely used in the ecosystem we may have the data to know when it is safe to build more then one semver compatible version. Even then we would have to decide if it is worth the complexity budgent. (The code being more complicated and the algorithm being harder to explain). All the conversations I have seen so far have felt that strongly discouraging `=` dependencies is overall better than adding complexity to make them work better. But reasonable people can disagree and the discussion can be had.
So we're stuck in analysis paralysis?
Not exactly. That would mean that the work to figure it out had been done but we can’t make a decision. There’s still actual work to do. There’s been a ton of talk but very few actual proposals.
Exciting work! I can't wait to play with it. Any plans for Typescript? &gt;:)
There's [an ancient open issue on the RFCs repository](https://github.com/rust-lang/rfcs/issues/414) about this and [at least one older thread with some promising ideas of a HKT-style solution](https://www.reddit.com/r/rust/comments/2a721y/a_safe_way_to_reuse_the_same_code_for_immutable/) but it doesn't seem like anyone's ever taken a serious stab at the problem. Having a \`Reference : Lifetime -&gt; Type -&gt; Type\` kind and writing functions that are generic over variables \`R : Reference\` seems like the logical way to go but it would require at least a restricted form of syntax for higher-kinded types and I have no idea what the implications would be for the implementation.
A quick and dirty solution will be to move `map` body to a macro and have code like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=37ce873537bd13a192f6ffac45b865d7).
Furthermore ´for e in v.iter_mut() {}´ takes ownership of v, so inside the for-loop you can only change v by changing e. // The following is legal for e in v.iter_mut() { *e = *e +1 } // The following is illegal for e in v.iter_mut() { v[0] = v[0]+2 } If you need to do something like the latter example, then you need to use indexes
That's a good idea. I didn't even thought of macros because I was trying to change the mutability of the reference. I'll probably do it this way. Thanks.
I'm not sure I understand what you mean. Wouldn't the `mut`and non-`mut` methods have to be implemented separately anyway? 
Thanks for the insight! That's the exactly same issue I'm having. I knew others would've had the same problem before because it's such a trivial task, but I couldn't find it. I'll try macros as suggested by others.
Don't worry, you _are_ special, just not in this particular way :)
Vectors are zero indexed, right? Does that mean it should be `0..v.len()-1`?
Neat trick, thanks!
The page was borderline unreadable for me due to the low contrast.
a..b is exclusive b. a..=b includes b.
I did not expect this to be so popular, so perhaps I should make a post about the joys of the PS2 and what I'd like to see from the Rust ecosystems that I inhabit.
I know it's not Operation Systems. I mean Open Source by that.
Remember that the macro is expanding to rust *source* code that will be put into the *consuming* library. That means that the consuming library needs to have an `extern crate your_macro_types` at the top. Then your macro can emit code that references these types, and your proc-macro crate should not actually have a cargo dependency, or `extern crate` line in it. 
In that case you can still use a similar approach: instead of returning a single index from `map_addr`, return an enum which has a variant for each array which the index might come from. Now your `map` and `map_mut` methods just need to handle each variant, and pick the corresponding array. They don't need to know about the actual mapping logic. Depending on how complicated the mapping code really is, this may be simpler, overall but it's of course a trade off.
I don't know if this is what you're looking for, but Jon just made a video which goes quite in depth about the whole ecosystem regarding futures and tokio. I learned a lot from it. https://youtu.be/9_3krAQtD2k
I'm about an hour into this already, but I had to stop it short. there was another great presentation I watched by one of the tokio guys explaining tasks and futures, etc. but this leads into a point I previously made that futures and tokio seem mutually dependent. you can't talk about futures without mentioning tokio, it seems. 
&gt; My point was that "significantly add to the complexity of the type system" has already happened with `const N: usize` so the cost is sunk and the step to `let n: usize` isn't great from the Rust developer's perspective. I am not convinced. The main difference is that with `const N: usize` everything still takes place at the compilation step, so the values of `N` are constrained and known. When `n` comes from I/O, then suddenly it must be validated that it is in range before it can be used as an input: struct SmallArray&lt;T; const N: usize&gt; where N &lt;= 64 { data: [T; N], } fn make_array&lt;T: Clone; const N: usize&gt;(e: T) -&gt; SmallArray&lt;T; N&gt; where N &lt;= 64; fn doit() { let array = make_array::&lt;42&gt;(1); forget(array); } // vs fn make_array&lt;T: Clone&gt;(e: T, n: usize) -&gt; SmallArray&lt;T; n&gt; where n &lt;= 64; fn doit(n: usize) { let array = make_array(1, n); // How do I specify that n &lt;= 64? forget(array); } It seems that dependent typing immediately brings flow-aware typing, as you need a branch, at run-time, to decide whether the value matches the constraints, or doesn't, and to handle the doesn't case. This is not a concern with const generics. &gt; I think we should divorce dependent types from formal verification. That's a different argument altogether, and I agree that dependent types may have other uses indeed. Of course, the two will necessarily be compared when checking the possibilities of *how* to do formal verification. &gt; This also means that if the annotations are optional you cannot rely on them in other parts of your application and thus the system does not compose. This is the main problem with systems such as LiquidHaskell and why I think DependentHaskell is a great idea. I... am not following your reasoning. My point was that with an annotation system, the user can choose to activate the checks in their application or not. This means that the same API can be used casually or formally, whereas with dependent types it cannot and thus the API author has to make a choice... or duplicate the API. You can rely on the annotations if present, at your option, and obviously cannot if not, which means that the author of the API can freely add the annotations without any risk of friction. &gt; What you see as cluttering the code I see as encoding essential invariants and semantics without which readability of the code suffers. I would much prefer to have the invariants stated directly and clearly when doing code review. Note that I was specifically referring to having the *same* invariant encoded *in multiple ways* for use by a multitude of plugins. 
Use mio. Your code will be simpler, easier to understand and maintain. use mio::{unix::EventedFd, Poll, PollOpt, Ready, Token} let poll = Poll::new().unwrap(); let stdin = 0; let stdin_fd = EventedFd(&amp;stdin); poll.register(&amp;stdin_fd, Token(0), Ready::readable(), PollOpt::level()) .unwrap(); 
You can use futures without tokio, but tokio does provide a lot of nice abstractions that make futures powerful. Tokio contains futures which abstract over the mio library, which gives you asynchronous IO. This means that you do not need to implement that yourself. Further tokio provides a great runtime. You don't need tokio, but I don't see why you wouldn't use it when writing a "normal" applications using futures. 
because I just need a subset of futures. and the task system is complexity overkill for what I'm doing. if I had thousands of streams, you're right; I'd reach for tokio. 
my problem is strictly with the semantics/ergonomics of futures, which seems a bit silly when writing it out like this. 
May I ask why you are not using tokio? It seems to do exactly the things you are struggling to do i.e. connect futures with async io
Unless they use a throwaway e-mail address anyway...
Here another loop function :) // print 0-9 (0..10).for_each(|value| println!("{}", value));
thanks for the lead! 
Okay, this laid out the steps of the render cycle pretty plainly for me, and I think I have a basic understanding of what I need to do. &amp;#x200B; I think I'm going to switch back to C++ from Rust because the Vulkan implementation looks nicer there, but otherwise I'm set. &amp;#x200B; This was very helpful! Thank you!
My point was not to use futures or tokio.
you're probably right, unfortunately. 
I've been tinkering on a similar project: https://github.com/evmar/j8t
this is a further abstraction over tokio, so I don't think it's what I'm looking for. thanks for the input though
Implementing `Future` or `Stream` yourself (not just a wrapper around existing `Future` or `Stream` implementations) is hard, and for 90% of the use cases you want to use implementations from crates glued together with combinators. Furthermore, `futures` itself is just an interface, it requires a runtime to work. Runtimes are also hard to implement, and that is why `futures` is so tightly coupled with `tokio` -- as that is the most mature runtime implementation for `futures`. Since you mention that you don't require a green threading runtime, I'm a bit confused as to why you're trying to use `futures`. If simpler threading with channel communication suffices, why not just stick to that?
That's odd, I thought VS code highlighting used the rls, and as a result it should match the warnings and errors as the compiler returns them. 
What kind of operations do you expect of a Stream interface? The only other Stream interface I personally am familiar with is that of Java, which is basically what `Iterator` gives you in Rust.
There is a light-weight executor for streams/futures, it is called [`wait`](https://docs.rs/futures/0.1.25/futures/stream/trait.Stream.html#method.wait). If you build something out of combined futures, you can always just call `wait` on it and let it run to completion.
If you're using nightly that's to be expected: you're using a new compiler version every time, after all. I think you should be able to set the version with a `RUN rustup default nightly-yyyy-mm-dd` in your dockerfile. 
&gt; my problem is strictly with the semantics/ergonomics of futures First of all, I have not watched the video that has been mentioned, yet, so I don't know if this came up during the part you watched... (The summary has 2:24:07 as the "Putting futures in the standard library" section.) async/await! (`async fn`s + `await!` macro in rust core) should only be a few releases after Rust 2018 is with is, after which tokio will be ported. Hopefully that will improve the ergonomics for your use case. (If it does, you could consider using nightly for a while.) Also, there is https://www.reddit.com/r/rust/comments/9wrtgs/asyncawait_status_and_tracking/ from 6 days ago.
If you are looking for a synchronous byte stream interface, https://doc.rust-lang.org/std/io/trait.Read.html might be applicable.
I need the kind of stream that `futures::Stream` looks like. non-blocking io, mostly. I need an Iterator over data that may or may not be there. maybe I could have an `Iterator&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt;` that returns `None` when the buffer is empty. or maybe it could return a `futures::Poll&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt;`. that's why the futures crate attracted me; it _looks like_ what I want, but also subtly isn't. 
If you're adventurous and want to stick with rust, I personally recommend gfx-hal even though there's no real documentation and you have to install it from git. Its API is based on Vulkan and it stays closer to it than Vulkano, so I was able to successfully use it by reading Vulkan documentation and translating vulkan-tutorial.com. Vulkano abstracts away some of the tedium of using Vulkan, but personally I think that dealing with the raw Vulkan or gfx-hal API is actually easier to understand despite requiring a lot more typing. It was much easier for me to understand vulkan's semaphores than vulkano's futures. for example.
needs to be non blocking
&gt; It seems that dependent typing immediately brings flow-aware typing, as you need a branch, at run-time, to decide whether the value matches the constraints, or doesn't, and to handle the doesn't case. Well; we sorta need this to do GADTs anyways (which I'm hoping to do...) so some flow / control-flow aware typing isn't so wild of an idea. NLL is also taking the CFG into account so it's not exactly new? What Haskell does with GADTs is to extend the set of constraints in the context when pattern matching has witnessed a certain constraint, that's basically the same thing. &gt; My point was that with an annotation system, the user can choose to activate the checks in their application or not. This means that the same API can be used casually or formally, whereas with dependent types it cannot and thus the API author has to make a choice... or duplicate the API. My main problem with annotations used by other tools is that the type system doesn't understand these and so it becomes harder to rely on. In particular, if the tool is not present and the attributes have no effect, then you cannot rely on the annotations in unsafe code. At the very least the annotations must result in runtime panics. However, we can apply this reasoning to other parts of the type system as well -- at the other end of the spectrum we have gradual typing which I'm not particularly fond of. Another advantage of dependent typing in-language is that it becomes universal; you don't have several disparate tools that uses attributes slightly differently and bolts different extra type systems onto the language; you have a unified approach which everyone interested in these things understand. &gt; Note that I was specifically referring to having the same invariant encoded in multiple ways for use by a multitude of plugins. That does not strike me as a virtue.
And thank you for an interesting and useful article. :)
&gt; Since these packages are fast evolving, we will be supporting them on a condensed lifecycle with an update cadence that makes sense for the specific package. For Rust, this means that there will be updates every quarter (approximately every 3 months) […]
Thanks, ok. I was hoping not to have to make my own Docker container to use as a runner. Maybe I can find a container with rustup installed. If that's the case, then follow-up question: is there a way I can cache my specific nightly installation from rustup so every build won't have that additional installation time? If it gets installed to `$CARGO_DIR`, then I guess we're good.
Ah, forgot it's a range. Thanks!
It is better to \*not\* emit code that directly references your types in the user crate. Everything breaks if the user renames your crate on import. One workaround is the impl-in-dummy-const hack I reference elsewhere on this post. This lets you have access to your parent crate's types while you e.g. impl a trait. You can also use \`extern crate ...\` inside a function you emit (although the return type shouldn't contain your crate types. Also, your proc-macro crate will probably need \`quote\` and \`syn\` as cargo dependencies, and \*must\* have an \`extern crate proc\_macro;\` (though this is not a cargo dependency).
See also https://github.com/FreeMasen/RESSA
First, you can `apt remove rustc` and in theory it should offer to remove the automatically installed libraries. But second, there's a better approach here. You can install with rustup *without* removing the system-installed rust. Pass the appropriate "force" option to the initial rustup invocation and it'll install anyway. Put `~/.cargo/bin` in front of your PATH in your shell startup files. And then run `rustup toolchain link system /usr`. You'll then have a rustup-installed toolchain and also have rustup aware of the system toolchain, and you can make either one the default. You can then run things like `cargo +system build` or `cargo +nightly build`.
Today I made the fifth challenge of the first set. You meant like that? ''' extern crate hex_slice; use std::io; use hex_slice::AsHex; fn main() { let mut string = String::new(); let mut key = String::new(); let mut counter = 0; let mut dec_string: Vec&lt;u8&gt; = Vec::new(); let mut dec_key: Vec&lt;u8&gt; = Vec::new(); println!("Please enter the string: "); io::stdin().read_line(&amp;mut string).expect("Failed to read line"); println!("Please enter the key: "); io::stdin().read_line(&amp;mut key).expect("Failed to read line"); dec_string = string.trim().to_string().into_bytes(); dec_key = key.trim().to_string().into_bytes(); while dec_string.len() % dec_key.len() != 0 { counter += 1; dec_string.push(0); } for i in 0..(dec_string.len()/dec_key.len()) { for j in 0..dec_key.len() { dec_string[i*dec_key.len() + j] ^= dec_key[j]; } } for _i in 0..counter { dec_string.pop(); } println!("{:x}", dec_string.as_hex()); } '''
You can use a build.rs script to toggle features based on platforms: https://github.com/rust-lang-nursery/compiler-builtins/blob/939cbca6e9d829265d6cf006d3532142a4061cd3/build.rs#L45
Are there any blog posts or more informational posts related to this? It seems like this is just a link to a wasm editor which im guessing is written in rust but other than that theres not a lot of info immediately available from the link.
Yes! We wrote a bunch of docs on what APIs the environment provides, but the landing page experience isn't ideal. The editor is a fork of Mozilla's open source [https://webassembly.studio/](https://webassembly.studio/), except rather than run WebAssembly in your browser, we deploy it to a server, sort of like how [glitch.com](https://glitch.com) works. As for what is written in Rust: the WebAssembly native compiler is built on top of [https://github.com/cranestation/cranelift](http://github.com/cranestation/cranelift), and the server it is running on is written in Rust as well. The WebAssembly runtime is written in C with Rust bindings, but we're about halfway through rewriting it completely in Rust. 
Cool stuff! I edited my comment so there might be a few more points that weren't visible when you started replying.
[Added to the list](https://gist.github.com/pitaj/b32e5d093698b311b793b29c7dab2b88)
[Added to the list](https://gist.github.com/pitaj/b32e5d093698b311b793b29c7dab2b88)
Tokio can run in a single-threaded mode, though, and while it solves the "http server" problem, it can also be a small library for using asynchronous io in general. As I understand it you're looking for an abstraction over asynchronous IO. For better or for worse, the community has centered on futures with a tokio runtime _as that abstraction_. Such an abstraction will need to deal with how the values are coming in, and that needs to be tied to some sort of runtime. No one has made a smaller abstraction than tokio because tokio works for this, there's a lot of effort put into it, and a less-functional alternative would probably have a hard time getting off the ground.
I often find myself writing a pattern like this: pub trait ThingTrait { ... } pub struct ThingData { thing_impl: Box&lt;ThingTrait&gt;, ... } I haven't really come up with a good naming convention for ThingTrait and ThingData. Like, `trait Thing` and `struct ThingState`/`struct ThingData`? `struct Thing` and `trait ThingImpl`? Coming up with good names is hard, are there any established conventions for this?
I think the person mentioning dpkg had the right idea. Since rust packages show up there, that means rust was installed using your system package manager, and should be uninstalled using it as well. I've replied to that comment.
I wrote a [tutorial](https://tinkering.xyz/introduction-to-proc-macros/) a while ago that you might find helpful. There are bits of it that may be out of date, but the general idea should still be instructive. 
What version of the Raspberry Pi in particular are you trying to detect? Different models have different processors (for example, I think the Raspberry Pi Zero was an armv6, while the 3 is armv7). 
Nice usability thing! I will reinstall Debian Rust alongside my Rustup bits. 
sure. so in my case a backing thread is enough of a runtime and doesn't require any global state. I feel like the idea of a future or stream that produces its own values using syscall abstractions absent any global runtime isn't so far fetched. 
Still working on my WASM based P2P Multiplayer Library (using webstd and WebRTC): [https://gitlab.com/BonsaiDen/wrp2/](https://gitlab.com/BonsaiDen/wrp2/) There's already a minimal "demo game" (triangle asteroids like space ships woaaaah!) included and the core library is only missing som additional edge case handling when starting games and state re-sync for specific error scenarios in the p2p mesh. After that's done, it's time to built an actual game on top it :) 
&gt; The size of a Vec&lt;T&gt; for a given T is always the same, independent of the number of elements, because the elements are allocated in a separate buffer. You are refering to this, right?: https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p So one blue and 2 green fields. so 3*4 or 3*8 bytes in total. By the way: What is the difference between the blue and green fields? Just that there is different info contained in those fields? &gt; You cannot pass an argument of type [T] by value, because to do that, you need to know the size of the type at compile time, and [T] denotes all arrays of T of every possible size! So you need to pass a reference instead. Hmmm my brain doesn't get that. What difference does it make if I directly give you a box of chocolates and you don't know how many are in there versus I put the box on a table and say "Hey over there's a box for you with chocolates in it". Either way you don't know if you get 2 or 5 or 100000 chocolates. So why is a reference to something that's unknown OK, but not the direct way?
I'm continuing to work on a vote-tallying library called tallyman. https://github.com/phayes/tallyman This is my first open-source rust crate, so it's been a huge (and rewarding) learning curve. 
Can you show us any code or the actual problem. I cannot seem to see your fork until I unlock the kata, and there is no option for me to use rust to train this. Usually, any additional output should be seen on the left side where the test outputs are also shown.
definitely. thanks!
Right, the `wait` wrapper for a Stream is an iterator, which means it only blocks until the next value is available. Without knowing your use case it's hard to tell what you need but let's say you want to merge two streams of bytes, then you can write: let combined = s1.select(s2); for ch in combined.wait() { println!("Got {:?}", ch) }
This is awesome! Just a quick note about the name though — and naming is hard — but as a German, „Prussia“ with the two ‚s‘ in emphasis has some [unfortunate connotations](https://en.m.wikipedia.org/wiki/Schutzstaffel).
The answers to your questions can be found on the Rust website. In particular [the FAQ](https://www.rust-lang.org/faq.html). 
oh right. cool. I didn't realize. however, I need non-blocking io to read the stdout and stderr during a guide loop
It really depends on your workflow. Release builds can be quite slow. Debug builds can be really fast. Compared to C++? I don't know, you'd need two projects with similar structure and dependencies. Overall, it's in the same ballpark and generally not a problem if you're accustomed to C++ build times. And even if it was a bit slower, it's worth every second IMHO.
C++ will usually be faster. Shout out to incremental builds for significantly shortening recompilation.
Basically, when you call a function, the caller and callee have to agree where and how the arguments are stored, and how the return value is, well, returned. Such a protocol is called a [calling convention](https://en.wikipedia.org/wiki/Calling_convention). In the diagram you linked, the blue fields are the bytes that are actually copied when a value of that type is passed as a parameter. The callee must statically know where the caller put the parameters and how large they are, which without a more complicated calling convention prevents passing parameters whose size is not known at compile time. The green fields can be anywhere in memory; they're just referred to via a pointer or a reference and don't need any special treatment. &gt; Hmmm my brain doesn't get that. What difference does it make if I directly give you a box of chocolates and you don't know how many are in there versus I put the box on a table and say "Hey over there's a box for you with chocolates in it". The difference is that in Rust a reference can actually contain extra metadata about the thing it refers to (a so-called *fat pointer*). In the case of array slices (references of type `&amp;[T]`), they contain *both* a pointer to the first element *and* the number of elements in the slice. So, when passing a slice, you actually say "Hey, there's a box of chocolates over there and it contains exactly six chocolates"! Whereas if you give the box to me directly I must have told you beforehand exactly how many chocolates fit in my hand, and trying to give me more or less would make me very confused.
I don't know about C++. But my project ([https://github.com/sporto/save-up/blob/master/api/Cargo.toml](https://github.com/sporto/save-up/blob/master/api/Cargo.toml)) with about 25 direct deps takes about 15-20 mins to compile if I clear all the cargo cache.
Rust also has incremental compilation enabled by default for debug builds. Had it for some time now. It obviously makes a big difference but might still be slower than C++.
I think this is really useful information and comes up enough where it should at the very least be added to the readme on rustup like here https://github.com/rust-lang-nursery/rustup.rs#working-with-custom-toolchains-and-local-builds 
It does similar things to Python, but is much more strict and solves some problems like runtime versioning and dependency messes. The detailed function signatures etc allow the editor to flag problems as you type. So more thinking up front, but much less problems later on. It also goes places Python won't, like inside your web browser (WebAssembly). Try it with vscode and RLS plugin and budget some time for tutorials.
See that's why I need to think deeper on how to get more contributors. Because there's the ptrace, DWARF stuff etc which can be quite intimidating. Though ultimately things like better tests go along way in helping just cause then I can be sure OSX is working as expected when it gets that far. I might try writing a wiki explaining concepts in an easy way to help people get started. My only thought is how many people look at github wikis...
I really like ruukh's approach (after having used Yew, which has certain [painful](https://github.com/DenisKolodin/yew/issues/350) [issues](https://github.com/DenisKolodin/yew/issues/435)). I also think component state changes should be auto-detected to trigger re-rendering. Halogen does it by leveraging the State monad. I'm curious, have you looked at how [PureScript/Halogen](https://github.com/slamdata/purescript-halogen) does things? After using Halogen in production I would really like to have this kind of convenience and type-safety in a Rust wasm frontend framework. Yew's issue 350 and lack of async-inline support (e.g. being able to ajax calls inline without handling the result in another Msg case handler) is the main reason why it's currently not as nice to use as Halogen. If you haven't looked at Halogen, I'd really recommend it, to take inspiration from it (I recommend looking at the examples at first).
If you have an async future stream you're going to need **some** runtime to poll said stream on your behalf (whether you use Tokio or something else or make one yourself). If you implement Future or Stream for whatever the type it is that you're trying to stream you can then just hand that type off to Tokio (or any other runtime - it's definitely feasible to implement a runtime yourself) and it'll run your work for you. 
You could invest in LLVM. That may introduce unknown-length delays waiting for changes to be accepted and released upstream and/or add complexity to maintaining Rust's LLVM fork. It's a reasonable trade-off. Maybe improving MIR -&gt; LLVM IR would be enough. It's also possible that going MIR -&gt; LLVM IR -&gt; LLVM -&gt; ASM does strictly more work than, say, MIR -&gt; ASM and thus _can't_ be made as fast. And there's the "why not both" option where you have a fast direct-to-assembly backend while the work to improve LLVM goes on. All I know is JAI has both LLVM and ASM backends and generating ASM is faster, which makes me think it's an interesting option for Rust debug builds too. I've since clarified the position in my original post so I'm no longer interested in defending or debating your interpretation of my word choice and the merits of a claim I didn't make. If you'd like to continue discussing the technical topic sans dismissive phrasing like "yet another inadequate toolchain", I'm on board. Otherwise, thanks for the conversation, and take care.
If you puts links to the wiki in prominent places folks will find it I think. 
haven't compared recently and I expect it to be 'as bad' or 'worse', in theory the easier parsing could allow more reasoning about caching/dependancy updates? ... but I seem to recall hearing 'the majority of the time is spent in LLVM' (is that still the case?) 
it really depends on your build system in c++ which is part of what makes this such a difficult comparison. A poorly setup makefile vs well optimized ccache cmake or bazel or w/e could make a large difference on the same codebase.
There isn't a `#[cfg(target = ...)]` attribute. Just `#[cfg(target_arch = ...)]`, `#[cfg(target_os = ...)]`, `#[cfg(target_family = ...)]`, `#[cfg(target_env = ...)]`, `#[cfg(target_vendor = ...)]`. See the [reference](https://doc.rust-lang.org/reference/conditional-compilation.html) for details. Additionally, some of these are more general than the components of the target triple. I think you'd want `#[cfg(all(target_arch = "arm", target_os="linux", target_env="gnu"))]` for the closest config you could have. On the other hand, there's a question of why you are trying to detect being on a Pi. Is it the existence of some hardware? Different configurations of your software? You should probably check for those directly, rather than using a `#[cfg]` attribute. Generally, the different `#[cfg]` options should be used for code that only makes sense on that particular config, and since there's no target specifically for a Raspberry Pi but instead for a class of different armv7 boards, it would probably be better to do runtime detection or use a [Cargo feature](https://doc.rust-lang.org/cargo/reference/manifest.html#the-features-section) to conditionally enable code for different builds.
You can use `Cell`, it's zero-cost. ```rust use std::cell::Cell; const RAM_CAPACITY: usize = 256; const ROM_CAPACITY: usize = 512; struct Foo { ram: [Cell&lt;u8&gt;; RAM_CAPACITY], rom: [Cell&lt;u8&gt;; ROM_CAPACITY], } impl Foo { fn map(&amp;self, addr: u16) -&gt; &amp;Cell&lt;u8&gt; { unsafe { match addr { 0x0000...0x1fff =&gt; self.ram.get_unchecked(addr as usize % RAM_CAPACITY), 0x8000...0xFFFF =&gt; self.rom.get_unchecked(addr as usize % ROM_CAPACITY), _ =&gt; panic!("Mapper not implemented for address 0x{:x}", addr) } } } fn write(&amp;mut self, addr: u16, value: u8) { self.map(addr).set(value) } fn read(&amp;self, addr: u16) -&gt; u8 { self.map(addr).get() } } ```
I do see your point, but it was a word that sounded like "Rust" but had a P and two Ses. Alternative names welcome!
Tasks are a core part to futures. They are how futures are arranged to be woken up at a later date. They aren't specific to tokio or anything.
You're right that this policy will alleviate some need to backport fixes, but not completely. Even on Fedora, where we update every Rust release across the board, you can still see some patch history of things we pull from git master. If it's something we're fixing ourselves, we try to keep upstream first -- get it merged to master, then immediately apply it to our release builds, without waiting for the nightly-&gt;beta-&gt;stable train. We're also building this Rust with the neighboring system LLVM, rather than the bundled one, so that's another aspect for us to stay on top of patches. I doubt we will ever update to "intermediate" versions as you suggest though. The LTS question is hard. If it were *just* a matter of compiler maintenance, I think we'd have no problem contributing directly to that end. The bigger issue is getting the crate community to support such a thing, which was an important part the postponed [RFC 2483](https://github.com/rust-lang/rfcs/pull/2483). If there's an LTS rustc, but most crates have moved on, then it will be hard to use -- especially when the breadth of crates is still growing. How many crates still support Rust 1.22 from a year ago? Rust 1.13 from two years ago? Yet these are short periods to call "LTS". So that's what we're trying to balance here. IMO, our customers will be best served by keeping up with the current compiler, and we'll do our best to keep that stable as we go. I'm sure Rust will eventually get to a place where it's plausible to use a compiler that's a few years old, and then even the more-conservative customers may try it, but we're not there yet.
That looks cool. It might be the solution. Thanks.
yeah, I've seen that part of the video, the simple implementation of the Executor. in my case you can think of the Executor as the gui loop that could potentially poll each stream every frame since there are only two. and if the inner thread is being blocked by the kernel, then I'm not just spinning useless cycles, I assume, except to poll the stream. 
It says in the announcement it will be for official [crates.io](https://crates.io) business only and won't be publicly accessible unless you explicitly also put it in Cargo.toml
My experience is that Rust build times are still substantially slower. For [my current pet project](https://github.com/saethlin/omnichat) debug builds with default settings take 5 seconds. With LLD (which requires nightly and musl target) it builds in 1.8 seconds. The improvement is partly due to improvements on nightly, but for my project the GNU linker is half the default debug build time. The exact comparison between C++ and Rust probably depends on the kind of project. For crates very heavy on metaprogramming (which is much more widely used in Rust) build times seem to explode much faster. The situation is not great but improvements are coming, though YMMV based on project style.
How much slower is accessing a `Vec` (i.e. `Vec::get`) in comparison with accessing a pointer in C (i.e. `pointer[23]`)? Basically I’m asking about the overhead of `Vec`
You're absolutely right in that your first example offers you more control. The limited semantics of subsequent examples are a *feature* -- when I see `for e in v.iter()`, for instance, I immediately recognize as a maintainer that we're just reading through each value. I don't have to keep any context in my mental stack to figure out if we're doing something else -- I just know enough about what it's doing unambiguously from the first line of the loop. This isn't the only interesting thing about iterators, though. The standard methods associated with [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) and convenience iterators associated with [`&amp;[T]`](https://doc.rust-lang.org/std/primitive.slice.html) are incredibly versatile and covers lots of use cases you might not know about -- have a look! Here's a teeny example: one that might cover a use case you MIGHT have modeled with your first example would be `enumerate`: for (i, e) in things.iter() { // do stuff } I've found it rare that I actually need a full `for(size_t i = 0; ....)` like in some older languages.
cool
Thanks for the feedback! I just tested myself with https://color.a11y.com/Contrast/ and I failed on every text color I'm using 🤦‍♂️ Will definitely look into improving that! 
If you need non blocking operations, then you need a task system. They're fundamentally, inextricably linked. Even a spin poll loop will be abstracted as a task system if you want to write even semi-reasonable code.
I've been fighting this off merely by backporting newer versions of Rust to the point releases we maintain. Still hurts when a Cargo crate we depend on decides to require the latest stable features without a second thought, though.
Yes, I believe this is the correct approach for Rust in Codewars. I just wanted to mention that we need more Rust translations of katas on Codewars. I think it's a great site for newcomers to the language to easily play and gain confidence with the language.
&gt; You could invest in LLVM. That may introduce unknown-length delays waiting for changes to be accepted and released upstream and/or add complexity to maintaining Rust's LLVM fork. It's a reasonable trade-off. I would be very enthusiastic about making improvements to LLVM, because those improvements would have far-reaching benefits, far outside of Rust. I realize that it may seem frustrating that LLVM moves more slowly than Rust, but that's precisely because it has broader impact. It would also demonstrate to the community outside of Rust, that Rust developers are interested in making good trade-offs, rather than just reinventing the wheel every time there is a need. &gt; And there's the "why not both" option where you have a fast direct-to-assembly backend while the work to improve LLVM goes on. There's a significant cost to maintaining more than one backend, though. You have to be careful where you spend your complexity budget, and adding another backend, without a strongly positive cost-benefit analysis, seems unwise to me. I would rather put up with slower compilation performance now, and work to improve it, rather than tolerate a large amount of unneeded complexity in the Rust toolchain. &gt; If you'd like to continue discussing the technical topic sans dismissive phrasing like "yet another inadequate toolchain", I'm on board. Please don't mistake criticism of your position (even if you have since clarified your position) as an ad hominem attack on yourself. I believe we have different perceptions of the cost-benefit of your proposal, and everything I have written has been about that, and not about yourself. I do believe that adding a new backend to a compiler *is* an "inadequate toolchain", because it *is*. It's not adequate to serve as Rust's primary toolchain (because it would generate unoptimized code), and because it would be new, it would require a long stabilization time. "Inadequate" is not a dirty word, it is an emotionally-neutral description of the traits of the proposal. 
Prussia is also the name of a place though? Or does no one in the German speaking world call that region by that name since WW2?
I've just been setting a `rust-toolchain` file to use the maximum-supported version required for the point release being supported. That's `1.28.0` for Ubuntu 18.10 and `1.24.1` for Ubuntu 18.04 LTS. If anyone is building applications for Ubuntu 18.04, you may be interested in using our Pop OS PPA, as it has backported `1.28.0` to bionic so that we move forward and support both bionic and cosmic equally without holding back.
This is rust the programming language, not rust the game
This is a subreddit for rust programming language, not game. Doubt you'll find an answer to your question here.
You're looking for /r/rustgame This is /r/rust, subreddit for the Rust programming language
This is the reason why having a unified build system on a language level is amazing. While C and C++ give you the most flexibility having this separation can be an unfortunate pain-point especially with large projects.
Could linking the system toolchain be automatic if present? I can think of no reason to hide it.
I have a [macro called `const_and_mut!`](https://www.reddit.com/r/rust/comments/77rdve/avoiding_code_duplication_due_to_mutability/doo8sr6) that can help with this in a gross sort of abstract way. You could write: ``` const_and_mut! { [$name:ident =&gt; map/map_as_mut] impl Foo { fn map_as_mut(self: cm!(&amp;Self), addr: u16) -&gt; cm!(&amp;u8) { unsafe { match addr { 0x0000...0x1fff =&gt; self.ram.get_unchecked_mut(addr as usize % RAM_CAPACITY), 0x8000...0xFFFF =&gt; self.rom.get_unchecked_mut(addr as usize % ROM_CAPACITY), _ =&gt; panic!("Mapper not implemented for address 0x{:x}", addr) } } } } } ```
If you get the `ChildStdin` struct from your child processes, you can convert them into raw file descriptors (i32) with the `AsRawFd` trait. Then you can pass those file descriptors to `libc::fcntl` like so: let flags: libc::c_int = fcntl(fd, libc::F_GETFL, 0); fcntl(fd, libc::F_SETFL, flags | libc::O_NONBLOCK); Then you'll get `Err` values for read: println!("{:?}", child_stdout.read(&amp;mut buf)); &gt; Err(Os { code: 11, kind: WouldBlock, message: "Resource temporarily unavailable" }) 
&gt; those improvements would have far-reaching benefits, far outside of Rust Indeed! Improving LLVM has lots of external benefits. No argument there. It's a valuable thing to do. &gt; adding another backend, without a strongly positive cost-benefit analysis, seems unwise to me Agreed! A PoC would go a long way toward showing what the potential benefits are. If my debug builds dropped maybe 10%, it probably wouldn't be worth maintaining. If they dropped _to_ 10% of what they are now, that's a pretty strong benefit I think. &gt; Please don't mistake criticism of your position (even if you have since clarified your position) as an ad hominem attack on yourself I haven't been taking any of this personally; no worries there. In fact I've agreed with most of your assertions. My issue is only when you have been criticizing mischaracterizations of what I said while sometimes suggesting and sometimes insisting that mischaracterization was my actual position.
Oh, I am sorry for posting in the wrong subreddit. I promise this won't happen again.
The kind of `cfg` flags you're trying to use are determined by what the compiler is trying to target, not what it or the eventual binary is running on. That has two implications: 1. You can't specifically detect a Raspberry Pi, because the compiler doesn't target with that much specificity. It'd be like trying to buy a power inverter to plug your laptop into a Ford Focus. The closest you can get is to order a power inverter that takes 12V DC input via a cigarette lighter plug. 2. ARMv8's architecture identifier isn't `armv8` but, rather `aarch64` because the primary feature that isn't backwards compatible with ARMv7 is 64-bit operation.
It wouldn't be too far fetched, but it also doesn't seem like it'd be too useful? You could indeed manage one stream at a time with such an abstraction, but to efficiently handle multiple there needs to be some coordinated way of polling multiple things, right? It could be useful for an application like yours, but I don't think it would have widespread use, and this is probably the reason no one has made one. It seems like it would be strictly less capable than a runtime based one like tokio, and would only have a small advantage? If you feel like this is a thing which needs to exist, though, it sounds like it'd be possible to create and publish as an abstraction.
Just deployed a new version that should have much better contrast! I still have a few issues but I think I need to alter the designs a bit to address them, rather than just adjust the colors. The blog post titles are the biggest issue at the moment still. I like my accent colors, but I don't think they are good for text. So I want to find a new way to use the accent colors elsewhere, so the titles can be more readable. Overall I darkened up the fonts, and I changed the code samples to have a dark background with light colors in the foreground. This fit my accent colors better, and I'm really happy with the results. Again, thanks for letting me know!
I'm a Python programmer who has taken up Rust and I'd say that it's hard to answer your questions simply. &gt; It's similar than python? Because it has type inference and good libraries, Rust feels quite high-level (somewhere between Python and Java or C# in my opinion), but it's not a dynamically typed language like Python, Ruby, Perl, JavaScript, etc. If you write code in Rust, you'll spend more time satisfying the compiler before your code will build, but a *lot* less time tracking down runtime errors and, when the compiler is satisfied, you'll have already written half of what would be unit tests in a good Python codebase. It takes some practice to wrap your mind around how Rust works but, once you do, you'll be a better programmer in *every* language. I'd recommend that everyone learn Rust, even if only for the improvements in how they think about code. &gt; What was it created for? When you need something that can be as fast and efficient as C or C++, but with modern comforts. As for what you'd *use* it for... * Whenever you want something that starts up really quickly (it's good for writing command-line tools) * Whenever you want something that takes very little memory (Rust allocates on the stack by default, doesn't use runtime type metadata, and makes memory allocation easy to infer from the code, so writing memory-efficient code feels easy and natural.) * Whenever you want something that uses a *consistent and predictable* amount of memory (Rust's ownership model, default stack allocation, and lack of a garbage collector combine to make it natural to only hold onto data for as long as you need it. Rust is also big on avoiding hidden costs, so it's harder to accidentally create memory leaks by holding references to data without intending to.) * Whenever you want to write code that is likely to work on the first try. (Rust's type system is powerful and the community likes to find new ways to write libraries that just fail to compile if you try to use them incorrectly. For example, [Hyper](https://hyper.rs/) will give you a "no such method" error at compile time if you try to set headers on an HTTP Request that's already started streaming the body, rather than a runtime error like in PHP.) * Whenever you want to write something which uses multiple threads without stress (Rust checks to make sure you're sharing data between threads in a safe way at compile time.) * Whenever you want to extend another language (Rust is really good for writing libraries you can load from other languages. For example, [librsvg](https://blogs.gnome.org/alatiera/category/librsvg/) is replacing parts of its C with rust to make the code safer and I use [rust-cpython](https://github.com/dgrunwald/rust-cpython) with [setuptools-rust](https://pypi.org/project/setuptools-rust/) so my Python programs can have backends written in Rust for better performance and compile-time checks.) &gt; When rust was created? Graydon Hoare started working on Rust in 2006, but it changed a **lot** since then, so that's not really a useful date to answer the question you're probably asking. Rust 1.0 came out in 2015 and I seem to remember it reaching roughly its modern design within the year prior to that.
Is there a tool for detecting memory leaks in Rust code? I've got some FFI code that I've been reworking the memory management on, and I want to verify I'm doing it correctly. 
The most reliable way is to check the Ethernet MAC at runtime. The Raspberry Pi Foundation has its own reserved MAC range.
I just finished my first non-trivial project in Rust: [a calculator](https://gitlab.com/jrop/rust-calc). After completing this, I am liking Rust a _lot_ more and considering switching to it for all of my personal projects. It really is killer.
Compilers are complicated, so you'll have to benchmark the code to get a precise answer. However in most cases the performance should be about the same. In simple cases the generated code is often almost identical: https://godbolt.org/z/yGR_HW
Note: Must work on Windows. 
The best pattern I've seen is: trait ThingExt {} struct Thing; impl ThingExt for Thing;
What would you call a "one click" IDE? Also CLion is excellent. 
Is there some studies that shows scala was held back by a lack of IDE?
thank you. you have been very exhaustive🤗
[https://drive.google.com/open?id=12Ized8l6CiGZg6vzY5Yo4H36vla6qQe\_](https://drive.google.com/open?id=12Ized8l6CiGZg6vzY5Yo4H36vla6qQe_) I can't see any output in the left window even for such easy example :(. You could try to write translation for any 8 level kata for newbies where unlocking takes seconds :)
&gt;std::io::stdout().flush() [https://drive.google.com/open?id=13lmgihGiDeWeyeKJD4V8rW-noY2gaTnc](https://drive.google.com/open?id=13lmgihGiDeWeyeKJD4V8rW-noY2gaTnc) Same result
Is fastlylabs associated with fastly who supports lots of open source projects?
Mine are rust and Scala. And you're right VS is the platinum standard of IDEs. But in vscode I have to install multiple things and looking up which ones to install. Then set path and what not. All this while needing admin permission. I don't like the situation... 
Xi is an editor... I don't see what xi Cando tomorrow what vim can't today. We literally need an integrated environment
Kudos to RedHat for taking what seems to be a pragmatic and sensible approach. This is quite different to all the whining that went on in that Debian thread and claims of how Rust was going to be no good for “enterprise” distributions.
It depends. Rust performs bounds checking in `Vec::get`, but the compiler can omit the bounds check when it knows the index is always in bounds (e.g loops, iterators). I think in general the overhead is negligible when compared to C with the necessary number of bounds checks, unless you hit some sort of edge case which inhibits optimization.
I strongly disagree. Working with eclipse for ten years now and some other IDEs before in the area of (mainly) embedded gave me the following insights: 1. IDEs hide the building process from its users. I observed lots of newcomers (including me back then) that lack the knowledge of how the code is transformed into binaries by compiling, linking, target configuration etc. because the were forced to use IDEs during studies. 2. Non trivial IDE configuration e.g. for deploying/debugging embedded targets is hard and has to be repeated on every new version of the IDE. 3. Lots of IDEs store their configuration in binary format or automatically generated XML which is a nightmare for version control and team syncronisation.
**Not a rust answer**. I'm also curious about this. My C# project takes 7seconds to rebuild but I think that's because the IDE needs to load things up. Rebuilds after that takes &lt;1econd. The source is 1/2 a mb and &gt;10K lines of code. Builds are in debug mode so no optimizing is going on and I use nothing but the main library. In C++ I know one of my similar projects took 30seconds and had templates everywhere. Taking them out brought it down to a second but IDR the size of it and how it compares to this C# project 
/r/playrust
The one you're using has it installed, check the dockerfile. Unfortunately, they don't offer specific versions of nightly, and you don't want to run that command inside a running container because it will just install another version of rust. 
My problem is solved, but for completeness I tried several variants with aarch64.. and aarch32.. but no joy on the Pi 3B+. I'm not sure what didn't line up. 
In 2021 crates.io will only take submissions from publicly accessible DVCS repos. 
For future reference, once you get things building, it'll have to be one of the architecture names you get from this command: rustup target list | egrep 'installed|default'
&amp;#x200B; &gt;In my understanding, static variable will not be dropped in full lifetime of an application. Correct. &gt;And static type is a type without other lifetime sign. Right? There is no static type - there are static lifetimes. This means if you have some types with different kind of lifetime annotations - they are still the same type. Just the requirement for how long they need to be alive is different. But you're partly on the right track, types without any type annotations have a static lifetime per default. &amp;#x200B;
Build times are much worse than C++. Not ghc-bad, mind, but the slow builds are easily my least favorite aspect of using Rust.
1. You can access the source code of any buílt-in type or function from the documentation via the `[src]` button. If you take a look at `String`'s [source code](https://doc.rust-lang.org/src/alloc/string.rs.html#294-296) you'll see it's just a wrapper over a `Vec`. So no, `String` is not a fat pointer - it's a vector, which means it owns and manages its contents. That's how `String` can work without lifetime annotations - if it could refer to memory it doesn't manage, it could cause all sorts of safety issues Rust is designed to avoid. 2. Cloning a string clones the internal vector, and cloning a vector calls `to_vec` to create a new vector. `to_vec` copies every element into a new vector. It deeply clones everything, because it couldn't work any other way. 3. If you pass a `String` to a function, it copies the stack parts of the vector (pointer to data and length) but doesn't need to clone anything on the heap, because the borrow checker guarantees the function has exclusive access to the `String` when the function call is made.
How do you join text in a Vector in place based on certain conditions? E.g. \["hello", "world \\", "rustaceans!", "how", "is", "everyone \\", "doing?"\] to \["hello", "world rustaceans!", "how", "is", "everyone doing?"\] &amp;#x200B; I tried using the window function but flatten doesn't work on the Vector returned by the window function. &amp;#x200B;
Yes, this is the same company :)
That's a win.
This looks really neat! Has a very familiar Sinatra type feel to it, for this old Ruby dog (: One thing I noticed is that the get and routes macros don't have docs, would be great to see some usage examples in there!
&gt; The idea that you can write your code in a language or language variant that compiles down to JavaScript may seem obvious now, but it's easy to forget how innovative it really is. Barf. There's nothing innovative about having to compile down to another language to work around the fact that we never settled on a proper virtual machine for browsers. There's nothing magical about JS as a compilation target, it's just path dependence that we have had to do such a workaround mess to maybe finally get back to a key characteristic of the early web, language independence. Paul Graham specifically named that as something that made him start ViaWeb, the original web app. That he was finally free to program apps in whatever language he wanted, in his case Lisp instead of being stuck with C/C++ and the Win32 API if he wanted to have customers. Then the frontend became dynamic and for the longest time JS advocates were extremely aggressive against any proposals that allowed other languages than JS to target the frontend. Yes I'm bitter :)
After the vice motherboard article about Rust and now this, it's apparent that Rust is getting outside attention and I think it's highly likely that Rust will have its breakthrough soon, and that we'll see many more Rust jobs in 2019. For everyone who already knows Rust, I recommend learning technologies that future Rust jobs will also require.
&gt;"What makes Rust outstanding is its safety," says the quant developer. "The language is designed in such a way that it checks during compile time that there are no circumstances where the program will be left hanging in uncertain memory conditions." While C++ purports to offer similar features, they can be circumvented by 'developer arrogance' from programmers convinced their code is fine. No. Just no. The only arrogance here is from the "quant" making these kinds of statements. The rest of the article is equally bad, such as unsubstantiated performance comparisons to C++ based on the "benchmarks game". Rust is a great language, but this kind of attitude will make you no friends and give you no followers.
Yeah, the article is not very factually correct, e.g. also: &gt; Unlike C++, Python and Java, which are object oriented programming languages (OOP), Rust is a 'trait-based' programming language. This means that, 'rather than building a structure and giving it abilities like in the OOP world, you need to define the behaviour on an abstract level," says the quant. "You then define this behaviour for particular data structures, therefore separating the data from the behaviour." He says this takes some "relearning" - especially if you're used to thinking in OOP terms. &gt; The extra effort is deemed to be worth it. This portrays Rust's trait system as the part that's hardest to learn, not mentioning the borrow checker at all.. Still, I think the article is a "bullish sentiment indicator" for Rust 2019. If Rust futures were for sale, I'd buy them..
At least a tiny description in English could be useful.
Any thoughts on what those other technologies are likely to be? 
I love(d) Scala and worked with it professionally but from my experience (using it in IntelliJ with the Scala plugin) it was not hold back by lack of a decent IDE. So, personally I cannot agree with all of the premise. If the premise is wrong, one can derive whatever one wishes - ex falso quodlibet. &amp;#x200B; That being said, I do agree though, that a nice out of the box IDE experience is something that could help Rust, especially beginners that are not coming from a C/C++ background but from JS, Python, Java etc. where a good IDE is half your developer. &amp;#x200B; Personally I found Clion with the (ever improving) Rust plugin to provide a very good IDE alternative.
The source code is in English 😁
There are different areas. One area is web server backends, for that I recommend learning Postgres/SQL, Redis, docker, microservices architecture, and other backend and cloud/CI technologies. Another area is cryptocurrencies (many of those projects will fail so it's not clear how long those jobs will last) and cryptography (e.g. there's an open Rust job for Tor, that requires cryptography knowledge). It will take some time until Rust frontend jobs will appear but even for backend Rust jobs, it's useful to know frontend technologies. And I know that e.g. AutoDesk wants to develop a wasm CAD software in Rust, and some other company is writing webgl charts in Rust (can't remember which one, right now).. Another area is gamedev, not sure how many jobs there'll be, since it's not a critical infrastructure for society, but for that you'd need math, physics, graphics, networking skills and probably still C++. Then there's low-level / embedded-like work where you need to be familiar with hardware, optimizations regarding resource usage etc. Finance also requires a lot of math, machine learning / data science, statistical learning. So I'd recommend learning python with pandas etc. Also, it depends what your own interests are, what you want to specialize in.
&gt; There's nothing innovative about having to compile down to another language to work around the fact that we never settled on a proper virtual machine for browsers. It was meant to be Java, but Java and applets had a long list of issues. By the standards of the 90s, Java was a very open platform. By today's standards it's extremely propriety. Plus the experience was horrible, and Sun basically had no interest in making applets a nice experience. &gt; Then the frontend became dynamic and for the longest time JS advocates were extremely aggressive against any proposals that allowed other languages than JS to target the frontend. This is just flat untrue. There have been bazillions of attempts of getting a pre-existing language to compile to JS. GWT, which used Java, was perhaps the most successful. Many also had the issue of requiring a large standard library to be bundled. Hello world programs would run into the megabytes. Why would I want to use say Python, when I have a dynamic language available already? CoffeeScript, LiveScript, and later TypeScript and Flow, were successful because they are just JavaScript. CoffeeScript is almost entirely syntax sugar. So the issues of compiling a pre-existing language disappeared.
&gt; It was meant to be Java, but Java and applets had a long list of issues. As far as I know Java was just applets and not actually scripting the DOM. That was a non-starter for the web. &gt;This is just flat untrue. There have been bazillions of attempts of getting a pre-existing language to compile to JS. That's not what I am saying. There were plenty of people compiling to JS exactly *because* the JS advocates resisted actually getting other languages to be available through a proper VM and DOM access. That still doesn't exist fully today, but Webassembly is getting close. &gt;Why would I want to use say Python, when I have a dynamic language available already? And this was the normal argument. Always of the form "you should like Javascript and there's not reason to like anything else". It's fine if you think that, but a lot of people don't and had no choice. &gt;CoffeeScript, LiveScript, and later TypeScript and Flow, were successful because they are just JavaScript. CoffeeScript is almost entirely syntax sugar. So the issues of compiling a pre-existing language disappeared. And so this was the ecosystem that was allowed to live. Thin layers over Javascript instead of actual choice of languages. In almost any other platform saying you prefer another language is not unusual and no one even cares. For some reason in the web world yours is the normal answer. I personally don't care for the language but it's fine if others want it. But actively forcing other people to use it to access the web platform has put me off web development for the last 10 years.
&gt;If you pass a String to a function, it copies the stack parts of the vector (pointer to data and length) but doesn't need to clone anything on the heap, because the borrow checker guarantees the function has exclusive access to the String when the function call is made. Ahhh yes. Because if you move it, the BC transfers ownership and if you only borrow it, the BC would manage it so that the original String would outlive all references. Possibly helping the compiler with the use of lifetimes. Got it! Thanks so much. I said it before, but literally not a day goes by where I don't learn something (new) about Rust! Just one last question: I suppose you're a professional Rust programmer? Do you ever actually have to check the source code for things like Strings in your every day Rust projects? Or is that something you only do if you want to learn more about the internals of Rust? 
&gt; If Rust futures were for sale, I'd buy them.. You actually don’t need to buy them, because in Rust futures are a zero-cost abstraction.
Thanks, I didn't know about cargo sweep, but I often needed something like this to clean up my 40+ GB target folder without having to rebuild everything.. 
Quote from our mod, &gt; As ever, a preemptive reminder to abstain from language zealotry. &gt; See also steveklabnik1's comment from the proggit thread: https://www.reddit.com/r/programming/comments/9xdvae/the_internet_has_a_huge_cc_problem_and_developers/e9rq3a6/ 
&gt; that &amp;mut has both a lifetime parameter and a type parameter, and it is covariant in the one and invariant only in the other? Yes. :) I was talking about the type parameter being invariant. &gt; I think the use case for doing this with library-defined smart pointers also exists Agreed. I think this is originally what `Unique` was intended to be used for, actually. So maybe now that we have an aliasing model, it is time to revive and stabilize `Unique`? `Unique` is somewhat weaker than `Box` though because it doesn't actually say *which memory* it is a unique pointer to -- there's no size information. For example, `RawVec` uses `Unique`, so the size might even be 0. &gt; Ah I see. I remembered some similar-sounding soundness issues having come up in the past of "lying with lifetimes" (I think it was w.r.t. Ref/RefMut), but apparently that must have been under the previous model. I am still not happy about "lying with lifetimes", but given that this model does not care about the lifetime, it cannot be a problem here... --- &gt; "Linear Regions Are All You Need" It's been a while since I looked at that paper. I remember trying to glance a model of mutable borrows from that, but didn't get very far and went with something altogether different for the RustBelt paper. But the part you quoted does sound related to "existential lifetimes", interesting!
Btw, is your wasm game framework open source? And which wasm game frameworks do you consider the most production ready? 
Heh, I'm not a professional Rust programmer :D, just a hobbyist for about 2-3 years. I don't think I've ever *had* to check the source code for something (at least not with the standard library), but I've been having peeks every now and then to learn about the internals.
Every time I see updates on Pijul I think to myself "I should try it some time". I still haven't gotten around to that. Anyway, in the "working with others" section of the book, the following is mentioned: &gt; However, Pijul is not (yet) able to push patches to an HTTP URL. Does this mean that you have to ssh every time you want to push to a remote location? Or does pijul have something similar to git remotes?
Btw, is there already an issue to improve that confusing error message?
Scala is held back by being too complex. Not much people want to deal with implicits, as they put a huge mental strain on the devs, are essentially time bombs, and make debugging a hell. Also, JetBrains IDEA has always been a great Scala IDE, so nothing is holding Scala back in that regard.
Did the author of cargo sweep just yank it from crates.io after being featured? 
I would recommend [quicksilver](https://github.com/ryanisaacg/quicksilver) if you want to find a wasm compatible framework to draw something simply. My [framework](https://github.com/shawnscode/crayon) is also open source, but i just made it for fun.
How is this different than the assertion macros? 
As someone who loves rust and has to do numerical analysis for design, Rust is the wrong tool for the job. Keep your prototypes and analysis in Python and MATLAB, implement your time critical code in Rust or C++. Also can we stop with the raw evangelism? Show code examples and benchmarks. Words are meaningless. 
\`cargo install cargo-sweep\` works on my machine.
Can I somehow link my rust app against older OpenSSL than the one that is installed on the system? I build the app on ubuntu with OpenSSL 1.0.2g and I would like to run it on the other machine with ubuntu with OpenSSL 1.0.1f. I've tried with `DEP_OPENSSL_VERSION_NUMBER` but I guess that it is designed to check what version has been used and not to point what version I would like to use. I've also tried to link OpenSSL statically but as far as I understand, I need a version with `-fPIC` and unfortunately, I cannot build it from the sources.
Are you talking about Tinkoff? But no, I had in mind Bank of America. And no, they are making a progress, not a mistake. As times goes, they will either have trouble finding workforce or they'll have to pay more and more for some contractor picking in their ancient Java code. Or start migrating to something newer.
But I want Rust to go to the moon.. 
Hmm... Maybe I found something old and wrong originally because now I see it on crates.io and it doesn't say yanked. Also the version is different. The one i saw before was version 1.0.1 and this is 0.2.0. Not sure what happened
I see where your grudge for Scala comes from. But that's from abuse of implicits and lack of experienced Scala dev in a team. When used right they are used mostly just to provide type classes (same as traits in Rust) or execution context for async code. But what about all other features? No null pointer exceptions, easy and safe concurrency with immutable types, strong collection library long before Java got one, easy async code with futures?
See, you're providing exactly the same argument to defend a hazardous language feature as people that would defend C memory management: it's just abuse, you just need better devs. Other Scala features are amazing, but now that we have Kotlin, that is much safer to use, write and most importantly read, Scala becomes obsolete. I feel this is getting way offtopic, though.
\&gt; Previously, concerns were raised that actix-web still contained unsafe code. However, this issue was resolved when the framework was written in a safe programming language — Rust. &amp;#x200B; Is this about [https://github.com/actix/actix-web/issues/289](https://github.com/actix/actix-web/issues/289) ? In this case the solution was not a rewrite in Rust but reducing the amount of unsafe Rust used
Yes [https://github.com/rust-lang/rust/issues/22750](https://github.com/rust-lang/rust/issues/22750) With a partial fix at [https://github.com/rust-lang/rust/pull/28300](https://github.com/rust-lang/rust/pull/28300)
0.10 was broken for months due to a dependency problem (i.e. the official install instructions using cargo did not work). I'm glad 0.11 is out and fixes it, since 0.10 gave me a real "oh this project isn't nearly as legit as I thought it was" first experience.
I use it cases like the following: \`\`\` match r { Ok(\_) =&gt; {}, Err(e) =&gt; { println!("error {:?}", e); debug\_panic!("error {:?}", e); }, } \`\`\` What do you think? I'm relatively new to Rust.
&gt; There are always "hazardous" features everywhere. E.g. unsafe in Rust. Unsafe in Rust isn't a tradeoff, it's something that is impossible to do without, due to technical limitations. There must always be some lower, unsafe (because hardware is unsafe) level to implement safe stuff for the general public to use. Unsafe doesn't exist just because language authors decided they like it, but because it's inevitable. There is nothing inevitable about implicits in Scala. It allowed them to architect a pretty cool collections framework (the best I've ever seen), but it's a case of "I want to make it pretty", not "this is technically necessary". Kotlin solved the collections problem way simpler and much more useful way than Scala: by providing extension functions (like in Rust, btw) over existing Java collections, therefore getting 100% interop, whereas Scala built their own collections class hierarchy from scratch with neverending conversions between Scala and Java ones.
I see that Pijul is licensed under GPL but depends on OpenSSL. AFAIK, OpenSSL license is incompatible with GPL.
&gt;As far as I know Java was just applets and not actually scripting the DOM. That was a non-starter for the web. It's fairly non-obvious that "scripting the DOM" was (or, indeed, _is_) the right model for building applications in the browser. Javascript back then was anaemic too, and "just applets" could look very different today if we had gone in a different direction back then.
Thanks a lot for posting this, I found it very useful! &gt; (If you do distribution Rust development, you should likely make +system your default toolchain.) And this is then `rustup default system`. 
Okay but what does it do
Thanks for fixing it. It's much more readable now.
Pijul is a free and open source (GPL2) distributed version control system.
You're probably looking for r/playrust. Regardless, take a deep breath and chill out buddy, games are meant to be fun. &gt; the server is full of assholes and just toxic people with a sample size of one, can confirm.
Applets might have been a way to build apps in the browser. But they're definitely not the web in the normal accepted definition of it. And we don't have to guess where applets would have gone because we experienced it all with Flash apps. Applets would look exactly like that if they hadn't died. It's the same kind of technology. A port in the web page that you can draw to however you want and an underlying desktop-like runtime to target. Compared to that Javascript+DOM won by a landslide and deservedly so.
I tend to use `debug_assert(false, "message")`, it's ugly so sometimes I wrap it in a macro, I don't really like the idea of having tiny crates, one for each little util that I can define in seconds (or just copy and paste). #[cfg(debug_assertions)] panic!("message") Also works Sorry if I'm shitting on your crate, but that's how NPM became a shitshow with thousands of tiny dependencies that can't be trusted.
I agree that as a community our bests interests are to show people what we've got with code. This is definitely a piece I'd attribute to the Rust Evangelism Strike Force...which is our way of saying, "We don't think that this is the best way to advocate for Rust."
Interesting, wonder how this handles null values. Does the struct field need to be wrapped in Option&lt;T&gt;?
Wasn't this changed in 2017? I don't have all the details but I thought they moved to Apache 2 which is compatible.
That seems to be what's going on in the test code [https://github.com/1aim/serde\_postgres/blob/master/src/de.rs](https://github.com/1aim/serde_postgres/blob/master/src/de.rs) down around line 380
Like git, but with some claimed advantages over git. See their [frontpage](https://pijul.org) for details.
This is basically the use case for `debug_assert`, which is a run time check that only happens in debug builds. There's a slight semantic difference to panicking, but it serves the same purpose here. For that code snippet I'd write something like if let Err(e) = r { debug_assert!(false, "{:?}", e); }
Thanks for any advices and help in advance!
I made a similar facility for the `bcder` crate since it doesn’t report what when wrong while parsing (on purpose): https://github.com/NLnetLabs/bcder/blob/master/src/debug.rs. Through a feature it panics instead of returning the vague error. Turns out this conflicts with using `#[should_panic]` test cases, so I am planning to replace this by an error type that contains a backtrace when the feature is enabled only.
Thanks! Interesting
/meme mode on `use serde_derive::Deserialize;` We're all living in 2015 while this man is living in 2018.
Cool, but won't get any traction until they figure out their story for interop with git.
What is the envisioned use case for this technology?
When building a binary, not a library, is there a way to tell the compiler to complain about functions marked as `pub` in a file but which are not used anywhere outside that file? 
Wow that was meant as a joke.. I'm sorry if I offended someone. And I do agree with the point that a small description in English would be beneficial. 
In addition to the video, the code samples are online: https://github.com/irh/freeverb-rs , with a Gtk app, a JUCE module, and a wasm target, all under MIT license.
I don't see how that would be done tbh
https://www.openssl.org/docs/faq.html#LEGAL2 &gt; 2\. Can I use OpenSSL with GPL software? &gt; &gt; On many systems including the major Linux and BSD distributions, yes (the GPL does not place restrictions on using libraries that are part of the normal operating system distribution). &gt; &gt; On other systems, the situation is less clear. Some GPL software copyright holders claim that you infringe on their rights if you use OpenSSL with their software on operating systems that don't normally include OpenSSL.
What's on the roadmap for the next release?
Ah, that's reasonable! I think people just took it to mean you didn't think the crate needed any description, and those are mostly "disagree" downvotes.
&gt;Previously, concerns were raised that actix-web contained a lot of unsafe code. However, the amount of unsafe code was significantly reduced when the framework was rewritten in a safe programming language — Rust. That's closer to the truth, but the unsafe code in question was *unsafe Rust code*, not some other language. Basically, Actix was doing some `unsafe` operations for performance reasons but their use of `unsafe` Rust turned out to be incorrect in a number of places. Thankfully, those problems were discovered and rectified.
I'm the author of the post. I confess I'm rather a noob when it comes to lexing/parsing, and I'll take any help I can get. &amp;#x200B; If you don't mind, please post corrections/suggestions as replies to this comment.
Isn't git just an inferior system where every path flattens all dingles? It should be possible to at least import a git history - and to generate patches for git from commits where all dingles are flattened... Something like that
According to https://news.ycombinator.com/item?id=14926851 Dropbox has it in the client as well. &gt; We're making a pretty big bet on Rust in the client (if you'd call it a bet, I don't see a scenario where we walk this back). The majority of new Sync code in the client (read: not UI) is being written in Rust and it's been a blast so far, not to mention much easier to reason about correctness which is really what we care about.
openssl is a non-optional dependency so I assumed that windows build bundles it. But instead it is simply dynamically linked to openssl and windows users are left to figure out how to get openssl themselves.
https://m12y.com/a-snakes-tale/
Sounds like you ended up at https://crates.io/crates/sweep/versions
Rust
Run it through WSL.
Would [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=050fcbdeed1375f6354fc7482e83dfc6) be what you were looking for?
Whoops... That makes sense
Oh that's a good point!
cool, working on something slightly related (Gameboy Emulator): [https://github.com/Ragnaroek/soma\_g](https://github.com/Ragnaroek/soma_g)
Why does this the with_event method return a new Handler instance? You should be able to return ‘self’ here, I believe, and still be able to chain this method call. Sorry, I can’t help with your two questions. I was literally playing around with generic types this week trying to do something similar. I kept getting hung up on my version of a struct that implemented a generic type handler being inserted into a HashMap. The compiler thought the first type it inserted should follow for all other insertions. And I couldn’t figure out how to coerce the types. If I get time, I’ll play around with your codepen. 
I don't get it
Oh, I didn't see that `with_event` took a different generic parameter than the one defined on the `impl` block itself. I'm surprised my code even compiled, now I look at it. In this case, dynamic dispatch will be needed, as I see you've outlined in your comment higher up.
That is the new import syntax macros in Rust edition 2018.
It's also in Rust 2015
https://github.com/rust-lang/rustup.rs/issues/1490
I mean I thought OpenSSL changed their license to Apache 2 to make it compatible with GPL (among other reasons for the change). There's a blog post about it on the openssl website here: https://www.openssl.org/blog/blog/2017/03/22/license/ 
Congratulations! Really happy to see it further evolving!
&gt; I think this is really useful information and comes up enough where it should at the very least be added to the readme on rustup like here https://github.com/rust-lang/rustup.rs/pull/1550 &gt; Also, I'd be interested in knowing how installing the rust toolchain through your distro when you already have cargo installed tends to behave. I can see this as being hard to track because its distro specific but it would be nice to know if its safe to add a system toolchain after you already have stable, nightly, beta all set up and that this won't ruin your existing rustup setup. No issue at all; in fact, it's a little easier, because you don't have to pass `-y` to rustup-init.
Well then I suspect Dropbox 'wins', it's probably more popular than Firefox :-)
Wikipedia uses rsvg uses rust, if you count that I bet it outstrips firefox and dropbox.
Very cool and interesting for someone from Ableton to be giving this talk. They're a big gun in the industry. 
It is a version-control system, like Git and many others, but with a [different](https://jneem.github.io/pijul/) model for changes and how they are combined.
Fix/Simlification: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=ace6f9212791ea1db154291eed68f785 Quick Summary: It's easier on the eyes to model "joining" as an iterator combinator (i.e. remove Join). Implement Joinable on T: Iterator and pass T and S to JoinIter instead.
You sure? I would have thought that even a browser with 10% market share would have more installs than Dropbox.
https://upload.wikimedia.org/wikipedia/en/thumb/3/30/Zak_Dingle.png/200px-Zak_Dingle.png
This should be it: https://arxiv.org/abs/1311.3903
Thanks for the heads up!
&gt; Also, there are a ton of IDEs and other tools with git integration. It would take years for Pijul to even begin to match that. That argument was used a lot in the SVN over git debates. There's bigger issues, e.g. people not feeling the need for a new system currently.
Cool thanks, but it would be better to list the softwares than the companies
Ok, there are also the softwares, but it's a bit confusing because some are Rust softwares and others are Saas that use Rust (so you maybe use it via a web service, not on your computer)
Don't forget about /s next time ;-)
Case in point: I *do* feel the need for something better. Every time I need to do a particularly nasty git rebase/merge. And maybe Pijul *would* make my day better, if only I could try it out on the problem at hand. How are you going to convince people that Pijul is better if they cannot evaluate it on non-toy example without doing a huge amount of work? And yeah, afterwards I'd like to browse my commit history in a GUI, compare what changed between two commits, etc. Currently Pijul doesn't have that. And won't have anytime soon, unless it starts getting traction and attracts more devs. 
Yes, thank you very much for giving me a direction, i've reworked some parts of the playground code so i have a working example added the parts u've simplified. &amp;#x200B; [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=43aab2001e3645d6b53c4459d3cc8e4c](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=43aab2001e3645d6b53c4459d3cc8e4c)
FYI: Your documentation is broken (at least on Chrome for Android) - the tri-bar/"hamburger" to pop out the navigation does nothing when clicked/tapped. Otherwise - cool project, I hope it gets some adoption.
I thought I had compiled it statically. Static Windows builds used to work anyway at some point, I'm sad they're now broken. If you know anything about how to link statically to OpenSSL, I'd be interested. &amp;#x200B; The goal of Pijul is definitely not to fall into DLL hell. We do whatever we can to become the easiest DVCS ever.
I like this kind of prophecies, but we have a prototype converter. It's not super widely advertised, though, and works only in one direction so far (import from Git).
I think that you need to use dynamic dispatch regarding the hashmap (Box&lt;dyn Mystruct&gt;). Since generics are statically "replaced" at compile time the type mismatches what the compiler expected when trying ro insert a struct with a new type as it's basically an entirely different struct (with different size) to the compiler, hence the type error. Which is why Box fixes it since it always have the same size (basically a pointer to the heap) 
Could you clarify? As far as I understand, I was being sincere in all of my messages.
Parity Ethereum client is pretty big given the number of miners running it
whats the difference between stdweb and web-sys? I don't understand how the generation of webstd works.
Author here. I've been working on-and-off on [Ratel](https://github.com/ratel-rust/ratel-core/) (JS parser/compiler toolchain) and earlier this day [Lunarity](https://github.com/paritytech/lunarity) (Solidity parser). Both projects share a lot of architecture, as one might expect, with lexers I've built for them being both an object of pride (because they were so fast) and shame (because they were so ugly). It seems I'll be working on more parsers in the future, so having that ugliness abstracted out behind an auto-magical derive macro seemed like a good idea. So, today, after getting a PR for Lunarity that migrates its lexer to Logos coming up green, I'm happy enough with the crate to start talking about it. There are still kinks to iron out, docs to write, and it might need a blog post or some such, but right now I'm happy. TL;DR: Here is a crate I wrote that allows you to quickly make a Lexer that reads source code at ~1GB/s on a 2016 i7 laptop.
Very few new technologies had managed to gain traction without a smooth migration path from their entrenched - very entrenched in this case - predecessors. Pijul may be special... but most likely it isn't. Good luck!
Is something like easier remote repos planned? Typing full urls can get annoying quite fast.
Well, that's exactly why I wrote a converter…
Thank you, that's really encouraging to hear! I'll add a "contributing" section to the readme when I get the chance 
Wow! What's the current state of this project: how close is it to meeting its goals?
This looks really interesting. Is there an index or something like that in the Nest? I would love to maybe download some repos to play around with, but that's going to be pretty difficult if I can't get a list of them.
In what context can this execute webassembly? I have not written wasm yet, but how can the wasm interact with the runtime? Could this be embedded in another project?
Hello there! With this code: ```rust type SyncMiddleware&lt;T, M&gt; = fn(T, chain: M) -&gt; T; fn wrap&lt;Ctx: Context&gt;(middleware: SyncMiddleware&lt;Ctx, impl Fn(Ctx) -&gt; Ctx&gt;, next: Option&lt;impl Fn(Ctx) -&gt; Ctx&gt;) -&gt; impl Fn(Ctx) -&gt; Ctx { let unwrapped_next = next.unwrap(); move |context: Ctx| { middleware(context, unwrapped_next) } } ``` I'm currently getting the error ``` --&gt; src/middleware_2.rs:53:25 | 53 | middleware(context, unwrapped_next) | ^^^^^^^^^^^^^^ expected type parameter, found a different type parameter | = note: expected type `impl Fn(Ctx) -&gt; Ctx` (type parameter) found type `impl Fn(Ctx) -&gt; Ctx` (type parameter) ``` My guess that this is happening because `impl` types actually are resolving to unique types, but I'm not sure if that's actually the case and if so, how to overcome it! All help/comments would be appreciated.
Is this not a good use case for static\_assertions ([https://crates.io/crates/static\_assertions](https://crates.io/crates/static_assertions))? I believe it uses something similar internally.
Are the file extensions different? You could match on that: // if `path` is `std::path::Path` match path.extension().map(|e| e.to_str()) { Some(ref ext) if ext.eq_ignore_ascii_case(b"gz") =&gt; { // decode with flate }, Some(ref ext) if ext.eq_ignore_ascii_case(b"csv") =&gt; { // process as plaintext }, Some(ref ext) =&gt; { /* handle unknown extension */ }, None =&gt; { /* handle missing or non-UTF8 extension */ }, } You can also read [the magic bytes (`1F 8B`) in the gzip header](https://en.wikipedia.org/wiki/Gzip#File_format) yourself and seek the file back afterward: use std::io::{Read, Seek, SeekFrom}; let mut file = File::open(path); let mut bytes = [0u8; 2]; file.read(&amp;mut bytes)?; file.seek(SeekFrom::Start(0))?; if bytes == [0x1Fu8, 0x8B] { // decode with flate2 } else { // process plaintext } This is basically what `GzDecoder` does internally but it might be a little faster since `GzDecoder` returns an `io::Error` which allocates on construction. However, since this sounds like a little one-off utility, speed isn't really the upmost importance and I would just attempt to decode first and seek the file back if it fails. That would be much more succinct than this.
I am continuing my [NES emulator](https://github.com/SnoozeTime/nes). Now I am doing the 'easy' part which is the CPU emulation. I found Rust macros to be really helpful here. In parallel, I'm studying a bit about the Ethereum VM and try to create an interpreter using Rust. 
&gt; You can also read the magic bytes (1F 8B) in the gzip header That's how I handle it in my project, for what it's worth.
I repeated the test from https://www.reddit.com/r/rust/comments/8dx08d/new_release_of_pijul_010_more_stable_than_ever/dxsuabt/ ... and it went better. Still not near usable on a large repo, but definitely better: - Import of the first real commit on mozilla-central went through in 1:15, creating a 2.1G .pijul. This is larger than what it was with 0.10, but took about the same amount of time. - Importing the next commit from mozilla-central, and then running `pijul status` returned a result in 1:30 (vs. &gt; 12 minutes with 0.10, and back then, I had Ctrl-C'ed, not knowing how much longer it would have taken). It's worth noting that the patch is effectively modifying 1 file from the first commit, and adding 10 new files. 1:30 is still a very long time to wait for status on this. `pijul record` took 30 seconds. Much better too, but still nowhere usable for such a small change.
You want the `unreachable_pub` lint. It appears to work both for binaries and libraries: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=4a41a2dd42c01d4b5182076aa12bfc6f
Tyler McMullen gave a talk at Strangeloop, "[Isolation Without Containers](https://thestrangeloop.com/2018/isolation-without-containers.html)" which goes into some of the design considerations of Terrarium.
Considering WASM doesn't have any way to communicate with its environment other than the environment providing functions that WASM can import, what imports are available? Is it based on CommonWA or what does it do?
It's unfortunate that triple-backtick code blocks don't work on old.reddit.com (Reddit's fault), that makes it harder to read. Fortunately the comment source retains the formatting. Secondly, your guess is correct. Each `impl Trait` in argument position basically expands to a separate type parameter, which means the desugared `wrap` signature looks like this: fn wrap&lt;Ctx: Context, F1: Fn(Ctx) -&gt; Ctx, F2: Fn(Ctx) -&gt; Ctx&gt;(middleware: SyncMiddleware&lt;Ctx, F1&gt;, next: Option&lt;F2&gt;) -&gt; impl Fn(Ctx) -&gt; Ctx { } What you actually want is to have a single type parameter for both. In this case it means avoiding `impl Trait` in the arguments entirely, which makes the signature shorter anyway: fn wrap&lt;Ctx: Context, F: Fn(Ctx) -&gt; Ctx&gt;(middleware: SyncMiddleware&lt;Ctx, F&gt;, next: Option&lt;F&gt;) -&gt; impl Fn(Ctx) -&gt; Ctx { }
&gt; My guess \[…\] `impl` types actually are resolving to unique types, \[…\] That's correct, `fn f(a: impl Tr, b: impl Tr);` means `fn f&lt;A: Tr, B: Tr&gt;(a: A, b: B);` with `A` ≠ `B`, in general (even if they both implement the same trait, they can be entirely different types). You just need to introduce another explicit type parameter `M`: fn wrap&lt;C: Context, M: Fn(C) -&gt; C&gt;(middleware: SyncMiddleware&lt;C, M&gt;, next: Option&lt;M&gt;) -&gt; FnOnce(C) -&gt; C { move |context: C| middleware(context, next.unwrap()) }
Something I didn't realize is that `flate2` wraps everything in `io::Error` which means you'd have to do some unwrapping to find the cause of the error before dispatching on it, which doesn't sound much like a succinct solution in my head anymore. I would personally go for matching the file extension unless you have a reason not to trust it. The advantage is it's already in userspace memory and you don't have to perform two syscalls to find the file type (read and seek).
Both cases are possible; I wouldn't consider checking the extension to be less correct unless the extensions are wrong in the first place. A truly robust solution might check both but this sounds like a simple script with a homogeneous input set.
Thank you both for the help! Reading the magic bytes sounds like a good solution since I can usually (but not always) rely on the file extension.
Mechanically they may do the same thing. However, the bounds are different so the implementations cover different cases. Here's a [slightly edited version ](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=1e08918019d9bf1b08520062d4afb212) to make the error more apparent. The error arises in the HRLB on line 64. From the [Nomicon](https://doc.rust-lang.org/nightly/nomicon/hrtb.html): "for&lt;'a&gt; can be read as "for all choices of 'a", and basically produces an infinite list of trait bounds that F must satisfy". I'm assuming since JoinIter implements IntoIter, it's included in the trait bounds (hence the infinite recursion). With that being said, I have no idea how to solve this.
So -- now I'm getting the following when I try to recurse calls like so ``` let inner = wrap(ctx_1, None); wrap::&lt;Ctx1, fn(Ctx1) -&gt; Ctx1&gt;(ctx_1, Some(inner)); ``` gives ``` error[E0308]: mismatched types --&gt; src/middleware_2.rs:113:46 | 113 | wrap::&lt;Ctx1, fn(Ctx1) -&gt; Ctx1&gt;(ctx_1, Some(inner)); | ^^^^^ expected fn pointer, found opaque type | = note: expected type `fn(middleware_2::Ctx1) -&gt; middleware_2::Ctx1` found type `impl std::ops::Fn&lt;(middleware_2::Ctx1,)&gt;` ``` Even when I try to be stricter about types I get the same error only moved up in the calls: ``` let inner: fn(Ctx1) -&gt; Ctx1 = wrap::&lt;Ctx1, fn(Ctx1) -&gt; Ctx1&gt;(ctx_1, None); wrap::&lt;Ctx1, fn(Ctx1) -&gt; Ctx1&gt;(ctx_1, Some(inner)); ``` gives a similar error, ``` 112 | let inner: fn(Ctx1) -&gt; Ctx1 = wrap::&lt;Ctx1, fn(Ctx1) -&gt; Ctx1&gt;(ctx_1, None); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected fn pointer, found opaque type ``` Not sure why the `fn(Ctx1) -&gt; Ctx1` typing isn't carrying through!
Can you explain what you mean? I don't see any political references in the post.
It's a joke, the thumbnail is similar to a political compass (grid split in 4).
Ah, I see what you mean. I had that concern, too, but when you rewrite `iter` to not use an HRLB, you get the same error: impl&lt;T, S&gt; JoinIter&lt;T, S&gt; fn iter&lt;'a&gt;(&amp;'a self) -&gt; JoinIter&lt;&lt;&amp;'a T as IntoIterator&gt;::IntoIter, &amp;'a S&gt; where &amp;'a T: IntoIterator { self.into_iter() } }
The blog post links to a [website](https://license.openssl.org/) they set up to aid in the transition, which includes the current status: &gt; **Update:** We are looking for the last few contributors, please see the https://license.openssl.org/trying-to-find page. Share it with your friends and colleagues who might have worked on or with OpenSSL. 
This looks pretty nice! Does it bake in whitespace handling? (And is there any way to capture formatting info (e.g. for diagnostics, or for code modifications that preserve formatting). Also, how would you deal with things like contextual keywords? (I'm not that familiar with parsing, so perhaps this isn't something that a lexer usually deals with...?)
Here is a solution using fold: https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018&amp;gist=06b9ce713f0599f137b730bc6ef4ec80 Note that it needs the 2018 edition because the match statement gives borrowing issues if you don't have nll (which are only in 2018 edition). thanks /u/Cocalus for the idea, it was a very good exercise
The compiler tells you that a function pointer is incompatible with/unequal to a closure type. `wrap` returns some (existential) type that implements `Fn` which means a closure (**not"* a fn ptr).Thus, `let _: fn(Ctx1) -&gt; Ctx1 = wrap(…);` fails to compile.
FWIW, I don't consider C++ and Java *very* similar. Syntactically, they look a lot alike, but the semantics of object lifecycles and references are fairly different.
I see, so is there a good way to make something like this work? ``` let ctx1 = Ctx1 {}; let inner = wrap(ctx_1, None); let _ = wrap(ctx_1, Some(inner))(ctx1); ``` Right now I get ``` error[E0282]: type annotations needed --&gt; src/middleware_2.rs:114:28 | 114 | let _ = wrap(ctx_1, Some(wrap(ctx_1, None)))(ctx1); | ^^^^ cannot infer type for `M` ``` I would have hoped that passing `ctx1` as type `Ctx1` would be able to propagate back through the typing to describe `M`, but I'm sure I'm missing something.
Not the typical advice but I think you should start with C. I don't mean you should go spend years writing gigantic projects in C but you should get enough experience to understand the rough edges of C, particularly around memory management. If you familiarize yourself with some of the pains of C, you'll have a greater appreciation for the gains from using Rust. Java and Rust attempt to solve the rough edges in C in notably different ways. Building your Rust understanding on a foundation of C mental models will likely provide more insights than jumping into Rust directly.
That sounds like a good idea, learn C then learn Rust, as C is the de facto. 
Thank you! I’ll check it out. 
Interesting, I didn’t realize that yet. I’ll keep that in mind. 
&gt; Video unavailable &gt; This video contains content from [Merlin] Beggars, who has blocked it on copyright grounds. :(
Any ideas around integrating lexing and parsing? Is it really faster to separate these two steps these days (I understand why it would be in the 90s when memory was at a premium)? Specifically, it would seem like the parser quite frequently knows the most likely token coming up (or at least the top 2-3 or so) and could ask call a specialized lexer function to try those first. For example, in C if you've just parsed "for" (and gobbled up any whitespace after it) you're almost certainly going to see a '(' next, so why not check for that character first? &amp;#x200B;
Hi! I'm trying to create a web application with Actix and having some troubles with something that I'm guessing has an easy answer. I have this API endpoint: pub(crate) fn signup( req: &amp;HttpRequest&lt;AppState&gt;, ) -&gt; Box&lt;Future&lt;Item=HttpResponse, Error=Error&gt;&gt; { req.json().from_err().and_then(|sr: SignupRequest| { match &amp;req.state().conn_pool.get() { Ok(conn) =&gt; { let _ = create_user(conn, &amp;sr.username, &amp;sr.password); Ok(HttpResponse::Ok().finish()) }, Err(e) =&gt; { error!("couldn't create user: {}", e); Err(HttpResponse::InternalServerError().finish()) } } }).responder() } This results in the following compilation errors: error[E0277]: the trait bound `actix_web::httpresponse::HttpResponse: std::convert::From&lt;actix_web::error::JsonPayloadError&gt;` is not satisfied --&gt; src/api.rs:12:27 | 12 | req.json().from_err().and_then(|sr: SignupRequest| { | ^^^^^^^^ the trait `std::convert::From&lt;actix_web::error::JsonPayloadError&gt;` is not implemented for `actix_web::httpresponse::HttpResponse` | = help: the following implementations were found: &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;&amp;'a std::string::String&gt;&gt; &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;actix_web::error::Error&gt;&gt; &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;bytes::bytes::BytesMut&gt;&gt; &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;std::result::Result&lt;I, E&gt;&gt;&gt; and 5 others = note: required because of the requirements on the impl of `futures::future::Future` for `futures::future::from_err::FromErr&lt;actix_web::json::JsonBody&lt;actix_web::httprequest::HttpRequest&lt;AppState&gt;, app::models::SignupRequest&gt;, actix_web::httpresponse::HttpResponse&gt;` error[E0277]: the trait bound `actix_web::httpresponse::HttpResponse: std::convert::From&lt;actix_web::error::JsonPayloadError&gt;` is not satisfied --&gt; src/api.rs:12:16 | 12 | req.json().from_err().and_then(|sr: SignupRequest| { | ^^^^^^^^ the trait `std::convert::From&lt;actix_web::error::JsonPayloadError&gt;` is not implemented for `actix_web::httpresponse::HttpResponse` | = help: the following implementations were found: &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;&amp;'a std::string::String&gt;&gt; &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;actix_web::error::Error&gt;&gt; &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;bytes::bytes::BytesMut&gt;&gt; &lt;actix_web::httpresponse::HttpResponse as std::convert::From&lt;std::result::Result&lt;I, E&gt;&gt;&gt; and 5 others error[E0599]: no method named `responder` found for type `futures::future::and_then::AndThen&lt;futures::future::from_err::FromErr&lt;actix_web::json::JsonBody&lt;actix_web::httprequest::HttpRequest&lt;AppState&gt;, app::models::SignupRequest&gt;, actix_web::httpresponse::HttpResponse&gt;, std::result::Result&lt;actix_web::httpresponse::HttpResponse, actix_web::httpresponse::HttpResponse&gt;, [closure@src/api.rs:12:36: 23:6 req:_]&gt;` in the current scope --&gt; src/api.rs:23:8 | 23 | }).responder() | ^^^^^^^^^ | = note: the method `responder` exists but the following trait bounds were not satisfied: `futures::future::and_then::AndThen&lt;futures::future::from_err::FromErr&lt;actix_web::json::JsonBody&lt;actix_web::httprequest::HttpRequest&lt;AppState&gt;, app::models::SignupRequest&gt;, actix_web::httpresponse::HttpResponse&gt;, std::result::Result&lt;actix_web::httpresponse::HttpResponse, actix_web::httpresponse::HttpResponse&gt;, [closure@src/api.rs:12:36: 23:6 req:_]&gt; : actix_web::handler::AsyncResponder&lt;_, _&gt;` `&amp;futures::future::and_then::AndThen&lt;futures::future::from_err::FromErr&lt;actix_web::json::JsonBody&lt;actix_web::httprequest::HttpRequest&lt;AppState&gt;, app::models::SignupRequest&gt;, actix_web::httpresponse::HttpResponse&gt;, std::result::Result&lt;actix_web::httpresponse::HttpResponse, actix_web::httpresponse::HttpResponse&gt;, [closure@src/api.rs:12:36: 23:6 req:_]&gt; : actix_web::handler::AsyncResponder&lt;_, _&gt;` `&amp;mut futures::future::and_then::AndThen&lt;futures::future::from_err::FromErr&lt;actix_web::json::JsonBody&lt;actix_web::httprequest::HttpRequest&lt;AppState&gt;, app::models::SignupRequest&gt;, actix_web::httpresponse::HttpResponse&gt;, std::result::Result&lt;actix_web::httpresponse::HttpResponse, actix_web::httpresponse::HttpResponse&gt;, [closure@src/api.rs:12:36: 23:6 req:_]&gt; : actix_web::handler::AsyncResponder&lt;_, _&gt;` I think my problem is that I'm not handling the \`JsonPayloadError\` that could result from \`.json()\`. I (unsuccessfully) tried to apply the \`map\_err\` and \`from\_err\` in various positons, but nothing seems to do the trick. This is my first foray into futures and higher-level combinators like \`map\`, so I feel like I don't have a good grasp on idiomatic approaches to resolving these problems. &amp;#x200B; What's the best way to do what I'm trying to do?
Nice post, really appreciated the overview. 
Even with regards to object oriented programming, Java and C++ have some very different feature sets and wildly different details.
We will eventually permit calling `panic!("foobar")` inside `const` and `const fn` and when we also stabilize control flow (`match`, `if`, ...) then you can do this without hacks... :)
I thought that safe rust (that is truly safe and not relying on “unsafe” somewhere down the line) made it literally impossible to leak memory. 
https://doc.rust-lang.org/std/mem/fn.forget.html
I hate the fact that I'm the guy who talks about the limitations of type classes / traits, when honestly they're fucking wonderful most of the time. No, if you look at the issues on the github that's provably incorrect, a strong type system that takes memory safety into account will stop you from hurting yourself sure, with a type class like system you can intentionally come up with ways to fuck with it's spec and you are prone to not being aware of what's going on due to their implicit nature, though there is a possibility that rust code can be formally verified in the future. You can't be overly confident before using property tests and fuzzers, in your code. 
Absolutely not -- the two most common sources of leaks are going to be improperly using `std::mem::forget` and having cycles betweeen ref-counted (`Rc`, `Arc`) types. Leaking memory isn't unsafe in Rust's definition, because nothing is getting improperly accessed.
This is emphatically not the case. Not only is leaking of anything explicitly permitted in Rust's definition of memory-safe, it's impossible be leak-free by construction. Preventing leaks means you must prove that the program _does_ something as opposed to the safety that Rust does provide which is all about _not_ doing a thing. Take for example a situation where I unplug your computer at the wall. _Where are your destructors now?_ This isn't just an academic example too, destructors can be responsible for important side-effecty tasks like flushing a file buffer to disk.
Being the bearer of bad news isn’t fun but it’s important! 
Surprised that’s safe but counter example checks out. 
It's probably like different stages of parsing. You can't get a tree of tokens without deriving at least some meaning from the tokens. A better alternate word to lexer is scanner, which doesn't produce a tree, right? In parsing xml, I'd expect it to be easier to first get a token list, then get some meaning from it and turn it into a basic tree, then finish more complex parsing and turn it into a DOM tree. Taking a quick look at Wikipedia for confirmation says that lexers scan using a regular language (aka regex), though sometimes do a little more complicated stuff if necessary, like Python paying attention to whitespace. So yeah, you're probably just doing multiple stages of parsing, or maybe merging some simple parsing into the lexer. You do not use any form of BNF in a lexer. That's the parser's job. Whatever. Now you know :)
So the 'static annotation is default for concrete variable. While a reference variable of other scalar should consider about its lifetime by annotation.
It's because memory leaks aren't memory-unsafe. Reference-counting cycles are often cited as a prime example or when destructors might not run, but another case would be allocating some memory and then going into an infinite loop. Or aborting the program without unwinding the stack.
Except that it means all rust code is basically unsafe because "destructors don't exist" and a conforming implementation can apparently just ignore drop if it wanted to be evil. All because a programmer can decide to `mem::forget` something for some reason, in which case it should be on them to know that not dropping stuff means it won't be dropped.. or has a reference cycle? Or, even flimsier, because somebody can choose to abort the process using a function explicitly documented to skip destructors? For one, most anything that needs cleaning up in a destructor would also be cleaned up by process exit.. Those are obscure edge cases, they shouldn't make the rest of the language unsafe. And `mem::forget` is only safe because of Rc, which is only considered safe because apparently reference cycles are stable guaranteed behavior?!
\&gt; No matter what you throw at Rust, it can deliver. Even in places where Rust still falls a bit short, there are no fundamental reasons for it. It's typically just immaturity of the ecosystem and libraries. &amp;#x200B; Still quite new to rust so forgive my ignorance, but what areas does rust still fall a bit short on? 
Oh, my bad - I misunderstood and, well, the source code _is_ in fact in English after all.
But can it lex Rust? Thanks to raw string literals, its lexical grammar isn't even context-free …
A memory leak is by definition when you incorrectly manage memory, and don't free it when you no longer need it. Reference cycles are the only example that are a memory leak. Going in an infinite loop is not a memory leak. The program exiting is not a memory leak. The computer losing power is not a memory leak. How in the world are those memory leaks? Operating systems free process memory on close. And cycles are a special case. Just document that if you create a cycle, it's possible destructors may not be run. "Destructors are guaranteed to run in the absence of Reference counting cycles, explicitly choosing not to run the destructor with `mem::forget`, and terminating the process through non-normal means" No need to inject the rest of the language with "destructors may as well not exist, never put code in them because they don't have to run!!11"
The OS will indeed free the memory after the process exits, but that's still different from destructors having run. Even if your destructor just prints to the terminal or something it's a behavior that doesn't occur in any of the leaking cases. And the language doesn't take the stance that "destructors don't exist". The stance it takes is that "unsafe code cannot be predicated on destructors running in all possible situations"
You should be able to check if `gz_decoder.header().is_some()` to check if the header did parse correctly.
Hello rustaceans :). The news of all the fancy new Macro stuff that landed in 1.30 excites me, and I actually have a great use-case for a custom-derive that I'd like to implement. The problem is, there's a lot of historic procedural macro documentation that exists and I can't tell what the best practices are anymore. &amp;#x200B; * Are there any great modern procedural macro references you'd recommend? * Is proc-macro2 important if I only need to support the latest compiler?
What /u/dsilverstone wrote doesn't do what you need, you can't alias traits like that (this `type` declaration creates an alias for a trait object type). There is a proposal (accepted I think) to have trait aliases that let you do this, like `trait T = A + B + C`.
It's safe to tell the `unsafe` code that leaking is safe - you cannot depend on value to not leak. Even if `mem::forget` was unsafe, leaking still would be possible, due to `Rc` cycles.
Because of irritation with rustc backtraces I did a little utility which filters them to only give traces for user code (I.e not stdlib or cargo cache). Was thinking of calling it cargo-trace? Any prior implementations?
Currently, the imports available are the ones that the developer defines (or already included in the library). &amp;#x200B; For example, this is how we are doing the Emscripten integration: [https://github.com/wasmerio/wasmer/blob/e59b95d95ee8e9a2c51b593b8b995af72575024a/src/apis/emscripten/mod.rs#L17-L84](https://github.com/wasmerio/wasmer/blob/e59b95d95ee8e9a2c51b593b8b995af72575024a/src/apis/emscripten/mod.rs#L17-L84)
Absolutely! One of the goals that we tried to do is to provide a very simple API for embedding a WebAssembly runtime in your own project: [https://github.com/wasmerio/wasmer/blob/master/src/webassembly/mod.rs](https://github.com/wasmerio/wasmer/blob/e59b95d95ee8e9a2c51b593b8b995af72575024a/src/webassembly/mod.rs)
Consider also the fairly common case of having a long-lived HashMap somewhere and accidentally forgetting to remove items from it when you're done with them.
GUI in rust is very much a work in progress by my understanding. Not a wasteland though. [GTK bindings](https://crates.io/crates/gtk) exist and seem to be pretty heavily used. I don't have experience with them, but they seem to be very mature. Also, I'm pretty excited about the [Azul](https://azul.rs/) library being worked on. Unfortunately it's pre 0.1, check back December or January. It might be a good exercise though once you get your feet wet to use a simple drawing library like [SDL2](https://crates.io/crates/sdl2) (which I highly recommend playing around with) to create a GUI. Just my 2 cents! :)
Numerical computing. I really miss a library like Eigen is for C++. But maybe its good to wait for const generics to arrive in Rust, they will provide better general base for development of multidimensional arrays of generic size.
This is super cool and a testament to Rust’s versatility. 
Can it be ran freestanding with no_std? Possibility for embedding in OS Dev/IoT?
I agree that it's more useful *in general*, which is why I want to make sure I ship a working `iter()` method. However, my specific use case, and the one that I really want to have first class support for, is an implementation of `Display` for joins. Iterators, which are generally single-pass, don't really lend themselves to this. I had a solution working with `I: Iterator + Clone`, but that led to unfortunately situations like cloning a whole vector on every `println`
hi all, I'm author of the crate , it is the source code of a Chinese book. [https://github.com/ZhangHanDong/tao-of-rust-codes](https://github.com/ZhangHanDong/tao-of-rust-codes) I don't know who post it here, I'm sorry if you are bothered. &amp;#x200B; &amp;#x200B;
You could put extern crate clap in module itself and re-export macros using `pub use clap::&lt;macro_name&gt;`
I am fully aware of that. In practice though all of these problems are gone for me, without me even trying or thinking about it.
Can't watch it here, too
Previously: https://www.reddit.com/r/rust/comments/7t6rsq/amp_a_complete_text_editor_for_your_terminal/?st=JOSBOJEH&amp;sh=a221c303
Lack of a proper graphical toolkit.
Rust's debugging story is still quite lacking.
posting this in r/playrust would be a good start. 
of course, it helped me a lot to understand, how the whole thing work. if i conding in rust, i compare everytime how it works in C and how unsafe C is. You leran what the Code really does. But this is only i my case the result, i don't will say everybody must go this way :) &amp;#x200B; Happy Coding