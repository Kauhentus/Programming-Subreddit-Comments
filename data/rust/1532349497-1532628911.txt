C# came a good deal later than Java and was targeted at the then-desktop-only windows platform, whereas Java was geared to 'run anywhere'.
Disclaimer: I dislike _design patterns_ and I'm therefore a bit biased :) My advice is to not worry about design patterns. Design patterns are in my experience typically just a jargon for "how things are usually done" and at times that jargon needlessly obscures what's going on. There's an old joke that says that a Java person doesn't go to a friend, they apply the visitor pattern to a friend element and themselves (I might remember the joke's details wrong but you get the gist). Of course sometimes it is genuinely useful to name a pattern and talk about it as such (I'd give a benefit of the doubt to the builder pattern for example), but in my personal experience this is a fraction of the cases design patterns are used eg. in Java... Translating your question from the design patterns lingo back to natural language, I'd say you'd like to know how things are usually done in Rust :-) (Right?) A good way to learn that is probably to read code of some higher-profile projects and/or to get your code reviewed. The latter can be accomplished by contributing or by just posting your code... 
Yeah, sure. Does that change anything?
Inspired by Ben Heck by any chance? :)
It was one of the commercial ones from a few years ago that had a really nice finish. Can't remember which one though. Still need to build the frame for this one, but I think the firmware is good (other than calibrating the steps per mm).
Ahh that's cool! I'd never seen anything like it until Ben Heck built something similar a few weeks back.
I've had good experiences with ClickHouse. Two caveats: 1. I haven't used it for a mission critical application, only an internal tool, and 2. it's a column oriented database, not specifically a time series one. With those caveats out of the way, it has the full power of SQL and it has built in support for automatic time partitioning. In addition, column-oriented data storage is usually pretty great for time series data (YMMV). It has a REST API that makes it easy to use from any language, including rust. I'd say that it easily checks the boxes of your first 4 bullet points. The last bullet point you might be able to accomplish with the CollapsingMergeTree, but I've never used this feature. Finally, it has grafana integration that just works and makes building visualizations easy. One downside is that loading data is best done from flat files or Kafka, not from direct insertions. This will make the data loading aspect more complicated and might not make it the right choice for a side project.
A single thread issues 2 reads. They are handled by a single event loop. Depending on the number of sockets used, and retry logic, etc... of the implementation, the second result may hit a zk replica and return in full to the client before the first, and the second future may be filled before the first. This is still linearizable from the event loop's prospective, but if the client is relying on history progressing forward with each subsequently issued request, they could be disappointed. Does the library preserve ordering across concurrent, single-threaded client requests?
The line format is a terrible mess. Some strings just cannot be represented -- and docs disagree with code. This written as someone who has to feed data to InfluxDB. I haven't used InfluxDB itself.
Working on a generic virtual DOM library that will be (not-easily) pluggable to different widget frameworks, for example the DOM.
Found it, it was the Sisyphus table. https://www.kickstarter.com/projects/1199521315/sisyphus-the-kinetic-art-table?ref=home_popular
A little program to do Bad Things to AVI files, such as removing keyframes and whatnot; the usual stuff! I'm very green with reading binary data in Rust, so I've probably done some very backwards things so far. At least it's functional! What I'll work on is to try and clean it up a little, and try to figure out how I can interface with it without having to recompile all the time. I don't have an example video of the Rust version yet, but I made a Python version which should behave just about the same way (given the same operation), and here's a [video produced by that](https://twitter.com/malpractitioner/status/1020658848162623488) https://github.com/chinatsu/avirus
That repo has been around for a while and has not gotten a lot of love. Most of the patterns are unfinished. It is repo I visit every once in a while to see if there's anything new though, I wish it got more attention.
I would implement `IntoIterator`. Then you will be able to use `collect::&lt;Vec&lt;_&gt;&gt;()`, but it will also work for different containers.
Both the ones that Steve mentioned are fine. I've done considerable hacking on comrak and can vouch for its near perfect spec conformance (and it will be perfect soon). It's maintained by a githuber who is closely involved with the reference implementation, and it includes all the GitHub extensions like tables. Pulldown is probably somewhat faster.
Not, that's nto what I want at all. The values shouldn't be consumed. Also,I already have implemented the function, I just need a name that describes what it does. Thanks anyways :)
Sounds like a good idea, thanks!
Have you tried to use [wasm-gc](https://github.com/alexcrichton/wasm-gc) and add `lto=true` to `Cargo.toml`? The latter especially helps in my experience, as it allows to remove a lot of unused `std` code.
When I have some time, I’ll see about doing that. Thanks for the tip!
Say I have an image or any other tag. How can I alter its "src", dynamically, before it gets rendered to html?
What happened to the missing bit? Also, why 11?
&gt; A good way to learn that is probably to read code of some higher-profile projects I've tried following this advice but it's always hard to know whether this code is of high quality, and also a lot of the time the code is really complex and super daunting. Do you have any follow up advice taking into account the above? I really wanna get better at Rust but I'm afraid I'm at an impasse.
Continuing work on writing a Vulkan(o) backend for Ggez. Things have slowed down a bit as I deal with real life stuff. My repo is here https://github.com/bsvercl/ggez under the vulkano branch.
Could you please help me with lifetimes here? use std::collections::{HashMap, HashSet}; pub fn main() { let foos: HashMap&lt;u32, HashSet&lt;u32&gt;&gt; = HashMap::new(); bar( 1u32, move |id| &amp;foos[id], ); } fn bar&lt;T, F&gt;(bar: T, get_foo: F) where F: Fn(&amp;T) -&gt; &amp;HashSet&lt;T&gt; { let _ = get_foo(&amp;bar); let _ = get_foo(&amp;bar); } This is extracted from some more compex code, but the error remains the same. I would like to avoid clone. https://play.rust-lang.org/?gist=e18eef95f482ac0a24cfe56165e255a2&amp;version=stable&amp;mode=debug&amp;edition=2015
For this (and many other) type of things you'll get better results searching for Python instead of Rust. Vim expects stdin/out to be a terminal, so you'll need to set this to its liking.
I have been keeping my eye on two compile to js "languages" in particular: reasonml/bucklescript and purescript. I think OCaml is a little closer to the way Rust sees the world, and it is growing fairly quickly. Purescript seems a little more stable, but growing much less quickly. I'd be curious to find comparisons of yew, reasonml and purescript. 
Ah, that's a good idea! I'll try my searches with python instead of rust. Thank you very much.
I haven't seen this mentioned here yet, but the advantage I see of `pulldown-cmark` over something like `comrak` (which is also fantastic) is that with it I've been able to build parsers for strict subsets of CommonMark. This has been really helpful for some domain-specific side projects I've had that implement a specific document publication flow, but for most people (who just want to offer a convenience for writing HTML) it might not even matter.
Yes. Different goals, different outcomes.
I can make it work by removing the `move` on the closure, but I don't think you can make it work *with* the `move`. The problem is that you need to tell the compiler that the lifetime of the result of the closure is the same as the lifetime of the borrow of the `self` parameter to the closure, *and you can't name that second lifetime*. If you really need this behaviour (callable that owns some context), you're probably better off defining a custom trait and manually implementing that for a context structure. Inconvenient, but possible to express.
I don't want to speak for OP, but it sounds like he meant _idioms_ rather than _patterns_ which it seems like you interpreted as GOF design patterns, at least based on your java joke.
Allocation functions on Windows, for better or worse, return either an error code or a null pointer if there is insufficient memory. e.g. documentation for \[malloc\]([https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/malloc](https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/malloc)).
&gt; The values shouldn't be consumed. If I understand the signature of your function correctly, you are consuming the values into the returned vector. &gt; I just need a name that describes what it does. By generalizing and implementing `IntoIterator`, you would basically rename your function into `Iterator::collect::&lt;Vec&lt;_&gt;&gt;`. I think it is descriptive. It is however a bit more work, because you need to implement an iterator struct.
I can't say that a `Mul` of a baseline Duration feels very idiomatic either.
You're asking this in the wrong place. I would do this I'd I were you- google "winapi check if executable" and is winapi trait. In some cases it's better to use special cases for OS rather than trying to leverage rusts platform independence and this send rto be one of those
Hi! I've written this small crate for another project I'm working on. Cargo allows to write your own test scripts with `[[test]] harness = false`. This means that you write the executable that does all the testing. It would be pretty cool if your test script would look like the built-in testing harness, right? That's where this crate helps with! Now the test script can concentrate on the actual testing logic. This is the first version sufficient for my use case right now. But I think this crate could be really useful for a couple of other projects. So: **if you are working on a project that could benefit from using this crate, please ping me!** I want to check if the current API is sufficient for your use cases and if not, change the API if possible. Thanks! PS: asciinema is awesome!
Well, you have `start` spawn a new thread in the background, in which case you can return quickly with something like a `JoinHandle`, or a channel where you can send a quit message, or some abstraction around all that. What I did not understand was, if you really want `start` to never return, who is going to call it? Is the caller supposed to spawn one thread for each component and then call `start` on each one? 
If you haven't used InfluxDB, how can you give an accurate evaluation? Line format maybe messy, but you programmer don't have to deal with it. Most of people use some InfluxDB client library, not play with the line format directly. There is request to support binary-based protocol, like Postgres one. But the InfluxDB developers think that it is not urgent, so they will not do it soon.
Yeah, `Windows` is the only widely-used OS that does not use overcommit.
I've got a collection of vectors of references to structs. I'd like to flatten all of these vectors into one vector and then remove duplicate references so for example: `struct SomeStruct {` `// ...` `}` `let mut vectors = Vec::new();` `let a = SomeStruct{};` `let b = SomeStruct{};` `let c = SomeStruct{};` `vectors.push(vec![&amp;a, &amp;b]);` `vectors.push(vec![&amp;a, &amp;c]);` `// SomeCleverFunction(vectors) -&gt; [&amp;a, &amp;b, &amp;c]` The internet suggested sorting and deduping the fields but as far as I can tell references don't support the necessary traits. I'd assumed there was some kind of built in comparison for this but the closest I can find is to cast it like in: `&amp;a as *const int == &amp;b as *const int` Is there any tidy way of implementing the equality functions on references of vectors or do I need to implement the dedup by hand?
You may have some luck with batch mode. Send a command to exit when you're done.
I'd say that the 'run anywhere' goal would be a _more_ of a reason to include value types compared to C#'s windows desktop target... 
folliwing python path, you can get this: extern crate subprocess; fn main() { subprocess::Exec::cmd("vim").arg("/tm/test").join().unwrap(); } which will reuse your app stdin/out.
This looks like a bug in `std`, since it should be using `inherit` by default, but maybe `inherit` doesn't do what it says?
I don't know how reproducible these benchmarks are, but they're interesting: https://blog.timescale.com/timescaledb-vs-6a696248104e TimescaleDB is also just a Postgred extension, so maybe it would work well for you.
This is really cool. I just started a site with a rust backend and elm frontend, and I'm sort of wishing I would've tried the elm-inspired rust wasm framework Yew like you did. Elm is nice though, and probably has more features as it's older. But still, very cool post and I'll definitely be trying Yew some day.
If I'm understanding you properly, you're asking about comparing the references, not the data pointed to by the reference. Then casting to a raw pointer is probably the easiest way to do this, and considering Rust references compile down to pointers, there is no performance loss this way.
that might work, but that's an inappropriate use of a materialized view. that should be a table, not a view, if the goal is for it to be the only copy of the data.
You can write from the file into stdout like writing to any other file or piece of memory. 
LINK???!!!
&gt; only use Rust for code (except CSS and initial index.html) next steps: add functions to build.rs that take some rust representation of css and html and write these out at build time
Interesting. What makes you say that?
Interesting! Thank you very much.
Out of interest: why un-`quote!`? To compile on stable in Rust2018?
I did too for years, but I think a large part of it is understanding what is being modeled by a particular pattern. You want to capture some aspect of a scenario, and systematize it so it can be easily expressed and therefor worked on. Usually this involves interleaving a couple approaches together. I personally really dislike most Java design patterns that try to solve the downsides of inheritance while maintaining something that is manageable, I'm more partial to interfaces. But those patterns do help when using inheritance as opposed to going all out with no planning, and I find data-oriented or functional design patterns to be even more useful. Some design patterns are merely implementing a feature that is otherwise first-class in another language. Having higher-level semantics unofficially-documented for manual use in a language is very valuable. e.g. Dynamic Dispatch and Run-time generics in C, or even static-generics with C macros (I'd just use C++ if I really needed the later, but some would run into the need.) Plus, if nothing else, you'll start realizing when your reinventing a limiting design pattern by your own design. So knowing poor patterns is also useful for defensive programming. It's hard to avoid bad things if you don't like them enough understand them. Most things that obscure are a result of people who have already grokked something talking with the shortcuts that they've earned for themselves (though I grant pedagogy can always be an issue, but that's another conversation.)
After some messing around, using status() instead of spawn() worked the way I wanted/expected it to. So I would guess that the inherit is working, and that spawn() just does something different than I thought it did. Thanks for the note!
How about `clone_into_vec`? But I'm not sure it's really necessary... if `x.iter()` returns something that implements `Iterator&lt;Item=&amp;T&gt;`, you can just write `x.iter().cloned().collect::&lt;Vec&lt;_&gt;&gt;()`. One part of missing context: why would need a `&amp;mut I`? `iter` usually returns an iterator over immutable references. 
UnsafeCell seems the way to go if you really want it.
I believe it refers to this issue: [llogiq/mutagen#126](https://github.com/llogiq/mutagen/issues/126).
The event loop also just manages a single connection to Zk. There is no multiplexing across multiple connections going on :) Given the nature of asynchronous responses, the client *may* see neither read fulfilled at one time step, and then both of them fulfilled at the next, if that's what you mean? But it shouldn't be possible for it to see only the latter read fulfilled, unless the server specifically allows that to happen by responding to the latter read request before it responds to the first.
I can give an accurate evaluation of the line format. It doesn't allow some simple ASCII printable strings to be represented. So for my code, I have to worry about tricky corner cases that were overlooked or hacked around (badly) in InfluxDB. Why didn't they use some existing known-good escaping mechanism? It looks like the end-result of a combination one or more of: YAGNI / Agile / caffeine-OD / deadline. Kind of like CSV only much much worse. This isn't just theoretical, we hit real problems due to this. Anyway, the rest of InfluxDB may indeed be excellent, I can't say. There must be some reason we're using it.
We are of mind :)
That's certainly weird...
I have a really huge elm front-end app with rust back-end and also tried yew. I can say elm is way more flexible and mature. Doing the view in elm is very much informative with the error and you can easily pin-point for where causing the error. Yew, however relies on the macro parsing of the html like syntax which is not quite nice at pin-pointing what causes the error, other than it is a macro error.
Look at projects by BurntSushi for example.
oooh, exciting. opencm3 is a pretty nice HAL
Didn't LLVM 6.0 add support for AVR?
There's still a bunch of work remaining: https://github.com/rust-lang/rust/issues/44052.
Would that work, though? https://github.com/thepowersgang/mrustc#progress
https://gonintendo.com/stories/314224-nintendo-sends-dmca-notice-to-github-for-gba-emulator
With my [by\_address](https://crates.io/crates/by_address) crate, you can do this: extern crate by_address; use by_address::ByAddress; use std::collections::HashSet; #[derive(Debug)] struct SomeStruct(u8); fn main() { let a = SomeStruct(0); let b = SomeStruct(1); let c = SomeStruct(2); let mut vectors = Vec::new(); vectors.push(vec![&amp;a, &amp;b]); vectors.push(vec![&amp;a, &amp;c]); println!("{:?}", SomeCleverFunction(vectors)); } fn SomeCleverFunction(vectors: Vec&lt;Vec&lt;&amp;SomeStruct&gt;&gt;) -&gt; Vec&lt;&amp;SomeStruct&gt; { let set: HashSet&lt;_&gt; = vectors.into_iter() .flat_map(|v| v) .map(ByAddress) .collect(); set.into_iter().map(|x| *x).collect() } (In Rust 1.29 and later, you can replace `.flat_map(|v| v)` with `.flatten()`.)
I'm not sure I follow. Could you show me an example?
std::ptr::cmp, I believe, is a convenience method for this comparison.
And here's how I would write it without `by_address`: use std::ptr; fn SomeCleverFunction(vectors: Vec&lt;Vec&lt;&amp;SomeStruct&gt;&gt;) -&gt; Vec&lt;&amp;SomeStruct&gt; { let mut v: Vec&lt;_&gt; = vectors.into_iter().flatten().collect(); v.sort_by_key(|a| *a as *const _); v.dedup_by(|a, b| ptr::eq(*a, *b)); v }
Could you show how you can make it work by removing 'move'?
Performance reasons, mostly... Saving a little on binary size is meaningless if it causes a much bigger increase in heap memory usage, which IMHO lack of value types brings about (by not allowing contiguous containers etc.). Not to mention the cost of additional indirection. 
It actually uses `sync::Once` internally rather than a `Mutex`. You have to use a `Mutex` yourself if your use-case requires it.
How do you use a macro to call a function with the name provided as &amp;str? This is my (simplified) code: macro_rules! call { ( $name: ident ) =&gt; { $name(); } } fn main(){ let names = [String::from("c1"), "c2".into(), "c3".into()]; ); }
Still working on my [distributed experiments](https://github.com/pierre-l/Pierre-s-Distributed-Experiments/). After my PoW blockchain network simulation, I'm working on a very simple cryptocurrency simulation. It should be similar to Bitcoin though it will only cover P2PKH transactions. I hope to complete this in a couple weeks. Have a nice week fellow rustaceans!
It actually doesn't use a `Mutex` internally. It uses `sync::Once` instead. So by default something created with `lazy_static` actually is immutable after creation; you'd have to intentionally use a `Mutex` yourself in order to introduce mutability.
That's the proposal, implement Mul&lt;Duration&gt; for numbers, and then multiply a number by one of the predefined duration constants.
Yes, I’d like to stream from stdin to stdout and from a file to stdout.
&gt;I wanted to write &gt; &gt;&lt;i class="fa fa-trash fa-fw", aria-hidden="true" /&gt; &gt; &gt;, but instead we must write &gt; &gt;&lt;i class=("fa", "fa-trash", "fa-fw"), aria-hidden="true", /&gt; You can, if you use: `[dependencies]` `yew = {git = "`[`https://github.com/DenisKolodin/yew`](https://github.com/DenisKolodin/yew)`"}` 
&gt; But if Duration should ever be used to represent a time interval It already can not be short of a model change, Duration is documented as composed of a number of seconds and nanoseconds. You can't do intervals / relative deltas with that. It matches pretty exactly to JSR310's own [Duration](https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html).
Spent the weekend converting my RSS reader backend from [here](https://bheisler.github.io/post/jarvis-impressions-of-rust-libraries/) from JSON-over-stdio to JSON-over-HTTP. In keeping with the theme of that blog post, some impressions of a couple of Rust HTTP frameworks: I initially used actix-web because it was supposed to be super fast. I ultimately switched away, but this shouldn't be interpreted as a knock on actix. The existing code is entirely designed around a synchronous request/response model, and I didn't want to change too much of the code. I found this produced a lot of impedance mismatch with actix' async-all-the-things design. It would have been possible to do, but only with a lot of boilerplate. At the end of the day, it wouldn't even have been much faster because the HTTP framework isn't a major bottleneck when almost every request has to hit a SQLite database anyway. I ended up switching to Rouille, and it was so easy! I converted the entire backend process in just a couple of hours. I think it took longer to modify the Java client to use HTTP than it did to implement the server. Additionally, it also made it really easy to use an `RwLock` to allow many threads to read from the SQLite database but only one to write to it (sure would be nice if I didn't have to implement my own locking &gt;\_&gt;). It's still plenty fast enough - `wrk` benchmarks it at \~2k requests/second (I expect on the order of tens of requests per day, max) and I think even that is limited by network bandwidth rather than disk IO or CPU speed. The only thing I didn't like about it is that the documentation doesn't make it clear that the programmer needs to explicitly apply content encodings like gzip, or how to do so. HTTP tools that I've used typically do that transparently, so I found this surprising. I think I like that it's explicit here, but it'd be nice if the docs were clearer about that.
In comrak everything is parsed into a \[tree\]([https://github.com/kivikakk/comrak/blob/master/src/arena\_tree.rs](https://github.com/kivikakk/comrak/blob/master/src/arena_tree.rs)) of \[nodes\]([https://github.com/kivikakk/comrak/blob/master/src/nodes.rs](https://github.com/kivikakk/comrak/blob/master/src/nodes.rs)). The arena\_tree API has iterator methods for walking the tree, and from there you look for the node you are interested in, borrow it mutably, and do what you like. The tree is completely mutable so you can mutate nodes, insert, remove, anything, during a traversal. Your 'src' attribute will be in a \`NodeValue::Link\`.
In comrak everything is parsed into a [tree](https://github.com/kivikakk/comrak/blob/master/src/arena_tree.rs) of [nodes](https://github.com/kivikakk/comrak/blob/master/src/nodes.rs). The arena_tree API has iterator methods for walking the tree, and from there you look for the node you are interested in, borrow it mutably, and do what you like. The tree is completely mutable so you can mutate nodes, insert, remove, anything, during a traversal. Your 'src' attribute will be in a `NodeValue::Link`.
copy() can help you with both of those things: https://doc.rust-lang.org/std/io/fn.copy.html That said, copy is a very simple function. It's worth taking a look at its source code, to get a sense for how it's using the Read and Write traits under the covers.
&gt; I'm wondering if there's any specific aspect of the impl period you're interested in that you feel is missing right now? /u/aturon I think that the difference was the last years fanfare and marketing of libz-blitz followed by impl period. There was a pervasive feeling that someone with little to no experience can and will really make a difference in the grand scheme of things while learning whole bunch and getting to know the community with toppics spanning full spectrum of required experience and incredible amount of effort put into mentoring. This years effort is much more structured but: - there seam to be less toppics available for newbies or these toppics are less advertized - there is an air of old guard needing to focus on important stuff which makes this years effort seam less approachable. I'm sure that exactly the same ammount of effort was put into all of these things and it boils down to marketing.
Reading code helps. Writing code (or even designing from scratch) helps more. I've noticed one thing about Rust. If you do a bad design up front, Rust will let you know. The first few attempts you'll do you'll end up with a dead end, fighting everything (the borrow checker, types, …). You could win that fight, but the code would be terrible. Then you'll change the design a little bit, it'll click and then suddenly everything will work and be elegant. After few attempts like that, go read some code and you'll recognize places that are good code and places where the code smells.
No one has really put together an RFC for named parameters, as far as I can tell. The closest thing is [this "wishlist issue"](https://github.com/rust-lang/rfcs/issues/323). In short, they're not coming any time soon, at all. If someone wrote up a thorough RFC and pushed it through the process, named arguments might land on stable in the next 6 to 18 months, but no one is actively, publicly exploring this. It's just a "nice to have" item on my list. Swift had to have it because it's such an integral part of the Objective-C APIs, and full Objective-C compatibility is necessary for Swift.
&gt; done in the C++-ish naming convention that Casey uses, not a single snake\_case name to be found. daaaamn. I got up to day \~25 or so and was glad I did but 140 is crazy =)
The problem is that there is no known invariant that perfectly distinguishes non isomorphic graphs. I can use this notion to hash the graphs, but it is lossy. There will be some non isomorphic graphs that nonetheless generate the same hash, and so one (or more) will be lost. As an example when I first tackled this problem I used as a label the number of red edges on each vertex. Using that approach there are a lot of non isomorphic graphs that generate the same label, and so I lost a lot of graphs and ended up with the wrong answer. Since posting the original question I have reached a point in the program where the vast majority of the time spent is on checking for complete subgraphs and on isomorphism checking a small handful of graphs I still can't distinguish. Now my bottle neck is mostly lack of memory so to continue with this project I need to deal with a whole other set of problems, like storing intermediate sets on disk, and potentially sorting lists so big they don't fit in memory and other such fun problems.
So I started working on [the Synacor challenge](https://challenge.synacor.com/) and learning Rust at the same time. Progress is very slow but I'm getting there. Also, already asked my fair share of newbie questions.
sqlite3 supports concurrency as long as the file is on a local (not networked) disk. It indexes tables with a BTree structure that very naturally supports range queries.
Taking a break from working on ggez for a week or maaaaaaaybe two. I want to make a simple UEFI bootloader in Rust, 'cause booting an OS directly into 64 bit mode is basically all I've ever wanted from life, but it's somewhat slow going.
There is no need to be always explicit - the documentation even has a chapter on lifetime elision, where it says: "Some lifetime patterns are overwelmingly common and so the borrow checker will implicitly add them to save typing and to improve readability." (https://doc.rust-lang.org/rust-by-example/scope/lifetime/elision.html, https://doc.rust-lang.org/book/second-edition/ch10-03-lifetime-syntax.html#lifetime-elision
Thank you for building this very important infrastructure!
Ahh. I'd forgotten. I generally agree there. I'd much prefer doing it by implementing `Mul&lt;u32&gt;` for `Duration`s and then using the predefined constants, to keep domain-specific `impl`s away from the primitives altogether.
Lifetime elision means that there are a lot of places where you don't have to put explicit lifetimes. So if you have just one argument that is a reference and your function return type is a reference (or even multiple references) then it is assumed to be of the same lifetime and you don't need to be explicit about it. This happens a lot (it would be interesting to know how often). If, however, you have *two* arguments that are references and the return value is also a reference then you have to be explicit. Maybe the two arguments have the same lifetime. Maybe they don't and the output argument takes the lifetime of the first one (or the second). There's no real way for the compiler to know. You need to know about lifetimes to handle this case.
I want to create a TUI (text user interface) in Rust, so I'm looking for some ncurses wrapper. What I *don't* want, at least from what I can tell by looking at the examples, is something like [Cursive](https://github.com/gyscos/Cursive) -- I don't want to take over the whole screen, but rather just be able to easily read keystrokes and move the cursor around the screen, and I'll take care of painting. [ncurses-rs](https://github.com/jeaye/ncurses-rs) seems probably what I want, but before I go too far into it, are there other options? (That seems fairly low level in some respects -- e.g. [output parameters](https://github.com/jeaye/ncurses-rs/blob/master/examples/ex_4.rs#L38) matching the C API instead of a tuple or something.) And to put this into context, I've been eying Rust for quite some time, but never actually given it a try yet.
Where's this being discussed? Seems like a more general problem with adding new keywords. 
Green threads were dropped because they were not a zero-cost abstraction. Go's existence had nothing to do with the change.
Would switching to `abort` also reduce binary size and improve performance due to lack of unwind logic? One are we'd still need unwinding (for the sake of catching) is tests unless we move away from tests reporting errors through panics. Is this an area where the default for non-tests could change through an Edition? Otherwise, it seems we're stuck with cargo-init and cargo-generate setting it by default.
One of the exciting things about Rust 2018 is that we're getting several features that allow lifetime declarations to be implicit and therefore elided in more cases. It's documented in the [2018 edition guide](https://rust-lang-nursery.github.io/edition-guide/2018/transitioning/ownership-and-lifetimes/index.html): * [Lifetime elision in `impl`](https://rust-lang-nursery.github.io/edition-guide/2018/transitioning/ownership-and-lifetimes/lifetime-elision-in-impl.html) * [In-band lifetimes](https://rust-lang-nursery.github.io/edition-guide/2018/transitioning/ownership-and-lifetimes/in-band-lifetimes.html) * The [anonymous lifetime](https://rust-lang-nursery.github.io/edition-guide/2018/transitioning/ownership-and-lifetimes/anonymous-lifetime.html) * ["outlives" inference in `struct`s](https://rust-lang-nursery.github.io/edition-guide/2018/transitioning/ownership-and-lifetimes/struct-inference.html) 
A quick ripgrep of approximately 300K lines of code in the Servo repo finds 9914 functions signatures containing \`&amp;\`, and only 376 of those contain explicit lifetimes. So in a large real-world code base, about 96% of lifetimes are not explicit. (Note, this only includes single-line function signatures, because I didn't have time to mess around with multi-line regexes.)
This reminds me of a question I've been meaning to ask. For most of Rust's existence, unwinding over FFI has been considered undefined behavior. Rust 1.24 introduced a change that defined unwinding over FFI as an `abort`, but then 1.24.1 came out and reverted that behavior due to some unforeseen problems that were introduced by the change. However, it's not clear to me if that change was ever re-introduced in a future release of the language or if unwinding over FFI is still considered UB.
My preferred compromise would be aborting on *unhandled* panics, even on helper threads.
You might take some legwork to get libcore building (custom target spec, libcore patches, and the odd backend fix), but should work.
I'm happy this kind of tool gains popularity.
Unwinding is also helpful for those cases where you have resources that you'd like to have closed even in the event of a panic, i.e. files or anything else using a RAII pattern. Yeah, yeah, destructors aren't guaranteed to run, etc, but unwinding at least gives it a best-effort whereas aborting doesn't try at all. And destructor-based resource management is an often touted feature of Rust so it would be kinda backwards to have a big part of it turned off by default.
In band lifetimes look like a horrible idea, on a level with making `let` optional and just introducing a variable on assignment if no outer scope has a variable with the same name.
I just ran this and found I was indirectly relying on `smallvec` - got it updated to a secure version in my app. Thanks for the work you're doing!
Compiler complaining about explicit lifetimes being required without me anticipating it are to me a marker that I'm trying to do something "the wrong way". Unless you're trying to nail a low-level memory usage pattern (like an iterator) I find that explicit lifetimes are usually best left unused. Coming from Java, I have absolutely no qualms opting for Rc/Arc references if it makes the code simpler. If required by performance or memory constraints, time can be invested later in devising a scheme which uses basic refs.
Well yes, if your OS lies about finding the requisite memory, obviously mere user-space code can't do much about it 😆 On my machine (Void Linux) it fails at the allocation: ``` const SIZE: usize = 156_250_000_000; // 10 Terabytes . . . let mut v: Vec&lt;u64&gt; = Vec::with_capacity(SIZE).expect("failed to allocate"); eprintln!("allocation succeeded"); for _ in 0..SIZE { v.push(1_u64).unwrap(); } eprintln!("program finished properly"); ``` ``` thread 'main' panicked at 'failed to allocate', libcore/option.rs:987:5 note: Run with `RUST_BACKTRACE=1` for a backtrace. ``` You can disable overcommit on Linux with the "vm.overcommit_memory = 2" sysctl. 
Maybe not that weird. The key difference between `status()` and `spawn()` is that the former waits for the process to finish. As originally written, the program started `vi` and immediately exited, leaving `vi` without a parent process, and thereby without control of the TTY. You can easily re-create the situation from the shell by running `sh -c 'vi &amp;'`. You can even run `sh -c 'vi &amp; sleep 10'` and for ten seconds you'll be able to control Vim just fine, but after that it will exit with "Error reading input." `status()` on the other hand waits for as long as it takes for the subprocess to exit, so the subprocess retains access to the TTY.
&gt; Unwinding is also helpful for those cases where you have resources that you'd like to have closed even in the event of a panic, i.e. files or anything else using a RAII pattern. In theory, the OS has a responsibility to clean up resources like files. Granted, that still leaves non-OS resources.
Unwinding over FFI is still UB. The 1.24 change was reverted because it accidentally broke longjmp on Windows: [https://github.com/rust-lang/rust/pull/48572](https://github.com/rust-lang/rust/pull/48572). I believe the implementation's been fixed up to avoid that but it hasn't yet been turned back on by default. Niko has a comment down near the bottom of that issue that has what I think is still the current status.
Is there a good way of detecting unhandled panics without unwinding?
Does it just make it compatible, or does it also apply enhancements new to the 2018 edition, such as the changed module system, which i'm not sure is finalized yet.
You can easily have non-committed data in user code, e.g. data inside `BufWriter` will be simply forgotten.
I think what they meant was making it so that thread boundaries don't automatically catch panics. Instead the unwinding would propagate up the parent thread by default (and you'd specifically use `catch_unwind` if you wanted a thread's panics to be isolated).
JavaCard users would want to habe a word with you...
Mostly, also to improve compile times and have a clear update path.
There's an issue filed for this approach: [https://github.com/rust-lang/rust/issues/49032](https://github.com/rust-lang/rust/issues/49032). It seems like a pretty reasonable option to add regardless of if it's the default or not.
&gt; ... most of Java code is bloated I'd like to know how you measure this.
You're right, it just takes `&amp;I`, no mutability necessary. Not sure where that comes from. I'm just using this function to shorten my tests. If I didn't use it, I'd need to write x.folds.iter().cloned().map(|(r, k)| (r[0], r[1], *k)).collect::&lt;Vec&lt;(u64, u64, Keyword)&gt;&gt; all the time, and I just wanted a function to shorten it, and got interested in naming schemes...
Isn't it reasonable to assume they'd be more common in multiline function signatures ? 
To quote a famous scientist: \&gt; It's alive! It's alive, it's alive! But really, had it installed for ages and the project almost felt dead.
&gt; If I understand the signature of your function correctly, you are consuming the values into the returned vector. No, they need to be copied (they're all `Copy` anyways), sorry if I didn't make that clear. &gt; I think it is descriptive. It is however a bit more work, because you need to implement an iterator struct. I do have an iterator, it's just that the overall situation is a tad more complicated. You can see the function implementation [here](https://github.com/KillTheMule/nvimpam/blob/impro/src/folds.rs#L215), and its usage [here](https://github.com/KillTheMule/nvimpam/blob/impro/src/folds.rs#L352). Note that when trying to just paste the function definition into the `assert`, I'd have to put in a type hint for `collect`, making this quite a bit long.
I think you would benefit from trying out [IntelliJ Rust](https://intellij-rust.github.io/) which automatically annotates variable declarations with types, as if the author had written out the type.
I don't think they really would, provided they know the limitations of that platform. People tend to do all sorts of things including running scripting languages like JS or Lua on MCUs. That doesn't mean any of that is a particularly great idea. Besides, JavaCard used a subset of Java (and a custom bytecode encoding) and so technically it's really Java. I hear garbage collection was particularly wonky and wasn't typically done (if it was supported at all). I believe JavaCard would've benefited from value types... 
I've personally found that it occasionally obfuscate scode when reading through libraries, but I've also found myself aliasing it when many functions use a result with the same type parameters. As long as I can find the unaliased definition within a single "go to definition" navigation, then I don't mind, but please don't send me on a wild goose chase.
This is a real problem that I've experience in production with Java. We have a complicated application with dozens of threads, from internal threads for data storage, HTTP, API, messaging, and more. When something happens such as an OutOfMemoryException, inevitably some thread somewhere dies and our application lives on in some sort of zombie state, different each time, depending on what thread got the exception. There appeared to be no real solution to this until Oracle Java 8u92.
The lifetimes will still have to make sense to the borrow checker. Can you come up with an example where that isn't sufficient to prevent people from making mistakes?
It only obfuscates code if you're choosing to import it and use it that way. Diesel uses (for example) `serialize::Result` and `deserialize::Result&lt;T&gt;` respectively, which is much clearer in my opinion than `Result&lt;(), Box&lt;Error + Send + Sync&gt;&gt;`
Continuing work on fixing papercuts in our C to Rust translator and preparing Rustconf talk on the subject :) Also, the demo site (www.c2rust.com) was recently updated!
I was wondering the same while reading the article. I looked and asked, it seems that we just forgot to undo the revert. I’ve filed https://github.com/rust-lang/rust/issues/52652
Yes, this seems likely. Note that 75% of function signatures in the Servo repo are single-line, so while the statistics above may be biased, they *do* account for a majority of the functions in the repo.
Lifetimes in function signatures aren't too common in my experience, no. Something that at least "feels" more common to me is the definition of types that are parameterized over lifetimes. But still overall somewhat infrequent.
I made it work by adding a lifetime parameter to bar. [https://play.rust-lang.org/?gist=c4c7bd74ea5ea2e3bb57e7a5b316bf5a&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=c4c7bd74ea5ea2e3bb57e7a5b316bf5a&amp;version=stable&amp;mode=debug&amp;edition=2015)
I expect because done components have no DOM node associated with them and do not need to be rendered.
Shouldn't `libtest` just export enough stuff for people to manually plug their own things into it?
I don't see how propagating up the parent thread would work in general (it could work for specific cases, like scoped threads). What I suggested was turning it into an abort using the same logic used when aborting on panics crossing FFI boundaries.
&gt; Also, you pay the price for being able to panic even though you never do. Functions that contain at least one value with a destructor (even a generated one) need to create „landing pads“ ‒ markers on the stack that are used during the unwind. These don’t come completely free, so this is against the philosophy of paying only for what you’re going to use. These costs are somewhat defensible in C++, where exceptions are commonplace, but panics should not happen in a correct, production program at all. I really don't understand this. Sure, programs shouldn't have bugs, and yet they almost always do! The *entire* reason that Rust exists as a language is the realization that human beings are literally incapable of writing large, correct programs in C and C++. Rust catches some of those bugs (e.g. use after frees) at compile time, but a large swath of them (e.g. index out of bounds) end up being caught at runtime through panics. Thinking that you don't need landing pads because of course your code would never be broken seems overoptimistic. &gt; This is obviously wrong ‒ having an application in a half-dead state in production, but not getting it restarted, for who knows how long, is something a robust application doesn’t do. If the application is in a half-dead state and isn't being restarted for some arbitrary period of time, then it seems that you need better service monitoring infrastructure. As an example, we had a small bug in our Rust-based service a month or so ago. One of the endpoints had a bit of user-provided configuration that specified the number of buckets to divide the output into. We forgot to explicitly check for a bucket count of 0, and hit a divide by zero panic when some upstream thing happened to make a silly request. Because panics unwind, that client got a 500 and the server continued to successfully serve all of its other requests. The panic got propagated through our logging infrastructure, we fixed the bug the next day, and rolled it out at the next convenient time. If panics had instead aborted, this would have been a catastrophic, page-me-at-3AM, user-facing-downtime, immediate-hotfix emergency. In what world is that preferable? Even if the panic was in some more critical component and the process started e.g. leaking resources, we'd be notified that the panic happened, and then be able to decide if we need to immediately bounce the service, or let it run for a bit until e.g. users went home for the day. &gt; A Mutex can get poisoned if it was locked while panicking and anyone else touching it will then get an error (which is commonly handled with unwrap, propagating the panic). I disagree with the stdlib's poisoning policy for synchonization primitives for the same reason. In my experience, a panic while a mutex is locked almost never causes some horrible corruption of internal state. A complete denial of service when a bug happens doesn't seem worth it. There have been a few contexts where I've needed a poisoning system for correctness-critical work, but in all of those cases I couldn't use the built-in poisoning *anyway* since a normal `Result::Err` needed to poison the component as well. For example, there was a period earlier this year where the RLS would panic inside of Racer or something while holding a lock. That would normally be fine - I wouldn't get autocompletions for that specific instanct, but that's not the end of the world. However, the RLS instead stopped working entirely as every single request from that point on resulted in a poison error when taking that lock again.
Another example, which I used in a userland driver, is detaching the kernel driver from a USB-interface and reattaching it on `drop`. When the program panics, the `drop` method will be called and the kernel-driver reattached, which wouldn't be the case if `panic=abort`. In my case I wrote a userland driver for a keyboard, so not reattaching the kernel driver meant that I was unable to use the keyboard, leaving me in an unrecoverable state if I wouldn't be able to unplug-then-replug the USB cable to the PC.
When RLS is playing nicely, VS Code shows the type of basically anything on mouse hover. You’ll want to install the right plugin for your editor, which I believe can be found [here](https://areweideyet.com/) .
Not a helpful response but based on the title I thought you were going to be lamenting about how other languages have omitted the Option type and instead opted for the abomination that is NULL. I agree with that other you.
I'm not too concerned with the no unwinding part. What I want is the ability to use `catch_unwind` while threads which don't bother to catch panics shouldn't silently exit while leaving the process running.
Well, whether it should or should not is a good question. But right now it doesn't. And it doesn't look like this will change anytime soon. Having an external crate is easier right now. It also allows more flexible experiments.
There's no such feature in the standard library, so your choices are to write your own library for it, or use one that someone else has written. Is there a reason you don't want to use a library?
[mrustc](https://github.com/thepowersgang/mrustc) \- although it seems far from production-ready, and readme makes it sound like the compiling to C is temporary measure. There used to be [crust](https://github.com/uwplse/crust), but it seems it's been inactive for quite some time now.
With LLVM you don't need (or shouldn't, at least) to worry about platform specific toolchains/compilers/linkers. Using `lld` (the LLVM linker) instead of the default one should be enough.
Is there a good resource for experience ES7+ programmers are prefer programming functionally to learn Rust? I'm going through the book now and honestly, I'll probably finish it, because it's really good regardless of it's audience, but it seems to assume everyone comes from an OOP background. The first half of the book worth of demo code felt like really terrible code, then I came to use iterators and realized I could write Rust in the same concise way I would write Javascript. I tried googling for resources, but only found an article helping basic javascript developers. It was focused on the specific languages constructs on Javascript, not on the concise new language features that make Javascript as popular as it suddenly is (functional programming, object destructuring, arrow functions, generators, etc.) Sorry that my question is sorta all over the place.
In the example you give me, I am not sure how the second solution is less clear than the first? There are more words to be read, but it is more communicative of what is going on?
How is the developer prevented from knowing additional steps must be taken, exactly? The type signature is very clear, and the compiler will complain when you didn't bother to read the documentation. I don't see the problem here, should all methods just allocate instead?
Passing each field of a struct individually is also more communicative of what's going on, but we still choose to use structs to give names to things which go together
Yes, because I added the comment. Imagine the example without the comment. Imagine its the quick usage example people see in github in the readme. Say you modify it and do the naive approach. I strongly suspect if we did this more in our usage examples, we'd make more ergonomic apis for accomplishing this task to make for better-looking examples. 
And don't just downvote because you think this is basic "read the documentation" type stuff. There's a lot of work in the Rust book for example, that avoids this exact trap. And there's a clear focus from that book about working with the way developers work unless its unsafe or leads to bad code. 
it looks like the commit that enabled that was made 28 days ago on `master`. I wonder when the next release to `crates.io` is going to happen?
This week in [tarpaulin](https://github.com/xd009642/tarpaulin) I'm going to close a couple of issues hopefully. I've already kicked off the week by merging a [PR](https://github.com/xd009642/tarpaulin/pull/137) which is nice! I'm not sure how much time I'll be able to dedicate since I'm fairly busy but I hope to get a few things done. Definitely won't have time to work on any rust embedded stuff :(
Is there a workaround for the poisoning issue? I'm facing the same thing, I have a local application that just runs on my desktop computer, and has a set of threads, one of which may panic and then never recover despite restarting the thread on catch_unwind, due to the poisoned mutex. Perhaps there's a crate for a mutex that can unlock the mutex on panic?
I want to second that suggestion. I think you have to turn it on in settings manually, it's not enabled by default. Here's an example image with annotation next to \`let mut vec\` [https://i.redd.it/1er3hcxevvmz.png](https://i.redd.it/1er3hcxevvmz.png)
Just to be clear, Rust always performs lifetime checking, even if you don't actually write lifetime annotations. Functions with no explicit lifetime annotation get elided, meaning that a few rules (which don't involve checking the function body) are applied by the compiler to guess what the lifetime annotation should be. The lifetime checker will still fail if the guessed lifetime doesn't actually work. For example, these two function signatures mean exactly the same thing: fn foo(x: &amp;T) fn foo&lt;'a&gt;(x: &amp;'a T) In both cases, rustc interprets it as "foo can accept a reference to T with any arbitrary lifetime." If you try to store x after the function returns, *neither function will compile*.
The thing is that Elm is *designed* for front-end development.
Yep, there are a couple of options: * The [`PoisonError::into_inner`](https://doc.rust-lang.org/std/sync/struct.PoisonError.html#method.into_inner) method allows you to ignore the poison error, so `mutex.lock().unwrap_or_else(|e| e.into_inner())` rather than `mutex.lock().unwrap()` will ignore the poisoning. * The [antidote](https://crates.io/crates/antidote) crate wraps the stdlib types and provides a non-poisoned interface by doing the into_inner dance for you. * The [parking_lot](https://crates.io/crates/parking_lot) crate provides a separate implementation of synchronization primitives that aren't poisoning in the first place.
https://github.com/japaric/rust-cross/issues/42
\&gt;I really don't understand this. Sure, programs shouldn't have bugs, and yet they almost always do! I believe OP is not arguing that panics shouldn't happen because your code shouldn't have bugs. They are saying that recoverable bugs should, and are, handled via Result&lt;&gt;, while panics are relegated to unrecoverable errors and should abort anyway. \&gt;If panics had instead aborted, this would have been a catastrophic, page-me-at-3AM, user-facing-downtime, immediate-hotfix emergency. In what world is that preferable? The common practice when deploying node.js and game servers is, simply, restarting the service if it fails. So you web server would have simply restarted and kept serving new requests in a consistent state. On the other hand, if one of the threads handling an important but not independent logic dies, you're entering the uncharted territory of inconsistent state.
&gt; I don't want to use an entire crate for this. The way to do this is to use a crate. If you're happy using the "entire text/template" package in go, then you should be fine using an entire crate too.
https://docs.rs/parking_lot/0.6.3/parking_lot/type.Mutex.html#differences-from-the-standard-library-mutex
What have your experience with actix-web been so far? Can you recommend it for a new web project?
Maybe [console](https://crates.io/crates/console)? Haven't used it myself yet.
Yes, `panic=abort` reduces binary size, and may improve performance.
Thanks for your insights. Rouille doesn't seem to be that well-known yet, atleast going from the stars on their github page (349 at this point): [https://github.com/tomaka/rouille](https://github.com/tomaka/rouille) Do you think it is stable enough for a serious project?
&gt; They are saying that recoverable bugs should, and are, handled via Result&lt;&gt;, while panics are relegated to unrecoverable errors and should abort anyway. That would look like forbidding things like `a / b`, `a[b]` in favor of `a.checked_div(&amp;b).ok_or(MyDivideByZeroError)` and `a.get(b).ok_or(MyIndexError)` in all of your code and all of your dependencies. That is not a realistic option. &gt; The common practice when deploying node.js and game servers is, simply, restarting the service if it fails. Sure you're definitely going to restart it, but all of the requests that were running on the server concurrently are going to fail. The server is going to take some nonzero amount of time to start up again, during which load on the rest of the cluster is going to increase. If whatever killed that server (either by accident or intentionally) keeps making those requests, it's going to start knocking over the rest of the cluster as well. If that divide-by-zero I mentioned up above was triggered by some user experimenting in an iPython notebook or whatever, should they have the ability to kill an entire cluster? They're probably going to try to rerun that request after it fails to come back with a response a couple of times! &gt; On the other hand, if one of the threads handling an important but not independent logic dies, you're entering the uncharted territory of inconsistent state. Why would you assume that restarting would put you back in a consistent state at that point? Nothing's limiting your buggy logic to only touching in-memory state rather than persistent state. A process that's partially in an inconsistent state is not uncharted territory. Things keep running while being unhappy all of the time.
Thank you. How can I wait for the spawned joined future to be finished executing?
That doesn't seem particularly constructive or concrete to me. Do you have more concrete problems with in-band lifetimes? Examples of where it would be problematic would be super helpful in demonstrating your point. I think that in-band lifetimes look like a great addition because it's just a bit of sugar on top of what already exists. Unlike your example of making `let` optional (which I think is so short that there's not much argument for losing the nice ability to reason about where things are defined), every case that I understand I would use in-band lifetimes don't really seem error-prone. IMO, in-band lifetimes are also way more straightforward to read and write conceptually.
Love it! Thanks for sharing! I'll make sure to try it in the following days and add some features if I see that something is missing 👍
 rt.spawn( join_all(futs) .map(|results| { println!("All the joined futures have completed without errors. These are their results: {:?}", results); () }));
When my instructions were originally written you could not use the LLVM linker while cross-compiling and so were forced to use the gnu toolset instead for its linker. This is no longer entirely true as the [LLVM linker is now included in the rust toolchains](https://github.com/rust-lang/rust/issues/39915) but it is still experimental and as far as I can tell requires nightly (and [is currently broken](https://github.com/rust-lang/rust/issues/52634)). While it would be nice to use the LLVM linker it is not fully practical yet (and prone to breakages).
Thanks, also (indirectly) linked from above: https://github.com/mdaffin/rpizw-rover/issues/2
In short, download a known working version of the gnu linker and use that. Not the most ideal solution but currently the most practical from my perspective. At least until rust has native and stable support for the LLVM linker.
Hmm, well yes, but I am still not clear on how that is related to what is going on here. This is probably because I might be misunderstanding you when you say: &gt; It only obfuscates code if you're choosing to import it and use it that way. What do you mean by "that"? As in the form `Result&lt;()&gt;`? 
Yup! or, spawn *something* for each component to run in. I didn't want to do the first thing you mentioned because it forces the caller to use `std::thread` (maybe there's some other concurrency primitive they want to use). In the second half of the post I went over what you'd need to do if you *did* want one thread per component
So you can choose to write `use diesel::serialize::Result` and then reference it as just `Result`, or you can choose to write `use diesel::serialize` and then reference it as `serialize::Result`. It's up to you whether you want that context or not. In a similar vein, I very rarely directly import items from the `mem` module. I think most agree that it's better to write `mem::transmute`, `mem::swap`, `mem::forget`, etc. Same with the `ptr` module. However, there's nothing stopping you from writing it however you want.
So far my solutions to this are: - Don't use Ubuntu (it is their gnu linker that is not compatible with armv6) - Download/build a working version of the gnu linker (like how [this example does](https://github.com/tiziano88/rust-raspberry-pi/blob/master/Dockerfile)). - Wait for the LLVM linker support in rust to mature, or at [least start working on nightly again](https://github.com/rust-lang/rust/issues/52634). None of these are ideal solutions.
Yeah, it's just not at that stage -- the alpha.1 release is the first time we've gotten tests passing. We worked closely with the Tokio/Hyper folks with 0.2 integration, and plan to do the same for 0.3. In particular, we're likely to see how far we can get with /u/seanmonstar's [shim approach](https://github.com/seanmonstar/futures-compat).
Yep, that all sounds about right -- many of the working groups have been good places for less experienced folks to dive in this year, but we haven't advertised it nearly as widely/consistently. Good feedback to think about for next year's roadmap!
/u/azure1992's reply is basically how I did it.
I wouldn't say that the code is terrible: its purpose is to teach you rust in an easy way, not to be production ready code, or to be succinct and *pure*. I do agree: a lot of the example code feels like it's based upon users coming from imperative/OOP style languages such as C, C++ and Java. If you're looking for [HOF](https://doc.rust-lang.org/rust-by-example/fn/hof.html) and the like, then I'd take a look at the API for [Option](https://doc.rust-lang.org/core/option/enum.Option.html) &amp; [Iter](https://doc.rust-lang.org/core/iter/trait.Iterator.html). [Tokio/Futures](https://tokio.rs/) builds on these for async programming. 
Perhaps something like a, using C++ parlance, [StrongExceptionSafety](https://stackoverflow.com/a/1853769) marker trait, which isn't implicitly implemented, could inform the compiler whether or not to abort upon panic.
According to the solution you've suggested in response to /u/thiez -- namely, allocating in order to favor owned values -- there's a fundamental tradeoff here between performance and ergonomics. I would argue that Rust gives you so much more of a safety net here that documentation is far less *absolutely essential*, since the ownership of data in the contract of the API has been encapsulated, but you're absolutely right in that documentation to help users fall into "the pit of success" is still super helpful and should be something we strive for where possible.
Depending on how complex your needs are, you could write a macro to do this pretty easily. Keep in mind you can also `write!` to strings. Can you write an example of the syntax you're looking for?
I wouldn't say it saves "a few" seconds. The average is probably a bit under a second... *per variable*. That *really* adds up over even modestly sized programs, though. It makes life harder for readers, yes, but you need to have a balance. Rust is already significantly more verbose than most contemporary languages, and it tries to claw back some of that "effort budget" in other places, like allowing for local type inference. Also, keep in mind that it isn't always practical or even *possible* to write a variable's type. Iterators lead to ridiculously long and complicated types that can span multiple lines, and I don't think anyone benefits from having to write those out. Anything containing an unboxed closure is flat-out impossible (with some changes on the horizon, it will merely become *somewhat* impossible). As others have said: if it bothers you, get an editor that either tells you the type of variables, or at least has a reliable "go to definition" so you can read it off the return type of the function (where the type is mandatory).
I want a struct to own an object, `Foo`, and also an vector objects that contain references to `foo`. Like this: #[derive(Debug)] struct Foo(u16); #[derive(Debug)] struct Bar&lt;'f&gt;(&amp;'f Foo); #[derive(Debug)] struct Baz&lt;'f&gt; { foo: Foo, // This is the foo that is referenced by each Bar in bars bars: Vec&lt;Bar&lt;'f&gt;&gt; } impl&lt;'f&gt; Baz&lt;'f&gt; { fn new(n_bars: usize, foo: Foo) -&gt; Self { let bars: Vec&lt;Bar&lt;'f&gt;&gt; = (0..n_bars).map(|_| Bar(&amp;foo)).collect(); Baz { foo: foo, bars: bars } } } fn main() { let foo = Foo(808); let baz = Baz::new(4, foo); println!("{:?}", baz); } The problem is that `foo` is borrowed in `(0..n_bars).map(|_| Bar(&amp;foo))`. I know that I could do this: #[derive(Debug)] struct Baz&lt;'f&gt; { foo: &amp;'f Foo, // This is the foo that is referenced by each Bar in bars bars: Vec&lt;Bar&lt;'f&gt;&gt; } impl&lt;'f&gt; Baz&lt;'f&gt; { fn new(n_bars: usize, foo: &amp;'fFoo) -&gt; Self { let bars: Vec&lt;Bar&lt;'f&gt;&gt; = (0..n_bars).map(|_| Bar(&amp;foo)).collect(); Baz { foo: foo, bars: bars } } } But I would really like `Baz` to own the `Foo`.
I believe this is the first AAA developer that is fully committing to Rust in production, although \[EAs R&amp;D group has also been experimenting with it.\]([https://twitter.com/repi/status/1002512705792733184](https://twitter.com/repi/status/1002512705792733184))
What is a parser generator? I've seen the term a few times lately
I'm continuing to learn Rust while working on my [git interactive rebase tool/editor](https://github.com/MitMaro/git-interactive-rebase-tool). Specifically this week, I want to remove the usage of `String`s in `Result`s, and instead use custom errors. A recent influx of users has been great motivation to continue work on the project.
To me, this is awesome news because big projects like this (and ReactOS) reveal uses cases in Rust that may need more attention (e.g. lang ergonomics, libs, tooling).
I loved the idea of having `pub` on parameters to signal they can be named by callers (and thus changing their name would be a breaking change). This just made so much sense. Like this: https://internals.rust-lang.org/t/pre-rfc-named-arguments/3831 Postponing named arguments doesn't make sense because APIs that could benefit from it are being written without it. Also, Rust uses named arguments on types.
How do I use `rand`'s `CryptoRng` to generate a number or choose an element? [rand::CryptoRng](https://docs.rs/rand/0.5.4/rand/trait.CryptoRng.html) Am I supposed to implement a function myself using it as a trait bound in order to make use of the crypto feature?
You linked the same tweet twice.
I've heard that Go is basically a replacement for Java. Ultra simple GC language that is supposed to "run anywhere". Also both were supposedly designed to increase developer productivity and quality. Obviously the languages are very different in implementation, but I thought the comparison was apt.
Oops, fixed. I'm not used to this new comment editor. 
Do you mean Redox or is ReactOS using Rust now too?
Do you mean Redox OS?
Excellent and thought provoking post! I've even accidentally written a blog post myself as a response https://matklad.github.io/2018/06/18/exceptions-in-structured-concurrency.html :-)
I have strong opinions about networking in Rust, and one of them is "why does the discussion about it have to live on a heavyweight proprietary webapp?"
We're working on getting an IRC bridge set up, and we'll be trying to keep [the repo](https://github.com/rust-lang-nursery/net-wg/) up to date on major issues. Meanwhile, it'd be great if you could cope with the web app for at least the kickoff meeting :-)
I think the "yes" was in response to "The type signature is very clear" "Yes, because I added the comment", not "should all methods just allocate instead?" "Yes, because I added the comment." This can be better, but this is also at least partially the fault of the user for just using the example and not the documented signature, \_if\_ the example came from [docs.rs](https://docs.rs); if it came from a README, I can see the issue. The *best* way to write this example to avoid this type of confusion would probably be with explicit type annotations: fn main() { let rdr = crate::Reader::from("/etc/values.csv"); let de: Vec&lt;&amp;_&gt; = rdr.deserialize(); println!("{:?}", de); } This would make the presence of the borrow relationship clear in a vaccuum where the example is not surrounded by any other source of that information.
Oh, huh...thanks for the clarification. I feel like that DOES make a lot more sense. I also like your suggestion way better than a comment -- having the compiler check your notes for you is way more healthy, in my opinion! :) One thing I'm still trying to understand in a cousin comment by /u/ZerothLaw is that "we'd make more ergonomic apis for accomplishing this task to make for better-looking examples." I don't think that in this case the API could get more "ergonomic", because a `Vec` of borrowed values seems pretty straightforward to me. Even in more complicated borrowing situations, making sense of how things are borrowed is usually pretty straightforward IME. Maybe I'm just preaching to the choir, but...any ideas there?
Is Vulkano production ready enough for games?
Whoops, yes I did. Fixed and thanks!
I meant Redox OS.
is there anything I can use this for today, directly or indirectly? I've been following it for a long time, and I'm excited to see what happens with it, but things to play with would be fun too!
I may have capitalized the name wrong in the title... oops. :) Some further Rust-related resources: * Preliminary roadmap for inclusion as an alternative backend for the Rust compiler: https://github.com/CraneStation/cranelift/blob/master/rustc.md * Cranelift compared to LLVM: https://cranelift.readthedocs.io/en/latest/compare-llvm.html
I can't help with Piston myself, but perhaps also try asking at /r/rust_gamedev.
&gt; LLVM additionally provides infrastructure for building assemblers and disassemblers. Cranelift does not handle assembly at all—it only generates binary machine code. Does this imply that a Rust build based on Cranelift could not support inline assembly?
is [Discourse proprietary?](https://github.com/discourse/discourse) It is heavy, I agree.
&gt; Protocol support 8, both async and sync (http, http/2, grpc, thrift, etc) I note the lack of https/ssl/tls mention. Having a first-party crypto library would do wonders I think and help sell the language. SSL/TLS/crypto is notoriously hard to do right and a perfect application of Rust.
We’re very aware of issues here; it’s a thing we’ll be paying attention to for sure.
Will there be IRC bridges for all WGs or just for those where important WG members insist on them?
If the bridge works well I imagine we'd apply it broadly.
Wonderful! &lt;3
From the docs we see that `rand::CryptoRng` is a _marker trait_. This means that it doesn't imply implementing types have any particular behavior in terms of required methods. If you click through to the source, you see the trait is empty. Lacking any particular behavior, we'll find that the purpose of a marker trait is to signify to the compiler (and consequently the humans involved) that implementing types uphold some property. In this case, the docs tell us that some type `T` implementing `rand::CryptoRng` implies that `T` yields random data such that the random data is cryptographically secure. Refer to the second sentence of the trait docs to see what _cryptographically secure_ means. In reference to your question, there are two options: 1) implement a CSPRNG yourself or 2) use one already implemented to get a random number (which perhaps is taken modulo some collection size and used as an index into the collection to obtain an element). In general, the advice given is to not implement low-level cryptography yourself because it is very hard to get correct. So let's assume you want to pursue option 2. The docs again help us out here by showing us the implementing types (at least in the `rand` crate) for `rand::CryptoRng`. I would again suggest you skim the docs for each implementor to see if one catches your eye for your use case. I would probably defer to the docs for the `rand` crate which use the `rand::thread_rng` function to get a `ThreadRng` (which we can see is `rand::CryptoRng`) and use that as a your source of randomness. If you give more info around your use case, someone can probably be more specific with the code you are looking for. 
To the extent that anything in the Rust HTTP space is stable, yeah. I don't know if I'd want to bet the farm on it. I'd say it's a good fit for non-critical systems.
At the risk of bikeshedding, what happened with the name change? I don’t see any note in the readme. What steps did you have to go to to make it fast enough to replace the macro assembler? Did rust help anywhere with that change?
Yes! I just contributed something similar in Actix: https://github.com/actix/actix/pull/111 you can `impl Drop` and check if the thread is panicking. This is the best option IMO. You can install a [panic hook](https://doc.rust-lang.org/std/panic/fn.set_hook.html) -- that's when I discovered how much stuff panics in a pretty bog-standard binary that uses Tokio. Failed DNS resolution? Panic. Failed connection? Panic. If I used a panic hook that outputted a backtrace and exited the process, it pretty much died as soon as I turned off my wifi. I love Rust, but there's some serious work to be done in the realm of panics. They exist in this pseudo-exception state that kind of hokey-pokeys around with some panics are "expected" (in which case it should be a Result...why are there _so many panics_?) and some are just unrecoverable. Even worse, the stdlib encourages panic as a fatal state by making Mutex et. all poison themselves on panic. There are plenty of cases where something is _wrong_ but I'd like to recover. For instance, in one application I accidentally indexed into a grapheme. Does this mean my mutex is suddenly invalid? No. That should be up to me to handle by recovering or letting the program crash.
Bonus Bonus: EA Seed have a gameplay software engineer job with required skills of "C++ or Rust" https://ea.gr8people.com/index.gp?method=cappportal.showJob&amp;layoutid=2092&amp;inp1541=&amp;opportunityid=151574
I can't imagine how a meeting in a chat channel works... Is there a reason to favor it over having a better record and including a larger audience?
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. Also: begging for free stuff rarely goes over well.
&gt; Rust comes with different ways to handle error conditions Nitpicking, but I don't classify panics as a way of "handling" errors. A panic is a failure mode of a Rust program, just like pulling the power cable of the machine that the program is running on is a failure mode (though a panic tends to be a bit more graceful, mind). I have never seen anybody try to "handle" (as in, recover from) a panic in a Rust program in the wild, which would have to be done by abusing `std::panic::catch_unwind`. &gt; If there was a time machine that could send a message back in time, I think the right solution would have been to implement panic as always aborting the whole program This would be quite bad for anyone embedding Rust code in foreign processes. For example, Skylight (https://www.skylight.io/) sells a Rails monitoring gem written in Rust. If panicking meant aborting, then any panic in their Rust code would bring down their customers' Rails servers. As-is, where panic can unwind, panics can be halted with `catch_unwind`, a log message can be written to note the failure, and the customer's business server can proceed uninterrupted with the only downside being the loss of the monitoring service. It's then possible to argue that aborting could be the default, and unwinding could be opt-in. But defaults matter, and it's easier to get people to care about unwind-safety (alternatively, harder to let them to ignore it) when unwinding is the default. If you're going to have unwinding at all, then making it the default is the safer option. &gt; This paradigm was dropped Keeping unwind-on-panic wasn't done because of Go or anything like that, it was because production users like Skylight needed unwinding. Likewise, production users like Dropbox needed aborting. There's not always an easy compromise for systems languages; this domain is inherently the grottiest and least elegant. I agree that people should consider setting panic=abort if they're not using unwinding (fail-fast is underrated), but both are important in different ways.
Would be amazing if ReactOS used Rust. Cannot imagine that is happening anytime soon though.
Ahhh, I think I see. Okay, that's a decent compromise.
No. But you can use ash or vk-sys.
Some of the rationale re: Discord is available [here](https://internals.rust-lang.org/t/exploring-new-communication-channels/7859).
See this [Github issue](https://github.com/CraneStation/cranelift/issues/362). It was renamed but the issue is still open for discussion.
Maybe inline wasm? Maybe some assembly could be safely converted to wasm? Not super familiar with this space, just a few guesses :)
Could be tricky without introducing reference types. This gets to the core of Rust's ownership semantics: when you construct `Bar`s with references to `foo`, you are pointing to the `Foo` on the stack which gets moved into `Baz` as we exit the function. This means that every `&amp;foo` is invalid in the `Baz`. Any particular reason you need `Baz` to own a `Foo` while still keeping a (vector of) reference(s) to it?
Is there a good way to deal with `dev-dependencies`for things like benchmarks and/or examples? According to the cargo manifest format docs `dev-dependencies` cannot be optional. I could feature gate the bench/example deps in the regular dependencies but I was hoping there was a more elegant method? The biggest issue I am running into is dealing extra compilation time during CI testing. 
This is amazing!
The thing is in golang the template package is in standard lib, which makes it easy for someone to just use it. Using an entire crate for string interpolation adds an extra external dependency to the project. Since, this is small thing I am talking about I don't want to complicate things and thus was looking for a workaround. Though, I will be fine with using a crate too. Any suggestions for some lightweight crate for the same.
I am looking something similar to golang templates library. To be specific I have a string for ssh `authorized_keys` and I want to dynamic fill it up with values. I am not great with macros too, can you direct me to some example for the same. It would be really helpful.
No, I don't say one should handle bugs with Result. What I'm saying is, if I don't care for recovering from bugs and, for example, have a single-threaded program that terminates anyway, I still get the landing pads even when they are useless to me. It's one of the few places I have to *opt out* of extra costs, not opt in when I use them.
Rather than `use std::io::Result` then `Result&lt;_&gt;`, I often write `use std::io;` then `io::Result&lt;_&gt;`. I think that’s enough to make things explicit, there’s no need to go all the way to `Result&lt;_, io::Error&gt;`.
Probably an answer to the general impression of the whole discussion. I wasn't saying that unwinding is inherently evil and saying that you'd *always* have no option but to abort is probably too extreme. But handling unwound threads correctly is a big heap of complexity that is thrown by default at everyone, very often without them knowing about it at all. Sure, if you want to survive a panic in web-page query handling, it makes sense to do so, but more as an opt-in (likely handled by the framework or threadpool crate that needs to do something anyway to restart the thread) than opt-out for everyone else, especially when `std` doesn't really offer any reasonable primitives to handle that complexity. In that sense, yes, a panic strategy "abort-on-uncaught-unwind" would make very much sense.
Would you mind elaborating on why you feel vulkano is not ready, but ash or vk-sys is? Asking as I'm not very experienced with any of them, but have been planning on bailing on glium in favour of vulkano or a project of mine. Curious to hear your thoughts.
Getter, setter, factory, bean, executor, builder... Lots of boilerplate before actually getting things done.
I want to be able to index into a vector with a raw pointer. let pixels = Box::new( vec![30; 100]); print!("{}", pixels[10]); This code works fine (though I would have expected to have to do `*pixels[10]` ) however neither this let pixels = Box::new( vec![30; 100]); let pixels = Box::into_raw(pixels); unsafe { print!("{}", pixels[10]); } nor this print!("{}", *pixels[10]); work. Compiler spits out the message main.rs:6:19: 6:24 error: cannot index a value of type `*mut std::vec::Vec&lt;_&gt;` main.rs:6 print!("{}", *k[10]); What am I missing?
I think this implies that in order to replace LLVM, rustc would need not only a code generator like Cranelift but also an assembler (converter from assembly syntax to machine code), for the `asm!` macro.
Worth noting that in Rust, out of memory is not a panic, but an abort.
The first doesn't work because raw pointers don't get auto-deref like `Box` and regular references do. The second doesn't work because you've got the order of operations wrong: unsafe { print!("{}", (*pixels)[10]); }
Brb Moving to Sweden Why are all the interesting jobs in other countries?
Perfect thank you.
Yes we use Rust as our primary language in SEED since about 4-5 months ago, building a new future based on it. Loving it and this awesome community. Esp. after 20+ years of C++ for professional game and engine development. We are hiring Rust programmers (or programmers keen on learning and embracing Rust) for a wide set of areas (gameplay, engine/graphics, full stack, and more) , primarily here in Stockholm but parts of our team is also in Los Angeles and remote (Netherlands, Montreal, BC). Will write up and share more about our experiences with Rust and what we are working on. But feel free to comment and DM me here or on twitter (@repi)!
We specifically phrased it in the order of “Rust or C++”, because if you know C++ (which is the most common in gamedev), you’ll be learning and using Rust with us :) Don’t find that it takes very long for a good gamedev/engine C++ dev to learn and be productive in Rust, which is great. And once you are, it is a very rewarding language, ecosystem and community!
I'm trying to write a little utility to serve static, multi-file websites for debugging/showing off front-end webdev stuff. I'd like to add a way to inspect HTTP requests, as well as live-reloading.
&gt; I just finished writing the bit where you improve the CLI search with an iterator and then they return... a vector! Gah, why not just return an iterator and keep going?! Because iterators were, and can still be, a huge pain to return due to the types. I've had iterator types that spanned multiple lines, and ended up being longer than the code that created them by several times. Even now, it requires using a non-trivial feature of the language, assuming it's possible at all. Returning a vector in introductory material is probably the correct thing to do.
Is the challenge even possible? Basically you want crossbeam scope with “extra” features, yet the post mention that this is not possible due to memory safety.
[Limn](https://github.com/christolliday/limn) is an early attempt at this. It uses WebRender, Servo’s rendering engine. It doesn’t have many features yet, but it’s a great start.
&gt; Well yes, if your OS lies about finding the requisite memory, Not only my OS, the _users_ OS. If I am writing a library, and I want to handle stuff like this, and I don't know in which OSes the library will be used (potentially all of them), then... this isn't really a solution that works for me.
Agreed. My strategy is "hold the show types button as I mouse over stuff", though this gets harder when skimming on github or whatever. Btw, this untyped thing is also a problem in any language that allows you not name temporaries (ie anything except direct LLVM or something), ie `x.f().g()`, where the return type of f is "infered without declaration and, even worse in this case, without even being documenred with a proper name, but in small amounts it isn't a big deal. One strategy to consider in very long functions is to "checkpoint" types explicitly after a while of the implied context grows too big, though at that point you might just want to split it up. So the conclusion to my ramble... of you lose track of types, just annotate them in the type signatures of functions you split off.
The typed languages that don't use local inference are getting fewer and fewer. Now that java finally added "var", I'm not sure what big holdouts there are?
Ah, it's a compiler, not a translator. I hoped it'd generate readable code.
Thank you! Now it makes perfect sense, I didn't know vim loses tty if its parent dies. Do you happen to know why it's so? I guess it's a result of some Unix design decision but I have no idea why it's designed this way.
Each WG chooses its own communication channels. Some groups have chosen IRC.
Inb4 rust gets bought and is available through lootboxes only...
Yes, that's the good practice!
I am the maintainer of ash, so take my opinion with a grain of salt. I am not too familiar with vulkano, the API seems really well done while looking at the examples. &gt; Plans to prevent all invalid API usages, even the most obscure ones. The purpose of vulkano is not to simply let you draw a teapot, but to cover all possible usages of Vulkan and detect all the possible problems in order to write robust programs. Invalid API usage is prevented thanks to both compile-time checks and runtime checks. If vulkano manages this without sacrificing too much freedom and performance and if vulkano becomes close to stable, then it seems like a no brainer and you should go with vulkano. But the Vulkan spec is fairly large and I think it is extremely challenging to create a complete safe API around Vulkan. I am always a bit weary when it comes to bigger libraries that haven't been used in production. Also some extensions seem very hard to support. Going with ash or vk-sys or any other low level Vulkan lib, seems like the safer choice. Although I have to admit there are some breaking changes coming to ash soon, so that it can properly support Vulkan 1.1. Also you should consider that you are most likely writing some kind of abstraction on top of Vulkan and you most likely only need a subset of the functionality of Vulkan. I also think using raw Vulkan will give you the most freedom in designing your renderer. Another option is gfx-rs but I can't recommend it yet because it is very much in flux. With gfx-portability you will be able to use the metal, opengl, dx backends with ash/vulkano in the future. I always look at it like this, if a project gets abandoned, I want to be able to maintain it. Considering that I only need a subset of the graphics APIs for my renderer, I don't want to maintain things that I don't necessarily need. 
Let's start with the basics. A _code_ generator is a program that writes code. An example most familiar to Rust users is procedural macros. They generate code. You may also say that compilers are code generators. They too generate code. Now, parser generators are programs that generate _parsers_. They take a grammar and give code for a parser. For example, I remember there used to be a `regexp!` macro that took a regexp as a string and generated code for matching a string against that regexp. You may think of regexps as parsers for regular grammars, roughly speaking. So `regexp!` was like a parser generator. On the other hand, `Regexp::new` analyzes the regexp string at runtime, so it does extra work at runtime. Here is a good comparison of parser generators. https://en.wikipedia.org/wiki/Comparison_of_parser_generators
**Comparison of parser generators** This is a list of notable lexer generators and parser generators for various language classes. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I would actually say it's the opposite. Because the ball is rolling in these areas, they don't need much attention. I was disappointed when the Rust 2018 roadmap didn't include anything about games and I don't think 'games' was mentioned in the entire roadmap *at all*. But I kind of see why. People are active in that area, so making it a priority isn't really necessary. Personally I'd still like to see it of course.
Distros are generally built out of a whole bunch of programs, which are programmed in whatever the authors of those programs choose. Generally, one doesn't choose a language around which to build a distro. I'm sure there's exceptions simply because the linux world is full of wonderful variety. Secondly, rust is *not* a one-size fits all solution. Whether its a good fit for a program depends on the needs of that program! Thirdly, a distro is several bajillion programmer hours of work. It's huge. "re-write in rust" would be a multi-year undertaking for a minimal distro.
Building a linux distro usually means to take a package manager and then package and configure a lot of programs to work together into a somewhat POSIX:y system. There is no "main language" for it. There are projects to replace some of the command line tools with Rust implementations. There is a project to make an OS based on Rust - Redox OS, but it will not be a linux distro.
Wrapper types sound like a workable idea, I'm going to explore this, thanks! Default impl + doc might not be workable, because it would be a breaking change, and I assume there's too little gain. I'll bring it up with the maintainer, thanks!
I'm not a rust programmer, but in C++, one the main advantage of using `auto` (witch mean "deduce the type of this variable") is to have a code much more resilient against changes. As long as the general properties of the type returned by your function stay the same (for example, it's a container), your code continue to compile and work, even if the called function's returned type changes. It's extremely useful in generic programming. And like many said, use an ide or configure properly your text editor to have access to this information.
When RLS isn't working (e.g. when I'm working on rustc), I usually try to find the last function or method that was called to create the value, and read its return type. It's not ideal, but hopefully the tooling will be there someday
CraneLift compiles to native code just like LLVM. The current use of CraneLift is as a WebAssembly compiler, i.e. its *input* is WebAssembly. In the future they want to use it to compile other things as well.
Well, if your goal is to develop in Rust but compile it as C, then readability of C part doesn't really matter.
I wouldn't redefine equality, I'd move the graphs directly in the hash-set. This approach just calculates some fail-fast criteria. It won't solve the small handful of graphs. Good luck with your other problems. I (luckily) don't have any experience with those yet.
http/2 is always https though.
Well you can use it to run WebAssembly (although you need to define your own API's for use with WebAssembly). However: * WebAssembly is portable, but CraneLift isn't really ready on platforms other than x86-64. * WebAssembly can be used to safely run untrusted code, but CraneLift makes no guarantees about security yet. I think it'll get interesting if somebody combines it with a decently secure sandbox implementation. Hardest part will be writing the API's that the WebAssembly could use to actually do something useful though.
Thanks ­— i found a few useful crates i hadn't known before too! 
&gt; Even if my OS does not lie, if I am writing a library, I need to care about my user's OS, which might. Yes, true, i have no answers here either. At least with containers, one can write code which deals gracefully on a non-overcommitting system, and behaves the same as otherwise on an overcommitting system. (I doubt whether most users of the latter care very much...) 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Game studio Ready At Dawn switching to Rust for all new development • r\/rust](https://www.reddit.com/r/rust_gamedev/comments/91fmcu/game_studio_ready_at_dawn_switching_to_rust_for/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
When it's ready ^(TM) :)
Only when the client is a browser right?
How notable should be a crate to consider filing rustsecs against it? Is just having some reverse dependencies serious enough for it?
I don’t know, that’s why stack sharing is optional :) Perhaps the API will have spawn and spawn_scoped methods which give you the choice between immediate panic propagation and stack sharing? Agree that a Trio-like reliable cancelation mechanism would help a lot. But implementing it would be tricky. For CPU-bounded loops you can require users to check for isCanceled flag, which not pretty, but works. However, if the thread is waiting in, say, a read syscall, theree’s just no good way to interrupt it (you can send a signal and that’s basically it?).
Awesome tool, thank you! 
&gt; Would you mind elaborating on why you feel vulkano is not ready, but ash or vk-sys is? I assume it's because ash and vk-sys are much lower-level APIs, as a result they're probably not *safe* (especially vk-sys which would just expose the raw vulkan API) but they're very easy to develop, the difficulty is laid at the field of the user. Creating a completely safe API is a much more complex endeavour (even more so creating a safe *and fast* API).
I am very new to rust. So I have this snippet of code: let args = env::args(); if args.any(|arg| arg == "-h") { help(); process::exit(1); } This will not work because of "cannot borrow immutable local variable `args` as mutable". I can of course fix this by adding "mut" to the binding, but this raises a few questions. 1. Why is there borrowing involved at all? I'm just using the variable I just bound. I thought borrowing came into the picture when passing the value to another function or another variable. 2. Why does it have to be a mutable borrow? I'm just reading it's contents. Is it because I'm modifing the iterator when iterating? 3. Does this mean I might as well use env::args() whenever I want to read the arguments instead of binding it into a variable since I want a fresh iterator anyway? This feels inefficient to me, am I wrong or is there a better way of doing it? 
I have a wrapper type `Wrapper&lt;T&gt;(T)`, and I want to impl `From&lt;Wrapper&lt;Vec&lt;T&gt;&gt;&gt; for Value`, where `Value` is a type of the same lib (just in another module). Now I need the impl be different for `T=u8` from all the others, is there a way to do that? I know about specialisation and it not being available, but maybe there's a way because this is all in one crate? Thanks for any pointers :)
Makes sense, I thought it would be nice to depend mainly on one language, and when it comes to some weak point in the language, I can contribute to the language, and enhance that point. It seems to be a lot of work, what I meant by distro though, is that I am going to build it on top of Debian, and rewrite all other main programs in Rust, so that the whole system function well together.
I have questions, if you don't mind! What was the catalyst for SEED to make the switch? I figured the industry would abandon C++ eventually, but I honestly wasn't expecting to see it start tipping so soon. Are other teams within EA investing in Rust, or is it just SEED for now? How are build times for you? I hear they're still working on reducing compilation times in rustc, and I'm spoiled by Incredibuild. And...I have many other questions, but I'm happy to await a writeup :) Thank you for commenting. Hearing companies likes EA and Ready At Dawn start to move past C++ is like finally seeing a light at the end of the tunnel.
Trying to improve the test coverage of [`wayland-rs`](https://github.com/Smithay/wayland-rs) before releasing the 0.21 out of alpha, as following this blog post: https://smithay.github.io/wayland-rs-v-0-21.html Once this is better I'll be able to bang my head on tricky problems such as attempting [linker black magic](https://github.com/Smithay/wayland-rs/issues/189), (if anybody has knowledge on that, I'd love to get some insights!)
&gt; Why is there borrowing involved at all? I'm just using the variable I just bound. I thought borrowing came into the picture when passing the value to another function or another variable. Because you're using `any`, which uses a mutable borrow, see [the doc](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.any). &gt; Why does it have to be a mutable borrow? I'm just reading it's contents. Is it because I'm modifing the iterator when iterating? Superflously, because the signature of `any` says so :) The reason is that `any` calls the `next()` method of the iterator, which changes the iterator (it needs to keep internal state). &gt; Does this mean I might as well use env::args() whenever I want to read the arguments instead of binding it into a variable since I want a fresh iterator anyway? This feels inefficient to me, am I wrong or is there a better way of doing it? How often would you want to read the arguments? In this case, you're reading all of them, but discarding them unless one is `-h`. If you want to keep them around for later usage, you can collect them into a `Vec` (like `let args: Vec&lt;_&gt; = args.collect();`). But you could also just run through them once, process every one of them and then be done with the arguments and get on with the rest of your programm. Of course, there are crates available to help you with this, but since you're learning, I assume you want to do things by yourself :)
I say: If it is on crates.io, file.
Yeah, there no main language, but do you think that you can replace your current desktop with Redox OS? For me I will never do this, it looks too ugly for me, and that's why I am thinking of making a distro based on Debian.
What i tend to do is provoke the compiler into telling me the type by explicitly giving it a wrong type (for which the unit tuple is a good general choice): let config: () = config::parse_config(&amp;env::args().nth(1).expect("command line should name a config"), &amp;mut log_publisher); And then running `cargo check`: error[E0308]: mismatched types --&gt; src/main.rs:65:9 | 65 | / config::parse_config(&amp;env::args().nth(1).expect("command line should name a config"), 66 | | &amp;mut log_publisher); | |________________________________________________^ expected (), found struct `config::Config` | = note: expected type `()` found type `config::Config` This does depend on you being able to edit and build the code, though. In a big codebase, that might be slow.
&gt;primarily here in Stockholm but parts of our team is also in Los Angeles and remote (Netherlands, Montreal, BC). Hope you haven't finished moving :)
Thanks for your answer, it's starting to make sense. Coming from higher level programming I so far feel Rust makes me more aware of what I'm actually doing :). The reason I wanted to check for the -h-flag first was that I didn't want my program to execute anything if it was present. But I guess I can solve this by splitting the argument processing with the program logic which might be a good idea anyway.
Stop the plane I have to apply for a remote job! Thanks for the update because I am seriously considering this 
[Yes](https://www.redox-os.org/)
That's unfortunate. CI is always pressured for more time... You could put benchmarks/examples that use expensive to compile libraries in a separate crate (this crate can share the same repository in a sub directory). It's not elegant but should allow you to avoid compiling dependencies needlessly. Keep in mind that part of the rust testing is that examples get compiled (checked only?) but not executed. This ensures that your examples don't rot and get outdated.
incredibly sad news for me. Rust functional-ish syntax has keeping me from trying it, seeing an AAA studio jump in means that I will probably have to use it someday. Slowly I havent been enjoying this field anymore 
That's not a Linux distro.
IIRC Rust is going to have it's own assembler anyway, because LLVM's assembler is considered an unstable interface and the `asm!` macro can't be stabilized while relying on it
I think there are still too many generally applicable to all use cases for the roadmap to be focusing too much on very specific cases yet. The roadmap is mostly in this style, plus a few things were Rust can have an advantage now. Plus webasm of course, which is probably a fairly stupid thing to focus on, but trendy. 
[The weekly rust newsletter](https://this-week-in-rust.org/) has a "Call for participation" section.
man redox-os is far from being daily driver. It is work in progress and early stage in it is development. Before "it looks ugly" it is not a complete OS. Anyway I'm very excited about redox project to see what can Rust bring in to OS development. And about making a "rust based linux distribution", it is possible (it might even done) write something like busybox in rust. But all the OS ecosystem requires too much work.
&gt; Sure, if you want to survive a panic in web-page query handling, it makes sense to do so, but more as an opt-in (likely handled by the framework or threadpool crate that needs to do something anyway to restart the thread) than opt-out for everyone else, especially when &gt; std &gt; doesn't really offer any reasonable primitives to handle that complexity. The problem is that not having it enabled by default makes it likely that libraries are not panic-safe. 
My first contributed repo in Rust is https://gitlab.redox-os.org/redox-os/ion (Recently, Redox-os project moved gitlab from GitHub) This is a shell language written in Rust. It seems to need help now (becuse there are many easy tags).
My intention was to secretly write the code in Rust, have it borrow-checked, transpile to C and declare it my code, which would get approval to be merged. ;)
Thanks for the comment! It's a bit hard to keep things in context and perspective, but now it's clear that the "next area of" work is really next, as in not even started properly, not "already started and in full force, and we already see the end so be ready to hold your breath!". The compat approach seems promising. And thanks again for relentlessly pursuing this! (Also with the WG Net reboot, which also answered my question.)
If you interested in an OS written in rust, search redox-os project. https://gitlab.redox-os.org/redox-os
I wrote a simple tool to help me manage my wireguard configurations. [https://github.com/endeav0r/wireguard-configuration](https://github.com/endeav0r/wireguard-configuration)
This data structure is pretty awesome, it should simplify a huge amount of my code. 
No explanation, but I find [this website](https://godbolt.org/g/BDDZZB) very useful when looking at assembly.
inline asm is used for inserting instructions/sequences of instructions that your compiler backend can't generate on it's own. Since you are using the same backend to compile wasm to native code, as you use for compiling rust to native code, it will have the same exact limitations. So having inline wasm will not be very useful.
&gt; assembler An assembler would be required, but it wouldn't be enough, since we use LLVM assembly template language, which often goes beyond what an assembler supports (e.g. we can leave register names unspecified, etc.). So we would need a system in rustc to do the same, perform optimizations on the assembly (e.g. choosing register names), and then the assembler itself. Honestly, if Cretonne doesn't provide an assembly template system at least similar to LLVM, GCC, etc., we won't be able to use inline assembly properly with it, because things like actually assigning registers is something that has to be done by the backend itself; I don't see how Rust could do this. 
I remember trying this a while ago. You can definitely notice the speed improvement. Nice job. 
&gt;when it comes to some weak point in the language, I can contribute to the language There are pros and cons with most designs. A weak point is often the consequence of some other strength, not something that is easy to fix. Like in Rust. It is hard to make graphs because of the lifetime rules, but they are there to make memory access safe without needing a garbage collector nor reference counting. In most cases a really good trade off. When it is a bad trade-off the program can be written in some other language where different trade offs have been made. There still is no magic one size fits all language. &gt; what I meant by distro though, is that I am going to build it on top of Debian So what are you going to build? Are you really talking about a desktop environment like GNOME or KDE?
FYI, I just fixed the panic on no people... There are probably better options, but now this won't break hard...
When all else fails I just append \`.fdfasfdsa()\` and then run \`cargo check\` and the type is in the error message :)
Same here :)
&gt;There are pros and cons with most designs. A weak point is often the consequence ... Can't agree more, at this time using another language is much more effective. &gt;Are you really talking about a desktop environment like GNOME or KDE? Yeah, I am interested in creating something like this, you seem shocked 'D.
&gt; is currently broken That looks like people trying to link directly with a linker instead of a compiler wrapper. Linking with `clang -fuse-ld=lld` has pretty much always worked.
Looking at [this link](https://gitlab.redox-os.org/redox-os) that @aimof provided, I can agree with you. I looked at there [Github](https://github.com/redox-os/redox), and they didn't push there from quite some time, so I jumped out to a conclusion that's early to consider, sorry about that.
When I tried vulkano a month or two ago the examples crashed on run. I opened an issue and other people saw similar issues, but nobody knew how to fix it. So, it still won't run on my machine but, ash and vk-sys do. yes, they are both unsafe because they are pretty much just exposing vulkan, but for now that seems to be the best option for using vulkan in rust. maybe pre-ll gfx too. 
I don't have any advice. Just chiming in to say that I'm with you. I also find it irritating that the type annotation is optional on bindings/variables. I know that the compiler is smart enough to figure it out, so it is technically redundant. So, I *understand* why it is the way it is, but it definitely makes it more difficult to read code. The amount of context switching is large. This is just how modern languages are right now (Rust, Swift, Kotlin, even C++ with `auto`). Maybe in a few years there will be a different fad. I also despise the advice to use a specific IDE to "fix" the issue. It rubs me the wrong way to lean so heavily on 3rd party tooling. I lean more and more on tooling for worse and worse languages (PHP, Javascript, Python are unusable without intense support from your editor). But it is what it is. I cope with it because Rust is still my favorite language by far.
Go, I think.
I would love to some day write a JIT for the regex engine using Cranelift. My hope is that it could improve some of the slowest parts of the library, namely, the PikeVM and the backtracker (which are used to resolve capture groups and handle any other case that the faster DFA chokes on).
[removed]
&gt;I don't know why the code is pushing and popping rax. I would have thought that was callee-saving a register, except AFAICT rax isn't callee-saved, isn't used, and should be used for the return value. Rust does not have a specified ABI, so you can't say whether rax or any other register is callee or caller saved (without knowing how a specific rust version is handling it - or if the register choice for the same purposes is consistent at all). &gt;Then there's a load from the stack into rax, a store from rax back into the stack, and a shuffling of a floating-point number from the stack to memory via xmm0! xmm0 is an SSE register (128 bits). While it can be used to execute floating point number operations on it, here it is just a 16 byte copy. movq 24(%rsp), %rax movq %rax, 16(%rbx) movups 8(%rsp), %xmm0 movups %xmm0, (%rbx) So this means (what I think this means) is: move 8 bytes to rax then to the destination of rbx (+16 byte offset) and move 16 bytes (the movups) to xmm0 and then to the destination of rbx (without offset). rbx should be a pointer to the stack space reserved by the caller of get\_value\_single. So in total we've copied the whole 24-byte String-Container to the callers stack. The reason why this is not done in your first examples is most likely because String::from is doing this already itself. Did you compile this with the `--release` flag? I would have expected the compiler to be able to see that it could write directly to the callers memory. (or maybe `#[inline(never)]` is limiting the possible optimisations.)
If so it would be good to have an actual issue in the net-wg repo (if there isn't already).
I don't know of anything other than specialization which is feature-gated. If you accept to use unstable Rust, the solution of your problem is a simple one: #![feature(specialization)] struct Value; // or whatever struct Wrapper&lt;T&gt;(T); impl&lt;T&gt; From&lt;Wrapper&lt;Vec&lt;T&gt;&gt;&gt; for Value { default fn from(_: Wrapper&lt;Vec&lt;T&gt;&gt;) -&gt; Self { unimplemented!() } } impl From&lt;Wrapper&lt;Vec&lt;u8&gt;&gt;&gt; for Value { fn from(_: Wrapper&lt;Vec&lt;u8&gt;&gt;) -&gt; Self { unimplemented!() // your specialization } }
Yeah, it's still sadly unable to provide information all the time. Same for autocompletion. When it does it's great though.
&gt; instead of a compiler wrapper That is an issue for the rust compiler. How are you supposed to use the LLVM linker with the rust compiler otherwise (my knowledge on this is limited as I cannot find much documentation on the subject)?
And he'd also lose the `localStorage` data when moving the html file to another folder..
The RLS is not 3rd party tooling. Sadly, it doesn't always work. I think we also need better tooling in general. Code is code though, and it should be readable by humans. If you see a place where it isn't clear what type comes out of something and that type isn't a huge template mess then I'd consider putting an annotation there. Functional code can especially make people get lost, so make sure its split into lines or the individual calls are commented where appropriate somebody else can understand. A moderately long self-documenting functional line might still need an annotated type just so humans understand.
Interesting, thanks. Would it make sense for Cranelift to provide hooks for register allocation (and whatever else is needed to "connect" to the surrounding code) to make inline assembly possible without Cranelift itself including a full assembler?
I'm not all that familiar with [the ABI used here](https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI), but I can take a stab. Let's analyze `get_value_single`: The function takes two arguments: `%esi` is the `b: bool` argument. There is a second argument stored in `%rdi`. You can tell because its register contents are read from without first being written to (indicating it's an input argument). They also match what the ABI specifies as inputs arguments. When returning structures larger than one register (some ABIs not relevant here allow a second register to store a return value) the compiler transforms your function to add an extra argument. This extra argument stores the address where the returned object should be constructed. Think of it like this, using imaginary `&amp;out` reference to indicate uninitialized memory should be passed and the function will initialize it: fn get_value_single(b: bool, ret: &amp;out String) { ... } Thus our second argument `%rdi` contains a pointer where the `String` should be constructed. Next up the input boolean is tested and dispatches to one of two branches. The compiler realizes both branches end in the same code and unifies their tails to reduce duplicated code. The length of the string literals happen to be the same, as is the call to `String::from`. Because `String::from` also returns a `String` by value the same thing happens here where the function is transformed to adding an input argument where the function can store the constructed `String`. Afterwards the return value from `String::from` is returned (copied bit for bit) from `get_value_single`. The compiler was unable to realize it could just pass the pointer `get_value_single` was given where to construct the `String` and instead gave a local address, then moved the local `String` from its stack frame to the caller. This moving/copying is done with `xmm` registers because they can move 16 bytes at the time. `String` is 24 bytes (3 pointer-sized words; pointer, size and capacity) so one qword (8 bytes) is moved afterwards. This means the input argument `%rdi` must be preserved across the function call to `String::from`. The way compilers do this is by using an ABI preserved register, here `%rbx`. It is used to hold the pointer where the `String` should be constructed after returning from the function. The other two functions `get_value_multiple` and `get_value_ternary` were optimized as expected, the compiler simply passed its argument where to `String` should be constructed through to `String::from`. The answer is that the compiled missed an optimization. I believe this optimization is called NRVO (named return value optimization), compare to RVO (return value optimization) which the compiler does support as demonstrated in the first two functions. I'm actually surprised that this optimization is not supported by Rust/LLVM as it's pretty standard in C++.
While you are free to feel sad, coming to /r/rust to state that Rust's design makes you sad with no constructive feedback isn't really helping anyone. You might as well tell us that $soft_drink$ is too bubbly for you, and you're sad that you may have to drink it some time, because it's getting more popular. We'd all be happy to help you if there were specific conventions you would like more insight into though. And if you're happier not touching Rust, feel free to do so too; nobody here wants to force you. :)
C# IDE's show you the type of var when you mouse over var keyword. https://areweideyet.com/ =&gt; nope
Please use 4-space indentation instead of three back ticks to mark code blocks on Reddit :)
You're generating crazy excessive amounts of combinations of every possible letter. There's a much easier option: you can generate every combination of _cases_. Here's a [dumb way](https://play.rust-lang.org/?gist=8cbf699864db9c3a9af2e71b7da75c44&amp;version=stable&amp;mode=debug&amp;edition=2015) of doing it with some bit hackery. It's probably possible to come up with a better way of generating all possible combinations of N boolean values, but I couldn't think of one off the top of my head, so that's that.
Oops! Sorry. I thought the new interface allows using the same Markdown like used on Github et al? The formatting certainly appears that way even though it has no syntax highlighting.
&gt; You're generating crazy excessive amounts of combinations of every possible letter. Yeah, I know. But I couldn't think of any other way to do it. &gt; Here's a dumb way of doing it Awesome. Let me try that. Thanks!
Const generics and futures stabilization is higher priority for me. Placement is good, but it's just an optimization. Expressivity features are much more important to me atm.
I think it's part of https://github.com/rust-lang-nursery/net-wg/issues/28
A reasonable alternative way to look at this is that *code isn't text* - it's just that the most generic reasonable method we have of encoding it for browsing/editing by humans is text - and tools which render your code in alternative ways to go along with that generic encoding are also useful.
No idea about the new interface, I'm saying this as user of the Boost Android app :) 
My experience with actix-web is very mixed. I believe it is a great libary if "just" you want to build a webserver without any special requirements. Unfortunately I have two of those unusual requrements in my Application: 1. I want a static fileserver which sends the user the requested file not for displaying it in the browser but to instantly download it. Since this is not mentioned in the docs, I asked in the Gitter Chatroom what I would have to research to implement such a feature, and one community member wrote me the workaround code for it and also explained it. 2. I wanted to have a dynamic path for a static file server. For this one I couldn't find an nice solution and just wrote an ugly and slow workaround. However, I believe in the actix subreddit there was a post about this very problem. So maybe they have found a solution for it, I just hadn't had the time to check it out (I should definitely do that in the next few days) To be honest there aren't that many alternatives. Rocket seems to be nice with a better API (at least thats what they say, I never tried it) but Rocket doesn't compile on Rust stable and after reading some Blogs about Rocket it seems that dealing with the nightly compiler can be a pain. One problem I have with actix-web tough is, that there aren't that many real-world application. Sure there is the actix-example repo but sometimes you want to combine two features or just want to look up how other people implemented a special feature. Last, I want you to take my word with a grain of salt. I am just starting learning rust and thumbcloud is my first real project.
it does though, you can do `foo, err := some_function()`
OK. I have updated the code block. Thanks.
Unrelated question: what's the monospaced font you're using in that screenshot?
What's wrong with functional syntax? 
You should definitely add a triforce to the basic shapes example ;-) Pretty sweet, although I'm not really sure what to use it for... is it possible to use this from some kind of markdown or similar?
Awesome!!!
Yes, https://github.com/ivanceras/spongedown 
Thanks for the feedback.
&gt; The answer is that the compiled missed an optimization. I believe this optimization is called NRVO (named return value optimization), compare to RVO (return value optimization) which the compiler does support as demonstrated in the first two functions. I'm actually surprised that this optimization is not supported by Rust/LLVM as it's pretty standard in C++. Yeah, this is what I thought as well. Even in C++, for a long time NRVO was a more difficult for compilers than basic RVO, and the same seems to happen here. In C++ (N)RVO and copy elision (even with side effects) is specifically mandated by the standard, and compiler vendors have made use of that. In Rust all copies are bitwise and observable side effects impossible, so (N)RVO is implicitly always permitted under the as-if rule. But AFAIK rustc itself currently lacks any concept of copy elision; it's up to LLVM to figure out.
Still working on getting lldb into rustup. The previous problem was that lldb wasn't being linked statically; the current problem is that static linking seems to interfere with the way that lldb finds its python library at runtime. Any day now though... I hope.
I understand: So put simply, Types in `rand` that have the trait `rand::CryptoRng` are supposed to be cryptographically secure, examples would be `ThreadRng`, `StdRng` and `OsRng`. Thank you for your answer, I should read up on traits and types now.
I am not sure I follow. AFAIK Cretonne is already using an assembler, so I don't know what you mean by "including it". For example, Cretonne takes WASM and emits x86 machine code. This probably works by mapping the WASM to some IR, transforming the IR, passing it to an x86 backend that further transforms it and lowers it to x86 assembly, and finally, calling the platforms assembler to generate x86 machine code. The platforms assembler is not bundled with Cretonne, but is rather a program that Cretonne just calls. For compiling WASM, none of the inline assembly stuff is necessary. But when compiling Rust to e.g. x86 with Cretonne, we wouldn't compile to WASM, and then use Cretonne, but rather, we would compile Rust down to Cretonne's IR, and then Cretonne takes it from there. So... you should ask `sunfish` about this, but probably what needs to happen is that the IR that rustc would generate, would need to support inline assembly templates somehow. That way, Rust would just lower the `asm!` macro to the IR for it in Cretonne, and then Cretonne would do the rest, calling the platform assembler at some point, just like for the rest of the code.
This might just be an Android web. View problem but it [appears](http://imgur.com/2aO2ZaG) part of your second statistics graph forgets to convert two of the Os to circles
Wouldn't that be covered by "documentation tooltips?" Anyway I know my editor (VsCode with the official plugin) does that.
Would it be useful in spidermonkey too then? I don’t know what cases it was designed for really, the existing rust code may be perfectly performant too. 
Personally I’m excited to see what Rust will bring to a compiler framework. I’m treating it as an opportunity to learn right now, which admittedly is a bit meta. 
So specially on missing registers in the template, luajit’s dynasm provides a feature to specify the register at runtime as opposed to assembly time. You just patch the bits for the register right? It’s used by the perl6 folks last I heard in that way. 
That is awesome. Do you see a way towards implementing [embedded-hal](https://github.com/japaric/embedded-hal) abstractions (GPIO, delays, I2C, SPI) atop of the libopencm3 abstractions?
Er, exactly as I said, by passing `-fuse-ld=lld` as a link flag (to the clang you're calling to link). Something like `-C linker="clang -fuse-ld=lld"` or `-C link-args="-fuse-ld=lld"` in rustc. I personally don't even have to do anything, LLD is the default linker on FreeBSD 12 :)
&gt;calling the platforms assembler (AS env variable) to generate x86 machine code. Uh no, Cranelift [emits machine code directly](https://github.com/CraneStation/cranelift/blob/master/lib/codegen/src/isa/x86/binemit.rs). I honestly can't think of any JIT that calls out to the system assembler; that's much more common in AOT compilers
Dunno. I've never worked on any Javascript engine, nevermind SpiderMonkey specifically. :-)
Step 1: Find a country that will support illegal underground human cloning. Step 2: Get DNA of some of Rust's top coders. Step 3: Clone 100s of each. Step 4: Wait 15 years. Step 5: Rewrite everything in Rust!
All 3 talks are excellent, you present in a very clear and easy to understand way.
Yep, like @KillTheMule said, any crate on crates.io is in scope
Wow, Redox OS is progressing quite fast. Pretty impressive work!
Domain of specialist. What is your use case?
I think I'm missing how the approaches you mention are able to detect unhandled panics without unwinding. - A top-level `catch_unwind` requires unwinding. - An `impl Drop` unwinds until that drop and requires manually instrumenting the code at areas you know the rest of the call stack won't `catch_unwind`.
What syntax are you familiar with? OOP? Personally, I learned programming through Java, then C#, then Python, so I can only really vouch for a transition from relatively high-level OOP languages. But once you get past the first few hurdles, it's not as hard to apply the knowledge from other programming styles to Rust's design philosophy.
HTTP2 does not require TLS (SPDY did). Many people use it in plaintext with grpc for their internal services.
This one was posted just 2 days ago: [Looking for wannabe rustaceans, that'd like to get their feet wet with some real project](https://www.reddit.com/r/rust/comments/90xh79/looking_for_wannabe_rustaceans_thatd_like_to_get/)
Because stdin and stdout are file handles provided by the parent process. And if that dies it will destroy those. So vi will try to write to a file handle that no longer exists.
Ah, nice catch. I keep changing the logic behind the renderer keeping balance on when it should kick in or not kick in, depending on the combination of characters. Keeping the balance of the algorithm to be aggressive or less aggressive requires a lot of use case and observation. This is on of the situation that gets sacrificed in keeping the balance. I could probably add: If alphanumeric characters (ie: 'o') is next to a common drawing elements (ie: '+') it will be treated as text characters, however if the arrangement is vertical try to connect the 2 for graphical drawing.
Mostly C, using C++ as syntactic sugar with operator and function overloading and so on
How about [this story](https://blog.faraday.io/saved-by-the-compiler-parallelizing-a-loop-with-rust-and-rayon/)?
Most of the logic on this app is implemented on this rust library https://github.com/ivanceras/svgbobrus . I want to highlight that instead of the webapp that just wraps the complex library.
The big one for me: a language, ecosystem, and community attitude of "do it right". No, that quick hack is *not* going to cut it. Yes it's going to take longer, but damnit, *do it right*. You want to put floats into an associative map? Did you *think* about NaN? No? Go do that. *Do it right*. Hey, you just added an enum variant, and now these two dozen matches are all inexhaustive. Fix them. *All of them*. No, you can't just compile anyway. You *could* whack a `_` arm at the end, but then you might forget next time. *Do it right*. No, you can't just slap a generic function together. List the constraints. A method you want doesn't have a trait? Well, define one, then! Oh, so *now* you notice the behaviour of those types are close, but *not quite* similar enough. Good thing you didn't just bodge them together, isn't it? *Do it right*. I don't need to bother with a newtype for this. It's just a velocity value. ... but what if it's NaN; that should never happen. And negative velocity doesn't make sense. And I can't meaningfully apply every operation to it. What if I forget to check the invariants, or use it wrong? I mean... I *could* just alias `f64`... *Do it right.* *(starts writing a newtype wrapper)*
It’s a fun exercise to think about this problem. Also the remarks about Trio make for interesting thoughts about how to combine panics and futures/tokio.
The existence of `A&lt;'_&gt;` is tired to the lifetime you give it. For as long as that binding is around, it has the same type, If that binding is in scope (or post-nll, is still used later), it has a hold on that lifetime. In this case, that lifetime is a unique lock on the borrowed data. You can't return it until dropping your `A&lt;'_&gt;`.
/u/K900_ has the right idea. If you're certain it will only ever be ascii (i.e. you are the only one using it) and you want speed. You could use [to_ascii_uppercase](https://doc.rust-lang.org/std/primitive.char.html#method.to_ascii_uppercase). 
It's nowhere near close to be deprecated, not in the next 10 years. Not at EA.
Now that I think about it, you can probably gain a little more speed by using `String::with_capacity(len)` instead of `String::new()` - this way you'll preallocate memory for your string.
The strings I'm experimenting on include non-ascii characters.
There is very little about Rust's syntax that shoves functional programming down your throat. The only thing that I can even think of is everything being an expression, which is pretty common in all new languages. It makes functional programming more pleasant than in C++, but by no means are you forced to write in a functional style, and the standard library doesn't even really encourage it.
We may yet end up writing an assembler. I'll update the documentation to be a little more open about the possible scope of the project. Another idea I have is that it may be possible to hand an inline assembly string off to an external assembler program, and then embed the output into Cranelift's output. This should work in many simple cases, though I don't know if it would support things like switching sections in inline asm strings. In any case, it'll take time. But, that's time that the Rust community appears to want writers of alternate backends to take, by pushing forward with inline assembly in the language. :-)
Yes, I noticed. I'm already doing that. Thanks anyway.
That'd be really cool! If you're interested in trying this, I'd be interested to hear how it goes for you, or if there's anything I can help with. Cranelift isn't super mature or complete yet, but it's never too early for feedback :-).
One important realization is that lifetime naming is only important if a function returns references.
&gt; It's probably possible to come up with a better way of generating all possible combinations of N boolean values How about counting from 0 to 2**len in binary base ? This is actually what you code is doing afterall...
The Rust community generally prefers to leave things out of the standard library if they don't need to be in there. The benefits of a large standard library are much less applicable with a really good dependency manager. Adding a dependency to a project in Rust is about as much work as writing an include directive in C++. It's better to give the programmer choices than to make a certain implementation of a feature official at the expense of other possibly better implementations.
It's on my TODO list to rewrite that comparison with LLVM, so don't take it as the final word on what Cranelift will or won't become :-). In the early days, we restricted the scope to focus on getting to a working base. However, this doesn't fully reflect the vision of where we want to go.
You should be able to write in basically that same *syntactic* style in Rust. I'm honestly not sure where you got the idea that its syntax is so different.
I was responding to the ancestor comments which quotes from https://cranelift.readthedocs.io/en/latest/compare-llvm.html &gt; LLVM additionally provides infrastructure for building assemblers and disassemblers. Cranelift does not handle assembly at all—it only generates binary machine code. (Also as far as I understand Cretonne/Cranelift itself does not support wasm directly. Rather it is one of the big components (generating architecture-specific machine code from an IR) that can be used in a wasm implementation such as SpiderMonkey.)
GCC-style inline asm is designed to allow a code generator to do the register allocation first, then substitute in register names etc. into the placeholders in the inline asm string, and then pass the result off to a plain assembler without the need for further hooks.
I would suggest using one of the Rust bindings for `libmagic`, which is what the `file` command uses to identify filetypes. This should recognize executables regardless of how they are named. Make sure to check for all of the different types of executables, though. MS-DOS and subsequently Windows have gone through quite a few over the years.
It's a known current limitation, however, this changes with the introduction of non-lexical-lifetimes, [it compiles](https://play.rust-lang.org/?gist=52f0a51e83c3e8c4ae1bf443e3c28a5d&amp;version=nightly&amp;mode=debug&amp;edition=2015) when the nll feature on rust nightly is turned on. If you need further documentation on nll, check out the corresponding [RFC](https://github.com/rust-lang/rfcs/blob/master/text/2094-nll.md). 
I'm curious, then, what you mean by Rust's "functional-ish" syntax? Full disclosure, I haven't delved heavily into C++ or C, so I don't totally know the extent of the differences. I know that the way does OOP, with traits rather than classes, is fairly different from how C# and Java do it.
Yeah, that's what I'm doing, but it's sort of expensive with all the bit twiddling. 
I have extensive experience with vulkano, and some experience with ash. Vulkano is just not ready. It's missing major functionality, most of the safety guarantees that motivate it aren't actually guarantees yet, and correctness issues leading to UB are common and don't seem to be taken very seriously.
I am definitely interested, but I'd say it's many months (perhaps even a year) before I get to it. I need to finish up my current project, and then my plan is a complete rethink of regex internals. So it will be a while! I did find your simplejit tutorial, which helped immensely with understanding how it all fit together. I think without that, I would have been lost. :-)
I heard talk of Cretonne or Rust a while ago but not much recently. Is there much active work in this area or a current status? All I could find are [a couple of rustc-tagged issues](https://github.com/CraneStation/cranelift/issues?q=is%3Aissue+is%3Aopen+label%3Arustc).
From a quick glance I imagine it could be done (though my opinion isn't worth much as I am not very experienced.). And, thank you for bringing it to my attention; it's nice to see a system for drivers like this. I would expect the difficult part to be working to the non-blocking I/O that embedded_hal seems to offer? I honestly will seriously think about trying it. It would be nice to have a common platform for drivers like this.
Thanks for clarification, my confusion probably comes from SPDY.
reqwest probably doesn't convert the `key:pass123` part of the URL to a Basic-Auth header and you need to either ensble it, use another crate to generate the header, or do it yourself.
I'm still really unhappy about the module changes. I really like having "extern crate" and explicit "use", they help me get a feel for dependencies and functionality when I'm looking through a new file. Does anyone else feel this way?
If what you need is an easy way to read keystrokes, I'd actually suggest rust-sdl2. It's ostensibly a graphics library, but its got a nice API for [events like keyboard strokes](https://docs.rs/sdl2/0.31.0/sdl2/struct.EventPump.html), (I would look specifically at the [textInput](https://docs.rs/sdl2/0.31.0/sdl2/event/enum.Event.html#variant.TextInput) event). It shouldn't be that much overhead if you don't initialize canvases and that kinda stuff. That being said, I've never used it purely for events before so I could be mistaken on overhead cost. 
I use these as visual hints when skimming over a new crate. It gives me a clear indication where things come from without having to checkout the source locally to use code navigation.
Not me. It always seemed redundant to have to declare your dependencies twice, once in your Cargo.toml and once in your lib.rs. Plus, you only had to `extern crate` in one file -- not in any sub modules you were using those crates from, so it still wasn't a great way to discover dependencies for the module file you were looking at. I appreciate the simplification work done for modules.
&gt; Plus webasm of course, which is probably a fairly stupid thing to focus on, but trendy. Actually, I think of the big reasons for the "popularity" of webasm is its synergy with embedded development: WASM is a stand-alone no-std environment, much like small chips, and therefore part of the investment for WASM involves making Rust more usable without std... which a great many people would like to see, myself included, even I could care less about WASM :)
Feel free to copy anothijg from https://killercup.github.io/presentation-rust-fb-dev-circle/#/rust-is-empowering (even includes a quote by Quxxy)
&gt; explicit "use" You still need to explicitly use `use`. I've always felt the `extern crate` syntax was very low value because its duplicating info in my `Cargo.toml` and most of the time I'm not in `lib.rs` or `main.rs` so I almost always need to change files to look it up. I'm happy to see pointless ceremony go away.
It seems really odd to me that it was changed. It's such a minor problem really, and changing name only creates even more problems. Cretonne was also such a great name IMO, perhaps because it's so unique? It's really a shame that sunfishcode changed it, but in the end it's only a name, who cares as long as you can search for it.
Thanks. I don't understand when people say there is no documentation for Rust. At least the beginner resources are awesome! I find the book is doing a great job, but even if it wasn't good enough, then you have rust-by-example. Also thanks for the link to Tokio. I'm trying to better understand Rust, so I can better evaluate where it'd be better to use it over something like Elixir, especially for web services.
I would have assumed this had been improved upon since C++ added iterators to the std lib. Well, as of the tutorial, iterators have been succinct :)
Here's a fun fact: had King Leonidas's small army of 300 programmed defensively using Rust, they would have won against legions of hackers
The pointless ceremony means that you need to prefix all your local use statements with `crate` now, I'm not sure if that's that much better.
Out of curiosity, how much CPU-demanding would you say RLS is? I remember trying out Rust integration in VS Code some months ago and I concluded it's too slow and CPU-intensive and turned it all off. But maybe things have improved since then? 
It does pin to 100% usage for up to a minute (for large projects) when you open a new project, and occasionally it has pinned to 100% indefinitely without visibly doing anything, but usually after the initial project-opening run it is barely noticeable. I can’t say anything about battery usage though.
You wouldn't just need an assembler; you'd also need the bits necessary to process inline assembly constraints on input and output registers, to optimally weave inline assembly with code generated from Rust.
As someone else coming from c++ there are some things with expressions that feel scary at first. Aka: if this were c++ it would be doing a lot of copies. That sets off alarm bells for me, and learning rust has been a journey in turning those alarms off.
Coming from procedurals, it's hard to grock. Ultimately it's cleaner in my experience. The journey breaks your brain though.
Few things. * I'm new to using `Futures` and `Streams` and I haven't done any multithreading stuff so my mind is still stuck in single-threaded synchronous code. * I'm also recently tinkering with the `websocket` crate for my client-server communication in my current project. * I know of `futures-cpupool`, if that helps. So there is this async `WsServer` that emits an `Incoming` `Stream` of `Upgrade` when `WsServer::incoming` is called. The `Upgrade` can be unwrapped into a `Client` which is a `Stream` of `OwnedData`. Is my understanding correct? How can I put the `WsServer` in a future running in an infinite loop, generating multiple threads of futures of `Clients` reading some data from their streams and, say for debugging and example purposes, displays the bytes read on console? Or perhaps is there a more practical way of doing this than what I have in mind?
That's what Cargo.toml is for, isn't it.
Other than voicing my opinion about Rust 2018 on Twitter and Discord some times, I have never fully written down my experience, so I guess here it goes: I didn't have any problems with cargo fix. While the multi step process here is definitely far from intuitive and you definitely need a guide while using it, it worked just fine on my first attempt. However it doesn't actually switch all idioms it seems. So I still need to spend multiple hours to actually switch all the match statements to default match bindings, switch all the trait objects to dyn, rewrite all the use statements again, ... So overall while it did work for me, it wasn't all too helpful in comparison to the total amount of work needed. I also ran into the crate renaming problem. However `crate use some_crate as some_other_name` in `lib.rs` at least mostly resolves that problem. This however means it's now part of the `crate` namespace and not global namespace where the crates reside in, that's mostly fine though. What however seems to be totally broken is the ability to reexport crates. It just doesn't work at all, so you still need to use `pub extern crate some_crate as some_other_name` in the meantime. I also ran into the macro problem, but there seems to be a feature that enables importing macros via `use some_crate::some_macro;` so I just used that and that seems to work fine. It's a bit surprising that attributes implicitly get imported then though (if you don't import the macro, they error out). I'm still not entirely a fan of default match bindings. While they reduce the amount of code you need to write out, the fact that the old system is still in place makes it hard to tell whether you are in default match binding mode or not. So a pattern may behave wildly different based on what you are actually matching on. So if you are not entirely aware of whether you are matching on a reference or not, everything just behaves in a really unpredictable way, which seems a bit scary. This also increases the learning curve for beginners, which doesn't help Rust, which already has a high learning curve. I hope we can get a more unified pattern system in the future. While I was initially a fan of wildcard lifetimes, they are a bit weird to actually use in practice. The initial idea, at least to me, was that you just type out `-&gt; SomeType&lt;'_&gt;` instead of `-&gt; SomeType` to signify that there's an actual lifetime dependency. But no, they open up a ton of new lifetime elision situations. Especially when used in multiple places at the same time, it's often not clear whether the refer to the same lifetime or are all distinct. So this can be somewhat surprising. I think this is definitely something we can get used to, so it's not too much of a problem. However it seems like they are somewhat untested, as using them in the generic bound of an impl makes them behave differently from being used in a generic bound of a function (They error out in the impl, even though you use the exact same bound). So with some more bugfixing, they seem fine to me. What's interesting is that in-band lifetimes are getting a lot of flack at the moment. But they work really well in practice, and are probably the least "broken" feature of Rust 2018. There's apparently some inconsistency where you can't use them for functions inside functions, but I wasn't affected by that bug in my code base, so at least while porting my code base, they seemed to be working just fine. Implicit lifetime constraints for generic types is for the most part a good change. However in at least a few places you still need to constrain your generic types by lifetimes, so it's mildly inconsistent, but in those places where you still need to constrain them, it actually makes sense to do so, so it's not actually that bad. Conclusion: I'm a bit concerned about Rust 2018, as a lot of these new features come with edge cases where they do not work. extern crate is sometimes still necessary, default match bindings aren't always active, wildcard lifetimes sometimes don't work and implicit lifetime constraints don't happen in all places. So while Rust 2018 is probably a more convenient version of Rust for someone who already knows Rust, it's going to have a harder learning curve for newcomers.
Ok, thanks
I want to create a structure that contains some type T in a vector, and another vector containing slices of the first vector. An example of how it would look is: first vector v is [1, 2, 3, 4] second vector d is [ [&amp;1, &amp;2], [&amp;3, &amp;4] ] I had the following design in mind struct someStruct&lt;'a, T: 'a&gt; { elems: Vec&lt;T&gt;, slices: Vec&lt;Vec&lt;&amp;'a T&gt;&gt; } How would you do such a scheme? Is there a better, more obvious way of doing this? I know one solution is to have duplicates items instead of references, but I am trying to be as memory efficient as possible 
I'm also not a fan of the verbosity of crate::, and I'd prefer \`::\` as a shortcut. With nested imports, you really only need one "use crate::..." per file though. use crate::{moda::{x, y}, modb};
I just don't even understand what "functional syntax" means. Is it "everything is an expression"? Is it lambdas? Is it tagged unions? Is it tuples? Is it generics? Is it iterator chains? 
`reqwest` depends on the `url` crates, which in turn implements the [URL Standard](https://url.spec.whatwg.org/#example-url-parsing), which specifically calls out URLs of the form `https://user:password@example.org/` to be invalid. A note under the [query encoding example](https://url.spec.whatwg.org/#query-encoding-example) states: &gt; There is no way to express a username or password of a URL record within a valid URL string. Looks like you'll need to set the [Basic](https://docs.rs/reqwest/0.8.6/reqwest/header/struct.Basic.html) header yourself. 
I would think *that* sort of thing would be a pleasant change. "Oh, this is move by default instead of copy? Whew :)"
&gt; Because stdin and stdout are file handles provided by the parent process. And if that dies it will destroy those. I'm not sure it's that simple. It's true that Vi's stdin file handle is inherited from the parent, but that one is in turn inherited from the grandparent. If it were any other file handle, say to an open regular file, the parent dying would not have any effect on the child, which would simply retain its own file handle pointing to the same resource. In this case vi's file descriptor 0 points to `/dev/pts/&lt;number&gt;` both before and after the death of the parent, but after the parent dies it starts receiving `EIO` when trying to read from it, or manipulate it in any way. (This can be observed when the whole command is traced with `strace -f`.) The reason is that `vi` gets detached from the foreground process group, as [described here](https://www.win.tue.nl/~aeb/linux/lk/lk-10.html) in some detail: &gt; All process groups in a session that are not foreground process group are *background process groups*. Since the user at the keyboard is interacting with foreground processes, background processes should stay away from it. When a background process reads from the terminal it gets a SIGTTIN signal. Normally, that will stop it, the job control shell notices and tells the user, who can say fg to continue this background process as a foreground process, and then this process can read from the terminal. But if the background process ignores or blocks the SIGTTIN signal, or if its process group is orphaned (see below), then the read() returns an EIO error, and no signal is sent. (Indeed, the idea is to tell the process that reading from the terminal is not allowed right now. If it wouldn't see the signal, then it will see the error return.)
Yeah, however at least with current rustfmt this is getting formatted pretty badly (maybe on nightly this is improved), and cargo fix doesn't generate this by default either. However it's definitely something that will help out a lot.
Very beginner, but I cannot find it out. I'm trying to split my code into multiple files. How to do that? I have a struct and some corresponding functions: https://imgur.com/a/wxfwG8E I can use that in my main file/function via the 'mod' declaration. https://imgur.com/a/77cyS52 Then using like: https://imgur.com/Xjotpyy However, when I try the same in a different file/module it does not work: https://imgur.com/a/nLO013Q All files are in the same directory. What am I doing wrong?
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/RmZ4Wxz.png** **https://i.imgur.com/htEv2WG.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e2yj6tw) 
There is also the cerberus project: http://www.cl.cam.ac.uk/~pes20/cerberus/ They explain *a lot* about how pointers work in C, mostly based around pointer provenance. They also define a memory model of de-facto used C (not necessarily ISO C). This paper from their website is very extensive, and should explain most of it: http://www.cl.cam.ac.uk/users/pes20/cerberus/pldi16.pdf In case you already knew, great work, carry on :)
Short answer: on your Generator.rs file you want to use a `use` statement. The `mod` statement should be in main.rs.
Are you trying to shift the values each time by adding a new one on the end and removing the first one? The best data structure to use for that is a queue, which is available in the standard library as [`std::collections::VecDeque`](https://doc.rust-lang.org/std/collections/struct.VecDeque.html).
A few pointers: 1. I noticed you use `Vec&lt;(A, B)&gt;` in a couple places (nothing wrong with that!). It is just that, if either `A` or `B` properly and uniquely identifies the elements in the `Vec`, you should consider using a `HashMap&lt;A, B&gt;` instead. 2. In general, source file names in rust are not capitalized and use snake_case. I recommend you rename your files to generator.rs, vm.rs, and format_vmw.rs. 3. As I mentioned in the short answer, you should write `use format_vmw` in your generator.rs file. All files in the src folder should be added to main.rs using `mod` (or `pub mod`) declarations so they are part of the compilation unit.
I'm thinking of this from a `futures` context. I don't believe there's a standard way to cancel a future, is there?
A lot of the work going on right now is laying the foundations this will need. It's still one of our major goals!
&gt; However, I fail to extract these at a later stage. I fail to reason why I cannot do this. The code you wrote is trying to move the entire `Option&lt;Box&lt;Xyz&gt;&gt;` out of the array, but I think what you wanted was to [`take`](https://doc.rust-lang.org/std/option/enum.Option.html#method.take) just the `Box&lt;Xyz&gt;` value out of the array and leave a `None` in its place. In that case, [try using `arr[0] = arr[1].take();` and `*arr[0].take().unwrap()`](https://godbolt.org/#g:!\(\(g:!\(\(g:!\(\(h:codeEditor,i:\(j:1,lang:rust,source:'//+Type+your+code+here,+or+load+an+example.%0A%0A//%23%5Bderive\(Debug,+Clone\)%5D%0Apub+struct+Xyz+%7B%0A++++abc+:+i32,%0A++++def+:+i64,%0A%7D%0A%0Aimpl+Default+for+Xyz+%7B%0A+++++fn+default\(\)+-%3E+Xyz+%7B%0A+++++++++Xyz+%7B%0A++++++++++++abc:0,%0A++++++++++++def:0,%0A+++++++++%7D%0A++++%7D%0A%7D%0A%0Apub+fn+test\(p+:+i32\)+-%3E+Xyz%7B%0A++++let+mut+arr+:+%5BOption%3CBox%3CXyz%3E%3E%3B2%5D+%3D+Default::default\(\)%3B%0A++++let+var1+%3D+Box::new\(Xyz%7Babc:1,def:2%7D\)%3B%0A++++let+var2+%3D+Box::new\(Xyz%7Babc:p,def:4%7D\)%3B%0A++++arr%5B0%5D+%3D+Some\(var1\)%3B%0A++++if+p+%3E+0+%7B%0A++++++++arr%5B1%5D+%3D+Some\(var2\)%3B%0A++++++++arr%5B0%5D+%3D+arr%5B1%5D.take\(\)%3B%0A++++%7D%0A++++*arr%5B0%5D.take\(\).unwrap\(\)%0A%7D%0A%0Apub+fn+demo+\(p+:+i32\)+-%3E+i64+%7B%0A++++let+res+%3D+test\(p\)%3B%0A++++res.abc+as+i64+%2B+res.def%0A%7D%0A'\),l:'5',n:'0',o:'Rust+source+%231',t:'0'\)\),k:33.333333333333336,l:'4',n:'0',o:'',s:0,t:'0'\),\(g:!\(\(h:compiler,i:\(compiler:r1271,filters:\(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',trim:'1'\),lang:rust,libs:!\(\),options:'-O',source:1\),l:'5',n:'0',o:'rustc+1.27.1+\(Editor+%231,+Compiler+%231\)+Rust',t:'0'\)\),k:33.333333333333336,l:'4',n:'0',o:'',s:0,t:'0'\),\(g:!\(\(h:output,i:\(compiler:1,editor:1,wrap:'1'\),l:'5',n:'0',o:%231,t:'0'\)\),k:33.33333333333333,l:'4',n:'0',o:'',s:0,t:'0'\)\),l:'2',n:'0',o:'',t:'0'\)\),version:4).
That would be self-borrowing, which is currently not possible to do in rust. An object cannot contain pointers to itself. It is a limitation of the ownership system that is being tackled with the immovable type API, in development. If you want to be memory efficient, you should look into using one of the owned pointer types, like `Rc` and `RefCell`. So your structure would like like this: struct SomeStruct&lt;T&gt; { elems: Vec&lt;Rc&lt;T&gt;&gt;, slices: Vec&lt;Vec&lt;Rc&lt;T&gt;&gt;&gt;, }
Indeed. In all, we can expect inline asm to significantly delay an alternative backend capable of full language support. Which is not to say it's wrong, just that there is a cost. 
I feel like I'm being pedantic, but isn't velocity a vector, so a negative velocity would just be in the opposite direction? Speed as as the absolute value of velocity wouldn't make sense to be negative..... Do it right!
The structure is to keep results of simulations for a toy game. There are a fixed number of moves (7) possible at each level and these are kept in the in array for simplicity. The Option&lt;T&gt;::None is used to indicate that one particular move is not possible. The box is used to to store the computed result of the move. And the structure is recursive as the simulator goes recursively deeper up to a given level. So the structure is struct AMove { moves : \[&lt;Option&lt;Box&lt;AMove&gt;&gt;; NUMBER\_OF\_MOVES\], .... } The code above does not represent the logic but exposes the problem. Once a move is selected the other simulations shall be ignored and the simulation resumes adding one new level to the previous simulation. In essences it's a tree of moves. I could change the representation by a tree, where after each move, the root node gets replaced by one of its children. So the idea is that at the top level I want to write something like: simulation = \*simulation.moves\[selected\_move\].unwrap();
Great article, though I'd like to point out that an assertion such as “pointers are simple: they are just integers,” requires some context for a fair evaluation. From the perspective of an everyday C programmer, I would say this is a reasonable stance. From the perspective of a compiler implementer, it's entirely false, as you've thoroughly demonstrated. Though I think this general theme holds true for most commonplace programming language features.
This is what nested imports is for.They seems to work fine in combination with rustfmt-nightly.
You can move out of arrays using array patterns: https://godbolt.org/g/BUfkuH.
[There is currently no way to move out of an array.](https://doc.rust-lang.org/std/primitive.array.html) The best you can do is to [`mem::replace`](https://doc.rust-lang.org/std/mem/fn.replace.html) an element with something else.
All right, then what you can do is use `Option::take` to replace the array item with `None` and give you a variable holding the value it used to have, and then assign that variable to `*self`. Pretty much what /u/HMPerson1 said. [Here](https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(j:1,lang:rust,source:'//+Type+your+code+here,+or+load+an+example.%0A%0A//%23%5Bderive(Debug,+Clone\)%5D%0Apub+struct+Xyz+%7B%0A++++abc+:+i32,%0A++++def+:+i64,%0A%7D%0A%0Aimpl+Default+for+Xyz+%7B%0A+++++fn+default(\)+-%3E+Xyz+%7B%0A+++++++++Xyz+%7B%0A++++++++++++abc:0,%0A++++++++++++def:0,%0A+++++++++%7D%0A++++%7D%0A%7D%0A%0Apub+fn+test(p+:+i32\)+-%3E+Xyz%7B%0A++++let+mut+arr+:+%5BOption%3CBox%3CXyz%3E%3E%3B2%5D+%3D+Default::default(\)%3B%0A++++let+var1+%3D+Box::new(Xyz%7Babc:1,def:2%7D\)%3B%0A++++let+var2+%3D+Box::new(Xyz%7Babc:p,def:4%7D\)%3B%0A++++arr%5B0%5D+%3D+Some(var1\)%3B%0A++++if+p+%3E+0+%7B%0A++++++++arr%5B1%5D+%3D+Some(var2\)%3B%0A++++++++let+old_arr1+%3D+arr%5B1%5D.take(\)%3B%0A++++++++arr%5B0%5D+%3D+old_arr1%3B%0A++++%7D%0A++++*arr%5B0%5D.take(\).unwrap(\)%0A%7D%0A%0Apub+fn+demo+(p+:+i32\)+-%3E+i64+%7B%0A++++let+res+%3D+test(p\)%3B%0A++++res.abc+as+i64+%2B+res.def%0A%7D%0A'\),l:'5',n:'0',o:'Rust+source+%231',t:'0'\)\),k:33.333333333333336,l:'4',n:'0',o:'',s:0,t:'0'\),(g:!((h:compiler,i:(compiler:r1271,filters:(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',trim:'1'\),lang:rust,libs:!(\),options:'-O',source:1\),l:'5',n:'0',o:'rustc+1.27.1+(Editor+%231,+Compiler+%231\)+Rust',t:'0'\)\),k:33.333333333333336,l:'4',n:'0',o:'',s:0,t:'0'\),(g:!((h:output,i:(compiler:1,editor:1,wrap:'1'\),l:'5',n:'0',o:'%231+with+rustc+1.27.1',t:'0'\)\),k:33.33333333333333,l:'4',n:'0',o:'',s:0,t:'0'\)\),l:'2',n:'0',o:'',t:'0'\)\),version:4) is a working version of the code you posted.
Here’s my top 10: 1. The community 1. Cargo 2. Cargo 3. Rustdoc 4. Cargo 5. Ease of unit testing, tests in docs 6. Compile-time concurrency safety 7. Low memory usage. 8. Speed 9. Cargo
To cancel a future is as simple as dropping it. Which will ensure that it won't get polled later. I don't know if this has changed with the new design, but that's how i remember it.
This. I've recently realized that a couple years of using Rust has dramatically raised my standards for correctness and consistency in programs. Mainly because Rust and the tools around it makes it *easy* to have high standards. For barely more effort, my programs are Better? Sign me up. This is contrasted with a large, well designed and we'll maintained Typescript project I'm doing for $WORK. Typescript is *great*, it's a bloody masterpiece. It is also nowhere, *nowhere* near good enough.
Thank you! This indeed fixing one of my problems. I am still facing another "similar" problem, where I want to access one of the components value in the test function (simulator). The code may look like: let \_i : i32 = arr\[0\].unwrap().abc; I cannot use take() in that context as I want to keep the box in the array. The error messages is the same. error\[E0508\]: cannot move out of type \`\[std::option::Option&lt;std::boxed::Box&lt;Xyz&gt;&gt;; 2\]\`, a non-copy array \--&gt; &lt;source&gt;:25:20 | 25 | let \_i : i32 = arr\[0\].unwrap().abc; | \^\^\^\^\^\^ cannot move out of here 
Am I supposed to be able to e.g. gzip the bytes of a pointer and then unzip the pointer back out? Is there any chance that the special-pointer-byte-ness survives that sort of process?
As per HWPerson1 suggestion the code for the line above is replaced by simulation = \*simulation.moves\[selected\_move\].take().unwrap();
Try `arr[0].as_ref().unwrap().abc`. [`unwrap()`](https://doc.rust-lang.org/std/option/enum.Option.html?search=#method.unwrap) consumes the `Option` whereas [`as_ref()`](https://doc.rust-lang.org/std/option/enum.Option.html?search=#method.as_ref) takes it by reference (note how the type signature says `&amp;self` instead of `self`). Side note: Try to use pattern matching wherever possible instead of `unwrap`. That way the compiler can ~~annoy~~ help you remember to take care of the `None` case.
You know that ownership memory model that modern C++ collections uses that you just have to 'know' to use correctly? Rust has the compiler checking that for you. yeah.
Again, it did the trick. I did try to use as\_ref() in one of my attempts but must have failed using it properly. Well it did not solve my first "assignment" problem. I know unwrap() is not always good. I do dislike it too. But in my case I know for sure the option is valid as the move was selected. For option I tend to prefer the "let if Some(var) = expression" syntax as this reflects my logic more elegantly than a match. If not a panic is a good behavior.
Ah that's good to hear. It's probably fine then.
I'm trying to motivate myself to finish my first [real rust project](https://github.com/SebRut/rust_shamir_secret), an implementation of [Shamir's Secret Sharing algorithm](https://kimh.github.io/blog/en/security/protect-your-secret-key-with-shamirs-secret-sharing/). 
It's not like those things haven't been done... [https://lwn.net/Articles/673724/](https://lwn.net/Articles/673724/)
If you're new to Futures and Tokio, I wouldn't recommend starting with `websocket`. I highly recommend working through Tokio's Getting Started docs: https://tokio.rs/docs/getting-started/hello-world/ They could use improvements, but working through those and then building a couple of simple apps with Tokio I was able to (mostly) wrap my brain around Tokio and Rust's Futures. The reason I'm recommending against websocket from the get go is A) it'll be helpful to learn Tokio and Futures by themselves first before doing something more complicated and B) it looks like the `websocket` crate is not well maintained at this point? Or really new. Half the links from it on `crates.io` are broken and I couldn't find any online docs for it. Regarding your specific question: &gt; How can I put the WsServer in a future running in an infinite loop, generating multiple threads of futures of Clients also in an infinite loop reading some data from their streams and, say for debugging and example purposes, displays the bytes read on console? Again, ignoring `websocket` for a second, take a look at the first Tokio example: https://github.com/tokio-rs/tokio/blob/master/examples/hello_world.rs That's a simple example that listens on `127.0.0.1:6142` and responds to all new connections with `hello world\n`. It does all of that asynchronously and in parallel. So you could hammer it with 64k or more connections to it and it'll be responding to all of them in parallel. `TcpListener` is (based on your description) very similar to `WsServer`. `listener.incoming()` returns an `Incoming` which implements `Stream`. In the example, we call `for_each` on Incoming: `listener.incoming().for_each`. This is a combinator method that will run the provided closure for each value that the stream produces. It'll keep doing that until the Stream is done (it will no longer produce any more values). So, the return value from `for_each` is a Future. A Future which completes once the Stream is done. We can spawn that Future (assigned to `server` in the example) on the Tokio runtime: `tokio::run(server)`. So Tokio is now going to drive that Future to completion. Unless the listening socket runs into an error for some reason, this code is going to run forever (or until interrupted by ctrl+c or something). The Incoming Stream will continue to produce new `TcpStream` values whenever someone connects, so the `for_each` future will never finish. Now how about that closure we passed to `for_each`? Inside it's creating a new future: https://github.com/tokio-rs/tokio/blob/master/examples/hello_world.rs#L36 It creates a new future using the `write_all` function. This is just a Future which completes after all the data has been written to the specified socket. So in this case, our closure is creating a future which will write "hello world\n" to the new socket that just connected to us. The future will then complete. We `spawn` that future on the Tokio runtime: `tokio::spawn(connection)`. This hands the newly created Future off to Tokio to be executed in parallel with all other futures it's managing. Here's what we now have: * At start, the Tokio runtime will consist of only one Future. A listener which waits until a new connection comes in, executes our closure for that new connection, and then continues waiting for more connections to come in (forever). * Each time a new connection comes in, our closure runs. It creates a _new_ future which handles that connection (just writes "hello world" to it). This future is spawned on the runtime, so it runs in parallel with all other futures. * If a bunch (e.g. 10) of clients all connect to our server at the same time, the listener future will spawn 10 new futures to write "hello world" to all of them in parallel. One last thing to note. All of these futures are managed by the default Tokio runtime (and executor and reactor). Conceptually you can imagine them all running parallel. If you created and spawned 10k futures all at once, they'd all in theory "run" at the same time. But in practice Tokio is doing magic to give the illusion that they're all running at the same time. Really most of them are just in a state of "waiting" (for data on a socket to arrive, or a socket to be ready for writing, etc). The futures that are actively doing work at any given moment are being scheduled against an underlying pool of OS threads. You don't have to worry too much about that yet. Just giving some context.
That might fall on the wrong side of the borrow checker, since you're reading `simulation` on the right side and writing to it on the left, all in the same expression. If it works, great, but if not you can split it into two separate lines.
&gt; Then, I realized that I was using it wrong, and it actually worked great! Exactly my experience. I even opened an issue because I was confused, and it was exactly the interplay of the guide and nrc's guide that sort of made things hazy for me. All is well now, the guide is actually crystal clear imho!
Join my effort to bring "Hearts" game back to Linux. [https://gitlab.gnome.org/andy128k/hearts](https://gitlab.gnome.org/andy128k/hearts) ;) I appreciate any help. 
Is there anyone going through binary crates on `crates.io` and/or `github` and running this tool against them for automated notifications? Just curious.
&gt; I'm not convinced that the new module system is actually better. It definitely is more consistent, but you need to prefix all your local imports with `crate::` now. Getting rid of like 5 `extern crate`s vs. having to type thousands of `use crate::` now is definitely far less ergonomic, so with most of the other changes in Rust 2018 being about ergonomics, this change seems to be contra-productive towards that goal. Ergonomics has never been about the amount of typing, but about the mapping between people's mental models and the actual semantics of the language. So while this is often phrased as "getting rid of `extern crate`," the important part is less the literal reduction in characters and more the removal of *duplication.* But that isn't even the *main* reason for `crate::`. That is, the point is not just to be a disambiguator to allow the removal of `extern crate`. The main reason is to make the behavior of paths consistent between the root module (`lib.rs`/`main.rs`) and other modules. This means people who don't know the rules of the module system yet will be able to intuit them more easily, and people who do will have to jump through fewer hoops to use it. Typing `crate::` is not a hoop- it's just something you *already do* for paths from dependencies. On the other hand, adjusting paths when switching between the root module and other modules *is* a hoop. Never quite understanding the module system and just guessing until things work *is* a hoop. This is something that was established fairly early on in the colossal multi-thread-spanning discussion- if we were going to resolve this confusing, mismatched behavior, *one or the other* of local or external paths was going to have to change. `crate::` is, IMO, still the best option we came up with- here are some of the other options we decided against: * `extern::std::mem::drop`- requires changes in even more places, and breaks "absolute path begins with a crate name" * `[std]::mem::drop`/`std:mem::drop`/etc.- subtle and line-noisy * `from std use ..`- changes *literally every `use`* rather than only ~half So while I can see typing `crate::` taking a bit of getting used to, I don't see how it's *worse* by any metric other than "I have to type absolutely more characters."
Gotchas, missable tips and tricks, etc e.g. * using a debugger - I'm on windows and setting it up with Visual Studio was quite a journey, couldn't get gdb to work at all * foreign traits on foreign types and "newtypes" * workarounds for trait specialization - I actually don't know any * sized/unsized/Box&lt;T&gt; in generics * Deref and DerefMut * error type coercion and Try - many ways but little docs, myself I use error-chain * needless .collect() instead of returning IntoIter or smth, clippy/fmt/doc * futures, async, tokio, etc - a lot of the stuff out there is outdated, confusing or too basic
I've been updating my Have I Been Pwned CLI tool [checkpwn](https://github.com/brycx/checkpwn), which now uses rpassword for reading passwords and some slightly improved list handling. I've also been working on my experimental crypto lib [orion](https://github.com/brycx/orion) where I now have cSHAKE implemented, and am now looking at some testing.
&gt; What's really weird to me here is that default match bindings introduce a whole new complicated system that is active in only some situations and wildly changes the meaning of the pattern, all in the name of ergonomics (not having to write out `ref`). As in my other comment, ergonomics has never been about the amount of typing, but about how people think about the language. The benefit of match ergonomics is not about avoiding `ref`, but about retaining the ability to work in the mode of "a `&amp;T` is just a `T` with different permissions" (as opposed to "a `&amp;T` is the address of a `T`"). Under that mental model, the new modes are *not* wildly different at all. They are exactly what you would expect- matching a `&amp;Option&lt;i32&gt;` with the pattern `Some(x)` gives you "an `i32` with the `&amp;` permission," because that's the only permission you had to begin with. Much like the other situations in which `&amp;`s and `&amp;mut`s are left out "while in transit" (passing them around, method call syntax, reborrowing, etc.), match ergonomics just pushes concerns about borrowing ("permissions") "to the edges"- arguments, uses, etc. So I really don't agree with your characterization here, of match ergonomics as "a whole new system to get rid of a keyword" and the module changes as "a new keyword for a unified system." They're both unifying -- making existing mental models work more consistently -- and the syntax is incidental (if heavily bikeshedded :P).
That's nice :) You might be interested in [clear_on_drop](https://crates.io/crates/clear_on_drop) for a Drop implementation for the structs `secret` field.
Thanks. I mainly just don't want to have to define `foo` in the `main` scope, because I'd also like to have a `Vec` of `Baz` inside another object. Is there a way to solve this with further encapsulation or a different constructor pattern?
Well, I'd argue that it's not pointers that are complicated, but C/C++ and Rust that layer their own complications on the matter. This is easily demonstrated by the fact that in Assembly pointers really are just integers and bytes are just bits. I do assert that you can also implement higher-level languages (similar to C) with those semantics. That doesn't take away much from the article (which is pretty good), which is centered on Rust/C semantics rather than pointers in general. But understanding the distinction is still important (at least to me).
I disagree. C is not assembly. As a C programmer or unsafe Rust programmer, being aware of the various ways the compiler (’s optimizer) is allowed to eat your lunch should be a very real part of everyday life. Thinking in terms of "pointers are integers" without regard for what is Undefined Behavior can lead to writing programs that happen to work fine in a given compiler version (and might even look reasonable at first glance), but that go Very Wrong when the next compiler version gets smarter about assumptions it’s allowed to make.
Sorry, i didn't create that screenshot. On my IDE i use FiraCode with ligatures enabled ([https://github.com/tonsky/FiraCode](https://github.com/tonsky/FiraCode)).
1. Most of the time it just works if it compiles 2. No nulls in runtime!!! 3. (Almost) no exceptions (there are pa 
I actually decided to make your question a bit of a learning experience for me with optimizing things. I'm using the unstable `cargo bench` functionality to get numbers, but the results were really interesting: https://gitlab.com/erichdongubler-experiments/rust_case_permutations/blob/master/src/lib.rs The key takeaways are: * Your OP solution is actually incorrect for characters that may correspond to more than a single character when their case is changed. Just run `cargo +nightly test` to see! * /u/K900_'s solution is about a magnitude faster and correct with respect to UTF-8, from what I can tell. * I was able to bump up the speed by a magnitude by preallocating cases, case strings, and uppercase/lowercase variants (the latter of which I haven't seen suggested here). Woot! * If you're willing to constrain your correct input/output to ASCII, then you can get a good speed boost (for the magnitude the benchmark is at, anyway). My suspicion is that you could get even more if you used something like the [`ascii`](http://docs.rs/ascii) crate and its string types instead.
Continue work on (graphql-client[(https://github.com/tomhoule/graphql-client) - I plan on starting to tackle the big issues on the [0.4 milestone](https://github.com/tomhoule/graphql-client/milestone/3), those are the last high priority items on the core library - then I want to start experimenting with more specific wrappers, starting with one for yew.
In a classical mechanics sense, yes. Then again once you start moving away from well defined systems momentum/energy becomes more relevant.
Yeah, from a high level perspective this is the case, but in practice, clippy for example used to suggest matching on a `&amp;Option&lt;T&gt;` by dereferencing the expression. So you wrote this: ``` let some_option = &amp;Some(String::from("foo")); match *some_option { Some(ref inner) =&gt; ..., None =&gt; ..., } ``` The problem with this is, this is now stuck in the old matching system. Even though you do in fact match on a reference, this does not get you the benefits of being able to remove the ref here. If you try, you get a compilation error. That's because the new system is only active if you do in fact match on something that is directly a reference. I guess however this is only confusing to someone who was already familiar with the old system. Newcomers likely will never even try to dereference before matching, so it's probably not a problem. If I'm not wrong, there's currently no way to force individual bindings to move though, so you still need to use the old system with partial refs in order to have control about what moves and what doesn't.
If you're hyperoptimizing, this sounds like a good scenario for some SIMD (ab)use, at least in ASCII (or any single-character fixed width encoding) land. You can have a vector of upper case character bytes, a vector of lower case character bytes, and then do something like `result = (upper &amp; mask) | (lower &amp; mask)`, stepping `mask` by 256 every time.
Thank you very much for in-depth explanation!
Can you (safely) modify the length of slices? What I'm trying to do is something like that: Given I have: let mut test: Vec&lt;&amp;str&gt; = vec!["Hello", " world", " testing"] I now want to modify the vector in such a way that the first slice `"Hello"`to refers to `"Hello world"` instead, the second slice is removed, and the third remains. So the result is basically `vec!["Hello world", " testing"]`. Or put another way, I want merge some slices that are consecutive in memory. As a workaround I tried something like `test[0] = &amp;test[0..2].join(" ")`, but it is a lifetime issue, since the `join` constructs a new String whose reference doesn't live as long as the `test` vector. It's probably not a good idea to do it that way in the first place and I should approach it differently, but I was curious if it's possible this way. (The real context is that I get a `Vec&lt;&amp;str&gt;` from using `split_whitespace` but it splits too much at one field and there's three split slices I want to merge into one again - else I'd use Regex or successive splitting to be more precise.)
I did end up playing with one of the examples in the article, and got somewhat curious result out of GCC (at -O3): https://godbolt.org/g/BbeuVt My belief is that this code is only implementation-defined and not undefined behavior, so the compiler is supposed to be somewhat constrained. In this case I'm inclined to believe that actually GCC is wrong here; uintptr_t is integer type, and I would think that if two integer typed values are equal, then they would be interchangeable. So while GCC would be allowed to optimize this to just `return 42` (like clang does), if it actually compiles in entering the branch (as indicated by the call to printf), I think it should return 23.
My impression of the development of programming languages is that history took the following route: 1. C/C++ era. We didn't like it, but it was the best tool we had for building applications. 2. Java/C# era. You mean we don't have to use C/C++ anymore? Yay! 3. Post Java/C# era. Man if only we didn't have to use Java or C# anymore. But we really don't want to go back to C/C++. We're in the middle of the beginning of era 3. People have reached the limits of C# and Java and they don't want to go back to using c or c++. So we are seeing the development of Go, Swift, P, D, Rust, Jai, Zig, and others. Even C++ is radically changing itself in order to provide a much more hospitable landscape. Rust is one of the languages in the new era and it has the facilities to provide a high level code base while being able to target otherwise low level concerns. Also we've learned a lot about what we want to have in our programming environments over the last couple decades and Rust incorporates these otherwise orthogonal ideas. For example cargo makes building and testing solutions standard across the entire landscape.
AFAIU, you don't need `use` anymore when you're addressing the top level of a dependency directly. For example: `type Str = tendril::StrTendril` will only have the `tendril` identifier in that usage and the `Cargo.toml`. Still going to do the redundant `use`s though.
Yeah, this won't be safe because normally you don't have any knowledge that the first two slices in `vec!["a", "b", "c"]` happen to be adjacent in memory. Maybe you just want to split on `"."` instead.
I agree. When necessary, it's still possible to do things like renaming dependencies with prefixes, or putting them in their own `dep` module. At least `mod` is still around :)
Ah yes you're right, outside of `lib.rs` and `main.rs` you would need to use a `use` in rust 2015. Now the behavior is consistent so I find it net better.
Yeah, I change my stance after reading your reply and thinking about it (way too much). You're right.
Is that such a big deal? rustc can just use LLVM for any functions that contain `asm!` blocks, and Cranelift for the rest. That is, unless we want to be able to ship a version of rustc that’s entirely LLVM-free… but as long as Cranelift is only targeting the “quick compile, low optimization” use case, that doesn’t sound like it would provide a good user experience anyway.
Damn was hoping I was missing something else, I had tried with that and many other options with no luck. I have managed to replicate the various attempts [here](https://gitlab.com/mdaffin/rust-cross-compile-tests/blob/master/.gitlab-ci.yml) with the results [here](https://gitlab.com/mdaffin/rust-cross-compile-tests/pipelines/26431923), maybe I am doing something stupid or missing something obvious? The two that actually manage to build seems to be using the broken ubuntu gcc linker rather than the LLVM lld which results in the binaries [1] 243 illegal hardware instruction (core dumped) ./t2 when run on the pi.
I wish that `match` did `ref` matching by default, and that the `move` keyword was used for moving so that, Some(ref x) -&gt; Some(x) Some(ref mut x) -&gt; Some(mut x) Some(x) -&gt; Some(move x) Some(mut x) -&gt; Some(mut move x) Unfortunately this version of match ergonomics is can break some code based on destructor ordering, and was rejected because the original intent was impossible to detect automatically. I still think allowing `move` in patterns is a good idea though.
The phoenix framework is definitely a force to be reckoned with, but [actix web](https://github.com/actix/actix-web) is a great contender in the rust space.
This is a great list, thank you!
You can force individual bindings to move by adding a `&amp;` back into the pattern: let some_option = Some(&amp;3); match some_option { Some(&amp;inner) =&gt; { let _: i32 = inner; } None =&gt; {} } Unfortunately this doesn't *quite* apply everywhere (e.g. it breaks on `&amp;Some(3)`), but that's the idea. Further discussion towards the end of [rust-lang/rust#42640](https://github.com/rust-lang/rust/issues/42640)- we may still be able to fix that last case, I hope.
Thank you for this spot-on summary of the rationale!
It is, but it takes getting used to!
Lambdas, iterator chains and match as an expression were the most confusing for me at first.
Hm, the seemingly correct option (`armv6:clang:lld:target2`) doesn't get to linking and fails before Option 'target' given more than once Try `armv6:clang:lld:target1` but replace `/usr/bin/ld` with (a symlink to) `ld.lld`
Damn, that's a lot of info. Thanks a lot! I'll be trying this out.
That's really interesting. What language(s) were you familiar with before Rust? Seems like most of the mainstream languages have lambdas and iterator chains these days.
I hit the same issue. I gave up, and fixed everything manually. I am generally bad at following instructions, so it is probably my fault, but I think `cargo fix` should print error messages if something is not like it expects it to be. I think 
&gt; I actually decided to make your question a bit of a learning experience Awesome. Thanks for sharing your findings! &gt; Your OP solution is actually incorrect for characters that may correspond to more than a single character when their case is changed. Yeah, I thought that might be the case. I just wasn't sure if there are such characters. Nice catch! &gt; /u/K900_'s solution is about a magnitude faster... Yes it is :) &gt; I was able to bump up the speed another magnitude by preallocating cases, case strings, and uppercase/lowercase variants (the latter of which I haven't seen suggested here). Woot! Would you be willing to turn this into a crate? I searched `crates.io` desperately for a crate that does this before I finally turned to `itertools`. I knew the approach I took would be slow and probably incorrect in some cases, as you have confirmed. &gt; If you're willing to constrain your correct input/output to ASCII, then you can get a good speed boost Unfortunately I can't. The input I'm working with includes non-ascii characters.
That's the plan, I believe. There's work ongoing to make the overall experience cleaner and less likely to unexpectedly fail with no feedback; we'd appreciate your thoughts on exactly what was unclear and (if possible) what we can do better. Feel free to send those our way in an issue, here, or on Discord/IRC, though an issue on rust-lang/cargo would be preferred at this point.
After having looked into it a bit, I think I would need to spend a lot of time to figure out how to make an embedded-hal crate in the first place, and then somehow align that with libopencm3. It doesn't look impossible but the example I looked at was using macros (which I need to figure out) and some traits which I didn't fully understand.
Does anyone know if there are any crates which allow basic multivariate polynomial manipulations? I mostly want to work with polynomial rings over the rationals, although it'd be nice to work over other fields. The end goal would be to implement some groebner basis algorithms, since I couldn't seem to find any of those for Rust (I searched for grobner/groebner basis and algebraic geometry crates and didn't find any). They wouldn't be anywhere close to industry level, but some people may find them useful and it'd be a good learning experience for me. I found the alga [Alga](https://docs.rs/alga/0.7.0/alga/) crate, which seems to support many algebraic structures. However, I could not find anything regarding polynomial rings. The only other related crate seems to be [Symbolic Polynomials](https://crates.io/crates/symbolic_polynomials) which does seem pretty good, and if no one else has suggestions I'll probably end up using it. If anyone used it before, let me know how it is! Thanks!
Empty enums are used because you can't create a value of that type.
Thanks! I appreciate all the work. I have nothing more to add - I just didn't know how to use, exactly in a way that OP described, and only after I read this article I realized that I was doing it wrong.
This is sick. Really nice work and an interesting project. I (think) I found a small bug: In the right-hand chart in the "Statistical charts" section, two of the "o"s were converted to the letter "o" again, rather than a circle. (maybe because there is no pipe underneath them?)
Ah shit you beat me to it lol
They're actually quite different, and both have their uses. Let's say you have these: ```struct Foo{}; enum Bar{};``` What kind of values does Foo have? Actually only a single value is possible: `Foo{};` . Such a type with only one value is called a Zero-Sized Type(ZST). What about Bar? Turns out you actually can not construct any instance of it. The only way (outside of unsafe code) to make an instance of an enum is to name a variant. Since there are no variants, you can never have a value of this enum (in fact, if you do produce one using unsafe code, it's UB). This is called an "uninhabited type". For more info, see here: https://doc.rust-lang.org/nomicon/exotic-sizes.html
One thing to note about the low memory usage, is that it means you can have smaller boxes. That saves money.
Webasm requires either a from the ground up UI framework or using the DOM. Rust hasn't even come up with a reasonable UI paradigm yet, let alone an assembly level UI library and trying to work with something like the DOM inside the rust paradigm is something that just sounds awful. Making rust more usable without std is a fine goal, but webasm is very much not a great fit for rust, even if you assume that webasm is a fit for anything. 
That's good to hear, I'm glad you enjoyed them! With any luck there will be more in the future :)
`let _result = join_all(futs).map(|_| ()).wait();` Why does this work? I am able to get rid of the runtime all together, and I never need to call `spawn`.
 n main() { let https = HttpsConnector::new(4).unwrap(); let client = hyper::Client::builder() .keep_alive(true) .build::&lt;_, hyper::Body&gt;(https); // let mut rt = Runtime::new().unwrap(); let mut x = 0; loop { // let mut futs = Vec::new(); let url = r#"http://127.0.0.1:10000/select"#.to_string(); let request_body = r#"{"query":"SELECT ACCOUNT_ID FROM ACCOUNT"}"#.to_string(); let fut = fetch_json(&amp;client, url, request_body) .map(|response_body| { println!("body: {:#?}", response_body.as_array().unwrap().len()); }) .map_err(|e| { match e { FetchError::Http(e) =&gt; eprintln!("http error: {}", e), FetchError::Json(e) =&gt; eprintln!("json parsing error: {}", e) } }); let _result = fut.wait(); x += 1; println!("{}", x); } /*drop(client); rt .shutdown_on_idle() .wait() .unwrap();*/ } When I run this... I get this weird "ticking" sensation. It'll burst to 250 iterations... then.. sleep? then repeat. I'm trying to achieve maximum performance to prove something. Any advice?
You should be strategic about it, if you want to "sell" Rust at your company. It depends on what your company does and which languages it's currently using (Haskell or C++/Go ?). 1. **What current dev problems at that company would be solved by Rust?** I would look at past problems at the company, bugs in their software, resource inefficiencies, how hard it was to use dependencies (e.g. with C++. Demonstrate how good of a package manager cargo is), how much time was spent debugging (maybe even in hour/dollar terms). 2. **Does the company care about security?** List all the exploits in history that wouldn't have happened if the software had been written in Rust (maybe also in dollar terms). 3. **Does the company care about runtime performance?** Show some benchmarks 4. **Does the company care about runtime resource usage?** There were lots of reddit threads about this. 5. **Preselection** Show a list of blog posts of other companies who are using Rust, and how happy they are with it (and the extensive "friends of Rust" page). Highlight some companies that your company "admires" (or the big ones like Microsoft, Dropbox etc.). Who are you trying to convince, the other devs, TCO, or the CEO? Your selling strategy would be different for each! If they are worried about the limited number of Rust devs available for hire, I don't think that's a problem, a lot of devs who are using Rust are looking for jobs.
It might also be worthwhile to expose the settings for how agressively to convert text to symbols
&gt; and you need to either ensble it, how?
thx
Beginner rustacean here, with more experience in ruby and elixir. The `extern` at the top of `main.rs` was kind of odd to me. I don't _mind_ it, but it's not something I'd have to do before. From my other language experience, I'm used to dependencies just being available in the global namespace as siblings to modules that I define myself. Now the module stuff in rust is still really weird to me. My two mental models of how it work are: 1. elixir style - the top level project defines where the source files are (e.g. `elixirc_paths: ["lib"]`), and then the compiler just loads up those directories, finds the files, and compiles them for you, adding all the module names into the global namespace 2. ruby style - files define classes/modules, and if one file wants to refer to another one's modules, then you require it by filesystem path with `require_relative` (at least, that's the way _I_ like to ruby). In both cases, all the files with their module definitions are what define the module names, and the languages just differ in how the files are found. In rust, I feel totally bamboozled by `main.rs` defining the module name `mod helpers;` or whatever, and then the compiler from that inferring that the code for that module must then live in `helpers.rs` or `helpers/lib.rs`. It still feels to me like the name of the module should be defined by the file that holds the code. I also have gotten confused a bunch about nested directories, since that has concrete implications about what the modules must be named, and how I believe you need some intermediate modules just in order to reach the leafs. And I think you can't have both `foo.rs` and `foo/bar.rs` - you need `foo/lib.rs`, right? Either that or I misinterpreted an error message. For my money, Elixir has the most intuitive setup. I didn't have to read a manual at all. But barring that, I don't mind ruby's approach, which is verbose - you need to refer to stuff via filesystem, but at least it's explicitly _about_ the filesystem. I think I've got the hang of rust's modules by now, and I assume the complications are because it does fancier things on account of being lower level, so I don't really mind it all that much, but it was a hurdle.
&gt; futures, async, tokio, etc - a lot of the stuff out there is outdated, confusing or too basic I can't reiterate this enough. I want to dive into Rust, but it's been absolute hell making even a simple HTTP request. Then doing so concurrently is a different story.
I had a TA who was very strict about calling what assembly uses addresses and not pointers to avoid confusion. I'm not sure I love the terms he picked, but I think calling assembly pointers something different is fair given how often what we actually have to use are C-style pointer and how different they actually are, Alternatively, you can think of assembly pointers as being C-style pointers where the allocation is the whole address space. 
In comparison to other systems languages like C++, rust has a "Safe by default" attitude. I'm new to rust but there seems little in rust or C++ that couldnt be done in either language, but in rust are usually easier to do correctly and safely. rust is usually more ergonomic though. Where rust shines though is choosing safety by default, for all your code. And tooling, it's so much amazingly easier than C++. 
&gt; Your OP solution is actually incorrect for characters that may correspond to more than a single character when their case is changed. /u/K900_ and /u/ErichDonGubler, I must be missing something, but why is `s.to_lowercase()`, not always equal to `string.to_lowercase()`? If I change `cases.push(s)` to if s.to_lowercase() == string.to_lowercase() { cases.push(s); } in your benchmark code then all the functions fail. Doesn't `std::str::to_lowercase` handle UTF-8 correctly?
'Enable' might be the wrong word here since it seems to be a built-in feature after all. The other thread already has the link: https://docs.rs/reqwest/0.8.6/reqwest/header/struct.Basic.html
If you're doing a few API calls per message, then taking a wild stab in the dark you might be spending about 0.5s per message*. Then if you can process 30 messages at one time, you have a throughput of 60 message per second. 1 Million messages at about 60message/second would take about 4 hours, which may or may not be ok. You can always jump that up to like 500-1000 threads as long as you don't plan on using the machine for much else at the same time, or if you fiddle with stack sizes even more. It won't be that efficient in terms of memory &amp; cpu time, but depending what the problem you're solving is that may not really matter. One last thing to consider is that if you even have to scale up beyond "millions" into "hundreds of millions", then async IO may go from being a "nice to have" to be required to get the performance you need. With that in mind, you might just want to use it from the start. * You should try to get a better estimate.
&gt; Then if you can process 30 messages at one time What is usually the limit of how many messages I can process at one time? In my eyes, as long as there is work in the queue... just pile it on as futures to the runtime/executor? Most of the time spent should be spent waiting for IO, right? &gt; async IO may go from being a "nice to have" to be required to get the performance you need. I thought it might be that async I/O adds overhead (scheduling/polling + the stack)
No, you're right. `impl Drop` does require unwinding -- I didn't read your message closely enough (or, I was a little tired when I read it, whichever -- sorry!). Only panic hooks will work with both aborting and unwinding, but it isn't _guaranteed_ to be called in all circumstances. 
\**sighs dramatically*\* \**begins refactoring `Velocity` into `VelocityMagnitude`*\*
&gt; even includes a quote by Quxxy Well, I *was* warned, I suppose. Still, this is why you need to proofread things you post, kids.
Mainly C and C++. Implicit captures took me a bit to get my head around. 
&gt; Rust hasn't even come up with a reasonable UI paradigm yet Rust doesn't have to "come up with a UI paradigm" but are you familiar with Elm or PureScript/Halogen? Those are functional languages (not OOP) and they work very well for UIs (I'm using PureScript with the Halogen framework for frontends at my job), and I think this approach also works well in Rust. Have you tried using yew? It's inspired by Elm and React, and it's basically the same idea. Every component owns some state, and has an update method that dispatches msgs on the component (that can modify the state) and a view method to render the state into html (but can't modify the state). If Rust gains proper GATs / HKTs, this approach would work even better (like in the Halogen framework).
Adds overhead compared to what? Compared to OS threads it certainly doesn't, as each has their own PID (with associated /proc filesystem), stack, etc. Futures are _supposed_ to have about as much overhead as a hand-rolled assembly state machine and split their work over multiple threads (at least I believe so). So I believe for your use case it uses about as little as possible, although a few other solutions (green threads, actix, etc) may also compete in this area depending on the use cases.
We've always had `type Str = ::tendril::StrTendril;` in the current system too though, right? I don't see anything _new_ we can do that we couldn't before- we've always had the ability to leave out `use` if we really wanted to.
There is a hard cap on how many threads or processes an OS can manage, and if those are processor intense, you'll be limited by the number of cores in the machine. I would design your program to be scalable through a configuration file or with a command line argument, if at all possible, so you can pass in your max thread count. Now, I haven't had to do this in rust yet but I have had to do it in C# with a particularly HDD-intense set of operations (and it's that exact program that I am learning Rust so that I can replace it and get something more performant).
If there will be any Python developers in the room, show off Cargo.toml and chant the phrase "per-project dependencies" I guarantee someone will start crying.
In my understanding it works as so In the original module system. If you want a modules `foo` and `foo::bar`, and you want them in seperate files (and also seperate to the root), you'd do: * add `mod foo;` in your root * create the file `foo/mod.rs` * add `mod bar;` to `foo/mod.rs` * create the file `foo/bar.rs`. So code for module `foo` goes in `foo/mod.rs` and code for module `foo::bar` goes into `foo/bar.rs`. If you then want `foo::bar` to have child module `baz` (aka add the module `foo::bar::baz`) that also rests in it's own file * move `foo/bar.rs` to `foo/bar/mod.rs` * add `mod baz;` to `foo/bar/mod.rs` * create file `foo/bar/baz.rs` In the new system (For Rust 2018). For the same setup `foo` and `foo::bar`: * add `mod foo;` in your root * crate file `foo.rs` * add `mod bar;` to `foo.rs` * create file `foo/bar.rs` so code for `foo` goes into `foo.rs` and code for foo::bar goes in `foo/bar.rs`. This already makes way more sense to me. And to add `foo::bar::baz` to this: * add `mod baz;` to `foo/bar.rs` * create file `foo/bar/baz.rs`
Sure, but that stands out as absolute.
&gt; If I'm not wrong, there's currently no way to force individual bindings to move though, so you still need to use the old system with partial refs in order to have control about what moves and what doesn't. You're right, and this is for me the most annoying part about it, because often I have a struct/tuple with many constituents and I want to use match_default_bindings for most, but move one out, I thought I could just cancel out the implicit ref by writing `&amp;` before that constituent, but it doesn't work! This is very inconsistent and feels wrong, so I created an issue about this: https://github.com/rust-lang/rust/issues/50008 Then I raised awareness for it [here](https://github.com/rust-lang/rust/issues/42640#issuecomment-386186568), where the discussion continued but nothing has been decided yet :( I'd appreciate if you could reply to that thread if you also want to have the ability to cancel out match_default_bindings for selected tuple/struct constituents (revert back to normal binding mode) by writing `&amp;` in front of them, like in the example I gave in that issue :) Or if you have an idea how to address the open questions (about this proposed solution) that came up in the discussion..
How do you mean? You still had to write `use crate::foo;` in 2015, e.g. `extern crate mycrate; use mycrate::foo;`. How is it more verbose in 2018?
Ok, but what when you're just using rustc without cargo?
I haven't looked at that code specifically, but UTF-8 itself can have asymmetries mandated by Unicode itself. For example, eszett (ß) was considered a ligature of "ſs" (long-tailed s, regular s) until the uppercase eszett (ẞ) was introduced in 2017, so software still implements uppercasing the lowercase eszett by converting it to "SS" because of that, which will then lowercase to "ss". (eg. tschüß -&gt; TSCHÜSS -&gt; tschüss)
To be clear, I'm not saying that Rust can't be a webasm client in future, I'm saying it isn't there today. Rendering HTML is only half the battle, you've still got to deal with the DOM, and the DOM is mutable shared state. Elm and purescript both compile to JS which is also vastly different than webasm. 
When you're using yew, it deals with the DOM so you don't have to. I'm currently porting my UI frontend for my DJ/VJing application from Polymer to Rust/yew, and it's working very well.
Looks great! I'd love to see a "Why would I want to translate C to rust?" FAQ near the top.
The new module system requires you to prefix all the use statements for all the items that you import from your own crate. So Rust 2018: `use crate::my_local_module::my_local_fn;` vs. in Rust 2015: `use my_local_module::my_local_fn;`.
Or just show them this tweet: https://twitter.com/OtaK_/status/1021676269233164288 &gt; Same here. I don't see any reason to use C/C++ anymore. Using Rust in production allowed me to work with juniors with no side-effects/annoyance/breakage! It's amazing! (The original tweet, too.) But the point about everyone on the team being able to work together on a huge code base without introducing bugs is a huge selling point for Rust! (Similar to the "fearless refactoring of huge code bases" point.)
Don't just emphasize language features. However, language features are important :) What I would emphasize would depend on what my company was using. If your company uses Python or JS on the back-end, I would show off things that emphasize how easy it is to refactor (adding extra cases to enums, renaming, etc.), how strong the type system is WRT to generics, and the emphasis on the correctness, i.e. "if it compiles, it works". If your back-end is statically typed, e.g. Java, I would emphasize the things that Rust does better than Java, e.g. really good generics, speed/memory footprint, and really really good first class macros, that are themselves type checked. I'm not an expert on C++, but I would probably emphasize safety and the inability to make use after free bugs or to have UBI due to race conditions. Oh, testing :+1:
Good point on the clippy lint; I'm responsible for that one. Maybe we can add a new "simplify match" one that covers most of the corner cases? (Hoping most of the cases are also mechanical enough for rustfix to do!)
You mean in main.rs/lib.rs? In other modules it was currently `use self::my_local_module::foo;`.
No you're right, there were even benchmarks shown between a simple futures-based (tokio) echo server and a hand-written state machine (mio), and the hand-written one was marginally more performant. Either one will be amazingly more performant than OS threads for sure though, I mean just consider that fewer context switches will occur
Yes, `use crate::` to reference local items like so: https://github.com/LiveSplit/livesplit-core/compare/master...rust2018#diff-d3e5ac6c5d1ce72252ef4054c718616dR1 With nested use it's not that bad though.
&gt; I have never seen anybody try to "handle" (as in, recover from) a panic in a Rust program in the wild, which would have to be done by abusing `std::panic::catch_unwind`. I wrap my atomic units of work in `catch_unwind` so that the various "'this can never happen' actually happens" bugs I've encountered in 3rd-party dependencies abort a single unit of work (eg. thumbnail, index entry, etc.) and log an error rather than taking down the whole process. I've mentioned before that goblin used to have a bug where certain perfectly valid EXE files [could panic it](https://github.com/m4b/goblin/issues/36) it but that's not the only case. For example, at the moment, I'm working around two bugs have made me very disappointed with `serde_json` because Serde itself [panics](https://github.com/serde-rs/json/issues/464) if the filesystem feeds it a `SystemTime` prior to `UNIX_EPOCH` and, if doing streaming serialization, invalid UTF-8 in a POSIX path causing an `Err` result still leaves the JSON output in an [inconsistent state](https://github.com/serde-rs/json/issues/465) that can't be recovered from.
But with `panic = 'abort'` you don't get the landing pads, right? So what's so bad being able to opt out when you don't want them? :) Are you saying it should be the default? But then people who need it forget to opt-in before a panic happens in production..
Looking at Yew that's a lot of turd polishing for me. Fundamentally the DOM is evil and wrapping that evil with rust doesn't make it not evil. The DOM is a gigantic blob of mutable shared state. 
I don’t know if that really works, though. Another comment sub-thread talks about how *inline* assembly needs integration with the code generator for the surrounding function, in order to know what registers to use.
Yes, you'd have to use LLVM for the entire function containing the `asm!` block. But most functions don't contain `asm!` blocks, so it shouldn't make much difference to compile times.
&gt;&gt; Then if you can process 30 messages at one time &gt; What is usually the limit of how many messages I can process at one time? This : &gt; and spawn like... 30 threads? The gp is talking about the synchronous case, to convince you that async is a probably a better idea for your use-case.
Even in assembly pointers are not necessarily integers. There is nothing stopping an architecture from having registers dedicated to pointers, or instructions that operate on pointers and manipulate the bits differently than they would for integers, for example preserving or ignoring certain special bits in the pointer. This is true for the upcoming Mill CPU architecture.
&gt; Yeah, I am interested in creating something like this, you seem shocked 'D. Not at all, just wanted to understand what you ment by "linux distro". If it is a desktop environment you really ment there is currently one major drawback, no stable ABI. That would make it hard to distribute binaries for it. I think that will stabilize in a few years and I guess it would take a couple of years to write a new desktop environment with the features of KDE or GNOME so probably not a show stopper. Other than that I don't see any major problems, besides lots and lots of work. To me that work would be better spent improving existing desktop environments, but to each his own.
&gt; assembly uses addresses and not pointers to avoid confusion. That is pretty clever, if bit pedantic. But pedantry is the name of the game anyway
True. There is actually pretty little you can generalize over all possible assembly languages. I should have said x86_64 instead, but I think the point came across still.
Or from the fact that all major browser manufacturers agreed to refuse to support TLS-free HTTPS as part of the same effort where they're making various new HTML/JS/CSS/etc. features contingent on the page being served over TLS to push the web as a whole toward encrypted operation.
I want to second clippy , rustfmt, and tokio. People rave about these features all the time. But at least on DuckDuckGo, there is almost no visibility for these beyond issues in those projects' respective github trackers. I don't know if I'm alone in this, but I also feel a want for a good introduction to the standard library. (Or more likely, I need to work through more basic exercises).
I agree completely with all but one of these. Cargo is just not that big a deal.
It is the difference between the additive identity (0, since x + 0 = 0) and the multiplicative identity (1, since 1 x = x). An enum is analogous to +, and sure enough, an empty enum has 0 elements. A struct is similar to \*, and again, an empty struct has 1 element. Both are fairly useless in typical day-to-day programming. But they are important in theoretical ways, and when engaging in needless typewankery.
\`termion\` is a cool pure-rust ncurses-like (and probably ncurses-lite). It offers a clean API to handle input and move the cursor around.
&gt; (Or more likely, I need to work through more basic exercises). Did you have any particular exercises/materials in mind?
I guess I am just thinking of my fluency in Python (my primary language) to Rust. Let's say I wanted to write a simple app that would walk a directory, reading each file, maybe parse it (as, I don't know, a JSON, let's say), process it, and append it to a list, then at the very end, generate a report, and write that to a file. I could get the job done, but it would be an exercise in reading documentation. 
Cargo.toml lists all the dependencies, so I don't think that much is lost with the removal of `extern crate` statements.
I don't get landing pads in my code, but I do get them in std, because that one is not compiled again. Being able to opt-out is definitely better than not being able, but I still feel abort should be the default. My point is, you don't need anything for abort to do something sane. But for unwinding to do something useful, you need to do other actions as well ‒ if you want to be able to survive bug in a query processing, you do want to at least log the panic, restart the thread in the thread pool… so if you go that path, you already know about panicking and unwinding. But I think many people are not aware of the downsides of unwinding or even that it exists and when it happens to them, it hurts more than helps. It is possible to get a backtrace with abort strategy and you actually should be able to get it in the panic hook. You also can take the core dump produced with abort and examine the backtrace (with values of variables, etc) in a debugger, which you specifically *can't* do with unwinding, because it doesn't create the core dump. Anyway, that thing with error_chain looks strange and it probably shouldn't be possible to mandate unwinding by a crate. At least I'm not aware of a way.
Much better :) I’d probably add some emphasis to “No &lt;type of person&gt; here”, though.
&gt; Is it better to use one over the other? It's not better, they have different uses entirely: an empty enum has 0 values, so it's used solely as a marker type with no runtime representation. An empty struct is a singleton (it only has one possible value), it can be instantiated and "exists" at runtime though its sole value is 0 bytes. byteorder uses empty enums because these types are used to statically select functions in a namespace, [the ByteOrder trait refers to neither `self` nor `Self`](https://docs.rs/byteorder/1.2.3/byteorder/trait.ByteOrder.html), there is no need to instantiate it and so this was made impossible.
Then you need to extern crate. That said I do not think that rust without cargo should be something to aim for. I rather have a way to establish something like an inline toml in a single .rs file.
&gt; I'm a bit concerned about Rust 2018, as a lot of these new features come with edge cases where they do not work. extern crate is sometimes still necessary, default match bindings aren't always active, wildcard lifetimes sometimes don't work and implicit lifetime constraints don't happen in all places. But that same applies to lifetime elisions and all the other things we have in the language that as comfort features. I don't think 2018 is in any way worse than that. More importantly I do expect that people will write different rust in 2018 that edge cases come up less. I remember when extern crate did not rename the dash to an underscore and what a controversy there was around this single character and crate aliasing. A lot of this conversation that currently takes places just echos earlier ones and if it's anywhere close to those then we can all collectively relax :)
&gt; Does anyone else feel this way? Absolutely the opposite. I always wanted this but I effectively gave up asking for it when 1.0 hit. The fact that 2018 brings an end to the mixed namespace madness is making me incredibly happy. Python programmers always prefixed imports with the absolute package name, so having a shortcut to refer to the current create is an ergonomic win over it.
&gt; if bit pedantic Pun intended?
&gt; As part of the Emacs build process, a simpler version of the editor, called "temacs", is built. That program consists of all of the C files in Emacs, which comprise the Emacs Lisp interpreter and not much else. It is then run to load the standard Lisp startup files and to dump a copy of the running program. That dump is then used as the binary that users invoke when they want to run Emacs. What....
Thanks /u/azure1992 and /u/Quxxy it works great.
&gt; Plus webasm of course, which is probably a fairly stupid thing to focus on, but trendy. I think this is just because new adopters tend to be web developers recently because that's where the most developers are right now. I also feel that they're less likely to be stuck in a giant corporate setting that has significant institutional momentum. Yes I agree they're simply catering to it because its the hip thing recently.
1. Cargo and Crates.io: the build process is so infinitely more straightforward than almost any other compiled language (except maybe Go) that I've used. It's awesome. It also adapts reasonably gracefully to using private sources more appropriate for proprietary software. 2. (possibly controversial) Error handling: the Result pipeline encourages really useful error data instead of vague garbage that frequently happens in other languages. Even if you just wrap the errors that you could produce, the wrapping gives a very specific failure chain which is useful. 3. Data-race free: especially for concurrent applications this elimonates a whole class of bugs that can be extremely difficult to debug. 4. Memory-safe: say goodbye to "segmentation fault, core dumped" except in extreme cases such as unsafe code or compiler bug. 5. Serde / strongly typing everything: Being able to transparently encode, validate, and decode JSON messages is really useful and eliminates the constant annoyance of poking received messages carefully to check their fields. This applies to things like enums and a variety of other libraries, but serde was the most impactful to me. 6. Documentation Support: it's really easy to generate genuinely useful rustdocs from your code, which is a godsend for dependent teams trying to use your API. 7. Unit and Integration Testing support: the cargo testing support is useful enough to handle reasonably large projects without issue, not to mention there are crates like stainless that build on it. 8. Statically linked: executeables are typically a single binary potentially linked against the libc, simplifing dependency tracking. Most of the time it's drag and drop on the same OS for me. 9. Clean syntax?: Generally doesn't have competing ways to do the same thing so much as C++/Java? 10. Community: the fact that we're having this conversation should be enough said. 👍 
I feel like I've missed something, what's Rust 2018? Rust 2.0?
&gt; But they are important in theoretical ways, and when engaging in needless typewankery. Unless you want [ergonomic safe APIs over low-level hardware details](https://docs.rs/nrf51-hal/0.5.1/nrf51_hal/gpio/gpio/struct.PIN0.html#method.into_floating_input) so that you don't need to be a rock-star programmer to avoid breaking stuff.
You should take care on how many API call you can do in parallel. Is it ratelimited? Does it behave on heavy load? Maybe you should consider that to make your choice.
Easy enough to start with, meaning if you come from Python, PHP, JS, etc. you will get _something_ done with some reading and trying things out. I've always wanted to learn C and similar, but the pure premise of having to set aside a secondary brain to manage memory and safety\* has always put me off learning it. With Rust, I can just jump in and only dedicate a portion of my brain to managing memory and safety, and often those things "just happen" with help from the friendly compiler. Rust has an awesome community and the ecosystem is great as well. With Cargo, everything is really simple to setup. Then there is the whole WASM thing. Write safe and fast Rust, then compile it into a JS compatible WASM lib that runs in the browser. Things like `stdweb` and `wasm-bindgen` really make Rust a good WASM tool. Many are saying WASM is the future of portable computing as well. \*With safety I mean things like undefined behavior and unwanted overflows. Exploitable application-level holes are easy to make in all languages.
As far as dashes in crate names go, the edge case wasn't that dashes weren't translated into underscores, it's that crate names were allowed to contain a character that was not a valid identifier name.
The people most excited about webasm are not really web developers per se. People already using JavaScript and happy with it aren't super excited about webasm. People who don't like and usually don't really know JavaScript are excited by webasm, because they think they can totally replace the whole html/js/css package, which is probably wrong. 
The way you avoid letting your programmers break things is to make the type system complex enough to induce measurable levels of survivor bias in your new hires ;) Empty types are actually especially important in dependently-typed languages. I would even go as far to say that they are the *key* ingredient to any safety beyond what your typical SystemF-derivative gives you. There's nothing that says `unreachable!` quite like constructing an object of an empty type.
Excuse me but typewankery is often very useful.
There were all kinda of discussions like that dashes should translate to `::`. 
I don't know a lick of JavaScript (other than somewhat reading it because its similar syntax to C-likes), but there's no way its going anywhere.
I didn't say it wasn't.
`Speed`
It's a common WTF of languages from the period also seen in things like SmallTalk. It's called having an "image-based language". (ie. You suspend the running and booted-up program to an image on disk and that's what you distribute as a "binary".) They also tend to have the image as the "source code" for the dubious benefit of being able to dynamically modify the running program.
Obviously before my time though if we go back far enough that wasn't occurring either (fortran, COBOL, etc were all compiled binary languages). So this must have been a temporary phase that occured. I wonder what the OS-span x year-span was of where this occured?
I've recommended this pattern before, but I don't think I ever implemented it. The way I'd do it (assuming no futures) is to have a fixed number of buffers in a channel. The workers dequeue a buffer, fill it, then send it across a channel to be read. When the reader is done with a buffer, it send it back on another channel making it available to the workers. This is nice because it handles rate limiting (when the workers are too fast) and avoids allocating the buffers. But note that sending a buffer across a channel still incurs an allocation; to avoid that you could probably use a ring buffer of sorts. There are some complications in your case, though: * with futures, you'd have to use something like `futures::sync::mpsc::channel` instead, which complicates things a bit * I'm not sure how you should handle the ordering (that probably depends on the specifics of your app)
It was more about a specific area of the period ecosystem associated with academia as a way to get high degrees of language dynamism without obscene startup times. You saw it with SmallTalk and with LISPs, but not with Fortran, for example.
&gt; (0, since x + 0 = 0) (0, since x + 0 = x) but i think it would also be helpful to explain a bit further enum Base{ A, B, C } Then it has Three possible Values. If you now define an new enum enum Sum{ One(Base), Two(Base), Three(Base) } then you have nine possible values, One(A,B,C), Two(A,B,C), Three(A,B,C) so an addition of the possibilities of each variant. were you to define a Struct instead struct Mul{ first: Base, second: Base, third: Base } you would end up with 3\*3\*3=21 possibilities {first: A, second: A, third: A} {first: A, second: A, third: B} and so on. That is why enums are sometimes referred to as sum-types. It also works if you use other Types for Base. An u8 has 256 possible values and so on.
To tie that in with the parent post: if you define empty structs and enums: enum EmptyE{} 
https://rust-lang-nursery.github.io/edition-guide/
I'm working on porting my old name generator code from node.js (ngn4 on mpm, though I've gotten much better at node.js since then) to rust to get comfortable with the topics for the first 12 or so chapters of the book since I started two weeks ago. I've found that a great way to learn by trying and failing multiple times, and seeing the performance of different approaches.
I think you have a typo in the installation instructions: ``disesel migratation run``
Can we agree on "Pointers in C/C++/Rust are complicated"? :) I hope I made the context clear enough in the post. "Pointers are complicated" is clearly also a provocative statement to trigger some discussion. Though it is still something that I think I can stand by. Vastly more people are in contact with C/C++/Rust's pointers than with assembly-level pointers.
Those are good questions. :) What really should happen is that pointers lose there "special-byte-ness" when converted to integers, and that's what you should do when doing such tricks. We didn't do that for miri because it is hard and has little benefit for the interpreter, at least right now.
I would be curious to see how this implementation compares: https://play.rust-lang.org/?gist=2848a05d5e05c5421f3a14559f366e94&amp;version=stable&amp;mode=debug&amp;edition=2015 I like writing code this way; moving things into structs with methods, and trying to expose iterators where possible. I'm curious if the compiler can optimise this stuff well.
3*3*3=21... ex falso quodlibet ;) 
I do, a lot :) But I don't want to rehash that discussion here.
Cargo... only or rather especially if you come from a language like C/C++. Don't get me wrong, Cargo is very nice, but it is less so, if you come from something like Maven, Gradle, SBT.
&gt; The way you avoid letting your programmers break things is to make the type system complex enough to induce measurable levels of survivor bias in your new hires "The type system chooses the programmer, Mr. Potter." 🤔
I see. Thanks for the explanation.
I wonder if I could beg a favour: as you point out that C and C++ actually have essentially the same issues in this area, could you please drop the use of C++. The relevant code changes are pretty trivial in your context, just a little more verbose, so for instance your first definition of `test` becomes: int test(void) { int *x = malloc(8 * sizeof(int)); int *y = malloc(8 * sizeof(int)); y[0] = 42; int i = /* some side-effect-free computation */; int *x_ptr = &amp;x[i]; *x_ptr = 23; return y[0]; } (unless the semantics of `new int[]` include zero initialisation, in which case use `calloc(8, sizeof(int))` instead). Having realised rather more than a decade ago that C++ is a huge mistake I treasure my growing ignorance of the language, and I don't think you gain anything by going there.
Yes. It should be better. I just wanted to get something in place that wouldn’t hang the rendering. This was a toy to play with these technologies, I’m not sure how much further I’ll take it.
I'd do sync, because 30 threads is not a lot. And currently async is hard. Async is used when you have long running sessions with conplex state and you don't want to write a state machine and fiddle with a global in memory database and so on. And of course threads are heavy, they need a lot of RAM and context switching is costly compared to an executor switching tasks. 
I've never written any Rust code, but wouldn't it make more sense to make [User::byUsernameAndPassword](https://github.com/marcocastignoli/rust_rocket_api_authentication/blob/master/src/user/model.rs#L32) return an Option&lt;User&gt; instead of a User object where the Id is None?
Thanks, I had no idea that Cretonne worked this way. I was extrapolating my knowledge from AOT compilers. 
Sounds like you need more tests. This is exactly the sort of scenario I'm dealing with as I refactor and improve the heuristics in my filename-&gt;title guesser and having a test framework which takes a big corpus of inputs and then produces an accuracy score and readout of failed guesses has been invaluable.
Good point. It's been about 2 years since I've touched Go, so I obviously forgot more than I thought...
Yes, fair point.
Right, fair enough. I was mostly referring to someone's suggestion to use IntelliJ as their IDE. I love the idea behind RLS. I just loathe vendor lock-in. But if you're using a language and the language has official tools, that's a bit different.
Yes it definitely makes sense, thanks!
Fixed thanks :)
&gt; &gt; &gt;User::byUsernameAndPassword &gt; &gt; return an Option&lt;User&gt; Fixed
&gt; auto x_ptr = &amp;x[8]; /u/ralfj that is actually undefined behavior as well. If you desugar it, what you are actually writing is: auto x_ptr = &amp;(*(x + 8)); The C++ standard allows you to do pointer arithmetic till one past each of the ends of the array, however, it does not allow you to dereference a pointer that is out-of-bounds (which `x + 8` is).
In any case, it's a nice project and a good demo for Yew. Cheers!
&gt; Is it better to use one over the other? It depends on your use case. * Empty structs are used in code that is generic for types that may or may not have state. Let's look at an example: The tait [`rand::distributions::Distribution`](https://docs.rs/rand/0.5.4/rand/distributions/trait.Distribution.html) is implemented for distributions that can be sampled to generate random numbers. Some distributions don't have a parameters (such as [`StandardNormal`](https://docs.rs/rand/0.5.4/rand/distributions/struct.StandardNormal.html)) and are implement as an empty struct. Others (such as [`Uniform`](https://docs.rs/rand/0.5.4/rand/distributions/struct.Uniform.html)) have parameters and require a non-empty struct to store them. * Empty enums are used in code that is generic in types that cannot have a value and only exist at compile-time. This can be used to implement functions that dispatch based on a compile time argument. You can think of it as an open enum argument of the function that works at compile-time. An example is the [`byteorder::ByteOrder::write_u32`](https://docs.rs/byteorder/1.2.3/byteorder/trait.ByteOrder.html#tymethod.write_u32) you mentioned.
Though Smalltalk - in its defense - has a whole runtime system controlling the memory around that. Emacs literally uses the GNU operating system components to achieve that.
I don't thnk the upper case ß has been adopted into the german language yet, so I always find this to be a funny example.
[Does not work](https://gitlab.com/mdaffin/rust-cross-compile-tests/-/jobs/84268084). Interestingly it seems that it is only taking the last of the link-flags arguments: "clang" ... "-l" "util" "--target=arm-linux-gnueabihf" However, I noticed that it is only passing a single link-args param, turns out I need link-arg instead... Sigh... There is also [a issue](https://github.com/japaric/xargo/issues/45) with spaces in the link-args flag, which was causing problems with some of the attempts. RUSTFLAGS="-C linker=clang -C link-arg=-fuse-ld=lld -C link-arg=--target=arm-linux-gnueabihf" cargo build --release --target arm-unknown-linux-gnueabihf [Is one step closer at least](https://gitlab.com/mdaffin/rust-cross-compile-tests/-/jobs/84287336). 
Isn't a signal the perfect way to interrupt it?
I have a different opinion of those systems than you do, I guess.
This is a self-referential struct, and it isn't very well supported by rust. Your `From` implementation only works because you're making a copy of the `&amp;'a str` you're passing in, but that doesn't seem to be what you want by the title. What are you trying to do? Maybe you can get the indices from `split` and save those as an alternative.
You can't keep them in the same stryct because what happens when you move the struct? The references inside become invalidated, as they were pointing to where the struct used to be. In general if you find yourself in this situation you should either try breaking the struct up into different parts or try a different way of indirection, such as integer offsets that make the &amp;str slices instead of pointers.
In my application, the original URL string and the segments parsed by the string are all useful lately.
Why couldn't this be left as it was? :( It doesn't conflict with optional `extern crate`..
Like cargo-script does it?
&gt; So I still need to spend multiple hours to actually switch all the match statements to default match bindings, switch all the trait objects to dyn, rewrite all the use statements again, ... So overall while it did work for me, it wasn't all too helpful in comparison to the total amount of work needed. Shouldn't it be able to convert trait objects to `dyn` syntax?
Sure but we don't have to worry about the DOM, we're just rendering to it.. We're not manipulating it manually. So its ugliness/evilness doesn't affect us.
I mostly did this out of laziness TBH.^^ `new` is just a bit simpler to use than `malloc`, and also more clearly a language primitive. Other people will prefer C++, so I am not sure I am gaining anything by changing this to C now.
So the URL, once acquired, can stay read-only? In that case, you could find an owner for the URL (maybe simply a Vec that only gets dropped after all your Sprig structs have been dropped), and have your Sprig contain `&amp;'a str` as a reference to the full URL, and `Vec&lt;&amp;'a str&gt;` as the references from `split`. I've implemented something similar, and didn't find it hard to do. Can't tell if that suits your needs, of course.
String allocates it's underlying str on the heap, so this isn't actually an issue
I ran them myself. test tests::bench_bitmasks ... bench: 44,804 ns/iter (+/- 2,201) test tests::bench_bitmasks_preallocated ... bench: 5,209 ns/iter (+/- 375) test tests::bench_bitmasks_preallocated_ascii ... bench: 2,675 ns/iter (+/- 510) test tests::bench_bitmasks_preallocated_ascii_1morebit ... bench: 2,713 ns/iter (+/- 160) test tests::bench_naive_iterator ... bench: 574,625 ns/iter (+/- 94,003) test tests::bench_peters_version ... bench: 15,122 ns/iter (+/- 2,231) So it's about 3 times slower than the preallocated bitmasks version. I think it's to do with the size of the `Case` struct. However, if you didn't need the full vec to be allocated, this method is probably faster because it can write into an existing buffer rather than needing to allocated a new `String` for each.
I'm learning Rust and want to make a static site generator as a project and thought about using \[Haml\](r/http://haml.info) as the templating language but then saw there were no Rust libraries for Haml, which made me want to create one. I learned a lot doing this project and wrestled with the borrow checker more times than I want to admit (though it did teach me about arenas, which is neat). I would welcome any feedback as well as any tips to make this more idiomatic Rust.
This is what I was referring to: &gt; In 2017, the Council for German Orthography ultimately adopted capital ß (ẞ) into German orthography, ending a long orthographic debate. -- https://en.wikipedia.org/wiki/%C3%9F However, even if we're not talking about the same thing, if anything, your argument merely *supports* my argument about ß being an example of asymmetric case conversion rules.
You don't need extern crate. Run `cargo -v` sometime; you'll see that it already passes a bunch of `--extern` flags in, that's all you need. cc /u/boscop
Hm, apparently I did not get the memo that we officially adopted it :) I wasn't disagreeing with you, just that it always seemed to me as Unicode being "overly correct".
Use Weak and Rc, it's made for that.
I'm not sure from context exactly what features the "test-dummy-unstable" feature flag enables. I tried to google to find documentation for that but I'm not seeing it. Anyone have a link?
Weekend ray-tracer! ( but i am sure it will take me many, many weekends...)
Yes, that's very interesting work! Unfortunately, the paper does not go into a lot of detail about pointer representation and provenance tracking. I can't even find the definition of what memory *is*, and I cannot find a technical appendix. Am I missing something? They seem to have a much broader focus, and the memory model is just a small part of their effort. Not saying the other part is not important, it totally is. The memory model is somewhat special though (I feel) because it is often shared by the surface language and the IR -- switching memory models during compilation is hard to get right -- and because it often has very "non-local" effects. Most of the rest of C can be "explained away" with a lot of work by a detailed desugaring (exactly what Cerberus is doing), but things like provenance tracking can need more profound changes like changing what data memory can hold. That said, even in terms of the memory model, C has other complications that I am not even mentioning in the post: You cannot rely on data layout. So even just thinking of memory as consisting of "bytes" is totally wrong, memory is more like a tree reflecting the nested `struct`s and arrays that are stored in memory. Pointer arithmetic is only allowed within an array. [Robbert Krebber's PhD thesis](https://robbertkrebbers.nl/thesis.html) does a lot of work in that direction; on a quick skim I could not see any of that in Cerberus?
I'd guess it's for testing the feature enabling system on Cargo.
The comment in the commit linked by OP says, \`test-dummy-unstable\` only enables the \`im-a-teapot\` flag. This is for testing.
Of course it does. You're putting a wrapper on top of the DOM, but that wrapper makes promises the DOM can't deliver. That's the problem. You can't make the DOM fit the rust paradigm. 
Ahh. Understood.
You are correct. It is a permanently unstable cargo feature for cargos internal test to use.
Searching repositories instead of google generally brings better results. Better yet, read the content in the OP’s link. // A dummy feature that gates the usage of the `im-a-teapot` manifest // entry. This is basically just intended for tests [unstable] test_dummy_unstable: bool, 
Rust `uses_this_naming_convention_for_methods` and not `thisNamingConvention`.
Sounds like you're looking for the [Rust Cookbook ](https://rust-lang-nursery.github.io/rust-cookbook/)
Also Rust uses `this_naming_convention` for methods and not `thisNamingConvention`, but I see most of the project is correct.
One issue is that there are 2 unstable features required for 0.3 other than `futures_api`: `pin` and `arbitrary_self_types`. I'm not sure how close to stabilisation `pin` is, from what I've seen it's pretty done, but `arbitrary_self_types` still has an open RFC so probably won't be stable anytime soon.
Great, I'm learning with this as well :) Another idea: Should [is_valid](https://github.com/marcocastignoli/rust_rocket_api_authentication/blob/master/src/user/auth.rs#L21) return an Option&lt;String&gt; instead of a string filled with "0"
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/opensource] [An API example written in Rust with the rocket.rs framework. That's the first time I write something in RUST, I publish this here to receive suggestions, and to help other newbies start building a web service in Rust. (x-post from \/r\/rust)](https://www.reddit.com/r/opensource/comments/91s78d/an_api_example_written_in_rust_with_the_rocketrs/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I don't think I can say strongly enough how well written this blog post is. Excellent work making a highly readable _and informative_ intro/user experience.
I was actually going to experiment with turning this into an `Iterator`, because I'm just like you -- if I can add some nicer zero-cost abstractions, I'll use them! It's way nicer down the road if you know you're going to be using it. :) One thing I notice reading your code right off the bat is an incorrect `assert!` on line 57: assert!(upper.len() == lower.len(), "Changing case should not change number of characters!"); This is actually potentially false. See a sibling response here for an example, or the UTF-8 cases I've set up in the Gitlab repo I linked (which happens to use the same letter).
Nice!
Yeah, it might not touch on completely the same points as your article did, but I felt it was related enough to be interesting. As the authors are mainly concerned with (de-facto) C, what memory *is* is probably mostly what the standard says (does it say anything?) and what common compilers and architectures do. Related to provenance tracking, I found these notes for the ISO committe on their website: http://www.cl.cam.ac.uk/~pes20/cerberus/notes97-2018-04-21-provenance-v4.html#proposed-semantics-in-detail These seem to try to give a clear scheme of how provenance is preserved through operations.
Also: remove temp files on panic may prevent disk filling up.
impl Clone for RustProgrammer
`NoInvariants` marker, so that `Mutex&lt;T: NoInvariants&gt;` doesn't poison mutexes would be handy too.
I had a very similar requirement in one of my crates. I [used the `rental` crate](https://github.com/addr-rs/addr/blob/ee97939cc9fac0a514a0bc661c23775c88ae3401/src/lib.rs#L110) for that. 
Partial moves generally speaking don't make sense. A tuple or struct with some of its pieces moved out isn't whole anymore. If you borrow some parts and move the rest, you may as well move everything out and then borrow the parts you want to be just borrowed. If the object you're matching is borrowed, it's moreover illegal to move anything out of it anyway. Unless the parts you want to "move" out are actually Copy. In that case you really are wanting to copy it (so the original stays in place). In that case, using &amp; to "cancel out" of being in the ref binding mode to force a "move" that's actually a copy (which can only be done for Copy types anyway) feels like quite the mental gymnastics. Maybe just add in a copy contextual keyword alongside ref and ref mut? This clearly states the programmer's intent without also being confused for a mechanism to do things that are not allowed (moving T from behind a borrow when T is not Copy).
&gt; This is actually potentially false The message is worded badly, but it's checking for exactly the thing you're describing :)
There is a small error in the blog post. It states that: auto x_ptr = &amp;x[8]; is defined behavior because the C++ standards allows you to build pointers to one element past any end of an array. The quote about the C++ standard is correct, that is allowed, but that is not what the code is doing. Replacing `operator[]` with its implementation, we get: auto x_ptr = &amp;(*(x + 8)); where the undefined behavior becomes clear. `x + 8` creates a pointer past the end of the array, but only by one element, so the behavior of that operation is defined. However, `*(x + 8)` dereferences the pointer, which is out-of-bounds, invoking undefined behavior. The C++ standard does not allow dereferencing pointers out-of-bounds, not even if they are only out-of-bounds by one element. What the post should have written is: auto x_ptr = x + 8;
I did something similar recently, focusing on how Rust can prevent common (Java) bugs. I drew some inspiration from Llogic's excellent blog post: [https://llogiq.github.io/2018/04/03/corners.html](https://llogiq.github.io/2018/04/03/corners.html). I guess to boil it down to one of your ten points: Rust prevents you making many common mistakes at compile-time. Obvious examples are memory/data-race safety - but also Option types, affine types (if you want to get into it), enums to make invalid data unrepresentable, etc.
Rustdoc is great for generating docs from your own code - but the ability to see generated documentation from *any* package on [crates.io](https://crates.io) via [docs.rs](https://docs.rs) cannot be understated. This is by far the thing I miss most when working with other languages.
It depends on what the expected outcomes are. Going by the name `is_valid`, I would expect the function to return a boolean. But what the function actually does is to retrieve the value for the key in a token (as far as I can tell), so I would probably rename the funtion to fit that purpose. For the return type, using `Option&lt;String&gt;` is certainly much better than returning a string with "0" in it. But the question of whether you should use a `Result` or `Option` depends mainly on *why* there can be an "empty" value returned. The idea with `Option` is that its two states (`Some` and `None`) both indicate that the function ran successfully, but `None` can mean that your result is just empty. For example, if you implement a search, actually using the search might still find no data for you, because there was no data that matched your search criteria. In this case `Option` is a great fit, because the `None` branch still indicates that everything went well, even though you didn't find anything. `Result`, on the other hand, indicates that a failure occurred. For example, if you always expect a token to have the value you are interested in, then the only reason you won't get the value is if token is somehow invalid. This is a great place to use a `Result`, because you can indicate *why* you didn't get a value, even though it should be there. And since the `is_valid` function looks like it's just used internally, you can get away with just using a `String` as your error (so returning a `Result&lt;String, String&gt;`) with an error message like "Couldn't validate token something-something-useful-information".
With a more "tricky" input string, `"ßßßßßßßßß"` it's only twice as slow: test tests::bench_bitmasks ... bench: 652,972 ns/iter (+/- 22,369) test tests::bench_bitmasks_preallocated ... bench: 73,196 ns/iter (+/- 3,515) test tests::bench_bitmasks_preallocated_ascii ... bench: 79,974 ns/iter (+/- 4,790) test tests::bench_bitmasks_preallocated_ascii_1morebit ... bench: 77,586 ns/iter (+/- 12,479) test tests::bench_with_iterator ... bench: 157,572 ns/iter (+/- 21,314) The naive version didn't complete before I got bored of waiting..
Ok, so you said "needless", which very strongly implies it.
Why add yet another keyword when we already have a mechanism that a) works, b) existing users reach for instinctively expecting to work, and c) makes perfect sense (i.e. the rest of the language already uses the same syntax for copy and move!)? This isn't mental gymnastics, it's making language features orthogonal and composable.
See my reply [here](https://www.reddit.com/r/rust/comments/91iy0n/my_experience_with_the_rust_2018_preview/e2yssid/). It's not about `extern crate`, but about fixing the confusion and annoyance caused by the difference in behavior between paths in the root module (where absolute and in-scope paths overlap) and paths in submodules (where they don't).
Wow, that is the clearest example of a C++ safety trap that I've seen.
So grep the directory above src? Or read Cargo.toml directly if you're just looking for deps!
Yep, this definitely need more test. I was so lazy writing test, when developing it since I keep changing my mind and then breaks the test. There were no preset of expected behavior, except I decide it when I see resulting graph then decide what's the appropriate behavior on the fly. It has been quite stable now, I may need to write more tests.
Why do you export an empty struct (`Haml`) only used to namespace the static method `to_html`? Why don't you directly export a function `to_html`, so users don't have to write `haml::Haml::to_html(input)` but simply `haml::to_html(input)`. Did you plan on using `Haml` in the future in a forward-compatible way to store the state of the transpiler? It's backwards-incompatible to add fields though because at the call-site, it'd look like `haml::Haml { cfg_a: false, cfg_b: haml::X }.to_html(input)`. If you want to do this, you should provide the function `new` which could then default to some flags in the future: // interface today haml::Haml::new().to_html(input); // interface in the future haml::Haml::new().to_html(input); // defaults to some flags haml::Haml::new(haml::X, haml::Y).to_html(input); 
Nothing, it's purely for cargo's testsuite to be able to test cargo features.
This is kinda gross, but you can put the original string in a `Box&lt;str&gt;` to ensure that it doesn't get relocated out from underneath you (resizing). Then you can store offsets for your parts in the struct, then have getters that return the slices using those offsets.
Regarding the idioms -- some of this is because the lints aren't that good yet (or nonexistant). We'll probably end up recommending fixing these only through cargo fix (and not trying the manual stuff) until we flip them on by default much later in the process.
&gt; The naive version didn't complete before I got bored of waiting "If you can wait, and not be tired by waiting..." Ha ha!
Maybe a pinned weekly thread like the "What's everyone working on this week" and the "Hey Rustaceans! Got an easy question? Ask here", called "Call for participation" or something to that effect, would be a good idea. Just a thought.
I can give an actual example. In one pet project I have if get: $ grep -r serde src src/lib.rs://! * Optional `serde` support with the `serde` feature. src/lib.rs:#[cfg(feature = "serde")] src/lib.rs:extern crate serde; src/lib.rs:#[cfg(feature = "serde")] src/lib.rs:mod feature_serde; src/feature_serde.rs:use serde; src/feature_serde.rs:impl&lt;'de, K&gt; serde::de::Visitor&lt;'de&gt; for Visitor&lt;K&gt; src/feature_serde.rs: E: serde::de::Error, src/feature_serde.rs: ::Text::new(value).map_err(serde::de::Error::custom) src/feature_serde.rs:impl&lt;'de, K&gt; serde::Deserialize&lt;'de&gt; for ::Text&lt;K&gt; src/feature_serde.rs: D: serde::Deserializer&lt;'de&gt;, src/feature_serde.rs:impl&lt;K&gt; serde::Serialize for ::Text&lt;K&gt; src/feature_serde.rs: S: serde::Serializer, which I find very informative. I can also say `grep -r serde src tests` to get it for source and tests. If I just grep the top level project directory I get 182 matches, including the `Cargo.lock`, lots of things in `target`, and everywhere it's mentioned in the `README.mkd`. It's why I'll still keep things that can act as markers in code. Having a simple `grep -r &lt;term&gt; &lt;source-files-dir&gt;` be a useful pattern is something I value.
&gt; what memory is is probably mostly what the standard says (does it say anything?) It does not. The C standard is fully axiomatic. It just says "all of these things hold at the same time" without giving an idea of how to make that work.
Thanks, fixed!
I made a PR for my changes to your repo. Also I made the iterator version _much_ faster. Partly by not passing as much information around with each `Case`, and partly by calculating the biggest possible string and using that as the initial capacity. It's now very close: test tests::bench_bitmasks_preallocated ... bench: 5,451 ns/iter (+/- 796) test tests::bench_with_iterator ... bench: 5,868 ns/iter (+/- 399) But, with the more tricky case of `"ßßßßßßßßß"`, the iterator version is now slightly faster. test tests::bench_tricky_bitmasks_preallocated ... bench: 73,729 ns/iter (+/- 4,397) test tests::bench_tricky_with_iterator ... bench: 69,214 ns/iter (+/- 3,905)
:D
12 (or 11 if you remove `use serde` too) out of those 13 matches are still there without `extern crate`, and are equally informative. I still don't see the problem if that's the sort of thing you're looking for.
Still need `disesel` --&gt; `diesel` lol
Have you looked at [nebulet](https://github.com/nebulet/nebulet)? It aims to be a microkernel executing WASM code directly. There is *no* mention of UI here, and indeed many services that you could implement to run on nebulet need no UI!
In this case, moving the struct isn't the problem because the slices point into memory on the heap. Even if you move the String struct inside of Sprig, all the slices will still point into the unmoved heap memory. The problem is that there is no guarantee that String won't be modified, potentially reallocating its buffer and invalidating all slices. Also, there is nothing stopping you: * Assigning a new String, causing the old one to be dropped. * Decomposing the struct, dropping the String, and leaving invalid slices.
Any thoughts to instead learn via contributing to existing static site generators, whether cobalt or gutenberg? Of course, I'm not biased at all about wanting additional contributors ;)
Well, `mod` was on the line too one time. Knowing it's an external thing is clear with `serde`, but might not be with other dependencies, or even things somewhere else in the workspace. If you don't see a problem then that's awesome for you, but in many cases *I will* see it as problematic and *will* include some findable, greppable markers.
Instead of `Vec&lt;&amp;'a str&gt;`, could you keep something like `Vec&lt;Range&lt;usize&gt;&gt;` and do the slicing on access?
I mean, if the String is perpetually borrowed as &amp;str you can't modify it because you can't borrow as mutable.
I think the same points would apply to \* versus ref in patterns. People seem pretty happy with that, even after the match ergonomics changes that basically relegated it to being syntactic sugar, so let me take a stab at explaining why that is. We like it because the purpose of ref is different from how we think of pattern-matching. Pattern-matching is about destructuring data, about unwrapping some packaging around it; on the other hand, the purpose of ref is to say *what to do* with the data once it's been destructured. "Instead of mutably borrowing, use a shared borrow", or "instead of/after moving, just give me a borrow". In our minds, the deencapsulation and "what to do" are different kinds of things. And whereas the \* syntax confuses this distinction (note it's only meaningful on leaves of the pattern), ref makes it clear. 'copy' versus '&amp;' is in the same situation. There's a T that we can only access through a borrow, so the default is to return a &amp;T. Sometimes we want to say "instead of giving me a borrow, just go ahead and copy the data out". This is very much a "what to do with it" kind of thing (we're not removing some packaging from around the T--we're literally making a new copy), thus it should get distinct, clear syntax. (For pure consistency, 'move' is the right word, but since this only makes sense for Copy types, I picked 'copy' instead.)
I'm actually in the process of learning Vulkan. Most tutorials are in C++ which is OK as even though it's been 10+ years since I've touched it, I can still read it. I've been using Vulkano but maybe because it is higher level there seems to be quite a bit of divergence from the C/C++ tutorials available. Once I learn it I intend to experiment with writing a simple GPU based UI library and some games of course. What library would you guys recommend for learning Vulkan from scratch, and why? 
Yes, I agree that `*foo`-as-a-pattern is arguably kind of strange because there's no actual "structure" to be "destructured"- you're instead creating structure, or talking about "what to do after the destructuring." But `*` isn't pattern syntax and never was, while `&amp;` is and always has been. So going back to my mental model argument, by the point that you're choosing to move (copy) out of a reference, you're already switching back to "`&amp;T` is an address," or at least "`&amp;` is a thing in my way." There is an actual, real pointer in the structure that you now care about, so you're intentionally asking the language to move past it.
SpiderMonkey already uses a regex JIT, though I myself don't know very much about it right now. Would doing real register allocation help a regex JIT? I don't know the answer to that myself yet, but I'm hoping to find out some day :-).
Your link to the commit raises an [http 418 error](https://en.wikipedia.org/wiki/Hyper_Text_Coffee_Pot_Control_Protocol)... Okay, it doesn't; but it should.
**Hyper Text Coffee Pot Control Protocol** The Hyper Text Coffee Pot Control Protocol (HTCPCP) is a facetious communications protocol for controlling, monitoring, and diagnosing coffee pots. It is specified in RFC 2324, published on 1 April 1998 as an April Fools' Day RFC, as part of an April Fools prank. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Second reply for your edit: I think it's probably better to approach that case from the other direction- make it more ergonomic just to use the references you get from the pattern. For example, we might add method-like auto(de)ref to overloaded operators.
First, 30 threads is nothing. People are afraid of threads, but especially on Linux they are very efficient, and until you get in &gt; 1k threads area, don't even worry about it. Considering futures and async are not ready, unless you want to spend additional time learning and/or improving Rust ecosystem, I would not go into this.
1. Rust on embedded is not as well supported as C++ yet, but there's a lot of momentum there, and you can already write Rust targeting many ARM microcontrollers easily. 2. It's possible to run Rust code on the GPU via [some hackery](https://github.com/japaric/nvptx), but Nvidia doesn't officially support it for CUDA. 3. There is some ongoing work on building idiomatic GUI libraries, and there are some not-exactly-idiomatic bindings to C/C++ GUI libraries like GTK.
We don't have a lot that's easy to dabble with yet, but we're getting close. Stay tuned!
Just to confirm, yes, Cranelift emits machine code directly.
That's right. We're working on being able to do more of the work in Cranelift, and eventually having a standalone wasm runner, but it's not usable yet.
Oh I have no idea. I've never written a JIT. I just understand some of the high level concepts and am vaguely aware that others have had good success writing JITs for regexes (such as for browsers, but also PCRE2).
3. No and its not even close to one.
Some of us see Rust as a better (less easier to get wrong) C++ or C. You get an easy to use build system, modules (as opposed to headers), great macros (as opposed to the C pre-processor) and a compiler that keeps you from running into memory issues or other undefined behavior (which is a really big thing that you can't appreciate until you use C and C++). But if you're wondering what people are actually building, you can take a look at https://github.com/rust-unofficial/awesome-rust.
Working on mscorlib-safe currently, after getting mscorlib-sys to 0.1.4 version (still more fixes needed there, screwed up more function bindings). Once I've completed the first publishable version of mscorlib-safe, I'll add it to crates.io and move on to the .Net CLR hosting api. Gotta figure out a good package name for that. 
Given that we're in the context of discussing major changes to pattern matching anyway: don't the match ergonomics eliminate uses of &amp; except the one we're discussing? Just keeping it around for historical reasons when we have an opportunity to do better seems less than ideal. Re: second point: Two responses: 1. My understanding is that part of the philosophy behind the match ergonomics proposal is that borrows aren't really full parts of the type from the perspective of pattern-matching. When matching against &amp;Some(&amp;Some(&amp;6)), it's "here's the 6, but you can only get &amp;-access to it", not "here's a reference to the 6" or even "here's a reference to a reference to a reference to the 6". This is admittedly inconsistent with some of the rest of rust though (eg you can't use a &amp;usize to index a Vec), but I'd submit it's those things that should be fixed. 2. Second, code is more for the people reading than the people writing. It's not "the compiler gave me a &amp;usize, and I want a usize, so I should put another &amp; in there" that I would call mental gymnastics; rather it's "this person wrote a &amp; in this pattern. What does that mean again? I suppose it'd be undoing a borrow, which I guess means claiming ownership of the borrowed value. Wait, is that okay?? Oh the piece of this struct we're matching is Copy, so really the &amp; means we're copying the data out."
Why exactly do local modules and external crates need to live in isolated namespaces? Why can't we just use simple lexical scoping?
Amazingly, I think I hinted at this in the reply I just wrote (before seeing this) to your other response.
&gt;Why do you export an empty struct (Haml) only used to namespace the static method to_html? To be honest, it's because I'm not used to being able to export just functions. Thank you for bringing this to my attention though, what you suggested makes a lot of sense and I'll make the change for 0.2.0
I guess it would make more sense to contribute than create yet another static site generator. Any thoughts on a good starting issue in Cobalt for somebody with minimal rust experience?
Woot! &gt; If people are interested in having a longer write-up on how this works, please let me know. Yes please!
Could the second vector just store usize indexes/offsets?
I'll extend this post over the weekend, then :)
How do you define lexical scope across files? We already don't show names from parent modules in child modules without a `use`. But really, the best way to think of this is not that there are two "isolated namespaces." There is still only a single hierarchy- the change is that all crates are now at the same level of that hierarchy. For example, in 2015, you get paths like `my_module::my_item` vs `some_crate::their_module::their_item`: * Universal root * Your crate root * Your top-level modules * Your submodules * Dependencies * Dependencies' top-level modules * Dependencies' submodules While in 2018, you get `crate::my_module::my_item` vs `some_crate::their_module::their_item`- every absolute path starts with a crate: * Universal root * Your crate root * Your top-level modules * Your submodules * Dependencies * Dependencies' top-level modules * Dependencies' submodules
termion looks pretty promising actually... I'll have to compare that to my ncurses-rs. For cursive -- one thing that I specifically need is to not take over the entire screen, by which I mean that I only want to use a "few" lines at the bottom of the screen, and don't want to re-paint over the prompt line where the program was launched or anything above there in the screen. This immediately nixes anything that requires using the "alternate screen" or paints over the entire thing. Do you know if cursive will work? At least all of the examples they show don't fit that requirement.
[removed]
I've mostly been taking notes for myself and especially haven't been actively curating for first-issues. Here are some that I've pulled out. I've generally put them in difficulty order (unless noted otherwise). Feel free to bug me on [gitter](https://gitter.im/cobalt-org/cobalt.rs?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge) - [Split jekyll import into separate repo / binary](https://github.com/cobalt-org/cobalt.rs/issues/438) - I could create a dummy repo for you to work with on this - This would mainly help in getting used to Rust's `use` system - [Update Liquid Parser/Template to have an `Arc` of filters to reduce clones](https://github.com/cobalt-org/liquid-rust/blob/master/src/parser.rs#L239) - [Update Liquid's rendering to take an `Arc` or reference to filters to reduce clones](https://github.com/cobalt-org/liquid-rust/blob/master/src/template.rs#L17) - An `Arc` will be easier to write but will be slower - References will teach you a lot about borrowing :) - `Context` will eventually need references anyways (see below about globals) - [Use a non-regex parser for Liquid](https://github.com/cobalt-org/liquid-rust/issues/138) - You could start small, experimenting and then work up to replacing the parser in Liquid - [Design a Globals trait to pass to `Template::render`](https://github.com/cobalt-org/liquid-rust/issues/95) - This will allow optimizations where cobalt doesn't eagerly merge multiple objects (page, collection, site) for every page, causing lots of copying/allocating - [Redesign the filter API for Liquid](https://github.com/cobalt-org/liquid-rust/issues/95) - Filters do a lot of error processing on their own - The current filter API won't work for when we add named parameters - A simple implementation would involve writing a trait, implementations for the trait, and an optimized version using an `Enum`. The hardest part is more of software design (language agnostic) - A more advanced version could involve digging into serde - [Add support for Jekyll-specific filters](https://github.com/cobalt-org/cobalt.rs/issues/350) - This is one where you could pick them off one at a time - Probably best to wait until the filter trait is solidified to avoid more churn
Things like this make me love Rust.
btw cobalt is setup to be able to support other templating languages (as long as they can accept `liquid::Value` or `serde::Serialize`) in case you are really attached to haml.
&gt; How do you define lexical scope across files? Lexical scoping of paths in a module tree could work exactly the same way as lexical scope of names in an expression tree. &gt; We already don't show names from parent modules in child modules without a use. On review, the main thing I'm hurting for is lack of [relative paths](https://internals.rust-lang.org/t/relative-paths-in-rust-2018/7883). `use self::...` is a constant papercut.
So in this case it would be safe to move the String, but unsafe to actually modify it, which is not possible to model in Rust. This reminds me a lot about the recent discussion about Async/Await, Coroutines, the `Pin&lt;T&gt;` type and things like StableDeref. String here is more like a `Box&lt;str&gt;` with some added bonus features to be able to modify it. `&amp;str` would then point into the heap-allocated data behind the Box (or in this case: String)
Thank for the link. 
There's a fundamental mismatch you're running into. Safe Rust assumes that memory won't be modified behind its back. mmap allows the OS to asynchronously free the memory - so if you don't abort on SIGBUS you're instead doing something that reinitializes the memory. This means it's not possible to soundly create safe borrows of mmapped memory. You have to either accept that SIGBUS will at a minimum crash the thread or that accessing mmapped memory is an unsafe operation. The copying in step 6 is probably necessary but `setjmp` is not. SIGBUS interrupts the current thread just before the offending instruction. So if you don't fix the error (bad memory mapping) then you can't continue execution. (This is also true for SIGSEGV and SIGILL and so on.) The SIGBUS handler should: - check that the current thread is in a critical section that intended to access the mmap segment - map a zero page so that the critical section can fall through to error handling - set a flag that will be checked when the critical section is left The critical section would need to look something like - lock the mmap segment - read or write through raw pointers to the segment - verify that no error was encountered before trusting any bytes read from shared memory. (E.g. don't interpret them as enum variants or follow pointers.) - unlock the mmap segment and trigger error handling (either a returned error or a panic) Finally remember that any thread-local variable that's shared between the main flow of execution and a signal handler needs to be volatile. Also, this is *volatile* not *atomic*. We need to warn the compiler that attempting to read from the mapped memory means that the signal variable may change. `read_volatile` does this because: - the mapped memory is accessed through a pointer which came from a system call. The compiler can't prove nocapture and must assume that memory is visible to the kernel or IO devices - `read_volatile` is an I/O operation
what people/projects are currently working on GUI libs? I know of conrod but no others.
Where I work we'd never use C++. We'd be too scared about the memory issues, the undefined issues, the platform targeting issues, and things like that. A lot of that might be FUD. Probably is. However that's how we view it. A lot of places feel the same. They aren't C++ developers, and so C and C++ feel like these dangerous islands you never visit. Rust allows one to go to that native world without any of that FUD. We could have a front end developer who has only ever worked in PHP and JS, work on a Rust code base. They may have an uphill learning curve, but in terms of the shipped code there is far less worries than with say C++. If it passed the compiler, a PR, and has tests, then it's probably right. On that note, it could work great as an alternative to Java (and similar). Namely because of the much lower memory cost.
https://github.com/antoyo/relm is one.
https://github.com/christolliday/limn (for some definitions of "currently working") and [gtk-rs](https://gtk-rs.org/) if you want to use an existing solid, beautiful toolkit instead of fresh Rust-all-the-things experiments :)
There's a couple I know of that are using webrender to make native rust GUI libraries. There's [limn](https://github.com/christolliday/limn), but it's development seems to have slowed, and there's [azul](https://github.com/maps4print/azul), which seems to be on its way to becoming a mature rust GUI library.
&gt; Lexical scoping of paths in a module tree could work exactly the same way as lexical scope of names in an expression tree. This was attempted pre-1.0 and it made name resolution literally impossible, due to circular references arising from this sort of pseudo-lexical `use` paths. The relative paths proposal sidesteps that problem, without changing anything about the new shape of the hierarchy.
I think it's an important distinction albeit too low level to be of concern to most people. Compilers abstract away register allocation and perform extensive optimizations so for all you know, your pointer is pointing to a register instead of memory or even a place in the register stack (for push/pop register commands). If you look at the x86 or x64 opcode documentation from Intel, you'll see that something simple like `mov [edx], eax` (store the value in ecx at the memory location in the edx register) can be fundamentally different from `mov edx, eax` (store the value in ecx in the edx register). I dont think there are any specifications for how various languages allocate registers since its a core piece of many optimizations so pointers abstract away far more than just memory addresses, things that assembly programmers have to handle manually.
[`cargo-generate`](https://crates.io/crates/cargo-generate) is a tool that downloads a template and with some inputs generates a new project for you. This tool will be _very_ to have for a lot of people getting started with Rust and we want to ship a 1.0 in time for the Rust 2018 release. But we are not there yet and we know there's a lot of possible bikesheds to paint and roads to go. So we need your feedback to get it right! Take a look at [these issues](https://github.com/ashleygwilliams/cargo-generate/issues?q=is%3Aissue+is%3Aopen+label%3A%22decision+needed%22), play with the tool (`cargo install cargo-generate`), and please comment!
&gt; New […] errors Rust is one of a few projects where I get really excited when I read this!
Rust supports similar macros, but for this specific use case, it's probably better to use `std::cmp::min`, which is generic for any comparable type.
This is cool but I also feel it should've been `i-have-baggage` instead of warming up that 418 joke ^(Wait, what? That award for "most puns per comment" is just a "grand project" and not a "project grant"?!)
&gt; for all you know, your pointer is pointing to a register instead of memory or even a place in the register stack But in C (et al) pointers do *not* point to a register or memory or whatever. They point to *objects* (I think they are called objects?). That was major point of the fine article here.
[https://play.rust-lang.org/?gist=4d3959383c920c131784f6f4cfbbde08&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=4d3959383c920c131784f6f4cfbbde08&amp;version=stable&amp;mode=debug&amp;edition=2015)
If you want to go the macro way, you don't need to evaluate the macro expression twice. https://play.rust-lang.org/?gist=fd4998875d4cabdda32ec3674f07e0d3&amp;version=stable&amp;mode=debug&amp;edition=2015
Just to give the Gutenberg side (you can see an almost up to date comparison of gutenberg and cobalt at https://github.com/Keats/gutenberg/tree/next#comparisons-with-other-static-site-generators except cobalt now has sass compilation as well). There is a big release coming very soon but there are still a few issues: - [make tera include work in a theme](https://github.com/Keats/gutenberg/issues/324): fairly simple one afaik, just needs to be recursive as an include can be in any content - [assets colocation for section](https://github.com/Keats/gutenberg/issues/340): the idea is to make https://www.getgutenberg.io/documentation/content/overview/#assets-colocation work for sections (_index.md) as well. - [emoji support](https://github.com/Keats/gutenberg/issues/292): add emoji to markdown rendering - [remove some `.clone()`](https://github.com/Keats/gutenberg/issues/205): I am actually not sure if this is doable at all but who knows! There is also a big discussion going on [ordering semantics](https://github.com/Keats/gutenberg/issues/338) where I would welcome more feedback as well.
What is the usecase? Looking at what variables can be used, it looks like a `git clone` will be simpler. I made a similar tool (https://github.com/Keats/kickstart) but where the template can define which variables they need/want with some defaults, see the README for an example of what I mean. It's currently stuck waiting for the TOML preserver-order feature to be merged but I will move the template file to JSON instead if I work on it again soon.
Awesome thank you
Thank you, but that was just an example :)
Still though, Rust gives you way more options to avoid using macros that you should probably use - macros add a readability cost that often doesn't have to be there.
See I have an instance where I'm grabbing and dropping mutable references constantly, and it'd just be more clear to have a line that says "do_the_thing ()" than a 212-character line or a 10-line chunk of code. Oh well.
Is there any reason that line can't be made a function?
Totally agree, the borrow checker is the 'big idea', but realistically without the borrow checker rust is still miles above C++ with all these little things!
There's a crate to help with implementing little expression macros like this: [defmac](https://docs.rs/defmac/0.1.3/defmac/)
Yeah because I'm new to rust and still getting used to the borrowing system. I'm working on a function for it though.
Thank you!
Using macros to attempt to dodge the borrow checker is _really_ not a good idea in most cases. Can you post your code here? I'm sure people will help you refactor it.
This type of example is better handled with a generic function. https://play.rust-lang.org/?gist=74b0a5c814d6d275852035fbab5a7c8e&amp;version=stable&amp;mode=debug&amp;edition=2015
I've been writing some utilities to unpack the assets for Tony Hawk's Pro Skater 2 from the CD files. Next I'll be attempting to reverse engineering some of the less well-documented file formats to try and render some visuals.
In which situations would you recommend `cargo-generate` instead of `cargo new`?
https://github.com/gtk-rs/gtk
There are good bindings to gtk.
Any sort of framework, lets you get a quickstart going. You know how `cargo new` gives you a hello world? This is like that, but for arbitrary initial prorams.
that was just a generic example of the type of thing I was trying to achieve, but thank you. Essentially I was looking for the rip-and-replace speed of C macros without having to type out a huge line of code every time. Unfortunately with function calls, it incurs a small cost (except in the case of telling it to inline, and even then it's not zero-cost).
I still really want the ability to write something like `$"{x} + {y} is {x+y}"`. A machine translation between that and `format!("{} + {} is {}", x, y, x+y)` is kinda all I would expect from that. Though constant folding of strings would be nice, if not already done.
Nope. I appreciate the help but it's under contract, and my boss checks this subreddit lol.
If you want zero runtime cost, you may also be interested in const fns/CTFE, which is something Rust supports pretty well right now. https://www.ralfj.de/blog/2018/07/19/const.html 
I've written quite a few GTK3 applications with Rust, personally and professionally. The official GTK bindings do great work when you know the right pattern to use with it. I've been able to write highly responsive apps with a lot of asynchronous actions in background threads to keep the UI from hanging.
A key question to whether you should use more threads is whether the API calls you are make block on some other resource. If your threads are CPU bound, adding more threads than you have actual cores (or hyperthreads) may actually reduce performance since context switching between threads adds overhead . If the API calls block on network or disk resources, then adding more threads will likely to help you: rather than idling while waiting for network/disk, you can process more messages. Another key factor is what kind of variance you have in terms of work/time to process your requests. If the amount of work/time is very consistent, it's relatively easy to adjust variables to hit optimal performance. If you have highly variable workloads, based on some discernible parameter, such as message type, you may get better performance by setting up different worker queues per message type, and tune them independently. Determining the optimal mix will be harder, but you have a better chance that way. You will need to benchmark your application on the hardware you are going to run on with data that is substantially similar to your production environment to properly assess and optimize performance. There is no way around this.
I can personally answer to 2 &amp; 3. For 3, GTK is the best that we have for Linux. All the features that you'd expect to get from the C API are accessible in the Rust API. You can make your life easier if you keep all your widgets wrapped together with Rc, and keep your State separate in an Arc. Negates the need for all the cloning that you'd do without the wrapping. For 2, there are a few libraries that are available. Most are still under development to a degree, of course. See \[Accel\]([https://github.com/termoshtt/accel](https://github.com/termoshtt/accel)), for example. For 1, it depends on the system that you are writing for. The system may or may not have Rust support yet.
For GPGPU, there's also [Accel](https://github.com/termoshtt/accel)
&gt; (except in the case of telling it to inline, and even then it's not zero-cost) What about an inline function is not zero-cost? The compiler has full knowledge of the local control flow, so it should optimize exactly as if the body of the function was placed there, including eliding copies and moves of arguments and return values.
Oh wow, this is great.
If I'm understanding correctly, you could look into what I'll call the "arena pattern." The idea is described here: https://rust-leipzig.github.io/architecture/2016/12/20/idiomatic-trees-in-rust/. Instead of handing out the object itself (move) or handing out a reference to the object (borrowing), you could have a third object e.g. `Quux` that owns all the `Foo` and then both `Baz` and the `bars` just have `usize` indexes that only `Quux` can resolve. But it could be too heavy-handed for your thing so you'll have to make that call.
And inlined function should be equal to or better than a macro, in the cases a function can be used instead. In Rust a inline function can work across crates, C requires Macro's or LTO for inline to cross object files. Rust library's hold some form of the AST for inlined functions to allow this. Also In Rust pretty much every reference has C's restrict on it, but I believe currently it's only applied at function boundaries due to limitations in LLVM. So that may speed it up the compiled code. A function should be faster to compile than a macro as well since it only has its token stream processed once, instead of every invocation like a macro. Though most of the compile time in Rust is LLVM optimizing to rather large LLVM-IR rustc gives it, so I wouldn't expect a huge difference there. Of course what you're trying doing may not be possible with just a function, or there's a slim chance the macro is easier than the function.
I think I could avoid allocation with a bounded channel (I know crossbeam\_channel has these); I assume it's implemented as a ring buffer. Or even if the channel wasn't bounded, I'd hope that it only grows as necessary, meaning I wouldn't make allocations after some number of sends. As far as ordering is concerned, I think futures make this much simpler. The task runner can just create futures and place them in the channel in the order it wants the stream to consume them.
Would it be safe to say that there's actually not a good reason in the world to allow pointer&lt;-&gt;integer casts?
Would it be safe to say that there's actually no good reason to allow pointer&lt;-&gt;integer casts?
What he's saying, and I agree, is that this is really quite pointless without additional variables that can be specified with flags or are otherwise prompted for interactively, and options for customization, eg: * do you want to add serde support? (y/n) * do you want to use postgres or mysql? (p/m) * ... Without that, git clone is just fine, replacing the author and crate name takes 15 seconds.
That’s good feedback, thank you!
You probably don't even need to tell the compiler to inline, as long as it has the source for the function being called at compile time (or link time with link time optimization).
Idea: cargo-generate.toml variables = [ { type = "bool", name = "use_serde", prompt = "Add serde support?", default = true }, { type = "choice", name = "db_type", prompt = "Which database would you like to use?", options = [ "mysql", "sqlite", "postgres"] }, ... ] In template: {% if use_serde %} ... {% else %} ... {% endif %} {% if db_type = "mysql% } .....
Sounds like silly microoptmizations to me. If it matters, you should benchmark it (and i highly doubt the difference is even noticeable in most cases, the compiler should know when to inline when appropriate).
Also: maybe assume Github by default, when not a full url. Eg: `cargo generate actix/actix-web`
Poor choice of words on my part. They don't "point" at registers in the sense of concrete usize values that the programmer can manipulate. When allocating registers, however, an optimization pass might decide that it is safe to take a stack value and keep it entirely in a register like eax for the duration of the call, adjusting the low level datastructure representing the C pointer. None of this concerns the programmer since abstracting away those low level details is why we have compilers but also why we should be clear on the philosophical difference between a C pointer and an asm address. Note: this is based on work I did on a C98 compiler for a proprietary architecture in the 00s. GCC is likely very different and with LLVM's frontend-backend distinction, I'm probably totally off.
No joke, this patch will probably save a billion man hours of productivity across Rust’s life.
You know, that's the first time I think I've seen such a simple, accurate breakdown of Rudy's benefits based on the language you're considering moving to Rust from. And I think it does a good job of explaining why some people think memory safety is Rudy's main feature, and others think it's one of its less important ones
Do you submit issue against https://github.com/rust-lang/rust ?
A lot of languages have been going for type inference at assignment recently. I think one of the reasons is that it's pretty common to have a situation where the type is redundant with the variable name, or the function being called, or both: let my_vec: Vec&lt;_&gt; = Vec::new();
You can always make it a function and let macros handle binding when a lambda capturing outer state wouldn't work. I can give you an example of the meaning of that suggestion is fuzzy. :)
Ask on /r/playrust
What? Which problems do you specifically have with the DOM when using yew?
would you recommend blocking threads over asynchronous I/O?
I wish we could configure Rustdoc to show `io::Result` instead of `Result`.
Would you like to show me the code? Thanks.
This seems fairly easy to do with a procedural macro! 
Is this extensible, so that user-defined proc macros could (using a bunch of unstable features, presumably) do similar things? Or is it currently "hardcoded" to `format!` and friends? 
I have to ask: were there good pre-invented wheels available already? 
Is there any mechanism in rust to chain the pointers with same lifetime? Or NLL mechanism in rust compiler to check the lifetimes of pointers within same memory allocation range?
I'd recommend storing `Range&lt;usize&gt;` rather than `&amp;str` and using them to index the string when you want to use them.
[removed]
Someone tried it: https://github.com/anowell/interpolate Their verdict seems to be that the big benefit is just a shorter macro name.
[removed]
(I have only just started learning Rust, two days ago). 1) When is shadowing used? It seems that the existence of shadowing makes immutable variables useless. That is, it seems like shadowing is a tricky way to mutate immutable variables? 2) How are having the option to make immutable variables useful? Should I be going out of my way to try to make some variable immutable even though it would be easier to make them mutable, and what are some common challenges that will I face when I try to do so?
&gt; For example, if we want to give clients fine-grained control over version selection and make it easy to find compatible sets of versions of libraries, we’ll be asking for a higher maintenance burden across the ecosystem. Perhaps it isn't such a dichotomy. I've been using Stackage which has immutable snapshots of packages (and a compiler version) that all build together with each other. That makes finding compatible versions trivial. If you want to have additional fine-grained control, you still have the option to override packages and use a version missing from the snapshot you're using. I'm curious -- has the Rust team considered this model before?
Do you have any links to any of those projects to see the code?
His requierement is decent. GTK can only be called that on gnome. Half of a mostly irrelevant desktop platform.
Thanks, that's great feedback! We've had some very similar ideas if you look at the issues :)
Can I ask whats wrong with serde\_json? I found its pretty easy to use serde\_json::Value if you like to avoid static serialization.
Very valid question. To me it was more a matter of integration with the rust ecosystem. One of the earliest ideas was to have crates contain their templates directly (and there are no other tools out there that can download their stuff from crates.io).
Oh! I hadn't seen that, thanks for sharing. I'll have a look
1 is kinda true, and there were pretty heated design discussions in the past, but do note that immutability is more then skin deep. Can't append items to an immutable vector, for example, so it still helps with stuff thats not top level binding related. Immutability adds value like types add value, it lets you double check your logic and limit what's possible to aid understanding and prevent mistakes. Personally I love being able to see at a glance what parts will be changing and need to be looked at over time when reading code.
What makes you think that serde_json doesn't meet those criteria? My experience with all serde libraries has been that they provide a very nice zero-cost abstraction. 
You're missing the point. Yew treats the DOM as a controlled piece of memory space which conforms to Rust's rules, but it's not. When you write code like that you take all the restrictions of Rust code, but you get none of the guarantees.
That sounds like a great idea. Then you get versioning too. 
Thanks for posting this as well, I'll take a look at some of the issues and see if I can be a help.
Thanks for taking the time to post this. I'll take a look at these issues and see where I can help.
Make it a new post, otherwise it wont get attention. Thanks!
`serde_json` is the defacto standard. As an alternative: you also have [jsonway](https://github.com/rustless/jsonway)
The reason `longjmp` works is that signal handlers are allowed to never return.
It isn't? I'm really curious: What are your criteria for lightweight and simple? Personally I think serde is the best thing since sliced bread. It's easy to use, fast and does a lot of validation - I would kill for a simple #[derive(Serialize)] in C++. But sure, like anything else it could improve (I'd like to have custom validations during deserialization and XML serialization). 
[removed]
Yep, and no dependency on git or github. Please note that this is not implemented yet and we only have very vague plans (see "what is a template" RFC)
&gt; It's currently stuck waiting for the TOML preserver-order feature to be merged but I will move the template file to JSON instead if I work on it again soon. Why not just switch to [toml_edit](https://github.com/ordian/toml_edit) for the parser instead? It's ready enough that I'm finally comfortable with using `cargo-edit` to modify a project's dependencies and using JSON like that in such a heavily TOML ecosystem would certainly send me looking for alternatives or perhaps even quickly hacking together one.
Azul looks promising. Any idea why it's not up on [crates.io](https://crates.io) ?
too many `unwrap()`s. should be avoided. May be use Result.
Shadowing isn't really related to mutability and certainly doesn't make immutable variables useless. It's a way to take a name that meant one thing and make it mean something else, while also preventing it from being used for that first thing. The types do not even have to match for the shadowed name. Here's one example where I think it actually demonstrates how it can augment immutability. let mut path = PathBuf::new(); // code to build up the path let path = path.as_path(); // from here on out path cannot be changed Or maybe you have some system with string identifiers but for whatever reason you want to calculate them numerically. let mut id = 13u128; // calculate away let id = id.to_string(); // now id is some calculated string and can't be changed numerically You can of course find other ways to express the same thing, like using a function with `gen_numeric_id().to_string()` or using a nested scope like let id = { let mut id = 13u128; // calculate away id.to_string() }; Ultimately shadowing is just another tool available to you for managing variable names, scopes, and permissions.
Ah, indeed, cursive doesn't do this kind of "integrated" UI. The main problem with `termion` is that it doesn't parse the terminfo database, and rely on xterm codes. This means that compatibility with some terminals emulators may suffer. This is one of the strengths of ncurses, which has decades of compatibility cruft, for better or worse.
I didn't see toml-edit before, I might switch to it since I only really ordered reads.
That's exactly what kickstart is doing actually: https://github.com/Keats/kickstart/blob/master/examples/rust-cli/template.toml
See MapViewOfFile to do the same on Windows.
Can you use conditional compilation based on a *dependency's* enabled features? For example, can you do this: ``` #[cfg(feature = "dep1/feature1)] fn do() { ... } ```
Yes, you can. Unrelated, reddit doesn't do the triple backtick code blocks, you gotta prepend four spaces to each code line.
do you know how I can find these heated design discussions? are they publically viewable?
you have: let mut id = [some code]; let id = [some code]; could these two lines be switched? because that would worry me if they could be switched; if I saw "let id = [some code]" near the top of a function, I would want to think "okay, the variable id is immutable", but I couldn't safely think that, in case a "let mut id = [some code]" appears later on?
[json](https://github.com/maciejhirsz/json-rust) crate is also available providing a more direct/dynamic style.
I believe there are multiple (somewhat conflicting) use cases for a build system like Cargo: \- When setting up a new project and adding dependencies I want Cargo to automatically use the latest compatible versions of all (transitive) dependencies \- During the development phase I want notification if there are new compatible versions available, but not automatic update to the new versions. I don't want any unexpected problems during the edit/build/test cycle. \- When building the project in a CI system or when building an old version from the VCS I definitely want to build with the exact same versions as when the code was committed. Any notifications of new versions are just noise here, unless I explicitly request this information. Neither minimal or maximum version selection is a suitable choice for all these use cases. I think I would prefer a system where the exact version of all dependencies (including transitive) are explicitly specified in my build configuration and then some tool support for finding new compatible versions and updating my build configuration to use one or more of those (although it could be done manually with some effort).
FWIW Serde also provides a dynamic style via [serde_json::Value](https://docs.serde.rs/serde_json/index.html#operating-on-untyped-json-values). You don't *have* to operate on typed structures it's just more efficient.
Cargo is such a critical piece of the ecosystem, yet its source code is impenetrable. I hope that once the Rust 2018 edition is released, we'd stop adding new features to it, and the efforts become focused on simplifying and documenting what the code actually does. 
It's not at all finished (hence the big, fat warning in the readme). There is no layout yet (prepared, but not implemented). The only thing it can do right now is display a full-screen button that allows you to open and then render an SVG file. And you can style said button via CSS, but that's about it. It's more at a proof-of-concept stage, if the proposed API would work and if the performance would be enough. Right now, drawing SVG-like shapes is more important to me than doing the layout. limn is a proof of concept that the layout can work (limn and azul have the same layout engine, cassowary). So while layout is perfectly possible, I just haven't gotten around towards implementing it. I'll release a 0.1 version "when it's ready". There are various webrender-related bugs that need to be resolved, weird memory issues and tons of other stuff - while the rendering and API concept is solid (in my opinion, obviously biased since I'm the author), it just needs time. I wanted to finish the SVG drawing stuff this month, maybe I'll have the time next month to look into the layout, at which point the library will become actually useful. It's just that I don't want to release a half-baked solution - I also need to test if the APIs work in larger applications or if there are problems that aren't apparent in Hello-World apps. So yeah, that's why it's not on crates.io.
Aha that's quite cool, I never noticed that and I do use serde\_json. But I only understood it as the json bits of serde framework and since it worked fine never bothered to read the docs properly! I've updated the original comment.
No problem. I might as well get *some* use out of the excessive amounts of time I spend lurking in /r/rust. :P
In Rust 2015, "Your crate root" *is* the universal namespace root, so there's one less level of hierarchy.
No, you never needed to use `use`. For example, you used to be able to write `::std::mem::size_of::&lt;usize&gt;()`, now you just write `std::mem::size_of::&lt;usize&gt;()`.
Yes. It works differently though. C preprocessor transforms text. Rust macros transform the abstract syntax tree after parsing. Maybe less powerful but it's impossible to get hosed by order of operations and missing parens. 
There were proposals to infer the module hierarchy directly from the filesystem, but a bunch of people (including myself) are against it — in part because version control systems like git will ignore unknown files, thus you could `git checkout master` to revert back to stable, then `cargo build` and get build errors from extra files left in your directory tree.
I would use plain mio.
Yes. The way I see it, this change is mostly about a hierarchy change from relative paths to absolute ones: - Rust 2015: all external crates are imported into your crate root - Rust 2018: your crate and all external crates exist in an abstract top-level-namespace Thus `extern crate` *no longer* imports into your crate root, and thus is not needed (except for things like `extern crate std as core;` or `#[macro use] ...`). I still don't really like the change, but it seems lots of people get confused by relative paths :/
\`std::simd\` was removed from \`std\`/\`core\` and is now in the nursery at: [https://github.com/rust-lang-nursery/packed\_simd](https://github.com/rust-lang-nursery/packed_simd)
If such feature is added, it should return not a `String` but a [`std::fmt::Arguments`](https://doc.rust-lang.org/std/fmt/struct.Arguments.html).
The example with the `winapi` crate rings very true... I know for a fact that I wrote in my Cargo.toml that I depend on `0.3` but I rely on a bugfix only available in `0.3.5`... I am interested in finding and solving these minimal version bugs.
Honestly I just want to be able to provide the values inside the curly braces. I don't really care about the `$` syntax, just make it work with `format!` and the other format argument macros.
I very much agree with this. I've never had any issue dealing with supported toolchains for stable crates. It is only when working with nightly crates that I've had any trouble at all. Publishing a nightly crate is particularly annoying, because breaking changes in the compiler require all developers on a dependent project to upgrade toolchains in lockstep when they switch to a new version of my crate.
`min(++x, ++y)`
&gt;n the stated toolchain approach, the toolchain being used to compile effectively imposes an =-style version constraint. &gt;we end up imposing more =-style constraints, which in turn can prevent us from choosing the globally-maximum version of crates. The effect could be that everything passes CI just fine, but a user with an older toolchain gets a crate resolution that fails to compile Why it's a "=-style" constraint? MSRV is a ^-style constraint. So I don't think that your concern is valid. In the current RFC, if crate was published with the specified MSRV, than it's guaranteed that dependency versions constraints can be resolved. (well, if we are being precise, it's possible that required versions will be yanked, but it's not different from what we have today) &gt;It’s hard to say for certain, but this seems likely to create a larger set of crate version combinations than we see today, and thereby diffuse the testing for compatibility. I am not sure why you think so. If you've specified MSRV, then in CI crate will be tested against it and stable Rust (with the respectively selected dependencies), exactly the same as today, you don't have to test all versions in between. &gt;effectively creates an LTS version of the library, because users stuck on old toolchains will also be stuck on old library versions, and hence file bug reports (and request backports) for them. It will be author's choice, to do crate LTS or not. At least they will communicate to users, that older versions are not supported, and you'll have to update toolchain to receive bug fixes. &gt;it seems possible that the benefits of the stated toolchain approach are illusory, and that in practice critical crates will stick with very conservative toolchain requirements. I don't think it illusory at all. The main benefit of the stated toolchain approach is *explicitness*. Crate authors will explicitly state that they support old LTS-sy versions (whatever policy we end up with), or they actively use bleeding edge stable features, or they don't care about MSRV at all and simply target latest stable or even nightly, or maybe they are so bleeding edge, they only support particular nightly versions (see `rocket`). You also will be able to deduce if authors do backports or not. As you've stated both MSRV and shared policy approaches will work best if combined with each other.
Haha, that was actually the typo I was referring to. Didn't even notice the second one.
This isn't my impression of why people like webassembly (and of course there will be multiple reasons). For most people I've heard, it's the appeal of writing (fast) cross-platform code that covers native devices and the browser. Basically, it's a better target language than javascript when you start with C/C++/Rust.
Ahahah :D
You need macros a lot less often because: - Rust has proper typing and polymorphism, whereas in C the only way (with a few exceptions) to make e. g. 'min' work on more than one type is to use a macro. - In Rust, almost everything is an expression, including multi-line blocks that might contain statements . Thus, macros are also not necessary to mimic multi-line statements. And even if you need a macro, because Rust macros work on the AST rather than being limited to very rudimentary string processing, you are a lot more versatile.
Worse: int main(void) { int x, y; x = 1, y = 1; int a = min(x, y++); x = 1, y = 1; int b = min_int(x, y++); printf("%d, %d\n", a, b); return 0; } Prints `2, 1` 
`{valueb}` Wait, format can use named arguments?!? TIL
``` let b = Box::new(42); let b_inner_ref: &amp;i32 = &amp;*b; ``` You dereference the box, and take a reference to the inner int. The reference is deduced to live at most until the end of the boxes lifetime.
&gt; Because `String` is larger than can fit in one or two registers the compiler transforms the function and introduces a hidden argument. This hidden argument is a pointer to a memory location where the returned type can be constructed. I hadn't realised this was happening, and it explains a lot of what's going on. I had imagined that something as small as a String could be returned entirely in registers - it's only three words. It's a shame to have to involve the stack, even with cleverness like (N)RVO. 
&gt; IE, if it compiles and runs on nightly without issue, will it definitely do the same on beta and stable? Not if you're using unstable nightly-only features. &gt; If it compiles on a toolchain from 2018, do I know anything about how it behave on a toolchain from 2016? No, but the opposite is generally true - code that compiles on a toolchain from 2016 and does not contain soundness errors will compile on a toolchain from 2018.
Thanks, I fixed it, I hope :) Now the is\_valid method is called read\_token and returns a Result
&gt; Accel Accel builds on the hackery the GP was talking about, and while it hides some of it, it is pretty much still as hacky.
Can't you just `git stash` in that situation (or `git clean` if you want to revert permanently)? I've been bitten more than a few times by the opposite problem: I have a file, I can see it's there, but rust isn't picking it up. Oh wait, I have to tell it that I wan't to use that `.rs` file sitting in my source directory. Why!?
Rust has a similar safety traps, for example, when you want to write to uninitialized memory in ‘x’, where you have to get a pointer to it, and many people do: ‘&amp;mut x as *mut T’ to obtain the pointer instead of using an union.
The problem with this situation is as follows: ``` struct SelfReferential { owned: String, slice: &amp;str } ``` Say you want to have slice point into owned. What lifetime does that slice have? It would be logical to say that owned has to live longer than the slice (or just as long) In that case, owned is now borrowed, and can't be modified. Now, if we look at SelfReferential as a whole, is it borrowed? Can we modify it? What if we have another member? ``` struct SelfReferential2 { owned: String, slice: &amp;str, foo: i32 } ``` Just from a logical view, foo can still be safely modified, even though owned is borrowed. That means the struct is *partially borrowed*. Interestingly, you cannot move the struct until you change slice to point somewhere else, say an `&amp;'static str`, because owned ia still borrowed, and you cannot move something that's borrowed. This seems counter-intuitive. String also just points to the heap. Moving that pointer doesn't change anything. It just has to live long enough. The problem with that is that in Rust, moving something means they now own it, and can do with it what they want. *There is no mechanism to say "You can have this, but keep it alive for at least this long"* Example: ``` fn main() { let owned = "Hello World".to_string(); let slice: &amp;str = &amp;owned; take_string(owned); println!("{}", slice); } fn take_string(s: String){} ``` In this case, `take_string` owns the string, it can just as well drop it (like it does). The moment the string is moved, the alice is atill valid. But there's no way in Rust to guarantee what happens after the move, because moves also transfer ownership. The other way to see it is that String and `&amp;str` are a special case. Usually an `&amp;T` points *at the T*. `&amp;str` points at the str, which is a string slice. String is just a fancy `&amp;str` with ownership. ``` struct HardToMove&lt;T&gt; { owned: T, borrowed: &amp;T } ``` This one is harder to move. Moving the struct while borrowed points at owned is impossible, the pointer will be wrong. The only safe way to move this is to temporarily point borrowed somewhere else, move the struct, and then restart the borrow to the now moved owned.
Not a solution but just a comment: If you use `cargo add winapi` you'll by default get a `winapi = "0.3.42"` (or whatever is current right now), so it's harder to initially get the minimum version wrong :)
I posted too late for it to be included but here's more for the call for participation section: https://github.com/Keats/jsonwebtoken/issues/21
I've been using c# lately and very much enjoy the in-line placement of variables/expressions (and abusing it to generate strings as well, but I think that isn't very rusty).
Ohhh, nice! Thank you for the work you put in. 
I'm very much with you on the benefits of the "shared policy" approach to MSRV over the "stated toolchain" approach. One of the other things I like about the "shared policy" approach is that it gives an explicit ecosystem wide rallying point on which version of Rust to target. That may happen naturally with the "stated toolchain" approach, but given the amount of extra control it affords, it's not actually clear to me that it will. I think having an ecosystem wide rallying point is extremely valuable.
&gt; Today, the most widely-used crates in the Rust ecosystem have adopted an extremely conservative stance, effectively retaining compatibility with the oldest version of Rust possible, in some cases with a three-year-old toolchain. For a language as young as Rust, that’s pretty painful. Back in the day I was quite enthusiastic about `pub(crate)`, allowing me to make parts of the API of my lewton crate private without having to resort to other more complicated means (like putting the code into lib.rs or using include (was include a thing back then?? idk)). So I made my crate depend on `pub(crate)` and published a new version quickly. This wasn't received positively at all. People got mad that I increased the MSRV for this quite minor change. The users of my crate are more important to me than whatever the language does. So I got more cautious and as of now lewton's MRSV is 1.20. Unless there is a good reason for me to increase that number, I won't do it. I'm still enthusiastic about new language changes. E.g. SIMD, or the upcoming const generics. One day I might adopt SIMD in lewton but only once the 1.27.0 release has been released a sufficiently long time ago. Until then I might do an opt-in flag for it or something. &gt; If we select the minimum possible version, dependency resolution will give the same result even if new versions are published, so no lockfile is needed to achieve reproducibility. A lockfile is still needed. You can both: * yank older versions of crates (and then cargo in a minimum-version mode would probably choose a more recent version) and * upload even older looking versions of crates... that's possible, unless I've missed something Also, lockfiles contain the checksum of the entire `.crate` file. This is invaluable as it allows for reproducibility independent of crates.io or registries or whatever. It guarantees that a crate version isn't just being tampered with during download, on the s3 storage or anywhere else. Not even signing would be able to achieve that. You can of course remove hashsums and *hope* that no changes have been made, that would probably work well in 99% of the cases. But there is a reproducibility benefit of hash sums inside lockfiles. ***** On a high level, I think there are various groups of people here. 1. Some library maintainers want to please users and this is their top priority. They are rather conservative with their update policy. 2. Some users don't want to have to update their Rust compiler every 6 weeks 3. Some library maintainers just shrug off any user wishes to support older language versions and require newer versions 4. Some language people want everyone to use new language features and everything to be on edition 2018 as soon as possible Group 2 wants to quickly find out which libraries fit into group 1 and which ones into group 3. They want to just have a non-painful experience (right now, you need to do `cargo update -p` because so many crates silently increase their MSRV) so they made the MSRV RFC. But group 4 is in opposition to the MSRV RFC because they are really annoyed about the existence of group 1 in the first place, and want them to become less conservative about updates (this seems to be the entire goal of the LTS RFC). IDK how they can be all fit together, and how a positive sum outcome can be attained. That's not for me to figure out, I'm not involved in language discussions any more.
In general, I can recommend to directly make a pull request with TWIR. They are quite quick.
No, `git stash` does not remove files not under version control. You'll get used to having to add `mod thing;` quite quickly :-)
Well, I, as author of the MSRV RFC, more closer to groups 1 and 3. :) I want users to get a meaningful error message if they'll try to use `aesni` crate which depends on SIMD on pre-1.27 Rust. When we get const generics I'll almost immediately migrate [RustCrypto](https://github.com/RustCrypto) crates to it, and I want users to understand MSRV requirements of my crates.
&gt; If I state that might library supports winapi 0.3.0, and it does not (e.g. because it uses features from 0.3.2), then that's a bug, and i'd like to be able to catch those bugs. So I care. I agree that its a bug, but because of maximal version resolution, it only impacts you if you ceiling your version to something less than 3.2. The problem is that it might actually be quite burdensome to manage this; cargo has just added a `--minimum-version` build to its own CI and it was surprisingly troublesome to figure out the minimum versions that worked together successfully. Basically, we're going to offer the option to build with minimum versions, but I'm not certain we're going to *recommend* that people use it in their CI; it might just not be worth the maintenance effort for the library author.
Except it won't give you that. Most of what makes JS suck is the DOM and the horrific security mess of the Browser environment. None of that goes away with webasm. Beyond that I honestly can't think of a language that's a worse fit for the Web than C or C++. All the horror of those languages with all the horror of the internet, fuck that. 
&gt; Some language people want everyone to use new language features and everything to be on edition 2018 as soon as possible What we want is to avoid mixed messaging: new users are going to be on 2018 by default, because its the most recent edition their compiler (the latest stable) will support. Since they'll likely look to open source projects for guidance, they can be confused when those libraries are using a different edition of Rust. Of course, looking to core libraries for guidance is actually not a good idea, since a lot of their code will be dealing with issues of platform and version compatibility that you don't have as a new user. But people don't think about that.
&gt; The problem is that it might actually be quite burdensome to manage this; Could you elaborate on why? I could understand how `--minimum-version` would probably be impossible to use for crates with many dependencies, e.g., if a couple of dependencies are broken, they will fail to build before you actually get to build your own crate. But as this gets used bottom-up by the ecosystem, if all your dependencies correctly specify their minimum version, then the bugs can only be in your own `Cargo.toml` file, and fixing them could be as easy as bumping the minimum version of a dependency to its appropriate value. 
We should be looking to reduce infrastructure coupling to a single 3rd-party commercial entity, not increase it further.
`&amp;mut x as *mut T` is actually legal even when the pointer is "bad". That's not great, but we don't really have a choice as there is no other syntax to e.g. obtain a reference to a field of a packed struct.
I mean not everything that runs in the web is UI. There's all kinds of things - games, libraries, idk audio processing? The point isn't that C is great and we should access the DOM with it - it's that sometimes we have native code that does a thing which we would also like to do in the browser. Obviously it's not appropriate for every problem, but nobody claimed that anyway.
I have a [fomat-macros crate](https://crates.rs/fomat-macros) that implements something similar: fomat![ (x) " + " (y) " is " (x+y) ] It doesn't support embedding variables in string like your example or `interpolate`, but because of that, it can on stable!
Yea, my opinion about MSRV is not so much against it as that it does not solve the right problem. It decreases the pressure against bumping your minimum version in a patch release, but doesn't give you any guidance about whether or not you should do it.
See here for the work turning this on in CI for cargo: https://github.com/rust-lang/cargo/pull/5275 https://github.com/rust-lang/cargo/pull/5757
I have a code something like this while some\_condition { if let Some(result) = somefunc() { return Some(result) } } None is there a better way to the `Some()` parts?
I believe there's good reasons why Rust chose this way to model owned strings (and vectors) as a (pointer, size, capacity) tuple but I can't quite remember what it was. Part of the reason I believe is because these internal details are exposed in eg. [`String::from_raw_parts`](https://doc.rust-lang.org/std/string/struct.String.html#method.from_raw_parts). 
Now rust can protest your pedocoins.
This is not a productive way to express your concerns, particularly in a Rust community forum. I suggest you try a different approach. I'm going to report this post and leave it up to the moderators.
Yeah I know it would be better to brag about what a great progress this piece of completely broken garbage has made and submit 20 bug reports every day for the sake of political correctness
Great opportunity for you to show us how a superior intellect works and actually improve this OPEN SOURCE project. You don'y even need to give back to the community your [efforts](https://github.com/rust-lang/rust/blob/master/LICENSE-MIT).
I've been using the RLS+atom integration for a few months now and haven't really seen anything untoward, and you're rather enthusiastically lacking in specificity as to what problems you're experiencing, so I can't really speak to your concerns.
Yes that's what every open source project tells people after producing crap. I'm actually submitting code to open source projects but if I had to fix every broken open source software I encounter I'd probably starve to death.
Why would you do any of those things in webasm though? It's going to be a long while before game development in webasm is practical, libraries in webasm need webasm apps to use them. Do you really want to download and execute random C code? 
Ordered from most recent to the oldest: - [Popsicle](https://github.com/pop-os/popsicle/tree/reflashing): Supports flashing USB drives in parallel. Displays a progress bar for each device that is being flashed in a background thread. Latest PR makes it possible to cancel the background jobs &amp; flash devices again. This utility is included by default in Pop!_OS 18.04. - [FontFinder](https://gitlab.com/mmstick/fontfinder): Simple utility that uses GtkWebKit to preview fonts from Google's font archive, and enables the user to install them. - [Systemd Service Manager](https://gitlab.com/mmstick/systemd-manager/tree/rewrite): Project is sort of in limbo inbetween a rewrite, as I've been busy with other projects. - [TV Renamer](https://gitlab.com/mmstick/tv-renamer): Renames TV series based on their directory structure, taking information from TheTVDB to fill in the details. First attempt at a GTK3 application, with zero async code.
No, you need to take a more productive approach if you want us to respond in a helpful way. We all have lives and various demands on our time, so, if you don't follow the correct channels, we just click downvote, report, and/or delete (for moderators) and move on with our lives. If you'd phrased your post so it sounds like you actually want an answer, rather than just wanting to bash RLS, those of us who know would be happy to give you one. (I use gVim without RLS, so I can't help you there) Likewise, if you politely report specific bugs, it'll help to improve the situation.
Yeah that's a great approach, just downvote even if it's an opinion about a thing you don't even use 
Some use cases for us to keep in mind - I'm assuming Linux distributions will be a major consumer of whatever toolchain policy we pick. So we should ensure we're aware of any relevant common policies. - A use case regarding minimum version that might be relevant is when someone has to hold back dependencies due to bugs. Finding a combination of working versions might be a bit of a pain.
Downvote means "doesn't contribute to the discussion". Your post has a lot of emotion and very few details, so it's hard to form a productive reply to it.
Elaborate 
/u/GilsonCosta doesn't represent the Rust community. Also, as a someone who is both a programmer and a heavy use of open-source software, I'm qualified to say that you'd be surprised how often a bug lingers because YEINR (Your Experience Is Not Representative)... in short, because the developers didn't know about it (or didn't know enough to reproduce it so they could track it down) while the person experiencing it assumed they *must* know because it's so easy to trigger. (KDE and GNOME users had (have?) a rather famous problem with this. Both sides would think the other is buggier, because they used the software in fairly disjoint ways, so they'd never run into the bugs in their preferred desktop and would keep tripping over bugs in the other one.)
Rust isn't particularly well suited for any of those purposes right now. It's a \*better\* language than C++, but the sweet spot is fast safe implementations of performance critical code for things like python and ruby, and CLI applications right now. Maybe, soon, web services... I don't think it's there yet. There's no good UI bindings. GPU compute is possible, but hard, and embedded systems... can't really speak about, but C/C++ is very heavily entrenched in this area, and its difficult to imagine that changing any time soon.
Username checks out
Most crypto volume is speculation followed by illegal activities then legit uses. Look up Brock Pierce and other luminaries of the the crypto world. 
&gt; a tool that tells me if I break API compatibility of my crate and need to do a major version bump automatically. You may want to check out https://github.com/rust-lang-nursery/rust-semverver
Yes but gnome for instance has the problem that it runs a fucking javacript engine in the main compositor thread. You can submit as many bug reports as you want, there is no way to fix it except if they do a substantial rewrite of almost everything Same with Racer, one bug is fixed, the next one pops up etc. In the end you fix a bunch of bugs and because the approach is garbage that stuff always goes on and similar problems appear short after
Thanks for those links. So yeah, turning this for cargo, with has dozens of dependencies, and where none of these dependencies is actually using this on their CI, was a road full of pain. But that was to be expected, I am amazed they managed to get it done at all. 
`git stash -u` (short for `git stash --include-untracked`) does ;)
Just because it could be used for bad doesn't mean it is bad, look at an axe for example. It could chop you in half or it could be used for something benign like chopping down a tree. 
Actually, I was referring to GNOME 2 vs. KDE 3, when it was all written in C or C++ and composited Linux desktops weren't a thing yet.
I went back and tried this. First, lto=true causes a compilation error, but lto=thin works. That might throw off the next finding, which is wasm-gc made zero difference to the output wasm. Made I didn’t something wrong?
How am I supposed to know what version you are referring to? When I say Windows doesn't support XY I obviously mean Windows 10 and not Windows NT 3.5
Sure, but axes aren't currently used \*mostly\* for chopping people in half.
A gun can be used to shoot humans or to shoot animals, unless all humans are animals :O
Getting too deep for me!
The main reason to test nightly and beta if you run on stable is to help find bugs in rust before they make it to stable.
The point is, when using Yew, you don't have to worry about the ugliness of the DOM. Yew abstracts over it and lets you render your component's DOM using Rust's rules. You still haven't answered the question though: Which problems do you specifically have with the DOM when using yew? :)
&gt; Downvote means "doesn't contribute to the discussion". That's what it *should* mean, but just because something is downvoted doesn't mean it's not constructive.
Well then what is a decent gui system in rust?
"Why would you want something to run in a browser?" Seems like a silly question. Don't know what you mean about executing "random C code" either. At any rate, I made my point: people want to be able to run their Rust code in a browser. The mere existence of the DOM does not invalidate that.
Just for fun: All humans \*are\* animals. All humans are not "animals." The first is an objective technical fact. The second is an opinionated statement using the colloquial definition of "animal" (hence the quotes) as something other than human.
How is that not the the max/lockfile system we have now?
&gt; How do people get started on hacking on cargo? Personally I just walked through a typical compilation, and took notes along the way. There's roughly 15 important data structures, and once you get familiar with them it gets much easier. If there are any specific issues you want to tackle, feel free to ask for help, there are several contributors who typically respond fairly quickly. Some of us have been adding documentation to a few areas, but if there are any specific ones that you think could use more information, just ask and someone will likely help. Also, if you think a 10,000' overview of how everything fits together would help, I could probably put something together. 
If `somefunc()` is an `Iterator` then you can write it like this: iter.take_while(|_| some_condition).next()
Shouldn't it be possible to have it do both depending on context? Or is there a downside?
&gt; (As the old comic from the *chan ecosystem showed... likely with a disinterested facial expression and our minds occupied with wondering what's for dinner.) Do you have this comic or can you say more about its contents such that I may find it?
If I may recommend to use indices/ranges for this use case. Have a separate vector `Vec&lt;std::ops::Range&lt;usize&gt;&gt;` which refers to the original string. I was going to show how to construct the initial whitespace delimited ranges... but I can't find how to do this. All the methods return string slices, not the indices where the string slices are found... 
&gt; If I state that might library supports winapi 0.3.0, and it does not (e.g. because it uses features from 0.3.2), then that's a bug, and i'd like to be able to catch those bugs. So I care. As one of the cargo contributors leaning toward recommending this, Thank you for that feedback. &gt; Also, Cargo is such a critical piece of the ecosystem, yet I found its source code impenetrable. I have tried to fix a couple of "trivial" bugs once or twice, but in retrospect I never stood a chance. ... &gt; How do people get started on hacking on cargo? ... I started with the `Resolver` witch is a homegrown SAT solver, and has been described as the thorniest part of the code. So I assumed that it was mostly inherent complexity, and spent weeks trying to wrap my head around it. Then my first several PR's where more ambitious than I had realized. I split them up into incremental improvements each with a justified use, until I had all the parts working together and the benefits clearly documented. But you are correct, it was a lot of work. &gt; I am honestly interested in learning how to hack on it so that I can fix the bugs I care about. I would love to help any way I can. Both with you fixing the bugs you care about and with the bigger issue of increasing the penetrability of the code. Where the code is too obfuscated for you to understand I consider that a bug. Please file issues asking for parts of the code to be explained, then PR to reorganize or to comment are welcome.
Hello, we are currently using a fork of \[fat-rs\]([https://gitlab.com/susurrus/fat-rs](https://gitlab.com/susurrus/fat-rs)) :) The full stub code is here: [https://github.com/deepaksirone/redox-loader/](https://github.com/deepaksirone/redox-loader/)
If SIMD is an implementation detail, then you can transparently enable it for compilers that support it with appropriate `build.rs` machinations. See the regex crate for an example.
I consider this on-topic because WebAssembly is very relevant to Rust's current strategy to penetrate the development market. I'm excited to see communities like Rust's push forward a way to deploy more than Javascript and transpiled-to-Javascript languages to the web!
Been toying with this idea for ages, very cool! Just for the record, 'isomorphic' is just another word for a single page application with AJAX for server communication, right?
you wouldn’t use hyper HTTP library with tokio?
It's a term commonly used for code that can run both in the browser and on servers. In this context it would mean that `percy` could both run using WASM, and used in a Rust service to generate static HTML.
No way, that's super cool, i had no idea this was even a thing!
&gt; 'isomorphic' is just another word for a single page application with AJAX for server communication, right? It's called 'ismomorphic' because the same code runs on both client and server. When a request hits the server, the server grabs the data, and renders the request. Like a traditional website. When the page loads client side, it then switches into a webapp. The bit that makes it isomorphic is if the server side and client side is *the same code*. You write code once, and it runs seamlessly client and server side. So you get the practical benefits of a webapp, with the performance benefits of traditional server side rendering. One thing to note is that today the big three web app frameworks (React, Angular, and Vue) all offer this. New ones offer it too. So whilst it's very cool, you'd expect it.
ohhhh okay, so just any SPA framework with server side rendering support is isomorphic?
In my example, no, because they result in different types. You probably couldn't even switch just the mutability because presumably the first one required it when it was written. There's a reason these are called bindings, though. The names represent only what they are bound to at the time, and can be bound to another. Thinking "this is immutable now" is good, because it allows you to reason locally about the code. Thinking "this is immutable always" is kind of lazy. Nothing will take away the necessity of reading code to understand it. But, like I said, shadowing is just a tool. You don't have to use it. But you do have to be aware you might encounter it in other people's code.
Actually I find Rust macros more powerful.
Wow, nice! That's what I needed all along..
Fair enough. It's what my downvotes mean and, here in /r/rust/, I've found people to generally be pretty good about it.
Basically, yes.
I remember there being multiple variations on it but my collection is well overdue for a cataloguing tool, so I only know the location of one. While not explicit, it's not quite what I'd call safe for work, so I'll send you a link privately.
Cool, I'm going to definitely have to take a look and steal some ideas. I've been working on a [project in a similar area](https://github.com/Nemo157/vdom-rsjs) with the intention of being able to have the virtual DOM kept on the server side and send diffs across a websocket to be applied to the real DOM.
No I do not represent the community. No one actually does. I'm just part of it. But I fail to perceive the relevance of this part of your comment. Anyway, sorry if I offended you. 
This only applies to the parser `format!()` uses, which is not a real macro, but rather a compiler internal. `print!()` and `println!()` also get it for free after removing a `concat!()` call which was making the parser lose its context of the formatting literal on every error. I have to dig deeper into proc_macros to see if there's a way to create custom diagnostics from within, but I can see how you could create a "known bad" resulting token tree from a "known bad" input to generate a nicer resulting error message.
I probably should have been more clear. What I meant was "The attitude expressed in /u/GilsonCosta's reply is not representative of this community". (That kind of sarcastic tone is discouraged here because it's likely to rile people up. In fact, for that reason, it's against what I understand the rules to be in this subreddit.)
Can an Arguments be passed to anywhere that expects a String? Because I'd expect the ability to use `$""` as a replacement for a string.
Every expression must return a specific type, so a partial conditional is not an expression, no. The type of `a` in `let a = if x { 1 };` is either a integer or nothing, and since we don't know which, we cannot reliably do anything with it. In a language like TypeScript, its type would be `undefined | number`, and we could check which one it is. Thats because in that language, all the types are tagged at runtime, which is a bunch of overhead that Rust would prefer to opt into. Rust declares a standard library enum (which in Rust is a "tagged union") like `enum Option&lt;T&gt; { Some(T), None }` for representing opt-in nullability. Then, you could go `let a = if x { Some(1) } else { None }`, and later on, you can unwrap this with a match expression like: let n: String = match a { Some(inner) =&gt; format!("The number was {}", inner), None =&gt; String::from("There wasn't a number"), } (The explicit type annotation is optional and inferrable here; its just for demonstration.) Another option for this sort of situation is to crash or infinite loop: let a = if x { 1 } else { panic!("Oh no x wasn't true") } let a = if x { 1 } else { loop { /* forever */ } } This works because both return a type `!` (also called bottom in some circles) which unifies with anything because it is a branch that will never directly a value and can be disregarded. Technically the language could have any one of these behaviors as the default if you didn't provide the else branch (or a complete branch), but instead they chose to make you be explicit if you want to use its return value. So no, partial control statements don't work as expressions, though if you prefer, you can think of them as expressions that don't return a meaningfully usable result, rather then as statements.
I love hearing about the progress WebAssembly and Rust+WA are making. Javascript and its ecosystem is a tire-fire-nightmare. I'm convinced that any developers actively working on a modern JS codebase are stuck in a mental state of learned helplessness and are unaware of it (because if their minds took even the slightest moment to question their reality they'd go insane). [React is pretty cool though...] In all seriousness, though, I'm very much looking forward to Rust and its ecosystem obliterating Javascript. Rust is not only a better language on many, many metrics, but it's just _so_ much better managed. The same applies to its encompassing ecosystem. Though I'm hoping crates.io can get code signing and other security niceties soon, so as to avoid those various failings of npm.
Ok, I understand that. Nevertheless, there's a huge difference between "we discourage" and "you don't represent the community". But again, I fail to see the relevance of the "ad hominem" comment, instead of "/u/GilsonCosta, it's our opinion that sarcasm should not be used".
That's actually a ridiculously smart idea. Good luck with that. The performance is probably going to be nuts 
The problem I see is reinforcement. Like one of OPs posts that went from 1, to 2, to 0, to -9. I had to call out downvoting people a couple times in the past because they quickly reached double digits when it wasn't warranted. To me it seems the difference is not that /r/rust is better at up/downvoting, but that we're lucky to have some people who can turn frustration into something productive. If that doesn't happen things can still turn into exaggerated downvote-fests.
This is an incredibly insightful and well-written post. I've never been more excited about wasm!
Or alternatively, in Rust 2015 dependencies are moved *down* one level relative to 2018, so there's one *more* level of hierarchy.
I started looking into some kind of schema and ended up with: https://github.com/Keats/kickstart/issues/2#issuecomment-408161951 This is essentially the same schema as a proposed change to cookiecutter but I only found it afterwards, which means it's probably acceptable.
I worked on something like that in the tech stack of a startup about 6 years back. Although cool, the statefulness on the server is a pretty big drawback. 
All that is orthogonal to the ABI representation, though. Strings are three words, yes, but you could pass those three words on the stack, or in registers. That's decided by the compiler implementation, not the language specification, or the library source. 
How can the pointer be bad? The problem is the reference :/
Agree that the Cargo's code base is not the easiest to work with. A good way to start hacking on Cargo would be: * Look through [ARCHITECTURE.md](https://github.com/rust-lang/cargo/blob/master/ARCHITECTURE.md) which tries to describe high-level bits * Read the code that is executed when you run `cargo build`. As cargo is a batch command-line application, the flow of control mostly flows forward, which helps with reading code a lot. Here's the entry point for build: https://github.com/rust-lang/cargo/blob/cef7c5667c1db2791c6373d0ad16ac416d25cef5/src/bin/cargo/commands/build.rs#L53-L64
No you can't, you can write the OP's code, but it doesn't work. 
Nope, there's no way to do this directly. You can have a feature on your own crate that activates the dependency's feature, and cfg on that. 
&gt; If we select the maximum version, then at any given point in time, the current maximum versions of crates will be actively tested against each other (due to CI), and hence likely to work. Put differently, there’s an ecosystem-wide agreement on which versions to test compatibility with each other: the latest versions. I pin dependencies on CI, also for my libraries. It happened too many times to me that a dependency (direct or transitive) released a new version under a semver-compatible version number, that broke my build. Whether you call such a change breaking depends on your definition of “breaking change”, but the fact is that a commit that compiled fine previously no longer compiled. A build breaking like that is not under your control. You are at the mercy of dependency authors. When it happens, you can’t do any productive work on your own code until you fix the breakage. I’m not saying updates are bad, but I want to do them at my own pace, when I have the time to do an update. A “dependency out of date” notification that I can shelve until I make the time to address it would be much nicer than a build that breaks suddenly.
Everything you've said about the DOM equally applies to the X86 instruction set. The entire point of Rust is that by restricting the things you can do in the language, you can add guarantees to the programs you write in the language even when the underlying machine doesn't offer those guarantees. 
Well, it's more intended for a local application using your browser as a UI toolkit than a real web application. I would probably have gone for a pure WASM app using something like Yue if I could, but I need raw UDP sockets for this application.
Could be? The vast majority of Bitcoin volume is market speculation/manipulation/fraud. 
WebAssembly being actually standardized and such is definitely a plus, I'm personally still worried. I've seen multiple comments on threads on say /r/programming of people having the brilliant idea to throw DOM out of the window and just use wasm + a custom renderer. The idea is pretty awful and would make the web a mess, but I wouldn't put it past a lot of developers considering how bad the web already can be. We'll see though. Wasm is definitely very neat.
True. I remember reading an article way back during the glory days of Slashdot about the unhelpful group dynamics surrounding up/down votes. I've always felt that voting which only the poster of the comment can see would be more appropriate to Reddit's design.
This is exactly what I asked for when the last wasm post was linked here. Thanks for the follow-up u/steveklabnik1 !
You're welcome!
&gt; I'm very much looking forward to Rust and its ecosystem obliterating Javascript. This is not the goal of wasm, nor Rust and wasm. You're going to be sorely disappointed.
https://www.reddit.com/r/rust/comments/91cepg/game_studio_ready_at_dawn_switching_to_rust_for/
This makes me really excited about Wasm. I wasn't really aware of what exactly it was before, but reading this post instantly sparks a ton of ideas for me. Thanks for sharing this!
[removed]
Looks like the url contains a token which triggers a gitlab login screen.
Everything is under multiple layers of abstractions and indirection. It's just too hard to get to something concrete and usable, as it is. Futures and async don't make any sense to me.
Ah fair enough, for some reason I had/have the impression that LLVM is responsible for things like ABI. As in you have a limited set of choices exposed by LLVM and you can't really do anything completely custom. Within this framework the usual is either one or two registers return values, not three.