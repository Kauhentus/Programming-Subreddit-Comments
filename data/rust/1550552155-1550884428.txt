Perfect, thanks! 
Please don't post in the wrong subreddit.
 [user@host:/tmp/usize_test]$ cat src/main.rs fn main() { let mut a = 100usize; a -= 50; println!("a == {}", a); } [user@host:/tmp/usize_test]$ cargo run Compiling usize_test v0.1.0 (/private/tmp/usize_test) Finished dev [unoptimized + debuginfo] target(s) in 3.18s Running `target/debug/usize_test` a == 50 [user@host:/tmp/usize_test]$ cargo clippy Checking usize_test v0.1.0 (/private/tmp/usize_test) Finished dev [unoptimized + debuginfo] target(s) in 0.71s [user@host:~/stile]$ rustc --version rustc 1.32.0 (9fda7c223 2019-01-16) I don't understand what problem you're running into. Can you post some example code?
Try subbing 200
 fn main() { let i = 100usize; let j = i - 200; }
Then don't use a `usize` to begin with... 
I try not to but there's always the elusive iter().enumerate()
Oh yeah sorry about the formatting. I just got a bit lazy with the copying and pasting. On the the answer, thank you very much. I will try this out and see how it goes. Will this work if I do it inside the `FnMut` closure inside the `filter` call? entries .into_iter() .filter(|e| { if let Some(ref m) = &amp;filter { m.is_match(&amp;e.tag().unwrap_or_default()) } }) .filter(|e| { if let Some(ref m) = &amp;search { m.is_match(&amp;e.label()) } }) .for_each(|e| println!("{}", e)); Would something like this work? I will check it out in a couple of hours, but I just wanted to confirm I interpreted your answer correctly. Again, thanks for your timely response!
You can't solve this general problem by adding warnings, etc.; there will always be cases where you subtract too much, and overflow at the bottom end, whether that's at `0` or `thetype::min_value()`. ``` [user@host:/tmp/isize-test]$ cat src/main.rs fn main() { let mut i = -5_000_000_000_000_000_000isize; let j = 8_000_000_000_000_000_000isize; i -= j; println!("i == {}", i); } [user@host:/tmp/isize-test]$ cargo run Compiling isize-test v0.1.0 (/private/tmp/isize-test) Finished dev [unoptimized + debuginfo] target(s) in 0.24s Running `target/debug/isize-test` thread 'main' panicked at 'attempt to subtract with overflow', src/main.rs:4:5 note: Run with `RUST_BACKTRACE=1` for a backtrace. [user@host:/tmp/isize-test]$ cargo clippy Checking isize-test v0.1.0 (/private/tmp/isize-test) Finished dev [unoptimized + debuginfo] target(s) in 0.27s ``` Short of warning on all subtraction, there's just no getting around that. You could introduce some kind of constrained integer types (I'm not sure what they're usually called) for some cases where you want to catch potential overflow at compile time, but they're generally too cumbersome to use in practice.
Damn, you just gave me more reasons to want const generics. That said, my previous response was incomplete (I was being lazy). An array will not be able to handle the case of heterogeneous types. For example, concurrent calls for three different sets of data which are all needed for page load. \`\`\`rust let (user\_preferences, search\_results, feature\_flags) = await ( ..., ...., .., ); \`\`\`
&gt; The only real gripe is the need of a Mac for developing. That's the killer right there. Developing for iOS has such a prohibitively huge startup cost. And for a long time, the iPhone Simulator didn't support things like location or push notifications which meant you needed a physical device to test on as well if you were doing anything complex. That's ~$2000 down the drain up-front if you bought the recommended hardware new. You also used to need to be a member of the Developer Program to download XCode which was another $99/year. It's free now, thankfully. I got started on a hand-me-down Windows PC with an $80 Android phone from MetroPCS, working for pennies on freelancing sites. The toolchain has always been completely free. I couldn't have done that just a few years earlier when the only option was iOS. Now having borrowed a MacBook Pro from my boss to test a React Native app on iOS, I can say that the development environments are actually rather comparable, though it was difficult at first to even find my way around XCode, not having used anything Apple since playing with our old Apple II GS as a kid. The big difference I've seen is that Android Studio has had first-party support for dependency management with Gradle for a number of years now whereas iOS's solution with CocoaPods still isn't officially integrated in XCode as far as I can tell. I haven't actually tried building a native app since it isn't relevant to my work at the moment so I can't speak to the developer experience of ObjC or Swift, although condemning Android due to Java is a bit unfair since Kotlin's now officially supported as well. I will concede that the API design and documentation in some areas is quite terrible, but I think there's more community resources to make up for that since Android is so much more accessible.
This only works for static data.
Your closures will need to return a bool in the else case, but otherwise I suspect that mostly works yeah.
Ah yes that was a silly mistake. Thanks again!
Yeah, I think in most cases, it's unclear what would happen I (as the consumer of an `Iterator`) keep going after getting an error, but probably nothing good. I searched for "rust iterator with error" just minutes before seeing this reddit post (while trying to figure out how to write a generator / implement `Iterator`) and found [this](https://users.rust-lang.org/t/handling-errors-from-iterators/2551/3), for example: someone complaining of a call to `last` that just never returns. I suppose that `Iterator` implementation didn't follow the contract properly that it stops yielding after the error value, but on the other hand I'd never seen that contract stated before...serendipitous that this was posted just now as I needed to know that. [This](https://docs.rs/rusqlite/0.16.0/rusqlite/struct.Statement.html) is confusing/gross (but I think the best that can be done at present): while let Some(result_row) = rows.next() { let row = result_row?; names.push(row.get(0)); } (`Item = Result&lt;...&gt;` is half of why that seems strange; the other half is explained by a doc comment there: "Due to lifetime restricts, the rows handle returned by query does not implement the `Iterator` trait.") I much prefer the syntax from your pre-RFC. If the other problem could be solved (I believe [RFC 1598](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md) is a step toward solving this, if not actually the solution), it could be simply: for row in rows { names.push(row.get(0)); }?;
You want r/playrust
`ls -al ~/.cargo/bin`?
The codes are well formatted and I tried `cargo fmt`
I'm now working on a side project with lots of small binaries. I'm used to structopt but I want to make creating new binaries as easy as possible. That's why I'm creating `mainopt`: ```#[mainopt] #[opt(long = "foo", default = "FOO", help = "some foo")] #[opt(long = "bar", short = "b")] fn main(foo: String, bar: u32) { // do something }``` It will create a struct decorated with structopt attributes and derive and then destructure it and call fn, e.g. ``` fn main() { #[derive(Structopt)] struct Args { #[structopt(long = "foo", default = "FOO", help = "some foo")] foo: String, #[structopt(long = "bar", short = "b")] bar: u32 }; fn main(foo: String, bar: u32) { // do something } let args: Args = Args::from_args(); self::main(args.foo, args.bar) } ``` Next: add a way to structopt to read missing parameters from stdin.
https://doc.rust-lang.org/nightly/core/iter/trait.Iterator.html#method.enumerate &gt; If you want to count by a different sized integer, the zip function provides similar functionality. https://doc.rust-lang.org/nightly/core/iter/trait.Iterator.html#method.zip &gt; zip() is often used to zip an infinite iterator to a finite one. This works because the finite iterator will eventually return None, ending the zipper. Zipping with (0..) can look a lot like enumerate
On reddit buddy. 
You're getting ripped off. 😉 Almost, because MINIX 3 does a lot in user-space. Ages ago, the OS course at uni included kernel algorithms, kernel data-structures technologies and kernel modifications to MINIX 2. MINIX 2 kernel and basic subsystems' source code is only a few kLoC. It looks like they changed the course to do loadable kernel modules that add syscalls to FreeBSD: http://web.cs.ucdavis.edu/~wu/ecs150/ Just wish OS courses looked at awesome μkernels like seL4, the first binary- and source-formally-proven correct kernel. Good luck in your OS spelunking adventures.
Witch is also a feature you want in a DnS to bypass advanced filtering system like cloudflare..
It's using backticks for delimited code blocks, which works on the new layout but not, I think, the old or mobile.
&gt; Just wish OS courses looked at awesome μkernels like seL4, the first binary- and source-formally-proven correct kernel. There's a lot to be said for this. I suppose in part it's a compromise between teaching "this is how operating systems are done" and "this isn't *usually* how operating systems are done, but it really should be". &gt;Btw, if you run rust on another build/host system and compile for MINIX 3, get the netbsd target component in rustup. If you want to run rust on MINIX 3, just use rustup. No cross-compilation required. `rustup target list | grep netbsd` shows only `x86_64` targets, while Minix supports only 32 bit x86 and ARM. Also, I started with the definitions in the `libc` crate from Netbsd, but `libc-test` showed some differences (after addressing various things that just didn't exist on Minix). So unless I'm misunderstanding what your suggesting, the prebuilt NetBSD targets from rustup wouldn't be of much use here. 
agreed, it wasn't enforced at all except for some handwavy idea of correctness. what i was attempting to say was that ownership does exist, whether your compiler enforces it or not. in the same way that strong static typing eliminates categories of errors, ownership enforcement eliminates a category as well.
Yes, correct. My bad. Entering long-mode (ia32e/64-bit) changes the CPU's structures and features. There is a [package](https://git.minix3.org/index.cgi?p=pkgsrc-ng.git;a=tree;f=lang/rust;h=30c3b452307b615ac9e05a594721a38dc0c51379;hb=refs/heads/3.4.0) for rust in the latest minix pkgsrc-ng ports collection that could probably be tweaked and built from source. Also might be interesting; [writing an OS in Rust](https://os.phil-opp.com/) shows how to setup and enter long-mode from protected-mode
Take care and remember that rest is more important than Rust. &lt;3
Make sure your user has access to .cargo dir. Most likely you have installed something with root privileges (ran some command with `sudo`).
Maybe you want saturating_sub?
You cannot send values that are non send to another thread and have them work. You can wrap it in this if you only need to pass it to a thread as part of another structure without being able to use it: https://docs.rs/fragile/0.3.0/fragile/
That's wired. Do you use the app or website? I post the screen shot here. &amp;#x200B;
Long term I wish rust would get the addition of ranged integers. That is, Int&lt;1..=10&gt; + Int&lt;1..=10&gt; = Int&lt;2..=20&gt;. This would prevent the technical bug of integer overflow, but also a lot of domain bugs introducing overflow. There is also some precedent. Ada does this IIRC, and shares a lot of the problem space rust is trying to address.
Context: GPGPU using Vulkano. TL;DR I have no idea what the `set` and `binding` are supposed to represent in the descriptor set, and other miscellaneous questions need answering. So I'm writing my own version of a genetic neural network which uses Vulkano underneath. My mental image of my program is as follows: * Each of the neurons (and edges) of the same ID across different networks in the population are grouped together * Inputs are stored in a [vector of] buffers (one buffer for each of the input neuron), whose each index of a buffer corresponds to an index in the population of networks * The output of one neuron (for the whole population) is calculated at a time, which is then multiplied by the edge's weight and then finally added to the sum of the next neuron's input. Are there any revisions I need to do in this mental model of mine? In the compute shader examples of Vulkano, I have no idea how to wrap my head around the `set` and `binding` of the `DescriptorSet`s. What are they supposed to represent and how do I leverage those? In a compute shader code, how do I `take` a `return value`; take it as in put it in the device memory but not yet put it into the host memory? Are there anything else that I need to be reminded of before I continue? Thanks in advance for answering.
Cool, thank you.
What happened to user flairs on the subreddit? I'm seeing only a handful of people with theirs, and mine's gone as well. Have they been restricted to just mods/team members?
Wouldn't `clear` be optimized to a simple setting of the length once the compiler realizes that u8 has no drop?
I imagine this is because this looks broken: impl From&lt;Vec&lt;u8&gt;&gt; for Slice { #[inline] fn from(v: Vec&lt;u8&gt;) -&gt; Self { Slice::new(v.as_ptr(), v.len()) } } The Vec v is dropped but you're holding onto its raw pointer. What is the purpose of the `Slice` type and why not use `&amp;[u8]`?
Any code that uses a spinlock trivially breaks on non-preemptive threading models.
&gt;rustfmt I'm using it. As far as I understand, rustfmt gives you code auto-formatting, rls gives you code suggestions and clippy helps you write idiomatic code.
These are a specific case of dependant types. As far as I know they've never been implemented in mainstream languages, but I'm not sure if that's due to inherent or implemention issues.
Please don’t include `-rs` suffixes on crate names. We already know it’s in Rust. (Same goes for `rust-` prefixes and other such things.)
Helping out with ML part of ONNX in [`tract`](https://github.com/snipsco/tract) crate; when this is done, this will basically bring XGBoost, LightGBM and sklearn tree ensemble models to native Rust.
Oh, I asked because my error message also listed rustfmt and yours didn't, so I assumed you just didn't use it :)
I followed up on our Paris discussion to explore the viability of a Dutch edition. :) &amp;#x200B; Are you currently looking for fall of 2019, or spring of 2020?
`build.rs` ?
The link in the post was flagged for being unsecure. Reason being "it contains potentially unwanted programs". 
I am very excited to see a prototype! Good luck! Also, what editor do you prefer?
To add on the particular error you get. When you define `mod filename` in root module (`lib.rs` or `main.rs`) then it refers to `filename.rs` next to that root module file. If you define `mod filename` in `mod.rs` inside some directory rustc will search for `filename.rs` next to this `mod.rs`. If you define `mod filename` in `modulename.rs` then rustc will treat it the same way as if it was `modulename/mod.rs`, i.e. search for `modulename/filename.rs`
Love this idea. I find it to be quite similar to how the Sourcetree git client visualises branches ([pictured here as a graph to the left of the commit messages](http://blog.seibert-media.net/wp-content/uploads/2013/05/SourceTree-visualize-original-windows.jpg)).
Oh thanks. I think that’s the problem. And maybe it works in my Mac by accident ?
We have not made any decision yet for 2019. One thing I can say for myself though is that I'm not going back to a RustFest twice a year. However, we are looking for interested people in general. To avoid doing a lengthy search _after_ every event we want to get people onboarded as soon as possible and then enable them to make their local event happen. So if you want to do an event in 2019, 2020, 2021 or beyond, apply and we get in contact!
We actually put the call out to be plan further ahead. RustFest is stable enough to do this and we believe more lead time for the local teams will improve the events. I'd be very happy to follow up on that discussion.
**tl:dr** Dgraph Rust client which communicates with the server using gRPC. Dgraph is an open source, scalable, distributed, highly available and fast graph database, designed from ground up to be run in production.
Casting to isize is not always correct either, max isize value is half as large as max usize.
Use the builder pattern: ```rust var my_config = ConfigurationFile::new() .with(Name("config.xml")) .with(DirectoryInfo(info)) .get()?; ``` I wont write a full code there, but Im pretty sure that youll find something about this on the Internet.
As others have already answered, a type that isn't Send works only on the thread it has been created on and no amount of wrappers will change that fact. However, from the specs docs, `with_thread_local` is specifically there to support this use case of adding a system that contains data that may not be sent to another thread. So something like: ``` struct RenderSystem { }
I suppose there is no easy way to obtain the lifetimes of particular variables directly from rust compiler or rls?
Maybe, I still found it weird that the example would do that. 
It is 100% use after free and is in 'Undefined Behavior' land. As for whether it 'works' or not does not matter. UB is allowed to look as if everything works, but fail mysteriously in different circumstances. In practice I imagine the allocator used on Mac does nothing with the deallocated memory and just marks the memory as 'free' for future use. Using raw pointers to read the values return their previous contents. It is still UB and is not allowed! A common debug pattern for allocators is to overwrite the deallocated memory with a special marker to be able to quickly diagnose when a use-after-free has occurred. It may also be an exploit hardening technique for allocators to try to reduce the impact of a use-after-free bug. This may be what happens on Ubuntu where the deallocated memory is overwritten with zeroes.
would cross compiling with musl have worked in that case?
I am trying to implement an enum with a variant that contains a generic parameter constrained by a trait bound, but I'm not able to figure out how to express the relationship I want to the compiler. The example below errors with `the type parameter `U` is not constrained...`. ``` use std::fmt::Display; enum Thing&lt;T&gt; { A, B(T) } impl&lt;T: Into&lt;(i32, U)&gt;, U: Display&gt; Thing&lt;T&gt; { fn out(&amp;self) { match self { Thing::A =&gt; println!("A"), Thing::B(t) =&gt; { let (num, display) = self.into(); println!("{}: {}", num, display); } }; } } fn main() {} ``` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1fc53b8fd4280a887b4db3e8f78b3962
One of my code bases has the same problem but there, I actually do implement \`Step\` (mostly boilerplate). Furthermore, \`Step\` will never be stabilized in its current form (source: tracking issue). I could not find an alternative if you wish to make use of the std range abstraction in combination with newtypes. One short solution is a function: fn lines(start: LineNr, end: LineNr) -&gt; impl Iterator&lt;Item = LineNr&gt; { (start.0..=end.0).into_iter().map(LineNr) } Or you just map manually at each `for`-loop. Not really nice because it does not really use `LineNr` like it's supposed to do: // user code for line in (2..=6).map(LineNr) { // range(LineNr(2), LineNr(6)) // ... }
Just to clarify, since there seems to be some misunderstanding. I'm interested if anyone else is interested in Generic SQL bindings, and if so, could we restart this RFC?
Hello folks! I've started learning rust only about a week ago so bear with me. I'm looking for the simplest way to display an image on a window. I managed to correctly grab the image from a database and decode it using the Image crate, but I am having trouble finding a way to display it to the user. I've looked into some GUI/Widgets Crates like Condor and etc but most of the ones I look were really poor on examples. Tbh, I haven't seen a single Image display example yet. Any help is welcome :)
As part of core/std? No. Definitely not. As a crate to pull in when needed? Yes that would be nice to have.
Lifetimes in general are scary and something that keeps people away from Rust, this could totally be a game changer, it makes all the difference. &amp;#x200B; Now Lifetimes are diagram interpretation, when you look at part of code you have never read before you can easily see the variable though. I can't believe this idea didn't came up in my mind earlier. I need this!
Perhaps if the ecosystem evolves Rust could be the language thats able to bridge usability and performance. I know that the current machine learning ecosystem in Rust is quite new, I personally think that Rust would be a good fit. See [arewelearningyet.com](http://www.arewelearningyet.com/) for the status of the Rust machine learning ecosystem.
What I find difficult about rust crates though, and maybe this is just me as a noobie to the language, is that it's difficult to know what's considered the de facto library for certain things. With the go standard library for example I know I'm getting a decent enough http lib when I include it from std. But it's hard to tell on crates.org that something's even remotely good, if that makes sense??
Tbh there is a demand for something which can simulate L2-L3 traffic generator. At the moment, the only tool I am aware of is IXCharriot which can be rather expensive. 
Using `.map(|s| *s)` or for that matter `.cloned()` is a lot shorter than implementing an extension and I don't need it that badly, however it is a possibility.
Just looking at the number of downloads, and recent updates is a good metric to gauge the health of the crate. Putting this at part of core/std would be burdensome to core dev, and would be very hard to get things right. &amp;#x200B; I can imagine the number of depredations and maintenance headaches developing over time having to support other projects using this. 
I don't find this line to be really persuasive. On one hand, yeah, keeping minimal language is a nice thing, by letting core devs focus on other tasks, on the other hand, it presents a sort of [Choice Paralysis](https://en.wikipedia.org/wiki/Analysis_paralysis) for the newcomers. And let's face it. If there is one thing you DON'T want newbies to sort, it's the which library will I use for Date/Time/SQL. 
Folks, we don't need to debate std inclusion now. It's simple, watch: * If SQL bindings were to be accepted in std, the first next step would be to prototype the bindings in the crate ecosystem and develop buy-in from stake holders. * If SQL bindings were never accepted in std, the first next step would be to prototype the bindings in the crate ecosystem and develop buy-in from stake holders. Do the next step first. And probably a few more steps after that. Then we can debate its inclusion in std.
The problem is that the impl is ambiguous - for example, how should it work when `T` implements both `Into&lt;(i32, String)&gt;` and `Into&lt;(i32, i32)&gt;`? If in your code it's not actually `Into` but some custom trait, then you might get away with changing its type parameter into an associated type. If the trait is indeed `Into`, then at first you need to answer the question of what do you want it to do.
is there a way to get goDef working with external crates? right now i don't see .rs sources for any of the crates anywhere, but rls does go properly into std:: sources. is there like cargo option or something? i need those sources.
I don't see how that's relevant. If someone doesn't like subtraction in a usize, they're not going to like subtraction in Int&lt;0..=2^64-1&gt; any more.
Thank you! But remember that Rust is more fun than rest. ;-)
Why would you want compiler internals people to start dedicating their time to database front-ends? Let the database experts do that.
Directly from the compiler, I don't think so. There has been some work to support it in RLS but I think that might require interacting with RLS directly as a library rather than through the protocol. I'm not sure.
This may be helpful: [https://github.com/rust-unofficial/awesome-rust](https://github.com/rust-unofficial/awesome-rust)
This entire post is very cool!
Search the subreddit for "are we GUI yet?" There was a discussion recently. The answer is, "not really, it's not *easy* yet." There's a sea of low-level and platform-dependant details. I'm currently using SFML, but am *very* likely to write my own abstractions once I make time.
Very nice! I still have to finish my MBC2 implementation on my emulator one day. My original goal was to be able to run Pokemon Red or Blue ob my emulator. Right now I have implementations for MBC0, MBC1 and MBC2. One day I'll finish it!
Great work with this! A nice addition would be the ability to exclude a list of stop words. That should help remove some of the most common words you expect to see in a language.
This would be extremely useful.
Thanks a lot!
Thanks! IRC pointed me to Piston which sounds like an Overkill and excessively confusing for my simple app I am building just as an learning project. This is a shame because other stuff like ODBC and image decoding went smoother than I expected.
I find [minifb](https://crates.io/crates/minifb) very easy to use for learning purposes.
You'll run into this issue with any unsigned integer. Its just the nature of the system at hand, and requires a developer to know which integer type they're using.
I'm just one random amateur nerd, but I'm not impressed with Piston. Before getting into anything opinionated, I'll point out that it's designed to draw *n* complete frames per second rather than updating as needed. So it'll use more power than necessary for a semi-static graphical application. SFML has the same limitation, so that's not a dig at Piston. Piston is allergic to using run-time liveness tracking (`Arc` or something similar). Instead it offloads that responsibility on whatever project is using it. If you're lucky, it'll at least use Rust's lifetime system to check your code at runtime. But at the time I stopped following it, there was some discussion of "lifetime are hard and `Arc` has non-zero runtime cost" with the conclusion being that they might just trust your code to do the right thing and not crash. SFML does this too. But at least it's upfront about being unsound. Basically there's a cavalier attitude towards memory safety (maybe acceptable for game dev) buried under a lot of team spirit and evangelism and brand building. I would dislike it less if the project as a whole had a lot more humility. But they squat a *lot* of good crates.io names and IMO bring down the first impressions of Rust. I'd rather say to newbies "the Rust GUI ecosystem is underdeveloped, expect FFI" than steering you towards something driven by a move fast and break things culture. Especially because that culture will say "if you have higher standards, it's your responsibility to fix our project." (And this *is* cultural. I'm a self-taught New England hacker who never liked OOP or Agile™ or so on.)
I'm also really curious about getting lifetime information from rustc or RLS or Racer. Does anyone have any references or resources they can point to?
I'll check thanks!
I'm more skeptical of it. I think a lot of the trouble with lifetimes is at function boundaries, and I don't really see how this helps you pick a correct function signature any easier. Or avoid self-references in structs.
Thanks! I stubbed out the MBC3 timer instead of implementing it and Pokémon Blue seems to run just fine! (Although it could definitely be messing with the RNG and I would never know the difference.) So don’t let that pesky timer hardware keep you from reaching your goal.
Thanks for the comment. Yeah in my conception turning to a gaming library to solve a lower level problem is kinda underwhelming. I am way too inexperienced to do any relevant commentary on this, but some of the crates I've checked had some bizarre approach to Rust memory safety measures, making that in practice their implementation was less than ideal. (But then again, that may be my inexperience with the language). I've been programming for a relatively short time (~8 years) and IMHO these new languages (cult) followings are all kinds the same. I've been liking the language by itself so don't worries there :)
Hi, The directories note was incorporated. I didn't understand what the user of the preferences library should do himself, and what is provided? I was expecting that the derive attribute will trigger building in the background a mapping between the simple TestConfig structure and a compatible Json struct that will be serialized to a file. Can you help me fix the example I'm trying to build above?
We are searching for Holonauts to join us on our journey to build a new, regenerative economy and a more human Internet. Join Our Team. Become a Holonaut! &amp;#x200B; Apply: We’re Looking for Rust Devs! [https://holo.host/careers/rust-developer/](https://holo.host/careers/rust-developer/)
*Wooo* It's your **3rd Cakeday** idle_zealot! ^(hug)
It'd be really interesting to develop a more formal visual model -- if we get that, then a core could be developed with the front-end bits remaining to be implemented.
I agree, and it seems like `try` blocks could work well for the case where you do want to continue iterating on error.
Do you only intend to support relational databases like MySQL or PostgreSQL, or is scope greater than those databases? If the scope is greater than the standard set of databases, what additional kinds do you intend to support? For instance, do you intend to support: * Columnar databases? * NoSQL databases oriented around key/value lookups or Document-oriented databases? * NewSQL databases like Spanner or CockroachDB? * Systems like QLDB or Kafka that provide materialized views? My concern is settling on a database implementation in the standard library would result in stagnation. I don't think we, as an industry figured out how databases _should_ operate, let alone their call patterns.
I had some code to scan an image in memory, handling various orientations of scanning. Using \`isize\` seems unavoidable for this, given that each scanning step (pixel or line increment) could be + or -, determined by how the code is used. Casting to \`usize\` at the last moment seemed the cleanest way to do it, after trying various ways. I agree \`usize\` is awkward for this.
Aside: I'm _unbelievably_ happy to see other languages building on top of Rust's ideas. While I want Rust to succeed as itself, true success in my eyes is inspiring new, better languages that eventually overtake it. It's not clear to me if this language is addressing the same problem spaces, but either way I'm very excited to see new things crop up. I'm also glad that you're sharing your ideas back to our community, hopefully we can work together on more such problems!
Which language are you referring to?
Here's what I (quite strongly) believe is the right solution: The one and only blanket impl should be this one: impl&lt;G&gt; Iterator for G where G: Generator&lt;Return = ()&gt; { type Item = G::Yield; } That's the obvious conversion from generator to iterator that everyone can agree on. The iterator's item type is equal to the generator's yield type, and there is no "return" type (because iterators don't have one). If you want the behavior where a yield type of `T` and a return type of `Result&lt;(), E&gt;` gets converted into an iterator with item type `Result&lt;T, E&gt;` (so that you can use `?`), then you have to request that by using a function adapter. The fact that you have to explicitly request this kind of behavior (rather than it being automatic) is in my opinion a good thing, because there are conversions going on, both when yielding and when returning. Rust has historically shied away from automatic conversions, and I don't see a compelling reason to break that tradition here.
When there are a fixed number of elements in a collection to which we want to apply a series of identical transformations and unpack into discrete variables, is there a canonical approach for doing so in a single statement with the stdlib? Or is using temporary variables the way to go? For example, to get the variables `first: char` and `second: char` out of `"I want to make f and g into chars".split_whitespace()` I first tried something like: [words.nth(4), words.nth(1)].into_iter().map(|&amp;c| { c.expect("unable to get word").parse::&lt;char&gt;().expect("unable to parse as char") }).collect(); but I don't think a single collection type will fit the bill; I could use `let [first, second] = ...` except that I can't collect into e.g. `&amp;[]` or `[char; 2]` (I think because there's no good way for rust to know the length of the underlying array). I can collect into a `Vec&lt;char&gt;`, but I don't think there's any way to unpack a Vec into the 2 discrete variables without requiring a temporary intermediate (i.e. `let Vec[first, second] = `... is not a thing). I could collect the map into a vector, create a temporary mutable iterator (`tmp`), then unpack with `if let (Some(first), Some(second)) = (tmp.next(), tmp.next())`, but this still seems a little clunky, and requires the temporary intermediate variable How would someone good at rust turn `"I want to make f and g into chars"` into two variables, `first: char = 'f'` and `second: char = 'g'`? Thanks for any thoughts. I am incredibly grateful for these easy question threads! Related links: - https://stackoverflow.com/questions/29504873/is-there-any-way-to-unpack-an-iterator-into-a-tuple - https://stackoverflow.com/questions/26757355/how-do-i-collect-into-an-array - https://www.reddit.com/r/rust/comments/3z582i/collecting_into_an_array_or_fixed_size_vectors/
Huh, I was actually working on a Holochain project for a client just a few days back. Cool project.
The website isn't doing the best job of explaining what Holo is. I'm guessing something blockchain related? But then what's that box they're holding in the pictures?
https://cglab.ca/~abeinges/blah/too-many-lists/book/
Adamant
Honestly, writing a parser with nom has been a great experience for me. My structs/enums generally require lifetimes, they all implement a few traits, and some structs/enums are generated using macros. Sure, I haven't really run into borrow checker issues, nor do I need multithreading, but I've definitely learned a lot from that project. 
It seem you have a problem with permissions. if your username is `chipp` you should not have permission problem to write in `'/home/chipp/.cargo/bin/rustup` You probably installed something in your .cargo directory as root. You should try to run `chown -R chipp ~/.cargo` and try again
OMG! It is super awesome! This visulaization will be the game changer for Rust, I believe.
I'm sorry this post got 0/negative points and that the submitter apparently deleted their account. I think there is a valid and important point to the article, which is that allocators and "other parts of the system" (whatever they may be) are often overlooked. It's obvious to most of us that an allocator should not return the same address for multiple allocation requests. But is this requirement formalised anywhere for safe Rust? What other requirements are there that we don't really think about? I remember one issue from the Linux kernel, which was: what should an allocator return for a zero-sized request? Is the allocator allowed to return NULL? (Does it count as an allocation failure?) Is it allowed to return an actual non-NULL pointer? Is it allowed to return the same pointer for multiple (zero-sized) requests, even when that pointer is not passed to free() in between? This is just to say that there are implications of allocator semantics that are important and non-trivial.
Rewrite in Rust a program that you've written before.
I'm not sure I'd call it a cult. Anyway, minifb is likely the best answer for your problem today.
`100usize - 200` is underspecified. The Rust abstract machine may choose either behavior: - produce MAX_INT - 100 - panic IMO the only thing that's broken is that you can't index slices by all integer types.
&gt; You don't suppose e.g. the write barrier problem could be helped with runtime support? Possibly... The problem is that pro-actively checking whether a pointer is "relocated" is an expensive operation, you wouldn't want to do that on every write through a pointer. This means that the `mprotect` trick is the cheapest alternative for the most common: it's free when there's no relocation ongoing! What would be great would be for the fault-handler to be able to change the value of the pointer by which it was invoked: this would allow lazily copying a span into another. I am not sure whether this is possible (with or without run-time assistance) :/
How would you structure the example? As far as I can see, clearing after the last line provides the clearest example code, and it's not like it's a bug.
Now that [alternative registries have been stabalized](https://github.com/rust-lang/cargo/pull/6654) it will be easier to build alternatives to crates.io that have different guidelines for submission and maintenance that solve some of these headaches. 
Xtensa have just released an official ESP32/Espressif LLVM backend and clang front end. See their announcement here: [https://esp32.com/viewtopic.php?p=38466](https://esp32.com/viewtopic.php?p=38466) Repos: [https://github.com/espressif/llvm-xtensa](https://github.com/espressif/llvm-xtensa) &amp; [https://github.com/espressif/clang-xtensa](https://github.com/espressif/clang-xtensa)
&gt; IMO the only thing that's broken is that you can't index slices by all integer types. Indeed :( I'm find with an `assert!(index &gt;= 0);`!
On the other hand, I came from C++ and found myself constantly thinking about how long stuff was supposed to live and where. Lifetimes aren't entirely unique to Rust, but they are, helpfully, explicit in the language, which makes things *so much* easier to debug and reason about. But you also have to get it right, which can take more time, and commonly called "fighting" the borrow checking, when IMO it's more accurately "working with" the borrow checker. The Rust compiler is your friend.
The video gives a better idea of what this seems to be about. Looks like a good idea, not too much neocurrency-orientated.
Running the program in `valgrind` should help to reveal issues like this. This series of blog posts provides details on what undefined behavior means: http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html Memory errors like this are very common in C, and tools like `valgrind` and `gdb` are pretty much mandatory. *Safe* Rust code is great because you can just not worry about it (the compiler will raise errors if you try to do it wrong). But with `unsafe` you can produce all the same issues as C code.
It took minutes to figure out what Holo does at all. Like not to figure out exactly how it works, but to figure out the basic, highest-level idea of holo. Terrible terrible website. Its so typical of startups to just be 100% marketing and zero actual substance. I'm not commenting on the tech or anything like that, its actually a decent idea, but damn does that website suck
&gt; As far as I can see, clearing after the last line provides the clearest example code, Clearing after reading into the buffer means that every loop iteration has a pre-condition on the buffer being cleared, so if I were to go this way I would prefer to avoid this precondition by clearing the buffer, then reading into it. &gt; How would you structure the example? I don't know, that's why I am asking. AFAICT, the API of BufRead does not offer a nice way to structure this example. The closes is the `.lines()` method, but that returns a new `String` every time, so a `.lines_ref()` method on buf reader would be nice.
&gt; Unfortunately, it appears that VS Code will not allow a plugin to add this kind of visualization [...] &gt; [...] these diagrams don’t seem well suited to generation with the HTML and CSS that Atom is built on What about vim? I have no idea how its plugins are written but in a cli editor "all you need" is a few columns padding on the left and some fancy unicode chars.
Ok. So I brew install rustup-init, then run rustup-init on shell to install rustc and cargo? &amp;#x200B; And rustup-init will not ask for rust? Thanks!
Very cool! I was just searching about the topic yesterday. 
GOTO Berlin **2017** ([Nov 16th](https://gotober.com/2017/schedule)). The talk may be slightly out-of-date.
https://github.com/matrizx/arg-soup Thanks a lot for any help! Feel free to make a pull request if you do anything.
Could you please also make a research on how much energy it costs to run all of the world's banks and their infrastructure, and all of their employees traveling to their work, etc.? And also what kind of impact current banking system have on people and their economic and social situation (which is why crypto started in the first place) .. Then this argument might be valid .. 
What OP asks for is compile-time warnings to not miss integer overflows. Ranged integers is a way to achieve that.
Was prototyping a game in godot, found it needs some UI stuff to make it better. So i think im at the point where I want to try a setup with SDL2 &amp; gfx. Either pre-ll or hal + rendy, i haven't decided yet. Pre-ll i could port my rendering code from [EnergyGrid](https://agmcleod.itch.io/EnergyGrid), and try to make it better.
Thanks! ☺️ Yepp, future work 😅 
Hmm, thinking a bit more about it, you actually *have* to clear the line after the last line. I mean the problem is: The only way to figure out if you're at the last line is to check the return value of `buffered_data.read_line(&amp;mut string)`, and if you call this with a non-cleared line, you risk it not being the last line and having a line appended to the non-empty string! If you attempt to move the `clear` up before the `read_line` call instead of at the end of the while, you would probably end up with something like this: |data| { let mut buffered_data = BufReader::new(data); let mut string = String::new(); loop { string.clear(); if buffered_data.read_line(&amp;mut string)? != 0 { break; } yield string.matches(|c| c.is_alphanumeric()).count(); } } Try to go backwards from the `break`. You'll notice that it ends with a call to `clear` even when it's formatted like this. As for why there isn't a `lines_ref()` method on `BufReader`, that's because returning a reference means you need to store it somewhere, and where should that be? Remember `lines_ref()` returns an iterator, so your first attempt would probably be to put it in the iterator, however the `Iterator` trait does *not* support returning references to stuff stored in the iterator. (This is the same problem as the one mention in "Self-referential and Unpin generators" in [the blog-post before this one](https://boats.gitlab.io/blog/post/generators-i/).) Storing it inside the `BufReader`? Well that'd be kinda weird because stuff like `lines` consume the `BufReader` and honestly what is the last returned line doing inside the `BufReader`? This way the string would also not be de-allocated when you drop the reference, because it's, well, a reference. Storing it inside a string provided by the user? Well that's what `read_line` does.
Good idea! It's noted: [https://github.com/ad-si/textalyzer/issues/5](https://github.com/ad-si/textalyzer/issues/5)
I'd add to this that languages with good abstractions and library support tend to allow you to keep the project size small. Important functionality can be moved to libraries and tested/developed in isolation relative to the main project. So in that sense, I'd hope that Rust helps keep more codebases to the size of "still hold whole program in your head fairly easily."
Sounds interesting! What exactly is then done in parallel?
`usize` is already a ranged integer. As far as I can tell, adding more of them would only produce a need for more silent conversions.
/r/playrust, or rather, /r/buildapcforme.
I’ve tried buildapcforme but haven’t had much luck as of yet really, I’ll check out playrust. Thanks man
Date, time, and SQL are very different things. The first 2 are concepts used everywhere all the time by almost everyone, even non-programmers. So it makes sense to have them in the standard library. SQL is only used by programmers writing code that talks to structured databases. I'd estimate that less than 5% of rust applications use SQL, probably significantly less. It just doesn't belong in the standard library.
That did the trick, thank you. I was sure I had already tried that, but I guess I lost track. :D
they handle 9 more orders of magnitude of transactions and use less power, lmao. fuck off
Godot rust needs a better getting started tutorial. There are examples of use in the repository that are hard for beginners to find. 
Not even necessary. Slice indexing checks bounds. It's purely a case of std being excessively cautious - or maybe just nobody writing the RFC yet.
I'm working on some video tutorials which will do just that. They will be paid but once I have the first up I'll send you over a free copy for some feedback.
Project: [https://github.com/brycx/orion](https://github.com/brycx/orion), Docs: [https://docs.rs/orion/](https://docs.rs/orion/) I've already tried to fill out most of the documentation myself, so writing it shouldn't be relevant. On the other hand, I could really use some feedback on its effectiveness. Is it easy to read and understand? Are there things that seem unclear? Are the examples effective and easy to comprehend? Something terribly amiss? Any feedback really. This is a crypto lib, so if you're not a crypto nerd yourself: even better! But in that case, the documentation outside of the \`hazardous\` module might be the most relevant to you. I really appreciate any feedback, thanks you advance!
https://github.com/ggez/ggez is a lightweight 2d game framework that has just gone through a fairly major set of API chang,e and there are numerous dusty corners that need to be swept up. Investigate the `RELEASE_PROCEDURES.md` and [this issue](https://github.com/ggez/ggez/issues/528) for places to start; feel free to message me if you want and have any questions.
&gt; As for why there isn't a lines_ref() method on BufReader, that's because returning a reference means you need to store it somewhere, and where should that be? Inside the iterator, but you'd need ATC for that; the Iterator associated type Item would need to be `type Item&lt;'a&gt; = &amp;'a String;`.
That's my point. Rust does not (yet) have that feature.
Agreed
write a thread-safe trie datastructure with simple insert/removal. Start super super simple and innefficient. Just make it able to be accessed between multiple threads. Then after that, make it as concurrent as possible as an optimization
Indeed. I'm personally hoping for a rust-style language with gradual typing that plays in the python/javascript space.
Why another FAT16/32 implementation? We already have [fatfs](https://github.com/rafalh/rust-fatfs) and [fat-rs](https://gitlab.com/susurrus/fat-rs), why not reuse them?
&gt; Yarte is optimized using ... to make your templates as fast as possible (literally). Is that "..." a placeholder? I'm actually very curious how it is optimized. It would be nice to see some benchmarks as well.
+ a million I had to stop reading this article because it made me miss 'sequence' too much https://en.m.wikibooks.org/wiki/Haskell/Libraries/Maybe#sequence
Looks great, I like how you’re able to use rust code directly from the HTML
I think the implementation uses [`::std::pointer::offset`](https://doc.rust-lang.org/std/primitive.pointer.html#method.offset), so the `usize` is cast to an `isize` internally anyway. But by using an `usize` for indexing only the upper bound needs to be checked.
**Summary** Holochain Developer Preview v0.0.4-alpha is now available for download! It brings the changes we’ve been promising — the name change from ‘Container’ to ‘Conductor’ (with renamed binaries), a massive documentation update, easier scenario testing, an important bugfix in core, and more. &amp;#x200B; **Highlights** 1. Developer Preview 0.0.4-alpha Released! 2. Traits: Logical Grouping of Zome Functions 3. Important Bugfix in Core: Fixes Failing Zome Calls 4. Simple-App Broken and Fixed Again 5. Documentation for 0.0.4-alpha is Live! 6. Signing, Signals, and Holo: Enabling Full Authority Over Data for Holo Users &amp;#x200B; Read the full Dev Pulse and install v0.0.4-alpha: https://medium.com/@holochain/developer-preview-0-0-4-alpha-and-enabling-full-authority-over-data-for-holo-users-3cc8794855d4
Im interested to know that too :P
Good job there! very interesting to see how Rust can be used to re-create a better and faster stuff that was written in js before.
Yeah, you're dead right about how to make loops go the right speed, I deliberately didn't do it that way for these demo/exploration scripts so that it'd be easier to spot issues, but yeah, longer duration averages are definitely the way to go. Overall I loved your idea, it made perfect sense that locking stdout could cause unbounded delays, but unfortunately taking out the print statements didn't solve the underflow panics on my machine, so there must be something else going on. How are did you generate the load? I'm using the following script: FILL_HALF_THE_RAM_LINKED_LIST_SIZE = 10000000 BE_NICE_TO_THE_RAM_LINKED_LIST_SIZE = 1000 def create_circular_linked_list(item_count): result = [[i, None] for i in range(item_count)] for i in range(len(result) - 1): result[i][1] = result[i+1] result[-1][1] = result[0] return result[int(.9 * len(result))] # return only 1 reference (far from the beginning) so it's maximally hard to GC def do_nothing_at_great_cost(_, ll_size): read_head = create_circular_linked_list(ll_size) while True: read_head = read_head[1] def add_unnecessary_load(ll_size): from multiprocessing import cpu_count from multiprocessing import Process for i in range(cpu_count()): p = Process(target=do_nothing_at_great_cost, args=(i, ll_size)) p.start() if __name__ == '__main__': add_unnecessary_load(int(FILL_HALF_THE_RAM_LINKED_LIST_SIZE * 1.75)) # add_unnecessary_load(BE_NICE_TO_THE_RAM_LINKED_LIST_SIZE) 
Should have generated a statically-linked executable with no library dependencies, basically just i686 code with syscalls to the linux kernel for the basic network socket functions and etc. The servers run kernel 2.6.24, and my dev box runs 4.13.0, but the core Linux ABI is very stable - Linus is famous for his rants about not breaking userspace. Musl on my dev box without cross-compiling turns a 1.5MB executable into a 30+MB one, so yeah, you carry a lot of baggage around with you, but disk space is cheap these days.
Hey OddCoincidence, thanks for the feedback. I believe our technical website maybe do a better job at explaining things. Holochain is the blockchain alternative. Holochain is a more scalable solution. &amp;#x200B; There are two things at play. **What is Holochain? \[tech stack\]** Holochain is a framework for creating and powering distributed applications, incorporating peer-to-peer content distribution protocol, cryptography, and hash tables. [https://github.com/holochain/holochain-rust](https://github.com/holochain/holochain-rust) Developer Portal: developer.holochain &amp;#x200B; **What is Holo? \[flagship app build on Holochain\]** Holo is a marketplace and distributed hosting platform that allows Holochain app developers to have their applications hosted by HoloHosts, thus making them available to everyday users of the Internet. &amp;#x200B; &amp;#x200B;
That is correct. Not token focused at all. 
I think I'm going with this first!
Cool that is good to know. Was it straightforward for you to build on Holochain? 
[https://github.com/petershirley/raytracinginoneweekend](https://github.com/petershirley/raytracinginoneweekend) You could build a ray tracer. I'm doing it now and it's not too hard, and it's cool to see graphical results coming from my code. I'm starting to understand why people build game engines even though they know it'll never be used. You can find many people who have done the same course in Rust, and can look at their code for examples.
(currently on mobile) I used your playground link to create this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=685a2066d4b35dbdbb2b7cab9e68b3ce Note that you could probably use `.chars` to get a char iter and filter if the input is f or g -- just a thought 😊 
Alternatively, rewrite in Rust a program that you've used before. I've started with a clone of `tr` from coreutils and it was quite educational.
Is it faster than [zapper](https://ceres1.space/posts/zapper/)? ;)
[broot](https://github.com/Canop/broot)'s story should probably be told with a different perspective, the documentation should feel more natural and less like the concatenation of different concerns. I'm not sure anybody's else than a "long time" user can do that work, though.
Because when I looked,l I didn't find any #\[no\_std\] FAT16/FAT32 libraries. Those two are interesting, I'll check them out. Thanks!
I think fat-rs also got some use and/or advancement in Redox, you might want to check that out as well. They were specifically shopping for a `#[no_std]` library as well.
Is there by chance a set of macros that make defining struct+impls more like in modern languages in a single block and with less boilerplate for "constructor"? Something like this: class! Blah { state1: u32; state2: u32; new! { state1 = 10; state2 = 20; } pub fn some_custom_method(&amp;self) -&gt; Unit { // blah } } that would get translated into struct Blah { state1: u32, state2: u32, } impl Blah { pub fn new() -&gt; Blah { Blah { state1 = 10, state2 = 20 } } pub fn some_custom_method(&amp;self) -&gt; Unit { // blah } } 
Surely LLVM will compile it down to the same code? (A single unsigned compare.) That would be a trivial optimisation.
I don't know if this is a Rust question or a "recommend me a library". I'm looking at producing raster images (PNGs etc) from vector data (points, lines, polygons). And I just haven't really found any crate/library which does this. There are some for doing images on the graphics card/GPU but that just seems complicated (I don't want to mess with graphics cards or drivers, I don't need that level of performance), and I need to support polygons with holes, which many don't seem to support (I don't think [conrad does](https://docs.rs/conrod_core/0.63.0/conrod_core/widget/primitive/shape/polygon/struct.Polygon.html), [imageproc doesn't](http://docs.piston.rs/imageproc/imageproc/drawing/fn.draw_convex_polygon.html). Can you recommend a library?
Amazing, thanks! Google about Digital security company. Дайте знать как начнете внутри компании Rust юзать :D
You could make a macro to do that. Here's an example. I've only made a very small number of macros so I suspect this could be made better. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9b06e22a297ec4a999c36b36432f877d
Maybe https://crates.io/crates/img_hash?
https://github.com/rust-unofficial/awesome-rust/blob/master/README.md#image-processing
I was about to disagree with you but I think you're right, since `[T].len()` must be less than `isize::MAX`. Interesting, perhaps indexing with `isize` wouldn't be so bad.
Do your word counting in parallel, e.g. spawn 4 threads, and give each thread 1/4 of the total words. Each thread can compute the word counts for it's chunk of the text, and then you just add up the word counts when each thread is done. Spoiler alert, I cloned and modified your code last night to test this it. On the 1984 sample, the multithreaded code runs ~5ms slower on my machine, likely due to the overhead of spawning threads and cloning the work (to appease the borrow checker). A larger piece of text would likely see the multithreaded code become faster. 
"-ansi" is horrendous. Why would they do that? How many years ago was this?
Disagree. C doesn't tell you why it crashes, it just does. I've seen many a classmate that simply does trial and error until they get their program to not crash (usually) and call it good.
*Rust* doesn't tell you why it crashes, it just does. It's good practice teaching you how to use valgrind, which *does* tell you why it crashes, for the most part. The point is not to have a safe language, the point is to have a simple language where you can learn about the various issues you can cause with memory unsafety, and how rust protects against them. I guess you could do the same thing with rust and using unsafe blocks and raw pointers everywhere, but C is handy to know in any case.
Wow, I would definitely not have thought of this. Thanks!
[https://github.com/atroche/rust-headless-chrome](https://github.com/atroche/rust-headless-chrome) &amp;#x200B; The [Browser](https://docs.rs/headless_chrome/0.1.3/headless_chrome/struct.Browser.html) type has okay docs, but [the front page of the docs](https://docs.rs/headless_chrome/0.1.3/headless_chrome/) and the [Tab](https://docs.rs/headless_chrome/0.1.3/headless_chrome/struct.Tab.html) type could definitely use some help.
It's this GabeN's alter ego?
Thanks for the response. Yes, I had mentioned this as a possibility (using a temporary intermediate like `items`): &gt; I can collect into a Vec&lt;char&gt;, but I don't think there's any way to unpack a Vec into the 2 discrete variables without requiring a temporary intermediate &gt; Note that you could probably use .chars to get a char iter and filter if the input is f or g -- just a thought The characters of interest will vary (including single letter words such as `a` or `i` that could be the variable of interest or just contextual text), so this will not work for my use case. Working on Advent of Code #7 if you're interested in looking further; I've used e.g. regex and nom on most of the others and wanted to get a feel for doing this one with stdlib.
I'm really excited to start learning / writing macros, but so far have not written any of my own, so thanks for this!
Yeah. Unreal is really the only one decent from the start. Even the HD rendering pipeline for Unity is pretty underwhelming.
Crate author here. `img_hash` can help identify _similar_ images but unfortunately finding an image inside another image's content is not implemented. That requires some advanced math that's outside of my expertise.
ive been looking around a lot more &amp; possibly another option ive just tested is AudioKit - annoyingly its the swift language \[because I personally find it an odd language\], but successfully built the AUv2 example right out of the box with no extra setup. ive tried AudioKit before &amp; asked for a long time \[way before this was put in\] to find out how. but finally it has been put in \[not sure when\]. but it does work, really well 7 fast but yeah, it is swift \[so no windows/linux support, but does have iOS stuff\], but the AudioKit glossary is pretty deep on what it can/could do &amp; did make some fun things when testing out many times ago. so I think ill bash on that to see what its like, especially for creating UI for it as well. I would personally not like to use Swift, but I guess thats the cross to bear right now &amp; get things making \[because AU is what I want to make\] for the better &amp; not leave anymore time searching but if Rust does get a AU thing going, ill be all over that again, thank you for the help, links &amp; words of wisdom
The OP wasn't very clear about what they are trying to achieve, and anyway it's either your crate or OpenCV.
Question about [procedural macros](https://doc.rust-lang.org/stable/proc_macro/): How to I refer to items from my crate? Eg. with macro_rules you get `$crate` but this doesn't work in proc macros. Not that it could work because the proc macro is in a separate crate with the items defined somewhere else. I could refer to it with the `::mycrate::ITEM` but then the proc macro won't work in the scope of `mycrate` (and I would like to use my own proc macro in both my own crate and for other consumers).
2003 I think. It's also not so much about the language, more about meticulously checking every error result. The only thing we were allowed to cast to `(void)` was a `fprintf` to `stdout`.
I want to add [tarpaulin](https://github.com/xd009642/tarpaulin) to [headless\_chrome](https://github.com/atroche/rust-headless-chrome), replace some uses of \`Mutex\` with message passing, and improve [the docs](https://docs.rs/headless_chrome/0.1.3/headless_chrome/struct.Browser.html) further. They're definitely gotten better since last week when I [announced the crate](https://www.reddit.com/r/rust/comments/aqgsxk/announcing_the_headless_chrome_crate_puppeteer/), but there's still a long way to go.
Coming from an Assembly, C, C++ background, the trait system made me better realize the uses of polymorphism: I hadn't really understood why would I need OOP at all before. I think that overall Rust made me appreciate what those other languages still lack: Enums that are this flexible, better inference for generics, design of the abstractions more tuned with the language, compile time safety (expecially seeing how easily returning references out of a scope can be caught and explained by the compiler) and that bit of functional programming that makes things soooo much simpler. I still miss a few features, but I am hopeful about the Rust project, I can see actual progress being done over the years and concepts that I thought of being impossible before.
Well, afaict Rust is still successful.
Now that's a lot of buzzwords.
what's the point? it's like trying to benchmark a cheese grater compared to a potato peeler...
Yes! I didn’t see the need for any of it either however after getting into it with rust it all makes sense now 
For me, definitely traits but also being more cautious when using pointers and understanding stack and heap allocation. I now think twice before doing something in C and pay more attention to how and where I allocate
I can't really put my finger on it, but I'd say Rust have made me think more about code design in general, and ownership in particular. I've noticed my designs are less dependent on inheritance/mixins, and often cleaner in general. Above all, I'm putting as much effort on avoiding unintentional misuse as on providing a clean happy path. On the flip-side, I've grown spoiled by the compiler and type-system having my back. My bug-ratio in dynamically typed system have gone up a bit.
Placing methods in separate impl blocks was a deliberate design choice for the language; it becomes useful when generics and trait bounds are involved. There is the [`derive-new`](https://crates.io/crates/derive-new) crate for reducing constructor boilerplate; by default it lifts all of a struct's fields to parameters of `new()` but you can provide default value expressions as strings as well. Converting your example: #[macro_use] extern crate derive_new; #[derive(new)] struct Blah { #[new(value = "10")] state1: u32, #[new(value = "20")] state2: u32 } fn main() { let _ = Blah::new(); } [There are more examples in their documentation.](https://docs.rs/derive-new/0.5.6/derive_new/) 
Why doesn't the following work? I understand why it doesn't, but I will argue that it should work. fn main() { let x = 42; f(x); // &lt;- error on this line } fn f(x: &amp;i32) {} Why doesn't Rust turn the `i32` into a `&amp;i32` implicitly? Was this just a design decision, or is there a technical reason why the implicit conversion cannot happen? It seems to be that because of the type signature of `f`, `f` has already promised to do less than it could do with full ownership, and thus actually giving it ownership shouldn't be a problem. Is there a trait I can implement to allow implicit conversion?
Okay so any ideas on a better description? 
Here's part of a talk by the author of [Cursive](https://cursive-ide.com/) (a widely used Clojure plugin for IntelliJ) about the pains of macros in an IDE, and his approaches to dealing with it: [https://youtu.be/2sPYiGxU4kA?t=1037](https://youtu.be/2sPYiGxU4kA?t=1037)
What web framework are you using? 
I'm much more particular about ownership, especially transferring it between threads/tasks. Most of my work that isn't Rust is single-threaded Python using asyncio, so causing a data race is actually pretty difficult, but passing objects through channels between tasks helps me reason about correctness.
Serde actually wraps the derives it emits in a dummy constant and reimports the crate there: https://github.com/serde-rs/serde/blob/bf27b285546a14265fef960ce218d22afddb8fbf/serde_derive/src/dummy.rs You see this `wrap_in_const()` call at the end of the derive implementation you linked. However, Serde doesn't use its own derives as far as I can tell. If you're using a function-like proc macro (e.g. `macro!()`) then you could wrap it in a regular macro that imports the items and then calls the proc-macro which just refers to them locally: macro_rules! my_macro( ($($input:tt)*) =&gt; ({ // we can import in blocks // glob-import the items used in macros use $crate::macro_prelude::*; my_proc_macro!($($input)*) }) ); You can apparently just glob-import from a proc-macro crate and it will make those macros available locally (although this was used for derives in this case): https://github.com/rust-lang-nursery/failure/pull/81/files#diff-b4aea3e418ccdb71239b96952d9cddb6R40
&gt;Yarte, Yet Another Rust Template Engine, is the fastest template engine right now. Uses handlebars-like syntax to make things easier for developers is aprox x144 more faster at big table than handlebars.rs on single core and rust stable and more in nightly
yes, but Zapper is way faster than handlebars, and Zapper has benchmarks. Your code doesn't seem to have any benchmarks.
Escape html is optimized with simd instructions and template is compiled in Display implementation over fmt::Formatter with minimum possible instructions. Sorry README is in 0.0.1
Thanks. The idea is to be able to nest rust code in handlebar expressions.
&gt; how should it work when T implements both Into&lt;(i32, String)&gt; and Into&lt;(i32, i32)&gt;? Thanks for the response. This is the scenario I was missing, and I see how it causes ambiguity. 
My code is benchmarked in CI, result in nightly [https://travis-ci.org/rust-iendo/yarte/jobs/495708517#L613](https://travis-ci.org/rust-iendo/yarte/jobs/495708517#L613) 
We've been planning a migration path from a PHP app to rust. We've been paring down the business logic for a while, so most of the interesting stuff lives client side in some reducers and react components. Server side is little apart from some glue so the graphql resolves with some SQL and/or service calls. We've moved the graphql schema completely out of PHP and into a `schema.graphql` file, and will be taking all inclined sql out into .SQL files with the prepared statements. Hopefully that'll give us an easy transition as we can share the queries and not repeat anything, but keep some of the complex PHP running as we migrate over the easy and new stuff on its own endpoint. 
In addition to valgrind, [miri](https://github.com/rust-lang/miri/) helps reveal issues in unsafe code. With OP's playground link, it emits the [error](https://gist.github.com/memoryruins/617f6e41e6b2d6d7b3aee7cec87fddf4) &gt;error\[E0080\]: constant evaluation error: dangling pointer was dereferenced
This is weird, and I don't know how I feel about it, but I think this kind of does what you want. I feel like making it one statement wouldn't work with this (but I didn't try), but if you can build the iterator first and pass it into the macro, you can declare as many variables from it as you want. Well, until it panics on an empty `unwrap()` anyway. The syntax inside the macro could change, I just tried to come up with something that was clear about what is going on. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=93c30897b4be74549ece6b9de920d17d
This is weird, and I don't know how I feel about it, but I think this kind of does what you want. I feel like making it one statement wouldn't work with this (but I didn't try), but if you can build the iterator first and pass it into the macro, you can declare as many variables from it as you want. Well, until it panics on an empty `unwrap()` anyway. The syntax inside the macro could change, I just tried to come up with something that was clear about what is going on. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=93c30897b4be74549ece6b9de920d17d
Also [https://github.com/not-yet-awesome-rust/not-yet-awesome-rust#computer-vision](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust#computer-vision)!
Thanks! I am using a derive proc macro but I forgot you can just bring crates into scope with extern crate. Renaming is then done to avoid causing ambiguity for the user which now has `_serde` item in their scope.
I can make your example work for `f(x)`, `f(&amp;x)`, `f(Box::new(x))`, and more by using the `Borrow` trait bound: fn f&lt;T&gt;(x: T) where T: Borrow&lt;i32&gt; + Debug { dbg!(x); } However, I would not do this and remain explicit unless you need your function to accept a wide variety of stuff.
Unfortunately, passing `x` by-value for a non-Copy type will move `x` into the function call and it will not be usable in the outer scope afterward.
Ok, so it can be done. But it sounds like you're saying that a single character is a small price to pay to be explicit in this case, and it's probably better just to add the single `&amp;`.
That's actually why Serde uses `wrap_in_const()`; because the import is done inside the initializer block for the const, it doesn't leak into the outer namespace, and more importantly, doesn't collide if there are multiple invocations in the same module. The name of the const can still collide but Serde generates a unique name for each one based on both the trait being derived and the target type: https://github.com/serde-rs/serde/blob/bf27b285546a14265fef960ce218d22afddb8fbf/serde_derive/src/dummy.rs#L8-L11
Rust enforces a lot of good practices and conventions by default. Many of these patterns are applicable elsewhere. Mastery of the borrowing and ownership system is the obvious benefit. It's good practice to adhere to this in other languages, including the object-oriented ones. Idioms such as `FromStr`, `Display`, and `Iterator` are likewise useful to replicate in other languages. As are many of the useful types and interfaces available in Rust. At the very least, if you delve into the aspects of systems programming, you'll have a greater awareness of the implementation details that many data types are built upon. Personally, I get very uncomfortable in other languages, as they often aren't very explicit about how their interfaces and types are implemented. You'll find people sending and sharing references across threads, but can we guarantee that these types are safe to do so? Even GC languages like Go struggle with thread safety.
Yes, thanks I was abbreviating without thinking. I’m not sure exactly what it was I ended up extracting some of the logic to a function and that helped me clear up the return types.
Your benchmark doesn't seem to include figures for zapper or handlebar though? I might be reading it incorrectly.
This post is so exciting that I was thinking I want laziness visualisation in haskell! I deeply think that "layers of reasoning" (lifetimes, effects, state, security,...) are the fundamental parts of software engineering. Being able to visualise even a few of them makes reasoning as a whole easier. This is how engineering should be.
Use `wrapping_sub` to specify you want to wrap.
I think the realization that mutation can be safe so long as it's unique. It felt like picking up a new paradigm in the same way I learned a lot from FP. Also, having not interacted with lower level languages much before, an appreciation of when allocation happens, stack vs heap, etc.
\&gt; Enums that are this flexible &amp;#x200B; These are called sum types in many languages, and I agree that once you start to use them it's hard to imagine working without them. I've always thought it was odd most mainstream langs only include product types.
Neat! I didn't know miri could do that, though it makes sense.
Personally I take the first approach and implement `From` on my application error type for each of the lower-level error types I want to handle. That way I can just `try` my way through everything and any errors I don't want to handle more or less automatically bubble up to be converted into a response in an application-level error handler.
Philipp set out to land 100 Rust PRs in a year. And they did. Kudos.
Amazing achievement. &amp;#x200B; I posted it to the subreddit so hopefully more will see it.
Wow, fantastic work!
The comparisons with other crates are in [https://github.com/djc/template-benchmarks-rs](https://github.com/djc/template-benchmarks-rs). The results have to be updated, I suppose the owner will update it in a few days, otherwise you can launch the `cargo bench` and see it for yourself. I recommend you launch them at *rust nightly*.
You should be careful about benchmarking code in CI; it can be unreliable. See [this blog post](https://bheisler.github.io/post/benchmarking-in-the-cloud/) about the subject.
Super cool. Awesome work!
Nice suggestion, thanks a million.
Good suggestion, thanks a million.
What's the difference b/w x: &amp;mut isize and mut x: &amp;mut isize ?
I believe that is Steve Klabnik
The Rust borrowing and lifetime rules have really helped me to understand memory safety in a way that I simply didn't before, even after writing C and C++ for years. In particular, I now feel that I might actually be able to avoid a lot of the segmentation fault type issues that I used to regularly encounter, often without fully understanding why in C or C++. Although I doubt I will ever go back to those languages now.
This feels like it's very similar to Askama. The thing about these speed gains is that you quickly hit a point where you probably want to have HTML templates dynamically loaded in, not compiled. I often find myself reaching for Tera, for instance, and then loading in Askama where I feel it's appropriate.
[rust-bindgen](https://github.com/rust-lang/rust-bindgen) [C2Rust](https://c2rust.com/)
[mp4 link](https://external-preview.redd.it/mp4/D6H_m1gbCwBNgmxM-GUydWiJG8V2OfXr4bMBH5rerzY-source.mp4?s=e35e2ff24fdd8d72ab455344d5af18233f8df7eb) --- This mp4 version is 84.61% smaller than the gif (2 MB vs 12.98 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
I'm working through the paper copy of "The Rust Programming Language" from No Starch Press. My end goal is to start up a project that has had fits and starts for the past 4 or so years. My end goal is to get around to recreating something along the lines of the linked program below. I fell in love with this game and has been one of my favorites. [https://www.myabandonware.com/game/one-nil-soccer-manager-1ka](https://www.myabandonware.com/game/one-nil-soccer-manager-1ka) &amp;#x200B;
visualizer was made with piston2d with cgmath (to project brain 3D points into piston 2D lines and points)
It is a comparison with the macro write! without escape html.
&gt;This feels like it's very similar to Askama. &gt; &gt;The thing about these speed gains is that you quickly hit a point where you probably want to have HTML templates dynamically loaded in, not compiled. I often find myself reaching for Tera, for instance, and then loading in Askama where I feel it's appropriate. It's normal to look like Askama, I'm a collaborator. It is as if I had redone the parser, the generator and the escape. Similar changes will be made in Askama. The main difference between what you comment is the performance, much greater in templates in procedural macros.
&gt; In this case, every use of the object would result in a copy, as shown by the bifurcation. Is this really the case? Or is it the case that every use *could* result in a copy? If not, does rust treat POD/primitives differently in this regard?
An example where parallel arrays hurt performance would show that they not always help. Anyways, the user of any performance oriented library is supposed to have benchmarks too.
The way rust chains its Iterators has really helped my thinking in javascript &amp; php too. I was frequently transforming entire collections repeatedly, which in js you can maybe cross your fingers and pray to the engine gods will be optimized out, but often isn't. The main reason people aren't in those languages is simply because it's ugly without a lib, and most libs like doing the full transform. You can implement map &amp; filter iterators in a few lines, so it's strange we're so obsessed with turning absolutely everything in javascript into an array.
Does it provide template inheritance? That's basically the number one feature I'm looking into when considering template systems.
What was the purpose of the immediately invoked function expression? I formatted the code and removed that and it's really not too bad. Could definitely be obfuscated more :) ```rust fn decode(a: &amp;String) -&gt; u32 { a.chars().enumerate().map(|(i, c)| { ("ABCDEFGHIJKLMNOPQRSTUVWXYZ234567".chars().position(|l| { l == match c.to_ascii_uppercase() { '0' =&gt; 'O', '1' =&gt; 'I', _ =&gt; c.to_ascii_uppercase(), } }).unwrap() as u32) &lt;&lt; (a.len() - i - 1) * 5 }).sum() } ``` 
Taught me to Design twice code once. I feel in particular, makes me really consider how things reference each other and if they really need to. 
Amazing
My original code had the immediately invoked function expression as a separate function. I moved the separate function into the closure without thinking about it.
I don't know if I can discuss it but it was about converting an existing rest app to work with holochain. It was straightforward to build on holochain because the APIs are well defined. But there were certain portions where I had to delve into the source code and would have liked better documentation, instead. Also, I was having some problem with scenario testing but I think that was slotted to be fixed with the next update.
You're absolutely right - how do I relinquish dominion over `uap-rs`?
"Coming Soon" but not yet implemented. We always appreciate more help if this interests you!
Schnatsel is right, I'm the author of fat-rs, which I specifically wrote to me nostd and last I know Redox is using it. I actually started it to write an SD library , just like this one, but I'm really excited that it exists! I'll have to give it a try at some point as I've got a bunch of embedded boards laying around I need to play with. And if you have any feedback on fat-rs or if it could serve your needs, i'd love to collaborate on it. 
As a student, I felt learning about the ownership model really helped me understand the "why" behind a lot of modern C++. I didn't truly understand the difference between copying, moving, etc. until it was made clear and explicit in Rust.
After some consideration I have decided to combine `Trie` and `TrieViewable` so that `Trie` can implement `get` and `insert` in terms of the TrieViews (which generalizes the involved algorithms). However this has required me to reintroduce lifetimes into places you had helped me removed them, and I am running into problems returning values from the views to the caller of `get`. I have pushed my latest changes to github and would appreciate any feedback you have.
It's taught me that shortcuts usually aren't worth it. Also that documentation trumps most other things. And struct composition almost always works great but sometimes the natural boundaries between things are rather different than what you think they are.
I came from a mostly Python and beginner C++ background, so using anything other than exceptions for error reporting was surprising/unsettling for me at first, but now that I'm familiar with it I feel uncomfortable writing code that could involve exceptions. Jon Kalb has argued for the use of exceptions in C++ to separate error handling from normal code (as if error handling is not as important as the rest of a program???), yet in Rust I don't find error handling woven into normal business logic. In many cases I find that Rust code is _more_ clear than exception-based code, because I can see exactly how and where errors are handled; and especially with networking code this is essential. Coming from a science background where most of the C and C++ I've seen or written touches arrays, I was worried about the overhead of bounds-checked `[]`. The Rust answer to this is "use iterators" and I was really impressed by how easy it was to learn the iterator tools required to get all my array operations without checking every access. When I go back to Python now I often want to use `map` or `filter`, but in Python they're free functions not methods. So you end up with `filter(map(x, lambda x: ...), lambda y: ...)` which is vastly less readable than Rust iterator work. Tail-call iterator methods are extremely valuable. This one took a long time, but learning the monadic interfaces on `Option` and `Result` really really cleans up error handling code. Chaining `and_then` calls is _vastly_ cleaner than nesting `match`es. [Simon Brand's 50-second talk on this really is accurate](https://www.youtube.com/watch?v=-5MlmugEzG0).
So I haven't made a post here because I don't really have enough of a question to really start a conversation. But, since this is a post about porting Rust to a less commonly used Architecture, I'm gonna ask you this. Do you know where I could look for information, if I wanted to port Rust to arduino/AVR chips? I just think it would be a lot of fun to be able to code arduino projects in Rust, and while it looks like people have experimented with this, I can't find an example of a working project. What does porting Rust like this involve. Would I just need to write Rust code? Or does it require some C or some assembler? I'm considering just using what I learned from Craftinginterpreters.com and transpiling Rust into Arduino's C language.
Great work. Getting Rust to work on weird targets should help make the language more portable. That said, I'd say the *actual* final frontier would be to get it to target an 8-bit home micro, but that might be a bit much... :P
Made a new pull request! This is interesting, the solution I propose is similar to what you just did. Split `Trie` along the lines of mutability.
Pinging /u/kuuff because of https://www.reddit.com/r/rust/comments/ane10g/creating_a_dos_executable_with_rust/.
Oh, I've tried getting Rust on all sorts of weird platforms before, and most of them weren't possible without non-existent LLVM backends, unfortunately. I would absolutely love to get Rust code running on the Commodore 64, but the options for code generation just aren't there, and no one is clamouring to write and maintain them.
The good news is that there's a [fork of the Rust compiler](https://github.com/avr-rust/rust) that adds support for AVR chips already, and it's hopefully going to be merged sooner or later. The last that I heard, they were waiting for a bug in LLVM to be fixed or something along those lines.
Oh yeah, I came across that thread when I was looking to see if anyone else had done this. I didn't realize that it was so recent. If Kuuff is still looking to do that, I can go into more detail as to what to do on Discord.
Handlebars-like templating uses partials instead of inheritance: https://stackoverflow.com/questions/13226930/template-inheritance-for-handlebars
Tbh I haven't felt like I've learnt any new concept or idea. What Rust has done is heavily reinforced those I already knew. It's very good at reinforcing good practices.
&gt; no one is clamouring to write and maintain them. How odd. I cannot *imagine* why that would be. Hmm? Oh, no, no. Sorry, I have to, uh... wash my hair, yeah. *Wash my hair.* All month. It's a mess, I tells ya...
Are you using that? I've been heavily using Godot lately, and been getting into rust. I'm interested in playing with this, but I've heard it isn't quite usable yet. I'm also not making anything that really needs any more performance than GDScript is already giving me, but I find it fun to tinker with alternative languages.
 fn main() { ["Baby", "Daddy", "Mommy", "Grampa", "Grandma"].iter() .map(|kind| format!("{} shark", kind)) .map(|shark| format!("{}{}\n", shark, " do".repeat(6)).repeat(3) +&amp;format!("{}!\n", shark)) .for_each(|a| print!("{}", a)); }
I thought rust had a working rust to C transpiler? Is this goal to go straight from rust to DOS or would IL count?
hi, I applied some days ago. But no record to be easy to send it again.
If you're talking about [this](https://github.com/thepowersgang/mrustc), it's true that it emits C code, but its primary focus is bootstrapping the Rust compiler that's written in Rust, and I've heard that it's not really ready for use for anything else, although that could be changing. Technically the normal Rust compiler does actually send your code through multiple ILs, including MIR and LLVM IR. What I tried to do here was to use the normal methods of building Rust code to target MS-DOS, though, yes.
I'm a young self taught developer and I looked at Rust a couple years ago, and regret not spending more time with it. The last few days, I've read 5 chapters in to The Rust Programming book, and while I've been reading about best practices for a year now, reading about how scope, ownership work. Like the rule about being able to borrow endless immutable references, but only one mutable reference, have already made me think so hard about when I declare variables and what I do with them. It's been crazy. If I do nothing with rust, this book will still have taught me a lot. And man, I actually hate dynamically typed languages. I use Ruby and Python a good deal, but much prefer my Java/Kotlin, and now Rust.
Hello, how can I contact you
The first is an immutable binding containing a mutable reference to an isize, the latter is a mutable binding to a mutable reference to an isize.
I'd like to use Petgraph to construct and evaluate binary trees/emulate recursive types; my situation is that I may have a bunch of different trees in use at any given time, and I need to be able to combine two trees into one. There doesn't seem to be any way for objects of the Graph type to be combined the way you would combine trees, so in the interest of avoiding the long-term footgun, am I better off having separate Graph objects for each tree and combining them by turning graph B's node/edge vectors into iterators and reading them into graph A, or am I better off having one Graph object with a bunch of trees behind like a lazy static and just not drawing edges between them until I want to combine them?
I'm in Seattle so I'm afraid I'll have to miss this one, any chance for a recording?
You could have an AppError trait which describes behavior that you expect an error to support (e.g. converting to JSON) and then use trait objects. That would allow you to add errors from separate modules.
Same story here; I’m 17 and self-taught. Couldn’t dream of going back to Python or Lua without type system guarantees. Been using rust for about 1.5 years now and it’s made me a much better programmer and thinker overall.
Now I wanna try my hand at rewriting FreeDOS in Rust.
&gt; weird I'm just went on a rampage in my dosbox biomenace when I heard that.
Correct me if I'm wrong, but aren't partials just document fragments you can include? How would you implement a site that has a base layout but different contents for each page? If you just include document fragments, you have to include the parts before the content and after content as different partials even though they form a single "frame" that nests the contents; that feels incredibly dirty to me. Dirty in a very similar way than what we used to do with JavaScript: `document.write('&lt;h1&gt;header&lt;/h1&gt;');`
There are very little blockers left! The new renderer is getting there, we just need to support rodio and Amethyst should build on mobile. Then we will simply have to create primitives for the mobile context, create deployment procedures and it will be usable.
I don't know much about Xamarin- but I heard it was nice but with rough edges. What made you think MS neglected devs there I wonder (sincerely, as someone who hopes to use it in the near future for x-plat app-dev, not trying to be a fanboy)
&gt; If you just include document fragments, you have to include the parts before the content and after content as different partials even though they form a single "frame" that nests the contents That's my understanding of how these are used, but I'm not an expert in them as I prefer the inheritance approach.
(`do_parse!`)[https://docs.rs/nom/4.2.0/nom/macro.do_parse.html] doesn't take a buf as first argument, you use it to build a function that you can call with your buffer.
I glanced over opened issues concerning mobile development and thought it was complicated into contributing ; that said, there was probably a waiting period for new renderer. Also, beta testing oncoming features might be easier to begin with.
Previously I was a developer of Nukkit, a minecraft server engine with official approval. I'd love to contribute to this project, as it's a great practice to work with async i/o and network frameworks.
With implicit borrows it becomes even harder to tell what is going on when reading some Rust code. This already became harder with NLL. I think this change would add complexity to the language that just isn't worth it.
[I’m working on the m68k target](https://lists.debian.org/debian-68k/2019/02/msg00003.html), want to join me?
That tree is very useful as the patchset showcases how to add a new architecture to Rust.
Does it work on partial matches ?
But you will have this problem with every language. One already said that the number of downloads can be a good first indication. I personally like to look through what others are doing. If you read the source of some big crates or rust projects you will very fast get a good overview on what others use. Additionally I think that asking which crates others prefer (on this subreddit/IRC or wherever) will yield some very good results and maybe even some pros and cons of each. 
The Rust source basically does what you do: it implements the operation for everything. The only thing it does different is that it uses macros to impl everything for a type in one go. See for example: https://doc.rust-lang.org/src/core/ops/arith.rs.html#102
Yeah, as I mentioned I read that exact code and it's what inspired me to implement my `Vec3` operations the same way. I was almost certain copy/pasting wasn't the answer until I saw that's basically what the standard library was doing. Granted, I didn't use a macro, because they're pretty intimidating.
So in real mode, are all your pointers far pointers? Or can you mix and use both near and far pointers within the same executable (e.g multiple segments for code and data, and being able to use near pointers within a segment, but also be able to use far pointers).
Speaking of "what is going on": What is the runtime difference between a move and a borrow? I was under the impression they were both equally cheap operations? I'm not sure about this though. I suppose `Copy` has to be considered when talking about moves as well.
I think there's no difference at runtime between a move and a borrow. Borrowing is purely a compilation concept and disappear once we reach LLVM stage. I might be wrong, I'm far from being a specialist ^^
FYI, here's the talk's **ABSTRACT** Over the last year, Rust has found production adoption beyond Mozilla at [Dropbox, Chef, Canonical and others](http://rust-lang.org/friends.html), powering whole new production systems. Why is such a young language suddenly so eagerly picked up? Rust is a surprisingly versatile language bringing safety increases to both the server-side and memory-constrained systems like IoT devices. But it isn't only a safe language, but also one to pleasantly program in. Rust provides both abstraction capabilities usually reserved to higher-level languages as well as fine-grained control upon need. The talk will give an overview of the problems Rust allows to solve better - in practice!
Do people selling perpetual motion devices tell you their secrets? Sad to see talented Rust devs wasting their time on ICO scams
There will be no more borrowing in rust? Or will the borrow happen under the hood but still happen?
Not necessarily. It depends on a number of things, crucially, whether it is a stack or heap allocated value, and whether it is passed between functions. E.g. moving a stack allocated value out of a function will likely be a memcpy of the value, since the value was allocated on the stack frame of the current function. That frame might become invalid once the function returns. Likewise, moving a stack allocated value into a heap allocated struct will also involve a memcpy in all likelihood. Moving a value might thus involve copying the entirety of the value. If the value is really big, you have to be mindful of the costs and consider allocating it on the heap instead. Borrowing, or passing around a reference, involves copying around a usize sized pointer to a memory location, so the cost is constant in this respect. The tradeoff is that to access the value, the pointer has to be dereferenced.
Yeah, perceptual hashing is meant to hash an image in a way that differences are quantifiable somehow, in comparison to most hash functions which are designed to produce an entirely different output for a small change in input. You have to quantify what you mean by "partial" though because it determines what kind of hash algorithm to use. Resizes and changes in aspect ratio don't defeat most hashes easily, (i.e. cause two visually "similar" images to produce completely different hashes), neither do changes in overall brightness or minor crops, or slight color differences or additions/removals. Basically, if it looks the same at a distance or with your glasses off or your eyes crossed then the hashes produced will probably be similar. Preprocessing with the discrete cosine transform gives you more robustness against color gamut or contrast changes and even some rather significant edits since you're looking at the image in a frequency domain and the hash only looks at the low frequencies (the mathematical "broad strokes" of the image). The hashes are also highly tunable, since they shrink the image before hashing to throw away details that aren't necessary; you can set it to shrink them less to retain more detail. If you're expecting to match against images that have huge differences in content or have been cropped significantly, or if you want to look for one image that might be embedded into another, then you're going to want to look into more sophisticated computer vision algorithms that look at an image in more detail. I put a lot of work into a new major version of the crate but I haven't released it yet because I wanted to write more tests and documentation for it but I've been sidetracked with work and life so I haven't gotten around to it yet. Part of the documentation I've been wanting to do is a guide for using my crate to match images, but I have a lot of data gathering to do still, and that requires a large library of test images that I have yet to find. I also have plans to incorporate `img_hash` into a commercial product in the not-so-distant future so some of my data I might keep to myself. The more advanced bit of maths I talked about involves wavelet transforms which can match the image inside other image content because they're spatially independent. Currently I have have little to no idea where to begin implementing those without digging through megabytes of whitepapers. I've implemented the Marr wavelet on one Github user's suggestion but all that does in practice is perform edge detection on the image, which is useful in its own right but then you have to figure out what to do with that information; right now I just have it as another preprocessing step in the new version.
Macros can feel intimidating initially, and case in point, there are plenty of extremely cryptic ones out there. I believe there should be a discussion about the proliferation of macros, because I also find some of them to be a cognitive burden. Having said that, nice and simple macros with no recursion or other black magic are very powerful and I don't find any issue with using them. Particularly in cases like this, macros allow you to concisely express concepts that would require inheritance and overriding in traditional OO languages.
If it's just for the purpose of printing, you could impl Display.
I was actually trying to implement intoIter for my struct....
https://docs.rust-embedded.org/faq.html#when-will-rust-support-the-avr-architecture
Sorry the wording was not correct, I've fixed it. You train the network and not the data of course ;-) It allows you to use a network that was trained with data set A and re-train it with data set B (which is from a complete different problem domain). And this re-training is faster than to train from scratch (= untrained network). So the goal is to have one big trained super-network that can solve most of the problems and can adapt very fast to new problems.
NetBSD can run on a C64, right? https://wiki.netbsd.org/ports/ Also "Power C" https://www.c64-wiki.com/wiki/Power_C Hmm interesting enough to make me want to buy some kind of monitor or adapter and brush off my old c64... But also I have a day job
actix-web, but with diesel it has a lot of boilerplate code for actor flow.
yeah, good approach. But then low-level layers will know about HTTP codes. Otherwise, I will need to downcast each AppError trait object for matching error to HTTP status code on the request handler layer.
I see that no one mentioned Xcode, which has a similar feature to visualise where data is retained or released with the macOS Objective-C language. [Potato screenshot embedded in a tweet because I love to self-quote](https://twitter.com/nokusu/status/958722624015749120)
Can you explain more about use cases where you've wanted them to be dynamically loaded?
Open source? Mind posting a link?
I hope that the gcc-ia16 ([https://github.com/tkchia/gcc-ia16](https://github.com/tkchia/gcc-ia16)) project gets some pressure on LLVM to even support 186/286 CPUs in the far far future
I'm fairly sure NetBSD needs an MMU. Either way, the 6502 isn't on the list of supported targets. The good news is that you don't need a special monitor for the Commodore 64, as it works with normal televisions, provided that they have analogue inputs.
I saw that a few days ago and I'm really excited about this. It sounds like a great opportunity to learn more about the Rust compiler.
internal error codes are just optional feature. We can skip it from implementation. General question: how to hide knowledge about HTTP codes from low-level layers (database,...), but in the same time have an ability to cast application error types to HTTP status codes in request handler/middleware without trait object downcasting. The first approach is a good start point, but with the central place of possible error variants for all application layers.
thanks a lot! ^^
I'm still learning about some of the more arcane aspects of x86, so please take all of this with a grain of salt, but it seems that Rust's pointers get compiled to 32-bit near pointers, strange as that may sound. Trying to access an address above 0xFFFF makes DOSBox complain that it's out of bounds for the segment. You can most certainly mix near and far pointers in the same executable. If you couldn't, it would be pretty hard to deal with large amounts of memory. Some inline assembly is probably in order to make that accessible from Rust. A lot of this would probably be a lot easier with a DOS extender, which would probably be a good idea if you wanted to write a DOS game in Rust.
yup: https://github.com/PsichiX/psyche but it's not yet documented - brain-activity can show you how to setup and use :)
into iter comey with iterator. you can just do sent.into\_iter() in the example above. If you just want the intoiter trait implemented. You could just split your string which returns the Split iterator. if you collect() on that, you will receive a Vec over which you can iterate too. 
Only slightly, as it's mostly documenting the strategy that led up to that success, but doesn't document a lot of minutia. (I'm the speaker)
At LLVM stage all borrowing become getting pointer.
What about comments from this thread [https://www.reddit.com/r/rust/comments/7zsy72/writing\_a\_doubly\_linked\_list\_in\_rust\_is\_easy/](https://www.reddit.com/r/rust/comments/7zsy72/writing_a_doubly_linked_list_in_rust_is_easy/)
Please tell me, that with a name like 'cbmuser' the intention is to get Rust compiling code that will run on an OCS/ECS Amiga?
This is amazing, thank you!
Sorry Bot, but this video needs a lot more bitrate and 444 subsampling.
From the looks of things, you are creating six instances of your `SplitWords` type (I'm guessing `InfiniteUnit` and `SplitWords` are meant to be the same type.) and then you want to iterate over the words in all those instances. However, there is no magic way to iterator over all the instances of one type. Instead, you'd have to, for example, put all the `SplitWords` into some iterable container (like `Vec` or `slice`) and then iterate over that. However, this is just an assumption, your code example doesn't make it all that clear what exactly you are trying to accomplish and what kind of solutions would be acceptable for what you are trying to do. Here is a playground which prints what you want to see, without implementing into\_iter on anything, maybe this is helpful in some way, maybe not: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e9a16ad61e6c75d268a32ec66c87d576](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e9a16ad61e6c75d268a32ec66c87d576). However, even if this doesn't help you directly, articulating why you need something different might help others to help you find a proper solution.
I think that you're looking for something like [Cairo](https://www.cairographics.org/) and [bindings for it from Gtk-rs](https://crates.io/crates/cairo-rs). As it's not a Rust library, there isn't be a lot of Rust specific documentation and examples out there but check out [this basic Rust example](https://github.com/gtk-rs/examples/blob/master/src/bin/cairo_png.rs) and [official examples](https://www.cairographics.org/examples/) in other languages.
Wrong subreddit... You're after /r/playrust 
ops i’ll change
the intention is to get Rust compiling code that will run on an OCS/ECS Amiga 
Old school exe is pretty simple, concerting shouldn’t be too hard. Also consider targeting one of that extenders like DOS4GW or Pharlap. Have you considered using Watcom’s linker? It’s been free for a long time, and may even be OSS now. 
Almost correct: there is no internal difference between a move and a *copy*. A move is simply a copy where you are no longer allowed to use the original value afterward. This is not true in c++, where moving and copying can run arbitrary code.
You can also check out [https://github.com/mitchmindtree/daggy](https://github.com/mitchmindtree/daggy) and [https://docs.rs/dependy/0.4.1/dependy/](https://docs.rs/dependy/0.4.1/dependy/)
I haven't used a DOS extender before, but it sounds like it should actually be easier and require less work, since it's in protected mode and therefore closer to what Rust is normally targeting. I'm fairly sure that Watcom's linker is OSS, yes. If it can generate an MZ executable from the object files created by LLVM, it might be worth using for this.
One thing though: Rust is **not** a low-level language; with its move sematics, borrow checker, traits and so on it's quite the opposite.
By partial I mean that the image might be resized or may have borders whereas the orginal may not
Does it work on stable?
Not for nothing but you haven't done much with zapper in 9 months. Speed is only one parameter among many others that lead to adoption.
It depends on the thickness of the border, but otherwise, yes. You'd actually want to hash both the image under test and the original multiple times, first with a small, fast hash for quick and dirty matching, and then increase the hash size to improve confidence of their similarity. All the hash algorithms in `img_hash` produce a bit string that you can then compare bit-for-bit (take the Hamming distance) and count the bits that are different. The smaller the number of bits different, the more similar the images are (assuming same hash algorithm and bitstring length).
Yeah, that’s why I’m doing it. Basically learning Rust the hard way ;-).
Yes, that’s the intention. I’m a huge Amiga fan since the 90s and Debian’s principal maintainer of the m68k port. The first target is *m68k-unknown-linux-gnu*, but it shouldn’t be that hard to add support for AmigaOS later. Although we would need to convert the ELF binaries to COFF to run on AmigaOS.
I see.. I was under the impression that "system programming language, means its low-level".
found this a really well-presented overview of Rust. I remember watching the talk when the video was first released. It motivated me to give Rust a try. I have been working with Rust full time for a little more than a year. It's my primary language along with SQL. Thanks for the help, Florian. ;) 
Would you like some help?
OC's recommendation about impl From conversion will get you where you want to be
In this blog post is an example of how you should implement a custom ResponseError implementation https://blog.sentry.io/2018/12/04/safe-web-services-actix-sentry 
Yeah, thank I have seen that post. This a good way for converting concrete error type to response. 
yeah, I use From trait to convert some 3rd-party error types to application error. This rather about is a good way to define a single enum with error types within a large application?
If you like the ability to use Rust code directly within HTML, you may want to consider [Display As](https://github.com/droundy/display-as) as a templating solution. It also is compiled and thus fast, and it runs on stable Rust.
If you have a large website built with Rust where templates are regularly being updated, it would be nice to be able to update the templates without having to recompile the entire application.
I think you're usage is fine. "Rust is high level" and "Rust is low level" are both correct _in some sense_. Moreover, they are themselves relative terms, which means they are heavily colored by experience.
Hello everyone, Please support by starring the issues on the issue tracker, if you are interested in using Rust on the GCP.
Its both. You can do raw C FFI, use inline assembly, control life before \`main\`, control memory allocation, which allocator is used, target embedded system without a heap, etc. 
Rust is a low-level language with \_some\_ high-level language features, but I don't think that makes it a high-level language. &amp;#x200B; A feature that most high-level languages have but Rust does not is fully-automatic memory management.
I implemented `Iterator` on two structs: `Foo` and `Bar`. I would like to expose a third struct `FooBar` that would be the flat map of `Foo` and `Bar`, to prevent the user of my library to write `Foo::new().flat_map(|x| Bar::new(x))`. How can I do that?
Thanks for the kind words :).
After thinking about it, I at least partially agree for the following reasons: 1) Implicit borrows would mean you could not create functions that take only `&amp;T`. Having a `&amp;T` parameter would mean you also must accept `T`. We would *lose* an ability, the ability to accept *only* `&amp;T`. Unless we added even more syntax to control the implicit borrow, but then we're really complicating things. 2) Rust already has a way to make polymorphic functions, and that way is with generics and traits. We already have a way to accept both `T` and `&amp;T` in a single function, and that way is using generics and traits. If I look at a function definition and see that it's not using generics or traits, then I know that function is not polymorphic; implicit borrows would change that. Maybe having a way to derive a basic `impl AsRef` would be good; is this already possible?
I'm pretty new to proc macros so thanks for the detailed explanations! I learned a lot. Are these techniques documented somewhere? The Book has a section on procedural macros but doesn't mention any of these techniques. After some experimentation I didn't manage to create a custom derive proc macro that works with both the crate which defines the trait which is derived and external consumer crates. In the end I created 2 proc macros `Trait` and `_Trait`. The second is `#[doc(hidden)]` and not reexported for use in my own crate then imported as `use crate::_Trait as Trait;`. It's not so pretty but now does what I want it to do. 
Please no. Rust already has enough random stuff sneakily going on under the hood of the syntax and it makes life harder. See [this gentlebeing's complaints](https://lobste.rs/s/l3o7fq/what_are_you_doing_this_weekend#c_kypm7l) and my [attempt at explaining why things be the way they do](https://gist.github.com/icefoxen/f5a781f5c38d73c108d8426da851d80c). Programs should do what you tell them to do, not what they think you want.
Why not use tower-grpc?
Nice report! I notice that this code seems to use `tokio` and async I/O. Now, `tokio` is great if you need to handle thousands of simultaneous connections, or if you need to tricky things with bidirectional sockets. But in my experience, `tokio` makes Rust about 10x harder than normal, thanks to [Rust's still-incomplete support for easy async code](https://areweasyncyet.rs/). At least in my personal opinion (as somebody who has used `tokio` in production), people should avoid async Rust for now unless they have a very compelling use case, and new Rust developers should avoid it entirely for their first couple of programs. We saw something similar with ESR's blog post on Rust—he started learning Rust, and immediately tried to write an async server, and because very upset at how hard it was. Why do so many new Rust users decide to immediately tackle `tokio`? I feel like this provides a terrible first experience. Is it just because Node &amp; JS have convinced some programmers that async code should always be the default, if a language supports it?
Could you cite a source that says that all high-level languages _must_ have fully automatic memory management? It seems like under that condition only entirely-garbage-collected languages are actually `high level`, leaving languages such as C++ in the `low-level` scene, which contradicts what everyone else agrees to (that C++ is actually a high-level language).
&gt;Could you cite a source that says that all high-level languages must have fully automatic memory management? &amp;#x200B; Even if I could, why would I? I never claimed that. You, OTOH, are claiming that: &amp;#x200B; \&gt; Rust is **not** a low-level language; &amp;#x200B; Citation needed.
yarte actually appears to be a fork of Askama that implements a different syntax (and probably some other changes) -- the code is very similar. (This is, of course, mostly fine, except that yarte [doesn't seem to adhere to the applicable license terms](https://github.com/rust-iendo/yarte/issues/5).)
&gt;Does it work on stable? How committed are you to the project? If it works in stable. I have left everything for an year to start this adventure and I am on the threshold of poverty. I do not like the current software companies, so I will dedicate a lot of time to the community even if I have to steal to get it. Do you think there is enough dedication? In rust-iendo Pantreon you can help to make it possible and not end up in the commissary.
\[quote="wahn, post:7, topic:25386"\] Anyway, I think I will clean up a bit and prepare a \*\*new release\*\* this week … \[/quote\] &amp;#x200B; Here are the \[release notes\]([https://www.rs-pbrt.org/blog/2019-02-19-v0-5-1-release-notes](https://www.rs-pbrt.org/blog/2019-02-19-v0-5-1-release-notes)) ...
I have no idea what it does, it's mesmerizing though :)
I think I saw Cairo, and shyed away because it wasn't pure rust.
Why not work with djc to improve Askama rather than create yet another rust templating engine?
Wait. I had that problem with a struct. I tried using it after passing it to a function and could not. My solution was to change the function to accept a reference and pass a reference. Is there another way? What is a "non-Copy" type, and is there a "Copy" type, and does that actually involve copying data? I suspect all this will be answered when I get further in my reading, but here we are.
May be this project helps https://github.com/JuliaComputing/llvm-cbe ? You can compile Rust to LLVM IR, and then convert it to C via llvm-cbe, and then use any suitable compiler for DOS that exists for your platform, I suppose there is good one C compiler for PC-98 that can produce exe files?
Sorry to hear about your economic distress. I think that it will be challenging to secure funding for "just" a templating project, especially because viable, mature, and feature-rich libraries already exist in the space. However, if you were to expand on templating and created something like an enterprise-quality open source reporting library, you might just find backers-- across language platforms, too.
&gt;normal televisions, provided that they have analogue inputs. I don't think that's normal anymore. :) 
Cheers!
&gt; I never claimed that, so why would I? You said that `Rust has some high-level language features, but I don't think that makes it a high-level language. Particularly, because it missing (...) fully-automatic memory management.`, which can be understood as if all high-level languages had a fully-automatic memory management. If there are exceptions, why isn't Rust one? What are those exceptions of the memory management rule and why? &gt; You, OTOH, are claiming that: (...) without providing a source or proof. Ad 1: Rust matches at least all those definitions of a high-level language: - https://en.wikipedia.org/wiki/High-level_programming_language (+ it's [here](https://en.wikipedia.org/wiki/Category:High-level_programming_languages)) - https://www.webopedia.com/TERM/H/high_level_language.html - https://www.computerscience.gcse.guru/theory/high-low-level-languages ... and, what's more important, Rust is promoted as a high-level language (e.g. https://doc.rust-lang.org /book/index.html - `Rust isn’t limited to low-level systems programming. It’s expressive and ergonomic enough to make CLI apps, web servers, and many other kinds of code quite pleasant to write (...)`). Some random internet links may not be representative for you and that's entirely acceptable - but nonetheless they are better that nothing. Ad 2: Similarly we can see that C++ is considered a high-level language (e.g. https://en.wikibooks.org/wiki/C%2B%2B_Programming/Programming_Languages or https://stackoverflow.com/questions/4380608/c-as-a-high-level-language). &gt; Since I know a couple of people that consider modern C++17 a low-level language, your claim that everyone else agrees that C++ is a high-level language is definitely false. I may have a couple of people that consider Earth flat, but that does not change a thing about the rest of the world.
&gt;You said that &gt; &gt;Rust has some high-level language features, but I don't think that makes it a high-level language. Particularly, because it missing (...) fully-automatic memory management. &gt; &gt;, which can be understood as if all high-level languages had a fully-automatic memory management. Now you are making things up. I said: &gt; it [Rust is] missing a crucial feature that most high-level languages have: fully-automatic memory management. I didn't say that all high level languages must have this feature, **you** did: &gt; all high-level languages must have fully automatic memory management
It thinks (i guess - i can't tell right now, because it is not connected to any host body, so i cannot tell if is it just a noise or not) :D
Amazing. I'm a huge Amiga fan too, and have done a little bit of C/C++ programming for it, although I'll be damned if I could get the Blitter to do what I wanted it to. Love the idea of being able to use Rust. I'll be following with great interest.
If all high-level languages are not obligated to have fully-automatic memory management, why do you then say that Rust cannot be a high-level language because of that precise reason? Or, rephrasing: if there are high-level languages without fully-automatic memory management, why do you claim that Rust cannot be one?
I'm waiting for a template framework that allows dynamic imports in debug builds, and compiling the templates in for release. That would really be the best of both worlds...
&gt;I don't know if this has been done before Not sure how much it helps, but [Free Pascal](https://en.wikipedia.org/wiki/Free_Pascal#Targets) has actively maintained code generators for several targets LLVM either doesn't support at all or only partially supports, including i8086 and m68k (also AVR.)
If only we had a working Rust to Pascal compiler. :^)
&gt; why do you claim that Rust cannot be one? Where have I claimed that ? &gt; why do you then say that Rust cannot be a high-level language because of that precise reason? Where have I said that? &gt; What is this definition then? There certainly must be some. Whether a language is high or low level is a subjective property, so there are many definitions, and everybody has its own, that's what _subjective_ means. &gt; Neither are Java or C# called high-level here) or here), although they are pretty high-level on the chart. See the points about it being a subjective property in this and my previous comment. &gt; On the other hand, I've linked an article that directly says that Rust is a high-level language, but - for some reason - you've decided to completely disregard that fact. I disregard that fact because if I was to argue about what those people think about whether a language is high or low level, I'd have to talk with them and not with you. You can replace programming languages in this discussion with "favorite color" and Rust with blue. You are basically arguing that blue is everybody's favorite color, asking for definitions of which one should be everybody's favorite color, and justifying that "it's blue" because it is the favorite color of some other people. 
It's still fairly normal for TVs to come with the analogue inputs, unless I'm really out of touch. They often only have one or two sets of RCA inputs instead of three, though.
There's Borland's compiler, yeah. However, LLVM optimizes really nicely and produces very small binaries, and I have a hunch that this would end up being bigger. It's a great workaround to the issue of the compiler crashing when trying to build the core library, though.
I have the following problem: **Borrowing References to an outer scope** ``` struct MyStruct { myvec: Vec&lt;ComplexStruct&gt;, } impl MyStruct { pub fn get(&amp;mut self, mystruct: ComplexStruct) -&gt; Option&lt;&amp;ComplexStruct&gt; { for a in self.myvec { if a == mystruct { return Some(&amp;a); } } None } } ``` The error I get is: "cannot move out of borrowed content". I think I understand the error and why this is not possible, namely I already borrowed self and self might go out of scope before the option does. But how do I somehow retrieve a reference to an attribute and make sure that it outlives self? Or is this not possible? My real code is a bit more complex, so I cannot direct access the vector to retrieve the value. since I need to compare to special identifier to make sure which element to retrieve. 
I looked at it and felt it's not quite ready yet for production use, whereas pingncap is more complete. What is the advantage over the other though?
The implementation of `Index` uses parametric dispatch impl&lt;T, I&gt; ops::Index&lt;I&gt; for [T] where I: SliceIndex&lt;[T]&gt; { type Output = I::Output; #[inline] fn index(&amp;self, index: I) -&gt; &amp;I::Output { index.index(self) } } which could dispatch to this - except that the compiler could recognize indexing a slice by a usize as an intrinsic operation impl&lt;T&gt; SliceIndex&lt;[T]&gt; for usize { type Output = T; #[inline] fn get(self, slice: &amp;[T]) -&gt; Option&lt;&amp;T&gt; { if self &lt; slice.len() { unsafe { Some(self.get_unchecked(slice)) } } else { None } } #[inline] unsafe fn get_unchecked(self, slice: &amp;[T]) -&gt; &amp;T { &amp;*slice.as_ptr().add(self) } .... } The `add` method of raw pointers actually does take `usize`. If it didn't an explicit cast would be required. Indexing by `i32` would have to check that the index is non negative. (Rust can't expose C-style negative-offset indexing to safe code because it wouldn't be sound to combine it with `split_at_mut`.) 
The problem is specifically that you're trying to consume `myvec` and iterate over it by value. If you instead iterate over references directly it'll work: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=128d155ecb1ed98112d4a83b31c20a89
Ok...i thought we iterate over instances of object. So that is not possible or not a good idea. Iterators are only for collections or array of same elements? 
The really hard definition of a low level language is that you can determine from the code what the hardware would be doing. I've even seen it argued that [x86 is a high level language](https://blog.erratasec.com/2015/03/x86-is-high-level-language.html). But if you interpret it as a spectrum of higher and lower level languages, it's basically how much thinking you have to do to know what the hardware would be doing, and it's easy enough to interpret that as "how smart does the compiler have to be?" which would definitely make rust high-level. But practically speaking the terms "high level" and "low level" are not very strict and you can make a case for rust falling into either category depending on both how you define the ordering and where along that ordering you draw the line.
Hm, yeah, what you heard sounds about right to me. I was joking a little bit, but... I do feel a bit neglected by MS. For reference, I've been using Xamarin at work for the past ~2 years. It's...complicated. In and of itself, it's got a lot of nice ideas. XAML is great, the interfacing with the Java World works very well, and a lot of stuff from WPF / UWP carries right over (MVVM is a *perfect* fit for this environment, imho). The problems come once you try to actually develop something in it. Now, just a list of things that reaaally get on my nerves: - Compilation times are abhorrent. Really, really abhorrent. We're in the Rust subreddit, so people may be used to this, but seriously. C# has great compile times normally, but *especially* on the Android backend, it's messed up. And after you successfully compiled your app, you need to deploy it. Which for *whatever* reason takes another eternity. - There are some very weird issues with performance. I...don't actually know what the status right now is regarding ListViews on Android, but traditionally, they can easily become laggy when using Xamarin. And there are other cases like that, stuff where you don't think about little details which end up destroying your runtime performance later on - Huge app size. A hello world in Xamarin is....well lol, I don't actually now for sure right now, but in Release configuration I *think* it's about 20, 25mb? Which is pretty insane. It makes sense if you think about it, and it doesn't really matter in a lot of scenarios (B2B enterprisey stuff for example), but still. Ugh. - Constant wars with the tooling. Now, tbf, a lot of this isn't Xamarins fault, but I wanted to mention it nonetheless. Visual Studio is an incredibly helpful tool, but Jesus. There is *no* real way to test your App UI Layouts without deploying and starting the app. Yes, there's a preview. It's been there for some time. It still. Sucks. Big time. There's something called "Xamarin Live Player" which they tried and it was kind of nice but *instantly* forgot about (a **very** common pattern in Xamarin, or MS in general lol)... So, yeah. Go tell your frontend guys they need to rebuild and redeploy the app, start it and navigate to the screen they want to change the font size of to see the effects. Great fun. Debugging &amp; building for iOS is a royal pain in the ass, although, as I said, not really Xamarin's fault and they probably did their best considering the circumstances. Also, they tended to break **absolutely fucking everything** in *every* update, no matter the version number. I say "tended to", because I did get the impression that it's now much better than about a year ago...But it still happens sometimes. All in all, it's a kind of "death by a thousand cuts" scenario. There's just sooo many little things, and it feels...incomplete, left behind by MS. The amount of times I need to clear my Solution, then delete the obj/ and bin/ folders, THEN delete the .vs folder and *THEN* rebuild and wow, it magically compiles now....yeah, too many to even count. **BUT.** It still has a lot of potential. For many cases, I think it's at least not the *wrong* choice to go with Xamarin. I can't emphasize enough how comfortable using XAML and the MVVM pattern is, it's very very hassle-free, easy, obvious and productive software development. The forums are pretty good, you'll find a lot of help there. The performance in general is fine. A lot of things about it are "good enough" that I don't have to mention them, so in general, Xamarin is often "fine". Which is enough for me at least. And of course, you get to work in C# (lol or F# if you're incredibly brave), which is a bonus in and of itself. So, yeah. Do I like it? Kind of. Programming with Xamarin is awesome. Building an App with Xamarin is oftentimes daunting. I think you know what I mean by now :D Would I choose it for a project? Maybe. But I would definitely at least seriously consider it. Just keep in mind the various pitfalls.
&gt; yarte doesn’t seem to adhere to the applicable license terms. And the author views giving credit as a "[waste of time](https://github.com/rust-iendo/yarte/issues/5#issuecomment-465643428)". Such a shame from an "open company" whose first project was primarily copied without permission
You must go deeper :-p So `add` is a method defined as the following: pub unsafe fn add(self, count: usize) -&gt; Self where T: Sized, { self.offset(count as isize) } Indexing with `i32` would be perfectly fine by casting to `isize`, then reinterpreting as `usize` and comparing to the slice length. I don't personally support indexing with the fixed size integer types, but it would be totally possible.
The author is trying to make money off of open source projects, so having a separate one is easier to market 
I read about multi threaded programming in the book. And it was interesting to me, and decided to use it in a side project. The idea is to handle multiple requests simultaneously. I believe multithreaded programming and asynchronous are the same. 
Few months ago a was helping someone on /r/archlinux and received a shitstorm, because I used &amp;#x200B; $ cat ./some_file to print out a single/double line file and was told to use less, because cat is for cocatenating files (who knew). Just wanted to say that :)
Does the author elaborate anywhere what kind of "fundamentals" they're trying to instill using Anki? 
This is a seriously impressive project. Kudos!
&gt; Was this just a design decision Yes, mostly. The compiler would have to look at the signature of `f` to decide whether to borrow each argument. The older, less-smart, borrow checker could have the side effect of restricting your code more than desirable if it automatically borrows arguments. So there is some automatic borrowing, but only in situations where it was decided the improved ergonomics outweigh annoying surprises - self-by-reference methods may borrow self - if you put a local variable (or other location expression) in an argument that's expecting `&amp;mut T` and the variable is already `&amp;mut T`, Rust will implicitly re-borrow the `T` with a shorter lifetime. But other situations require an explicit borrow. Even with the new borrow checker, implicit borrowing would change when values are dropped, and that is a surprising sharp edge which Rust tries to avoid. Dropping `&amp;mut` is a no-op. Dropping `i32` also has to be a no-op because it is a Copy type. But if you have a meaningful drop things get confusing: let g = mutex.lock().unwrap(); something_with_protected_data(g); // is the mutex still locked here? With Rust today, I can tell you "the mutex shouldn't still be locked at that point". The function takes g by value, meaning it is responsible for dropping it when done. If a function doesn't drop its arguments, it should be clear either from what the function does or at least in its documentation. For example, I know `vec.push(x)` doesn't drop x, because transfering ownership is what it does. Since `something_with_protected_data` doesn't have a place to put `g` that satisfies its lifetime restriction it almost certainly drops it. But if `g` is borrowed: let g = mutex.lock().unwrap(); something_with_protected_data(&amp;mut *g); // is the mutex still locked here? I know for sure that the mutex is still locked because `something_with_protected_data` never even *saw* the MutexGuard. I looked at the target of g (`*g`) and created a new unique borrow (`&amp;mut`). And with this: let g = mutex.lock().unwrap(); something_with_protected_data(&amp;mut g); // is the mutex still locked here? Well, that's a little bit implicit. I know that `g` still exists and the mutex is still locked. However, depending on the signature of `something_with_protected_data`, it might be able to see MutexGuard and I dunno, maybe do something tricky with it. That third form is probably the most common in Rust source code today. Rust will implicitly remove a second or higher layer of indirection - in this case it likely converts `&amp;'b mut MutexGuard&lt;'a T&gt;` to `&amp;'b mut T` by invoking `ops::Deref`. 
After the borrow checker has evaluated your code, all that information about lifetimes and their relationships gets discarded. If Rust had no lifetimes, borrowing would be much harder to get right, but the generated machine code wouldn't be any different.
Rasterizing vector graphics is a fairly large problem, so until someone is crazy/dedicated enough pure Rust won't exist. In fact, it's a difficult enough problem that many devices have fixed-function hardware that computes pixel coverage for a set of triangles (a "raster operations" pipeline / ROP). Other steps like converting piecewise polynomial paths to 2d regions by convolving them with a pen (stroking), and curve-bounded regions to triangles (tessellation) need their own algorithms - often different ones for execution on a CPU vs GPU. That said, there certainly was 8-bit microcomputer software that did rasterization on tiny CPUs - that requires imposing conditions and special cases on the primitives (such as no sub-pixel positioning or alpha compositing, often no polynomial curves) or output (needing to support indexed color) but it could be a fun project. If you just want to do something with those graphics, Cairo is probably the way to go.
Implicit borrows have been discussed by the core team as far back as [2013](http://smallcultfollowing.com/babysteps/blog/2013/11/20/parameter-coercion-in-rust/) and more recently in this [2017 post about the ergonomics initiative](https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html#ideas-implied-borrows).
I felt like I tried this before, and then I just tried it a few minutes ago and it now works haha. Thanks a lot! You really saved my day :)
It surprises me that people would be nostalgic about DOS, but I guess my POV is skewed. each to their own. MS-DOS/windows: that horrible software step backwards you had to take after the Amiga, if you wanted to get the 256color byte-per-pixel screen and faster intel CPUs. I'm sure there are people out there who grew up with that platform and have great memories of it. if it gets slightly more rust users, fair enough.
&gt;Please tell me, that with a name like 'cbmuser' the intention is to get Rust compiling code that will run on an OCS/ECS Amiga? awesome and good luck! I'd love to help, write demos or go back to my side scroller etc \*in rust\*, but my distraction list is too long already. &amp;#x200B;
Actually this is an issue I'd like more people to be aware of in todays lazy era - "64bit everything" There's cases in that era of x86 where you want 32bit pointers, and 16bit indices. It might not immediately be obvious but the reason for this mix is the crossover between 'bit sizes', where one is too small, but the other is overkill - so you mix (what they really wanted was a 24bit CPU,etc) IMO we have the same situation today IMO. &amp;#x200B; 32bit isn't quite enough for an 8gb,16gb machine.. but 64bit dresses and indices everywhere are also memory wasting overkills. So 64bit collections with 32bit indices would be a very valid thing to have. This would also play to VGATHER support (which can vectorise exactly that with indexed lookups.. smaller bit sizes = more lanes in parallel) so imagine if the Vec type was parameterised with a default, allowing you to have 64bit pointers with 32bit indices (essentially a compile time limit on capacity) - and for this use case, 32bit pointers with 16bit indices.. and I'm sure the people running on C64's etc would love the option for 16bit pointers with 8bit indices. &amp;#x200B; (i've rolled something like that myself but it was a big pain to do .. lots of cut paste.. i wish the type could be generalised to include it. Vec&lt;T,Index=usize&gt; .. i suppose it might also allow switching to isize which many would like aswell. &amp;#x200B; &amp;#x200B;
Agreed, it seems mostly up-to-date still. I did a double-take when you talked about shipping Rust in Firefox though, and that's what prompted to check the date :)
This is so exciting! I hope to see everyone there. :)
Always love reading about this project. Really cool stuff.
Thanks. I‘m just porting existing C++ code to Rust, but it‘s good to learn the language ...
Thanks ;-)
Ah. Thank you. In that 2017 blog post he was calling it "dropping ownership" which makes sense. Then I looked at the "roadmap tracker" ticket linked near the bottom of the blog post, but "dropping ownership" was not tracked or discussed in the ticket. So as best I can tell it was mentioned, it's not a new idea, but I still haven't found any formal discussion of it.
Thank you!
I belive that there is no memcpy when moving a value into a function as an argument. Rather, a pointer is passed under the covers. TL;DR: They are equally cheap.
This only works for up to 6 input bytes...
I came across this some days ago: [https://restdb.io/docs/rest-api](https://restdb.io/docs/rest-api) it may give you some ideas
&gt;The solution to this is to change your LLVM target to end in “code16” instead of the name of an ABI such as GNU Cool! I wonder how you managed to figure it out? I want to learn how to do it, to be as good as you are. &amp;#x200B;
For many collections, 32 bits size/indices are most likely sufficient. In fact, I would be fine with a standard library opting for 32 bits size: the usecase for storing over 4 billions of elements in a single collection is so rare that it warrants dedicated "large size" collections. *Note: storing 4 billions of `u8` in a `Vec` requires a 4 GB allocation; don't be surprised if the memory allocator barfs up before reaching this point.* On the other hand, one key aspect to consider is that mixed 32-64 bits arithmetic is slower; I am not sure how much this would play.
No idea what the purpose of this is, but it looks great!
Its in the book: https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html In short, enums allow you to express something cane one of a few variations. For example, you can define a Vehicle enum and then have the variations Bicycle, Car, and Airplane.
Does [Cargo: Stabilize Alternative Registries](https://github.com/rust-lang/cargo/pull/6654) being merged mean that companies will be able to maintain their own registry (rather than crates.io) and point their build bots to their internal registry? I considered this to be one of the most significant barriers for adoptions in the corporate world, it would be big news if this was solved!
I'm just thinking you want to rewrite [CouchDB]( https://en.m.wikipedia.org/wiki/Apache_CouchDB ) in rust
It most obviously works well when you want one of a few specific values. For example, imagine you wanted to make a type for representing the `text-align` CSS property, which can be either `left`, `center`, or `right`. In JavaScript, you might do this using strings `"left"`, `"center"`, and `"right"`. In Rust, you might define an enum called `TextAlign` with variants `Left`, `Center`, and `Right`. But more generally, it is a type that could be one of multiple, different types. In JavaScript it is common to create functions that accept values of multiple different types. For example, `new Date` can be given a string to parse or a number representing a Unix timestamp. In Rust, you cannot do something like this. Instead, you could use an enum with a variant for strings and a variant for numbers. (This `new Date` example is a bit misleading because it would be better solved with traits, but the point is that an enum is like a single type that represents one of multiple types).
Big picture for this project is to make AI based on approximated neurobiological solutions for brain activity and to implement use case game about evolving virtual pet/organism that thinks for itself in any real-life-like way. or to fail and find out why, where are the obstacles. Small picture idea of this animation is to help me visualize what is happening in developed virtual brain embedded in virtual host body, trying to stay alive and produce offsprings in virtual environment :)
You can implement `Iterator`s for all kinds of things, as long as you can name a single type `T` for the items the iterator returns and write a `next` function that returns the items as `Option&lt;T&gt;` with a `None` once the iterator is at the end. Look at the std api docs for `Iterator` for the details. In the std library there are many `Iterator`s that are not just iterating over a collection, for example `"foo".chars()` returns an `Iterator` over the characters in a `String`/`str`, `BufRead::lines()` returns an `Iterator` over the lines in some io input. The thing that is impossible about what you were trying to do is that there is no magic way to figure out which instances of a type exists at runtime. If you need some kind of list of your instances you'll have to keep track of them yourself in some way.
/r/playrust
Cool! Definitely interested to see how wasm bindgen helped with the keyboard events. I had a lot of trouble with this on my emulator that I ported to WASM (in Go) https://djhworld.github.io/post/2018/09/21/i-ported-my-gameboy-color-emulator-to-webassembly/
Yep, it's not universal anymore but it's still extremely common e.g. if you go on the bestbuy website, they list 244 TVs, of which 103 have RCA inputs.
Check out a few examples in the standard library. They should give you a sense of how it's useful. The big ones are [Option](https://doc.rust-lang.org/std/option/enum.Option.html) and [Result](https://doc.rust-lang.org/std/result/enum.Result.html), which both work in similar ways, but I'm also a big fan of [IpAddr](https://doc.rust-lang.org/std/net/enum.IpAddr.html) and [Cow](https://doc.rust-lang.org/std/borrow/enum.Cow.html) (Copy-on-write).
Hey man, we've actually chatted before (I submitted some Actix PRs to Askama awhile back). The thing about Askama is that in development, or when working with people who don't grok Rust, you generally don't want everything linked to the recompile cycle. As I saw by peeking at Askama again, it looks like 0.8 has some stuff to help with this, but until then it's kind of a no-go in a larger project for me. :(
I love Ferris, but why is the Rust mascot a crab?
interesting read, may I ask you how long this took you from beginning learning rust to this post?
yeah, I kinda know it's complicated. I was kinda hoping for something pretty simple. Oh well.
I'm actually having a number of issues even running the examples with ggez = "0.5"
Is it really such a big hurdle? Checking out crates from git works fine, and most corporations will have infrastructure in place to host git repositories. What benefits do they get from running a cargo registry?
If all you want is to make it easier, and you won't have to store `FooBar`, then you could just have a function like this. fn foobar() -&gt; impl Iterator&lt;Item = &lt;Bar as Iterator&gt;::Item&gt; { Foo::new().flat_map(|x| Bar::new(x)) } The simplest solution if you do want the struct would just be to have `struct FooBar(Box&lt;dyn Iterator&lt;Item = &lt;Bar as Iterator&gt;::Item&gt;);` and delegate to the inner iterator. Otherwise, you could basically reimplement `std::iter::Flatten` and specialize the types. I believe something like this would do it. pub struct FooBar { foo: Foo, bar: Option&lt;Bar&gt;, } impl FooBar { fn new() -&gt; Self { FooBar { foo: Foo::new(), bar: None, } } } impl Iterator for FooBar { type Item = &lt;Bar as Iterator&gt;::Item; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { loop { if let Some(inner) = self.bar.as_mut() { if let elt @ Some(_) = inner.next() { return elt; } } let x = self.foo.next()?; self.bar = Some(Bar::new(x)); } } } &amp;#x200B;
Very cool. I've been using the DW1000 the last few years in my work and never expected to stumble across a mention on r/Rust!
&gt; Note: storing 4 billions of u8 in a Vec requires a 4 GB allocation; don't be surprised if the memory allocator barfs up before reaching this point. I'd be surprised if the allocator gave a damn about it. Especially if you don't touch the memory and the allocator just has to reserve some vmem (uninitialized or zeroed allocations), OSX will give me a 1TB Vec instantanously as long as it's zeroed, even if the size is provided at runtime. Replace the 0 by a 1 and things get iffier as Rust will actually have to go and fill the memory with ones, which takes a pretty long time and commits the relevant memory. It's not really the allocator which makes trouble though, it's that you start swapping if you don't have enough free memory (or some form of memory compression, x-filled buffers obviously compress ridiculously well: on my machine, creating and filling a 64GB vec doesn't even reach 2GB RSS, though it takes ~80s).
What we do is basically design our custom errors in a way that it is possible to distinguish between something that is caused by the user or an internal error(or else if needed). Almost all errors from 3rd party libs map to the latter. We than use an `ApiError` on the edge from the inner application logic to the web framework which can be converted into a JSON response. In many cases a `From` implementation is sufficient. Sometimes one wants to use specific `StatusCode` on the edge. I started a small project to do exactly this: [HttpApiProblem](https://crates.io/crates/http-api-problem) There is also an ApiError in there that can be enabled via a feature toggle that can be converted to an `actix-web response`.
Seeing that list of supported targets (from 8086 to JVM to RISC-V) almost makes me want to start writing Pascal code.
How does semver works if you're using git ? Idk about cargo/crates.io but with npm this was the main motivation we had to set up our own registry.
Next step: Convince your work to use Rust :-)
It's not unique to Rust, it's used in a large number of other languages as well: https://en.wikipedia.org/wiki/Enumerated_type
Thanks. So do you use ApiError within all application layers or only in HTTP handlers?
Only in the handlers. The goal is to keep HTTP out of the application logic/layers. So basically one can say to use it where you would say "this part/layer of code is HTTP/webservice related". Another advantage of having a single error in the HTTP code is that you can easily return it from authorization code etc. and the errors always match. 
Yeah, I remembered your name! Just wondering if there is something I can do to make Askama easier to use/more appealing for your projects. I just (finally) released 0.8.0, so I hope that helps with your use cases.
To be quite clear, copying without permission is totally allowed. They only thing they're required to do by Askama's licenses is give credit to the upstream project.
&gt; You must go deeper :-p Bwaaaap! &gt; I don't personally support indexing with the fixed size integer types Do you know if there's been a rejected RFC? I've been looking for a discussion and haven't found it yet. 
On this subject I prefer composition than inheritance, although a functionality similar to the one described is not discarded.
It's actually the [unofficial mascot](http://rustacean.net/) and it comes from [c**rust**aceans](https://en.wikipedia.org/wiki/Crustacean).
yeah, I prefer the same approach. So, for example, you have defined a single Error type for application layers with ErrorKind variants. Then you can convert different ErrorKind to correct HTTP status code.
It makes it possible to use registry but AFAIK there are no good tools to create and maintain them. I was working on a solution for a while but stopped here: https://github.com/rust-lang/cargo/issues/4497#issuecomment-454222681 and not sure if I'm going to continue the work since it may be not worth.
Can you just check out tags or branches? You could maintain semver that way, although it's a little harder to check when a new version has come out.
Definitely, which is why I included "without permission", although "without proper attribution" would also work
I've been waiting for this! Hoping I'll be able to come!
&gt; a functionality similar to the one described is not discarded. You lost me there. Is Askama inheritance still in the template format somehow?
Wouldn't incremental compilation make this less of a hassle? Do templates really change *that* frequently compared to application code?
Exactly. The trick is to avoid being too detailed with the error kind pattern. It turned the level of detail in the errors(the error kind) reduces the more you move to the endpoints. 
This was actually the talk that got me into Rust! Thanks for sharing it again. It was the first time I heared about Rust, and I was hooked after "fearless concurrency". A language as low-level as C with familiar and high-level syntax, strong static typing, that doesn't allow memory errors AND is thread safe? That was basically the manifestion of a dream at that time. It was love at first sight \^\^
As mentioned, a traditional linked list requires scattered allocations which make each node distant from each other. This leads to cache misses for each traversal of a pointer in each node. A single arena allocation keeps each node together in the same region of memory, leading to significantly faster lookups. CPUs today aren't designed for the traditional linked list.
Oh wow. You did a lot more performance profiling than I did. I just got it kinda close to 60fps and called it a day. I'm surprised you had so much of an issue constructing an imagedata and using the canvas api as that's exactly what I'm doing and it seems to work ok. Though "ok" may be a stretch. I don't actually get 60fps, the frame rate is inconsistent, I haven't tested in Chrome, and my controls are a bit squishy. wasm-bindgen made handling keyboard input a breeze. All I had to do was define some callbacks in my rust code like this: #[wasm_bindgen] extern "C" { #[wasm_bindgen(module = "../index")] fn key_down_callback(f: &amp;Closure&lt;FnMut(web_sys::KeyboardEvent)&gt;); #[wasm_bindgen(module = "../index")] fn key_up_callback(f: &amp;Closure&lt;FnMut(web_sys::KeyboardEvent)&gt;); } In other words, I'm passing a rust closure to js. On the js side my code looks like this: export function key_down_callback(func) { document.addEventListener("keydown", event =&gt; { func(event); }); } export function key_up_callback(func) { document.addEventListener("keyup", event =&gt; { func(event); }); } The rust closure that I pass to JS just matches on the web_sys::KeyboardEvent keycode and tells the emulator to react accordingly.
Cool. So do you define ErrorKind with some common variants, like NotFound, Internal, BadRequest and etc? and not too detailed like UserNotFound, EmailIsNotValid which maybe be used once...
There is a tremendous difference between a move and a borrow. A borrow creates a pointer; all access to the object is done via that pointer. The existence of the pointer *does not* alter the lifetime of the pointed-to object. By contrast, moving an object copies the bits to a new place, and the lifetime of the object is now determined by the lifetime of the new place it has been moved to. That lifetime may be shorter or longer than the previous lifetime, had the object not been moved. These lifetimes are visible to you, because the lifetimes affect when Drop::drop is called. 
I haven't found an RFC, but there seems to be some discussion [here](https://github.com/rust-lang/rfcs/issues/2249). I think a great argument *against* indexing with types other than `usize` would be breaking countless lines of existing code that rely on type inference :)
Yes. But mostly even simpler. Let's say you call an HTTP service or a database somewhere. On that level some detailes like "is the error IO related", "does the other side return an error and maybe whats the staus" are interesting. But the layer that uses that code might already be fine if it just returns error kinds like "InternalError" and "InvalidArgument"(in specific cases there may be more). That's already sufficient to decide for the status code on the API level. Basically we have a message in the error kind and use the "causes" of failure to log properly. In most cases even the message from the error kinds are just logged because you need some customized message you can pass to your clients anyways. 
Nice! Yeah I suspect my issues were 90% my fault for not really understanding what I was doing and could probably be improved with a bit of refactoring. I think what happened was, I coudn't get the emulator running on the main thread properly so I found web workers and went all in - which was probably my downfall! 
huh, AmigaOS uses COFF I'd like to see a Palm OS 4 target :D
How do you deal with the translation of inheritance? I glanced at your code but I couldn't figure out for sure what your strategy is. I ask because in the PBRT book they talk about using abstract base classes. I looked for an `Integrator` trait, but I couldn't find it. Instead I found the `SampleIntegrator` trait. Did you merge the interface of abstract parent class with the child in this case?
Whoo! I'm really excited to see i18n support land, too. Pretty important for projects here in Germany 
It seems like you probably need `poll_read` and `poll_flush` from the `AsyncWrite` trait: https://tokio-rs.github.io/tokio/tokio/net/struct.TcpStream.html#impl-AsyncWrite
&gt; I think a great argument against indexing with types other than usize would be breaking countless lines of existing code that rely on type inference :) Ooo, shoot I hadn't thought of that. Yeah, that's a pretty big one. It's not insurmountable, but it means adding another special case to the compiler. I'm not a fan of negative indices being enabled across everything a la Python. The buggy example by ExpHP: def last_n_items(xs, n): return xs[-n:] is fixed simply by translating it the most obvious way into Rust. fn last_n_items&lt;T&gt;(xs: &amp;[T], n: usize) -&gt; &amp;[T] { let start = xs.len().saturating_sub(n); return &amp;xs[start..] }
You mentioned that you you told programming interviewers about your gameboy emulator project. Can I ask you how that went? I'm working in a totally different field right but now but I always wondered I "had what it takes" to get into being a programmer.
ok, thanks for the explanation. I will use the same flow.
Today I learned that the `-Z unleash-the-miri-inside-of-you` option exists
not to mention you can get rca to hdmi adapters
Yeah you want to be running off of git master. :/
&gt;almost makes me want to start writing Pascal code. &gt;I only started using it for a few things here and there recently, but I find it pretty nice. It's kinda like C# without the garbage collector, if C# was also able to act like C when you wanted it to.
Haha, that was just a silly comment. Usually in software engineer interviews they ask you to talk about projects etc you've done that might not be related to work, I've often just used my gameboy emulator as the anecdote. Unfortunately it's quite easy to keep using that anecdote if you don't have many projects like me! 
Judging by [these](https://github.com/Shizmob/gfxi) [two](https://www.thpatch.net/wiki/Development_notes/PC-98) search results, Open Watcom C/C++ can also target PC-98 and it'd probably be a better choice. Back in the day, Watcom C/C++'s competitive strength was that it had the best optimizers, while Borland had faster compile times and a better IDE, and Microsoft had better documentation and the advantage of being the creators of MFC. These days, Open Watcom has some *very* attractive strengths as a one-stop shop for a retro-computing compiler: * It's free and open-source * It still includes DOS/4GW with the blessing of its creator, who was gearing up to track down a more recent release of the DOS/4GW source to donate when he passed away recently (DOS/4GW = "DOS/4G, Watcom Bundle Edition") as well as three other, superior but less nostalgic DOS extenders. (DOS32A, PMODE/W, and CauseWay) * A single install gets you cross-compilation to all supported targets, which makes it very easy to compile without using emulation on a modern CPU for lightning-fast edit-compile-test cycles. * It supports over a dozen different targets. (`.com`, real-mode DOS EXEs, DPMI EXEs, 16-bit OS/2, 32-bit OS/2, various flavours of 32-bit Novell NetWare, Win16, 32-bit extended Win16 via Win386, Win32s, Win32, Linux, and possibly QNX... though I don't remember if they had to drop that from the Open Watcom releases for licensing reasons.) * While not specifically relevant for DOS, it inherited Watcom 11's superior knock-offs of the tools from the Windows 3.1 SDK, as well [Win386](http://www.os2museum.com/wp/watcom-win386/), a DPMI extender-alike for Win16. (essentially a Win32s before Win32s that gets bundled into your EXE. Sierra and FoxPro use it.) * It's got a Make implementation named WMake with platform-identifying defines that makes it easy to develop a codebase that builds under both DOS and more modern platforms for testing purposes.
It was meant to decode the base 32 into 32 bit identifiers
Rust enums are more powerful than enumerated types as described in this article. They're sum types, and enumerated types are a special case of sum types. [relevant article](https://en.wikipedia.org/wiki/Tagged_union)
Watcom's linker is OSS... it just has a quirk in its license that keeps Debian and Fedora from including it in their repositories. To quote the Wikipedia page: &gt; The Open Source Initiative has approved the license as open source, but Debian, Fedora and the Free Software Foundation have rejected it because "It requires you to publish the source code publicly whenever you “Deploy” the covered software, and “Deploy” is defined to include many kinds of private use."[5] (When you "Deploy" Open Watcom itself, not what you compile with it.)
They're not the same. Multithreaded code is asynchronous, but asynchronous code can also be singlethreaded.
Yeah my dream is to make a tiny NES game in rust. Sadly LLVM backend for that arch likely will never exist. (There were a few failed attempts but none went well afiak)
...though, depending on the games you're playing, the TV might not like particularly esoteric resolutions or might impart too much upscaling latency unless you throw in something like the [XRGB-Mini FrameMeister](http://junkerhq.net/xrgb/index.php?title=XRGB-mini_FRAMEMEISTER). (The FrameMeister is a box which takes analogue input and, imparting very little latency (20ms with firmware 1.10 and it has dropped since, according to the page I linked), outputs a high-quality upscaled HDMI signal to bypass the quality and latency concerns with the upscalers built into HDTVs.)
&gt; However, LLVM optimizes really nicely and produces very small binaries Hm, but this workaround remove only arch specific optimizations, as I know the most of optimization works on IR level, so you can still use them with such workaround.
Is rust better fit to implementing Neural Network from scratch (with GPU parallelism) than c++ (i know c, but not c++)? Is it easy to wrap the low level code in something like python? 
Soon you'll be wondering how you could have ever lived without it. :D
You have an empty item 4 in Bindgen section.
I'm myself trying to grok Tokio, but I think you should be able to use the BytesCodec to create a Framed stream of chunks (from the tokio::file::File), which can be sent to your tcpsocket using Framed and BytesCodec. See Sink.send_all.
As someone who has never programmed or really looked into Javascript, my main thought is "wait Javascript doesn't have enums?"
Thanks, I thought I already fixed that.
Would you mind elaborating on your Askama dev experience with non-Rust programmers and how it motivated you to use Tera instead? What was wrong with the workflow?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/h_n] [DOS: The Final Frontier](https://www.reddit.com/r/h_n/comments/asufn0/dos_the_final_frontier/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
The real Quote of the Week was from elsewhere in that same article: &gt; At some point you will find yourself in a situation where you're passing a reference, the borrow checker tells you that the lifetimes are unclear, you start sprinkling lifetime annotations all over your entire code base, next thing you know you're wrapping things in Box and RefCell and stuff is getting weird.
On my MacBook (with fast SSD), some programs actually even run OK with huge allocations. I had an application at work which would hold all of it's data in memory (a bad design - but that's a separate issue!), and it would run fine with 56gb allocated on my machine with only 16gb of physical RAM.
map is transforming each part of the line into an integer i.e given a string "1 0 2 5" split_whitespace makes an iterator yielding "1" "0" "2" "5" map takes each element yielded by split_whitespace, and passes it into the closure, which turns each string into a number, then returns that. So overall map yields 1 0 2 5 The unwrap looks at the Result that parse returns and checks, is it Ok, if so, return the value, otherwise panic. This way you can get the value out of the parse, but you will panic if you get invalid data.
Sounds like you can use [loop\_fn](https://tokio-rs.github.io/tokio/tokio/prelude/future/fn.loop_fn.html) function
&gt; Why do so many new Rust users decide to immediately tackle tokio? In my case it solved my immediate need of building a cross platform input device server. Getting started was a pain (made worse because my project had generated files) but once it worked it was pleasant to work with because of the various support crates for tokio; for instance throwing in udev hotplug event support took maybe a minute or two having no prior experience. I suspect this is a more common pain point which is underserved by existing unmanaged memory languages and really only solved when similar libraries can trivially share common primatives.
&gt;because the type of the future contains all previous futures, the number of futures I create must be known at compile time This isn't true, you can use dynamic dispatch using boxed futures. However, I don't think that's what you need here; you might be able to break a file into parts and send it that way, in which case you'll be able to send other packets while you're transferring a big file. But yeah, see [tokio::codec::length_delimited](https://docs.rs/tokio/0.1.15/tokio/codec/length_delimited/index.html) for a very easy way to let you create your own protocol. You'll get a `Sink` that you can send whatever packets you want with. I suggest using something like bincode or cbor. Of course, it's still possible to _just_ send a file using `.write_all()`; usually this is done like this: stream::iter_ok(bytes_to_send) .fold(writer, |writer, buf| { tokio::io::write_all(writer, buf) .map(|(writer, buf)| buf) }) Since the `write_all` call returns the writer, you can use it as an element to fold over.
Tera is an actual templating engine, Askama is compiled Rust code. They’re slightly different in that it’s easy to completely reload the templates for Tera without recompiling the entire project, Askama not so much. It means your turnaround time on design iteration is linked to compile times. Note this may be better in Askama 0.8 so take it with a grain of salt...
Phew, well, that's one bullet dodged for me! I've been making that joke for quite a while :).
Glad to hear that :). Thanks!
One of the nice things about Rust is that you can do some pretty cool stuff with terse code, once you get a feel for it. But, when you're learning, terse isn't helpful, because it obscures things. So try this: for every bit that you don't understand, break that bit into a separate variable, with an explicit type. It'll help you unpack what's going on. `br.lines()` has a return type: it returns Lines, which is a struct that implements the Iterator trait, which is why you can use it in a for loop. This particular iterator produces a `Result&lt;String&gt;`. `Result` is a type used to indicate a return value that might be an error. that `let line = line?;` bit uses the question-mark operator to propagate the error, and unwrap the result if there's no error. You end with with `lines` as a String. Later on, when you call `.unwrap()` on the `Result` returned by `parse`, you're doing something similar, but this time you're saying, "Panic at runtime if this Result is an error". That leave us with your call to `map`. `map` is a method on `Iterator` which is a trait implemented by the return value of `split_whitespace()`. It transforms each item in the iterator somehow. In this case, you're parsing strings into `i64`s. You should probably spend some time with [the Book](https://doc.rust-lang.org/book/index.html).
I've found it helpful for myself to think of structs and enums together as a type system version of AND/OR. Not sure how correct this is - hopefully someone more experienced can chime in. When writing an enum or a struct you are combining a bunch of simpler types into one compound type. By writing `````` struct NewType { field1: Type1, field2: Type2, field3: Type3, } ````` you are creating a `NewType` that contains a `Type1` AND a `Type2` AND a `Type3`. By writing ````` enum NewType { Type1, Type2, Type3, } ````` you are creating a `NewType` that contains either a `Type1` OR a `Type2` OR a `Type3`. Using these two tools you can combine the fundamental types rust includes in the standard library to express complicated parts of your program within the type system. You'll sometimes hear people talk about sum and product types. Hopefully the and/or analogy makes this connection clear. 
Me to! Kazimuth just kind of showed up and started making it happen. 
r/playrust
Unless rustc started banning people for using hacks, I think you are in the wrong subreddit. I think you are looking for r/playrust
Alternatively, 64-bit vectors should never need to reallocate.
shhhhh i totally knew that uhhhh.... yeaahhhh
Thank you very much for your detailed answer!
Do you want `flatten_stream` instead? I'm not sure why you'd return a boxed stream as the result of a future, and then convert the future into a stream whose success value was another stream.
I think I'm just not sure how to compose the operation I'm trying to do. The goal is to return a stream, but what's in the stream is dependent on the eventual result of a future.
I'm only 21 users old, but my nostalgia for MS-DOS comes from playing around with old computers that people kept giving me as a kid. I didn't discover anything like the Amiga until I was older.
I wasn't able to get your version of the program to compile, but here's a [somewhat different version](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1e98bacc47e325211acb5ef24f9caca2) that ought to work. The main changes I made were to simply do an `unwrap()` in your `main` function since that's pretty much exactly what your `match` block was doing anyway. I also noticed that your `read` function has multiple failure modes: in addition to IO errors when reading the file, there is also the possibility for parsing errors. So I changed the function so that it can return both kinds of errors. Finally I couldn't get a straight-up iterator version of your read-parse loop to work because of some borrowing issues (I think it's because a `BufReader` only has so much of the file in memory at a time), so I used nested for loops and some temporary variables instead. I also commented each place where I made changes, so hopefully they help make things a bit more clear.
Thank you so much. How did s.parse() know to convert to a integer?
A local or semi local caching registry can be a big bandwidth, availability, or security win. 
That's the magic of type inference at work. At line 26 you create a `Vec` and at line 41 you insert into the `Vec`, and since the function returns `Result&lt;Vec&lt;i64, Box&lt;dyn std::error::Error&gt;&gt;`, the compiler works backwards and realizes that the `Vec` you're working with is a `Vec&lt;i64&gt;` and therefore the thing you wanted to `parse` into is `i64`
Hehe, I wouldn't brag too much about figuring that out when it took me so long. It actually struck me as a bit odd that the CPU would be able to run 32-bit code just like that in real mode, but I dismissed the possibility that my target was wrong because it *sort of* worked regardless. Also, the [tutorial for compiling C for MS-DOS with GCC](https://nullprogram.com/blog/2014/12/09/) didn't do that, although I wonder if the compiler picked up on the assembly directive at the beginning of the file, or maybe just inlined all of the functions (the latter seems like a stretch when he managed to make an entire game, but he did mention that he was constantly struggling with the optimizer, which was just like what I was experiencing, although it seems like he might just have been talking about volatile memory accesses being optimized away. I then read something on the OSDev wiki about the “operand size prefix” need for 32-bit instructions in real mode, and I remembered hearing about the “-m16” flag years ago and got it generated code which wasn't really 16-bit. It occurred to me that maybe this flag caused the compiler to simply add this prefix, so I looked it up, and it seemed promising, and it turned out that LLVM had a target called “code16” that went with it. When I got back home after reading about this while out, I tried it and it solved by issues.
That all sounds very attractive, actually. I've used it before, but I didn't know everything on that list. If I try the C backend down the line, I'll be sure to try using it with Watcom.
Huh, that's certainly a weird quirk. It's fairly small, but I know how seriously repositories have to take licences.
That's true, I forgot about that part. Well, I'll definitely take a look at the C backend the next time I want to compile Rust code to a platform that it wouldn't otherwise support, and maybe even try using it with MS-DOS sometime.
Need to identify a workflow for rapid iterative design of templates without the overhead of a full recompile. How to decouple in a project to do this?
You know you can delete threads right?
Instead of having the AppError trait return HTTP errors directly, you could have it return some data structure that the server code knows how to turn into an actual HTTP error.
Exactly, that’s crazy, but if I’m not mistaken Python lacks them too.
The quick and easy functional way: let result: Result&lt;Vec&lt;i64&gt;, ::std::num::ParseIntError&gt; = fs::read_to_string(path)? .lines() .flat_map(|line| line.split_whitespace()) .map(|integer| { let integer: &amp;str = if integer.ends_with(",") { &amp;integer[..integer.len()-1] } else { &amp;integer }; integer.parse::&lt;i64&gt;() }) .collect(); println!("{:?}", result); 
TypeScript has them IIRC. You usually don't need enums with a dynamically typed language.
Every variable is a tagged enum. You can redefine them whenever you want to whichever type you want. if (var === "3") console.log("whatever" else if (var === 7) console.log("whichever")
HandleMaster#9723 Discord
Typescript doesn’t have sum types. What it calls “enums” are like Rust’s enums, but variants can’t have data associated with them. It also has union types, which are like enums but without the tags.
This might help https://github.com/sn99/rust-ffi-examples,specifically https://github.com/sn99/rust-ffi-examples/tree/master/cpp-to-rust
Wow, thanks for that detailed reply. You clearly are in a passionate love/hate relationship with Xamarin. It's good that I now know all the downsides to not scare me away right away. But yeah- I hope MS continues to invest in Xamarin. If one company can do cross platform right, it would be (ironically?) Microsoft. Plus usually their tools are good quality so fingers crossed they bring Xamarin at par. Thanks again and I hope you have a great luck with Xamarin soon. 
[removed]
Not in the language itself, but Python has an `enum` module: https://docs.python.org/3/library/enum.html Of course, it's not the algebraic data type kind of enum like Rust, just the more basic kind. And python has nothing like Rust's `match`.
I don't see a link to any code here. It would nice if you created a GitHub repo or similar with whatever this involved. I know there might not be that much to add, but just the target specification file, and a simple example could be helpful to anyone who wants to try the same.
A few git deps aren't too bad. Several hundred (transitively) are awful. Git clone is one of the most stressful things you can do to a git host, remember that for the most part you don't clone just the files at commit, but the whole repo (ironically shallow clones can be [more expensive](https://blog.cocoapods.org/Master-Spec-Repo-Rate-Limiting-Post-Mortem/) in the long run) bringing along excess history. Not only that, but git repos are lots of small files that are read from random locations. And there are some bad inefficiencies in the git protocol that mean the rpc traffic for requesting objects is [excessively chatty in most cases](https://opensource.googleblog.com/2018/05/introducing-git-protocol-version-2.html), this has been fixed in git upstream but there are a lot of really old git clients running around (I'm looking at you git 1.8 in rhel 6). I admin GitLab and Github at a former employer, clone traffic from package managers (specifically bower) forced us to need servers 4x, and 2x the recommended for our user counts respectively: even then, they'd still choke if CI run coincided with a user clean `bower install`. Compare this two a typical package registry which for the most part is a small api query layer, and a CDN that serves nicely sized tarballs. Caching the packages is trivial and there are dozen of tools out of the box to do it. Last but not least, if you run your own registry you can use all in one tools like artifactory or nexus, which have security scans and license policies integrated into them.
Is there a module for AES encryption or no?
Sure, I can add what I have so far in a bit when I get back to my computer.
Why not SG :(
You cannot specialize impls yet, that is waiting on [specialization](https://github.com/rust-lang/rust/issues/31844)
I noticed that you have `none_if_string_is_empty(s: String) -&gt; Option&lt;String&gt;` and `none_if_str_is_empty(s: &amp;str) -&gt; Option&lt;&amp;str&gt;`. You can actually combine these with the `AsRef` trait so the final would be like: pub(self) fun string_to_option&lt;Asref&lt;str&gt;&gt;(s: T) -&gt; Option&lt;T&gt; { if !s.as_ref().is_empty() { Some(s) } else { None } } Otherwise, since all of the callers of the `str`versions convert the `str` to a `String` then you could just get rid of one and convert the `str` to `String` before calling the function.
This contains only `c` example. I am looking an example with `c++` features like classes.
You can actually have tagged unions, they're just a bit clunky https://www.typescriptlang.org/docs/handbook/advanced-types.html
Ooh, I much prefer this - thank you!
As someone who has only ever lightly used Jinja, can someone explain to me why people care so much about template engine performance? They always seem to advertise their speed.
Things like classes aren't usually exposed via FFI as far as I know. Usually the C ABI is the way to go. Perhaps you could do some trickery by wrapping C++ classes as C functions and passing around pointers to C++ classes to said C functions.
Alright, it's up now.
To some extent CouchDB feels similar, but again it's a nosql db with REST interface. With changing trends in the Web Service techniques, it's necessary now that the DB engines and interfaces, the way we interact, do crud operations and how data is represented should change.
Thanks
Should someone who understand basic programming concept learn rust? Is rust beginner friendly?
The method that Jinja, askama, handlebars, etc. use is called 'server-side rendering'. As the name implies, the server has to burn compute cycles to build the page. When you're trying to handle hundreds of connections at once, those compute cycles matter. Minimizing render time reduces load and allows more connections. 
You can't, not directly. You need to wrap the Rust in a C API then wrap the C API in a C++ API. As a shortcut you can actually forward declare the C wrapping code (just mark the functions `extern`, compile the C++ code in a build script, and link against the rust lib. You get one binary with a C, C++, and Rust API. Just make sure you compile it as a cdylib or staticlib crate, rlib and dylib don't make sense to C+++ compilers. 
I'm creating a thing to help people in the blockchain space become more familiar with Rust and learn the concepts that are unique to Rust and not other languages. Starting with macros!, traits: T, and 'lifetimes, but more stuff will be added soon. I'm just winging it, but figure the explanations will get better over time as people ask questions and correct my mistakes. If you guys know any good resources that explain the concepts unique to Rust that are not in other languages that would be awesome :) btw here's where I'm starting to explore/explain that stuff: https://www.reddit.com/r/dot/comments/asuwrr/rust_reading_rainbow/
Okay, it seems like you can actually point out of a segment with a 32-bit pointer sometimes without it crashing or doing anything. I really don't understand exactly what's going on here, so I'll leave it at that for now. When I'm more experienced with DOS programming in Rust, I'll probably know. Ask me on Discord if you ever run into issues and I'll try to help.
Yeah. I'm poking away at a DOS hobby project and I'm quite enjoying Open Watcom. In fact, there's an aspect of WMake that I forgot to mention. It also implements internal versions of certain commands so you can write things like `rm -f *.o` and have your `clean` task still work in DOS as long as you don't pass options that force it to fall back to the system-provided version. (See the [tools guide](https://open-watcom.github.io/travis-ci-ow-builds/tools.html#Command_List_Execution) for more details on that, but be aware that the `-r` option for `rm` was added in the 2.0 fork, so Open Watcom 1.9 doesn't have it.)
A huge plus for Jinja is that Django templating is very slow by comparison — it can actually significantly add to response times. The same can be true for Askama vs. Handlebars. As shown in [these benchmarks](https://github.com/djc/template-benchmarks-rs/blob/master/README.md), the difference can be pretty stark. If my web server is serving responses in ~1ms otherwise, every bit will make a huge difference in efficiency. 
Different people are going to have different opinions about this of course. Mine is that if you have a strong grasp of any other programming language, I think learning Rust is a great idea. But I don't usually recommend it as a first language. (I prefer to recommend Python.) Rust tends to front-load a lot of concepts, such that your programs won't compile until you understand all the concepts involved. That's great for writing correct software, but I think most people learn better when they only have to learn one thing at a time.
This is awesome! Thanks for the hard work :)
Saying the same thing a different way: Both allow you to mutate the isize at the location x is pointing to. But only the latter allows you to replace x with a pointer to a different location. Example: let mut a = 5isize; let mut b = 6isize; let mut x = &amp;mut a; x = &amp;mut b; That final assignment requires the `mut x` above it.
Cool, I am sure our HR team will respond accordingly. Thanks for your interest. 
You don't have to discuss or mention the project. Thanks for the information. We'll continue to make improvements.
Does anyone know of any tutorials or resources that focus only on the concepts that are unique to Rust and not most other programming languages?
If people don't understand the current description how are they supposed to offer a better one?
I'm an electrical engineer by trade the only pc programming language I know we'll enough to claim is C++. I've never really used a dynamically typed language other than recently had to do some VBA stuff for work. I guess it makes sense though that you wouldn't need them though.
You missed adding static to the println!. Great article. Saved for later use.
I'm not the author!
Nice. I don't want to have to resort to C for writing the software itself, but if a C compile can give me these goodies, I would definitely consider adding Rust-to-C compilation into the pipeline.
Hello there fellow EE! VBA is all over the place in the semiconductor world, usually because there are just so many spreadsheets.
Regarding type level "and" and "or", that's exactly right. Product types (i.e. structs) and sum types (i.e. rust's enums) are isomorphic to conjunctions and disjunctions in logic. This is the Curry Howard isomorphism.
In my opinion it only really makes sense when you understand pattern matching. The fact that your control flow is part of the extraction of data from the enum makes it super useful. Here is an example https://gist.github.com/FreeMasen/7c641964f9ef0c4e04e3ecb1b293e844 I wrote those both on an iPad late at night so if there are any syntax errors I apologize but will try to fix in the morning. I recently saw that there is a WIP proposal to add pattern matching to js https://github.com/tc39/proposal-pattern-matching
&gt; const generics That's definitely the Nr1 missing feature to make Rust great on embedded. I worked around it a few times with constraining types with \DerefMut&lt;Target=[u8\]&gt;` and passing `[T; 32]`, but that's doesn't really propagate well throughout a codebase, and is even unsafe for some uses (where one really wants a plain-array type). Looking forward to const-generics. The just propagate a plain numbers version is totally sufficient for all my use-cases. &gt; The current implementation of core::fmt uses trait objects and function pointers to make all uses of core::fmt fast to compile but this makes core::fmt impossible to inline which makes no_std programs that use formatting large in (binary) size. It might be possible to leverage std-aware Cargo to fix this: we could add a Cargo feature to core to replace the current implementation with one that's fully inlineable but as featureful as the current one -- this should produce smaller binaries. I'm surprised by that. Wouldn't going away from dynamic dispatch increase the codesize even more, since inlining and momorphization creates more code and duplicates?
Good catch! It's fixed now.
Sometimes someone from the outside can provide an objective critique and perhaps write a better description. 
The example is a little hard to follow. Are you looking for the following struct Sentence{ words: Vec&lt;String&gt;, } impl IntoIterator for Sentence { type Item = String; type IntoIter = std::vec::IntoIter&lt;std::string::String&gt;; fn into_iter(self) -&gt; Self::IntoIter { self.words.into_iter() } } https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a0125b4b3263e38da5a0c409d98b4600 But if you are just starting out it is probably easier to make the fields public. Then you don't need to implement the trait struct Sentence{ pub words: Vec&lt;String&gt;, } for word in sentence.words { println!("{}", word); } 
\*nod* Unfortunately, my current project is a little less suited to Rust, so hand-written C it is. (It's an installer builder that should be compact enough to be used for software distributed on floppies without crowding out the actual product and efficient enough to perform without visible slowdown on an original IBM PC. I'm going as far as writing my own FFI wrappers around BIOS APIs using snips of inline assembly to avoid paying the base overhead of the more general-purpose abstractions provided by Watcom's libc.) Otherwise, I'd probably be using Free Pascal's DPMI target and Turbo Vision port.
Good point. I should have thought of that, I suppose; the examples that came to mind were more convoluted. Looking at what uses the spin crate (https://crates.io/crates/spin/reverse_dependencies), a lot of it is nostd stuff (unsurprisingly). `lazy_static` tops that list, but it only uses `spin` for nostd. `ring` uses `spin` on platforms other than iOS. For programming using `spin` (or another spinlock crate), the crate could be probably patched to use a method a method that involves yielding to other threads. I presume that should be possible without breaking things? So yeah, definitely some things will break. But it seems hard to predict how much will be broken, and how much will be difficult to fix without preemption. I don't if there have been other ports of Rust's std to targets with non-preemptive threading? I think a fair number of people have done at least partial ports of std to odd targets, so likely someone else has tried.
Personally, I'm using doing something weird and using Askama to generate only static HTML pages... about 150,000 of them. Having it take 3-5 seconds is *real nice*. I started with Tera, which is lovely but took 3-5 minutes IIRC. The tradeoff you make is having to recompile your program when you change a template; Askama templates are basically compiled into your program.
My main bit of advice as someone who builds databases is to really nail down what you mean by "would also satisfy ACID properties to some extent" to a very precise definition. This is the core property that all design will flow from, and it will be the property that will be the most expensive to change over time. Also, be very specific about whether you want to target sharding from the beginning or not. Do you want to support huge datasets? Do you want to be able to do transactions across items on different shards? Do you want your transactions to be strong enough to seem like they happen at a single atomic instant? Do you want to support usage from phones or devices that are sometimes disconnected from the network? Do you want to be able to synchronize multiple systems without any leaders or strongly-defined membership? &amp;#x200B; With databases, the interface is the easiest part to change. From a developer's perspective it's usually the most important, but from an operational, design, and implementation perspective it's not as important up-front. &amp;#x200B; If you don't care about any of the details below the REST interface, I'd recommend you still try to answer the questions above and then build a nice interface on top of an existing database.
Perhaps I'll look into it; though I have a lot of languages I generally intend to look into at some point. I've never really looked into Pascal; but I've taken a bit of a look at Ada (which has a Pascal like syntax, though a it's a different language). Like Pascal it seems to mostly be viewed as an old language that isn't really relevant (outside narrow areas it's still used), but nevertheless it has newer standard with modern features, and Ada is interesting due to it's unusual focus on safety (like Rust, though not necessarily in quite the same way).
Great to see this continue, I loved the old posts.
It just costs half of what my C64 did back in -85. :-)
There is an existing VCS called quilt: https://en.wikipedia.org/wiki/Quilt_(software)
Porting our blockchain core node software over to rust. Used tokio for the networking and is able to maintain stable connections with the network. Next stop consensus and a modified merkle Patricia trie https://github.com/elniallo/tokio-experiment
For static site generators it's really nice to have very quick site builds, which feels like a similar use case. I use Hugo right now because it builds my sites in under a second even on my 9 year old computer.
Everyone who shares this sentiment, please head over to https://github.com/djc/askama/pull/211 and help us figure out the best possible API for this, please! 
Thanks, that's a really good bit of advice. To answer your question yes it's not just about the interface, rather more detailed reorganization of the underlying layers and functionalities. Considering support for replication of date out of box, easy querying techniques, etc. 
To be fair, I understood the same exact thing as him. Rust doesn't have memory management and thus isn't a high level language.
**A WORKING EXAMPLE:** toml: `[package]` `name = "test_it"` `version = "0.1.0"` `authors = ["Israel Shainert &lt;israel.shainert@3dsig.com&gt;"]` `edition = "2018"` `[dependencies]` `serde = { version = "1.0", features = ["derive"] }` `serde_derive = "1.0.88"` `directories = "1.0.2"` `serde_json = "1.0.38"` code: `use serde::{Serialize, Deserialize};` `use std::fs::{File};` `#[derive(Serialize, Deserialize, PartialEq, Debug)]` `struct TestConfig {` `version: u32,` `value: u32,` `}` `fn main()` `{` `let config_file_name = directories::BaseDirs::new().unwrap().home_dir().join("config.json");` `{` `let c = TestConfig { version: 1, value: 7, };` `println!("write conf={:?}", c);` `let file_writer = File::create(&amp;config_file_name).unwrap();` `serde_json::to_writer_pretty(file_writer, &amp;c);` `}` `let file_reader= File::open(&amp;config_file_name).unwrap();` `let c2: TestConfig = serde_json::from_reader(file_reader).unwrap();` `println!("loaded conf={:?}, ver={:?}, val={:?}", c2, c2.version, c2.value);` `}` 
People openly admit to using Scripts in UKN all the time. I think im done after @3400 hours now. There is no competitive edge anymore. Its just how much you can get away with now. EAC is trash
Looks amazing. I haven't read your previous posts about this so the question is: are you excited with rust for this kind of project?
This [post](https://hsivonen.fi/modern-cpp-in-rust/) by Henri Sivonen might also be helpful. It's about how the C++ API for encoding-rs, which is also used in Firefox now, is done.
Not yet. There's an issue for adding block ciphers, but it's likely that they're quite a ways off given some of the design challenges around the API. If you're curious for details, [here's the issue](https://github.com/google/mundane/issues/5).
I don't know much about this project, but from my memory of PBRT's architecture, most inheritance is a single layer deep, and mostly behavior rather than data. Traits seem like actually a better model of that type of thing than c++ classes.
Im gonna hijack this question to ask a question, I am fairly compentent in python i’d say, and i am interested in learning another language (rust). But I’ve heard that there are a lot of more hardware(?) general computer knowledge(?) you need to understand rust. What are some keywords for these things so that I can begin researching these things ahead of learning rust? Thank you!
I can render a 100k pages blog in Zola (the next branches Tera v1-beta) in ~78s on my 5 year old laptop and that includes reading the 100k files, markdown rendering, taxonomies, paginations, sitemap etc. Do you have some of those templates/context around so I can figure out why they are 10x slower than Askama? 
&gt; Where have I said that? Right here: `Rust has some high-level language features, but I don't think that makes it a high-level language`, accompanied by `it missing (...) fully-automatic memory management.`. &gt; Whether a language is high or low level is a subjective property, so there are many definitions, and everybody has its own, that's what subjective means. I think our main misunderstanding comes from the fact that you think that `high-level PL` is _obviously_ a subjective term, whereas I think that it's _obviously_ not - we won't agree on other things while we differ on this one, so: why do you think that this definition should be entirely subjective? I've linked a few sources (e.g. [Wikipedia](https://en.wikipedia.org/wiki/High-level_programming_language)) that give a pretty detailed description (e.g. you cannot classify Assembly as high-level, since it makes no abstraction over the machine and so on). Paraphrasing `none of them call Rust a high-level programming language` I might say that none of my linked sources call `high-level programming language` a subjective term. &gt; Instead of arguing about why you think that opinion is incorrect, you are only showing ignorance about what "high-level" and "low-level" mean when talking about programming languages (...) In a similar way you define `high-level` to be a subjective term and stick to that definition, showing ignorance about other possibilities. &gt; It shows that you are more concerned about "winning" a discussion, than about the discussion being fruitful such that everybody learns something. Up so far it seems that I've cited at least a few sources that support my opinion, whereas all you did was telling me `for me "high-level" is a subjective term` - I don't think that's particularly educational. You've also used a few eristic tricks (e.g. with the `because when you click on Rust in those links, none of them call Rust a high-level programming language` part), which also does not seem especially fruitful.
Untyped programming languages like JavaScript don't have Rust-like enums, but can be emulated with a map with a tag field and an arbitrary number of other fields that may or may not be set based on what the tag is. For example, the following object literal in JavaScript `{ "tag": "foo", "value": "bar" }` could be considered an enum where one of the tags is `"foo"`. It's all informal though, even if you write down the expected values in documentation (and if you don't write it down, you're writing unmaintainable code...). Even in the Erlang/Elixir world do they use (Elixir syntax) `:ok` or `{:ok, value}` and `{:error, reason}` for their equivalent usage of Rust's `Result`. And it's all convention based.
Are you using Serde's custom derive? That probably won't work. Try raw serde_json?
Also: LabView
Do you mean like serde\_json::value::RawValue? Because my compiler isn't picking up RawValue in serde\_json::value for some reason.
Have you tried using [`serde_json::Value`](https://github.com/serde-rs/json#operating-on-untyped-json-values)? Do you have some code that didn't work?
No, I mean using `serde_json` directly instead of writing types and deriving `Serialize` for them. 
Have you created a struct representation of that json? You can have strongly typed and untyped structs, but you have to have one that tells serde which fields have what 'type of type'. For the Json above it would look like this: enum MyJson { Object( Object( String(String), String(String) ), Object( String(String), String(String) ) ) } This tells serde in a non-strong typed manner what to expect.
The problem is that it's dynamic. The user could specific any depth, so it needs to be recursive. 
You can put MyJson recursivly in an Array/Vec too, then you can put as many of MyJson intoMyJson as you want. &amp;#x200B; enum MyJson { Array(Vec&lt;MyJson&gt;) } &amp;#x200B;
The Rust book is probably a good resource. There’s been a bunch of blog posts that cover the memory model, lifetimes, concurrency, etc. many of which I’ve posted to Read Rust. Sorry I can’t point at specific ones but searching this page might reveal some good ones: https://readrust.net/all/
&gt; why do you think that this definition should be entirely subjective? I don't think that it should, I claim that it is. If you teach a 40h/week x86 assembly programmer C, they will think that C is a super high-level language. If you teach a Python programmer x86 assembly, they will think that assembly isn't even a programming language because of how low-level it is. Whether a programming language is high or low level depends on the languages they know. A definition, whether it is coined by one person or by many, it is going to depend on the programming languages that this group of people know well. While they can know many programming languages, they can't know all past and present ones, much less future ones. Therefore, such definitions are always subjective. The assembler programmer calls C high level, the machine code programmer call assembly high-level, the Python programmer calls them both "too low-level to even be a programming language", and the LISP programmer calls python low-level. &gt; In a similar way you define high-level to be a subjective term and stick to that definition, showing ignorance about other possibilities. I know there are people like you that think that high-level is an absolute term, I never found one of them that was able to think for themselves. They always stated "my professor told me that the term is absolute, therefore it must be" and similar things. I've never thought much of those people, nor needed their recognition in any way. None of them was able to refute the claim that it isn't a completely subjective term with their own arguments. IIRC, they only had arguments of authority. &gt;Right here: &gt; &gt;Rust has some high-level language features, but I don't think that makes it a high-level language &gt; &gt;, accompanied by &gt; &gt;it missing (...) fully-automatic memory management. &gt; &gt;. Where exactly? I don't see it. Either you can't read, or you can't tell the difference between a claim, and an opinion or a feeling. Either way, this makes me not think very highly of you, which is why I don't put much effort into arguing with you: 
Ah didn't even realise you could do that. It looks like it partially works in a sense. If I do that I can reference nested items but the problem is I only know how to do so by explicitly providing a key i.e. parse\_json\["key"\], and I would need to be able to iterate over the structure. Sorry, I'm very new to Rust so I'm probably not explaining this very well. &amp;#x200B; Say I was trying to do this in JavaScript I could take an arbitrary unknown object and and do something like obj.key().forEach(key =&gt; {...}), and check if the key's value is a primitive or a more complex type like an array or an object, and that's kind of what I'm trying to do here. I'm trying to get the program to receive a completely unknown json object, it could be deeply nested or it could be a single key value pair or anything in between. Then I want to go through each key and say "if this key's value is complex, i.e. another object, then recurse the function, other wise break out and return the flattened path string and the value".
Sorry I've not be version controlling the code and my Cmd+Z history only goes back so far so I'll have to just try to remember what I did but the first thing I tried, which is probably wrong due to my Rust ignorance, was to create a struct with an attribute with the type set as an enum which I defined, the enum contained options of either a string or a type of the struct I made. This was recursive and rust didn't like it so I boxed my struct in the enum which got it working a bit more but ultimately it didn't work. &amp;#x200B; &amp;#x200B;
&gt;I'm surprised by that. Wouldn't going away from dynamic dispatch increase the codesize even more, since inlining and momorphization creates more code and duplicates? I found that part weird as well.
You don't have to create any struct or enum. Just use `Value` instead.
u/jneem, if you decide to rename it, I would be interested in using the name for a crate I've been working on. :)
Yeah I think that works, if I parse json into Value and I println it it does seems to be capturing the whole structure as I would expect. I’m just wondering now how I go about iterating through this structure so I can check when a key’s value is a terminal value e.g. a string or an int, or whether it’s another object in which case I check those containing keys. I think this is less to do with serde now and more a fundamental misunderstanding on my part about Rust. 
I'll never know, because I'm never going back.
If you install nightly-some-version and then go into `~/.rustup/toolchains` and rename the directory from `nightly-some-version` to `nightly` does that do what you want? If not, looking at &lt;https://github.com/rust-lang/rustup.rs/issues/1628&gt; and weighing in might be helpful.
Yes, you can absolutely do that with `serde_json::Value`.
Most people don't, since for most sites this is not a bottleneck. When you get to the point when it is however, you are in a tough situation because you have large amount of complex templates and its hard to do much about it. If you look at jinja-style template engines, speed is all you care for because nearly all other issues (that is managing complexity) have been solved.
You can check whether the value is an object -- meaning you must recurse (note that you don't need explicit recursion, a stack/`Vec` is enough) -- or a string. But yes, this is more of a CS thing than specific to the language.
Yes, that solves half of it (I wasn't aware that a simple `mv` would fix it), although you still have to know a valid `some-version` to get to that point, which can be difficult as I noted. However, knowing this trick, it's presumably at least OK if you pick one that is "too old", since `rustup update` fixes that.
Okay please don't scold me for such bad code but at your suggestion I've attempted this: let dej: serde_json::Value = serde_json::from_str(&amp;sej).unwrap(); println!("{:?}", dej); for item in dej { match item { Value::Object(obj) =&gt; println!("{:?}", obj), Value::String(string) =&gt; println!("{:?}", string), } } I really need to read more into match syntax because I'm not sure if I'm doing it right, my understanding is that Value is an enum and I can match on enum item and pass the contained object through to the println. But that aside I'm struggling because serde\_json::Value is not iterable so I don't know how I can move through the object. &amp;#x200B; Sorry to keep asking stuff, my google-fu isn't on point today.
Damn, the fold solution is so simple it pains me that i spent so much thinking about it... Thanks! Is the solutions using the sink prefered over using the `write_all` function?
Well, with `Integrator` I didn‘t see a need to use a trait (yet), but for `SampleIntegrator`, basically all implementors of that trait can use the same render loop: https://www.rs-pbrt.org/doc/crates/pbrt/integrators/fn.render.html So, it might look a bit arbitrary, but most of the time a base class will end up being a trait. Sometimes I don’t see a need for it right now, but I might add it later (for completeness).
Have you seen [PostgREST](https://github.com/PostgREST/postgrest)?
I think it still has a postgresql which is a relational db behind it. 
I can't run your code right now, but you're almost on the right track: - there's no need for the outside `for`, unless you expect your root to be an array. You can match against it - `Value::Object` contains a Map, which is iterable So it should be something like https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=33710352d1aaac4b98a9fa5968334195. If the lifetime annotations confuse you, you can remove `'a` and replace `'b str` with `String`, adding some clones.
A note about python, it's equivalent to iterators are really list/dictionary comprehensions. I'd recommend using them over the built in methods.
Postgres supports flexible schemas with it's JSONB type.
It's a lot more easy to work with than the raw approach, and lets you do other stuff in the meantime.
I definitely am. My first goal ist to make the resulting images very similar, most of the times identical. I solve a problem first without multi-threading (but keep it in mind), then I compare the results and if I find bugs it’s easier to debug that way. After that I try to run the same code multi-threaded, but there might still be room for better performance. So far I have been only investigated serious performance problems (using perf) twice. One was related to building a BVH recursively: See https://users.rust-lang.org/t/profilers-and-how-to-interprete-results-on-recursive-functions/13222/4 The other one was described in the last release notes: The base class shares a huge vector of data which should be calculated only once, but the first implementation did it many times and was expensive to clone. What I can say, comparing C++ vs. Rust: The signatures of Rust methods tell you much more about what’s going on than the C++ counterpart. Sometimes I need to single step through C++ code to see what’s really going on (or where there are differences I didn’t expect), whereas looking at the Rust code most of the time tells you the whole story. Anyway, the C++ code is most of the time still faster, but I did some shortcuts in Rust (regarding memory management), which I might have to rethink at some point. But especially with multi-threading I feel much more confident with Rust, that the resulting code is working without any side-effects ... So far I was more interested in how easily existing C/C++ code can be ported to Rust. At the very end of this project I will invest some time in real performance measurements and will try to end up with a faster executable than I could get through C++, but there is so much more to do before I can start doing that. At least someone, who is willing to help with that, will have a solid implementation, which can be optimized to run faster ...
Honestly though it must have taken a strike of genius to realise that in lining was the reasoning for its "sort of" behaviour. I guess you could have inspected the byte code, but that makes sense when you're debugging an exotic target. Great post! 
It's unfortunate that Rocket still requires nightly, as that could be a turn off for people comparing this Rust implementation to other languages. Also, for a demo it'd be nice to use the 2018 edition. There is some non-idiomatic error handling, particularly the code snippet below, but I'm not sure what the best way to improve it and keep the exact behavior you have now. I'm going to look into it a bit more tonight and maybe make a PR. ``` if !errors.is_empty() { return Err(errors); } ``` Overall, thanks for putting this together and sharing!
I use it to render entire pages because I'm a nut job lol
Good point, thanks. I'll make it into 2018 soon.
I think he just means as a project matures through different frameworks the effort involved in transferring a large sum of documents written in `&lt;html/&gt;` is a lot less than converting from `html! {}`
True. That's why I said "something like". Unless someone has come out with something new since I last checked, the FrameMeister is the best option money can buy.
&gt;It surprises me that people would be nostalgic about DOS, but I guess my POV is skewed. each to their own. MS-DOS/windows: that horrible software step backwards you had to take after the Amiga, if you wanted to get the 256color byte-per-pixel screen and faster intel CPUs. right i was quick to qualify. I specifically have \*anti\* nostalgia for DOS. It took windows a while to become good. paradoxically, I get some nostalgia from the Atari ST. it's an inferior platform to the amiga, but I specifically remember the excitement of the 8 to 16bit transition in the home, which started with the ST - at that time Atari was a much stronger name -their 8bit computers were good, and they had arcade presence. &amp;#x200B; I've also got a strong itch for a commodore 64.. the 8bit machine I missed out on &amp;#x200B; some people collect old workstations (SGI, NeXT..) . Imagine the way \*those\* seemed godlike objects of desire (like supercars) when you had home computers
You can have multithreaded code without asynchronous calling, using queues, fork-join, etc.
I'm interested in how you bridged specs, nphysics &amp; ggez. Will you publish your code or at least blog about it ?
Those are all conceptually also asynchronous, they just don't use the language mechanisms Rust and the Future crate provides.
&gt; but learning the monadic interfaces on &gt; &gt;Option &gt; &gt; and &gt; &gt;Result &gt; &gt; really really cleans up error handling code. Chaining &gt; &gt;and\_then &gt; &gt; calls is &gt; &gt;vastly &gt; &gt; cleaner than nesting Would you mind elaborating on the last part (chaining and\_then calls) or if you know of any sources which explain this? Cheers!
Amazing write up!!! I'm a Rust newbie so your post was incredibly valuable to me! Thank you so much for taking the time and writing it! &amp;#x200B;
We will make the code public when the game is done! I will certainly post it on r/rust (if it's appropriate?) and on r/rust_gamedev when it's ready so you'll be able to see how we managed it then :) Also if you want to talk about it before that (I don't exactly know when the game will be done), we can discuss it on discord.
You can use https://github.com/dushistov/rust_swig it generates C intermediate level plus c++ classes that uses this C API.
Hey, I've never used serde. But why not just use regular expressions? It seems a simple enough problem.
Non-expert impression: Note that using trait objects involves erasing the type of an object being passed into the formatting engine. The formatting engine is reachable code, and thus so are all formatting routines of all formattable types (after monomorphisation). Thus one has to generate every format routine of every formattable type that appears in the program. So it's actually pretty expensive, since so many types qualify. Once you get rid of the type erasure, dead code analysis saves you a lot of space. OTOH, it seems like it would be very useful to allow inlining functions that take trait objects, and letting constant propagation (here the vtable) simplify this situation. Is that a thing that could be done? Or am I missing something?
Mind blown. That's a great way to think about it!
I mean, to me the reason for the performance difference seems obvious, as I said. Tera loads and parses templates at runtime, and so has to do its syntax and type checking at runtime. Askama loads and parses templates at compile time, and then turns them into Rust code. So it does a lot more of the validation work and such at compile time. I haven't profiled both to see what the difference actually is, but that would be my bet.
Can you still use \`version = \` when using \`git\` and \`commit\` and \`branch\`es? &amp;#x200B; If not, dependency resolution won't work great. Like if you have two components in your organization, depending on slightly different versions of a library, dependency resolution can find a version that works for both. But if you are using commits, you are going to get two incompatible versions compiled and linked. That's not bad if they don't need to interoperate, but if they do, then that won't work well. Also, the versions link C libraries, that won't work at all.
Nice work! Thanks for sharing. 
The way it's explained with most languages (rust enums do a little more than that) is that, when you want to describe, say, a deck of card, you might be tempted to describe the symbol on each card by giving each of them a number, so Hearts = 0, Clubs = 1, Spades = 2 and Diamonds = 3. The problem with this is that numbers have their own meaning and semantics that you're trying to paint over with those numbers, but nothing would stop someone from saying their age is "Winter multiplied by Saturn divided by Hearts". Enums let you have a type with an explicitly limited amount of *qualitative* (can't order them, multiply them, etc.) variants and that usually avoids the issue and lets the compiler make sure you're calling your functions the way they're meant to be called and make your code a bit more self-documentin in the first place. Again, that's not all enums are in rust, but since you're coming from a JS background (where this sort of thing is usually achieved with strings that get checked inside the function that takes them), that's probably what you wanted to know.
me: mentions something cool that someone's doing in rust other guy in the office: "rust strike force at it again"
Just put some of my thoughts into the thread 👍
I obviously don't expect Tera to be as fast Rust code but I also don't expect it to be that much slower. I had a typo in my previous comment, I meant 60x rather than 10x. A 10x difference is to be expected I think, there is always the overhead of serializing data to JSON and well, not being compiled.
Usually if you don't have enumerated types in your language but want to have symbolic names for some set of things, you'd just use a bunch of constants with integer values. Enums in C aren't much more than that anyway; the compiler happily lets you pass an integer where an enum is expected and does nothing to check that it's one of the enumerated values. The `enum class` feature in C++ is a bit stricter, though.
I wouldn't say there's any special hardware knowledge you need. If you know the difference between memory on the stack and in the heap, that'll help you understand better *why* some of the ownership rules work the way they do, but it's not really a requirement. And that stuff is also covered in The Book. I'd recommend just diving right in and reading The Book. This subreddit will be happy to answer more questions as they come up too.
Python's comprehensions work great if you only need one map and one filter. Beyond that you get into madness like nesting them which is very hard to read and write.
Well, the easy solution would be to put them in a separate crate.
What happens in this scenario: 1. remove line from a function 2. move (i.e. create and delete) the function to somewhere else in the file 3. unrecord 1 My guess is it won't result in a conflict, but the deleted line will appear where the function used to be. That's a pretty poor user experience if it says there's no conflict and it results in broken code.
I believe OP is the author of quilt.
Let's open a socket, read from it, parse a message, then send it on a channel: Socket::open(address) .and_then(|sock| sock.read_some_bytes()) .and_then(|bytes| Message::from_bytes(bytes)) .and_then(|message| channel.send(message)) Try doing this with `if let` or `match`: if let Ok(sock) = Socket::open(address) { if let Ok(bytes) = sock.read_some_bytes() { if let Ok(message) = Message::from_bytes(bytes) { channel.send(message); } } } No matter how much work I chain together in the first one I don't exceed one level of indentation, but in the second example it quickly gets out of control.
Step 1, don't mindlessly post in the wrong subreddit.
I think you are a lost redditor, and you would like to ask this question in /r/playrust
Indeed, although amusingly rust-lang is quite effective at "banning" hackers from programs written in it.
I would really like to try and take this course myself, buy I could only find small parts of the slides and no lectures... Does anyone know if the lectures were filmed / have a full set of the slides?
Thanks! this is what I was looking for.
Check your config. On Linux, mine does generate a .gitignore automagically &amp;#x200B;
You should get a .gitignore file automatically unless something is wrong with your installation. Do you have git installed? For templates, check out Cargo generate: https://github.com/ashleygwilliams/cargo-generate
The more I dive into rust the more I enjoy it. 
Alright, thank you very much, seems like a very nice community :)
Ah, good point. I guess it's time to find another name... &amp;#x200B; The annoying thing is that I googled "quilt software" before choosing the name, but that didn't turn up on the first page...
That is indeed an interesting scenario. It's related to what I'll be talking about in the next couple of posts, and it's also related to what pijul calls "zombie lines." Quilt doesn't handle this situation well right now, but it's something that I plan to address.
Thanks!
Definitely use failure. It's the go-to standard for applications now. The trick is making `Error` useful as a response. [Here is a `WebError`](https://gitlab.com/snippets/1828217) type that works well alongside failure and implements a custom responder.
&gt; That's definitely the Nr1 missing feature to make Rust great on embedded. Note that generic-array lets you parameterize over arrays of any length *on stable*. The downside is that trait bounds get unwieldy pretty fast and [the bounds can leak implementation details](https://github.com/japaric/heapless/blob/773360b5fd702697866fd20b6ebb245360733d6b/src/indexmap.rs#L90). &gt; I'm surprised by that It's more nuanced than "trait-objects = smaller binaries; generics = duplication / bloat". With trait objects and function pointers llvm can't do as many optimizations, like dead code elimination, as it can when it can inline code. For example, if the only thing in your program is `println!("Hello, {}", "world")` today you will still end up with functions like `fmt_u32` and `pad_integral` which are never invoked. Ideally, the only thing you should get in that case is a single instance of `write_str`. IME, if you only have a few instances of a generic function then static dispatch usually produces smaller binaries (or rather I have only ever seen dynamic dispatch increase the binary size of my programs). If you have many instances of a generic function then dynamic dispatch (trait objects) is likely a better option for binary size but the only data I have seen on this was generated using opt-level=3 (which optimizes for speed, not size) so I would measure. Trait objects will certainly make things faster to compile since llvm doesn't have to evaluate the effects of inlining for dynamic calls -- we saw this with the `debug_struct` API which is why all arguments are trait objects.
That is a very organized way to think about it! I'd always thought of `enum`s as `OR`s, but I had never thought of `struct`s as `AND`s.
The team at pingcap are/were themselves considering switching to tower: [https://medium.com/@siddontang/use-tower-grpc-for-tikv-6109cf8c61](https://medium.com/@siddontang/use-tower-grpc-for-tikv-6109cf8c61) 
Cool thanks :)
Will the `core::arm` module get a way to issue a Software Interrupt instruction?
Just learning about the planning of Adamant, and I'm quite impressed with how it is shaping up. Rust is playing such a great role in its memory management considerations while, I think, the syntax is following the same spirit of Swift in terms of readability. I'm definitely following it now.
I have actually followed this as a template for starting to build something in rocket and it's very easy to follow and understand. I just wanted to say thank you and I appreciate the effort you put into it. 
The generated assembly seems [really different](https://rust.godbolt.org/z/LMBphv), but I'm not really sure why.
I need help importing the proper link to a trait. Here is the rust error message error[E0599]: no method named `to_string` found for type `&amp;std::path::Path` in the current scope --&gt; core/src/utils/config.rs:73:39 | 73 | config.config_path = path.to_string(); | ^^^^^^^^^ | = note: the method `to_string` exists but the following trait bounds were not satisfied: `std::path::Path : std::string::ToString` `&amp;std::path::Path : std::string::ToString` `std::path::Path : std::string::ToString` = help: did you mean `to_str`? So the question is: How do I know which paths to import?
I think you got the wrong sub.
I saw a post about cargo ship that is in rust so idk... it should be a new one...
Cargo is a package manager for the Rust programming language, which is what this subreddit is about.
Welp yikes then.... imma delete lol
&gt; If you look at jinja-style template engines, speed is all you care for because nearly all other issues (that is managing complexity) have been solved. What are the other issues?
Late response, but would it be possible to call `to_sql` on the `Vec&lt;String&gt;` and insert it directly into a query string? I can't find any examples of doing this, so if you could point me to one that would be great (assuming I can do this).
Have you seen https://twitter.com/alicegoldfuss/status/1098604563664420865?
No, to_sql uses Postgres's binary encoding rather than the text encoding.
Huh? The only differences I see in the assembly are 1. Different label names, e.g. `LBB0_1` becomes `LBB1_5`. 2. The order of the second and third `xor` instructions is reversed. 3. Near the end, `rcx` is used in one function and `rdx` is used in the other.
This is only a backend implementation correct? There is no frontend? I've been wanting to build a blog webapp in rust, so this looks like a very helpful example project to me. But, as I've been looking at rust web frameworks, none of them feel complete enough for me. I'm not looking for something as feature packed, and as large as Rails or anything. But I want a rich text editor, and an easy way to upload photos, and it seems that with rust frameworks, I'd still have to do just a little more work than I have time for, building that functionality.
I'm guessing that the compiler can do some fancy optimizations on iterators because the way they behave is more predictable than a for loop. [This section](https://doc.rust-lang.org/book/ch13-04-performance.html) of the book talks a bit about why iterators can achieve better performance than for loops.
Interesting, I was initially thrown off on its readme saying not to use at production, but browsing through the documentation and example, it does make quite a lot of sense. Will look into migrating to this the future. Hopefully they get the library in [crates.io](https://crates.io) soon
Ah, okay. Thanks for the quick response. Turns out I was just being dumb and incorrectly binding the query parameter to my query string.
Yeah, you're right. I was messing around with different ways to write it, and I guess I was looking at one of the older outputs. Then it sounds like OP is doing something wrong.
I took a stab at implementing this: [does this work for you](https://gist.github.com/nwtnni/a769fa093c4118c9716957957dcee332)?
I think one very powerful feature of diesel is the ability to embed migrations. One area of improvement I can see is that rather than forcing someone to install the diesel client tool and then run migrations from the console that migrations are automatically run on rocket launch. If you are open to pull requests I would be happy to submit a PR with this feature, along with adding in rocket's database support which would get rid of your current pool implementation in favor of the built in pool support. 
I *think* it's an interaction of the mutable `s` with `println`. In the loop version, if I insert `let s = s;` just before the `println`, that version becomes as fast as the iter version.
I don't think it's the OP doing something wrong, the functions do behave differently if the `println` is moved into the function, but they are the same when the `println` is moved out.
Huh. This is a weird one.
I honestly thought I was doing something stupid but I ran it several times and I see the same.
Check out /u/tspiteri comment. It seems like the compiler is not optimizing things quite as much as it should.
Wow. I see this as well. This scares me that performance can be so sensitive depending on how we write code.. 
It's not pretty, but it works: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b13d5e3f8c1bdddf53501073df9697b4 extern crate serde_json; use serde_json::Value; const INPUT: &amp;str = r#"{ "foo": { "bar": { "alpha": "alphaval", "beta": "betaval" }, "baz": { "alpha": "alphaval", "gamma": "gammaval" } } }"#; fn parse(json: &amp;serde_json::Value) -&gt; Vec&lt;(String, String)&gt; { let mut data: Vec&lt;(String, String)&gt; = vec![]; match json { Value::Object(map) =&gt; { for (key, value) in map { match value { Value::String(s) =&gt; { data.push((key.clone(), s.clone())); }, Value::Object(_) =&gt; { let inner_data = parse(value); for (inner_key, inner_value) in inner_data { data.push((format!("{}/{}", key, inner_key), inner_value)); } }, _ =&gt; unimplemented!(), } } }, _ =&gt; unimplemented!(), } data } fn main() { let result = parse(&amp;serde_json::from_str(INPUT).unwrap()); println!("{:?}", result); }
Do you have a link? I’ve never seen anyone do this. Right now I build a docker image with diesel CLI, but if I could move it into code that would be great. 
Maybe it's worth [filing an issue](https://github.com/rust-lang/rust/issues).
Hmmm On windows git bash it does not generate the .gitignore. I'll have to look into it. Luckily it looks like Rust makes that pretty easy to configure. &amp;#x200B; Thanks!
This issue isn't that the trait isn't in scope, it's that it's not implemented for `Path`. I believe this is due to the `String`/`OsStr` dichotomy (paths may contain non-UTF-8 characters). Either way, [`Path` does provide a `to_str` method](https://doc.rust-lang.org/std/path/struct.Path.html#method.to_str), but I think that [`to_string_lossy`](https://doc.rust-lang.org/std/path/struct.Path.html#method.to_string_lossy) may be better for you if you know the path is valid UTF-8.
why does it say in the error message that the 'to_string' function exists if it is not implemented. Yes i checked the docs and there is no to_string() method on sight but that's what it is confusing me.
That's telling you that the `to_string` method exists *in the `ToString` trait*, and that said trait is not implemented (trait bounds not satisfied).
You can actually do this a single `match`. Check out my other comment.
Yeah. Whether it's Rust, C, C++, or any other compiled language, the degree to which output performance is dependant on little details with not-necessarily-intuitive implications for the optimizers has always made me uncomfortable. It's one of the reasons I've been sticking to I/O-bound programming despite no longer being restricted to languages like Python by my fear of memory unsafety.
Oh, I was doing a fair bit of disassembling, yeah. There were a few early red flags that I ignored such as my 16-bit startup code being disassembled incorrectly while everything else was disassembled correctly.
I mean, I find MS-DOS way more elegant than either early or modern Windows. The Win32 API is a huge mess. They keep wanting to add functionality to existing functions, and sometimes there are more than six versions of the same function with names such as SomeFunction2 and SomeFunctionEx. The MS-DOS interrupt table is clean and simple.
Great to hear progress on making druid more portable!
It creates one for me on Windows..? 
&gt; Edit: Maybe it's impossible for the example function to return a stream if that's what I want to do? Maybe the return type has to be a future that resolves to a stream. This is what `flatten_stream` accomplishes.
You might want to try some other emulator combinations, such as DOSEMU, and FreeDOS inside emulators like Bochs to rule out the possibility that it's a DOSBox bug. After all, they do explicitly say that they're not aiming for a perfect emulation and they won't support your efforts to run productivity software... just one perfect enough to play all games.
For the first question: yes, you have to add it yourself because diesel's macros currently only work nicely with `#[macro_use]`. For the second question, try &amp;*db. In most situations &amp;db wound be enough, but diesel's methods take &amp;Conn where Conn is a type parameter and rust doesn't do type inference there. This is somewhat addressed/discussed in https://github.com/SergioBenitez/Rocket/issues/855
That didn't answer my question. So I installed pijul and tried testing the commands out. It did not at all behave the way I expected. Pijul seems to do a best effort in recreating the line where you would expect. However, it does so in an unintuitive way. When I unrecorded the deletion patch, pijul _also_ unrecorded other patches that modified code adjacent to the deleted line. This had the effect of resurrecting code I didn't intend. I also discovered it panics if you try to unrecord a patch made prior to a tag. That makes sense, you shouldn't be able to mutate something you intended to be immutable (i.e. the code the tag represents). I think fundamentally the mistake pijul has made so far (though you hinted at them planning to correct this) is that patches should never be able to be deleted.
To be honest, it seems to me that due to the heavy duty I/O, whatever the language, the project will require interfacing closely with the underlying platform to achieve good performance. A corollary is that frameworks which abstract the platform may get in the way, and thus the ecosystem will probably not matter much. In this case, I'd say Rust is a strong contender: the language is good, and the fact that the web ecosystem is still volatile won't matter. --- In their article [SOCKMAP - TCP splicing of the future](https://blog.cloudflare.com/sockmap-tcp-splicing-of-the-future/), Cloudflare details what are the current solutions for I/O heavy workloads (and how SOCKMAP isn't quite there yet).
Yeah, for the PC-98 I've started using Neko Project 21/W instead, since it is said to be the most accurate emulator (it can even run Windows 2000), and although it's only released for Windows, it's actually open source and it works well with Wine. I'm flip-fleep-flopping between whether 32-bit pointers are offsets into the current segment up to 4 GiB, whether they're offsets into the current segment up to the normal limit of 64 KiB, or whether they're linear physical addresses. I still haven't been able to determine for sure with my experiments. Either way, I've been working on code to convert linear addresses and access memory that way, in case I need it.
Raph's small updates are the size of major milestones on my own personal projects oO
It's worth noting that people should prefer to use stable if possible. These tools will always be available there. If you have to use nightly then these points are valid, though tbf a whole week without rls should be rare. I built in a bunch of helpers into ide-rust on atom to aid nightly usage. Perhaps the history site could be updated to tell you the latest dated nightly including rls &amp; the other tools?
Thanks.
I think more broadly any VCS that just sees code before/after editing is going to have a hard time diffing them in the way we think of the changes having been made. I wonder to what extent it would be worth integrating a patch-based VCS with a text editor such that, when editing a file (eg in vim), a small collection of patches are built up with each step of the edit. When you save and/or quit (optionally on-demand), the patches are mushed together and stored as an in-progress patch. The idea being that all the extra semantics conveyed by the editing process provide extra information to store in the patch, and this allows for better conflict resolution. The challenge here is that, with more expressive patches, it becomes more complicated to reason about them. Still, it would be an interesting problem space to explore. Is there a collection of fundamental edit operations one can make to a file (not just 'add line' 'remove line') that form a coherent set of operations suited to patch management? Such a collection needs to balance that (1) antiquing must be well-defined and reasonably effective, (2) antiquing must be efficiently computable, and (3) human editing operations must map reasonably well into the operations set. A good solution to this could even double as improved "undo" functionality within the editor.
Here's a project I just started recently (the project itself is definitely very early stages) but it does implement a pg pool and run embedded migrations on rocket launch: [https://github.com/PrismaPhonic/flashcard](https://github.com/PrismaPhonic/flashcard) Take a look at main.rs for where that's happeneing
Oh interesting. Thanks! Didn't realize that migrations crate was public api. 
[https://github.com/rust-iendo/template-benchmarks-rs](https://github.com/rust-iendo/template-benchmarks-rs)
God what an insufferable answer
Recently did a project in Rust where I needed this that might be useful to you. You can find the c++ wrappers here: https://github.com/udoprog/ptscan/tree/master/pts-cpp/pts Here's the C exports using cbindgen: https://github.com/udoprog/ptscan/tree/master/pts-c
There has been quite a bit of research in that direction in the context of collaborative editing, though I think the focus was more into the direction of supporting richer data models. As a starting point, I'd look at [operational transformation](https://en.wikipedia.org/wiki/Operational_transformation).
Yes, I'm guilty of becoming insufferable to someone that continuously claims that I said something I did not say. 
The idea that a line of code has an identity allowing it to move around and be changed is something we create with our imagination. It's not a tractable problem for a VCS to figure that out, where a line moved, if at all, is subjective. Any solution to maintain that facade will require disciplined development practices on the user's part. Patch theory isn't going to save us from disciplined practices.
/r/playrust?
Thank you! Collaborative editing is indeed very similar to the problem to be solved by a VCS.
My thoughts as well! That's a huge amount of work.
/r/playrust
&gt; It's not a tractable problem for a VCS to figure that out, where a line moved, if at all, is subjective. Any solution to maintain that facade will require disciplined development practices on the user's part. Well, maybe. The idea I proposed was to take advantage of the fact that most human text editing is itself a sequence of very simple steps, each of which often has additional information about intent. If there is an extent to which intent can be parsed out of user's actions *while they edit*, then we can rely on tools to do grunt work/maintain discipline for us. A bad-but-legal example is recording VCS history information by storing a complete history of vim commands. Recovering vim commands given the start/end of a large source code change is only possible in uselessly simplified ways. But if you store the user's history while they type (in vim), then you have a richer history of changes to work with.
I can't help but think that the team doesn't manage the scope of work properly: taking on the 2D abstraction, then rewriting parts of winit, in addition to actually building the text editor - seems like more things on that plate than could be. `winit` got the issue resolved, as far as I see - https://github.com/tomaka/winit/issues/786#issuecomment-460311240 also, TIL about the Libre Graphics conference - definitely the venue I'd love to participate in ;)
Someone please explain how to fold a hashmap to get the pair with the max value, i know this can be easily accomplished with `max_by_key(|&amp;(_, val) val)` just that I want to understand how that would be with fold. I'm trying this: &lt;code class=" s90z9tc-7 cMUrmP "&gt; for (k, v) in hashmap .iter() .fold(HashMap::new(), |(n\_prev, m\_prev), (n\_next, m\_next)| if n\_prev &lt;= n\_next { vec!(n\_next, m\_next).iter().collect() } else { vec!(n\_prev, m\_prev).iter().collect() }) { println!("{} {}", k, v); } &lt;/code&gt; First issue compiler says mismatched types (obviously), and i dont get how to aggregate the result to the hashmap. Second issue the logic behind (is it even good?) any feedback will be greatly appreciatted.
Most resources I've seen focus on calling C from Rust. I'm more interested in making libraries in Rust that compile to the C ABI so they can be called from C (or node, Python, etc). The best resources I've found for that are the \[FFI omnibus\]([http://jakegoulding.com/rust-ffi-omnibus/](http://jakegoulding.com/rust-ffi-omnibus/)) and \[this talk\]([https://www.youtube.com/watch?v=x9acx2zgx4Q&amp;feature=youtu.be](https://www.youtube.com/watch?v=x9acx2zgx4Q&amp;feature=youtu.be))
great example! I'm very excited about async/await, just today I am working on converting some currently non-future based code, and I lamented that I couldn't yet use async/await (on stable), and that I'll need to either box some combinator results or destructure the code into some state machines. Neither of which is exciting.
1. Immutable by default is nice 2. Only a single mutable reference at a time is nice 3. Strict static typing is nice 4. Not everything has to be done using OOP approach 5. Generics/type params and enums finally make sense to me 6. Most runtime errors in higher-level languages should be parse errors exposed either via parse phase or via static analysis tooling 7. Exceptions and nulls are useless and add unneeded complexity and uncertainty to a language 8. Most of the time composition is better than inheritance 9. Verbose language syntax can be intimidating but often is there for a relatively good reason My past experience is mainly with PHP, JavaScript, and Python. These days I use PHP with strict static typing (can't wait for 7.4 with typed class properties!) and mark all my classes either `final` or `abstract`, and I use tooling for in-depth static analysis. I have dropped Python usage as much as possible because it is just too fluid for my tastes. JavaScript is a necessary evil for browser interaction development, I should really check out TypeScript though.
Some help understanding `fold()`, I'm trying to get the pair with max value from a hashmap, I am currently tying: ''' for (k, v) in ejemplo .into\_iter() .fold(HashMap::new(), |(n\_prev, m\_prev), (n\_next, m\_next)| if n\_prev &lt;= n\_next { vec!((n\_next, m\_next)).into\_iter().collect() } else { vec!((n\_prev, m\_prev)).into\_iter().collect() }) { println!("{} {}", k, v); } ''' Some feedback will be appreciated. P.S. i know `max_by_key()` would do the exact thing i need,just want to be the cool guy who knows how to do it with `fold()` (or `filter()`):D
That's true, but I think there's also an important difference: collaborative editing is interactive, and so in cases where there's an ambiguous ordering it's reasonable for the editing system to just choose one (because everyone will get to see interactively which order was chosen, and then they can fix it if necessary). A VCS needs to be more willing to throw up its hands and ask for someone to disambiguate.
I didn't mean to hint that pijul was planning to change anything; I don't have any insight into their plans. &amp;#x200B; I do agree that deleting patches is generally bad, and that a VCS UI should be designed so that it isn't the natural thing to do. I don't agree that it should be impossible: experience with git suggests that "git reset" is a pretty useful thing for manipulating your private working copy. Of course, public repositories should be append-only.
Sure, let me know when you have something to publish and I'll transfer the name.
if in doubt add the `--vcs git` to `cargo new`
Thanks a lot! &lt;3
I'm reasonably happy with the scope and the progress we've been making. I admit it's a bit of experiment to take so much on. My plan for managing it is to delegate lots to other contributors, and that's been working pretty well. The winit question wasn't just about that PR being merged, but an evaluation that the cost of coordination and dealing with the architectural impedance mismatch would be more than writing what we needed. This decision was based on other inputs, including discussions with the Rust VST group, which had also done a similar evaluation and come to a similar conclusion. But I see the value on converging to one solution. Here I pose a challenge. If somebody can demonstrate that it is possible with winit to achieve smooth window resizing on Windows with performance competitive with what druid-shell offers, I'll reconsider and likely switch to winit. But I think this will be a lot harder than people think. If you're at LGM, I look forward to meeting you there! I think we'll have lots to talk about.
*cough cough* Haskell has Applicative functors *cough cough*
100% Yes. Thank you. 
Sounds reasonable. We use it in production with actix-web too.
PR's are always welcome! Though I'm not entirely sure that migrations is the responsibility of the application. I think it would be nice to have them in debug build, but not in release.
[https://github.com/KallDrexx/rust-media-libs/tree/master/examples/mio\_rtmp\_server](https://github.com/KallDrexx/rust-media-libs/tree/master/examples/mio_rtmp_server) There are also bindings to gstreamer: [https://gitlab.freedesktop.org/gstreamer/gstreamer-rs/](https://gitlab.freedesktop.org/gstreamer/gstreamer-rs/)
You should see a doctor about that.
I was reviewing [this error handling code from a sample Rust project posted today](https://github.com/TatriX/realworld-rust-rocket/blob/master/src/routes/articles.rs#L34-L57), and it looks unlike most other Rust error handling code I've seen, but I'm struggling to find a way to make it more idiomatic. I've created a [minimal executable example with passing unit tests here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b7ae888cfb448ade2274a8e03a7a1671). The `validate` function in the example works, but it seems to me that there should be a better way to handle this without the golang like `if !err {return err;}` block.
FYI, I've posted in the weekly questions thread trying to get some help refactoring the error handling. https://www.reddit.com/r/rust/comments/aru33x/hey_rustaceans_got_an_easy_question_ask_here_82019/egzs10c
What's VST? 
[A plugin standard](https://en.wikipedia.org/wiki/Virtual_Studio_Technology) for audio effects and synthesizer modules, to integrate with digital audio workstations. There is a [rust-vst](https://github.com/rust-dsp/rust-vst) effort.
At a minimum, it absolutely cannot be done with a model that only understands lines or any sequence of tokens. Programs are representations of ASTs, not sequences. If we were programming in ASM, there _might_ be an argument. Even then, the idea that a line of code has an identity that you can track over time is a fiction we create in our heads. It doesn't exist in the code, and a VCS only has the code to work with.
If pijul patches are analogous to git commits, then git reset is not analogous to unrecord. Unrecord actually deletes the patch (as far as I can tell) which has implications for all... downstream? versions in the repo (in git it would be upstream, but the arrows seem to go the other direction in pijul). Reset only updates a branch's pointer, nothing is deleted and no other versions of the code are impacted. So I guess I still don't see a use case for the user deleting patches / commits (short of saving space). For context, the only time I'm aware of git actually deleting a commit is if the garbage collection operation runs while there are dangling commits with no references to them.
By the way, this is in no way a criticism of you. I'm actually very thankful for these blog posts. They taught me more about pijul than all of pijul's documentation. It also taught me about patch theory. My suspicion though is that patch theory is not very useful for source code VCS's.
Up to you. I personally can't think of a reason why you wouldn't want your server to ensure your migrations are up to date on launch.
It's also worth noting that text editors aren't the only things that modify code. Think about any refactoring tool. Would all refactoring tools be required to record their operations with the VCS if any? Personally, I often use shell commands for modifying my source code, commands created long before any such omniscient VCS.
&gt; since it is said to be the most accurate emulator [...], and although it's only released for Windows, it's actually open source and it works well with Wine. Sounds like [Project64](https://en.wikipedia.org/wiki/Project64) for the Nintendo 64.
Sometimes migrations can be complicated and you want to manually ensure that everything went smoothly in production before letting users in. But for the demo, sure it would nice be reduce number of steps user has to perform.
Try here: https://tokio.rs
Huh, I never knew that Project64 worked well with Wine. I always just ended up using a different emulator when using Linux.
Well, there's currently work on supporting WebAssembly without LLVM, so maybe more non-LLVM backends will be coming to Rust at some point in the future.
I think you're looking for r/playrust
Oh, that's interesting. Thank you (and sorry for the long delay!).
It's appropriate; despite the ecosystem churn anticipating async/await, Tokio's streams and channels should work for this; you'll also want Hyper (or a web framework that doesn't hide Hyper too much) if they're over HTTP. I wrote a video relay server for WebM streams last year that works fine: https://github.com/Tangent128/webmetro/
Have been experimenting with the new Channels-based API over the past few days (mainly to handle network requests and updating UI elements with the responses from those requests). Really liking it thus far!
Extremely disappointed that your stance on correctly licensing other people's code (especially when it's MIT so the due diligence is trivial) and giving polite credit when you fork other people's projects is that it's a [waste of time](https://github.com/rust-iendo/yarte/issues/5#issuecomment-465643428). 
So instead you forked their code without credit and without adhering to the very trivial requiements of copying MIT, describing it as a [waste of time](https://github.com/rust-iendo/yarte/issues/5#issuecomment-465643428). Also, with all due respect, there is nothing wrong with making money off of open source; you yourself link to a Patreon at the bottom of your Readme.
Ideally, rustup could parse this information directly, and list versions that match certain criteria. I think nightly is going to be a feature in many peoples' use of Rust for at least another couple of years...
Why though? If it's immutable compiler can do more optimizations. 
I think it only does this if you already have a git repo set up in the directory? I haven't tried on Windows though.
The nice thing about Rust is that its usually Fast Enough by default, so one usually just doesn't have to worry much about the details and leave the optimization to the machines.
I think you replied to the wrong comment; I'm not OP nor am I affiliated with this project 
Yeah. It works really nicely and I'm *very* glad for that because, for some games, it's the only way I've found to get them to work on Linux. (eg. Donkey Kong 64)
I remember there being a lot of work done on a cycle-accurate N64 emulator a while ago. I wonder how that's coming along.
I would love if Rust had strong support in one of the DL frameworks. I think there are a lot of people that would be interested in such bindings. I would go with MXNet over PyTorch even though when using Python I prefer PyTorch. MXNet is open to having language bindings in multiple languages. Once you get a minimum viable product you could donate it to the main project. Bindings that are part of such a large well known project are likely to attract more contributors than bindings maintained under your account for PyTorch (I could not see PyTorch officially supporting Rust). MXNet is also attempting to become an Apache project which may help in attracting contributors. MXNet officially supports the C API to allow bindings whereas PyTorch provides a C++ frontend which is more work to maintain bindings for. It's a lot of work to create and maintain such bindings, I think that MXNet represents a better choice as once you get it to a certain point it can become more of a community owned project. By the way just the other day someone on the MXNet mailing list was asking about Rust bindings.
I'm the kind of person who burns himself out chasing unit test coverage and I don't have any experience writing performance regression suites.
Thanks! I don't understand why you say that patch theory isn't very useful for source code VCS's. I mean, I agree that it isn't capable of understanding your intentions and getting everything right, but I do think it's an improvement on the current systems (which are also not capable of understanding your intentions).
So I'm not sure exactly what pijul does, but the toy VCS that I wrote (which is called "ojo" for at least the next 12 hours...) is non-destructive in the same sense as git: if you unapply a patch then it is still in the repository, but it is merely removed from the set of patches making up the current branch. &amp;#x200B; Anyway, I think that's orthogonal to the other principle I was talking about, namely that public branches should be append-only. Indeed, although git allows you to reset and push to a public branch, its UI tries to discourage that. &amp;#x200B; (And I think both of the above issues, although important, are orthogonal to the question of how the history is represented and managed internally, which is what the patch theory part is all about.)
When you say "stream a video", do you just mean serve a video file over HTTP, possibly with some strategic rate limiting? Because that sounds pretty easy in actix-web. Live capture, or transcoding, or something like that might require a lot more library support. Similarly, it would be slightly more work to support byte range requests, and possibly quite a bit more work to support time-unit range requests (IDK if that's even a thing that browsers attempt, though I would kind of hope so).
You need to install the opencl c headers. 
I think that thought goes a bit too far into the extreme side (what solutions do cloudflare or Netflix require for video). &amp;#x200B; Video is a wide field. Everything from streaming one compressed video to streaming thousands of compressed videos concurrently, or even handling lots of different uncompressed life-streams in realtime. &amp;#x200B; I think the question is mostly about compressed video, and for that the requirements are very similar to any file download server (since HTTP Live Streaming (HLS) and MPEG Dash are actually nothing different than that). Handling a single file download with somewhere between 1 and 10Mbit/s is easy in every environment. An order of magnitude more is still fairly easy. But at large scale one might need a very special and optimized solution, like those described in the blog posts. &amp;#x200B;
Here is the GitHub link: [https://github.com/bcamp1/Gravisim](https://github.com/bcamp1/Gravisim) &amp;#x200B; \- Any suggestions additions, clean up, or changes to the code is welcome! Make a pull request. Our goal is to make this a clean example of what rust can do. \- If someone knows how to port this to iOS / Android, that would be awesome! \- If someone knows how to make this a windows exe with the libraries installed, I would love the exe so I can distribute it to my windows-loving peers (I have a mac) 
At the point where `s` is used it's not longer required to be mutable, and the compiler should be smart enough to figure that out. So it's definitely worth an issue.
Please check out `quicksilver`. It is a simple 2D game engine.
In this code, the validation parts are all run, even if the first one already `Err`ed. This is something that is not very often done, but I consider the code idiomatic. The alternative would have been an `errors?;` statement, and that would look weird by itself.
In my opinion, the easier is to just call the C++ code from the rust code with the cpp crate [https://docs.rs/cpp/0.5.1/cpp/](https://docs.rs/cpp/0.5.1/cpp/) 
This reminds me of the game [Orbit](https://play.google.com/store/apps/details?id=com.ChetanSurpur.Orbit). Have you played it? It's awesome.
Congratulations on the work for the new release. Since I will only have access to a Linux system in a couple of days, how long are Pango compile times now? It is one of the reasons why my dummy app takes around 18m on a dual core.
Is the fps hard-capped? Or what do you think is the reason for the relatively low fps? Nice stuff though!
Yes, it's great!
Im running this on a 2017 MBP with an i5. I turned on Retina display for the program which basically doubles the resolution. Without Retina display it gets 300 - 400 fps.
PyTorch!!!
Forgive me if I'm wrong here, but wouldn't most of the overhead be calculating the physics not drawing the objects on screen? Thus I'd assume resolution to make a minor overhaul impact on the FPS?
Zach Boldyga had sent me an email talking about my project and the MXNet mailing list. I also reply on the mailing list but it seems that people pay little attention to the rust binding.
I want to rephrase this now that I've had more chance to think about. I've been wrestling with the winit question, and in the long term I would love the Rust ecosystem to converge on one solution. But making winit do what we need is more work than I want to take on right now. So I think the right way to think about this is that the code in druid-shell is a requirements document for what I would like winit to be able to support. At the heart of those requirements is performance, and I believe running code is one of the absolute best ways to express the performance goals, along with hard data on what's achievable. The "challenge" probably came across as aggressive, but I don't mean it to be. I think taking it up is a good idea, as I think there's lots to be learned from it, a synthesis of fairly intensive study over a long period of time. Determining the performance methodology will take some work. In particular, I've used an Arduino to measure input-to-display latency and am willing to put some work into polishing and releasing those tools. It's not my intention to do "Not Invented Here," and I think the best thing for the ecosystem would be for winit to evolve. I'm willing to do my part to help make that happen, which is why I filed #786 in the first place.
To me the value of using winit is not to have one single solution. The value is that people **vastly** underestimate the difficulty of creating a window (I can't under-stress vastly enough). Winit has started in 2014 and has gotten thousands of hours of work put in it. And yes I agree that it's crazy that such a stupid problem is still so complicated in 2019.
What algorithm are you using to compute interactions? Real Newton laws? 
I hate how loosey goosey C++ feels. And there are some things you have to do that make you notice the inefficiencies. Oh, look a copy, another copy, random memory usage, stale pointer. Ugh it's just gross. On the other hand. Had a C/C++ programmer peering over my shoulder watching me code some rust. He said the syntax was gross. I then goaded him about his Objective-C days. 
I recently designed, coded, TOSSED OUT THE ENTIRE PROJECT, designed again, coded. I feel you. 
Nah, two body simulating your cap is going to be memory fill rate on the gpu. Especially at a retina resolution.
Uh that might be a tough one. 
Honestly I don't care. If you only generate simple bindings and do not provide high level primitives (like pytorch nn module does), it will still be very painful to use. Other viable approach is just to build autodiff above arrayfire primitives. And what is tvm (in "tvm will support training")?
I care
This reminds me too much of habitat.sh
Have you seen the stratis filesystem. Created in rust and python. My gripe is who decided THAT for a FS. But I bet they have some cool FFI stuff you can borrow for this. 
Adding to your question, which integration method is OP using?
My hopes is that just like IPFS we can have IPCPU. And maybe an IPGPU then all we'd need would be a dumb terminal, a network card, and some more ram. 
What part of dataframes are going to be implemented. Are we talking full Pandas style dataframes or something simpler? 
Additionally, here is the documentation for it: [https://docs.rs/diesel/0.16.0/diesel/macro.embed_migrations.html](https://docs.rs/diesel/0.16.0/diesel/macro.embed_migrations.html) It's from an older release, but I can't seem to find it in recent versions.
Here's a good [blog post](http://www.brunton-spall.co.uk/post/2014/05/06/database-migrations-done-right/) on why you might want to separate db migrations from application deploys.
When working on some FFI bindings, the question came up if returning an `enum` with only discriminant values (and using it from C) like this is well-defined: #[repr(C)] pub enum E { X = 1 } #[no_mangle] pub unsafe extern "C" fn f() -&gt; E { E::X } Can I call `x = f()` from C and expect `x` to properly compare to `X`? 
Are you wanting to write the frontend in Rust as well? Actix and Rocket are more than capable of the tasks you listed with server-side rendering and some JavaScript, but I'm not sure if you're asking for that sort of frontend functionality in pure Rust.
Awesom! Nice progress on the zooming feature. Got to implement this for my own galaxy simulator... (https://github.com/wullewutz/nbody)
[TVM](https://tvm.ai/) written by [Tianqi Chen](https://github.com/tqchen), who's also the author of MXNet. It was designed as a frontend compiler for all dl framework, but the [roadmap](https://github.com/dmlc/tvm/issues/2623) says it's going to support training. If it does, there will be no need to bind the MXNet, since we can just use those operators to build a new dl framework for rust. Arrayfire is a good choice, but it support up to 4D array, which is not enough for deep learning. Besides, it doesn't support cudnn.
It's possible to use proc_macro to mark which attribute of a struct is a Module, make it work as `torch.nn.Module`.
Looking at the code he is using Euler's method :(
CEN64 has been fairly playable for a year now, at least in multithread mode.
&gt;\[...\] in most of the Rust code that I reviewed, there are a *lot* of *unwrap()* calls, because trying to handle all errors is too much of a burden. When you aren’t doing that, your code size balloons, but the complexity of the code didn’t, which was a great thing to see. I don't understand this part. Changing .unwrap() to ? and the return value to Result&lt;T, E&gt; doesn't really make the code size larger. Where is the code size ballooning happening? &gt;The type inferencing bit also come into play when you write the code, because you don’t have the types in front of you (and because Rust *love* composing types) it can be really hard to understand what a particular method will return. Well, just add the types to the variable declarations or a turbo-fish to the function call. I sometimes do it if it makes the program easier to understand or during experimentation. &amp;#x200B; &gt;However, Rust is full of ceremony that sometimes seems really annoying. You have to use *cargo.toml* and *extern crate* for example. No, not with the 2018 edition. What are the other examples?
You need to start from somewhere!
&gt;If someone knows how to port this to iOS / Android, that would be awesome! There are target for apple osx and ios you can use to cross compile your project for the platforms for arm, x64, i386 chips. $ rustup target list Not sure how to wrap that into an ios app. but for android you probably should separate your app from the lib, then create an android app and access your gravity lib (computing) from a JNI or similar. Maybe it's possible to install rustc on android as well. 
I recently pushed reworked validation&amp;extraction. I hope it's more idiomatic while being more concise.
AWESOME x 100
I would also love to have DL framework for rust and I would go with MXNet. It has a C API that is nicely managed by the community for more than one language. PyTorch focus more on Python. They don't really care about other languages. I would also like to help with the mxnet rust binding. :-)
I'm so glad you are continuing this! I'm very interested in pijul, but I've been put off by the absolutely atrocious documentation. Your posts are the only things I've found that explain how it works. I'm particularly interested in the details of 'antiquing'. It seems a bit like 'descent' from category theory. Does ojo have this?
If the C definition matches and is only used with the values it defines, then yes: https://doc.rust-lang.org/reference/type-layout.html#reprc-enums However, there are some things to consider: &gt; Note: The enum representation in C is implementation defined, so this is really a "best guess". In particular, this may be incorrect when the C code of interest is compiled with certain flags. &gt; Warning: There are crucial differences between an enum in the C language and Rust's C-like enumerations with this representation. An enum in C is mostly a typedef plus some named constants; in other words, an object of an enum type can hold any integer value. For example, this is often used for bitflags in C. In contrast, Rust’s C-like enumerations can only legally hold the discriminant values, everything else is undefined behaviour. Therefore, using a C-like enumeration in FFI to model a C enum is often wrong.
I'm a bit surprised that no one mentioned that enums and structs are the basic tools used for modeling the data (the objects, entities, relations, connections) of whatever you want to software-ify. Enums allow you to model objects of the problem domain, on particular those, that have some kind of well defined state, where the possible states can be enumerated. For example a faucet can be closed or open. And if you want to, you can tuck a raw data value - that corresponds to the state - into the enum. For example it's Open(u32) so you know how much open is it. (Maybe a car analogy would work better, with the car states composed of stopped, moving and for moving a corresponding speed is stored.) Or to compare to something that comes up in JS, an enum is ideal to represent the possible states of an XHR request.
Perhaps a VCS can support both a semantically rich input from an editor and a before/after view of the file from other tools? On the other hand, in most cases when I ran some tool over the source files I find it necessary to run that tool on other branches as well before they can be merged. Think cargo fmt, cargo fix etc. It would be nice if the VCS could have info about that instead of just having the before/after view and thus avoid merge conflicts.
Pango never been long to compile iirc. Gtk however... :p
It's an interesting comparison. Thanks for sharing it! (I think you've pretty much reinvented an old, old protocol style, except the original had 3-digit codes on the front of messages, which are pretty handy. SMTP is an ancient example of this style—yes, it's request-response, but the same style could be used in a symmetric protocol.) I'm not sure how comfortable you are in Rust, but it sounds like much less than in C. It takes about a year of regular programming and study in Rust to get used to it: there's a lot to absorb. The same can be said of C, but many of us put in that year ages ago. I've found the extra time invested in Rust to be worth it. Using `tokio`/async-await for this task is not what I would have done: it's way more machinery than you want to bring into a simple problem like this, and it's not really finished yet. I'm not seeing the source code for either implementation offhand. Are they available somewhere? (I wonder if your C code still has memory bugs?) Sincere thanks for an interesting viewpoint. As an old-school C programmer who is now firmly in the Rust camp it's nice to get some perspective on what people are seeing.
Great! Feel free to email me if you have any question about current code.
I'm a bit mystified by the comment about ceremony as well. You need to add something to cargo.toml and use extern crate, sure, but how does that compare to C? You have to install / compile your dependencies then instruct your build system to add the correct path to the include path, and to link to the correct libraries. And then you have to actually include the headers too. Doesn't seem that much simpler than Rust to me
Haven’t tried out Habitat. I wonder what those platform independent artifacts are and how they compare to OCI images. Furthermore, which languages do they support? It sounds cool though, will give it a spin. Thanks!
&gt; In this code, the validation parts are all run, even if the first one already Erred. Yes, that is one of the interesting requirements. I believe the goal was to provide the user feedback about everything they did wrong, rather than just the first thing. The reason it doesn't seem idiomatic to me is that `b` and `c` (in the playground example) are initialized with invalid values, and the compiler can't enforce that we check for errors before using those values. I created another playground which introduces a `Combined` type and a `Combiner` trait that somewhat solve the problem. At least now the `validate` method looks how I'd like, and there are no cases where variables are initialized with invalid values. Of course implementing `Combiner` for every possible combination of values is infeasible, but perhaps a large number of them could be implemented with clever use of macros? https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=6eee2170e0e7d91f610192dfb948fa2a
Thank you so much for this!!! The and\_then solution you provided is ultra clean! :D Now I feel extra motivated to study more Rust (I'm on chapter 14 in TRPL book). &amp;#x200B; Have a great weekend, Sir! :D
https://github.com/ayende/generic-network-protocol seems to be the C one. The one in Rust doesn't seem to be public. Pinging /u/ayende as he might not be aware this was posted here.
Live capture. Somewhere something runs. The proxy proxies it to other site, which perhaps have better tools for control access to that video for the video creator for example. That obviously would require hiding any original source links to the video which might be implicitly publicly accessible (but due to long url token or something, good luck guessing, but if you get the source link, when you can share with people who haven't paid for the access for example, or just save the link and have access to it even if lets say subscription ran out).
I'll check it out, thanks.
The rust code is in the rust branch. https://github.com/ayende/generic-network-protocol/tree/rust
In many cases that is true but in C/C++ there is a culture of single header file libraries that make adding things fairly simple ([https://github.com/nothings/single\_file\_libs](https://github.com/nothings/single_file_libs)). It is not as good or complete as cargo but avoids some of the things you describe. &amp;#x200B; Slightly off topic as the author didn't use any but I personally find them very useful when coding in C/C++ &amp;#x200B;
I was kind of excited then, ick: &gt; Unfortunately, as the STL often uses internal self-references for optimization purposes, such as the small-string optimization, this disallows most std:: classes. (https://docs.rs/cpp/0.5.1/cpp/macro.cpp_class.html)
As this is done with SDL, it should be a bit easier. I saw a tutorial a while back for packaging Rust SDL apps for android, but it's a bit more complicated compared to an SDL app in C++.
I'm using newton's inverse square law. It BADLY needs integration. Please add it if you want to help.
That's really cool
It's mostly the GPU, until you spawn in hundreds of planets
&gt;It's one of the reasons I've been sticking to I/O-bound projects c'monnnnn 
For android, I found [this](https://lliwynd.blogspot.com/2018/05/rust-for-android-games-using-sdl2.html). I haven't tested it, but it might be helpful.
You should use owned strings (`String`) instead of `&amp;'a str`.
Hey, it looks like you're using basic Euler integration at the moment. This works for a quick test, but it has several problems: the error grows over time, and more egregiously, it doesn't conserve energy - this last one means that orbits will eventually decay, for instance. It would be better to use [velocity Verlet](https://en.wikipedia.org/wiki/Verlet_integration#Velocity_Verlet). I might submit a pull request adding that in a bit.
Hey, this was exactly what I noticed! The orbits keep getting more elliptical until they escape. If you submitted a pull request that would be AWESOME
you could go async but for that small amount of concurrency i would save myself the pain and just run 20 threads honestly. depends on what your requirements are.
Done :)
This bot is cute :upside\_down\_face:
Yes, the network protocol itself isn't anything really interesting. It is just that it is sufficiently non trivial task for me to explore a lot of topics. The asymmetric part of the protocol make it very useful for a lot of scenarios, but that is probably just outside the scope. I would love to see an alternative implementation.
AFAIK failure is **not** the standard for error handling. As also stated in the Readme it was a nursery for a better Error trait which lead to the changes in the issue you linked in the std. The future of the failure crate seems to be unsure and it might be superseeded by the update std implementation. I personally would go for the std because of future proofing and interoperability. But that is a matter of taste I suppose. 
&gt; One of the missing pieces in the Rust ecosystem is text layout. It's a little hidden as a library but [glyph_brush_layout](https://docs.rs/glyph_brush_layout/0.1.5/glyph_brush_layout/) does basic bounding boxes, alignment, and Unicode word wrapping with multiple font types and weights.
A direct answer to &gt; any alternative to reqwest in rust You could try [cHTTP](https://docs.rs/chttp). But if "reqwest is taking too much time to execute", I don't know how to solve that. Can you elaborate a bit on what you are doing? Reqwest is not slow, if that's what you're getting at. Maybe your Internet connection is slow? Or if I understand correctly, spawning 20 processes is slow, try spawning 20 threads instead.
Just FYI, you aren't using the Rust 2018 edition. To do that, add `edition = "2018"` to your Cargo.toml file [here](https://github.com/ayende/generic-network-protocol/blob/c31c21ae6aea305bc01c4858f716371b39ba4a77/Cargo.toml#L5). At which point you can run `cargo fix --edition` to have it migrate your code. That should also remove the `extern crate` statements in your `main.rs` file.
I'm very specifically talking about text layout that can do shaping for complex scripts (and refined typography for Latin etc). Because I'm going to do my work at a low level, I think it's likely that glyph_brush_layout can adopt my crate as a dependency, to get these features.
Had a friend in undergrad who made exactly the same thing when he was learning Python, eerie how similar it is 😅 Looks really really cool
Yes of course it is a copy that goes almost three times faster with a lot more syntax. It is a copy where the compiler goes by stack instead of recursion, where simd is used, with memchr and syn to parse until the last expression of Rust. It is a copy of the interface supertrait of Display. It is a copy of the MarkupDisplay that escapes by type without cost. Eachs that detect the internal use of special variables so as not to put the enumerate. The scope control, the search of imports, the control of the extension, and a long etc that you can discover by launching \`diff -r\` in addition to being built in a structure reformatted completely and scalable to infinity. Which is impossible, and I challenge you to try it with the current structure of askama. Instead of making me spend time writing in a post when I could be writing code. And that is why there is yarte, because the structure of askama, should be reformatted. Use what you like best. Above all, program, never stop programming. &amp;#x200B; I'm fed up, the next I copy the output of the **cargo bench** and the **diff -r**
Wow! Has 3(N)-body problem been solved already?
I personally am more concerned with ecosystem coherence. And yes, window creation is a hard problem. I've read through the winit codebase pretty carefully by now and am grateful to have it as a reference, as code is one way to encode the arcane references. There are a few other references I've found helpful as well, including [minifb](https://github.com/emoon/minifb) and [rutabaga](https://github.com/wrl/rutabaga). The latter is in C, but it's battle-tested to work well in the VST case. It's good to see different ways to do things - for example, minifb uses Objective-C for the macOS platform code, which from what I can see is more performant and more understandable code than using the [objc](https://github.com/SSheldon/rust-objc) crate. As I've written, a particular subtopic that's hard is smooth resizing, and I've similarly put a big chunk of time into figuring it out. It requires binding WM_ENTERSIZEMOVE and WM_EXITSIZEMOVE, and also having a very synchronous approach to painting and other events. I've skimmed through [winit#638](https://github.com/tomaka/winit/pull/638) and can't figure out how to implement my approach. I'm sure it's possible, but it's also not easy, as it almost certainly requires changes to winit. Also, "events loop 2.0" seems more complicated than just having callbacks tightly bound to the platform event loop, which is what druid-shell does. Perhaps I'm just not understanding well.
I'm not sure you can have any useful analogies here, they are misleading. I suggest you to show some key concepts: 1. Traits instead of interfaces. Tired of TaskExtensions, DitionaryExtensions?.. Always wanted to declare static members in interface? Here we go 2. No more nasty `using's and "Should I dispose Steream input parameter when I'm done?" and so on. Welcome: ownership. 3. No more NullReferenceExceptions 4. No more visitors: hello, ADT. 5. Welcome Self placeholder and associated types in traits: no more `Foo : IComparable&lt;Foo&gt;` 6. No more thoughts "hmm, is this query rare enough so I could use LINQ or should I hand write it?". Welcome: free iterators. 7. ... More you can imagine. I think it's better approach, because it explains "Why"s instead of "How"s. If they see why they will get "how" themselves.
Easy do not use it. Use askama the original.
very good sugestions! will be included! \^\^
Patch theory feels like a mismatch with the goal of what a VCS is trying to do. Holistically speaking, a VCS allows you to save snapshots of your code so you can restore any snapshot that you want. Saving the edits is certainly not necessary, so it would have provide some uniquely useful functionality. I haven't seen anything yet that is compelling to me. It looks like it can help in fringe cases like reapplying merge conflict resolution and such, but even then it requires the user to be disciplined to gain value there. Is the cognitive overhead of patch theory really worth those fringe benefits? I'm not so sure.
You can try the `ifaces` crate on Unix and `ipconfig` crate for Windows. I don't know any that works on both platforms.
It sounds like your tool is making better fundamental design decisions, nice! As far as append only, you have to be careful with what you're talking about. In git, branches don't get appended seeing as they don't store any content. They are pointers to commits, the only operation you can perform on them is to update the pointer. So it sounds like from a git perspective what you want is to only fast forward branches. I think that's a good practice for long lived public branches, but I'm less strict about it when it comes to short lived branches, even public ones. The usefulness of rebasing over merging is significant enough that I would not want to restrict myself to not being able to rebase public development branches. Typically there is only 1 or 2 developers working with those branches, so the pain of a non fast forward change to the branch is not so bad. This is especially true since such a change doesn't lose the commits as they will remain available in the ref log for some time.
`reqwest` should be pretty fast. What do you mean by "taking too much time"? Are 20 concurrent `curl` invocations faster on your network connection?
Hi TravisVZ! I work at nFront Security where we offer a password filter for Windows. We offer custom password dictionaries to prevent the use of commonly hacked passwords. This is similar to checking passwords against haveibeenpwned, however you won't have to make any external calls. Please feel free to reach out to us and I'd be happy to put you in touch with some of our customers if you'd like to know their experiences with nFront. We're currently in over 50 different countries. Here's our website: [www.nFrontSecurity.com](https://www.nfrontsecurity.com/) 
&gt; Yes of course it is a copy Exactly. 
Thanks! Ye, looks like there is no cross-platform way of doing it :(
The way I see it, failure is effectively a stable preview of the future std. So if it isn't the standard, it should be thought of as an implementation of the standard. Although I could be wrong, I've been hoping that using failure is *more* future-proof, since you don't need to worry about the coming deprication of std's error system. And if std never makes the switch, failure will remain popular. Plus, failure is perfectly inter-opable with all major error systems (error chain, failure, and std) used by imports. Sure, an importer may want an std Error instead of Fail but OP is making an application not a library, so that isn't an issue.
This is so rad!! Can't wait to get into trying out stuff like this after I read the rust "nomicon"
All of that is fine, this is all exactly the point of open source. No one is saying it's bad that you copied it. We're saying it's bad that you copied it without following the terms of the license of the original code.
Couldn't the Rust version use iterators to avoid bound checks? Also that inner loop looks like something that could benefit from explicit SIMD, either using shuffles, or gather / scatters. 
That's great to know!
Actix has an async HTTP client that perhaps could be useful? At the end of the day keep in mind that you might just be bound by network speeds, too.
Wasm doesn’t support SIMD yet.
This article describes the Rust implementation of the procedural generation algorithm known as "Wave Function Collapse", from the author's https://github.com/stevebob/wfc crates
This was from Dropbox a long time ago: https://dropbox.github.io/divans/
That’s describing the native implementation; wasm is still single threaded and doesn’t have SIMD support.
[https://doc.rust-lang.org/nightly/core/arch/wasm32/index.html](https://doc.rust-lang.org/nightly/core/arch/wasm32/index.html) 
That’s sort of like Rust nightly; it’s not something that’s in the spec yet. See https://github.com/WebAssembly/proposals/issues/1 You can read the draft text linked from that issue, but it’s not actually in the specification yet.
Would you mind rephrasing that into something I can constructively respond to?
Being uncomfortable about compiler optimizations is a strange reason to stick to IO bound tasks. For one, it avoids the entire set of tasks which are not IO bound, but which will perform just fine whether you perfectly massage you code for optimum performance, and really, almost no code has been perfectly massaged so you will be in good company. Modern C/C++/Rust compilers do an amazing job, so imperfect is still amazingly fast almost all of the time. 
This, x100. Rust is slow to learn as a beginner, even if you have a lot of experience in a low-level language like C. It takes a lot of concepts you may be used to and reframes them in a totally different context that solves the problem, but also requires you to re-learn solutions to those problems. For example: - Data races are replaced by ownership and aliasing errors - Use-after-free bugs are replaced by move semantics errors Rust's solutions to these problems tend to leverage the type system as a way to enforce consistent and safe rules. If you're not used to the subtleties of affine type systems and functional approaches to types, this can seem like annoying busy work at first. Rest assured that with practice, this problem will resolve itself and you'll become accustomed to predicting what the compiler will complain about before it does. But again: this only comes from practice.
I don't really like javascript, but I would expect to use it in the frontend. I've looked at Rocket and Actix. I plan to play with at least one of those when I've got some more time. They are just both a bit more barebones than I'm used to. I'm also still learning Rust.
The [current tiling implementation](https://github.com/GoogleChromeLabs/squoosh/blob/master/codecs/rotate/rotate.rs) uses iterators a bit more. (Disclaimer: I contributed some extra complexity there due weird behavior I saw from V8, see [this](https://github.com/GoogleChromeLabs/squoosh/pull/474) and [this](https://github.com/GoogleChromeLabs/squoosh/pull/476).)
is there a way to prevent rustfmt from touching my blank lines? i want this trait Neuron { } struct NeuronRelu { } impl NeuronRelu { } struct NeuronOut { } impl NeuronOut { } impl Neuron for NeuronOut { } but this piece of shit turns everything into monotonic slate of garbage. like, fuck off! in config there's only unstable option to have max/min blank lines. is there a way to disable this ``feature" COMPLETELY?
You can use the async client of reqwest and spawn 20 get request futures. 
I liked and i will support it.
Really nice!
IMO, the \_most\_ ridiculous aspect of this thread is that Rust (arguably) \_does\_ have [fully automatic memory management](https://words.steveklabnik.com/borrow-checking-escape-analysis-and-the-generational-hypothesis)!
/r/playrust
Hey there! Unfortunately, this subreddit won't be able to help you much -- this is definitely a post that belongs to /r/playrust. &amp;#x200B; Just wanted to say, though: Your polite post made me do a double take. This subreddit has relatively high expectations for etiquette, so it wasn't unusual for THIS community, but it's unusual to see somebody request something nicely on the internet in general! Kudos to you for making the internet a better place to be. :)
It seems like this would be better posted on the relevant issue on GitHub where the discussion is occurring.
You actually can make a cross platform program that does this, there's just no single cross platform method because the system architectures are too different. You can, however, detect the target OS at compile time and set the correct implementation yo use.
So does F77 btw. Turns out automatic memory management is really easy if you don't let the user arbitrarily allocate memory and create references between allocations. 
I wonder what the times mean
`int` and `int32_t` are definitely not as good as a simple `i32`.
&gt; Now, borrow checker could be useful if you have a team of junior programmers who don't know anything about ub, but are there any such workplaces in reality? Yeah, I can't recall any memory bugs ever affecting serious software. /s
Saying that someone ha severe autism trouble because you don't like the syntax is not respectfull. I like the separation of field function, because of the trait system and the fact that you can implement method on every type, not just struct. let saus enum. Furthermore there are traits which require a separation too. So this is quite elegant actually.
I did say *one of* the reasons. It's not about being uncomfortable with compiler optimizations. It's about having been habituated to having Python as the best option for my needs for so long (I've been using Linux without dual-booting since the early 2000s and I don't trust myself around C or C++) that: 1. I tend to gloss over ideas which would require me to write CPU bound code without noticing. (eg. I'll think of ideas that could be solved by shelling out to ImageMagic or binding to libxml or OpenCV but ideas where I'd have to write my own CPU-bound code tend to get squashed by the impulse to check my backlog of ideas or projects in need of work before I become consciously aware of them.) 2. When I do think of a CPU-bound idea, I tend to wind up at "Yeah, but what if. I have no idea how to intuitively evaluate the *amount* of performance I'd need for this... and I can't read assembly. What if I spend all that time writing some code and then it's *not* already fast enough. Let's just take the low-risk option and do something familiar instead." 3. It's made me lazy in the sense that, if the CPU-bound portions haven't already been done for me in PyPI or crates.io, I tend to either go looking for another language where they *have* been done for me or try another project. (Though, to be fair, this is partly because I've burned out so many times from trying to reinvent type system-esque guarantees in unit tests for projects where I chose Python for the ecosystem that I tend to feel like my coding output is nothing but a pile of backlogged work. That's the main reason Rust appeals to me. The powerful type system.) The closest thing to being uncomfortable with compiler optimizations is that I take great comfort in an "edit, run automated tests, repeat" cycle and I haven't had time to read about statistical analysis so I can merge "running time changed in X way" into my usual "Run the suite. Did the number of failures increase?". (Compared to, for example, my on-hold project to write a heuristic "filename to title" routine, where the tests generate an accuracy metric based on a corpus of input strings and information on acceptable, attainable, and ideal target strings and I can have the improvements and regressions boiled down to a simple integer score.) That said, now that I think about it, I do actually have one on-hold project which is guaranteed to at *least* be CPU-bound in Python... a parser for the "theoretically machine-readable" outline note syntax I've been evolving since high school... because it's too NIH to ever have a ready-made parser in *any* language's ecosystem.
Thanks, I haven't had a good laugh in a while.
It seems pretty clear you're missing the point of the language. Try doing the same thing in C++ (or C!) and see how it compares. Or just go use a GC language since you seem to want that. Whatever you do, maybe be a little more measured in your language next time. Name-calling in critiques isn't a good look.
I never heard of your project until now, but I like it. I doubt I'll contribute anything else than possibly fixes for bugs I encounter, but I'll definitely use it.
Numerically? Yes.
This syntax had drawback :braces. Maybe it's you don't write async code often it's not a problem. But trust me, when you write I-do-not - know - what - thousand-await you will curse a guy invented braces it async code. You can learn it yourself if you write js, c# or any other major language with async
Code is read immesurably more often than written. Now you are reading rust sources andd come over i32... except it's actually f32, but you can't notice the difference. OH SNAP. i personally use float, double, byte, ubyte, short, ushort, int, uint, int64, uint64 in seppls.
Well i'm no mozilla teamlead, but at my day job we have a pretty huge codebase, alright, and it's fucking awful too. Tens of 1000-line templated lambda state machines sort of awful. And it's thoroughly tested by a team of 30 men, since we work in finance. Now, with clang sanitizers i can't remember a single uncaught ub that ever caused a bug.
That is so cool ! A while back I discovered that, but the documentation was not great so I did not really understood it (and tried to play with it and Minecraft, it kinda worked). Can't wait to try it again (and understand it) !
I dunno what to tell ya except that I've never mixed up my types like that. It's probably just an acclimation thing, you're just not used to it. Also, it looks better in monospace.
&gt; sometimes there are more than six versions of the same function SomeFunction / SomeFunctionEx ... i think that was a reasonable solution for the problem otherwise demanding overloads and default parameters.. a full version of the function with comprehensive detail, and a simpler more common version (which i'm guessing would setup the parameters for the ex call) the lack of overloads/defaults will mean rust apis will end up like that, but they have their reasons I know. (personally I have come to terms with no overloads r.e. simplifying the type inference, but i still think default and named arguments would be a net win i.e. doing more with the same search in the documentation. 'no breaking changes in APIs' ... only add parameters if you can give a default. 
While I fully agree about `future await` and `future.await` (though I prefer postfix sigil variant), I think we should wait a summary from the team as was proposed [here](https://github.com/rust-lang/rust/issues/57640#issuecomment-464152929).
Yes, i do agree that decoupled traits are very elegant. Trait approach is what allows for amazing things like rust's iterators. It's the forced struct/impl separation that drives me nuts. If this was optional - i'd be ok with that. It's this sort of ricing that spoils the language. Same story with f64/i64/i32/f32. Obviously whoever designed those names thought "we're gonna have very short 3-letter awesome types that look really leet", but he didn't think about them being indistinguishable when read.
You need runtime polymorphism; the simplest way is to return a `Box&lt;dyn Iterator&lt;_&gt;&gt;`. You can wrap that in your own wrapper that implements `Iterator` if you wish.
I did, with templates and my own take on ++. It''s much more readable. I was implementing this network in rust just to concretely decide how it is in real action.
If you have counterarguments - by all means, do share. I wanted to like rust, but after studying it i have to conclude that it won't fly.
&gt;a team of 30 men, since we work in finance. Well, everything absolutely makes sense now. What an embarrassing shitpost.
Writing like you do most of your reading on 4chan probably isn't a fast route to having your concerns taken seriously.
It is the time it takes to allocate and format two examples of html: a big table of 100x100 and teams. It shows the time it will take your web server to generate it in each thread.
Who is leading the Mozilla Rust team now?
There are a few issues with your code. First, iterator methods, like `filter()`, do not modify an existing iterator, but consume it and return a new one. You need to do something like `result = result.filter(…);` instead of just `result.filter(…);` to ‘modify’ your `result`. Second, as you want to do it dynamically at runtime, like you noticed, you cannot do static dispatch – you do not know at compile time which struct will be used, and which implementation must be used. Thus you need **dynamic dispatch**, and that means [**trait objects**](https://doc.rust-lang.org/book/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch), you can use `Box&lt;dyn Iterator&lt;Item = Scalar&gt;&gt;` instead of `impl Iterator&lt;Item = Scalar&gt;`. One way to achieve this is (you can try it on the [Rust Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5cd5c452151b00030a87755b12ab773a): #[derive(Debug, Clone, PartialEq)] pub enum Query { All, Where(Scalar), Limit(usize), Sort, } #[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)] pub struct Scalar(u32); fn exec&lt;'a&gt;(input: Box&lt;dyn Iterator&lt;Item=Scalar&gt;&gt;, of: &amp;'a [Query]) -&gt; Box&lt;dyn Iterator&lt;Item=Scalar&gt;&gt; { let mut result = input; for query in of { result = match query { Query::All =&gt; { result }, Query::Where(value) =&gt; { let value = value.clone(); Box::new(result.filter(move |x| *x == value)) }, Query::Sort =&gt; { let mut r: Vec&lt;_&gt; = result.collect(); r.sort(); Box::new(r.into_iter()) }, _ =&gt; unimplemented!() }; } result } fn main() { let iter = vec![Scalar(1), Scalar(40), Scalar(21), Scalar(32), Scalar(5), Scalar(40), Scalar(8)].into_iter(); let boxed_iter = Box::new(iter); for element in exec(boxed_iter, &amp;[Query::All, Query::Sort, Query::Where(Scalar(40))]) { println!("{:?}", element) } } this prints: Scalar(40) Scalar(40)
30 qa testers are not enough for your proper team, or too much? justfuckingkilly0urse1f, hun
YOUR types, man. you aren't gonna read your types, someone who has no idea what your code is will. No matter how you look at it f32/i32 is just a plain bad idea.
and ad hominem is?
[removed]
I mean for both code written by me and code written by others. It's a type error to write an `i32` to an `f32` field anyway. It's impossible to accidentally do a silent conversion between the two.
It's locked because comments like this don't add anything and it wasn't getting anything but a large volume of comments that didn't add any objective benefit to the thread. &amp;#x200B; It might re-open once the core/lang teams have built and presented a position/opinion, but until then we just need to wait. IIRC, currently the concern is more on the backbone implementation than the surface syntax.
Out of curiosity what about your design causes the unstable framerates? I would imagine most possible algorithms for this sort of thing would mostly just depend on the number of simulated objects.
Excellent, thanks for the help. 
The thread clone wars 😂
According to the [roster](https://www.rust-lang.org/governance/teams/core), it appears that no one is at the moment. I am not sure if this is a permanent change, though.
That page has always represented Rust itself, not Mozilla. The core team has never had an official lead, though at times people have considered Aaron or Niko a de-facto one. Since I’m no longer an employee I can’t give you answers about Mozilla’s management structure though.
Yep, got it working. Thanks! Left diesel cli in my tests so I that ‘migration redo’ is a failing test, but my docker image is several lines cleaner!
I mean, my opinion on the matter is that Windows API functions take way too many arguments. There wouldn't be so much need for duplication if they were broken up into smaller pieces, which would also make the API much easier to extend.
Thanks!
Thanks! I want to use Rust for ML.
Could this be used to build a tiny low power tracker for my cat? Are there any eval boards yet?
If you want to go **very** deep into zero cost abstractions compared to LINQ, I went into detail on exactly what happens when the compiler interacts with Diesel's query builder in [this talk](https://www.youtube.com/watch?v=wxPehGkoNOw)
Probably!
Yes!
Depending on what that third branch turns into you may be able to do it with static dispatch still. If you want to combine the iterators: of -&gt; filter (remove All) -&gt; flatMap (turn items into iterators) -&gt; chain it onto the start or end of the original If you want to pick one of them: of -&gt; filter (remove All) -&gt; chain iter::once(input) on the end -&gt; take(1) or something -&gt; flatMap(|x| x) Sorry for the pseudocode but that’s some ideas. 
I'm having trouble passing a closure to another function. Ultimatively, I'll be wanting to send the closure through a channel to another thread, but that might be the 2nd step... So there's this trait [`RequestHandler`](https://github.com/KillTheMule/neovim-lib/blob/5b06301d95202a2a49bebe5230ea1e4a3375246c/src/rpc/handler.rs#L6) where `handle_request` should take an appropritate closure argument. I'm trying to use it [here](https://github.com/KillTheMule/neovim-lib/blob/5b06301d95202a2a49bebe5230ea1e4a3375246c/src/rpc/client.rs#L269). The closure fullfills the signature, and I might be missing some things, but the error message is really confusing: error[E0271]: type mismatch resolving `&lt;[closure@src/rpc/client.rs:251:27: 267:20 msgid:_, wrtr:_] as std::ops::FnOnce&lt;(std::result::Result&lt;rmpv::Value, rmpv::Value&gt;,)&gt;&gt;::Output == std::result::Result&lt;(), std::boxed::Box&lt;dyn std::error::Error&gt;&gt;` --&gt; src/rpc/client.rs:269:59 | 269 | handler.handle_request(&amp;method, params, Box::new(f)); | ^^^^^^^^^^^ expected (), found enum `std::result::Result` | = note: expected type `()` found type `std::result::Result&lt;(), std::boxed::Box&lt;dyn std::error::Error&gt;&gt;` = note: required for the cast to the object type `dyn std::ops::FnOnce(std::result::Result&lt;rmpv::Value, rmpv::Value&gt;) -&gt; std::result::Result&lt;(), std::boxed::Box&lt;dyn std::error::Error&gt;&gt; + std::marker::Send` I have no idea what this is about. From the types, it looks like it's complaining about the return value of the closure, but it's marking the call to `Box::new`... Any hints? 
If you wouldn't mind, where do you work now? And does it involve Rust?
I am still interviewing in a bunch of places. We’ll see!
Great-looking crate: really great name.
It looks a bit odd with the diagonals having the same cost as non-diagonals.
Very cool. Looking forward to Rust bindings for comms and how embedded hal is used.
Well, so let's split all errors into 3 groups: 1. Out of your reach (std/3rd party libs) - Can't expose those to anyone - Can't do much about them - The end user just gets a generic 500 in most cases if not all - Error logged - Internal error in your code - Might leak implementation details - Full control over them - Might be mapped to a high-level error - Might be just generic 500 - User Error - Have to be exposed - Some control over them - Some of them originate in higher level code (validation of request) - Some of them originate in low-level code (record not found) As you said you have a few options on how to implement them. I would go with more generic implementation: instead of `UserNotFound` -&gt; `ObjectNotFound`, `UserCreationFailed` -&gt; `ObjectCreationFailed` and so on. This will enable a significantly easier mapping of errors. Second, you can introduce trait on a higher level and implement it there. While HTTP level will know that `ObjectNotFound` is 404, code where that error originated (repository) won't. In other words: have multiple error enums, have one trait that turns subject into struct Error { code: String, message: String, link: String } I would make error code available on lower level errors and "namespace" it for each error type. It won't be 10xxx for 400, it will be 10xxx for diesel and 20xx for http client, and 30xxx for validation errors.
I guess this means I should hop back on the train for the Grammar WG, I've been busy lately. The super weird behavior of my PR not working properly is not helping of course. Wait, I have an idea. I just wish I knew how the proc-macro backend worked better to understand why `"%%"` isn't working...
The solution is in whatever's different between the bootstrap hack version and the `-macros`-compiled version. I might just end up breaking bootstrap the way I did for Pest? Depends on what the rest of the team say, I guess.
I'm rooting for your Fuchsia engagement :)
I knew a guy in college who did just this a few years ago, is there some unmet market need for iot kitty tracking?
I see, but what's most appealing to me about Rust is the typing system which enforces memory safety, if I understand correctly Zig doesn't offer that.
I've been using the async reqwest client for package fetching, and it's pretty fast.
It may count as a captured allocation. If so the compiler guarantees that any side effect would see the "correct" value at that location. And, still guessing, that may include panic on overflow. Maybe. If the compiler decides to write `s` to the stack every iteration, that's a significant speed loss. The correct go-fast way to write this kind of sum loop (in assembly or hand-optimized C) is to distribute your items across several (probably 4-16) accumulators so the CPU can have multiple SIMD instructions in flight at once. The compiler will try to do that, but can't if it changes whether the code decides to panic, or what is visible in the core dump. If a location is captured, the compiler can't actually rewrite it as 8 independent locations all held in registers. And it's entirely possible for the "captured allocation" attribute to be propagated backwards in the high level progam order - the compiler may start being careful long before it's required to. I'm certainly not expert enough for my guesses to be worth anything. But I'm curious enough to look at the generated code when I get the chance.
Honestly, I just put a little thought into best practices for data structures and intentionally let go and trust myself and a profiler to catch anything egregiously wrong with generated code. Most of your time and energy cost will be in a tiny fraction of hot code. Worse it's hard to predict where that will be, especially once other things change. Fortunately Rust tends give me more nice surprises than nasty ones when it comes to performance. Perfectionism isn't good. 
I see. Thank you for explaining.
I did not realize you had left Mozilla! 
I was thinking the same, but about Elasticsearch.
As someone who's used c# a lot, all I can say is to read the rust book and you'll have a blast. With rust it's really not worth taking shortcuts because it is very different in a lot of areas from anything else.
The general N-body problem doesn't have a "closed form" or analytical solution, you have to numerically integrate it -- but Newton's laws of motion apply just as well to N bodies as they do to two.
NoSQL is just a dumb term. Call what it is - Document-Oriented database. Not trying to be an ass, but what are you trying to achieve with this? REST is a terrible interface. If anything - GraphQL would be the best HTTP speaking interface to the database. Unless your client is only talking to the database, then RBAC is going to be PITA.
Trust me, I know that *now*. Back in the 2000s, I burned out quite a few times before I got it through my thick skull to "Make it work, *then* make it perfect." My biggest problem with writing CPU-bound code these days is that, if I have explicit performance (or binary size) goals, I still have a tendency to slip into analysis paralysis and premature optimization, requiring a mental reset to get myself back on track. Aside from that, I really like to have automated tests I can run after making changes and, while I can do that for exploratory programming (eg. design a test that calculates an accuracy score for a heuristic), I don't know how to ask the right questions to write an automated test for "Is it still 'fast enough'?"