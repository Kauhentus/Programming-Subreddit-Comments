 &gt; Using Rust already allows you to avoid all of the well-known terrible behaviors of double-free, buffer overruns Somewhat playing devil's advocate: buffer overruns are (at least sometimes) translated to indexing a slice, which will panic if you try to access it out of bounds. So you're trading one potential security issue (out of bounds r/w of data) for another (instruction pointer jumps to a bad location). Also, there are static analyzers that help C a bit (but sure, it's not the same thing as using Rust from the start). &gt; these UB holes will be fixed sooner or later Let's hope for sooner. The probability of this happening is also very dependent on the programmer (w r t choosing whether to `unwrap` or `Result`-based error handling). 
Freely available/original source: https://www.microsoft.com/en-us/research/publication/so-long-and-no-thanks-for-the-externalities-the-rational-rejection-of-security-advice-by-users/
Annoyed more than upset. I choose an appropriate language for the project, put in fifty or a hundred hours of work, and some random stranger says that I should redo it all in a different programming language because they like it more. "Have you considered rewriting this in Rust?" is the nicest version of it that I could hope to hear, and it would be at most a minor annoyance, at least if it only happened once. "I'd like to work with you on porting this to Rust" would be nicer, but I don't have that much hope.
Sorry man, I still don't get it. Why are you annoyed at what some random strangee thinks?
&gt; Malloc doesn't fail. It fails when you run out of address space instead of physical memory. Relevant for 32-bit users, especially when they use memory mapping.
&gt; instantiating a type with a special destructor on the FFI calls I'm not particularly fond of relying on destructors to be run for safety, when we explicitly say we don't guarantee destructors to be run. IIRC, Rayon does the same. But I realize the decision is not up to me :-)
This isn't appropriate for /r/rust. Random subjective complaints about Rust's syntax are annoying, but about other languages it is needlessly off-topic, exclusionary and rude, especially when accompanied by a sentiment along the lines of "I hope it fails". Please refrain from doing this.
&gt; Should we be thinking about this the same way we do in other languages? My opinion is: basically, yes. Rust isn't really all that special in this case. When do you usually prefer accessors (getters/setters) over public fields? When the user could shoot themselves in the foot by leaving the fields in an invalid state. Validity checking is a lot more easily done in the accessors than in methods that otherwise assume a valid state (though you should have at least debug assertions there as a sanity check). In this aspect, Rust is not really any different than any other language that supports OO patterns. You might want to consider an opposing case, though. If you anticipate the user will want to extract/access multiple fields at once, or if you anticipate accessor calls to be the primary usages of your struct, then you might prefer public fields and then sanity checking in methods that need it. This allows the user to destructure instead of calling accessors, which Rust supports really well. It also supports concurrent mutable borrows, which would be really difficult to do correctly with just accessors (except for providing a composite accessor that returns the fields as a tuple, but that leaves user code somewhat less readable). It's all about balancing user experience against complexity of implementation. 
Thank you.
&gt; Panicking inside a C callback is, AFAIK, still UB, i e, a security hole &gt; &gt; ... &gt; &gt; You could use catch_unwind on every C callback, but that is easy to forget This is something the compiler could warn about, right? It could warn on an explicit `panic` and not for things like failed allocations, since the former can be handled while the latter most likely cannot. I would definitely like a warning for stuff like that.
What features do you find missing for interactive use? Filing issues against the `liner` crate is advisable if there's features you want in the prompt.
&gt;&gt; pretending it's a bonus is silly &gt; &gt; it's not pretending. It was an intentional decision by the Rust developers. Not every intentional decision is a good one. Look at Go. In the case of function signatures, though, being explicit about types is good. I recall fondly the times I had to hunt through a call chain twenty elements deep to figure out the return type of a function in Python, because I knew what the data it returned was supposed to be, but I couldn't automatically intuit what properties it had.
You must be fun at parties.
Have to looked at PROST! for a?
Hmm, to me it does not sound like something that would be easier to implement than actually fixing the UB in the first place. But I don't know enough about the compiler to tell for sure. Maybe the clippy devs knows better how reasonable this request would be.
There are still holes in garbage collected languages that Rust catches, such as data races. I use Go primarily right now, and I'm considering switching because I feel like I've wasted *far* too much time tracking down data races, which Rust will catch at compile time. Depending on which garbage collected language you're using, there could be other concerns where the memory model breaks down. However, some things that I like about Rust vs garbage collected languages: - no nil/null/etc, so no surprising, preventable exceptions - nice synchronization primitives (I really like how mutexes wrap the data so it's impossible for me to forget to lock something) - deterministic destructors (destructors will run in a defined order) - hygienic macros (GC doesn't prevent this, besides D's `static`, I haven't seen a GC language that has a decent macro system) And then there's the usual suspects for Rust vs other languages (not specifically GC languages) that really make me like Rust, but I won't rehash those as other posters have done a good job.
Not really, no. I haven't considered rust for production for any service that would use those things (I have not considered rust for production much at all, though).
Perhaps it's already a thing, IDK. I expect that it should be pretty easy, since I'm guessing the compiler has to instrument the code for `panic`. I'm not sure where to ask that. RFC? Forums? Bug report? I don't do enough C FFI to really put the effort in, so I'll probably pass for now.
&gt; security has consequences I've spent *far* too much time tracking down data races, fixing null pointer exceptions and other issues that the Rust compiler warns or errors on. It's not just a security issue, but a time savings one for me. Yes, there's an initial investment, but that investment will pay for itself with fewer released bugs, fewer missed deadlines and shorter debugging cycles.
I actually did realize that later, but people had already started replying by then and, as a matter of policy and especially in situations where others have responded, I prefer to leave records of my past mistakes intact unless asked to do otherwise. **EDIT:** In hindsight, I should have at least put a note like this on it to make it clear that I recognized its inappropriateness and to provide my rationale for leaving it up.
It takes time out of your day to respond. If this happens once, whatever. But if this happens every month or even more frequently, it can get quite annoying. I've had requests to port stuff to JavaScript, Java and Python and it *does* get annoying. If you promise to do it yourself, I'd be much more likely to accept and even help out, but if you're expecting me to do work, it's annoying noise.
Holey moley, that's a very confident statement and one that can only be true if "write by hand" is interpreted very narrowly. When it comes to the complicated beasts that are compiler optimisers and their heuristics, I've found things are rarely so black and white. It is true that, in theory, a sufficiently smart compiler could convert any and all uses of enums into code that one couldn't hand code better, but there's numerous ways in which rustc isn't sufficiently smart in practice. One of the easiest to observe is layout: `Option&lt;bool&gt;` is two bytes not one. There have been times in the past when uses of `Option&lt;i32&gt;` on 64-bit platforms resulted in poor code, and there's no guarantee there aren't more little failings like that waiting to be uncovered. Rust does have zero-cost abstractions, but not everything is one, nor even every use of features that *can* be zero-cost. The parent might've been more accurate as "enums *can* have performance cost", but overenthusiastic "well actually"s that aren't true are less good than a mild mistake.
&gt; Cargo doesn't require you to use crates.io I used the `git` head of a project (commit hash, actually) because a bug in the released version was fixed in the head and it worked pretty painlessly. I also did this for a patch I was working on (I used a directory path) where I tested my local clone of the repo against my application before submitting the patch. Git dependencies are first class citizens with `cargo` and work *very* well.
I'm rather interested what your usecase is that you need modern OS features for a 32bit OS? Surely you have access to 64bit hardware?
its loved and i am in love with it for many reasons, but its not useful at all, i am trying Iron but there seems no way that i can use it in production, there is nothing there that helps us learn to use it, ZERO use case examples. By using i mean doing real large scale work with it.
The one thing that makes this consideration more important in Rust is the safety aspect. For example, `Vec`'s length field _must_ be private because code in the module assumes it is always correct, and the setter is unsafe because incorrect modification leads to reading uninitialized memory (undefined behavior).
It's certainly worthwhile to mention that the ability to use custom allocators is an in-progress feature. My concern is how this comes across to people who are not already Rust developers and familiar with the ecosystem. The whole premise of the original article is to appeal to people with large, old C codebases, who haven't already been convinced to give Rust a shot. Suggesting that they should even consider the unstable nightly channel for actual use propagates the (in my opinion correct) view that nightly Rust is still required for a lot of Rust development. Think of how it sounds to an outsider. "Oh yeah, Rust can do that, you just have to use the unstable development compiler." That won't inspire the confidence that people with these large C codebases require.
&gt; significant indentation to denote the extent of blocks. Minor nitpick: Crystal (and Ruby) use `end` to denote blocks. def fn body... end
PLEASE put units on the x-axis of that first graph!!! 😫
I'll continue to work on my style-preserving toml library. If I have time I'll also try to follow japaric's embedded rust tutorials
Yes. I'm saying that I prefer coarse structure be indicated by either punctuation (eg. Rust) or signification indentation (eg. Python) since unique glyphs or rectangles of whitespace which are guaranteed to be semantically representative take less mental effort for me to process than glyphs like `e`, `n`, and `d` which only derive meaning from the sequence they appear in (eg. Ruby and Crystal). (For the same reason that it's easier to scan a page for an icon than for a word.)
Right, but that's somewhat a logical extension of sanity checking. We have `unsafe fn set_len()` which the user could shoot themselves in the foot with anyway, it's just that Rust doesn't have the concept of unsafe field accesses. That could be kinda cool, though... maybe it could be safe to read but unsafe to write or something like that.
You misunderstand "we don't guarantee destructors will run"; it's not a guarantee that _arbitrary safe code_ upholds. You can still rely on it in code you have written. Here it's a local destructor bomb instantiated at the top of the FFI function, which isn't used throughout (might want an explicit drop) You can design a version of catch_panic that works by encapsulating this behavior but is faster.
Potentially silly question. The post says that the 6k unit tests may be a surprisingly low number, but that's ok since Rust's type system is expected to catch more errors at compile time. To what extent is that assuming what we're trying to prove? How many compile-fail tests do we really have, and how well do they cover the cases we'd expect in unit tests in other languages?
Not every project needs to be as fast as C/C++.(most projects are very happy to be in factor of 2-5). Aside from performance aspects, there are many languages that beat rust pretty convincingly(also they provide something more valuable depending your abstraction needs), when you consider the cognitive burden of managing ownership and lifetimes. That said, rust imo is a good use-case for the projects that care about performance deeply and use C++. 
I don't really want to argue about whether nightly is "required" in general or not—that was just my opinion. All I meant to say in my original comment was that this interaction is a bad sales pitch for Rust: "Try replacing some of your C code with Rust." "I'd need a custom allocator." "You can do that, but only with nightly Rust."
What you need to do is separate the lifetime of the vector you're borrowing (or rather, it should probably be a slice) from the lifetime of the string slices contained within, such a signature might look more like this: fn recursive_walk&lt;'a&gt;(vec0: &amp;[&amp;'a str]) -&gt; Vec&lt;&amp;'a str&gt; This makes it clear to the compiler that the slice you're passing it only need to live as long as the function call, but the strings live on longer 
Ocaml, racket both work for me, when i don't need performance of C++. Complex lifetimes(subtyping) do add cognitive burden and we are not comparing to C/C++ here; these things don't exist in gc languages.
It's just the way that Criterion does its display. In the original HTML version of the output, the bars are hoverable to show the units. It just doesn't work out as nicely with a screenshot unfortunately.
C++ Web developers.
I love the name! I'm going to have to play around with this when I have some time; the library looks really solid, too.
Does anyone know if there is a recording of the talks?
https://air.mozilla.org/game-developement-in-rust/
Thanks!
That's a fine point, that while Rust code is expected to require fewer tests, The Rust _compiler_ is the thing that enables that, so the same might not hold for it. I think the degree to which the test suite is providing adequate coverage is unknown. I have high confidence in the test suite, as the project has always been developed with a strong testing discipline, but it would be awesome to have better data about this, and relatively easy. For example, I don't think we even know whether every possible error generated by the compiler has at least one test. There are 2474 compile-fail tests in the Rust test suite. 
It would be really cool if cargo-bomb ran clippy too, it could give crates a badge like "Clippy Approved". 
Can `Rc` handle cycles?
Another thing that might be worth noting is that compile-fail tests sometimes test multiple things at once, like [this test](https://github.com/rust-lang/rust/blob/master/src/test/compile-fail/private-in-public.rs) which is testing all the 'private in public' rules, at least as they were known at the time.
The majority of scientific uses of Python is as a more advanced spreadsheet. Data cleaning, munging and creating plots. Python is ideal of this task.
Video games are increasingly multiplayer over networks (or perhaps have peaked), or take in mods or custom content. Being able to install those without risk of hacks via buffer overflows and variants would be nice.
64-bit hardware is not the same as being able to run 64-bit programs. I'm under the impression that 32-bit processors are common in embedded contexts. The discussion isn't about modern OS features, but about Rust, which, last I checked, aims to be a general purpose programming language used in the same places you'd otherwise turn to C or C++. I generally want modern programming language features whenever I'm writing code.
Which is, yet again, better suited for [Julia](https://julialang.org/), which provides first class features for each of those use cases, as it is designed explicitly for scientific computing. Python is not, and should not be used for scientific computing, period.
Your example seemed very specific so I was curious that is all. 
i'm (finally!) learning some rust by way of gradually migrating a c project. i've been very impressed by how i can define the same struct in rust and c, guarantee a compatible memory layout, and then rewrite functions that use the struct one at a time. plus it's a lot of fun :)
Generally open-source maintainers don't have their code online in order to solicit random comments from unqualified and uninformed people on the internet, especially if those comments amount to "your work hasn't been done to my liking, please do it again [in this language I like that you probably don't know]". Bug trackers serve a purpose, i.e. to track bugs.
I agree with you about Python. I've used Julia for a few things now, though, and although I'd initially agree with you, I've kind of scaled back my enthusiasm. First, I think the benchmarks for Julia are somewhat misleading. I've seen cases where it was amazingly fast, in line with what's reported on the website, but other cases where it was ridiculously slow compared to other options. As I've used it, I've come to appreciate the need for something more general purpose, that's not so specifically focused on numerics. Something more general-purpose will always have the advantage of allowing you to seamlessly integrate the numerics with other things. Having said that, it's difficult for me to gauge where Rust fits into this. Sometimes it seems too low-level to me for routine scientific computing, but I also haven't seen examples of higher-level libraries in that area, so it's hard for me to tell what it would look like. 
Exactly, it also means there is no natural way to get a reference to a function/method. If Ruby was curried by default, it wouldn't pose a problem. But instead, if we need to pass a method to another method, we need to wrap it in a block or turn it into a block with `.method(:method_name)`. No bueno.
&gt;I haven't been a fan of paren-less function-calling syntax or using words like end to denote blocks That's a pretty minor nit. Haskell gets along quite well without parens for function calling and I personally find it a pleasure to read.
I think another issue is also just the tribalism that permeates FOSS. I think FOSS is more ruled by tribalism and association than proprietary software and that's probably due to how FOSS recruits new members. In proprietary software you often start as quid-pro-quo; you apply for a job and you get it and get paid. A lot of FOSS people started contributing out of passion and later got a paying position because they were good; while this may bring in compassionate people who stand for what they believe in it also brings in _passionate_ people who feel a strong sense of belonging with a certain identity and that's a great way to shoot objectivity down the drain. I had some discussion about Rust with a clique of OpenBSD contributors; it is clear that they are thoroughly capable people but it was also clear they criticized Rust without understanding anything of it and they completely worked themselves into a corner and couldn't admit any more they in fact did not know anything about how Rust worked and never wrote a line of code in it; but they hated Rust and had made up their minds about it and that's probably just purely association and tribalism. Their tribe is the "greybeard tribe", the old Unix way of certain sensibilities; of thorough code review and a certain competence and they associate Rust with another tribe of new people whom they probably personally dislike: young, energetic people who weren't around when Unix was founded who don't understand KISS who have a background in fancy things like ML and Haskell which they never liked due its lack of low-level control. And purely by that association they hate Rust without even knowing what Rust is and how it works. And that mentality seems to absolutely permeate FOSS; it's _everywhere_. Almost everyone has a tribe and they are fiercely loyal to their tribe. Ever noticed how every GNU developer uses screen and every OpenBSD developer uses Tmux? That's not because they decided that it was better for them but tribe loyalty. Or ever noticed how SuSE devs almost always use KDE? How a lot of RH people swear by GNOME? Lennart Poettering uses GNOME; I don't think he independently came to that conclusion but RH pays him; RH is his tribe and he experiences some weird loyalty to his tribe. This tribe loyalty is absolutely a pest that fills FOSS and influences decisions everywhere; I think a lot of Rust developers also use software just because it was written in Rust and while I've not seen it yet I feel that eventually some kind of loyalty to Mozilla is going to develop amongst Rust developers. Linus Torvalds has said some things about C++ which a lot of people have and while I definitely think that C++ is a complete mess I think a large part of the hatred C++ gets is purely because people associate it with a certain breed of developers who don't understand what they are doing in the slightest and Linus half-admitted that by saying that he would not use C++ for the sole reason of keeping the typical C++ dev out of his project. Suckless goes so far to refuse `//` comments in C because it was invented by C++ and backported to C. So yeah I think a lot of people will just not use use Rust because they associate Rust with a certain kind of person they don't like; people do this all the time but the FOSS community is _especially_ guilty of this, far more than is usually found in people of their intelligence level. (I do think tribalism negatively correlates with intelligence).
&gt; require fewer tests I'm definitely more confident in my code in Rust, but in many ways I find I write tests more often in Rust than other languages, simply because the tooling has made it so easy to add them; ignore integration tests as necessary; run selections of tests, etc. It's such a nice experience. I also find that I write tests just to see if the code compiles :)
See the current().notify() sibling answer.
Sweet, the lack of handling of Crtl-C was a big blocker for me to use it on Linux, I'll give it another try now.
I keep wanting to jump into this project, but haven't had the time. As a quick question, is the idea behind self-hosting to also include writing and reloading kernel services? That seems like it would allow quite rapid development.
I think it's uninteresting to think about zero-cost abstraction on such a low-level. The "abstractions" in that phrase is about stepping away from implementation details like "tagged union". In the low-level frame of mind, you can call essentially anything a zero-cost abstraction for exactly the set of trade-offs it has, e.g., CPython's `list`: "you couldn't hand-code a reference counted collection of heterogeneous reference counted pointer values (etc.) any better". This isn't necessarily *wrong* technically, but it does seem to be missing the point, because it is so focused that it doesn't easily translate into a relevant property for real-world code. It seems far more useful to me to refer to higher-level properties, like, for `Option&lt;bool&gt;`, storing three separate values. This is certainly the sense in which people mean that Rust's iterators are (often) a zero-cost abstraction: it's not that you couldn't hand-code a function that takes a pointer to a piece of state and returns a tagged union of the next element or nothing any better, it's that you couldn't hand-code the whole "execution" of the iterator any better, i.e. the actual loop. In this broader framing, enums are often not zero-cost abstractions: someone hand-coding it optimally would store the three states of the `Option&lt;bool&gt;` in a single byte.
You still have the ability to edit in a note, please do.
Specialization is driven purely by traits, and using that to specialize the in-memory representation of `Option` is a nonstarter because would be a massive breaking change, and, even ignoring that, it would be very ugly to use. This is better driven by the compiler, in a similar manner to the null pointer optimisation for `Option&lt;Box&lt;T&gt;&gt;`, so that it is transparent to the programmers. The latter works for any enum shaped like that, including `Result&lt;Box&lt;T&gt;, ()&gt;` or `enum Foo { A(Box&lt;T&gt;), B }`, and these sorts of representation-compression optimisations can similarly be applied more generally: - enums other than `Option`, - contained types other than `bool`, - when the `bool` (or otherwise) is buried deep within something else, like `Option&lt;(Foo, Bar)&gt;`, where `struct Bar { x: Baz }`, `struct Baz { y: bool }`. https://github.com/rust-lang/rfcs/issues/1230
I noticed in Bash I used Ctrl+Left Arrow or Ctrl+Right arrow a lot and it moves the cursor to some sort of word boundary. 
I have a had a lot of fun playing around with this crate recently! My only real complaint is that, because it requires SDL, you need to have the binaries for that handy. This can be a little bit annoying to set up on windows, but with a build script it's pretty much fire-and-forget. There is some information on the github repo though about the reasoning for this, and it's understandable that [there are still some issues standing in the way of a pure-rust implementation.](https://github.com/ggez/ggez/issues/29) That said, I love this crate because it feels like one of the few out there that actually allows you to focus on the *game* aspect of game development. Unlike many of the other options that are out there, ggez feels far less intimidating and easier to get into for someone like myself whose background is in applications and not in game dev. Everything else I've tried feels far too complex to just tinker with. Now if only I could find the motivation to ever *finish* a side project...
Excellent essay. We like to think that we are critical and rational, but group dynamics play a larger role than most of us would care to admit. This is one thing I would like to see in Rust, a reverence for the ideals of Rust over the thing itself. If other languages start adopting the philosophy and desire for provable correctness, Rust is still successful. If tomorrow, someone figures out how to give C++ every quality that Rust has, Rust is still successful. Computing is filled to the brim with false dichotomies and an extra serving of butter side up / butter side down.
What I like to see is that even though the code that's running might not be quite as efficient, it does give the programmer sufficient latitude to develop whatever they want without fear of breaking existing code. For example: I wouldn't usually parallelise image generation for a quick and easy program in c++. With rust I can just add rayon into the equation and be done with it. On top of writing fast code, I can also include features that I would usually deem to out of my way or risky in c++.
That's pretty much due limitations of the current Implementation. The optimization is only done for types that can't be zero (implement the Nonzero trait). Therefore it's also limited to Option or Option-like enums.
Haskell has a much longer list of syntax decisions which I find painfully alien. (Not objectively bad... just so alien to my experience that I really don't want to think about how much mental effort it would take to reformat my brain to work comfortably with that combination... and that doesn't even touch on the effort to build up an understanding of the DOs and DON'Ts for writing performant Haskell.)
We're specifically discussing the cost of using enums as abstractions, where some tight loop might not be as fast as it could be or some memory allocation might be twice the size (both of which will only have a large impact on certain programs), not the more general benefits of the language. However, I can definitely see your point that maybe arguing about such things is missing the forest for the trees, because Rust's static guarantees can often mean one can do unexpectedly "aggressive" algorithmic optimisations.
That was initially a major frustration for me in Ruby! Still is, actually, and with Elixir too - in the latter case you have to prepend the function name with a `&amp;` to mention a function by value.
Right - I think it's a good thing to call out the assumptions we're making, implicitly or explicitly. I think it's great to limit the number of necessary unit tests (on the assumption that the type system makes having more unnecessary), but then I think it would also be important to test that the type system really does catch those errors in rustc's testsuite. (Your emphasis was helpful - I momentarily lost sight of the difference between "the Rust Language" and "rustc".) Another thought, just spitballing - how useful would it be to use something like quickcheck for augmenting the unit test suite? Would it be possible to write a version of quickcheck that generates code snippets that would give us more confidence in the type system/compiler? I.e., "all code snippets that have this property should compile, and all others should fail to compile". That feels like duplicating the compiler's logic though, now that I write it out.
&gt; Why are Rust iterators slower than looping? Your understanding is basically right. I've talked about this more on my post [Rust’s iterators are inefficient, and here’s what we can do about it.](https://medium.com/@veedrac/rust-is-slow-and-i-am-the-cure-32facc0fdcb) See also [the /r/rust conversation](https://www.reddit.com/r/rust/comments/5ez38g/rusts_iterators_are_inefficient_and_heres_what_we/). It's worth noting that whilst external iteration can be slower when the loop body is small, internal iteration can be slower when the loop body is large. No solution that I know of is perfect; if you need that last bout of performance you should be looking below the abstractions anyway.
Done. Sorry about that. I was drowsy and forgot that not everyone has a `?context=3` view putting the explanatory reply right up next to the original mistake. With that in mind, I'll now abstain from further posting until tomorrow morning.
Yep. As a career Rubyist, I completely agree. It doesn't rank highest in my complaints about Ruby, though. Nonetheless, I definitely think there is a superior ergonomic middle ground (my preference: curry all the things!) E: grammar/typos
In the end, everything is always better suited for general purpose programming languages in the long run. As for Rust, it's just a matter of library support. Every use case could eventually have a high level framework, including scientific computing. It just takes someone from that background to implement such a library.
 Yeah that was my point - it doesn't matter how fast it is at low level if you are too afraid of breaking things to optimize further. 
I'd recommend filing a request against the liner crate if you want this feature. If you switch to vi mode, you can do that with vi bindings. `set -o vi` and then `Esc+:w`.
`fn recursive_walk(vec0: Vec&lt;&amp;str&gt;) -&gt; Vec&lt;&amp;str&gt;` takes the `Vec&lt;&amp;str&gt;` by value so will destroy the input vector.
It is not "very specific" though. It is completely applicable to out of memory situations which happens often in embedded programming. Plenty of low powered devices don't have a MMU which means they don't have a separate virtual address space. In these situations, memory allocation fails more often.
is there *ever* an advantage to octal over hex? I find it's just easier to grok hex, but maybe that's because I'm EE
There's https://clippy.bashy.io (IIRC), but I don't know its status.
This is something many folks want! Do you have a public repo so others can join in?
At last, `Iterator::for_each(_)` is on the way, and one can use `fold((), |(), x| ..)` until it stabilizes.
The only place I ever see them is Unix access permissions (modes). Each component (user, group, other) has three permissions (read, write, execute), so octal (2^3) means one byte per component which is easier to deal with than hex. I'd rather just use u=rwx,og=rx notation, though. More verbose but much less likely to cause error.
I had a brief skim through the code and something that concerned me performance-wise is that the sprite batcher doesn't actually do any batching. It's uploading new data to a buffer and performing a draw call once for every sprite, when it should be done all at once (the entire point of sprite_batching_). With small numbers of sprites it probably isn't noticeable but when you get into the 1000-10000s I'd expect dramatic slowdowns.
&gt;&gt; So I agree, sell Rust as a whole, there's way more to it than "safer than C" correct. My interest in Rust was/is immutable-by-default, no header files, nicer lambdas etc.. 'its safe' doesn't help me. I need to test my code in other ways, for other reasons - and if it gets through that, then I can use a static analyser aswell
&gt;&gt;"but I also think that's a huge problem." it's a pragmatic compromise: in the cases where security is the #1 concern there are already other options. C and C++ are being used in areas where the priorities are different. Rust is one of many approaches/options.. I suppose where security is the primary concern, they can work from the other end 'trying to retrofit smarter compilers/performance hints..' this is why I prefer to think of rust holistically rather than just from one POV, 'security'. It will live or die based on it's whole blend of features (e.g. I'm personally drawn to it for other reasons, and the security is actually a drawback )
Isn't Juniper a server library, not a client library? Looking at creating an API wrapper whose endpoints utilise GraphQL
&gt;&gt; Rust has all this "hairy stuff" like lifetimes and ownership thrown in. those are ok ; I find my frictions in Rust (why i'm not 100% committed to switching) are from other decisions; e.g. I'm 100% happy with needing an ```unsafe{}``` to do something dangerous, but within that needing to double cast the raw pointers and bloating *both* ```*const T *mut T``` gets a bit much More significant are the differences in traits,overloading,namespacing (basically I end up with a cats cradle of traits/single-function traits ... I've always enjoyed the free-function overload ability of C++ and just want it enhanced with UFCS really) &gt;&gt; It would be nice if our rotten foundations could be renewed. The risk is throwing the baby out with the bathwater. I want X/Y/Z features , but do I want to lose A/B/C to get them... not necessarily
`for_each` is neat, thanks for sharing! Unfortunately I don't think `for_each` adds anything `fold` doesn't in this context; a fully general solution for internal iteration needs to be able to signal early termination (eg. `fold_ok`). That means we don't get to rip out all the incidental complexity that exists to short circuit `all`/`any`/`fold`/etc.
If you want to make a 2D game, consider using [ggez](https://github.com/ggez/ggez). If you want to prototype something 3D, look at [three-rs](https://github.com/kvark/three-rs/). If you want something more low-level, there's [gfx-rs](https://github.com/gfx-rs/gfx) (there's also a [small tutorial](https://suhr.github.io/gsgt/)). Font rendering is a little bit complicated though.
&gt; I tried to use piston but example code wont compile. Which piece of example code?
https://github.com/PistonDevelopers/piston-examples/blob/master/src/image.rs
` pub fn read_data(&amp;mut self) { let mut buf: Vec&lt;u8&gt; = Vec::with_capacity(1024); println!("length of th ebuffer : {:?}", (buf).len()); let len = match self.socket.read_to_end(&amp;mut buf) { Ok(len) =&gt; len, Err(_) =&gt; 0, }; println!("length of th ebuffer : {:?}", len); println!("Data in the buffer : {:?}", String::from_utf8_lossy(&amp;buf[0..len])); () ` This is not working.
AFAIK, the layout of tuples is undefined, unlike the layout of `[T;N]`. &gt; There is of course the fact that [T;N] is indexable, but again, once a certain level of generality is reached, could [i] be overloaded to work on (T,T), (T,T,T), (T,T,T,T) etc. You can index tuple with `tuple.0`, `tuple.1` and so on. Being able to generalize over `(T, ...)` or `(T1, T2, ...)` would be nice to have, but I have seen something like that only in concatenative languages (like [Kitten](https://github.com/evincarofautumn/kitten/)). 
I wrote some code using futures the other day and wow the API is weird. I'll be honest, I don't like it at all. I was working with streams and it took me some time to realize that each operation returns a new stream that needs to be from then on. ClientBuilder::new(CONNECTION).unwrap() .add_protocol("rust-websocket") .async_connect_secure(None, &amp;core.handle()) .and_then(|(s0, _)| s0.send(websocket::OwnedMessage::Text("send a message from here")) .and_then(|s1| { // fold the stream to process all incoming messags while keep sink as // the state so it can be used to send messags out let (sink, stream) = s1.split(); stream.fold(sink, |sink, msg| match msg { OwnedMessage::Text(txt) =&gt; { future::ok(sink).boxed() } OwnedMessage::Binary(_) =&gt; { future::ok(sink).boxed() } OwnedMessage::Ping(data) =&gt; { sink.send(OwnedMessage::Pong(data)).boxed() } OwnedMessage::Close(_) =&gt; { sink.send(OwnedMessage::Close(None)).boxed() } OwnedMessage::Pong(_) =&gt; { future::ok(sink).boxed() } }) }); I think this is a convoluted mess but I couldn't see a way to make it any better. I think it is still more straightforward than the example in `websocket` repository which converts the stream to a future and uses `futures::loop_fn` (that one is more generic though). Contrast this with an API from language such as OCaml: let (stream, push_fn) = Lwt_stream.create() in (* not monadic (async), result type is just () *) push_fn(1); push_fn(2); push_fn(3); (* this is monadic. result type is Lwt.t that needs to be run to get a value out *) Lwt_stream.next(stream) &gt;&gt;= fun x -&gt; Lwt_stream.next(stream) &gt;&gt;= fun y -&gt; Lwt.return(x+y) Since we can reuse the `stream` we don't have to return it over and over. This makes types much simpler. A lot of methods in `futures` API return tuples and very quickly it gets very hard to see through it.
&gt; AFAIK, the layout of tuples is undefined, unlike the layout of [T;N]. so i guess the rule would have to be extended to 'the layout is undefined per change of type..' for any of this to make sense, &gt;&gt; You can index tuple with tuple.0, tuple.1 and so on. that sugar is indeed awesome (especially for making tuple-structs more appealing), but i'm referring to the use of a runtime index.
&gt;&gt; Being able to generalize over (T, ...) or (T1, T2, ...) would be nice to have, but I have seen something like that only in concatenative languages (like Kitten) after thinking 'well, [T;N] is more efficient for the compiler', maybe that is an incentive to figure out where it can be stored like that internally (and figure out when many of the types are the same) although I suppose you could just say 'use (A,B,[C;3])' I suppose with rust macros already there , there isn't such a big incentive to extend the type system so far in that sort of direction. I guess I still view macros as a 'catch all whilst we wait for language features' but they are supposed to be taken more seriously in rust
What advantage does using `(T, T, ..., T)` have over `[T; N]`? I'm having trouble understanding why runtime indices of homogeneous tuples would be useful when you can just use arrays.
Personally, I'd ask something along the lines of "If I implement [new feature X] and/or rewrite [module Y] in Rust, would you accept the pull request?".
I really like the looks of this, and hope to use it someday for a game I've got in the back of my brain. Maybe we can try to get together an organized Rust effort for one of them game jams.
I think a suite of generated tests would be awesome. It's quite noticeable to me how little quickcheck and parameterized tests are used in Rust. There's definitely room for them. SQLite, the project I linked to as inspiration, has giant quantities of generated test cases. As you say, there's the possibility of just uselessly reflecting the compiler's logic back at itself - they key to avoiding that is to use different code bases to do the generation than the implementation. For the standard library, there is probably an obvious role for literally using quickcheck. For the language itself we might want a machine-readable spec, and from that generate test cases. We might e.g. be able to use Niko's chalk project to generate facts about the language and from that generate test cases. Likewise, the grammar I mentioned in the post is an independent implementation of the production Rust parser, and from that one could imagine generating syntax that we expect to hold in the real compiler.
How about you set up a patreon to fund some real cores behind this. I'd contribute a few dollars a month.
&gt;&gt; What advantage does using (T, T, ..., T) have over [T; N]? the notion is 2 fold [1] could the compiler internals be generalised, (e.g. once you have Foo&lt;T,N&gt; capability, could the compiler be generalised to be using (T,T,T..) but more so:- [2] **could the syntax space be opened up**; e.g what if 'let x=[0,1,2]' was using programable sequence constructor sugar that just happens to be generating (T,T,T) by virtue of standard library code; for reference (i) see how C++ has successfully generalised it's {...} initialiser syntax , but also (ii) see how haskell has generalised the use of [..] for pattern matching with elements of any sequence types, I think) similarly what if [T] in the types became programable; imagine if (in future with HKT?) it could generalise to 'any kind of sequence of T's' ..) e.g. imagine if ```foo&lt;A,B&gt;(x:[A])-&gt;[B]``` was actually sugar for ```foo&lt;A,B,SEQ&gt;(x:SEQ&lt;A&gt;) -&gt; SEQ&lt;B&gt;``` I realise some options may be closed off based on what has been set in stone at 1.0 already. compact type signatures are useful IMO because you see these when searching (again for more reference, see the power of Hoogle ). theirs of course means 'list' (perhaps more useful in their lazy-eval world) but here i think 'randomly accessible sequence' would be more useful 
[GIFV link](https://i.imgur.com/LJcnPhK.gifv) --- _^I ^am ^a ^bot. ^[FAQ](https://www.reddit.com/r/livven/wiki/gifv-bot) ^// ^[code](https://github.com/Livven/GifvBot)_
https://github.com/Gigoteur/PX8 The devlog of the project https://hallucino.itch.io/px8/devlog 
They really aren't. But... `(T, T, .., T)` has deterministic look ups without checking, also the LLVM is more free to split the tuple, provided Rust doesn't try to treat homogeneous tuples as arrays during the IR conversion. You can still run into scenarios where `[T;N]` may do indexing checks.
I see, thanks for the explanation. So musl libc is statically linked and works on "glibc Linux", too?
Managed to get the `termios` API PR merged today, actually, so now it's on to pushing `nix` towards its next release!
&gt; `(T, T, .., T)` has deterministic look ups with zero checking Only because it doesn't support runtime indexing. If it did, it would have to do checking also.
LLVM is very bad at vectorizing state machines. If you where to write the same code using range-v3 c++ ranges and compile it with clang you would run into the same issues as rust. Or in other words, your C vs Rust benchmarks are actually benchmarking GCC vs LLVM. If you want to benchmark C vs Rust you should compile your examples with clang instead.
&gt;I think FOSS is more ruled by tribalism and association than proprietary software and that's probably due to how FOSS recruits new members. In proprietary software you often start as quid-pro-quo; you apply for a job and you get it and get paid. In my experience, the propietary software world has (more or less) the same level of tribalism. However, their problems are usually invisible to people not in the company. By contrast, every discussion in FLOSS is accessible to everyone. Of course, YMMV 
They asked for advantages, this is _technically_ one
Even at 12 minutes is a huge win over *"Rust (stage 1 only) 45 minutes"*.
But this is not how things work. You can learn Go on a weekend so it "obviously" saves time. Rust don't. That this is obviously shortsighted is without question. But the problem is "how to sell a drug where you first get the hangover?" it is really hard for humans to plan for the future. 
&gt; On most C++ codebases however touching header files will lead to worse since Rust still has course grained compilation units (crates) whereas most C++ codebases don't split stuff up that way. This is not quite true. Properly architected C++ builds make use of static and dynamic libraries, whereas cargo still builds the world from source code and is not able to use binary libraries in its current state. So in my C++ code, I have binary libraries, incremental compilation and linking being used. If I am wrong about cargo and binary libraries (crates), I would like to be corrected. So far I only managed to make use of a common target directory.
I mean, what error did it give you? It compiles for me with `cargo run --release --bin image`
Still very very early and there are some issues that I know of :) but the core features are ready.
This… does actually end up sounding like a plausible path. 1. Make `(T; N)` sugar for a homogeneous`N`-tuple of `T` values (i.e. in types, `(T; 0)` ≡ `()`, `(T; 1)` ≡ `(T,)`, `(T; 3)` ≡ `(T, T, T)`, _&amp;c._; and in values, `(x; 0)` ≡ `()`, `(x; 3)` ≡ `(x, x, x)` conditional on `T: Copy`, as with `[x; 3]`, _&amp;c._); 2. Ensure the compiler writes `(T, T, T)` as `(T; 3)` in its messages because otherwise `(some long type name; 65536)`… yeah; 3. Define the layout of homogeneous tuples as equivalent to such arrays and slices; 4. Implement integer generics in the language; 5. `impl&lt;T, N: usize&gt; Index&lt;usize, Output = T&gt; for (T; N)` (and `IndexMut`); 6. `impl&lt;T, N: usize&gt; Deref&lt;Target = [T]&gt;` (and `DerefMut`); 7. Do compiler magic to ensure all this indexing (static or dynamic) is at least as fast as array indexing, both at compile time and runtime. 8. Genuinely remove arrays from the language, making them just sugar for homogeneous tuples, probably deprecated. At this point, for known indices, you could index your homogeneous tuple via `x.5` or `x[5]`, and `[]` array/slice construction syntax *could* be removed from the language altogether if desired (provided epochs has landed). This would be a step backwards in terms of type inference, I suppose—`[1, 2, 3]` knows it’s homogeneous, `(1, 2, 3)` needn’t be and thus the type must be determinable for each element. So maybe square brackets are still useful there.
I think it's better that the API supports sprite batching, because that means it can seamlessly be added later. Whether or not it's implemented yet is less important 
What are you doing with boosting? I'm not aware of it being implemented in any of the rust machine learning libraries, so a solid implementation would make a nice addition to the rust ML ecosystem :-)
i didnt add image as argument when run it. sorry, dont have the code now.
yeah, maybe. But those would have found another way to complain. Right now I'm talking to people that might be interested but are still uneasy
great! I'll publish another post today or tomorrow about the process to rewrite some code
&gt; Properly architected C++ builds make use of static and dynamic libraries, whereas cargo still builds the world from source code and is not able to use binary libraries in its current state. &gt; So firstly, I'm not clear on what you're trying to say here. Static and dynamic libraries from where? Are you talking about the ones provided by the distro for external deps, or the ones built for a C++ codebase's own code? For the latter Cargo definitely does the same thing; it stores static binaries in the target dir. These binaries won't work (and will be rebuilt) across rust versions, but they still work in general. If you're talking about external dependencies; sure; the distribution of precompiled binaries isn't something Rust does well (it can, but then you'd need to distribute one per version or something). It's not what I was talking about though, I was talking about project build times; i.e. the build times that have an actual effect when hacking on something. I agree that Rust's story here isn't great. Put another way: It is a common tendency to split large Rust codebases into multiple crates all stored within the same VCS. These have unidirectional dependencies. It is a common tendency to split large C++ codebases into folders which do not have unidirectional dependencies; includes go both ways. You may not call these "properly architected", but I'm talking about what one tends to see in the wild ("on most C++ codebases") For single-crate Rust projects (i.e. where all other crates are external dependencies) compilation time is usually worse than the equivalent C++ for an incremental build, however usually these are small enough for it to not matter. All of this changes if you turn on incremental compilation, however, since incremental compilation effectively gives you all the benefits of splitting up your code into tiny compilation units without the drawbacks of having to manually do it (and without issues like how touching one function in a header file forces consumers of _anything_ from that header file to recompile). &gt; If I am wrong about cargo and binary libraries (crates), I would like to be corrected. So far I only managed to make use of a common target directory. Provided the library is compiled on the same version of rustc you can distribute binaries without any issue. That's just not the standard way of doing things, and cargo doesn't give you an explicit way to do it. (You can still use this with cargo if you want to, it just requires some extra shims you have to write)
Given what you have it isn't a very big jump. Just modify the `style` macro to call `unit` for you: macro_rules! style { ( $x:expr, $($s:ident($($unit:tt)*)),* ) =&gt; { $x.apply_styles(vec!( $( $s(unit!($($unit)*)), )* )) }; } 
that's a tradeoff I could live with. Honestly, comparing that with all the other crashes and UB I'd get in the C part, the choice is easy for me
I'm using freetype-rs and glium. Previously I was using OpenGL directly instead of glium, you can find the code for that here (including the font rendering part): https://github.com/jhasse/rust-opengl-test
Kind of off topic but If there is a hidden security hole in Rust compiled code, wouldn't that propagate out to all software written in it? That could be a huge problem. I guess even in an ideal utopia where Rust is used everywhere it would be ideal for several implementations of the compiler to exist. 
Aha! When you say that lifetimes do not determine runtime representation of the values of types, do you mean in trait objects? That is, that trait-objects do not support dispatching on lifetimes, but they do support dispatching on types ? &gt; What enables function pointers to be higher rank over lifetimes is not that lifetimes are "coalesced into a single one before trans," it is that they do not determine runtime representation at all. But say `fn foo(x: i32)` vs `struct I32(i32); fn bar(x: I32)`. I expect the "runtime representation of `i32` and `I32` to be equal, but obviously a function pointer to `foo` won't accept the address of `bar`. I guess above I was talking only about monomorphizised code.
It is very similar to Scala's match, with most of the same features.
&gt; I would love to see these happen, and they likely will eventually. There is a language reference which obviously is not as detailed as an ISO standard. Independently of whether being as detailed as an ISO standard is a good or a bad thing, everybody agrees that it must get better. Yet actually the biggest part missing in the Rust reference, and the one receiving most work is Rust's memory model. In particular with respect to what does exactly happen when you screw up unsafe code. The current objective is that all undefined behavior can either be detected at compile-time, or checked at run-time. This makes it much harder to specify than C and C++ memory models, which don't give you this guarantee. That is, hopefully, one day Rust will only have a single "sanitized" run-time mode, that catches all undefined behavior and gives you a nice backtrace of which events caused it. Doing this in C++ is impossibly hard, and believed to be impossible in practice. There are some types of undefined behavior in C++ that the undefined behavior sanitizer (UBSan) just cannot catch without incurring extreme costs. &gt; jemalloc brings a lot of performance benefits with it, from what I've seen. This is only sometimes true if jemalloc is the only allocator in your whole binary.
Thanks for the reply and the great crate. I evidently got confused so I am in support of removing ocatal escapes.
Anybody using C's know about e.g. pragmas / attributes / extensions of specific compilers, and have at some point seen some macros for conditional compilation that call one attribute in one compiler and a different one in another. If you need to access LLVM specific intrinsics that might not be portable to other compilers, you are going to need to use nightly rust often. If we had a GCC frontend for Rust, you will probably need to use its nightly compiler as well to access some GCC specific features. Controlling the global allocator doesn't seem worth it of requiring a nightly compiler, and this will probably change, but C programmers do know about non-portable specific compiler features and that is just what it is. We haven't stabilized an API for it, so right now it is just a compiler specific option that is not portable and hence requires nightly. Nothing more, nothing less. You can explain it as "the compiler has a specific option to change the system allocator but we haven't standardized the API for that yet so right now you need to opt into using unstandardized language features for that; once it's standardized you'll be able to use it from all conforming compilers". Does that make sense?
I created a little crate for generating an 8x8 bitmap font from a string, because I needed this for my project and nothing simple seemed to be available. Give it a string and in return you get a width value and a vector of bool (or u8 for grayscale) that is your string bitmap starting at (0,0) and going to (width,0), then (0,1) to (width,1), etc. You can then dump this onto an image, or to the console, or whatever. https://github.com/david-griffith/rust-bitmap
&gt; Static and dynamic libraries from where? From everywhere, I don't care from where. Just having the possibility to say here is the "link directory", "vendor directory" or "package server" and use those binaries. I guess it is a matter of perception, for me all components that end up in the produced *.exe* are part of project build times. If I have to compile external dependencies, my project build times suffer because of that. What I have observed when compiling multiple Rust projects, that happen to depend on common crates is that those crates, are recompiled on each project build anyway. Redirecting the output target dir, appears to make it less so, but I still see it happening sometimes, maybe due to something that makes a project not able to re-use an already compiled crate.
+1 for removing them. I'd say staying compatible to Rust expectations is more important that staying compatible to other RE syntax.
Ahhh, `ident` is what I was missing. I didn't know that could be used on enum variant names (that's what's happening, right?) It works, thanks!
&gt; and [] array/slice construction syntax could be removed from the language altogether if desired sure.. what I had in my head is the standard library would give a default implementation that worked exactly like the existing constructors .. but they'd be opened up for generalizing. ( although I wonder if you'd already have cases where some code triggers one behaviour or another based on (..) vs [..] ) I think that's what got me thinking this way: If I'm writing 'immediate short arrays' (testing stuff out), I can write (..). I was more naturally drawn to those for 'vector-maths' type cases (even though that is really 'an array of 3 floats..') ; the more useful use of the [..] chars would actually be the dynamic array ('here's a vertex array: an dynamic array of x-y-z vectors'). I know this is 'unscientific' but I already have this intuitive preference that (..) is for the fixed-size stuff and [..] tends to mean something more dynamic - simply by virtue of how it's used elsewhere (e.g. seeing JSON); but it might be justifiable as 'the most complimentary use, for the premium syntax of inbuilt brackets'. I'm recalling the neat feel 'old rust' had with it's ~[T] which was light enough to 'melt away', giving something that was getting remarkably close to the experience of haskell whilst still being a full-strength systems language ('try these functions out and see if they do what you want, whilst writing tests , reading output, and seeing coherence between what you read and write'')... and the type signatures for common stuff being quite light* (asside, I was also asking about making [K=&gt;V] a type-syntax shortcut for hashmaps aswell, and I note that swift has actually done something similar [K:V] .. ) perhaps the more useful outcome would be if the [] chars were freed up for a more versatile use in the type syntax. I'm also inspired by Hoogle, and a tool I've seen for 'clojure' where you can search for functions by typing in input-output pairs. *this is the great value of having an efficient literal syntax*. 'find me the function which turns [1,2,3,4,5] into [1,2,4,3,5]' answer '.swap(3,4)' "find me a function which turns [1,3,9,4,2,7] into '9', and [5,4,3,1,2] into '5'" .. answer: 'max_by(..)' imagine a website accumulating queries and answers as well as doing brute-force searches of the sourcebase, trying things out till it matches.. 
[https://github.com/bschwind/yoga-rs/pull/6](https://github.com/bschwind/yoga-rs/pull/6)
It can be used on any identifier (hence the name)
This is not at all what I mean! We are talking about higher rank function pointers - `for&lt;'a&gt; fn(&amp;'a i32)`. The point is that a hypothetical `for&lt;T&gt; fn(T)` would *not* be monomorphized, which would be impossible without RTTI because different arguments passed to it would have different sizes and layouts - it would need to accept not only `i32` and `I32`, but also `i64` and `i8` and `[i32; 1024]`. This is *not* true of lifetimes, which play no role in runtime representation of values.
I read the [macro chapter in the Rust book](https://doc.rust-lang.org/book/first-edition/macros.html) and thought identifiers were only variable names.
I'm guessing users of non-natively compiled GC'd languages would sooner move to a natively compiled GC'd language than to Rust.
double post
So what you mean is that though life-time could affect dispatch via e.g. specialization on lifetimes, they never change the layout of a reference: `&amp;'a i32`, `&amp;'static i32` and `&amp;'b i32` all have the exact same size, layout, alignment, etc. at run-time? So even though they are different types, this doesn't affect run-time representation? So if we could have something like `fn foo(i32 | I32);` where the types of `foo` are a closed set with the same representation (e.g. using a raw `union`), we actually can do the same for `foo`, but we cannot do this for `fn foo&lt;T&gt;(T)` because that allows types of different layouts?
&gt; Rust tracks whether individual values can be mutated or not. And it even defaults to (IMO) the right behavior of immutability. Nonetheless, there is no indication in the type signature of a function that it performs side effects. This is a little misleading. A function type in Rust can express exactly one kind of side effect: variable mutation - which happens to be the side effect under consideration here. If you replaced `&amp;mut self` in your function with `&amp;self` then you would find that it would not compile.
Dynamic types languages also have type systems. The here used language Python has a *strong* type system. So this article is really about *static* vs *dynamic* typing. Imho nothing new 😉
You can of course trigger this with ulimit and changing the overcommit settings as well
It can be done from within a library https://crates.io/crates/dont_panic
Much of what had to be said has been said in previous comments. Just a quick note. Manual memory management is the hard part. But also the easy part , because rust does it very well compared to C. The reason i would call it the hard part ( for you ) is because you are going to see a lot of constructs that are really helpful and powerfull, **if** you understand what problem they are trying to solve. Personanly im pretty good at ELM which tough me the basics of Iterators / Results / Options. I know enough of C to understand pointer arithmetic and vtables, which helps in understanding the use of Box and trait objects. And still i had to fight the borrow checker for the first week or two ( But perhaps that was partly because i thought i could get by without Rc&lt;_&gt; stuff ). So yeah. you should go for it! but if you don't understand the previous paragraph , make sure to read a lot of other people's code &amp; examples. P.S. Fighting the borrow checker might be frustrating, but trust me when i say it is a joy compared to segfaults , data corruption and all the other bugs you would get with C.
&gt; So even though they are different types, this doesn't affect run-time representation? Yes, that's what I mean.
&gt; jemalloc &gt; impossible to handle OOM You could write `struct MyBox` that is practically identical to `std::Box` (except for `DerefMove`, but that is minor issue, since you can implement it as a static method). It can call `malloc` using FFI and return `Result&lt;MyBox&lt;T&gt;, OOMError&gt;`.
&gt; Still, test coverage is currently unknown, and assumed to be far from complete. So it takes a lot of work, effort, time to run Rust's test on so many platforms, yet we don't know if the relevant code paths are tested? It looks to me that getting accurate code coverage for the Rust ecosystem is a critical missing piece of its testing infrastructure.
I've never thought of references and lifetimes this way. I always thought that `&amp;'a i32` and `&amp;'static i32` to always be different types, but they are only different types at compile-time, at run-time they are the same type `&amp;i32` (so to speak).
If that language is Haskell, there's probably no advantage. dynamically typed language -&gt; statically typed language =&gt; less bugs, less tests required language with null -&gt; language without null =&gt; less bugs, less tests required What about other (non-memory) resource management? I can understand if you pretty much don't need it, if all you do is read data at program start, then process it and then save it. But maybe it's not that simple. Rust helps with that. From all langs I've ever seen Rust has definitely the best error handling. (operator `?` is both explicit and succinct; sum types prevent errors)
We could, with RTTI, also have function pointers be higher rank in types, but that would not be zero cost. The important point is that with lifetimes it costs nothing to be higher rank over them, because they are all the same at runtime.
I still have one question: Why aren't references with different lifetimes incompatible run-time types? The answer seems to be "because they can" but that doesn't mean that they must.
how to load and render texture with piston_window? cant make documentation example work
I will be working on my first semi-useful project, [ent](https://github.com/Badel2/ent). It allows you to calcute the entropy (quantity of information) of the files passed as arguments. Some planned features are: * support for folders * calculate the space that could be freed if the files were compressed * do some useful statistical analysis on the file contents * better error messages: instead of "entity not found", "File does not exist" If you have any more ideas, feel free to leave a comment!
Looks promising! I've been experimenting with iron but not enough have formed an opinion yet. What are the primary reasons not to use one of the existing frameworks?
What you say is equally true for all other programming languages, and could even be true for different implementations (except perhaps for those with formally verified assembly output). So I don't really see your point. 
&gt; A lot of FOSS people started contributing out of passion and later got a paying position because they were good; while this may bring in compassionate people who stand for what they believe in it also brings in passionate people who feel a strong sense of belonging with a certain identity and that's a great way to shoot objectivity down the drain. That's a clever observation. I'll try to remember that.
What about `wrong code generation bugs`? As I see there is `codegen` tests, but they checked input of llvm, what about output of llvm? I ask because of last huge break after update to LLVM 4.0. But https://github.com/rust-lang/rust/pull/42930 not contains any regressions tests. You run llvm tests instead?
&gt; Currently the jne .LBB1_2is completely trashing the branch prediction The processor ought to be very good at predicting "every other branch is taken". Anyhow, it's a compiler issue. GCC is able to avoid the double loop on very similar C code, while clang is not: https://godbolt.org/g/opdZAM (I disabled loop unrolling because GCC only performs it at -O3). In fact, GCC compiles the double loop to even better code than the `c_loop` function from the blog post! The first iteration is peeled out of the loop, then final value replacement can effectively transforms the double loop to an `i+=2` and the code becomes effectively the same as the post's `c_cheating` version.
Well, I'm not entirely sure at the moment if I'm honest! At my uni we can either propose projects and then badger people to supervise them or we can pick from a list of projects the staff have proposed. I did the latter, however these are typically quite broad and can be changed by the student. Mine was pretty much "implement some boosting algorithms". I have implemented binary AdaBoost with decision stumps (decision trees of depth 1). I think it's working, although I thought that decision stumps would be worse than they are and therefore that boosting would improve them more than it did. That'd be cool. Not sure how great the quality would be. I know in Python everything data-y uses numpy but at the moment I'm just using Vecs. I'd also have to check with my uni anyway, I don't know what languages are allowed and also if they're funny with licences/copyright. 
Well in languages with type systems like Rust/Haskell*, we often have computationally equivalent terms which are of different types. If I make my own `data B = T | F`, that's computationally equivalent to `Bool`, but the compiler will reject it none the less if I conflate the two. Regarding tuples and vecs, keep in mind that the types in each tuple slot are independent of each other, while in vec they are not. From a Haskell perspective, there are lenses `_1` and `_2` to map over `a` and `b` in `(a,b)`, respectively, but there is no way to make such a polymorphic lens for `Vec 2 a`. The best you could get is to monomorphise it to a single type or map over all the values at once using the usual `Functor` instance. EDIT: * I say with "type systems like Rust/Haskell" because there are other more exotic ways of thinking about type theory which do not have this property, conveniently called "computational" type theories
It might be useful in [`dont_panic`](https://crates.io/crates/dont_panic) crate.
I need a bit more time to read through and parse this function definition to understand _why_ it worked, but it worked perfectly, allowing the input to be recursively processed while leaving the input non-mutated. Now for some fun... is there a way to visualize what happens to the memory used with the new code? fn main() { let vc = vec!["A", "BB", "CCC", "DDD", "EEEE"]; let vc1 = recursive_walk(&amp;vc); if vc1.is_empty() { println!("Vector returned from recursive_walk is empty."); } else { println!("Vector returned from recursive_walk is not empty:"); for item in vc1.iter() { println!("vc1: {}", item); } } for item in vc.iter() { println!("vc: {}", item); } } // recursive_walk // Recursive function that walks a Vec&lt;&amp;str&gt; to the end. // Should not be destructive to the input vector. fn recursive_walk&lt;'a&gt;(vec0: &amp;[&amp;'a str]) -&gt; Vec&lt;&amp;'a str&gt; { let mut vec1 = Vec::with_capacity(vec0.len()); let mut x = 0; while x &lt; vec0.len() { vec1.push(""); x+=1; } vec1.copy_from_slice(vec0); let vc1 = vec1.split_off(1); for item in vec1.iter() { println!("vec1: {}", item); } if vc1.is_empty() { return vc1; } else { return recursive_walk(&amp;vc1); } } 
See above. I was experimenting with trying to figure out how to pass a slice of the Vec as an argument, rather than a Vec, because I suspected that pass-by-value was destroying the input vector. Thank you for confirming my suspicion.
Even file modifications or network access are usually visible, because you always need to pass something as &amp;mut that has a file/socket in it. The whole Result producing warnings when not used and file/socket usage producing results results in stuff being kinda similar to Haskels IO imo.
Seems like it's a neat wrapper around Tokio, whereas Iron is another animal entirely.
Vectors have two values associated with them. There's the `capacity` which dictates how large the actual block of allocated memory and the `size` which indicates how many elements are actually in the vectors. In your wxample` buf` has a capacity of 1024 but a size of zero. When it is conviertes into a slice, it's still a slice of size 0. In order to create a vector of a specific `size` you can use the `vec!` macro. let must buf = vec![0; 1024]; This line creates a vector of `size` 1024 where every element is initialized to 0.
&gt; we often have computationally equivalent terms which are of different types. fair enough; i'm not objecting to the fact that you can represent the same thing in different ways: the main motivation here is to free up the ```(,.)``` and ```[...]`` for a more complimentary uses. I suppose you're saying it would be *bad* if you automatically get array indexing on (A,A,A) , whilst not getting it on (A,B,C) .. but I would argue that you could introduce new types , 'ReallyJustTuple&lt;A,A,A&gt;' or a 'ReallyArray(A,N)' in the cases where it *does* matter. (in another tangent i've been asking about A!=B type constraints,maybe there'd be other ways of filtering out what you really mean..) imagine if those types were created then we just assigned the (,) and [,] as constructors for whatever we found to be most useful (and most complimentary to each other) I guess you might have 'vectors of tuples' and the tuples really represent key-value pairs, and it would be confusing if they also fit a 'Nx2 matrix'. However, in the 'key-value-pair' scenario, maybe you want to go further and distinguish the key and value types from eachother (I have other posts about wanting to generalise the Vec&lt;T&gt; to take an index, e.g. distinguishing 'vertex indices' from 'primitive indices' instead of them both just being 'ints'). i also find myself wanting 'anonymous structs' which might fit the key-value pair case .. although tuple-structs are pretty close (you could name the whole thing with a strong hint that it's a pair of names.. KeyAndValue(k,v) 
^ /u/steveklabnik1 
&gt; This would be a step backwards in terms of type inference, I suppose—[1, 2, 3] knows it’s homogeneous, (1, 2, 3) needn’t be Thats a great point, what I had in mind though is that any replacement uses of ```[...]``` *would* still assume all the contents are of the same type. Conversely, I've been trying to write my vector maths general enough to use different types for X,Y,Z, X,Y,Z,W so that you could slot in 'constant zero, constant one,constant minus one' as 'phantom types', such that homogeneous points x,y,z,1 vs x,y,z,0 could be represented just taking up 3 slots in memory; single scalars in memory could be semantically marked up as 'axis vectors' (Zero,f32,Zero)='a vector along the y axis'; an 'identity matrix' could be constructed as ((One,Zero,Zero),(Zero,One,Zero),(One,One,Zero)) .. a scaling matrix=((F,Zero,Zero),(Zero,F,Zero),(Zero,Zero,F)) etc etc.. These things would flow through the maths operators, with f32*One-&gt;f32, One*One-&gt;One, T*Zero-&gt;Zero, etc etc. Unfortunately I'm still fighting trait bounds there :) but I get the impression it should technically be possible.
You will probably need the following: * [UdpSocket](https://doc.rust-lang.org/nightly/std/net/struct.UdpSocket.html) for incoming UDP packets (as far as I know there is no such thing as a UDP connection) * [serde_json](https://crates.io/crates/serde_json) for JSON serialization * [rs-es](https://crates.io/crates/rs-es) to use the ElasticSearch rest API
doesn't work with mio. ``` note: the method `read_buffer` exists but the following trait bounds were not satisfied: `mio::net::TcpStream : buffer::ReadBufferRef ```
Do I need to parse JSON? ES batch requests are fairly trivial, just some string concatenations/ What about multithreading? How will this be solved? Multiple nginx workers will try and send the data to the service.
&gt;The processor ought to be very good at predicting "every other branch is taken". It really isn't though. I benchmarked the following: (0..high +1).filter(|x| x % 2 == 0).map(|x| x * 2).sum() vs (0..high +1).filter(|x| (x &amp; 0x20) == 0).map(|x| x * 2).sum() They both generate practically the same assembly, except that for the first skip test is: test 1, dl while the latter is. test 32, dl Now the only real difference between them is that the first one switches behaviour constantly while the second one only switches behaviour every 32 iterations. When I benchmarked it on my machine, this was the result: iter_1_cycle: 1402 us iter_32_cycle: 998 us Now the only difference between these was how often the skip branch would change behaviour, so the 40% perf loss is clearly just branch mispredict. Quite interesting that GCC was indeed able to perform the unroll-fuse optimization. Guess Clang still has to learn some tricks.
`read_to_end` is not working. just `read` is working, but it also not incrementing buffer size.
&gt; Maybe the reason is just me being not very experienced in Rust, but most of the code I write don't need to be super-performant, and in this case Rust feels less productive than garbage-collected languages. &gt; I have been through this phase you are describing, and now I feel like I can be equally as productive as I would be in Rust and C# which I used extensively prior. It takes time and effort to be proficient in Rust, but IMO it's worth it.
Despite your edit, I'd still say `Box&lt;[u8]&gt;` is an antipattern. Better to use `vec![0;1024]` here.
Working on my first Rust webservice, an OpenRTB Win notification handler. Still lots of learning.
&gt; Do I need to parse JSON? ES batch requests are fairly trivial, just some string concatenations If you want to manually munge protocol data that's doable, but you'll have a much harder time dealing with malformed data, should anyone ever send it. &gt; What about multithreading? How will this be solved? Multiple nginx workers will try and send the data to the service. Multiple NGINX workers can send to a single UDP socket, and that socket can be serviced by a single thread, it doesn't have to be 1-to-1. It's unlikely that you'd fully saturate a single thread unless both the producers and consumers of input live on the same machine (and even then you'll end up outpacing the disk). If that were to happen the first step would be to find what is the bottleneck and parallelize that part. It is totally possible for multiple threads to call `recv_from` on the same socket (although what that does might be OS dependent).
&gt; 40% perf loss is clearly just branch mispredict. Protip: there's a lot more measurement that you can do just as easily as `time`, for example `perf stat`; on the other hand, a benchmarking harness often gives too much importance to the timing. In this case, the difference is simply more instructions executed because both of the loops do `i++`: for every time the (smaller) inner loop iterates, you execute the rest of the outer loop one time fewer. If the inner loop advances i by 32 instead of 2, the outer loop now has to do 16 times fewer additions, comparisons and jumps. Here is what perf says with "x % 2 == 0": 765,338798 task-clock:u (msec) # 0,999 CPUs utilized 2614644838 cycles:u # 3,416 GHz 615977674 stalled-cycles-frontend:u # 23,56% frontend cycles idle 7999409067 instructions:u # 3,06 insn per cycle 1499914588 branches:u # 1959,805 M/sec 20463 branch-misses:u # 0,00% of all branches With ~~"(x &amp; 32) == 0"~~ "(x %32) == 0 (_edit_: this is not the same test mentioned in the parent comment, though I suspect that he messed up his numbers as well, since as shown above there are no mispredicted branches in "x %2 == 0"): 593,509985 task-clock:u (msec) # 0,998 CPUs utilized 2048907208 cycles:u # 3,452 GHz 916826277 stalled-cycles-frontend:u # 44,75% frontend cycles idle 5187190074 instructions:u # 2,53 insn per cycle 1031211220 branches:u # 1737,479 M/sec 27098 branch-misses:u # 0,00% of all branches Note how the processor actually _prefers_ the "x % 2 == 0" variant quite strongly (3.06 ipc vs. 2.53), because it's harder for it to schedule the very tight inner loop. But the sheer number of instructions to execute makes "(x &amp; 32) == 0" faster.
Right, "read" only with only works with an existing slice. Can you elaborate on "not working"?
I'm very confused how you're getting such different numbers of instructions executed. looking at the assembly generated, it shouldn't execute a significantly different amount of instructions. Essentially the assembly is structured as a block of outer loop (O) followed by the inner loop (I). in the 1 case they execute in the following order: OIIOIIOIIOIIOIIOII.... In the case of 32 (or well, let's keep it at 4 for this example because it gets hard to read), it executes: OIOIOIOIIIIIOIOIOIOIIIIIOIOIOIOIIIII Both have a ratio of 1 outer loop per 2 inner loops, the division is just different. Barring speculative execution, they should just execute the same amount of instructions. I'm not sure how you think it's only executing every 16th addition, unless you misread the `(x &amp; 32) == 0` (execute 32 additions, skip 32 additions) as `(x % 32) == 0` (execute 1 addition, skip 31 additions).
Nit: the reason for 1 being less than "fish" in python 2 is not that strings compare by their length, it's that when incomparable types are compared, they sort by their type, so all ints will come before all strings. In fact, it's also just not true that strings ever sort by their length in python. They sort in "alphabetical" order, by byte value.
I'm not a fan of calling Python's type system "strong". It is only stronger than dynamic type systems that have less runtime checks (and for instance allow `1 + "1"` or don't even have different runtime types for that).
It's going to be linux first. I am not sure I understand the single threaded scenario too well. while recv_from(buffer): accumulator.add(buffer.to_json) if (size(accumulator) &gt; batch_size): elasticsearch.send(command.from(accumulator)) accumulator.clear() Again, if I understand you right. It has a nice property of non concurrent access to accumulator, but what's gonna happen to the socket? Will it maintain an internal state whilst the data is being pushed to ES? If there's a buffer, how big is it?
Good analogy, and I know it all too well from trying to pitch new technologies to my boss. He already wants to know what the ROI is, and with Rust, that's a really hard sell since the costs are at least a couple weeks for any developer coming into the project, and the benefits can't really be measured since they're mostly preventative. Which is one of the reasons I haven't pitched Rust. I guess the way to sell it in this case is to add up all the time spent fixing bugs that Rust would've prevented, and, assuming that once learned, there's no practical efficiency hit with Rust, and compare that with the time to learn Rust. I leaned it at a hobby (I like learning languages), so the ROI for he didn't include the learning time.
That seems like it has the same problem as using `catch_unwind`: you have to remember to use it.
I'm referring to the basic function calling syntax, performance is a bit off topic.
If you filter by "(i % 2) == 0", the inner loop is a "while ((i % 2) != 0", and the outer loop executes for i = 2, 4, 6, 8, ... ~~If you filter by "(i &amp; 32) == 0", the inner loop is a "while ((i &amp; 32) != 0", and the outer loop executes for i = 32, 64, 96, 128, ...~~ If you filter by "(i &amp; 32) != 0", then you execute 32 additions and skip 32 additions. The instruction count is indeed the same as "(i % 2) == 0", but so is the performance: 735,030556 task-clock:u (msec) # 0,999 CPUs utilized 2546754902 cycles:u # 3,465 GHz 561862672 stalled-cycles-frontend:u # 22,06% frontend cycles idle 7998509050 instructions:u # 3,14 insn per cycle 1499764496 branches:u # 2040,411 M/sec 145607 branch-misses:u # 0,01% of all branches And for whatever reason, the branch prediction is a bit worse than for "(i % 2) == 0", but still most branches are predicted. I'd expect a Pentium 2 to predict the "(i % 2) == 0" version perfectly, since it tracked the last 16 outcomes.
Most of what you arrayed there sounded like arcane references so I _definitely_ have a lot of reading and learning to do. I've gotten off to a rather slow start as I've had little free time to devote to learning rust but hey, it's a start! As for the frustration and the "...if you understand..." parts.: That's the main reason why I was asking if I would be better off learning the fundamentals of CS and moving on to C before even considering Rust. It seems to me that the language is low-level enough that I will eventually have to deal with things I don't even know about. And that at other times I won't have to deal with things at all and instead it will be completely babysitting me, without me even knowing it's doing so or what's truly going on underneath. Which on one hand is certainly nice. Better to prevent the error altogether than to allow it to get compiled and segfault or whatever. But on the other hand instead of getting a nasty error and having to devote the time to learn from it I will simply get told "oh no, none of that, it's bad". Of course, the alternatives I'm considering would do a similar thing but at least they are higher level so I'm thinking it unlikely that I'd have to deal with the things I'm likely to have to deal with in Rust. Thus the _easing_ into it. Of course, as I know none of these languages all of this is nothing more than a set of assumptions.
With the difference beeing that it is 1) statically checked and 2) (applies to `catch_unwind` as well) ~~can~~ **could** be enforced via compile time checks. Still sucks though.
The OS maintains a buffer, which can be adjusted if necessary: https://stackoverflow.com/questions/2090850/specifying-udp-receive-buffer-size-at-runtime-in-linux
Recent users have found some weaknesses in ggez that could be fixed: Window resizing and some changes to how the input handling works. So, I'm hoping to work on fixing those. Also still making my own game, bit by bit. It's gotten to the point where there's lots of options of what to work on next, and it's not terribly clear which is the lowest hanging fruit, so it's a bit slow going.
I'd like to lean on other crates in the ecosystem (e.g. noise-rs and rand). I'm still not sure if I'll wrap those with an API closer to libtcod and re-export. It also might be good to have each slice of features in a separate crate, then an umbrella crate so one can have a more `libtcod`like experience, but still have useful individual crate if that is wanted. "In spirit" means everything is available, but might not be the same API, or it might be in another crate. I'm not really trying for a drop in replacement, but it should still feel familiar. I worked a little bit with the python wrapper, and it was pretty strange python. There is actually another library that attempts to wrap it in a more pythonic way. I haven't looked much at tcod-rs, so it might already be idiomatic Rust. Everything is still really early. Do you have any particular likes and dislikes from libtcod and tcod-rs?
&gt;If you filter by "(i &amp; 32) == 0", the inner loop is a "while ((i &amp; 32) != 0", and the outer loop executes for i = 32, 64, 96, 128, ... No, that is again how "(i % 32) == 0" would behave. Just think, x &amp; 32 is 0 for x = 0 up to 31, it is 32 for x = 32 up to 63 and then repeats. Saying it would execute for x =32, 64, 96 etc doesn't even make sense as 32 &amp; 32 == 32 while 64 &amp; 32 == 0. How would it then trigger at 64. I'm also not sure how you expect x &amp; 32 == 0 and x &amp; 32 != 0 to have different cyclic behavior? After all they are just each other's complement. 
Oh wow! Did not know that. Will fix. Thanks for the info :-)
Do you have a reference for that? Would love to add it to the article.
The slides are very interesting. I agree it is important to consider the cost of security measures for the users. However I don't agree with the "actual damage per year" calculations. Just because security holes are currently not exploited as badly as they could be does not imply they cannot or will not be exploited in the future. These future damages might be orders of magnitude higher than the current ones.
If you're in a particularly strict situation and you need to be able to handle malloc returning an error, it *is* possible right now in stable Rust to bind to malloc directly and just use that. It's not as convenient as just using jemalloc, of course.
You're right, in the first comment I was using "(x % 32) == 0". But I'm still skeptical of your results. In the last comment I was doing the right thing: as I expected `OIOIOIOIIIIIOIOIOIOIIIII` is slightly _harder_ to predict than `OIIOIIOIIOIIOIIOIIOIIO`, not easier, but performance is the same. And the similarity between my wrong results (770/600, i.e. +30%) and yours (1400/1000, i.e +40%) is striking. Are you sure you were not doing the same mistake? Do you have a godbolt link I can use?
&gt; pretending it's a bonus is silly. It's a tradeoff. If you have global type inference, changing a local variable can be a breaking change, because it can propagate anywhere. In Rust it always stops at the function boundary.
but that is the definition of strong. Python has a strong, dynamic type system. A language like PHP has a weak, dynamic type system. Rust has a strong, static type system. C has a weak, static type system.
/u/bjzaba/ made an [excellent point](https://www.reddit.com/r/rust/comments/6mf0bx/why_you_should_actually_rewrite_it_in_rust/dk1mk0x/) with regards to that: &gt; It makes sense in Haskell, OCaml, Elm, etc. because everything is curried by default. It makes little sense in other languages, and forces you to think 'should I put parens around this argument list, or should I not?' whenever you call a function/method. I have no experience with "curried by default" languages, which would be yet another alien thing stressing me out when I'm still trying to stop stressing out over how little I know about evaluating my success at pleasing LLVM's optimizer (I can't read LLVM IR or x86 assembly), the CPU caches, and the branch predictor. The mention of performance was just a way of saying "I already have enough to misunderstand without piling the syntax on top of that".
 Could you define 'mqtt broker'?
https://rust.godbolt.org
Here's an [old page](https://docs.python.org/2.3/ref/comparisons.html), that describes the behavior. The key quote is here: The operators &lt;, &gt;, ==, &gt;=, &lt;=, and != compare the values of two objects. The objects need not have the same type. If both are numbers, they are converted to a common type. Otherwise, objects of different types always compare unequal, and are ordered consistently but arbitrarily. In later versions of python 2, [the documentation changed](https://docs.python.org/2/reference/expressions.html#comparisons) to describe the behavior more precisely, but in a way that is not quite as intuitively clear. The default order comparison (&lt;, &gt;, &lt;=, and &gt;=) gives a consistent but arbitrary order. Which is to say that comparison that the only way to get non-arbitrary ordering is to define a custom ordering (or use a type that already defines a custom ordering). Technically an int and a float are different types, but they compare as you'd expect. Strings and Unicodes can be compared. But in the absence of specific rules, the ordering is unspecified, but consistent.
&gt; Just having the possibility to say here is the "link directory", "vendor directory" or "package server" and use those binaries. You can, just that Cargo doesn't have de facto support for this, and binaries only work with the same Rust version. But C++ doesn't have a default package manager in the first place, so it's not a fair comparison if you only look at cargo. Rustc does fine with binaries taken from wherever, as long as they were compiled for the same Rust version. `rustc -L directory/` works. I use this all the time when writing test programs that depend on crates I already have compiled; via `rustc -L target/debug -L target/debug/deps`. &gt; I guess it is a matter of perception, for me all components that end up in the produced .exe are part of project build times. Fair, but these are things you only compile once, so it's not the annoying part of build times. Anyway, I was only talking about core project code in that comment -- external dependencies have no impact on incremental build times, and my header file comment was only about incremental builds (hence my confusion when you started talking about staticlib dependencies). &gt; Redirecting the output target dir, appears to make it less so, but I still see it happening sometimes, maybe due to something that makes a project not able to re-use an already compiled crate. Often if cargo features are in use this gets muddied. Also you may be using different versions of the same crate. The best way to share a target dir is to stick everything under a Cargo workspace (a sort of toplevel shadow Cargo.toml). I think. It's not what the feature was intended for, but this probably will work. Ultimately if you want this to work you probably need to design a makefile based system instead. (Might not be hard to get cargo to cache all deps in a global target dir, though. This is something that could potentially be a cargo feature, it's just not something that would be priority)
&gt;- hygienic macros (GC doesn't prevent this, besides D's `static`, I haven't seen a GC language that has a decent macro system) Racket is garbage collected, and it seems to have nice, hygienic macros to my untrained eye. 
Not really a point, just brain dumping. I was just imagining a world where every piece of software is written in Rust and so that means there is a single point of failure (rustc). C, for example, has many implementations and so the security/safety issues are less likely to be shared between these. Rust is a much larger code base, performs more complex compile time checks and is more heavily leant on by developers. So while compiled object code issues can occur other languages, it is more likely and more dangerous to manifest in Rust. https://en.wikipedia.org/wiki/N-version_programming slightly relates
higher rank lifetimes are extremely useful and for this reason they were implemented.
At least when using this using Gitlab CI, it doesn't seem to want to compile anything using `cargo build`. Running with gitlab-ci-multi-runner 9.3.0-rc.2 (110d530) on docker-auto-scale (4e4528ca) Using Docker executor with image tomastomecek/rust:nightly ... Using docker image sha256:80ee70038ad0c28fb552e40382b03214f4505df77e08f06831c388b4b3a8325c for predefined container... Pulling docker image tomastomecek/rust:nightly ... Using docker image tomastomecek/rust:nightly ID=sha256:d79c350039686e8bdd437b1fa090ee5c6fc61bf8c9ddbed8cb57869052893b9b for build container... Running on runner-4e4528ca-project-3683601-concurrent-0 via runner-4e4528ca-machine-1499785192-4085b70b-digital-ocean-2gb... Cloning repository... Cloning into '/builds/binero/testproject'... Checking out 9a3f829c as master... Skipping Git submodules setup $ cargo build error: failed to open: /src/.cargo/registry/index/github.com-1ecc6299db9ec823/.cargo-index-lock Caused by: Permission denied (os error 13) ERROR: Job failed: exit code 1
"Dynamic types" is a misnomer: what they are is *tags* (associated to values) not *types* (associated to expressions in the source language). So Python differentiates between, say, `PyValue::Integer(1)` and `PyValue::String("1")` but from a *typing* point of view these are of the same type, namely `enum PyValue { Integer(/*…*/), String(/*…*/), /* … */ }`.
You can always use Tokio, which was built for all this async networking stuff.
Pronounced su-sa-no-o if anyone's curious.
This is very cool! A good MQTT broker, especially one in Rust, is very relevant to my interests :) One question : What was your motivation for using Box&lt;&gt; for several members of the Packet enum? I can imagine lifetime management would be a hassle if you wanted to use references. Did you compare with just using the value instead of a Box?
And I'm sure there are others that have decent macros as well. It's very hard to make sweeping generalizing about a class of languages, but I'm this case I made an exception because it seems very common for GC languages to not have hygienic macros for some reason, but I don't think this has anything to do with GC.
Partially true of course, but types are way more than just "tags" with a different phase separation. The whole point of a type system is to perform static type checking (and perhaps other things like inference, or assisting "type-dependent" language features such as traits/type classes). This is not something you'd get out of simple "compile time tags"!
Also, I noticed that you are an author of [rumqtt](https://github.com/AtherEnergy/rumqtt) It seems like that project isn't quite as modular, and is built using blocking sockets. But you also have a client implementation broken out in the rumqttd repo. Would you recommend using rmqtt, or just use the rumqttd/client bits and create a new, standalone package?
The thing is, macros operate on a token tree so syntax doesn't really matter to them: https://is.gd/2aFjzM It's a bit confusing because $expr, $ty, etc. seem to be higher level than tokens. I think the Marco parser just pulls tokens until something parses correctly as the pattern. In this case, it's not matching an enum variant name, it's matching an identifier, then an open parentheses, then...
Can anyone compare ggez to Amethyst? I watched the Mozilla video, and my impression was that ggez was fine for noodling around, but anything 'serious' would be using Amethyst. However, the Amethyst docs appear to be a shambles at the moment, so I'm immediately turned off to using it (I had already played with Piston and found the lack of documentation to be excessively frustrating). I'd like to hear from people with experience if my impressions are off base or not.
I'm so excited for this feature! Once this, unsafe ptr methods, impl trait, impl specialization, and const generics are done almost all of my pain points with Rust will be gone! Until I find more...
&gt; Look at this list hmm, `aarch64-unknown-freebsd` isn't even Tier 3? A pull request for that landed a while ago…
variadic generics?
I won't say no, but I don't personally have a use for it, now.
My perspective on them is that, while they do have their uses, they'd be as risky as adding classical inheritance for the minority of cases where it *would* be the most appropriate solution. ...novice Rust developers who are used to reaching for them would probably use them much too eagerly in places where Rust has a better option.
&gt;&gt;how often do you think typical Rust code needs to drop into unsafe not often, but, someone somewhere has to write the unsafe code, and that remains a big part of my interest. to my mind actually writing 'unsafe{}' is enough, you don't need to make it *even more verbose* to discourage it.. I argue this does not make it any less error prone; this sort of thing has to be checked empirically anyway; as such *the speed of writing tests* is more important. &gt; but I prefer it, as do many other people. I do prefer some aspects.. but not all; &gt; Rust doesn't require losing features, though? Obviously with any rewrite, it's a challenge to maintain parity' not sure if you're talking about program features or language features; what I mean here is language features, obviously 'a language comparable in complexity to c++' is not going to spring up in a short span of time; but to explain why C++ people aren't unanimously going to move over: every little difference adds up; there's a few key differences that are really useful (e.g. to me: 'transitive immutability by default.. restricting global variables' .. I think we could quantify the number of times we have to write 'const' vs 'mut', to demonstrate objectively that immutable is a better default ; i like the default of immutable inputs and returning an output) .. whilst others are more opinion based. (things like 'default function arguments aren't needed..' .. 'overloading is bad' ..) the trade off then is "do we wait for features to be added to C++, or take the leap to rust" . Safety (contrary to evangalists claims) *can* be retrofitted IMO, i.e. use a static analyser and make a 'ref&lt;T,LABEL=1&gt;' template to label lifetimes outside of a default assumption. it's the other syntactic conveniences (the bits of rust that I *do* like) that are harder.. because C++ legacy constrains choices. But you could even do something like the SPECS idea to change the syntax. (I've given up but this was my attempt to 'mash up the bits of C++ and Rust that I like, with the intention of being able to eventually transpile a subset:' https://github.com/dobkeratops/compiler ) (i do like rusts' 'expression based syntax' but people have pointed out you can retrofit this to c++ using lambdas. x=[](){switch (..){case... return.. case.. return .. }(), messy but maybe you could clean that up with a macro..) The use of a language becomes instinctive/intuitive, plus you have the value in existing sourcebases.. This is what you're throwing away by taking the leap. The productivity boost has to exceed a certain threshold to make this worthwhile. r.e. instinct: - I logically prefer Rusts '''let x:Type =..''' expressions; but '''Type x''' *always* flows first from my fingers, because I've been doing just that for 20 years. I'm just looking into Rust in free time for personal interest.. trying something different for the sake of different; .. for an organization built around an existing c++ sourcebase it would be a much harder sell IMO ("a rewrite can be the death of an organization") &gt;&gt; "if it's that common, you could write some macro " shouldn't be having to write macros to patch around language choices.. just for things that genuinely can't be done any other way. if we accept peppering code with macros for workarounds.. we've already got C++..
We need them to implement `Clone` for tuples though. It's sorta required from a language completeness/self-consistency standpoint.
How are you sending the batches to ElasticSearch? HTTP POST? Is everything going to one ElasticSearch cluster, or are there multiple clusters? How big do you think the packets will be, and how fast will they arrive?
True. Likewise, it'll be interesting to see how the Qt bindings develop, given how heavily some parts of Qt rely on classical inheritance and clever workarounds don't always become apparent. There are always difficult trade-offs to be made in these sorts of situations.
You're totally right! I guess I'm just irritated after that shitty post about Haskell vs Rust benchmarks got upvoted and taken seriously a few days back. I think Rust users should *totally* check out Haskell (both phenomenal languages with similar design approach in niches defined by somewhat opposite trade-offs) and I don't want it's reputation ruined here by shitty evangelism. In hindsight, I don't really think this is an example of that.
thanks for the heads up; we're gonna be doing a different thing for 2.0 :)
Ah, right. I guess most feedback for the current book is probably moot with the new one.
i mean, i created vec![0; 10], now when I am trying to put more bytes in that vec, it is not growing as it suppose to be. it is showing same behaviour as simple array [0; 10].
Strong vs. Weak is about how the system handles typing errors. `1 + "1"` in Python gets you an exception, in JavaScript it gets you `"11"`. Similarly, `ptr + int` in C gets you another pointer, in Rust it gets you a compile time error.
...generators, async/await, incremental compilation, RLS, procedural macros, macros by example 2.0, MIR optimization, better const-fn/CTFE, miri-verified unsafe code... We might not get all those this year (or ever), but there's a lot to be excited about in the future.
Yes. It doesn't matter what other C libraries on your system were built with. Binaries compiled with musl have no dependencies at all.
Now I'm confused. How is C's type system weak and Python's type system strong? Implicitly casting numbers happens in both systems. 
`if ("hi" &gt; 35)` is valid in C, but it will result in an error in Python, for instance. C also has `void*` which is literally an Any/unspecified/basically-unchecked type. You can assign a void* to anything but a float, AFAIK. Watch this: #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; typedef struct { int x; } xs; int main() { xs* x = malloc(sizeof(xs)); void* y = (void*)x; char* z = y; printf("%s", z); } even compiling with `-Wall` on `clang` and `gcc`, neither of them give a single warning about this code, let alone an error. You could remove the intermediate `y` variable and just assign `(void*)x` directly to `z` and you would also get no errors. These and several other things make C's type system *weak*er than Python3's. But, it's all a continuum. There are no strict definitions of "weak" and "strong", just relative ones. Implicit casting of numbers makes Python's type system *weak*er than Rust's, but it's still *strong*er than C's.
I'm continuing work on [oxidoc](https://www.github.com/Ruin0x11/oxidoc). This entails opening a bunch of issues on various useful dependencies (HTML-to-text, terminal markdown rendering) with improvements. In the meantime I'm also experimenting with a Rust roguelike (https://github.com/Ruin0x11/sabi) with `glium`, Lua map generation, and dynamic AI. However I've got the code architecture more or less handled, and it's now in the stage of 'make it fun before motivation runs out'. So it's more of a game design issue than a code one.
"dynamic types" isn't really a misnomer. It's a classic example of jargon terms meeting colloquial terms. If you go read type theory papers, then "types" as a concept don't exist at runtime. They are a purely static construction that can be determined from the source text of a program. This is why type theorists tend to use the term *unityped* to describe "untyped" languages. Outside that context though, we refer to "types" in the PLT sense as "static types," which helps differentiate it from "dynamic types," which are types that are determined at runtime. So when someone says "dynamic types," I think it's pretty unambiguous and clear what they mean. This is important, because "dynamic types" can be further sub-divided into other classifications that are meaningful even though it might be hard to derive any rigor from said classifications.
&gt; that's an implementation detail. By that same logic, all Rust types are just "tags" that only exist at compile time No, the difference is fundamental due to the halting problem and due to external I/O. In a typed language, all variables are *proven* to have their declared types. A variable with an integer type *is proven to be an integer by the compiler.* This is a mathematical proof. If a program's declared types cannot be reconciled, it's not even a program! It's just a jumble of text, has no semantics and thus cannot be executed. In a dynamic language, no general method can ever be constructed for such a proof due to the halting problem, and due to the unpredictability of external input. It is possible to infer types for specific programs, but a general method is provably impossible. (You may "infer" that every variable in your program has a single common type, but this is not very useful.) This is a fundamental distinction that arises from the lack of a type system.
That's right. If anybody is interested in adding coverage reporting to the Rust tree, that would be greatly appreciated. I can probably mentor a bit. I imagine there are tools in the ecosystem to help crate authors do their own coverage, but don't know. That would also be a useful thing to explore. With such a tool we could run coverage under cargobomb to get some pretty interesting global information.
I've checked it again, and I can't see where my approach would be wrong. I've put my code into [this gist](https://gist.github.com/CensoredUsername/36f3bb1ffce99166fd871ccfd368da4b). It contains the code I used, the output of building it in release conf at opt-level=3 (the same as what `cargo bench` should use) .. Scratch that, I think I've figured out the issue. For some reason the optimizer is being really iffy about optimizing the `rust_iter_trash` function. In the original code I put an `assert!(total !=0)` in the bench as to prevent it from optimizing the complete thing away (for some reason `test::black_box(total)` was not doing this as it just gave me 0ns per iteration). When I changed said assert into a proper black_box function it suddenly cut the execution time for `rust_iter_trash` in half while not affecting the time of `rust_iter_notrash`. For some reason it was generating significantly inferior assembly in the total != 0 case. Unfortunately, when I tried to see what it was actually using for the bench using a disassembler by making the bench compile with debug symbols, it compiled to the inferior version again, benching slower. Optimizing compilers are fickle beasts. Furthermore there's the issue that rustc attempts to inline both functions into the bench functions. This however just causes both to bench slower. When I declared both `rust_iter_[no]trash` functions as `#[inline(never)]` The benches actually got faster again, and the difference between both is negligible, so you were right about the branch predictor being able to handle both, no issue. Anyway I've tried to extract assembly dumps for all cases, you can find them in [this gist](https://gist.github.com/CensoredUsername/d9667fe33e162b18af06001f8eb2c73a) (and assorted timings). Looking at the actual asm, I've got no idea what's actually causing the differences, as most of them end up exactly the same. I feel like all these benchmarks are really just an exercise in figuring out how to best fulfill the wishes of your specific hardware. edit: there's no perf results as I'm on windows unfortunately 
Most bugs that classify as incorrect code generation are covered simply by running test cases on the affected architecture and confirming they behave as expected, so don't require a special class of test. Where you might want a special kind of test is for confirming that specific optimizations are happening, and you are right that we don't have any kind of test, as far as I know, that checks the exact assembly generated by rustc. The specific PR you link looks to me like it should have been accompanied by a test case, but perhaps the author had reasons not to. Note though that we may not be running tests on the architecture that codegen bug affected, so even having tests might not help. It may even be that we have preexisting test cases covering that bug, but because the CI isn't testing that architecture it didn't get caught. Codegen bugs mostly happen on 2nd tier architectures that are not running tests on CI - x86 codegen bugs are much rarer than other platforms. 
Python only upcasts numbers iirc, so you can't have your int -1 turn into unsigned 2^64 - 1 because your compiler thought it would be funny.
Oh, to your last question, we don't run llvm's test suite ourselves, but that would be an awesome extension if we had the resources - we're quite dissatisfied with upstream llvm's own qa.
&gt; really? pulling out the halting problem here? Yes, really. You cannot infer types for an arbitrary program in a dynamic language. This means that you cannot prove the type of an arbitrary variable in such a language, which you can do in typed languages. If you strip types from a typed program, you lose information which cannot be recovered in the general case. This distinction is so fundamental that it cannot be swept under the rug as an "implementation detail."
It says 60fps at the top... Is there a higher frame rate video?
Rust doesn't even have regular variadic functions, isn't this a step beyond that? 
No, an identifier is the token that appears anywhere that things have a name.
Without variadic generics, type-safe regular variadic are (semantically) isomorphic to a function that takes an array/slice, and so there's not much reason for them to exist as a separate feature other than a slight bit of syntactic sugar.
Try `False + 1` or even `False + 1.0`. Python's type system is weak, and annoyingly so.
It's weak compared to Rust, but strong compared to PHP or even C, as discussed. "Weak" and "strong" are not absolute terms.
(Note that cargo uses a more useful variant of semver, where 0.x.* versions are compatible: it assumes things are compatible unless their first nonzero digits are different.)
There's also the explicit vs. implicit axis, which represents the most immediately visible difference between how local variables are declared in languages from C and Java (most explicit), through C++ and Rust (type inference allowed in some contexts), to Haskell (more type inference allowed). I've seen a lot of people get confused about that and think that "static" or "strong" will inherently imply Java-level type declaration verbosity.
That doesn't clear it up for me. Soosayno-oh? sussahno-oh? 
No, an identifier is the token that appears anywhere that things have a name.
It's basically a server which routes packets from one client to other(s)
Packet enums are defined in underlying crate which isn't written by me. I modified it a bit and made it fit here. I'm on mobile now but I'll post links to original repo tomorrow 
Tribalism is very prominent basically any time you put people in groups together, and apart from others. Its something most humans naturally gravitate towards.
Sure, I think Rust is in some ways harder to learn than C++. Some things are just daunting to understand and deal with because everything is wrapped inside something. And the weird/stupid things, like I was also amazed to find out String doesn't have a substring method or that you have to workaround to get class-files-in-a-namespaced-directory structure which is a must have especially for a new and shiny language trying to compete with the big boys. I'm not sure at all learning Rust is worth it because it's not a net gain, it's just a huge trade-off.
That's a poor example. Bools are explicitly defined as a subclass of ints. I'm not going to argue that this was a *good* design decision, but it's not a weakness of the type system. I'm not saying python's type system lacks annoyances (UnicodeDecodeError, anyone?), but the case you mentioned is not an example of type weakness.
Without seeing example code it's difficult to tell what's happening vs what you expect to happen. One extra complication here is that you're using Mio and nonblocking sockets, so depending on what event has fired there might not be any pending data on the socket for you to read. Here's an example of read_to_end working: https://is.gd/73RhDX
Yeah I wrote that client implementation quite some time back for my org. But simultaneous publishes and subscriptions isn't possible with TLS &amp; blocking sockets AFAIK. I stopped developing that. I plan to release tokio based client when I figure out how to do automatic reconnections. I'm not very comfortable with tokio yet. 
I don't think it is a good advice to someone who have never write anything in rust.
No, an identifier is the token that appears anywhere that things have a name.
This proposal seems to be focusing on references, but what might happen if we tried applying it to values? If values could follow similar rules, than they can be dropped right when they stop being used rather than all at the end of their scope/function. If everything that needs to be dropped can be dropped before the return, than *tail calls* should be possible without a dedicated `become` syntax.
Amethyst is undergoing many changes at the moment, that's why there is no effort to improve docs right now. Try checking again in a few weeks ;) Other than that, I cannot say anything about ggez because I never actually used it.
60 fps is the max
Amethyst seems like the sort of thing you'd want to use if you *know* you're going to want an ECS. For any thing else, it may be better to use a simpler framework or roll your own thing with gfx and glutin.
+1 I would definitely participate in a Rust game jam!
&gt; but it will result in an error in Python, for instance. $ python -c 'print "hi" &gt; 35' True To be fair, this is all being done through the specifics of the standard library implementation, rather then a language level cast. But the difference is subtle.
Python 3, which is "Python" in 2017, not Python 2. Python 2 is the old stuff. Still used, but Python 3 is the one that I believe *should* be used, and it is the one I used in the comparison above. $ python3 -c 'print("hi" &gt; 35)' Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: str() &gt; int()
Okay, that's fair.
Since dropping can (and often does) have non trivial side-effects that'd be a breaking change. It'd also make understanding code much more difficult.
Offtopic, but I wonder why Lua is in the most dreaded? I think its an excellent and simple language... is it just the nature of the code bases where it ends up being used or something?
That would break many side-effecting Drop impls.
It looks like a Japanese name and if that's the case, a "standard" American accent in a complete monotone will get you pretty close. Soo sah no oh (with no inflection anywhere)
What does the `micro` in a "micro Web framework" actually means?
You might not be a fan about this, but that doesn't change the reality 😉 The separation between *weak* / *strong* and *static* / *dynamic* is really senseful, because those are orthogonal concepts.
that it's an order of magnitude smaller than a "milli web framework" but an order of magnitude larger than a "nano web framework," would be my guess (sorry)
Good aspect!
You would need to special case RAII classes such as [LockResult](https://doc.rust-lang.org/std/sync/type.LockResult.html) which rely on the syntatic behaviour. It could be interesting for trivial `Drop` impls but that can come later without losing too much by doing the lifetime version first.
genuine question: so did python the language change from being weakly typed to strongly typed when it moved from v2 to v3?
You raise a good point. Thanks for the feedback.
The only principled definitions from the PLT literature I've read is: * Well-typed vs ill-typed (e.g. Rust vs C) * Untyped vs typed (e.g. Python vs Rust) I've yet to see a formal definition of what strong/weak typing means. People say C is weak and refer to examples that aren't well-typed. And then they say Javascript is weak and refer to examples that are well-typed but use implicit conversions. And nothing prevents you from doing the same shenanigans in supposedly "strong" languages like Python (i.e. redefine the number types with an overloaded plus operator with JS behaviour).
Somewhat related rejected RFC (with a useful comment thread): https://github.com/rust-lang/rfcs/pull/210
Tail calls should already be possible if you arrange for any nontrivial drops to happen before return explicitly.
You can use the MSVC toolchain. It requires the Visual C++ runtime, but that's probably present on any Windows machine.
There is no strict definition, but as opposed to a "full-fledged" web framework (think Django, Ruby on Rails, etc.), which provide you with things like ORM, micro frameworks usually focus on just basic abstractions on top of a HTTP library, like routing.
I'll open it up soon, but I want to get it feature complete first. I'll definitely want people's input on the API and the error reporting at that point though, and welcome help on polishing issues :)
There's nothing stopping you from building a shared-ownership version of futures just like that (and even making it compatible with futures-rs!). The goal of futures-rs is to have no overhead, which precludes all the heap allocation going on behind the scenes in your OCaml example. This does involve some compromises, and isn't meant to be the best solution for literally everything.
This is a peculiar nitpick. Box and Arc etc are always referred to as pointers (they're both "smart pointers", the former is a "pointer type for heap allocation" and latter a "reference-counting pointer", according to their docs) and that's how the data is being passed around.
Cool. Mentioned your comment in the article. Thx.
&gt; if I would be better off learning the fundamentals of CS and moving on to C before even considering Rust Hmmm... i just wrote a paragraph telling you to go for C to understand the fundamentals, then i remembered that stack and heap stuff is decently explained in the book. So don't be to afraid to just start reading. But in the grand scheme of things I do suggest you try and learn some core CS stuff chronologically. So that you at least have the passing knowledge of how we used tool A to build tool B. So just to give you the CS 101 course : &gt; We have a heap , a stack , we can point to memory , we can save pointers in memory. How do these basics allow us to do the fancy stuff like dynamic dispatch through [vtables](https://en.wikipedia.org/wiki/Virtual_method_table) P.S. &gt; The cool thing about [elm](http://elm-lang.org/) is it forces you to use result , option and map them with specific functions. Rust will let you pattern match yourself to death before you realize there is a function to map from A -&gt; B 
Seconded. I consider that cells, Rcs, and the other Deref types are references.
This is a new crate for automatic struct of array generation from a struct definition. Struct of array idea is to replace `Vec&lt;Foo&gt;` by FooVec with: struct Foo { x: f64, y: f64, z: f64, } struct FooVec { x: Vec&lt;f64&gt;, y: Vec&lt;f64&gt;, z: Vec&lt;f64&gt;, } This allow to minimize cache miss when working with such array in tight loop, and is a common technique for game programming. I am using it for my molecular simulation engine project, [lumol](lumol.org): molecular simulation and game engine are quite similar from the performance perspective. I got the inspiration to to this with a blog post six month ago: https://www.reddit.com/r/rust/comments/5lrb9y/soa_in_rust_with_macros_11/. I extended the code from there to support most of the standard library functions for `Vec&lt;T&gt;`. I am happy to get any feedback you have on this!
It probably isn't just you, but the post's title/use of "pointers" is 100% inline with how it is used elsewhere in Rust including official documentation. The unsafe pointers are rarer, and are often "raw pointers".
&gt; They sort in "alphabetical" order, by byte value. alphabetical or ascii order? it's not the same.
Presumably it is named for [Susanoo-no-Mikoto](https://en.wikipedia.org/wiki/Susanoo-no-Mikoto), Shinto god of the sea and storms, in which case you are correct.
**Susanoo-no-Mikoto** Susanoo (須佐之男 (スサノオ), romanized as Susano-o, Susa-no-O, Susano'o, and Susanowo), also known as Takehaya Susanoo-no-Mikoto (建速須佐之男命) and Kumano Ketsumiko no kami at Kumano shrine, is the Shinto god of the sea and storms. He is also considered to be ruler of Neno-Katasu-Kuni (now Yasugi, Shimane-ken). He is married to Kushinadahime. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
Neat!
Also to addition to msvc build you can build with `crt-static` https://users.rust-lang.org/t/statically-linking-to-crt-on-msvc/9755/2 not sure is this feature in beta/stable or only nightly.
This is not talking about the `array` primitive, it is talking about `Vec&lt;t&gt;`s.
Formally dynamically typed languages are unityped or untyped languages; all expression have the same type. Though really you can mix and match between this. A "type" in python within type theory is not a type and a 'tag' is not a formal idea. A tag just a property of a datum and occupies a place that is no more special than "is this number even?" or "is this number greater than 5". Now just like Rust functions can be _partial_ which I define as: 1. The function can panic on some of its input 2. The function can diverge on some of its input Essentially all functions in a dynamically typed language are partial; pass it input with the wrong """type""" and it panics but this is not the same as a type error in type theory. This is like an out of bounds index. This is further made more complex in python because it does not formally distinguish between errors and exceptional situations; it has an exception system yes but using it is oten intentional and by design in Rust _any_ panic signifies a mistake made by a programmer, your code should never panic but we cannot escape this possibility sadly. We could indeed design a type system where all functions are _total_ and thus never panic but such a language can never be Turing Complete. However just like we can delegate undefined behaviour to `unsafe` and mark functions which can lead to undefined behaviour on certain input in theory we could have a `partial` keyword for functions which are partial and keep "partial Rust" and "unsafe Rust" out of the main language because it turns out you can get really far with only total functions if you got a strong standard library for many use cases.
I love Rust as much as the next person but Rust's type inference is a far cry from proper Hindley-Milner. E.g. fn good(b: bool) -&gt; u8 { let v = Default::default(); if b { v } else { v.saturating_add(1) } } fn bad(b: bool) -&gt; u8 { let v = Default::default(); if !b { v.saturating_add(1) } else { v } } The first function compiles. The second, which has the exact same semantics and only inverted the boolean condition and swapped the if/else branches, does not compile because the compiler can't figure out the types.
Strength and weakness is rather relative; Rust also does a lot of implicit coersions in many cases. Really formally there are three things which are interesting: 1. Is the language unityped? Rust and C are not unityped. Python and Scheme are unityped 2. Is the language total? Rust, C and Python are partial, Agda is total 3. Does the language have undefined behaviour? C has undefined behaviour and with Rust it's a fine-print thing. Static versus dynamic typing isn't a formal distinction, unityped vs multi-type is. I think a lot of people would call a language which is duo-typed as in expressions can have one of two types which are enforced at compile type, say scalar and vectral values have a different type and all other """type checks""" are done at runtime dynamically typed but this language is not unityped.
*three orders
Looks good! I never really got around to fully implement this library. One thing never really liked is when types are generated behind your back. Some readers might get confused by the `ParticleVec` types. They might not know where the types are coming from. I sort of found a workaround for this in my [enumflags](https://github.com/MaikKlein/enumflags) crate. #[derive(EnumFlags, Copy, Clone, Debug)] #[repr(u8)] pub enum Test { A = 0b0001, B = 0b0010, C = 0b0100, D = 0b1000, } gives you the type `BitFlags&lt;Test&gt;` instead of something like `TestFlags`. So in your case you could have something like `SoA&lt;Particle&gt;`. But this is highly subjective and you probably should leave it as it is. I am not even sure if this is a good idea.
awesome, will look forward to that!
stronglyer typed. It's 2017, we have spectrums
I'm writing a serializer and I'm having troubles with lifetimes. The basic idea is that I have a struct that has a reference to the `[u8]` buffer I'm writing to, together with some extra data (in this example only the current write position). This is needed because each message is made of a "fixed" part and a variable length one. (In the example, I have 3 bytes as fixed fields, rest is variable). Let me show first the code (a shorter example just for this post): struct Data&lt;'a&gt; { buf: &amp;'a mut [u8], pos: usize, } impl&lt;'a&gt; Data&lt;'a&gt; { pub fn new(buf: &amp;'a mut [u8]) -&gt; Data&lt;'a&gt; { Data { buf: buf, pos: 0 } } } struct MainWriter&lt;'a&gt; { buf: &amp;'a mut Data&lt;'a&gt;, } struct VecWriter&lt;'a&gt; { buf: &amp;'a mut Data&lt;'a&gt;, curr: usize, count: usize, } impl&lt;'a&gt; MainWriter&lt;'a&gt; { pub fn new(buf: &amp;'a mut Data&lt;'a&gt;) -&gt; MainWriter&lt;'a&gt; { buf.pos += 3; // skip fixed fields MainWriter { buf: buf } } pub fn write_first(mut self, n: u8) -&gt; MainWriter&lt;'a&gt; { self.buf.buf[0] = n; self } pub fn write_second_and_third(mut self, a: u8, b: u8) -&gt; MainWriter&lt;'a&gt; { self.buf.buf[1] = a; self.buf.buf[2] = b; self } pub fn vectors(&amp;'a mut self, count: usize) -&gt; VecWriter&lt;'a&gt; { VecWriter::new(&amp;mut self.buf, count) } } impl&lt;'a&gt; VecWriter&lt;'a&gt; { pub fn new(buf: &amp;'a mut Data&lt;'a&gt;, count: usize) -&gt; VecWriter&lt;'a&gt; { VecWriter { buf: buf, count: count, curr: 0, } } pub fn next(&amp;mut self) -&gt; &amp;mut VecWriter&lt;'a&gt; { self.curr += 1; self } pub fn write(&amp;mut self, v: Vec&lt;u8&gt;) -&gt; &amp;mut VecWriter&lt;'a&gt; { if self.curr &gt; self.count { panic!("out of bounds") } { let mut dst = &amp;mut self.buf.buf[self.buf.pos..]; dst[0] = v.len() as u8; dst[1..1 + v.len()].copy_from_slice(&amp;v); self.buf.pos += 1 + v.len(); } self } } fn main() { let mut buf = [0u8; 256]; { let mut data = Data::new(&amp;mut buf); let mut writer = MainWriter::new(&amp;mut data) .write_first(123) .write_second_and_third(45, 67); { let mut vecs = writer.vectors(3); // let mut vecs = VecWriter::new(&amp;mut data, 3); vecs.next().write(vec![1, 2, 3]); vecs.next().write(vec![0, 9]); vecs.next().write(vec![1, 2, 3, 4, 5, 7]); } } println!("{:?}", &amp;buf[..32]); } The idea is that I can borrow the buffer while I need to write the vectors (using a sub serializer, in this example it's only 1 level deep, but I will need to be able to go arbitrarily deep), when I'm done with the vectors serializer I can use `writer` again. The error I get is: error[E0597]: `writer` does not live long enough --&gt; src/main.rs:89:5 | 83 | let mut vecs = writer.vectors(3); | ------ borrow occurs here ... 89 | } | ^ `writer` dropped here while still borrowed | = note: values in a scope are dropped in the opposite order they are created error: aborting due to previous error which surprises me because I thought by putting `vecs` in a nested context the buffer would be unborrowed at the end of the context. * What I am doing wrong? I'm clearly missing something about lifetimes and borrowing * Is it possible to have the API i have in mind? Or i need to change something to accommodate the borrow checker?
&gt; Yes, really. You cannot infer types for an arbitrary program in a dynamic language. This means that you cannot prove the type of an arbitrary variable in such a language, which you can do in typed languages. I mean in theory you could create a dynamically typd language where you could but just don't and plaster a tag over it and only do it at runtime and assign every _expression_ a type like in a static language but only panic at runtime when said expressoin gets computed Extremely wasteful and useless of course but not theoretically impossible to get the worst of both worlds in fact I think GHC has a mode where it does this for prototyping where it disables the typechecke but endows every thunk with a typeid of the type it should deliver and when it doesn't raises an exception.
No, they're absolutely not in the formal context of type theory. dynamic "types" have _nothing_ to do with a type in type theory and whoever decided to call it types instead of tags just spread misinformation and misconceptions. A type in type theory is a formal rigorous mathematical concept and "dynamic types" have nothing to do with it. Python indeed has a "type system", every expression grammar has a type system, Python's type system is unityped which means that all expressions have the same type which is another way of saying untyped and that they don't have a type. "types" in Python are as unremarkable and unspecial as "exceptions" (Option, Result) in Rust; there is nothing that makes them formally different from ordinary values. The "type" of a value in Python is just a property of a datum which is not anything more special then: - does this string start with an uppercase character? - does this string have a length longer than 4 - was this object created at least 2 hours ago? - is the memory address of this object smaller than 10? And just as in Rust you can check for such things and decide to panic if they don't hold some-how you can elect to raise a `TypeError`in Python if those conditions don't hold where "raising a typeerror" is also not formally different than "raising 5".
&gt; The Rust compiler is eager. It's reading the code top to bottom, and `.saturating_add` forces it to decide whether it has enough information or not right then. Yes, to my understanding this eagerness makes it non-HM. &gt; you know, you and I have actually had this argument many times here. I too wonder why you have to keep repeating that Rust has HM type inference while it does not. :p &gt; Who would use `Default::default()` for an integer value anyways? Minimal examples are rarely very realistic. &gt; But, regardless, it is an extended Hindley-Milner type inference engine, from my reading of that. It's not implementing the Hindley-Milner algorithm precisely, because it has at least one extension. The document you link to itself claims that the inference is merely 'loosely based' on HM. Perhaps the extension is to blame, but swapping if/else branches should not affect the outcome of real HM type inference as I understand it. Regardless of the causes, I think it is incorrect to refer to Rust's type inference as being HM, although I won't disagree that it shares some of its qualities. &gt; It's still not something worth getting upset over. What makes you think I'm upset? A bit disappointed perhaps. &gt; It would be nice if they made the inference engine lazier, but that could have negative effects on compile time and other issues. Ah yes, the unquantified "negative effects on compile time and other issues". I remain unconvinced. Given that the current algorithm almost always succeeds with type inference, I imagine fixing the flow sensitivity could be as simple as using the current implementation in all cases except when type inference fails, and only then fall back to something slightly more creative. That shouldn't affect compile times of existing programs. But I suppose neither of us is going to convince the other, so I'll leave it at this. I'll crawl back under my rock until I hear you publicly proclaiming the virtues of Rusts "HM" type inference again in a few months :-p 
HTTP POST to a single endpoint, no authentication required. The packets can be quite substantial, but as the cluster is generally not under my control, on timeout I'd like to overflow the messages into a log file, that will be picked up and resent to the ES cluster, once connection is reestablished. 
I looked at Tokio, seems like an interesting (reactive?) way of writing. Maybe a bit over my head at the moment. 
He was asking about a higher framerate video because the gif you linked to is very choppy.
Sorry I don't have the time for a full explanation, but the gist is that you have references like `&amp;'a mut Data&lt;'a&gt;`, which indicate the borrows last as long as the data, and this causes the borrows to be extended past where you expect. You can use a second lifetime parameter on your structs to say that the lifetime of borrow can be separate from the data itself, yielding `&amp;'b mut Data&lt;'a&gt;`, and use this second lifetime when calling `vectors`. This might not be the most optimal way to express the solution, but it runs: https://is.gd/ogc6uC
That sounds a lot like what I would like. A shame that it was turned down in favour of different dynamic drop semantics. Once this is implemented though, I wouldn't be surprised if someone tries to bring back static drop semantics. And shouldn't Drop implementations be limited to just doing what's necessary to clean up the data structure? Things like closing resources or letting the OS know that you're done with something? [EDIT] It seems there was another proposal for eager drops which looks interesting.
Is there a `try!` or `?` equivalent for `Option&lt;T&gt;`?
[It's coming](https://github.com/rust-lang/rust/issues/31436). There's [a PR](https://github.com/rust-lang/rust/pull/42526) already.
let r,g,b,a=get_color() is safer and nicer than accessing by index
&gt; With PyPy, for instance, Python code can be compiled into optimal machine code at run time though a JIT. Does it still not have a type system What does that have to do with type systems? &gt; Or even with Shed Skin, you can compile Python code to C++. C++ has a type system, so how is this possible? ...why would it not be possible? You can compile _any_ language that is functionally equivalent to any other language. C++ to Python, Python to Javascript and either to machine code which is the usual target language of compilation and bereft of a type system. A programming language without an implementation can have a type system if it's purely a specification that no one has implemented; in fact a programming language without any operational semantics of which no one ever bothered to specify exactly what it should do but just what the type rules of the expressions are can have a type system. A simple rudimentary set theory language has a type system. &gt; Is code running on a bytecode VM untyped because it isn't running on machine code? Why is machine code special? Considering machine code definitely does not assign types to values, each instruction interprets data as a particular set of types, but values themselves are meaningless. Type theory does not apply to assembly to begin with because assembly has no concept of _expressions_. You can device a Turing complete mechanism that is devoid of expressions and the Universal Turing Machine itself is a good example of that. In order to speak of a type system you need some kind of expression-based language however. &gt; We could coin the term "real time monomorphisation" if we wanted to sound fancy. Each time a function is called, a monomorphic instantiation of that function is created for arguments of the types provided. Does it matter that it doesn't happen in a distinct compilation phase? Python has no monomorphization, monomorphization is also not a property of a language; it is an implementations strategy. Rustc could elect not to perform monomorphization while retaining identical semantics; it just performs it because it's more efficient to in how Rust does it. CPython doesn't. GHC also typically does not perform monomorphization because all values are boxed in which case it makes less sense to monomorphize. &gt; Python is not TCL, where everything is a single type: string. Python has actual types. I'm sorry but have you _ever_ ready any literature regarding type theory? Do you know the formal definition of types and terms in type theory? "string" in python is not a "type", it's a _tag_ and this is not a formal thing at all. 
Just a fun historical fact. Rust didn't have arrays before, instead only vectors and tuples. There was a proposal to add arrays [but making them more like tuples than vecs](http://smallcultfollowing.com/babysteps/blog/2012/05/14/vectors/). &gt; The type `(T * N)` represents a fixed-length array. Here `T` is another type and `N` is a constant expression. This is primarily intended for `C` compatibility: a fixed-length array has no length field and is simply represented by `N` instances of the type `T` laid out one after the other. In most ways it is precisely equivalent to a tuple. There is no literal form for such arrays: they are in fact supertypes of tuples of equivalent size, and so share the tuple syntax `(v1, ..., vN)`. We can introduce a macro for repeating the same element `N` times to avoid repetition. &gt; ... &gt; Note: I think this idea of having fixed-length arrays and tuples be closely related makes sense. I’m mostly trying to keep things simple and not introduce too much machinery for an edge case. But maybe there is a problem with it. Personally I would like for there to be a universal way of declaring sets of things, without making a special case separating when all elements are of the same type. Still this would have broken C's conventions and that might not have been the best decision for Rust.
very interesting (although it is also slightly worrying that increasing numbers of ideas that I like were lost in earlier states of rust...) Imagine if they deferred the decision on this, e.g. releasing 1.0 with a macro ```array![..]``` &gt; Still this would have broken C's conventions speaking as a C/C++ person.. we all know C's inbuilt arrays are terribly broken . We do look in envy at how other languages made much better use of the [] chars in declarations. Now I realise an inbuilt [T;N] or (T*N) whatever its called might have been deemed an important workaround for the lack of 'N' in type-params (which is why they couldn't just do Array&lt;T,N&gt;), hence the special treatment.
I guess that means that Rust is the best language because it's statically typed. Nope, there was never any language before it the have static types. Nuh uh; no sire. \s
&gt; You didn't actually provide any explanation for why Python does not have a proper type system I didn't use the term "proper", I said python is unityped. Python is unityped because every term in python accepts the top type; that's the definition of a unityped language in type theory. If you believe that this is not the case in python; then show me a single counter example where the expression grammar of Python not in an expression consume the top type. &gt; I have not spent my time reading papers on type theory, no, but I have read a lot of the more common literature, such as you would encounter while learning and using Haskell, as well as Wikipedia, and some of the excitement around Idris. I'm not completely uneducated about type systems, I'm making the point that your argument seems empty. Okay, let's play it simple then, in your own words formally define what a _type_ is. &gt; On what grounds does Python not have a full type system, but rather is unityped/untyped? You are referring to an implementation detail, aren't you? yet that's what you just spent paragraphs railing against. No, it's irrelevant what the implementation is; the semantics of python simply say that every term consumes the top type which makes it unityped.
Aren't it's rvalues strong? As in they require explicit casts. But it's lvalues (the variable bindings) are weak? As in they will take on the type of whatever gets assigned to them at runtime. In C it's almost the opposite. Strong static lvalues but rvalues are static but weak. Meaning the type contract with code is static but data at runtime is dynamically interpreted by whatever type coercion was established prior for a code block.
Quick question: which is generally more performant? Mutexes or Channels?
Definitely agree that something like `Soa&lt;Foo&gt;` would be a little clearer to follow, but I suspect that's not really possible at present. Presumably, you need some way of indexing the individual sequences, but I don't see how you'd do that through a trait.
As long as you accept "no" with grace and without arguing, that's fine.
&gt; listening to incoming UDP packets &gt; accepting only local connections (from PHP in this case), Why not use some local IPC system like Unix domain sockets or pipes? Does PHP have no bindings for those? Using UDP for this means you will have to involve the network stack, which adds a lot of overhead - that makes no sense unless the service can benefit from network transparency, at least potentially.
Seems like an Iron clone but on hyper+tokio. Iron's migration to async hyper is slow and it's good to see alternative with similar design. 
&gt; from wikipedia. Python types meet those criteria. And every operation in Python is legal on every type thus the language is unityped; every expession consumes the top type. &gt; Can you provide in Rust a counterexample like you're asking for? Absolutely. A simple example in Rust would be: 4 + "string" Which is syntactic sugar for: std::ops::Add::add(4, "string") The type signature of `std::ops::Add::add` is `forall X,Y (X, Y) where X : Add&lt;Rhs = Y&gt;` since `i32 : Add&lt;Rhs = &amp;'static str&gt;` is not satisfied the entire expression is a type violation. This is entirely different from in Python: 4 + "string" This type checks as there is only one type and it has a defined result which is raising an exception containing the datum that may be constructed in Python with: `TypeError("unsupported operand type(s) for +: 'int' and 'str'")`. It would be nonconformance for any Python implementation to reject the following program: def do_you_like_being_added_to_a_number ( x ): try: 4 + x return true except TypeError: return false Or a function which decides whether something likes being added to a number. However any conforming Rust implementation _must_ reject the following function: fn do_you_like_being_added_to_a_number&lt;T&gt; ( x : T ) -&gt; bool { panic::catch_unwind(|| 4 + x).is_ok() } It just isn't valid Rust, it doesn't type check. THe type checker refuses `4 + x` here because the type of `x` here is `forall T. T` which it can't satisfy with `Add`s trait bounds. It doesn't "panic" at runtime when you try to do this it doesn't return a Result whether or not it considered the addition sensible; it just won't have any of it; it's rejected by the type checker.
It should be stable in Rust 1.19. https://github.com/rust-lang/rust/issues/37406
Could it be implemented for all types that don't manually implement the drop trait? Also nice username. Big fan of the series. 
This is perfect for a Unix Domain Socket using Datagrams.
Functional given imperative: `x.clone().update(d)` Imperative given functional: sometimes something along the lines of `*x = update(x, d)`, but you generally can’t truly do it. I feel that a lot of the reason why a functional approach can be good is poor ownership semantics; I tend to feel that Rust’s type system substantially undermines the *need* for a functional approach. Generally I’d say that imperative is better, because it is normally the more efficient approach. But there’s certainly still a place for the functional approach sometimes. I say, assess how you will need it and how you will use it on a case-by-case basis.
&gt; Both Rust and Python have a limited set of operations that can be performed on a given type. However, Rust is a statically typed language. It provides these errors at an arbitrary point in time known as "compile time". Python, being dynamically typed, provides these errors at a different arbitrary point in time known as "run time". From a mathematical point of view, as you're so fond of talking about, there is no distinction between these two. They're both arbitrary points in time. But it's not limited in Python. There is nothing particularly formally unusual about "raising an exception". `4 + "string"` in python is a fully applicable defined operation with a defined operation. It is neither a type error nor undefined behaviour, it is completely defined and it raises an exception. And even if it were an _error_ some-how either by it being undefined behaviour or Python differntiating between panics and exceptions it still wouldn't be a type error. &gt; When I speak of a "proper" type system, I mean one that is not unityped. I believe that under the strictest definition, Python may be categorized as unityped, but it's easy to make an exception for TypeError and say that it is not part of the language's normal type system, but rather it is a tool for a form of metaprogramming at runtime in a dynamically typed language, where the TypeError type only exists as part of except TypeError as err: blocks, which are used to manipulate the runtime flow of the rest of the program in a metaprogramming-esque capacity. But it is part of the language. I can just put `raise TypeError` wherever I want and the `TypeError` class isn't special in any any way. Would you say that the python script: #!/usr/bin/env python3 raise TypeError Doesn't type check some-how? What about this function: def raise_a_value_in_global ( s ): assert(isintance(s, str)) raise globals()[s] Would you say it is a TypeError if you feed it exactly the string `"TypeError"` but not on any other string and if you feed it 3 it then becomes a type error because of assert though it raises the same thing? &gt; In a macro in Rust, you have ident and expr and other types which exist only as part of a separate type system: they are not types in the conventional type system Rust presents, and they can only be used in a specific context. TypeError can be treated the same way, thus providing Python with a non-unityped type system. A "proper" type system, if you will. They are actually not types as well type-theoretically; they're grammar elements. Essentially in Rust `Vec![1]` and `[1,4,5].into_vec()` both have the type `Vec&lt;isize&gt;` but entirely different grammar element; one is a macro invocation and the other a method call. Likewise a struct instantiation like `Foo { x : 4}` and a function call `Foo::new()` may very well have the exact same type but are very much different grammar elements.
Checkmate, Jai!
I'm still just trying out different projects to get a better feel for Rust. Hopefully by the end of this week I'll be able to start on something larger in size (probably a game). This week I wrote an [immutable binary search tree](https://github.com/keeslinp/immut_bst). I think I'm gonna start on a space invaders clone or something on that scale soon. Edit: Also can I just note, Clippy is really awesome. It's been teaching me some great things :).
&gt; And shouldn't Drop implementations be limited to just doing what's necessary to clean up the data structure? Things like closing resources or letting the OS know that you're done with something? It's a common pattern in C++ to have "scope guards", which are values whose destructor is used to perform some deferred computation. Things like a mutex: { let _lock = mutex.lock(); // Use variables that aren't directly protected by the mutex, // but still need to be accessed in a synchronized way } // _lock must be dropped here, and no earlier or a timer: { let _timer = Timer::start(); // do stuff } // _timer must be dropped here to accurately measure execution time
Generally it means it only provides the bare bones. Usually it just includes: * An easy to use API to read http requests and return responses. * A way to map paths/routes to handlers. On the other end of the spectrum you have your full fledged Enterprise level frameworks like Rails, Spring, Django, Symfony, which come with a ton more stuff: * Templating * dependency injection container * database ORM * event and listeners system * security/authentication tools.
You could have: pub trait StructOfArray { type SOA; } where #[derive(Debug, Clone, Copy, Default, StructOfArray)] #[soa_derive = "Debug, Clone, Copy, Default"] struct Test { ... } implements `StructOfArray` like this: impl StructOfArray for Test { type SOA = TestVec; } then have `SoA` be a type alias like this: pub type SoA&lt;T&gt; = &lt;T as StructOfArray&gt;::SOA; then you can do: let my_test_vec = SoA&lt;Test&gt;::default(); EDIT: SOA, not Sword Art Online
Hmm... kinda ugly, but I guess that works.
Might be worth cross-posting this to /r/love2d.
Do we actually need Qt bindings? If idiomatic rust does not play well with Qt's design philosophy, then maybe it isn't worth trying to fit a square peg into a round hole. I'm definitely excited to see how it turns out regardless.
For the mutex example, I feel that if the compiler could keep track of uses, that it would retain the lock for as long as you're using it and unlock it right when you stop using it rather than holding on to the mutex longer than necessary. Part of why I'm suggesting this is because mutexes shouldn't need a new scope in order to work properly. For the timer, I feel it would be best to explicitly indicate when you want it to finish, or to have what you want timed passed in as a closure. I'd much prefer writing this: timer::benchmark(|| for i in (0..100) { function_to_be_benchmarked(i) } ) The way you specified it feels like too much is happening behind the scenes. Also, how do you get the value if the timer only stops when it's dropped? In your version, it seems like there should be a `_timer.get_time()` which would keep the timer alive in this case. I checked for a timer module/crate and I found one that's used for scheduling, but it still feels like the wrong use for Drop. The number of braces you wrap something in shouldn't change the time that critical code fires.
It seems that it does have bindings for those: http://php.net/manual/en/transports.unix.php Are we talking about this? https://doc.rust-lang.org/std/os/unix/net/struct.UnixListener.html
Given that Qt applications are the only things which feel 100% native in a KDE desktop, I don't like the direction GNOME 3 is dragging GTK+, and I don't use web UIs unless they're *actually* suited to the task at hand (eg. hypertext), I certainly need them. (Plus, Qt is the most advanced and best documented open-source toolkit by a large margin. Now that I have experience with PyQt, I won't go back to reinventing wheels like persisted panel/toolbar customization in PyGTK/PyGI.) My current approach to writing GUI apps is to use rust-cpython and PyQt to bridge the gap, at the expense of reducing Rust's effectiveness as a way to ensure correctness at compile time.
Yes, if you're using the standard library's `Mutex` type. Not if you're using one for other synchronization that doesn't contain itself to a single value.
You have inner mutability though, which is much less of an antipattern than Haskell's `unsafePerformIO`.
&gt; In here how much copying is going on ? Your assessment is correct. &gt; So only those three peices of data are copied and returned ? The actual elements are not copied ? Correct, the actual elements are stored on the heap. It should be noted that the copy may be elided by the LLVM during optimizations.
Could you elaborate on that and /or show an example? Do you mean it could be as easily misused as inheritance would be misused in rust or that it can be misused for inheritance? I tend to the first from what I read in this post but your next, mention Qt, got me a little confused. 
Performance, from fastest to least fastest, would be Atomics, RwLocks, Mutexes, and Channels.
maybe i should stop now but imagine if array indexing on (A,B,C) yielded an enum Either3&lt;A,B,C&gt;{t0(&amp;A),t1(&amp;B),t2(&amp;C)} .. and reduce that for all the permutations, e.g. (A,A,B)[i] -&gt; Either&lt;A,B&gt; ..
Yes, I made this crate: https://crates.io/crates/closet You can do #[macro_use] extern crate closet; let callback_count = Rc::new(Cell::new(0)); obsv_int.set_callback(clone_army!( [callback_count] move || callback_count.set(callback_count.get() + 1))); assert_eq!(callback_count.get(), 0); It's actually a very simple macro because you don't have to modify the closure at all. macro_rules! clone_army { ([$($var:ident),*] $cl:expr) =&gt; {{ $(let $var = $var.clone();)* $cl }}; } 
Thanks. So, by default the Move trait is called when you return something ? Which under the hood is a bitwise copy ? And as you said the compiler might optimise the copy away so the only place where new memory is created is the function return stack space, and heap allocation ?
I'm not aware of any "Move trait". Move semantics are used to transfer ownership and a function returning a value is simply transferring ownership of the returned value to the caller. The fact that the move itself is implemented as a bitwise copy isn't important to the semantics. Moves also aren't limited to returning values from a function: let x = "foo".to_string(); let y = x; Here the value of x is being moved into y, meaning ownership has been transferred. As to what is and is not elided, I can't really say anything definitive as it's all up to the LLVM and the heuristics it uses.
Your crate doesn't have any documentation / code examples though. You should fix that.
Thanks !
Got it now, thanks!
Ah, thanks. Creating a block *inside* the parentheses and then returning the closure as the last statement in the block - neat. While I still would love it if this were part of the language, a macro seems like a decent workaround for now. And it's great to know I'm not the only one who wanted this pattern :)
It's impossible to say in isolation: they've got completely different APIs, and so it depends entirely on what you're doing. For instance, it is possible to use mutexes to create a channel, but this will be slower than using the "true" channels, and it's also possible to use channels to create a mutex, and that will also be slower than a true mutex.
Seems this pattern pops up in a few places: I've stumbled onto [this slight variant](https://github.com/koute/stdweb/blob/76f6ca9474be6d02b7277984fed8f7f00b65cac3/examples/todomvc/src/main.rs#L37-L44) using parens instead of square brackets.
I believe that on many platforms rwlocks have significantly higher overhead than mutexes, so one has to be really benefiting from the increased parallelism, with a relatively long-running critical section, before they're a win. See, for instance, [this table](https://www.arangodb.com/2015/02/comparing-atomic-mutex-rwlocks/) where rows #1 and #3 are mutex vs a rwlock used "properly": even for the read-heavy workload there, the rwlock is a little slower than the mutex on Linux but much faster on the other two platforms. However, additionally, at least on Windows, using a rwlock as a mutex (i.e. only acquiring write critical sections), in row #2, is faster than using it as a rwlock. Additionally, focusing on the cost of an individual operation can be misleading: especially for atomics, one often needs to string together multiple to actually achieve something useful.
Until the PR lands, one can always use the combinator functions (`map`, `unwrap_or`(`_else`), `map_or`, etc.) Or `if let`.
Continuing parser work for my toy language/calculator [stalc](https://github.com/passcod/stalc), using [nom](https://github.com/Geal/nom). Also evaluating some game engines for a little game I've been drafting.
Just go with general anonymous sum types and it’s `A | B | C` and `A | B`. Expressing such an `Index` implementation… you’d need a concatenative approach to expressing tuple types, but once you had it it’d merely be crazy foolishness of at best dubious performance, rather than impossible.
Yes, this look nicer ! I am not sure how you could you access the fields of the SoA vector with this: we need direct access to get all the niceties of SoA (only loading part of the struct in the cache), but I don't think we can do this with a trait. 
I'm a rust newbe, but as I tend to favour OOP, and when using an object, my go-to solution would be x.update (d) unless any other way would obviously be more consisent. Consistency matters; users of your library won't like your design if you make the wrong decision for your problem at hand, but at least they will learn to use your library faster.
[Google translate link](https://translate.google.com/#ja/en/%E3%82%B9%E3%82%B5%E3%83%8E%E3%82%AA)
You should be able to access the fields and methods on it. All it's doing is throwing TestVec into an associated type and then looking it up with a type alias. It's still the same TestVec type. It's not wrapped in anything, so it should be the exact same as if you used TestVec by name. 
For most Rust RAII types that's correct. However there is at least one where this is not true. I don't remember what it is offhand, but just last week I read some code where I noticed this.
"2". It is implemented, not sure why the platform tier page is not updated.
What is the idiomatic way to save the result while running a parallel iterator? I would like to avoid collecting all and save as it may take a little bit too much memory and the result may lost if the program is killed half way. Currently I am using something like this: use std::sync::mpsc::channel; use parking_lot::Mutex; use rayon::prelude::*; pub trait MutExt: ParallelIterator { fn for_each_async&lt;F&gt;(self, func: F) where F: FnMut(Self::Item) + Send, { let (tx, rx) = channel(); let bundle = Mutex::new((rx, func)); self.for_each_with(tx, |tx, item| match bundle.try_lock() { None =&gt; tx.send(item).expect("rx should not be dropped"), Some(mut guard) =&gt; { let (ref mut rx, ref mut func) = *guard; func(item); for item in rx.try_iter() { func(item) } } }); let (rx, mut func) = bundle.into_inner(); for item in rx.iter() { func(item) } } } impl&lt;T: ParallelIterator&gt; MutExt for T {} and in the main program let mut wtr = File::create("foo.txt")?; let mut pb = ProgressBar::new(setting_vec.len() as u64); setting_vec .into_par_iter() .map(|setting| { expensive_function(setting) }) .for_each_async(|result| { write!(wtr, "{}", result).unwrap(); pb.inc(); }); 
You can add methods to the trait `StructOfArray` and then you implement `Deref`. But not for T, but for T::Type. Something like this should work. struct Soa&lt;T: StructOfArray&gt;{ inner: T::Type } impl&lt;T&gt; Deref for Soa&lt;T&gt; where T: StructOfArray{ type Target = T::Type; fn deref(&amp;self) -&gt; &amp;Self::Target{ &amp;self.inner } } You can also have a look at https://github.com/MaikKlein/enumflags/blob/master/src/lib.rs#L28. But it is still a bit hacky.
Statically linking with bionic is not going to work I'm quite sure. For binary size: https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html 
 struct S&lt;T&gt;(T); The above type does not have a manual `Drop` implementation. But what would happen when we put a type that manually implements `Drop` in `S`? When does `S` get dropped?
Is it possible to know the name of a field of a struct at runtime? My use case is that I'm writing validation for some data and every function I need to pass both the data and the name of it so I can create an error message about the field which is failing. 
And that's why I should not post before my morning coffee ... Yes, it could work. I'll give it a look, and maybe change the API for a v0.2 !
For what it's worth this is why specification of properly defined typing rules and semantics is useful. If python spec said that 1 + "a" is actually not accepted, not just a by-product of it's implementation detail, your argument would be correct. But many things in most languages are simply the by-product of their implementation and even expose some details of the implementation language.
Depends on the type of x. If it's something small, like a u32, it doesn't matter. If it's large, imperative is more efficient. The advantage of functional is that in case the object could be invalidated, you can write fn update(self, ...) -&gt; Option&lt;Self&gt;. Some crates still don't do it for performance || ergonomics.
&gt; So, by default the Move trait is called when you return something ? FWIW there is no invocation of anything special in either "move" (default) or "copy" (opted in via the Copy trait) case, these are *markers* used for static checking[0]. At runtime, both are just a bitwise copy, possibly RVO'd[1] or copy-elided. [0] well there's the drop flag but we'll ignore that here [1] the caller allocates room for the return value, and rather than build the return value on the stack and copy it to the allocation afterwards the callee can just use the preallocated room as scratch space directly
FWIW the relevant concept here is called "copy elision" (most of the literature will be C++). A related but not identical concept is Return-Value Optimisation.
CTFE would be most excellent.
Most of the relevant stuff is in the `gfx` crate. You should look at the examples on GitHub. The main relevant thing you need to get out of the window is a factory. You can load your texture with the `image` crate. Rendering it is pretty involved, so you're better off reading the example code. 
No, these days Rust binaries do not depend on libgcc dll.
I am having trouble writing a function that returns a generic type bound by a trait. use std::iter::Iterator; fn test&lt;T, I&gt;(vector: Vec&lt;T&gt;) -&gt; I where I: Iterator&lt;Item = T&gt;, { vector.into_iter().map(|s| s) } fn main() { test(vec!["testing", "one"]); } I get: error[E0308]: mismatched types --&gt; src/main.rs:7:5 | 7 | vector.into_iter().map(|s| s) | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected type parameter, found struct `std::iter::Map` | = note: expected type `I` found type `std::iter::Map&lt;std::vec::IntoIter&lt;T&gt;, [closure@src/main.rs:7:28: 7:33]&gt;` The code can be found at the playground: https://play.integer32.com/?gist=170d70354903e46cf1f854dc77691de1&amp;version=stable Is this even possible? Or do I have to return `Box&lt;Iterator&lt;Item = T&gt;` instead?
You appear to be taking a pointer to stack data and storing it; *i.e.* line 115. If you don't understand why that's a problem, you might want to learn more about memory management *before* attempting to bind a C library. **Edit**: The [Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/objects/) might be useful.
No, I think you need to build the tests in order to run them. If you only want to compile the tests you can run `cargo check --tests`, I believe this will give a lot of spurious dead code warnings though.
Choice quote: &gt; I think I'm going to push forward with learning Rust, technically it looks sound (so far) and I have no issues with it, I don't plan on engaging with the official Rust community.
What's the point of posting it here? voat being a cess-pool of people that can't write a sentence without including an insult and the same happening when they talk about Rust has not a lot of news content. It isn't even a hot discussion, you're pointing to 4 people having a round of bile and someone mistaking the language and the game. The OP isn't even citing an actual actionable issue, except their very basic disgust for communities that have rules, which isn't anything you can interact with.
I think we should be aware that there are people with strong negative reaction to our community, and that it can hurt Rust. I am not suggesting we change our community norm (no way), I think benefit greatly outweighs cost, but I think we should be aware of cost.
We already know that. We also know that there's a very positive reaction to our community in general. That's inherent in having a community.
Mutable references inside of other types are always tricky; transitive mutable references are nothing short of mind-boggling. Perhaps a better way is using move semantics for your writer types: Have them own a `Data` value outright and move it when switching types: struct MainWriter&lt;'a&gt; { data: Data&lt;'a&gt; } struct VecWriter&lt;'a&gt; { data: Data&lt;'a&gt;, curr: usize, count: usize, } impl&lt;'a&gt; MainWriter&lt;'a&gt; { pub fn vectors(self, count: usize) -&gt; VecWriter&lt;'a&gt; { VecWriter::new(self.data, count) } } The drawback is that you have to switch back to `MainWriter` at the end of `VecWriter` if you want to keep using the data: impl&lt;'a&gt; VecWriter&lt;'a&gt; { pub fn done(self) -&gt; MainWriter&lt;'a&gt; { MainWriter::new(self.data) } } This also is the first step of making your serializer generic. If you make `Data` a trait, you can have all your writer types generic over that trait instead of just a lifetime.
Not everybody. (After all, &gt;20 people subscribe to /r/rust every day.)
Am i right in saying that the idiomatic way to make this work in current Rust is to put the pointed-to data (here, the NLoptMinimizer) in a Box, so that it never moves, even as its ownership is passed around? I read recently about a possible future opt-out marker trait for moveability, which presumably would allow the author of NLoptMinimizer here to ensure that it is always used safely.
Sure, but there's already enough of this talk happening on this subreddit, and in a much more complex fashion. Cross-posting these kinds of discussions just adds noise. I'll leave it at that.
placement allocation, some way to handle allocation failure..
Well, *some* kind of heap allocation. And a non-movable marker probably won't help much since this isn't a problem of using the type, but of defining it correctly in the first place.
Oh. That is quite obvious in hindsight. It also explains why my tests worked inside the constructor, where I'm still in the scope where min is valid. Thank you. So the correct thing to to would be to use a Box (which allocates on the heap, equivalent to malloc() in C?), yes?
Well, I don't know what the library does or expects, but... *probably?*
To be more exact, for now they discuss only Julia.
I suspect the overhead isn't as high as you might think. But i agree that this is a nice opportunity to use unix domain sockets. As well as a possible efficiency advantage, unix domain sockets have a security advantage, as there is no (well, less) need to verify the identity of the sender.
If by "discuss" you mean "note the existence of". They're talking more about Julia and Nim.
It boggles the mind why Voat has such a bad reputation
That's an extremely charitable choice of quote
Can you provide any references for your first claim?
Your code lets the *caller* select which `Iterator` instance to receive. Since you can only return a specific one, it will fail. Returning `Box&lt;Iterator&gt;` it will work, as would specifying the full type (but that is not possible here since it involves a closure). There a nightly-only feature called `impl Trait`, which will enable returning the type unboxed without naming it. It will look like fn test&lt;T&gt;(vector: Vec&lt;T&gt;) -&gt; impl Iterator&lt;Item=T&gt; and will probably be stabilized soonish.
&gt; [Chlorotrifluoroethylene](https://en.wikipedia.org/wiki/Chlorotrifluoroethylene) (CTFE) is a chlorofluorocarbon with chemical formula CF2CClF. It is commonly used as a refrigerant in cryogenic applications. Yes. Yes. Excellent! :P For those that didn't know, CTFE, in the context of Rust, seems to be [Compile Time Function Evaluation](https://github.com/rust-lang/rfcs/issues/322). (Heh, just discovered that the Wikipedia article on Chlorotrifluoroethylene has a disambiguation link to [Compile time function execution](https://en.wikipedia.org/wiki/Compile_time_function_execution))
If i remember correctly . read_to_end will read until the socket is **closed**. Sending a 'packet'/'message' on a socket doesn't translate to the other end. For the receiver it is just a stream of bytes with variable delays ( that can be caused by a million different things ). 
&gt; I think we should be aware that there are people with strong negative reaction to our community I think most people in /r/rust in particular know there exists those who object to the idea that a community should promise to treat folks decently regardless of what they look like, who they date, where they're from, or whether they're a newbie or a pro. Most also know that such people constitute a minority; that their arguments are based in dishonest hypotheticals; and that they deliberately segregate themselves away in safe echo-chambers like voat to preserve unfounded beliefs about their perceived oppression. At this stage the majority of programming languages have codes of conduct. Rust gets singled because it was one of the first to have a code of a conduct, and because it's been _successful_. The only thing Rust can do to attract such people is be technically excellent, which is exactly what it's doing. All the things in the pipeline for the next two years will do more to attract such people than any sort of political discussion or outreach about rules or conduct ever will. Listening to the noise on Voat is a bit of a distraction.
&gt; If it's large, imperative is more efficient. If x is moved into update(), changed and returned, it's should be as efficient as an in place update (at least that is my understanding, please correct me if i'm wrong). Another advantage of this approach is that the type of x can be updated too to reflect the change.
I haven't used it, but I believe valgrind works on Rust programs too.
&gt; everyone loves it, but no one wants it The point I wanted to make was that number of people who respond are different, which makes comparison tricky because you aren't sampling from the same population. So it's not the case that 'everyone' loves it, but that a small number of people are very enthusiastic, while the rest of the people make no response. When you look at 'want', you are sampling a different population because most people would respond to the 'want' question (when only smalltalk users would respond to a smalltalk question). 
As good as it looks on Linux, GTK looks and feels incredibly alien on macOS and Windows. You'd struggle to develop a commercial product with GTK. Qt and libui do a much better job on those platforms. Arguably Qt is a poor fit, since it's quite a heavy-weight framework, with it's own collections APIs, threading primitives, and even Strings, and since it's a fully C++ framework, making it tricky to create bindings. Libui might have a bit more potential, since it's written in C, and uses native widgets on its three supported platforms: Windows, Linux and macOS.
Cool, thanks for posting. One note: `process::exit(1)` is probably a somewhat unsuitable way to handle errors in a library. It would probably be better to use `Result`.
IIRC the reason is that it would make using RAII to weird, but maybe those reasons aren't valid anymore.
Maybe this should be a goal for this year. I'd be interested into looking into this.
You probably want to have a single size, capacity, instead of N copies of that. Also, I would like the interface to look like `Vec&lt;Foo&gt;`, that is, `soa_vec_foo[3].z = 5;` and `soa_vec_foo[4].method()` should work. Otherwise you have to rewrite all your code when switching between `FooVec` and `Vec&lt;Foo&gt;` which prevents you from easily experimenting with the layout of this. If you cannot experiment without rewriting your whole program due to syntax changes, then you leave performance on the table, which kind of defeats the point of SoA / AoS. Ping me if you ever get to any of this, because I'd love to use it.
&gt; Yes. Yes. Excellent! You missed a perfect opportunity there for "Very cool!"
Very nice post. What is your motivation to use the actor model here? I'm a huge fan of Akka (Scala), mostly for FSM and (specially) for the ability to supervise other actors. I'm not sure how feasible is to have something like that in Rust, but it is a game changer when I need to implement a complex logic.
Correct! You don't need to wrap a Vec into a Box to make moves efficient. `Vec&lt;T&gt;` is already like a kind of box wrapping a pointer to heap-allocated data similar to `Box&lt;[T]&gt;`. But compared to such a Box, a Vec can grow and shrink. For fixed-size arrays it could make sense to use `Box&lt;[T]&gt;` or `Box&lt;[T; n]&gt;`. You'd save a capacity field and in the second case also save a size field because the size is known at compile-time. 
Thanks! I think I get it now. I didn't know the syntax to tell the compiler a lifetime outlives another one.
Seems like I've hit that barrier. I made a [small demo](https://github.com/Maplicant/purplerain), but I'm limited to ~1000 raindrops because I can't handle more at a reasonable framerate
I'd recommend to remove the API key from the source code immediately. edit: Apparently I can't properly write English today.
By removing I mean: * nuke the repo out of existence * set the repo up again without the API key in the code
I think revoking the API key is the safest bet here. Then it doesn't matter if the key ever was in the repo.
"1". Linking to anything else than default would require to compile your own rust std library that is linked to whatever you need. That may need patches if there is something missing or maybe different configuration for bionic libc everywhere libc is used. Note that rust standard library uses [libc crate](https://github.com/rust-lang/libc/tree/master/src) for binding to libc, so if it does not support bionic library in some way it would need to be patched too. From experience, I can tell that this path is very time consuming (I have only added aarch64 support to rust, and that was enough for me). "3". Rust uses [libc](https://github.com/rust-lang/libc) crate to abstract away platform-specific methods. I can find [calls to open64 and lseek64](https://github.com/rust-lang/libc/blob/472ffbb75fcbb771d59208641846db196295c021/src/unix/notbsd/mod.rs#L940) there and it looks like [low level calls to open file](https://github.com/rust-lang/rust/blob/6ccfe68076abc78392ab9e1d81b5c1a2123af657/src/libstd/sys/unix/fs.rs#L433) in rust standard libary [use these android functions](https://github.com/rust-lang/rust/blob/6ccfe68076abc78392ab9e1d81b5c1a2123af657/src/libstd/sys/unix/fs.rs#L28). "4". You can find if there is already a support for your call by searching [libc repository](https://github.com/rust-lang/libc/tree/master/src). Otherwise, rust static library is no different from c static library (if jemalloc is disabled), and it is linked in a similar way. Therefore, if a c library could link to a function, rust can do it too. There is a useful [rust-bundgen](https://github.com/servo/rust-bindgen) tool that can generate FFI bindings given some C headers. "5". No, std library does not handle that. But you can do whatever you may do in C (and avoid std lib for these specific cases). EDIT: Reddit likes to re-number my lists. I have not replied in order.
Oh yeah, the author would want to revoke the key anyway as it has been published for a while.
Unfortunately, it's been too long and I don't remember the specific examples in enough detail to reconstruct, but I meant the former. Variadic generics and classical inheritance are both language features where at least one popular non-Rust language uses them in a way that, if naively translated to Rust, would make for very un-idiomatic code, so significant care must be taken to counter that mistaken "I know this!" effect if the decision is made to implement them in Rust. Default argument values for functions are another such example. It'd be convenient to be able to write a function such as `split_camelcase(text, whitespace=Split)` where, most of the time, it's treated as a single-argument function, but relying on intuition built in other languages could easily result in novices ignoring the builder pattern in favour of functions with a ton of optional arguments. (Especially since simply deriving a builder requires another crate)
&gt; What is your motivation to use the actor model here? I'm really a novice when it comes to actors, but I absolutely love the fundamental concept. I'm used to queue-based microservices at work, and actors just made perfect sense when I learned about them. &gt; I'm not sure how feasible is to have something like that in Rust, but it is a game changer when I need to implement a complex logic. FSM is easy, and actually way better in rust I think, due to the ability to consume old states. I've already written FSM actors and they're awesome. Supervisors are harder. Specifically, what do you do with the failed message? If it's clone you can hold it until the message was successful. If it isn't, things get harder. Still, I have patterns in mind for this and it shouldn't be too hard.
https://stackoverflow.com/questions/9154388/does-untyped-also-mean-dynamically-typed-in-the-academic-cs-world A lot of those comments cite a bunch of sources that define what they mean with a type.
I thought that too few months ago. A simple way to find out is to write a test code and look at assembly. That's how I found it's not the case.
no, but it is working fine with [u8; 1024] slice. but not with vec![u8; 1024];
&gt; You probably want to have a single size, capacity, instead of N copies of that. I think this means working directly with pointers and unsafe code. It could be done in a later release if someone find the time to do it =) &gt; Also, I would like the interface to look like Vec&lt;Foo&gt;, that is, soa_vec_foo[3].z = 5; and soa_vec_foo[4].method() should work. This is not possible currently, because the Index trait is required to return a reference to the `Index::Output` type, and we can not create this reference with the SoA layout. It might become possible with HKT/ATC, where the lifetime become part of the output type, but without needing it to be a reference.
Hey hey, don't worry! That is a special API key I generated for use with this library much like the same way pafy did [here](https://github.com/mps-youtube/pafy/blob/develop/pafy/g.py#L24). No worries at all! :D
I had a pretty strong negative reaction when people were ACTUALLY discussing a piece of code that said enum Gender { Male, Female, } and were talking about how that's wrong or whatever. Have you people heard of modeling? Not every model is a perfect representation of reality...
&gt; some way to handle allocation failure.. You can already do this today by linking to a different allocator and calling it.
&gt; by default the Move trait is called when you return something ? There is no `Move` trait, moves are always a memcpy of the exact bits of the thing that's moving, and it's not changeable.
&gt; EDIT: Reddit likes to re-number my lists. I have not replied in order. Yeah that's markdown...
Thanks! This solves a lot of boilerplate for me.
&gt; Index::Output type, and we can not create this reference with the SoA layout. Can `Index::Output` just be a custom type with a pointer to the soa_vector and an index and that forwards method calls to `Foo` ? That way if the users implement getters and setters for the `Foo` elements, and only uses those, one would be able to switch to SoA without changing any code. There is also an RFC for defining fields in Traits that might be useful here to allow access to fields.
&gt; Not every model is a perfect representation of reality... While that's true, it's just as bad as saying struct 3dPoint { x: i32, y: i32, } That is, it's pretty trivially and demonstrably incorrect. It's also more complex than the right answer, which is one of type Gender = String; struct Gender(String); Actually, while that's the common best answer, Rust has a better answer: trait Gender { because it actually represents an open set.
This is neither constructive nor true. The main advantage of Jai is that you can switch the layout of a type inside an array of contiguous memory from AoS to SoA and vice-versa by changing a single line of code, that is, without changing any other line of code in your whole code-base. While this macro is neat and shows what's possible with Rust macros today, it doesn't come even close to Jai. In fact, whether you do this transformation by hand, or using a macro, is a drop in the bucket of changes that one must introduce inside a Rust crate to change the layout of a type. This makes this macro approach interesting to showcase "what's currently possible", but irrelevant in practice. 
AFAIK you don't publish API keys FULL STOP. What if someone abuses your key for malicious use? That comes back to bite YOU.
That's a strawman argument. struct 3dPoint { x: i32, y: i32, } this logic works never the other enum works over 99% of the time and in some cases might be an acceptable model in any case, that's not an issue that should be discussed on a bug tracker, that's not a technical issue someone's API design is their own problem
Also it would be cool if one could change the layout of inner types #[derive(SoA)] struct OuterType { #[AoS] xs: [f32; 3], // use AoS for this #[SoA] ys: [f64; 3], // use SoA for this #[bits] u: bool, // use SoA for this, but store the bools as bits }
It's because rust uses jemalloc. For debugging purposes, you can build with nightly rust and change the allocator. See https://stackoverflow.com/a/37215627.
&gt; Can Index::Output just be a custom type with a pointer to the soa_vector and an index and that forwards method calls to Foo ? No, because if `Index::Output = Foo`, then you need to return `&amp;'a Foo` from the [`Index::index()`](https://doc.rust-lang.org/std/ops/trait.Index.html#tymethod.index) function. This is a bit of a pain in the current system, I hope it is possible to improve it with coming changes. In the mean time, using SoA with a Rust crate needs a bit of work and adaptation of the code. This macro can help with part of the tedious code that one could write by hand, but we are still limited by what is possible with Rust.
Yes, this would be a nice improvement!
Alternatively to boxing the iterator, you can implement a little helper type that wraps `std::vec::IntoIter` and implements `Iterator` by running `map()` inside its `next()` function: https://play.integer32.com/?gist=170d70354903e46cf1f854dc77691de1&amp;version=undefined As a side note: `std::iter::Iterator` is in the [prelude](https://doc.rust-lang.org/std/prelude/index.html) and doesn't need to be `use`d.
*facepalm* of course, thanks for the correction :)
Neither. By byte value. ASCII only goes up to 127, but the sorting applies to all 256 possible bytes.
Thanks for your suggestion. Your playground link is the same as mine. Did you paste the wrong link?
Thanks. I had this mis-impression that `impl Trait` is the same as specialisation. Guess I misunderstood. Edit: I have a question: why would trait bounded type parameters work for input but not for output? I don't really understand what you meant by "you can only return a specific one". Is this because static/dynamic dispatch only takes into account the input type parameters? 
We don't have a certain date, as there were *so many* responses and they require some degree of manual work. It's progressing though.
I don't quite understand. say you're using some library and it allocates stuff. How could you handle such an allocation failing in a reliable way by linking to a different allocator?
&gt; No, because if Index::Output = Foo, then you need to return &amp;'a Foo from the Index::index() function. This is a bit of a pain in the current system, I hope it is possible to improve it with coming changes. What I meant is that you can generate from `Foo` a `struct FooWrapper` and then when you implement `Index` on `SoAVecFoo` you make `Index::Output = FooWrapper` instead of just `Foo`. Then you can make `FooWrapper` just have a pointer to `SoAVecFoo` and an `usize` as index, and then you implement for `FooWrapper` getters / setters that change the fields of `Foo`. Then for `Foo` you implement the same getters / setters, and as long as the user only access the fields through the getters / setters, they don't need to change the code.
I would move `example_app.rs` into an `examples/` directory at the top level of your crate: http://doc.crates.io/manifest.html#the-project-layout &gt; Please refrain from submitting a PR for a while, I have few bigger changes comming before gathering community around the project. I'll refrain on detailed comments in the event you are going to change things but did you purposely build this as a binary crate? I would have thought this would be a library crate (`main.rs` vs `lib.rs`, etc.).
Just found this cool tutorial while looking for a C++ tutorial :D
Apparently. And of course I closed the tab already. Another try: https://is.gd/XkhDdd
&gt; API design &gt; not an issue that should be discussed on a bug tracker &gt; not a technical issue I'm baffled.
gonna be lib, set to bin cause its easier when prototyping. gonna move examples to separate folder later. edit: actually found out you can run examples... going to convert to lib soon!
[Valgrind doesn't report allocations with jemalloc on nightly #28224](https://github.com/rust-lang/rust/issues/28224) Apparently [rust-san](https://github.com/japaric/rust-san/blob/master/README.md#rc-cycle) can catch Rc cycles
also please comment if you have any feedback, currently looking for a direction (make library feel more like unity3d or maybe go with react/flutter style)
Thanks. It's a nice workaround.
The `enum` in question was an example in a completely unrelated issue. Then people started being up in arms about it instead of discussing the actual issue. Regardless, I maintain that for SOME purpose this is a good enough API. For EXAMPLE, when referring to grammatical gender in languages such as Spanish. (Although usual terms are masculine and feminine, not male and female) Did it occur to you that the `enum` itself never said it was to be used for people? In the case of animals, it's kind of hard to determine what they identify as
new gui library with high level api
Your function signature lets the caller choose types for `T` and `I`, but your function body actually choses a specific type to return, namely whatever `::std::iter::Map&lt;::std::vec::IntoIter, _&gt;`. Thus, the type you return and the return type in the signature are not the same. You can totally be generic over output types. A function like fn into&lt;T, U: From&lt;T&gt;&gt;(t: T) -&gt; U { U::from(t) } is fine. `impl Trait` is most useful for cases where you can’t spell out the return type. For instance, if you want to return whatever `Iterator::map()` returns for a specific closure, you cannot because you can't write the second type argument for `Map&lt;T, _&gt;` if it is a closure inside your function body.
It works if the third dimension is always assumed to be the same. Though I would personally more group it in with "validating email addresses", "names as required firstname/lastname parts". These will also mostly work. But if they don't work for you, or you know of people for whom they don't work they become wrong from your perspective.
I've done a bit of research on how larger UI systems are made. They usually are built on top of a system of inequalities with an objective function, e.g. "maximize the space this button has". Then they have a solver that solves these inequalities. Here was a good article, sadly only half-finished: https://croisant.net/blog/2016-02-24-ui-layout-constraints-part-1/ You can solve using three methods: Simplex, cassowary (has a rust implementation) and the inner point method. For making more complex layouts, I'd definitely go with a tree-like structure. Your library has no way of getting to the parent of a Rectangle or to add / remove nodes dynamically. It's not only the UI, it's also about how you handle callbacks. If you want to work on this, you should look into an established library such as `rctree`, which solve the borrowing constraints in a tree-like structure with iterators over parents and children. I've done this here: https://github.com/sharazam/layout2d/blob/master/src/ui_screen.rs where I have a UIScreen which can be "flattened" into rectangles later on, but it as itself is an abstract data structure that can be manipulated by code before the actual layout is done. You've made it easy by using absolute layout. I'd simply do much more research before jumping into such a big project.
I mean, you can't control what your libraries do; this is true in general. If a library isn't designed to deal with fallible allocation, then it's not, even if the allocator gives you that option, just like you can't control if a library uses `unwrap`. That's not a problem Rust can fix.
I suggested it for inclusion in `mio`: [carllerche/mio#628](https://github.com/carllerche/mio/pull/628).
This suffer from the same issue: `Index::index()` needs to return `&amp;FooWrapper`. We need to have a `FooWrapper` somewhere in order to return a reference to it, we can not just create one inside `Index::index()`. This gives the "borrowed value does not live long enough" error: https://play.rust-lang.org/?gist=3846988b485855d454a93ecefdb9779c We can not have `FooWrapper` implement `Deref&lt;Target=Foo&gt;` either, because we need to return a reference to Foo, and we don't have one. The memory representation is not the one of Foo -- and that's the whole point of having SoA representation. Another way to see it is that functions that take `&amp;Foo` directly can not be used on a `FooRef` as contained in a `FooVec`: the different fields offset is not the same at all, and compiled code would not be valid.
&gt; Did it occur to you that the enum itself never said it was to be used for people? If that were the case (but honestly, it sounds like you're strawmanning) that's a technical question then, that could have been answered very quickly. If that's not the case, though, and the field actually referred to the gender of a person, then it is certainly a technical issue. Counter example. I go by my middle name, and always have, so when I see a form that provides space for first name, middle initial and last name, I always try to put my first initial and middle name in the first name field, so the site can be more accurate when referring to me. Sometimes, I'm told that my name is invalid, either because of the period after the first initial, or because of the space. Thus the modeling has a technical limitation. Maybe you'll tell me I should just put my first name in that field instead, but people with hyphenated or otherwise punctuated last names, with capital letters after the first letter of their last name (McKenna, O'Connor), with compound names (Mary Sue), have the same problems. These are social problems, but they're also technical problems. Pretending that the social and the technical can be separated is naive and harmful.
Both the post and Reddit discussion of it were very informative, thank you! We've had this same back-and-forth between internal and external iteration in the Haskell community, especially between the enumerator style up to the stream fusion approach. And then we have coroutine-based streaming like Conduit, which get the worst of both worlds :).
I'm also hitting this issue. My error is: | 23 | while let Some(e) = events.next(&amp;mut self.window.piston_window()) { | ^^^^ the trait `piston::&lt;unnamed&gt;::Window` is not implemented for `&amp;mut piston::&lt;unnamed&gt;::Window` = help: the following implementations were found: &lt;piston_window::PistonWindow&lt;W&gt; as piston::&lt;unnamed&gt;::Window&gt; This exact code works fine if I just shove everything into `main.rs`. I've not seen this before.
That's a big main file
&gt; If that were the case (but honestly, it sounds like you're strawmanning) the `enum` was an example piece of code, never in any code base it's the people in the bug tracker that started bringing attention to how it's bad design - even though it wasn't actual code used in any program, but simply an example and the example didn't say whether it was a person's gender
The example NEVER specified it was to be used for a person.
I've just casted it to a `PistonWindow` reference and the compiler seems happy now. Really weird. This is what I'm doing now: while let Some(e) = events.next(&amp;mut self.window.piston_window() as &amp;mut PistonWindow)
The discussion on this very page on `enum Gender { Male, Female }` is evidence of exactly why so many people think this community is toxic. I cannot figure out why that's hard for people *inside* the community to understand, except that I guess they just don't get much exposure outside of that bubble. I imagine that bubble is as much geographic (where they live on the earth) as it is social (who they talk to).
Then that issue should be cleared up quickly: * "This is the terminology specified by the cable vendor and we mirror that." * "This is about grammatical constructs." Although in the latter you might also get hints that for some languages there's at least also a neutral case, and there might be more cases in other languages. I inferred the person context from the discussion. And even if it isn't about that, you wrote: &gt; Have you people heard of modeling? Not every model is a perfect representation of reality... Then you'd usually have a reason for the simplification I assume? Would you not say pointing out that a model is incomplete/wrong/too simple is a valid critique? If you do date/time handling without timezones, or not handling leap years, it might be enough for your context. But pointing that out I'd still see as relevant.
&gt; Then that issue should be cleared up quickly: That's the thing, the code in question was AN EXAMPLE. It was never intended to be working code. But people made a stink about hypothetical example code. That's what's upsetting, you can't even post example code without people jumping in saying "Ackchyually there are more than two genders" even though you never said your example was about people.
thanks or your feedback :) there is a way to manipulate parent by changing state and rebuilding ui with new state. thats how you manipulate ui with react/flutter :). also I used absolute layout because couldnt decide on the relational layout yet. in html you have margins, in unity3d you have anchors/pivot system. you mentioned inequality systems but I think its worth to consider other systems too. thanks for tips, ill look into it later.
Ok. I can see how going off topic in a bug tracker (thank you for the clarifying details, I was confused because you originally referred to it as part of the API design), and how that can be annoying. I can also see how someone who has seen dozens of sites that actually do represent human gender in a binary way that doesn't allow them to identify themselves accurately would be defensive about yet another model of gender that does the exact same thing. This is actually why I think the rust community's approach is a good one. Rather than doubling down on a model that's obviously touching a nerve for someone (and helping the thread derail further), why not acknowledge that the model bothered people, present an alternative example (`enum Doggo { Cute, Cuter }`), and get back on track discussing whatever the real issue was?
There's also a [Rust port](https://tomassedovic.github.io/roguelike-tutorial/) of the popular Roguebasin tutorial by the author of tcod-rs.
Thanks slamb, I didn't implement that yet as I switched to another Rust project of lower difficulty and helps with learning more. But I still look forward to come back to here and eventually use what you helped with :)
Very true. On my list!
&gt; why not acknowledge that the model bothered people, present an alternative example (enum Doggo { Cute, Cuter }), and get back on track discussing whatever the real issue was? Sure, that's the productive way of doing things. But instead we had a huge argument on the bug tracker. That's what made me angry, since I came for the technical discussion. I called the discussion in the bug tracker "garbage" and got admonished for not being inclusive. THAT'S what made it memorable for me. It's not enough that the issue was wasting space in the bug tracker, but if you disagree with this being discussed at all you're a bigot apparently.
There's no built in way. Your best bet is to write a custom derive macro that saves the field names in a static array or something.
Interesting (perhaps) I consider the builder pattern to be a hack to work around the lack of default arguments. What are the situations where a builder is better?
For layout I would definitely recommend using cassowary, I've actually built a higher level library around it: [limn-layout](https://github.com/christolliday/limn/tree/master/layout), as a sub crate of my own experimental gui library. There are some rough edges around the API, but should still be much easier to get started with than using cassowary directly. You can use it to describe layouts like this: layout!(widget_top_right: to_right_of(&amp;widget_tl), align_top(&amp;widget_c), align_right(&amp;widget_c), match_width(&amp;widget_tl), ); As for tree structures, agree about rctree. I made the mistake of using petgraph in my ui lib, which is closer to using arena-tree (requires passing around and modifying the entire widget tree) and am planning to convert to something based on RefCells.
Yes, I just wanted to give ideas on what I thought. Rebuilding the whole UI becomes cumbersome not for you, but for the library user, because the user has to constantly keep the UI and elements of it in scope and track what elements have been removed and which ones have not. `conrod` does this with their ID system, and it's just a pain. With the `rctree` approach, you only have to maintain the scope of the root element, a library user can say "allright, this reference is the 3rd child of the 4th element of the root node, is it still there? If yes, please remove the element and its children". Elements can appear and disappear at any time without memory issues, the layout is more dynamic. My layout2d system is more like the unity system with an added flex constraint. The problem is that most UIs are either over- or underconstrained. You have two choices: Either solve inequalities or make a system of precedence (i.e. if you set min-width, the width of an element will be clamped to this value). Just ideas, don't take it personally.
Because they probably assumed it was about the social construct. At least in my experience, it usually is too. That's why I assumed that as well. My advice would be to not use social/civil rights hot topics as examples.
I'm not the one who posted the example, but it drowned out actual USEFUL discussion on the bug tracker.
Well comparing with c++, if a library throws std::bad_alloc, I could catch it and continue, so in that sense c++ offers more flexibility when it comes to fallible allocation. In such cases the ergonomics of c++ is much better: you don't have to check every allocation, but you can still handle failing allocations if you want to.
Wouldn't requiring `&amp;Stream` be enough? In that case there is no overhead. Something like this: use std::cell::*; use std::collections::*; struct Stream&lt;T&gt; { elems: RefCell&lt;LinkedList&lt;T&gt;&gt; } impl&lt;T&gt; Stream&lt;T&gt; { fn new(elems: Vec&lt;T&gt;) -&gt; Self { let mut l = LinkedList::new(); for x in elems { l.push_back(x); } Stream {elems: RefCell::new(l)} } fn next(&amp;self) -&gt; Option&lt;T&gt; { RefCell::borrow_mut(&amp;self.elems).pop_front() } } fn main() { let s: Stream&lt;i32&gt; = Stream::new(vec![2,3]); let x = s.next(); let y = s.next(); println!("{:?}", x.and_then(|x| y.and_then(|y| Some(x + y)))) } Although this example is the other way around. It would be appropriate to maintain a linked-list of items to send while items coming to the stream wold be represented by some more abstract source. I looked at `futures-rs` implementation and `send` wraps the current stream in a struct (in fact every operation wraps things in a struct). So not sure if internal linked list would make much difference (allocating a struct vs allocating a list node).
Sure, but if that library doesn't throw that, but instead aborts, you can't do anything about it. You're still relying on the library to do the right thing.
I'd say "topical" rather than "useful" because I do see the use in those kinds of discussions. The thing is, simplifications like binary gender classification do hurt real people in the big picture. And so that is bound to come up at some point.
no, in c++ if `new` fails, it throws `std::bad_alloc`. The library might have been built without once thinking about the possibility of running out of memory but you can still use it and handle that situation if you need to
That's basically an [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html) in a RefCell. It's not much use for async IO. If you don't need async IO, don't use tokio!
Let me refer you to [this chain from last week's thread](https://www.reddit.com/r/rust/comments/6kxnzr/hey_rustaceans_got_an_easy_question_ask_here/djuiyhu/) where I answered the same question.
Publishing API keys, even if you made a demo one specifically to be public, is still a bad idea. If someone forked this, or cloned it and then changed the key, they are being persuaded into storing sensitive keys in GIT. This is not a good idea at all, and has been the subject of a huge amount of security breaches. Keys should be environment variables, or stored in an untracked file, or anything that is not within GIT that the library can read and write to. The library looks neat otherwise though!
extended ascii goes to 255.
And worth mentioning that there is a series going on in /r/roguelikedev right now where people are going through that tutorial in various languages.
so, after the ['why' article from 2 days ago](https://www.reddit.com/r/rust/comments/6mf0bx/why_you_should_actually_rewrite_it_in_rust/), here's the how ;)
**Here's a sneak peek of /r/roguelikedev using the [top posts](https://np.reddit.com/r/roguelikedev/top/?sort=top&amp;t=year) of the year!** \#1: [Roguelikedev Does The Complete Roguelike Tutorial Starting June 20th](https://np.reddit.com/r/roguelikedev/comments/6h4z09/roguelikedev_does_the_complete_roguelike_tutorial/) \#2: [Been experimenting with a 3D ASCII renderer with bells and whistles.](https://www.youtube.com/watch?v=zfa9wJ47qDQ) | [41 comments](https://np.reddit.com/r/roguelikedev/comments/5o1oq9/been_experimenting_with_a_3d_ascii_renderer_with/) \#3: [RoguelikeDev Does The Complete Python Tutorial - Week 1 - Part 0: Setting up Python](https://np.reddit.com/r/roguelikedev/comments/6ibqev/roguelikedev_does_the_complete_python_tutorial/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
Exciting to see all those proc macro APIs merged finally!
Funny you talk about this, I'm currently working on android utilities in rust too ! 1. Static linking with bionic will probably involve some work, but should be possible. Rust works very much like a traditional C compiler, it has its own source -&gt; object pass that's managed by rustc, and a linker pass that's managed by gcc. You can pass flags to the linker with `-C link-arg`, and specify the linker you want. How do you do your static linking with a C program ? If you give me a sample cmdline, I could probably give you an equivalent rust one. 2. Yes it is, since rust 1.18 IIRC. 3. Rust's file abstractions are more or less the same between linux and android, and attempt to do the same thing. It's based on the libc crate. Furthermore, if you find rust is missing something, it is fairly easy to do your own idiomatic wrapper using the correct APIs. 4. The [nix](https://github.com/nix-rust/nix) crate provides idiomatic wrappers around many linux-specific APIs. It recently got support for android, too ! 5. So, by default, rust fails on bad allocation. Worth noting that in rust, allocation is done by using Box, Rc/Arc, or collections. If you don't use any of those, it's unlikely you'll get an allocation. "7." This is very interesting. So I'm using [rust-fuse](http://github.com/zargony/rust-fuse) which is a complete rewrite of libfuse in pure rust. I must say it's a very high quality crate, and has been a blast to use. For a lot of stuff, you can probably just use bindgen to auto-generate FFI bindings from the C/C++ projects. I'm currently in the process of writing a full rust rewrite of libbinder for a project of mine. As soon as it's done, I'll publish it as a crate.
What can we do to make build system integration smoother. I just learned about the object file option and that would be a solid option for some things I work on. Maybe we need a central place of options and best practices?
You seem to really want to be right about something. Why don't you spin up a python interpreter and figure it out for yourself? 
Please, just for me, correct the 'you' in the title on the blog. I know you can't on Reddit.
&gt; no, in c++ if `new` fails, it throws `std::bad_alloc`. Yes. However: - no-one is forcing a C++ developer to allocate with `new`; they could very well prefer [`posix_memalign_alloc`](http://man7.org/linux/man-pages/man3/posix_memalign.3.html), and abort in case of allocation failure (or even segfault), - no-one is forcing them to let the exception bubble up, they may catch it and abort. At the end of the day, you cannot but rely on the quality of the libraries you pull in. &gt; The library might have been built without once thinking about the possibility of running out of memory but you can still use it and handle that situation if you need to. That's unfortunately not the case. Signalling that an error occurred is easy, but **recovering is hard**. There is no telling that critical internal structures of the library have not been corrupted by the unexpected exception! And if the writer of the library did not anticipate the possibility of an exception, it's quite unlikely that they took care of implementing the Strong Exception Guarantee. Once again, you are down to the quality of the libraries you pull in.
You may want to look at my explorations of this idea here: https://github.com/matthieu-m/rust-poly 
It was a technical discussion in which you brought up an interesting and important point, I just wanted to be clear on it. nothing more nothing less. Ascii vs unicode and sorting orders are two things which have bit projects of mine more than once. Knowing that users want alphanumeric sorting and programmers consistently get this wrong, using ascii sort instead, means I check this anytime someone mentions this sorting to be sure which they mean.
The point of this would be to enqueue data, mark the stream as available and let scheduler pick it up to send (i.e. actually perform IO) whenever ready. There's no actual async IO above because it's a toy example to demonstrate the difference between enqueuing to internal linked list vs wrapping things up in another struct. Unless I'm missing something crucial it's basically the same operation with different interface. Taking `s` to `Send(x, s)` is basically adding an element to the list but it uses up the original stream `s`. While enqueuing to internal list allows to re-use the object.
This is a major goal of this year https://github.com/rust-lang/rust-roadmap/issues/12
It definitely makes sense to use crates from the existing ecosystem. I also think it's best to try to provide the functionality that `libtcod` has, but in a Rustic interface. `tcod-rs` does a pretty good job in this by supporting unique features that `libtcod` provides while purposefully not exposing features that other crates provide. See: http://tomassedovic.github.io/tcod-rs/tcod/index.html#features-already-implemented All this to say that I agree with your approach :) I don't yet have a ton of experience with `libtcod`. It seems to do what it does well, but stops just about there. For example, it only draws text/tiles. This is great for many Roguelikes, but prevents going out of the grid. `tcod-rs` does a great job providing that Rustic interface I mentioned earlier. It doesn't support all `libtcod` features yet, but the author happily accepts pull requests.
Looks like it's the integer32 playground under the official label. Neat!
For ipc-channel, the basic overview is here: https://docs.rs/crate/ipc-channel/0.8.0 . It's essentially the same interface as `mpsc`, with the added requirement of passing an opaque token/name to the peers so they can communicate over the same channel.
You could find more gif on the website or here https://youtu.be/8WR3HAtjumU
oh, right, done :)
Oooh, those posts are a great jumping on point for threading in Rust. Thanks! Been meaning to get started playing with that stuff.
Capnp-rpc probably is worth a look, it is in my opinion the most promising rpc framework. Other than that, std crate has basic support for [unix sockets](https://doc.rust-lang.org/nightly/std/os/unix/net/struct.UnixStream.html), so if you don't need higher level stuff then that could work
It's difficult for me to guess at what async IO you're imagining if you don't implement it. Your description of how `Sink::send` works is wrong; you're not appending an item to a list, you're constructing a future that will, if driven to completion, transmit an item to a sink. A sink is not a message queue, it's much more general than that. It could represent the sending half of a TCP socket, for example.
Yeah I agree you're of course at least partially down to the developer. Still I feel that the C++ support for it is much better. As you say if you want you can do what you want in c++, but the default, if you write 'modern' c++ you get decent handling of out of memory. Contras with rust where you would have to base your entire api around the possibility of allocation failure. It's possible to write code in both that doesn't handle out of memory well, but it is much easier to write code that does handle it in c++ than rust. And that's a shame, because I really like rust. 
What's the status of the IRC bots?
It looks like the flow is larger in the other direction. Rust -&gt; Go has a score of 9, whereas Go -&gt; Rust has 12. Though I'm not entirely sure if the scores are comparable like that. It does seem that C and C++ developers are switching to Rust which is encouraging; Rust is at least tempting its target audience. Unlike Go which was initially targeted as a C++ replacement but has almost no C++ users.
They're currently running off of the old playground (though I haven't seen playbot for a while). I believe the hope is that someone will implement the IRC portion on top of the new playground.
That's really cool! New users can now try a part of the ecosystem without installing! Is there a way / configuration option for the end user to place the source code view and the output view side by side again (I have a widescreen monitor) and to hide the compiler invocation? Nitpicks: Clicking on the "?" opens a page which in turn references the official playground. The permalink on a permalinked page loses the compiler channel information, e.g.: https://play.rust-lang.org/?gist=e7be40c38fcf8d4817b81f6aaba45e61&amp;version=nightly Where should one file issues? Against rust-lang/rust-playpen or integer32llc/rust-playground?
It reappeared today!
Stack Probes! Finally! Thanks to all who pushed on this.
Hey! `posix_memalign_alloc` is used in modern C++! *The problem of `new` is that it is only guaranteed to return memory aligned suitably for `std::max_align_t`, which may be insufficient in some circumstances: cache-line aligned types, page-aligned types, ...* As for writing code that handles *failures* in C++ compared to Rust, well, it *really* depends on the task. Unless you are only concerned with `noexcept` movable types^1 , then writing correct containers can be very challenging. I still have nightmares about implementing a double-ended vector (ie, one that has both a front and back capacity, but otherwise guarantees memory contiguity), handling the possibility of throws on moves without leaving "holes" in the vector was really hard. In Rust, this is trivial, because a move boils down to a `memmove` so it's guaranteed not to have exceptions. And yes, `noexcept` matters, because if you accidentally allocates in a `noexcept` function, the compiler will *not* complain. It will silently insert a `try { ... } catch(...) { std::terminate(); }` call around your function body, and your program suddenly crashes on allocation failure :( But well, [I may be biased against handling allocation failure](https://stackoverflow.com/questions/44923306/why-doesnt-boxnew-return-an-option-or-result/44924283#44924283) ;) ^1 *I personally think this is a reasonable restriction; unfortunately sometimes you have to deal with the others...*
Writing asynchronous servers in Rust is tough. Tokio ain't no fun. This is where Go shines. Goroutines may not be optimal, but leveraging them to write servers is straightforward. Things will improve as Tokio matures, and with `impl Trait` and async/await. But right now, I wouldn't be surprised if developers switching from Rust to Go did because of a bad experience with writing asynchronous servers.
It's mainly that default arguments don't scale well. For just a handful of arguments, they're simpler and cleaner but, for many, as you might find in something like [LXML](http://lxml.de/), you end up with ugly, unwieldy code and ugly, unwieldy function signatures in your API documentation. The builder pattern allows you to break up the code for acting upon large masses of arguments more easily chunks that are easier to document and . It's actually another case similar to "traits vs. classical inheritance". When used by people who know what they're doing, both clearly have their place, but the question is whether supporting both is worth the potential mistakes from people who aren't experts in API design.
Yeah, I've been there. If you want to use rust for servers, it's painful right now. Go is very attractive and I've considered switching for specific projects - if I ever cared about production, I'd use go for servers. Since idgaf about writing for prod in my free time, I use rust.
Small fix: Go -&gt; Rust has 12 
Continuing work on [cargo-tarpaulin](https://github.com/xd009642/tarpaulin), there's an issue which seems to only occur on minimal ubuntu server so I'll be working on that. Hoping to get it sorted either today or tomorrow. Once that's done I should continue with my initial implementation of decision coverage (and what will be required for condition coverage). This is really exciting to me as no other open source coverage tools I can find implement these types of coverage, and they're definitely more useful for identifying gaps in tests than line coverage! 
This is...unsurprising. Go is a much better fit for many server tasks right now. It's easier to learn, put together a server with, and there are tons of libraries for gluing APIs together.
Tokio? [`tokio-uds`](https://crates.io/crates/tokio-uds)
That's correct!
&gt; Is there a way / configuration option for the end user to place the source code view and the output view side by side again (I have a widescreen monitor) and to hide the compiler invocation? https://github.com/integer32llc/rust-playground/issues/162 &gt; Clicking on the "?" opens a page which in turn references the official playground. I saw them tweet about this, it'll get fixed. &gt; Where should one file issues? Against rust-lang/rust-playpen or integer32llc/rust-playground? The latter!
&gt; range How's it going? It's been 6 days since you said you'd try.
You likely want dbus bindings for rusts, using the standard IPC everything else uses seems like the best idea. For example, https://github.com/diwic/dbus-rs AKA https://crates.io/crates/dbus
Worth noting that this was written in August 2014, which is pre-1.0, so that code might not compile anymore. 
What are stack probes and why are you excited about it, exactly? I've seen people mention that a few times, but have no idea what it is. edit: Found a short article that looks promising: https://geidav.wordpress.com/tag/stack-probing/ edit2: I got lost in the "How does Windows manage stack memory?" section actually. I don't know enough about how OSes manage memory.
I noticed there's `winapi` on the list. I guess the server runs on some kind of Linux, right? Wouldn't it be reasonable to remove it in that case, since it's useless there? It'd free space for other crates I.
It was also a decision that was made late in Python's life. The `bool` type was spec'd in [PEP 285](https://www.python.org/dev/peps/pep-0285/) and added in Python 2.3. (Coincidentally, the very first version I ever used.) They were concerned enough about backwards compatibility with the "`1` or `0`"-based approach to booleans in existing code that the PEP actually addresses the concern that there could be code breakage from the new output of `str(x)` if `x` is produced by a standard library component or language construct that formerly returned `1` or `0`. Here's a very relevant snip of the PEP: &gt; 6) Should bool inherit from int? &gt; &gt; =&gt; Yes. &gt; &gt; In an ideal world, bool might be better implemented as a &gt; separate integer type that knows how to perform mixed-mode &gt; arithmetic. However, inheriting bool from int eases the &gt; implementation enormously (in part since all C code that calls &gt; PyInt_Check() will continue to work -- this returns true for &gt; subclasses of int). Also, I believe this is right in terms of &gt; substitutability: code that requires an int can be fed a bool &gt; and it will behave the same as 0 or 1. Code that requires a &gt; bool may not work when it is given an int; for example, 3 &amp; 4 &gt; is 0, but both 3 and 4 are true when considered as truth &gt; values.
The code definitely won't compile: the current tcod-rs API is different from the one in the post (also, using the built-in libtcod should be pretty straightforward now). Edit: There are also a bunch of examples in the examples folder of the GitHub repo which is a pretty good place to get started.
I develop (also) on macOS and I find Autolayout really neat. I advise looking into it.
I see, this is consistent with the descriptions of "drop-in replacement for Rust channels". Thanks for pointing to mpsc, this is where I needed to look at.
FYI, AutoLayout is built on top of Cassowary
I think Apple's autolayout is so far the best I've seen.
is this going to change soon? Implementing message passing or channel abstraction in a library should not be too bad right (ie similar to scala akka)?
It's probably here as a dependency of something else?
I agree capnp-rpc-rust looks good! Initially I wasn't able to find references to Unix socket but after looking deeper I just saw that: https://github.com/capnproto/capnp-rpc-rust/blob/master/test/test.rs#L130 So now I'm hopeful that it's possible to use it over a Unix socket by setting the streams to a [mio_uds::UnixStream](http://alexcrichton.com/mio-uds/mio_uds/struct.UnixStream.html)
If you remove it, crates like `rand`, which require it regardless of platform, can't build.
Thanks for the link. I'm not sure where to start with that however. Would it mean that an implementation using this crate would be designed just like the [getting started examples](https://tokio.rs/docs/getting-started/simple-server/), with the protocol defined as a codec? But replacing TcpServer by .. ah on that I'm not sure what from the code here: https://github.com/tokio-rs/tokio-uds/tree/master/src Any example welcome :) I'll look at [existing projects depending on it](https://crates.io/crates/tokio-uds/reverse_dependencies) Edit: just found [tokio_uds_proto](https://docs.rs/tokio-uds-proto/0.1.0/tokio_uds_proto/) in [libvirt-rpc source](https://github.com/polachok/libvirt-rpc/blob/master/src/lib.rs), that might work.
Huh? Since when dependencies aren't pulled transitively?
Yeah, I think I've read that somewhere. I remembered it correctly.
Looking at the Go workarounds for lacking generics, I can't imagine switching willingly
And it's a fair criticism, I guess. Go is trying to be Node but faster -- quick prototyping, very easy to learn, simple concurrency. It's great at that. Rust isn't trying to be that. If you're trying to build a server in 20 minutes, you shouldn't start with Rust. (If you're trying to build a server for 20 years, on the other hand...)
On the playpen. You can only use those 100 crates; all dependencies in the graph must be in those 100. Otherwise, someone could publish a crate that depends on every crate and then you wouldn't have the restriction. Furthermore, this doesn't compile dependencies on the fly; it precompiles them.
This might not address the question but for me working 100% on windows, a cargo subcommand that generates a vcxproj would be pretty cool. It just would need to call cargo to build and register the output files, then it should be able to be included in arbitrary solutions. It's probably a trivial crate to write, but solves a very windows-specific problem that's not all that hard to do manually either.
that would be awesome!
Glad to see `bindgen` in there :) Couple suggestions: * You shouldn't need `whitelist_recursively(true)` in the `bindgen::Builder`, as that's the default. * Its probably worth panicking eagerly if writing the bindings to disk fails, so that devs don't have to spend time rediscovering the root cause of some compilation failure due to a missing module. That is, I'd `.unwrap()` rather than `let _ = ` the result of `.write_to_file(...)`. Cheers!
The [standard library uses this pattern itself](https://github.com/rust-lang/rust/blob/32cbbffea2ebf4bb222b54bd67e1a4e54c1ca3c5/src/liballoc/string.rs#L1882), so yes, I think you can rest assured that it's supposed to work this way.
Correct but AFAIK Rust doesn't track panics. It's just able to optimize-away simple stuff - like `some_expression()`.
Usability aside, my main beef with `tokio` is that it fractures the ecosystem. I wanted to try &amp; replace a small web service at work w/ a `rocket.rs` implementation as a sort of pilot for developing our software in Rust. Unfortunately the only [MS SQL](https://github.com/steffengy/tiberius) driver I could find is async. Integrating it with `rocket.rs` is proving to be quite a pain, since rocket expects its managed-state has to be thread-safe. -- Not to mention afaict a futures-based database driver can't (trivially) be wrapped to work w/ the [`r2d2`](https://github.com/sfackler/r2d2) connection pooling library. If I recall correctly: a major nail in the coffin of libgreen was because it fractured the stdlib. I want to know why is it bad to fracture `std`, but OK to fracture the ecosystem at large?
Rust is a complex language, and Go has a rather shallow learning curve. Can't blame anyone for picking Go to start with. I mean, if I hadn't learned bliddy Haskell beforehand, I'd have a much harder time learning Rust! Go's gc is pretty amazing as well. Nothing wrong with rewriting that ol Python script in Go for a measurable performance boost, and rewriting the Go app in Rust later to get even closer to the metal.
This is perfectly fine. `NoError` is an instance of the never type, which is planned for inclusion in the language with the special symbol `!`. [Playground example:](https://play.rust-lang.org/?gist=0469a4178bce4f90bbbffbcae2bd08da&amp;version=nightly) #![feature(never_type)] fn cannot_error() -&gt; Result&lt;i32, !&gt; { Ok(5) } fn main() { println!("Hello, {:?}!", cannot_error()); } Tracking issue: &lt;https://github.com/rust-lang/rust/issues/35121&gt;
Libgreen was killed because it made c operation more difficult and did not really have performance numbers to back it up. It also came from a different era of rust that was targeting a higher level with some amount of runtime. 
One way to look at it is that [every arm](https://en.m.wikipedia.org/wiki/Vacuous_truth) of the `match` returns `&amp;str` so it is okay for the whole method to do so too. The compiler is essentially recognising that that method can never be called/the `match` never executed, so the types don't matter.
Non-Mobile link: https://en.wikipedia.org/wiki/Vacuous_truth *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^90604
There's even a crate for scope guards in Rust: https://crates.io/crates/scopeguard/ I've used it before for a Go-like `defer`.
&gt; (If you're trying to build a server for 20 years, on the other hand...) Maybe, but I'll offer a counterpoint: a web app written using Go's `net/http` in 2012 will still compile today without modification. What's more, recompiling it today would gain both runtime performance improvements and additional features like HTTP/2 support for free. Go's stability guarantees are similar to Rust's, except the standard library covers a larger scope of problems and it has been stable for longer. The Go ecosystem relies on the platform-provided event reactor, and has since before Go 1.0. As a comparison, a Rust app I wrote using last year's HTTP libraries doesn't play nice with `tokio` today. Instead of recompiling and getting improvements for free, it's an upgrade treadmill full of API redesigns. This will change as the Rust ecosystem matures -- but as of right now, Rust lags Go in this area.
Yep. Part of being ~\**enterprise ready*\*~ is stability.
To be honest, I write a *fair* amount of rust code without generics. I wrote an entire microservice recently with very, very few generics - and it was all in the name of testing/ mocking. I would hate to give generics up, but it's not like I couldn't write code without them.
Previously it was possible for safe rust programs to have undefined behaviour when they overflow the stack, if one stack frame was sufficiently big (for example, if you have a local variable of type `[u32; 1000000]`. Stack probes prevent that from happening, and will cause the program to crash instead. This is potentially a big win for security.
After checking I see that even the headless Raspberry Pi which I configured with as few packages as possible runs D-Bus already, so it would be an acceptable dependency. Thanks, it's a great solution to investigate as well!
Well if you look at both of the thread from a distance you will see that 3.5 dudes on voat talking about how they don't feel safe and welcome by /r/rust. Please tell me how saying: `voat being a cess-pool of people that can't write a sentence without including an insult` Meets this rule: `We strive to treat others with respect, patience, kindness, and empathy.` Which in result proves their point. Look most of the comments here (this post) are about that gender enum... which in 99% of cases can be a boolean in another language and never see anyone that can't be describe with it. Now the real question is `true` is Male or Female. 
https://github.com/insanitybit/derive_aktor That's a serious WIP/ unstable, with lots of things I realize now need to change. But I used it to generate code recently for this: https://insanitybit.github.io/2017/07/10/building-a-microservice-in-rust Note that that code uses a naive implementation of actors, mapped to OS threads, but I plan on experimenting with other future-based approaches.
How could Go possibly target C++ users? What does Go have at any point that could mae someone want to use C++? I could understand a Java replacement C++?
What? You don't think characters from the Canadian aboriginal syllabary are a most elegant solution?
google funded go to replace C++, it clearly doesn't meet those aims and much of the marketing these days is use go as a replacement for dynamic languages and java. Though I bet there are users of java who'd ask what go has to offer them over java especially on the server. 
Couldn't the macro produce the attribute then?
I honestlyhave no idea what Go has to offer _at all_. It brings nothing new and it omits essential stuff and doing simple shit in Go is very verbose and long. But then again you would say the same of Python and man did that take of by storm.
Ah, that makes sense, thanks for explanation!
Closures are not only defined by their scope, but also by the code they run (their implicit `impl Fn/FnMut/FnOnce` block) - this is required for static dispatch. Having "equal" closures would mean the code is the same, which is both hard to write down in the type, and to check for the compiler. As for Clone/Debug, it could be interesting indeed to implement `Clone` for closures with only `Clone` scoped variables. [Right now, it doesn't](https://play.rust-lang.org/?gist=97d9f4bbd473652c9a1807866b7cb41f&amp;version=stable).
Nice to see some interest in ui! I don't recommend depending on piston_window, since it's just a window wrapper. Better depend on the piston core (perhaps just pistoncore-window and pistoncore-input). Use generics. This will make it possible to swap the backend. Or, perhaps you plan to do that later? One idea I've been prototyping for UI is changing the semantics of rectangles relative to their parent. You have two anchor bits for each dimension, assigned to each edge, that can "point" left or right. - If both point left, the widget is left aligned and of constant size. - If both points right, the widget is right aligned and of constant size. - If the left points left and the right points right, the widget is stretched when parent is resized. - If the left points right and the right points left, the widget fills the parent. This is done for each dimension, such that for 2D, you have anchor flags for both horizontal and vertical direction. The thing I figured out is that the number used to describe a rectangle, can change meaning depending on which anchors you use. When changing anchor flags, you convert between the various rectangle formats. This requires less memory and makes it easy to edit anchoring layout. I don't have minimum size working yet, but it could be a bottom-top approach to get maximum minimum size and then top to bottom for layout.
Oh ok. Thanks! I think the link I gave had nothing to do with that, despite the "promising" url ^^
Most of *my* code uses almost no generics (except, as you mentioned, for testing) but a lot of the libraries I know and love wouldn't be possible without them. OTOH Go's stdlib would obviate a lot of the need for the libraries that I use, possibly with a slightly lower sense of fitness-for-purpose.
I see it similarly.
That plus lack of enums in Go, nil pointer exceptions and horrible error handling are my pain points with Go.
Yeah, this is a void type or empty type. It's a sum of no types, the sum of nothing is 0 so this type has no inhabitants unlike the product of nothing called the unit type which has exactly one inhabitants. What this means is that you cannot create an instance of this type outside of evil unsafe stuff violating the type system. Since there is no instance of this type the `NoError::description` method can't even ever be _called_. This is why it all type checks; it doesn't matter what it does internally as it won't be called to begin with; you need an instance to call it and you can't create one. It should absolutely not return `()`, `match *self {}` _does not return_ ever because it can never be called. You can in fact use the return type `!` to indicate that it will never return but that violates the trait protocol here so `&amp;str` is fine too. A couple of other things like `loop {}` also never return and also have type `!` as a consequence.
Yeah this is me. I tried to write a fairly simple bot in Rust, but after plugging away at it for a few days, the crate ecosystem seemed to make it impossible, so I switched to Go and wrote it up in half an hour. I don't even like Go. :/
I prefer to write it in 20min instead of 2months. Why would I got the route with the highest resistance? It doesn't make sense. Moreover I think it's more of the lack of easy to use libraries than a problem with the language itself. No need to be defensive.
I mean, I'm well aware of libgreen's history, I've been using Rust since v0.5 or so. _(I still miss the tilde.)_ `libgreen` performed reasonably well until segmented stacks were removed which effectively neutered the idea of a libgreen task being lightweight. It's ill-performance was a motivating factor, but as I understood it at the time the driving factor in it's removal was so that `std::io` could stop being a facade that had to paper over two fundamentally incompatible APIs. My question wasn't "why was libgreen removed," rather I wanted to know what the justification is for fracturing the crates ecosystem into two relatively incompatible implementations of IO. It really sucks to find that a library I need lives in the "tokio ecosystem" which puts it at odds w/ both `std::io` and a plethora of other crates I'm interested in using. Admittedly this is mostly a "growing pains" thing, if there were competing sync &amp; async implementations of the TDS protocol then I could just pick whichever one integrated well into my project. As it stands though my choice is either to buy into a fairly immature async story in its entirety, or forego the use of Rust re: my professional programming.
`regex` exposes a C API: https://github.com/rust-lang/regex/tree/master/regex-capi --- And here are bindings to that library for Go: https://github.com/BurntSushi/rure-go With this sort of thing, I often find it useful to do it "TDD-style" and start with unit tests in C: https://github.com/rust-lang/regex/blob/master/regex-capi/ctest/test.c Oh, and of course, for a guide, I think the [ffi omnibus](http://jakegoulding.com/rust-ffi-omnibus/) is where it's at.
What does `rand` use `winapi` for?
What is the limiting factor for how many crates can be included?
If you want an example, I use `fg-uds` (which is basically the same as `tokio-uds` but running on another event loop) in one of my project. [Here's the server](https://github.com/antoyo/titanium/blob/master/src/message_server.rs#L202) and [the client](https://github.com/antoyo/titanium/blob/master/titanium-web-extension/src/message_client.rs#L134). I use [`tokio-serde`](https://crates.io/crates/tokio-serde) to ease the serialization process. There are some [examples here](https://github.com/carllerche/tokio-serde-json/tree/master/examples): you will need to change from `TcpListener` to `UnixListener` and such, but it should be easy to change.
Thank you for the reply! &gt; "1". Linking to anything else than default would require to compile your own rust std library that is linked to whatever you need. That may need patches if there is something missing or maybe different configuration for bionic libc everywhere libc is used. Note that rust standard library uses libc crate for binding to libc, so if it does not support bionic library in some way it would need to be patched too. From experience, I can tell that this path is very time consuming (I have only added aarch64 support to rust, and that was enough for me). I'll try and figure out if I can compile the std library in a way that can link to static bionic. I've had to hack around bionic libc way more than I cared for (esp. with the headers not matching the library), but I'm hoping it won't be too bad. &gt; "3". Rust uses libc crate to abstract away platform-specific methods. I can find calls to open64 and lseek64 there and it looks like low level calls to open file in rust standard libary use these android functions. Great! This is a pretty huge deal as I can drop 100% of my file abstraction classes in C++ (for opening `HANDLE`, `FILE *`, file descriptors in a LFS-compatible way) if I use Rust for handling files. And I don't need to manually convert UTF8 filenames to `std::wstring`/`const wchar_t *`/`LPWSTR` for Windows. &gt; There is a useful rust-bundgen tool that can generate FFI bindings given some C headers. I'll have to give this a try. Some of the C libraries I use are not the easiest to use in C++ right now, like libsepol, which uses `bool` as the name of a struct field. It might be easier to use these in Rust.
Because easy to prototype is not the same thing as easy to maintain or expand
The post was updated to say that the dependencies are also included. &gt; Specifically, the top 100 downloaded crates of all time are available (edit: as well as their dependencies, when possible).
The rust docs mention the following: &gt; An application that requires an entropy source for cryptographic purposes must use OsRng, which reads randomness from the source that the operating system provides (e.g. /dev/urandom on Unixes or CryptGenRandom() on Windows). The other random number generators provided by this module are not suitable for such purposes. [OsRng can be found here](https://doc.rust-lang.org/rand/rand/os/struct.OsRng.html)
Does return-value optimization in Rust work in pretty-much the same way as C++?
As someone who hasn't and isn't interested in writing servers. I keep wondering why there is such a focus on writing servers. There are dozens if not hundreds of products/libraries that implement a server for you without even needing to code anything except a config file. Is it simply because that is all people know and they don't have any experience other than servers so they keep writing more servers? I don't understand the appeal.
&gt;It brings nothing new The [Go Assembler](https://www.youtube.com/watch?v=KINIAgRpkDA) is impressive to me. One assembly language for all archs.
Awesome, thanks. I'm going write me a YouTube crawler tonight! 
Thanks for the reply! Seems like the libc and nix crates are very complete, at least for what I intend to use. &gt; Static linking with bionic will probably involve some work, but should be possible. Rust works very much like a traditional C compiler, it has its own source -&gt; object pass that's managed by rustc, and a linker pass that's managed by gcc. You can pass flags to the linker with -C link-arg, and specify the linker you want. How do you do your static linking with a C program ? If you give me a sample cmdline, I could probably give you an equivalent rust one. I'm currently just passing `-static` (via CMake linker flags) to `clang++`. The NDK provides the static version of bionic libc and all of my dependencies are compiled as static libraries. &gt; So I'm using rust-fuse which is a complete rewrite of libfuse in pure rust. I must say it's a very high quality crate, and has been a blast to use. Looking through the examples and the documentation, the API seems to be great! I'll definitely give it a try. &gt; I'm currently in the process of writing a full rust rewrite of libbinder for a project of mine. As soon as it's done, I'll publish it as a crate. I'm very much interested in this. There are [some places](https://github.com/chenxiaolong/DualBootPatcher/blob/29b8af4d2b375d8a437d073a8fb78dc5bb45a38f/libmbutil/src/reboot.cpp#L58) where I'm calling `am`, which requires [patching the SELinux policy to add quite a few rules](https://github.com/chenxiaolong/DualBootPatcher/blob/29b8af4d2b375d8a437d073a8fb78dc5bb45a38f/mbtool/sepolpatch.cpp#L1011). I could reduce that by using binder directly. (and it's one fewer place that I have to call out to an external command.)
Thanks! That's good to know.
LLVM and GCC both had that, and better, decades ago. In GCC it's called RTL, and in LLVM it's called `MachineInstr`.
Go's GC is one of the weakest parts of the implementation, because it's not generational.
OK, so it's not that it _uses_ `winapi` on all platforms, but that it's in the list of dependencies, is that right?
Time and money, as usual :-) Each crate is compiled 6 times ({debug,release} x {nightly,beta,stable}), and they are placed into a Docker image which needs to be uploaded out of Travis and onto Docker Hub.
&gt; libgreen performed reasonably well until segmented stacks were removed which effectively neutered the idea of a libgreen task being lightweight. Green tasks were never particularly lightweight. They simply can't be lightweight in terms of memory usage in a runtime where stacks can't move (Rust, right now). The good news is that by paging in stacks lazily, on 64-bit architectures (basically all servers nowadays) this is not as much of a problem as you might think. &gt; My question wasn't "why was libgreen removed," rather I wanted to know what the justification is for fracturing the crates ecosystem into two relatively incompatible implementations of IO. This is always a problem on Linux. Go deals with it by making cgo very heavyweight and by foregoing proper preemption (loops with no function calls can still result in starvation in Go). If we were to bring back libgreen-friendly std::io, then we'd still have a big problem, because Rust code idiomatically doesn't shy away from leveraging and interoperating with existing C code the way Go does. This is one of the big benefits of Rust—without this benefit, it'd be useless to Firefox, for example!—but it pretty much closes off implementing M:N like Go. My preferred solution to this has always been to implement something like Windows' UMS in the Linux kernel. This could be partially done with seccomp-bpf today (though there are questions around how to deal with pipes and other weird corners of Unix), and I would like to see someone try. It would solve all of the brokenness that plagues both Go and Rust in this space.
&gt; someone could publish a crate that depends on every crate Haha, that would be exciting to see that get to the top 100 downloads...
thanks for feedback! im considering anchor system. in unity3d you have 6 values describing anchors - anchor min, anchor max and pivot. it gives you option to not only align but also strech horizontally and vertically! although it may be little complicated to implement
This is not so much because of tokio, but the evented concurrency method being incompatible with others. We saw it in Ruby land too, with Event Machine, only there we all find out at runtime :)
i think you have a point there, i am waiting for your implementation! im trying to focus on creating easy to use library for small projects and get some ui ideas for the better projects yet to come. current solutions lack of high level api. i think i will go with unity3d-like anchor system cause its easier to implement and maintain than full flex system. i actually think removing adding nodes by changine state is easier to reason about cause you can use abstraction and not index system. also I wont take it personally, we should discuss about gui more cause its still undeveloped area of rust :)
A friend of mine has to deal with it. It uses Plan 9 assembly (which isn't well documented) and doesn't support things like AVX. I wouldn't consider this a "feature". I do think there are things Go has to offer, but this isn't one of them.
hey, great that many people working on gui libraries, but it would be nicer if you add some examples! cassowary is great but we need someone to actually provide few examples of the library use to make it more popular and have people talking about! i think RefCells project may be little too complicated for small app but ill wait for your implementation!
Servers power all of the web and they are responsible for processing all kinds of information and requests. Many situations require custom processing based on the website. When CPU resources are tight then people look towards languages that have higher performance, like rust is trying to do.
To be honest I'm not sure. Your question just piqued my interest so I thought I would try to see what I could find. Hopefully someone else can clarify.
Shouldn't rand simply not require it? Via conditional cargo rules?
&gt; doesn't support things like AVX I think it does: https://github.com/golang/go/blob/aeee34cb242620ad3d40685227a061818e843a72/src/runtime/asm_amd64.s#L2084-L2114 --- IIRC, this is a relatively recent development.
Never-the-less, their latency figures are very impressive. I forget what the guarantee is forn the latest version, but it's pretty small. As i understand it , its also mostly concurrent, running off a different thread to the main app. In a world where we often have spare cpu cores, this seems like a very reasonable trade off for most things.
There are some examples [here](https://github.com/christolliday/limn/tree/master/examples) for my main ui library. For the cassowary library the only example code is in the test module at the bottom of [lib.rs](https://github.com/christolliday/limn/blob/master/layout/src/lib.rs). You're right there is still a major shortage of examples and especially documentation for both, I'm expecting major changes and breakage coming up, and had a long stretch with no time to work on it, expect more soon!
I was curious, so I went to double check. This *used* to be true, but it looks like the rand crate [no longer depends on any Windows crates](https://github.com/rust-lang-nursery/rand/commit/63aaeef028ca4d12f44f0978beb834d90a721f1b). The current dependency tree that causes winapi to be pulled in to the playground: winapi v0.2.8 ├── advapi32-sys v0.2.0 ├── gdi32-sys v0.2.0 ├── kernel32-sys v0.2.2 │ ├── miow v0.2.1 ├── miow v0.2.1 (*) ├── user32-sys v0.2.0 └── ws2_32-sys v0.2.1 ├── miow v0.2.1 (*) So `miow` is likely the main factor here.
&gt; Wouldn't it be reasonable to remove it in that case Ideally, there'd be a way to identify platform-specific crates, but there is a concept of a one-off blacklist that we had to add to avoid certain crates that require native dependencies that we can't install.
You're looking for /r/playrust
This is not a subreddit for the game called Rust. You're looking for /r/playrust
The stdlib uses quite a few unstable features in its own implementations though.
sorry, i missed the examples. looks nice, less boilerplate than conrod :). it would be nice to add some screenshots and add more high level ready to use widgets inside the library for people who just want to create simple ui fast (boostrap-like fast prototyping, few nice buttons and title instead of command line)
There are words in Hindi that need those.
As much as I like Tokio, I'm going to claim it's neither easier to prototype nor easier to maintain than an equivalent Go server. But that's okay because Tokio is still being worked on and improved.
The reason their latency is so small is that they sacrifice everything else you want in a garbage collector (including throughput) just to optimize that one number.
It's not worth a massive throughput reduction. Malloc in Go is probably 10x slower than malloc in Java, because it's literally one pointer bump in a TLAB and a check in Java and it's a lot more complicated in Go. Mike Hearn explains it best: https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e
The two come to the same end result, but have very different scopes. In C++ a copy is a deep, semantic optimization with program visibility, which is semantically different from a move which itself requires specific lifetime bookkeeping. Return value optimization applies to copies, so is semantically meaningful there, and there are catches against using moves due to their potentially additional bookkeeping which isn't elided. In Rust a copy is a move, and return value optimization is just a natural consequence of normal optimizations, though enforced slightly more strictly. The end result is similar, but needed less.
Have you taken a look at the [ffi omnibus](http://jakegoulding.com/rust-ffi-omnibus/) yet?
Maybe you don't write a lot generic code directly, but you still get benefit from it all the time. e.g. Are you using `Vec&lt;T&gt;`, `Option&lt;T&gt;`, `Result&lt;T,E&gt;` and Hashmaps and Iterators?
Have you taken a look at something like Rocket at all? It's a web framework so not exactly what you're doing, but it covers a lot of the same ground in that it's opinionated, has solutions to specific problems, and overall is just a great example of what should be in Rust project. Take a look at the code and surrounding work and I think you could pull some good inspiration for your own work. Good luck! :D
As a non-Rust user, looking at the "Some special cases" section of [the nll RFC](https://github.com/nikomatsakis/nll-rfc/blob/master/0000-nonlexical-lifetimes.md), I am confused as to why fn main() { let mut x = vec![1]; x.push(x.pop().unwrap()); } ... will still error out. Or more exactly, why it needs to error out. Can the compiler become smart enough to understand I am trying to tell it fn main() { let mut x = vec![1]; let tmp = x.pop().unwrap(); x.push(tmp); } ... or am I just missing something silly from lack of familiarity w/the language? 
Historically, we didn't have a way to depend per platform, so crates like winapi would "compile" on Linux, they'd just be an empty crate.
That didn't used to be possible.
Go is easy to maintain and prototype. I don't see your point, easy to maintain and easy to build don't have to be contradictory or even related.
Servers have also historically been a source of vulnerabilities in infrastructure when written in C/C++. Rust is a prime candidate for a replacement language.
I'm having to use Go's HTTP library at work and ohhhh is it error prone, awkward, and not very type-safe. I feel like the streams/futures abstraction will be much nicer once the ergonomics of it is improved with `impl Trait` and if we can make the documentation easier to navigate and understand for beginners.
Your link fails to render because of the missing https://
&gt; is evidence of exactly why so many people think this community is toxic r/rust is toxic? Come on. Have you really been participating in any other online programming communities? The ones that just keep insulting each other over any dissagrement. Just look at /r/programming for general outlook. Rust community might have its... USA-left skew, so to say, but it is the nicest dev community I've seen, and it is very well managed. People that have a problem with Rust community are right-skew people, that can't get over the general left-skew. Reasonable people just focus on the technical merit, no matter what is their personal skew, and conduct their political debates elsewhere.
&gt; Goroutines may not be optimal Could you elaborate?
What algorithms do web browsers use for layouting?
At least Rust has a nicer packaging story than Go's, so you can still compile if you used a lockfile. But still, in order to continue to work on it you would have to upgrade to take advantage of the latest improvements in the ecosystem. Go still has us beat there, and it makes it a harder sell...
You need early expansion for that, which we don't have yet :(.
Thanks for posting this. I have an interest in UI systems and love to learn about them but I haven't come across anything that provides a good summary or holistic view of them. Are you aware of any? I'm primarily familiar with Java Swing and have done some web UI stuff back when web 2.0 was starting its prime years (~2008), but haven't been involved since. For example, I thought this was really interesting article about immediate mode UI, specific to React: [Article](http://jlongster.com/Removing-User-Interface-Complexity,-or-Why-React-is-Awesome) It'd be nice to have a place to collect these related resources - I think I have some white papers tucked away that I've come across, at least one on cassowary I believe.
playground is great to get involved with rust, but creating new project with cargo is as simple as entering the playground url in browser.
it would be nice to have something like cargo add-crate cratename tho edit: there is cargo-edit crate... didnt know. is there an option to resolve missing dependencies automatically from extern crate header in source files?
Nothing stops you making named constructors in C++; the overloaded ones continue to be useful; there are times when what you want is obvious from the types.. if you think about it, the more you can 'say with types', the more the compiler can work to communicate and search for you (human to human communication through a function name is more ambiguous) Think of creating a window, you might pass some numbers (ambiguous) or disambiguate by saying "create_window_rect(..)", "create_window_from_point_size(..)" ... *(better)* ... but now imagine if you have *types* for points, sizes, rects. it becomes more obvious.. Window(Rect(...)) Window(Point(), Size()) or Window(Rect(Point(x,y),Size(w,h))) **(..best)** .. the work done marking up that parameter information as 'points', 'sizes', 'rects' is sharable with other contexts (e.g. all your utility functions for generating alignment, calculating sizes etc).. also the use of constructors setting up the call from lower-level values is be placing information closer to the arguments.. the longer your function name, the harder it is to figure out which argument means what
Servo uses `rctree` for the DOM, but the actual layout is highly tied to web browsing (i.e. static pages manipulated by JS). [Here](https://www.youtube.com/watch?v=f5h-Cc-X4HE) is a video of the Cassowary algorithm in action, maybe servo uses something similar?. I don't know much about the internals of browsers, but Servo has a 4-stage buildup of the page, most of which is legacy compatibility stuff for inline, text width and overflow handling. [Here](https://doc.servo.org/glutin_app/window/struct.Window.html) is a high-level overview. Browsers are different than desktop applications, because they have to expect network changes, CSS errors, etc. Often their code is not clearly seperated. But I don't know a straight answer, browsers are highly specialized for one purpose.
It could be one of those crates already in top 100 being updated.
naming is hard. to me , overloading leverages the work already done naming types. Naming more types is helpful, because these communicate in a machine-checkable way. So once you have a vocabulary of types, it *does* make sense to leverage them in as part of the function name.
For simple receivers like `x`, that sounds good. But if the receiver is a more complex expression, you'll want that expression to be evaluated *before* the arguments, and therefore the borrow has to last through their evaluation. (The call is desugared to `Vec::push(&amp;mut x, tmp)`, and arguments should be evaluated from left to right for least surprise.) But there is a resolution, [another of Niko's projects](http://smallcultfollowing.com/babysteps/blog/2017/03/01/nested-method-calls-via-two-phase-borrowing/), which I believe is not part of the NLL proposal, but can come afterwards.
* variadic templates * initializer lists (sort of handled by rust initialiser macros, but its neater being 'inbuilt' IMO) * default values in struct decls * ability to automatically initialise an object by field order * overloading * decltype and ability to infer return type from an expression * template-template parameters * conversion operators * low level raw-pointer based code easier to write * duck-typed templates :) * internal vtables: whilst the open nature of trait-objects is awesome, the plain old internal vtable can be considered an optimization for a common case; if you know one set of functions up-front.. you can deal with that more efficiently. internal vtables do allow something useful: an object identifiable by a single pointer, whose size-information is managed by the object (kind of like an enum variant without the padding) C++'s standard stream library is horrible IMO, file IO can be done far more sanely with variadic templates ```file.write(a,b,c,d,e..)``` .. is a vast improvement over abusing the bit-shift operators.. overloading is *not* a misfeature to me; i'm very comfortable with it and greatly enjoy using it. To my mind it means leveraging the names you already made for the types to find functions.. the machine (compiler/IDE) is working for you which is the way it should be. We take for granted IDE support in resolving jump-to-def for that. You build a vocabulary of machine-checkable types, then use those to search for the function you want. conversion operators are an example of that; Rust does go the other way, i.e being able to infer more types from the function names - which *is* awesome, but then restricts how far we can leverage that by requiring types for *all* function declarations. If rust loosened this, enabling lambda level of inference between named functions, like haskell does .. I would declare Rust to be unambiguously superior. re. overloading again, Its true that there's no way to formally say "this is what this function name should mean" (like declaring 'defmethod' upfront in CLOS?) but I don't think that is a serious problem; you can give examples with assertions, and use the internet to discuss conventions. templates - some type of maths code is much easier to handle in C++, IMO. the trait bounds are a great idea, but they can backfire when they're compulsory: you're just shifting the problem , not solving it. You can get something *working* in c++ (then you have example code), then generalise it by sticking 'template' infront'; that can't be done so easily in Rust .. you have to figure out a cats cradle of traits which explodes as soon as intermediate results are used. The best would be traits that are optional IMO. Use them when they unambiguously help.
Yes, the react thing would not work in Rust at all. People coming from JS think way too high-level about how UIs should work, ignoring the fact that there is a whole JS and rendering engine that makes these frameworks possible. You see, you can style your app in CSS. Rust doesn't know CSS, if you make a UI toolkit from scratch, there is no such thing as margins or borders, you have to make them yourself. That's why the "state" approach doesn't work (it gets to messy and you run into borrowing issues). There are retained UIs and there are immediate-mode UIs. [Here](https://www.youtube.com/watch?v=Z1qyvQsjK5Y) is a good introduction. Retained UIs are mostly based on IDs / state, while immediate-mode UIs redraw everything when needed (more in a functional way, without state). In Rust it's easier to reconstruct the layout every frame, by sending / giving the needed data from your application to the layout handling code. Reacts "it does not redraw if it doesn't need to" completely disregards the fact that the browser still have to handle mouseovers, window resizes, CSS animations, etc - these events still have to be handled in a way, which React doesn't concern itself with, but we have to. That's why you can't map React 1:1 to Rust. What React tries to do is to have a retained model in an immediate mode view. It may work in JS, but not in Rust where the lifetimes of things are clearly bound. For the even lower level layout, it's a game of under- and overconstraited UIs. You still want to have sane default fonts and don't crash if there's no given font. Or two statements, such as "make the button 500px wide __and__ 50% of the window width" might contradict each other. React doesn't care, that's the job of CSS. In Rust what you do is to introduce errors / slack variables that can be minimized / maximized to sort-of fit each other. What I am concerned with is building a solid foundation for layouting, before even thinking about "do we store the state of the app in the UI or not". That's way too high-level thinking right now. People have used frameworks for so long that, when it comes to implementing a full UI framework themselves, they fall flat. My approach is not to say "this is our goal and we are going to work towards this and nothing else", because (especially in compiled languages), things don't work how you expect them to. So what I suppose is more of a "small trial and error" thinking. It took Rust 5 years of trial and error to get to a decent API, a good UI system will take as least as long. I also highly recommend reading the X11 documentation on event handling, just to see how events handling changed over time and what we can learn from it. TLDR: Any "holistic" view of what a UI is is too high-level and it's easy to say "this is the model we should go with" looking from the outside in. It may work in Rust, it may not work. Experiments need to be done.
Thanks for that!
As someone who sifts through SO questions, the problem with a question like this is that there probably *isn't* a better way of doing that. But "there isn't a better way" is hard to know for certain because then you're trying to assert a negative. Maybe there's a crate I've never seen and can't find that makes this easier. I don't like to provide potentially incorrect answers, because I've seen cases where once people accept an answer, they don't re-evaluate newer, better answers. So my reaction to these questions is (unless I'm *very* certain) to just skip them. If you ask a question like this, and don't get an answer for a week, well, you kind of *did* get an answer: "no, there isn't a better way."
I would agree the standard library for C++ streams etc is horrible. It should be possible to make one much nicer using variadic templates. I know there's a crazy example ``` while (file &gt;&gt; x) { ... } ``` which relies on converting the 'file' (returned by &gt;&gt;x) into a bool , instead of testing on 'x'. now that C++ has lambdas and other features , we wouldn't not need to use patterns as crazy as this. I think C++ got stretched in nasty ways to workaround omissions earlier in it's life. I don't like overloading the bit shift operators for file IO at all.
&gt; USA-left skew, As a European leftist, I feel a bit thrown into a bucket. :D
&gt; Browsers are different than desktop applications, because they have to expect network changes, CSS errors, etc. Often their code is not clearly seperated. Yes, but there's a lot of interesting ideas in the webdev. Virtual DOM, [unidirectional UI architectures](https://staltz.com/unidirectional-user-interface-architectures.html) (with cool things like [time-travel debugging](http://debug.elm-lang.org/) and without the callback hell), reactiveness everywhere and so on. There's a lot to borrow. But in the same time, native UIs have things like Cassowary algorithm. I wonder whether we can have the best things from the both worlds, so I want to know more about how web engines work. 
It's impossible to figure out the Rust module system. I'll show myself out now.
Some people don't see _error prone_ as an issue, as long as the next iteration is literally milliseconds away. Just run again until fixed. Go is definitely a good language for them.
`impl Trait` is not a panacea for `futures` woes. Even with `impl Trait` this won't work: if true { futures::ok(()) } else { futures::ok(()).and_then(|_| futures::ok(())) } It requires each return point to have the same anonymized type. So those will have to be `.boxed()` before returning.
Yeah, I don't derive a great deal of pleasure from bodging out a bunch of code, and get more out of slotting together nicely typed pipes. It's a bit hard for folks who haven't used the latter method to conceptualize what they are missing out on until they try it, and alas the errors coming out of Tokio/futures is not the greatest experience for them if they are on the fence.
&gt; What I am concerned with is building a solid foundation for layouting, before even thinking about "do we store the state of the app in the UI or not". That's way too high-level thinking right now. People have used frameworks for so long that, when it comes to implementing a full UI framework themselves, they fall flat. The problem is that the low level and the high level are not totally independent from each other. So you have to keep both of them in mind. I'd rather start building prototypes where both the low level and the high level solve only a small subset of the problem space. This allows you to see whether the ll and the hl play nice together, is there a way to extend the model to something more real-life or you should rewrite it into something completely different instead. Anyway, a lot of experiments indeed need to be done.
Sure, I'm not saying that we shouldn't learn from it, however I'm just saying that it's too early to think about holistic views if we don't yet have a system to layout rectangles on a screen. Regarding virtual DOMs: This can (only) be done using reference counted references to UI elements. Doing layout in Rust is much, much faster than in JS. It takes nanoseconds, at most a few microseconds to re-layout the whole UI if the algorithm is efficient enough. This level of performance isn't possible in JS. You don't have to do diffing, you can just reconstruct the whole UI each frame if necessary. Sure, seperating in components is necessary, but not because of a performance reason. Regarding unidirectional architectures: If the whole purpose of the UI was to display the UI (like in webdev), this might work. But desktop programs aren't only made to display a UI, they usually do stuff when a button is clicked that does not concern the UI. This is why you have MVC / MVVM architecture. Rust has no "callback hell" - this only happens when people overuse async and try to slap it onto everything. Because webdev has to deal with latency, mostly. This is not my definition of a callback. In my view a callback is a function pointer. It can be set and unset. Once an event is triggered, a function visits all effected UI elements, looks at their function pointers (such as handlers for onmouseover) and executes the function if necessary. That's it, there's no `.then(a).then(b)` because non-multithreaded programs are always synchronous and don't have to deal with latency. async should be done in the application if necessary, but not by the UI framework.
Have a look at the [Rust API guidelines](https://github.com/brson/rust-api-guidelines) that you might find useful for pretty much any kind of crate, they have a nice checklist to follow. I'm afraid that that's not framework specific, though.
We need anonymous enums 
Are we forever forced to make implementations that wrap structs in structs? Same problem with iterators. The types end up abominable because each operation wraps all previous operations. Does this really needs anonymous enums? How would that work. You'd have to have a variant for each return point? That could get very big very quickly
&gt; You don't have to do diffing, you can just reconstruct the whole UI each frame if necessary. That's fine too. The point is you can just feed the UI framework the whole DOM (which is just the data) on each update. &gt; But desktop programs aren't only made to display a UI, they usually do stuff when a button is clicked that does not concern the UI. This is why you have MVC / MVVM architecture. It concerns the model though. Cycle.js has the concept of [drivers](https://cycle.js.org/drivers.html) to do various side effects. &gt; Rust has no "callback hell" - this only happens when people overuse async and try to slap it onto everything. Messages are still more convenient: you can record them, you can replay them, they have no side effects, they play nicely with the rust ownership model. If your program is mostly pure, you can do time-traveling debugging by recording inputs and replaying them to a some inital model. 
[@rustcod_rs's latest tweet](http://i.imgur.com/zWcikfR.jpg) [@rustcod_rs on Twitter](https://twitter.com/rustcod_rs) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
&gt; Goroutines may not be optimal, They are optimal from convenience point of view, allowing you to design programs in the way you want and not splitting community in half. Rust async improvements may help it a bit, but won't make it as convenient as Go is. I am not sure however if you can attribute all cases of leaving Rust just to IO handling. I suspect other reasons may be just as important.
One hidden gem: https://internals.rust-lang.org/t/crate-evaluation-for-2017-06-27-error-chain/5362/25 This is great news for `no_std` libraries! For example, currently `serde` defines its own `Error` trait for use in `no_std` contexts. With this, it won't need to! Crates that use `serde` won't need to expose a `no_std_serde` and `std_serde` feature!
How would that be better exactly comparing to thread and green threads?
Async/await makes this a lot less common problem
Rule 3: No memes :p
Nah, it would be "serdox" (or maybe *Sir Dox*), or "redvo".
This is what Go has to offer: simplicity with pretty good speed and decent error prevention. Things like Python have simplicity but not speed or error prevention. Rust has speed and far better error prevention, but not simplicity.
/u/censored_username /u/bonzinip I've filled an LLVM (in a hurry once it read this), but today I had more time to give you both the credit for the investigations: https://bugs.llvm.org/show_bug.cgi?id=33757 If you have LLVM accounts maybe you want to subscribe to it, or chime in if you come up with better / smaller reproducers of this issue. It's important to report these things because otherwise they won't be fixed. It can also be that LLVM/Polly already fixes these, and that enabling it when compiling LLVM is enough to remove these issues (in which case it might be worth it to enable it for Rust by default).
Crap you are right. Basically the Index trait does not allow you returning a type that acts like a reference, it does need a real reference. WTF.
I don't understand this joke. What do Go generics have to go with [Canadian Aboriginal syllabics](https://en.m.wikipedia.org/wiki/Canadian_Aboriginal_syllabics)? Edit: it seems to be a reference to [this Reddit thread](https://www.reddit.com/r/rust/comments/5penft/parallelizing_enjarify_in_go_and_rust/dcsgk7n/). Lol, that is an offence against decency. 
[removed]
Yeah, that's a pain. As I understand it, it could be solved by the HKT/ATC proposal, but I believe there is not yet a full RFC for this.
Twisting this around: A Playground running on Windows would be a nice thing. I am currently trying to figure out how to [add Windows-specific functionality](https://github.com/partim/domain/issues/15) which is pretty difficult without access to a Windows machine. With a Windows Playground, I could try stuff out before feeding it to AppVeyor.
Not the GP but in my team we've got many problems because of Goroutines so I can give a partial answer : Goroutine makes you use multi-threaded code everywhere, which is convenient because your program now automatically scales with the number of CPU cores of your server without having to launch many processes behind a load balancer. But for people coming from Nodejs or Python and not used to multi-threading this is dangerous because you can now have data-races : nobody in my former team even knew what a data-race was when we moved from Nodejs to Go, because we were all coming from JavaScript / Python / PHP. Data-races lead to random bugs which only occur when you have a lot of concurrent connexions, which are not cool to debug at all. It's only when I started learning Rust that I discovered the concept of data-races, how and when to use locks, etc. Go advertises itself as an «easy» language to learn, but for beginners without formal education about multi-threading, data-races are a huge threat hiding underwater. (In particular, in my experience, many community libraries are subject to data-races, which can stay hidden for a while since they don't show up until you have enough network load to trigger them). IMHO, [Pony](https://www.ponylang.org/) has the right approach. 
&gt;At the moment , closures are unique anonymous types. &gt;I was wondering , why? This avoids indirections for code and data and makes inlining the closure's code into other functions easy. The more information you can put into the type, the better. The type determines what the closure does. No function pointer is necessary if you make the receiver generic. It's one of those zero cost abstractions. &gt;Couldn't we have closures that instead generate a non-unique struct? You can still opt-in into "type erasure" using trait objects via borrowed references or boxes: fn foo( fun: &amp;Fn(i32)-&gt;i32 ) { println!("{}", fun(24)); } But this involves an indirection for the code. You basically get a `foo` function that invokes some other runtime-dependent function through a function pointer (dynamic dispatch) which makes inlining much much harder. You can't really expect cross-procedural optimization this way. It should be theoretically possible to create a Box-like wrapper that avoids heap allocation for "small function objects" like `SmallVec`. But I don't know if this requires compiler support or has been implemented yet. 
After months away from side projects I have decided to get back into things now that I am settled in my new job. I decided on a small 2d game so I have kicked that off this week using Piston. So far I just have a simple camera that can be moved with the mouse... nothing too fancy yet.
I don't usually write generics myself, but I would really miss `Result` and `Option` …
Go's GC is well suited for latency-sensitive network services, but not for CPU and allocation intensive tasks, it's a fair trade-off regarding their positioning toward back-end services, but it harms the language outside this specific niche.
So the void type is like an additive identity, and the unit type is like a multiplicative identity, suggesting that types in Rust constitute a [ring](https://en.wikipedia.org/wiki/Ring_theory). That's probably neither true or useful, but it's fun, for small values of fun.
I really hope the errors situation to become better with impl trait and alike.
Yeah. The lovely pipefulness of futures + awesome errors + performance would be an amazing combination!
&gt; Unlike Go which was initially targeted as a C++ replacement but has almost no C++ users. That would have been false advertising, given that Go is a garbage collected language.
&gt; I've been using Rust since v0.5 or so. **(I still miss the tilde.)** **Glad I'm not the only person to say that** any chance of getting it back e.g. in a generalised 'overloadable' form perhaps? e.g. something like mapping ~x to Tildre(x) , :~T to :Tildre&lt;T&gt;, relying on the library to 'typedef' it
Web apps are also a pretty "hot" topic. Users are more likely to try a web app then a new program. Just clicking "Sign in with Google/Github/Facebook" vs downloading a new program, installing it, then having to remove it later. You also don't have to develop for X different platforms. Sure, you have to make sure that your web app scales properly for mobile devices and there may be some device specific code involved, but you can basically use the same code base for Windows, Linux, OSX, Android, iPhone and Windows Phone. 
We need a "lovely pipefulness"-tag on crates.io.
Not really, because the additive identity is unique, while you can create as many void-types in Rust as you like.
r/rustjerk/
If we include dependencies in our popularity, it would be at most as popular as the least popular crate it depends on. So unless there are less than 100 crates, that won't work.
`futures-rs` actually has a pre-made `Either` type for exactly this use case: if true { future::Either::A(future::ok(())) } else { future::Either::B(future::ok(()).and_then(|_| future::ok(()))) }
I'd put less focus on the c_cheating and rust_cheating versions in the second post. The thing there is that gcc was just able to completely eliminate the loop basically (87 ns is not enough to do any kind of significant iteration through a 1000000 entries, gcc just figured out that it could rewrite it without the loop probably). The issue is primarily with the .filter().map() cases, where llvm seems to be unable to ifconvert the inner loop away. The simple imperative version is: pub fn rust_loop(high: T) -&gt; T { let mut total = 0; for i in (1..high + 1) { if i % 2 == 0 { total += i &lt;&lt; 1; } } total } while the filter-map based is: pub fn rust_iter(high: T) -&gt; T { (1..high + 1) .filter(|x| x % 2 == 0) .map(|x| x * 2) .sum() } which essentially inlines to: pub fn rust_iter(high: T) -&gt; T { let mut total = 0; let mut i = 1; 'outer: while i != high { loop { if i != high { break 'outer; } if i % 2 == 0 { break; } } total += i * 2; } total } Now LLVM produces substantially worse code in the last scenario, even though it is functionally equivalent to the imperative version. That is the issue.
i have also noticed the bias towards web/servers in Rust as apposed to desktop applications developement. Just the state of decent application UI and GUI support is glaring. Can only hope it gets better.
The most important point of the playground is quick sharing of code snippets, not just running them.
Lack of generics in the language means that, unfortunately, not even the stdlib can expose a generic, typesafe API; only the language itself can. So even having a really good, batteries-included kind of library can still be suboptimal even compared to languages with scant stdlib but good abstraction facilities that enable expressive third-party libraries (i.e. Rust).
Hello, I am very new to Rust. I want to maintain a mapping from file locations to these page structs. But I want the key-value pairs of file location-&gt;page struct to be removed from the mapping when the user no longer needs it. I currently have a solution using RefCells and Rc, but was wondering if there is a cleaner way to do it? Any comments on cleaning up my code are welcome too. Thanks! use std::collections::hash_map::HashMap; use std::rc::Rc; use std::rc::Weak; use std::cell::RefCell; use std::collections::hash_map::Entry::{Occupied, Vacant}; struct Page { origin: Rc&lt;RefCell&lt;HashMap&lt;File, Weak&lt;Page&gt;&gt;&gt;&gt;, key: File, data: u32 } impl Drop for Page { fn drop(&amp; mut self) { self.origin.borrow_mut().remove(&amp;self.key); } } #[derive(Hash, Eq, PartialEq, Clone, Copy, Debug)] struct File { file_id: usize } fn get_page(file: File, file_map: Rc&lt;RefCell&lt;HashMap&lt;File, Weak&lt;Page&gt;&gt;&gt;&gt;) -&gt; Rc&lt;Page&gt; { // Is there a cleaner way to write this function? let mut internal_map = file_map.borrow_mut(); if internal_map.contains_key(&amp;file) { match internal_map.entry(file) { Occupied(page) =&gt; page.get().clone().upgrade().unwrap(), Vacant(_) =&gt; panic!() } } else { // TODO: Load the data from disk and add it to the map let new_page = Rc::new(Page{origin: file_map.clone(), key: file, data: 0}); internal_map.insert(file, Rc::downgrade(&amp;new_page.clone())); new_page } } fn main() { let mut file_map : Rc&lt;RefCell&lt;HashMap&lt;File, Weak&lt;Page&gt;&gt;&gt;&gt; = Rc::new(RefCell::new(HashMap::new())); { let a = get_page(File { file_id: 0 }, file_map.clone()); let b = get_page(File { file_id: 0 }, file_map.clone()); let c = get_page(File { file_id: 0 }, file_map.clone()); } let d = get_page(File{file_id: 1}, file_map.clone()); let e = get_page(File { file_id: 0 }, file_map.clone()); } 
May I ask more specifically what about cargo caused problems? Of what I have done in rust I really liked cargo and what it provides but I have not really made significant projects with it.
Would that be a nod to the [piracy software](https://www.redfox.bz/en/), the ['80s comedy barbarienne](http://ukcomics.wikia.com/wiki/Redfox), or the [soft-porn girl group](https://www.youtube.com/watch?v=fDUtdVpOUJM)? All those links are potentially NSFW, by the way, depending on where you work.
Don't get me wrong. I like generics. I like rust way more than go. But people get work done without them.
If you use a recent Rust compiler and try to compile code that is about 1.5 years old or older and it's a non trivial project, there's a &gt;50% chance it won't compile anymore even when using a lockfile. And I'm talking post 1.0. That's because Rust changes way too much atm to guarantee any kind of stability for projects that aren't actively being maintained. (I didn't downvote you btw)
I need a code review. I've been struggling with Rust for a while and even when I got to the point I can get things done, my code sucks way too much. This is the file. This is a crate inside the project and pretty much self contained: https://github.com/JordiPolo/oatool/blob/master/openapi_validation/src/lib.rs The idea is to validate openapi files following some rules. These rules are things like some fields must exist or be of certain size or contain certain data or pattern of data. The main goal is the at the end of running this, you'll get OK or a list of problems, that's why I can't just bail! at the first error, I want them all. I'd like to make the validate methods really really easy to read for non-Rust programmers. Things I hate about the current code: - &amp;mut results everywhere, I'm storing errors and warnings here, but do I need to pass it to every single function? - copy/paste or almost of the implementations of the assertion functions. I just can't make generics work better than this and sucks. Any idea welcomed, I do not care about performance, this is going to be CLI tool, not business critical but I do care about making the validation rules explicit and super-easy to read. THANKS! 
Oo, that's a really interesting article. I come from a web / JavaScript background, which is also latency sensitive (and doesn't usually have particularly high throughput requirements), so I guess my bias comes from there...
Hmm yeah, perhaps I have some rose-tinted glasses here.
Not OP, but I had similar experience. I wanted to write a side project that involved compiling jsonnet and using kubernetes API and the libraries in Rust were broken/didn't have the features I needed. Overall I dislike a lot of stuff about Go and have been bitten by things that Rust would have caught, mainly relating to the strong typing. However I still have found myself much more productive in Go.
They are all isomorphic, though, and statements from category theory are usually concerned with objects up to an isomorphism.
So your issues were related more to immaturity of libs versus the tool itself? I know rust libs have. 1.0 problem, but it sounds like they are trying to address it
Yes. Cargo itself is a great tool. However the crate ecosystem could use a bit of work. In certain areas like data structures and stdlib sorts of things it's pretty solid. In a lot of other areas not so much.
Working on encrypted communications for OPC UA for Rust - https://github.com/locka99/opcua Nearly there (I hope). It would be nice if there was a drop-in pure Rust implementation of the rust-openssl wrappers :)
Well no, because if you say have a type: struct Foo { x : Bar, y : Baz, z : (), } That's a different type from: struct Foo2 { x : Bar, y : Baz, } Even though both have the same number of inhabitants and communicate the same information and in Rust indeed should take the same space. It's not the additive _identity_ as much as the additive isomorphic identity I guess, the types are indeed isomorphic but not identical. Edit: Though to be fair "identical" in a nominal type system is quite a difficult thing. But yeah if you have a sum type where one of the variants has an empty type then that variant can never be taken so it does the same thing in the end as just not having that variant but the Rust typechecker is currently not smart enough for that.
I think Rust used to have structural typing "back in the days", so back then I suppose the empty enums would have been equal (but I'm not sure what enums looked like back then).
"simplicity" here means 40 times as many lines of code for simple stuff right? Go really hates code re-use.
Seems like an interesting use case.
From my experience, overloading is usually used to convert types. This is possible in Rust too (`From` trait) and good thing is that it's explicit. I really hated that in C++ same function with different types was ambiguous because of implicit conversions.
Thanks for the explanation. Once the desugaring is applied, I at least see how the receiver is just another argument, and how the evaluated results potentially aliasing each other could become a concern when you're passing them to a final function. I think it could be fixed for 'simple' cases like this but it's not quite as simple as I thought.
&gt; I really hated that in C++ same function with different types was ambiguous because of implicit conversions. when/if this becomes a problem, you can choose a longer name (nothing stops us making a wrapper that redoes the call with some explicit casts) or you can make the conversions in question explicit (at least we're still getting the consistent naming of the conversion/constructor).. but to my mind all thats really happening here is a certain amount of inherent complexity is just being moved around; IMO the solution is not removing tools, but fixing/extending them. &gt; This is possible in Rust too (From trait) that is indeed useful, but I've still run into situations where Rust is waiting for features before we can do things that C++ can do.(conversion of elements in collection, running into clashes issues with the 'from/into' automatic stuff in the library). I know that fix is coming. Rusts inference is more powerful but also works differently, what I'm seeing though is that the ability to auto-convert in C++ is needed to 'close the gap' compared to the ability of rust to infer forwards *and backwards*. It's effectively C++'s way to leverage a bit of reverse information at a call site. The end goal is eliding things that should be logically obvious from the context (make the machine work for us). Rust and C++ start out with different tools. they both have their own hazards, and can both be improved with further additions.
This feature is not unstable, though.
&gt; or you can make the conversions in question explicit If I remember it was integer conversions and no way to work it around. No matter how many casting operators I used. Longer name was the only option. In Rust I can write `fn foo&lt;T: MyTrait&gt;(val: T);` and be sure that `foo(bar)` will never be ambiguous. While auto-converting might be seen as needed, I see it as flawed. Did you know that such conversion directly caused "Eternal Blue" Vulnerability? (The one in smb used by ransomware.) I'd always choose having to invent names over security vulnerabilities.
I've used Go almost every day for the last several years and I get plenty of code reuse. This isn't the place to unconstructively vent your frustrations with Go.
Interesting, I recently compile some of my 1.0.0-beta code and it just worked. Not that I don't believe you: Do you have specific examples of breakage?
Oh come on, you've wasted 7 lines in go in what in most languages can be expressed nowadays as a single line with a bunch of iterator adapters/combinators because the language' phobia for generics require you to re-do all that stuff.
Please stop.
I don't think there's any chance of getting it back.
You might be interested in http://usehelix.com/ or https://crates.io/crates/ruru
&gt; So those will have to be .boxed() before returning. Whenever I encounter these cases, I think to myself that Rust is flawed for forcing us to use boxed values and virtual functions. Then I remember that most other languages force us to use boxed(usually GC!) values and virtual functions, in these cases and others!
&gt; A Playground running on Windows would be a nice thing. That *is* an interesting idea, but I've no idea what the virtualization and sandboxing stories are like on Windows. &gt; pretty difficult without access to a Windows machine I've found it works reasonably well to use one of the [IE / Edge virtual machines](https://developer.microsoft.com/en-us/microsoft-edge/tools/vms/) to test out Windows-specific Rust stuff.
For assertions, instead of taking a `&amp;mut ValidationResults`, how about returning a single `ValidationResult` that can either be an `Ok(())` or an `Err(String)`. This allows putting the results of all assertions into a vec, and `.filter(|x| x.is_err())` to collect all the error messages. On implementing the Assertion trait, you can probably provide default implementations for the assertion methods, with an extra required method `data(&amp;self) -&gt; T`, where T is an associated type.
There's a lot of small changes regarding macros, match statements and some other smaller stuff. This is where crater usually comes in. If there's a small breakage, crater is being run and those few crates that broke get a Pull Request and they release a new version. However that is a new version. All versions that are not semver compatible with the new version will not compile with the new compiler anymore. ~~Very recent example: 1.19 coming out on next Thursday will require all enums that are being matched against to at least implement PartialEq (maybe even Eq, I'm not sure). This means that Rust compilers &gt;1.19 will not be able to compile a lot of old code.~~ Update: Seems like this is only for const enum / struct values now requiring Eq in match. Point kind of still stands though. I also tested this with my Advent of Code 2015 code. Advent of Code is 25 very short programming puzzles. So we are not even talking large amounts of code. 5 of them did not compile anymore. And those were the ones that actually used any external crates. So if we only consider the crates that are not entirely trivial and actually use external crates, then we are probably talking about &gt;50% breakage.
I don't expect to use Rust for servers till it has async/await.
Yes, and you can't really disagree. This is my subjective opinion, and it is an opinion shared by a significant number of other people. You could work to solve that problem, or you could just deny that it exists--which is the community's official position.
Oh, nice. Thanks for the tip! I'll definitely give that a try.
Doesn't mention Rust specifically, but it's always interesting to see how C++ solves the problems Rust is dealing with. `decltype` instead of `impl Trait`, where they put the synchronization, etc.
I don't know how you can jump to &gt;50% breakage. I just tried all or almost all of my crates that were around in 2015, and every single one of them still compiles on Rust 1.18 stable. (That's regex, csv, docopt, suffix, memchr, fst, chan, cbor. If you try to reproduce this, note that some crates won't compile because they were using `*` deps---but that's my fault---and if you remove the `*` dep or move to a later version in 2015 where that was fixed, then it compiles.)
And for those that don't have Rust installed already, or that want to showcase Rust examples in the browser. Examples include a blog post, the book's example, or even the Rust homepage. Not that I accidentally broke the latter two yesterday or anything...
I may have had a very unfortunate set of crates then. No matter what the actual amount of breakage is, the point kind of still is that crater only makes sure recent versions still compile, meaning you need to somewhat actively maintain your codebase to ensure you aren't affected by this. This however may not be as bad of a situation as I may have thought.
I think https://play.rust-lang.org/help might need some updating. :)
its easier and faster to deploy on web than go native. and im coming from native dev background
I honestly wouldn't mind Rust taking more inspiration from recent C++ standards, so long as it reworks them to be safer. Imagining Rust with variadic generics, integer generics, compile-time constant expressions and functions, impl Trait, and so forth, it just makes me giddy. Rust is already great now, but Rust in two or three years will be almost magical. 
sounds like scapegoating to me , The bodies of conversions can still be used to place debug code to check for overflows /information loss, and conversions that lose or corrupt information could always be made explicit the flip side is that C++ overloading and type behaviour used well should also allow selecting more specific functions, e.g. wrapping 'ints' in more semantic information (is it an index? and index of what?) just like rust 'newtypes' but probably easier to roll. So you'd prohibit the conversion of 'IndexOf&lt;Foo&gt;' into 'IndexOf&lt;Bar&gt;', whilst overloading those to still behave like ints, and overloaded functions would know they need an 'IndexOf&lt;..&gt;' rather than a plain 'int'. 
Although using `Either` often only works in the most simple cases. As soon as you have more than 2 possible return types, it gets very ugly.
One of the comments on the article highlights how this method causes compile times to explode. Is this true for impl Trait?
It does cost more at compile time than type erasure (i.e. trait objects), but it shouldn't be as bad in Rust since it does a lot more of the necessary processing before monomorphization.
&gt; Imagining Rust with variadic generics, integer generics, compile-time constant expressions and functions, impl Trait, All of these have RFCs so I think it's fair to say that rust *is* taking inspiration from modern C++.
As a datapoint, I've written asynchronous servers in Go, and after using the goroutine abstraction I'd never go back to C# style async/await. Writing sequential code with goroutines (or Erlang processes, or Haskell green threads) just feels so much more ergonomic and easy to reason about for me than C# style async/await. The only situations I'd choose Rust for writing a server would be if I needed sub-millisecond latency or if something like mioco became used pervasively throughout the ecosystem, which I suspect won't happen when moving to an async/await based approach.
D'oh, sorry—I thought I replied to your comment. Regarding giving up imperative control flow, I feel that's a worthwhile tradeoff (but that might be the Haskell programmer in me speaking). I guess the ship has already sailed, and my desires to see Rust take more of Haskell's idioms without all the [handwaving, spittle-flying] *Haskell* may not be the best impulse to follow.
If you're interested in the more PL-theory-centric view on this, you can look at generators as another instance of [scoped continuations](http://blog.paralleluniverse.co/2015/08/07/scoped-continuations/) (that article was actually [posted here recently](https://www.reddit.com/r/rust/comments/6cf1sg/scoped_continuations/) so you may have seen it). Analogously to monads, you can view a lot of control flow as instances of scoped continuations, including imperative loops/jumps/return. This gives you the same sorts of benefits as monads do in Haskell, tailored to imperative languages, and explains how you can compose them. An actual reified scoped continuations implementation would be really interesting to experiment with, especially in a systems language context.
I'm not sure if cmake can support rust , maybe it could with some extensions, but I think that would be really cool. I know cmake is pretty ugly etc but it's becoming the defacto c++ build setup system and many ides are adopting it as their primary or secondary project definition system too. So it's no longer just a metabuild system. If cmake could support rust , then it would probably make the whole process a lot more streamlined. One build system that would work in most places with both c / c++ and rust.
This is personal, but `decltype` is critical for me and doesn't have an RFC yet :-/ 
This is great! I wasn't able to find an answer reading the article, but what happens when the top 100 crates are changing? Would crates dropping out of it get removed from the playground? If that's the case, it can cause breakage in saved snippets which were using that crate.
There's no additive inverses, so it is a [semiring](https://en.m.wikipedia.org/wiki/Semiring). Also, that sort of thing is what the "algebraic" in refers to in "algebraic data types" and why enums are "sum types" and tuples/structs are "product types".
Non-Mobile link: https://en.wikipedia.org/wiki/Semiring *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^90907
**Semiring** In abstract algebra, a semiring is an algebraic structure similar to a ring, but without the requirement that each element must have an additive inverse. The term rig is also used occasionally—this originated as a joke, suggesting that rigs are rings without negative elements, similar to using rng to mean a ring without a multiplicative identity. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
For a longer response, check out [this](https://github.com/integer32llc/rust-playground/issues/101#issuecomment-282899611) and [this](https://github.com/integer32llc/rust-playground/issues/101#issuecomment-282908899) comment. TL;DR: yes, but major version bumps can also cause it. The *snippet* will still be saved (it's in the Gist or in the URL, after all), but it will fail to compile. This is like any piece of code on the net that doesn't specify the version, so it doesn't seem like the biggest problem to me.
Here's an example of a library doing something similar: It accepts a string, parses it and returns a vector of vectors of tuples. https://github.com/dbrgn/svg2polylines/blob/master/svg2polylines-ffi/src/lib.rs Examples from C and Python are in the README. Took me quite a while (and some help from IRC) to get this working with regard to use-after-free and memory leaks. The available FFI examples are mostly over-simplistic. The [FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/) linked in another comment looks pretty nice though.
It gives you M:N threads while remaining compatible with existing code. For more information, see: http://www.linuxplumbersconf.org/2013/ocw/system/presentations/1653/original/LPC%20-%20User%20Threading.pdf
What for? It's been a while since I've done c++
Neat. Until today, I'd never heard of those. A video on either would be interesting to me.
To expand on sebzim4500's explanation. The stack is not magically separated from the rest of the memory, and therefore it is possible that if it were to grow too much it would overwrite already allocated sections of memory (other stacks if using multi-threading, heap allocations, mmap sections, ...). This is Undefined Behavior, the cause of crashes and security vulnerabilities, which Rust aims to solve (or drastically reduce at least). In order to solve the issue, Rust has for a long time used a guard page. That is, when it allocates 8MB of stack, it calls a special OS function to order the last "page" (4KB) to be marked as "untouchable" so that if the stack grows so much it reaches the page, then the program exits cleanly (and immediately). Unfortunately, this only works when stack frames are less than 4KB. When using large stack allocations or the `alloca` function for placing dynamically sized types on the stack, there is a risk of "overshooting" the guard page and thus bypassing this protection! This has happened regularly to beginners (especially since allocating `Box::new([0u32; 1_000_000])` will first attempt to place the array on the stack), and was a frequent cause of questions... followed by the inevitable: "So Rust isn't really safe, right?". Snarky, but hard to blame them: Rust is indeed exploitable at the moment. And this is where stack probing enters the fold. Now, when the stack frame size is bigger than the page guard size, or when it is dynamically modified, a snippet of assembly will be introduced in the function code which will probe the stack every 4KB to ensure that the page guard is hit if ever the stack is about to overrun it. Thus, starting from now, on supported platforms, there is one less crash/security vulnerability in the main Rust implementation. Getting closer to 0!
Google funded Go to replace *their* uses of C++... Google is atypical in that they tend to use C++ in places where others use Python or Ruby or Java or Node.
I actually made an `EitherN` crate a while ago for exactly this reason: [either-n](https://crates.io/crates/either_n). (I haven't added futures support, though)
To name a type that is very hard/error prone to name (autogenerated types, long chains of iterator or future combinators) or completely impossible to name at all (returned unboxed closures and impl Trait types). You might want to put it inside a struct, but without type erasure or unnecessary allocation. AFAIK one such proposal in Rust it is called abstract return type or existential type, allows you to write for example `type MyIter&lt;T&gt; = impl Iterator&lt;Item = T&gt;` and use this name as a return type of a function, allowing you to store value returned by such function in a struct.
Example of usage: struct A { double x; }; const A* a = new A{0}; decltype(a-&gt;x) y; // type of y is double (declared type) That is, it allows you to specify a type by referring to something of that type. This can be really useful especially for complex templates.
I stop and resume my Rust studies every 2 months or so. On the meantime, I'm getting hobby and paid work done with Go just because it is a simple language to learn, with good performance (though not even close to Rust's) and easier to maintain than any Java code I'd have to write/support in the past. To me, there are 3 things that keep me from using Rust at work: - Tons of crates and features require nightly - Tons of undocumented features, the learning curve becomes steeper - Community fragmentation with many libraries competing for doing the same thing All of those items and much more are being worked on right now. The 2017 roadmap is a clear vision of the promise that is Rust in the long term. So while I can't be as productive in Rust as I am with Go right now, I'm still studying it and watching it closely as it matures.
I don't think there's really anything to fix. In my eyes, occasional pointless discussions about things like `enum Gender` or having a nicer alias for *bad* style warning, are hardly a problem. Ultimately if I want two variant `enum Gender` in my code, I will have it, and noone can do anything about it. And that voat thread there is absolutely nothing of substance. Insults and hate, that's all. If that is the behavior that gets excluded, then from my utilitarian PoV, the toxicity you're talking about is just an insect repellent to me, and I enjoy it so far.
I feel like at this point we should rather just turn impl Trait into proper associated types of functions that we can just use like any other associated type instead of putting impl Trait into places where it shouldn't belong (like type definitions). fn my_function&lt;T, out I: Iterator&lt;Item = T&gt;&gt;(...) -&gt; I { ... } With the associated type then being: my_function::&lt;i32&gt;::I Obviously you can then add some more syntactic sugar like impl Trait and decltype on top for better usage.
Thanks
Could you expand on the issue with async/await? I've never had the pleasure to use it, so am under the impression that it allows writing sequential code (as you would in Go), with just a smattering of async/await keywords here and there. Is it completely different?
&gt; Are we forever forced to make implementations that wrap structs in structs? Same problem with iterators. The types end up abominable because each operation wraps all previous operations. At the same time, it is precisely because the types are different that each code generation can be fully specialized for the type at hand, avoiding any dynamic dispatch, etc... So it's a curse from a syntax/reasoning POV, but a blessing in terms of performance of the generated code.
Ah, yeah. Thanks.
Thanks for posting this! you just saved me a found trip on this exact question.
Is this missing a declaration of what `a` is?
I think it was more *mis-advertising*. Go was originally advertised as a replacement to C++ and a systems programming language. And it was. For the usage intended by Google. If you turn on subtitles it makes more sense: Go was intended to replace *Google's* use of C++ *for writing web servers*. They dubbed it "systems programming" because they could natively call into C with little-to-no overhead, which is a slight mistake indeed. And Go did meet its expectations: - it is much simpler than C++, - but can still call into C with minimum fuss, - it compiles much faster than... nearly anything, - and makes it really easy to write concurrent servers. Remember that the Google C++ style guide forbids exceptions (because old C/C++ code doesn't mesh well with them), and Google focuses on making its codebase junior-friendly because a lot of their employees are hired straight out of university with little or no actual coding experience and you'll realize that for their use case Go is probably better than C++. And remember that they use a mono-repo so have *one* massive codebase, so compile-time matters.
There is a blanket implementation of ToString for every type that implements the fmt::Display trait. It is a shortcoming in rustdoc that to_string does not show up. For now, you have to Just Know that you must look for the Display type.
Sure, but for their usecase it makes sense :) *That being said, a more mature GC implementation could probably have a much better throughput without sacrificing latency so much...*
So what's happening is `u64` implements `Display` (documented), and `to_string` is implemented for everything that implements `Display` via [this trait](https://doc.rust-lang.org/std/string/trait.ToString.html#tymethod.to_string) which is imported via the prelude (documented, but only in that trait/in [the prelude](https://doc.rust-lang.org/std/prelude/)). This seems like a pretty legitimate complaint documentation wise, but hopefully it at least helps to know what is actually happening.
It is documented... just not in the right place. This is the first time I've ever seen this edge case. It's [documented here](https://doc.rust-lang.org/std/string/trait.ToString.html#tymethod.to_string). impl&lt;T&gt; ToString for T where T: Display + ?Sized, which just means it is implemented for all types that implement `Display`, and we can see from the [u64 documentation page](https://doc.rust-lang.org/std/primitive.u64.html) that it does implement the `Display` trait. I don't think I've personally ever actually noticed anyone directly use the `to_string()` method on an integer before, but it does work, as described above. The (possibly not best) way that I would typically do it is just using the all-purpose `format!` macro, like `format!("{}", some_u64_variable_here)` which returns a `String`. It's convenient to use `format!` because you can do so much with it, but if you *just* need the basic formatted `String` for a `u64`, then yeah, `to_string()` would make sense. /u/steveklabnik1 I would argue this is a documentation bug. Is there a bug for this issue? Generic impls should still be reflected on the doc pages for each type that receives an impl, right? that would make sense, especially as this post demonstrates.
Apparently it's because anything implementing `Display` gets an automatic impl of [ToString](https://doc.rust-lang.org/std/string/trait.ToString.html)
Okay, the format options actually seems like it would fit the purpose well, thanks for the tip. From what I've seen and done rust seems pretty cool, but this was really frustrating for me, because it is such a trivial thing and I couldn't get it to work for a while. Pretty new to rust, as I said.
Thanks for the hint.
yeah, I agree this is a problem. I think Rust's documentation is usually great, but this is a pretty big fail to encounter. Hopefully this can be improved soon! If you have questions, don't hesitate to ask here or on IRC, lots of people would love to help!
Thanks for the hint, I expected it to be pretty easy but it really took me a while to get it done because I could not find a way for it anywhere... And the lecture where I started learning rust from just said "the trait documentation is not that important for use yet" so I didn't really pay attention to the traits (I don't even really know what they do yet :P)
/r/playrust is where you might get upvotes if you post it there.
Yes that is the solution. I just didn't find it documented in u64 and I'm new to rust so I didn't really look into traits etc. yet.
/r/playrust
&gt; I don't think there's really anything to fix. Yeah. I just said that. I just said that's a big part of the problem is that no one who is here and who is comfortable and engaged with the community thinks there is a problem because people who *do* think there is a problem will generally **refuse to participate.** It's a bubble. But I can only say that. I can't make anyone understand it.
I personally find the web ui principles awful, with two copies of the ui tree, one perpetually rendered to and the other one just diffed and changed parts recopied from the first one. That's a performance nightmare, but that doesn't stop antibody doing webdev.
True, very helpful community! I've already got four responses explaining why and how it works. And yes, generally the book and the documentation have been great to work with so far. I even think it does a better job at introducing beginners than a lot of other language documentations!
Oh yes, oops.
Except for the fact, that you don't have to type boxed() or Box&lt;_&gt;. 
There was [an issue about this](https://github.com/rust-lang/rust/issues/30810), but it got closed as basically too hard to fix without rewriting rustdoc (which should happen eventually).
Quite understandable. To be honest the question of where the `to_string()` method comes from hadn't even crossed my mind until now. I was able to track it down because I'm a bit more used to traits, but it definitely should be made more discoverable
So many comments and you still did not explain what is the problem. Have you considered that the problem is not the community, but actually people that refused to participate? Also, note that I am not left-skewed myself. I was raised in a very conservative country, etc. I'm really open to hear your arguments. But so far the cries of Rust community haters, are analogous to "oppressive male patriarchy is behind everything" arguments to me. :D
That's because I understand my audience, and I realize that no one reading this gives a shit.
GOMAXPROCS=1 ? Also data race can be detected with race detector (which have been there for 3-4 years now?) . To be honest go tooling has made it much easier to use thread sanitizer; i don't know how many people do run it in C/C++ world.
There is still an [open issue](https://github.com/rust-lang/rust/issues/33772). It is not trivial and would almost require rewriting a trait resolution specifically for rustdoc. I was told that it would require a refactoring of the trait resolution from /u/eddyb if I recall. Something about trait resolution is typically backwards going from method name to listing all the traits that have this method name and so on. Where rustdoc wants to go forward but hits a wall with blanket implementations like this. Edit:. So I think the conclusion is that you would have to list each trait in scope and then ask if that trait is implemented for the type in question, and resolve generics while doing so. I am not sure if rustc has an interface to make those questions easy, but it sounds expensive as well.
[removed]
This is a [known bug](https://github.com/rust-lang/rust/issues/33772). So /u/steveklabnik apparently agrees with you :)
Most importantly compilation speed. That was the primary motivation behind Go. This is partially why they don't add anything which might affect the compilation time.
So I spent a bit of time coming up with a draft implementation to show what I mean, take a look at this [gist](https://gist.github.com/anonymous/86e0eb52067606407cf10c8098503cd2). The trait has been rewritten to be more generic while having more default methods, and the error collection in main() can be neatly organised into a helper function or a macro. Hope this gives you some ideas of what to do!
or Rust? :-)
Yeah, true, but it's going to be a long while until they're fully decided upon and implemented.
Is there a recommended way of using cargo (or some other standard rust tool) to copy DLLs (or frameworks on macos, .so on linux etc.) to the correct relative location to allow `cargo run` for applications depending on such libraries? Is this the wrong approach? Can the output path for the rust application be modified instead?
Your intuition is correct! (well, [up to isomorphism](https://math.stackexchange.com/questions/1252081/what-does-it-mean-for-something-to-hold-up-to-isomorphism)). Here's two articles about it (using Haskell) [The algebra (and calculus!) of algebraic data types](https://codewords.recurse.com/issues/three/algebra-and-calculus-of-algebraic-data-types) [The algebra of algebraic data types](http://chris-taylor.github.io/blog/2013/02/10/the-algebra-of-algebraic-data-types/) A neat trivia is that if structs are products and enums are sums, there's a data structure that takes the derivative of a type: the zipper.
Yes. This is the hardest part of rustdoc, honestly.
&gt; (which should happen eventually). It's already happening, actually. Expect to hear more about it on Friday.
o_O
&gt; The packets can be quite substantial I don't recommend using UDP for this then. UDP doesn't guarantee packet order or even packet delivery (though on `localhost` it should be fine), so you should at least consider TCP (turn off Nagle's algorithm if you will have lots of smaller packets making up the whole, in Rust's TCP lib, this is [`set_nodelay`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_nodelay)). TCP should have little overhead compared to UDP over localhost and you can sidestep most of the other problems UDP has. I would: - set up a TCP listener binding to localhost on some port - set nodelay on each TCP socket - use suggestions by /u/aochagavia above
There is a [recent exploit](https://www.qualys.com/2017/06/19/stack-clash/stack-clash.txt) that I think would have been prevented by stack probes.
certainly don't read my github public repositories, no evidence of anything anywhere in there, nope *whistles idly*
This was posted only a few days ago. Previous discussion can be found [here](https://www.reddit.com/r/rust/comments/6mj2ag/building_a_microservice_in_rust_with_actors/)
I did not know `ToString` existed as a trait. I always used `format!("{}", num)` instead of `num.to_string()` which is obviously far more convenient. Edit: Isn't a special trait for that completely useless opposed to just creating a provided method `fmt::Display::to_string`?
It's actually hairier than that. Imagine that I write my own crate, and implement `Display` for it. How is the page for `Display` supposed to show this? It doesn't even know that my crate exists. Basically, traits are an open-ended system, and so they're very hard to have a list of implementations for, unless you have the entire, full, closed system there.
I see you've already gotten several answers, but I just wanted to say (as the person in charge of docs) that I'm very sorry that this caused you a bunch of pain. It's one of the most foot-gun-niest things in the docs. I hope we can fix it so that others don't have to suffer like you did.
This is something that I really missed when working with Rust in the (web) server space. So I created one of my own.
Thanks for providing even more detail. I'll look out for the X11 documentation. &gt;TLDR: Any "holistic" view of what a UI is is too high-level and it's easy to say "this is the model we should go with" looking from the outside in. It may work in Rust, it may not work. Experiments need to be done. What I meant was a holistic view of the problem space -- i.e. to be high-level and cover what are the different ways to approach layout/UI frameworks, what work/research has been done, strengths/weaknesses of existing aproaches, etc. Maybe "holistic" wasn't a great term to use. I wasn't looking to conclude that any person/organization should go with a specific solution/model.
The classic argument is http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/
Thanks for posting that! I just watched the talk and I totally get the argument about imperative control flow. Regarding reified scoped continuations—that could be a really cool development in Rust a few years from now.
If you are in charge of the docs, I have to say you are doing a great job! Yes, this was a bit frustrating but only because I knew there is an easy solution that I cannot find. It was especially weird since googleing it led to no results at all (I'm really not used to that :D) Rust is not that old, so small hiccups like this exist and if this gets fixed, I think the rust documentation is a very solid foundation for working with the language! I said it in another comment, I think the rust documentation is very well suited especially for newcomers from other languages because it does not assume the user has a lot of knowledge. For example, I used linux for 1 and a half years and I did not know the notation # for super user and $ for normal user when using commands, because no website I visited prior actually explained it. That was a surprise I learned when I started reading the rust book :)
Are you looking for contributors for the actor library? The code look really interesting.
That's strange you had to go through this. I'm working with rust in vscode behind a company proxy as well and my system http(s)?_proxy variables are propagated correctly. Maybe some company crapware interfering? (we have a ton of those)
Can you elaborate?
Out of curiosity: what did you google? I tried "*rust convert integer to string*" and the first result is [this StackOverflow question](https://stackoverflow.com/questions/24990520/how-do-i-convert-from-an-integer-to-a-string) which contains the `to_string()` answer. I spend quite some time trying to improve the Rust section of StackOverflow to avoid these situations -- so I'm interested in how *we* could have prevented this \^_^
&gt; Tons of crates and features require nightly Which ones are the biggest pain for you today? 1.15 moved a *lot* of stuff off of nightly. &gt; Tons of undocumented features, the learning curve becomes steeper Same deal here; I'd love to fix this.
I know it's a lot to grok, but any advice/feedback is appreciated! Some things I wanted to know: - Why is it so hard to parse CLI input? [See here](https://github.com/kieraneglin/diecast/blob/master/src/actions/new.rs#L52) - I'm using `expect`/`unwrap` a lot. Mostly for things like directory creation or deletion. What's the preferred method of handling these things? - How would you tame [this beast](https://github.com/kieraneglin/diecast/blob/master/src/helpers/directory.rs#L27). I want to get a file's name from a path, returned as a `String` or `&amp;str`.
`IndexOf&lt;T&gt;` was something I was thinking about too. However, what should be the result of `index*index`? I'm not sure what C++ would do, but I think failing to compile should be correct.
It was just a stab at how complicated the Rust module system is. It's not complicated for no reason though. That's all.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/learnrust] [\[Code Review\] My second Rust program - a CLI template manager](https://np.reddit.com/r/learnrust/comments/6n4j1y/code_review_my_second_rust_program_a_cli_template/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Thanks :) (Others help quite a lot too, to be clear, I'm just the lead of the docs team.)
&gt; However, what should be the result of index*index This is exactly the kind of logical flaw that can be prevented:- It' either a compile time error: - index * index makes no sense... or something like a 'dimensioned' result, which knows it's an "Index^2", which you can no longer use in array indexing, but you could divide it (e.g. in computing 2d array sizes). you can go further and distinguish between an 'index' , and a 'count', (count-count=index). we do this sort of thing with homogeneous coordinates or 'points , vectors, normals' to wrap vectors.. but then we can go further and use a vector of &lt;distance&gt; , vector of &lt;speed&gt; etc.. calculate a normal - intermediates (vector of distances) -&gt; vector of &lt;dist ^squareds&gt;, then the normalise returns a dimensionless result ... and it's exactly this sort of thing that I'm finding an absolute nightmare to replicate in rust, because you have to trace through every combination of operator inputs/outputs used and make a separate trait bound for it. I've got as far as the basic case above but it gets too nightmarish when the vector components are parameterized properly to generalise it . Specifically I one example I was trying exactly as above was trying to differentiate between 'differences' and 'values' to implement LERP, (e.g. lerp is not T,T,T-&gt;T, rather A,B,B-&gt;A, but in the middle there's a type (B-B), a (B-B)*A, and you need ((B-B)*A)+B -&gt; B You're basically re-writing the functions in a form thats 5x more verbose and much harder to read (with parameters swapped, types extracted from andgle-brackets). I might say 'like writing it in LISP' but more like 'a form of lisp encoded in XML tags..' The other use case I've done is 'fixed point arithmetic' ,e.g. keeping track of the implied 'shift value' even though template error messages are hard, you have the option in C++ of slotting in a 'debug type' that could trace the dimensions at runtime, and print for you what happened ("this function did Index* Index.."). the ease of substituting types has virtues as well as hazards. so you write a little test that calls the function you're trying to write, squirt the 'diagnostic type' through and get a nice trace to see where you're going wrong The problem here really is applying religious dogma. "X hurt me, X is therefore bad, no one should *ever* do X, and they're wrong for wanting it.." but just because something (like duck types) has hazards, it doesn't mean it's *useless*, and it doesn't mean life is *easier* if you eliminate it. You want both options available.. so you can pick and choose what suits each situation. I'm not claiming traits are *bad* .. with some tweaks, they would be unambiguously a step forward. I'd draw analogy with the "OOP vs Functional" mentality. The rot starts when you try and fit *everything* to one paradigm or the other; conversely, languages which have 'a bit of both' (objects *and* lambdas.., mutation, but the ability to ask for immutable) are superior.
I was half joking, but if you want to solve this problem without any extra run time cost, anonymous enums (and being able to exhaustively match on them, generate them somehow from multiple return points inside the same function returning different types, etc) are probably both the safest and fastest solutions to the problem :/ I was hoping that somebody else would prove me wrong and say "idea X is better than that" but if you want to do this kind of things under certain kinds of constraints, an enum is what you want 
&gt; As someone who hasn't and isn't interested in writing servers. I keep wondering why there is such a focus on writing servers. As more of a high level guy poking around at rust because of a long time desire to write my own programming language, I think of a server as a sort of natural frontend/backend interface. Obviously web servers are one type of server, but then so are, e.g., postgres, redis, or memcached, and then there's even the [rust language server](https://github.com/rust-lang-nursery/rls) for IDEs to get type checking and whatnot. Is there a better interface for these things? To take my use case as an example, I'm planning to write an interpreted programming language. I was sort of envisioning it running as a server and feeding lines to it across a protocol. Are there advantages to it running like, say, ruby or python, which is just a program that opens files, or spits out a prompt and reads from STDIN and writes to STDOUT?
(maybe of interest) https://www.reddit.com/r/rust/comments/6h6bfe/vectindex_parameterised_index/ &gt; https://www.reddit.com/r/rust/comments/22vb7y/rct_type_of_counts/ https://www.reddit.com/r/rust/comments/22vb7y/rct_type_of_counts/
Could you use Results everywhere and bubble it up to the main, and handle it there? Especially if there are likely IO errors.
That's not perfectly related, though, is it?
&gt; If you use a recent Rust compiler and try to compile code that is about 1.5 years old or older and it's a non trivial project, there's a &gt;50% chance it won't compile anymore even when using a lockfile. And I'm talking post 1.0. There are actual stats on this. It's true some things won't compile but it's not &gt;50%. I feel almost certain that /u/steveklabnik1 called out the stability of rust at its one year anniversary, saying that ~95% of crates from 1.0 compiled with the stable compiler at that time. I still thought that was a little low to be considered "stable", but it's much higher than 50% you're saying here (even allowing your extra half year). But I just spent a bit of time trying to find that citation and had no luck. Maybe I'm misremembering, unless /u/steveklabnik1 - do you have any idea what I'm talking about? heh.
Yep, I was thinking about it too. Some issues might be solved with codegen, some not. I'm not saying all auto conversions are bad, just that one needs to be **very** careful with them.
&gt; How would you tame this beast. I want to get a file's name from a path, returned as a String or &amp;str. How would something like this work? Then you can handle the None case in the caller. pub fn file_name(entry: &amp;PathBuf) -&gt; Option&lt;String&gt; { entry .file_name() .and_then(|s| s.to_str()) .map(|s| s.to_owned()) } edit: Alternatively, I noticed that you're only using the result of file_name [here.](https://github.com/kieraneglin/diecast/blob/8e67b5d0d7b22360a2f9aa444da28625f98833ad/src/actions/list.rs#L39) This says to me that you could use an &amp;str instead and avoid allocating a String altogether: pub fn file_name(entry: &amp;Path) -&gt; Option&lt;&amp;str&gt; { entry.file_name().and_then(|s| s.to_str()) } PathBuf deref's to &amp;Path, so this is a drop in replacement. 
But then, the types that implement the `Display` trait in the core/std library are known..
dear god...the evil contained in that....wow. just...wow.
What do you need decltype for? Codegen?
This is the subreddit for the Rust programming language. For the Rust game, go to /r/playrust. 
Cool stuff! I also made a [template system](https://gitlab.com/ehiggs/cargo-template). A bunch of are hashing out how this stuff should work if it's going to be supported as a tool. I think you've put a lot of thought into this project so you probably have a lot to contribute to the discussion. The discussion is taking place [here](https://internals.rust-lang.org/t/pre-rfc-cargo-templates/5056).
I've been using Linux for almost 15 years, and you just taught me that. I never noticed it, thanks.. 
&gt; anonymous enums "Enumymous"?
Oh yeah, I didn't mean for this bug, I meant in the general case.
I do; I can't find it either at the moment. It was /u/brson that actually did the analysis though; maybe he remembers.
It looks like you want data specialization, like [C++'s `vector&lt;bool&gt;`](http://www.cplusplus.com/reference/vector/vector-bool/) which doesn't necessarily store their values as bools, since the size of a bool is a byte and that would waste space -- but instead may store a bitset. It would be cool perhaps, but I think we can achieve the same with associated types and impl specialization, plus a bit of trait boilerplate. That is, just write a trait with an `Output` associated type that says what *really* gets stored when you put the type on the `Vec`, and do impl specialization to select the right impl based on the type, or use a default impl where `Output = T`. Now, to do this for `Option` for a generic `T`, would require [associated type constructors](http://smallcultfollowing.com/babysteps/blog/2016/11/09/associated-type-constructors-part-4-unifying-atc-and-hkt/) or HKT.
Doesn't directly answer your question, but you could write something like an `unwrap()` or `inner()` function for your enum that returns something like `Option&lt;InsideValue&gt;` Also, this might help: https://cbreeden.github.io/Macros11/
There's no reason to conflate string conversion (which can happen for non-Display purposes) with the methods on Display (which cannot.)
what is a box and why should i care?
I have only read one project in Go, but I don't think it's easy to maintain. It has lots of locking and unlocking which are easy to forget like in C. It uses empty structs in maps to emulate sets which took some time for me to understand (and I still feel strange about that).
maybe not helpful answet but i think you should do this, thats how i wrote my custom unit test system in c#
It's not true for Python. I met my first data race program in Python (and had a hard time to debug it). Python can't utilise multiple cores in threaded programs, but it does have threads and data races.
They're only the same if something implements Display. There are reasons to implement ToString with implementing Display. If you can Display something, then obviously you have a good way to make a String of it. But just because you have a way to make a String doesn't mean you have a good way to display it: the resulting String could be impractical to display for various reasons.
Box is a way to represent data on the Heap rather than the Stack. https://doc.rust-lang.org/book/first-edition/the-stack-and-the-heap.html 
You don't need to use .call on the closure, you should just call it like `func(args);`. The error message should definitely be improved there
Oh yeah the trait bound doesn't require `Display` it's just implemented. Lookint at the implementors though aren't those overlapping trait bounds? How can it be implemented for both `String` and `Display + ?Sized` The conversion mechanism is kind of a mess suffering from the lack of specializatoin and dealing with overlapping trait bounds correctly honestly: 1. `From` should in act be `OutOf` as a counterpart to `Into` 2. `From` should exist but take `(&amp;self)` and `To` should exist but take `(&amp;self)` again. 3. Things like `FromIterator` should surely not exist and be handled by this so 3.to::&lt;String&gt;() But sadly even the proposed specialization mechanism cannot handle all these overlapping bounds sanely.
Ooooh, that does clear things up a bit. I've had to use a fair bit of Java at work and was used to explicitly calling closures. From there, it found some lifetime errors in regards to the function I was binding. I decided to just use a static lifetime for now (I think that fits most of my needs for this anyways). For completeness, if others stumble across this, my working code is now: pub struct ServerBuilder { funcs: HashMap&lt;String, Box&lt;FnMut(&amp;Mutex&lt;Write&gt;, MutexGuard&lt;Read&gt;)-&gt;Result&lt;(), Error&gt;&gt;&gt;, } impl ServerBuilder { pub fn bind&lt;A, R, F&gt;(&amp;mut self, name: String, func: &amp;'static F) where A: DeserializeOwned, R: Serialize, F: Fn(A) -&gt; R { self.funcs.insert(name, Box::new(move |stream_mut, mut stream_mut_guard| { // todo: there's no way this ugly deref mut syntax is best practice let args = bincode::deserialize_from(&amp;mut *stream_mut_guard, bincode::Infinite)?; drop(stream_mut_guard); let result = func(args); let mut write_stream_mut_guard = stream_mut.lock().expect("poisoned mutex"); bincode::serialize_into(&amp;mut *write_stream_mut_guard, &amp;result, bincode::Infinite)?; Ok(()) })); } } Thanks!
Any reason you aren't just taking `func: F` by value? That's usually much more useful, since that closure then just gets owned by the ServerBuilder instead of needing to live longer
But since you aren't in the same library as ToString, and ToString contains a blanket impl, doesn't it break the coherence rules to try to implement ToString for your own type?
I've always thought allowing whole-program inference would open possibilities Whilst it's true that in haskell you often have to add signatures to figure out how to make something work, it doesn't mean that the whole-program inference is *useless* ; and there are scenarios where losing it makes life *harder*. (I don't know if this would help in your specific cases, but maybe decltype is a workaround for things that Rusts inference if 'fully unleashed' could do better)
I tried that earlier and the tracking issue for fn_traits made it seem like I couldn't do that (although this confused me). That is what I want to do. I've changed it to take func by value now, which compiles fine. I had to move the 'static lifetime to the F trait bound but that's fine. You've been helpful so far, so I have one more question - in the code above, I have a MutexGuard&lt;Read&gt;, which I take by value. The only combination of operators I could find to get it into deserialize_from was what you see: `&amp;mut *stream_mut_guard`, which seems awfully noisy. Maybe I just don't understand deref coercion, but I thought I could write `&amp;mut stream_mut_guard` which would mean "coerce this to a reference of the underlying type". That doesn't seem to work, though.
&gt; Tons of undocumented features, the learning curve becomes steeper I have similar feelings too. Sometimes I want to look up a feature, but I can't easily find it in the Rust Reference book. E.g. I want to know what I can put inside `pub(....)` and their meanings. I have to guess where it is documented. An index will be useful. Also, the sections don't show up in the Contents. The Reference documentation has too many big examples but no syntax description in EBNF or similar. Big examples use too much space, I prefer such examples to be in the Book or folded or linked, and shorter examples are provided instead. In short, my feeling about the Reference is, it's hard for me to find what I want.
Hm, I'm not quite sure on the deref coercions, those "usually" (heh) just work but it might be interacting with the closure lifetime parameters in an odd way. Maybe someone who knows more about the compiler internals will see this and explain it better
Additionally, you could generate a Serialize and Deserialize for the closure state. Storing closures on the disk and sending them over network, imagine that!
If you aren't afraid of being on nightlies forever, just write your own compiler plugin. ;)
Well... except you can't actually derive Display :P
i know the heap and the stack but i dont understand what is a practical use for it except for generic return signature Result&lt;_,Box&lt;Error&gt;&gt;
I was doing something earlier, and had a `Vec&lt;A&gt;`, but needed a `Vec&lt;B&gt;`, and had implemented `From&lt;A&gt;` for `B`, and to my utter surprised there seems to be no way to automatically do that. I ended up having to `map().collect()`. So I wrote [AutoMapCollect](https://play.rust-lang.org/?gist=ed7c0857b6e011b0cae928b9f360aae6&amp;version=stable). Read and weep. If you called on `iter()` you need to have `From&lt;&amp;A&gt;`, and for `into_iter()` you need `From&lt;A&gt;`. I did also try to just do an `auto_map()`, but got hung up on returning a `Map&lt;I, F&gt;`. I couldn't figure out how to represent the closure in a way that would please the type checker. [Edit] I just realised that I *could* just implement an `AutoMapType&lt;T&gt;` for `auto_map()` to return. Don't program when tired, folks. You miss obvious things.
I checked the playground, apparntly it also works by making patterns irrefutable, this is quite nice: #![feature(never_type)] fn main () { enum Foo {} let Ok(x) : Result&lt;i32, Foo&gt; = Ok(3); }
First problem is that you are not allowed to use synchronous calls in it, so you must carefully investigate all libraries you use. If there is only one that does what you need but is not using IO model you are using, you are out of luck. If you are an author of a library, you have hard problem of either supporting one model or figuring out how to support 2, at least doubling the work. Second problem is that with async/await you design everything around IO loop. Your code structure is not representing your logic and data flow, but is constrained by technicalities. This makes understanding your code much harder. Also with server handling multiple requests for example with goroutines you don't mind that you might do some computation somewhere, it won't block handling of other requests. With async/await it is not allowed, so you have to export any computation to separate thread/queue and the fact that you may do intensive computations is not always obvious, which bites many people. The end result is often that async/await leads to throwing bits of your code into complicated libraries people have hard time fully understanding.
As far as I know it doesn't: https://play.rust-lang.org/?gist=c3d3503022cb0277d8d29f00aef1ffca&amp;version=stable 
looks very cool. 
maybe that is the answer
Quite right, apparently specialization [is indeed necessary](https://play.rust-lang.org/?gist=244b6b358f98d6009e423c46a0be646c&amp;version=nightly) here (as might have been obvious had I [looked](https://doc.rust-lang.org/src/collections/string.rs.html#1940) :-P)... Sorry for the noise.
&gt; Which ones are the biggest pain for you today? 1.15 moved a lot of stuff off of nightly. I work mainly with web development. Rocket is a library/framework I'd love to try outside of nightly. But it has features that are undocumented or unstable. I'm not experienced on Rust enough to know my way around it, I need the stable channel and documentation that will come in the near future.
You could just use stream_mut_guard.deref_mut() directly. Make sure to import std::ops::DerefMut. 
Ah yeah, that's the big downside of Rocket. Thanks!
Thanks!
It doesn't need ATC or HKT, e.g. struct Option&lt;T&gt; { storage: &lt;T as OptionStorage&gt;::Storage } enum TrueOption&lt;T&gt; { None, Some(T) } trait OptionStorage: Sized { type Storage: Sized; // ... } impl&lt;T&gt; OptionStorage for T { default type Storage = TrueOption&lt;T&gt;; } impl OptionStorage for Special { type Storage = CustomStorage; } 
I think this is a valid point, and worries me when designing my own libraries. I feel that you need to offer a synchronous API to consumers who may not already be in the context of an executing `Task`, like a CLI app, as well as an async one for those who are, like a `hyper` server. And making an async computation run synchronously with `futures` isn't as straightforward as it appears. Maybe in some hypothetical future (hue, hue) if `fn main() -&gt; impl Future` and building futures is more ergonomic the situation would be different.
I mean, something on `Vec` that would do something special when you store an `Option` on it.
so there is a chance that my project wont compile in one year? will it compile with old compiler? why isnt stability a priority?
Your first link 404s.
&gt; something on `Vec` that would do something special when you store an option on it. I'm not sure what you mean. Does [this count as doing something special when you store an `Option` in a `Vec`?](https://play.rust-lang.org/?gist=e204c3760b0d993df447bca3ba97933d&amp;version=nightly)
Finally got some time to do it. https://github.com/diesel-rs/diesel/pull/1021 It's still a WIP as it's missing Nullable impls, doc and tests, but I'll do that tomorrow.
I still don't think that needs ATC or HKT, as the same basic trick works: https://play.rust-lang.org/?gist=cbbde55e408bb942dc2f09fc7a6578df&amp;version=nightly (Fleshing it out to actually work might involve a `VecOps` trait to bound the `Storage` associated type that provides indexing, swapping etc., and then the outer `Vec` type's API would be methods that call those.)
Oh :D /u/dobkeratops.. that's what you wanted, right? --- On an unrelated note, how can you write struct Vec&lt;T&gt; { storage: &lt;T as VecStorage&gt;::Storage } Without a `Vec&lt;T: VecStorage&gt;` bound when declaring the struct?
The blanket `impl` for an unbounded `T` means every type implements `VecStorage`, and the compiler recognises it.
... so, changing the API this way is a non-breaking change? !!!
A `Box` is useful: - For an object that's too big to keep on the stack ^(though it may be difficult to allocate such an object^on^stable) - When you want to own an object that implements a trait but without knowing the specific type (as in `Box&lt;Error&gt;` as you point out) - To define a recursive structure such as `struct LinkedList&lt;T&gt; { item: T, next: Option&lt;Box&lt;LinkedList&lt;T&gt;&gt;&gt; }` without getting infinite size errors - When you need to allocate something and get a pointer to it, to pass to FFI (i.e. `Box::into_raw`) - Likely other reasons I forgot
Yes, but I struggle to think of type `T` that could benefit from this for `Vec&lt;T&gt;`, because indexing returns (mutable) references (i.e. one can get a `&amp;T` or `&amp;mut T` out of a `Vec&lt;T&gt;`), and so there needs to be a true `T` stored in memory for them to point to. This is actually one (major) reason why the `vector&lt;bool&gt;` optimisation in C++ is regarded as a mistake: it breaks a whole pile of assumptions about what, e.g. indexing returns and what a reference into a vector looks like (`vector&lt;bool&gt;`'s references have to be a custom non-`&amp;`-reference type).
Being able to put complex types in a struct. Imagine if you want to store a `(0 .. 12).filter(|n| n &gt; 3).skip(4).map(|n| n * 2)` in a struct. The type of these kinds of expressions is very painful to write (and in this specific example, impossible to write). In this example it can be fixed by storing it as a `Box&lt;Fn() -&gt; u32&gt;`, but boxing does not only slightly decreases performances, it also means that the boxed trait cannot have associated types and cannot have methods that take generics. Vulkano currently uses several hacks to bypass this problem, but a specific part of the library (binding vertex buffers) is totally unsafe right now because I can't figure out how to bypass the problem. With an associated type I could make it safe in five minutes, but that would mean that the user couldn't store some objects in a struct anymore. 
I believe `impl Trait` is going to be supported in structs too, and that fixes this. There is some level of support for impl Trait outside of functions planned, basically.
Afaik it has been briefly discussed but not planned. We don't even know what the syntax would look like for example.
Also DSTs
I think I saw more in depth discussions of it at the recent Mozilla all hands. At least I got the impression that the lang team has a clear idea of how to move forward and will RFC sometime.
Is there a Github issue for this? This looks like a bug...
Why doesn't this macro respect hygiene of CellType, MEM_SIZE, Result and Vec? https://wandbox.org/permlink/3cjukb3ChyLtw1Sq
Thank you, I figured out a decent solution!
&gt; allocating `Box::new([0u32; 1_000_000])` will first attempt to place the array on the stack What is the better way to do this that doesn't place it on the stack first? Just use a `Vec`? ISTR that box syntax aimed to fix this but doesn't seem to have ever been promoted out of nightly
That is good news.
&gt;&gt; This is actually one (major) reason why the vector&lt;bool&gt; optimisation in C++ is regarded as a mistake: i've never personally used that.. if i wanted a bitfield i made a dedicated bitfield - but perhaps we could get around that by returning some sort of dedicated bitfield accessor rather than a plain &amp;bool. I didn't really have specific use cases in mind when I posted this - I was just interested in the symmetry 
nope; that doesn't :) what i had in mind would be replacing a Vec&lt;Option&lt;T&gt;&gt; with an object that held a Vec&lt;T&gt; and a bitfield (i.e. concatenating the presumed array of bools that the 'option' part would have) I suppose you could even use this idea as a means of discovery: if you *did* make a dedicated 'VecOption&lt;T&gt;' the compiler could tell you of it's existence , if you'd given a composition from known primitives that is functionally equivalent ( I would personally make an 'optbox&lt;T&gt;' purely as a means of reducing nesting, there may be many other popular pairings)
&gt; If you are an author of a library, you have hard problem of either supporting one model or figuring out how to support 2, at least doubling the work. IME it's easier if the core library is async and provides sync adapters for the API. I structured my [LDAP crate](https://github.com/inejge/ldap3) in that way. Going from async to sync is nearly trivial in most cases: you just have to wait. My estimate is that supporting both I/O models in this manner is about 5-10% additional effort compared to having just async support. However, since async is more difficult to write in the first place, I'd raise the total effort to +25-30% compared to sync-only. Still less than 2x. &gt; Also with server handling multiple requests for example with goroutines you don't mind that you might do some computation somewhere, it won't block handling of other requests. Golang does a good job hiding the I/O-compute dichotomy, but [it still has some tradeoffs](https://github.com/golang/go/issues/10958). Rust is more explicit by design, and with that explicitness comes the pain. I believe that judicious library design and future language improvements will make it tolerable.
Yes, but it's closed because it's not considered to be a bug.
Woah! https://github.com/rust-lang/rfcs/blob/master/text/2033-experimental-coroutines.md
I think the problem here is specifically the implicitly imported prelude. If the `ToString` trait wasn't automatically used everywhere, to get that functionality you'd have to import it manually, at which point you'd probably read the documentation. Maybe the sufficient solution is just to special case the prelude in docs and make sure to display methods from traits only if they are from the prelude?
You could want a string conversion (aka to_string) without conforming to Display or invoking the whole formatting machinery. I expect the latter is why `str`, `String` and `Cow&lt;'a, str&gt;` implement ToString explicitly.
[byteorder](https://github.com/BurntSushi/byteorder). Bytes can be expressed as a `Vec&lt;u8&gt;`, but watch out for endianness. A CPU cannot adress individual bits, only bytes. You can still safely do bit manipulation with shifting left / right, casting from / to differently sized types and or-ing ints together. For interaction with C structs, you can use `#[repr(C)]` which respects the order of fields.
Firstly, the trait [explicitly conflates those two things](https://doc.rust-lang.org/std/string/trait.ToString.html): &gt; This trait is automatically implemented for any type which implements the Display trait. As such, ToString shouldn't be implemented directly: Display should be implemented instead, and you get the ToString implementation for free. Secondly, i'm skeptical about the meaningfulness of a generic to_string method. Strings aren't just strings; they're strings in some particular context. A data type might need completely different string representations for human consumption, in JSON, in XML, in logging, in an HTTP header, in ls -l output, etc. Sure, we need ways of converting things to strings other than Display, but they have to be just as specific themselves. 
Electron is a nice addition to that in having cross-platform desktop apps using web technologies like React. While I have quite a few programs built on it that I adore like Atom and GitKraken, the performance and especially memory usage to comparable native apps can be pretty shocking :| I'm wondering how much of a difference they'd be if Servo gets to a point of replacing the Chrome layer for the webview, and Rust to replace the Node.JS backend(which adds a sizable chunk to the apps file size).
&gt; Also data race can be detected with race detector (which have been there for 3-4 years now?) As I said, if you don't even know what a data-race is, how are you supposed to run sanitizer check for it ? There is (or at least two years ago there was) not a single explanation about data-races in go's tutorial. Rust isn't affected by data-races but it *does* explain what it is in its tutorial. Moreover, the race-detector is helpful but not a panacea : it doesn't detect everything (it's been improving though, some times ago after a new Go release we ran the race-detector again and it found a hidden race that wasn't detected before. &gt; GOMAXPROCS=1 ? Well, if I want a single threaded server, I better stick with nodejs. Async/await syntax is **much better** than Goroutine + channels.
aargh the formatting is all wrong. i'll try to fix it quickly.
Indent all your source code with 4 spaces and it will render properly.
thanks
Love the irony in `sort_unstable` becoming stable ;)
&gt; You see, you can style your app in CSS. Rust doesn't know CSS, if you make a UI toolkit from scratch, there is no such thing as margins or borders, you have to make them yourself. Facebook has a C lib from memory for using CSS to handle layout with React-Native(Andoid/iOS), it doesn't support all of CSS, mostly focused around it's layout features including the more modern kinds like FlexBox. There are some other approaches for styling components that deviate a bit from traditional CSS approach with React, I think one of them that is quite popular atm is `styled-components` which had a tonne of benefits and addressed issues that other libs and traditional CSS would have. &gt; Reacts "it does not redraw if it doesn't need to" completely disregards the fact that the browser still have to handle mouseovers, window resizes, CSS animations, etc - these events still have to be handled in a way, which React doesn't concern itself with, but we have to. Those sorts of things could be handled in a way that you could still support the React approach of rendering with a virtual view tree. Again this was handled with React-Native supporting several mobile platforms and there are implementations for both Windows and macOS, clearly this is doable? The React devs attributed alot of the ease in supporting additional platforms that differ from the browsers handling of views/UI to their virtual view trees which allowed alot of the code to remain the same and be shared(React internals, not the users react UI code which also benefits from this). &gt; It may work in JS, but not in Rust where the lifetimes of things are clearly bound. I can't really comment on this, but I would think the lifetime of a component is something that Rust could in someway support? React components have their own lifecycles and state, tie it into something like Redux which is really nice to work with(but at present from what I've seen no one has had luck porting it to Rust to work as well, it's only around 100 lines from memory). Not sure how other UI libraries (native rust or FFI to popular ones like Qt) handle this issue. &gt; and don't crash if there's no given font. Default to system fonts? Most UI libs I've worked with do this, it's not something specific to CSS / browsers. &gt; two statements, such as "make the button 500px wide and 50% of the window width" might contradict each other. Facebooks CSS layout implementation in C handles these issues. If you're parsing something you can overwrite it, same as if you had a struct that had different methods, the last one would override the prior change. Alternatively depending how you go about it, you can have a compiler error? This again isn't an issue specific to CSS. Making use of the power of CSS for layout though is pretty neat especially if you can utilize the logic to parse and output the values for you already. &gt; What I am concerned with is building a solid foundation for layouting, before even thinking about "do we store the state of the app in the UI or not". Absolutely agree with having solid foundating for layout. As for storing state of the app in the UI, I'd strongly suggest looking at how Redux approaches it, React just handles the view/rendering, Redux handles the data state with uni-directional flow, small and simple methods that compose the larger state tree for UI where multiple components can reference the state(immutable) and be updated in sync. Having one component alter a value that should update other components just works, you don't run into data binding issues as was seen with Angular 1 and other UI frameworks. From the dev user point of view, it's easy to reason with, follow and well just simple :\ Debugging and developer experience as a whole has a tonne of praise, due to how things were nicely isolated, see the time travel demo, state hydration, debugging(dev tools) and testing(automation with appium) of components. &gt; I also highly recommend reading the X11 documentation on event handling, just to see how events handling changed over time and what we can learn from it. Martin, author of KDEs Kwin compositor has a pretty useful blog, he has quite a few detailed blogposts on his experience dealing with rendering and input events. --- React aside, I had pretty good experience with Flash/AS3/AIR platforms popular UI lib, Feathers, which was built on top of Starling. It might be of an interesting reference for how that UI lib has matured, it's still actively developed even thouogh I haven't used it since 2013. It utilized the GPU for rendering which was a bit different to other UI dev I was used to prior. Haxe, is an interesting language with one or two UI libs too that may be of interest. I don't have any personal experience with them, though I was lurking their dev for some time. Before I stopped another one was getting a lot of traction, they tackled alot of these issues/questions themselves I think, and also created something that used CSS like syntax for layout, so there is another reference for that sort of thing. That particular UI lib was split into several modules, layout being one, rendering another and so on. I believe they supported the cassowary layout approach too, this UI library I think was known as Snow and the layout might have been Flow. No idea what state it is in today. CSS can do anchor point like stuff too though it isn't as straight forward, I think it used a transform with a value like px or % to move the element or adjust it's pivot. Flexbox can also do similar, quite nice to work with. That said I do like UI systems with more direct anchor/pinning support. u/jaroslaw-jaroslaw , u/gopher9 , u/horsefactory Might interest you guys too?
&gt; That's a performance nightmare, but that doesn't stop antibody doing webdev. I take it you don't know too much about it in relation to web dev then? The approach React uses is proven to be much faster and easier than manually modifying the DOM. Might have also been the case for the mobile versions, can't quite recall. 
How is that going to work? Suppose I had struct T(impl Trait) let xs: Vec&lt;T&gt; = ... Then `T`s may contain different anonymous types. Would I be able to store them in a vector?
&gt; Well, if I want a single threaded server, I better stick with nodejs. If you know about threads, how can you not know about data races? &gt; Async/await syntax is much better than Goroutine + channels. Purely subjective opinion. Edit: My point was that if you just wanted things to work(without learning abot data races) , there is workaround GOMAXPROCS and it's well documented. 
&gt; Regarding unidirectional architectures: If the whole purpose of the UI was to display the UI (like in webdev), this might work. But desktop programs aren't only made to display a UI, they usually do stuff when a button is clicked that does not concern the UI. This is why you have MVC / MVVM architecture. You can have both MVC and MVVM in web dev too. React is just the view layer, uni-directional data flow for state management like Redux is for dealing with that UIs state. You can still have non-UI state managed elsewhere if appropriate, actions can still happen beyond updating UI, JS can do computation or queries as you know, these days alot of the logic for an app not UI related may happen on the backend, I'm not really seeing what sort of point or difference you're trying to make here in relation to this UI/state approch. &gt; That's it, there's no .then(a).then(b) because non-multithreaded programs are always synchronous and don't have to deal with latency. Again I'm sorry, but I'm a little confused with what you're trying to say here. What about programs with multi-threading/processes? They may be less typical, but still a possibility. It's also quite possible for a desktop app to want to make network calls and have to deal with async logic due to that. It's quite possible to have a webapp without any async if you wanted to I guess? Promises are useful for when you don't want something blocking until a task is done/ready, especially undesirable in UI, to which I've experienced some desktop apps freezing up because of some operation blocking UI logic from doing anything. I believe callback hell references heavy nesting of callbacks, before promises you'd get heavy indentation and poor readability due to that. Not sure why you compare callback hell to a definition of a callback. &gt; async should be done in the application if necessary, but not by the UI framework. Maybe I'm tired, or I haven't used React in over a year. When was async used by a developer explicitly when dealing with UI?
Heh, thanks for [teaching me](https://github.com/maghoff/bart/commit/89153a58698c90862c59dca483fc2a3f5d5703f9). I haven't been aware of `to_string()`, but have instead used `format!("{}", ...)`. And it seems like I'm not the only one :)
Has anyone solved the Windows installation headaches yet? I tried Rust 6 months ago and gave up because I couldn't get the initial Hello World to compile. Tried again today and it still won't compile, but now for totally different reasons. The biggest issue seems to be that Rust requires old versions of the C++ build tools, and doesn't recognise current versions. It's a big of a major issue because installing the older tools can be nonviable or a major pain in the arse if you're not *exclusively* doing Rust work. 
Why would you want to collect into two separate vectors instead of into `Vec&lt;(u32, u32)&gt;`?
`zip`'ing an iterator of `T` and an iterator of `U` gives you an iterator of pairs of `(T, U)`. It's a single iterator, so you can't `collect` it into two vectors.
You can't collect into fixed size arrays or tuples. Fixed sized arrays aren't supported because Rust doesn't have generic value parameters, and tuples because it doesn't make sense in general (and also because Rust doesn't have variadic generics). Even if they *were* supported, it still wouldn't work because you seem to be trying to turn `[(a, b), (a, b), ...]` into `([a, a, ...], [b, b, ...])` which isn't what `collect` does. What you want is `unzip`.