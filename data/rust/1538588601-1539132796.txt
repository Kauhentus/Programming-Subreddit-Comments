The trait system is very close to OCaml's module system- traits map to signatures, impls to modules, and generic impls to functors. The major difference is that impls are canonical (one per type), and are thus selected automatically. I'm not sure I would compare functors to const generics directly, though they can often accomplish the same things (much like C++ templates and C++ constexpr).
Yeah. It is weird that a language that gathers so much enthusiam has barely any jobs (except for a few in san francisco).
[Actix](https://actix.rs/), because it's fast, well supported, and I'm using it for another project anyway (game server with TCP and websocket support). I *may* consider building it with tower-web, but it's a bit too new for me to try to go to production with it just yet.
not open source. From C.
Is tower-web production ready? Last I checked it basically said don’t use this in production (maybe in misremembering). 
This was my exact experience, except I didn't review books for them. They contacted me to review some book about enterprise Java. I had some Java on my public profiles, but nothing with the particular tech the book was about. Then later in the year they emailed me about writing a book for tech that I had no mention of on my public profiles. I had never even installed the software in question, much less used it.
Very cool! How are you intending to interface with IPFS? Just through a node's JSON API?
This crate is a Rust port of the [Constant Time Encoding](https://github.com/Sc00bz/ConstTimeEncoding) implementations of Base64 and hexadecimal encodings originally authored by @Sc00bz. They provide a best-effort attempt to handle serialization of these formats in a timing-safe way. This hopefully addresses the same needs as crates like [hex] and [data-encoding], but in contexts where the serialized data is e.g. cryptographic secret key material. [hex]: https://crates.io/crates/hex [data-encoding]: https://crates.io/crates/data-encoding
Those are some pretty cool additions. `dbg!()` is a great addition; `#[marker]` looks useful; `await` is now treated as a keyword; and overflowing literals are now denied.
[removed]
Really a lot of the data is going to be stored on its own nodes since there's a lot of data that has special rules for how it's created and destroyed, like user identities and the encrypted message payloads. But [history tracking](https://gitlab.com/treyzania/quickpixel/blob/master/core/src/history.rs) and message passing is going to be done through IPFS/libp2p. But yeah using the [JSON API](https://github.com/gkbrk/rust-ipfs-api) for talking to nodes until there's an actual Rust implementation of IPFS so I can directly integrate it into the node/client software.
Nope, but this is for "production", which is essentially a tech preview. I *think* Actix is a bit further along, which is why it's my default.
In my experience, Packtpub has the worst quality books of all. I would rather trust more reliable publishing houses such as Manning, O'Reilly, Apress, or Wrox.
I'm working on my programming language. "Russet" Right now I'm creating prototype of VM in Rust. So it's very low level, no parser, no AST (yet) or syntax. Just my bytecode IR. It uses Tokio Async Await (2018 Rust edition) features to provide async/await and some kind of "fibers". I want to implement hot code swapping by having "source code snapshot" for every fiber, which is readonly. Now, when new fiber spawns, it would load new fresh snapshot of code. I'm not sure if it will work in the future, it's just prototype. Aaaand, in November I'll be rust developer in new (local!) company ;) Life is great folks! Life is great!
I like how there seems to be an explosion of reactive wasm web frameworks! I hope they pollinate each other with awesomeness!
Well, as others have amply shown, Packtpub does indeed deserve its bad reputation. Whither the problem?
+1
&gt; The item is now at a new address. I was under the impression that this didn't happen. What distinguishes a copy from a move then? Only the fact that the original can't be used? Wouldn't that waste space in memory?
Are there better resources anybody can recommend? Is O'Reilly's any better?
marker is especially useful because it allows overlapping implementations
O'Reilly 'Programming Rust' is very good. It's the best Rust book in my opinion.
Yeah, it does seem like the broader point about the publisher is being corroborated; my, uh, complaint, was something narrower. I think what bothers me is talking about someone's work as if they're not in the room, when they might well be.
&gt;You can get good books on Packt, but it's a crapshoot. Haskell community noticed the lack of quality controls a while back. Disappointed, but not surprised, that the affects Rust offerings from Packt, too. I wouldnt even call it books, i more call it toliet paper.
you have a immutable binding for a mutable reference
`_b_ptr` isn't `mut`. Rather, it contains a pointer that can mutate the value it's pointing to. If you want to be able to change the value of `_b_ptr` to point to the same value as `_a_ptr`, you'll want to declare it as `mut _b_ptr: *mut u8`.
ahh, ok, there is access control for the pointer address itself AND the stuff it is pointing to... Cool. I'm brand new to this language.
have the same experience with Packt books, they really seem to go for quantity over quality and have a bad review/proof-reading process also i've heard bad experiences from people approached by them; how they work is that if they see that you contributed to X on github, they keep sending mails asking you to write a book for them about it, no need for any prior writing experience or such…
[https://github.com/rust-unofficial/awesome-rust](https://github.com/rust-unofficial/awesome-rust)
Anything written by /u/BurntSushi
Seconding the O'Reilly book as well as The Book on the docs site!
Pierre Krieger (/u/tomaka17) has taught me a great deal about how to use rust's type system to wrap C libs and maximize safety/minimize incorrect usage of APIs while keeping overhead extremely low. Github: [https://github.com/tomaka](https://github.com/tomaka) He's no longer directly involved in glium and [has voiced regrets about it](https://users.rust-lang.org/t/glium-post-mortem/7063), but it still was useful to me as a learning tool. Some neat tricks I borrowed for a react-like project was [the way uniforms work](https://github.com/glium/glium/blob/master/examples/deferred.rs#L338). Stack-allocated heterogeneous maps with a great API. Vulkano is an in-progress graphics project, which he switched away from glium to work on (but is currently pending a semi-rewrite? Still quite useful). &amp;#x200B; Rayon is an incredible task parallelism library [https://github.com/rayon-rs/rayon](https://github.com/rayon-rs/rayon) Crossbeam is another thread-focused lib [https://github.com/crossbeam-rs/crossbeam](https://github.com/crossbeam-rs/crossbeam) &amp;#x200B; The standard library can be quite interesting. Rust iterators taught me a great deal about how to make things that would incur a cost in other languages be totally free [https://doc.rust-lang.org/stable/src/core/iter/iterator.rs.html#40-2529](https://doc.rust-lang.org/stable/src/core/iter/iterator.rs.html#40-2529). It was a fun project trying to reverse them into Observables without allocating. &amp;#x200B; I've not looked closely, but a lot of servo components are likely to be well-written and production-quality. [https://github.com/servo/webrender](https://github.com/servo/webrender) [https://github.com/servo/rust-cssparser](https://github.com/servo/rust-cssparser) &amp;#x200B; I could keep going, but that's a good start. &amp;#x200B; &amp;#x200B; &amp;#x200B;
The latter solution worked for me. Thanks!
Yeah that helps. I want to keep in mind wasm compatibility for some simple crates I want to write. Thanks!
Ha, I had the exact same experience!
I know the term tangle form emacs org-mode. The following is the docs of the command to tangle code blocks in org-mode : ``` C-c C-v C-t runs the command org-babel-tangle (found in org-mode-map), which is an interactive autoloaded compiled Lisp function in ‘ob-tangle.el’. It is bound to C-c C-v t, C-c C-v C-t. (org-babel-tangle &amp;optional ARG TARGET-FILE LANG) Write code blocks to source-specific files. Extract the bodies of all source code blocks from the current file into their own source-specific files. With one universal prefix argument, only tangle the block at point. When two universal prefix arguments, only tangle blocks for the tangle file of the block at point. Optional argument TARGET-FILE can be used to specify a default export file for all source blocks. Optional argument LANG can be used to limit the exported source code blocks by language. ``` 
Hi killercup ! I watched a lot of your talks about rust. I like them. Glad to know that there are many such tools in rust already. 
ring is a pretty good codebase as far as I can see. The authors are clearly obsessed with cleanliness of the code and APIs.
They once contacted me to review a Ruby book. I sent them back my standard terms of engagement letter saying that I'd love to work with them on their project and outlining my day rate, etc. I never heard from them again. I think that's a win.
I happened to be looking at both projects today and it looks like both have WASM on their roadmap but it doesn't appear to be supported today by either.
I'll have to take a look then. Actix is fine, but I was hoping for something closer to Rocket, but compatible with stable Rust, and I think tower might fit the bill.
Ah, that's probably wherr the charqcter's name comes from too. Thanks!
Most of the Diesel core team got contacted for the same book &gt;_&lt;
&gt;access control for the pointer address "Access control" isn't quite the right idea. What you should be thinking about is "can I mutate this or not?". And you should also be thinking about the value itself instead of things in terms of "addresses". Yes it has an address on the stack somewhere, but in Rust you should think about it a little more abstractly than that. I take it you were a C/C++ programmer before?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/webassembly] [Announcing \`twiggy\` 0.3.0](https://www.reddit.com/r/WebAssembly/comments/9l6bsk/announcing_twiggy_030/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
yup
Dang. Isn't there still an exploitable DoS in a popular PNG library? And way too much `unsafe` code in `actix-web`?
Woah, I feel like I need to comment on how cool that site is. Great design, great responsiveness, and as if that weren't enough, it uses wasm in a really cool way. Hats off to that!
For small tools, I like `warp` a lot so far. Feels very productive. I'm trying to build a more complex example, but haven't gotten around to it. I also want to implement a tree based router for `warp`, but not sure how that would fit into the `Filter` design.
Oh my, I was literally just thinking about this since when I'm desigining an application or script I like to write my notes in markdown and embed code fences, and here you appear! Especially after installing the `vim-markdown` plugin which adds nested syntax highlighting, I'm thinking I'll switch to literate programming style for some stuff so that it is self documenting. For shell scripts, I could even make the markdown file executable with a shebang that extracts the code, and then runs it (`.sh.md` anyone?).
Looks nice! I'd be interested to see it contrasts with Yew. https://github.com/DenisKolodin/yew
With Rust being as young as it is, any experience with architecting for it and choosing the best-fitting cargos is good to share. I'll certainly be reading all you write on this topic!
Great work - and a nice website! I'll definitely give this a try.
This might be a loaded question, but why use yew? Could the front end be some simple html and JavaScript? 
Amazing work on your behalf and also the rest of the team!
Thanks! I am also a archlinux user :) 
There's dozens of us! Excellent :) I feel like I see a higher percentage of arch linux in the rust community. A lot of rust crates are already available in the community packages for pacman. 
The rules don’t treat marker traits as any different than any other trait. This ability is motivated by exactly your point: it should be allowed. Today, it isn’t.
What does "constant-time encoding" mean here? Naively, it seems to me that encoding will need to take time linear in the input size. Encoding a single chunk will always be constant time unless the encoder does something silly. 
Just a guess, but it could mean "same exact time for all inputs"? I know some cryptographic things care deeply about not taking different times for different bit patterns since that can allow timing attacks.
No need to guess, that's exactly what the description is describing. They're defending against timing attacks. One caveat though, it's for all inputs of the same length. Encoding a gigabyte is going to take longer than encoding a kilobyte.
Next week is pretty good too. 0xFF FTW!
Cool, thanks for the confirmation. I hadn't read the actual crate description yet and only have passing cryptographic knowledge so I was being cautious.
Looking on c++ code, there is nothing extraordinary in encoding hex in there. So, what's the difference? How else it can be encoded to be constant or non-constant?
This matches my experience as well.
You should be able to start your Regex with “\A”, which is a special symbol in regular expressions that only matches the beginning of the input, and then use re_find. 
Wow, no kidding. That site is awesome.
I read this book and loved it. No affiliation with the author or packt, but this was one of the best technical books I've read in a long time. Definitely advanced. The author did so many things right. Great technical density, but also very readable.
Updated the other day. Thanks for getting rid of the lifetime on Error. \o
I've been using pest for a while now and it's amazing to see how much this project has progressed. A lot of credit needs to go to dragostis for being such a quietly persistent maintainer.
Sorry, I should have been more specific . Why use Yew compared to using rust to render dynamic html? 
What I picked up from this was that testing correctness is difficult, particularly with concurrent code. The author seems to have enough experience to distinguish a pointer from another data type, so maybe just ask him his intent, or file errata. The references at the end of each chapter are extensive and interesting (at least to me). The book goes into some advanced topics like Michael &amp; Scott queues. Lots of new things to learn and tools to play with. I came away with a much better understanding of rust and lower level programming techniques in general. The author also blogs about the process of writing the book and provides pretty cool insight. It's not an easy process, and you can tell he cares about producing a quality product. My experience was just vastly different then yours. To each his or her own.
If you think about it, it rather obviously has to happen in some cases, for example, when using [Vec::append](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.append) the value has to somehow appear inside the receiving vector which is necessarily at a different address. But yes -- if I'm moving something by passing it as a parameter to a function, or initializing a smaller value that itself becomes part of initializing a larger struct, then it should be possible for the optimizer will poof those move into a no-op. Otherwise, at runtime, a move is exactly the same as a copy. At compile time, the compiler understands that the previous address of the moved value is now uninitialized memory. That's the only difference as far as I know.
Check out the \`quicksilver\` crate, as far as I know that's currently the only framework that works with wasm transparently.
I would also like to point out that Rust is really bad at optimizing out moves, for example even a simple case* of fn main() { let b = Box::new([0; 1_000_000_000]); for i in b.iter() { println!("{}", i); } } will fail to run successfully, even on release mode, due to overflowing the stack. It overflows the stack because the array is put on the stack temporarily, then moved into `Box::new` and then put on the heap, which should have just been inlined. If we take a peek into `Box::new` we can see that it is defined as so impl&lt;T&gt; Box&lt;T&gt; { fn new(value: T) -&gt; Self { box value } } using the unstable feature box_syntax, what if we used that directly? Effectively inlining `Box::new` and doing a move optimization. (keep in mind this only works on nightly) #![feature(box_syntax)] fn main() { let b = box [0; 1_000_000_000]; for i in b.iter() { println!("{}", i); } } it magically works, because the box syntax puts the array directly on the heap, instead of putting it on the stack temporarily. *I know that this program is absurd, but I'm trying to prove a point that move optimizations are not there yet, and this is an easy way to see it.
Pet peeve, but people who make video presentations on multimedia - please put in the effort to make a decent recording! Even if all you can do is turn off the AC... it's very difficult to hear what the presenter is saying in this video. Some questions though just to followup. At about 4:00, it says that wrapping behavior can be explicit, I had no idea you could do that! Does it include saturating arithmetic for integers? 
It showed lots of false positives last time I tried to use it (admittedly 5 years ago or so), which was a deal-breaker. AFAIR the problem with false positives in DUMA, Valgrind, etc was the primary motivation for the development of sanitizers. Also, it caused roughly 20x slowdown, which is impractical for fuzzing jobs, and you probably won't trigger reads from uninitialized memory on valid input anyway. Unless the situation has dramatically improved on both counts in recent years, Valgrind is still nearly unusable for discovering security vulnerabilities.
The biggest difference is that pest separates the grammar from consumption. Thus, you get a formal, up-to-date representation of your parser that is easy to read.
Not sure what this is replying too. Neither of those is currently a problem?
One cautionary tale is that Cap’n Proto includes **over a thousand lines of `unsafe` code** in the core serialization and deserialization components, due to being essentially a direct port of a C++ codebase. Therefore, I do not recommend exposing Rust Cap’n Proti servers to the Internet, and would use Serde instead.
Have you given [the book](https://pest.rs/book) a chance?
I'm a little bit confused. What exactly is this? Is this just a library for validating a text file against a given grammar? Or is it something like a compiler?
do you have a link to their github or any other place I can find a collection of projects made by them?
It's a parser. It parses a text, i.e. tags it, according to what you specify in the grammar.
https://github.com/BurntSushi
https://github.com/BurntSushi
Not yet. I'm planning on doing a medium post on getting the system up and running, the reasoning behind my hardware choices, and basic concepts in audio driver programming (I once had to reverse engineer two drivers for the same hardware - had never written embedded code before and shit was a wakeup call). It's not the most complicated thing in the world, but it's certainly things that I'd guess the average programmer whose never done embedded has dealt with. I don't think I'll write much about the DSP because there's some secret sauce in my oscillator (I'm making a tremolo effect). It's not particularly interesting to the average Rust dev, because the interesting part about it is mathematical and would probably detract from the goals of anyone trying to copy the work down the road. 
Going off what OP said in his comment, a parser is useful for alot of different things for example, say you're building a window manager and want to create a custom config file for it. Writing a grammar to nicely parse all the variables into a custom struct may be something you want to do
`&lt;core::iter::Map&lt;I, F&gt; as core::iter::iterator::Iterator&gt;::next` is the name of a function. It has a complicated name because it was generated through static polymorphism, but it's no different from a call to something like `fn add_one(x: i32) -&gt; i32 { x + 1 }`. In the actual machine code it's just represented as a single address or offset. The name is stored in the debug information, which the playground's assembly printing code looks at to make it easier to read. The actual function that's being called is [here](https://doc.rust-lang.org/src/core/iter/mod.rs.html#1393-1395). It calls `self.iter.next()` on the range iterator that it's mapping over, which can be found [here](https://doc.rust-lang.org/src/core/iter/range.rs.html#213-228).
I'm such a lucky ass to work full time in Rust in Johannesburg. We're probably the only shop in town
How did you manage to be faster than nom? I thought that the whole purpose of nom is to avoid PEGs in order to generate faster parsers. 
I've written a parser in nom for sysctl.conf files. Maybe I should try pest as well and post the results. 
Wow, that's a cool project! I also didn't know about PEGs. I had \_heard\_ about them, but I thought they were just a specific parser type; but it seems that they might be their own class of formal languages, between regular expression/finite state automata and context free grammars/stack automata. However this is still an open problem! It seems that they are a bit stricter than context-free grammars but because of this strictness, they have some additional "nice" properties. On a more practical note, I'd love to have a benchmark against Serde JSON parsing too! &amp;#x200B;
I have managed to get all the way to atomic rules and now I am lost! I understand what a silent rule is (discards characters) but what is an atomic rule?
They both ignore the [implicit whitespace rules](https://pest.rs/book/grammars/syntax.html#implicit-whitespace). But @ also only produces a single token for all the sub parsers rather than separate tokens for each subparser. This is useful if say you need to parse a float where you have some digits optionally followed by `.` followed by more digits as a @atomic you get one token for the whole float rather then the three separate ones which are harder to turn into a useful value.
&gt;quicksilver awesome! Thanks!
This looks interesting, I may have to reevaluate my use of nom. &amp;#x200B; One thing I couldn't find on skimming the documentation: does this take care of incomplete input? This is one feature that nom has and it's been pretty useful for my IMAP parser in imap-proto.
Ah, "input-independent timing". Probably right. Thanks!
How does this compare to LALRPOP?
I've always enjoyed working with Antlr, and I'm really excited to discover this project! The interaction on the site is also really cool!
Yes
I find it a bit misleading, because the comparison is done on a JSON parser that is not optimized at all: pest's parser iterates over elements, while the nom example first parses everything, allocates entire vectors, then gives the result. It would be interesting to reproduce pest's behaviour in nom, though, and I find pest's one quite readable
To figure out ASM I usually use the [compiler explorer](https://godbolt.org/) but in [this case](https://godbolt.org/z/FzXduB) it's not as helpful als the closures surely get inlined and the loop unrolled.
I also want to point out that showing the x-axis with steps 20, 30, and 40ms is pretty misleading as it shows the nom version having an almost 2x as large bar while takes in fact only 1.3x as much time.
Would it be practical to use Pest in a Serde deserialiser? Or would there be overhead in connecting the two models?
That's surprising. Valgrind normally has a very low false positive rate. In the last year or two clang has started generating code patterns that trigger false positives more often, but that wasn't a thing five years ago. As for speed, Valgrind is slow, but a lot of that is precisely because it does the tracking of uninitialized data. That's the major part of the slowdown.
&gt; I think what bothers me is talking about someone's work as if they're not in the room, when they might well be. Fair enough. From my own experience, I have realised that it is best to deal with concrete facts (Section 3.2 is incorrect - that is not an example of tail recursion. Here is a proper example..., etc.) rather than getting embroiled in emotion (Section 3.2 is totally wrong - the author clearly doesn't understand what he's talking about, and that puts the rest of the book into serious doubt). Of course, if the whole book is a veritable mess of incorrect assertions, I don't mind posting the second form of comment. In general, it's better not to get your emotions involved, even if the author is making some bizarre and possibly wrong statements. That also elicits a better response from the author - professionally dealing with massaging the content into proper form than sinking the project before even getting started. That is just the general approach, of course - some authors don't deserve to be writing books, and it becomes a very difficult endeavour to even review such books. In such cases, I always make sure to review my comment draft and make it as professional as possible while still being precise - not as easy to do at times.
&gt;wrapping behavior can be explicit, I had no idea you could do that! Does it include saturating arithmetic for integers? Yes, see [https://doc.rust-lang.org/std/primitive.isize.html#method.saturating\_add](https://doc.rust-lang.org/std/primitive.isize.html#method.saturating_add). All the common operations are covered, and methods with different semantics are prefixed with `checked_`, `overflowing_`, `saturating_`, and `wrapping_`.
Yeah! it does. Yew is Elm/React inspired whereas Ruukh is React/Vue inspired.
Is there an overview of all the frameworks that we have? (arewewebyet.org)[https://www.arewewebyet.org/topics/browser/] is not really up to date.
I was convinced that `re_find` was lazy and would return the first matching substring instead of the largest. Apparently I made a mistake, because I just tried it again and it does exactly what I need it to.
The format looks incredibly convenient, but if I’m understanding this correctly, after I parse a file, I still need to hand code the logic that converts the parse result into my data structure, right?
I believe it's not the author, but the publisher who is be responsible for content quality. Authors usually want to spend a lot of time polishing their sketches but it's often impossible because of tight deadlines and poor support from the publisher. &amp;#x200B; A friend of mine spent huge amount of time on his Haskell book (since he really wanted to deliver first class content) but in the end his contract was terminated by the publisher.
I love the Programming Rust one. It explains things down to the metal. Easy words, no wordplay fuss, practical example. 9/10.
I noticed that when you do `this.set_state()`, `this` is actually a shared reference (a `&amp;Self`), not a mutable reference that you might expect for a `set_` method. Why is it not a `&amp;mut Self`, especially if you do mutation through it?
nice
&gt;story). Personally I went with Go for my current project while this is being hacked on and am waiting for the day I can switch confidently Yea I'm doing the same.
[@atomic's latest tweet](https://i.imgur.com/ohocGUh.jpg) [@atomic on Twitter](https://twitter.com/atomic) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Not starting a bar chart at 0 is a common and very misleading mistake. If nothing else, that needs to be fixed soon. 
unfortunately, there's no link to the code used for the pest graph, so I had to start from what I had available
[This graph](https://i.imgur.com/jLY7WdW.png) comparing the performance with other parsers is extremely misleading and off-putting. Otherwise it looks like a nice parser.
&gt; This looks interesting, I may have to reevaluate my use of nom. Not if it is [about performance](https://unhandledexpression.com/general/2018/10/04/no-pest-is-not-faster-than-nom.html).
Ah yes, starting at a non-zero value when you plot a graph, the oldest trick in the book, one of the cardinal sins in statistics. I also don't understand what correctness means on their website, quoting from pest.rs "By leveraging Rust's memory safety guarantees, parsing will run within the confines of its specified grammar. Any issue will be fixed from there, in a declarative fashion." There are plenty of memory safe parsers out there, and I'm not sure if any of them ever made any claim close to this one.
`&amp;[&amp;str; 3]` and `&amp;[&amp;str; 2]` are different types. You want to use `[&amp;str]` instead: [&amp;arr1[..], &amp;arr2[..]]
It looks like [the docs of quicksilver on docs.rs](https://docs.rs/quicksilver/) are missing. If you use the docs.rs search tool, you can get to [essentially the readme](https://docs.rs/crate/quicksilver/), which has a banner suggesting a build error for the latest version of quicksilver (0.3.0) is to blame. Perhaps the crate's contributors are on /r/rust and can fix the issue.
&gt;Pests on popcorn
Or one could check their issue tracker, which would reveal [they are already aware of the issue](https://github.com/ryanisaacg/quicksilver/issues/378). Looks like it would be easy to fix.
No, it's just you usual CSS + JS. WebAssembly is used only for the fiddle.
Is the wasm part only the bottom pest try it yourself thing?
Worth reading just for the owl gif at the end. It's annoyingly easy for this kind of chicanery to occur, even when people are well-intentioned and just a little careless about their number crunching. I'll personally give `pest` the benefit of the doubt, and attribute the errors to sloppiness rather than malice. This time. But let's also keep each other honest. :-)
Yeah, especially this sentence was hard to… well, parse: &gt; Any issue will be fixed from there, in a declarative fashion 
Well at least pest grammar is superior to shitty macros :D
Such an obnoxious title!
I think you could benefit from [`memchr`](https://docs.rs/memchr) and [`memmap`](https://docs.rs/memmap/) crates. Because you return `String`s memory maps should be completely safe for you if you'll first copy binary data to heap and then validate that it indeed contains a valid string.
Oops, sorry, I don't know how I missed that. I had even checked their issues. [Issue 344](https://github.com/ryanisaacg/quicksilver/issues/344) had caught my eye since it discusses docs, but for that issue they still assumed the link to https://docs.rs/quicksilver worked. I must have read past issue 378. Still, they just state that docs.rs is "flaky", which doesn't necessarily mean that they know that the current version is down.
I have to say that I love your dedication! I never meant to make nom look bad; adding ANTLR to any of these benchmarks would make the difference between the native parsers invisible. I guess the charts are off-leading if performance is your choice factor between the two libraries, but that makes little sense to me at these levels, anyway. If performance competition was my goal, I would have compared against rust-peg or lalrpop which are comparable libraries to pest. Thanks a lot for going through the effort! I'll update the values when I get home.
That's a fair point. I'll change the way that's phrased when I get back home today. However, it is not uncommon for software to make claims about what it does without being formally verified.
Yes.
Thanks. If I understand you correctly, that's what I'm trying to do in the second and third stanzas. And I think second stanza works because I'm explicitly using `as &amp;[&amp;str]` to force the type. But why doesn't the third stanza work? If `arr1` is of type `[&amp;str]`, then shouldn't `&amp;arr1` be of type `&amp;[&amp;str]`? To clarify, here's the error message for the third stanza. error[E0308]: mismatched types --&gt; src/main.rs:18:24 | 18 | for arr in [&amp;arr1, &amp;arr2].iter() { | ^^^^^ expected an array with a fixed size of 3 elements, found one with 2 elements | = note: expected type `&amp;[&amp;str; 3]` found type `&amp;[&amp;str; 2]` 
Wait, I think I got it. `I DECLARE THIS FIXED` Yep, all good now.
Totally for it! I honestly wish there were people helping out, in a gathered effort, who want to get performance benchmarks and make this a bit more federated. I wasn't able to invest a lot of time in this, unfortunately, but I'm more than happy to have your time spent doing comparisons be used more than just to prove a point: feel free to open a PR!
Combines some popcorn with salt and butter.
&gt; Worth reading just for the owl gif at the end. an excellent gif indeed 
Hey, What is the best (i.e. most efficient &amp; idiomatic) way to this: ``` pub struct A&lt;T&gt; { size: usize, data: [T; self.size], } ```
What is the most efficient (performance-wise) way to create fixed-sized array (do they even exist ?) ?
The website timed out for a little while. Must have been the pest guys pounding on the server door.
pest has its own strengths, especially readability and nice error messages :) Also the benchmarks still show that they are in the same range, which is awesome!
This is interesting. I'll make some tries asap
Depends on what the values are supposed to be. If all values are the same, the `[value; NUMBER]` syntax is the most efficient way. For other cases, you will likely have to use unsafe code for maximal efficiency.
What I meant to say was that the user would fix the issues from the grammar, not messing around with pointers and indices.
See my comment above. I don't think there's any need to be too cheeky about it.
Absolutely disgusting
This is my proposal: I'll write a pest grammar parser in nom and make a benchmarm that compares performance in more complex grammars and I'll just add it to the parser benchmarks repo.
that would be extremely nice :) I have to improve nom on parsing text languages
Maybe you are using a extensions like "care your eyes" ?
You are looking for /r/playrust. /r/rust is for programming language.
unles you're going to write yor server using Rust programming langiage, you'ce on wrong reddit. Try /r/playrustservers
&gt; However, it is not uncommon for software to make claims about what it does without being formally verified. You're very correct on that, which is fine. We only feel it's a problem when non-trivial claims are made in close to absolute terms without clear mentioning of caveats/assumptions. You can see from [here](https://www.sqlite.org/hirely.html) that one of the most well-tested project, SQlite, is very careful on their wording despite their testing effort. But yes, I'll admit I probably have been overly pedantic on the matter as well, apologies if my complaints stop making any sense. Unfortunately there are quite a bit of logic/formal verification people in the Rust community, which are almost the most pedantic people you would find after mathematicians. So you might see another one of these comments again.
[actix-web has removed almost all its unsafe code](https://www.reddit.com/r/rust/comments/8wlkbe/actixweb_has_removed_all_unsound_use_of_unsafe_in/)
Are you looking for a preprocessor? Because Rust doesn't really have one - macros are part of the language proper, and are expanded by the parser. What's your end goal here?
Depends on what you want to do with it. If you're OK not having it on the stack, you can use ``` struct A&lt;T&gt; { size: usize, data: [T], } ``` but this is just a slice. You can't have your version on the stack because you can't know at compile time how big it needs to be.
It seems only fair to start the graphs in this post at 20000 and 10, respectively, to make the nom results similarly nuclear.
I would caution that starting graphs at zero is not a requirement generally. It may be misleading in this case, but imagine you have an hour long process, and you want to visualize important millisecond time differences with a graph. You won't want to start the graph at 0. &amp;#x200B; It may just be the case that graphs are often just a bad idea and we should just look at tables of numbers! &amp;#x200B;
Thanks; I think I understand. I was going off of [this](https://doc.rust-lang.org/rust-by-example/primitives/array.html) doc which gives the example let xs: [i32; 5] = [1, 2, 3, 4, 5]; ... // Arrays can be automatically borrowed as slices println!("borrow the whole array as a slice"); analyze_slice(&amp;xs); This is auto-dereference, right? I.e. it's passed as type `&amp;[i32; 5]` but the function expects `&amp;[i32]`. And it's valid here because it's a function argument? 
If `data` is an array, then its size probably won't change, and you can just remove the size field entirely. `data.len()` will give the same result.
Well, I am trying to implement a kaitai-like [1] libray in Rust. You define your file layout in a YAML file and you compile that to a rust library that does serialization and deserialization. For this it is required to have access to the parent struct (in case a substruct's size/value depends on the parent struct's value). It's quite complicated to wrap my head around this, but maybe I can live without having a `mystruct.parent` field but just a `parent` variable instead. I have to think about this issue a bit more since you should be able to access the parent's parent too (aka `mystruct.parent.parent`). [1] http://kaitai.io/
I disagree. In that case, what you should be graphing is time relative to some reference sample. I've never seen a case where a non-zero axis for comparisons like this wasn't disingenuous or at least misleading.
I've seen interop things like [rust-cpp](https://github.com/mystor/rust-cpp) but no reimplementation of the C preprocessor in rust. If you wanted to embark on this, Rust does have parsing combinatorial libraries which could help, pest and nom are the two that come to mind.
You picked an unfortunate example, because `println!` is a macro, and I think `impl Display for T` implies `impl Display for &amp;T`. So this probably does not involve auto-dereference. However, if you defined and used `fn my_println(&amp;[&amp;str])`, it would work as you described.
Since combine is mentioned as well I should also point out that the table in question uses a combine without https://github.com/Geal/parser_benchmarks/pull/18 which causes it to fail on leading whitespace and lack some optimizations. I think the repo may lack some automation to collate the results though, so I can see why maintaining it is a bit burdensome.
How does using pest affect compile times? I've gone with hand-written recursive descent in the past because using libraries made the builds so much slower.
Sorry, I meant when the siwe is not a constant! 
SAD BOIIIII
Protip: when publishing a benchmark, contacting the maintainers of the alternatives beforehand to ensure the numbers reported are not duds is better.
I agree. However, I have merely used what was already available on parser_benchmarks. I do agree that it was sloppy on my behalf, but I've only got a limited amount of time I can invest and launching 2.0 was a pressing matter.
If you do not have anything constructive to say; please pass your way.
wrong sub
Totally fair! I’ll check it out :)
The test environment should find infinite looping grammars statically, so this sounds like a bug. Could you please open up an issue with the example? Yes, unfortunately you are going to have to do this manually. Pest doesn't yet support streams as input, even though some effort has been made in the past to include this. Pest might not be the best tool in your particular case, unless you're fine with parsing everything once you know that the line has ended. (You could have a simple grammar rule that simply checks if the line ended.
I was wondering about this claim on the https://pest.rs site: &gt; Performance measurements place a pest-generated JSON parser in a competitive position against one of the most optimized JSON parsers, ujson4c Seems like Serde + serde_json outperform that pest-based JSON code by a factor of 2-6, and outperform the nom one by a factor of 1.5-2.5. Table of results: https://github.com/Geal/parser_benchmarks/pull/20 The good news is this means both pest and nom have plenty of opportunity for performance improvements remaining. :)
I'm Dutch and that name makes me giggle. Getver is a pretty innocent cuss word which is used to express disgust regarding food and/or drink. 
I want to write some productivity tools for processing C source files in order to automate some tasks that I seem to do quite often (multiple times every year). Pragmatically speaking Python would probably be a better choice for this task but I want to do it in Rust for the sake of the learning experience :-)
You have to initialize with a dummy value first and then overwrite the values. Or you can use unsafe code, but that's dangerous.
Fair enough. Would the message have been acceptable if instead expressed thus?: "I think opposing a claim by a title saying 'No, ⟨said claim⟩ is not the case' comes across as uppity, and gives the impression that it's a shouting match."
Got it, thanks for the context. A common way people deal with this sort of thing (which was kind of the subject of a [whole keynote talk](https://youtu.be/aKLntZcp27M) recently) is to keep a unified collection of "objects", often just in a `Vec`. Then instead of holding actual references/pointers to each other, objects just hold indices in the vec. Functions that need to do something to the objects take a `&amp;mut Vec&lt;...&gt;` reference to the collection so that they can traverse these "pointers", and otherwise not much about the code needs to change. Downsides: - It's a bit more verbose than just using references. (Though luckily, none of your types need to reason about reference lifetimes, so verbosity-wise you might break even.) - You can still have logic bugs if you ever delete objects from the list and then reallocate the same index. As discussed in that video, generational indices can help here. Upsides: - All safe code. Logic bugs or panics might be possible depending on your approach, but no undefined behavior from dangling pointers. - The whole state is easier to serialize, if you need to. Serialization would normally require you to replace your pointers with some kind of index anyway. - Good cache coherence. Objects packed into a `Vec` tend to perform well when you load lots of them from memory. All of this might be overkill, though, if you don't need arbitrary pointers. If you really just need some fields from the parent, you could consider passing references to those fields along with each function call that operates on the child. In general Rust will allow you to take references to independent parts of a struct at the same time, as I did in my example above. Let me know if any of that helps.
Am I incorrect in believing that deriving Clone and Copy for an enum w/o associated data is cheap? for example #[derive(Clone, Copy)] pub enum Kind { Single, Multi, Html, } Wouldn't that essentially be the same as the copy semantics of a u32?
It's very cheap! I don't think that the representation of `Kind` is actually specified, but [on the playground it's represented with just one byte](https://play.rust-lang.org/?gist=bdb7687b4f24f371e4560cbf60f7daa0&amp;version=stable&amp;mode=debug&amp;edition=2015).
Missed opportunity
I'd like to formally start the correctness and performance wars as part of the new epoch.
Yes it is. Note that the only difference between a copy and a move is that the latter invalidates the source.
Do you want [ANTLR](http://www.antlr.org/)? Because this is how ones gets ANTLR.
I'm surprised BurntSushi was down at #4! Always nice when data violates your expectations.
&gt; There are plenty of memory safe parsers out there, Including every parser written in a garbage collected language.
Huh, I was wondering when I'll peak. I guess it's all down from here
Parser benchmarks are quite hard IMO. 
Specialization, I guess. To be honest, I was surprised to learn he had so many crates to his name, I immediately think of `regex` and `xsv`, and there are probably 1 or 2 sub-crates for each, but that does not make 13.
Does anybody use `f128`? How did you compile it? I'm getting `#![feature] may not be used on the stable release channel` on stable and beta, and `unknown feature \`zero_one\`` on nightly.
Thanks!
You're definitely on to something. Look at the dependencies of regex, for example: * aho-corasick * memchr * regex-syntax * thread_local * utf8-ranges All of those---except for thread_local---are owned by me. If I were writing C, none of those would be separate libraries. They would just be part of the regex library itself. But those things are legitimately reusable. If they weren't direct dependencies, at least some of them (like `utf8-ranges`) probably wouldn't have &gt;100,000 downloads. In other words, it's "easy" to have "inflated" counts if you're already maintaining a popular library, because you might be the one that splits out some code into a separate crate. It gets downloaded a lot by consequence. Same thing for `csv` and `csv-core`. Nobody (probably) should be using `csv-core`, but it gets downloaded a lot because of `csv`. Same for `termcolor` and `wincolor`. I mean, heck, `regex-syntax` is the 9th most downloaded crate ever, but very very few folks directly depend on it. I'm sure there is a different measure one could make here by distinguishing between direct dependencies and transitive dependencies. But this is a fine first approximation. :-)
One possible hint to emphasize that a bar graph doesn't start at 0 would be to dither/fade the bars as they approach the edge, and make sure that the bar size variance nearly covers the entire axis to more clearly focus on the size differences rather than absolute sizes.
That's a good point. My viewpoint is that this is a high quality book. Got a lot out of it. Didn't find too many mistakes. The author carefully included references to specific commits so the reader can follow along smoothly. Haven't seen many books from any publisher that have done that. This thread is more about the publisher than it is about the book. I hope people give this book a chance, and post a review about what they like or dislike. Preferably after reading it. As a community, it would be beneficial to provide such feedback to one of its members, and also to encourage more books to be written for this great programming language. Literally the first review said something like "haven't read it, cheap paper, 1 star".
it is merged, thanks!
damn, that's an interesting result, I must get back to work then :D
Hats off to the maestro! When thinking about all the time spent optimizing nom/pest, this is super impressive. Seems like there's a lot of room to improve.
I believe Cargo uses the "Modify Time" to detect when a file changes but `mv` may not update that.
Yes, I do. And I hope that anyone else does. 
I really think they should sue pest for this haha :)
I really think they should sue pest for this haha :)
That feature error unfortunately means that the crate is built against a much older nightly than current. There's no direct repository link but it wasn't hard to find: https://github.com/jkarns275/f128 The code hasn't been touched in 10 months so it's unlikely to be updated anytime soon, but you might try reporting the error you're getting on nightly on the repo's issue tracker and see if the author responds. Alternatively you can try downloading a nightly from around the time the crate was last updated, so early last winter. If you use Rustup you can try `rustup install nightly-2017-12-02` and `cargo +nightly-2017-12-02`. You might have to try slightly earlier dates even: there's no way to tell what nightly the author was building against, as far as I know. The last alternative is to fork and remove the code that deals with that feature, anything referencing `std::num::One` or `std::num::Zero`. It should build on the latest nightly with that stuff removed.
Filed an issue: https://github.com/pest-parser/site/issues/1
Filed an issue: https://github.com/pest-parser/site/issues/1
Yep you're right, my comment was unfair and was simply just to make fun of the matter, which isn't very constructive. Sorry about my comment.
Why do you not like it? It seems pretty awesome to me.
Body temperature.
What's happening in two weeks?
I think cloning the [crates.io](https://crates.io) index from github and iterating over each entry to create a histogram of direct deps would probably work pretty easily. You also get to drop all the network traffic that way, which would be gentler to the [crates.io](https://crates.io) servers.
this week I'm rest 256 or 0x100
No harm done. I'd very much be interested in any formal methods to this. Rust tooling is a bit lacking right now.
Wait, is your Travis config downloading from crates? I would think it should download your crate from git and not crates. That said, if other crates that have you as a dependency use CI, that _will_ download from crates every time the Travis cache gets reset.
I wrote a \[python script\]([https://gist.github.com/ethanpailes/6b734cf99cada88a47b704fcb618caef](https://gist.github.com/ethanpailes/6b734cf99cada88a47b704fcb618caef)) to do this. The top 20 crates by direct dep seem to be: &amp;#x200B; \`\`\` ('serde', 3013) ('serde\_derive', 2405) ('serde\_json', 2224) ('libc', 2078) ('log', 1920) ('rand', 1782) ('clap', 1498) ('lazy\_static', 1383) ('regex', 1083) ('hyper', 1078) ('futures', 1010) ('byteorder', 978) ('chrono', 845) ('failure', 825) ('env\_logger', 819) ('winapi', 779) ('url', 747) ('time', 673) ('error-chain', 668) ('rustc-serialize', 660) \`\`\` &amp;#x200B; The script will automatically download a [crates.io](https://crates.io) index, so it should be super easy to run and tweak. &amp;#x200B; I'm sorry for posting python code on /r/rust, but I knew it would be easy to rip off the regex crate's [crates.io](https://crates.io) scraper.
Aha, yes it works well enough: https://github.com/peterjoel/pest_calc/blob/master/src/main.rs 
Well, these are both noncommercial open-source projects. I do wish pest would clear up the misleading graph (there's no competition in open source), but there's nothing at stake to "sue" over. (That's why you're getting downvoted btw. It's just such an out of touch statement that people think you're crazy, but it's okay, we all start somewhere 😊)
crater/cargobomb don't matter for this measurement though, as they apply to all crates equally. (Well, I suppose it benefits older ones.)
I don't think this thread was about what steve was doing? Even so, crates with many versions are affected more strongly as are older ones (as you mentioned).
I would have expected you to exclude crates created by bots. Everything by Alex should clearly be excluded here.
Oh weird! Can you trick git in the same way?
Not to be mean, but I sure hope you're joking. I'm working on pest for free and out of my own time and passion.
It only counts downloads in the past month, so this effect is pretty limited.
But inside `bar`, the only guarantee we have is that `T::Inner` impls `B`; we know nothing else about `T::Inner`. Why can't the compiler figure that out? Am I missing something obvious? 
There are two reasons for that: 1. If it were `&amp;mut self` then you would mutate even the props. 2. `set_state` mutates a `Component::State` type not the component itself i.e. it mutates a state type wrapped in `Rc&lt;RefCell&lt;T&gt;&gt;`. This provides for a way to check if any state has changed. The component is updated with the new state in the next cycle (not immediately like React).
Do you know if Rust pays special attention to RVO, specifically? Not because they're special, but that's a major C++ optimization, and if LLVM does it then rust probably benefits implicitly
You're comparing synchronous code with tokio code, it would be nice to have threaded code (rayon/par_iter) as well as a comparison. I suspect it would as fast as the Tokio version and look less noisy, but I'm not sure at all.
For context: https://www.reddit.com/r/rust/comments/67x46l/announcing_rust_117/dgu8tgb/?context=5
You have to add pub to every function to return asm.
I highly advise Rocket by Sergio Benitez. I will admit i am very biasedd as I was his student in an OS class he taught in rust :)
It's odd that serde is used more than log, because not everybody needs serialization but everybody has logs (at least for debugging purposes). No?
So would you be open to PRs if somebody with enough spare time would be willing to RIIR?
&gt; You can absolutely claim there is a heavy focus on correctness(via fuzzing, careful audits etc), but stating in absolute terms especially with no mentioning of any caveats/assumptions or methods is certainly not the way to do it. Rust's front page does it when it guarantees memory safety without caveats.
You can println! all the way but there's no easy way to force a struct into a tcp socket:)
On Linux you can use `sysprof` to find out where that time is spent. It's got a nice GUI too. On your Ubuntu box that's `sudo apt install sysprof`
A rust char is always 4 bytes or 32 bits. Did you mean to post to a different subreddit?
Ah, thanks. 
std pretty much just calls stat as well. So probably would not make a difference. 
How about writing a C implementation which also goes through libc if that is slower as well?
Not quite! `char` is 24 bytes. The remaining bits can and will be used by the niche filling optimization. https://play.rust-lang.org/?gist=fe0238b11202753ff65c6404a1e563f5&amp;version=stable&amp;mode=debug&amp;edition=2015 (I would use a `NonZeroU8` but the compiler isn't quite smart enough for that yet. But that layout is fairly simple and valid: `[Non0u8][---------char---------]`)
Just wrote the same in C, it outperforms Go i.e. about \`100-105 ms\`. 
&gt;in an asynchronous fashion I am not sure async will help here. Besides, I think go does not do async disk IO, so it is on-par with Rust in this aspect atleast.
Ah, didn't think to check there. Good to see you guys actively improving the security of the Rust ecosystem, great work! I hope to be part of this effort some day once I've become more knowledgeable in Rust :)
I hadn't run it and prefed it, I am on my phone but seeing a println inside a hot loop let's me questioning if you are benchmarking println here. println is locking stdout ...
It's just the error path, doesn't change anything :)
Well with snaps and other packages existing for ripgrep, those downloads won't count on crates.io.
You re right. Callgraph link: [https://imgur.com/a/rA2TpMX](https://imgur.com/a/rA2TpMX)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/0qfT4aN.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
&gt; I'd love to have a benchmark against Serde JSON parsing too! That would make the performance claims somewhat less compelling. Serde is 2x - 6x faster right now. :D https://github.com/Geal/parser_benchmarks/pull/20
&gt; I think what bothers me is talking about someone's work as if they're not in the room, when they might well be. I posted on a subreddit about Rust about a book about Rust. How am I talking about the author as if they're in the room? Give me some credit here. I refrain from attacking the author personally (I mean, why would I). But saying that somebody does not have the basic understanding of something to write a book about it (which I've shown with an example) if perfectly fine (albeit possibly negative) feedback. Don't you think?
&gt; But if not thinking about title it was the only packt book that i read for several years that offered some depth. What? This book was first published in May 2018.
Would you mind filing a performance bug at https://github.com/rust-lang/rust/issues ?
Is there any precedence for `PrecClimber` in other parser libraries or is that your own invention? I am used to expressing precedence in the grammar and that took a bit of figuring out.
With my actual code, I used 20 Goroutines with GOMAXPROCS=4 to scan the NAS filer. The actual threads it spawned was about 30. For disk IO it treats it as a blocking call and hence it spawns the thread. In anycase, there is async read &amp; write disk IO calls in Linux but I am not aware of any async stat call. 
So one problem is that `CString::from_vec_unchecked` causes a reallocation for your case. Usually, if you have a `String` that you know you want to pass to C at some point, it is worth to allocate it with `capacity + 1`, so that when `CString::from_vec_unchecked` is called, the null terminator can be appended without issues. 
Looking through the source for `metadata` and `symlink_metadata`, the only "extra" thing that these functions do, apart from making the FFI call to libc and checking `errno` afterwards, is that they allocate a new `CString` to store the path in. I suspect that this conversion is the culprit, since there is really nothing else going on. This allocation is necessary since libc requires all strings to be null-termianted, and a `Path` could potentially be a slice into another string. For instance, if you have a `PathBuf` containing "foo/bar/baz", you can create a `&amp;Path` containing just the "foo/bar" part without allocating. When passing this to libc, you need to copy the bytes somewhere else in order to put the null byte at the end. &amp;#x200B;
The web-sys crate looks really interesting!
Huh, did not expect to see myself there
That may have been true back then (8 years ago), but it isn't true today, at least on Linux. Memory maps can be faster for searching a small number of large files. Moreover, the OP's use case doesn't appear to be simple sequential access, so that mailing list post is doubly wrong in this context. :)
24 bits, not bytes, you mean?
In short, `strptime` function comes from POSIX. It is only required to update fields of `struct tm` that were explicitly specified in a format (but it is allowed to change unspecified fields). As a non-standard extension, glibc's implementation of `strptime` updates `tm_wday` field if any of day, month or year elements was changed. The `strptime` implementation in `time` crate is pure Rust implementation doesn't do that.
/u/fn_rust Reddit doesn't support fenced code blocks like Github. You have to indent by 4 chars instead.
It's great that Rayon could give such an easily gained speedup. I just want to correct one misconception that really comes up very often: &gt;Programs that have race conditions in them do not compile in Rust. If this were true, it would be truly fantastic. However, it is not. Rust guarantees (provided no incorrect unsafe code) that there are no \*data races\* in your program, meaning concurrent access of (mutable) shared (memory) resources from multiple threads. Other forms of race conditions, of which there are plenty, can still happen essentially as easily as in any other language. As a simple example, consider buying a couch from Amazon: * You're looking at [Amazon.com](https://Amazon.com), and you see that there is 1 couch left. * You click order. * In between "availability 1" having been shown and you ordering the couch, someone else ordered it, and it is no longer available. Now imagine that this happens between a database and the frontend, and you have a software race condition, from which Rust (in general) cannot protect you. That said, the fact that you cannot have data races in safe Rust code \*is\* wonderful.
It actually does. I think only old.reddit.com has trouble with it.
Ah okay.
How do you generate call graphs like this?
The repository is here: https://github.com/DeMille/encrusted
Didn't he just break the random number generator? The old code generated a series of random numbers starting with a single seed. Now it looks like he reseeds the generator every iteration and so gets the same numbers.
Enable symbols in Cargo.toml: ``` [profile.release] debug = true ``` Then I used callgrind: ``` valgrind --tool=callgrind --dump-instr=yes --collect-jumps=yes --simulate-cache=yes ./target/release/fstest-rs ``` Then using this python [util](https://github.com/jrfonseca/gprof2dot) ``` $./gprof2dot.py --format=callgrind --output=out.dot /path/to/callgrind.out $ dot -Tpng out.dot -o graph.png ``` 
He appears to be using a different seed for each run; note that he seeds the RNG with some member of the element he iterates over.
I think `println!` macro is pretty slow too. I have no proof though.
Add to the code in the question please.
So Reddit doesn't support fenced code blocks like GitHub ;)
I don’t believe Rust provides deadlock-safety in safe code - current std Mutex struct is not reentrant and trying to recursively lock it will result in deadlock (on some platforms; also it’s easy to imagine two threads holding two Arc&lt;Mutex&gt;es trying to acquire them in different order (Excuse brevity and no backticks, I’m on mobile)
What's the difference between `impl Trait' and `dyn Trait`?
Have you tried putting the path string into a PathBuf then calling metadata with pathbuf.as_path() parameter? 
Also the mobile web interface.
&gt; I don’t believe Rust provides deadlock-safety in safe code The `parking_lock`'s `Mutex` with `deadlock_detection` enabled is dead-lock safe. 
Go should have to do this too though, since its strings aren't NUL terminated either. Specifically, see the [implementation of `unix.Lstat`](https://github.com/golang/sys/blob/8469e314837c2e2471561de5c47bbf8bfd0d9099/unix/zsyscall_linux_amd64.go#L1814-L1825), which calls `BytePtrFromString`, which in turn allocates and copies: https://github.com/golang/sys/blob/8469e314837c2e2471561de5c47bbf8bfd0d9099/unix/syscall.go#L29-L50 Go does seemingly use raw syscalls directly here, thereby bypassing libc. I'm not too familiar with the lstat syscall, but it too appears to require a NUL terminated string? https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/stat.c#n257 Therefore, I _think_ Rust and Go should have roughly the same cost model in terms of allocations required. One other possible explanation here is that since Go uses a syscall directly, it doesn't have to go through the dynamic linker at runtime, but my intuition says that this cost should be dwarfed by the cost of the syscall itself. Looking at the Rust side of this, the implementation is basically what I would expect and should match Go's cost model, naively at least: pub fn symlink_metadata&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; io::Result&lt;Metadata&gt; { fs_imp::lstat(path.as_ref()).map(Metadata) } From `sys/unix/fs.rs`: pub fn lstat(p: &amp;Path) -&gt; io::Result&lt;FileAttr&gt; { let p = cstr(p)?; let mut stat: stat64 = unsafe { mem::zeroed() }; cvt(unsafe { lstat64(p.as_ptr(), &amp;mut stat) })?; Ok(FileAttr { stat: stat }) } where fn cstr(path: &amp;Path) -&gt; io::Result&lt;CString&gt; { Ok(CString::new(path.as_os_str().as_bytes())?) } and `CString::new` is pub fn new&lt;T: Into&lt;Vec&lt;u8&gt;&gt;&gt;(t: T) -&gt; Result&lt;CString, NulError&gt; { Self::_new(t.into()) } fn _new(bytes: Vec&lt;u8&gt;) -&gt; Result&lt;CString, NulError&gt; { match memchr::memchr(0, &amp;bytes) { Some(i) =&gt; Err(NulError(i, bytes)), None =&gt; Ok(unsafe { CString::from_vec_unchecked(bytes) }), } } and finally pub unsafe fn from_vec_unchecked(mut v: Vec&lt;u8&gt;) -&gt; CString { v.reserve_exact(1); v.push(0); CString { inner: v.into_boxed_slice() } } Which all looks about right to me? I think I now see what /u/0b_0101_001_1010 was talking about elsewhere in this thread though: this might actually wind up doing two allocations instead of one. In particular, the `t.into()` call in `new` will do one allocation and then the `v.reserve_exact(1)` call will probably force a second allocation assuming that `t.into()` creates a vec whose capacity is exactly equivalent to the minimum required. I don't think this can be fixed using the `new` API, since it requires `Into&lt;Vec&lt;u8&gt;&gt;`. So you'd want to introduce another API that knows it has to do a copy (which is always the case for most of the file system related APIs, since they operate on a `&amp;Path`), and then make sure you only do one alloc instead of two. This is of course conjecture. :-)
All the more reason I'm going to use this crate :) My flow is always broken by having to look up crates, this is a great solution! Maybe I'll stop using '*' so much during prototyping
cc /u/boyter I wonder if this is the root cause of some of the slow downs you were noticing for similar programs between Go and Rust.
Wouldn't that be more of a library feature, rather than something inherent to Rust? I imagine you could do the same in C++.
The println! macro is only in the error path.
The characters in the background are .. real characters rotated with css. wow
the author posts graphs that suggest nom is still slower than pest, though.
Yes, bits
Hey, I just tried compiling [this](https://livebook.manning.com/#!/book/rust-in-action/chapter-11/v-7/203) listing about NTP from Rust in Action, but it fails because it does not know the imports on line 219. error[E0432]: unresolved import `winapi::SYSTEMTIME` --&gt; src\main.rs:219:22 | 219 | use winapi::{SYSTEMTIME, WORD}; | ^^^^^^^^^^ no `SYSTEMTIME` in the root error[E0432]: unresolved import `winapi::WORD` --&gt; src\main.rs:219:34 | 219 | use winapi::{SYSTEMTIME, WORD}; | ^^^^ no `WORD` in the root In the [winapi documentation](https://docs.rs/winapi/*/x86_64-pc-windows-msvc/winapi/) I've seen that `WORD` is defined in `winapi::shared::minwindef::WORD` and `SYSTEMTIME` in `winapi::um::minwinbase::SYSTEMTIME`. But after changing the imports, I get the following error in line 249: error[E0308]: mismatched types --&gt; src\main.rs:249:27 | 249 | SetSystemTime(systime_ptr); | ^^^^^^^^^^^ expected struct `winapi::minwinbase::SYSTEMTIME`, found struct `winapi::um::minwinbase::SYSTEMTIME` | = note: expected type `*const winapi::minwinbase::SYSTEMTIME` found type `*const winapi::um::minwinbase::SYSTEMTIME` Does anyone know how to fix this? According to the documentation, there is no `winapi::minwinbase` module :/
He's so overloaded he can't do the hand-offs himself? That figures.
Ah, I suspect you're right. It allocates twice and copies twice, which it doesn't have to. The code could be optimized by calling `Vec::with_capacity` and pushing the contents into it, instead of `into` followed by `.reserve_exact(1)`.
There are ways to deadlock besides locks, though. For example, if you create a pipe for some child processes, but forget to close all your write ends, you can deadlock in `read_to_end()`. In general, the nomicon [has a list](https://doc.rust-lang.org/nomicon/what-unsafe-does.html) of dubious things that safe code is allowed to do, and race conditions, deadlocks, and memory leaks are all on the list.
I don't see how that's possible. A `&amp;Path` is a fat pointer to some existing memory and can be arbitrary subslice of some other region of memory. If `PathBuf`/`OsString` had a nul byte at the end, and that was actually carried through the APIs, then maybe that would help in this specific case? But I mean, this is only in the most trivial sense possible. The real meat to that question is thinking through the ramifications on all other uses, including platform concerns.
&gt; Go does seemingly use raw syscalls directly here, thereby bypassing libc. Yep, they do this even on platforms where the syscall interface isn't stable; that's why they get 100% statically linked binaries all the time, and we don't. IIRC, if you use cgo it will use libc though. 
wow! the idea is so cool. I will consider adding this feature. thank you for your suggestion :)
Right. Although, I don't know to what extent libc will be used for each syscall. While looking through the code here, I didn't see the same kind of case analysis that you see in its networking code, where it can explicitly switch between the libc implementations of certain things and its own. IIRC, it's not just cgo that will land you into libc for Go, but pretty much any use of networking with cause you to link with libc by default on Linux. You can override this though with various flags.
thanks :) that's why I made it. looking up crates really bothered me
When Rust gets a way to do `alloca` then that allocation might be avoided since it can just be done on the stack.
I think the map is awesome. Feel free. :)
Note that it's not just about locking. `io::stdout()` is itself line buffered, so if you are doing lots of iterations and each one prints a line, then you've got a syscall executing for every iteration. To fix that, you'll want `io::BufWriter`. This does of course increase latency at which lines are shown to the user, but if you're printing enough content at speeds where this matters, that's probably acceptable.
is there a Stratis quick start? also, am I reading this right that raid1 is not supported? I want to pair 2 hdds with 1 ssd for cache, and I wonder if I should go with a stratis solution. 
I use serde in almost every project of mine but rarely have logs.
And various mobile apps.
As the author explained in the paragraph following those numbers, `nom` is doing more work so the benchmark isn't an "apples to apples" comparison. A `nom` benchmark which doesn't convert to Rust types gets the following results: - canada.json: 20,623,381 ns/iter (+/- 1,952,297) - data.json: 10,757 ns/iter (+/- 1,462)
This is pretty awesome... I'm a fan of zmachines and rust (see https://github.com/olson-dan/rustzork) but you really took it to another level. And unlike most zmachines on github the code is designed well. Nice work!
I was using the latest version of both, since I didn't find a specification in the book. But it seems you're right, there is a `SetSystemTime` [function](https://docs.rs/winapi/*/x86_64-pc-windows-msvc/winapi/um/sysinfoapi/fn.SetSystemTime.html) - Using this function, the code from the listing works! Thanks for giving me the right hint :D
Those games never rust, or do they? ;)
Ah right, I forgot that exception, thanks.
Raid is not yet supported, that is correct. 
BTW I'm working on a quick start/tutorial, it's 1.0 software so there are some rough spots still.
Hello there. Suppose I have this code : `struct Something {` `value: i32` `}` and a function, `fn as_something() -&gt; Something {` `// code goes here` `}` How do I make this function callable after Vector declaration? I want to make something like these : `let things = vec![1, 2, 3, 4].as_something();` or `let things = Vec::from(&amp;[1, 2, 3, 4]).as_something();` which lets each member of `things` to become `Something`. 
And the perf issue
Mine has no color as well.
&gt; I was using the latest version of both, since I didn't find a specification in the book. Listing 11.12. has a list of crates; I think that they carry on through the examples.
Ah, that must be part of the [libre GPU effort](https://www.phoronix.com/scan.php?page=news_item&amp;px=Libre-GPU-RISC-V-Vulkan) that Phoronix covered earlier. Curious.
If the work can be done with the C preprocessor and is working on C files, then why not simply use the preprocessor to do the work?
&gt;struct Something { &gt; &gt;value: i32 &gt; &gt;} Using \`trait\` you could do something like that: [https://play.rust-lang.org/?gist=07cfe90bebffae4c1e202f8ab9518493&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=07cfe90bebffae4c1e202f8ab9518493&amp;version=stable&amp;mode=debug&amp;edition=2015)
Whoa, suddenly surprised to see a talk about wlroots-rs when I had no idea. Will there be translations for the talks? Would like to hear what is said about my library (even if I can't fix any issues until next month) 
Yep, 600 is around what you should expect to see when parsing strongly typed data (structs and enums, rather than `HashMap&lt;String, Value&gt;`). The [serde-rs/json-benchmark](https://github.com/serde-rs/json-benchmark) repo provides throughput numbers. A different input file there hits 840 MB/s, and I have seen 1000+ on input that happens to be heavier on strings.
And please link it here :)
Oh boy, this is great stuff. I've sent the tip to guys from "Eaten by a gru", they might pimp it on their show if we're lucky :P
You're right! Totally missed that when skimming through the previous pages again :/
On my machine it does make the Rust code *slightly* faster, if not equal, by using `nix::sys::stat::lstat` with no other changes. I'm assuming due to the `CString` allocation issues others have elaborated on.
I’d love to know as well
Since everyone seems to have decided to come back to this thread and complain about the benchmark debacle, I thought I'd leave a positive comment. Assuming all of the benchmark stuff gets sorted and [we all hug](https://old.reddit.com/r/rust/comments/9lc6tg/no_pest_is_not_faster_than_nom/e75md08/), none of the complaints will matter in a week. Because of `pest 2.0`, I was able to finally write a parser I'd struggled trying to write for several weeks. I spent hours reading through the `nom` docs and every 'getting started' blog post out there, but I could never grok it. I have never written a parser, but needed something simple and somewhat modular. With in 2 hours of reading this announcement thread I had a semi working parser and by the end of the day I had an MVP of that project done. Thank you, /u/dragostis, for writing a parser for the people.
Oh interesting! That's cool. nix is doing stack allocation. See: https://github.com/nix-rust/nix/blob/771a2fc793f3b1a1d85408578ff3b054f22b041b/src/sys/stat.rs#L96 and https://github.com/nix-rust/nix/blob/771a2fc793f3b1a1d85408578ff3b054f22b041b/src/lib.rs#L213
That would be great! Unfortunately, I don't know of anything like that currently.
The OP could also try something like [`hyperfine`](https://github.com/sharkdp/hyperfine) in the absence of wiring up the benchmarking frameworks of each language. It won't give perfect results compared to a true bench framework, but it's better than nothing :)
GLSL is the OpenGL Shading Language. Quasiquoting enables you to use GLSL directly into Rust and have it verified by rustc at compile-time. The current version only performs formatting analysis. No semantic analysis is correctly available in the `glsl` crate, but I plan to fix that at some day – maybe with your help? &lt;3
This is neat! Thanks for creating it! Looking forward to where it goes :) 
Good work! Really neat to see quasiquoters make their way into the rust language.
&gt; I'm sorry for posting python code on /r/rust Nothing to be sorry about! rustc's codebase itself is built using a script called `x.py`! 
/r/playrust
Using `rustc` directly will allow you to operate on individual source files.
This is too broad for me, I'd spent my whole life looking for what I need there. Could you point me somewhere there which can at least help me?
You can use `rustc --emit=asm`, but you're right that the translation unit here is an entire crate. There's no way to do this for a single module file within a crate.
Just I thought of extending `disaster.el` so that it supports rust (I think that would be very cool) but since it needs the whole crate to be compiled with all its dependencies, I doubt this would be helpful or even usable. Okay.jpeg
[Okay.jpeg](http://i.imgur.com/42G7fd8.jpeg) --- ^(*Feedback welcome at /r/image_linker_bot* | )[^(Disable)](https://www.reddit.com/message/compose/?to=image_linker_bot&amp;subject=Ignore%20request&amp;message=ignore%20me)^( with "ignore me" via reply or PM) 
Hey, cool, I tried my hand at doing something like this once! Was going to write a procedural macro that turned a Rust `mod` containing functions with Rust-like syntax into a SPIR-V module, statically compiled into bytecode and the required entry points. I gave up upon realising that writing compilers is hard.
You might be able to implement it using [cargo-asm](https://github.com/gnzlbg/cargo-asm). It may not be fast if the whole crate needs to be compiled, but it might still be useful.
What's the difference between quasiquoting and an actual macro?
I was messing with macro's, and I noticed this when exporting macros. [Easy clone](https://github.com/rubdos/macro-hierarchy-mwe): `src/lib.rs` mod foobar { macro_rules! bar { ($i:ident) =&gt; {struct Bar;}; } #[macro_export] macro_rules! foo { ($j:ident) =&gt; { bar!($j); }; } } `tests/foo.rs` #[macro_use] extern crate macro_hierarchy; mod m {} foo!( m ); `cargo test`: error: cannot find macro `bar!` in this scope --&gt; tests/foo.rs:6:1 | 6 | foo!( m ); | ^^^^^^^^^^ | = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info) Also getting stuff about `bar!` not being used. Do I miss something here?
Same here, I had no idea of this talk either! I hope the talks will be recorded. 
Yeah `rustc` needs a manual page, or an official documentation for its `cli` flags. Try some: rustc -C opt-level=3 --emit asm -o "${MY_FILE}.asm" "${MY_FILE}.rs"
comment
rebuttal
We usually record our talks (see the previous events on the site), but I can't promise it this time as we are in a new location. If three are no slides posted in a week, however, ping me and I'll bug the speaker :)
If you program it to
It depends on how you define "macro". The terms overlap, but neither is a subset of the other. In the Rust case of "macro", "quasiquoting" is not a subset of Rust macros because Rust macros require the macro's contents to satisfy Rust's parser. (eg. The `&lt;script&gt;` tag in HTML is an example of quasiquoting. It works even if you don't wrap the JavaScript source in something like `//&lt;![CDATA[` and `//]]&gt;`. (Which is the XML/XHTML equivalent to using `glsl_str!` instead of `glsl!` here.)
Macros don't follow the normal scoping rules of rust,they can only see the macros that were imported where they are used.This is why it tells you \`cannot find macro \`bar!\` in this scope\`. Either export both macros,or rewrite it to something like this: mod foobar { #[macro_export] macro_rules! foo { (inner;bar; $j:ident )=&gt;{ struct Bar; }; ($j:ident) =&gt; { foo!(inner;bar; $j ); }; } } In the future you will be able to do this with macros defined with the macro keyword. &amp;#x200B; To use items other than macros inside macros you can use the $crate path which expands to the root of the crate wherever the macro is invoked.
What is the question? Now is October, i read this one in August 
Is there a difference between —release and opt-level=3?
https://unhandledexpression.com/general/2018/10/04/no-pest-is-not-faster-than-nom.html
nope. Cargo's `--release` trigger's `rustc -C opt-level=3` when compiling 
This looks like a plain diagnostics error to me- I can't think of any reason rustc would report it like this. I doubt the way the type checking was done has anything to do with why the error is like this. In my understanding the errors are put in whatever order makes the most sense for a given situation regardless of the way rustc couldn't unify the types. Could you possibly open an issue on https://github.com/rust-lang/rust/ for this bad error reporting?
Could you also generate one seed for each thread/run using another PRNG?
Also note that while `char` in Rust logically represents a Unicode Scalar Value, which *could* be stored in as few as 21 bits, the Rust `char` type is encoded as a UTF-32 code unit, which is physically stored as 32 bits in memory. (However, as mentioned in another comment by CAD1997, the compiler knows that many of those bits will always be zero, and so in some cases will reuse them for other purposes.)
I don't know where I got 24 from then. /Shrug
i would suggest you find a repo about something you are interested in and dive in! &amp;#x200B; any sorts of programs you want to learn more about? like graphics, web stuff, etc.?
I had the same result as you did comparing `rustc -O` and `go build` of the sources given in the OP: rust code faster than go.
why do you have `T: From&lt;Scalar&gt;, Scalar:From&lt;T&gt;`? `T:From&lt;Scalar&gt;` should be enough
assuming `x:T,y:T`
In practice I think that likely helps, but my understanding is that the "right" answer is no: independence of separately seeded streams is just not a mathematical property of most PRNGs. I'm not really an expert on this topic, though.
This documentation says that release uses opt-level=3: https://doc.rust-lang.org/cargo/reference/manifest.html#the-profile-sections If that isn't the case anymore, it would be good to update the docs. 
I managed to trigger an error in Zork 1 with the command “Walk through the door”. 
It is still opt-level=3: https://github.com/rust-lang/cargo/blob/6f9ef6eb642a6bba9f88ff0d7a5a23f1103d3df7/src/cargo/core/profiles.rs#L469
For a progress bar, take a look at \`indicatif\` ([https://crates.io/crates/indicatif](https://crates.io/crates/indicatif)). &amp;#x200B; \`reqwest\` ([https://crates.io/crates/reqwest](https://crates.io/crates/reqwest)) can be used for simple (synchronous) downloads. &amp;#x200B; To use a progress bar during download you'll need something async for the download part as the download part needs to report its progress in some way. You might also take a look at curl's binding, maybe it offers this (I don't know, never used it).
Heh, that's not really the case :) That comment was a bit of an intentional confusion of cause and effect. The goal is actually to help set up more accessible maintership structures around fundamental crates, especially those that have fallen by the wayside in the nursery. alexcrichton helped originally put together a lot of those crates.
[https://blog.semicolonsoftware.de/building-minimal-docker-containers-for-rust-applications/](https://blog.semicolonsoftware.de/building-minimal-docker-containers-for-rust-applications/)
That is really smooth and beautiful. Thanks for this excellent piece of work!
&gt; ::&lt;i32, _&gt; Excelent, this was the missing piece.
However, I hit another weird thing, this not work: fn bin_op_by&lt;T, Op&gt;(op: Op, x:Scalar, y:Scalar) -&gt; Scalar where Op: FnOnce(T, T) -&gt; T, T: From&lt;Scalar&gt;, Scalar: From&lt;T&gt;, { //bin_op(op, x.into(), y.into()) match (x, y) { (Scalar::I32(a), Scalar::I32(b)) =&gt; bin_op::&lt;i32, _&gt;(op, a, b), ^ the trait `std::ops::FnOnce&lt;(i32, i32)&gt;` is not implemented for `Op` } } 
This is not weird, and I already mentioned this: because `i32` is not `T`. Generic parameters are chosen by the *caller*. You do not get to decide what `T` is going to be inside your function. If you want to do something, *anything* with a generic type, you need to go through traits you've explicitly stated that type must implement. It doesn't matter if `T` *might* be `i32`, the compiler will only allow what it can prove is *always* valid. Also, you cannot pass a generic thing as an argument. `Op` has exactly *one* type. It supports being called with `(T, T)` *for one and only one specific type `T`*. Not for all `T`, or many `T`. *One.* And you don't know what that `T` will be. The caller can choose which `T` and which `Op` to pass, but they still have to pick *just one of each*.
I would add if you are making https requests and depend on openssl you will want to add the CA cert similar to what is described here https://github.com/gliderlabs/docker-alpine/issues/260. In my containers in production I use a multistage Dockerfile based on Alpine that retrieves the cert and then copies it on to a container running scratch with just the certs and my executable.
I suspect that sequential pruning is going to give a way more than 4x speedup. Look at alpha-beta and at the tricks used for stochastic tree search in Mogo.
There’s docs at https://doc.rust-lang.org/stable/rustc/ They’re pretty basic at the moment but it does exist!
Thanks, this is what I wanted to do. 
I think at this point the solution is just to use chrono? I don't *think* it'd be a breaking change but there are tons of nonideal things about `time`.
That's what you usually do in massively parallel code. You need an RNG implementation that lets you have multiple independent generators (not all do). You'd use them in two ways: When all threads need to agree on the random number they all seed a generator with the same seed, then they're very careful to always pull the same number of random numbers from it to stay in sync. For example, you may want to initialize a system to a random state, and all threads need to do it in the same way so they agree on the state. The second is as you say to seed them with different seeds, and they all get a different sequence of random numbers. With a good generator it really doesn't matter which seeds you use, so all code I've seen usually just adds the thread index to the "master" seed and uses that. 
I read [this](https://mattgathu.github.io/writing-cli-app-rust/) tutorial the other day. I hope it helps.
I guess really what you'd need to be portable would be a `FullPath` or `PathSuffix`; a `PathBuf` or various other things (`CStr` on posix) could be turned into that without a copy.
OP link is to the Github mirror of the [Gitlab Redox/relibc](https://gitlab.redox-os.org/redox-os/relibc) repo for some reason. Looking at the Gitlab issue tracker, it looks like there's still quite a bit of…opportunity for folks to contribute.
Not necessarily. While `reqwest` has a (hidden) async API, you don't need it. Wven with a sync API, you get a stream, so you can still report progress between reading chunks.
we use multistage builds in [sozu](https://github.com/sozu-proxy/sozu/blob/master/Dockerfile) to separate the build phase. The resulting container is about 41MB, but I suspect we could reduce it further.
Thanks for posting this. The [Libre RISC-V](http://libre-riscv.org/) stuff Luke Leighton's organising is really cool. Eventually we will have fully open, auditable computers.
The proc-macro crate itself can definitely depend on `std`. It's built for and executed on the machine currently compiling the code, and there's no `rustc` without `std`. The code you emit from the proc-macro, on the other hand, won't be able to use types from `std` since it's getting compiled into the `no_std` crate. That'd kind of defeat the purpose, no? (Come to think of it, there's no way currently for a proc-macro to tell if it's being invoked from `no_std` code besides explicitly telling it in its input. Seems like a missing feature to me.)
The distinction between -O2 and -O3 is usually not about "more insane" in terms of UB exploitation. It's about speed vs code-size trade-offs and speed vs compile time trade-offs. So -O3 might enable more aggressive loop-unrolling (increases code size), or perhaps an O(N²) analysis.
/r/playrust
If the no_std crate uses the same dependencies as the proc-macro, then the std feature leaks from the proc-macro into the no_std crate though. So you need to be very careful using proc-macros in no_std crates. Essentially cargo doesn't differentiate where features are coming from, so features activated by dev / build / proc-macro dependencies will leak into your normal dependencies.
*** u/daboross, you've [been sent](https://explorer.bitcoin.com/bch/address/bitcoincash:qrelay2k463x9585s2l7tur3apfdkjludvxast6qzy) `0.00784115 BCH`| `~ 4.05 USD` by u/eyeofpython via [chaintip](http://www.chaintip.org). Please [claim it!](http://www.chaintip.org/#claim) *** 
That seems like a Cargo bug. Has it already been reported on the issue tracker?
Yeah it's been known for a very long time.
No problem, glad you got it working! Honestly I'm inclined to think `read` being missing from `tokio::io` is a bug. Everything else in `tokio::io` is simply a re-export from`tokio_io` anyways (https://github.com/tokio-rs/tokio/blob/master/src/io.rs#L64). I've opened https://github.com/tokio-rs/tokio/issues/688 to address this. Re: stack arrays: Agreed that this is annoying. I think the standard library has decided to not do anything for this until we get const generics, but in the meantime, the [arrayvec](https://crates.io/crates/arrayvec) crate provides more useful array types. It has a bit of overhead in that it stores a length, but they're available in many more sizes and implement traits missing from bigger raw arrays.
Rust 1.26? This should totally work with 1.0 😄
I remember doing C++ plugins back in early years of century when the ABI (and name mangling) were still in flux. Things worked. As always this requires consistent attention to dynamic linking otherwise you do not get a single allocator. Cargo is not very good at dynamic linking so my Rust experiments have been using rustc directly. 
Mike, this is great! I'll read the code of yours like it's holy :) I wonder why you split up your project into several crates? To reduce compile time? Or because you use them elsewhere too?
Why did you create this crate?
I assume this is a parody of the `is-odd` type packages that plague the JavaScript ecosystem.
That's a lot of code for such an easy operation...
Maybe we could get a channel in Rust's discord about this?
So is it considered too difficult to solve, a non-issue, or no one's gotten around to it yet?
Argh. Code generation bugs are the worst :(
I don't have the solution, but the same problem... i've started to experiment witz ggez (which uses sdl2 under the hood) and it stopped working after updating to mojave in the way you described. I didn't had the idea to move the window around, so i figured it was just broken. So you actually helped me quite a bit with your question. Maybe it has something to do with the opengl deprication in mac os majove?
If it were me debugging this issue, I would first try to reduce the code to the bare minimum that can reproduce the issue. extern crate sdl2; use sdl2::pixels::Color; pub fn main() { let sdl_context = sdl2::init().unwrap(); let video_subsystem = sdl_context.video().unwrap(); let window = video_subsystem.window("rust-sdl2 demo", 800, 600) .build() .unwrap(); let mut canvas = window.into_canvas().build().unwrap(); canvas.set_draw_color(Color::RGB(0, 255, 255)); // Note: No event handling, you have to kill the process to quit loop { canvas.clear(); canvas.present(); } } This should show a cyan colored window. Does it still show as black until you drag the window? If so, I would next try to reproduce it using bare SDL and C, leaving the Rust SDL bindings completely out of the equation. If the problem still persists, then it's either a problem with SDL, or your local system (video driver, etc.).
This is one of the issues about this problem: https://github.com/rust-lang/cargo/issues/5730
&gt; This should show a cyan colored window. Does it still show as black until you drag the window? It showed a cyan window. Hmm. Thanks. 
As the next step, I advise you to keep experimenting with the example program until you can determine which line(s) of code cause the blackness until you move the window.
I believe this is a bug in SDL2 and its interaction with Mac Mojave, as discovered by [this awesome person](https://github.com/ggez/ggez/issues/478). The SDL2 bug is here: &lt;https://bugzilla.libsdl.org/show_bug.cgi?id=4272&gt;
Ultimately, it's the [event_pump.poll_event()](https://rust-sdl2.github.io/rust-sdl2/src/sdl2/event.rs.html#1653) inside the poll_iter() call that causes it. #[macro_use] extern crate log; extern crate simple_logger; extern crate sdl2; use sdl2::pixels::Color; pub fn main() { simple_logger::init().unwrap(); trace!("Init"); let sdl_context = sdl2::init().unwrap(); let video_subsystem = sdl_context.video().unwrap(); let window = video_subsystem .window("rust-sdl2 demo", 800, 600) .position_centered() .build() .unwrap(); let mut canvas = window.into_canvas().build().unwrap(); canvas.set_draw_color(Color::RGB(0, 255, 255)); canvas.clear(); canvas.present(); let mut event_pump = sdl_context.event_pump().unwrap(); let mut i = 0; 'running: loop { trace!("loop"); let _event_option = event_pump.poll_event(); canvas.clear(); i = (i + 1) % 255; canvas.set_draw_color(Color::RGB(i, 64, 255 - i)); canvas.present(); } } 
Yep, I have a branch with that as well. It could be a good starting implementation.
Next, I would try replicating this code in C and SDL. If you can't reproduce the issue in C, it's likely that this is a problem with rust-sdl2, at which point you should submit a bug report at [https://github.com/Rust-SDL2/rust-sdl2/issues](https://github.com/Rust-SDL2/rust-sdl2/issues).
TIL SQLite doesn't enforce foreign keys by default. I think you want `connection.get_result`: `execute` returns the number of affected rows.
Interesting; what do you think about [this review](https://www.reddit.com/r/rust/comments/9l2rmk/meta_beware_of_books_published_by_packt_low/) of `Hands-On Concurrency with Rust`?
This was really helpful thank you!
Yeah. SQLite has a strong backwards compatibility guarantee so a lot of performance improvements (eg. WAL mode) and features are opt-in.
It is considered both very important, and extremely difficult to solve.
&gt; To use a progress bar during download you'll need something async for the download part as the download part needs to report its progress in some way. You don't need async download to use a progress bar, just that the download be done through a Reader of some sort: read some bytes, update progress bar, repeat.
I did that because that's we're I found it. 
With that said, it's complete enough that software like opens, curl, etc. are functional.
Here's an example dockerfile that builds a 2MB rocket image. https://github.com/softshellack/okcjug-2018-07/blob/master/hello-rust/Dockerfile
I'm decoding some JSON with Serde. The data I care about is nested inside other data. I managed to get it to work, by decoding to a generic Serde value, then re-encoding the data I care about as JSON, then decoding into a Vec of my struct. [https://play.rust-lang.org/?gist=61c1a3f573a3fbe1f73d6e1bc63643e4&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=61c1a3f573a3fbe1f73d6e1bc63643e4&amp;version=stable&amp;mode=debug&amp;edition=2015) Is there a better way to do this?
Thanks for the reply. I think all of those requires some domain knowledge. I have no knowledge in graphics, systems programming, games. My background is primarily web development.
I've heard that they've stopped doing it on macOS. Apple really didn't like them doing that. Though, to a first approximation, everyone deploying Go in production is using Linux, so it doesn't really matter.
Thanks! Code is undercommented as solo side projects often are, but I'll hopefully find the time to rectify that at some point. &amp;#x200B; Several crates: In theory, this is meant to be a general framework for emulation. Although right now it all boils down to a command line program using SDL for multimedia, I want to be able to swap out SDL for other libraries, I want to provide a Python interface for a debugger and for poking/examining memory, and several other goodies. So I didn't want to cram all that into one crate. Also, there's a \`euphrates\_x64\` crate that gives a performance boost but doesn't work on every CPU, and a \`euphrates\_virtual\_memory\` crate that uses virtual memory for memory banking, which is more performant and will be utilized heavily when I eventually get around to that dynamic recompiler but only works on Unixy systems. &amp;#x200B; Yes, this is my first emulator. 
The [nix](https://github.com/nix-rust/nix) crate provides safe bindings for the vast majority of libc functions, including [lstat](https://docs.rs/nix/0.11.0/nix/sys/stat/fn.lstat.html). Worth switching to if you have a specific performance reason (or need to use a call that is not otherwise present in std).
I do not know how to ask cpp to do partial evaluations. I have related post in r/gcc if you might have some ideas how to achieve that: [https://www.reddit.com/r/gcc/comments/9lcn4u/how\_to\_strip\_a\_single\_compilation\_flag\_from\_a/](https://www.reddit.com/r/gcc/comments/9lcn4u/how_to_strip_a_single_compilation_flag_from_a/)
So if I have a no_std crate whose only dependency is the proc-macro crate, std will leak into it? 
&gt; Because 1 and 2 are not of type T. This is what bug me. Is not the point of generic to define T so I can pass any value (that match the constrain)? I never found this problems on other languages. So, why is Rust being pedantic here, what exactly is his definition of generics?
you need to call pump events every frame
I didn't realize that the Julia project implemented their own libm
Something like that is way over my head, for now at least. But as far as I can tell, there's no runtime overhead when using the state machine. The only runtime overhead you do get, is when you use the machine as an enum variant, but that's the overhead of the enum itself, and there's no requirement to use that. I am (and plan on extensively) using this state machine in my game, and performance is critical, so any change that can make this better than it currently is, is more than welcome, and presumably also useful for the use-case you mentioned.
I see that crti and crtn were implemented. I might be able to rebuild entire OS packages with this now!
I think I went into reading the book with much less background on systems programming than the poster of that review. The book exposed me to several topics around performance testing and memory safety that I hadn't seen before.
I think \` for event in event\_pump.poll\_iter() { \` should have the same effect. &amp;#x200B;
The thing that absolutely kills me about this is 70 commits in the repo.
Is the underlying LLVM bug figured out yet, or still unclear?
Ok, that's what the original example from rust-sdl2 used. Does not work due to a possible bug in either SDL2 or macOS Mojave.
You're right -- i think /u/steveklabnik1 just recently have shown how it is done in [Who authors the most popular crates on crates.io?](https://words.steveklabnik.com/who-authors-the-most-popular-crates-on-crates-io)
I reread this I think I get it now. I hit this same problem before: https://www.reddit.com/r/rust/comments/9j8o8e/how_pass_a_closure_with_generics_to_a_non_generic/ Then the problem is how archive the intended effect. 
In the past I have used mockito (https://github.com/lipanski/mockito) for testing at the client layer. I strongly prefer it to the trait approach. My issue with the trait approach is that generics poison the signature of anything that sits on top of the Client layer. The only fix to remove this generic signature poison is to use a dyn Trait which is unideal as well. Another worthy mention is mocktopus (https://github.com/CodeSandwich/Mocktopus). This crate allows you to create mocks when running in #[cfg(test)] such that you do not need to add generics simply for testing. It is not 100% ergonomic yet but I am sure they accept pull requests to make it better. 
```rust #[derive(Debug)] struct Foo { bar: Option&lt;String&gt;, } impl Foo { fn new&lt;S: Into&lt;String&gt;&gt;(bar: Option&lt;S&gt;) -&gt; Foo { Foo { bar: bar.map(|c| c.into()) } } } fn main() { println!("Foo: {:?}", Foo::new(None)); // Doesn't compile // "error[E0283]: type annotations required: cannot resolve `_: std::convert::Into&lt;std::string::String&gt;`" println!("Foo: {:?}", Foo::new(None::&lt;String&gt;)); // Works } ``` I understand that without any type information for `None`, rustc can't monomorphize `Foo::new`. I'm not really well versed in all the internals, how hard would it be for rustc to "not care" about the type of None, until it sees it's going to be used as `Option&lt;String&gt;` in `Foo`, and maybe use that to generate the monomorphized version of `Foo::new`. My motivation is that it's meh for the user of this struct to have to use `None::&lt;String&gt;`. But I'm mostly curious.
I apologize for the confusion! I of course meant it as a joke (that's why I put the haha at the end). I do believe misleading graphs are a bad thing to do, but only if they were intentionally chosen to be misleading. Since we can never know that I will refrain from taking any stance on this. And again, to sue was only meant as a joke. I guess I estimated people's responses wrongly. Sorry for that.
It was indeed meant as a joke! I apologize if it was interpreted wrongly. Maybe the misleading part of the graph was not intentional at all in the first place.
Note the weird one: use std::marker::PhantomData; #[derive(Debug)] struct Foo { bar: Option&lt;String&gt; } struct Zizi&lt;T = String&gt;(PhantomData&lt;*const T&gt;); impl&lt;S&gt; Zizi&lt;S&gt; where S: Into&lt;String&gt; { fn new(bar: Option&lt;S&gt;) -&gt; Foo { Foo { bar: bar.map(Into::into) } } } fn main() { println!("{:?}", Zizi::new(None)); } Using such a builder type should work to me. I guess it’s `rustc` here that doesn’t quite do the things in the order I expected. But `type FooZizi = Zizi;` is authorized and you’ll get that `String` type variable set there (so we should expect `Zizi::new` to be akin to `Zizi::&lt;String&gt;::new`… right?).
Or simply provide: fn nein() -&gt; Option&lt;String&gt; { None } :–––°
Thanks for the answers! I don't think this really fits what I had in mind, (being able to specify `None` and be done with it), but that's interesting to know how it works nonetheless.
Right, or having another API endpoint, split the Some case from the None case. `impl Foo { fn new(bar: String) -&gt; Foo; fn new_none() -&gt; Foo }`
Is there a way to divide the methods of a struct into some kind of mini-mod? I've got a struct with a large amount of methods, and the doc page is starting to look ridiculous. I'd love to divided these up, but I don't know how.
 **I wish to share an actual prison breakout scenario with you guys that I’ve had in Rust during the alpha days. NOT scripted. This was a 100% organic experience and to date one of my most victorious and fulfilling experiences in a PU environment, ever.** Let me explain the context a little: I came upon a village of what appeared to be a collection of shanties - simple one room dwellings. Most of the doors were unlocked. Some were left ajar. I went into a couple, and when I turned around to leave one of them, I saw the door close. Someone locked me in. They started to talk to me, interrogating why I was there and what I was doing. I wouldn’t say, just laughing. They said I was going to starve in there, and that is where the video starts. I pinged one of my clannies to come rescue me, because frustratingly even though I had an M4 and ample ammunition to realistically blow a hole in any measly wooden door, the mechanics were such that I couldn’t. Thankfully, my boy had some C4. I had to attempt to describe to him where I was. It took him 20 minutes to find me, even though our main compound was located just a valley and some change away. He had trouble determining the exact shack I was in. That is when I threw the grenade and made a sound. He dialed in on my location and set the charge, telling me to get back. And.. well, the rest was history. Those people were history, rather :’). I’ll never forget the whole experience. Sure. I could have just logged off, leaving them to be able to loot my unconscious corpse or kill me. Sure, I could have just /suicide’d. Yet I was that immersed that my will to survive drove me to mobilize my squad. I’ll never forget the feeling of rushing out of there guns blazing. Never. And I’ve done a lot of rust. Thousands of hours. I’ll never forget that. &amp;#x200B; Thank you FP team. &amp;#x200B; \-Koa
I looked at both of the examples provided by [echo\_oddly](https://www.reddit.com/user/echo_oddly) and [Hitife80](https://www.reddit.com/user/Hitife80), and thank you guys so much, but I'm still not quite sure what the write approach is the rget tutorial uses an older version of openssl and I get an error when building it and it won't build when I update the cargo.toml to recent versions of reqwest. &amp;#x200B; Here is what my code currently looks like &amp;#x200B; \`\`\` extern crate reqwest; &amp;#x200B; use std::io; use std::fs::File; use std::borrow::Cow; &amp;#x200B; fn basename&lt;'a&gt;(path: &amp;'a String, sep: char) -&gt; Cow&lt;'a, str&gt; { let mut pieces = path.rsplit(sep); match [pieces.next](https://pieces.next)() { Some(p) =&gt; p.into(), None =&gt; path.into(), } } &amp;#x200B; fn download(url: String) { let mut resp = reqwest::get(&amp;url).expect("request failed"); let mut out = File::create(basename(&amp;url, '/').to\_string()).expect("failed to create file"); io::copy(&amp;mut resp, &amp;mut out).expect("failed to copy content"); } &amp;#x200B; fn main() { download("[http://releases.ubuntu.com/bionic/ubuntu-18.04.1-desktop-amd64.iso](http://releases.ubuntu.com/bionic/ubuntu-18.04.1-desktop-amd64.iso)".to\_string()); } \`\`\`
I'll bet r/playrust would appreciate this more.
Where do I go from here to either get asynchronous or to read how many bytes is being downloaded to feed into the progress bar?
True rofl &amp;#x200B;
/r/playrust 
I think that if you managed to define a primitive type with a 24-bit size, you'd run into weird alignment issues. That's a non-power-of-2 alignment, and I think most allocators require a power of 2. Or else the type could be 1-byte-aligned (unaligned?), which I guess would have weird consequences for the code that gets generated when you cast it around? I think there are platform reasons that this sort of thing isn't done, but I don't know the details.
&gt; You will need to patch syn to add derive(Serialize) in a few places to make it possible to dump json. Or just walk the syn data structures, pull out what you need, and dump that.
&gt; Eventually we will have fully open, auditable computers. But will they ever be price and performance competitive with the security-nightmare black boxes?
A simple project I made this Saturday to speed up my PostgreSQL laziness. I really love how easy it is to make a CLI app with \`quicli\`.
You might be interested in [rmsbolt](https://github.com/emacsmirror/rmsbolt).
&gt; or pass a different op for each combination of types. This one is how I get it, but can't figure how &gt; Have op implement Fn(Scalar, Scalar) -&gt; Scalar and do the dispatch inside op
 fn add(a: Scalar, b: Scalar) -&gt; Scalar { match (a, b) { (Scalar::Int(a), Scalar::Int(b)) =&gt; Scalar::Int(a + b), (Scalar::Float(a), Scalar::Float(b)) =&gt; Scalar::Float(a + b), ... } } 
I'm just curious as to how the performance of really basic stuff like the [printf implementation](https://gitlab.redox-os.org/redox-os/relibc/blob/master/src/header/stdio/printf.rs) stacks up against the originals, personally.
What's the point if it's just gonna be stuff [like this?](https://github.com/anp/rusl/blob/master/src/string/strcpy.rs)
[There is already a very popular opensource data-related project named Pig](https://en.wikipedia.org/wiki/Apache_Pig). You may want to consider another name if that's not too late.
My biggest problem personally with *everything* about Redox and all of its associated projects is that despite being based around an entirely new operating system, they still fall in to the same old tired trend of abject non-portability. Sorry, but I simply find it difficult to have much faith in devs working on stuff of this magnitude who can't even make their stuff cross-platform from the getgo. It's *not* that difficult, and if you think it is, that's just a reflection of your own personal ability level.
&gt;Or you can use unsafe code, but that's dangerous. I mean this is exactly the use case for unsafe, just like in the the implementation of `Vec`. The difference is there's a max size requirement and no heap allocation. 
The only time you should be using `Vec` for function parameters is if you actually *need* to dynamically resize it at some point. If you don't need to resize, you don't need `Vec`, so you shouldn't ask for it. Take a slice. The caller can pass a slice whether they're using a `Vec`, or an array, or anything with contiguous storage. If you need to accept a *something*, and you don't know what to take, but you do know what you need to do with it, then make the parameter generic and constrain it by the traits that give you the functionality you need.
Thank you! This is exactly the advice I needed. 
Relibc has Linux support
Could you expand on that? Do you mean, you want it to be supporting Power, Sparc, and MIPS right out of the gate? Because, they are working on AArch64, and between that and x86, you have the vast majority of the market for such an OS.
yes, that's the idea: reach reasonable price and performance of mid-end *mobile* processors initially. this is far easier to do than targetting high-end or intel-style desktop processors, or trying to make something similar to intel's Z-series (which requires EIGHT AMPS at 0.7 volts just for the GPU alone). so the target is: 4-6 cores @ 1.5ghz or above, 14-22nm, below 2.5 watts total power consumption, *WELL* below 400 pins, BGA 15x15mm, 1080p60 video decode, and MALI400 / Vivante GC800-like graphics performance, which correlates to around 6GFLOPS, 100 MPixels/sec and 30MTriangles/sec. it's enough to do around... 720p @ 30fps. target price in volumes of 10 million: around USD 3.50 this is perfectly achievable for a first processor. anything above that has implications in the rest of the stack (it's not just about the processor in other words), including requiring vastly higher current Power Management ICs, fans, advanced thermal cooling instead of passive air cooling, licensing of SATA, PCIe, risks associated with the same and vastly higher NREs, and so on. lots of people keep writing "pffh, total rubbish, i wanna producta competing wivva intel desktop, dis mobile stuff is total wasta time" and the only reasonable answer to that is, "put up the USD $50m to get that done, or stop whining!" whereas the above strategy has a reasonable chance of success with under USD $5m. that *should* be around $10m. around $5m is saved by using libre-licensed HDL. 
As far as I know, \`macro\_rules!\` macros can't produce match arms (\`pat =&gt; expr\` is an arm...) at the moment; they can however produce patterns and expressions.
I was just talking about basic desktop platforms actually. Like I said, *no aspect* of Redox-anything works on Windows, at all (other than maybe their "Orb" stuff because that's just OpenGL.)
`jemalloc` provides increased and much more reliable allocation performance, debug symbols make debugging a much nicer experience (both with gdb/other debuggers and just when panicking), and panic unwinding is a somewhat essential feature in the language to be able to recover from otherwise unrecoverable errors. None of these have significant performance disadvantages, the only disadvantage is code size. For 90% of rust developers, binary size doesn't matter at all, and the above factors are at least somewhat important. Hard drives are big and network speed is fast! The assumption is that if you work in one of the few areas where binary size matters, you'll know that it matters and thus change rust's configuration. Since the majority of people aren't working in one of those areas, having these as default is worth it.
Isn't the same true of a lot of Linux software? Even "Bash on Windows" is literally normal Linux Bash making Linux syscalls that Windows translates into Windows syscalls through their WSL thing.
You might possibly be interested in [kythe](https://github.com/google/kythe), which has Rust support, and there's also a "cargo kythe" tool.
Another one is monomorphisation. If you define a function in a trait, rustc compiles a version for every single struct implementing this trait. This is not true in C++. The benefit is that you get static dispatch by default, and the code generated is typically faster.
It's pretty incomplete. It looks like it lacks support for width, padding, etc.
the "trade-off" is making slightly larger executables. How often is an extra megabyte so important in 2018, outside of microcontrollers? The Reddit page you posted this on is probably comparable in size to whatever Rust executable you're talking about.
You should go ahead and delete this post.
BTW, the Rust this sub is about is free to download and use. Given a long enough timeline, you could learn how to program in it and would pot money in your PayPal in return for code. 
I don't think it's fair to expect a project to be Windows-compatible when Windows isn't free and so one would have to buy a license just to test it (as far as I understand).
May I introduce you to the best learning tool for this? https://rust-lang-nursery.github.io/api-guidelines/checklist.html Gives you explanations, steps, links, etc, to all sorts of stuff you may not even know existed. My favorite little trick is the way to at test time check if your types remain Send/Sync'able. *Super* useful when working on FFI. 
/u/Quxxy seems to have deftly handled your specific question, but just wanted to share for your journey later: One of the best resources I've found for making sure my APIs and docs are up to snuff is the [Rust API guidelines](https://rust-lang-nursery.github.io/api-guidelines/).
I may use this in a new project. Does this batch load data or go row-by-row?
Can I recommend my (reasonably) language-agnostic [printf test suite](https://github.com/BartMassey/printf-tests)? I wrote it when I reworked Haskell's `Text.Printf` and folks have used it for other things since… I think it would be a good aid for whoever finishes out the `relibc` `printf`.
&gt;How often is an extra megabyte so important in 2018, outside of microcontrollers? Wasm code size in webapps. Less than 1MB of wasm would be ideal in webapps written in rust. I have a webapp with crate dependencies on markdown parsers and csv processor. It has a size of `3.5MB` when compiled with default configuration. Optimizing for size with configurations: [profile.release] debug = false lto = true opt-level = 'z' Squeeze it to `2.5MB`. Finally, reduce it even more by using wasm-opt from binaryen. `1.9 MB` Reducing from 3.5MB to 1.9MB is already quite impressive. I haven't replace the default jemalloc allocator though. I wonder how much more it can reduce to? Maybe it will be able to reach a my `1.0MB` webapp target.
It was promising, but the last commit was 3 years ago :( and of course it doesn't compile anymore (it used the old compiler plugin infrastructure). Perhaps a new version of glassful can be built on top of your glsl crate?
But why? The WASM file can be cached ad infinitum (even weeks or months later) after the first page load, and it's rare for websites to have less than 4MB in images alone. Don't get me wrong: all else held equal, we should make the executables as small as possible. Using opt-level=z makes you code smaller by making it slower, so it's not a free reduction. I'm not sure what binary-opt does. One thing the Go compiler team is working on is an option to output one WASM file per dependency. All of those could be hosted on a CDN, which the user might already have cached from visiting some other website, and then you application WASM file is super tiny because it only contains your code. This is not implemented yet... but it's something I've seen discussed. The obvious performance trade-off there is that there can be no optimization across library boundaries.
Wow cool! I did not know about that!
Debug symbols are present in release builds on linux and on windows-gnu. Hello world executable is 4meg instead of 500k. Yes you can remove it with `strip`, but I don't see a reason why it needs to be there in the first place. It just gives rust a bad image, because no one expects release builds to have debug symbols, and may think rust compiler is terribly inefficient producing 4meg binary for helloworld.
Have you tried to use [`cargo bloat`](https://github.com/RazrFalcon/cargo-bloat) to inspect binaries? (AFAIK it does not support wasm, but I think it should give a general idea) In my experience by enabling `lto = true` and running [`wasm-gc`](https://github.com/alexcrichton/wasm-gc) I was getting wasm binaries of several hundreds kylobytes in size.
Why should Redox stuff run on Windows, of all OSes? Running on Linux is already hard enough and proves they have a strong commitment to portability. If enough people volunteer, I suppose they can support even more OSes too.
I suppose this stub will be replaced by a Rust implementation when someone writes it. 
I'd say WASM is still a case where one knows that size matters and will configure these options, but it might be good to switch defaults on wasm32-* platforms anyways. I use `panic = "abort"` as well as what you state for my wasm projects since panics get translated to wasm's `unreachable` anyways. If I recall correctly though, jemalloc is already skipped on wasm32-* targets and replaced with a smaller allocator.
It's pretty useful! Especially in FFI. Other big uses are doing cleanup in `Drop` implementations, and allowing threads to die via panic without killing the entire process.
Replacing jemalloc should reduce your wasm file by around 100KB . Have you tried twiggy ? On tantivy I noticed that the major part was taken by stuff that was never called but that couldn't be excluded statically. Parser also do take a lot of space...
Noob here. I worked on mimicking function overloading with traits to find what primitive type integer was passed to my “function” I thought it would be useful Incase you let rust infer the data type when you initialized a variable. As it turned out it looks like, for me at least, on a MacBook Pro it isn’t. Rust seems to make things i32 if you don’t give it a type. If it won’t fit in an i32 it won't use anything else and just gives an error. Was a good bit not to traits for me. Working with microcontrollers and Arduino getting the size of your ints right for a. library that could’ve but used on either a 16 bit or 32 bit micro was important. Compile for aan atmega chip and it's a 16 bit int, cortex-m arm an nit is 32 bit so we use things like uint32_t. 
4MB is way too large for most websites. Even if you re user has a good connection (e.g. 500kB/s) you are asking them to wait for 8s. If they live in country with shitty internet, or in a plane or in a cafe or in a building in Paris multiply that by 10. What percentage of your traffic do you think you will lose? Also caching is great but if your company releases weekly or less you will have problems. 
The biggest contributor to binary size is static linking. This bundles most (or all, depending on the target) of the libraries you use together into the final binary. This way stuff “just” works at the nowadays mostly irrelevant price of binary size.
&gt; I've heard that they've stopped doing it on macOS. Apple really didn't like them doing that. They did stop in 1.11 yes. I don’t know that it was due to direct pressure rather than it blowing up in their faces several time. 
The issue is that you're using `io::copy`, which saves the full file. You should declare a buffer, read a chunk into it, save it to disk, update the progress bar, then continue reading. You don't need to check the size on disk (because you know how much you've written), you know the download size (because the `reqwest` response has a `Content-Length` header), and you probably don't even need the other thread.
I've hit a stumbling block on my journey to understand tokio/futures better. So, with `io::read_until` we will get a bunch of bytes and might want to convert the `Vec&lt;u8&gt;` into a `String` - which could fail. Can convert the `FromUtf8Error` to `io::Error` no problem, but I'm completely lost on how to pass on this future.
I don't think replacing jemalloc will do much good for wasm as there's not really a default allocator.
What everyone said already, but also consider supporting [no_std](https://blog.japaric.io/embedded-rust-in-2018/). It's useful not only for embedded but also web development.
&gt;no one expects release builds to have debug symbols Is it just me who always adds a long list of `-g` flags to the release configuration when starting a project? Why would you *not* want good debug information in your core dumps and stack traces when something goes wrong in production? Some problems are extremely hard to reproduce and if you need to make a new build with debug info to make sense of the core dump then you're hosed—either you spend days or weeks reverse-engineering *your own software* to figure out what the optimizer did to it, or you make the build with debug symbols this time, deploy it, and wait for the problem to happen again. I can see the reasoning for wanting to keep the files separate with `objcopy --only-keep-debug` in package managers because having debug symbols for *everything* on your system would use quite a bit of disk space. But for the one custom application that you're developing?
1) Get Rust (programming language), it's free! 2) Learn it, documentation is free too! 3) Write your own Rust (game) clone… …and there you are! Don't forget to share it with the community! ;P
[r/playrust](https://reddit.com/r/playrust/)
Wut?
Thanks :-)
&gt; panic unwinding is a somewhat essential feature in the language to be able to recover from otherwise unrecoverable errors. Remember, when creating a library, that the consumer may very well use the `panic=abort` strategy and it's therefore best NOT to attempt to recover from panics in your (shared) library code. Also, be careful of (1) poisoned state and (2) panics in `unsafe` block; after a panic, the memory may be in an unrecoverable state to start with.
&gt; Replacing jemalloc should reduce your wasm file by around 100KB . Doesn't WASM use `dlmalloc` instead? I have a small WASM project, and switching to `wee_alloc` didn't seem to give any improvements. And a large part of my binary size is some `Debug` implementation from `web-sys` and the panicking infrastructure (even though I'm compiling with `panic="abort"`). I suspect I could probably remove that with `wasm-snip`, but I didn't try.
&gt; The issue is that you're using io::copy, which saves the full file. I don't know that it's an issue, save that `indicatif` does not provide a `Read` wrapper (whereas it provides an `Iterator` wrapper) so one'd have to provide their own, which should not be too hard. `io::copy` simply does the bufferying and copying on its own internally, /u/The_Rusty_Wolf is using it exactly as they should.
I guess 1. boils down to preference. In my experience I have never *not* wanted debug information, and I have had many, *many* cases where I'm debugging a crash and cursing the gods because no debug information is available so literally the only thing I see in the debugger is `value optimized out`. I get a visceral reaction of disgust even just typing that phrase out. Ditto for 2. As for 3., if that's what actually happens then that sounds like a bug rather than a design decision. And as you mentioned, you can always use `strip`.
Are these config changes "you'll know that it matters and thus change rust's configuration" documented somewhere ? I'm rust noob and haven't seen anything like those around. Thanks!
jemalloc does not support wasm
jemalloc doesn't support wasm though, so if you are compiling for it, it shouldn't be linked
While we often disagree in details of some discussions, I just wanted to say that I love your crates.
One thing I didn't see mentioned is the string formatting machinery and the unicode tables. They can't really be removed if you want to do anything with strings, but they do show up in the size profile when trying to make tiny binaries.
When would you ever run a Web server on a platform that didn't support the standard library? Or by "Web development" do you mean WebAssembly?
Sorry, I do mean WebAssembly. Unless you have a specific reason to use libstd (i.e. sockets or file manipulation), [liballoc](https://doc.rust-lang.org/alloc/) and [libcore](https://doc.rust-lang.org/core/index.html) can provide useful APIs but at the same time your library would be usable in no_std environments (say, embedded development) and in places where it could be desirable to use no_std (wasm). See [httparse](https://crates.io/crates/httparse) for an example of a full library with optional no_std support. Also, the [no_std keyword on crates.io](https://crates.io/keywords/no_std)
Question: Have you looked at this subreddit before posting? :-)
Rewrite it in Rust.
Is there a way of automatically running strip on the resulting \[profile.release\] binary? I'd like to keep the debugging symbols in \[[profile.dev](https://profile.dev)\] though.
Just to clarify, are you suggesting this? fn do_something(stuff: &amp;[usize]){ for i in stuff { println!("{:?}", i); } } fn main() { let stuff: Vec&lt;usize&gt; = vec![1,2,3,4,5]; do_something(stuff.as_slice()); }
https://www.reddit.com/r/playrust/ ?
You would probably run into that info in groups were it matters. For example the embedded work group. The Seconded book is to their getting started documentation. &amp;#x200B; &amp;#x200B; [https://rust-embedded.github.io/blog/](https://rust-embedded.github.io/blog/) [http://book.rust-embedded.org/](http://book.rust-embedded.org/)
IIRC macros can produce almost anything. Except new identifiers. @daboross correctly explained the problem
r/lostredditors
Still unclear.
The subtlety is: macros can create match arms provided that the macro also creates the enclosing match expression.
I'd rephrase this slightly and say it's better to not ever panic in a library as an error propagation strategy. Attempting to catch *user* panics has valid use cases, e.g. the tokio runtime could catch panicking tasks so that tasks have thread-like isolation (note: I don't know if tokio does this).
I am trying to use rayon to parallelize calculating the sum of the first N primes, but I am running into an issue. The playground link below is the working, non-rayon version, but when I try to replace `into_iter` with `into_par_iter` I start getting error messages that I can't work out a solution to. https://play.rust-lang.org/?gist=b5c6cb022bf59d2025fe7b51cc40c55d&amp;version=beta&amp;mode=debug&amp;edition=2018
Depends what you're making but you'll likely need all of those for the frontend. The browser can only really display html and CSS, and you'll need JavaScript to interact with rust anyway.
It was in service of this blog post, linked from the README: http://blog.adamperry.me/rust/2016/06/11/baby-steps-porting-musl-to-rust/
Looking through the config docs for rustfmt it seems you have to deactivate the "small" heuristics for that: https://github.com/rust-lang-nursery/rustfmt/blob/master/Configurations.md#use_small_heuristics
Aww. :) Do we often disagree? Thank you for the kind words! :)
&gt;Do these need to be statically linked? Could we save binary file size if jmalloc and most of the panic unwinding code would be in a dynamic library? &gt; &gt; &gt; &gt;If Rust gets more popular it might be viable to have these things in an external library that is usually already present on the target system.
Switched from *attempt* to *expect*. You can indeed *attempt*, it's just that as it may not be possible, it would be best if your library usefulness did not depend heavily on panic recovery.
I'm using the [alacritty](https://github.com/jwilm/alacritty) terminal. Originally, binary size is about 30Mb. I changed the release profile and it reduced to about 6Mb. Here is what I use: ``` [profile.release] opt-level = 3 lto = true debug = false codegen-units = 1 panic = "abort" ```
It really depends what you want out of error-handling. I would say that Rust, the language, has the basics of error-handling built-in: - `Option` for `find`-like functions, - `Result` + `Error` for more complicated failure scenarios, - the `Try` trait for succinct "pass-to-caller" cases using `?`. What is still under development is in the ecosystem at large: - Handling conversion of errors from one type to another; and especially conveniently defining said conversions. - Enriching errors with extraneous information, such as backtraces, but also human-defined extraneous bits and pieces. The latter is mostly useful in bigger applications, where tracking down the origin of an error is more complicated; for small applications, it does not matter as much. The former is mostly useful when defining fine-grained `Error` types, used for automatic handling errors. Once again, for small applications, the small overhead of defining a handful of error types should not be too dramatic. So, for now, I would say just go with `failure` and it should be good enough for your usecase as CLI tend to be on the smallish side.
Neat!
That's a great idea!
Honestly, if you can program in rust at an intermediate level, learning the basics of html and css won't be difficult. Just read some of the tutorials on w3schools.com to get started and play with the examples. Can't really give you much advice on Javascript. I only know the basics and I've learned those by just searching for the things I needed to know. 
Which is an html element.
Is it like ffi ? Do rust and javascript work the same way by calling rust functions for heavy calculations ?
Do you want dll dependency hell? This is how you get dll dependency hell. Do you want users to have to update your stdlib for you? This is how you get "plain old Java" "only use Java 1.6 features". Or you could include code to download said libraries in every application... defeating the purpose. Do you want 20 copies of the same redistributable on your computer that nobody dares remove lest someone else be depending on it (my Windows life, gotta collect all the VC++ redistributables...)? Do you want the Rust calling convention frozen forever so that dynamic libraries can communicate with the current level of Rust layout but it can never improve again (ok this one actually has some pros to it other than binary size). My (poorly executed) point is that any decently sized application is going to be shipping its dynamic dependencies along with itself so that it can be sure that it has them and they're the right ones. The only place dynamic linking by default makes sense imho is linking to the OS.
&gt; Do these need to be statically linked? Choice of static linking is a pragmatic one. For projects of non-trivial size dynamic linking will usually yield almost no size benefits whatsoever. Even when they *do* use dynamic linking, it is usually not by choice (e.g. licensing requirements). It is not required that rust binaries are statically linked – in fact you can produce binaries that link dynamically to most of the stuff even now (rustc flag `-C prefer-dynamic`), but if you do, you’re in for a lot of pain dealing with all the nonsense that dynamic linking entails. &gt; If Rust gets more popular it might be viable to have these things in an external library that is usually already present on the target system. As long as everything compiled with exactly the same build of the rustc compiler, sure. As soon any of the components is compiled with a different build of the rustc, everything would collapse like a tower of cards gently caressed by gust of wind.
Yes, is essentially the same. The details are different of course but the basic idea is the same.
&gt;This debug info is coming from standard library not your application. This is expected, for now- there is only one build of the standard library (per target) in the rust distribution. It thus is optimized, but with debug info. At some point the design work may be done to allow Cargo to build things like the standard library (mostly for cross compiling to less-common targets). This, or perhaps distributing several copies of std for common build profiles, is a prerequisite for leaving out its debug info.
why do you still need js when making a website from scratch?
Rayon does not support infinite ranges like `RangeFrom` ([GitHub issue](https://github.com/rayon-rs/rayon/issues/520)). You need to replace `1..` with `1..std::u64::MAX`. The next issue is `filter` in combination with `take`: The latter is only defined on `IndexedParallelIterator` (a superset of `ParallelIterator`). Unfortunately, `Filter` (the return type of `filter`) does not implement this trait. This is mentioned [in the docs](https://docs.rs/rayon/1.0.2/rayon/iter/trait.ParallelIterator.html). I am not familiar with Rayon and thus, don't know any work-around. I hope, someone else can answer this.
Thanks for the response. Intuitively it makes sense that it would be difficult to implement `take` on a parallel iterator, but I was hoping Rayon did something clever to work around this. 
&gt; The only time you should be using `Vec` for function parameters is if you actually need to dynamically resize it at some point. That's not the whole story. If you want to pass a buffer you want to be overwritten to a function, you should pass a `Vec` created using `Vec::with_capacity()` instead of passing a slice. The reasons are performance and security. To make passing a slice safe, you need to initialize it with something, which takes a surprisingly long time. You could pass a slice without initializing it, but that's unsafe and easily leads to security vulnerabilities. However, you can safely write to a `Vec` without initializing the underlying memory first. I've written a [more detailed post on the topic](https://medium.com/@shnatsel/how-ive-found-vulnerability-in-a-popular-rust-crate-and-you-can-too-3db081a67fb), if you're interested. **TL;DR:** if you're writing a function accepting `&amp;mut [T]`, consider accepting `&amp;mut Vec&lt;T&gt;` instead.
Yes; I wasn't thinking about passing an out parameter.
How will you call your rust code?
[A similar discussion](https://www.reddit.com/r/rust/comments/8lt8k6/do_i_really_need_failureerrorchain/).
&gt; My AES takes slices because it's fundamentally an operation on a buffer (block), and they return a Vec&lt;u8&gt; because I need to allocate the result. In general you [don't need](https://docs.rs/aesni/) allocations. (see `BlockCipher` and `StreamCipherCore` impls). Also `IntoIterator&lt;u8&gt;` is usually too fine-grained for most tasks and thus results in an ineffective code, mostly you should used either `Read` or `AsRef&lt;[u8]&gt;`.
I suggest you check out wasm-pack and see how it works https://rustwasm.github.io/wasm-pack/book/tutorial/index.html
I am currently doing that :P
My interpretation is that `failure` 1.0 isn't *deprecated* so much as 'the original plan for 1.0 wasn't going to work'. The library itself is still under active development
Personally, I switched to just defining an `Error` enum on a per-crate, or sometimes per-mod, basis and haven't looked back. It's simple and performant. Backtraces are more of an issue when your program is prone to crashing and you need to figure out what happened. Crashes are rare in idiomatic rust.
I am also affected by this. By the way, even after patching SDL2 with \[this changeset\]([https://hg.libsdl.org/SDL/rev/55489adbb75c](https://hg.libsdl.org/SDL/rev/55489adbb75c)), I was still not able to get consistent behavior (the initial render only worked when the window isn't fullscreen). There are other strange-seeming behaviors too, such as the window being invisible if I launch it from a fullscreen terminal, or inconsistent behaviors between the app launcher and the CLI. &amp;#x200B; I was thinking of giving SFML a spin, but it looks like there are weird issues there too: [https://github.com/openframeworks/openFrameworks/issues/6149](https://github.com/openframeworks/openFrameworks/issues/6149) &amp;#x200B; I'm extremely irate with Apple for deprecating their OpenGL support, and I have to wonder if this is their way of making sure everyone knows.
Failure crate is nice. Defining your own error enum is also a possibility. 
The backtrace is useful when you need to identify where things went wrong and you can't from the error value itself. If a function calls another function two times, and that second function returns an error, how caller of first function knows which call to second one failed?
&gt; this is perfectly achievable for a first processor. That sounds great and all and I hope it succeeds, but RISC-V won't be very relevant to me personally unless it someday, in due time, can compete on the desktop, which is what my question was really about. &gt; licensing of SATA, PCIe Aren't there already RISC-V dev boards with these?
From data in the `Error` type, usually. 
As I mentioned in my answer, this is a scalability issue. For small programs, there's often a single place where a given error payload (type + value/message) originates, so it's trivially located. As the program grows, this may become a handful of places, but given context, logs, etc... it's still relatively easy to reason about it, reproduce the issue in a unit-test, or live-debug. The backtrace could be useful, but is not yet necessary. When you reach medium size, and the combinatorial explosion of execution paths mean that there are dozens or hundreds of a way a particular error could occur... then I hope you've got backtraces, or excellent logging, else you're doomed.
This is my first blog post! I have no idea what I'm doing with web stuff so if everything is broken please say something.
I've really had a hard time without backtraces. Honestly it's the main reason I'm currently on failure right now. I also have the misfortune that my CLI app depends on the C library libgit2 which generates all sorts of different potential errors all over my code. :(
Is there a roadmap for the future of failure, or is that still under discussion?
I worked on a [Game Boy emulator](https://github.com/squidboylan/corroboy) and read the [Programming Rust: Fast, Safe Systems Development](https://www.amazon.com/Programming-Rust-Fast-Systems-Development-ebook/dp/B077NSY211) book when i was in a similar situation. I found the emulator was a big enough project to learn new stuff and get practice with the borrow checker, but it was probably a little too large. If emulators are interesting to you maybe a chip-8 emulator would be a better size project. The book is great for learning a little bit more about the details of rust and how things are implemented. It assumes you're somewhat knowledgeable in programming which is part of why i like it so much.
I think it's Emacs.
I just fixed a content-type SNAFU, so if you saw the page before this comment and nothing happened when you typed, it's now more fun. You may need to super-reload with Ctrl+Shift+R or something for it to see the new version of the WASM file.
Wow, that's really cool! I could imagine something like this being useful for refactoring, too.
I'm not that much into emulators but I did think at some point about making one. Thanks for the pointers!
The readme links to this RFC, which I think is a big part of the story: https://github.com/rust-lang/rfcs/blob/master/text/2504-fix-error.md. As I understand it, the std::error::Error trait was designed a long time ago, and several years of experience building error handling frameworks had given us some important ideas about how to change it. The evolution of `failure` will depend on what gets decided there.
Thanks, this make the trick.
I don't know of any way to do that. There's `debug = false` in the profile section but I'm not 100% sure that that get rid of everything `strip` does.
Rust by example is often recommended after reading the book: https://doc.rust-lang.org/rust-by-example/
I know the clippy folks have wanted this _for ages_!
The next thing to do is always to write some code. You'll know when you're doing it right when your program works.
For me, `failure` is strictly better than \`error\_chain\` or defining error types by hand. Even if the only thing you use is the automatic `Display` derives it's worth it. That said for libraries I expect other people to use I usually define errors by hand anyway, just so they don't necessarily get bound to a particular version of `failure`. It depends on your needs. 98% of the time I need exactly what `failure` does.
Idk, how is js code called?
Can't you manipulate the dom with https://github.com/koute/stdweb? Or does that fall in to the framework glue category?
The browser, from the user facing view can only present html, CSS and execute JavaScript. To call into anything web assembly, JavaScript has to do the call. So you can't write a web assembly site without some JavaScript. Maybe you can use some libraries that preconfigure the JavaScript for you, but you're still calling your rust code with JavaScript.
It's the same as it's always been. If you want any sort of dynamic content or interaction etc that is not generated server side, you need JavaScript. If you're okay with static elements then you've never needed JavaScript Rust and web assembly don't change that. They allow you to offload more to a compiled space for performance but you'll still need JavaScript. Think of html as the description of the document being displayed. CSS styles the document elements. But anything beyond that, needs JavaScript at some level.
Yea but with stdweb i don't need to write js myself anymore, do I?
Most learning resources, posts require some prior knowledge. It is possible but what do you want to do it with it later? Having a clear goal in mind will help learning even the hardest things.
You still need to. It just reduces the amount you need to write but you'll still need to write some. Again, this all depends on your site and its needs. Not all uses of JavaScript make sense to do in rust either, and there are many libraries etc that you may need that are in JavaScript.
If you want to work on embedded try the embedded rust book https://rust-embedded.github.io/bookshelf/book/ . Embedded is a little in flux now, but you can still do some fun stuff with it. The tooling is gradually getting nicer to work with. 
&gt; Normally in C I would just use "char *" with a length parameter You can do that in Rust. You can also use a raw slice `*const [T]` which is exactly equivalent, just tying the two parameters together into one type. A "normal" slice `&amp;'a [T]` is the same, with lifetime tracking added.
Try https://learning-rust.github.io/ :)
Do you have a plan to upstream this into the [SparkPost community repos](https://github.com/SparkPost)?
That's the approach I'm taking, too. Besides Programming Rust I really like Rust in Action, but that's in early access. My Chip-8 emulator is missing the Rendering and User interaction part, this will be fun to tackle. Can't wait to play Pong :D 
No plans, but I don't mind 
Looks awesome! Seems like a well designed API for use in rust. One tip for posting on this subreddit though: descriptive titles go a long way. I imagine a lot more people would be interested in this if they knew before clicking on the link what the crate was about! I found the title of the blog post itself much more helpful to guage whether I would be interested or not than the title of this post. It's cool that it's your first crate! Most people aren't interested in _all_ kinds of crates, though, so having that at the end of the title or in the first paragraph would let more people who are interested see the post and give some feedback.
Really cool. I think this is usually called semantic grep? See for instance similar tool for C :http://coccinelle.lip6.fr/. But why stop here when can implement semantic patches which are the really cool stuff for refactoring 
I would recommend you start with a non systems language. JavaScript is a great place to start since you can develop right in your browser (no environment/told needed)
I'm 90% sure that git hashes all the files in the working directory and does hash comparisons to check whether anything's changed rather than using modification timestamps. I could be wrong, though.
Rust does do RVO, but that doesn't save this problem of passing in large things by value. This can be easily demonstrated with this #![feature(box_syntax)] pub fn box_large() -&gt; Box&lt;[u8]&gt; { box [0; 1_000_000_000] } pub fn box_new_ret() -&gt; Box&lt;[u8]&gt; { Box::new(return_large()) } pub fn box_syn_ret() -&gt; Box&lt;[u8]&gt; { box return_large() } fn return_large() -&gt; [u8; 1_000_000_000] { [0; 1_000_000_000] } fn main() { let boxed = box_syn_ret(); println!("{}", boxed[1_000_000_000-1]); } Unfortunately, the Rust playground won't run this, because it takes too much stack space. But using such absurdly large numbers is what overflows the stack and makes it obvious what is happening. 
These kinds of unsafe things belong in abstractions, though, not end-user crates. It's why crates like [arrayvec](https://crates.io/crates/arrayvec) exist to do exactly this and handle all the unsafe bits.
Here's what the CTO of Dawn Studios says about learning Rust, for what it's worth: &amp;#x200B; [https://twitter.com/AndreaPessino/status/1042120425415700480](https://twitter.com/AndreaPessino/status/1042120425415700480) &amp;#x200B;
&gt; Running on Linux is already hard enough Redox the OS is just that, an OS in and of itself. The associated projects have no particular reason to run more easily on Linux than they would on anything else. The only people who would believe that's the case are the sort of people who hardcode stuff like `/usr/local/` into source files, for example.
There's more than a few complete programming language projects written almost entirely by *one* person that just casually run on all the major platforms, and always have. [Zig](https://github.com/ziglang/zig) being one. [Odin, which is quite a bit more on the "obscure" side than Zig, being another.](https://github.com/odin-lang/Odin) It's a matter of effort, nothing more.
Everything in this thread is ignoring the fact that Redox is at its core a *new operating system.* Linux vs Windows vs Whatever should be largely irrelevant.
I don't understand the second proposal enough but I think the semantic patch feature would be really nice for the community. You mention clippy for matches but rustfix is a good target for patches. It would make rustfix like tool usable by everyone not only compiler author. For instance dev of a popular a crate could distribute a set of patches to run while upgrading to a new major version. This would not cover 100% of the upgrade work probably but that would be really nice
I'd highly recommend the Discovery book for anyone looking to get started with embedded programming in Rust. I was able to follow along with basically no background in embedded programming, and learned a lot in the process. https://rust-embedded.github.io/discovery/README.html 
For other examples in the space, take a look at IntelliJ [Structural Search and Replace](https://www.jetbrains.com/help/idea/structural-search-and-replace.html). 
That does sound vaguely promising. I hope the larger effort pans out! Moneyed interests must be getting as sick of this as the rest of us.
0.0.1 you mean? for a language shouldn't this exists in the first day?
To be fair, 70 commits is for the number parse engine, which is not too obvious... So it is just reinventing the wheel of `FromStr`.
Because you have to parse the parameter manually, `char` by `char`.
How can you assert that it is only a matter of effort and ability level when it is an indisputable fact that access to Windows costs money? I agree that for people who have such access, then it is only a matter of effort and ability. But the reason that complete single-maintainer multi-platform projects exist is that their creators don't have to go too far out of their way to test their code on multiple platforms (or the software is simple enough that it doesn't use any OS-specific features). Sure, Appveyor lets you have Windows CI for free, but if your project requires non-trivial changes to port to Windows then it would be crazy to push to Github and wait half an hour for Appveyor every time you want to run code. Especially if you aren't familiar with the Windows API or the shell language -- and I think most people would consider it more effort than it is worth to learn an API or language without having access to an environment that you can test in, regardless of ability level.
To use the Crystal developers as an example, they claimed months and months ago that they were very close to proper Windows support. But since then, nothing. They've objectively stated they're trying, so the money aspect doesn't really factor in. Presumably they just can't get it working properly. I also have an extremely hard time believing that the Redox team as a whole could possibly be outside the realm of financial access to Windows.
Maybe I'm a purist, but I'd say get a grip on C before you try to dive into Rust. C as a language forces you to have an understanding of what's going on with the system (in particular considering the size of types) which should give you some inkling as to why certain things are and aren't allowed in Rust. Additionally, I'd recommend learning a functional language (like Scala) since those will get you very comfortable using iterators and chaining them with calls to `map` `fold` `filter` etc. &amp;#x200B; I personally picked up Rust after learning a ton of C and playing around with Scala for half a year and then only had to learn about Rust's borrowing and ownership concepts in order to get a grasp of the language. Trying to learn Rust without experience with structs, first-class functions, and manual memory management from other languages will be hard, because you'll need to learn how to deal with all of those in addition to fighting the borrow checker.
It is Emacs. I visit his GitHub and found the configuration that made Emacs look like that. Thanks for the reply
`dbg!()` is something I didn't know I wanted until now.
Rust is a great language but not as a first one. Try something easy like Perl. It's just straight declaractive programming. Ruby is a fun language but can get complicated when you start adding your own classes. Bash is a great language to learn if you are a Linux user. Python isn't a favorite of mine but it is extremely popular.
I have a naming convention question. I often find myself wanting to have a trait and struct with the same name. For example: \`trait Ratio { const NUMERATOR : i64; const DENOMENATOR : i64 }\` \`struct Ratio&lt;NUM: typenum::Integer, DEN: typenum::Integer&gt; { }\` I have a small handful of these trait/struct pairs. I've been appending 'T' to the name of my structs. I don't particularly like that. But I can't find a good solution. Thanks!
[DMS\_Software\_Reengineering\_Toolkit](https://en.wikipedia.org/wiki/DMS_Software_Reengineering_Toolkit) uses this approach in automatic refactoring. So this would probably enable someone interested to write a code refactoring tool based on that, or to perhaps enable clippy to do the refactoring of some cases.
I would suggest you start with [The Book](https://doc.rust-lang.org/book/) first. If you don't understand certain concepts or ideas expressed in the book, it's worth either googling or asking here (besides, the book should also explain these concepts at least in brief and not expect the reader to have any prior experience, so if it doesn't mention some information - that's a flaw and it needs to be corrected). While rust is built on some common concepts shared by many other languages, it has an explicit notion of lifetimes, which is a concept so pervasive that many newbies struggle with it the first few months, despite having a programming background. I would posit that this is from rust's lifetime ellision rules not being described anywhere (or at least anywhere obvious) and from using design patterns from other languages that are either subtly flawed or only applicable because the other language is very high-level.
that's the "bait". and in a corporate world, developing a new DDR3/4 interface would mean "lots of future customers and therefore profit". the issue is, unfortunately, a libre project in the current world economic climate, once the HDL source is available, corporations are quite likely to sponge off of that (take, take, take). got to pathologically obey those articles of incorporation to maximise profit, right? so this project has to stand - profitably - on its own merit, without expectation that the resultant libre-licensed HDL that will be released to the world would automatically imply that corporations will pay (retrospectively) for its development. shocking, but realistic.
Since you're using WASM (and presumably Rust for this), could you post the source code for the page perhaps?
See [the `chunks` method from `itertools`](https://docs.rs/itertools/0.7.8/itertools/trait.Itertools.html#method.chunks), maybe.
You're looking for /r/playrust :)
If you're concerned with the quality of your code, then consider making documentation contributions. They're a good way to expose yourself to the code base and find trivial bugs that you'll feel comfortable fixing. As your confidence increases, so will the likelihood that you'll be able to tackle "entry" issues. 
thank you, I am very delighted to learn about this class. It is really interesting and there is so mich more to learn on this page. Thank you!
And this is exactly what op tries to do
&gt; I'd highly recommend the Discovery book for anyone looking to get started with embedded programming in Rust. I was able to follow along with basically no background in embedded programming, and learned a lot in the process. Getting started with the Discovery board is probably a better idea than bluepills : the f3 crate has better support !
I'll partially repeat what others already said, but I think that point is important. (Also, for context: I was heavily involved in my university's programming introduction course for the last couple of years.) Learning to program requires learning a couple of new things. I think the core part of programming is the "algorithmic thinking": being able to take a situation/a problem description and express it as an algorithm. This requires a completely new way of thinking and is really hard for most people to get used to. But I also think that this is a really important life skill and every human could benefit from algorithmic thinking. However, programming is more than that. In particular, a beginners brain has to switch between different "levels" of problem solving: - the already mentioned algorithmic thinking - expressing the high level algorithm in your head as an algorithm in the target programming language - the syntax of the language - the semantic rules (mostly the type system) of the language - the tools (editor/IDE, potentially terminal, ...) Having to take care of all these things at once can be very challenging if everything is new to you. Sometimes it can slow down learning a lot if you are not able to concentrate on one aspect. For example, to reduce the number of "problem layers" in the students head, we switched the recommended editor from vi to Atom. The latter is way more intuitive and requires basically no learning at all ("basically works like Word"). And reducing layers is also the reason why we usually way: think about the algorithm first, express it however you want (usually just as a natural language description), test the algorithm by executing it in your head and only then try to implement it in the programming language. That way, one can concentrate on one thing at a time. And finally, this is also why visual programming languages (with drag'n'drop blocks) are popular in education: that way, we can basically get rid of the whole "syntax" layer. So how does this relate to Rust and you? Rust's type system (with borrow checker) is another layer one has to keep in mind. This could lead to the learning slow down as described above. A dynamic language like Python does not have the compile step and the (static) type system, so especially beginner have the feeling that their programs work way quicker with python. The step "expressing the algorithm in your head as $programming_language" is way easier there. However: - I think many dynamic languages also teach some harmful assumptions about the programming world (like sharing everything by default (as opposed to moving or copying by default), having everything mutable everywhere by default, ...). - C++ was my first language and I know a lot of good programmers that started with a "hard" language. I assume those programmers had a ton of motivation in order to bite through all the problems they initially had with learning programming, but it's certainly possible! So my recommendation is: make sure you learn "algorithmic understanding" first -- at least to a degree that you feel comfortable crafting easy algorithms from problem statements. For this step, I think Rust is absolutely not the best language. Rather use a dynamic language or maybe even a visual one. But then switch the language as soon as you think you got a basic grasp of algorithmic thinking. This also avoids the "first language fixation": when you spend too much time in the first language you learned, you get really used to thinking in that language and have a hard time to think in a different way (At my university, many students learn Java two semesters long before even seeing anything else. In my Rust course, I noticed that those students usually had huge problems learning Rust features that have no equivalent in Java (like real sum-type enums)). 
Indeed. I was explaining how you and etareduce can disagree with each other and still both be right.
Thank you for the feedback, I'll keep that in mind
I typically do it manually, by using lots of enums everywhere and passing them up to the caller with `?`. I also typically use a trait like `From&lt;MyError&gt;` instead of the error directly so that clients can use their own error types. Also, I removed `std::error::Error` impls pretty much everywhere in my crates (if any left, I’ll remove them!). I don’t see any point in that trait (so far). Just my very humble opinion: I prefer spending time on manual error handling, assuring that I understand the impact of my designs well, instead of using crates such as `failures` or `error-chain`, which have drawbacks, are a bit invasive (i.e. design with macros) and impact your public API IIRC.
I'm happy to contribute it to upstream, if approached. or even give up the name if someone has a better implementation. 😀
this is a subreddit for the rust programming language not for the game rust. please refer to the subreddit r/playrust for those issues. 
\*DOH\* thanks man!
I have yet another Rust PR in flight, one more clippy lint, and I intend to publish new versions for flamer, overflower and mutagen to work with current nightlies if time permits (and $work + $life conspire against this – wish me luck).
I need to read a large-ish file fast. Is there something "special" to do to read it? I'll probably use a buffered reader, but is there something beyond? I need to read it into a `Vec&lt;String&gt;` or a `Vec&lt;Vec&lt;u8&gt;&gt;` exactly once from beginning to end... would threads help somehow? Here are the conditions I'm operating under, if it is any help: * Only interested in bytes, so I can skip utf8-validation. Doesn't really matter for the reading, I think. * Each entry in the `Vec` represents a line, without the newline. Empty lines need an empty `String` or empty `Vec&lt;u8&gt;`. * Truth be told, I only really need the first 81 bytes of every line. There will be more than that very seldomly, though. * If a line starts with a `#` or a `$`, I can only read that one byte. Does this help? I don't know how, I still need to keep reading to find the newline, right? Thanks for any pointers. I'd surely be willing to employ any crate that helps with this :)
If you want to have static dispatch, I think you could use a generic type parameter: #[derive(Debug)] struct Foo&lt;T: Iterator&lt;Item=u32&gt;&gt; { iter: T } impl&lt;T: Iterator&lt;Item=u32&gt;&gt; Foo&lt;T&gt; { fn new(iter: T) -&gt; Self { Foo { iter: iter} } } fn main() { let v = vec![1u32, 2u32]; let x = Foo::new(v.into_iter()); println!("{:?}", x) }
A similar feature is the [IntelliJ structural search and replace](https://www.jetbrains.com/help/idea/structural-search-and-replace-examples.html), where a template language is used for finding certain code-patterns.
I'm doing Advent of Code 2017 (r/https://adventofcode.com) in Rust to polish up my very limited Rust skills: [https://gitlab.com/GuzTech/aoc2017](https://gitlab.com/GuzTech/aoc2017)
[FundWarrior](https://gitlab.com/leggettc18/fundwarrior) is getting close to its first release! There are still some non-trivial tasks to go before then, but the end is in sight.
you are looking for /r/playrust/ this subreddit is about the rust programming language
working on a cmd tool to split sql file.
I think the still way to go should be defining own error types and not rely on something like `failure`
From a feedback from another thread, I have marked the crate with \[UNOFFICIAL\] in the readme so people don't get confused.
I have wrote a windows-only Minesweeper clone this week. https://github.com/crlf0710/charlesmine-rs Now it's playable, but there're more things (menus, dialogs) upcoming.
There's also the [chunks] method in available on slices, which might work if you're starting with something like a `Vec`. [chunks]: https://doc.rust-lang.org/std/primitive.slice.html#method.chunks
Can you show the final working example?
(If you are the author), please don't use javascript to add smooth scrolling. It'sjuddery at best and doesn't work well with mobiles/tablets.
I just started learning Rust over the weekend. I will continue working through the O'Reilly book while finding some smaller features on open source projects I can implement and make PRs to.
"Be the change you want to see in the world"... I'm sure they'll accept your patches. 
Hi, I am indeed the author. Thanks for your feedback. This is my companies blog, so I have little control over the technical aspects of it. Using javascript for smooth scrolling has not been a conscious decision I made and I have no idea how not to do it. 
It's probably the "jquery.nicescroll" plugin. Part of the wordpress theme? You could pass a suggestion along to whoever maintains the website/bog. `&lt;script type='text/javascript' src='https://tech.blue-yonder.com/wp-content/themes/stratus/assets/js/vendor/jquery.nicescroll.min.js?ver=3.5.4'&gt;&lt;/script&gt;`
Dogfooding my sudoku library and building a GUI on top of it really brought out the pain points. The reporting of human strategy results is now in a usable format and I can give [hints](https://i.imgur.com/kabdPHb.png). I'm going to clean up a few remaining hijinks in the API this week and then I can publish a new version of the crate.
#### Yep, here it is. ```rust use std::{fs, io::{self, copy, Read}, path::Path, }; use reqwest::Url; use exitfailure::ExitFailure; use indicatif::{ProgressBar, ProgressStyle}; use reqwest::{header, Client}; struct DownloadProgress&lt;R&gt; { inner: R, progress_bar: ProgressBar, } impl&lt;R: Read&gt; Read for DownloadProgress&lt;R&gt; { fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; io::Result&lt;usize&gt; { self.inner.read(buf).map(|n| { self.progress_bar.inc(n as u64); n }) } } fn download(url: &amp;str) -&gt; Result&lt;(), ExitFailure&gt; { let url = Url::parse(url)?; let client = Client::new(); let total_size = { let resp = client.head(url.as_str()).send()?; if resp.status().is_success() { resp.headers() .get(header::CONTENT_LENGTH) .and_then(|ct_len| ct_len.to_str().ok()) .and_then(|ct_len| ct_len.parse().ok()) .unwrap_or(0) } else { return Err(failure::err_msg(format!( "Couldn't download URL: {}. Error: {:?}", url, resp.status(), )).into()); } }; let mut request = client.get(url.as_str()); let pb = ProgressBar::new(total_size); pb.set_style(ProgressStyle::default_bar() .template("{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {bytes}/{total_bytes} ({eta})") .progress_chars("#&gt;-")); let file = Path::new( url .path_segments() .and_then(|segments| segments.last()) .unwrap_or("tmp.bin"), ); if file.exists() { let size = file.metadata()?.len() - 1; request = request.header(header::RANGE, format!("bytes={}-", size)); pb.inc(size); } let mut source = DownloadProgress { progress_bar: pb, inner: request.send()?, }; let mut dest = fs::OpenOptions::new() .create(true) .append(true) .open(&amp;file)?; let _ = copy(&amp;mut source, &amp;mut dest)?; println!( "Download of '{}' has been completed.", file.to_str().unwrap() ); Ok(()) } fn main() { download("http://location/of/file/you/want/to_download.ext"); } ``` ### Put this in your Cargo.toml ```toml [package] name = "Name of your program" version = "0.1.0" authors = ["Your Name &lt;you@email.com&gt;"] edition = "2018" [dependencies] reqwest = "0.9.2" indicatif = "0.9.0" failure = "0.1.2" exitfailure = "0.5.1" ``` 
You can also check it out at [example](https://github.com/FriedPandaFries/Rust-Examples/blob/master/examples/download.md) if you'd like to see it with syntax highlighting.
Finishing up pre-release testing for the next version of [journaldriver](https://github.com/tazjin/journaldriver). It's a tiny log-forwarding daemon for Google Cloud Platform users that writes to Stackdriver directly from the `journald`-APIs. On systems running (and logging to) systemd/journald this is much more efficient (and easier to maintain) than something like fluentd with a ton of plugins to support essentially the same functionality. Last news is that priorities from journald are now correctly translated into Stackdriver severities, so if you were to log application errors to journald they would get picked up by Stackdriver Error Reporting (if they're in the expected format). Probably not too interesting overall, but it was fun to write and scratched an itch :)
I stared [a new thing](https://github.com/killercup/output-rs) last week, and will try to continue to work on it as much as possible this week.
I think you meant to post this to /r/playrust/
You can’t load a web assembly module without using JavaScript. So you’ll at least need a tiny bit. 
It’s good that you kept the benchmark with a small string. Crossing the language boundary can have per-call overhead, and (depending on use cases) short strings might be more typical for quoting things into URLs. At one point I played with Python/CFFI bindings to html5ever that would create Python objects for each node in the document tree. This was ~5× slower than parsing to a Rust tree data structure! (But still faster than the pure python html5lib library.)
While that's probably true it's splitting hairs :) I say probably because I don't even see any reason for it not to be possible to just load a web assembly module directly from a script tag in HTML. But doing it in JS to allow polyfill for old browsers is probably the best idea anyway. I don't even care if you have to go through a JS glue layer to the DOM as long as the developer experience can be 100% Rust (or whatever language you want) instead of being forced to write JS to do web frontends.
My [reverse geocoder](https://github.com/llambda/rust-reverse-geocoder) is now implemented as a library, an Actix REST API, an Iron REST API, and as a command-line utility, thanks to Cargo workspaces. Cargo workspaces are amazing and it seems like the combination of workspaces/crates/modules are breaking down the rigidity of the microservice vs. monolith debate. The user of this library can choose to use it either compiled-in, with normal function calls, or stand it up as a REST API or (perhaps in the future) a gRPC microservice.
&gt; I don't even see any reason for it not to be possible It may be possible, but it's not possible today.
I'd never heard about heaptrack. That's a cool tool.
I skimmed through the examples a bit to make myself familiar with how idiomatic rust should be written. I did that in about 1-2 hours. E.g. how to deal with optionals, results, iterators etc. This already made me aware of the most common solutions for rust code. When implementing i typically compared my code against the examples given in the documentation, or on stackoverflow if nothing was available. Especially when it felt that things could be done simpler i tried to search for solutions. For me that is the fastest way to learn and just reading through the documentation doesn't stick for me.
Thanks. Take the small string benchmark with a grain of salt, though. Its density of characters to escape is way higher than for the larger Lorem Ipsum string. My intention has been to provide a simple example of how Python / Rust FFI works rather than to measure performance accurately.
Triying to find a neat way to surface rust functions for an [interpreter](http://tablam.org), and finding how hard is on rust (hard **Polymorphism on rust**): &amp;#x200B; [https://www.reddit.com/r/rust/comments/9ivuig/best\_way\_to\_implement\_many\_traits\_for\_custom/](https://www.reddit.com/r/rust/comments/9ivuig/best_way_to_implement_many_traits_for_custom/) &amp;#x200B; [https://www.reddit.com/r/rust/comments/9j8o8e/how\_pass\_a\_closure\_with\_generics\_to\_a\_non\_generic/](https://www.reddit.com/r/rust/comments/9j8o8e/how_pass_a_closure_with_generics_to_a_non_generic/) &amp;#x200B; [https://www.reddit.com/r/rust/comments/9iwsz1/for\_interpreter\_any\_vs\_enum/](https://www.reddit.com/r/rust/comments/9iwsz1/for_interpreter_any_vs_enum/) &amp;#x200B; [https://www.reddit.com/r/rust/comments/9lr5zq/why\_bin\_opop\_1\_2\_bin\_op\_byaddadd\_a\_b\_if\_opaddadd/](https://www.reddit.com/r/rust/comments/9lr5zq/why_bin_opop_1_2_bin_op_byaddadd_a_b_if_opaddadd/) &amp;#x200B; Eventually, I settle for a macro that write the boilerplate code that will be necessary: [https://www.reddit.com/r/rust/comments/9lr5zq/why\_bin\_opop\_1\_2\_bin\_op\_byaddadd\_a\_b\_if\_opaddadd/](https://www.reddit.com/r/rust/comments/9lr5zq/why_bin_opop_1_2_bin_op_byaddadd_a_b_if_opaddadd/) &amp;#x200B;
Short answer: It can't work Long answer: &gt; I don't even know why it's bitching about lifetimes because I'm moving the texture into the map. It's not a reference so like wtf. Well, there is an reference: Inside of Texture. That's why it's type is Texture&lt;'a&gt;, where a is some lifetime. I'm not exactly sure what self.texture\_creator.load\_texture but I guess it reads some file and creates a texture&lt;'a&gt; from it. The lifetime 'a is most likely some reference into the read file. But whatever it is pointing to does not exist after the function anymore, while you're tring to keep the Texture&lt;'a&gt; alive. Whatever you're reading from has to stay alive longer than the hashmap, because it the HashMap Values reference into it. &gt;I'm just at a total fucking loss and I swear every time I try to do anything remotely interesting in Rust the borrow checker has to piss me off. Well you've been protected from a use after free. I don't think it would have been easier to debug in C/C++. At least here you know which function is the problem. 
I already thought the borrow checker was desireable before learning Rust. I come from a javascript background where I take memory safety for granted, and having a compiler to hold my hand while I make stupid mistakes is much more appealing than writing a program in C and having to spend hours searching google or using a debugger when it fails for some unknown reason...
I've been adding significant amounts of stuff to the `nalgebra-glm` docs (https://github.com/rustsim/nalgebra). A lot of this has been cross-referencing, "See also" sections, as well as a bunch of doctests. (Adding doctests has, so far, found 2 bugs.) Hopefully, this will help make the `glm` API to `nalgebra` even better and easier to get started with. There's a lot to go though!
I'm still working on my processing-esque graphical framework. I completed some basic things last week but have since deleted that because of terrible coding styles and learning new things. &amp;#x200B; Currently I am reading up on creating outline of shapes of varying thicknesses using some improvised vector maths. &amp;#x200B; I'm also going to try and use this framework as an opportunity to learn either [gfx-hal](https://github.com/gfx-rs/gfx) or [vulkano](https://github.com/vulkano-rs/vulkano), as I'm still a complete newbie when it comes to graphics programming. &amp;#x200B; No public links yet, sorry.
That's why I have to read stuff a few times. 
1. Having two levels of nested errors returned by `send()` is strange. I'd define an error enum like this: pub enum TransmissionError { HttpError(reqwest::Error), ApiError(ApiError), } //impl Debug, Display, Error, From&lt;reqwest::Error&gt;, From&lt;ApiError&gt;, etc If the API returns multiple errors, you can use [`Error::cause`](https://doc.rust-lang.org/std/error/trait.Error.html#method.cause) to allow callers to get the underlying errors. A library like error_chain could make this easier. 2. Pretty much every API either makes the user copy data, or copies data internally. This is probably fine for how I assume this API is usually used (sending the same email/attachment to many people with a recipient list), but if someone wanted to send different content/attachments to many different people those copies would add up. You could change `Attachment.data` into a `&amp;str` (or `Cow&lt;'a str&gt;`) or make `Message::add_attachment` take an `&amp;Attachment`. 3. It would be nice for users to be able to add attachments without having to manually base64 encode the data. You could change `Attachment.data` to a `&amp;[u8]` or provide constructor methods which would do the conversion like `Attachment::from_file(path: &amp;Path)`, `Attachment::from_data(name: String, mime: String, data: &amp;[u8])`. 
I've written a version that builds the python nodes on demand with which I got a 3x speedup over html5lib for a scraper (it's also faster than lxml, but lxml failed at parsing some pages, so I had to discard it). I've added code and benchmarks [as an example for setuptools-rust](https://github.com/PyO3/setuptools-rust/tree/master/html-py-ever). Building this was really easy thanks to your great work with kuchiki! I've also made a small shim that allows using it as a drop-in replacement for BeautifulSoup in the scraper.
Not entirely sure what you say, but does it lag a lot for you too?
I've got a lot of irons in the fire. On xi-win-ui I plan to add basic support for animations through a `request_animation_frame` widget trait method. On the synthesizer, I plan on wiring up GUI module graph editing to actually modify the realtime audio rendering graph. Also, I want to catch up a little on the backlog of xi code reviews and design decisions, hopefully contribute to a roadmap.
/r/suicidewatch if your serious, /r/anger if you're not. 
I've had people say "a day" and I've had people say "I tried to read it, got stuck, and came back six months later and tried again and it made more sense." It really just depends.
At college I read the first edition on the bus and whenever I was waiting till I reached the end and it took about 2 weeks. I never wrote any code until I finished though. It will work a lot better if you mess with lifetimes, traits, enums and patterns a bit before you start coding, so I recommend using the rust playground links on the code samples.
Cool, but something is going on with those benchmarks. Two million nanoseconds to insert is quite poor.
Came here to suggest this. The scrolling in my browser is so horrible that i stopped reading after the first paragraph. 
huh, i don't know of anything offhand, unfortunately. have you looked at Khan Academy, though? i feel like they might have something
The maddening thing for me is that for a language where the move/borrow semantics matter so much, the behaviour is implicit, rather than explicit. You can't tell by just staring at the code, you have to understand that 'such &amp; such means ...'. If there were actual keywords for move &amp; borrow calls, it might be less frustrating.
You might try looking into diesel which seems to be the current defacto ORM for Rust. It looks like it has support for SQLite which would give you an embedded database. I haven't looked into it extensively but it would be a good place to start if there are no other alternatives. 
This is exactly what I was looking for. The error message is a strange one, I will have look at using Error::cause etc to simplify it. I have never used `Cow&lt;'a str&gt;` and sounds like it stays as a reference unless you do something with it apart from reading it. I have plans for creating `Attachment` from the file itself. It would add more dependencies which I didn't want to do to start with. But I guess I could just implement them as a feature maybe. Thanks a lot
Caveat: I've never used Go. I would expect that debug binaries in Go work just fine with heaptrack for purposes of allocation, it's just the freeing that's not guaranteed to ever happen. And given that it's a native binary, the debug symbols should display fine. All that said: I'd be interested to know about the results if anyone's used heaptrack and Go!
I'm amazed how much effort people put into fixing this non-problem. &amp;#x200B;
You could try [https://github.com/TheNeikos/rustbreak](https://github.com/TheNeikos/rustbreak) &amp;#x200B; I haven't used it myself, but I have used `daybreak` which it lists as an inspiration. &amp;#x200B; From the readme: &gt;Rustbreak is an [Daybreak](https://propublica.github.io/daybreak/) inspired self-contained file database. It is meant to be fast and simple to use. You add it to your application and it should just work for you. The only thing you will have to take care of is saving.
You can use serde if all you need is write and then read structs (i.e. you are not going to query that by id or some other attribute). This is not a database, but simple serialization / deserialization (hence ser-de) to disk. 
Fair enough, I was just googling and saw that comment thread. Maybe a bug report is in order?
This entirely depends on the person. Someone with a lot of experience programming can go through it in no time while a beginner might take days / weeks. Just go at the pace that you feel you're learning comfortably at and don't worry about how long it takes. 
It's emacs. I put my config and guideline here https://huytd.github.io/emacs-from-scratch.html
`Texture&lt;'a&gt;` works as if it contained a reference to the `TextureManager` which created the texture (in reality `Texture&lt;'a&gt;` contains only a `PhantomData` marker). Rust `struct`s must be trivially copyable (and any `struct` referencing its own data obviously isn't trivially copyable). So a `struct` can't contain simultaneously a `TextureManager` and textures created by it. The two obvious solutions are following: * don't bundle `TextureManager` and `HashMap&lt;_,Texture&gt;` together (cf. https://play.rust-lang.org/?gist=d23e9f0adc0ebc61dab010b0e65a2411&amp;version=stable&amp;mode=debug&amp;edition=2015 &amp;mdash; an example of a working solution) * use `unsafe_textures` feature described in [README.md](https://github.com/Rust-SDL2/rust-sdl2) for rust-sdl2 
Thanks for sharing. I have already visited your gist and transformed my Emacs close to how your looks like. So dope :)
&gt; At one point I played with Python/CFFI bindings to html5ever that would create Python objects for each node in the document tree. This was ~5× slower than parsing to a Rust tree data structure! I'm surprised it was only 5x slower if you were crossing the FFI boundary twice (to create a Python object from Python with data generated by Rust, that's what I'm reading in your comment) for every single node.
I liked the Arival themed drawings.
Explain, please. I'm not a Haskeller so I don't fully understand everything here. Right now your comments is not informative or helpful at all. (That's why it accumulated so many downvotes so fast, I guess).
It's not like the `Drop` trait and its implications are a tent pole of the Rust value proposition or anything /s
I released an update for [orion](https://github.com/brycx/orion) yesterday, so that both Poly1305 and the ChaCha20Poly1305 AEAD construction are now supported. Next up is adding XChaCha20 and a high-level API interface for authenticated encryption. I unfortunately doubt I'll have much time to work on this at all this week.
Honestly I don't remember. That was long ago in the pre-1.0 days so maybe `Read` wasn't implemented for `&amp;[u8]`?
Options for databases: * sqlite - really reliable and the safest choice; if you're building something for the longterm this is what you want * sled - RUST! pre-1.0 but quite good, imo; a key-value store with basic get/put/scan capabilities Options for serializing structs: * bincode - RUST! take a rust type and turn it into bytes and back again: ez; downsides: not forward-compatible so if you change your struct you'll need to write a custom migration * protobuf - forward compatible, but you'll need to get * json - confidence that you'll be able to read the data base out with a variety of tools; downside is it will probably take more space in the db Also, rather than sharing a pointer to a database between threads, you might consider using channels to communicate with a thread that just writes to the db.
*leans toward mic* I don't recall, Mr. senator
I'm still waiting on the host binding proposal (I predict that wasm usage is going to explode when that lands), but this is a pretty big deal!
I think the issue in Haskell is you can escape the "bracket" by the assignment `myResource &lt;- withMyResource pure`. Doesn't look like a non-problem to me, but I'm just an amateur in these languages.
As you expect something from the official reddit app. Lol. Reddit is fun on Android works as expected.
So I think the issue here is the ability to just copy the `MyResource` type willy-nilly. The `withMyResource` and `bracket` seem sort of fine here because `&lt;-` calls bind which will "escape" the value returned by the inner function and place it in the `IO` monad. All of this seems fine because `MyResource` can be implicitly copied and used later. I think this is more-so a function of the fact that `MyResource` is just a type along the lines of an integer. Calling it `MyResource` is a slightly tricky way of making it seem like you're accessing the same exact handle for the resource which exists uniquely. I don't think there's *really* much of an issue in this example, to be totally clear.
Started working on a high-level host-side CUDA wrapper library. No link yet. I'll publish and announce it properly when I have something worth sharing.
This just introduces a standard interface for backtraces though. It was mostly done to make the `Fail` trait from failure redundant, I think. This doesn't really change all that much from a user perspective, you still need to add a backtrace to your errors, which is rather cumbersome without `failure::Error`.
I think they're planning to add an actual backtrace generating API too! At least it sounds that way from the tracking issue: https://github.com/rust-lang/rust/issues/53487
[It seems to be a pitfall that some people want to avoid](https://blog.skylight.io/rust-means-never-having-to-close-a-socket/). Given that a big selling point of Rust is in minimizing foot-guns for us mere mortals who are capable of making a mistake, it seems quite relevant here. 
This is really neat, but I struggle to imagine a scenario where this would make a difference. I've been abusing WASM bindings to get an iterator-like interface and marshal a few million numbers back and forth through it. That's basically the only case where such optimizations would matter, and is actually blatant abuse of the API - the fast solution is passing a pointer to WASM heap. Old code executed 100 million function calls in 6 seconds, so in my wildly abusive use case it would speed up the relevant part from 0.06 seconds to 0.0006 seconds. Eeeh. Still dwarfed by the actual work done in the function, even if it's trivial math.
It looks to me that misuse of "bracket" is like returning a disposed object from a function in F#. Of course ya done messed up. It's pretty cool that rust lifetime management just works though in the face of such patterns.
More specifically, Rust's lifetime system guarantees that bugs like that will be caught at _compile-time_. Haskell's compile -- absent lifetimes and RAII -- will not catch them. In Haskell, if it compiles, it may not work. One can approximate Rust lifetimes, as the article mentions, but using ST monad, except you have to explicitly thread the "lifetime" all the way through your code.
Yeah, I think the only real major difference in this case is the fact that Rust will move the value by default rather than copying/referencing (not sure how Haskell's type system works with data types like this exactly). I think Rust's typesystem is great, and I think move by default is great, but if we'd just been using an integer rather than a custom type, it would really illustrate how this example is pretty silly. Make the data type not-copyable in Haskell (which I think is what the solution does in a contrived way) and the problem will disappear I believe.
I get the feeling that it is more hevy weight than what you are imagining, but I have been very happy with using (statically linked) SQLite through Diesel for several projects.
Weird that `Off` is between `Default` and `Max`. You'd think that `Off` would break the list in the same way as `Default`
Hey this is awesome, thanks for sharing!
Haskell is pretty opaque about pass-by-reference vs pass-by-value: it can get away with this because nothing can ever be mutated so everything can be shared. If you let `MyResource` be some arbitrary type with memory or IO implications, the "bad" example will still compile and run: [e.g.](https://gist.github.com/BartMassey/111b1bedcdcf2bf39e25d98d007de9c1). You are right that the solution makes this problem (not really a copying problem, but definitely a lifetime problem) disappear in a contrived way. It's not obvious to me that there's a less-contrived way.
&gt; this is probably the wrong place Idk, but thanks. I read the code a bit too lightly, it seems.
This is absolutely amazing work, please don't get burned out and please do continue it, Rust is lucky to have this!
It's nice to see a blog post about it! I'm currently prototyping a somewhat similar thing. I've noticed that the [recent str::repeat vulnerabilty](https://www.reddit.com/r/rust/comments/9hssab/security_announcement_for_strrepeat/) should be fairly trivial to discover with a fuzzer combined with some kind of memory debugger (Address Sanitizer?). However, writing a fuzz harness for every function in the stdlib would be incredibly tedious, so I decided to try to automatically generate fuzz harnesses for stateless functions in the stdlib. I've started with manually writing a proof-of-concept fuzz harness for the known-vulnerable function and tried to get it to crash. It also uses Arbitrary to generate types from fuzzer input, although I've used the one from quickcheck crate. So far I only got OOM crashes, and the fuzzer has failed to hit the actually interesting overflow case. It might be due to the fact that I've been fuzzing on a 64-bit architecture, and most allocation sizes in there are actually invalid, since the entire address space is 16 exabytes, and we can only allocate a few terabytes on modern PCs. Especially so under Address Sanitizer, which imposes even more strict limits. Curiously, in case of fuzzing stateless libstd functions panics are actually allowed - many functions document that they panic under certain conditions. I've altered my fuzz harness to ignore panics, yet I'm getting OOM cases recognized as crashes anyway. My next step would be setting up a 32-bit chroot and trying fuzzing there. Perhaps that way I'll be able to hit valid values instead of OOM cases most of the time.
Correct me if I'm wrong, but once they eliminate all overheads in calling browser APIs, I figure writing your entire app in wasm become much more attractive? Right now, if you're pushing for more wasm in your webapp you're justifying it by claiming you'll have superior performance. But that claim is somewhat undermined if you have additional overhead of calling any browser API. If there is 0 overhead, then I see no reason that for example, a framework like React couldn't migrate performance sensitive code to wasm. 
Doesn't Go have a heap allocation profiler of some kind? I'd expect any competent VM to expose that kind of debugging info. Hell, even JavaScript has that.
&gt; In fact, try as I might, I cannot figure out a way to get this to close the resource before using it. That's good to hear, because if you *could* figure out a way to close a resource before using it (without unsafe), that would be considered a bug in the language, since use-after-free is one of those classic categories of C bugs that Rust seeks to statically guarantee against. :)
Per our on-topic rule, I would like to ask someone to leave a comment explaining this submission's relevance to Rust for someone who may have never heard of WebAssembly before. If there exists a dedicated page explaining WebAssembly's relevance to Rust, then please also link that, because I suspect we'll be seeing a lot of WebAssembly articles in the future and it would be nice to not have to re-type this every time. :)
That overhead comes mostly from the fact that WASM only operates on JS integer and float values, and most browser APIs (e.g. DOM) require other data types. This introduces overhead because you need to do extra work to build those types out of arrays of raw bytes, and this has to be done on the JS side, which is relatively slow and sometimes negates all the performance gains from using WASM.
I read the book in bits and pieces over the course of a few weeks.
"Back in the day" you had to explicitly say `move` or `copy`. I assure you it sounds like a much better idea than it is.
About a month ago I experimented with porting a small-but-nontrivial C library to Rust, and this is the results of it. Hopefully people will find it useful, or at least interesting!
This isn’t just limited to one tool, I’ve logged an issue with amethyst for the same problem. Also I’ve got some apps like KiTTY which show the same problem. Apple screwed something up with OpenGL in Mojave that’s breaking things. 
Agree with you fully, but like the article says &gt; But WebAssembly is getting [more flexible types very soon](https://github.com/WebAssembly/reference-types). Once these types are in place, you will be able to call these other built-ins directly from WebAssembly without having to go through JS. So the overhead they've eliminated here, and the overhead they will eliminate in the near future makes wasm a very attractive platform. If you were starting a new project, you could genuinely consider wasm instead of JS.
Reminds me of when I had to implement a concurrent skiplist back in University... fun times (and by fun I mean a lot of debugging) I gave the code only a short look, but [this part in the code](https://github.com/sch00lb0y/SkipMap/blob/master/src/lib.rs#L47-L51) is very dangerous: ``` unsafe { (*node).key = key; (*node).value = val; (*node).lanes = mem::zeroed(); } ``` `node` is freshly allocated and thus uninitialized. But assigning to it will mean it first reads whatever is left in `key` and `value` and, if the corresponding types `K` and `V` have drop implementations, call `drop` on them. [See this example on the playground](https://play.rust-lang.org/?gist=1545360df76afc5d84ed98a619b6e4e9&amp;version=nightly&amp;mode=release&amp;edition=2015). You probably want something like `std::ptr::write(node, Node { key: key, value: val});` instead. Your dealloc is also dangerous. Your SkipMap is carrying around `PhantomData`, no need to set it to uninitialized, just set it to `PhantomData`
There's this linked article: https://hacks.mozilla.org/2018/03/making-webassembly-better-for-rust-for-all-languages/#wasm-bindgen. Not sure if it counts.
Rust is frequently marketed (though I can't be bothered to dig up sources) as the language for webassembly. However, I personally feel wasm isn't relevant to this sub, unless it deals directly with Rust.
docs.rs is on a very old nightly by now, so I'd suspect this is using some new Rust feature that docs.rs doesn't support yet.
Hi! &gt; I'm currently prototyping a somewhat similar thing. I've noticed that the recent str::repeat vulnerabilty should be fairly trivial to discover with a fuzzer combined with some kind of memory debugger (Address Sanitizer?). However, writing a fuzz harness for every function in the stdlib would be incredibly tedious, so I decided to try to automatically generate fuzz harnesses for stateless functions in the stdlib. Heh, I wrote about this very thing in my last [commit message](https://github.com/blt/bughunt-rust/commit/c34fe102718a072078a1467f2ed037cc358c4bd9). It is _very_ tedious and means that any updates would have to be propagated by hand. I'll be really curious to see where you get with this. &gt; So far I only got OOM crashes, and the fuzzer has failed to hit the actually interesting overflow case. It might be due to the fact that I've been fuzzing on a 64-bit architecture, and most allocation sizes in there are actually invalid, since the entire address space is 16 exabytes, and we can only allocate a few terabytes on modern PCs. Especially so under Address Sanitizer, which imposes even more strict limits. The trick, I think, is that for many of these interesting crash cases they'll occur well after the allocations will start causing panics. I _think_. Anyway, that's why I want to start fiddling with introducing custom allocators, see if I can't get the fuzzer target and allocator cooperating in some fashion. &gt; Curiously, in case of fuzzing stateless libstd functions panics are actually allowed - many functions document that they panic under certain conditions. I've altered my fuzz harness to ignore panics, yet I'm getting OOM cases recognized as crashes anyway. Right, right. If the panic handler allocates anything then that allocation will panic and blow up the whole thing. Oops. Also, how are you ignoring panics? My concern with ignoring panics is that cuts you off from `assert_eq!` and the like. &gt; My next step would be setting up a 32-bit chroot and trying fuzzing there. Perhaps that way I'll be able to hit valid values instead of OOM cases most of the time. Oh! Hey now, I hadn't even considered this. Side benefit to working with a smaller word size is your search space for overflows is drastically smaller. 
&gt; It would be even better if I could compare against the corresponding C functions somehow. I believe this is one of the goals of c2rust. You can probably use some kind of symbolic execution engine, such as [KLEE](http://klee.github.io/), to automatically generate per-function tests with pretty good coverage and compare those between C and Rust implementations. It is going to look at edge cases, especially the edge cases, which may or may not be relevant because the function is assumed to only be called in a certain way. Autogenerating lots of test vectors with an instrumentation-guided fuzzer would work too. Probably easiest with AFL on the C side, although libfuzzer would work too.
The first time I tried going through TRPL was with the first edition. While I don't think it's really that bad, I don't feel like Rust made sense to me until dabbling in haskell and other ML languages. Then when I gave it another shot, the 2nd edition of TRPL was mostly complete and that definitely helped too.
It is my understanding that "panic" is for when there is nothing reasonable that the code in question can do with the inputs and there is nothing reasonable the caller could do either because either the hardware is failing or the program has a fatal logic error meaning that any computational result would be suspect and unreliable. It is not an exception. Having "No Panic" would be like saying, "I'll never have a logical programming error so, let me prevent you a way to put the brakes on if I do". Does that sound reasonable? It doesn't to me when looked at in that light. If you think of panics as just less capable exceptions, it seems like they could be "disabled", but, they aren't that.
&gt; …oh, it becomes less simple than that when the slice is mutable. Darn it. Well, for now we can just hack around it a little with an unsafe code, writing a function to defeat the borrow checker and let us assign a slice to a sub-set of itself, and re-visit the issue later. This is a common issue for decompressors of all kinds. I have put forth a [proposal](https://internals.rust-lang.org/t/pre-rfc-fixed-capacity-view-of-vec/8413) for a safe abstraction which allows that kind of thing, but don't have the time to write a production-grade implementation of it.
&gt; Haskell is pretty opaque about pass-by-reference vs pass-by-value: it can get away with this because nothing can ever be mutated so everything can be shared. And the converse is possible as well—it can in principle choose to duplicate instead of sharing because it doesn't alter the semantics of the program. One example (though it's work instead of memory duplication) is [how GHC is deliberately a bit sloppy about memory races](https://stackoverflow.com/questions/31972800/how-atomic-are-ghcs-thunks): &gt; GHC tries to prevent reevaluating thunks, but because true locking between threads is expensive, and thunks are usually pure and so harmless to reevaluate, it normally does so in a sloppy manner, with a small chance of duplicating work anyhow. 
On the topic of custom allocators: https://github.com/mirrorer/afl/tree/master/libdislocator https://github.com/Shnatsel/libdiffuzz (rust rewrite [incoming](https://github.com/Shnatsel/libdiffuzz/pull/4)) Address Sanitizer also uses a custom allocator. However, all of these work through the C memory allocation API. Rust has its own API, perhaps building something directly for it might be a better idea. I haven't tried yet.
This works for systems small enough to be mathematically proven or unimportant enough that crashes are acceptable. But there are programs where this isn't the case, where the presence of programming errors has to be assumed and guarded against - having a panicless mode would make this much easier.
That's a good point, I agree that panics are important part of Rust runtime security model. What I'm not sure about is if this is the only solution. Rust has excellent tools for panic-less support for errors like Result and Option. It's a common approach for crates to have doubled API, every fallible function gets version which panics and version returning Result or Option. Are there situations when error can't be expressed in returned value and must panic? Remember that C still has no exceptions, it's ugly but it works.
I believe this guy's infamous for starting inflammatory threads on this subreddit. Apologies if I've confused him with someone else.
Now that I think of it, simply calling `exit(0)` on OOM in the custom allocator would suffice to avoid false positives on OOM. At least they wouldn't be treated as crashes. Also, did your fuzz harness for `str::repeat` actually expose the bug? This would help me narrow down what's wrong with [mine](https://gist.github.com/Shnatsel/4a907d44d6429de93d63d6e7c4d1361e).
https://github.com/Technolution/rustig might be relevant to what you're trying to accomplish
Being able to statically know for sure that a crate or set of code can't panic would indeed be lovely and make it much easier to reason around. And potentially require a bit less integration testing and manual verification. &amp;#x200B; Have run into a couple of scenarios where I want users to be able to extend a program with their own logic and where I really wanted to not allow that code to panic as any errors should be handled and returned back to the main app, instead of bringing down the main app.
Such as? Plane autopilots actually have fault conditions in which they give up and hand over controls to the human pilot. This is a reliability-critical system in which you actually need to detect cases when the impossible happened (e.g. due to hardware fault), and if it did, panic. High-availability networking equipment in programmed Erlang, which generally handles errors by crashing the entire faulty process, immediately respawning it, and possibly dropping some crash-inducing inputs. In fact, Rust's panic mechanism was inspired by Erlang supervision trees.
I'm using TryFrom so that may be it. 
`winapi` supports Rust 1.6. I really doubt this is the case.
\**Engages psychic powers.*\* Did you remember to gate `winapi` so that you only use it on Windows builds?
I'm enhancing Rust Qt Binding Generator so one can build GUI applications with Cargo as the only build system. Using CMake or other build tools is still an option, but not a requirement. 
It will be interesting to see what if anything can be done with the addition of linear types to Haskell ([https://ghc.haskell.org/trac/ghc/wiki/LinearTypes](https://ghc.haskell.org/trac/ghc/wiki/LinearTypes)). I haven't thought about it deeply, but naively it seems like it should help.
I would LOVE the option to prevent compilation of the code panics. I find it hard to support using unwrap() in production code.
Winapi does that itself, doesn’t it?
I think statically verifying that things cannot panic is useful for mission / safety ciritcal aspects of your code; it also gives one peace of mind and reduces the reasoning footprint required for some bit of code. However, I think that the \`#!\[no\_panic\]\` might be a too blunt instrument; it seems to me that \`no\_panic\` is a restriction (where \`panic\` is an effect / capability) that should be tracked locally on individual functions as is done with \`const fn\`; To make such a thing tractable and to enable code reuse across the ecosystem (to avoid splitting it along the lines of \`const\`, \`no\_panic\`, and \`async\`), I think you'd need some sort of effect polymorphism (see [https://en.wikipedia.org/wiki/Effect\_system](https://en.wikipedia.org/wiki/Effect_system)).
&gt;Being able to statically know for sure that a crate or set of code can't panic would indeed be lovely and make it much easier to reason around Not possible. Hardware failures could always result in "Panic" situations. "Panic" doesn't mean, "There was some error condition that you can decide what to do about", it means, "There was either a hardware failure or logical programming error such that any further computation will likely produce meaningless and unuseful (or dangerous) results".
Looks great, I've been using my own simple gql client since I could not get previous version to work with prisma.io schema. It seems this new version handles it perfectly. Great job!
fwiw, I've found you can remove the last two characters off the end of the URL (`-🎉`) and it still works, eg: [https://hacks.mozilla.org/2018/10/calls-between-javascript-and-webassembly-are-finally-fast](https://hacks.mozilla.org/2018/10/calls-between-javascript-and-webassembly-are-finally-fast)
Fair point. I just assumed for no real reason that there are cases where you need to assume programmer errors happen and continue the program without introducing the overhead of a panic and multithreading - but this isn't sufficient to justify an addition to the compiler.
&gt; as any errors should be handled and returned back to the main app That's pretty much the reason why panics exist. You can catch and handle those, unlike a process-wide segfault and/or silent data corruption that C would give you.
Function call overhead between the two systems would definitely make one have to choose, now WASM is first class and that choice doesn't need to be made. 
Source is at https://github.com/mit-pdos/noria Client bindings: https://crates.io/crates/noria MySQL adapter: https://github.com/mit-pdos/noria-mysql Improves performance of https://lobste.rs by 5x!
I hadn't even noticed that yet. [Unfortunately I can't take credit for it.](https://github.com/lieff/minimp3/blob/master/minimp3.h#L756)
nit: It is implementation defined not undefined. It is allowed to panic, as it does in debug. Or wrap, as it does in release. But it is not allowed to cause arbitrary memory corruption, like undefined behavior is allowed to do.
The module system confuses me. I try to split a test program into separate files. For example, this: -- main.rs: fn main() { a(); u(); } fn a() { print!("A and "); u(); } fn u() { println!("U") } ...outputs this: A and U U Now, I try to split it into 3 files (before adding mod code): -- main.rs: fn main() { a(); u(); } -- aux.rs: pub fn a() { u(); } -- util.rs: pub fn u() {} ...then I tried several variations of the declarations, with/without wildcards, explicit function names, such as: -- main.rs: mod aux; mod util; use aux::a; use util::u; fn main() { a(); u(); } -- aux.rs: pub mod aux { pub fn a() { print!("A and "); u(); } } -- util.rs: pub mod util { pub fn u() { println!("U") } } All wrong. What's the trick? 
This *would* be an excellent excuse for me to play with AFL.
You can also try `sed 's/\(\*([^)])\)/\1/g'` (gosh, it looked much better in my head) to remove needless dereferences. 
Honestly, I see no reason to not just use a slice+offset instead of having a direct pointer to the point of interest.
It does. Which is why if you don't gate *your* usage of it, you'll be trying to access types and functions that don't exist on not-Windows, which would explain the error.
&gt; There’s like… TWO places in one function where instead of just doing some_struct foo; it does some_struct foo[1]; and then proceeds to use foo as a pointer for the whole damn function. Is… is this a thing? I've seen this too! Is there some subtle advantage to doing things this way in C land? I was worried there was some tricky array behavior it was relying on that I didn't know about, but so far if there's a difference I haven't been bitten by it...
With a little luck I'll have time this week to play with the Rust specific API. That was going to be my next avenue of research. 
&gt; Now that I think of it, simply calling exit(0) on OOM in the custom allocator would suffice to avoid false positives on OOM. At least they wouldn't be treated as crashes. Hrm, good call. Honggfuzz will complain a little since this breaks the persistent mode it runs targets under but there's an idea here. &gt; Also, did your fuzz harness for str::repeat actually expose the bug? This would help me narrow down what's wrong with mine. I haven't given it enough CPU time yet. Tomorrow is when I start the run. 
`unwrap()` is intended to be used in production code in situations where you can *prove* it will never panic. Because humans are bad at proofs, you still need a plan for what happens when you were wrong. As bad as terminating the production program is, it's way better than the other things that might happen…
Unfortunately: 1. there is a certain way of writing Rust code wherein panics occur for conditions that aren't as fatal, and 2. there are countless ways of writing Rust code wherein a panic is inevitable, due to some sort of mistake in programming, in which case we would've liked to have caught that mistake before running the program and executing that particular codepath.
Man, I think I have a problem. Every time I see someone doing something game related I reflexively look into the deps to see what graphics libraries they're using. Sometimes it makes surprising results! As someone who is not much of a Windows programmer, what is the benefit of your `apiw` over just `winapi`?
Don't forget to disable checksum verification in the code. Otherwise most of the fuzzer input will be rejected outright.
Fixed that with correct feature/config flags and still happening. 
I *suspect* it's just programmers being lazy and not wanting to add the extra &amp;, but I really don't know for sure. I suspect Google can answer this if we ask appropriately, but I'm too tired to do the research right now.
AFL should handle this just fine. It restarts the binary every several hundred executions in in-process mode anyway, and has a stdin mode that is basically "call binary, feed it input on stdin or in a file, wait for it to terminate, repeat".
[The book explains this with examples](https://doc.rust-lang.org/book/second-edition/ch07-01-mod-and-the-filesystem.html). `pub mod aux { ... }` inside `aux.rs` defines a module `aux` *inside* module `aux`. Don't write the extra `pub mod X { ... }` inside a module source file.
Ah! If you're working with slices and want to copy a part of slice into another part of the same slice, [`split_at_mut()`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) got you covered.
&gt; Sadly, most of the times the file will be on a network drive. In that case, network speed will probably be the dominant factor, so hyper optimising IO will be mostly pointless. I'd recommend first working out what proportion of time your code spends waiting on the network vs. parsing, so you know how much it's going to matter. There's not much you can do anyway, given that you're reading lines, which means you *must* parse the entire file byte-by-byte. If you really need `Vec&lt;Vec&lt;u8&gt;&gt;` as opposed to `Vec&lt;&amp;[u8]&gt;`, then you can't avoid the copies. Caching files depends on your OS and configuration; I doubt there's much your program specifically can do by the time it runs. Using a [`BufReader`](https://doc.rust-lang.org/std/io/struct.BufReader.html) is about as good as you're likely to get without dark magics.
I always looked at traits as multiple inheritance
(author here) There's a [MySQL adapter](https://github.com/mit-pdos/noria-mysql) that allows existing things that just use a mysql library to connect to Noria without any modifications. It pretends to be a MySQL server and translates all the queries as appropriate. For the benchmarks in the paper we had to cut out Rails and just issue the SQL queries directly, otherwise Ruby immediately became the bottleneck. 
Quicksilver maintainer here: I'm aware! The docs.rs compiler is fairly ancient (it's a nightly from 1.28, the current stable is 1.29.1 and the current nightly is 1.31) and therefore fails to build some crates that are transitive dependencies of Quicksilver's. Until their compiler gets updated, there's nothing I can do on that front, unfortunately. I will at some point in the future be setting up some self-hosted Quicksilver docs, but it's a hassle and there's no great way to do it.
A source file is a module? I didn't realize that, thanks. After removing the module declarations, the compiler tells me that aux should be file aux.rs in the src directory, which it is already... 
Please fix it, the "smooth scroll" is a disaster.
I have to agree. Just considered this for my code and adding a trait specifically for testing seems a bit too much. Not that it won't work, but one generally doesn't expect whole constructs added just for testing purposes. So far I was able to get away with a more modular approach (http calls are conveniently strings and json in and out, so you can create methods that just work directly with those) but I did have to use a similar approach once with Readers, where I was swapping test files in to emulate stream input. Mocking seems to be a bit of a challenge in Rust.
Iirc it got me covered until the parts might overlap... :-/
`winapi` is just `-sys` style binding, all functions are unsafe, it has long paths for `use`ing, and it care nothing about ownership etc. I wrapped the API a little to create a safe interface.
Maybe we should have a seperate subreddit for WebAssembly or just Rust-Wasm?
I view a Rust panic as the same as a C abort or failed assert. You shouldn't catch a panic, you should debug how it happened and fix the bug that allowed the panic to happen in the first place. I'm no experienced Rust programmer, but the vast majority of the panics I've gotten were the result of using unwrap() where invalid inputs were a possibility or a logic bug that allowed me to access an invalid index of a slice or Vector.
Pushing at work to open source two tools written in rust. Here's to hoping.
If you assume programming errors happen and just continue along as best you can, you have no idea what invariants are broken or how your data has been corrupted. That seems much more dangerous than a panic and controlled restart.
I mean, if you returned an error whenever you paniced you could let your caller know about what the nature of the broken invariant or corrupted data is. 
r/WebAssembly exists, though it doesn't seem to be terribly active.
I think she's the GOAT at explaining the web
If using "panic" properly and for its intended purpose,then, yes. If misusing it, perhaps not. But, that itself is a bug.
I mean, *division* panics instead of returning a DivByZero or whatever error. I don't think sanitary this-only-panics-if-literally-everything-including-you-is-borked panics are really the norm. 
Here is the complete information: Directory of C:\Keep\Development\Rust\temp\src 2018-10-08 16:36 &lt;DIR&gt; . 2018-10-08 16:36 &lt;DIR&gt; .. 2018-10-08 17:56 56 aux.rs 2018-10-08 18:03 70 main.rs 2018-10-08 17:56 30 util.rs 3 File(s) 156 bytes main.rs: mod aux; mod util; use aux::a; use util::u; fn main() { a(); u(); } aux.rs: use utils::u; pub fn a() { print!("A and "); u(); } util.rs: pub fn u() { println!("U") } C:\Keep\Development\Rust\temp\src&gt;cargo build Compiling temp v0.1.0 (file:///C:/Keep/Development/Rust/temp) error[E0583]: file not found for module `aux` --&gt; src\main.rs:1:5 | 1 | mod aux; | ^^^ | = help: name the file either aux.rs or aux\mod.rs inside the directory "src" error: aborting due to previous error I don't know why it doesn't see file aux.rs, which is in the same src directory, but that's the message I get. Something is amiss.
... check your `Cargo.toml`. If it has a line that says `edition = "2018"`, delete that line, then try again.
I'm curious to see where you've seen it, I can't say I've ever seen it before (and I've read a lot of C code, both good and terrible). I managed to find where they do it in [minimp3](https://github.com/lieff/minimp3/blob/master/minimp3.h#L1656) and it *looks* like they're just being lazy, at the cost of being a bit confusing.
Madman! 
&gt; They are rarely caught, sometimes even disabled completely, so panicking is usually equivalent to termination thats.. thats the point of panics. Panics are not exceptions. Panics should not be treated as exceptions. Panics are hard errors, code panics when you have done something *wrong* which there is no reasonable way recover from, panics should indicate you have a bug in your code. They enforce invariants. The rest of this post stems from the misconception that panics *should* be caught, and that they're exceptions. &gt; Panic flows are hard to support and easy to forget, especially in unsafe code, so catching panics may leave system in undefined state Panic flows don't matter because panics are hard errors, not recoverable exceptions. &gt; Panic flow support sometimes impacts convenience. For example Mutex in std lib can be poisoned and this state must be explicitly supported by the user. See the [nomicon on poisoning](https://doc.rust-lang.org/nomicon/poisoning.html) for why rust mutexs poison. &gt; Std lib is loaded with panicking functions, it's almost impossible not to use them and small mistake while doing it may crash whole program Thats because such a mistake is called a bug. &gt; Documenting panic condition is only an act of good will and thorough code analysis by function author Thats true of all documentation, should we add `#![no_functions]` to prevent using functions because they might be poorly documented?
Hmm, I what kind of blogging platform they're using, whether it does the url route handling, or if they have some other kind of router in front of it.
No such line: [package] name = "temp" version = "0.1.0" authors = ["Anyone"] [dependencies] 
Ah found it! Thanks. 
The problem is that, when some component encounters such a situation, you often don't want it to take down the whole program. That's why I've resorted to the Rust equivalent to my solution for Python. (Wrap every logical unit of work in `catch_unwind`, just as I wrap every logical unit of work in `except Exception:` in Python.) ...and, if I don't feel confident that I can ensure unwind-based panics in a project, I'll probably move the workers into their own subprocesses to get my way.
(Not my project, no association with said project.)
My experience is that the most common cause of panics is faulty assumptions by crate authors about what forms input data can take and that the proper way to handle them is to log an error on that unit of work and move on to the next one.
**OOOH!** [*It's a special file name!*](http://kizu514.com/blog/forbidden-file-names-on-windows-10/) There was talk at one point about warning on these names in Rust, since all they fail in weird, inexplicable ways on Windows machines. Clearly, that never happened. :D You might want to raise this as an issue, because this is *nasty.*
Thanks for pointing out. I'll update it. I didn't understand the dealloc part. could you explain me that?
&gt; Is `#![no_panic]` an idea, which could fly? Would anybody care to use it? Is Rust std lib without panicking possible or is it rooted to deeply? Allocation can panic, so yeah, it's pretty deeply rooted. You'd need an alternate standard library for this.
&gt; If you want to twiddle bytes in a concise and low-level way, holy shit C has got you covered. That sort of low-level memory-mongling is what C was designed for, and it is good at it. Can someone give me some example and/or explanation of this? How do you manipulate bytes in C and how it differs from options available in, say, C#?
implement my editor slowly: https://crates.io/crates/read
That would be awesome :)
That's probably the most important comment, thank you!
That's something worth considering, thank you!
I don't know if rust has such a thing, but Go has a `recover` keyword, which catches all `panics`. That's useful when running a server, so an Array out of bounds (a example of a Go panic which exists in Rust, but a badly placed unwrap would have the same effect) would be caught at the goroutine level, so the server stays up, but the individual listener (for all practical terms) would dump a stack trace and return early. Java also has the `try { DoSomethingWithTheResponse(r)}catch(Exception e){e.printStackTrace();}` which does the same. Generally, that's more of what you want that a true no_panic.
In theory, libraries should never panic, so it shouldn't split the ecosystem. In practice, using array notation introduces possible panics, so it's just too bothersome, especially that until fairly recently (the `?` keyword), you had to `match` on every `Result`.
Only in debug mode. In compile mode it overflows and continues going. It's unfortunate, but math would be way too slow otherwise.
I did a year ago a planet (news aggregator statically served) in Rust, called [planetrs](https://github.com/Vagdish/planetrs). It's not the same as a dynamic news feed (and far less user-friendly) but maybe it's a good start for you.
As others mentioned, panics are asserts, so there's no way to fix them. For example, you try doing a regex. You do something like this: let a = vec![1,2,3,4,5,6,7,8,9]; println!("The 9th number in the above vec is {}", a[9]); This panics. The reason is that you've got an off by one error, and it can't always be caught by static analysis. So how woul;d you fix it? let a = vec![1,2,3,4,5,6,7,8,9]; let re = a.get(9); match re{ Ok(e) =&gt; {println!("The 9th number in the above vec is {}", e); //the rest of the function}, Err(e) =&gt; println!("I've got a bug here: {}",e) } So what would you stick in the `Err` branch? You have to stop whatever you're doing, because you've got a bug in the code. You've got to get out. The thing that's true, though, is that often you need your program to continue, even when you've got bad code. For example, a server shouldn't go down completely because if someone tries real hard, and sends a precise sequence of bytes, he'll cause the server to try reading past the end of an array or something. So rust actually provides you with a special closure: fn main() { use std::panic; let result = panic::catch_unwind(|| { println!("hello!"); let a = vec![1, 2, 3, 4, 5, 6, 7, 8, 9]; println!("The 9th number in the above vec is {}", a[9]); }); println!("{:?}", result); println!("See, I can continue in a loop"); } Total safety when you need it, and none of the downsides.
Thank you for submitting your entry for the first clippy and rustfix benchmark challenge!
&gt; If you really need `Vec&lt;Vec&lt;u8&gt;&gt;` as opposed to `Vec&lt;&amp;[u8]&gt;` Oh, but `Vec&lt;&amp;[u8]&gt;` suits me fine as well, I just thought I'd _have_ to copy out the bits (because they bits have to go _somewhere_ after reading, I figured). Could you give me a hint how to achieve that? I was planning to use `BufRead::read_until`, what would be the alternative?
Read the whole file into a single, giant `Vec&lt;u8&gt;`, then split *that*.
I'm not familiar with modern C# so I can't compare it, but the features of **non-portable** C that are good for this kind of low level stuff is: Bit fields - you can give names to single (or many) bits and access them like a struct's field. Unions (they work like Rust's). Pointer casting between char (in practice byte) pointers and other types (including structs). If you want to write portable C, it gets a lot harder. There are plenty of things that are undefined or implementation defined, like padding and alignment between fields (including bit fields), the size of the data types and so on.
Ahh so easy, thanks :) Will see if that all fits my bill indeed, but it's a good start, thanks again!
If I'm not mistaken, faliable containers are planned.
&gt; That didn’t seem hopeful though, ’cause the C functions are almost all static and thus their symbols don’t get exported. Sometimes when I've unit tested C I've created a new file and added: #define static #include "file-i-want-to-test.c" #undef static &amp;#x200B;
&gt; Such as Factory line. You don't want to continue running indefinitely, but you certainly want to end up in a clean state and halt all the machines if something is fatally wrong, because that way you only pay for a factory halt instead of a new factory. &gt; High-availability networking equipment in programmed Erlang, which generally handles errors by crashing the entire faulty process, immediately respawning it, and possibly dropping some crash-inducing inputs. Throwing away some crash-inducing inputs doesn't sound all too good if you're a plane pilot, does it? *Let it crash* is an acceptable strategy if the crash causes people to [dramatically turn towards the camera](https://m.imgur.com/gallery/H9qf8) because their internet just dropped for 10 seconds. As soon as the damage becomes expensive or humans are involved, I would want something more deterministic that returns the system to a known-good state before shutting down.
Not all units of work can contain the problem though. Like, if a logical inconsistency is introduced that causes every single unit of work to panic, a hard reset is needed anyway. The best solution probably depends on the specific type of application. In distributed services, usually failing the job is more robust, because the task manager, like kubernetes, will just bring it back up. Something like flight software might require a different approach, I don't know.
This is not RAII but linear types. Brackets is RAII. You could write a C++ code, similar to this failure example in Haskell: void f (Test * t) { Test x; x.show(); t = &amp;x; } int main () { Test * t = new Test(); f(t); t-&gt;show(); } Now I'm curious if linear monad or behavioral types are to help in this case.
`dealloc` takes an immutable reference to the node (`&amp;self`). You are then mutating that into a mutable pointer and deallocating that, taking away the data behind the reference that's still around. The calling code in theory would still be able to use the Node. In your code that's not directly as dramatic as there's only a single place this is called and it's internal. The whole allocating/deallocating thing also looks more complicated than it needs to be. You should be able to get away with a `Box&lt;Node&lt;K,V&gt;&gt;` just as easily (and maybe turning that into a pointer/integer). (Again, this is looking at only a few specific places. I didn't read the code in full, there might be other problems hiding.)
&gt; I managed to talk my coworker out of using it. :-) Did they manage to tell you why they wanted to do it thus?
IMO, it's very important for Wasm in Rust because Rust can not yet access directly the Web API. Most calls to Web API have to be done through JavaScript, that's why the web-sys crate is a breakthrough is Wasm usability. Unfortunately since JS calls are slow, it often nullifies the Wasm performance improvement.
My one thing to add is that if I were translating something into rust, the first thing I would do after getting it compiling is to run Clippy. It can catch many patterns that are unidiomatic and provide more idiomatic replacements. Simply going through what it spits out will automatically make it better Rust code. It obviously can't do everything, but the default settings are extremely unlikely to make the code worse.
I'd love to try and run clippy through that if it weren't time for me to head to bed. I might tackle it tomorrow if I feel like it.
There are cases where panics are there for construct convenience though e.g. `[]` panics on OOB access. You could easily avoid it and use `.get()` instead, but you have to be aware of the issue.
The result is the same, yet for some reason the `if` has been ever so slightly faster in the `cargo bench`marks. Come to think of it, it is not worth it. I would accept your PR.
What hardware errors cause panics?
One reason to do this is if the function originally accepted the structure as a parameter and was changed to use the structure as a local. It's easier and produces less noise in the diff.
I think you forgot that changing `t` inside `f` has no affect on `t` inside `main` since the `t` in `f` is just a copy of the other one. You get the behaviour you expected using references: void f (Test *&amp; t) { ... } But even then, `t` points to near the top of the stack which probably just makes `show` display garbage data instead of causing a segfault. Anyhow, it *is* undefined behaviour.
Great post. Why not share what you learned about mp3 encoding, too?
Have you tried adapting Noria to Postgres?
Does this detect integer overflows etc.?
&gt; Not logic bugs, so that's a good deal for `HashMap` and `VecDeque`! Perhaps https://github.com/rust-lang/rust/issues/54477 might make a good test case.
Yes, you are right. Not sure about UB, but `reset(Obj ** x)` is quite a common pattern in [C](https://gstreamer.freedesktop.org/data/doc/gstreamer/head/gstreamer/html/GstObject.html#gst-object-replace)
I'm curious, why do you dislike ternary operators? I in fact think they're *better* than if statements, since they are so much more concise. E.g. if Rust had ternary operators: // bad IMO let x = if a {b} else {c}; // good IMO let x = a ? b : c; Of course when you have multiple statements, and are not using it as an expression, it may look odd: a ? { b(); c(); } : { d(); f(); }
&gt; Being able to statically know for sure that a crate or set of code can't panic would indeed be lovely and make it much easier to reason around. And potentially require a bit less integration testing and manual verification. The problem is that panics are quite common. Case in point would be slice indexing.
For reference the project is [Aardwolf](https://aardwolf.social/). Open source, federated, Facebook-like social media software being developed in Rust. [Git repo](https://github.com/Aardwolf-Social/aardwolf)
And this is exactly where you use `catch_unwind`
It was a case of cargo cult programming, there was another case of it in the code he was working with...
You mean that's the reason \`Option\` and \`Result\` exist. Panic is for fatal errors and can be turned into an abort instead of an unwind at compile time, Option/Result is for "expected" errors
You probably meant to post on /r/playrust. Please check before posting.
This needs to be on hacker news
What're your coding goals?
Thanks, I'll check it out.
oh come on. https://github.com/search?q=language%3Arust+%22panic%21%28%22&amp;type=Code There are **heaps of people doing this**, and its annoying as hell when you use a crate that does it.
Thank you so much for sharing this. :)
In Go the idiom is to add context at every propagation point. It's essentially a backtrace at that point.
Manual error checking never worked; doing it in Rust doesn't suddenly make it work. And given that almost every line of Rust code you write could produce a panic, your "exactly where" becomes "everywhere". GL HF.
&gt; Thats because such a mistake is called a bug. Then why does `catch_unwind` exist? ...because if what you posit is correct, any application panic should result in a hard application termination event. You can't have it both ways: Either you can recover from panics (in which case we acknowledge they *are* bad, and that you should be able to recover from them), or you can't, and a panic is hard, irrecoverable application error, which must terminate the application. The problem is that, in practice, the wrong things panic. .unwrap() of a None is a panic. ...but maybe, that was an icon that you wanted to show next to a user instead of the default user image. Did you really *abort the entire application and halt the website* because of that? ...that seems a little extreme. Maybe panic should be exactly what you're saying it should be... but then there's a whole lot of little things like `unwrap` that should be removed and replaced with `unwrap_or` as the only alternative. That's not going to happen. ...and panics are therefore, here to stay, for stupid reasons like, someone forgot to check a value before calling unwrap() on some trivial piece of data, or worse, used a crate the somewhere, deep in its internals, did that. So... I think it's a bit rough to sit on a high horse and say 'that's a bug, just don't write code with bugs'.
I interpreted his comment to mean that certain hardware failures caused rust panics. I understand that hardware failures could cause unexpected behaviour which could somehow trip a panic but I thought he meant more directly which I don't believe is the case as it does not make sense for a userspace program to attempt to recover from a hardware failure.
Huh, didn't know you could do this ! Makes sense though. I wonder how many syntactic "tricks" like this are possible that my brain just assumes aren't because I'm coming from other c style languages. if { np = np - 1; np } == 0 { ... }
I'm not sure what you are trying to show with those links, but, I'm not sure how it show ANY particular point. It's just a raw search for Panic and Unwrap. The first 10 unwraps I looked at would never panic except if there were a Hardware issue (memory corruption, memory bus failure, etc, stray cosmic rays, etc). So, if anything, I think it proves my point more than the point you are trying to make.
Nope OOB access on an array is an indication of faulty algorithm logic. In other words, your program is fatally flawed. So, PANIC!
/r/playrust does not allow server advertisement, you want /r/playrustservers
OOB access on slices/arrays is an indication of a faulty algorithm that cannot produce consistent correct results. The only sensible thing is to panic.
You don't need to catch for that, just set a handler: https://doc.rust-lang.org/stable/std/panic/fn.set_hook.html &gt; The panic hook is invoked when a thread panics, but before the panic runtime is invoked. As such, the hook will run with both the aborting and unwinding runtimes. 
&gt; Then why does `catch_unwind` exist? For situations like FFI, where panic-ing over a language boundary is UB. Or, so that you can have things like thread pools, where the thread can die but not kill the entire pool. Those cases are important enough to have `catch_unwind`, but not important enough that Rust went for over a year after 1.0 without having a way to catch a panic.
&gt; I in fact think they're better than if statements, since they are so much more concise. Concision is not the only value. I find in your first example, `if/else` is *marginally* worse, but in the second version, ternaries are *significantly* worse. The downside is larger than the upside. 
Yes it detects every possible panic. Though in my case I ended up using `#[no_panic]` only in release mode, because in debug mode basically everything is able to panic -- most real-world code requires optimization to eliminate panic codepaths. Integer overflow currently does not panic in release mode.
Trying to write a clone of a soon-to-be released card game. My clone isn't meant to be actually played though; I don't think the real game has a bot API, so I'm trying to write my clone in a manner that it can be interracted with through external scripts. I'd like to use it as a machine learning exercise, but I've never made a game before, so making the clone is quite an exercise already :P
I'd like to read each line of a file into some sort of collection, probably an array or vector. Currently I have: let file = File::open(file_path) .expect("Couldn't open file."); let buf_reader = BufReader::new(file); let mut word_list = Vec::new(); for line in buf_reader.lines() { match line { Ok(l) =&gt; word_list.push(String::from(l)), Err(_) =&gt; break }; }; word_list As my function and it appears to work, but it doesn't feel very idiomatic or clean. I'm convinced there's a more concise way to do this and basically have the whole thing just be an expression that is then implicitly returned, but I'm not entirely sure how to do so. My initial thought was to do something like `Vec::from_iter(buf_reader.lines())` but `.lines()` returns `Result` enums, so I'm not sure how to go about extracting the actual value from the results it provides in a concise manner. This is cobbled together from reading the first handful of chapters of the Rust book and a bit of searching, so I fully expect I'm doing something horribly wrong. Any thoughts? 
try this book. great examples of custom list like data types: http://cglab.ca/%7Eabeinges/blah/too-many-lists/book/
This is what I did in lewton as well. I even [used a macro](https://github.com/RustAudio/lewton/blob/0333ce511e5d588cf3dee28689158869e8ae2f21/src/imdct.rs#L79-L92) to make it more pleasant.
&gt; 1. Are custom iterators optimized the same way that the built-in iterators by the compiler? If yes, under what conditions? The code is given to LLVM, which then inlines/optimizes aggressively (because it's all monomorphized). &gt; 2. What would be the most idiomatic way to solve this? Use `.map` on `idx.iter()`, and construct your pairs of mutable references in that method using `index_mut`. The biggest performance overhead will likely be that `index_mut` will want to do bounds check and the compiler will not be able to deduce that they are unnecessary.
More like "webboy from toxic office" news
&gt; Did you really abort the entire application and halt the website because of that? ..uh, yes? Because using `unwrap` means i, as the programmer, am 100% abso-fucking-lutely sure i actually *have* an icon to display. Since that turned out false, there is a horrible bug. Without panics you just get some corruption because `None` isnt an icon, the icon is nonexistant in your scenario, and by using `unwrap` you have signaled that it is impossible for it to not exist, and that you explicitly have no error conditions you want to handle, no placeholders, nothing. If you wanted to display text or a placeholder if the icon was missing, the proper solution is to actually fucking handle the possibility of the icon missing, which in this case would be to handle the `Option` and, yknow, match on it. Display the icon if it's `Some`, placeholder if it's `None` just because panics exist doesnt mean you still don't have to handle your damn errors, like trying to display a nonexistant icon. Your scenario is "no error handling, just blindly attempt to display an icon that may or may not actually exist". Kinda like in C/C++ having a pointer to an icon, and then trying to display it, but it's a null pointer because it doesnt exist. So now your program is experiencing UB, possibly/probably crashed, displaying garbage, nasal demons, whatever. the proper solution isnt to make it so C/C++ don't have UB on null pointer dereferencing, it's to check to make sure your Icon actually fucking exists &gt; That's not going to happen. Thats because you should just write your code correctly, not make the language weaker because you can't be bothered to handle error conditions and just want it to silently fail and/or corrupt your program. &gt; for stupid reasons like, someone forgot to check a value before calling unwrap() on some trivial piece of data, THOSE ARE CALLED BUGS. THOSE ARE BUGS. Jesus christ, what the hell do you want? Without panics you'll still have forgotten to check the data and still have a bug and your program will still probably crash or do something else wrong! No panics won't magically solve the problem of you writing terrible buggy code, at best it will just silently break, like in C/C++! Except even there trying to use nonexistant objects will probably crash! except when it doesnt, making debugging fun. &gt; I think it's a bit rough to sit on a high horse and say 'that's a bug, just don't write code with bugs'. Panics are meant to *catch* those bugs. Nobodies saying "Just be a perfect programmer and never write code with bugs!" panics alert you to the presence of bugs. which you can then pinpoint and fix, instead of everything just silently breaking! Sure, crashes suck. Yknow what else sucks? *BUGS*! Yknow what sucks more than bugs? Silent bugs. The kind that cause a crash or error 3000 lines and 20 functions away 15 minutes after the bad code ran. The ones that don't helpfully yell "Here i am! here is where something went wrong! please fix me! i'm right here!" That take hours just to find and turn out mind numbingly simple to fix. I don't understand why you're so agaisnt a nice polite bug telling you where it is and why it's broken, and i ***really*** don't understand what you want to replace it? Silent breakage? Why? Why would anyone want that?! ---- Also, to add on to the other commentator about threads, catching threads that panic is useful, and importantly it's probably memory *safe*, because in the absence of shared state or unsafe code, if a thread crashes it hasnt corrupted any other part of the program. This is also why mutexs get poisoned. You're not so much "catching" the panic like an exception as you are being notified it crashed. Think of it more like two processes. Monitoring to see if one crashes and noting the exit code it isnt "catching" a crash, even if they use IPC to communicate.
Excellent! I've been hoping for a database system like this for years. I've always thought that all of the manual caching layers and cache invalidation, and denormalization, is something that the database should be able to handle rather than hand-crafted layers built on top for each application. Really glad to see that this can be done! Glad to see that you worked with Frank McSherry on the differential dataflow benchmarking. Interested in your thoughts on including transactions and full consistency in such a database. As you mention, full consistency is part of what causes differential dataflow not to scale as well. Are there ways to allow for a small subset of queries and transactions which require consistency, while still having the better performance of eventual consistency for the majority of read-only queries?
It's not a Rust problem though, it's an OS problem that affects any and all software that can create files on Windows. I would think that the Windows file system should be preventing it, or at least issuing warnings when a file with a reserved name is created, instead of silently accepting a new file that has a name known by the system to be problematic. It doesn't. Thanks, Microsoft!
`#[no_panic]` is more reasonable. Usually you only care if function may or may not panic when you write unsafe code. Having `#[no_panic]` attribute on method guarantees that you can call it with no worries. And there are lot more functions that may panic than panicless. Cause having at least one panicking function in call tree make function panicking.
Raspberry Pi?
Makes sense
I'd argue that `Stream` trait is possible.
Thanks for the tips. I think the bounds check overhead can be sidestepped with some unsafe{}. The indices are guaranteed to be disjoint, but of course there might be headwind trying to get the borrow checker to accept this fact. The bigger problem would be that I don't think the checker will allow the mutable references to escape the closure passed into .map(). Ie. I don't think I can do something like this: &amp;#x200B; `idx.iter().map(|i| {&amp;mut v1[i.0], &amp;mut v2[i.1]}).filter(...).collect()...` &amp;#x200B;
You can do this eith unsafe code. But then you should put data into struct, implement iterator for borrowed struct, ensure that no one can create struct with repeated indices. 
https://news.ycombinator.com/item?id=18172234
Well, Windows is unlikely to change. That leaves Cargo/rustc the only things in this situation that can really do something about it. So really, it's a choice between *something* or nothing.
Yep :)
If/else is a lot easier to find in code than ternary operators, also reusing if/else means you don't have an if/else statement and then ternary expressions, they're the same thing in both cases when if/else can be used in expressions.
Okay, I think I've finally realized why silent panics are a good idea. Suppose we live in a world where instead of division or array access panicking on 0 denominator, out of bounds, etc. they returned an error. This would obviously be silly if you can prove in the caller that your input was correct because you'd be checking things for no reason, so you might want a method that bypassed the sanity check and just did the division/array access. Except what is that method to do if your proof is wrong and your input really is invalid? If it panics or aborts and there's loud panicking, you've basically created a second version of the same function that does the exact same thing and either isn't easier to call or is more unreliable, not less. If it just continues as normal, it's going to do something extremely nasty like memory unsafety that Rust is supposed to be designed to avoid. This is unacceptable. So instead of writing the same function two different ways, or writing only the code that returns errors and hence having to type ?s absolutely everywhere in your code base, it's better to write the function only one silent way and if you really want to recover from a panic for some reason you can catch it.
IIRC, this is a place where Erlang *really* shines.
This is great! We need more media libraries in Rust to prevent vulnerabilities.
Maybe we should do the opposite though : add a #[cant_panic] annotation, that would allow developers to mark the few function which are panic free. Of course it would rarely be used, because so many things can panic in Rust, but it would provide two benefits : - give a tool to avoid panics to people who really care about them at all cost. - kill the “panic annotation” meme.
&gt; idx contains indices into v1 and v2, before I go and google.. is there something like a scatter/gather crate, with utilities like 'inverting'* indices (and checking if they're invertible without overlaps) (* figuring out indices for a gather equivalent to a subset of possible scatters, etc etc)
And if you're doing it for a job, you'll have all day to go through it, whereas if you're doing it on the side, you probably only have a few hours here and there.
@unsafe-experts: I'm not completely sure if the suggested solution at the bottom is 100% safe or invokes undefined behaviour. Please keep on reading and correct my if I'm wrong... I think it's safe to say that, as far as the compiler is concerned, there is no difference between "build-in" and "custom" iterators. All the iterators are implemented in Rust. The optimization potential comes from the fact that usually the compiler knows all the details about an iterator and can inline and optimize code properly. One way of creating new iterators is by using the iterator methods `map` and similar. You don't have to write your own named user-defined type and implement the Iterator trait. And thanks to `impl Trait`, you can write a function that returns such a thing. So ... one might be inclined to write this: fn indexed_pairs&lt;'i,'a,'b,'r,T,U&gt;(idxs: &amp;'i [(usize, usize)], v1: &amp;'a mut [T], v2: &amp;'b mut [U]) -&gt; impl Iterator&lt;Item=(&amp;'a mut T, &amp;'b mut U)&gt; + 'r where 'a: 'r, 'b: 'r, 'i: 'r { idxs.iter().map(move |&amp;(i1, i2)| { (&amp;mut v1[i1], &amp;mut v2[i2]) }) } But this won't compile. And for good reason! The compiler basically stops us from creating multiple mutable references to the same slice elements. Consider what would happen in this situation if the compiler let us do that: let idx = vec![(1, 0), (1, 2)]; // &lt;-- Index 1 appears twice! let mut v1 = vec![1, 2, 3]; let mut v2 = vec![1, 2, 3, 4, 5, 6]; let mut iter = ...; // create the iterator let x = iter.next(); let y = iter.next(); Now, we would have two usable mutable references to access v1[1]: `x.0` and `y.0` because the index `1` appears twice in the `idx` array. This must not happen as it violates a basic rule in Rust: sharing XOR mutation. This is where `unsafe` could come in. The compiler can't really check whether the values in `idxs` are all unique. You have to do this yourself. Not necessarily in that function. But if that function relies on the uniqueness of indices to stay safe and it doesn't check it, it better be an unsafe, too: /// This function is unsafe because it does not check the uniqueness /// of all the indices in `idxs` which is required in order to avoid /// multiple usable mutable references to the same slice elements. unsafe fn indexed_pairs&lt;'i,'a,'b,'r,T,U&gt;(idxs: &amp;'i [(usize, usize)], v1: &amp;'a mut [T], v2: &amp;'b mut [U]) -&gt; impl Iterator&lt;Item=(&amp;'a mut T, &amp;'b mut U)&gt; + 'r where 'a: 'r, 'b: 'r, 'i: 'r { idxs.iter().map(move |&amp;(i1, i2)| { // Adjust lifetimes and prevent reborrowing of v1/v2 // This is safe as long as all values for i1 are unique // and all values for i2 are unique. let r1: &amp;'a mut T = &amp;mut *(&amp;mut v1[i1] as *mut _); let r2: &amp;'b mut U = &amp;mut *(&amp;mut v2[i2] as *mut _); (r1, r2) }) } I'm not 100% sure, though, that this is correct. I don't know whether it's OK to store the slices as mutable references into the iterator. Obviously, there is aliasing between the references it hands out and the whole mutable slices. If that's not OK, you would have to go one level lower and store the references to the slices in terms of raw pointers and lengths.
Do you have pictures of what the frontend looks like? I didn't see any in the readme.
I don't think it needs to be thought about uniquely. If external function calls were optimised in some way on another official Rust target platform would it be relevant? If so the same reasons would be relevant for the official target.
Nice! There have been various attempts by people to write one, including me, but none really ended in a finished product. This is the closest to a finished product that I know of.
Mainly due to your second example. Even worse is trying to chain them, analogous to a long chain of `else if`'s, is not easy for my brain to parse. I'm sure it would be with practice, but, we can just use normal if statements and not sweat it. Also since the `?` is after the first statement, there's always a bit of a mental gear-clash when I'm reading code; "oh wait, this is part of a ternary operator". When I can see the `if` first thing, what kind of expression I'm reading is obvious as I read it.
I hadn't thought of it this way or it's true. Try searching for `?` or `:` in Rust code!
Thanks, I guess I should have poked around the project a bit more rather then just looking at the top directory README.
Downvoting my comment doesn't make my statements about my own experiences any less true.
This would be very helpful for people how just want to take a look. But frankly there is no kind of user managements implemented and I don't know whether this would be wise. Perhaps a dummy server with disabled upload is doable, I will open an issue :) (and I have no public server atm ..)
I finished off and published my new crate [oaidl](https://crates.io/crates/oaidl) which allows for conversion to and from three major COM/OLE data structures - BSTR, SAFEARRAY, and VARIANT. (SAFEARRAY of VARIANTs is treated by C# as an object[] as an example.) 
It is a database that integrates a cache and automatically keeps it up to date. This makes all your reads very fast, and avoids complexity in application code (like cache invalidations, read-throughs, etc.). You may want to give the first two or three sections of the paper :)
Yeah, perhaps there should be at least a picture on the front readme or some kind of demo ..
I'd assume it's for similar reasons to the Python world, which Rust learned quite a few lessons from. `*` imports make it more difficult for a new/returning developer to figure out where a symbol is coming from and increase the chances that an update to a dependency could break a build.
I’m not a fan of adding near-useless things to the language to win internet arguments.
The 3 is `(3, 5)` would be out of range there BTW.
and it completely breaks "back" gestures with magic mice and touch pads
I have a naming convention question. I often find myself wanting to have a trait and struct with the same name. For example: trait Ratio { const NUMERATOR : i64; const DENOMENATOR : i64 } struct Ratio&lt;NUM: typenum::Integer, DEN: typenum::Integer&gt; { ... } I have a small handful of these trait/struct pairs. I've been appending 'T' to the name of my structs. I don't particularly like that. But I can't find a good solution. Thanks!
`self` is the current module (when dealing with paths) or the current object. `&amp;self` is a reference the the current object, useful if you want to use the object but not take ownership. `Self` refers to the type of the current object. For example: impl MyTrait for i32 { fn to_larger(self) -&gt;i64 { // This function takes ownership of self, meaning self is effectively destroyed when this function runs. } fn add_one(&amp;mut self) { // This function takes a mutable reference, it can modify itself, but will continue to live after this function } fn new() -&gt; Self { // Self means the current type, which is i32 } }
Honestly I think this idea makes sense but only under an very very specific circumstances to the point it’s probably not worth it yet. My thoughts: a single no_panic attribute and only if your runtime has absolutely no panics, so if your only using core or an alternate std, an ideally it’s at a very high level like per-crate, not per call site/function definition. 
&gt; The point is that many code fragments can be statically verified not to panic, and it would be useful if they could be marked as such, even if not all of the program could be made panic-free. Why? Especially in those cases where you cannot afford to panic (say, in a kernel or server), you can catch the panic (thereby guaranteeing that nothing inside will panic).
Borrowing is explicit, via "&amp;" or "&amp;mut". Move is every call where you don't borrow.
Wow, a pure Rust database. And it seems really mature. Very impressive.
Of course, Python also has gratuitous unfortunate behavior with `*` imports: see `module-fail` [here](https://github.com/BartMassey/python-fail). I have mixed feelings about all of this. My general rule for Rust code is to use `*` imports when using a substantial amount of the names in a module, specific imports for symbols I will be using a substantial number of times, and DRY for symbols whose use is more-or-less one-off. Not sure this is the *best* plan, but so far it has seemed to keep my code pretty reasonable. The other corner case for `*` is to publish bare enum names: in a lot of situations, I think that a qualifying enum typename is just a hassle and makes the code less readable.
What you recommend is commonly refereed to as the 'prelude'. Many crates re-export important parts of their api in a module called 'prelude', which are TYPICALLY niche enough that they shouldn't cause name collisions. Actix and Diesel are two off the top of my head that use this strategy. You could define your own prelude, and have other parts of your programs `use crate::prelude::*`, which would import a consistent baseline namespace. 
&gt; I don't think I can do something like this: That's right. The lifetimes of `&amp;mut v1[i.0]` and `&amp;mut v2[i.0]` are not the ones you want/need.
There are pros and cons to both approaches: - manually adding context means adding only relevant details, - automatically providing the callstack means much more succinct code, and no risk of "empty" context. I think a *mixed* approach would be even better: - gather the stack trace by default: low-effort, low-cost, good pay-off. - manually add context (in `defer`-like statements) that is only formatted/gathered in case of error: small effort, low-cost, increased pay-off. That is, I mean: fn create_database(name: &amp;str, config_file: &amp;str) -&gt; Result&lt;Database&gt; { context!("while creating database {}", name); create_database_from(name, read_config(config_file)?) }
This week I'm finishing off ptrace support for BSDs in nix-rust/nix. Also had to do some rust-lang/libc PRs to add ptrace constants for the BSDs. Once that's done I'll see if OSX support for [tarpaulin](https://github.com/xd009642/tarpaulin) "just works", it probably won't though. Also if I have time finish the RCC part of my embedded-hal crate so I can implement the timer traits.
If you know the indices are disjoint then my recommendation would be to build up your pairs of references right away if at all possible: let v1 = vec![...]; let v2 = vec![...]; let refs1 = v1.iter_mut().collect(); let refs2 = v2.iter_mut().collect(); // Shuffle the refs around as needed by using `swap`. ref1.into_iter().zip(refs2.into_iter()).do_more_stuff Then the lifetime issue won't be a concern (the lifetimes are long but known to be non-overlapping).
There are two breakdowns here. First, `Self` is a type. In `impl MyType`, a function `fn new() -&gt; Self` is equivalent to `fn new() -&gt; MyType`, while in a `trait MyTrait` requiring `fn trait_func() -&gt; Self` means requiring a function that returns the implementing type. `self`, on the other hand, is the "receiver"; that is, the value on which a method is called. In the expression `a.my_method()`, `a` is the receiver. If `my_method()` has the signature `fn my_method(self)`, `my_method` will take ownership of `a`. Similarly, `&amp;self` means the method takes an immutable reference, and `&amp;mut self` means the method takes a mutable reference.
&gt; Std lib is loaded with panicking functions, it's almost impossible not to use them and small mistake while doing it may crash whole program AFAIK these reveal design errors in the stdlib itself. If you could detect such errors at runtime, there's at least two options: (1) do nothing and start to violate guarantees/behavior offered by the stdlib or (2) panic/terminate. Do you prefer #1 over #2? Is there a better third option?
I don't understand what any of this has to do with DRY. DRY is often misunderstood as "don't type too much and never something of the same shape twice", while it's really about "don't encode the same information twice in a system". \`\`\`rust use std::io::Result; use std::io::Error; \`\`\` is \_as dry\_ as &amp;#x200B; \`\`\`rust use std::io::{Result, Error}; \`\`\` or &amp;#x200B; \`\`\`rust use std::io::prelude::\*; \`\`\` Or no code at all (implicit import, if it were possible). Language semantics like having to explicitly import or not (and where) are really not part of it DRY. It's about systems construction and from that perspective, all of the above is the same. See [https://www.artima.com/intv/dry.html](https://www.artima.com/intv/dry.html) (Lower part)
I concur! One of the biggest bottleneck and pieces of complexity I've seen in one of the applications I maintained was a trivial *counter*: how many X are associated to one Y? The problem is that the answered ranged from 1 to a couple millions, and in the latter case attempting to actually count them was just too slow no matter how the query was tweaked. Multiple generations of developers desperately tried to make it work, adding convoluted strategies to try and keep concurrency on insert/delete (because updating a single counter hundreds of time per second doesn't work) and ultimately just introducing complexity and bugs; the counter was always wrong, and wrong by orders of magnitude on the larger folders... In the end, I just axed the feature (limiting the count to 1000+). I *could* have made it worked I think; my plan was to parallelize the counters (one counter for each (Y, updater) pair) which would still lead to a trivial query for the value of the counter (sum across updaters for a given Y), but once axed we realized nobody really cared anyway...
Yes I'm aware it can panic, that's why there's an attribute. The reason I used `shouldnt_panic` rather than `cant_panic` is because I didn't want to indicate that it can't panic. The attribute is intended to be used in situations where local context ensure it can't panic (indexing with known length) or when you want to explicitly ignore that type of panic (formatting, allocation, etc).
I'm having a discussion about it on the Windows Forum. I've learned that there are checks in various place to prevent the creation of files and directories with reserved names: the command line window prevents it, Windows Explorer prevents it, the non-Microsoft products I tried like Notepad++ also prevent it, but somehow VS Code does not. I cannot rename a source file aux?.rs for example, it issues an error message and changes the name to auxÉ.rs on my installation, yet somehow I can rename it to aux.rs without problem or warning. So Windows is not devoid of safeguards, they just fail to catch all possibilities and may not be aware of the glitch. I'll see if I can report to the right MS tech group.
To add to that, arithmetic may panic depending on compiler flags.
With Cargo, [Build.rs](https://Build.rs) allows us to execute stuff before we compile. Just need to find a hook that will pass the full path of the resulting binary, once complete. (Then decide if the path contains debug or release.)
I agree this isn't about DRY as we typically use it, but the acronym is entirely valid in this post. main.rs: use a; use b; use c; lib.rs use a; use b; use c; otherlib.rs: use a; use b; use c; Is a lot of code that basically says "I need a, b, and c in the global namespace'. If OP comes from Javascript this seems awfully repetitive, and it feels like he's having to *repeat himself*, which the acronym DRY (Don't repeat yourself) would describe perfectly fine. 
I've been looking for a comprehensive pure Rust solution for music tagging, i.e. TagLib for Rust. I'll be keeping tabs on this in case you decide to support formats other than opus.
Your particular problem is not possible to solve. This won't compile, for a good reason. fn main() { let idx = vec![1, 3, 5]; let mut v = vec![1, 2, 3, 4, 5, 6]; let iter = idx.iter().map(|&amp;i| &amp;mut v[i]); } If it would, this would work. fn main() { let idx = vec![0, 0]; let mut v = vec![1]; let mut iter = idx.iter().map(|&amp;i| &amp;mut v[i]); let a = iter.next().unwrap(); let b = iter.next().unwrap(); } `a` and `b` would be mutable references to the same memory location, violating Rust memory safety requirements.
It is indeed, but can see use cases for scenarios where one would want to use a [no_panic] and disallow such slice indexing and other functions that can panic. Unlikely to be a super common case, but still
I wonder why more people don’t rename the module to something brief and use it as a scope. It’s something I’ve seen in Haskell quite a bit and I’ve noticed people working with numpy and pandas doing it a lot more often lately. I think it more or less satisfies the desire for both concision and clarity since the one or two letter name import and rename is right at the top and it doesn’t add a lot of finger burden in actual use. Rust supports it without issue as far as I can tell and I can’t think of any problems off the top of my head except maybe a VERY new Rust user who might think the short names are special.
If you have anything resembling a modern runtime environment, you can be ready to have a main controlling process "panicking" (crashing) at any point and restore a wanted fail-safe state using another one dedicated to that (or depending on the system, dedicated hardware). Trying to have your *whole* program completely bug free is vain, and trying to write it in a way so that any possible bug will be recoverable from inside is extremely hard, and nearly impossible in a system that can allocate. So don't pretend that programming errors won't lead to crashes: if possible instead check your invariants often, and be ready to handle crashes from anywhere. And no, this can't be *totally* covered dynamically with no possibility of "panic", because those paths would be by far the hardest to test, probably the majority of LOC, and there is no reason that they themselves do not contain programming errors. So at best you will have some paths that would yield to completely random behavior at the applicative level (think of it like it is a virtual machine running potentially unsafe code: even if your VM implementation is perfectly bug free, and as a reasonable approximation binary produced by Rust from unsafe-free source is langage-level-UB free, you can still have any possible bug in the code running in the VM: that the same think for other applications than VM: it can be panic free yet have totally unacceptable behavior because some important higher level invariants have been broken) And TBH industrial control systems go way beyond that: you can destroy the main PLC, all components in the field will take their fail-safe states all by themselves. The main idea is that you can't attain safety by pretending that crashes or even in some cases complete controller/network destruction will not happen. You get safety by, despite trying your best to not having to get into this stage, having your system ready to handle failures at various levels, and that means using safety components somehow separated from those you want to protect against failure. Protecting from the inside is not enough (at least not to prevent costly destructions, loss of life, etc.) 
A context macro seems great. It fixes the most annoying part, that it needs to be appended to every error-producing function call. What would that expand to?
What is the relation between the trait and the struct? Is the struct like a default implementer of the trait?
Current (Okt. 2018) version of rav1e can encode video at a rate of about 0.08 fps, on my Ryzen 7 1700, which is huge already - this is not taking multithreading in consideration, 
I was wondering that too
(Lobsters admin here) What Jonhoo said, also: this research was based on [statistics gathered from Lobsters usage](https://lobste.rs/s/cqnzl5/lobste_rs_access_pattern_statistics_for). We did not share our db, production logs, or switch the production Lobsters instance over to this. (Footnote 32 in the paper references this thread.) Just don't want anyone wonder if we gave away data like Facebook or [migrated away from Rails](https://lobste.rs/s/rxxkly).
Beginner here, but I would think that a trait is a general characteristic that will apply to many cases while a struct that implements the trait should be specific to the case at hand and would be better named RatioOfSomething for example.
Very interesting. I'm going to try to get involved. I'm truly interested in seeing emacs ported to Rust. &amp;#x200B; Out of curiosity, is there any reason that something like RMSBolt ([https://gitlab.com/jgkamat/rmsbolt](https://gitlab.com/jgkamat/rmsbolt)) wouldn't work with the remacs?
The JavaScript (and Ruby) community have much the same discussion around the misuse of DRY (which, capitalized, goes back to “the pragmatic programmer” and is a standing term.
I thought half the draw of emacs was how pervasively you could use elisp to configure, extend, and modify it. Not to say that this effort isn't cool... but it seems like it wouldn't really fulfill the philosophical goals that emacs was going for.
I [did some research on it a while back](https://github.com/beetbox/beets/issues/2388) and it should be 100% possible to make beets way faster. However, it would require ripping out and redoing a lot of the database code, and everything that touches it, so...
Great to have you :) Anything that works in Emacs should work in Remacs as well. We don't want to introduce any regressions.
&gt; ... Achieving abstraction is super hard when you can just reach down into some bytes and noodle around with them instead. Reaching down and noodling around with bytes is one of my favorite things to do in C! 🤣 
I have a pretty boring setup, but it does have Racer configured.
... in which hear about the infamous brothers Fatan and Satan :). Sorry, couldn't resist. Just curious: Is there some hope that any/all of this work will be upstreamed into GNU Emacs? (Or is it already being upstreamed, perchance?)
Damn, i'm reading that thread now, and you put in a lot of work. I'm sad it wasn't more fruitful. I just posted a reply, because while I don't know beets at all, I do know a small bit about solving that specific kind of problem. 
Yes, I love those variable names. It's just a convention, but every convention has some fun quirks :) I don't really know how to quantify the hope in this case, but very little effort that I know of has gone into a future merging of the two. Personally I'm helping out with Remacs because it's fun, and because I'm interested in learning a thing or two about the Emacs internals.
can someone briefly explain what this is, what is can be used for, etc? &amp;#x200B;
Thanks :) If something doesn't work or if you have ideas for improvements please feel free to open issues. I thought it would be pretty simple but if you want to support the whole spec and all the edge cases it is definitely non-trivial - we need a good crate to share efforts on this.
Are they guaranteed to be evaluated at compile time or just act as a marker? Are they cached between compilations?
Yeah, I alias modules sometimes. I think a lot of Rust programmers aren't aware that you can rename a module, since it's not in a lot of standard new-programmer documentation. Scoped module `use` is one of those things that I typically don't do, just because if I'm bringing a module in I'll probably use it in several scopes, and I'm not too worried about accidental name collisions within a single file.
Wow now do nvim
Finally no more runtime! I'll henceforth let the compiler carry out all my computations.
A \`const fn\` is a function that behaves deterministically (e.g. a "pure function") and thus you can know that if the function is passed two expressions that evaluate to the same value, then the function will always provide the same output back. This means that you cannot define a true random number generator in a \`const fn\`, do FFI, or generally perform any input/output operations. For example, you may not write: \`\`\`rust const fn foo() { println!("bar"); } \`\`\` Because a \`const fn\` is pure, if all the arguments provided to it can be computed at compile time, then the output can also known at compile time. This means that you can write: \`\`\`rust const fn is\_even(x: usize) -&gt; bool { x % 2 == 0 } // OK! The value \`42\` is known at compile time, so we know that \`is\_even(42)\` at compile time: const FOO: bool = is\_even(42); \`\`\` A more elaborate description of what you can currently do with the \`const fn\` that we are stabilizing is described in the [reference](https://github.com/rust-lang-nursery/reference/blob/3a7b6d863183079d46d92313df7875e22801de8d/src/items/functions.md#const-functions).
The Rust Networking Services working group is conducting a survey on writing Web services in Rust. If you have a few minutes to complete the survey it would be most appreciated, even if you don't write Rust.
gotcha, so as long as the compiler can verify the input to a const function is also const, it can compile time evaluate? 
Reading that reference, why are &amp;&amp; and || not allowed in constant contexts? The explanation there doesn't make sense to me, why can't we just emulate the short circuiting behavior during constant evaluation?
Yes. However, to actually force CTFE ([compile time function execution](https://en.wikipedia.org/wiki/Compile_time_function_execution)) you must also use it in a context which requires a value known at compile time, such as the length of an array (`let foo: [u8; multiply_with_2(21)];`), a `const` item, a `const` parameter (see [RFC 2000](https://github.com/rust-lang/rfcs/pull/2000)), or a `static` item.
The list of restrictions in the minimal implementation seems so severe it may be more helpful to describe what *is* allowed, rather than what isn't.
I'll probably use this to pre-hash strings to integers on lookups, so I can use friendly "GetValue("stringName")" calls and not incur the price of string hashing.
This is discussed in the tracking issue: https://github.com/rust-lang/rust/issues/53555 -- I suspect we'll start lifting restrictions as soon as reasonably possible. In the interim, you can use `&amp;` and `|` on `bool` typed values for the non-short-circuiting behavior.
An exhaustive list of what is allowed is described in [the reference](https://github.com/rust-lang-nursery/reference/blob/3a7b6d863183079d46d92313df7875e22801de8d/src/items/functions.md#const-functions). We'll likely be lifting some of the restrictions soon.
So like C++'s `constexpr`? Is there a resource that compares `const fn` with `constexpr`? Thanks!
I would suggest implementing normal collection traits like `FromIterator` and `Extend`, and add `Default` too for `Iterator::partition` and `unzip`. If you like, it should be *really* easy to add the same for `rayon`, something like: // same K and V constraints as Sync for SkipMap impl&lt;K: Send + Sync + Ord, V: Send + Sync&gt; ParallelExtend&lt;(K, V)&gt; for SkipMap&lt;K, V&gt; { fn par_extend&lt;I&gt;(&amp;mut self, par_iter: I) where I: IntoParallelIterator&lt;Item = (K, V)&gt;, { par_iter .into_par_iter() .for_each(|(k, v)| { self.insert(k, v); }); } } In both the serial and parallel cases, maybe implement for `&amp;SkipMap` too, since you don't really need `&amp;mut self`.
&gt;and I have no public server atm Maybe you can simulate the responses from the server, so the demo doesn't need any remote machine. Thus, you can host it in GitHub Pages or a similar service. 
Just like in the old days, when people discovered make was Turing-complete
My point is the `shouldnt_panic`, no matter the name, is defeating the purpose of the `can_panic`. You are providing an escape for exceptional case, while panic are already supposed to be for exceptional cases.
Is this part of the work or relevant to "Constant Generics"? If so, how far down the field does this move the ball with respect to getting "Constant Generics" implemented?
Will you be able to use `const fn`s inside a `const` expression? For example, using `.log()` or `.ceil()` on a number.
There was [an issue](https://github.com/Wilfred/remacs/issues/238) once discussing copyright assignments (which are required for GNU Emacs contributions). No conclusive answer to your question though :)
A whole lot of people have responded to this thread about the importance of panicking and the meaning of panics and how panics are not "errors" as much as they are "bugs", and I agree with them, but I'm not going to delve too deeply into all the things that have already been said. I do however want to make two points that I don't think have been discussed so far. I've had conversations like this before quite a few times where people were really quite scared of things like `.unwrap()` and friends and would go out of their way to avoid them to kind of ridiculous lengths, and I sort of struggled when trying to explain why I thought that was a bad idea. I think now that the difference we had in our thinking was that I was thinking of things from sort of a theoretical perspective and they were thinking of things from a practical perspective, and I don't think either is wrong really. The reason that the presence panicking just *doesn't* bother me personally is that... well, there's just an unlimited number of ways to write `!`, `panic` is just the nicest one, and I don't feel like taking away the *nicest* way to write `!` is really a good thing. If you'll permit me a bit of theoretical wankery which I am not qualified to perform, Rust is not a "total" language, so all functions in rust have the ability no matter their type to "diverge", aka infinite loop, abort, cause an assert, cause an illegal instruction, mess with the stack, shut down the computer, you name it. From a theoretical perspective, being able to say that a function is `#![no_panic]` just says that it is not able to diverge in *one* way, which is also the most manageable way that we have of expressing divergence. HOWEVER, I can see the desire to have something like a lint that's available on specific functions that just makes certain potential panics more visible! This is where I think I've gotten desynced before in talking about this, that the thinking is not necessarily that forbidding panics will forbid divergence (not possible in a Turing complete language like Rust), but simply that they want to make the fact that say integer division panics really noisy for a particular piece of code, as a simple lint. Just because something is not a perfect solution doesn't mean that it can't be at least helpful in some contexts, right? It's probably a lot easier to accidentally introduce a panic by missing a `checked_div` than it is to accidentally write `loop {}` most of the time, right? Now, looking at this from a "linting" perspective, with the knowledge that nothing we do short of making a total subset of Rust will really remove `!`, the idea of using this as a *crate* level marker and splitting the ecosystem around it is *really* not something that I think is worthwhile. Imagine you wrote a crate that was marked with `#![no_panic]`, and of course being marked as such is now a *compatibility* guarantee. Imagine you had to improve an algorithm in your crate, but to do so you just *had* to take a `Result` and get the `Ok(v)` enum value out of it. You can't add an error because it's an API breaking change, you can't remove the Result, the best you could do is either something like: // We know my_result is Ok here because of &lt;insert logical proof&gt;. We can't panic because // we are marked as `#![no_panic]`, but if this returned a default value that would be a bad // bug, so we need to make sure that can't happen. my_result.unwrap_or_default(); Or, even potentially worse: match my_result { Ok(v) =&gt; v, // This should never happen because of &lt;insert logical proof&gt;, but we can't use panic // because our crate is marked as `#![no_panic]`. Don't worry though, this will never // happen so it's okay! Err(err) =&gt; ::std::process::abort(); } Neither of these outcomes are at all better than panic, in fact they would be much much worse. The next thing you might say would be well, just don't do that, but the two deeply related problems are that Rust's type system cannot encode every invariant you might need to hold, and there are an unlimited number of ways to write divergence, so even if you *do* manage to simply not write this code, you still can't know that you didn't accidentally write `loop {}` etc. You haven't just linted against panicking, you've removed the *best way to diverge* leaving only other worse options. That's my 2 cents anyway.
Can't you use enums ?
[Come on, Toshi!](https://youtu.be/kGXWDqQB3NU) (NSFW)
It will be an interface to shader variables in GPU programming. I won't know the names ahead of time.
Sure, you should be able to if I'm understanding you correctly wrt. "const expression" (there's no `const { .. }` block or something like that).
Great work, rewriting a whole OS seems like a daunting task. 
That is mainly up to LLVM I think; since the operands on either side of `&amp;` cannot perform any side effects, then there's a chance that LLVM may realize that it can short-circuit (if that is beneficial). However, I'm not the most knowledgeable person wrt. optimizations so take what I say here with a grain of salt. :)
This is indirectly relevant to "const generics" ([RFC 2000](https://github.com/rust-lang/rust/issues/44580)) in the sense that the results of `const fn`s may be passed to `const N: usize` parameters and such. However, I don't think it brings us much closer to getting const generics on nightly; that work is done separately and is ongoing.
I dont think Stallman will ever accept that! But who knows! 
Const generic arguments can be obtained by calling `const fn`s, or passed to `const fn`s, but they're otherwise two separate features. The implementation work for const generics is going on here: https://github.com/rust-lang/rust/pull/53645
I thought that they already were partial? I've always used partial to mean what it means in Haskell, which is that something is undefined for some argument, and `undefined` is just Haskell's version of `panic`? Am I using that term wrong?
Huh. I haven't taken a look at your code yet, but Blockly looks pretty cool. I'm personally of the opinion that visual programming can be done well and I'm interested to see how well Blockly does. It seems to power AppInventor which I used a while back. It being able to output code in arbitrary languages is very nice. Looking at how code generators are setup, it should be possible to compile to WASM and load it directly.
Yes, but it does exist now. You can’t have it both ways. Sure, I agree in principal that certain types of errors should panic. My point of contention here is the supposition that a panic is an *application level abort* error, or should be. This is not a point of discussion, it is simply wrong. You can recover from panics, and they are not application abort events. The issue raised in this thread is *not knowing* if a code path will panic or not. ...you can certainly expect not to panic, in some deep path in some dependency, but you don’t really know. So, if you’re writing a robust highly available application, do you just always use catch_unwind, just in case? ...because unexpected application termination due to some bug, in say, Firefox, would be very bad, due to some misplaced unwrap(). I’m not sure what the answer is, but I don’t think it is “panics are fine”.
It’s *not* two processes though, that’s the point. Recovery from a panic is part of rust, it is *not* an application level abort, it’s part of a graceful recovery, and a compelling reason to use rust over say, C++. I don’t know what else to say.