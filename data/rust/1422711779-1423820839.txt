The whole lifetime system is fundamentally based on rooting a lifetime at some place in the control flow graph - which can roughly be though of as the start of a scope in the source code of a function. The concept of a sibling lifetime would mean that no matter where the concrete value of your struct ends up in, it would always be valid. In other words, a sibling lifetime would throw out the dependency on the control flow graph, and thus the whole borrow-checking system itself. It might still be possible to define a usable abstraction for pointers into sibling fields, but it would not _use_ a _special_ lifetime, but at most be a system for _creating_ a _regular_ lifetime based on the current lifetime of the location the struct value is stored in.
I'd argue that what you are describing is still type inference, as I've never seen type inference defined as an algorithm but rather by the ability to leave certain types off. In this sense, even Java 7 added a tiny amount of type inference with generic constructors. But I was wrong to say it applies to anything other than the function signature, so I've updated by previous post to fix that.
Yeah, I can see how that example is confusing. Let me try to explain in a way that hopefully makes sense: A somewhat simple, but correct way to look at it is to say that a concrete lifetime is _exactly the same_ as a variable on the stack. That is, a lifetime is a variable - not the content of the value stored inside the variable, or part of the type of that value, but the variable itself. In other words, everytime you write a function and define local variables, you also implicitly define the lifetime of those variables, by their location in the source code: let a = 5; // Implicitly defines the lifetime of the variable a let b = 6; // Implicitly defines the lifetime of the variable b let c = 7; // Implicitly defines the lifetime of the variable c What the rustbyexample example does is to just give those defined lifetimes ad-hoc names - it gives the lifetime of the first variable the name `'a`, the second one the name `'b`, and so on. That also means that that example is invalid rust code, because it then proceeds to use concrete lifetime names like `'b` without having them actually be declared with that name somewhere in the source code. Rust does not actually have the concept of declaring a concrete lifetime with a name explicitly. There is a single concrete lifetime named `'static`, but all other uses of `'foo` actually refer to a lifetime _variable_ that got instantiated with some concrete lifetime at some point: let a = 5; // variable a has some unnameable lifetime let b = &amp;a; // variable b now contains a reference instanciated // with said unnameable lifetime. // That is, it contains a &amp;'foo i32 where // 'foo == lifetime of variable a. Now, lets look at the concrete code snipped you posted: let boxed_integer = Box::new(4); // `'b` starts here // This is a valid operation let ref_to_box: &amp;'b i32 = &amp;*boxed_integer; //'c starts here First, as said above, that snipped is invalid because there isn't actually a lifetime named `'b` in scope - neither concrete or as generic parameter. If we want to make it more correct, we would either need to explicitly declare the lifetime, which there is __no syntax__ for in current Rust, or talk about the lifetime `'b` purely in the comments. With __hypothetical__ syntax: // Declare the lifetime 'b explicitly 'b: let boxed_integer = Box::new(4); // `'b` starts here // This is a valid operation let ref_to_box: &amp;'b i32 = &amp;*boxed_integer; //'c starts here With comments: let boxed_integer = Box::new(4); // `'b` starts here // This is a valid operation // v this reference inferrs to the lifetime 'b let ref_to_box: &amp;i32 = &amp;*boxed_integer; //'c starts here Hopefully this also shows what relationship `'c` has to `'b`: `'c` is the ad-hoc name chosen for the lifetime of the variable `ref_to_box`, and that variable contains a reference valid for the ad-hoc choosen lifetime name `'b` of the variable `boxed_integer`.
It would be nice Cargo to be installed by default
True, inference is the concept itself, not its concrete implementation. I'd argue that that in the context of Rust though, using the term inference as shorthand for "the kind of inference used for type unification inside a function body" is what usually is expected, and using it for the mechanism named "lifetime elision" instead, while not wrong, can confuse matters more and makes it hard to talk about the conceptual difference between those two.
I was using nanosecond since the epoch as my time-based ID and that doesn't exactly have any uniqueness guarantees. If you really wanted unique time-based IDs, you'd need to use something like the UUID library which tacks on a random tag and takes ~750ns to generate a single UUID (v4) (on my machine).
Good point. Done.
When you say "passed as-is" you mean that my iterator should yield IoResult&lt;Record&gt; instead of Record?
SHA-1 still has appropriate applications. One could use it to implement a DVCS, for example. Both Git and Mercurial use it to great effect.
That's what I've done in similar circumstances. It's a little unwieldy, but there you go.
&gt;Would "Please don't use multiple pseudonyms in this community" be a valuable addition to the CoC, or would there be no point because it's unenforceable? I think it's a good community norm to have, enforceable or no. This is something that's worked out well for Metafilter, for example. Reddit in particular has very different ideas about the appropriateness of identity shenanigans.
Usage of Show and String are backwards. Show can be derived, String must be implemented. I guess it's good that they've been renamed to Debug and Display, respectively. Also, the error of Show not being implement when using {} tells me it's a version of rustc before the String trait was added. 
I did not realize that the politically-correct bullshit was so widespread. I think it should be made pretty clear that no one can be "excluded" from a project (Rust or any project in general), for any reason, including violations of a Code of Conduct (which is a good thing, but is supposed to be a set of guidelines, not an enforced policy). If someone feels offended by someone else, there is a simple solution: stop feeling offended. Freedom and free speech are the most important values and should only be curtailed if absolutely necessary (which means only if someone is flooding with nonsensical messages to achieve a denial of service effect or something like that). 
You're looking for /r/playrust.
&gt; It's like the difference between having your parents tell you climbing trees is bad and fencing off the trees, and you climbing a tree and hurting yourself. With C it's like you fall of the tree and then you notice that you broke your arm. Maybe[1]. Or maybe you feel fine and that climbing trees is no big deal, until you try and catch a ball three days later. I guess Rust is more like being stuck in a harness which is attached to some complicated safety system with wires and ropes going seemingly everywhere. Then you try and take a step to the next branch, and the harness won't let you, and so you think "What the hell, I am completely supported and that branch can definitely support me. This is bullshit." [1] Falls from more than 10 feet is undefined.
The is at least one book planned : http://www.reddit.com/r/rust/comments/2rnked/rust_book_by_packt_publishing/
Very well done and fun to watch. Thanks!
I think you do not understand why the so-called "abuse" happens. For instance, what you call "abuse" by thestinger was mostly strong language used to try to stop and call attention to what he perceived (often correctly) as bad decisions on very important matters. More in general, the so called "abuse" is merely strong language used to communicate that one feels strongly about something. For instance, I used the words "politically-correct bullshit", because such an expression makes it clear that I feel that this a really undesirable thing. If I had used less strong terms, the message might have not been so clear. That's what most "abuse" in development communities is: someone saying "STOP THIS IS REALLY BAD DON'T DO THIS REALLY". This is actually a good thing, and there is no intent to disparage or exclude anyone. Most of the rest of the so-called "abuse" are attacks done to make the writer feel smarter or simply for amusement; this is less useful, but generally still does contain constructive criticism. There are also indeed people who harass others, often the same target repeatedly, merely to cause harm, but this is extremely rare, especially in technical communities. 
And you don't understand too. See my reply to graydon2... And regarding so-called warnings, what are you going to do? Ban accounts for expressing their opinions? As I'm sure you know, there is no way to technically enforce a ban against a competent and motivated adversary and since banning someone might enrage them and actually cause them to start being abusive, I don't think that's an effective policy. 
Also if you just want the docs you can download e.g. https://static.rust-lang.org/dist/rust-docs-1.0.0-alpha-i686-apple-darwin.tar.gz
Many rustbyexample examples are out of date but the main question I saw through most of that IRC discussion was "What *is* a lifetime? Please use small words". Not, "Please explain all the minute details of lifetimes to me". The text may be out of date but the picture shows how the lifetime lines are tied to the scope, at least in a general sense. This should show the concept that lifetimes are supposed to represent, even if all the details are not precise anymore.
Well rust is currently in alpha (which is rather well advertised), so there are no compatibility guarantees right now. If you feel that you are unable to use the language in it's current state then I recommend you wait until beta is released soon. Also, the documentation is updated whenever a change is made (and the Rust guide and rustbyexample are usually very good with this as well), so if you can't identify the issue from the compiler's message then the resources available will usually show you what to do instead.
To be clear: the reason drop(bar) doesn't work is because &amp;T is Copy. You're not moving `bar` into the `drop` function, you're just passing a copy in.
Digging in / making it over "access to an environment" is pointless. We phrase the response as "asking someone to leave" or "exclude you from conversation" in acknowledgement of this fact. You can, indeed, spoil any environment for its users if you wish to stage a dedicated attack. And then it is spoiled and all the people you so much wanted to yell at will leave, because they don't have any time or interest in this nonsense. I happily avoided reddit for a decade and will equally-happily delete my account and go back to avoiding it because of _this_ kind of bullshit; this barely-restrained norm that one has some kind of moral obligation to escalate, attack and shove your opinions into people's faces as aggressively as possible if they dare to express disinterest in hearing you, "because free speech". I only stepped in to try to mediate a fight between people I care about, because I know neither of them really want to hurt one another. A significant slice of the internet seems to have a different agenda -- conversation is a game to win, by making the other person surrender -- and I try to avoid it because life is short and it's actually a losing game for everyone involved.
Well, that's true, although those tools should be looking at changing to SHA256+ as well, especially when they purport to offer security features like signed tags that depend on the digests.
Im not asking to reach the level of python, Just basically making the Syntax easier in general.
1.0.0 beta? I remember reading it on their site
Then we must only hope that, in your benevolence, you do not decide to become enraged and abusive from the ban that you have just received. :)
Thats not the reason - `&amp;mut` is not copy, and it would not end its scope either if passed to `drop`
An O(1) remove should be possible as well, taking advantage of Vec::swap_remove.
&gt; To put it another way - If you train someone with Rust, then teach them all about C and tell them to write a moderately complex program, they're almost certainly going to do the memory management wrong. Analogy: Sure, a person who learns to drive on stick shift will find automatic a breeze. But, I'd say there's zero downside and lots of upside to learning to drive automatic before learning stick. Stick will be a new animal and a time-consuming struggle to learn, but all the other aspects of driving mastered while learning automatic will only support the effort. So is this a bad analogy for learning Rust first then C? Like you'll pick up bad form or something, so that when the time comes to "learn stick" you'll have to unlearn ingrained habits, rather than just add new skills?
How far along are you with this project?
I was initially in favour of first come first serve, but the more I see the practical effects the less I like it - I see a lot of reserved packages, I see worry about making sure we get a good name, and I see a lot of half finished stuff that probably would have been kept private if it weren't for the naming pressure. I guess this increases pressure for collaboration and other open source type benefits, but for a lot of small stuff, I think green field programming is motivation in itself. Anyway, I am hopeful that as the ecosystem matures, this will become less of a problem. But my cynicism about the system is raised for the moment.
I'm not sure there is much scope for improvement of type inference. It is very good already, you only need type annotations at function boundaries and in very rare situations where there is not enough type info (for example, using Iterator::Collect). For most of the latter it is clear that user input is necessary, it is not a weakness in the inference algorithm. Certainly, I don't think we will make improvements which will have a significant effect on the overall feel of the syntax. In particular, we very much intend not to implement global (as opposed to local) type inference. So we will always have type annotations on struct fields and function parameters, etc.
Is there anywhere specifically you find the syntax of Rust difficult? I'm aware that the semantics of lifetimes, etc. are somewhat complex, but my impression is that the syntax itself is pretty nice. I personally like it a lot (well, except for some very minor things - no braces for empty structs, colons for struct initialisation, comma/semicolon inconsistencies in lists, etc. I think only the first of these has a chance of changing).
It's probably not necessary! That's my error then.
When creating all these crates I discussed it with several core rust devs to ensure that I did everything in the nicest manner possible. Unlike most squatters I provided abundant contact information, and all the crates actually have a github repo that people can submit pull requests to (and I'll usually respond within a day or two). Also unlike most squatters I fully intend to flesh out all these crates over time, I'm not just reserving the name in case I feel like using it in the future or to sell to other people. Since I'm one of the few Rust developers that cares deeply about Windows, I took it upon myself to maintain WinAPI bindings for Rust, and reserving all the names in advance is a step I had to take to ensure that I would be able to maintain everything indefinitely into the future without compromise (except for three libraries that had periods in their names, which is apparently illegal for crate names, so I had to compromise by using hyphens instead). 
Nope, [alpha](http://blog.rust-lang.org/2015/01/09/Rust-1.0-alpha.html). 1.0 isn't supposed to release until around April or later. Since it's not even release yet, everything is definitely work in progress. The docs will probably still be for a while after release. Documentation is hard without breakage. Makes it pretty difficult now when there's lots of breakage.
Seems ok to me, since this was done transparently and after consulting core rust devs beforehand. However. 1. retep998 has now committed. You should be prepared to deliver. On all counts. 2. This presumes retep998 is the best person available to do this, since it precludes anyone else from stepping up and creating those crates. retep998 may be one of the few Rust developers that cares deeply about Windows *now*. There may be better qualified and more deeply caring Rust developers out there that haven't devoted much time to Rust because it's not done yet. Maybe not, but still ... 3. If someone clearly more qualified comes along and expresses an interest in adopting and maintaining one of these crates, retep998 should be prepared to hand over control to them. 4. For something so fundamental as crates for the Windows SDK, I think perhaps the Rust team should have reserved those names with the intent of awarding them to the best implementation in the future, after which they are pulled into the standard library. But too late for that now. retep998, you're probably good at what you do, and it will probably work out ok, but you must admit, that was a pretty impressive display of hubris, even if well intentioned. Expect a little flak. Best of luck. 
Sorry to hijack the thread. Why is winmm-sys in crates.io still pointing to your old, standalone winmm-sys repo instead of the new winapi repo?
I would expect there to be a good number of books written after the actual 1.0 release. 
I like this idea a lot. Then you can even avoid collisions with library forks or similar yet independent libraries.
The way you've handled of this situation is a good sign for /r/rust and the rust community in general. Kudos! I've always felt that technical online communities should lean towards more heavy-handedness when it comes to personal discussions, especially ones involving personal attacks. As a moderator of another technical community that has gone through similar issues with personal attacks and threads discussing particular personalities, letting such discussions run for a bit (to avoid the inevitable cries of censorship and tinfoil hattery) and then shutting them down on the first sign of devolution into personal attacks and whatnot is in my experience a good way of dealing with such things. The community is lucky to have a mod like you :)
That makes sense, thanks! Though I'm still uncertain as to why rust cares about the size of the closure memory here. Is it creating owned memory on the heap for thread safety?
Well, for things to work on the low level, sizes must always be known at compile time. That's why there is no variable length, stack allocated array or string, but instead heap allocated vectors `Vec`, and `String`. Many languages default to always allocate stuff on the heap and pass by reference, which is arguably simpler for the user. Rust is a systems language, however, wherefore the users are expected to decide for themselves whether to allocate statically on the stack, or dynamically on the heap. In your example, you could theoretically pass the closure through a `Box` or `&amp;` as `Box&lt;Fn() -&gt; u32&gt;`, aka a trait object, which would fulfill the requirement of being sized, since a `Box`, or any other pointer/reference is always of a specific size known at compile time. **Edit**: I realized that this might not quite have been what you were asking about. It seems you are confused about how generics work. When a function takes as parameter the generic type `F`, the compiler generates multiple functions, each for a different type for `F`. When the code is compiled, there will be a variant of the function for each different variant of closure in the code. I.e. the `fn foo&lt;F: Fn() -&gt; u32&gt;(f: F)` will become `fn foo_1(f: Closure #1), fn foo_2(f: Closure #2) e.t.c.` so there is no heap allocation going on.
Yes, that's probably a major factor.
This suggestion really needs more eyes on it. Here take an up vote. I like. We could even have graphs like github for related forks so we could easily see what forks from what and which is more recently updated. Or not, dont know :P
As before, this heap allocation is a property of the standard library (above `core`) not something inherent in the language. It should be possible to use an implementation of unwinding that does no heap allocation.
There was a discourse post about this that gained traction, but it seems the core team made an executive decision. Edit: it was in the package policies announcement [thread](http://internals.rust-lang.org/t/crates-io-package-policies/). There was little (maybe zero) support in the comments for non-namespaced packages.
Trait objects are one of the features of Rust I have yet to document, for now, http://huonw.github.io/blog/2015/01/peeking-inside-trait-objects/ is great, and may end up being rolled into the official docs.
No, my confusion is that heap allocated memory in glibc makes it the caller's responsibility to do memory managment, so a function pointer doesn't need to know how large a region of memory for a reference it is passed is, it just at some point needs to call `ret` to pop itself back off the stack. (Never mind that in most system's languages these tend to be static regions). If a rust function took ownership of a new fn and `memcpy`'d something new onto the heap then it would need to know the size of the region, but even if ownership was directly passed and it called `free(ptr)` at the end that wouldn't necessitate that the size was explicitly known (since glibc heap allocation includes the heap size as extra memory along with each allocation). Basically what I'm getting from this is that the size of a memory region is a compiler annotation that isn't carried along with a pointer at run time (or is ignored for this purpose) and the compiler wants to guarantee that all memory accesses are valid at compile time, is that right?
I've been contacted to write one but I don't think I'm the write person for the job ;)
I'm not actually all that knowledgeable about what's going on at the lower levels, more than what I wrote above, but as I understand it, the problem is simply that the function trait `Fn() -&gt; u32`, just like an interface in C++, does not have a fixed size, and as such, cannot be allocated on the stack and passed by move or copy, but only through a pointer of some kind, or as a fixed size type, like a specific closure, which implements the trait. Passing the bare trait, `Fn() -&gt; u32`, as an argument does not imply heap allocation, and as amount of bytes to copy must be known at the lowest levels, this not possible. I don't think it has anything to do with safety.
Yeah, this seemed to be so obviously the correct solution that I don't understand why it wasn't picked by default. I did start reading the Discourse thread, but somebody started talking about how the need to come up with arbitrarily nonsensical names would help people create "exciting brands", at which point I ran away screaming and hid under the bedclothes.
I'm not sure there's any heap memory involved here: if `foo()` take a generic `Fn() -&gt; u32` as a parameter, it would be on the stack. `foo()` gets a single pointer to the "end" of the stack, and it needs to know how big `Fn() -&gt; u32` is so it can add (or subtract, depending on ABI) that value to the stack pointer to find the next/previous stack items. Since `Fn() -&gt; u32` doesn't have a fixed size (it might be a closure that closes over a bazillion variables, or over none), then either the compiler needs to generate a new version of `foo()` for each size it's used with, or you need to use a "fat pointer" that includes the size of the target as well as its location in memory (so called "trait objects").
at a simple level, curly braces vs significant whitespace (python,etc) seems like an issue of personal preference. For me, the braces are just familiar, and they make a lot of sense with Rusts' expression-based syntax; I like how it has significant semicolons signifying the return value. 'match' statements as expressions are extemely elegant. (but I completely see why others like whitespace) At a deeper level, overall I think Rust is a tradeoff where you pay more information 'upfront' (syntactically/semantically) to achieve safety and better error messages/robustness for large projects. Its not going to be the best first language. There's certain complexities that are part of its' 'mission statement.' and you pay for those with debugging, tests,security hazards,or heavy runtime in other languages. Coming from C++ I already appreciate the 'cleanup' it has.. 'let', proper tuples, better use of '[T]' in type signatures, a more powerful/less hazardous macro system, if ..{} , and "everything is an expression" . Overall, I'm very happy with Rusts' syntax choices. I would like the option for 'duck type traits' and full inference but when there's an IDE that want will probably go away a little (since the IDE could lookup traits for you or give full autocomplete in generic code). there's also some cases like default/variadic parameters where some additions might mean less use of macros (which are a bit uglier, but thats' fine for complex uses).
As far as I know, 1 + 1 = 2, so I'd use `Int::one() + Int::one()`. Because generics in rust are compile time constructs, it will be inlined to 2 at compile time. 
I personally find it very hard to remember where the explicit lifetime annotations go in a function signature. After the ``fn``? After the function name? Or *before* the function name?
How is it that in all these Rust v. Nim benchmarks that Nim keeps up and even beats Rust while still using a GC? Serious question, I'm new to systems programming and genuinely curious. 
Yes, you're right that this could be made more clear. Please either send a PR with a fix or just file an issue and I'll take care of it. Thank you for reporting!
It bothers me that the main argument behind the namespacing question is that "it has worked out for other ecosystems" (so far). If a library creator wants to market their work with an exciting and unique name, they should be free so, but I don't think everyone should be burdened with the task. [Thread for the lazy.](http://internals.rust-lang.org/t/crates-io-package-policies/1041)
This is a massive pain for generic programming. The best I can do is: let two: T = num::cast(2).unwrap();
&gt; Why is this extra indirection required? Well, it sort of trades one kind of indirection for another. You *can* write this: fn foo(f: &amp;Fn() -&gt; u32) { println!("{}", f()); } fn main() { foo(&amp;|| 42); } You save a type parameter at the cost of a pointer indirection. This indirection is necessary, because the size of a closure is not “standardized”. If you close over many variables by value, for example, the closure will be big. If you don't close over anything, the closure will be small. So, you have the choice between * introducing a type parameter for the possible closure types (with varying sizes) * introducing a pointer indirection (trait object) You should prefer the first option just for consistency with everything else and also because this allows the compiler to do the inlining optimization. And if you need type erasure, nothing stops you from calling such a generic function with a boxed/borrowed and type-erased closure.
where should I do these things? sorry I'm a bit new.
Hey, I made a dice roller! ...it was a lot less complicated: $ d 20 19 But it did use OSRng, which meant that it was probably considerably more random than actual dice. 
No worries! http://github.com/rust-lang/rust/issues/new would let you file an issue. It's just one form if you have a GitHub account. If you want to make a PR, https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md#pull-request-procedure has you covered. For a small change to just the English, rather than the code, no `make check` required. This is a bit harder, but it means you'll be an official contributor to Rust, eligible for that purple flair :) If you don't want to do any of this, just let me know, and I will on your behalf.
&gt;As far as I know, 2 = 1 + 1 I would make sure to write some unit tests for this, though, in case the code is ever used in a parallel universe where this is not true.
Haha, that's a fantastic analogy.
Right on, will file an issue shortly.
My issue with this specific instance (WinAPI FFI) is that there are just so many crates taking (some rather general) top-level names. Like `format-sys`. Crates need some way of grouping (so you'd use `winapi/format-sys` or `user/format-sys`) or these should have all been qualified in the name (`winapi_format-sys`). What if someone else wants to make bindings to a `format`?
I've made [similar arguments](http://internals.rust-lang.org/t/crates-io-package-policies/1041/10?u=tikue) in favor of namespacing.
And I thought portability between CPU architectures and operating systems was pain...
I'm working on my slides for FOSDEM tomorrow, and noticed we hit 1,300 crates on crates.io. Woo!
Entirely reasonable, as someone who does Windows stuff a lot I'm excited for this project, thanks for putting in all the hard work so far!
Thanks for taking a look. I'm sorry I don't have a Linux box handy for testing. There are some Linux instructions for Piston here: https://github.com/PistonDevelopers/Piston-Tutorials/tree/master/getting-started But they don't seem to go into much more detail than helping you install SDL2. Oh and, sorry, I should mention the SDL2 dependency in the Readme as well. 
If you look at the docs for `Box`, you'll see this: impl&lt;T&gt; Clone for Box&lt;T&gt; where T: Clone `Clone` is only implemented on a `Box` if the thing in the box is, itself, cloneable. `[T]` is not cloneable, and *cannot be* cloneable. If it was, then it would have to implement the method fn clone(&amp;self) -&gt; [T] This involves returning a dynamically sized type (which `[T]` is) from a function, which is impossible. As for why that is: ask yourself how much space should the compiler allocate on the stack to store a `[T]`? Keep in mind that the compiler cannot know how many elements are in said array, but it must be able to statically compute the space requirements. **Edit**: I suppose I should propose a solution, too. I'd probably go with `boxed_array.iter().cloned().collect::&lt;Vec&lt;_&gt;&gt;().into_boxed_slice()` or the nearest equivalent.
Right, I can see how that would be faster. Thanks for taking the time to explain it.
It only showed up a few days ago, and I believe that so long as `old_io` exists, new `io` is still not done. The rename was to allow existing code to keep working while functionality is transferred/rewritten/refactored rather than just rendering Rust incapable of IO for a while.
Natalie Weizenbaum and I designed [the package manager for the Dart language](http://pub.dartlang.org). One of the many things we deliberated on in the early days was whether to have a flat namespace or scoped by author. All of the arguments *against* a flat namespace are, I think, based on a fear of what *could* happen. Yes, people *could* squat. Yes, the simple short names *could* get taken. Yes, you *could* run out of nice short names. But, in practice, none of those things *do* happen. There are over 122 *thousand* packages on npm. There are over 208 *billion* possible eight letter names. There is *plenty* of real estate for settlers to move into in a flat namespace. I understand the sentiment. It does feel a bit scary to say "yeah, we're all just going to play in this one big room." It triggers some sort of monkey territoriality instinct that some people shy away from. But it turns out that that one big room is *really* big, and a slapping an author name before every package name just isn't needed. Having scoped names adds a lot of real complexity. It makes packages harder for humans to easily discuss. Either the package name is unambiguous without the namespace, in which case it adds no value, or a collision *has* occurred in which case people have to always mention the author. It gets pretty tiring to talk about "fred's http" all the time. It's even worse if Fred originally had the *only* HTTP package and everyone got used to calling it "http". Then dave/http gets hugely popular and now you've got an Internet full of outdated blog posts mentioning "http" that are misleading and confusing. Even more problematic in my book is the simple fact that *packages change owners*. When Joe gets tired of maintaining his package and passes the torch onto Bill, now you've thousands of references in code that are wrong. I like how GitHub scopes repos to the owner (because GitHub has different constraints from a programming language package manager), but you'll notice that most high profile projects end up creating an organization for their repo eventually. You end up with scala/scala, angular/angular.js, iojs/io.js, nwjs/nw.js, Homebrew/homebrew, rails/rails, jquery/jquery, django/django, laravel/laravel, etc. When it comes down to it, the package has a *name*—an identifier that's meaningful to the actual humans that really matter in this equation. That name doesn't usually include any kind of qualifier. If that's how the users think about it, it's a net win if that's how the package manager thinks about it too.
Because that's not actually the full definition. Look at [the source for `Ordering`](http://doc.rust-lang.org/src/core/cmp.rs.html#107-156). You can ignore the `stable` annotations (they don't affect anything). Aside from the enum variants themselves, there's also auto-derived implementations of the `Clone`, `Copy`, `PartialEq`, and `Debug` traits, *plus* a public `reverse` method. Incidentally, that `PartialEq` is what you need for `==` to work.
All in all I think you have a very sound stance here. The one thing I mourn is that the internet communities rely so heavily on centralized forums to communicate. If Rust or any other community didn't rely on central fixtures to converse, I'd feel much better about your direction to go find one's own platform. Overcoming the network externality that we lock ourselves into is impossible with the current setup, and so exile and falling into disfavor is a harsh bitter thing. If we existed in a digital system where inbound links were more visible, where conversation could spread out, I would feel much better when a community decides it doesn't want to host a particular voice. There is a free speech issue here, and it's one created by our reliance on fixed meeting-places online, and while I don't think we have an obligation to host everyone, I do think we have a reciprocal obligation to ourselves to hear more than the approved, channeled, moderated voices of any given community: communities need an element of dissent that they don't readily wish to support or permit. EFF's [Facing the Challenge of Online Harassment](https://www.eff.org/deeplinks/2015/01/facing-challenge-online-harassment) talks a little about the difficulty of moderation, and goes on to say: *We think that the best solutions to harassment do not lie with creating new laws, or expecting corporations [ed: or community moderators] to police in the best interests of the harassed. Instead, we think the best course of action will be rooted in the core ideals underpinning the Internet: decentralization, creativity, community, and user empowerment.* I don't see a way to apply those future-sighted ideals today, but I feel like your well-levelled and justified stance deserves a footnote in defense of those who do find themselves still wanting a voice, but who have been sanctioned by the official mods of a community. Certainly the community ought be able to amass ways to work-around what they find displeasurable, but individuals should also at least have means to make themselves aware, should they want to look out from the moderated core and see what was happening at the periphery. This kind of decentralized happening is not something our online communities are designed to be aware of, and I think communities suffer because this exclusion of voices they don't like is so self-enforcing and so absolute.
This was the reasoning that persuaded the core team to pick a flat namespace. As I said in the other thread, I believed this then and still do, although to a slightly lesser extent. I would like to continue on the current path and see how it plays out - the success of other flat namespaces persuades me. Also, if it does become terrible, it would be fairly easy to move to a namespaced system. Moving in the other direction would be much harder.
Oh I had it backwards, It's the trait that needs to be defined in the crate in order to implement it for arbitrary types. e.g. impl Iterator for str { /* ... */ } gives: error: the type `str` does not reference any types defined in this crate; only traits defined in the current crate can be implemented for arbitrary types [E0117] 
The [an](http://crates.io/crates/an) crate was a semi-joke (but working!) library with the original planned name of `a`, a fun plan only to be wrecked by squatting.
All `#[derive]` does is, for each trait specified, write the "obvious" implementation of it for the annotated type. It's used *a lot*, so you should get used to it. :)
I believe the planned solution to discovery is some kind of promoted/recommended section. I don't really see how namespaces really solve that problem.
The bug for this is [here](https://github.com/rust-lang/rust/issues/21196). It's well known that the example could be better. I'm hesitant to try to fix it again because I'm uncertain my PR will be accepted. [Here](https://github.com/rust-lang/rust/blob/27cc058f67f630003f125516288e2a610a73c090/src/doc/trpl/compound-data-types.md#enums) is also a little elaboration on the issue if you find it helpful. It tries to avoid `==` but also explain a little in case it's tested. Regarding NewType, it's probably short on details so they can defer it to a later section like [match](http://doc.rust-lang.org/book/match.html) and [pattern matching](http://doc.rust-lang.org/book/patterns.html)
&gt;Rust is similar to C/C++ syntax's, but how much farther will Rust move away from that to much easier language syntax like python and such? I think C's syntax is much better than pythons, of course I am no longer a beginner. The first lang I played with was "just basic", no curlies in intro cs I learned java; from then on I have found curly brackets to be awesome and other than python if the lang doesn't use them I'm not sure I like it. scope delimiters you can actually see is a great thing to have, especially when debugging: "was that line supposed to be in the loop, or was the indentation changed by mistake?" or tabs vs spaces?
hm, interesting. Any examples of the namespaced approach going badly? The only example of a namespaced package manager I can think of is github, and it works pretty well for them. Pypi and cpan are both examples of where a flat namespace have turned into a pain over time (full of cruft, abandoned packages, multiple bindings of the same library); in npm its worked ok so far. The big benefit of namespaced package managers I can see is in 'curated sections'. For example; the core team could maintain /crates/rust/* which is the set of blessed core libraries (libc, time, etc). Someone else could have /crates/database/* with a curated list of database drivers. Or /crates/piston/ with a list of game related crates. If you look at npm (or indeed pub.dartlang), there's nothing like that; you just have to search the results and hope that you get the right keywords. I think is kind of foolish to force crate authors to basically engage in crate metadata SEO in order for their crates to turn up in search results. 'Most downloaded + keyword' is a very primitive heuristic, and I'm absolutely certain it doesn't result in the best search results. (otherwise you're starting to go down the 'silently mess with search results by secret factor' path, which is just terrible) 
&gt; I like how GitHub scopes repos to the owner (because GitHub has different constraints from a programming language package manager), but you'll notice that most high profile projects end up creating an organization for their repo eventually. You end up with scala/scala, angular/angular.js, iojs/io.js, nwjs/nw.js, Homebrew/homebrew, rails/rails, jquery/jquery, django/django, laravel/laravel, etc. As has been pointed out in the past, this can be codified (as leinengen does) so that for larger projects you only need to write out the name of the project (x/x can be abbreviated to x).
Significant semicolons seems to have come from the ML family. Braces and indentation are both compatible with expression-based languages (in Haskell do notation has support for both braces and indentation)
Lifetimes seem to me like one of those things that you simply do not learn by just reading. One has to practice, practice and then practice a bit more. That would suggest that any document trying to teach people lifetimes should have lots more problem sets than prose.
There is an [initial implementation](https://github.com/rust-lang/rust/pull/21836) now of type ascription, RFC wanted!
It should be possible to also implement `Clone` for `Box&lt;[T]&gt; where T: Clone`, though. I wonder we need to abstract over cloning unsized types to a new allocation - I could imagine `Box&lt;Trait&gt;` being cloneable if `Trait` implements a certain trait.
&gt; You end up with scala/scala, angular/angular.js, iojs/io.js, nwjs/nw.js, Homebrew/homebrew, rails/rails, jquery/jquery, django/django, laravel/laravel, etc. Maven uses namespaces for packaging via the `groupId`. Clojure packages have an established convention, set by the Clojars repository and Leiningen project manager, that the `groupId` is optional both when publishing a package and when referencing a package as a dependency. If the `groupId` is omitted, it is taken to be equal to the `artifactId`. The `artifactId` is roughly equivalent to the package name in Cargo-land. In practice, this convention works very nicely. Some authors choose to namespace all of their projects under their Clojars username or a personal reverse domain. Most choose to use the default "`artifactId = groupId`" convention for "primary" packages but publish smaller, related packages under that primary group. Forks of popular packages meant for niche use-cases typically fall under special Clojars groups that are automatically created for each Clojars username. To provide some concrete examples, these are what you might expect to see as Cargo dependencies with a hypothetical Clojars/Leiningen-style: [dependencies] iron = "1.1.3" # "sugar" for `iron/iron = "1.1.3"` iron/bonus-middleware = "*" iron/debugger = "*" iron/hyper = "2.1" # iron's own fork of the `hyper/hyper` package. Clojars has some other very nice things like package "promotion", which enforces that unsigned packages live in a separate namespace (you can't publish an unsigned package to any group but the one created for your username). This and other aspects of Clojars/Leiningen cultivate a security-conscious culture around packaging that I find a little bit lacking in Rust's package system. Overall I think Clojars and Leiningen provide a very nice model for packaging and distribution of packages and I'm somewhat disappointed much of the conversation around building Rust's package system left them out.
Would you need negative impls to avoid coherence issues? impl&lt;T&gt; Clone for Box&lt;T&gt; where T: Clone + Sized impl&lt;T&gt; Clone for Box&lt;[T]&gt; where T: Clone + !Sized The other thing I've used a few times is a `BoxClone` trait in cases where I'm deliberately using virtual dispatch.
This actually gives me an error while compiling. error: the type of this value must be known in this context the specific line I used is k * p * (p + Int::one()) / (Int::one() + Int::one()) plus, while this may work for two, it gets pretty long at numbers like 100 ;)
`[T]` is not `Sized`, so why would it matter?
Because I have, in the past, overestimated the coherence checker's ability to infer (what feels to me like) the blindingly obvious. As such, I tend to be very conservative now. :P I mean, if it was any other trait, I'd expect it to fail. I don't know offhand whether it's clever enough to know that `Sized` is special.
You can implement arbitrary traits for your local type. You can implement your local trait for arbitrary types.
Very interesting. Your project launched me on an adventure through wikipedia's secret sharing pages. Question about your implementation: can you still guarantee information security? I can imagine that having m shares of 1 byte can reveal more information than a single share of m bytes. Do you generate a new polynomial for every byte? Edit: I've browsed through your source code and it appears you use a field of size exactly 256. Isn't a prime-sized field more secure?
We would have just named it time-rs or something in that case. Not a huge deal. As GitHub is cross-language, and not even just for software, namespaces make a lot more sense for them.
&gt; Any examples of the namespaced approach going badly? Yes, Githubs gem host was a disaster: http://www.reddit.com/r/rust/comments/2ncpv9/cratesio_package_groups_proposal/cmclbg7
The only limit a small field imposes is a limit on the number of shares. The field size of 256 elements upper bounds K and N to 255. But I think this is enough. As for information security, yes, for each byte a new polynomial is chosen with their own K-1 randomly selected coefficients. Such a polynomial contains one byte of the secret as offset (coefficient for x^0) as well as K-1 randomly chosen ones (via OsRng to make it reasonably unpredictable) for higher powers of x. But since the shares sample these polynomials at points x != 0 every byte of every share is masked by a nonzero linear combination of K-1 randomly selected bytes. This still leaves at least 256 possibilities for each byte if you have less than K shares available. And this is why it's information-theoretically secure. I think the reason why *prime* fields are mentioned in the Wikipedia article is simply the fact that they make examples simpler. What's important is that these caluclates are done in finite fields, not necessarily prime fields. The construction of non-prime finite fields with, for example, 256 elements are just a little harder to explain. Of course, I'm a human and humans make mistakes. :) If you think there is a way to get any idea about a secret's byte given the respective bytes of K-1 shares, I would be interested in hearing about it. As far as I can tell, non-prime finite fields don't pose an information-theoretical threat. Given a good source of entropy for the randomly chosen polynomial coefficients, the offset (coefficient for x^0) should not leak anywhere.
_Either_ the trait _or_ the type need to be defined in the local crate for a impl to be coherent.
I don't understand why you can't just do this: #[derive(Eq, PartialEq)] struct IntStr {value: i32} #[derive(Eq, PartialEq)] enum ShouldBeEq { HasInt(IntStr), HasNothing } 
Thank you, I am slowly wrapping my head around it. BTW: Episode 4 is the most entertaining (and dramatic) of the bunch.
I can't rule out that I overlooked something. I don't yet see any issue but that doesn't mean that there isn't any. I'll try to work through the security proof and see where makes assumptions that are not met in my implementation… What's bothering me about the english Wikipedia article is that they are presenting an example with S=1234 which could never be the size of a finite field since it's not a power of a prime but the product of two different primes. So, I havn't put a lof ot trust in this article. I'm checking Shamir's original paper right now. :) Thanks for your interest! You've raised my doubts enough so that I want to investigate this further…
The branch is a snapshot of the upstream skia repository on that date, which we merged a couple months ago. I don't know much about Skia, but it sounds like maybe it's usable on its own now?
i would go one step further and add tagging-functionality for crates. so it would be possible to have multiple crates which have e.g. a "http" tag and order the results by popularity
I'll get there eventually :) thanks for making these!
That is already there today. (Except the sort, IIRC)
Yes, it was being recorded. Barring any unexpected issues, it will appear in few weeks at https://video.fosdem.org/ (kudos to the video team here). The slides he used are on his github account or http://www.steveklabnik.com/fosdem2015/
Thanks :)
why not?
You don't even know the half of it. Anyway, this is even more offtopic than my original sorta-kinda on-topic post, so have a good one!
I think it's funny that it reads like a newspaper review would, of something like a book.
As Steve says, this exists in the form of 'keywords': https://crates.io/keywords/http?sort=downloads (That sort isn't necessarily what you meant by popularity, but it is better than nothing.)
The community part was cut off. :( Otherwise, great!
Yeah, I was already over time :(
You are right. I apologize. 
Would be cool if we had it displayed on each crate's page with few neighbouring dependencies.
The second one is invalid, because to have [T], the T itself still has to be Sized
It gets the stability bit wrong. Rust hasn't guaranteed language stability post 1.0; its guaranteed stability of a subset of the language, and that subset isn't changing now save for a few last minute features (eg isize) which couldn't get in pre alpha.
Maybe better to say "consuming a `!Sized` object". 
Can I ask, is there a reason you didn't prepend these all with `winapi_` or something? That would've prevented these issues (taking obvious names), made it clearer what they're for, and would make them more logically grouped as well in searches.
Except almost none of those names were really used by anything except the Windows SDK, and if someone does want bindings to a Windows SDK library, it is easier to have them all organized and maintained together. I don't know why anyone would want their own version of the bindings. The few remaining conflicts (which I have yet to find, perhaps you can enlighten me), can be dealt with on a case by case basis, including ownership transfer if it turns out one of my crates is almost useless and there's a big native library using that name.
I agree, it's wrong. &gt; Despite the claims in the Rust pre-alpha announcement of lanaguage (sic) definition stability, the language changes enough every week or so to break existing programs. This is a classic Mozilla problem; that organization has a track record of deprecating old features in Firefox before the replacement new feature works properly. I don't know where John is getting his "claims" from. Rust pre-alpha has no claim of not making breaking changes. The plan for rust 1.0 [was laid out in December](http://blog.rust-lang.org/2014/12/12/1.0-Timeline.html): &gt; That is, we will reserve the right to make minor breaking changes to both the language and libraries – including #[stable] APIs – throughout the duration of the alpha cycle. But we expect any such changes to be relatively minor tweaks, and changes to #[stable] APIs to be very rare.
I can understand that you think it would be non-disruptive, I just can't see the harm in prefixing. It would completely remove the chance of someone asking for ownership, as moving your crate would make the WinAPI crate naming scheme inconsistent. If anything it makes the names themselves clearer too.
In any large social system, some fraction of people will do less than cool stuff. You can't throw a big party without at least one douchebag showing up. The question then is do you make *everyone* at the party follow more complex rules to cope with that d-bag, or do you just handle the few bad actors on a case-by-case basis? If you've got some people squatting on names and not using them, you could always just give them a while and then email and say, "Hey, this isn't very helpful. How about you let those go?"
llvm should optimize it out if the argument is known at compile time.
There are a couple of generic ones in there that seem like candidates for current or future conflicts on other platforms. I made a list of generic ones here: http://www.reddit.com/r/rust/comments/2uc3m9/placeholder_packages_at_cratesio/co7um14 Also, if you're willing to have a library switch over to something completely different, isn't that kind of harsh for Rust Windows developers? Plus, having a library name suddenly switch to implementations, even for completely different platforms, sounds like it could lead to unpleasant experiences when trying to get old code to build. I'd hope that these are very rare exceptions on crates.io, and not a standard procedure. To me, these are all arguments for having some form of namespacing.
But what if cast returns an error for some reason? Will the panic happen at run time? It would be nice if this kind of error would happen at compile time.
I used that suffix because that's what the documentation recommended I do. http://doc.crates.io/build-script.html#*-sys-packages
Yes, definitely. When I was talking about a performance penalty I was talking specifically about the generic implementation of return-based error handling, as it seemed like it was the generic aspect the author was questioning.
You know, one of the reasons I did this was actually to bring more attention to the lack of namespacing. It seems like my plan worked :P
Ah, that's possible, though my guess is that's not the context they were using. As to the problem itself, I'm not actually sure what the best practice is here. If a more experienced user doesn't happen upon this it might be a good question for StackOverflow.
That's a fair reason. Thanks for the response.
&gt; you would usually pick a random password for encryption and use that password as secret for secretshare A randomly generated binary key, surely.
The discussion with /u/sellibitze below was quite informative. "They way we used to do it" and "Why we changed it" sections might be useful for closures and other features for anyone coming across old examples too, but I imagine that might be restrictive having to document the past too.
I love this idea, and it's awesome to see this is finally being realised. Until now the best approach I ever seen was Apple's Metal shading language that uses subset of C++, but I believe Rust is far better choice. Everything in Rust! 
Where is the giant blob of 420 -sys crates depending on winapi? D:
Try running it through LLVM's own optimizer. It's smart enough to remove most of that. 
I agree with it all but point 1 really brings the bread home for me. Especially being a new language, finding the blessed crate could end up being a pain point for new users. 
The problem with over relying on LLVM is that it makes compilation slow and unexpected slowness (due to optimizations not being done) in some occasions. 
Oh, ha, ditto. How'd you email the admins? I used the email in `whois`, but was there a different one on the site that I missed?
Agree with that last paragraph a lot.
I enjoyed it! Thanks, Steve.
First off, I'm a huge fan of Rust. Second, I'm with the people who think that Rust is still too unstable to be called an "alpha". In the Rust project, _alpha_ was used as a term to signal that it was time to **start** stabilizing the language. The expectation in the greater community for a library in alpha would be a much greater level of API stability, and a level of operational stability. Rust has been all over the place. We're not talking about breaking changes once a week, we're still having them come down almost **daily** (with decreasing frequency). For example; moving the io module to io_old without even the beginnings of a replacement. This wasn't changing a few small functions, this was en-masse deprecating an entire *module*. And it's not just the scope of the changes that is the problem, it's the number of changes happening, and the pace at which they're happening (documentation is often lagging more than a week behind [current compiler behaviour](https://github.com/rust-lang/rust/pull/21834)) That said, I think many of these changes were necessary, I just don't think alpha should have been declared until they were done and the API was stable, or at least close to it. Alphas and Betas should be about bugfixing and runtime stabilization, not continuing to add new features and APIs. At the same time the Rust dev team did need an explicit start and end gate to finish off all of these last minute changes in, otherwise I'm sure they could go on forever. I think now that they've applied the alpha label, they should keep releasing under that label **until** they can all but guarantee language and API stability. The **beta** phase should be about fixing performance, stability and usability bugs; as well as updating the documentation and creating any other tooling and external libraries around the language that are needed. This doesn't mean the language won't make breaking changes in beta, but there should be guarantees around keeping them to one breaking release each week at most. 
steve is defacto the PR guy of rust, i actually checked comments in the article for his reply, so it was useful to me. why did you ask this question? why not send a pm?
If hyphens aren't removed than a way of renaming a dependency in the Cargo configuration would be nice. The current method (`extern crate "a-b" as a_b;`) is unpleasant and seems like one of the little things that will put people off the language. &amp;nbsp; That said, I would prefer it if hyphens were disallowed as that is the least painful solution (having to use an underscore instead of a hyphen isn't a big deal imo).
Yes. That would be the smartest move. Since the app already asks OsRng for bits and bytes, I could go the extra mile of generating the secret randomdly as well. But I havn't yet figured out how it should work out w.r.t. the user interface.
This is very neat. If you are translating from rust to glsl, why not try and hide some of the strangeness of glsl? Like the fact that main function does a really poor job of of expressing flow. Since rust supports multiple outputs, it seems like there could be a very nice way to express the interlinking of the output from the vertex shader into the input of the fragment shader. Maybe something like this: fn vertex(position: vec2) -&gt; (vec4, vec3) { (vec4(position, 0.0, 1.0), vec3(0.5*(position + vec2(1.0, 1.0)), 0.0)) } fn fragment(pos: vec4, color: vec3) -&gt; vec4 { vec4(color, 1.) } 
&gt; What happens when too many dbags show up at your party and you can't kick them out one by one? What happens if a solar flare takes out the Earth? What happens if the Spice Girls get back together but as a metal band? Reasoning like this is based on fear. It's important to worry about things like security and trying to ensure most participants do so in good faith, but if you spend most of your time worrying about bad people and things they can do, you won't make a social construct that's optimized for good people. We live in open source. If we couldn't take for granted that most people are good, the whole system would have collapsed long ago. &gt; Do you just throw your hands up and let the party get ruined? No, of course not. If that happens there are lots of easy steps you can take. Remember, ultimately the Rust folks have total control of crates.io. They could purge the whole thing, switch to model where you have to request a name or whatever. It's still your party. &gt; Also what if a squatter is emailed about relinquishing a name and they either refuse, or are legitimately unable to (say they are in an accident and unable to transfer ownership)? What happens then? Handle it on a case-by-case basis. We're talking about people, not a finite state machine. You don't have to have every possible state transition worked out in advance.
It depends on some more of the context, but the best way to deal with that would be something like this: struct SomethingBox { ptr: *mut Something, } impl SomethingBox { fn new() -&gt; SomethingBox { SomethingBox { ptr: unsafe { alloc_something() } } } fn process(&amp;mut self) { unsafe { process_something(self.ptr); } } } impl Drop for SomethingBox { fn drop(&amp;mut self) { unsafe { free_something(self.ptr); } } } You'll basically have your own kind of box that frees its resources in drop. Now you've got a safe interface over your C interface.
I'm wondering if it's possible to implement zippers in Rust. From what I understand, they don't "tie the knot", so the backlink problem should not be present. Thoughts?
Hard to say; it's all very hush-hush. I doubt there'll be an official IL-&gt;GLSL converter - NG is all about ditching legacy - but that's not to say that one couldn't be built. All the IHVs are on board, so I'd expect good driver support across the board for new HW. No idea yet how compatible it'll be with old HW. I have a hunch that one as-yet-unstated goal of the IL is to reduce porting pain by allowing D3D shader source to be compiled to GL IL, making API abstraction libraries *much* more doable, but obviously that's just a hunch. I don't even work in graphics, let alone have any insider information.
Interesting. It's all very new to me, as I've done hardly any OpenGL programming in the past 8 years. I think Rust and glium have solved about 80% of my frustrations from that era, with the remainder on the GLSL side, hence this project :)
You can't take down packages published on crates.io.
Some of the dependent libraries of e.g. cargo are problematic to build on FreeBSD. libgit2 for example regularly breaks :(.
Or they could just keep using up greek letters. "The dzeta release contains new braking changes."
GC does not need to be slow upfront. One problem with GC is that it is hard to control when it will happen. GC is not a bad thing if you can use it. Rust simply targets use cases where you can't have a runtime or no GC. Rust "has to work (safely) without GC". And I also think it is not about "Nim". You may also compare Haskell, Go, Swift or anything else that "compiles" and pick a benchmark where Rust will "lose" against them. Benchmarking also compares the standard libraries more than the language in anything I have seen so far.
You might choose to use a `Rc&lt;RefCell&lt;Car&gt;&gt;` instead of `&amp;RefCell&lt;Car&gt;` if you need to return your `Wheel`s. In this snippet, the wheels can't live past `car_owner`, so for example you couldn't return your wheels from a function. The `Rc` does have some runtime overhead, so if you don't need to use it you're probably better off not. However, the lifetimes of the wheels could get complicated, so using an `Rc` might make your life easier if you run into ownership problems.
Seems to run fine on the playpen: http://is.gd/A5cPFm I added the `black_box` to ensure it wasn't just optimizing it away.
You could always use unsafe!
Is Rust really at fault here? Our own linked list `DList` used to have the stack overflow on drop bug (But I needed more than 1 million elements to reproduce it). I guess that if you add enough elements, it will overflow even in the optimized version. (*confirmed with 1 mil elements*) What you need to do to defuse it is to implement Drop manually and pick the list apart in a loop.
# My personal opinion # It seems you are a beginner? Please, do not learn Rust. That sounds terrible and frank, but Rust is ***not*** a beginners language. It includes concepts that are not necessary for a beginner to know, and it will be confusing if you don't have the upbringing to understand some of the technical decisions. I would say the same thing about JavaScript, but that is because I have a very negative opinion toward it, that I do not want to get into. # Conclusion # Try [Python](https://www.python.org/)! A language with syntax and semantics that makes sense, with a great and helpful community over at /r/learnpython, and with great learning resources (see /r/python sidebar). I have had a ton of success teaching programming through Python. I also believe that Python and Rust can go hand-in-hand (to a point that I do not understand the Ruby communities' interest in it), with their structured and disciplined outlook into programming. Rust is complicated, you do not want complicated when you are learning to programming, you need simple, and a way to easily grock thinking like a programmer. Python will help you with that. Have fun! Programming is great!
That would only make your code not compile with optimizations turned off, if it needs any amount of work to actually allow TCO.
Honestly, you should usually go with `&amp;` over `Rc`. You can get around the "return" issue by just splitting up the API into two parts (the first returns the thing you want to share, and the second borrows it and returns the struct with the borrow). `Rc` is really only necessary in some specialized situations.
The *Rust team* certainly can. They can nuke the whole site from orbit if they want.
&gt; Question: which one of those packages is of the best quality, stable, maintained? Answer: none of them. What you are looking for is called amqplib, which does not even appear in search results. Discovery—where a user knows the problem they have and wants the best package to solve it—is a hard problem. Names are one facet of that, but in practice, they end up being a relatively small piece of the puzzle. When you need to find the answer to some question on web, how important does the actual URL end up being to determining which page is the best answer? Not very, right? There are a lot of other signals a mature package manager can use to determine what package you're looking for: 1. Let package authors provide multiple tags for what their package pertains to. Unlike the name, these don't have to be unique. 2. Curate lists of blessed packages. 2. Rank packages better. You can use signals like: 1. How often the package is downloaded. 2. How many other packages depend on it. 3. How recently or often it's been updated. 4. Run its tests and see how many there are and how many pass. For kicks, I (locally) ran a few cranks of PageRank on the dependency graph of the Dart packages on pub.dartlang.org. It was pretty interesting and did seem to correlate to which packages are most "important". It would be even better to include packages on GitHub or have some other way of seeing application dependencies. (The packages on pub.dartlang.org are mostly reusable libraries, so dependencies between them don't give much insight into which *applications* use them.) There's a *lot* of things you can do to make this better. There's only so much value you can jam in an identifier. Even if you did have namespaces, all that means is that when a user searches for "amqp", they see "fred/amqp", "bob/amqp", "nercury/amqp", etc. Now what? &gt; What is going to happen? We are going see names like user1-amqp, user2-amqp, ... anyway. In practice, that doesn't seem to happen much. People tend to come up with "brand" names instead: unique words that don't mean anything, or are some play on words for what the package is about.
Piston existed on Github -- which is namespaced -- before crates.io was a thing.
oh wasn't aware of that - thanks
?
?!
OMG DON'T ENCOURAGE HIM (;) &lt;3)
I don't get how it is weaponized? :q!
Thanks for the feedback about Rust not being for beginners. Python seems wonderful.
Great tips! Really appreciate you taking the time to write them. The IRC thing is a great lead, and the other stuff just makes tons of sense. I took a semester of C++ in college, and I've done a little bit with it over the years on my own. Monte Carlo sims and combinatorial analysis for card games as a personal interest. But the numbers they crunched for me are questionable, since I know next to nothing about even stuff as basic as pointers and memory management, or even objects and methods!
I think Ruby people are looking for a complement, rather than a companion, in Rust ;)
I keep holding back learning/using rust because of the frequent breaking changes, I suspect many people are in the same boat. Hopefully there will at least be one six week cycle where everything is stable before 1.0 final, and hopefully the pace of breaking changes grinds to a halt once it is deemed beta.
The meaning of alpha and beta software has become rather mixed up, but I thought alpha was always more of a stabilisation and bugfixing stage, while beta was "we think we're stable but we're not going to guarantee it yet".
Ah ok, makes sense though I thought the whole rust produces unoptimized bytecode was specifically so llvm could do better optimizations.
Having learned HLSL first, then deciding to learn WebGL... The whacky globals for shader inputs in GLSL threw me off. Making a rust macro for GLSL that uses function inputs over globals would be great.
Yes. I get bug reports all the time in the book where I say something like this: &gt; The following won't quite compile: &lt;code&gt; People just skim and then think the example is broken :/ Hopefully we can mitigate that with some CSS.
I was luckily able to attend in person. Steve delivered a great talk, and I think he put Rust on a lot of people's radar. There was historical content that he got from Graydon that will be new even to a lot of rust folks, so I recommend it even if you already know rust. Great job Steve!
My understanding is that Python and Rust have some overlap in the general-purpose programming domain. Within that overlap, under what types of circumstances will it be a better choice to stick with Python? What about within the same major program, is it going to be preferable to code the whole thing in Rust for some reason, or more preferable to only use Rust when its extra power is needed and keep as much in Python as possible for ease/clarity/development speed? And outside of that overlap, in what domains is Python widely considered one of the top options? It does seem hard to beat Python for the pure goal of learning programming fundamentals. I'd find it very motivating to find out that it will also be a language of choice for many purposes later on down the road.
Array having it's size as part of the type is currently baked into the language. Parameterizing a type over an integer is a post-1.0 feature. If your list always has the same length, you could use a tuple, but otherwise, there's little reason to try to keep the size as part of the type. Compilers are pretty good at inferring when the size is static and unrolling loops when beneficial.
Unfortunately, this causes it to *also* concatenate lines that aren't separated with blank lines (look at revision 2 to see the effect :P). It wraps fine if you view the "Raw" version.
As single line statements are more common, I feel using semicolons as end-of-statement marker can be made optional. for multi-line statements, specify line continuation using '\', as in C. for multiple statements on a single line, use semicolon as a separator.
Why is 'ref' a keyword? Why can't operator &amp; be used instead?
Ahh, bummer. That is how Markdown works...
Not exactly what you are looking for but I have a [library](https://github.com/epsilonz/shoggoth.rs) which implements type-level arithmetic for binary numbers among other things like type-level lists, zippers, curried composable type operators (mappable across type lists), etc. One of the eventual intended use cases is data types indexed with exact size or state information. I have a rust [fork](https://github.com/darinmorrison/rust/tree/feature/type_macros) that allows you to use types in macros which makes the whole thing a bit more ergonomic. Using them in conjunction, for example, you could write things like `NatVec&lt;A, nat!(1024)&gt;`, where `nat!` would be a compiler plugin producing the type-level binary natural number. There's some machinery that still needs to be implemented in the library to make it actually usable for that case and I've mostly been focusing on other things. But feel free to open an issue if you like.
At this point, you should just use old_io, and switch to the new io module as it gets created. The rename now is to allow projects to gradually move to the new io module as it is made. You can also see in the docs that old_io isn't actually deprecated, just renamed.
It's for the benefit of the programmer(s), too. I don't want to look at a Vec and wonder, "how many things should be in here?" If I know ahead of time it should have exactly X things, I would like to be able to encode that. That makes it more self-explanatory to read and gives more compile-time safety.
If you are going to learn JS... might as well go for ES6 and spare yourself several pains I (we? everyone handles it differently) had to endure for years - random example: `function` is criminal eye-stabbing. I never personally liked CoffeeScript, but if you prefer Python's syntax, then you can also go for that.
&gt; darn, I have to remember an author and a name This is actually a really nice benefit. When you've been part of a community long enough, you start to recognize names. Some users publish a lot of really good libraries, and seeing that is a kind of brand recognition. With a flat namespace, you have to look at the package metadata to see who published it. That's a little unfortunate, since it's one of the biggest factors for me (aside from popularity of course) in deciding which library to use. I really don't see a downside to namespaces, but a lot of upsides. Sure, you may have lots of packages named the same thing, but it's pretty easy to sort things by popularity, so it really shouldn't be confusing.
&gt; It includes concepts that are not necessary for a beginner to know, and it will be confusing if you don't have the upbringing to understand some of the technical decisions. Maybe I'm biased, but aren't the things for beginners to learn basically just 1.**variables**, 2. **ifs**, 3. **loops** and 4. **functions**? You can learn them in any language, they are the same everywhere. Why not learn them in Rust, then follow to more complex aspects?
First of all, let me say Python is an excellent choice. It lets you start out slowly and pick at it piece by piece. Also, it has paid my bills for years. What you have in mind is reasonable – you can indeed write programs in Python, and extend them in Rust when it is required. Although this is usually done in C, people have used Rust for it [already](https://gist.github.com/atheriel/3ede430057f9dd25da36). That's a useful thing to do in certain circumstances, since Python is, by its very nature, slow. However, "slow" is very relative. There are [very fast web servers](http://www.tornadoweb.org/en/stable/) written in pure Python. Writing extensions is not the only way to optimise Python either. In my work you typically end up with processing tasks that are heavy, taking their time to munge some data – say import large data sets or convert a video. If there weren't tools for it already, I'd write everything in Python and use a [message queue](http://www.rabbitmq.com/) to offload this to a small and specific Rust program that does that one job really quickly and solidly. People use Python for [scientific purposes](http://www.scipy.org/) and data analysis, and it's big in finance. Visual FX use it a lot as a glue language. I mostly write web backends using ([Django](http://djangoproject.com/) and [Flask](http://flask.pocoo.org/)), and you can use it to write mods for Civ V if you want to. It's generally an excellent scripting language that can be used for things well beyond that without trouble. The reason I write in Python in the first place is because it's quick to develop in. I cost more money than hardware, and compiled languages are generally more tedious and error-prone. However I miss some of the things they have. I've played with Rust for a few weeks now, and it seems that it might bridge that gap in an enjoyable way, but there are lots and lots of things missing before I could use it professionally. It'll take at least a year or two before Rust is in that place. I'll also echo that Rust is not for beginners. I'm a professional programmer, and Rust is making my brain hurt – it takes a while to wrap your head around things, and you would probably have way too many concepts to learn at once. In the meantime, Python will serve you well. Good luck! If you have any specific questions about usage domains or whatever, I'm happy to help out.
The breakage to libgit2 is that someone regularly fixes it and the maintainers break it again: https://github.com/libgit2/libgit2/search?q=freebsd&amp;type=Issues&amp;utf8=%E2%9C%93
&gt; First, where in the code does the memory actually get allocated when you type `&amp;[0u8, 1, 2, 3, 4]`? The stack. That is, the fixed-size array (`[0u8, 1, 2, 3, 4]` is typed `[u8; 5]`) is no different from ordinary values. You can write `&amp;0u8` in Rust, but `0u8` is definitely on the stack. Same for arrays. If you are not aware of the distinction between the stack and the heap, some of the following might be very confusing. Take a look at the [Pointer Basics](http://doc.rust-lang.org/nightly/book/pointers.html#pointer-basics) if so. &gt; The code references an `[T]` type (like when implementing SliceExt), but the struct is defined as Slice&lt;T&gt;, where is the sugar defined to make these the same, and how does it work? It's magic! `Slice&lt;T&gt;` is not how the magic happens, it's rather the result of the magic (i.e. it reflects the internal representation but doesn't affects it). The compiler recognizes `[T]` specially and generates an appropriate code. &gt; Also, reading about unsafe code, I read if you want to free the memory, you have to have a destructor. A type can't have a destructor if it implements Copy, as a slice does, so what happens to the allocation once your slice goes out of scope? It can be somewhat confusing. What `Drop` actually does is cleaning its contents. `Box&lt;T&gt;` will definitely deallocate the memory for `T` since the pointer to that memory *is* the contents, but if `T` is `Copy`, then it doesn't need to clean its contents. Cleaning the memory on deallocation takes time (much like the initialization), and as we cannot directly access the uninitialized memory from safe Rust code, we can safely ignore this step. (I should also note that the current `Box&lt;T&gt;` doesn't actually use `Drop`. It is another magic for now, but this magic can be hopefully removed.) &gt; And lastly, if I try and `println!("{:?}", foo)` with a *const T, it gives me a hex formatted view of the pointer location, which seems sensible enough. But when you `println!("{:?}", foo)` a slice, it gives a nice representation of your slice. Does anyone know where that is implemented in the code? Magic! Uh, no. It is actually a job of trait system: both `*const T` and `&amp;[T]` has `std::fmt::Debug` implementations, which are used by `println!` to print the contents.
It prefer teaching and using `try_borrow_mut()` which doesn't panic!, but returns `Option`.
... and "catching exceptions" happens _all over the place_ in order to run destructors.
I just wonder why ["features"](http://doc.crates.io/manifest.html) cannot be used on these crates. You could just have one `winapi` crate, and then put the kernel32 / user32 / etc code in a `#[cfg(feature="kernel32")]` module. If user wants those extra features they could put the `features = ["kernel32", ...]` in the dependencies section.
*blinks* But... I wasn't *trying* to write it in Markdown. Just because it's plain text doesn't automatically mean it's supposed to be Markdown. :P
&gt; Python seems wonderful. For me, Python was the first programming language that made it fun to program.
These things just happen. You just want to write a small text file, and before you know it, you've got Markdown. Aside: That would be a cool Dr. House episode.
I'll note that this does *not* have all the issues that Heartbleed had - specifically, it can't leak data that wasn't recently passed through the buffer, and so can't leak the encryption key or other in-process data.
Remember: Rust is memory safe. There are many kinds of bugs that don't relate to memory safety. Rust will not magically make your code free of security vulnerabilities. Let's be careful when sharing our love of Rust with others, and not suggest it does things it doesn't do. (I don't recognize any of the names in the HN thread, except kibwen, who didn't say anything of the sort. This is more of a pre-emptive kind of comment.)
Absolutely, I agree. It's just a nice reminder that Rust doesn't necessarily mean secure code, although some might think it does due to lack of knowledge of what things can lead to security issues. It simply means secure-r code - certain classes of vulnerability are impossible.
Also, potentially things like personally identifying information, possibly tied to things like partial medical records, depending on the system and its use.
&gt; On top of that, the program the author provides is doing some funky stuff. To be fair, the OpenSSL code was also doing some pretty funky stuff. I think that is somewhat the authors point, so long as us mortals are writing code, someone somewhere is going to write some funky stuff. To catch these issues requires discipline and constant vigilance. A well designed language isn't going to stop someone from, for example, making a sql injection vulnerability.
I did what the documentation recommended that I do. http://doc.crates.io/build-script.html#*-sys-packages
Yeah, exactly. Though from what I understand OpenSSL did match the spec, the spec was just crazy. This one doesn't match, as it doesn't handle the length according to the description. &gt; A well designed language isn't going to stop someone from, for example, making a sql injection vulnerability. Definitely not. However, with a good type system and some smart coding it is possible to enforce input sanitization in a codebase.
Depends, a well designed library might not allow un-clean user input to be used directly in queries, which could be enforced in many ways.
Someone did this some days ago, there's a thread. I can't find it because I'm on a phone, but the basic idea is having the list represented as a Vec, and each node having the index for the previous and next elements. 
Yes, I agree. But the argument is about compilation speed and not optimisation. The question is "what optimisations can rustc do that would result in faster compilation time than if left to LLVM?"
This should be obvious for anyone that has more than one working brain cell. Propably Heartbleed could be prevented but, i. e. ShellShock was not problem with buffer overflow or anything memory related but with logic part, so even the best programming language could not read programmer mind. It is brainless tool that do things only as written and everything what was written (in order what that was written). So even hypothetical language Ź could not prevent Poodle or ShellShock as that are logic bugs, not memory related.
Looking at the IR, there appears to be quite a bit of superfluous code (though my LLVM skills are a bit rusty, I must admit), so I'd guess that the rust compiler could get faster by a good amount. However, let's just wait until 1.0 hits, and then let the compiler optimizers descend on it. :-)
Yes. The [docs](https://bluss.github.io/ixlist/target/doc/ixlist/struct.List.html) and [Reddit discussions](https://www.reddit.com/r/rust/comments/2u53le/this_is_a_doubly_linked_list_in_safe_rust/).
&gt; To be fair, the OpenSSL code was also doing some pretty funky stuff. I think that is somewhat the authors point, so long as us mortals are writing code, someone somewhere is going to write some funky stuff. But the author complains about people not being specific, and he specifically tries to show that the *Heartbleed* bug can be written in Rust. So if someone shows that the Heartbleed bug - *specifically* the Heartbleed bug - *can't* be written in Rust, then let's not move the goal post to logic bugs in general and *funky stuff*. I haven't seen any indication that anyone has claimed that *security bugs* in general can not be written in Rust.
By not accepting a string for the query. (I'm sure you could do something to get around it, still.)
Oh nice, thank you.
While I agree that Rust can’t prevent logic errors. The heatbleed version of Rust would look more like this: http://is.gd/SBV3dd After all, the real size of the buffer was known and also passed to the leaking function. Rust might not have prevented heartbleed but it would have required a mistake at two different places in the code.
Thanks. Not as satisfying as I was hoping, but it is a useful design pattern.
https://github.com/sfackler/rust-postgres-macros#sql
You could definitely make a syntax extension which does it (basically, a plugin for the compiler that implements a macro, rather than using Rust's macro meta-language).
I've seen that. It validates a SQL string, but that is somewhat different from a macro that rejects strings all together. In my example, you would get past it simply by saying let mistake = format!("SELECT * FROM Users WHERE id={}", userId); sql!(mistake); or am I missing something?
AFAIK, the macro only accepts a string literal (like `format!` itself), so your example would not work. Otherwise it would not be possible to parse it deterministically.
&gt; You should note that Rust does not allow unintialized value by design and thus it does prevent heartbleed from happening. Well, suppose the openssl maintainers don't trust the malloc used in Rust and thus creates a custom malloc that doesn't zero the buffers... That should be the comparison here, when creating your own allocator, would rust still prevent this error?
You mean with the Cursor? Yeah I just didn't bother yet. :)
This guy can make it work! Nice.
It's possible. I had a proposal to make direct SQL access `unsafe` (it's a misuse of the unsafe keyword, though), and only expose macros that enforce that the first argument is a string literal (and do string substitution similar to how PDO and friends do it). This is easy enough to do.
So a side-effect to `try_unwrap` is that it decrements the reference count, right?
Since they re-used the buffer for heartbeat, in theory they could keep using that buffer for other data too. There is no reason to; at that point you've replaced the memory manager with a poor pool manager with a pool size of one. It's a terrible idea, but not far off from the equally terrible implementation that lead to heartbleed.
&gt; OpenSSL custom malloc that does not zeroes the buffer when allocating it. Normal ``malloc()`` doesn’t do that either nor should it. &gt; You should note that Rust does not allow unintialized value by design and thus it does prevent heartbleed from happening. The Heartbleed issue resulted from *reuse* of chunks of memory. These would leak information irrespective of their being properly initialized. I doubt that it’s impossible to implement the same kind of free list in Rust (or Java for that matter). Forcing an entire chunk of the free list to be zeroed out completely before reusing it will lead to serious performance degradations, and, face it, would be plain redundant (C programmer talking ;-)) with the proper length checks in place. Btw. dependent types might have been the right tool: I imagine the compiler could require a proof that all data access to the buffer holding the heartbeat payload be bounded by the memory region that is reserved for the corresponding TLS packet. 
&gt;even Haskell if I were smart enough to understand burritos my sides
~~~It was a buffer over-read vulnerability so the out-of-bounds checking would also catch it.~~~ ~~~Edit: actually not, because the problem was that too big buffers were allocated that still contained data from previous allocations, still not being able to access uninitialized memory would prevent heartbleed.~~~ Edit2: the bug is actually that memcpy reads from a too small buffer, so it would actually be caught by out-of-bounds checking We have basically 2 buffers, let's call them `source` and `target`. `source` will have the actual size of the packet data and target will have the user defined size, which I'm going to call `user_size`. What then happens next is a `memcpy(source, target, user_size);` that reads over the bounds of source. http://www.seancassidy.me/diagnosis-of-the-openssl-heartbleed-bug.html
The content of the post is about how it wasn't really exactly a buffer overflow issue.
Given this line of Perl: $ffi-&gt;lang('Rust'); ...and given that the Rust function is presenting a C ABI, I'm curious what Rust-specific behavior this library is presenting. It does say that it "provides native Rust types for FFI::Platypus in order to reduce cognitive load and concentrate on Rust and forget about C types.", but it doesn't expand upon what that actually entails.
Neat. Is it easy to relate this to the [Columnar](https://github.com/frankmcsherry/columnar/blob/master/src/lib.rs) code (disclosure: something I wrote)? It does something pretty similar, but it is much simpler and possibly missing the point of what you are doing. But, I'm not sure I grok the constraints on your approach. Is it roughly the same, but with the goal of supporting more than just `Push` and `Pop`? :D
For a tree, I wonder if using `into_iter` would not make the issue trivial: just consume the iterator dropping everything on the floor.
Hmmm. It might be convenient, but at some point, somebody has a work stack, right? It would depend on how into_iter implements its tree walk. If your tree had weak up-pointers, then you could avoid using a work-stack. You could iterate down to the lowest level of child nodes, find one that had no children, then move to its parent and drop the child-less child node. Then descend again, find another, repeat, until the end.
The basic idea of implementing data-structures without a clear owner in languages where a clear owner is required is generally to cheat and *introduce* an owner (here, `Vec`), possibly hiding it from the owner. I would point out, though, that this is basically just using `Vec` as a backing allocator, but without the niceties an allocator offers: fixing half the indices manually at each erasure is not particularly appealing. Not fixing them, however, would require maintaining a free-list! This can be done easily (and without memory allocation) by interleaving the free-list with the data: struct InternalNode&lt;T&gt; { Node(T), Free(u64) } And then simply program with a `store: Vec&lt;InternalNode&lt;T&gt;&gt;` instead of directly manipulating `T`. You fix the convention that: - `store[0]` is always `Free(n)` where `n` points to the next free node - `Free(0)` means there is no next free node and then you don't have to fix-up the indices every time you remove an element! *Note: while you don't have to fix-up the indices of the nodes holding up elements, you cannot take their address because that would require freezing the vector, its growth could cause invalidation of pointers*
*scold*, huh.
Sadly no, `bootstrap` is thread parallelized under the hood, so I can't have each thread push to the same vec without heavy sync overhead.
Then it sounds like you want concrete methods!
I'm not trying to sell you anything, but: The approach I took with Columnar stuff was to implement a trait `Columnar&lt;T&gt;`, which maybe you can think of as `LikeVector&lt;T&gt;` (note: not `Vec&lt;T&gt;`). The pair implementation was then just implementing `Columnar&lt;(T1,T2)&gt;` for `(C1,C2)` where `C1:Columnar&lt;T1&gt;` and `C2:Columnar&lt;T2&gt;`. Perhaps SoA could do the same thing, giving you a cheap-ish version for multiple fields (pairs of pairs of pairs ...). Rather than a `SoA3&lt;T1,T2,T3&gt;` you get something more like `(SoA&lt;T1&gt;, (SoA&lt;T2&gt;, SoA&lt;T3&gt;))`, where for me each of the `SoA&lt;T&gt;` types end up as `Vec&lt;T&gt;`. Alternately, it has been pretty easy for me to implement `Columnar&lt;MyStruct&gt;` for a `MyColumns` struct, mostly as a copy/paste (though, perhaps I think it is easy because I just have four methods, whereas the SoA implementations are much more complete). Anyhow, I totally support thinking out a good pattern for this, and doing it well. Happy to help out. :D
There's more details on the [FFI::Platypus MetaCPAN page](https://metacpan.org/pod/FFI::Platypus). I haven't used it personally, but it seems to be a framework to make loading compiled libraries easier. For example, this would allow you to use `i32` instead of whatever the C equivalent is (I always have to look that up, being a mostly high-level developer myself) when interacting with Rust libraries.
You might be able to write a macro that provides a SoaN&lt;A,B,C&gt; type with A,B,C filled in at compile time
Another difference I just noticed is that SoA only stores one set of len + cap. Columnar has one set for every column, which can potentially lead to some pretty weird bugs. Or if not bugs, just plain waste.
Lots of flaws come out in cryptography implementations, even the entire scheme sometimes. You can still use AES without integrity checks in rust. You can still implement an algorithm just plain wrong. You can still use zeros for your IVs. You can still use bad random number generators that aren't crypto safe. Memory safety is great, it really is, but people will always find a way to fuck up, myself included.
At some point you need to make an sql query string from it.
[Obligatory xkcd](http://xkcd.com/353/).
[Image](http://imgs.xkcd.com/comics/python.png) **Title:** Python **Title-text:** I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/353#Explanation) **Stats:** This comic has been referenced 110 times, representing 0.2186% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_co96r5g)
By default Rust doesn't allow uninitialized data. To screw up you have to use an `unsafe` block and explicitly fake initialization: let data = unsafe { intrinsics::init() } So if OpenSSL devs *really* wanted to shoot themselves in the foot, they could. I'm not sure if it would be possible to implement a generic custom allocator willy-nilly recycling memory within Rust's rules of safe memory ownership. You'd probably have to void the warranty by using `unsafe` code. 
As it turns out, non-prime fields are perfectly fine. It does not have to be a prime field. The Lagrange polynomial of every share always evaluates to a non-zero value at x=0. So, the secret that you decode always depends on every one of the K shares in a way that you can pick and modify an arbitrary share to get *any* secret back. The number of possibilities for the secret does not change with K-1 shares.
That seems to be a syntax error: src/html.rs:2:17: 2:20 error: expected `;`, found `...` src/html.rs:2 use super::dom::...; Or do you mean to import individual names from `dom`, e.g.: use super::dom::{Node,element,...} Either way it does not seem to work. My Rust version is: rustc 1.0.0-nightly (1d00c545e 2015-01-30 19:56:34 +0000) Is that syntax explained somewhere in the docs? I looked, but have not found it.
Is the opposite possible? I.e. having vector of structs, create a wrapper that would give me API of struct of vectors ? Formally it seems that we want index elements by pairs field_name, index. 
(I'm working on it, though)
Yes, I guessed that [see above], and have tried several variations, including use super::dom::*; and use super::dom::{Node,AttrMap, ...}; // see, I can do that too I also tried putting my grammar into a separate `*.rustpeg` file, with the `use` directive there. The parser generator doesn't accept that: src/html.rs:2:1: 2:41 error: Error at Line 1:17: Expected HashSet {"[ \t\u{a0}\u{feff}\u{1680}\u{180e}\u{2000}-\u{200a}\u{202f}\u{205f}\u{3000}]", "_", "*", "\r\n", "\u{2029}", "[a-z]", "//", "\u{2028}", "\n", "{", "/*", "\r", "[A-Z]"} src/html.rs:2 peg_file! parser("html_parser.rustpeg"); ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ I'm quite prepared to believe there is some little syntactic detail somewhere that I'm getting wrong, but I have no idea what it might be. That's why I asked about documentation. 
Just submitted a PR to fix the worst of that. https://github.com/rust-lang/rust/pull/21877 Note that this specific problem shouldn't appear in that many places, since it only affected code that implicitly converted &amp;T to *T pointers.
Okay, I seem to have found the solution. I now have use super::dom; in the Rust file that includes the grammar, and use super::dom::*; at the top of the grammar definition itself, and the import errors are gone. So now I can move on to debugging the grammar ;-)
Well, the opposite is `Vec&lt;(A, B)&gt;` which has been always kicking around. If you want to project `Vec&lt;(A, B)&gt;` into an iterator of `A` or `B`, use `map`.
I'm sympathetic to your point in principle. Indeed, I spent quite a lot of my time on my project-before rust ([monotone](http://monotone.ca)) trying to break the previous over-centralized control free software project administrators had by virtue of the write-bit on CVS repositories; and on my most-recent project after rust ([stxt](http://github.com/graydon/stxt)) trying to break the current over-centralized control IM and social network services have on their users by virtue of transport hubs. But I think these efforts, while enjoyable to hack on and useful in certain extreme cases, do not reflect the main power imbalances we have online presently. In my experience of 2015's internet we have more of a problem of highly distributed harassment and abuse than we have a problem of centralization of control (though I do lament US-EAST-1 every time I consider it). I think even _with_ the centralized services we use, it's still pretty simple to make more communities, more sites, more subreddits, more forks, clones, mirrors, forums and groups, and more sockpuppet accounts; massively easier than it used to be. Whereas it's still more or less a matter of luck whether someone stops attacking you when asked; indeed the mere concept of "asking to stop" is a sort of quaint anachronism when considering the actual harassment campaigns people are subject to these days. As hdet pointed out (and I sadly agree with): we really don't have _any_ effective means to prevent a dedicated attacker from destroying a person or a community online. I'll grant this is a hard-to-measure and possibly subjective view of things, but I do not believe EFF represents an honest broker in this discussion; they have a (valid) political agenda to prevent blunt new laws with high risk of abuse _themselves_ being enacted. I can sympathize there too: most such laws, as they say, _aren't enforced_, and get misused. It's hard to say anything positive about the utility of an unenforced law. And I'm not a fan of starting with the legal system, in any case. You might need to end there -- I mean, what else do you really do with a bomb threat? -- but most of the time, problematic behaviour doesn't escalate anywhere near that far, especially if you nip it in the bud with a little early, well-meaning but firm feedback. I _am_ a fan of starting with such feedback, and making clearly-articulated community norms about behaviour that merits it. I think you can usually de-escalate most problematic behaviour by either clear, respectful feedback about boundaries, or at most an agreement to part ways. Occasionally someone will escalate still further into an all-out structural attack, but most people mean well and are surprised and unsettled to learn they've honestly hurt someone on the other end of the wire, or are acting in a way that's souring the community. I think the longer you let such problems grow, the harder they are to change: the boundary you want to enforce is too far in the distance, the community's norms have shifted too far to accommodating a high level of casual sniping and flaming. I should also point out in passing that I'm absolutely a strong supporter of _dissent_. You're blurring the concept of dissent and abuse here, which is rhetorically tempting but imo a bit unfair. I realize these are subjective categories, but if you blur your eyes enough, _all_ categories of discourse become subjective and impossible to differentiate. I think it's well worth taking the time to think about and delineate the distinction, in an objective-as-possible fashion -- which CoCs are actually _helpful_ for -- and see if your resulting guidelines have space for a meaningful form of dissent. We had and have plenty of dissenting voices on the rust project (including strcat's); the dissent itself really wasn't the problem. We've overhauled virtually every facet of the language many many times, often due to dissenting voices. We even incorporated a majority of strcat's input, albeit slowly and circuitously. He just too-often provided it in a way that was over the line, behaviourally. And even then, he left not because someone asked, but because of his own frustration with the slow and circuitous response to his dissent, his sense that there was a political agenda against him. Finally, returning to the matter of harassment -- which is really quite a ways past anything that happened here -- I should point out that you're being very selective with your reading of the linked EFF page. If you read to the end, including their "Starting Points for Good Solutions" section, you'll see their _first_ suggestion is "Law Enforcement and Laws" and their _second_ is "Empower Users, Really" (to block abuse and moderate our own communities effectively). Even EFF, free-speech champion, feels that this is a nuanced topic requiring a mixture of technical and social responses, not a "just add more speech" free-for-all. (I find it darkly amusing that adjacent to the save and cancel buttons beneath this textarea, there's a link to 'reddiquette', which is much more detailed than the Rust CoC, but of course includes no consequences.)
https://gist.github.com/bwo/13965d418c552dbd2303 far from perfect!
Please don't take this personally, but SoA reimplements something Vec-like instead, which may have its own bugs in critical code.
You're right! It may have bugs. However, if you're worried about unsafe code, I recommend against using the rust hashtable, or even vec. They both use quite a bit. :)
Wow. That's a lot farther than I got! Thanks!
Did you use any glob imports in the problematic version? They are buggy in some situations with submodules (yes, really). So when nothing else can explain it, that might have been it.
Everything is a trade-off. SHA1 is short enough to be used as a file name, and the design of Git's object store hinges on that. There would have to be a big payoff for disrupting that design.
That sounds rather fragile for very little run time benefit. E.g. that API gives you a 10 item list TODAY when you pass parameter n=10 but isn't it better to be able to handle whatever you're given?
That's totally fair. :) The upside (other than me being scared of unsafe code I write (yours is fine; as you say, I use that code a lot ;)) is that you get a bunch of implementations on the cheap (pairs of `Columnar` things implementing `Columnar` for pairs of things). You get to avoid worrying about a four/five element implementation, and just pair up some things. Ignoring for the moment questions of efficiency and possible other error sources (I have a shameful `unwrap`, I know), does it make any sense to define (or talk about) a `Vector&lt;T&gt;` interface with the relevant vector-oriented methods? I know for columnar stuffs, most of the methods are pretty cheap, with random access being a bit of a pain for variably sized elements (e.g. `Option&lt;T&gt;` or `Vec&lt;T&gt;` elements). But coding against `V:Vector&lt;T&gt;` rather than `Vec&lt;T&gt;` would be great, no?
I'm totally stymied on `zip_iter` implementation. It looks like macros just aren't allowed anywhere that they could go, for some reason. (Actually it looks like it's possible if I can CPS the macros properly but I'm a little too tired to pursue it right now.)
&gt; Are you saying that, when I call an API, I should plan for it to stop supporting some of the things it provides? In your particular example, this would mean that I can pass in the number of things I want, but I shouldn't, because in the future it might no longer have that parameter? No, I'm saying you shouldn't TRUST it. Resilient code is better than fragile code. Fixed sized arrays are EVIL. They have caused any number of remote exploits. How much do you REALLY trust all the code you call?
If I'm understanding correctly, you're advocating a "validate everything everywhere" approach. Is that right? It sounds very security-oriented, which is not a way I'm used to thinking. I agree though, I want my code to semantically express what I expect to happen, and not just have my assumptions embedded in comments. But, if possible, I want the compiler to guarantee it rather than having to add asserts or anything else that only works at runtime.
then test it :) the unsafe code for a library like this isolated. What should be scary is when unsafe has to leak out.
I'd like to piggy back on this question to ask you, where is memory allocated when I call new on a struct? E.g, `let x = Vec&lt;u8&gt;::new();` Is `x` on the stack or the heap? Or is `x` on the stack but it's contents (in this case the contents of the `Vec`) on the heap? I am confused about this aspect of Rust. Edit: also, if I do `let y = MyStruct{number: 45};` is y on the stack or heap? What about `number`?
`x` is on the stack (takes three words, a pointer, a size and capacity) and its contents pointed by the pointer lives on the heap. `y` will be entirely on the stack, including `number`. Simply put, *everything in the variable is on the stack*, but it can have a pointer (safely wrapped in most cases) to the heap memory.
Thanks, that clarified it for me. :)
We're still on the 1.0-alpha. For now the language is still changing breaking occasionally. We will enter 1.0-beta before too long, then after a few months will be the full 1.0 release.
Ah, but how about reallocating a piece of a buffer that was just filled with different data and released? Or not actually freeing a buffer, [but putting it on a freelist for a while](http://www.tedunangst.com/flak/post/analysis-of-openssl-freelist-reuse)? The point is that for the heartbleed bug to work you have to go out of your way to do it wrong, even in C. And you can't prevent that in Rust either. Heartbleed was a mix of carelessness and very bad design. No compiler will help against that.
http://blog.rust-lang.org/2015/01/09/Rust-1.0-alpha.html
Yeah, it's kind of a pain at times. I *suspect* the reason behind it is that `a[i]` gets rewritten as `*a.index(i)` (or `*a.index_mut(i)`, depending on whether it needs a mutable borrow or not). It has to do that, otherwise you'd never be able to index collections of affine types (*e.g.* `Vec&lt;String&gt;`). Making it so that `Vec&lt;T&gt;` implements `Index&lt;Output=&amp;T&gt;` instead has the issue that *now* you have to manually de-reference the result of all indexing operations... except on built-in arrays. So they'd probably have to be changed for consistency. Yuck. **edit**: this is wrong: ~~The compiler can't do it automatically because there's (currently) no way for the type system to express "`Output` must be `Deref`-able", without bringing in *spooky compiler magic*.~~ I further suspect that this wouldn't be an issue if Rust had Higher Kinded Types, so that we *could* express this idea in the trait itself. At this point, I think changing from the status quo would break so much code that it'd never get accepted. We might just have to wait for HKT and a hypothetical `IndexHKT` trait to get wired in. Hopefully that'll happen around the same time `IteratorHKT` happens as well. :P
Maybe this is totally n00by, but couldn't the `Index` trait just specify a `Deref` trait bound on `Output`?
That would not help. If you would change the return type to `Output` you would not be able to return mutable references using save code. This is a [problem](http://stackoverflow.com/questions/25730586/returning-mutable-references-from-an-iterator) `Iterator` has at the moment, you can’t return mutable references into the collection using save code.
**edit**: Wrong. ~~Nope.~~ ~~Not yet, anyway.~~
`try_borrow_mut` was actually [just deprecated](https://github.com/rust-lang/rust/pull/21854)
**edit**: Also wrong. ~~The usual reason for these sorts of things: because it hasn't been fully specced/implemented.~~
Do you think an API like this could be possible? struct Vector2{ x:f32, y:f32 } make_soa!(Vector2); // creates Vector2SoA let v_soa = Vector2SoA::new(); v_soa.push(Vector2{1.0f32,2.0}); assert_eq(v_soa.pop(), Vector2{1.0f32,2.0}); Okay I guess not because there is no type information for macros but maybe make_soa!( struct Vector2{ x:f32, y:f32 } ); // creates Vector2SoA and Vector2 
Ok, I actually thought trait bounds on associated types was implemented?
The reason the `Index` traits return references is the same as the reason why the `Deref` traits return references: Both operators semantically return an lvalue in `Self`, which requires some kind of pointer behind the scenes. If the traits returned an value, then those operators would instead have to be defined as returning rvalues, which would be less useful. // With lvalues // let x = &amp;foo[0]; // creates reference to first element // let y = &amp;*bar; // creates reference into bar // With rvalues // let x = &amp;foo[0]; // creates reference to a stack copy of the first element of foo // let y = &amp;*bar; // creates reference to a stack copy of the dereference of bar
As I understand it, function overloading isn't supported and will not be supported because of the way type inference works in Rust. Where C++ selects the function based on the type of its arguments, Rust will often select the type of the argument based on the function (!). There is one way to get around it, and that is to have different traits define methods with the same name, in which case the decision can become part of the type inference. Look up [Hindley-Milner type inference](http://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system) for more information. :-)
I appear to be wrong. The following compiles and works as expected: use std::num::Int; trait Dummy { type Thing: Int; fn dummy() -&gt; &lt;Self as Dummy&gt;::Thing; } struct Blom; impl Dummy for Blom { type Thing = i32; fn dummy() -&gt; i32 { 42 } } // Does not compile: /* struct Flang; impl Dummy for Flang { type Thing = f32; fn dummy() -&gt; f32 { 3.14159 } } */ fn main() { let x: _ = &lt;Blom as Dummy&gt;::dummy(); println!("{}", x); } 
&gt;&gt;Declarations are comparable in wordiness to C++. &gt; &gt; Rust has fantastic type inference, so this is rarely an issue. Example: inside a generic Trait implementation, how to call a trait function from another trait function: `&lt;Self as Trait&lt;T, U, V&gt;&gt;::fn_name`. In my opinion, this is wordy, and wordier than a lot of C++. If the function I want to call is declared one line above and inside the same Trait, the expectation that the user should be able to _just call it_ by name (`fn_name`) is in my opinion fair. The annotation `&lt;Self as Trait&lt;T, U, V&gt;&gt;::` is there just to help inference and the compiler. It might get better (`Self::fn_name`), but I still think that anything besides `fn_name` is wordy.
Why couldn't `Output` just be `&amp;mut T`?
True! I guess what I meant is, changing the existing traits would be less useful. Adding additional ones to allow for both usecases is probably the best solution.
it seems the Rust community considers overloading to be a misfeature in C++, they want you to be more specific with function naming. it does still dispatch on the first parameter, and there's multi parameter traits. you could put all the parameters in a tuple and impl' for that, but it would look messy. r.e. inference, I think you still can infer types with overloading, it's just it's easier to produce ambiguity? I've been experimenting myself with a language trying to infer more than c++, but still having overloading. I'm sure it has many holes - but I figured at worst you could infer forwards like C++ does, and still get some reverse information, such as return type for returned temporaries and template parameters working better (I've demonstrated those cases working... the cases I was noticing when I went back to C++). my 'dream language' would start with overloaded free functions - plus d-style UFCS - and any notion of traits/interfaces/classes would just be sugar for grouping functions. but we are where we are.. many languages start with all that already and thats' how existing api's are designed
What would be the lifetime of `&amp;mut T`? There is (currently?) no way to connect the lifetime of &amp;self to the one of the return type. I'm not saying that it won’t work and it is also possible to provide a safe interface but you can’t write such things right now without using unsafe code to cast the lifetime appropriately.
Yes, that works. Well, you need fn overloadable&lt;T: ArgumentForOverloadableFunction&gt; (arg: T) { arg.answer(); } but you got the gist
Sounds like a good point, but (in your example) if you were to represent coordinates in different ways, like separate parameters and pairs (which arguably might not be a good idea, but I can imagine having this kind of problem working with different libraries with different representations), I don't see any benefit in having "from_cartesian_xy" and "from_cartesian_pair".
Here's how `Index` currently looks like: pub trait Index&lt;Index: ?Sized&gt; { type Output: ?Sized; fn index&lt;'a&gt;(&amp;'a self, index: &amp;Index) -&gt; &amp;'a Self::Output; } You can see that `index()`'s result lifetime is tied with `self` lifetime. This is quite natural - you need this in order to return references into collections safely. If, however, `index()` returned a value instead of a reference: pub trait Index&lt;Index: ?Sized&gt; { type Output: ?Sized; fn index&lt;'a&gt;(&amp;'a self, index: &amp;Index) -&gt; Self::Output } then suddenly the link between `self` and result lifetimes is broken - `Self::Output` doesn't refer to `'a`. This means that you just can't return references into other objects with this method because you can't name their lifetime: impl&lt;T&gt; Index&lt;usize&gt; for [T] { type Output = &amp;'??? T; fn index&lt;'a&gt;(&amp;'a self, index: &amp;Index) -&gt; &amp;'??? T } Ideally it should be possible to do something like this: pub trait Index&lt;Index: ?Sized&gt; { type Output&lt;'a&gt;: ?Sized; fn index&lt;'a&gt;(&amp;'a self, index: &amp;Index) -&gt; Self::Output&lt;'a&gt; } impl&lt;T&gt; Index&lt;usize&gt; for [T] { type Output&lt;'a&gt; = &amp;'a T; fn index&lt;'a&gt;(&amp;'a self, index: &amp;Index) -&gt; &amp;'a T { ... } } however, this is exactly what higher-kinded types are and they are not implemented in Rust (yet).
It should be solved by some way of destructing call. Like let pair: (i64, i64) = (4, 2); let point = Point::from_cartesian(..pair); or similar. Or maybe tuple should be autodestructed when do not match function argument. But I'm worried that this will be counter-intuitive.
/r/playrust
Higher-kinded lifetimes do exist. pub trait Index&lt;'a, Idx: ?Sized&gt; { type Output; fn index(&amp;'a self, index: &amp;Idx) -&gt; Self::Output; } use with bound as: T: for&lt;'a&gt; Index&lt;'a, uint&gt; which is also already implemented.
Those are higher *rank* lifetimes.
This is also nice, but definitely a step above-and-beyond allowing unvalidated user input, since something like this also helps against mistakes in the SQL itself.
Some algorithms must be written less efficiently if you must take care not to leave an object in an inconsistent state while performing potentially-throwing operations.
In addition to what others have said, even after 1.0 there will continue to be breaking changes, but only to the unstable part of the language.
Sorry that I can't currently give you an example that is totally impossible with exceptions. Maybe I'll look this up later. However I can give you one example where exceptions make problems in LLVM: with exceptions you need to use `invoke` instructions instead of `call` instructions. `invoke` instructions are terminators and have two following basic blocks. For optimizations you want your basic blocks to be as big as possible, because some of them work on a basic block level.
Couldn't that be optimized if he only uses constants? 
I personally don't understand the fuss about function overloading. It's such a superficial feature. In C++, functions with the same name but different arguments are still _different_ functions. It's really no different than having functions with different names. "Hey man, does Rust have function overloading?". "No". "Oh, okay". That's how I imagine a conversation about function overloading should go.
I think the core team wants to stress the fact that the `internals` forum is not for general discussion, so they do not want `discuss` to redirect. Also having two forums named `discuss/internals` and `forum/talk` respectively will confuse people. "What's the difference between `discuss` and `forum/talk`?" But yes, having broken links is not a good thing either. :( 
Yeah, I see. 
Will do, when it arrives :)
Can't seem to open the full example via your url
He didn't make any argument. He asked a question and somehow asking a question is flawed and fallacious?
It is identical to the authers
I'm not a fan of reusing zip the way I'm doing right now. The type signature is far too terrifying, and I'm sure the performance sucks far more than it needs to. I might just write a custom iterator, which might make the macro significantly easier.
Good riddance!
Dude, chill out. I get what you're saying, but *tone*. There's no need to be so aggressive when someone asks a question.
That is not strictly true. If we had proper higher-level-lifetimes, it would be easy to define an `Index` trait that covers both. Only now it's impossible and Rust had to choose one.
Personally, I'd be happy with something much simpler. One thing I've seen mentioned in the past is simple struct name inferrence: pub struct SearchOpt&lt;'a&gt; { haystack: &amp;a str, needle: &amp;a str, } // destructures, but doesn't have to pub fn search(opt: SearchOpt { haystack: h, needle: s }) -&gt; usize { unimplemented!() } search(_ { haystack: "foo bar baz", needle: "bar" }); Of course the `_ { ... }` is just an example and might not be syntactically sane. I feel something simple like this has a couple advantages: * The inferrence is useful everywhere, not only in function calls. * It takes away the annoyance from having to fully name the extra struct containing the named parameters. * It keeps a very consistent API. * It is still explicit in what it does. * It's visually and conceptually compatible with having multiple option struct types and being generic over them (a way to do overloading, also more in a more explicit variant, since you now have to specify your struct type). * Default parameters work like everywhere else. * It's easy to pass groups of parameters around. Works just like everrywhere else. * I can easily write functions that transform my data into specific named arguments. * I can reuse groups of named arguments. What I like most about the above is that everything besides the inferrence already works :) I'm already using structs as named argument groups quite successfully in my experiments. Inferrence would just lower the amount of motivation required to not just add a bunch of sequential parameters. Again, not really my idea, but I'm unsure where I've read it first.
I think I like your alternative solution better: enum ObjectConstruct { Default, WithDims(u32, u32), WithDimsAndPos(u32, u32, u32, u32) } #[derive(Default, Show)] struct Object { name: String, width: u32, height: u32, x: u32, y: u32, } impl Object { fn new(name: &amp;str, options: ObjectConstruct) -&gt; Object { match options { ObjectConstruct::Default =&gt; Object { name: name.to_string(), ..Default::default() }, ObjectConstruct::WithDims(w, h) =&gt; Object { name: name.to_string(), width: w, height: w, ..Default::default() }, ObjectConstruct::WithDimsAndPos(w, h, x, y) =&gt; Object { name: name.to_string(), width: w, height: w, x: x, y: x } } } } fn main() { let test: Object = Object::new("Object Name", ObjectConstruct::Default); let test2: Object = Object::new("Object Name", ObjectConstruct::WithDims(100, 100)); let test3: Object = Object::new("Object Name", ObjectConstruct::WithDimsAndPos(100, 100, 50, 50)); println!("{:?}", test); println!("{:?}", test2); println!("{:?}", test3); }
OCaml retrofitted keyword arguments and ended up with two kinds of modules in their standard library: [one that uses keyword arguments](http://caml.inria.fr/pub/docs/manual-ocaml/libref/UnixLabels.html) and [one that doesn't](http://caml.inria.fr/pub/docs/manual-ocaml/libref/Unix.html). Every library, likewise, needs to decide whether they want to use keywords or not. It's annoying to switch between those styles, and work around inconsistencies. It's true that keywords aren't always the best option, but if you need to do something special to have keywords, in practice, many libraries won't bother offering them. But when you define a function, it naturally has keywords (the name of each parameter). It would be better if Rust had the notion that those names are part of the API. That way, every function can be called normally, without keyword arguments; but, optionally, the user can supply a keyword. That would perhaps be surprising for users (in C or C++ or Java or basically any language you can change the name of a function parameter without changing its signature), and seems like a too big change. But it's the cleanest way to add keyword arguments: it would be supported uniformly in every Rust code, and it's up to the user to use one way or another. I actually am not sure how badly this would impact type inference, specially regarding closures. I would like to know if there's a language with interchangeable keyword and optional arguments like this.
&gt; Why doesn't Rust have function overloading? "Why not" is a bad way to design a language. The question is always "why do we *need* this extra bit of complexity in the language?". As others have pointed out, traits already provide a more principled form of overloading.
I have no idea how you went from "share some common roots" to "trivial". All UNIXes share some common roots. And please let's stop labeling things as "trivial", it's just an arrogant way of saying "easy" that discourages beginners.
The issue is whether being rude and condescending is an appropriate means of communication towards a beginner asking a question about Rust, likely someone who might be coming from a background in C++, Java, or C# where function overloading is common. About being nice and pretty, your post would have been shorter and more to the point if you left out the sentence "Your argument is flawed and fallacious" despite the fact that no argument was made and there is no known fallacy that one can apply to the question being asked. In other words, either you did have time and you just chose to spend that time by talking down to someone who was genuinely curious, or you are just naturally condescending towards other people and the first thing that comes to your mind when someone asks a question is to find a way to put that person down. If you are someone who is naturally condescending, then note that there is no need to reply. Let someone else reply to this question in a helpful and productive manner so that you can spend your valuable time on other matters.
I could see some issues with that: * Implementations of trait methods would have to mirror the parameter names from the trait. * You can't prefix a variable with `_` to silence unused warnings. * The big one: Parameters are patterns. What would this do to `fn foo((x, y): (i32, i32))`? * I'm also not sure how this will impact closures.
&gt; I'm sorry that I offended you with my harsh tone The mother of all non-apologies
If you can't distinguish between being nice as a community norm and some 1984 dystopia, then you might want to leave now. It's funny that you say "We are adults"... This idea that treating people with respect is a slippery slope to a nightmare future is about the most childish shit I've ever seen in the open source world, and it needs to end.
You could give a proper apology for becoming hot-headed yourself, instead of blaming everyone else for being "sensitive".
Oh man. Please don't give me _another_ choice to make when designing a library.
Getting closer to an actual apology. &gt; I felt offended that the OP was unable to just search for previous posts It's funny because you were just framing "getting offended" as something that only those unreasonable thin-skinned childish people do. I think focusing on who's "offending" whom is usually a distraction from finding a satisfactory outcome for everyone, which will [depend on context](http://en.wikipedia.org/wiki/Coase_theorem). &gt; I have a harsh tone, and I know that. And maybe these incidents will help you adjust your tone, at least for the purposes of interacting with this community. Our norms are very clear, and the downvotes you're receiving indicate that your harsh tone is not welcome here. The fact that being abrasive is the norm in some other open source communities is really irrelevant here. We are doing things differently, we have been quite clear about that from the beginning, and it's *your* job to adapt if you want to stick around.
Rust could allow arity overloading, though, which traits don't. I'd be interested to see whether the proposal for variadic generics covers most of the practical usecases where that makes sense.
Sorry. I'm done.
&gt; I never encountered any issue tracking system which has "easy" and "hard" tickets. Rust's, for example. I've never actually seen "trivial" as a tag. However it's not a big deal and I was kind of harsh on you. Sorry about that.
&gt; There was bigtime drama after strcat stopped maintaining his Arch packages. thanks for not beating around the bush. yup, this it was :)
On the whole I actually judge this one as a cute hack and no more. The reason is that Rust supports "genericized borrowing", i.e. you can borrow with anything you return. When you extract an iterator, you borrow the slice and the iterator carries a lifetime marker, and the iterator value behaves just like a borrowed pointer w.r.t borrowing. Slicing is forced to only work with the dynamic size types, most notably the built in `&amp;str` and `&amp;[T]` types. We can't really recreate this in a library, we can make structs that use "genericized borrowing" but we can't make and use them with the slicing syntax, unfortunately. I would like this to work: impl Index&lt;Range&lt;uint&gt;&gt; for MyContainer { fn index&lt;'a&gt;(&amp;'a self, index: &amp;Range&lt;uint&gt;) -&gt; MyContainerSlice&lt;'a&gt; }
No hard feelings
I think it's more or less the same, text-wise. Here you need to stuff all the function variants into the `match` arms, there you divide them into trait `impl`s. But the trait version gives you static dispatch.
I don't really know if higher kinded lifetimes is even a thing. Your example looks like higher kinded types to me. Although frankly, I think a more appropriate term is higher kinded *polymorphism*. Rust has higher kinded types (i.e., type constructors), but you can't write code that is polymorphic over those types. But even this has its issues, because a "polymorphic type" could be considered higher rank! Blech. This SO post looks pretty good: http://stackoverflow.com/questions/6246719/what-is-a-higher-kinded-type-in-scala Here's some info on higher rank types: https://wiki.haskell.org/Rank-N_types TL;DR - The terminology is pretty confusing, but I've never heard of "higher kinded lifetimes."
Pretty cool changes all around. The only thing that has me slightly worried is the addition of new coercion rules. Of course it makes things more ergonomic, but I am afraid it detracts from strictness and clarity. Can anyone tell me why I shouldn't fret? 
A somewhat unrelated note, i'm an happy user of rust on DragonFlyBSD (probably one of the two :D), and as an user, i'm really pleased by the way the rust team has reacted to mneuman's patchs to support this platform, without questioning the usefulness of merging such code in the rust repo. Not all languages are treating obscure systems like DragonFly in such a way, and it's nice to see that happenning so quickly. I'd like to thank mneuman for doing the work obviously but also the rust team for the quick merge.
Indeed. The touch-up on removal I understand, however I still have to understand how you manage to find a slot in the vector when it comes to inserting.
We know, and we are looking for ways to improve it. Any complains and suggestions are welcome, just provide more details please.
The vector is kept dense by removing only from the end (which may require swapping a node). Then all new nodes are just the next in line.
Ah, thus why it only seemed to pop/push. And since this is a doubly-linked lists, you have the indices of the elements that need a fix-up. Clever.
As mentioned by [heinrich5991](http://www.reddit.com/r/rust/comments/2umad5/the_output_of_the_index_trait_should_be_a_value/co9vks7) this is due to the absence of Higher Kinded Types/Higher Level lifetimes. You would ideally want something like: impl IndexMut for ... { type Output&lt;'a&gt; = &amp;'a mut T; fn index&lt;'a&gt;(&amp;'a mut self) -&gt; Output&lt;a'&gt; { } } However this is currently impossible due to limitations in the type system. HKT are really, really, a must have for generic code; but I do not envy those who are going to implement them, it sounds a tough challenge.
That's a tougher issue than it looks: - the constant is in the caller context - the optimization need to occur in the callee code Today, for the optimizer to propagate the constant, you need *inlining*. However, if the function is too big, then it will not get inlined by default, and forcing it to get inlined might yield worse performance. You can work around this by adding an inline "trampoline" function whose sole role is to dispatch the call and be optimized away: enum Arguments { Default, OneArg(i32), TwoArgs(i32, i32), } use Arguments::{Default, OneArg, TwoArgs}; #[always_inline] fn overloadable(arg: Arguments) { match arg { Default =&gt; overloadable_default(), Arg(x) =&gt; overloadable_onearg(x), TwoArgs(x, y) =&gt; overloadable_twoargs(x, y), } } and of course you will then have to implement the various `overloadable_*` functions, and you can (and probably should) just let the compiler decide whether to inline them or not. Oh, and for the case where the argument is not "constant", then suddenly inlining `overloadable` might yield worse performance... going with traits is probably better.
I think it's beautiful. I [took rustc's graph](https://github.com/bluss/petulant-avenger-graphlibrary) which uses this kind of linked list for the edge lists (and each edge is a member of two lists, source and target node's, so it's even more appropriate to use a linked list). I implemented remove node/remove edge with that graph structure first in the naive way -- removing from the vector and updating all indices in the whole graph. Then I realized I could use the backlinks to do this instead; first I felt dumb and then I felt better.
&gt; overloading to be a misfeature in C++ Actually, I think the answer is more "YAGNI": there are other ways. &gt; It seems that perfection is attained not when there is nothing more to add, but when there is nothing more to remove. &gt; &gt; -- Antoine de Saint-Exupery Overloading as in C++ is ultimately syntactic sugar in Rust (because traits offer principled generic programming, instead of C++'s duck typing which requires overloading of free-functions). A language with too much sugar cannot be digested, a language with too little sugar leaves a bitter taste in the mouth, ... I don't envy the balancing act when everyone's pet feature is pushing at the gate.
I agree; it's also probably among the most compact/cache-efficient doubly-linked list implementation available. A really elegant solution. The most amusing, for me, is that in C++ it would be widely unsafe because `list` guarantees a node-based structure and people expect to be able to keep references to the arguments so switching to such a design would break everything (silently, of course) whereas in Rust the type system guarantees the absence of aliasing during the touch-ups, so you're golden.
I meant something like this (not sure if this is what you want): trait ArgumentForOverloadableFunction { fn answer(&amp;self) -&gt; i32; } struct Default; struct OneArg {arg1: i32} struct TwoArgs {arg1: i32, arg2: i32} impl ArgumentForOverloadableFunction for Default { fn answer(&amp;self) -&gt; i32 { 0 } } impl ArgumentForOverloadableFunction for OneArg { fn answer(&amp;self) -&gt; i32 { self.arg1 } } impl ArgumentForOverloadableFunction for TwoArgs { fn answer(&amp;self) -&gt; i32 { self.arg1 + self.arg2 } } fn overloadable&lt;T: ArgumentForOverloadableFunction&gt; (arg: T) -&gt; i32 { arg.answer() } fn main() { println!("{}", overloadable(Default)); println!("{}", overloadable(OneArg {arg1: 1} )); println!("{}", overloadable(TwoArgs {arg1: 1, arg2: 2} )); }
[Rendered.](https://github.com/iopq/rfcs/blob/keyword-arguments/active/0000-keyword-arguments.md)
See ToSocketAddr and that it's implemented for (&amp;str, u16).
Thanks :) 
I wasn’t able to read the comment, but I try to give people the benefit of the doubt. “I’m sorry that I offended you” sounds like an earnest apology to me. “I’m sorry that you were offended” is definitely a non-apology because it attempts to shift the blame.
There is indeed a bin section somewhere in here. I've used it, though not recently.
Python has interchangeable keyword and optional arguments. For every arg, you have the option of specify it either via keyword or via positional parameter. Positional parameters are unpacked first, then keyword parameters, then defaults, then any remaining position and keyword arguments are assigned to \*args and \*\*kwargs. It works well in Python's domain, which is dynamically-typed scripting. It gets really messy when refactoring larger programs, since whenever you change the name of a parameter, you can't be sure that some caller hasn't used that name as a keyword argument. It also appears to play havoc with type inference. I did some experiments about 5+ years ago on coming up with an inference algorithm that works with interchangeable keyword &amp; positional arguments, and it failed miserably. The problem is that you get a combinatorial explosion in possible type signatures for the function: for each argument, it may be either positional or keyword, it has a type, or it may not even be supplied if there is a default or a *rest param. Checking whether a call-site is compatible with the function's definition quickly becomes impractical.
&gt; peak memory.
But IIUC that is an optimization that the programmer has to write, not the compiler (is an algorithmic optimization).
Indeed, [that is what the current deprecation notice looks like](http://doc.rust-lang.org/nightly/std/slice/trait.SliceExt.html#tymethod.slice_from). I guess someone reworded that?
Move a complex bound into `where` clause: `impl&lt;S: ...&gt; Hash&lt;S&gt; for Silly&lt;...&gt; where (&amp;[A], &amp;[B]): Hash&lt;S&gt; { ... }`.
Thanks, the autocorrect on my phone is horrible. 
I don't think this is a good point. Every time you end up doing that to live without overloading you're moving semantic meaning from a statically checked function-type pair to a name to maintain manually. In this case, I think C++ wins out in safety and clarity, because this: struct Point { explicit Point(const Cartesian&amp; coord); explicit Point(const Polar&amp; coord); } in the case where you change your mind about what the coord you send in is, will automatically accomodate the new type or give a compile error. Not so much with your Rust example, which just silently accepts garbage unless you go and change all names manually. Of course in Rust you can have Cartesian and Polar as well, but still changing types means going around and renaming callers, which isn't really optimal to me. 
&gt; why can't I treat it as I do plain old `A`? I don't know if there's a hard parsing reason for it, but consider the following: * `struct Foo&lt;A: Copy&gt; ..` -- introduces generic parameter `A` which must be `Copy`. * `struct Foo&lt;(A,): Copy&gt; ..` -- doesn't introduce a generic parameter, in fact the struct isn't generic *at all*. **Edit**: Note that, as you've seen, that second example isn't valid code. I'm trying to give hypothetical examples that show how this idea doesn't work or is very misleading/confusing. Also, consider this: * `trait Blah&lt;T&gt; { fn spaz(&amp;self) where T: Clone; }` -- trait is object safe, can be used for dynamic dispatch. `spaz` is not generic. * `trait Blah&lt;T&gt; { fn spaz&lt;T: Clone&gt;(&amp;self); }` -- trait is not object safe and cannot be used for dynamic dispatch, because `spaz` is generic. Or maybe it's not. I'm not sure. Wait, is the inner `T` the same as the outer `T`? Maybe it should be... * `trait Blah&lt;T&gt; { fn spaz&lt;T: T + Clone&gt;(&amp;self); }` -- still not object safe, and now it's getting silly. One syntax introduces generic parameters and, in some cases, allows you to specify constraints inline. `where` is for expressing arbitrary constraints without introducing parameters. At least, that's my take on it.
I like the `IntoIterator` trait and how it can be used for `Iter`, `IterMut` *and* `IntoIter`. Also, don't forget to rebuild the HTML pages after merging the "fix typo" PRs. :) 
If anyone is interested in the RFCs/shepherds' communication stuff, there is a concrete proposal on discuss: http://internals.rust-lang.org/t/rfcs-status-board-etc-request-for-comments/1533
Uh, it sounds like I'm on a similar path. I actually want to write a sound type system with currying, and freely mixing keyword / non-keyword arguments, and just that, to see whether type inference is usable. I just hope to fail in a different place than you failed, so if you could share the more about your results it would be great! I've been studying some topics in type theory, also [this](http://dev.stephendiehl.com/fun/) has been invaluable to understand the implementation of HM-style inference. I think a good mark of a type inference algorithm is that they should be local: when you give me a piece of code and the types of the things it refers to, I should be able to assign it a type on the spot. So the multitude of possible types of a value should be itself type, and the task of inferring types is just to check the rules locally at each function application, lambda abstraction, etc (there should be a finite number of such rules). In places this is not possible, inference should just fail. The inferred type should be a principal type as well, in the sense that all other possible types are just special cases of the principal type.
(not related to the proposal at the OP, but just keyword arguments in general). My only issue is that if a function receives, like, three i32s and two Strings, and there's nothing more to group them (like two of those integers form a (x, y) pair, etc), then you're left with having the five parameters at an arbitrary order. This is awkward and perhaps bug-prone. I wanted keyword arguments just to, at call site, specify the name of each argument. Then it gets translated to normal positional arguments (the keywords used just to rearrange the arguments). That is, more like passing a struct, not an enum. But using a data structure to hold the possible values could work (even though there's additional boilerplate), is there a performance penalty? For example, would it inhibit passing parameters through registers?
Well, the example above is destructuring. You could also write pub fn search(opt: SearchOpt) -&gt; usize { // access opt.haystack and opt.needle instead unimplemented!() } An anonymous `struct` seems like a different matter, since it would seem odd to have such a thing just for parameters. The whole trick is really just the inference of the struct name where a `_` is used. And since it's just a struct, you can put it wherever you want.
&gt; Wait, is the inner T the same as the outer T? Maybe it should be... They're different, and in fact disallowed exactly because it is confusing and almost never intended. &lt;anon&gt;:1:17: 1:41 error: type parameter `T` shadows another type parameter of the same name [E0194] &lt;anon&gt;:1 trait Blah&lt;T&gt; { fn spaz&lt;T: Clone&gt;(&amp;self); } ^~~~~~~~~~~~~~~~~~~~~~~~ &gt; trait Blah&lt;T&gt; { fn spaz&lt;T: T + Clone&gt;(&amp;self); } -- still not object safe, and now it's getting silly. NB. this doesn't compile: you can't use generic type parameters as trait bounds (atm).
I know; I was pulling up hypothetical examples of trying to shove constraints into the generic parameter syntax to demonstrate why it's not a good idea. Clearly, my defensive edit was insufficiently defensive.
Chrome on Windows and in Android and all I see is the title and the logo. Page ends then without any context. 
Yes. I've been meaning to file a bug against sliderust...
Yes, arrow keys work. This is using /u/kmc_mozilla's sliderust, which works in Servo.
I'm not saying there shouldn't be. I just find the above strategy useful without them. And I can see uses for anonymous structs outside of a parameter context. That's why I feel they are separate issues.
&gt; Hopefully we can mitigate that with some CSS. You mean, kinda like Discourse minimizes quotes, but can expand them to full length? I guess it could work; problem is that most people (myself included) won't read them until there is a problem or they need to buff up on some aspect of a language.
Use left and right arrow keys to navigate. See elsewhere in this thread for why.
Did you try hitting the arrow keys (to the right)?
Namespacing: no plans. Hyphens: there is a pre-RFC: http://internals.rust-lang.org/t/pre-rfc-resolve-support-for-hyphens-in-crate-names/1459
&gt; Goal: get some Rust into Firefox by the end of 2015. Wow. So, Servo isn't the only browser getting some Rust lovin' but as well as Firefox? That's pretty hawt. 
^((I'm not a programmer so feel free to ignore me.)^) After reading that article I don't understand why the two languages are in any way contrasted together. 
I understand why people use html/js for presentations, but that's totally useless on mobile devices. Pdfs on the other hand work everywhere.
I don't give the presentation from a mobile device, and I didn't really intend for people to read them without watching the video either.
I'm just shooting blindly here: because they're new? 
So why did you post it ahead of time without the video ?
&gt; Unfortunately, this video is not available... Sometimes, I hate being in Germany.
I just updated `rustc`, dropped that code into a new cargo package with `rlibc = "0.1.2"` as a dependency... and it built just fine. It warned about `entry` and `kmain` not being used, but that's to be expected. **Edit**: rustc 1.0.0-nightly (eaf4c5c78 2015-02-02 15:04:54 +0000)
Oh, my bad. Sorry about that.
I think /u/happilydoge's answer is a good one, but there's another: Go's original marketing was that it was a 'systems' language, and Rust's marketing is also that it's a 'systems' langauge. Go does not describe itself this way anymore, and http://commandcenter.blogspot.it/2012/06/less-is-exponentially-more.html is an interesting read on this topic. By the way, as not-a-programmer, what brings you to /r/rust? 
No worries. :)
Again it depends. Are we talking about variables that are all required? Then the programmer will probably give them decent names (and when they aren't needed the position will make it obvious). At this point the argument names would only repeat data. I've seen this in both python and Javascript, naming required parameters explicitly is code-smell, either I've named my variables wrong, or the API I'm using is pretty bad. The one case where I've wanted named variables was for optional variables (with default values or functions with variable arity). That can be solved with enums or structs. Enums have the advantage that, if arity is very different, they might save you some space. I'm not going to say, though, that this feature is or isn't useless, time will tell as the language evolves and the need becomes apparent. Still implementing it has the cost of added maintenance, and then there are many complexities (what happens if I mix named and unnamed? Can I put a named parameter between unnamed ones?) that will affect every single other effect. And then how would closures handle it? Could we get a generic function with named parameters? It's too much cost for a benefit that might not be required after all: last I checked JS is only adding support for setting default values for data inside an object so named parameters can still be used. I think we'd better wait a bit more on this thing.
There are nice browser extensions automating the use of a suitable proxy.
Any chance to us in the touch screen world to have a viewable version? 
I am not using them for moral reasons. The internet makes it too easy to just avoid issues by routing around them. The frequent reminder that copyright is an issue here is something I'd like to have.
Not sure if joking.
[My suggestion](https://www.reddit.com/r/rust/comments/2uml9r/rfc_keyword_arguments/co9y2q6?context=3) is that the parameter name itself should be the keyword argument. So I prefix a `~` before each keyword argument. If I define a function like `fn f(~x: i32, ~y: i32, s: &amp;str)` with two keyword arguments, x and y, and one non-keyword argument s, then I can call it normally, `f(1, 2, "a")`, but also it can be equivalently called as: f(x =&gt; 1, y =&gt; 2, "a") f(y =&gt; 2, x =&gt; 1, "a") f("a", x =&gt; 1, y =&gt; 2) Keyword arguments would let the caller specify the arguments in an arbitrary order (except for non-keyword arguments). As long as the function f is resolved the compiler can look at its signature in order to turn the keyword arguments into the positional form `f(1, 2, "a")`. Then there's those two examples f(y =&gt; 2, 1, "a") f(1, "a", y =&gt; 2) They seem ugly (having y as a keyword argument, x as a positional argument) so a rule could be that if there's a keyword argument, then all arguments need to be provided with keywords, except those that can't. And some really can't, like more complex patterns like tuples. I'm not sure how it would interact with closures and generic methods or traits or anything else. But I think a major obstacle would be to try to infer f's type.
It'd be an all in or nothing in deal, otherwise it would be hard to know which is which. Other issues might arrive. You can set rules to fix it, but they'd just complicate things a lot. Again the main uses I can see for named parameters could be solved by structs: 1. Not clear what the parameters do. Then they probably are not related to the function, they should be wrapped around a type that makes their function clearer. That or the naming of function is not good at all. A wrapper changing the name could fix this. 2. Too many parameters (easy to loose track of). Probably a code smell, parameters could be grouped into (tuple) struct types representing logical group. 3. Wanting to specify only subset of parameters. Probably better done as an enum or struct, in both cases the costs are made explicitly clear, and it's easy for programmers to realize the consequence. 4. Want to change the order of the parameters. Again I feel this is code smell of sorts. It implies that the original order is not good enough. In that case a wrapper should be done instead. Again these solutions cover 98% of the cases. The remaining 2% probably are things that should be done with macros or syntax plugins. Complicating the language such, for a feature that only offers sugar syntax, when we have yet to see how bad the need is, is a premature action. Also what would be the syntax for generic functions or closures that use named parameters? If this only works for static functions it'd be too limiting and things would be easier using struct/enums.
Thanks for your reply. I guess I can understand the desire for a common standard for all programs in a language. 
It's that not writing "return" that's making me cringe. I suspect I won't be doing that too often. I don't see the benefit in doing that. I'll likely try the brace on the same line, but it'll take some time to break the habbit. :) Thanks for the reply!
Not writing `return` has a clear benefit that converting from the expression to the function or closure (and back forth) is much more natural. This, combined with the nested functions, encourages more functional refactoring.
In the Hyphens-related discussion, some folks expressed interest in crate-namespacing; a pre-RFC should appear soon. Edit: Borrowing from python, Namespaces are one honking great idea.
Might have a try, but not right now (at work).
I've been on this talk, it was pretty good. Cheers!
I've often got an editor on the same screen as a browser for reference, and the editor gets about 80 columns. More than that, and the browser's damn near useless. More than that, though, I strongly feel that *if* you're going to have a line length limit, it should be chosen based on technical grounds, to ensure code is (99+% of the time) going to fit on screen. That puts it in the 72-79 range (depending on whether you want to account for line numbers in a terminal editor or not). As it stands, if code is hard-wrapped at 100, you can't make the editor window narrower without ending up either needing to scroll horizontally, or with jagged soft-wrapped lines, both of which ruin readability. As someone who has had to mark programming assignments that were hard-wrapped at 100, then printed out at 80: this will give you one *hell* of a headache really damn fast. You also, obviously, can't make the window wider since it won't do anything, though that's less of a problem. To give you an idea of what this is like, here's [what the Rust documentation looks like next to a 100-column editor on my monitor](https://imgur.com/uqFwSNU). The editor and Firefox are taking up the entire width of the screen.
I just went with the first item I could think of that would have a bunch of generic methods with lots of nice, verbose `where` clauses. :D That said, I still say it's fairly representative of the experience in general. As an aside: the best thing about the whole "Web 2.0" malarkey is that occasionally, I run into a site "designed for mobile" that actually works in a narrow desktop browser window. Now, technical documentation pages in HTML? Odds aren't so good for those.
Thanks :)
This conference only happened a few days ago, give them some time :)
Right now I'm using a weird (Pythonic) fn foo() -&gt; i32 { 8} style simply because it works best with Sublime Text ability to fold the code. I hit Ctrl+K+1 and see just the signatures of the functions (or Ctrl+K+2 if I want the signatures of the methods). In IDE with a smarter cold folding I would've used a different style.
I'm not afraid of using more lines to make the code easier to use. I think `where` clauses unilaterally forced me to change the style, to use braces on their own line. fn foo&lt;T&gt;(t: &amp;T) where T: Clone { // function body }
One of the nice properties about `return` is that it is *only necessary for early returns*. If nobody uses it redundantly (i.e., at the end of a function), then scanning a function for early return points is as easy as looking for the `return` keyword. It's quite handy in my experience.
We support mouse events, but I guess having floaty buttons wasn't a priority :p
Firefox will mostly be using one of Servo's components. `rust-url` and `html5ever` are some candidates under discussion.
Woa, `html5ever`? That sounds like a pretty substantial change!
I really don't like this reason at all and calling a different style poor even less. People have been programming in different styles since forever. Sure, there are benefits in sticking to a single style but ultimately it's a matter of taste and everyone should stick to what he or she likes most.
I use slightly different syntax: fn foo&lt;T&gt;(t: &amp;T) where T: Clone { // … } The only thing that I need get used to is that Rust use 4 space indentation instead of 2 space, but it is minor issue for me.
So much this. I don't care if some people say braces on their own line is bad style, because I think the example speaks for itself. fn foo,T&gt;(t: &amp;T) where T: Clone { // function body } If that's right, I don't wanna be right. And of course, being consistent, I don't choose the style based on the function signature, I use a brace on its own line for all function definitions.
I guess that the automatically derived `Hash` and `Eq` assumes that type parameters are used, and therefore must be included in the comparison/hash. This results in `impl&lt;P: Eq&gt; Eq for Key&lt;P&gt;`, requiring that your phantom type implements `Eq`. The "obvious" way to get around this is to implement the traits yourself.
&gt; Namespacing would've prevented that. I'm not convinced that this is such a big problem though. Sure, it prevents someone else from registering another `format-sys` crate, but you can always pick another name - or, even better, collaborate with the original crate. If `http` is taken, and you have no better name, it's easy to disambiguate with `doculope-http` or something like that. That's effectively namespacing, but not enforced by the system. &gt; I know people have left ecosystems because the package ecosystem had become a nightmare I do believe you, but has the package ecosystem "become a nightmare" in those cases only because of flat namespacing? Could you share some example?
Those aren't under serious consideration right now. We're aiming for an image decoder to start with.
The HashMap requires its keys to be hashable and obey an equality relation. Which is as it should be. Or how would you try to store something into a *Hash*Map for which no hash can be computed? And how would the HashMap decide wether the given key is *equal* to a stored key if the keys are not equatable? Edit: I stand corrected; the problem was that the deriving did not work.
Nevermind, https://github.com/rust-lang/rust/pull/20790 has details
If you're trying to update a git repo from behind a proxy, this is a known bug with libgit2: see https://github.com/rust-lang/cargo/issues/636 and https://github.com/libgit2/libgit2/issues/2555 .
It's a bit tangential, but can you please explain what the practical use for something like this might be? Giving your Key a type parameter and filling it with Phantom, that is.
http://www.reddit.com/r/rust/comments/2s0i6d/rust_guide_coding_style_question/
Can't you just insert an empty line? fn foo,T&gt;(t: &amp;T) where T: Clone { // function body }
I think the no return guideline comes from a preference that control should be expressed as "far out" as possible, changing: if (condition) { return x; } else { return x + 1; } to: return if (condition) { x } else { x + 1 }; for example, and the general rule from this is that return should be avoided whenever possible. Some people (myself included) think that this makes the program structure clearer, and it makes it easier to refactor if you decide to do additional processing on the output (eg. make it an option to deal with some error condition), as it only needs to happen in one place.
Look for "Penguin Cafe Orchestra - Perpetuum Mobile."
90+% of the time I don't need any explicit lifetimes on references. Lifetime elision takes care of the most common nontrivial case: returning a reference based on a passed-in reference.
I'm not saying you should have to do this, but you can use arrow keys on Android: https://play.google.com/store/apps/details?id=org.pocketworkstation.pckeyboard&amp;hl=en
Please. Finish rustfmt already and get this silliness over with. I'm so, so, so bored of these conversations. I'm tired of people thinking brace style is a function of their personal expression and identity. Folks, code is easier to read when it follows convention. Come on, I just want to write fn foo() -&gt; i32 { return 8; } and write my whole program on a single line. gofmt is a god send in the Go community and I don't know of a **single** widely used project that doesn't follow the gofmt styling.
I'm not sure what the advantage of Rust for such a program would be. Just write it in Haskell/OCaml/F#/your favorite language. If you need the performance+safety Rust provides, write the components that need that in Rust and communicate over FFI or a socket. I like Rust, but I *really* think it just doesn't have any advantage in a "script" scenario.
&gt; Rust's complexity will slow down its adoption for wider usage particularly Enterprise and Big Data community where Java/Python are dominant and Go is becoming popular. Rust will catch on first in situations where the main alternatives are C and C++. That is: kernels, embedded systems, realtime signal processing, game engines, web browser engines (which are very similar to game engines), high frequency trading, etc. It's a long list of people who are completely sick of C++ and desperate for an alternative. Java, Python, and Go are mostly not viable in these domains, for fundamental reasons. Areas like enterprise Big Data or webapp backends will see slower adoption, based more on the convenience of Rust and the powerful compile-time checking. In these contexts, top performance is a money-saver but not a must-have, as you have pointed out. That's fine, I don't expect Rust to take over the world all at once ;) &gt; Given improvements in C++11/14 If you think Rust is too complex for industrial use, then idiomatic C++14 is absolutely hopeless. Yesterday I was reading about the [incredibly complicated rules](http://thbecker.net/articles/rvalue_references/section_01.html) for rvalue references: when is an rvalue reference [really an lvalue reference](http://isocpp.org/blog/2012/11/universal-references-in-c11-scott-meyers), how do nested combinations of lvalue and rvalue references decay into single references, etc. Moves and ownership are *vastly* simpler in Rust because it starts from a clean state. Also: screwing up the rules in Rust is a compiler error; screwing up in C++14 is a mysterious crash or an exploitable security hole. Modern C++ has a lot of benefits, but at a great cost. The cost increases as you scale up a project to include more developers. The cost increases when you need to include developers who aren't seasoned C++ experts. And the cost will only increase as C++ gets even more complicated. My experience is that only small and exceptionally skilled teams can really get the benefit of idiomatic C++, and only under the best of circumstances. Rust provides the same benefits and more, at *much* lower cost. &gt; I feel tooling particularly smart IDE which understands borrow/checker This would be *so* cool. Imagine having pointer lifetimes shaded in your code.
That's not at all decided yet, and it *certainly* won't happen in 2015. We have plans to ship an alpha-quality tech demo browser based on Servo. But anything with the "Firefox" brand would be much further down the line.
I didn't intend to say Servo will replace Gecko by the end of 2015, but that, in the future, Gecko will be replaced by Servo, as far I as understand.
&gt;I could understand that this eliminates bikeshedding /shrug "could"? I'm telling you, there is not a single project in the Go community that is in any sort of non-trivial use that does not use "gofmt". It's not built into the compiler, but it might as well be. No one is arguing for it in the compiler, and it isn't there now, so I don't know why that's even being brought up.
"Git is hard, make a source control that's easy to use" "Lifetimes are hard, make the compiler do it" Some problems are just hard. Like, a computer-can't-infer-meaning-you-haven't-told-it-about hard. If the compiler could infer all lifetimes, then it would. As is, it's actually inferring a large number of lifetimes already for you. If a pre-processor could determine the lifetimes, then they would just always use the pre-processor and Rust would be some magical pinnacle of all programming languages. If you want to write scripts without the masochism of bash scripting, then just opt for Python or better, Go.
Gofmt works for a few reasons I think (and I could be wrong): Go is more of a dictatorship with google, so people take that seriously; the rust is more freedom/democracy based. The language itself is also dictatorial: I mean no generics? Rustlang on the other hand is more multi paradigm Go's compiler due to the (crappy in my opinion) decisions to focus on compilation speed, and do the auto semicolon insertion blocks the allman style braces already (and iirc gofmt does too), rustc on the other (and correct imho) hand trades compile time speed for runtime so those excuses would not work. Golang could concievably a first or second language, but rust is probably a 2nd-3rd language, so by the time users get to it they have their own style. Golang had a quicker stable release than rust, so I imagine they started with conventions early, while presumably rustacean's have evolved their own styles and are probably not going to change. Finally due to the heritage of go, and not being able to brace as you please; is it really that big of a step to follow the rest of conventions? The braces were my main hangup. tl;dr: I think the communities are different, golang seems more like a monarchy and rustlang like a democray/republic; and that is why a 1tbs won't happen here. (I hope anyway, allman 4 evah)
I don't want to address a lot of what I perceive as FUD about Go. I love Go. I love Rust. I think this whole "Google runs Go" is misleading and inaccurate given history. Rust **will** be better off if the community chooses to adopt 'rustfmt', and I'd be willing to bet a huge sum of money that it will happen. I watched 'gofmt' fall out of the r60 release series and I watched the community organically adopt it. I don't expect non-Go-programmers to understand this, but every single damn Go project in the world is written with the exact same styling. No reading run-on lines. No guessing about unused variables. It's incredibly empowering to be able to grab random code and immediately start making contributions. All of these things are vitally important. And the Rust team knows it. Steve has mentioned that rustfmt is desired by everyone. A huge amount of effort was taken to ensure that crates.io and cargo exists... which is a direct acknowledgement of the success of projects like Go and Node that have canonical package managers with them. Predictable, repeatable, common. I guess maybe another way to put it - I'd be shocked to see projects that opt into Cargo but don't opt into rustfmt. It's like writing a new OSS project and not putting it on GitHub --- you're welcome to do so, but the entire community is going to say... "Uh, what?"
My screen can fit 3 ~85 char wide docs side by side, so 80 seems even better. I actually tend to work with two 1920x1080 monitors side by side, and still feel like I'm running out of space, with three buffers side by side on one monitor, and either two terminals or a terminal and a web browser on the other monitor. I am considering getting a stand so I can add a third monitor that can be devoted to terminals; when working on distributed systems, I frequently need to be SSHed into up to 6 machines at a time to monitor all of them, or sometimes its helpful to be SSHed into two but with three terminals open on each, one tailing logs, one monitoring various status, and one for entering and running commands. And that's just terminals. When browsing around a code base, I frequently find it easier to follow code when I can have three buffers open at once, or two buffers plus one for manipulating Git. Screen space is still precious! 80 is a better compromise between being able to fit enough on a line, while still being able to fit a lot of buffers on screen at once.
As I said I could be wrong, but based on my use of go (which is an ok lang, but they made mistakes to be sure {generics? interface{}???? derp}) and research; so no fud from me I'm afraid. Heck maybe people will use rustfmt, maybe not (If it is brace on same line its not for me.), but if it doesn't take off as much as gofmt did I would not be too surprised. And for the record I like bitbucket; let the gits keep their hub.(Free private repos w/ up to five users let me keep school projects and personal things safe for free un like gh). 
I just found this relavent quote from the "C programming language" written by the great prophets Kerningham and Richie The position of braces is less important, although people hold passionate beliefs. We have chosen one of several popular styles. Pick a style that suits you, then use it consistently. So do what you feel, but be consistent.
&gt;As I said I could be wrong, but based on my use of go (which is an ok lang, but they made mistakes to be sure {generics? interface{}???? derp}) and research I miss generics in Go very rarely -- but I do. I also like Rust's completeness here over Go, but now we're talking a completely different subject. I'm quite sure that Rob does not consider Go's lack of generics to be a "derp", and if you have a way of adding them to Go2 without breaking things, literally thousands of people are dying to hear a new proposal. :) &gt;Heck maybe people will use rustfmt, maybe not (If it is brace on same line its not for me.), but if it doesn't take off as much as gofmt did I would not be too surprised. I don't know why you think Rust users would be less likely to be interested in having a standard convention than Go users, especially given that Rust arguably has far more syntax and is harder to read-at-a-glance, which is what conventions really enable over time. &gt;maybe not (If it is brace on same line its not for me.) I've seen a dozen of people with that attitude in the Go community. Their repos are gofmt'd now. /shrug Eventually most people accept that having approachable code and having a wider pool of collaborators is more important than brace placement.
Glad you enjoyed it! There will be one episode per day until I see Rayspheres :), I am so curious how the performance will be!
In golang code with allman style braces can't even compile. To me brace placement is the biggest issue; so I imagine once these devs got used to being forced to alter their style with braces they decided to bite the bullet and just use gofmt. Without the compiler forcing me to not place my braces in "the wrong place" in golang I doubt I'd even know about this crud. The other reason I think go folks are more likely to use gofmt is that they have this mentality that your code is either fmted or unreadable, I doubt such a strong view on the position will come into this community. (I could be wrong however)
Yeah, I'm sure they have their reasons for not having generics, but for me its a no. As for ideas on retrofitting it? Not sure if that is a good idea at this point, looking at java the generic system is cool and all but very evident that it was added later. T[] blah = new T[];//y u no work? type erasure gah! Then again maybe type erasure could work.... Then again not designing a lang is a reason I want to use rust XD. (also the lack of gc and other lower level approaches) It is off topic, you are right sorry.
Yeah, this would be my advice as well. If you want mutability with your reference counting, you can either wrap a RefCell around it, or go with a copy-on-write solution like what I do with [crates.io/crates/cowrc](https://crates.io/crates/cowrc)
&gt; high performance, open source systems like HDFS/Hadoop There is a recent MSR [paper](http://www.frankmcsherry.org/assets/COST.pdf) comparing various state-of-the-art big data systems running on 128-core clusters to a single-threaded rust program. It's not pretty :) In a lot of high-performance systems the bottleneck is memory access, which is where having control over the layout of your data becomes a big win. Even those people who are succesfully building high-performance systems in java often [resort to manual memory management](http://mechanical-sympathy.blogspot.com/2012/10/compact-off-heap-structurestuples-in.html) to improve memory access patterns. Java is often a win over C++ for productivity and simplicity (which can also lead to better performance in the end), but that doesn't mean that it's a comfortable tradeoff. Being able to keep the level of control that C++ gives you but get close to Java levels of simplicity is pretty exciting.
Maybe something like this? struct Graph&lt;T&gt; { nodes: Vec&lt;Node&lt;T&gt;&gt;, } struct Node&lt;T&gt; { index: usize, adjacent: [usize; 6], pub letter: T, } Instead of referencing by pointer, you reference by the index to a `Vec` of `Node`s. The disadvantage here is that the Nodes themselves cannot connect themselves to a neighbour, so all functions must be defined on the `Graph`. You also have to be careful with how you let external code access the nodes. If you let it modify the `index` or `adjacent` fields, or let it add `Node`s without any validation, you could end up with some invalid graphs which will probably cause errors in other parts of your code. Another option would be to use `Rc&lt;RefCell&lt;Node&gt;&gt;`, but then you have to make sure you use `Weak` appropriately to avoid cycles. All of this makes code a lot more verbose and possibly slower (citation needed).
You might be looking for something that is actually called [Cell](http://doc.rust-lang.org/std/cell/struct.Cell.html) :-) Or [RefCell](http://doc.rust-lang.org/std/cell/struct.RefCell.html) if your cell is non-trivial, which it is if it contains pointers to other cells. Combine it with [Rc](http://doc.rust-lang.org/std/rc/struct.Rc.html) or weak pointers as necessary. That said, if you start with a large allocated array of cells (e g, in a Vec) anyway, it might be easier just to store indices into that array instead of storing direct pointers.
Most of the Big Data and web apps are driven by open source community. Example the big data softwares which I mentioned above are all community driven, open source project. I was reading https://typesafe.com/blog/why-enterprises-of-different-sizes-are-adopting-fast-data-with-apache-spark where more enterprises will be using Apache Spark which is written in Scala. I think C++/Rust would be better suited language for in-memory, fast data processing but don't see any initiatives either from community or enterprises.
"Close to Java levels of simplicity" is an overstatement. You still have to think about memory management quite a bit. As you pointed out, high performance systems require this anyway, so it's nice that Rust puts it in the language proper. But when you *aren't* going for maximum performance, the relative complexity of Rust's type/lifetime system can be irksome. Garbage collection is indeed a huge time-saver, when you can afford it.
The first link is dead, by the way :(
ok, I'll just stick with [higher-somethinged-somethings](https://twitter.com/horse_rust) then!
We'd love for someone who feels strongly about `rustfmt` to make it. Everyone wants it, nobody has stepped up. The team has to focus on the language itself, so unless someone else makes it, it's not likely we'll have time until after 1.0 lands.
Neat. Thanks for sharing, and welcome!
`Cell` is meant for `Copy` data (that is, plain old data), when you want to create interior mutability. `RefCell` is meant to be passed around as immutable references. It effectively lets you get around the "no two mutable references" problem. It uses a single threaded lock to prevent anything unsafe (it will catch reentrancy problems at runtime!)
I think the core issue you have is that you haven't carefully laid out how this data is to be freed. That is, Rust requires it to be very clear *who* is responsible for freeing a given piece of memory. `&amp;` means "Someone else is responsible for freeing this memory". `Box` means "I am responsible for freeing this or passing it on". The solution that others are suggesting is to use a `Vec` to hold your data (which will be responsible for freeing the data). If you use `Vec&lt;RefCell&lt;T&gt;&gt;`, you'll even be able to create safe inter-node pointers! Creating a graph that builds itself up and tears itself down is really hard, because each node needs to keep track of which nodes it constructed, and ensure that as the structure is torn down, all invariants are maintained at all times. Writing this in safe Rust (thus proving its soundness) sounds like a wonderful challenge!
Intended target of first link: http://www.frankmcsherry.org/assets/COST.pdf
We actually do test Android/ARM cross compiled binaries every commit, so that should never break too. (I should know, since I was involved a bit automating tests with adb, Android Debug Bridge.)
I have a pull request for you that fixes some style things, but the wifi i'm on doesn't let me push to github, so i'll send it later. I think overall this looks great, but there are a few other minor things I'll send a PR for later as well. One thing that's hard about translating stuff from a language like Python is that you end up with a different design than you would in a language like Rust, considering everything in Python is GC'd. This is a small enough program that there's not a ton of that, but there's a little.
For a general solution to a graph that is a bunch of connected nodes look at [`rustc::middle::graph`](http://doc.rust-lang.org/rustc/middle/graph/). It is a start to more or less how it should look. The idea is that Nodes should not contain their neighbors, but instead the "graph" owner should. Nodes would expose this through a trait. pub trait Node&lt;T&gt; { fn data(&amp;self) -&gt; &amp;T; fn mut_data(&amp;mut self) -&gt; &amp;mut T; } We can then have Graph trait pub trait Graph&lt;T&gt; { type Node: Node&lt;T&gt;; fn start_node(&amp;self) -&gt; &amp;Self::Node; fn mut_start_node(&amp;mut self) -&gt; &amp;Self::Node; // This one can probably be done better, but I'm too lazy. fn make_node_mut(&amp;mut self, n: &amp;Self::Node) -&gt; Option&lt;&amp;mut Self::Node&gt; } I think that I need to add two different types, Node and MutNode to the above trait, but I need to sit down and write this down, and I'll be brutally honest with you: I'm just not invested enough on your problem to sit down and finish it when my friends are waiting for me at a bar.
Once upon a time, when I had no idea what a cross compiler was, I was able to use the regular windows version of gcc with wine. And the resulting executables worked! I was able to link to GTK even. I wonder if something like that would work with Rust too (I'm not saying that OP should do this, it's probably a horrible idea. Just a random thought).
What does "some jQuery support" mean? Does it mean that jQuery needs stuff that Servo doesn't implement, or that jQuery needs to be changed to work with Servo?
The former.
Remote debugging support sounds like we support stepping through JS line by line. Do not be fooled; all we support is executing JS through a remote console.
That's a relief :)
Ah, nice.
When I had to debug some ARM problems for [Mosh](https://mosh.mit.edu/) I set up a magical [QEMUlated chroot](https://wiki.debian.org/QemuUserEmulation) with actual Ubuntu Linux for ARM installed inside. It's easier than building a cross compiler, and easier than setting up a whole-system emulator. Performance is good because it talks to the native kernel and uses all your cores and RAM. On Debian all it took was (approximately) $ sudo apt-get install ubuntu-dev-tools qemu-user-static $ mk-sbuild --arch=armel precise $ sudo schroot -c precise-armel-source
Thanks! We really need better Windows support, so we really appreciate this. You could ping windowsbunny on irc, they seem to be doing a lot of Windows work at the moment and I'm sure they know of areas where you could help out. We should probably start handing out FOTT just for installing Windows...
They don't seem to exist. Basically you run Servo with `--debugger &lt;port&gt;` and then use the "Connect" option in Firefox's devtools menu to connect to it (https://developer.mozilla.org/en-US/docs/Tools/Remote_Debugging/Debugging_Firefox_Desktop). Seems [broken now though](https://github.com/servo/servo/issues/4844).
Part of the problem is having one function receive references to both the Updater and the Updatee. Instead, the main `update` function could just take a reference to the Updatee. It can then perform operations on both the Updatee and its Updater, but not at the same time. [Something like this:](http://is.gd/EvTpGf) fn update(updatee: &amp;mut Updatee) { let new_value = updatee.updater.update(); updatee.update(new_value); } This requires some way to separate the operations on the Updater from the ones on the Updatee. You can pass values between them, but not borrowed references.
Let me compare Rust and Go: they are hardly comparable. Certainly not to the degree that would inspire so many articles. 
That's very cool! I didn't know QEMU did emulation of individual programs too.
rustfmt will allow for different formatting conventions, or it will be forked. If you want me to format my code the way you like it, you best be prepared to pay me. Within a single project, however, it makes perfect sense to have automatic formatting, so I hope a rustfmt that takes a nice indentation scheme from a configuration file is created.
To avoid ref counting and if you want all your nodes to be destroyed at the same time, you can use arena allocation, if the lifetime of the arena is 'a, then each pointer to a node will be something like `&amp;'a Node&lt;'a&gt;`. This is the most efficient and clearest way to implement a graph, IMO. However, it doesn't solve the mutability problem - you will either need RefCells or unsafe code for that (remember to use `UnsafeCell` so that compiler know where you might mutate). In particular, even if your graph is immutable, then initialising the graph will still have to be unsafe.
You might try axial coordinates from here: http://www.redblobgames.com/grids/hexagons/ Makes adjacent indexing independent of column again, and has several other benefits vs what you're using (article calls them offset coordinates).
I hope Rust's simplicity (in some ways) relative to C++ can outweigh its complexity (in other ways). C++, for all its insanity, is still sometimes easier to make *something* run, even if it'll probably be full of holes.
I wouldn't explain it better myself, and I'm the guy designing the language. Well done!
I would **love** your help to get [libpnet](https://github.com/libpnet/libpnet) up and running on Windows! I spent a lot of time trying to get it working, but stumbled at the last hurdle... If you're interested, let me know! Either PM me or catch me on IRC (same nick, freenode/libpnet or mozilla/rust), I'd be happy to talk you through the code/getting started. Edit: I forgot to mention - there's a tracking issue here with a little more info: https://github.com/libpnet/libpnet/issues/2
Even if parameters are used it still doesn't mean they require `Hash` and `Eq` if they are used only as function arguments/return values and not stored inside of `struct`.
Sure, but they are usually not attached to the struct itself, then. They can offcourse be, but it doesn't look like `derive` takes that into account. "Used" in my previous comment can be expanded to "used as a type for a field in the struct".
You can keep the original layout of having the modules nested as `::b::a`, with `c` being the crate root, but you need to change your filesystem layout of the source files for it: If a module has submodules that life in their own source files, that parent module needs to be located in its own subfolder and be named `mod.rs` So, for your code, your filesystem would look like this if your `c` module is your crate root: c.rs b/mod.rs b/a.rs --- Alternatively, you can structure your module tree differently and have all submodules be submodules of the crate root, which would simplify the situation somewhat because the module tree is now only 1 deep and not nested.
an encapsulated Graph&lt;T,Edge&gt; container or something like that seems like a good idea to me, even if it needs unsafe internally.. but the benefit of indices would be they needn't be 64bit. if you've gone through the graph's interface for creating nodes it shouldn't need bounds checks, and it could expose iterators for a nodes' connections, etc.
As comparison, [this](http://is.gd/KrYdVQ) shows both how `derive` currently implements delegation of trait like `Hash` and `Clone`, and how it _should_ do it now that we have where clauses.
Works for me on Linux. I'm not sure, though, file an issue :)
Ok done…
I think it’s a philosophical question. Multiplication is more “scientific” while methods are more natural (like in smalltalk where you could just write `5.0 meters`).
Depends on where you draw the line. You can't call the memory allocator without `unsafe` :-) Of course there are lots of layers that are safe, building on top of that like Box; but you could then also include Vec.
 impl A for E { fn fun(self) { match self { E::V1(s1) =&gt; s1.fun(), E::V2(s2) =&gt; s2.fun(), } } }
Can you think of examples of this done right? And are there libraries (with generics in place, I presume) of pre-made essential structures?
The standard library has them.
[Pure, Declarative, and Constructive Arithmetic Relations](http://www.cs.indiana.edu/~dfried/arithm.pdf) implements arithmetics with guaranteed termination that can be embedded in Haskell type classes.
Not if you sugar it with a macro - though I wish deriving would work for this.
You can have function overloading without automatic type conversion.
--devtools, not --debugger. But yeah, broken during the last rustc upgrade.
The downside of this is that your namespace gets "polluted" with units. So if you go this route, I would at least use, i.e. "meters" instead of just "m." I ~think the convienience constructors proposed above avoid this. I have heard that embedding units/dimensions in typesystems is much harder than you would think to really get right; a friend who worked on this in Haskell is still not happy with what what has been achieved even after several attempts. I'll see if I can get some more specific info to point you to. I'm sure Radians throw a wrench in the works, for example. It is probably also harder to ~do conversions than just to check them...
That's really cool. Thanks for putting in the effort to do this. I wonder, could you also do something like `Vector2&lt;Dim&lt;Meter&gt;&gt;`? Somehow this feels more natural to me…
These are not higher-kinded types, these are higher-kinded trait bounds.
~~Higher-rank types and higher-kinded types are the same thing in fact) they are synonyms.~~
Yesterday's update on https://github.com/rust-lang/cargo/issues/636 from @alexchrichton: &gt; Ok, as a status update to this I've finished binding libgit2's custom transport API and I've written a simple HTTP backend using libcurl: https://crates.io/crates/git2-curl. &gt; &gt; I'll try to hook this up into cargo and then we should get proxy support for free because libcurl supports it out of the box. Unfortunately the implementation is not super efficient (reads an entire network operation, aka repository, into memory) due to the current design of curl-rust, but it should serve as an adequate enough stopgap for now. 
This is why I wish custom literal suffixes was a thing in Rust. It makes code like this so neat looking. let speed = 5.0m / 1.0s;
Exactly. Plus, properties hide side effects. Do you want immutable or mutable getter properties? Properties lead to a very, very mutable design, which is not very rust idiomatic in my opinion.
That kind of sugar could probably be implemented via macros. Rust itself should probably remain as low-calorie as possible :) I don't see properties as a compelling enough feature to warrant bloating up the language. It's likely that the developers of the language felt the same way. You are, of course, welcome to submit a proposal.
In C++ you can get automatic type conversion from operator= and constructor overloading. But I suppose they aren't necessarily linked. I guess my point is that both share a philosophy of implicitness for the sake of convenience versus explicitness for the sake of safety, ie without these features you know which function your using and you know when a type conversion is happening. 
what would properties look like in rust? how does this differ from a struct with pub elements?
&gt; Seems like Box&lt;T&gt; does this: I think that's compiler magic unfortunately. Although ... what you can do (maybe? I can't test this right now) is change the macro to implement `Deref` instead? impl Deref for &lt;name&gt; { type Target = &lt;trait&gt;; fn deref(&amp;self) -&gt; &amp;&lt;trait&gt; { match *self { &lt;name&gt;::&lt;variant&gt;(ref x) =&gt; x //...etc } } }
That repo looks like everything is written by hand. I feel a bit skeptical about it, and would rather build some sort of header parser and autogenerate.
 fn foo(b: &amp;Bar) { let c = b.num_entries; } Where `b.num_entries` is essentially a method call instead of data access. This allows `num_entries` to be e.g. lazily computed if desired, even if the original implementation had `num_entries` eagerly computed and stored because it was originally thought to be always used/needed. EDIT: Although I think I see some of the complications already. It would need to be `b: &amp;mut Bar` if the `num_entries` getter actually DID do any caching... (...right?) And so the caller would need to change anyway (in addition to this causing a ton of extra `mut`s)...
Mouse scrolling is inverted by default in MacOS X, it can be changed in mouse options. It's the first thing i change after installing MacOS X.
Now that I'm confident that the new `Drop` rules won't interfere with this use case, I can freely recommend the `TypedArena` solution for graphs (using a `TypedArena` to allocate / own the nodes, and then using `&amp;` references between nodes instead of `Rc`). This solution has a ton of advantages when (as is often the case) you are working with largely immutable data (with mostly the connections between nodes and some pod data mutable, which can be modeled with `Cell`).
Now that I'm confident that the new `Drop` rules won't interfere with this use case, I can freely recommend the `TypedArena` solution for graphs (using a `TypedArena` to allocate / own the nodes, and then using &amp; references between nodes instead of `Rc`). This solution has a ton of advantages when (as is often the case) you are working with largely immutable data (with mostly the connections between nodes and some pod data mutable, which can be modeled with `Cell`). Example of this mode of use (almost certainly doesn't compile with current Rust, but I am going to fix it up to compile cleanly on the nightly shortly): https://gist.github.com/pythonesque/fc43fe529adf8ddc26cb
The match is dynamic as always, the method calls on the variants are monomorphized. If the client code is in the same crate, or you mark the `fun` implementation on `E` with #[inline], the optimizer might be able to deduce which variant the value gets and optimize away the match.
Nobody disagrees about this, but writing a C parser is not an easy task. I don't remember why rust-bindgen was not used, but there is also a reason.
Is it really that bad? I can't say that I'm a big fan of this "properties" idea, but it's not like it's the great plague of the software industry, is it? I can actually understand that people find it convenient, even though I think it obscures more than what it helps. Object-oriented programming, itself, is so wide and can be interpreted in so many ways. I would say that Rust is quite object oriented with its ownership model and the way that any type is treated more or less the same. I mean, even functions and primitive types can implement traits. The data seems to be at least as important as the logic. Some object-oriented languages out there may have some odd, misused or less pleasant features, but I don't think that makes the idea of object-oriented programming harmful. There is no such thing as a perfect language, as far as I know, and I'm all ears if someone happens to find one.
I see what you're saying, perhaps [this](http://is.gd/rISnOj) achieves something similar
Yeah, Deref works. Thanks. I had to play a bit with lifetimes. I will post complete solution later.
I'd be in favor of adding properties to the language. They're one of the few things I miss from Scala.
Obviously I meant that it is inverted with respect to the current system behavior.
One problem is, that there are two kind of property implementations that would be desirable. The newer kind used in Java/C#/++ using static/vtable dispatch or the old school message sending approach as used in ObjC and C(GObject). What to do about it? Support only one or both? And how? Nothing one should decide just to have the feature on the list.
Couldn't you have mutable and immutable properties? Mutable properties are then checked recursively that they don't call any setter methods.
In other words, trees of heterogenous objects with no back-links can be represented directly with no overheads. Anything else needs an optimised unsafe implementation, or else needs to use higher-level/higher-overhead stuff like runtime reference- and borrow-counting types. So optimising a data structure for Rust means trying to make it into a tree. (Hopefully I'm not too far from the truth with this summary.)
I don't like getter setter at all, because they are basically just like freely accessible variables with some extra checks and extra boilerplate. Instead data structures should provide a high-level access to the functionality and keep members as implementation detail. Properties are just syntactic sugar for getter/setter and if the basic mechanism is bad then there is no need for systactic sugar.
&gt; I'm not worried, because our language doesn't have to be everything to everyone. It'd be cool to take on those domains eventually, but I think the language needs more ergonomic improvements first. Totally agree. I would also add that performance is *one* aspect for using Rust certainly, but not the only one. Rust offers a lot of compile-time checks compared to most of the "mainstream" languages today (C++, C, Java, C# for example). Beyond performance, added "safety" can also be a reason to switch language.
Can you please explain? I'm having difficult reconciling your claim with [other definitions](http://research.microsoft.com/en-us/um/people/simonpj/papers/higher-rank/putting.pdf): &gt; [...] arbitrary-rank types; that is, types in which universal quantifiers can occur nested. Which seems clearly distinct from higher kinded types to me. Another point that I find difficult to reconcile is that Haskell98 has support for higher kinded types but [not higher rank types](https://ghc.haskell.org/trac/haskell-prime/wiki/RankNTypes).
One thing that crossed my mind was my use of strings to represent the binary numbers instead of just binary. I didn't know how to do binary in rust, or what problems I would run into had I done that, but I realize the inefficiency of representing 8 bits as "00000000" The trade-off was that using strings made splicing extremely easy. Which is what this program is essentially
Just because a feature can be abused doesn't necessarily mean it should never be allowed. edit: Also, `operator()` is *operator* overloading, not just function overloading.
Well, it was demonstrated that a [doubly-linked list](http://www.reddit.com/r/rust/comments/2uipmv/doubly_linked_list_without_unsafe_code/) could be implemented without resorting to `unsafe` directly (using `Vec` under the hood though, which itself uses `unsafe`). The principle is very elegant too: - use a `Vec` as backing storage - use indices to point into the structure And with this you can implement any other data-structure without directly using `unsafe`, you win.
I got solution: https://gist.github.com/krzat/d2c8263c43b6f3238401 Thanks for help. The only annoying thing left are these V1 and V2 variant names. I will think about how to get rid of them.
&gt; Plus, properties hide side effects. This, Rust has gone out of its way to be explicit. It may add some verbosity, however it also helps figuring out by just reading the code locally.
Reliance on upper case vs lower case and especially reliance on IDE coloring isn't really helpful. Image a pastebin, monochrome displays, etc. There's a plethora of reasons. It's not just knowledge about your own code. Imagine accessing a library and going through code examples. You cannot distinguish if the property is just a mere access or doing something very costly that you for example might not want to access inside a loop.
That's really interesting design. Would love to see it in practice. I also wonder how does multithreading tie in all this?
Why are these two separate meetup groups?
The `wrap` call is a bit weird indeed, maybe it would be possible to leverage the `Fn` family here: #![feature(unboxed_closures)] #![feature(core)] struct Wrapper&lt;T&gt; { data: T, } impl&lt;T&gt; Wrapper&lt;T&gt; { fn apply_once&lt;F&gt;(self, f: F) -&gt; &lt;F as FnOnce&lt;(T,)&gt;&gt;::Output where F: FnOnce&lt;(T,)&gt; { f.call_once((self.data,)) } } fn doit(s: String) -&gt; usize { s.len() } fn main() { let s = Wrapper{ data: "Hello, World!".to_string() }; let result = s.apply_once(doit); println!("{}", result); } You might need one `apply` per `Fn`, so 3 in all... ... but then you could call something like `let speed = vel.apply(Vector2d::norm);` ? (might not work all the time, especially when the return type of the function contains a lifetime...)
It's orthogonal, just like the standard Rust collections. It is Send + Sync* which means you can freely transfer it between threads. Synchronization happens using separate primitives for that (like Mutex) \* (If the stored element type is Send + Sync)
Rust [killed pure functions](https://www.reddit.com/r/programming/comments/1t8y6g/why_rust_ditched_pure_functions/) so I suppose your proposal wouldn't get any traction, for the same reasons.
OOP is an antipattern. The only thing good from OOP is the convience of method chaining.
Code is really simple: fn main() { io::println("hello!"); }
I actually love the "natural" mouse scroll and I believe that the OP wanted to point out that Servo doesn't follow that.
This is awesome! Does it work with fractional exponents? (e.g. `Time^(1/2)`)
&gt; doing something very costly that you for example might not want to access inside a loop But then the library is badly designed so the competence of library writers is really the issue. &gt; Reliance on upper case vs lower case and especially reliance on IDE coloring isn't really helpful. I know. I guess properties have drawbacks too so it becomes a matter of balance. Maybe settes/getters don't really add that much to spaghettification and in that case it's better to leave them out. On the other hand it could be that lack of properties would cause the language to be in practice write-only and then it would be better to add them. 
Awesome! You could totally make unitsmaker.py a syntax extension. Are the generated units compatible with other units of measure generated separately?
&gt; But then the library is badly designed so the competence of library writers is really the issue. Or the language designer to allow for such easy to miss errors. A language should be expressive and explicit and not allow for any ambiguities. 
Hmm, i don't understand this one :(
You mean this? std::old_io::stdio::println("foo"); It's just a multiply-namespaced name, meaning: std crate -&gt; old_io module -&gt; stdio submodule -&gt; println function That code could also be written as: use std::old_io; fn main() { old_io::stdio::println("foo"); } or use std::old_io::stdio; fn main() { stdio::println("foo"); } or use std::old_io::stdio::println; fn main() { println("foo"); } And so on. Also, keep in mind the `println!` macro (note the exclamation point), which is available by default. Also also, in the future you can use the [API docs](http://doc.rust-lang.org/std/index.html) to find out where a function lives. It is easily searchable. Though you seem like you're at a stage where you might have trouble interpreting that documentation. No worries, everyone has to start somewhere.
Regarding the cargo support, I have started with a new cargo subcommand to make working with dependencies - like locating their source - easier: https://github.com/rust-lang/cargo/pull/1225.
Could you give an example of where properties might lead to better code as opposed to a set_foo/get_foo method (if at all necessary)? &gt; If code is hard to read then not as many people will read it and fewer people will chose to contribute improvement so libraries in general will be of lesser quality. Exactly my point. Properties make code less readable, as they hide away complexity and are not distinguishable from fields when reading the code. So, without some sort of intellisense, that makes the code really unreadable.
I argue that that setters/getters contribute to spaghettification which turns people away. Nobody voluntarily reads/contributes to "enterprise" java code. This is my gut feeling, but so is that people will follow bad design practices in the world where rust have properties. Properties don't contradict core principles of rust, which is memory-safety and systems programming, because it's possible to avoid properties when necessary. 
Your form is confusing. It says " United States/North America only please" rather than "Continental United States", which suggests you're willing to ship to both U.S. overseas territories and non-U.S. parts of North America like Canada, but then it insists that the Zipcode field be both present and purely numeric. (Canada uses British-style `A1B 2C3` postal codes)
Stickers look cool. I ordered one.
PM me your address if you don't live in NA ~ I'll see what I can do. It was like $2 a letter :P
Sorry :( I don't write a lot of mail forms.
Thanks a lot
First of all, if you are going to give examples so complicated give a link to a play ground that shows them. The code you give, even with all variations, is complicated and has a lot of issues not ready before it compiles. Giving code that generates the exact error you are talking about will help people deduce what is going on and play with it. Second simplify the case. I will simplify it quite a bit, but leave it similiar enough to you case that it should be obvious what is going on. I'll do this by making the Silly structure only have 4 elements. The problem is that in converting things to slices you are not respecting who the owner is, you are "erasing" the fact that the slice belongs to the vector that is giving it, which the compiler will not let you do. If it confuses you and seems weird, it's because you are doing this in a very weird and strange way. The rust way is to not expose internals as much as possible, when you call `vec.as_slice()` you are exposing internals. In reality you don't need to do this. First you can hash `&amp;Vec&lt;A&gt;` as long as `A: Hash`. Also hash `(&lt;&amp;Vec&lt;A&gt;, &amp;Vec&lt;B&gt;)` as long as `Vec&lt;A&gt;: Hash` and `Vec&lt;B&gt;:Hash`, which are going to be true as long as `A: Hash` and `B: Hash`. This leads us to an impl much like the following: impl &lt;S: Hasher + Writer, A: Hash&lt;S&gt;, B: Hash&lt;S&gt;&gt; Hash&lt;S&gt; for Silly&lt;A, B, A, B&gt; { fn hash(&amp; self, state: &amp;mut S) { (&amp;self.a, &amp;self.b, &amp;self.c, &amp;self.d).hash(state); } } You can see working code [here](http://is.gd/X5FD1k). We can easily make it work for [more values](http://is.gd/pVfa55). There's one limitation: tuples with more than 12 elements do not implement `Hash&lt;S&gt;`, there'll always be a limit until variadic generics (or something that allows more generic tuple destructuring) appear, so not for this case. But for this case there's a simple solution! *[Tuples of tuples](http://is.gd/zvIMuf)*. --- The following part is all about a hacky way to implementing something kind of like limited variadic templates. You might feel it sucks that you can't use variadic templates, but there's a "hacky" way around it using something that I call cons tuple. Basically something like`(first, (second, (third, (last, ()))))` and you can unwrap the first element and keep the rest as a ConsTuple. You can then your "variadic-esqe" impls something like: trait ConsTuple{} impl ConsTuple for () {}; impl&lt;H, T: ConsTuple&gt; ConsTuple for (H, T) {} impl&lt;S: Hasher+Writer&gt; Hash&lt;S&gt; for () { fn hash(&amp;self, state: &amp;mut S) {} // does nothing for the end case } impl&lt;S: Hasher+Writer, H, T: ConsTuple&gt; Hash&lt;S&gt; for T where T::Head: Hash&lt;S&gt;, T::Tail: Hash&lt;S&gt; { fn hash(&amp;self, state: &amp;mut S) { let (&amp;head, &amp;tail) = self; head.hash(state); tail.hash(state); } } Then you could make a nice macro `ConsTuple!(...)` that gets a bunch of things and converts them to the (Head, Tail..) format above. I won't go into more detail than that, but I feel your example was building towards this kind of issue lacking variadics. --- The following part is just extra musings on solving a part of this problem that the std library solved. What would have we done if `Vec&lt;T&gt;` did not implement `Hash&lt;S&gt;`? Well we'd have created the implementation for it ourselves! Of course orphan rules will get in the way, but what we do is a "wrapper struct" that is a tuple struct that just makes one type be our own (without us implementing). So we'd get something like: struct HashableVec&lt;'a, T: 'a&gt; (&amp;'a Vec&lt;T&gt;); impl &lt;'a, S: Hasher + Writer, T: 'a + Hash&lt;S&gt;&gt; Hash&lt;S&gt; for HashableVec&lt;'a, T&gt; { fn hash(&amp;self, state: &amp;mut S) { let &amp;HashableVec(v) = self; v.as_slice().hash(state); } } Then you'd only change a single line in the hashing function in Silly's hash impl: impl &lt;S: Hasher + Writer, A: Hash&lt;S&gt;, B: Hash&lt;S&gt;&gt; Hash&lt;S&gt; for Silly&lt;A, B, A, B&gt; { fn hash(&amp; self, state: &amp;mut S) { (HashableVec(&amp;self.a), HashableVec(&amp;self.b), HashableVec(&amp;self.c), HashableVec(&amp;self.d)).hash(state); } } This should work with no orphan issues. Again here's a fully [working example](http://is.gd/tMBDSa).
The Vector3 was just an example. You could replace it with every other data structure. The function makes it clear that something is computed and might thus change if I alter a field inbetween 2 calls. With a .X getter, as the *v.length* one above, that isn't clear. And often one has to get an overview of the code first. If I have to dig down into the module to first see of that is a property or a getter, then the code is less readable. Especially when the language doesn't feature a full blown IDE with Intellisense like VS or, god forbid, Eclipse. Of course getters/setters don't rescue me from crappy code that I might encounter. But it makes the crappy code more readable in comparison to the same crappy code with properties instead. It's just one (or two, if we count getters and setters separately) less source of errors.
I will definitely take a look at that and see how much of it I can use. Thanks!
I'm still confused - are you shipping to Canada at all? If so the form validation for postal code needs to be relaxed, since it's not just a number here. I'd love to take a sticker off your hands. :)
To have `5.0*m`, I need to be able to implement the following: impl&lt;T, V, Num: Mul&lt;V&gt;&gt; Mul&lt;Dim&lt;T, V&gt;&gt; for Num I believe that such will be allowed but it looks like there are bugs with it at the moment (or I just haven't figured it out yet).
Yeah... I thought I had to order 50 when i made them so StickerMule would resell from my ordered quantity. At the time I didn't know you could submit a design to their Market Place for everyone to buy, and then I could have just bought one for myself.
Oh, sorry -- I had no idea. I'll turn off validation. It was just for automatic address printing lol
haha cool :) what's your address -- as long as everyone doesn't live in Europe then it'll be fine
One of the major purposes for properties is that the syntax looks the same as a field. This allows you to keep your API backwards-compatible in many cases where you'd otherwise have to replace a field with a method. For instance, I wrote a simple physics engine in Scala a while back. The objects had a 'position' field which users could assign to. That worked fine at first, but eventually I needed to implement an optimization (a bounding box tree) which required that users couldn't update that field directly or it would cause problems. Since Scala has properties, I was able to keep the public API the same by replacing the public field with a property. You couldn't do that in Rust. If the position field was public, you'd be unable to implement that optimization without changing the field to a method and breaking all the code that uses the library. For this reason, it's a bad idea to expose fields directly in Rust; instead you have to expose getters and setters, which are essentially the same as properties, just more verbose. I see your point about assuming that field accesses are very efficient. The best compromise might be to provide some kind of syntactic sugar for properties that's more concise than getters and setters, but that doesn't look the same as a field. I don't have any ideas for what that syntax would be, though.
Sweet!
Can we agree that nobody wants to write in enterprise java inside rust? &gt; But it makes the crappy code more readable Becomes a question of whether people should or will continue using crappy libraries in the instant when they discover that they are crappy instead of just dropping/forking them. 
That works great until you want to write `500us` for microseconds. :)
I'm generally not a friend of public fields/properties. Except for cases Luke x/y/z in vectors for example. Plus, if it does compute something, it should clearly be marked as a function. If we'd extend properties with extra syntactic sugar, for exampke foo#bar onstead oft foo.bar, then why not just use functions directly? Edit: sorry, I'm in my smartphone right now.
You got a PM (2 because I failed to remember my own house number ... I need sleep). Big thanks in advance :)
Good idea, I just did that.
Was trying to do SI Units in Rust as a learning experience last year, really excited to see this! Great job!
Criticism welcome. I took a bit of a different approach than what is in `std::old_io`. Namely, you choose the byte order with a type parameter. It's nice in that it reduces method explosion. Also, I've removed serialization for pointer sized types (`usize` and `isize`) because that seems like a bad idea intuitively, but I'm happy to be wrong! This also has a few nice examples of using QuickCheck. :-) (The motivation for this is that they tend to be really useful routines to have, and `io` reform is removing them from the standard library.)
Is there an RSS feed for these? Wasn't able to find one at `/rss` or `/atom.xml`.
Yeah no problem!
I really enjoyed [the presentation](http://thesecretlivesofdata.com/raft/) you linked illustrating how the algorithm works. It was illuminating. Thanks for working on this! I'm excited to try building a distributed system in Rust. 
Interesting. I'll save that post for tomorrow and see if I'm convinced :) I'm aware of some of the OO related problems in languages such as Java and C++. I do find inheritance to be especially messy, both due to the diamond problem and the difficulty of classifying things, and I'm more comfortable with a composition based model. I don't think that purely this or purely that is the answer, so I'm hoping for a healthy synthesis in the future. I guess that only time can tell what stays and what goes away.
Those stickers look fantastic!
For sure! I loved that presentation! It inspired me to try this. I think Rust has some great potential in distributed systems where anything can happen (and will!)
You can buy one from StickerMule if you want one. However, I misunderstood their order process and got 50 of them...needed to get rid of those :P
Aww, too slow.
Unfortunately it means you have to do manual garbage collection in the Vec. This is like going back to C! Probably you'd want to keep a free chain, just like implementing your own malloc library. Perhaps you'd need to compress the storage in the Vec from time to time, in case of fragmentation, like a compacting collector. Edit: I was wrong -- the implementation is neater than that (see below). Sorry!
Way more than that, but there's probably an order-of-magnitude more JS programmers in the city than there are people who have even heard of Rust at this point :)
Properties are a fix to the verbosity that exists within languages that mix data and function (the old way of doing OO). Objects are really "doers" they are things that do stuff. A good way of envisioning an object is like a separate machine to which you can send requests and then you receive responses, sure you don't have to worry about 404 and other such networking issues in this case, but the metaphor still applies. The object gives you an interface and you can only work through that interface. Think of reading a public member as "asking the object to tell you what the value of the member is" to which the object does what it's asked, setting the value is "asking the object to set the value" which it does. The problem is that most of the things we ask objects to do are through functions(), and accessing data members is drastically different. If you, in the future, want to change what an object does when a member is accessed, you'd have to change the interface. So it became good design to *only interact with objects through their methods* and not expose members directly, but through setter and setter methods. In the Java world this became overhaul. Properties are a solution that makes methods that appear to be member variables. By doing this you get an illusion of simplicity, but it's impossible to know what the consequences of code is going to be. Its basically a hack to get some of the previous element where simple members could be public from the onset. There's one patter in OOD: "Tell not ask", that is tell the object what to do, don't ask it how it is. Exposing members, even through getters and setters, generally is not the right solution. This brings back a concept from the 80s: separating verbs and nouns. Some objects (such as domain objects) are nouns, they represent some data or knowledge, other objects (such as services) are verbs: they do stuff, and can receive or give you back noun objects, but show no information about their internal. Rust instead grabs something from functional languages and such. The idea is that an object can be a noun (a struct, or enum) or a verb (impl) but that this two views are handled separately. It sometimes makes sense to have objects that can be both, but things are kept "clean". That is if you want to have dynamic dispatch, you have to loose access to the internals (you can't access the struct or enum that is under the impl) and can only access things through the trait's methods. It makes no sense, in Rust, to have an (trait) object with member variables, it just isn't possible the way the language is defined. Because of generics you don't get the normal "hit" in speed from dynamic dispatch and can have the compiler truly know what is the data underneath (it's simply hidden from the programmer). In short: * `get_foo()` and `set_foo()` are generally code smell. If the variables should not be altered directly, make a better name for what it's doing. Don't expose internals, period. Don't add ways to access/modify data unless it's absolutely necessary. * If you want someone to be able to manage data freely, given them a struct or enum. Use immutable references if you don't want them changing the data. Let the access the data directly. * Don't let people tell your object/trait how it should work, let your object decide the best way to do it without anyone else having to worry about that.
Matt gave a similar talk in SF back in November and it was very good :)
Thanks! I'm planning on using this in one of my projects.
If you are interested in more details, try running rustc with `-Z time-passes`. You will be amazed (and equally disappointed how much time is spent inside LLVM :).
&gt; If you made a unit system of fruits, what would you want the result to be of `Apple*Meter`? Obviously I would want it to be `Apple*Meter`. I don't see what is wrong with this. It should be possilble to mix arbitrary units because it usually makes sense. apple/meter^3 - how many apples can fit in cubic meter. apple/second - how many apples can you eat per second.
There's no reason not to learn C++. Learn it now or it will come to bite you in the ass later.
Rust's from scratch compile speed is reasonable (not good like Go, but reasonable, and IMO better than C++), but lack of incremental compilation means that in compile speed, Rust is currently inferior to even C++.
The point I was trying to make was that a significant number of projects use C++. Sooner or later you'll work on a project that uses C++. Haskell on the other hand... 
I can't upvote this as much as I'd love to. 
A bit more nice to what? The compiler? I don't think anyone is under the impression that it's a rockstar, and that's not a slight against the developers in any way. It's an old program that's been dragged through dozens of huge language changes kicking and screaming. I'm impressed that its as well maintained as it is! Seriously, shoutouts to all the rustc devs who have been working hard to improve it. Anyway, it's harshly stated because it's a total bummer that compiling programs takes so long. :( (although incremental builds wouldn't help with building rustc itself, as I understand it) 
I just don't want a culture where we so fillipantly talk trash. It's true that the compiler is not a person, but at the same time, this kind of comment is both mean-spirited and technically lazy. I'd much, much prefer a detailed explanation of why it's so painful. OP would learn a lot more, and we'd just all be better off for it. Furthermore, in this kind of situation, we have a new person, asking about the language, and a simplistic and highly unconstructive answer not only may give them an incorrect impression (we _are_ slow, but it's fixible _and_ we're not as bad as it could be), but also sets the tone for the kinds of criticism we do around here. That's all! I can totally empathize with the frustrtation, just want to nudge us in a direction that's not mean-spirited.
&gt; Enum structs take the memory of their biggest variant. All enums do. Incidentally, there are "enum struct variants", but there aren't "enum structs". An enum can mix-and-match existential variants (just an identifier with no associated data), tuple variants and struct variants freely. Your change hasn't altered the size of the enum at all. If you want to cut the size of the enum on the stack, you'll need to heap-allocate the contents of the variants and eat the associated costs. But yeah, not being able to use an enum variant as a type can be a real pain.
Well, maybe, but in that case C++ compile speed is worse than trash... toxic waste? [This article](https://ruudvanasseldonk.com/2014/10/20/writing-a-path-tracer-in-rust-part-7-conclusion) shows Rust compiling substantially faster. Rust will never compile as fast as Go because we have a powerful static type system and amazing backend optimizations from LLVM. If you want a language that sacrifices a lot for fast compiles, use Go :) Also it's simply not true that Rust has no support for incremental builds. The compilation unit is the crate. You can make crates as big or as small as you want. Managing lots of small crates is a pain, but so is managing header files and dependency-breaking in C++. The difference between C++ and Rust is really not so huge when you consider unity builds, huge template libraries in headers, and LTO. btw, check out [rest_easy](https://github.com/cmr/rest_easy) :)
To be fair, that's partly rustc's fault. We emit extremely verbose IR and count on LLVM to reduce it down. That approach has served Rust remarkably well, but in the long term, when we have a proper pre-LLVM IR in the compiler, we may want some "rough cut" optimization passes in the frontend just to speed compilation time. As I understand it, creating that verbose IR through the LLVM API consumes a fair bit of time before LLVM even gets around to throwing most of it away.
Can LLVM be fixed to throw it away faster? It just seems wasteful to do AST-&gt; custom IR -&gt; simplifying -&gt; LLVM IR -&gt; more simplifying. Can't you just have LLVM do all the simplifying instead? I get that it's not designed for that amount of LLVM IR, but maybe it can be optimized for those use cases upstream?
You need analysis to simplify, but since analysis time is proportional to amount of IR, multi stage simplification is in some sense inherent in the domain. That is, you do small analysis, simplify, big analysis, simplify, because that's faster than big analysis + simplify, saving big analysis for IR that can be eliminated by small analysis. LLVM certainly could do better here, but given the above dynamic having a simplifier in rustc also makes sense.
I agree with this. The rust docs still need a lot of work. A format more similar to manpages would be nice. Although, manpages have their job a lot easier. Documenting C functions is relatively simple compared to the rust docs.
It is a fantastic post. Everyone should read it.
[Obligatory](http://xkcd.com/859/) [xkcd](http://xkcd.com/541/). Anyway, I'm going to put one more character to increase your anxiety; this particular one is not curable unlike an opening parenthesis.)
When building on Linux, does this link against `libpcap`, and on Windows against WinPcap (which implements the `libpcap` API)? I just noticed that there is a reference to a `packet.dll` library that hangs out in SysWOW64, which made me think this was some built-in Windows stuff. EDIT: cool project, +1
I am also interested in this; it was rolling around my head as an idea for a startup company this morning. In my head it is some big fancy GUI that is helping you map, and manipulate the mapping between the C++ concepts and the Rust concepts, highlighting the parts and features that don't translate well, nudging you to gradually migrate pieces of your code... You do also have codebases that were written in an old C++ standard, and have maintained that for uniformity, i.e. iirc open cascade, the only really big piece of open source mechanical CAD code, was written without namespaces, templaces, etc.... I think it's pretty much "C with classes". If you can help people map their code in their HEAD by making the migration very visual, they will be willing to put up with much more coding pain. I imagine having something visual would also make it easier to pitch ports to bosses.
I didn't know if it. I'll check it out!
i'd be interested to hear any thoughts you have. I had a bash at starting a rust-inspired language that was inherently more C++ compatible; enough works to make it look possible but there's also a feeling of futility .. so many language options already and few gain a community.. so I haven't worked on it since the end of last year. https://github.com/dobkeratops/compiler Basically I figured: instead of struggling with a language thats' hard to transition - why not take certain features from C++ and Rust and blend them, for something where you can auto-translate a subset. Then we could have continuity. its' basically the lack of overloading in Rust and some choices on namespacing that makes life hard for C++ crossover; and the language has so many benefits besides that - macros, ADTs, expression-based-syntax, no headers, proper tuples,... I think it would be totally possible to have a language that bridges between them, its' just a question of whether or not enough people want it and can agree on such a thing... it seems in the Rust community, Overloading is regarded as a misfeature. Everything I want could theoretically be added as an alternate front-end to C++ (e.g. resyntax like SPECS+ a few new features), or as a fork of Rust (add overloading, full forward inference, relaxed namespacing), however I don't feel confident attempting to start such a complex fork myself working in someone else's source base. What I've written here so far isn't Rust compatible - but with enough work maybe it could be. `&amp;T` could be rusts' borrowed ptr, whilst `^T` could be a C++ reference. (currently what I have is closer to re-skinned C++ so `&amp;T` behaves like a reference). Thats' a little confusing but Rust has made its' choices. (i had made the suggestion for Rust, why not make `^T` a borrowed-ptr, to keep the sigils complimentary to C++ meanings -.. then a `^T` could be retrofitted to a C++ compiler as a 'transitive-immutable-non-aliased pointer'... but we just have to do this symbol swap ourselves) Still lots of details to iron out for a translator, like move vs copy. If existing in a vacuum, The feature set that I personally want could be simpler than Rust or C++ in some ways since with UFCS+overloading I could ditch the idea of classes or traits, and I'd be happier. (but I'd need classes for C++ translation.. foo(a,b) and a::foo(b) are of course distinct) The experience of Rust has left me more dissatisfied with C++, (having seen how certain parts can be different), but I remain a captive to C++ momentum (libraries, mature tools) - and there are parts of it I genuinely prefer (i.e. overloading) ; so I remain interested in Rust for many reasons. The appearance of UFCS* as a C++ proposal gives me a bit of hope that C++ will continue to evolve in a positive way (* D-style UFCS ) 
Well if I send you postage costs can we figure something out? I live in New Zealand.
Well, then, here's another tip: http://stackoverflow.com/questions/21538563/can-f-units-of-measure-be-implemented-in-ocaml The answer to that SO question has some good hints about implementing a feature like this (Abelian Group theory)... and why leveraging an existing typesystem might be insufficient.
Absolutely. You also can't cheaply split off or append two lists like you can a real linked list like the DList in the libstd.
You should look closer at that implementation, removing is much simpler than that.
The Peano numbers that I implemented and use to track powers are an abelian group (a ring, actually---I've even debated implementing the rationals for full field status, but probably won't). I believe that neither OCaml nor Haskell have a Turing complete type system, whereas Rust does, so we've got that working for us. Someone even implemented brainfuck in Rust's type system already.
Can't you create a new namespace by using a new section name like other packages do? Like '3rust'.
Yeah, PM me your address and throw a few bucks to blakev@email.com on paypal :) never shipped to NZ before.
PDF is literally the portable document format ("that most people have a PDF reader installed"). That's a pretty big advantage.
Wasn't there an RFC for changing that to usz though? Or you could do it like C++ did and reserve every suffix that doesn't start with an underscore (but that's kinda ugly). 
You can always do `struct BigEndian(());` which is a zero-size structure that can't be externally instantiated. :D
If I have an unspecified type, I could create a trait that limits the dimensions to the one already existant in that trait. E.g. I want any type, but it must have at most m^2 /s (e.g for a normalization or extraction method). Otherwise, bounded types come to mind. But mostly it's a cool idea. ;-)
It cleans up the methods but it does not really help to abstract away the endianness because it’s a pure compile time feature because you can’t instantiate any implementation of ByteOrder. I still would have to create my own ByteOrder-enum. enum ByteOrder { LittleEndian, BigEndian } struct EndianLessNessReader&lt;R&gt; { rdr: R, order: ByteOrder } impl&lt;R: Reader&gt; EndianLessNessReader&lt;R&gt; { fn read_u16(&amp;mut self) -&gt; IoResult&lt;u16&gt; { match self.order { ByteOrder::LittleEndian =&gt; self.rdr.read_u16::&lt;LittleEndian&gt;(), ByteOrder::BigEndian =&gt; self.rdr.read_u16::&lt;BigEndian&gt;() } } }
Even discovering that it's called UFCS basically requires following Rust RFCs or this subreddit…
What about a more common use case, like pixels/inch? I would want my unit systems to be composable.
What about something like this? pub struct VerbatimReader&lt;'a&gt; { inner: &amp;'a mut (Reader + 'a) }; pub struct ByteSwapReader&lt;'a&gt; { inner: &amp;'a mut (Reader + 'a) }; #[cfg(target_endian = "little")] pub type LittleEndianReader = VerbatimReader; #[cfg(target_endian = "little")] pub type BigEndianReader = ByteSwapReader; #[cfg(target_endian = "big")] pub type LittleEndianReader = ByteSwapReader; #[cfg(target_endian = "big")] pub type BigEndianReader = VerbatimReader; pub trait EndianReader { fn read_u64(&amp;mut self) -&gt; IoResult&lt;u64&gt;; // ... } impl &lt;'a&gt; EndianReader for VerbatimReader&lt;'a&gt; { // ... } impl &lt;'a&gt; EndianReader for ByteSwapReader&lt;'a&gt; { // ... } 
A great page with tons of nice papers by Andrew Kennedy (dude who did F#'s unit system): http://research.microsoft.com/en-us/um/people/akenn/units/index.html
Oh, does the type `Dim&lt;Meter&gt;` not guarantee the dimension to be meters?
The screenshot in the article has function definitions when auto completing. Is that an Emacs only feature, or can I get that in vim?
Okay, I see now. So they move stuff from the end to fill the free spaces as they go. This relies on no external references to the Vec indexes. Cursor keeps a mutable ref to the list, so I guess the borrow checker guarantees that. This is interesting. The borrow checker changes the rules about what is possible or sane to do.
Thanks for your interest Manishearth! Maybe I could consult you on some issues and concerns I run into? Having someone to even just talk about the protocol itself (and it's mechanics) would be quite helpful. As mentioned in the post, my primary concerns right now are: * Do I need some way of tracking what `RemoteProcedureResponse` (Or `Result`) is for which `RemoteProcedureCall` (or `ClientRequest`)? From reading the paper again I think the `term` will help, but I'm not sure. * Is a simple channel "good enough" for the consumer of the library?
In Rust mathematical functions are usually methods of numbers. [Here's a playpen example](http://is.gd/MqzGIc). The trait needs to be "imported" for its methods to be used, that's the `use std::num::Float` line. For your example you'd want `(input / pplPerBatch).ceil()` It's weird at first, but you'll get used to it.
This is not going to be the best answer to your question, but it's an answer. It used to be that trait objects were always behind a reference, either mutable or immutable. So you'd have `&amp;MyTrait` or `&amp;mut MyTrait`. These are implemented as fat objects: a vTable and a pointer to a struct. There were problems with this as you'd have to do Box&lt;&amp;MyTrait&gt; creating a double indirection. To solve this, dynamically sized types was introduced, and there's RFCs and blog posts discussing that. As for whether the identifier is being used as a Trait or a Trait Object depends on context. If it's used as a bounds on a generic type, it's being used as a trait. If it's being used instead of a generic type, it's a trait object. It's not ambiguous once you understand that rule.
No, the problem isn't compiling anymore, the problem is, that it segfaults when I run it… https://github.com/crabtw/rust-bindgen/issues/172
Yes, you need to track the acks. I suggest using a uuid or something. Channel based stuff is fine, though providing a way to set this up on TCP would be great too.
If compilation speed is really that high on your list of criteria, there are probably many other aspects of Rust that will also need to mature more before it is ready for you. Everyone probably has their own wishlist; my top two are generics-over-integers (forget what that is actually called), and a general mechanism for compile time specialization of computations (i.e. constexpr on sterroids or supercompilation). Someday I would like to not have to annotate what is known at compile time and what is not; that, by definition, is already known by the compiler.
Sounds like you want to do destructuring. You can get a mutable reference to both fields using something like this: let FlipTexture { ref mut first: first, ref mut second: second, ref flipped: flipped } = *this; You can leave out either `mut` to make them read-only.
The borrow checker allows a lot of boldness in the choices indeed; between guaranteeing the absence of aliasing and guaranteeing that references to stuff you don't own will live long enough, it sets you free.
I'm not terribly excited about a language that would be starting from scratch, unless you plausibly think it could mature fast enough to catch up with Rust. I am eager to have a tool I can actually use for what I do, and Rust isn't even all the way there yet. Are you proposing this intermediate "superset" language as a migration path from C++ to Rust? I am NOT on the level of a compiler writer, but it sounds more tractable to take either clang or rust, and fork it so that some of the most superficial parts are closer to the "other language." The syntax could be uglier than either language; the point would be that it reduces cognitive dissonance during the porting phase where your eyes and fingers are going between the two codebases, and it would be perfectly machine translatable to the language it is derived from. A social benefit would be that you would be seen as strengthening the community smoothing migration, rather than forking it.
rust-bindgen worked for me (well, 2 weeks ago anyway) using osx homebrew llvm 3.5.0
Woooah super jealous!
I encounter this a lot. Generally I either create a new class like `UpdateController` that owns both `Updater` and `Updatee`, so that Updatee does not have to hold it directly, and passes one to the other for modification, or I just wrap something in a `Cell` (or something similar). The first approach: http://is.gd/nSp1Ax Also, I think first approach generally leads to better composition of your data.
First: I'm not saying you're wrong, just that I perceived Gankro's comment differently. That being said: I wouldn't call his comment mean-spirited or lazy. While the comment could have been more detailed (but that's true for a lot of comments and not a problem), it clearly communicated that compile times are slow, but that the slowness is caused by the current implementation and not any fundamental reason (unlike C++). It also didn't attack (or even criticise) any person, and I think the compiler thick-skinned enough to take some criticism :) I guess what I'm trying to say is: Yes, it's important for a community to be friendly and constructive, but it's also important to apply the principle of charity to people's comments and not interpret any harsh words as trash-talking.
Has there been any thought given to intra-crate incremental builds for Debug builds? I don't think anyone is that worried about from scratch compilation time (5 minutes to build Servo is probably fast enough!), however in the edit-compile-test loop (most of which happen in Debug) large incremental compile times are really painful.
It's not as simple as that. The bindings generated can depend on the platform. For example, my project has working bindings for Mac and Windows, but I'm waiting for someone with a working rust-bindgen build on Linux to generate bindings for that platform. So any online tool will need a big disclaimer at the top of it.
1. Annotating what is known at compile-time is a statement of intention; it means that you guarantee that this will *always* be known at compile-time, and won't suddenly need to connect to a database (for example) 2. generics-over-integer is part of non-type template parameters in C++, so I would go for non-type parameterization? Not sure :p Not that this lack of support prevents implementing traits for all arrays for example, today the work-around is to implement the trait for some dimensions (1 to 20, for example). 3. I wish for variadics too, even in a restricted form, as this would solve the implementation of trait issue for tuples much like generics over integer solves it for arrays.
While composable unit systems sounds nice, can you think of an actual use? In the case of pixels/inch, it makes the most sense to me to just create a unit system with those units. One could also make conversion functions pretty easily. Say you have a `Screen` unit system that has pixels and inches, and you have `SI` as well, then you could implement something like: fn inches_to_meters(a: Dim&lt;Inch, f64&gt;) -&gt; Dim&lt;Meter, f64&gt; { Dim(a.0 * 0.0254) } If you want to do it by mixing an imperial system with a system including pixels, then you're able to have things like `pixels / horsepower` which strikes me as something you'd want to error out. If you can come up with a compelling argument for making unit systems composable, then I'll look into it, but I suspect that it would be quite difficult to implement, and it would require doing things very differently than I currently am.
Yeah, a supplement. Raft is usually implemented with nodes on different servers, a trait based way of letting the user select the backend for communication would be nice.
rust-bindgen wasn't used because it failed to parse the official Microsoft headers, probably due to Microsoft's C extensions.
Yes, this is something you can depend upon. On Unix-like platforms at least (I'm not all that familiar with Windows), the first argument is whatever the invoking program set it to, but the convention is to set it to either the full path to the executable, or the name of the command that the user invoked. It can be useful to look at this value if you have multiple programs bundled into one executable, with several names symlinked or hardlinked to the same actual underlying executable. Then you can look at the first argument, and invoke the correct behavior on that basis. This is common for collections of utilities intended for embedded platforms, like BusyBox. If you're not doing this kind of trick, where what behavior you invoke depends on the name you were called under, or using it for some other purpose (logging error messages), you can just ignore the first argument.
Yeah, my problem is already solved. But thanks for the link. 
If you provide a link I'd be happy to give it a try. 
Learning Rust has made me a _far_ better C++ programmer.
You can run the preprocessor to generate a monolithic header.. include.c #include &lt;stdio.h&gt; ...and then... gcc -E include.c &gt;monolithic_include.h (edit formatting) 
Agreed, it wouldn't be suitable for all purposes. The one time I used rust-bindgen I deleted about 2/3 of the output and hand-cleaned the rest. Much of the output was platform-specific crud that could be safely removed. For *that* use a playpen would have been great. 
&gt; You don't want a culture where people can state bad facts about the compiler ? I explicitly did not say that. I said I would prefer that they stated facts, rather than the lazy "it's trash." &gt; The new person got its answer They got their answer later in the thread, specifically because people were willing to elaborate rather than just make an offhanded "it sux" comment. &gt; (most likely because there are far more people working on increasing its speed) This is not true, actually. This is why I want a focus on technical details rather than just general statements, becuase people will have the wrong understanding.
&gt; it clearly communicated that compile times are slow, but that the slowness is caused by the current implementation and not any fundamental reason This is proably where we differ in reading, while it said we're missing a certain feature, it didn't actually say this at all. Even saying the sentence you just said would have been much, much more constructive, and barely more effort. As I said, I don't think the original comment was the worst thing ever. But I'd like to see us be better than the bare minimum.
You can tell that it should be called this way because http://doc.rust-lang.org/nightly/std/num/trait.Float.html#tymethod.ceil it takes `self` as an argument.
Ah, I'm very sorry, you're of course right. Don't know what I was thinking when I was writing that. I believe higher-kinded types are types with kinds like `* -&gt; *`, `* -&gt; * -&gt; *`, etc., while higher-rank types are types with kinds like `* -&gt; (* -&gt; *) -&gt; *` (rank-2), `((* -&gt; *) -&gt; *) -&gt; *` (rank-3) etc.
Right. OK, the world is sane again. :-) Frankly, I wish that we could just banish "higher kind types" from our vocabulary and stick to "higher kinded polymorphism" and "type constructors."
Thanks, that was helpful. Makes me wonder, are these kinds of optimizations covered by automated tests?
This is still static dispatch. It does not help if the endianness of the data is only known at runtime . To bad rust does not have references to trait implementations (ie I can't get a pointer to BigEndian as ByteOrder).
Hmm. You could still put this behind a trait object though: trait EndiannessReader { fn read_u16(&amp;mut self) -&gt; IoResult&lt;u16&gt;; } let rdr = if {big endian} { Box::new(EndianLessNessReader::&lt;BigEndian&gt;::new(blah)) as EndiannessReader } else { Box::new(EndianLessNessReader::&lt;LittleEndian&gt;::new(blah)) as EndiannessReader } let num = rdr.read_u16().unwrap(); I guess you'll incur the overhead of a vtable lookup for each call though.
Great, that it's that flexible. On that note, you may be interested in [this little abstraction](https://github.com/bjz/algebra). It's still a work-in-progress (mostly questions about how to work around limitations in Rust's type system), but we aim to abstract algebraic concepts like groups, fields, vector spaces, etc. in a common trait infrastructure for library authors. It would be really awesome if your library could fit in to eventually integrate with, say, [nalgebra](https://github.com/sebcrozet/nalgebra) or [cgmath](https://github.com/bjz/cgmath-rs).
Works for me: struct Expr; impl Expr { fn is_match(&amp;self, _: &amp;String) -&gt; bool { unimplemented!() } } fn get_expr() -&gt; Result&lt;Expr, String&gt; { Err("oh noes!".to_string()) } fn get_value() -&gt; Option&lt;String&gt; { None } fn main() { let func = |name| if let Ok(expr) = get_expr() { expr.is_match(&amp;name) } else { true }; if let Some(value) = get_value() { if func(value) { // work } else { // nada } } } This is why you should post a complete example. I've had to guess at details, and it's those details which are probably where the problem lies. That or you have a really old `rustc`.
I would *love* to hear from the cargo folks at the next bay area rust meetup. 
(for those curious, the code is here: https://github.com/rust-lang/crates.io) &gt; How's the performance been? The site isn't really under a huge amount of traffic that often, but in general the performance is quite good. The busiest time that I can think of was when crates.io was first released and it was on the front page of HN for awhile. From what I can remember the stats looked roughly like: * cpu: never above ~0.3 load avg * mem: constant ~40MB * response time: &lt;20ms (median) Under normal load the numbers look about the same. Looking at the console on Heroku right now we've got: * cpu: ~0.05 load avg * mem: 35MB constant * response time: 10ms Although we don't get a huge amount of traffic right now :) &gt; How many requests per second can it handle? I'm... not sure! I don't think it's been stressed much beyond 1k rpm, but I don't remember the precise numbers when it was first launched. In general I don't think we've been stressed at all in this respect. &gt; How robust has it been? To be honest, I'm not quite sure. I haven't set up a huge amount of logging, analytics, or tracking for the site. I get an email each day saying there was about 5 "Requested Interrupted" errors (which I have no idea how to track down), and other than that I haven't really seen much at all. I think that I've configured a panic to at least show up in logs or an email one day, but I have yet to see even one panic on the server. I think, however, this means the logging infrastructure is probably broken rather than the server never dying. In general though, it at least seems like it has turned out quite robustly. It is a relatively simple service right now to start out with, but I don't seem to see many surprises. &gt; I'd love to just generally hear more about the use of rust here, and cool &gt; parts and expected and unexpected pain points. In my personal opinion, I absolutely loved having a type system behind writing crates.io. I've written a number of Rails apps some years back, and I found it so much more comforting to have a compiler at my back. Now do keep in mind I'm probably a little biased on this point! I also was very careful to only use Rust as an *API server* and nothing else, as opposed to using it for server-side rendering of HTML. Rust has pretty decent JSON encoding/decoding support so it made it pretty easy to get this aspect up and running (to hook it up to Ember). I suspect thiings would have ended up a bit more painful if I had tried to write up a templating language in Rust for this! One of the cool parts I found was writing the whole "web server stack" from scratch. I got to write an implementation of cookie parsing, a cookie jar, encrypting/signing cookies, caching midleware, etc. It was pretty fun writing all this stuff from scratch (albeit somewhat exhausting after awhile). I will say that one of the most surprising aspects so far was that a day before releasing I finished a multi-hour-long bug hunt only to figure out that my cookie parser was broken. I was so used to that aspect of an app "just working" it was the last place I looked! --- Overall I'd basically say that I'm pretty happy having used Rust for the backend of crates.io. It was an excellent way to shake out some use cases in the language, ensure that some nice dependencies existed in the ecosystem, and in general have fun on a big meaty project. I'm not sure I would necessarily recommend the same fate on others, though. The site has a pretty big dependency graph and keeping up with master consumes a good bit of my time (and I'm even at an advantage so closely following rust already!). The other major point is that the infrastructure for analysis of the app is basically just nonexistent. There's very little error logging, error reporting, analytics, etc, which I suspect many other production sites would require right off the bat. One important piece to note, however, is that when I first started the other stacks like nickel and iron didn't exist yet (or at least weren't ready to go). I suspect that those frameworks may make this sort of infrastructure much easier (and it may already exist), so my advice may be a little dated. I hope that answers at least some of your questions, but feel free to ask more if they come up! 
&gt; I also was very careful to only use Rust as an API server and nothing else, as opposed to using it for server-side rendering of HTML. imo this is how webapps should be: define an API, and serve an API client as static HTML/JS/CSS.
&gt; The site has a pretty big dependency graph and keeping up with master consumes a good bit of my time (and I'm even at an advantage so closely following rust already!). Would it be possible to adjust the buildpack so that the Rust nightly version can be pinned to a specific date, configured via an environment variable? This might save you some effort and let you apply bug fixes and so forth without having to update everything to the latest nightly before being able to deploy.
check out the previous revision and paste it here?
You'd pass a reference to the local into the function. fn main() { let x = 0; f(&amp;mut x); } fn f(x: &amp;mut i32) { *x = 42; } Rust *can* do mutable global variables, but they're hard to use because they're rather unsafe. They're not really recommended. See also the [std::sync::atomic](http://doc.rust-lang.org/std/sync/atomic/index.html) module.
I was actually meaning on doing that for the next web tech meetup. /u/acrichto, you up for yet another talk? Not sure when this one might happen. Possibly April or May?
I admire your ... Tenacity. :)
Please let me know [what you think about the issue I posted](https://github.com/Hoverbear/raft/issues/1).
You can use struct to pass multiple arguments. Or define your function as method so it can use &amp;self.
In all seriousness, mutable globals are **dangerous**. Quite aside from making a program *significantly* harder to reason about and understand, they aren't protected from data races. If you want a mutable global, you're going to have to dip into `unsafe` code, or make explicit use of sync primitives. Rust is more verbose here, but it's because it's forcing you to confront the fact that mutable globals **aren't safe to use** by themselves. Some of this stuff changed recently, and I'm not up to speed, so I can't give you a code example. The other alternative is to use thread locals (see the `thread_local` module), which are much safer.
On the other hand, is crates.io actually a webapp? It seems rather document-oriented to me (i.e. the concept of a document sufficiently describes each view into crates.io), which implies that dynamically generated HTML would do just fine, without the added complexity of writing a single-page javascript app.
Oh, yeah, dealing with Rust on the march toward stability, that makes a lot of sense.
In Rust, mutable globals are not memory safe in general (and even thread local ones need additional restrictions). This is partly because Rust's compile-time guarantees for safe mutation rely on unique access (which the language can't guarantee for arbitrary globals, though IIRC Nim can?), and partly for other reasons (Rust's stance against "life before main", no destructors in statics, etc.), but what it sums up to is that if you really want to work with mutable global state, you'd better be prepared to break out some `unsafe` blocks. While it's *memory safe* to mutate shared globals in Java, it's still just as hard to reason about as it is in Rust. The *only* guarantee the JMM makes, without additional synchronization, is that a data race doesn't cause undefined behavior. All the other data races issues can (and do!) still happen. If there's a possibility that another thread tries to access the data at the same time, which is not infrequently the case, you're going to minimally want an atomic (which will also work in Rust). This isn't just about globals: in safe Rust, *all* mutation of shared state must be synchronized. And I'm quite confident that Java would have done the same if they could have done so without compromising on garbage collection or mutable state (and if you don't believe that, ask yourself why Java objects come with a monitor :)). As far as how you actually go about doing it safely in Rust: I already mentioned atomics. If you need a higher level abstraction, there is a very popular crate by kimundi, https://crates.io/crates/lazy_static, which basically does the unsafe dance I mentioned above to enable you to use types like `Mutex` (and other related types) in statics. In many cases, you should prefer a thread local to any of the above options, as it sidesteps data race issues and avoids synchronization overhead. There are a lot of different ways to do it, but there's one thing they all have in common: they're not necessary for your use case (as you noted in the second sentence!). Just return the tuple... or use a `&amp;mut` pointer if you want to take the scenic route :)
Those docs are way way too old if you're using a recent rust from [rust-lang.org](http://www.rust-lang.org/). The general recommendation is to use nightlies which have changed so so much since 0.10. You're looking for [`sqrt()`](http://doc.rust-lang.org/std/num/trait.Float.html#tymethod.sqrt) on the nightlies. Here is what you need to do: // Float is the trait which provides `sqrt()` use std::num::Float; fn main() { let f = 4.0f64; // `sqrt()` is now a method instead of a function. println!("{:?}", f.sqrt()); } [playpen](https://play.rust-lang.org/?code=use%20std%3A%3Anum%3A%3AFloat%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20f%20%3D%204.0f64%3B%0A%20%20%20%20%0A%20%20%20%20println!%28%22{%3A%3F}%22%2C%20f.sqrt%28%29%29%3B%0A}%0A%0A)
I found this explanation very helpful, thank you!
Sounds like a design issue, there are few cases where you really need mutable globals. If your functions all rely on the same state you might want to bundle them in a trait or a struct impl as you would use a class in Java.
Damn, didn't look at the version ... thank you :). I stumbled across a "problem". sqrt() is only possible for f64 numbers, but I need i64 in my function. I don't care about the loss in information. So I have to cast several times to get an i64 with several dummy variables and it looks so ugly. Any better way to handle this? Code snippet: let float_number = 600851475143_f64; let mut float_dummy: f64 = 0_f64; let mut float_dummy2: f64 = 0_f64; let mut number = float_number as i64; let mut lower_limit: i64 = 2; let mut upper_limit = float_number.sqrt() as i64 + 1; In a function used: float_dummy2 = number as f64; float_dummy = float_dummy2.sqrt(); upper_limit = float_dummy as i64 + 1;
 (number as f64).sqrt() as i64 + 1
interesting post, but going against dogma - have you seen the most recent Jonathan Blow video, with data-oriented features aimed at cache-efficient low level performance tuning (rather than any high level programming philosophy). https://www.youtube.com/watch?v=ZHqFrNyLlpA He's solved this with dedicated language features; some minimalists retorted that its' unecasery complexity -and advised "use getters and setters" - (which is the workaround you'd need in Rust or C++) - then it struck me that having Properties would get you some of the way. Properties are more general and have other uses, so I'd be in favour of adding them. The specific use case is where you start out with things that are clearly 'nouns' in your worldview, but you want to abstract and change the data-layout... the logical 'objects' might be distributed in memory in non-intuitive ways, and there's no initial plan behind this because its' done empirically based on profiler feedback (the optimum layout is achieved by experiment &amp; measurement, refactoring .. a major pain in gamedev that has motivated him to write this new language) 
Actually SOA is very strongly noun vs. verb separated. Sometimes you want static insertion (SOA requires this) and this is good. Sometimes though the having to load a whole different function stack per type becomes to expensive (think when 10 different functions all forwarding the type from a function that is only called every 45 seconds) and the cost of bigger code is bigger than the cost of dynamic dispatch. I've though of SOA in Rust myself, strongly inspired by what Blow talked himself of. That is code something like [#derive SOA] struct soable_struct {...} // iterating through x gives elements similiar to soable_struct // but its fields are actually references to elements withing // separate memory sections. let x := soa::vec&lt;soable_struct&gt;; I've been thinking about this and it should be possible, though some critical issues of interface are still being though about. The idea is, if you make an API offer functions recieve traits in the format: fn takesTrait&lt;T: some_trait&gt; f(t: T); then any user can choose to make it use dynamic dispatch by using `&amp;some_trait` as the type if they so wish.
Semi-related, but I remember that dlang got quite a lot of [good press](http://www.reddit.com/r/programming/comments/ppre5/the_new_d_online_forum_software_written_in_d/) when they released their new web forum written in D.
Each page should at least be served as a minimally formatted static HTML page, otherwise you're completely excluding the security/privacy conscious who're using the tor browser or who run with JS disabled by default. Sure use JS for making it pretty or for actual applications that have been shoehorned into the browser like googleapps or whatever, but depending on JS for base functionality is extremely unsatisfactory.
&gt;&gt; This said, if someone wants to write a libpcap backend to libpnet, that would be lovely. &gt; &gt; I guess this could be a good compatibility fallback? That's what I'm thinking of, yes. Would be particularly good for porting to new platforms - you'd only need to get `libpnet` compiling, and not have to worry about subtle differences in the method used to work with the data link layer (since libpcap is probably already working there).
Two programs are not equally safe just because they are both written in the same language. There are a lot eyes on Linux than a random webapp.
Cool, I've been looking for a good forum software!
The point I was trying to make is that properties are too expensive/unpredictable for the world of the people that work with SOA. Properties themselves are not SOA friendly (since some properties don't exist concretely and make actually consume multiple separate pieces of memory). BTW when I made a referenc to the "cost you can read" I meant run it on the CPU. SOA itself was a surprising realization that wasn't obvious unless you actually measured wall-clock and CPU clock. The point is that people need a way to choose things. Johnathan Blow's language proposes solutions that use static abstractions that have 0-runtime cost. Properties are not one of these. So to be safe I'd actually keep data (structs and enums) separate from interfaces (traits). Structs, tuples, enums, primitives are very SoA friendly, and I can make special SOA-friendly containers that will split them. Traits and such are assumed to be *not data* but doers. I find that using methods in SoA is, though not bad, a danger: functions can be used to guarantee static dispatch while methods make no such guarantee.
Sure, but I wouldn’t count on that any more after the last year. I’m also not saying I would do it, but it’s more probable that somebody uses well-known exploits in your dependencies instead of trying to trigger a memory corruption in a custom closed-source c++ webapp.
Windows exposes a different API for this than the traditional unix argv, but `std::env::args` abstracts over it to always provide the unix interface.
Or even `Result&lt;T, E&gt;`, where if the operation fails it's an `Err(E)` and if the operation succeeds it's an `Ok(T)`.
Ah, UDP is fine too. Nah, I was just giving examples of things the interface could abstract over. Usually you'll want a TCP or UDP socket, but some people may even need a more complicated scenario so it's nice if you have it work over a `Channel` trait (or `Sender&lt;T&gt;`, `Receiver&lt;T&gt;` where both are traits, not the objects from the stdlib), and then provide implementations of the trait for a few common types like `UdpSocket`
&gt; 5 "Requested Interrupted" errors (which I have no idea how to track down) This is just background noise. It happens any time the client closes the socket before the server is finished sending the page (e.g. because the user hit 'stop'.)
why so much memory? 35MB seems high. 
Definitely! I thought there was actually a buildpack that already did that but I can't seem to find it. I think that in the long run this is what will happen primarily for being able to fix bugs. On the other hand rebasing over 1 month of Rust changes would be awful, whereas rebasing over 2 days isn't so bad (most of the time). It at least keeps me motivated to update it!
That was my guess as well, but it seems odd that it would show up specifically in the logs. I figured something like that would be auto-filtered out by default. We are running a custom HTTP backend called [civetweb](https://github.com/sunsetbrew/civetweb) which may have nonstandard behavior though which could also explain it.
That's a good question! I'm not sure if Heroku's console is reporting individual or total memory consumption (we have 3 dynos running). I haven't exactly put any effort into optimizing memory usage, however. One contributing fact is that I think we spin up an HTTP server with 8 threads and use 3 helper threads for the database, so that may contribute to the overall amount.
Talking about Rust is one of my most favorite things to do! This sounds like a good idea to me :) (I'll also be at the meetup in Februrary)
Yeah that's a very good point. I think there are techniques to structure your app as a JS client thing and then precompute renders on the server side -- for something like Google Groups, these might as well be static pages cached forever.
On that, the problem with Blow's solution is that it's *implicit malleability* which makes it hard to know what is going on. I already said my opinion, which was that it'd be nice to allow pattern destructuring on struct members so something like: struct inner { a: i32, b: i64, } struct outer { x: i32, y{a, b}: inner, } The above would make `outer.a`convert into `outer.y.a`. You still get the inlining but having to "import things" explicitly makes it easy to guarantee that there will be no conflict of things. You also know all the members of `outer` by just reading it's definition, and don't have to see what `inner` has. Jonathan Blow's using patter would mean that I'd have to jump to the other one. That's malleability, a *static interface* that doesn't reflect some details of the inside. Rusty thinking isn't against that, but it is for making this things explicit. The idea in SOA that makes properties attractive is that you could have an object that would show you were things are, but instead we could have something like: trait SOA { type SOAAccess; // special type that is like the object, but with references // other things that are used to implement SOA structures. } [#derive SOA] struct Split{ a: (i32, i32), b: f64, } Then you can make a `soa::vec&lt;Split&gt;` which creates a vector that stores to separate lists of `(i32, i32)` and `f64` and joins them to give you a `Split::&lt;SOA&gt;::SOAAccess` which looks something like `struct _&lt;'a&gt;{a: &amp;'a (i32, i32), b: &amp;'a f64}`. Notice that you'd use it like a Split, except it's members are references, which makes it explicit (when you look into a debugger) that you are actually accessing things in some other place of memory. If you make a function that iterates through only `Split::a`the compiler would have a function that iterates over only a single array of i32s (eating them by pairs). I'm not wanting to poop on Blow's language, I find it interesting myself. But understand that Rust is not that language and why, different choices were made. We will know which ones are the right ones with time.
Tldr: Expose behavior, not state
Yes, libraries [like React](http://maketea.co.uk/2014/06/30/building-robust-web-apps-with-react-part-4.html) are designed to render both server-side and on client side.
&gt; I can't pass `Vec&lt;u8&gt;` to C as `*mut u8` [I'm pretty sure you can!](http://is.gd/gtZlkP) &gt; and I can't give its ownership to NSData. That's true: (Obj-)C has no idea about ownership and all that. But it can already mutate it (albeit unsafely) if you give it a raw pointer.
Can "pass ownership of this data to a non-Rust function" be implemented in general, such as with a trait? What about getting ownership back?
That's what I use to pass ownership to C and back: (**edit: [it's now a crate!](https://crates.io/crates/capi/)**) pub unsafe fn to_c_owned&lt;T&gt;(give: T) -&gt; *const T { let obj: Box&lt;T&gt; = Box::new(give); let ptr = std::mem::transmute(&amp;*obj); std::mem::forget(obj); return ptr; } pub unsafe fn from_c_owned&lt;T&gt;(take: *const T) -&gt; T { let obj: Box&lt;T&gt; = std::mem::transmute(take); *obj } and then I create `foo_create()` function that returns `to_c_owned(foo)` and `foo_destroy(fooptr)` that calls `from_c_owned(fooptr)` and that makes Rust take ownership back (and free everything as usual).
I was thinking about looking at the internals of the given type (Vec has a [`NonZero&lt;*mut T&gt;`](http://doc.rust-lang.org/src/collections/vec.rs.html#139-143). If you call forget in a Box, will it also forget its, well, contents? What if `give` had allocated many chunks of memory in different places? Or has a field storing a `Rc`, etc.
Via google search, but I can't remember the search term I used. Tried every combination I could remember (rust sqrt, rust sqrt(), rust how to sqrt, rust square root etc) but couldn't find it. Sorry :/. /edit maybe I got it via http://forums.xkcd.com/viewtopic.php?f=11&amp;t=109031, where the 0.10 docs are linked. This page shows up as the 2./3. search result when using the above terms.
I'm assuming that if you forget in one place and then transmute back to an owned object in another, then everything will be freed properly.
[Ember is going to support that too in the future](http://emberjs.com/blog/2014/12/22/inside-fastboot-the-road-to-server-side-rendering.html)
Wow, thanks for the answer! That's exactly the kind of stuff I was hoping to learn. I didn't realize crates.io was on heroku. What's the deployment process like? Is there a public buildpack you're using? Are you just deploying a static, all-encompassing binary, Go style? Pulling together your answers, it looks like rust is serving 1000rpm at ~10ms responses on 3 dynos? That's certainly better than my rails apps! Are they 1X dynos? What's the 95% response time? (Not sure if you're aware, but you can see that at http://log2viz.herokuapp.com/app/your-app . I *think* that would work out of the box for you, since it's based on heroku's router logs, and not any app server logging.) &gt; I think that I've configured a panic to at least show up in logs or an email one day, but I have yet to see even one panic on the server. I think, however, this means the logging infrastructure is probably broken rather than the server never dying. I'm confused here: if the server panicked, wouldn't that mean it stops serving requests and would be quite evident? Or do you have it configured to be restarted if it dies or something? &gt; I'm... not sure! I don't think it's been stressed much beyond 1k rpm, but I don't remember the precise numbers when it was first launched. In general I don't think we've been stressed at all in this respect. Hmm... have you never wanted to `siege` or `ab` it? That seems like it would be fun. :-) Pull up log2viz as I showed above, and then throw requests at it and see how the response times / load are! Thanks again for the detailed response!
I think Haskell naming is really unfortunate, Rust at least say which is the "main" value. Also, `Ok` and `Err` are incredibly short. Also, seeing a `Result` and knowing it's about errors is very good. If anything, it's `Result` that is poorly named, should be `MaybeError` or something more direct. But one could perhaps talk about `Value` and `Otherwise`? Well it doesn't look good. By the way, the code your linked makes more a case for the branches of an enum to be valid types themselves rather than for renaming `Result` or making it more broadly applied than just errors.
I don't use vim much personally, but it looks like there is an experimental [extended complete feature](http://i.imgur.com/t0W2NbY.png?1) added by [rsw0x](https://github.com/rsw0x). You need to add the following to .vimrc to enable it: ``` let g:racer_experimental_completer = 1 ``` I guess it's experimental for a reason so YMMV
You should be able to take the method as a function item
Wow, high praise indeed! Thanks v much
Good call, the docs were lacking. I've added a couple quick examples to the block module documentation: http://ssheldon.github.io/rust-objc/objc/block/index.html
Such as...? I can't think of any shared-functionality that all A-or-B relationships have that isn't covered by match and if-let.
&gt; Hmm, what's the implementation of your rust_vec_free? Second function in the [comment below](https://www.reddit.com/r/rust/comments/2v3yyx/using_rust_from_objective_c/coecwt3). It seems that `into_boxed_slice` would reallocate and copy memory, and that's something I wanted to avoid (if copying is an option then it's better for me to call `libc::malloc()` and give that to C).
Either in haskell started as some sort of general purpose structure but when used, it's quite counterintuitive that fmap maps the function to Right and leaves Left unchanged. I like Result and Ok more but I think Err is a little too strong because when speaking about errors you normally mean something that should not happen and will crash the application but a failed result is in many contexts quite normal. I think, Other is a good name and maybe Failure/Fail. On the other hand it is just a minimal variance in the meaning of words and does not justify renaming a stabilized and commonly used identifier, so I am ok with the current version. Please don't create own versions of Result except for special cases. Use the standard library as a common, cross-library and consistent way of dealing with alternative results.
What other thing could fmap do, given the defitinition of Functor in Haskell?
What you'd call an Error in other languages is a Panic in Rust. ;)
That's kind of like saying, "I can't think of anything you can do in language X that you can't do with the lambda calculus." :P The difference is one of degree, I guess... [There are lots of convenience methods and trait impls defined for the `Result` type in the standard library.](http://doc.rust-lang.org/std/result/enum.Result.html) I imagine the GP is saying that similar methods would be defined for a hypothetical `Either` type.
Wonderfully thorough docs. Rustless is quality.
&gt; Programming in modern C++ I never saw a single buffer overflow in my code, it's very different from the old days. You may not have buffer overflows but you can still have use-after-free with references (even when they come out of smart pointers), and iterator invalidation on the apparently safe containers like `vector`. These may be harder to exploit than a classic stack smash, which today wouldn't work anyway with no-exec stacks. With sufficient motivation, though, [extremely limited forms of memory corruption can be exploited](http://phrack.org/issues/57/8.html). Rust really is different, because *any* undefined behavior in the safe language is a compiler or language bug. We [aren't](https://github.com/rust-lang/rust/issues/22073) [doing](https://github.com/rust-lang/rust/issues/22040) [so](https://github.com/rust-lang/rust/issues/22008) [great](https://github.com/rust-lang/rust/issues/21407) [lately](https://github.com/rust-lang/rust/issues/20314), but it's still early days. It will be a long time before I'll trust Rust's type system alone to sandbox actively malicious code. Still, the guarantees you get today are much stronger than C++ can deliver. &gt; BTW, even if programming in Rust (or in Java) you should still wrap your application in a system firewall, such as AppArmor I totally agree. In Servo we are pursuing a defense-in-depth strategy with unsafe code auditing, custom lints, OS-based process sandboxing, and more on the way.
Keep in mind that `Vec` is *very likely* allocating its memory on a completely different heap to the Objective C runtime. Even if you could convince NSData to take it, it'd never be able to free it. Unless you can pass a custom deallocator as well...
I agree. `Either` in Haskell was seemingly designed with error handling in mind, and yet the name does not reflect that. `Either String Int` is totally different than `Either Int String`, and the way the Monad instance for `Either e` is defined, it is used for error handling 99% of the time.
&gt; Tntnet sticks to the safe APIs, such as C++ string and vector. You're only in danger of creating a buffer overflow bug when you go low-level for some reason. This is not so different from Rust unsafe. Programming in modern C++ I never saw a single buffer overflow in my code, it's very different from the old days. Unfortunately these aren't safe. As kmc says, it's easy to get iterator invalidation and use-after-free, and, anyway, the `[]` operator is unchecked, so buffer overflows can still occur unnoticed. I think it's worth noting that never seeing a buffer overflow doesn't mean that there isn't one, it could easily be that there are latent non-obvious memory safety problems, which take malicious input to trigger. (This isn't meant to disparage you at all, it's a general property of a lot of C/C++/`unsafe` Rust code.)
&gt; Result is the natural thing to return when there are two meaningful possibilities. I think it’s not, precisely because: &gt; Often the possibilities will be "success and here's what you asked for" or "failure and here's why it didn't work" but not always; in the latter case the name "Err" for the second option is a little weird. `Result` makes sense for "success or failure" kind of things. For other things, even if they happen to be isomorphic to `Result`, you may be better off writing a custom enum type with more meaningful names. Others have already commented on the `Either` enum type with `Left` and `Right` variants that used to be in Rust’s standard library and was removed. &gt; For instance it's not an [error](http://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html) if you get a VacantEntry. Yes, exactly.
&gt; What's the deployment process like? Currently it's just me running `git push heroku-prod master` locally I tried to setup the auto-integration awhile ago (push to a `prod` branch and it auto-deploys) but it didn't quite work out for me. &gt; Is there a public buildpack you're using? Yes! https://github.com/alexcrichton/heroku-buildpack-rust It's pretty ancient though, and there's lots of improvements I'd want to make to it at this point, not the least of which is pinning to a specific Rust version. I might also recommend https://github.com/emk/heroku-buildpack-rust which may be better maintained than this one (which was basically written just for this site. &gt; Are you just deploying a static, all-encompassing binary, Go style? Basically, yeah. The site is just built with `cargo build --release` and then we just run the server directly out of the `target` directory. &gt; Are they 1X dynos? Currently have have 2 web dynos and 1 worker dyno. The worker currently just handles collecting statistics about downloads (e.g. aggregating all stats). &gt; What's the 95% response time? It looks like it's 40-50ms, sometimes up to 80ms. &gt; Not sure if you're aware, but you can see that at http://log2viz.herokuapp.com/app/your-app Oh man when I checked that out we were all the way up at 13rpm! Thanks for the link! &gt; I'm confused here: if the server panicked, wouldn't that mean it stops serving requests and would be quite evident? Or do you have it configured to be restarted if it dies or something? I believe Heroku auto-restarts crashed servers, and a panicked server would probably take down the whole thing which would just get auto-rebooted by Heroku (in theory). I don't really have evidence this works one way or the other though! &gt; Hmm... have you never wanted to siege or ab it? I tried it out from what was a relatively decent network, and here's the results I got: https://gist.github.com/alexcrichton/80c18b0fe068f641c415. It looks like the latency from the computer I'm testing it at is much higher than reported with Heroku (or maybe it just means an odd network or time for routing?). The peak on the log2viz console looked to be about 1k rpm.
I'm normally a Windows-only dev (at my day job, anyway), but (partly because I want to keep my Windows machine free of the whole bastardized posix-like thing) I have never touched Rust on Windows... I know that in, say, C#, you don't get that first argument--the path you used to call the program. You're saying that you would still get it in Rust?
Isn't that more of an argument that &lt;Entry,VacantEntry&gt; shouldn't be expressed as Result? Result has the advantage that it is so specific that a special lint for them makes sense, which is not true for Either.
Point to one method on Option that isn't covered by match :-)
Well this is not ObC specific. For every FF-interface you need to expose things in the same way. Especially if you want to transfer ownership you usually want to expose a custom deallocation function as well. In an object oriented language you can simply wrap the Rust type with a class and call the deallocator in the destructor of it. It’s a pretty common pattern if you call into some C-code from a higher level language and works most of the time (you of course need to be aware what guarantees you have when and if the destructor is called).
&gt; [1] Whats frustrating is that rust solves so much of what we do need (I've frequently commented that I like Rusts' handling of globals, and immutable default) - and only a few simple additions on top of whats' there would make it suitable. I don't think these additions would damage the rest of it. You'd just use the features you need. I agree with this completely, in that Rust could be extended to do this. Sadly we won't be able to push this discussion until post-1.0 which is the big aim of Rust right now. The idea is to have things such as lifetimes, the basic std lib and other issues well handled, then we can begin building on top of that. &gt; [2] In this specific case, i've mentioned how Properties would be a general purpose tool that could help (in conjunction with Macros) ... they'd offer a different way of addressing the same issue. My whole issue with properties is a simple one. A property is a thing were what appears as data access is actually a function call. I can live with function calls that are actually just data access (inlined functions) because they'd be at least as good as functions. Data accesses that are actually function calls are not good, they'd be worse than the worst I could expect (lets not even assume property were reading a variable has a side effect that can panic). OTOH I think that accessing a struct member actually altering data on a piece of memory that is far away from the other member data is a perfectly valid thing. This is I don't mind the idea of having members actually aliasing something not immediately "within" (in the conventional way of thinking) the struct. Properties do not do this though, properties just mean that the following code: s.x = v Can do anything and is completely unpredictable.
IIRC, you can disable that behaviour by passing "-- --nocapture" as argument.
Why was this downvoted o.O
Indexing via [] is one of those low-level things when you have the `for (element: collection)` loops.
&gt; Rust really is different, because any undefined behavior in the safe language is a compiler or language bug. Any undefined behavior in the safe subset of C++ is a compiler or library bug. The idea of using the safe C++ APIs isn't new, it was expressed by Bjarne a long time ago and repeated ever since. And you know what? It works. While Rust *is* helpful in limiting you to a safe subset by default and helping you use the real pointers safely instead of resorting to garbage collecting smart pointers and by-value semantics, the real difference I see as a C++ programmer is the thread-safety constrains. The idea to limit every thread to it's own memory is what got me to Rust.
Yes, direct indexing in a `for (i = 0; i &lt; len; i++)` is low level, but vectors have other uses than just linear iteration: doing any sort of random access requires some sort of "indexing" and most of the default ways are entirely unchecked. Also, many of the high-level functions in the `algorithm` header do little to protect against overruns. E.g. [`copy`](http://en.cppreference.com/w/cpp/algorithm/copy) takes three arguments: the first two are the start and end of the input iterator and the third is the start of the output. There's nothing about the end of the output. If one uses this to overwrite the elements in a `vector` or a stack buffer, there's nothing stopping a buffer overrun if the input range is longer than the space allocated for the underlying buffer. Similarly, just on the first screenful of [the docs](http://en.cppreference.com/w/cpp/algorithm), `equal`, `copy_n`, `copy_backward`, `move`, `move_backward`, `fill_n`, `transform` and `generate_n` all suffer from the same problem. Of course, the improvements in modern C++ likely reduce the occurrence of such problems, but they don't remove it entirely.
That's right, it's easy to shoot yourself in the foot, nobody is saying that C++ isn't full of unsafe APIs. What I'm saying is that there is a safe subset. For example, `for (auto&amp; el: collection) vec.push_back (el)` is much easier for me to understand than the `copy` and it will never overflow. Maybe the difference I'm seeing between the "old C++" and "new C++" is actually the reflection of this safe subset forming itself in my mind.
1. Nope. That second one would be a trait object (though you'd need `&amp;Digest`, which does dynamic dispatch, and the first is just static.) 2. No return type is the same as `-&gt; ()`. 3. https://github.com/rust-lang/rust/issues/21859 :( Sorry!
In this case it is the same thing as `fn do_hmac&lt;D: Digest&gt;(digest: D)`. Bare traits can't be treated as types usually (since they're unsized), though you can put them behind a pointer.
.as_mut_slice() is redundant (and deprecated).
[the difference between fn `do_hmac&lt;D: Digest&gt;(digest: D)` and `fn do_hmac(digest: Box&lt;Digest&gt;)` (or some other pointer) is that trait resolution is compile time for the former, and runtime, via vtable, for the latter]
The `where` syntax came way later (to be more general to support adding constraints to associated types). I guess no one wanted to change all the existing generic code to remove the old-style trait bounds, and people are fond of it for simple cases.
You say tomato, I say tohmato. They are different ways of stating the same thing. Your answer is more 'rusty' though.
Very nice work on that readme! I will definitely play with rustless a bit
You should [submit a PR](https://github.com/teepee/arewewebyet) to [arewewebyet](http://arewewebyet.com/ ) to add rustless to the list!
`fn foo()` would correspond to `void foo(void);` in C, but there is `fn foo(_: ())` as well. I find that conflating the unit type with void and vice versa is more confusing than illuminating. (Other pet peeves around `void` also include `return void_returning_f();` which is allowed, whereas `void_taking_f(void_returning_f())` isn’t; this all makes generic programming in C++ more painful than it could be.)
Personally I use the latter form only if there are few bounds. If it gets more complex or if I have to split lines I switch to the former form.
Plus, the where syntax is more verbose for simple bounds.
Thanks for your comments!
A release build of `image` takes roughly one minute on my computer, that is quite a lot for some rudimentary image processing.
One API design thing: You could take the "hint" and "default" fields of the Port struct and make them members of the Control* PortDescriptor variants - that way the user doesn't need to worry about them when they don't have a control port. (Although that is two enum variants with the same data, which is slightly ugly...)
There were some halfhearted attempts to change it, but the community was against it. Personally, I agree with you, the `where` syntax is way nicer and the existence of the old syntax is confusing.
The last part already works, the syntax is match value { [0, 1, n..] =&gt; { println!("{:?}", n); } _ =&gt; {} }
Honestly I never ever searched for a “late” return statement. It is at the end of the function anyway, not that hard to find. On the other hand Rust still allows for early returns and requires a explicit return statement in that case. Omitting the return statement in the usual case thus provides a great too to spot early returns.
You can write equivalent code in Rust without `unsafe`: fn main() { let mut v: Vec&lt;i32&gt; = Vec::with_capacity(1024); for _ in 0..v.capacity() { v.push(0); } for it in &amp;v { v.push(it + 2); } } And the compiler identifies exactly what's wrong with the C++ version: &lt;anon&gt;:9:13: 9:14 error: cannot borrow `v` as mutable because it is also borrowed as immutable &lt;anon&gt;:9 v.push(it + 2); ^
Explicit return is really annoying in closures. For example, it was a major pain in JavaScript before ES6 arrow functions were introduced—`myArray.map(function(x) { return x * 2; })` is gratuitously verbose, even without the `function` keyword. Once you have implicit returns somewhere in your language, you might as well have them everywhere for consistency's sake. The fact that it makes code less verbose is just an added bonus.
One misconception is that implicit `return`s mean searching for them in a function body - an implicit `return` can still only happen at the end of the function, so rather than looking for a trailing return statement, you look for the trailing expression. If you have a function, you know exactly where to look for that. Only any `return` that is _not_ the trailing expression is an early return, and requires the use of the keyword.
Scala uses Try&lt;T&gt;. There is no type variable needed for Error since it is always a Throwable. The advantage of Rust result is that the error can be polymorphic. Try could be a subclass of Result. type Try&lt;T&gt; = Result&lt;T, Error&gt;;
This is being called "isomorphic JavaScript" by all the cool kids.
Small nit: `expr;` is a `stmt`, no?
&gt; Interestingly the result is less bogus with the C++11 for (int i: v) loop. I wonder what's different there. I believe the difference is in the `end` iterator. Instead of for (std::vector&lt;int&gt;::iterator it = v.begin(); it != v.end(); it++) { C++11 is doing for (std::vector&lt;int&gt;::iterator it = v.begin(), e = v.end(); it != e; ++it) { Anyway, Rust is cool. Glad I'm tagging along. : )
&gt; The bounded synchronous channel can do this, but has the peculiar property that messages may be dropped if the buffer is not empty and the sender drops the connection before the receiver reads them That's really surprising behaviour. Is that really the intended design? The language in [the API docs](http://doc.rust-lang.org/std/sync/mpsc/#disconnection) is pretty vague, so I can't tell from a quick look. The [recv documentation](http://doc.rust-lang.org/std/sync/mpsc/struct.Receiver.html#method.recv) seems to imply that buffered data will still be returned, but it will return errors rather than block if the sender has gone away (but it only mentions Sender, not SyncSender).
`native` is gone. `green` is gone. There can only be one: `io`. (you may want to check out https://github.com/rust-lang/rfcs/pull/230 )
I think this is an area where allocators were meant to help, but they haven't been added to the language yet in a meaningful way?
Sure, but so can be an explicit return ;) return if x { ... if y { expr1 } else { ... expr2 } } else { Lots of stuff... expr3 }; So thats not a problem of implicit returns, but of the expression-based grammar in general. If you have such involved code, then thats an issue of the code being badly structured, and not of the language having implicit returns, imo.
Ahhh, that's where it's all gone. Still can't see a replacement for native::start though. Can't see `#[start]` is meant to be handled. I've fallen back on a normal style main and some different setup for now which works around my problem.
 #![feature(start)] #[start] fn start(_argc: int, _argv: *const *const u8) -&gt; int { return 0; } http://doc.rust-lang.org/book/unsafe.html#avoiding-the-standard-library has some info as well. 
I can't see anything in the [current docs](http://doc.rust-lang.org/std/sync/mpsc/fn.sync_channel.html) that reflects that behaviour. All it says is: &gt;Like asynchronous channels, the Receiver will block until a message becomes available. These channels differ greatly in the semantics of the sender from asynchronous channels, however. &gt;This channel has an internal buffer on which messages will be queued. When the internal buffer becomes full, future sends will block waiting for the buffer to open up. Note that a buffer size of 0 is valid, in which case this becomes "rendezvous channel" where each send will not return until a recv is paired with it. &gt;As with asynchronous channels, all senders will panic in send if the Receiver has been destroyed. 
That's C terminology, in programming language theory void is the `!`, and this appears to be the favored meaning in Rust community.. So perhaps it's better to say, an unspecified return type means "unit", which is like "void" from C.
Your `Result&lt;i32, Void&gt;` seems very neat... any variant that has a `Void` anywhere can't be created. If dropping unused variants were implemented, `Result&lt;i32, !&gt;` looks ok. It seems OK to add syntax because Rust is a systems level language that cares how the types are represented in memory (so removing impossible cases shouldn't be done only as an optimization step).
We are purposely leaving the rust memory layout undefined so we can do these kinds of tricks right now. For example, `Option&lt;T&amp;&gt;` gets compiled down into a `T*` pointer, where the `None` variant is represented as `0`. We might also be doing the same optimization with `Result&lt;T&amp;, ()&gt;`, with the `Err` variant also represented as `0`. So this is just continuing the tradition.
Interesting, thanks. This would mean that Chromium becomes a dependency of my program, right?
Actually one could argue that "void" in C is a misnomer, as semantically it'd be closer to !, "never returns". In the context of algebraic types, "unit" is a type that has only one value, so it can be said to contain no information, zero bytes. Whereas "void" is even less than that, it is a type without any values, which is kind of an oxymoron, therefore stating that something never returns. (Or when passed as a parameter, it states that the function can never be called.)
Wrong subreddit.
Wow this really happens. Please visit: http://www.reddit.com/r/playrust/
/r/playrust.
You are right. I remembered incorrectly. The behaviour is in fact documented here: http://doc.rust-lang.org/std/sync/mpsc/struct.SyncSender.html#method.send
Could you please elaborate? Getting the index of an element which isn't there is arguably an error. We have some precedent in other languages, e.g. in python map[unsetKey] will throw (note however, that there ist `map.get(…)`). Granted, e.g. perl and Java just return their respective null, but we don't have those in Rust.
You basically explain the whole thing: wether it is an error or not is a question of library design. perl and Java (and Ruby) choose to make getting a unset key a valid operation, just returning null. Python does both. Rust chooses to actually return an Entry enum with to variants, one marking an empty slot, which allows setting values on the slot, by the way. It again wraps that in a Result. I don't feel that's necessary, the OP seems to agree.
Then this is probably a remnant of an earlier design that used Result&lt;Entry, VacantEntry&gt;.
[`.take()`](http://doc.rust-lang.org/core/option/enum.Option.html#method.take) depends on `mem::replace()` ;)
Hm, I read the API a bit further... Actually getting the entry from the hashmap returns `Entry`. Not unwrapping the enum and then using `get` on `Entry` instead of `OccupiedEntry` returns a Result. That is quite sound - in that case, I do not understand why a `VacantEntry` is in the Err value, though.
Actually, CEF is self-contained. Chromium itself is not a dependency.
Does Discourse support linking the accounts?
What's wrong with starts_with? Are you trying to avoid a clumsy if-else chain? A pattern match like that would pretty much have to work the same way internally. Anyway, I think it's a good use-case for pattern guards: fn main() { let test = b"connect 1234132"; match test { s if s.starts_with(b"connect") =&gt; { println!("connect"); } s if s.starts_with(b"something-else") =&gt; { println!("something-else"); } _ =&gt; { println!("nothing to see here"); } } } 
Discourse supports SSO, so it's possible for each instance to use the same login information. That's it though, it doesn't support profile syncing. It's possible to write a plugin though (see the 8tracks forum for an example).
Here's my advice: Every time you want to use global variables, try to wrap those status into a struct, and do stuff inside `impl` of that struct. It works for me, anyway. And tuples sometimes work the same way. 
The `raw::Slice&lt;T&gt;` struct is the representation of a pointer-to-a-slice. That is, its the repr of `&amp;[T]`, `&amp;mut [T]`, `Box&lt;[T]&gt;`, etc. So a copy of something like a borrowed slice just involves a copy of that the fat pointer itself, which has a define size.
I'm not sure if I'm understanding you correctly. Are you asking why `&amp;[T]` is Copy even if `T` isn't? Because `&amp;[T]` is a pointer and a length, trivially copyable. Passing `&amp;[T]` into a function doesn't copy the contents of the slice, just its representation. `Slice&lt;T&gt;` is actually what the `&amp;[T]` type looks like in memory. It's often used to construct or deconstruct the latter through a call to `std::mem::transmute()`
Awesome! I've been hoping for something like this. Great work on the docs. My only issue so far is that the syntax ends up being very nested. I don't have any great suggestions, but it would be interesting to hear if you had any thoughts on making those parts a bit smoother for a larger project.
&gt; From what I understand, copy works on structs that have a defined size, because a memcpy call would require a size parameter. It's obvious how this would work for something that is Sized, as the ccompiler calculates the size of the struct. I think this is the key misunderstanding. This is not how `Copy` works. For example, `String` fits your criteria here (and it is certainly `Sized`), but it does *not* implement `Copy`. You should try to think of `Copy` as, "Can I produce a *semantic* copy of a value with this type by just copying bits?" If so, then you can make that type implement `Copy`. In the case of `String`, you can't do this because it is heap allocated. If you just copied the bits, then you'd have two distinct values with type `String` pointing to the same underlying piece of memory. That would not be good! This is why `Clone` exists, and is typically implemented on types that you want to copy but require more work than just a plain ol' `memcpy`. In the case of `String`, you need to create a new heap allocation. Another way of looking at it is: `Copy` is a shallow copy and `Clone` is a deep copy. `Copy` can be implemented for types when a shallow copy *is* the deep copy. (I'm not sure if this is 100% correct to say, but it seems like a useful thing to call attention to.) And in this light, `Copy` makes sense for `&amp;T`. It's just a pointer. And when you want to copy it, you just want its raw bits.
&gt;&gt; For instance it's not an error[1] if you get a VacantEntry. &gt; Yes, exactly. As discussed in another subthread, it is only an error if you `.get()` on an `Entry` that is empty. The Err value just happens to be the `VacantEntry`. All other interfaces to retrieve entries return `Option` or explicitly destructure the `Entry`.
Thankaz ing to you my gr8 friend i Love you for teaching Me if IIIIIIIII could do the afording moneiy of rust gold I would do donations to your bodily self,. PS Should/can i delete thsi post since it's irrelevant?
There is now `std::slice::from_raw_parts()`, so there should be less need to deal with raw `Slice`.
There is an RFC for placement new/box. This sounds like just the thing to help you: https://github.com/rust-lang/rfcs/pull/809
So the subtext is: Sorry, but there is no official support yet :/ You might want to look at [IxList](https://bluss.github.io/ixlist/target/doc/ixlist/struct.List.html) to see how data structures can be implemented with contiguous backing buffers. 
Thanks for sharing! I think it'd be really interesting/educational to see some of the Rust/Servo core devs record themselves while working to hear their thought process.
Can you or someone else please explain concretely how an allocator API is going to provide the ability for `TypedArena`s to be used to allocate slices? I don't think this has much to do with `emplace_back`, so much as it's just missing functionality, but I might just not be understanding how this would work.
I've added a [how-to](https://github.com/japaric/ruststrap/blob/master/1-how-to-cross-compile.md) about setting up cross compilation to ARM to the dropbox folder/repository.
Streamer here. I have no idea why it would be saying that! I've set the licence to "Creative Commons - Attribution", and there's no background music nor anything that could be triggering its content detectors.
I'm not sure I could compete with someone of that caliber :)
thanks so much for this in depth comment.
Yes, it sadly is.
Thanks - VPN would certainly help, but streaming on Twitch next time would help even more :) !
Anecdotally, I used this library to assist in some throughput testing in my company's QA environment. I wrote a minimal program to spawn a number of threads with one session each and consume from the same queue. Each thread would count the messages it consumed and report that number occasionally. If you're interested, I've shared the source code [here](http://goo.gl/lyZmHG). It was able to keep up under a load of a couple of hundred messages per second (each up to a few kb in size) for several minutes while consistently using about 2.5MB of RAM (RES).
&gt; The explicit closure kind syntax (|&amp;:|, |&amp;mut:|, |:|) is obsolete and closure kind is inferred from context. Thank you so much!
The [docs](http://doc.rust-lang.org/core/result/enum.Result.html) might be useful in the future, if you haven't found them already :) (They're rather flaky in places missing things like cross-crate impls and generic impls, but they're good for most things)
If it doesn't hold a reference to the arena, can't the allocation escape the stack frame?
Hah, that's true :)
Some critiques: 1. Audio is not audible until the 17:54 mark, when a configuration dialog suddenly pops up and the Input Level is adjusted slightly. That results in barely audible, muffled narration. At 19:06, the config dialog pops up again, and the Input Level is finally adjusted to a reasonable level. 2. The entire video is 2:46.14 long. Nearly 3 hours. Regarding critique 1: Nearly 20 minutes of silence before figuring out your video has no sound is not a good practice if you want your video to appear competent, let along professional. As it stands now, it comes across as being on the low end of the amateur spectrum. Regarding critique 2: Nearly 3 hours? Really? I suggest editing this massive video, splitting it into reasonable segments with a particular focus (Intro, command-line tool 1, command-line tool 2, etc) and posting the results as a series. 3 hours is too much time to expect any busy human to pay attention. That's as far as I got. The lack of audio and the extreme length was enough to turn me away from what looked like a potentially interesting video tutorial. First impressions are lasting impressions. Take a little time to review your work before posting to the world. That's my advice.
You know it would maybe be cool if we got a snippet of why the choices were made as they were, I don't know something like: &gt;Don't actually document using / ** *comments *** / because they are more useful for commenting out code when debugging.(well thats my guess) Sure some like me will still disagree on some things, but some rational may be cool. Then again we are all busy so I guess it isn't too important.
Hm, You mean &gt;Note that a successful send does not guarantee that the receiver will ever see the data if there is a buffer on this channel. Items may be enqueued in the internal buffer for the receiver to receive at a later time ? I read that as meaning that if the receiver never calls recv() they won't see the message. Ie, usual buffer semantics - a successful send doesn't imply recv has been called, not that destroying the sender will also destroy the buffer
I don't understand why move out of fixed length array is prohibited. AFAIU, for regular variables, there's a boolean flag allocated on the stack, which is set when value is moved. That flag is used to track whether value should be dropped at the end of the block. For fixed size arrays, it is possible to allocate boolean array of the same size as value array to track which element is moved. E. g. let a: [Foo; 10] = ... move_to(a[index]); can be compiled to: let a: [Foo; 10] = ... let a_flags = [false; 10]; move_to(a[index]); a_flags[index] = true; ... if (!a_flags[0]) drop(a[0]); if (!a_flags[1]) drop(a[1]); ... if (!a_flags[9]) drop(a[9]); This does not seems to be hard to implement.
Many things have gone through the RFC process, and those should be linked, iirc
So it's like \_|\_ ("bottom") in Haskell, right?
I guess I don't get it then. Watching 20 minutes of silence then another 2.5 hours of someone talking to themselves while coding just doesn't make sense to me. I could have spent that time writing my own code and then I would have something to show for that time. To each his own, I suppose. I would prefer a prepared lecture to this.
Yeah.
As long as you push to github with "conventional style" applied, then no one would be the wiser.
Yeah, thats the idea; but I had heard there was an issue about format to my style -&gt; format back might lead to a bunch of lines appearing to change when they have not. Although it sounded like some bool to me. Also bitbucket is where it is at, free private repos (w/ less than 5 private contributors) good place for code that is in progress/not ready for being public (though they have that too for free)
I don't know what's up with `image` but I've noticed it as an anomaly in my glutin/glium projects.
Gosh darn it, here's the real [link](http://erickt.github.io/blog/2015/02/09/syntex-syntex-extensions-for-rust-1-dot-0/)
Now with a working link!
&gt; Short-circuit on the first error? ...Like, it stops trying to read arguments after the first failure? Yep. There's a corresponding instance for `Option` as well, which halts on the first `None`. If you want a full list, it's in [`std::iter::FromIterator`](http://doc.rust-lang.org/std/iter/trait.FromIterator.html). You can see all sorts of containers listed there. &gt; Also, a major problem I have with code like that is that it's *extremely* difficult for me to discover the type of an expression, so I usually try very hard NOT to write things like `let args: Result&lt;Vec&lt;String&gt;, OsString&gt;`. That's actually one of the number one drivers for why I find myself using so many closures in my code rather than just factoring things out into functions. &gt; Any tips on figuring out what a thing *is*? Personally I think it's just something you'll get used to. Writing out the types is a good thing anyway, as it forces you to think the problem through. This is especially true in a language like Rust, which encodes a lot of meaning in its type system. Haskell has features like ["type holes"](https://ro-che.info/articles/2014-03-13-type-of-local-function) which can help. IDEs would fill the gap for Rust, but it'll be a while before we get those. But note that in this particular case you don't have to write the full signature. Using the "infer this please" symbol, `_`, we can strip out everything but the skeleton of the result: let args: Result&lt;Vec&lt;_&gt;, _&gt; = ...
The possibilities for arbitrary compiles-to-rust preprocessing step support in cargo are very interesting. This seems far more plausible than a 'stable' api for syntax extensions.
Can you use the placeholders in function declarations?
Wait, will #[derive(encodable)] not be available in 1.0? What about regex macros?
It requires the rustc-serialize crate, but Erick has been working on serde, which is an attempt at a better serialize crate. 
It really isn't a big deal except with iterators. ...iterators. :( /shiver The worst thing there is, coming from C#, one of my favorite things to return from a function is exactly that. :)
Sure, but if you can't use plugins at all, then does it really matter? I don't see anyone actually writing their own encoding / decoding functions. 
there were about 10-12 people at this meeting
A stable API eventually becomes necessary to interact with tools like editors. You don't want a repeat of the camlp4 shitshow.
The thing is, this isn't an entirely safe operation when concurrency is taken into perspective. Try making a struct containing the data you need, creating one in main(), and passing an &amp;mut pointer to the function. If you *really* don't want to pass around structs, try using a thread local variable. See http://doc.rust-lang.org/std/thread_local/struct.Key.html (also RefCell)
Ruby is pretty exceptional in its weird treatment of return here. Most languages treat returns in a closure as returns from that closure, and it's not tricky or surprising
Just some news about my progress : using your binaries, I'm trying to compile rust from the lastest git revision on my Raspberry. It is slow (reaaaally slow : ~3 days now), but it seems to work ! It seems stage2 is in progress now...
Interesting! When providing a framework for writing a plugin library the question arises, how should the framework set up calling into the actual plugin code? You have done it by requiring the rust plugin code to implement a function called `get_ladspa_descriptor`, I wonder if there's a more Rust idiomatic way to do it? (I don't have a good answer myself.)
That wasn't a problem IIRC, an array that was moved out once cannot be used again.
It's a perfectly valid interpretation though, making `return` behave the same at all places in the lexical scope. Also, considering the lengthy explanation of `return` in different languages in the wikipedia article about closures hints that "most languages" is a bit sloppy an that interpretations differ. http://en.wikipedia.org/wiki/Closure_%28computer_programming%29 Hence, I prefer just doing away with return. It is a hyperspecific instruction that the compiler does for me and adds noise. Take for example a Thing that has an inner storage vector. I delegate `len()` to the inner: fn len(&amp;self) { self.inner_vec.len() } Read as: the length is the inner_vec length. (i would even cosider the "self" noise here) fn len(&amp;self) { return self.inner_vec.len(); } Compare: return the length value of the inner vec. I appreciate that this might differ for other people, but I prefer the first notation.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Closure (computer programming)**](https://en.wikipedia.org/wiki/Closure%20%28computer%20programming%29): [](#sfw) --- &gt; &gt;In [programming languages](https://en.wikipedia.org/wiki/Programming_language), a __closure__ (also __lexical closure__ or __function closure__) is a [function](https://en.wikipedia.org/wiki/Function_(computer_science\)) or reference to a function together with a *referencing environment*—a table storing a [reference](https://en.wikipedia.org/wiki/Reference_(computer_science\)) to each of the [non-local variables](https://en.wikipedia.org/wiki/Non-local_variable) (also called [free variables](https://en.wikipedia.org/wiki/Free_variable) or upvalues) of that function. A closure—unlike a plain [function pointer](https://en.wikipedia.org/wiki/Function_pointer)—enables a function to access those non-local variables even when invoked outside its immediate [lexical scope](https://en.wikipedia.org/wiki/Lexical_scope). &gt;The following program fragment defines a ([higher-order](https://en.wikipedia.org/wiki/Higher-order_function)) function startAt with a local variable x and a [nested function](https://en.wikipedia.org/wiki/Nested_function) incrementBy. This nested function incrementBy has access to x, because x is in its lexical scope, even though it is not local to incrementBy. The function startAt returns a closure containing a reference to the function incrementBy, which adds the y value to the x value, and a reference to the variable x, so incrementBy will know where to find it once invoked: &gt;Invoking the variable closure1 (which is of [function type](https://en.wikipedia.org/wiki/Function_type)) with closure1(3) will return 4, while invoking closure2(3) will return 8. While closure1 and closure2 are both references to the function incrementBy, the associated environment will bind the identifier x to two distinct variables in the two invocations, leading to different results. &gt; --- ^Interesting: [^Loose ^coupling](https://en.wikipedia.org/wiki/Loose_coupling) ^| [^Computer ^and ^Video ^Games](https://en.wikipedia.org/wiki/Computer_and_Video_Games) ^| [^Apache ^Excalibur](https://en.wikipedia.org/wiki/Apache_Excalibur) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cogxaic) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cogxaic)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
They're going to stay feature gated as they are now. At the moment, references to "1.0" usually mean to the stable branch, where uses of feature gated and unstable things will be disallowed. The nightly branch will still have access to plugins.
So, just to clarify, in a few months time if I hit the download button for 1.0-stable, there will be no way to opt-in to feature-gated/unstable features, without switching to a nightly? If that's the case, we still lose lots of useful libraries, since they're unusable in the version of the language which people are actually using.
We want to avoid de-facto stabilisation of bad/restrictive APIs, and provide as good a guarantee as possible that code that compiles with 1.0 will compile with 1.1, 1.2, etc.. There's no sane way we can offer full plugins at 1.0, as exposing the AST/compiler internals would require stabilising them, which would essentially stop all future language development: it would be hard to find a way to make internal compiler changes without breaking anything. Yes it would be nice, but it's essentially entirely infeasible to do syntax extensions and lints stably with the current plugin scheme. [RFC 507](https://github.com/rust-lang/rfcs/blob/master/text/0507-release-channels.md) has more details about the process. Note that the nightly compilers will still exist, and we will encourage people to use the stable compilers (it makes life easier if you don't have to update code a lot) but the nightly channel will definitely be prominent.
What! seriously!? Now i feel stupid, i wasnt sure whether that would work, or if it would be ASCII thanks anyway :)
I have some thoughts about using syntax extensions, but it may bring more harm than good. Please see a complex example with rustless https://github.com/rustless/rustless/tree/master/examples/postgres. Nesting is quite ok for me. What do you think?
This seems reasonable, thank you for clarifying! It's a shame to need a preprocessing step, but I suppose it's better than nothing.
Hm, I guess my primary worry is that the example essentially mixes several concerns – like [here](https://github.com/rustless/rustless/blob/master/examples/postgres/src/api/tweets.rs), we're building an URL scheme, sort of defining a JSONified model, and controlling the data in one nested bunch. That wouldn't be sustainable in the long run. It's great that you can quickly do an app in a small amount of space, but to grow I guess you could use more implicit standards – automatically mapping GET on an url to `get` on Tweet, for instance, and perhaps inferring the schema from the model if that's at all possible. Anyway, I'm not really sure what I feel is right before using it for a bit, so the above is basically not of very much value. And right now I can't even get my little test app to compile, so :)
This works because the first 128 unicode code points are identical to the corresponding ASCII characters.
Could you please describe the problem you're trying to solve by matching on the type of a value?
There is one question. Why? You cannot deal with that arument in any way other than wrapping it. So what's the point?
Oh, is there a way to convert the rest (there is 255 total right?)
No, rust will perform runtime-tracking. See this part from the RFC: https://github.com/rust-lang/rfcs/blob/4aca0827d11c19b9c3c1a987de045539300e2394/active/0000-nonzeroing-dynamic-drop.md &gt; For every dynamic drop obligation induced by a merge point, the compiler is responsible for ensure that its drop code is run at some point. If necessary, it will inject and maintain boolean flag analogous to &gt; &gt; enum NeedsDropFlag { NeedsLocalDrop, DoNotDrop } &gt; &gt; Some compiler analysis may be able to identify dynamic drop obligations that do not actually need to be tracked. Therefore, we do not specify the precise set of boolean flags that are injected.
For that question, I think the OP need an `enum` to represent all SHA types... Or use `String` works, too. Although I will agree that if I'm writing C++ I may try that way, just because C++ don't have good `enum` to use. 
If anyone near Göttingen, Germany wants some Rust stickers, come [visit](https://cccgoe.de/wiki/OpenChaos) [us](https://cccgoe.de/wiki/Hauptseite). I still have about 50 stickers left. They're not as cool looking as the ones shown here. They're just black and white.
I'm currently doing Episode 2: https://www.youtube.com/watch?v=Fh1z1Eke_pk
Why not use traits? https://gist.github.com/paholg/270784970f4229e50793 Edit: If you really want to use an enum then this doesn't solve your problem, but it will be faster than using a match. You can also make a pointer to T to contain whatever data you want, instead of the enum, if you want one variable to be able to be any of your defined types.
That is a hard choice. I do like the idea of a very small hardwired language with most features as a library. Something akin to `Object&lt;Traits&gt;` or `Object!(Traits)` which is a ducked-typed object. OTOH this would require constantly redoing the language and at some point they had to stop and aim for 1.0. There's never going to be a language that is 100%, only time will tell us how well it went.
It becomes much harder when said array is embedded in a structure and that structure is dynamically allocated (imagine a BTree for example). I would imagine this is a conservative change: it's much safer to restrict now, and potentially reintroduce it later. If you allow it now and then it prevents useful optimizations (or other things) then you are stuck...
Nah, I like .ok() fine; just had no idea what it was used for when I saw it in that example code.
Hurray! :D I was beginning to get worried.
I don't see how it is harder than tracking several variables in the same dynamic structure. Array a: [T, n] is essentially same thing as: a_0: T, a_1: T, a_2: T, .... a_n1: T and array[i] is equivalent to match i { 0 =&gt; a_0, 1 =&gt; a_1, ... n - 1 =&gt; a_n1, }
&gt; Rust upgrade: It appears to be that we’re stuck in the state of perpetual rustup. Is Servo going to continue tracking Rust master after 1.0 is released?
Oh yes. We are never satisfied with the status quo.
Thanks!
We could. We could make a conscious choice not to use the stuff that isn't going to be stabilized anytime soon, and this should just work. Maybe not Rust 1.0-stable, but a couple versions after that. I'm not entirely sure of how the stabilization will happen so I can't say exactly when we'll be able to do it. But we probably won't. It's far easier to use the shiny unstable things Rust gives us, and it lets us define our own abstractions with less work and less duplication of code. Besides, we use syntax extensions for some codegen and safety checks. Those will take quite a while to stabilize. (We could remove their necessity, however, and use codegen for stuff like html5ever's atoms and all) So future Rust (some version after 1.0, not too far in the future) probably will be enough to build an efficient browser engine. But we might not actually use it. The cost of rustupping is decreasing and will continue to decrease, but the cost of duplicating work and rewriting unstable libraries in-tree will stay the same. So we'll stick to pinning for the forseeable future. _Eventually_, when everything except stuff like syntax extensions stabilize, we could probably semver it and declare that compatibility (bump the major number whenever the edge stuff changes). But that's far future. ---------------- FWIW we don't plan to declare our own 1.0. Servo just downloads a snapshot of a particular recent nightly, not too strange in my opinion. It's the same as a normal nightly except it has support for two cross compilation targets (regular rustc with its libs built for the various targets). ----------- And yeah, the symbiotic relationship will probably play a role. When the time comes that we _can_ switch to a stable Rust release, we'll probably decide not to both because of what I mentioned above, and because having Servo run on nightlies with all the unstable APIs and features provides good testing for them.
&gt; FWIW we don't plan to declare our own 1.0. Interesting! So Servo isn't going to have a version scheme? &gt; Servo just downloads a snapshot of a particular recent nightly, not too strange in my opinion. Certainly not for people used to Rust, but maybe to outsiders - I certainly would be surprised if I tried to build some project and it started downloading its own version of `gcc`, `go` or `ghc`. Hopefully that's not a dealbreaker for Linux distros. &gt; having Servo run on nightlies with all the unstable APIs and features provides good testing for them True, there's no point in having unstable libraries and feature gates if no one actually uses them :)
As an embeddable engine, Servo will need version numbers eventually, so that embedders know what they're getting. This could use semver on the embedding API (CEF). Because this is a C API, we can upgrade Rust without a backwards-incompatible release. The version numbers on user-facing products are a different story. It's possible that, say, Servo 2.2 will ship in Firefox OS 4.0, and a year later Servo 3.0 will ship in Firefox 52 for desktop. (Numbers obviously very made up.)
So I'm going to say. If what you want is a disjoint type that can apply anything that works on _all_ objects then you'll have a hard time. You could do something like [this](http://is.gd/SaTtgQ) then manually implement all shared traits (and they'd just run a match and map the functionality). I guess if you wanted some sort of object type that could be casted back to the original type this would be slightly safer/faster than using `any`, but not by much. The cost is that you actually have to do all the work yourself, because even though this one specific case may seem obvious to you, it wouldn't be clear at all to the compiler (and could lead to dirtiness). You could simplify things further, by having a macro that would create the type (and impls) for you so you could have something like: type Input = DisjointTypeEnum!(A, B, C); And then you could access its members like `Input::A(..)`. Of course this macro would still not be smart enough to realize what you should implement for them. So instead you should do something like impl SharedTrait for Input { fn SharedMethod(&amp;self) -&gt; Output { match self { A(a) =&gt; &lt;a as SharedTrait&gt;.SharedMethod(), B(b) =&gt; &lt;b as SharedTrait&gt;.SharedMethod(), C(c) =&gt; &lt;c as SharedTrait&gt;.SharedMethod(), } } } You could probably do a macro that builds the function above, something like `ApplyEnumMethod!(enum, method: type1, type2...)`. I would not push macro wizardry further than this. --- Seeing your case though, it'd probably make more sense to use traits and templates if what you want is efficiency for whatever reason. Something like fn some_func&lt;T: MyType&gt;(some_str: &amp;str) -&gt; bool { //could also be create_hmac(T::hmac::get_HashType(), some_str); let mut hmac = T::create_hmac(some_str); //some calculations goes HERE, NOT in create_hmac function... hmac.input("fdsfdsfdsfd".to_string().as_bytes()); //something else.... true } That way you get compiler safety and efficiency. If you don't like the idea of `some_func` getting copies for every form of T you can create a closure/function that hides the actual type at the moment you want the function to stop expanding for each type (or just use a trait object and call it a day).
You are missing an important detail here: what's the host? i.e. what's the triple of the machine you are cross-compiling from? But more importantly, why do you want to cross compile to x86_64-apple-darwin? AFAICT that triple is [officially supported](http://www.rust-lang.org/install.html), why not just natively compile on the target device? That's going to save you a **lot** of trouble.
Oops, the host is `x86_64-unknown-linux-gnu`. I have a mac to compile binaries for `x86_64-apple-darwin`, but despite the extra work it would still be much more convienient to build multiple target binaries on a single machine.
&gt; despite the extra work it would still be much more convienient to build multiple target binaries on a single machine I think you are greatly understimating the complications of cross compiling. Anyway, [these notes](https://github.com/japaric/ruststrap/blob/master/1-how-to-cross-compile.md) may be of some use. I haven't cross compiled between different OSes before, but at the very least you'll need a `x86_64-apple-darwing-gcc`, a `libc` cross compiled for the target triple, and `libstd` and friends cross compiled for the target triple (you can get those crates from the official nightlies). Good luck.
I feel like *Alt* would be good as well
awesome this gives me some hope...
True, but that's not the issue here :) We need to pin the snapshot right now; nightlies won't work for us. Well, nightlies perhaps. I can imagine a time when the rustup process is small enough that we no longer need to pin. Imagining a time when Servo is written with the conscious choice of avoiding rustups is harder.
I understand what are you talking about and I think that it can be added later as an additional layer when some fancy ORM will appear.
I think you're looking for /r/playrust
There is also Nickel - https://github.com/nickel-org/nickel.rs
&gt; Besides which, docs are best for finding out what symbol_a is for--they aren't as helpful for mapping random thing I just came up with to symbol_a. That's one great thing about hoogle. If you can give a rough type-outline for the *random thing you just came up with*, you plug those types in and it'll list a bunch of functions which kinda sorta match. Can get kinda abstract though. For instance [Either err ok -&gt; Maybe ok](https://www.haskell.org/hoogle/?hoogle=Either+err+ok+-%3E+Maybe+ok) (which is ~ `Result&lt;a, b&gt; -&gt; Option&lt;a&gt;` in rust) has no obvious direct result but the second match is either :: (a -&gt; c) -&gt; (b -&gt; c) -&gt; Either a b -&gt; c with `Either a b` marked as matching `Either err ok` and `c` marked as matching `Maybe ok`, so let ok = either (const Nothing) Just
A self contained example of Piston-quack would be nice.
"This" referred to using code such as `65u8 as char`. But I was wrong, it’s not Windows-1252 since Windows-1252 does not quite map byte values to code points 1:1. The point remains that if you want to "decode ASCII", you should think about what to do with bytes outside the ASCII range.
&gt; We will never, ever support Windows XP. ;(
Opened https://github.com/PistonDevelopers/quack/issues/35
You can manually type "Programming" as a game name there. But streaming non-gamedev is against the rules: http://www.twitch.tv/p/rules-of-conduct &gt; Non-gaming, non-music content: Video games, board games, card games, fantasy sports, LARP games, and acceptable music content (see above). And while it's nice to take a break and just chill out with your audience, please ensure that your channel's primary focus is on gaming or music creation.
That's rather unfortunate. I use the following workaround for now: trait B is changed to: trait B : A { fn upcast(&amp;self) -&gt; &amp;A; } and the implementation for `I` becomes: impl B for I { fn upcast(&amp;self) -&gt; &amp;A { self } } The call to `f` finally is: f(i.upcast())
That looks like what the devs did too, when they had to deal with the problem in rustc. It is unfortunate and hopefully upwards coercion for trait objects will get added at some point.
Dude it's web scale, what more do you want? /s
I haven't benchmarked anything yet and it's very likely that the channels in the standard library are currently faster because they use the highly optimized implementations from http://www.1024cores.net. My bounded MPMC implementation is particularly slow because I wanted to make sure that invalid memory access is not just unlikely but impossible. I believe the 1024cores MPMC implementation is less safe in this regard. (It is highly unlikely that the 1024cores version actually causes unsafety on 64 bit systems.) In the future one could add a MPMC channel that is slightly less safe but much faster. I've also noticed that some implementations could use cheaper atomic operations if they didn't have to synchronize with potentially sleeping threads (send_sync / recv_sync.) One could add channel types that simply don't have these blocking functions and test if they are faster in practice.
&gt; If we land some components of Servo (at least, something in Rust) in Gecko as we're planning there will be XP support (I think) for them. Eventually, but for now we may land components that are optional or already have alternative implementations. Our Rust code can't progress beyond Firefox Nightly until we at least have support for the MS toolchain on Windows, but I don't know if XP support is a blocker in the same way.
This is great! I was actually thinking of pulling some people together to build up selectable queues. I've not looked through the code too thoroughly, but I like the hot-path approach that you take, leaving mutexes only if the common operation fails. 
&gt; Users can use their own channels with Select What is meant by this? I thought [select in rust std](http://doc.rust-lang.org/0.11.0/std/macros/macro.select!.html#example) used your specified channels?
&gt; What is meant by this? This means that the user can implement a channel and certain traits and then use the `Select` provided by the crate to wait for messages from this channel. This is possible with the `Select` in the `comm` crate but not with the `Select` in `std::sync`.
[**@luisbg**](https://twitter.com/luisbg): &gt;[2015-02-06 11:37:03 UTC](https://twitter.com/luisbg/status/563662654385172480) &gt;Are you part of one of these open source projects? Want to make a living contributing upstream? Samsung OSG is hiring [*pic.twitter.com*](http://pbs.twimg.com/media/B9KIMnfIIAMnxYM.png) [^[Imgur]](http://i.imgur.com/fKaobA3.png) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2vkurp%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
The trait based way of calling math methods is a bit odd, but it makes sense because they use the `Float` trait. I think there might have been some talk earlier about eventually letting functions on traits be called as regular functions. It's not really common to have `pow` on integers in the standard library, though. To my knowledge, there's isn't one in C, C++, Java, or C#.
Rust is never really going to have a 'freeze,' it will just stop having backwards incompatible changes. This is actualy a great example of the kind of change to make during the beta period: additions that make ergonomics better.
Python and Haskell have pow()/(**) returning Integers when passing Integers, but maybe that's somehow because of their functional style. Most important point to me - I forgot to mention it above - If you try to find the pow function in Rust using Google, you are going to have a bad time. All the functions are really hard to find down there in std::num::Float
Try the Rust docs' own search function? http://doc.rust-lang.org/nightly/std/?search=pow
My first PR didn't even get merged because I opened it against the wrong branch: https://github.com/rust-lang/rust/pull/4305
Functions on traits as regular functions is already working, so you can use Float::powi(x, n); Edit: http://is.gd/LrqoVl
People already answered very well. I would just add, with a little bit of irony that it is also a way to give a meaning to ";". Without the return thing, semicolumns would have no purpose anymore. So rust dev chose to constantly tell the compiler to shut up instead of telling it when to return things. I said "a little bit" because this was actually explained to me on IRC the other way around, but it still seems silly: "we can't remove semicolumns because, in Rust, they have an important meaning". I still find it suboptimal in 2015 to have to write semicolums to help pars... hum sorry, to tell the compiler NOT to return the current expression and to tell it NOT to keep on parsing the next line as ponctual explicit returns and rare line continuation symbols would require too much typing.
This does not look like official vacancy.
On std::num, is there a good reason not to have a fn for the quadratic equation? Well other than the face to be perfect It would have to return 2 possibly complex numbers.... (thinking 4 element tuple) I'd be happy to write such a thing, but I figure if you guys wanted it there it would be there by now......
I feel like x.pow(n) actually reads more naturally and clearly as "x to the power of n" than pow(x, n).
Pow is implemented for more than just float: use std::num::Int; fn main() { println!("{}", 2.pow(3)); }
GCC is included with the Rust install but its folder isn't added to the PATH. Additionally, it's doesn't seem to look for header files from the Windows SDK so it's useless for compiling, e.g., the `time` crate.
Password is "rhex" (as you might have guessed :) ) And you might need to run export TERM=xterm-256color before sshing into to make it work 
I just read that `push_all` is supposed to be removed as well? Why? The alternative is insanely non-obvious and it will result in people doing a for elem in slice.iter_move() { vec.push(elem) } which is equally verbose. To be honest it will take a while until we get HKT und they’ll get added back. That’s not a good mid-term solution.
A couple notes: - [sound_stream](https://github.com/RustAudio/sound_stream) (and thus most of these crates) rely on having [PortAudio](http://www.portaudio.com/download.html) installed. I'm currently trying to move over to tomaka's purely rust [CPAL](https://github.com/tomaka/cpal) to get rid of the nasty C dep. This involves getting CPAL working on OS X first though (I'm looking into this, but if anyone out there already has experience with the CoreAudio C API then plz halp). - [synth](https://github.com/RustAudio/synth/) is currently built against HEAD, so it might not work for you atm if you're on the nightlies (it'll probably start working when the nightly updates in a few hrs). EDIT: Also, if you're a rusty audio/music dev feel free to hit me up and I'll add you to the RustAudio team! We're always keen to get more useful crates together to try and turn RustAudio into a one-stop shop for all your waveform-ninja arsenal needs.
There seems to be a Samsung OSG and there were pervious news they are hiring http://www.reddit.com/r/linux/comments/2o961e/samsungs_open_source_group_is_growing_hiring/ but i do not seem to find anything on the web regarding their current vacancies.
You could just declare them… const pow: fn(f64, f64) -&gt; f64 = Float::powf;
Just one remark, the blocks `{}` you are mentioning, are no closures but just blocks (unfortunately the documentation of those vanished from the reference).
The confusing error is [this issue](https://github.com/rust-lang/rust/issues/21793), which hopefully will get fixed soon. What's happened is that your `Process` means a different thing on Windows and Unix. On Windows, its [`handle` field](http://doc.rust-lang.org/src/std/old_io/process.rs.html#71) (type `sys::process::Process`) [contains a `*mut ()` pointer](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/windows/process.rs#L50) whereas on Unix it [doesn't](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/unix/process.rs#L36). I'm not sure exactly how this pointer is used, but it might be possible to do an unsafe impl of Send on this struct to get this to work. In the meantime, [this should work around it](http://is.gd/eYmLFZ), though I can't guarantee that it is _safe_.
Sweet! I've been planning on porting my c++ WAV writer over to Rust soon as an excuse to learn the new std::io - maybe we can merge them together at some point :)
How does that work for cyclic references?
Niiice, thinking of building one myself for a long time, but with Adafruit NeoPixels. I'll check out the code for sure.
Yep, I agree. The issue is that in capnproto-rust, a `foo::Builder &lt;'a&gt;` needs to act like a `&amp;'a mut Foo`, but it doesn't get to use the special built-in reborrowing semantics of `&amp;'a mut Foo`. My impression is that it ought it to be possible for Rust to have a trait that would allow custom reference types to hook into these special reborrowing semantics. See [this blog post](http://dwrensha.github.io/capnproto-rust/2014/12/27/custom-mutable-references.html) for some more discussion.
CPAL doesn't support PulseAudio output, right? On the other hand, PortAudio does.. So, even though PulseAudio provides ALSA compatibility, dropping support for PortAudio would be a regression of sorts.
Samsung OSG's primary web presence is Twitter: https://twitter.com/SamsungOSG I found two job openings that are clearly Samsung OSG at LinkedIn, one for Linux and one for WebKit. https://www.linkedin.com/job/samsung-electronics-america-open-source-jobs/
I don't think portaudio uses the pulseaudio API directly. At least on my system it uses alsa, and a search for "pulseaudio" on its codebase returns nothing. That said, my understanding is the default on modern linux distributions is to make alsa output to a virtual pulseaudio device, so that everything works seamlessly. For example, I'm able to see alsa-using applications on `pavucontrol`.
You are totally correct, I've fixed this, thanks!
I totally agree! Even something like #[derive(capnproto)]
Samsung OSG is hiring in a huge range of open source projects. This tweet just contains the most important projects in which developers are needed. The best way to find out if you might be a good fit is to email the address shared in the tweet.
Hey Steve! Hugely enjoyed your FOSDEM talk. Thanks :)
Interesting. Didn't know about that.
Generally you'd want a framerate similar to that of the content you're viewing. Upwards 60 for games, 25 for movies etc. By using some sort of smoothing, the experience can be somewhat enhanced even at lower framerate, at the cost of responsivity. A smoother transition will, obviously, feel more smooth. However, when lots of things happen very fast, like the whole screen epileptically flashing from one color to another, this will cause an annoying delay. In Helion, I have not yet implemented smoothing, and, as such, you really want to refresh at a high rate, in order for things not to feel flickerish. I intend to add support for this though. To more directly answer your question: Yes, you want to sample as often as possible or things might appear either flickerish, or unresponsive. The returns are, in my experience, diminishing after circa 40hz, wherefore I typically limit my refreshrate in Helion to 40-50hz.
Right now, it's a community effort. Rust has actually been moving stuff *out* of the standard library and into the crates.io ecosystem. This has several advantages over bundling it with the language itself. [Hyper](https://github.com/hyperium/hyper) is probably the more fleshed out HTTP implementation so far. One missing piece is an non-blocking http library so we can build high-performance http servers. [mio](https://github.com/carllerche/mio) is leading the effort in this area.
Balkanized ? Anyway, there are https://github.com/hyperium/hyper and https://github.com/chris-morgan/rust-http
It is unfortunate that `pow` is not in the standard library of those languages, since the naive implementation (not using exponentiation by squaring) is inefficient.
rust-http has been declared dead for a while. Don't use it.
Just tried it out and that's pretty awesome!
I think it would make sense to have a group of libraries, like Piston is set up but for web server networking. Rust provides the low-level socket interfacing, but to translate http a library should be used in my opinion. I don't see web server libraries spread out and compartmentalized but compatible on a general level, eg: routing, http parsing, connection pooling, sessions. Http is also complicated because websockets basically sit on top of the initial http connection, so it requires this http parsing for like 2 interactions during upgrade but then it is its own encapsulation on top of socket connections and has nothing to do with http really. In other languages, like Clojure, this compartmentalized library grouping is the common case because sharing functions and data between libraries is a breeze on the language level. That's not to say Rust isn't/can't be, but just my experience with another language. Please correct my misconceptions!
Be careful that you don't get a bunch of Philips lawyers knocking on your door. Anyway very nicely done. I must admit, this is the first time I think ambilight actually looks nice and useful. 
Rust is a language being championed by an organization that traces its roots back to the first widely used web browser in history. Netscape-&gt;Mozilla-&gt;Rust. None of this would even exist were it not for HTTP. Of all the organizations in the world, I would expect this one to be able to produce a standard HTTP library that is blessed and done right. Who else could do it better? 
One big problem with writing the struct in Rust is that you're missing the "@n" field number annotations, which means you risk breaking backwards-compatibility when adding new fields. You can make the rule that field numbers will be applied in increasing order and therefore new fields must always be added to the end, but experience has shown that programmers like to insert new fields where they make semantic sense and often won't be aware of backwards-compatibility issues. So you'll really want a field number annotation, which gets a bit verbose. Another problem with writing structs directly in Rust is that people working in other languages won't easily be able to use your protocol. :)
Exactly, we have too much experience to promise a perfect HTTP interface on day one...
&gt; Rust is a systems programming language, which makes it all the more important that it should have a standard http library. Is there really only this one kind of system anymore?
Measure twice, cut once. 
I think Cargo makes this point moot, you can add Hyper to Cargo.toml and use it as easily as if it were part of the stdlib (in a sense it's even better, since Hyper's design mistakes - if any - won't need to be supported in the stdlib)
That's kind of depressing, in a way. But that seems to be the nature of the world. To paraphrase "HTTP is the worst form of network protocols tried for the internet, except for all the others that have been tried." I'm ready for the next big advance. :-) In the meantime, I guess we're stuck with HTTP.
Yeah, a lot of people ask for such a feature, but I'm not convinced it would be worth the trouble. A while back, I wrote down some of [my thoughts on the matter](http://dwrensha.github.io/capnproto-rust/2014/06/01/libserialize-traits.html).
My friend [Asheesh](http://asheesh.org/) just started working on [Sandstorm](https://sandstorm.io/), which represents HTTP traffic using [Cap'n Proto](https://capnproto.org/). A Rust web framework (or web framework interface, a la Rack or wsgi) could talk directly to Sandstorm's routing and sandboxing systems, without going through the legacy HTTP/1.x serialization. SPDY and HTTP/2 are similarly efforts to improve the on-wire format without discarding all of the semantics. They can even benefit from [non-TCP transports](http://www.chromium.org/quic).
&gt; I find your arguments about HTTP fairly compelling, but to many with a C / C++ background it would be a bizarre thing to bake into a systems language. Which reminds me of DNS... The standard C library _has_ a DNS resolver, but it's one of my least favorite interfaces out there, and there are plenty of third-party resolvers in common use (`libadns` and `libc-ares` both come to mind, and they're async unlike the libc one). They're compelling enough that people do deal with the relative difficulty of using third-party libraries in C. If C had the Cargo ecosystem, I imagine a lot more people would be using a third-party DNS library. So if C putting DNS in the standard library early in its life was in retrospect a questionable decision, I can definitely understand the hesitance to put HTTP in Rust's standard library.
In fact, Sandstorm has one app (Acronymy) written in pure Rust. It implements a web interface without any HTTP library. :)
Yep! Found this just the other day. I don't know who's maintaining that site, but it's much appreciated! [edit]: bottom of the page says Chris Morgan. That's what happens when you tl;dr!
Thanks!
&gt; as thing stabilize, the community will begin to curate some kind of "extras" library Yeah, that's [what Haskell did](https://www.haskell.org/platform/).
Right now Hyper is well established with practically no competition. Teepee might resurrect, but even so I think Chris Morgan said he wanted to merge Teepee into Hyper anyway. What if a contender appears? Well, then it needs to be considerably *better* than Hyper to displace its mindshare. And I think that would be good. Right now, Hyper advertises its API as unstable. After its authors are confident in stabilizing its API, perhaps it could be added to the stdlib? I suppose that would be well after Rust 1.0.
And I've still got the instance running that I created last April, as announced [here](http://www.reddit.com/r/rust/comments/22y6oy/acronymy_a_web_app_written_in_rust/). Help us define all the words! http://dwrensha.ws/acronymy
Yeah, the question is, should we add or remove Send. I, pnkfelix, and huon discussed it a bit in IRC, it seems safe to impl Send for the windows one. (we also discussed designing a test for such discrepancies) 
No, but it is increasingly more common for convenience.
&gt; And even then, I think the problem was that it didn't do SSL checking by DEFAULT Sure, but you can't change the default without breaking existing code. Rust isn't willing to do that in a point release, so we'd hypothetically be stuck with insecure-by-default SSL until Rust 2.0. The Web evolves very quickly, especially with regard to security. What looks like best practices today can be dangerously naive tomorrow. Building HTTP security policy into your core language is a questionable decision — and you can't really have HTTP support without security policy. &gt; But the reason for 2 http libraries and the third party one that pretty much everyone universally uses now, requests, is the ease of use Right, the security issue with urllib2 isn't the main thing for most people, it's just something I find egregious. :) Mostly it's about API design, which is another major reason we should let HTTP libs evolve out-of-tree. Nobody in the world has much experience yet at designing APIs for modern Rust. And there are back-compat language features coming in the future that will enable richer APIs.
The point is: without those two, we wouldn't have been able to easily attach things together at all. You call them terrible - I call them things that have worked 99% of the time without problem. What you call "fractured" because other options became available is probably the result of people looking at the first solution(s), figuring out the pain points based on actual real world experience and coming up with solutions. Kind of like Free/Libre/Open_source software. Release early, release often. Innovation and improvement happens incrementally, not by painstakingly climbing the ivory tower to the pinnacle of perfection. That doesn't exist. History shows that it doesn't. Commit to a path and take it. It won't be perfect, but it will be useful enough. Many someones will figure out ways to improve it, and the best solutions will be adopted as new standards. The world isn't perfect. The reason existing standards aren't perfect isn't because people didn't spend time to figure out the most "decent" solution, it's because you can't determine that solely by thinking without action. That's the basis for the term "analysis paralysis". I am firmly convinced we would not have a perfect "screw" standard if only society had spent just a *little more time* figuring out the best solution. We would still be sticking things together with wooden pins. The problem is not moving to the better standard when it comes along and instead clinging to the original way of doing things in the name of "stability". Consistency is the hobgoblin of small minds. Pick a freaking standard. Put it in the library. Fix it where needed. Replace it when something better comes along. Don't get all verklempt because the perfect solution to survive eons didn't get implemented first. Hostory shows that never happens. History shows incremental improvement wins. That's why intellectual property laws and patents stifle innovation - because innovation is the antithesis of stability.
Speaking of software verification, I saw this today: &lt;http://coq-blog.clarus.me/a-blog-engine-written-and-proven-in-coq.html&gt;
Yes the "less ambiguous" is precisely because it is an established notation for arrays. Extending the `[x; n]` sugar (which the vec macro already supports) just a bit for vec is fairly natural. I don't know if/where the vec macro is formally documented (it's *defined* in `libcollections/macros.rs`, but that's a private module with no docs), but it's so pervasive in our documentation examples that it'd be pretty hard to miss (many also treat `vec![]` as the canonical constructor for Vec). `vec![x; n]` being possible today is indeed obscure, though. Although if it becomes "better" it may become more folklore like the rest of `vec!`'s functionality. Discoverability *is* my primary concern with the current proposal.
It would be convenient to have HTTP, SQL, HTML, UI and so on in the stdlib but I dont think thats a good idea. Look at java for example its bloated with stuff like that, theres more stuff in java thats not being used than stuff that is being used, it just sits there for backward compatibility. I think the best thing you can do is to provide good building blocks and let the community build on that.
Yeah. It's replacing C++ code in managing a seccomp sandbox, which should be a clear win.
Oh hey it is documented: http://doc.rust-lang.org/collections/macro.vec!.html
&gt; After its authors are confident in stabilizing its API, perhaps it could be added to the stdlib? I think the idea is that it wouldn't be added to the stdlib, but it would be marked as "blessed" on crates.io. That way people know where to go if they want an http library, but the library isn't cast in stone forever.
Cool! Would definitely love to see a stream example working with sound_stream/cpal. Not sure if you're interested, but I've sent you an invite to the RustAudio org, feel free to tweak things / add repos or whatever :) We don't have any encoding/decoding crates yet but I'd love to get something like [PistonDevelopers/image](https://github.com/PistonDevelopers/image) going, but for audio formats. 
rimd looks awesome! I'll definitely have a use-case for this in the near future. Just sent you an invite to the RustAudio org :)
I'd much rather have people have to learn Cargo (which they will have to anyway) than for us to be stuck with a Tkinter.
 impl FromStr for Options { type Err = (); fn from_str(s: &amp;str) -&gt; Result&lt;Options, ()&gt; { match s { "A" =&gt; Ok(Options::A), "B" =&gt; Ok(Options::B), "C" =&gt; Ok(Options::C), _ =&gt; Err(()), } } } Then you can write `string.parse::&lt;Options&gt;()` and get a `Result&lt;Options, ()&gt;`.
Got it. My fault. It wouldn't have been a string except for the uppercase conversion, so I just needed to convert it back to a slice. Is there gonna be some kind of coercion on that at some point?
I don't think it's anywhere in the language right now, but it's definitely possible with a syntax extension.
I would venture to say that says more about people that are bothered by different semantics than the quality of the Python libraries. It reminds me of the computer classes where folks were taught to use, say, MS Word by showing them a series of screenshots of where to click the mouse to accomplish a task. After an upgrade, those people were very confused, because the things they needed to click weren't in the same place, and they needed new training. Ok, I jest. But different semantics shouldn't daunt capable developers if the new semantics are better, particularly if they are informed by experience from an earlier iteration. They will learn it. Just like people are learning the strange new semantics of Rust right now. To be honest, if the Rust developers are capable of developing the perfect library with perfect semantics after giving it some serious thought, I fear for the future of the language, because those people are going to be in high demand to work their magic for other languages or products in development. Nobody has been able to do it right the first time in the history of development. That's a rare skill, and a marketable one. :-)
Frankly I think you’ll find that such a prosaic implementation of `FromStr` on an enum is uncommon. The only situation where a `#[derive(FromStr)]` could really make sense is for a C-style enum, and even there you won’t normally care for such a direct comparison between string representations and the variant names. Therefore I don’t think that it would be a useful thing to have.
What really grabbed me on their homepage was this: &gt; Codius is an open hosting protocol. It makes it very easy to upload a program, whether you want it to run on one host or thousands. &gt; &gt; It also has built-in billing. That means once a program is uploaded, anyone can pay to keep it running — the author, the users and even the program itself. I've used many webapps that were shut down through corporate acquisition or simple cost-cutting. I'd be much happier to put my time and data into such a system if I know I can kick in a few bucks a month to keep it going. I have no idea if their technology can deliver on this. It sounds pretty far-out, but I like that :)
There is (kind of). When referencing a value, rust will try to dereference until it has an acceptable type. That is: let a = String::new(); let b: &amp;str = &amp;a; // gets converted to &amp;*a; let c = &amp;a; // Is an &amp;String let d: &amp;str = &amp;c; // gets converted to &amp;**c; Basically, rust will fill in any number of `*`s before an `&amp;` to get the right type. Note: this works in this case because `String` implements `Deref&lt;Target = str&gt;`.
Rust and Cargo is specifically designed so that everything works fine with diamond dependencies. Rust enforces coherence and Cargo uses versioned dependencies.
Have you considered rendering the hex tiles with Unicode full-width characters, the ones that take up two character cells? I believe there's just about a full ASCII set, which isn't much compared to all of Unicode, but is no worse than Rogue had to work with. ;)
Yes, Cargo can build two separate versions of X and link them.
Thanks! I'm somewhat interested in audio in general. I find Rust interesting because of its non-alloc core separation; it looks like it should be possible to write hard realtime code with the `no_std` stuff. Speaking of that, how do you think about the realtime concerns of audio programming - i e, never getting an underrun in low latency code?
I haven't. I wasn't aware that this is possible. So far any Unicode character that was too wide, was ruining whole display (ncurses). Also, I have noticed that Putty has weird issues displaying even single-wide unicode characters. :/ I've implemented a neat trick that blends "empty spaces" between main coordinates and so far I'm happy with how this looks.
&gt; I forget what Nim was doing for memory management but IIRC it's primarily garbage-collected, which requires a heavier-weight runtime, dependence on heap allocation, and is non-deterministic--artifacts I wouldn't want to deal with in developing an OS kernel. Indeed, mostly you use Nim with the [garbage collector](http://nim-lang.org/gc.html). But for writing an OS the GC is deactivated, so you have to manage your own memory.
I believe what he means on module system is that "crates" and "rlib"s are Rust's invention. Objects compiled from C files are conventional. What Nim does for memory management is raw pointers and optional garbage collection - so in OS kernel it's probably much more like C anyway.