So \`\*mut foo\` is an address-of operation? Uh. Not sure. I wonder if \`&amp;raw\` has any chance of being accepted.
&gt; and undefined behavior is invoked in release builds. Not true. While overflow is checked in debug builds, Rust defines wrapping behaviour in release builds as two’s complement wrapping like most modern CPUs do natively. Source: [Myths and Legends about Integer Overflow in Rust](https://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/) by Huon Wilson
Listed in my [crates list](https://users.rust-lang.org/t/list-of-crates-that-improves-or-experiments-with-rust-but-may-be-hard-to-find/17806), together with `bus` itself.
&gt; By default, both signed and unsigned integers in Rust have "checked (UB) arithmetic" - that is, an assert is triggered in debug builds when -C overflow-check=1 and undefined behavior is invoked in release builds. I don't think this is correct, Rust goes from _checked (assert) arithmetic_ in debug builds (ie _-C overflow-check=1_) to _wrapping arithmetic_ in release builds. If Rust actually allowed UB in overflow it would be trivial to exacerbate it to arbitrary memory safety issues.
Thanks, I didn't know that. I always assumed that it would just be "unchecked" since `-C overflow-check=0`. I've updated the comment with that.
This was mu point about Windows. you can `__try/__except` the access. You may still be in a bad spot even if you do this. OOM handling becomes a thing only on custom/embeded systems. On most modern OSs you can't do much to protect yourself. 
"old and boring" in functional programing, but "modern" in systems programing. ;)
I've been looking for a way to get unchecked arithmetic in Rust without any luck, do you know if this is possible?
Modern 64 bit architectures generally don't take a hit from this, since the difference between log₂(32) and log₂(64) is small enough to sweep under the rug with a little hardware. 32 bit architectures do require extra time, but that's down to missing functional units and needing to do the operation in two parts.
Edited to `project based` due to existing approach for `examples/**/main.rs`.
It's always a good time to get into a language. But to give a more helpful answer, I'm only recently hearing of people doing Rust as there primary language at work but plenty of mentions if people using the language for optimising hot code over writing C/C++. Specifically making use of WebASM I'm sorry I don't know too much about the state of Rust's support for it other than it can target it. 
Yes. In particular, WebAssembly has first-class support in Rust. You should start by reading TRPL (The Rust Programming Language Book), in particular, the FAQ: [https://www.rust-lang.org/en-US/faq.html](https://www.rust-lang.org/en-US/faq.html) 
If the CPU natively wraps, then there's no performance penalty incurred from wrapping arithmetic. It would only make a difference if you were targeting an architecture which has some other default behavior.
Reposting my question since the last post was a wek ago. Why are Futures so hard (unergonomic)? Are there any examples from the web which uses Futures **extensively** so as to see how they are used and how I may learn a lesson from them? My main gripe is that if I continuously using closures to augment the functionality of futures the end code may look a lot like spaghetti and a lot of nestings. I tried to mitigate the problem by moving the futures into their own (generic) structs or to their own functions that return new futures but the compiler "expected a type parameter".
As far as I understand Rust 2015 is an other name for the language implemented by rustc 1.0. The compiler named rustc 1.28 is able to compile Rust 2015 programs, and therefore you can call it a rustc 2015 compiler. Furthermore rustc 1.28 has understands some additional language features that are not part of Rust 2015. These features will be probably part of Rust 2018.
If someone wants to just launch into it, here's the book: https://doc.rust-lang.org/stable/book/second-edition/index.html
&gt; I am a web developer by trade Of course an unpopular opinion here, but no not for you unless you are looking to expand/move into other kind of work.
Can I ask why?
Rust is great for native code. Running on the server or client in a mobile/desktop app. You are not doing this so Rust will be of little help. WebAssembly until it has access to DOM is of limited use atm.
It depends. If you are doing in it in order to find a job as soon as possible I wouldn't advice it.
32 bit integers are not normally faster than 64 bit integers, since computers tend to have functional units for both, and these are sufficiently parallel that size doesn't matter a great deal. In fact, on Skylake Agner Fog's instruction tables point to some cases 32 bit is slower! Instruction | Operands | µops | µops each port | Latency | Reciprocal throughput :----------:|:--------:|:----:|:--------------:|:-------:|:----------------------: MUL IMUL | r8 | 1 | p1 | 3 | 1 MUL IMUL | r16 | 4 | p1 p0156 | 4 | 2 MUL IMUL | r32 | 3 | p1 p0156 | 4 | 1 MUL IMUL | r64 | 2 | p1 p6 | 3 | 1 That is, a 64 bit multiply has lower latency and takes fewer µops ('internal' instructions) than a 32 bit multiply. It's throughput is still one per cycle, though, which means if you're doing multiplies in parallel instead of in sequence you won't see any speed difference. Signed and unsigned integers generally don't have different speeds either, because they use the same functional units, most of the time the same *instruction*─this is one of the major reasons two's complement is used to represent signed types. C and C++ suffer from a historic design artefact that makes their signed and unsigned operations not equivalent (overflow is UB only for signed types); Rust uses a single rule for both (no UB). This means C and C++ may show differering speeds simply down to a signed add not meaning the same thing as an unsigned add. [There is a proposal to fix this in C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0907r0.html); let's hope it passes. Sometimes you will see little differences simply due to instruction choice, but this is context-dependent. Sometimes, for example, you need to zero the top 32 bits when a 32 bit value is held in a 64 bit register, which might take a cycle. Primarily, though, the modern reason for there to be a speed difference because of this choice is SIMD; a 256 bit vector has space for 8x32 bit operations or merely 4x64 bit operations. So if the compiler can vectorize your code, use small types!
Just a wild guess: Is your demo format supposed to be interpreted as 1 byte per component? Because I think glium interprets it as _4 bytes per component_ (not per texel) when you pass `DEMO_FONT as `[u32]`.
WebAssembly is pretty cool and Rust has good support for it, but the cases where WebAssembly is clearly superior to JavaScript are not that many for now. It's mainly very good for heavy number-crunching or for cases where you have some existing Rust code that you want to bring to the web and it would be too much work to port. One other very interesting aspect of Rust is that it's a fairly low-level language that is still relatively easy to understand and use for people coming from languages like JavaScript, and it integrates well with NodeJS on the server (through native bindings or WebAssembly) and with the browser (through WebAssembly). One problem with that though is that the Futures (called Promises in Javascript) and async/await support in Rust is still not quite ready yet, and there's likely to be some churn this year on that front. It's entirely possible to write Rust without using Futures or async/await, but coming from JavaScript that will probably be the style you are most familiar with. 
regarding comments on SIMD, note the trend with CPU design is toward adding instructions that make it easier to vectorise general purpose code, e.g. VGATHER. Some machines may have unusual issues (there are situations where keeping things in a machine's preferred size is faster.. craziness on the CELL years ago meant padding some data out to 128bits lol) but in general if you reduce the number of bits to the minimum needed, you can fit more into a cache or into a register, or use more computational resources in parallel
Check out [`wasm-bindgen`], especially the `web-sys` crate. You can already interface with DOM bindings if you write the type signatures manually. Hopefully, you won't need to even do that soon. [`wasm-bindgen`]: https://github.com/rustwasm/wasm-bindgen/
Check out the amethyst project for a crate that already does this-ish.
Thanks for reminding me. Amethyst’s examples are arranged in examples/**/main.rs, while my rfc suggests examples/**/ where inside the folder is a complete cargo project. 
Care to tell what do you do? Was using Rust a company wide decision, or Yoy have a position that allowed you to choose your own tools?
Is code [like this](https://godbolt.org/g/jqv3Eb) an example? It gets optimized quite nicely. Even better then the C++ code in comments at the bottom.
That is not true. Sources of undefined behaviour always lead to enablement of optimisations. Lack of UB, then, prevents optimisations from occurring.
**[AES instruction set](https://en.wikipedia.org/wiki/AES_instruction_set)** &gt;Advanced Encryption Standard instruction set is an extension to the x86 instruction set architecture for microprocessors from Intel and AMD proposed by Intel in March 2008. The purpose of the instruction set is to improve the speed of applications performing encryption and decryption using the Advanced Encryption Standard (AES). ***** ^[About](https://www.reddit.com/user/ultimatewikibot/comments/90r969/about) ^| ^[Leave](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) ^[me](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) ^[alone](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) 
Yes you can at the cost of the JS-WASM bridge. For anyone familiar and is already using standard web technologies, moving to Rust makes zero sense unless they have a very specialized use case. You are just making your life difficult for no reason. 
Because it makes using JoinIter much more complicated. IMO you should instead check if the iterator's item can somehow be converted into the separator's type. Sadly, isize does not implement Into&lt;String&gt; or anything as far as I can see.
&gt; Sources of undefined behaviour always lead to enablement of optimisations. Lack of UB, then, prevents optimisations from occurring. Undefined behaviour isn't magic. Making overflow undefined in C allowed the optimization of "just call the CPU's native instruction without checks". Since then, the vast majority of CPU architectures have *de facto* standardized on two's complement wrapping, so Rust defined overflow as "Promise what every major CPU does natively, so it'll just be a loss of performance rather than a potential security hole if you run the same code on a niche CPU that does something else." Where do you think UB would magically allow further optimization on a CPU that natively does two's complement wrapping?
The pure aesthetic pleasure of type-fu.
I referred to [this blog article](http://edunham.net/2016/04/11/plushie_rustacean_pattern.html) when doing sewing works. I did modifications on the eyes ane mouth to make it more cute. And I photoshoped these photos to put them together as reddit only allow me to send 1 photo per post.
That's certainly true at the moment. It's only really useful at the moment for stuff that you must wouldn't consider in js at the moment - like building a relational database on top of indexeddb, or calculating sha hashes, etc.
Could you elaborate on this? I understand UB makes certain optimizations possible, but you claim that these same optimizations are impossible without UB. That's a big assertion. I'm not inclined to agree with that without a source. It's my understanding that the extra invariants of Rust can enable the same optimizations.
Maybe if `raw` was made a contextual keyword and you write `&amp;raw const x` and `&amp;raw mut x` (using `const` here because `raw` isn't a keyword) Note: your inline code blocks aren't working because you're using the WYSIWYG editor, try the markdown editor.
Don't use deny(missing_docs)! 😋
&gt; But unchecked arithmetic should just invoke undefined-behavior on overflow, which is different from wrapping. Undefined behaviour is not a concrete thing you invoke. It's a blank check for the compiler's optimizer to output whatever it wants. Wrapping without a check is one of the possible things the compiler could output that satisfies the constraint of "undefined" and it's also the most efficient thing on the vast majority of modern CPU architectures. That's why Rust standardized on it. (Don't think of it as "Rust wraps instead of undefined behaviour". Think of it more like SIMD. C will do whatever is fastest for the CPU. Rust will insert a shim if the processor doesn't provide the "hardware-accelerated wrapping" that all major CPU architectures specify.)
Just in order to make it complete :)
I'm writing a cli task management tool for personal use called 'imeci'.
In the context of the `failure` crate, what is meant by a "backtrace"? An error has a chain of "causes", that is, you can get all the errors that led up to the one you're handling right now, which is sort-of-the-thing you might want to print to your user. What then is a backtrace for an error? I know what a backtrace for a panic is, but I can't really connect that to errors.
\&gt; will be awesome in the future \^ this.
IIRC overflow panics in debug only and triggers UB in release.
[https://www.arewewebyet.org/](https://www.arewewebyet.org/) Has a broad overview of the current situation. The high level comment there bares repeating: &gt; **If your service primarily provides an API** to be consumed by other computers, requires little external services and you are happy with writing most SQL yourself, then **Yes, You Can!** Otherwise, we would not recommend it just yet.
I made this mistake too :(
&gt; WebAssembly until it has access to DOM is of limited use atm. On the other hand, if /u/aiiqi learns Rust now, then they'll be prepared when the DOM interfaces become available, and might be able to help move them forward. It's also notable that interop with JavaScript just got a bit boost with the release of [js-sys](https://rustwasm.github.io/2018/07/26/announcing-the-js-sys-crate.html). This may lower the barrier to entry enough that you can write core logic in Rust then ship the data to JavaScript for rendering.
I'm not sure this is possible to implement for arbitrary type `T: Serialize + Ord`. Consider a type `struct Foo { x: X, y: Y, }`. Let's make it implement `Serialize` via `serialyze_seq` which is used to serialialize `x` then `y`. Now if it implements `Ord` but compares fields in opposite order (`y` then `x`) then serialized bytes will be compared differently.
&gt; On the other hand, if /u/aiiqi learns Rust now, then they'll be prepared when the DOM interfaces become available, and might be able to help move them forward. Even then the advantage of Rust compared to existing way of doing frontend development is limited. 
I don't think reddit is where you're supposed to propose things for rust, nor is "remove this thing i dont like" the proper way to propose things at all, nor is one mistake enough justification to propose something like this anyway. Especially when it's easily caught by linters that you werent running for some reason? It may be worth adding an optional compiler warning for it though. 
I'm not proposing to remove anything. Linters WERE being run, not just this flag. Lesson learned. What a dangerous default...
Is it really so dangerous, though? It was only one mistake out of how many lines of code?
Your font sheet has dimensions of 192 * 192 and a length of 36864 **items** a **32** bytes, but `RawImage2d` more or less expects your data in `u8`s - note the documentation: "data.len() must be equal to width * height * format.get_size() / mem::size_of::&lt;T&gt;().". Since `ToClientFormat` returns `ClientFormat::U32U32U32` for an array of `u32`, RawImage2d assumes that the source is made up of **4 * 32 bytes** for one pixel, instead of the actual texture having **4 * 8 bytes** packed in one pixel. The easiest way around this is to declare your `FONT_DATA` as a `[u8]` instead of an `[u32]`. Also you can use `include_bytes("my_image.blob");`, you don't need to paste the numbers making up the texture in your source code, the compiler can do that for you. Aside from that, you can make your `FONT_DATA` const instead of static, so just do: `const FONT_DATA : &amp;[u8] = include_bytes!("prerendered_font.blob");` Now, `FONT_DATA` will be a (compile-time) array of 147456 items a 8-bits, with 4 byte making up one pixel. Now `RawImage2d::from_rgba_reversed` will work, since `ToClientFormat` for `[u8]` returns `ClientFormat::U8U8U8U8`, which is the correct format for the source texture.
It's dangerous because it makes for the kind of bugs that's very hard to detect and track down.
Your claws came out fantastic! Mine were a bit too flat when I tried it.
Opening up a subset which won't compile for lack of dependencies would still be useful to ensure the reimplementation doesn't introduce edge-cases in how it responds to requests from a given game's UnrealScript components.
I *believe* GP's question was: if this problem was caught after the fact with the linter, why weren't you linting against this in the first place, and why can't you just turn that lint on the future? Personally, I see rebinding as just a safer variant of mutable variables. We have immutable bindings to guard against mistakes with mutation, so it seems reasonable to have a way to avoid mistakes with rebinding. I'm unconvinced in regards to disabling it by default, though.
I filled as much cotton as possible into it and compacted it using a pair of chopsticks. The claws turned to be very hard in the end. :) 
&gt; like this No, Rust doesn't have any `unchecked_add` intrinsics, so you can't really do what C++ does here.
&gt; Sources of undefined behaviour always lead to enablement of optimisations. Not quite. UB means we can make additional assumptions, which means we *may* be able to reduce instruction count or use faster instructions. But this is dependent on the program and the instruction set. &gt; Lack of UB, then, prevents optimisations from occurring. Also not quite. Lack of UB means lack of certain assumptions. But explicitly defined behavior means that 1) we get some assumptions, 2) at the cost of enforcing the defined behavior. If the architecture defaults to the behavior which the compiler enforces, then the cost in 2) is 0, and we get free assumptions / potential optimization.
&gt;why can't you just turn that lint on the future? We did. This is a warning to future projects to avoid our mistake of not doing that in the first place.
&gt; Don't think of it as "Rust wraps instead of undefined behaviour" I don't think of Rust like this, I think of Rust like "Rust does not have an `unchecked_add` intrinsic", period. One might be able to emulate it with `core::intrinsics::assume` though, but I don't know how good that would work.
&gt; I see rebinding as just a safer variant of mutable variables. What's the problem of having a rebind keyword for these cases to avoid costly mistakes?
&gt; If the CPU natively wraps, then there's no performance penalty incurred from wrapping arithmetic. The performance penalty comes from the compiler not being able to assume that wrapping will never happen which allows certain transformations to become possible. These types of optimizations come before the target specific ones in the pipeline. 
I have a couple on-going efforts in [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) that I'm planning to work on this week. The first is going through build scripts in an effort to reduce CI build times and the second is to finish reviewing the changes to support thermodynamic temperature and temperature interval and merge those changes in to master.
No, integer arithmetic guaranteed to either return the wrapped result or to not return at all (e.g. panic). If it were UB, you couldn't do integer arithmetic outside an unsafe block, which would be mighty inconvenient. (Though there are some similar compiler bugs, like casting out of range floats to integers resulting in UB. But since these are bugs, they'll hopefully get fixed at some point)
Note that even C doesn't just call overflow UB: it does for signed integers, but unsigned are defined to have wrapping semantics. Additionally, leaving overflow undefined is even something even stronger than just being unchecked: that sort of arithmetic is effectively a strong hint to the compiler that overflow will not occur and it can optimise based on this. This isn't the same as just "do whatever the hardware does" (the C term for this would be "unspecified" behaviour).
&gt; Where do you think UB would magically allow further optimization on a CPU that natively does two's complement wrapping? I've answered this here: https://www.reddit.com/r/rust/comments/931leq/why_are_i32s_the_fastest/e3aa2vx/
Increased verbosity to defend against something that, in my experience, isn't that significant a problem. Depends on how it's handled, I suppose. Incidentally, if you really want to build support for this, your best bet is to *show* cases where implicit shadowing has caused issues, so people can directly see the issue. Also, you *might* be handicapping your argument somewhat by suggesting that we break lots of people's existing code, and by playing the "this will kill people" card.
&gt; At this point, I did do a bit of research into existing streaming UTF-8 support in the Rust ecosystem, but didn’t get too far. If there is a go-to solution to this kind of thing, I’d love to hear about it. It looks like encoding_rs would support some of this, for example. I started experimenting with this via the [`encoding_rs_io`](https://docs.rs/encoding_rs_io/0.1.1/encoding_rs_io/) crate. I think the "future work" section in the docs should properly put it into context, but I'm happy to answer questions. The primary advantage of using something like `encoding_rs` is that it operates on chunks as opposed to a byte-at-a-time iterator. Operating on chunks allows all sorts of nice things to happen in terms of performance.
I think shadowing can be useful, so I don’t really understand what you’re saying. Can you give more specifics about the bug? Is this a case of creating a new variable with `let foo = …;` where what was intended was to mutate / assign to an existing variable?
Not on topic, but I would be in favour of disallowing bots by default.
As mentioned here: https://www.reddit.com/r/rust/comments/931leq/why_are_i32s_the_fastest/e3aa0i9/ One might be able to work around this by using `core::intrinsics::assume`, but I don't know if LLVM does always transform a wrapping add into an `add nsu nsw` when the appropriate `assume`s are present.
I recall yet another such mistake made by one of Rust core devs. I hope our comments will motivate others to find a solution.
\&gt; I think shadowing can be useful, so I don’t really understand what you’re saying I think it's pretty obvious. You have a long function and in the middle you want to introduce a variable "x" for some purpose. Problem is, it was already declared ABOVE and used BELOW, so now you've changed the semantics of the function.
&gt; "this will kill people" card I admit it's a bit over the top, but I stand by my position: this is a dangerous "feature". I think a show case would be good, but I'm sure you understand that the ENTIRE problem is that this causes issues in large code bases. A small example would be shut down by "don't do that" statements, which is futile. I think it's pretty obvious that allowing rebinding of a variable in the middle of the lifetime of an existing one is rather dangerous.
I think we've hit peak rust, tbh. ;)
Whilst I can see why it might be hard to track down, but then so are all the other bugs that Rust has actually solved 100% . All sorts of applications are currently being written in languages that do not solve these problems. It's probably worth a look at the benefits vs cost of local variable shadowing but I don't think it needs to be done in the context of hyperbole.
I'm sorry I'm only joking, but using warn is preferable IMO because deny cascades into dependencies and bites you sometimes.
*You* believe so, but the fact that it's been a relatively uncontentious part of the language for quite a long time should be clear proof that not everyone agrees with you. If it was obviously so awful, it probably wouldn't be in the language. If you want to effect change, you have to *convince* people. That's going to be *much harder* if you come across as the crazy beard guy in the street holding up a "doomsday is here, shadowing will kill us all" sign, or if you outright reject the world view your "opponents" hold.
Another random use case - build an excel file from some data in the browser.
Hi, I'm seeing you get some push back to your proposal. I am not related to Rust in any professional capacity, but I think I can offer some feedback. I'd like to make it clear that all of us share your concern and certainly don't want to minimize the impact this had on your client. Your feels like you're still in panic mode about what happened and this is reflected in your proposal. Decisions made when in this state are often reactionary and suboptimal because you're not allowing yourself to think about it clearly. The push back you're getting is not because your issue isn't important, but because this way of approaching problems leads to problems down the road. If I may, I recommend you post an issue on [the Rust issue tracker](https://github.com/rust-lang/rust/issues) ^if you don't have a github account, I or others don't mind doing this for you. Do not make the issue about your proposal! Instead treat it like a bug report. Explain with concrete examples (preferably the actual code snippet that caused the problem) how this mistake was able to be made. Actual concrete evidence will help your cause a lot more than hypothetical examples. This will allow the Rust community/developers to give serious thought to this issue and come up with ways to guard against this error in the future. Whether this is in the form of linting against shadowing by default or some other mitigation can then be discussed in detail. It is important to know that we are sympathetic to your issue, I'm just trying to help you express it in a way that will find acceptance and enable people to work with you on this issue instead of finding yourself at odds and being frustrated at being pushed back against.
Nice! It also looks like the whole crate can be used in a \`no\_std\` context, which is awesome for embedded or OS developers!
It's always a good idea to improve and broaden your skillset. That could be Rust, or it could be something else. Pick something interesting and challenging to do with your new technology and see it through to completion. At the very least it is something to put down on the resume. Even if employers aren't interested in that skill it still demonstrates that you are capable of learning new skills. Whether Rust is right is another matter, but web developer is a fairly nebulous term and it wouldn't hurt to have some kind of server side, or compiled language to complement whatever you write for browsers.
And these variables had the same types or whatever functions were accepting them were able to take either of then despite them being logically different? I'm not sure shadowing is to blame here, it could just as easily have been a typo and there's no lint under the sun would be able to catch that situation. Insufficient typing sounds like the root cause of this logic error to me. I'm fairly neutral on the topic of shadowing, but this doesn't sound like shadowing's fault.
I find shadowing extremely useful, and allows me to "mutate" variables without having to make them `mut` (which basically forces me to keep in my mind that the variable can be mutated at any point): fn foo(a: u32) -&gt; u32 { let a = a + 1; a } 
Heyo, mostly backend web-dev here. I've been doing Rust off and on for 3 years. Here are my thoughts: 1. Assuming you just want to learn something new and have something fun to hack on that expands your mind, Rust is a fantastic language. I've learned _so_ much writing Rust. So much, in fact, that I've become really unhappy doing web dev and I want to move further down the stack. I've quit my job and I'm going for it. Which brings me to point two: 2. If you want to be writing Rust as your primary language, or even 30% of the time, you're going to need to learn C/C++. Very few people are hiring Rust developers who don't have C/C++ experience because anywhere writing lots of Rust is also going to be writing lots of C/C++. There's just no such thing as a "Rust shop" yet, outside of Mozilla. 3. If you're not looking to move into full time Rust development, Rust is still a really useful language. There are all kinds of tasks that don't call for ultra-low-level programming but still benefit from a language with performance at its core. Rust is great in these spaces: You can write what feels like high level code but tune it to your performance needs. It's really fantastic. tl;dr: Yes! Learn Rust! But not if you want a Rust job. 
I hope to release Thumbcloud 0.0.3 this week. Thumbcloud is an app/server to share files on your local network (built with actix-web). This version will be the first one to be actually usefull. For example you will be able to upload and download files and browse through the shared directory. I will write a post about the app and my journey developing it, on this subreddit after the release. www.github.com/flofriday/thumbcloud
For embedded development it will be also nice to add hardware accelerated ARM [implementation](https://github.com/RustCrypto/block-ciphers/issues/10). But unfortunately related ARM intrinsics are currently available only on Nightly and I don't have hardware right now to test code on.
We are a group of developers responsible for in-house software infrastructure for a decent-sized company in the field of data storage. We develop tools and infrastructure which is used in multiple places along the development pipeline - with a strong emphasis on the testing and integration phases. We try to encourage people to explore new technologies which could benefit our projects and tools, and Rust came up a while back as a promising endeavor. We started with a relatively small project using it and are slowly in the process of migrating more and more of our code base to it, so far with very pleasing results.
New rustacean here. I've been wondering why this feature exists since the very first time I read about it. The minor convenience of not having to think of another variable name doesn't seem worth the risk of inadvertently substituting a value. Of course, the error can be detected, but does the work involved in using a new label really greater than the work involved in detecting such an error? I am yet to be convinced.
Great to hear. It's always nice to work with something that makes you tick the right way and not hate your job. Cheers and good luck to you all!
Finished up some upgrades to my RSS reader. Now I'm working on a little command-line app to connect to Questrade's API and calculate how to rebalance my stock portfolio. Even as long as I've been using Rust, I was still impressed by how I was able to build all of the command line arg parsing, configuration file support and the API connection code in 2-3 hours. I love how Rust can be as productive as Python once you get used to it.
I use `deny(missing_docs)` in basically all of my crates and I don't think it's bitten me once. The only thing it's done is help me, and it encourages contributors to include public docs in PRs. I honestly don't see how `deny(missing_docs)` would bite you unless the algorithm to determine missing documentation was changed somehow to include more things. AIUI, the general advice is to not use `deny(warnings)`, since new versions of Rust can introduce new warnings. You can do `cfg_attr(test, deny(warnings))` though, in order to cause warnings to fail the tests.
When completed, how do you see this framework will compare to Yew?
What's your color scheme?
Darcula
This is the kind of issue I wish there were a better solution to. Specifically, while shadowing is a fine thing to happen in many instances (as other commenters are suggesting), it happens too transparently. It's the kind of thing I want a linter to give me a warning about not because I want to remove it, but because I want extra attention drawn to it. When using linters, I set this kind of rule to "warn" and anything I actually never want in the code base to "error", but I wish there were other levels. "attention", for example. Alternatively, integrating the parser with the syntax highlighter would unobtrusively allow us to color variables with different (randomly generated) colors and make sure shadowed variables get different. This is probably a less practical though slightly more whimsical solution. 
Sorry, not my post, but I thought it was relevant to the Rust community! I think /u/snoyberg is the author!
This is exactly what bytekey is meant for, but the library predates serde, and I haven’t put any effort into keeping it up to date with the rest of the Rust ecosystem. As far as the data types supported, check out the big header here: https://github.com/danburkert/bytekey/blob/master/src/encoder.rs. If nothing else, it may provide a good starting place for implementing your own solution.
I think a case can be made that this isn't obvious in a code review. The local code in the change looks fine to the reviewer. However the reviewer can't see that the variable name is already in use above and below, and the compiler doesn't complain. So it is a danger particularly during maintenance of the codebase. (Actually it could be used to get malicious code into a project.)
Builders are another example of where this is very useful.
I think you're right - thinking about it it was when unresolved links in comments became warnings, which got upgraded to errors.
&gt; Do not make the issue about your proposal! Very much this. - Helps us focus on making sure we fully understand the problem first - Helps us be more open minded to alternate solutions. For example, if the current lint doesn't, maybe a good compromise is a new linto that only warn if the new variable doesn't consume the old one.
To format block code on reddit, prefix each line with four spaces
I sent off my PR to merge lldb into the rust build. While that's pending, I'm going to update my patch to improve debug info for enums.
It was breaking `core` in Linux kernel modules, mips, some ARM and MIPS targets, it was breaking `wasm32-unknown-unknown` on basically every update of `stdsimd` in rust-lang/rust, etc. All of this was happening even though `stdsimd` CI is huge, in that it tests all of tier1, most of tier2, beyond what rust-lang/rust does, running tests on almost all tier2 targets, etc. There were just too many issues that were all filled at more or less the same time (~3 weeks ago), and some were hitting beta. We just did not have the throughput to look and fix all of them in 6 weeks until the beta became stable. So... instead of trying to put out all of those fires as quickly as possible, I just waived the idea of splitting it into its own optional crate in the nursery (here: https://github.com/rust-lang-nursery/stdsimd/issues/525 - by then `packed_simd` was far from ready) and alex agreed that it was the best thing we could do given the state of things. So I sent a PR that did this (https://github.com/rust-lang-nursery/stdsimd/pull/528), while I sprinted to get `packed_simd` ready. The idea was to merge it when `packed_simd` became ready. But if you take a look at that PR, something else broke in rust-lang/rust and the best fix was to just merge that PR and update `stdsimd` upstream.
I doubt having `foo1`, `foo2`, `foo3`, `foo4`, and `foo5` around makes your code less bug-prone that just having a single `foo` which shadows previous `foo`s.
I hope not. Peak rust sill hopefully involve non crypto jobs
There *is* such a thing as a "Rust shop", but these are few and far between for now (there are a couple in crypto-currency things and was some mention of game development recently).
Is there a lint¹ that warns when you shadow a binding but don't change its type? let entry = entry?; Or the same using `if let` is a common pattern I see and use often. I expect this to be way less controversial (assuming shadowing is indeed controversial). ¹ will check this when I get to a computer
I'd still assume that anyplace calling itself a "Rust shop" is going to be doing a lot of C library wrapping and so on to get things done. It seems unlikely that a pure rust shop would be interested in a Rust developer who doesn't know C. But of course, there are always exceptions (well, maybe not in Rust, we get results instead). 
One thing I’d hope to see is more reusable parts. The current rust frameworks all have their own vdom, macros etc. Surely some of this functionality could be offered as crates?
I agree with you. This was a common source of hard to find bugs in Go, for me as well. However knowing to always lint it is a reasonable workaround.
Writing a mdbook for the CLI WG. Anyone want to help out?
Lint that checks that either the type is different or the shadowed variable is moved would be nice, I think. 
&gt; It's my understanding that the extra invariants of Rust can enable the same optimizations. That is specifically because breaking those invariants is UB. Since the compiler was told that there’s no way for that invariant to be broken, your code will not behave as an expected in… undefined ways. Thus an invariant (if broken) is a source of undefined behaviour and enables optimisations. Rust does not require any particular invariant to be upheld when operating on signed integers, whereas C requires for the operation on signed integers to not overflow (this is an invariant that is easily broken). This gives C more leeway to optimise in ways that Rust is not able to. See [this comment](https://www.reddit.com/r/rust/comments/931leq/why_are_i32s_the_fastest/e3aa2vx/) for a more in-depth example. Consider another example: `&amp;mut` and requirement to only have one such reference to the same object at any given time. This gives information to the compiler that it is allowed to do things (e.g. elide reads and writes) that wouldn’t otherwise be possible if `&amp;mut` was allowed to alias.
Extra bit to add to that: futures are available as a separate crate and provide combinators (like JS' .then) for futures and streams, but there are no generators or async/await. Two different versions of the futures are often used my the most recent versions of various crates due to them being unstable still. It's possible to use futures, and some do, but some stuff is going to get pulled out from under you as they stabilize. Your code should continue to compile tho if you use the old futures, but it just wont be able to upgrade trivially until the community stabilizes on std futures (which will be soon/months/days (for some) after they stabilize considering how fast the rust community adapts to such things).
jetbrains products has that kind of highlighting.
Yew is a very impressive framework! It very much served as a motivational example for Smithy. Hats off to Denis and the team for such a great framework. Overall, Smithy is a lower-level framework than Yew. First, Yew provides an Elm-like architecture, which can be summarized as: `DOM&lt;Message&gt; is generated`, `callbacks return an instance of Message`, `component::update(&amp;mut self, m: Message)` is called, and the loop repeats. Smithy does not provide that architecture. The biggest reason I made this decision is that not all messages might be valid at any one point in time, and there is no compile-time way to say "if you're in the ListView state, Messages::GoToListView is invalid" (I would love it if the Yew maintainers could correct me here!) This is even more complicated in the presence of asynchronous code. The Rust type system is stronger than the Elm type system and better at making illegal states unrepresentable. That being said, Smithy is *not* ergonomic or easy to use right now, and trying to stay low-level is a big reason :)
Yeah but you'd have to write very custom integrations with every editor, and it's probably less noticable than what the editor already does for linting (underlining, highlighting, margin sign, etc.). I've always wanted to try it but have never found/used a relevant plugin for vim. 
Yeah, we need to get beyond this point.
but of out topic but which monitor is it ? text looks really crisp and clear
Correct, I'm the author, thanks for posting and for the ping. /u/burntsushi: it looks like that crate is _exactly_ the kind of thing I was looking for, I'm glad you commented. The chunking discussion is interesting. In Haskell, we absolutely need chunking for decent performance, because otherwise we'll be swamped in insane amounts of garbage collection. Instead, with chunking, we end up with a situation along the lines of: * I/O call to grab a chunk of data from the file descriptor as a `ByteString` * FFI call to some C code to decode the UTF-8 points into a `Text` value (chunked characters) * Perform operations on the chunked `Text` values * Same in reverse for writing Unless I'm mistaken (which I very well may be), the Rust code I wrote will instead do something like: * Read the values from the file descriptor as chunks into a buffer * Use `Iterator`s/`EIterator`s to stream individual bytes, then individual characters, then back to individual bytes * Fill up buffers of bytes and then write the values as chunks to the output file descriptor The important bit being: the I/O is still performed in a chunked manner. The rest of the code should be CPU bound. Without benchmarking, I can't say how much of a performance impact—if any—the element-wise operation has in Rust. I just know that with the coroutine-based implementation of conduit in Haskell, such an approach would be massively slower.
Yes, I understand all of that. That is exactly what I was referring to when I said "this isn't the same". My point is "unchecked" arithmetic doesn't have to mean "undefined behaviour". Whether overflow is undefined behaviour or not is an extra question on top of a "unchecked" answer to whether overflow is checked or unchecked. (Also, I edited an extra paragraph into my comment soon after I posted it, that you may have missed.)
&gt; UB means we can make additional assumptions, which means we may be able to reduce instruction count or use faster instructions. In some specific example, yes. By saying “always”, I meant this: ∀U.∃p. where U enables an optimisation in p where `U` is a source of undefined behaviour and `p` is a program. If this equation wasn’t true, then the source of undefined behaviour is absolutely worthless and should get defined :) --- &gt; Also not quite. I guess “lack of UB sources or invariants” is a better phrasing :)
Ayu dark is similar
&gt;Instead treat it like a bug report. Explain with concrete examples. Thanks for the feedback, much appreciated. I feel the problem is that this issue is the kind that only tend to rear its head in large code bases. The mistake is easy to spot (and debunk) in a testcase-style example, and will thus not generate a good discussion. I think the overall concept and why it's dangerous (my claim) needs to be explained, and I'm not sure how to.
An explicit way to rebind a name to a new value would be quite awesome. I agree that it is very useful but can also be dangerous.
Yes, useful, just like pointer arithmetic is useful when writing device drivers. Pointer arithmetic is dangerous, and I claim shadowing is dangerous as well. Local variable shadowing would STILL be useful if an "rebind" keyboard was required, and that would make it very hard to make mistakes.
その算法の本がいい奴？
Exactly. In fact, the mistake was done during refactoring.
&gt;this class of bug it could just as easily have been caused by a typo That's not true. Certain variable names (like length, size, x, i) are very common and easily shadowed by mistake.
It's true that chunking I/O is one aspect of this, but it's not the only one. UTF-8 decoding might be implemented using vector instructions, and/or it might benefit from other types of algorithms that are capable of processing multiple bytes at once. I would speculate that there may be other bad things about doing byte-at-a-time, but now we're probably talking about how well the compiler generates code for your particular iterator. I note that in your description of the Haskell implementation, it sounds like you are doing more chunking there than in the Rust implementation. Namely, you are benefiting from chunking not only at the I/O layer but also at the layer of UTF-8 decoding by decoding potentially many codepoints at once. The other twist to this, that `encoding_rs_io` specifically tries to solve, is that UTF-8 validation may not even be what you want, because something further down the pipeline can handle potentially invalid UTF-8 implicitly (say, a regex engine). And _that_ also benefits from chunking for similar reasons. The `encoding_rs_io` implementation was born inside ripgrep, and I wrote it the way I did because it seemed like the fastest possible way to do it without building (say) UTF-16 into the regex engine. Indeed, if I enable SIMD optimizations everywhere, searching UTF-16 encoded data is only about twice as slow as not doing decoding at all. Which is pretty impressive. (And that's not because of work I did, but because of the awesome optimizations in `encoding_rs` proper.) Disabling SIMD optimizations has a notice impact, so there is definitely benefit from using vector instructions that would be defeat by byte (or character) at a time iterators.
&gt;clear proof that not everyone agrees with you That much is clear. I still stand by my position.
It is true, comparing running checks versus not running checks. Just because there are no checks (that is, arithmetic is "unchecked"), it is not automatically true that overflow is undefined. You are entirely correct that there is a difference if overflow is undefined, but that's a different question to just being unchecked.
&gt;It's probably worth a look at the benefits vs cost of local variable shadowing I did, and my conclusion is that shadowing should be allowed, but only in the presence of a "rebind" keyword. That solves the problem, and makes intensions clear. Sure, some existing code will break, but in my opinion it should break (most likely a few bugs will be discovered)
&gt; Maybe a good compromise is a new lint that only warn if the new variable doesn't consume the old one I think this lint would indeed be very useful and I would use that by default and I really like shadowing variables. But all other cases in my codebases at least would most likely be bugs or simply misnaming of variables. However instead of only consuming, there's also the case of locally borrowing which should be considered though. E.g. ```rust let mything = some_arc(); { let mything = mything.make_mut(); do_things_with_mything(); } ```
I think it's exactly the same, a code backtrace like you'd get in managed languages.
As a web developer also getting into Rust, why not? Learning another language is always good. I've been learning Rust (while playing with Haskell) and reading [Professor Frisby's Mostly Adequate Guide to Functional Programming](https://drboolean.gitbooks.io/mostly-adequate-guide-old/content/) and the overlaps and differences have clarified a lot of things. The little functional background I have has made me uderstand some Whys about Rust's designs, and Rust (specifically its error-handling) has influenced how I write JavaScript. Also, the [Rocket](https://rocket.rs/) framework is a good entry point to backend web development with Rust--especially for someone coming from Node.js. Here's [an example](https://github.com/crashspringfield/prrr_demo) Rust/Rocket web app I build, with links to articles in the README. As far as job prospects....? I like to think that by the time I get competent at the language there'll be more. 
Thanks! Once you get the hang of Rust, it does make programming more fun - no doubt about that. Also - the community is simply awesome.
Are you mad?! O.o If you want a library to be complete (if you're developing, there's no point, we agree), you should definitely use it!
Good proposal, make it explicit. I've always hated LV shadowing myself specially feels put of place in rust. 
That's what I was doing initially, I might switch back if it breaks some builds. 
Aha, I saw the Stream Cipher trait I always wanted.
I'm going to add a couple of features to [kickstart](https://github.com/Keats/kickstart) (a tool to easily start a project based on templates) and release 0.4 of [Gutenberg](https://www.getgutenberg.io).
Or cryptography jobs
Hmm, I don't know what I would get in managed languages, I can just compare this to a panic. But a panic has a clear "start point" so you can print the call stack when it happens, an error moves around in code, is subsumed into others, maybe discarded...
Thank you! You know, it's interesting. I had considered a number of levels of genericism— for instance, allowing you to provide an iterable separator, or a closure. But in the end I settled on this design, which felt to me like the right balance. As a side note, it's worth noting that I did play around with an interleave based design. It's actually non trivial, because the decision about whether to emit another separator is based on the state of the primary iterator; the two streams aren't independent.
I actually do do that! Rust doesn't have all the sort complex TMP stuff that C++ has— SFINAE, CRTP, etc— but I do implement `AsRef` and `into` on JoinItem, as helpers for converting them to a value or reference of a common base type.
&gt; I think it's pretty obvious. You have a long function and in the middle you want to introduce a variable "x" for some purpose. Problem is, it was already declared ABOVE and used BELOW, so now you've changed the semantics of the function. How large of a function was this? Why was it so large? Granted, I am very aware that we can't always have perfect code and we shouldn't dismiss problems with the language with "write better code" (otherwise we'd still be using C).
&gt; I feel the problem is that this issue is the kind that only tend to rear its head in large code bases. I've seen you make a couple references to large code base. Could you help me understand why this problem is unique to those?
I completely agree, I've been surprised by it in C++ as well and it baffles me that it's acknowledged as a feature in the Rust Book
Types catch some cases, but I believe the real issue is locality of information. A chain of let x = foo(); let x = bar(x); let x = quux(x); is not confusing regardless of whether those are of the same type or not. But if you separate these by large blocks of code, then there're lot of places where you may be mistaken about the value of x, all the while thinking that x couldn't have changed because it's immutable. let x = foo(); /* code */ // predictable x let x = bar(x); /* code */ // x didn't change, right? let x = quux(x); /* code */ // of course not, x is immutable That may cause type errors or it may not (shared method names, shared Trait impls). Maybe we should lint against a long lived binding shadowing another long lived binding for some heuristic of "long lived". Shadowing chains in the same scope are easy to spot. Shadowing of an outer variable in a short lived scope also preserves locality of information and should be fine. let x = foo(); /* lots of code */ // predictable x { let x = bar(&amp;x); quux(x); } /* lots of code */ // predictable x
I was wondering if references would be valuable but I couldn't remember how. Inner scopes do make sense. Granted, I think within the same scope (my original intention) and nested scope (your example) are different problems to consider.
Still working on my [distributed experiments](https://github.com/pierre-l/Pierre-s-Distributed-Experiments). I'm making progress on the cryptocurrency simulation: chain verification is almost complete, I'll then have to implement the miner and the network. I'm thinking about working on blockchain shardingas the next topic :) Have a nice week!
iMac 27’ 5K
The *Introduction to Algorithm*
/r/playrust
thanks
&gt; My point is "unchecked" arithmetic doesn't have to mean "undefined behaviour". Ah, I see what you meant. Yeah, I shouldn't have used the word unchecked I guess. Unchecked without undefined behavior would just mean that whether overflow happens or not is not checked, but the overflow behaviour would still need to be defined somehow (wrapping, saturating, etc.). But the optimizations I had in mind are only allowed when "overflow is undefined behavior", so maybe "arithmetic with undefined overflow behavior" would have been a better term.
Proposing a new keyword for avoiding shadowing seems like wishful thinking, since if you don't want shadowing you can already enable a lint and deny it, and if you want to optionally allow it for a binding, you can just switch the lint to allow for a single statement. And all of this happens without requiring any keywords. 
You're choosing to write code that makes that kind of bug easy. I'd say typoing i as j is just as easy as accidentally shadowing i if not easier. If you're choosing to write a lot of imperative code that throws indexes and lengths around the place rather than taking the time to abstract out those details then you're going to run into the problem you experienced regardless of whether shadowing is a thing or not.
Unpopular opinion: no. Wait until Rust 2018 is done and the tokio stuff has stabilized. Right now, constant breaking changes are off-putting.
Epic will not release the source of the first UE due to middleware licensing. Honestly, you'd be better off remaking Unreal Tournament 99 with Unreal Engine 4.
Can you give a minimal example of the kind of code that triggered this? I'm assuming it involved a `mut` parameter or `mut` global (hopefully not). I suspect we come up with a set of unsafe/suspicious shadows that can be default-linted rather than forbidding all shadowing (or introducing a new keyword). This way we could potentially catch legitimate issues like this while still leaving the nice syntax that /u/0b_0101_001_1010 was talking about. For example, ``` fn foo(x: i32) -&gt; i32 { let x = x + 1; x } ``` is safe to shadow because the parameter isn't `mut`, but ``` fn foo(x: &amp;mut i32) { let x = *x + 1; // whoops, we just shadowed a `mut` and any further x references are now referring to the local and not the param // ... } ``` The above would be detectable by a rule that says if you shadow and the type changes, warn. You could also potentially restrict this by saying "if you shadow a `mut` and the type changes, warn". I haven't fully thought about the ramifications of a rule like "if you shadow any `mut`, warn" but it feels like that could be a good default as well.
Maybe in your issue report, you can demonstrate on a simple example how refactoring introduces shadowing. It may help a lot of readers to see the problem.
Is there a page for CLI WG?
I definitely have to admit ignorance on many of your points, especially since I have little to no experience in which optimizations are triggered in Rust compilation. I can speculate a bit, but it's only speculation, and your actual experience from `ripgrep` would trump such speculation. But ultimately: yes, my previous comment was intended to say that, given sufficient compiler optimizations kicking in, the streaming code _may_ be as efficient as the chunked variant. You're correct about my description of the Haskell code. To my knowledge, there is no vectorization going on in the C code used by Haskell's `text` package (the relevant piece of the puzzle here). The chunking is definitely an optimization in the Haskell case, allowing us to eager fill up an immutable `Text` value, and avoid excessive FFI calls. At the end of the day here: one of the benefits that I saw in the Rust code is that you get to ignore the chunking going on in the stream, which is something which is a bit more "in your face" in the Haskell version. It may be that, with proper profiling, that benefit disappears, and explicit attention will need to be paid to chunking.
In rust I think it's because when you're assuming a type for a mutable integer, It should be signed by default, because the programmer might try to make the variable negative. And 32 bit perhaps because of compatibility with 32 bit systems.
"If it's taken this long for a language with memory safety to appear, I'm inclined to conclude that there isn't really a need for it." lol
IMO rust is a perfect language for web developers to learn. It allows them to learn about lower-level programming while providing a strong safety net and allowing them to write production ready code mich sooner than if they learnt C, C++, or even something lile Go.
This is really cute! ^(And also really impressive!)
Been learning as much rust as I can in prep for RustConf. Started a blog where I just write up either what I learn or notes from what I read. So far have blogged everyday since I started! Link: http://therustykrab.fun/
Why would `x` in your second example not be safe to shadow? fn foo(x: &amp;mut i32) { let x = *x + 1; } `x` is an `i32`, so any attempt to use it as a `&amp;mut i32` (dereference, mutation, ...) is already a compilation error.
Thanks ;)
I can probably do my own research, but off hand, what are some good examples to look at for macros? I am reading through the little book of macros in attempt to create a small project based on macros (yet-another-struct-generator). It'd be super helpful to see some more examples!
I currently need a list with lockfree read to finalize the UDP stream service the company I work needs. We need to constantly sign users to the multicast while the multicast is happening in N threads, to allow N frames to be sent consecutivelly without the multicast delay. I looked it up and found a solution but it didn't seem fit, so I'm making one, kind of a challenge but rust makes it incredibly easy. I had never used unsafe rust and made the list in 2 days, in C I had so many problems every time I had to implement something kind of complex. So now I have to thoroughly test it before deploying. (It's basically a linked list that creates a iter that makes sure you only read what has already been inserted, so other threads can insert elements to it (to be used in the next iteration). Writing has a mutex, reading doesn't.
&gt; Any How is the story of Any on Rust? I can downcast and be performant? I know I need to pick the right type at run-time. But maybe could simplify the whole design. I need to build several operators (working on maps, filters and reducers) across rows, columns &amp; scalars. 
Java is memory safe. There were also plenty of languages safer than C *before* C. Know your history.
I didn't carry the thought experiment through far enough to come up with an example where the type doesn't change, just kind of handwaved that such a scenario could exist and would cause problems with further usage. I wanted OP to come up with an example that has the exact kind of shadowing that caused the problem so we can determine if there is a way to lint against something that caused an issue, rather than talk about the broad topic of "shadowing" as a whole.
&gt;is now a good time in terms of popularity and potential to get into the language? I am a web developer by trade Popularity is a poor metric. As for potential, Rust is already mainstream. Garbage-collected languages that run on WebAssembly will likely be more useful, but there's no harm in learning.
Got it working by setting `LIBSSH2_SYS_USE_PKG_CONFIG`. I just checked with a bare project with nothing but git2, and it slurped in *20* dependencies and took about 90 seconds to build. Seems expensive for what it's being used for.
Yeah, I want to see OPs example as well. I think the discussion about shadowing is worth having to improve our current lints. The more examples we have about good and bad usages of shadowing the better that discussion is going to be.
It's not an uncontentious feature. I know many Rust programmers (and non Rust programmers) who think it is a misfeature. I suspect they don't bring it up because they get the same sass this person gets. :) I've definitely stopped commenting on issues I have with the language, for this reason.
The thing I always hated about entire modules in directories is having a million mod.ra files and not being able to easily switch between them in a text editor cos I have to figure out which one is which. 
&gt; I'm sure you understand that the ENTIRE problem is that this causes issues in large code bases My own personal opinions of shadowing aside, surely the issue is with large functions and has nothing to do with large codebases? 
We use this repository for tracking our progress: https://github.com/rust-lang-nursery/cli-wg
&gt; It's not an uncontentious feature. Hence "relatively". People moaned about the module system almost on a daily basis; shadowing only came up infrequently, and usually in the form of "uh, isn't this kinda dicey?". &gt; I suspect they don't bring it up because they get the same sass this person gets. For my part, any perceived sass was directed at how the complaint was phrased. I'm somewhat against this particular issue, but I can't think of any particularly convincing arguments against it. So I'm open to being convinced, and I suspect others would be to... but I don't like the chances of this particular thread. My immediate reaction when I got to the bit about shadowing causing death and destruction was to very nearly write the whole post off as just inflammatory and close the tab. &gt; I've definitely stopped commenting on issues I have with the language, for this reason. Well, for what it's worth: the 2018 epoch is, for me, characterised primarily by a sense of resignation. So, I think I understand the feeling.
Well, the Ludum Dare game jam is less than two weeks away, so I should probably get ggez into a shape that's suitable to work for it. I could just use the latest released version, but it would be nice to be able to give the pre-release a good hard shakedown...
Not the OP, but: ```rust let index = my_data.position(|x| looking_for(x)); // code passes let index = other_data.position(|y| not_the_same(y)); other_data[index] = whatever; // more code my_data[index].counter_thingy += 1; ``` The introduction of the inner two lines of code change the outer two lines of code but (as observed elsewhere) they may look fine in a code review because locally they seem fine. You can do the same thing with some borrows too (e.g. `let borrow_inner = &amp;mut self.inner;`), and write data back at the wrong address, clear the wrong vector, etc.
(IMHO) Backtraces can be useful for debugging whereas `cause` can be user-facing. For example with cause you could print out: Error: Could not load configuration file `config/foo`. Caused by: Permission denied. But let's say the code doesn't carefully add causes, and just has something like `fs::read_to_string("asdf")?`, all you're going to see is "NotFound" without any additional information. If you run with `RUST_BACKTRACE=1`, you'll get a backtrace to the call to `read_to_string` to help you debug the situation.
Thank you. I fixed the link.
Were a small team as of now it's only five of us, who at some point have written in C or C++. Most of our projects are in Python or C++ or a combination of the two. Three out of five want out next project to be in Rust so we're going with Rust, this will, however, be a pilot for the language within our group. There are a lot of other teams that have expressed interest in what we're going to be doing because it's going to be done in Rust. I'd say enough desire and interest are there to move forward.
The amount of feigned ignorance in this thread is disheartening. We get it, some of ya’ll really like shadowing. That doesn’t mean you have to pretend like you don’t see the obvious way to shoot yourself in the foot with it. Why does advocacy for a feature have to take the form of going bugeyed in disbelief at anyone who suggests it might have a downside?
Currently futures are deemed a work in progress and new alpha versions are coming up that support await (nightly only for now), so yes, at the moment they have bad ergonomics, but once the niggles have been worked out of 0.3 it's going to be *glorious*.
Surely a subtle mistake is harder to spot in a large, non-trivial and concurrent code base?
You can try this yourself by making a new crate, enabling the 2018 edition, and playing around with adding files!
&gt; These types of optimizations come before the target specific ones in the pipeline, although their outcome might enable further target specific optimizations to trigger down the pipeline as well. Ahh. I'm not a compiler writer, so I didn't know that and my intuition still wants to point to "these optimizations are not target-specific" as the real problem to be solved.
The function wasn't that large, but it's a fairly complicated piece of logic that's hard to factor further. It's a good piece of code with a devastating mistake due to a language defect (IMO)
&gt; How is the story of Any on Rust? I can downcast and be performant? I know I need to pick the right type at run-time. I've never benchmarked it (you may want to check the internets) but looking at the implementation it probably isn't too bad. `downcast_ref` basically gets the subject's TypeId, compare it to the target's TypeId, and if the two match casts the Any reference to a Target reference and returns that. I wouldn't expect it to be significantly more expensive than a downcast in other languages.
I'm sure you understand that a large code base makes it harder to track down subtle bugs like this. 
An example is pointless. Any example where a local variable name was reused by mistake will do. Why is this so hard to understand...
Just make this a blog post already. Fantastic comment.
I think needing five subsequent bindings like that in the same function is really smelly, shadowing or not.
What does lint has to do with anything? It would be a compile error to shadow without the keyword. That \*does\* solve the root problem.
I understand that but shadowing only comes into play within the lexical scope of a function. It doesn't matter how much code exists outside the function. It only matters what variable name bindings exist inside the function. With small functions, it's quite easy to tell if shadowing is happening because it's easy to read the entire function to understand what's happening. With large functions, that can be impractical.
I'm afraid you have demonstrated that you don't understand the issue at hand.
&gt; ToClientFormat Oh oh oh, I thought that it meant the client format that _I told it_, not that it guessed for itself. And I was passing `UncompressedFloatFormat::U8U8U8U8` and all. Okay, I'll get this sorted out. And yeah, I know about `include_bytes!` and all that, but since it's over 100k I didn't want it to ever live directly on the stack.
*my* least favorite thing about mod.rs is that if you decide to add a submodule to a module, you have to move foo.rs to foo/mod.rs, and that makes your git blames not as nice.
The real alternative is to have explicit shadowing with a rebind keyword, not make up variable names.
Working on [tarpaulin](https://github.com/xd009642/tarpaulin), last week I didn't get chance to do much except comment on some issues and merge in a PR. This week I plan on closing 1-2 issues and maybe doing the upgrade to the 2018 edition!
It can be useful to specifically replace a binding to avoid using something after the beginning of a function (like an Into Option, although that gets moved anyways). However, I also sometimes write code that shadows variables in bad ways and I probably shouldn't =X. I don't know a way to solve this entirely, but it might be good to lint it within single functions and their scope. I haven't had shadowing issues yet, but I have written bad code recently that shouldn't be shadowing what could be a closure capture and I know it is an issue.
Thanks Ill give it a look!
I wonder if a lint like this would've detected /u/nugatty's problem or if their case was different (shadowed variable neither consuming nor borrowing from the original value with the same name)
I split the shadowing lints on purpose to allow you to directly reuse a binding. While I agree that the lints can be noisy, I doubt there is an easy fix.
Meh, I actually just sent out a request to Epic about releasing the source for UE1. I even mentioned if they can't release the full source maybe part of it. Worse they can say is no.
Dude at this point I think a lot of people have sympathy with you and even agree with you to some level. However if you really want to actually effect a change report the Bug/Issues do what people say and post some code examples. That looks like the way to get this moved forward.
Fair enough.
Was the shadowed variable from a much higher scope, or in the midst of a very long function? Could you not go over each function one by one, or was your code base that big? (Just how big is it?)
OK been playing with Rust for a week and trying to port an application of mine which uses multicast. So far so good but having a problem with the multicast side, what im trying to do is pass a multicast address and port, udp://x.x.x.x:1234 or x.x.x.x:1234, and have the code open this multicast stream, but im stuck on the new construct. `pub struct Multicast {` ip: String, port: u16, `sock: SocketAddr,` `}` `impl Multicast {` fn new(udp_address : &amp;str, port : u16 ) -&gt; Multicast { `Multicast {` `ip: udp_address.to_string(),` `port: port,` `sock: &lt;SocketAddr&gt;Ipv4Addr::new(0, 0, 0, 0),` `}` } pub fn start( channel: Channel) -&gt; Multicast { `let url = Channel::get_url( &amp;channel);` `let mut url_ip : String;` `let mut url_port : u16;` `let parts : Vec&lt;&amp;str&gt; = { if url.starts_with("udp://") { url[5..].split(":").collect() } else { url.split(":").collect()}};` `match parts.iter().count() {` `2 =&gt; { url_ip = parts[0].to_string();` `url_port = match parts[1].to_string().parse::&lt;u16&gt;() {` `Err(_fail) =&gt; 1234,` `Ok(n) =&gt; n,` `};` `}` `1 =&gt; { url_ip = parts[0].to_string();` `url_port = 1234;` `}` `};` `let mut mcast = Multicast::new( &amp;url_ip, url_port);` mcast `}` `}` Can anyone help a newbie and get me going in the correct rust way br Joolz
I would just like to say that I think you've hit on the right solution here. It's not more effort to use a different keyword, and it adds safety while more or less allowing the original feature to continue to be part of the language.
&gt; That *does* solve the root problem. It wouldn't because that would be too noisy and controversial, so no RFC would be merged for it, so nothing would happen as a consequence.
Update: I did what you said, but now what do I need to do to make it resolve the tile_id_texture as a `USampler2d` when putting it into the `uniforms!` macro?
&gt; An RFC proposing your suggested changes would never be merged Are you in the position to decide that? Seems like I'm not the only one having issues with this.
I've even done an example for you fn transfer_bank_funds(from_account : Account, to_account: Account, user: &amp;User) -&gt; Result&lt;Account, &amp;'static str&gt; { match check_account_has_funds(from_account) { HasEnoughFunds =&gt; {} InsufficentFunds =&gt; { return Err("Not Enough Funds")} } let user = User::BankManager; match authorised_to_access(account,user) { Authorsied =&gt; Ok(to_account), NotAuthorised =&gt; Err("No Authorised"), } } In theory this wouldn't throw a compile error, and the transfer of funds will always be authorised.
&gt; Any example where a local variable name is reused by mistake will do, For every example where a local variable is reused by mistake, there is another one where the user explicitly intended to shadow a name. For any of this to have any effect in Rust programs, we need an automatic way to detect when shadowing introduces a bug with a low false positive rate.
&gt; we already have a lint that you can turn to deny, and a way to opt-into allowing the lint locally, which AFAICT is what rebind would do That is actually GREAT idea you just had, sort of middle ground make lint enabled by default AND make optional keyword rebind which when used instead of let disables a lint just for that one line of code that way if lint is disabled nothing changes if lint is enabled and let is used lint complains if lint is enabled and rebind is used lint does not complain in big codebases people enable lint and use rebind, everybody else just disables lint 
In the midst of a somewhat long function which is hard to break up. A refactoring rebound a variable name and that introduced a failure situation that happened once every blue moon (this is a rarely executed function in a concurrent system, so we suspected timing related issues for the longest time, but it was just a shadowing bug causing the function to compute a slightly wrong timer delay... very very subtle, but wouldn't happen if shadowing had to be explicit)
&gt; For every example where a local variable is reused by mistake, there is another one where the user explicitly intended to shadow a name. That's EXACTLY why there should be a keyword to record that intention. The lack of should be a compile error.
This already exist. The problem is that nobody uses it because it is too annoying.
The problem is that this lint already exists, but nobody uses it because banning all shadowing by default is a horrible user experience.
Alright I have it compiling and running with no errors.. but also not drawing correctly :(
&gt; Are you in the position to decide that? This RFC is already implemented it, a tiny % of the projects in crates.io use it. So while I would be against it because it provides a horrible user experience, the evidence suggest that a lot of people would be against it too. Particularly given that we used to warn against shadowing by default, but we turned that warning off because too many people complained against this.
Of course, index has to be used above the re-assignment as well or else you'll get an unused warning and hopefully notice the issue.
&gt; I got to the bit about shadowing causing death and destruction was I think most people got the tongue-in-cheek vibe of that statement. Also, everyone else saw through it and commented on the technical issue at hand.
Alright, I think I'll refrain from writing that RFC.
Could you help me out and tell me what the lint is called? Couldn't find it via Google, and `rustc -W help | grep shadow` gives no results. None of them in the list look like it to me, but I might be overlooking it.
&gt; That means that no RFC about this will get merged I just got a PM that told me to ignore your statements on what gets merged and not, not sure why.
Clippy has a triad of lints for shadowing for various degrees, one of them permits shadowing \_only\_ if you're using it to rebind
I think Frank's example was closer to what I imagined ([link](https://www.reddit.com/r/rust/comments/9337zh/local_variable_shadowing_is_at_least_a_50000/e3aluja/)). Just looking at the two middle lines it is completely normal and harmless code. Unless 'index' was also used in the previous or following 10-15 lines, no reviewer would suspect that anything was wrong. Setting user to "bank manager" might at least cause the reviewer to double check a few things. This seems like the kind of thing that (hopefully) everyone learns from someone else's expensive mistake. For example at work we now have a policy in C/Java of always using braces on multi-line `if`, after that patching problem that Apple (IIRC) had.
I'm not saying that you shouldn't write an RFC, I'm suggesting that the effort might be better spent into improving what we already have to actually make it useful. A lint about shadowing that would prevent bugs and that people would use would be great, but our current lint is always off because it is too annoying to use. I honestly don't think that proposing our current shadowing lint for stabilization would work because of its limitations, but if you are convinced otherwise go for it.
This post was partly to encourage people to turn that on. I'd prefer language support though to make the intension clear with a rebind keyword.
No, I'm convinced a language change is the correct solution, since shadowing does make sense occasionally. You just need to make it more disciplined. Best of both worlds... allowing shadowing and a good night's sleep.
Most people will use default settings because Rust is "safe by default" ...
Not the person who PMed you, but * It might have been removed before RFCs were a thing, I'm unsure. * There might be enough people for it now to find some solution. For example, even with shadowing allowed, a `rebind` keyword would have the function of enforcing there to be previous binding, making it easier to keep shadowed names in sync. With the lint shadowing would be explicit. * Worst case there will be a larger discussion that we can use as contrast in the future. I believe things like this will become more of a focus once Rust matures and there are a whole lot of large scale codebases. But in the river of Rust it can be tough to swim against the stream. An RFC discussion will be tough, not going to lie.
**To Shadow Or Not To Shadow?** There are advantages, and disadvantages, in both cases. **Advantage: Avoid Accidental Reuse** fn foo(x: i32) -&gt; i32 { let x2 = i + 1; bar(x2); x // oops, meant to return x2!!!! } Here, had the author used shadowing instead, then the mistake would have been avoided. Shadowing is useful when a variable *expires*, so that it cannot be accidentally reused after its function has been served. **Disadvantage: May Shadow** fn foo(x: i32) -&gt; i32 { let x = i + 1; bar(x); x // oops, meant to return the argument!!! } Here, had the author used another variable instead, then the mistake would have been avoided. --- Maybe the answer would be to make shadowing *explicit* (ie, require another keyword than `let`)?
The thing is, these lints were enabled by default, but now have been disabled. Any argument about re-enabling them by default and making them part of the language without distinction of the different types of shadowing and without discussion about why they were disabled and how does the new feature overcome the issues that forced these lints to be disabled, is woefully incomplete.
By breaking changes, I'm assuming you're referring to tokio, but you don't have to directly rely on tokio for writing web applications and such.
Just figured out a way to do this! struct Doom {} struct Gloom{} trait X&lt;T, D&gt; where T: Deref&lt;Target=D&gt; {} impl&lt;T&gt; X&lt;T, Doom&gt; for Ctr&lt;T&gt; where T: Deref&lt;Target=Doom&gt; {} impl&lt;T&gt; X&lt;T, Gloom&gt; for Ctr&lt;T&gt; where T: Deref&lt;Target=Gloom&gt; {} Type specialization for the win. 
OCaml has the same shadowing behavior for `let`, which makes it natural to me. Most shadowing bugs are caught by the "unused variable" warning in my experience. However it's interesting to note that for module shadowing there's a construct which is `open!` instead of `open`, in a way that resembles OP's `rebind`. A `let!` construct for disabling a shadowing warning would be reasonably readable, IMHO. It's just too late to add it now. 
Failure's backtraces are "anchored" to where you convert an error struct to a `Fail`, or add a `Context`. 
These lints used to be enabled by default with `clippy-pedantic` but this is not the case anymore :/
I strongly disagree. Without local variable shadowing a lot of things would be significantly harder than they are currently. This applies to macros as well as just type changing along the path.
I'd prefer something like `rebind` in patterns. For example: let x = 23; let rebind x = 42; let rebind x = match foo() { Some(rebind x) =&gt; x, None =&gt; 99, };
I wouldn't necessarily assume that. Not everyone who is using Rust is using it as a C/C++ replacement. Some people are using it instead of python/javascript/go (and this is going to become a lot more viable once the async story is properly flushed out :)). There's a good amount of libraries already wrapped (or re-implemented in Rust). YMMV depending on what you're doing of course.
The real alternative is to write some unit tests for the critical parts of your project if you stand to lose $50k when it doesn't work :p. Or to keep scopes small. If the newly inserted code in your broken method had been put into a simple `{ /* code here */ }` block it would also have been fine. Or, as others have suggested, just activate the already existing lint. Adding a new keyword just because something bit you once just seems silly, especially given that lints already exist (which nobody uses because nobody wants them).
shadow_unrelated probably belongs under pedantic tbh
Still working on [Projects.rs](https://gitlab.com/anire/projects-rs). I hope to finish the "Numbers" section soon! Once it gets to 0.1 (i.e. all projects finished, somehow) I think the community could contribute more.
Not with a new edition and rust fix. That's the whole point -- you can upgrade the syntax. So adding a ! or `rebind` could be done automatically. Anyone with doubts about their use of rebinding could track down all the instances after rust fix with a grep.
Can I ask how many lines of code the function where the fault lies is?
Reinventing of names is rarely a good idea. I understand confusion with "green threads", but why not "greenlet"?
Ok, I see. That's indeed very subtle and hard to catch without an extensive review. I'm sure there are a million things people could tell you you could have done better (stringently testing timer calculations for one). Still it's the case that allowing unfettered shadowing of variables produced nonlocal changes to the code semantics. Perhaps the lint should just be against shadowing variables whose last appearance was more than a few lines away, and having that turned on by default. That should be uncontroversial and generally beneficial.
I think there's something to be said for a pull request feature that highlights shadowing declarations in diffs for code review. It would have been sufficient to catch this, and doesn't require making breaking changes and adding new keywords. Might be useful for other programming languages too. E.g. Java doesn't permit local variables shadowing other local variables, but a local variable may shadow an instance member.
&gt; ust sent out a request to Epic about releasing the source for UE1. I even mentioned if they can't release the full source mayb There are numerous threads about that on https://forums.unrealengine.com/ and the answer is always a "no".
Oh ok, might make sense. Thank you!
Just figured out how to use type specialization to make my code simpler and less verbose. Here's a [playground link](https://play.rust-lang.org/?gist=d940a6993e56aa99ffce68e8947f395d&amp;version=stable&amp;mode=debug&amp;edition=2015) that shows the test example of how it works. Basically needed two similar but distinct implementations based on the type of T. 
I personally hope never as it's a moving target and static compilation of it is ideal. How significantly are your binaries affected by the stdlib?
Well, it's not *only* variable name bindings that can shadow. You can go pretty crazy, [really](https://play.rust-lang.org/?gist=9dac8d59638d3c206320d295fc14bec6&amp;version=stable&amp;mode=debug&amp;edition=2015)...
You've convinced me... that we should not allow shadowing at all. Every one of your examples is terrible from the standpoint of readability. Imagine you have a function that takes a parameter called "x" and is particularly long and you are debugging some code at the end and you see a reference to "x". You would assume that "x" refers to the parameter that is passed in, but then it turns out it isn't because someone decided to "mutate" it in the middle of a function.
&gt; I find shadowing extremely useful, and allows me to "mutate" variables without having to make them mut (which basically forces me to keep in my mind that the variable can be mutated at any point) If you think about it, that's really NOT what you want: Having a "mutable" variable, that is not `mut`. I do not see any downside of having a `mut` variable and if you use it like `let a = a + 1` you are having a mutable variable and you should declare it as such! I usually only use shadowing if the type changes.
&gt; `Poll&lt;Result&lt;T, E&gt;&gt;` now implements the `Try` trait. Are there plans to stabilize this trait soon?
Just checked, line count is 34, the diff context just missed the declaration and use-after-rebind.
Unit tests to cover rare timing related bugs are not easy to conceive or implement.
Nobody is suggesting the removal of shadowing, just an additional keyword to avoid this source of hard-to-find bugs.
I think I'll need one... :)
I don't think that is any better and just adds needless complexity to the language.
I'm slowly reimplementing the JS roguelike library rot.js in Rust. My plan is to facilitate shipping roguelikes both as native executables and to the browser from a single codebase with minimal modification. https://github.com/royallthefourth/roguekit
Is this actually shadowing? Per your example, all of the `foo` functions are callable.
Windows actually does not do that. If you get a pointer that’s not null from malloc, touching the memory wont crash the process. It’s the only reasonable OS here.
Because I introduce some scopes. After `use foo` I don't think there remain a way to call the function-local `foo::foo` in the same scope. Likewise `let foo = ||();` will irrecoverably hide the function-local `fn foo` in the same scope. Variable shadowing works the same`let x = 5; { let x = true; } println!("{}", x)` will print `5`, not `true`.
&gt;But in the river of Rust it can be tough to swim against the stream. I've noticed ;)
It's better because it solves the problem of shadowing by mistake.
Why do they need to be named foo1, foo2, ...etc ? func(list : vec&lt;u32&gt;) { mapped_list = list.map() } Seems more readable and less error prone than func(list: vec&lt;u32&gt;) { let list = list.map }
If that's the case post an some example code demoing the problem so we can discuss the general problem rather than the facet you've chosen to blame
If you read more closely, OP isn't debating usefulness of shadowing. I also find shadowing useful, but also extremely dangerous. I agree with the proposal of a rebind keyword, as that keeps the feature, while preventing accidental rebinding.
If a function is both critical to the product and hard to test, perhaps the code reviewers should have looked at the entire function instead of just the modified lines. Without seeing your code there is actually no way for anyone to conclude whether you could have done things differently. You say 'we need a new keyword for rebinding' and the rest of us just have to take your word for it when you claim changing the language is the only solution. I hope you can imagine that some of us are a little skeptical.
At work we run tests under virtual time using an internal tool to keep a bunch of processes (all wired up for virtual time) in sync with each other. So we can run on a simulated infinite GHz CPU, or wind it down all the way to realtime. Practically, we use 3 settings: pure virtual time, virtual time jumps with realtime in between, and realtime. This in the past has shaken out some timing-related bugs, because things happen in different orders in the different processes depending on which setting we use. However I really appreciate how hard it is to make time-related bugs surface. We don't have any way to intentionally trigger a particular ordering, for instance, or to cycle through all the possible different orderings in testing.
I've personally made this mistake in surprisingly small functions, in one instance due to moving a small fragment of code from one function to another. A local was silently shadowed, and the bug was indeed rather hard to track down.
In new design three backticks works as expected.. will change to indentation, thanks
Yeah, same with dynamic languages. The reviewer should've checked that it all makes sense and that there is 100% test coverage. Fortunately statically typed languages exists to avoid that mindless job. Adding rebind would enhance the situation while keeping a desired feature.
I published my first rust crate, [joinery](https://crates.io/crates/joinery)! It lets you do generic joins over any iterator, with any separator: extern crate joinery; use joinery::{Joinable, JoinItem}; fn main() { let content = &amp;[1, 2, 3, 4]; let hello = &amp;["Hello", "World!"]; println!("Numbers: {}", hello.join_with(", ")); assert_eq(content.join_with(", ").to_string(), "1, 2, 3, 4"); let join = hello.join_with(' '); let mut join_iter = join.iter(); assert_eq(join_iter.next(), Some(JoinItem::Element(&amp;"Hello"))); assert_eq(join_iter.next(), Some(JoinItem::Separator(&amp;' '))); assert_eq(join_iter.next(), Some(JoinItem::Element(&amp;"World"))); assert_eq(join_iter.next(), None); } I'm currently on version 0.2.1, but I'm hoping to stabilize to 1.0.0 soon, after collecting a bit more feedback.
That doesn't even look like valid Rust :p The code might look like `let list = list.into_iter().map(...);`. The `IntoIterator::into_iter` function consumes `self`, so the original `list` wouldn't be available after that line *anyway*. So no harm in reusing the name. Or it might be `let list = lint.iter().map(...);` in which case the original `list` is still valid (but immutably borrowed), so *perhaps* you'd still want to use it later? Regardless, the new `list` is of the type `::std::iter::Map::&lt;::std::vec::IntoIter&lt;u32&gt;, *magic*&gt;` which is impossible to confuse with `list` so I don't see any danger of confusion here. Besides, with that naming scheme you are likely to end up with variables such as `manyselected_filtered_mapped_cloned_taken_skipped_list`, at which point I'd rather take the shadowing. But in the cases where it helps there is nobody preventing you from choosing informative variable names.
You're basically saying reviewers should do a compilers job. You should code in Perl.
As asked, what’s the theme/editor combo plz, looks great! :)
&gt; For example, when signed integers are used as loop indices, the optimizer can assume that the loop always terminates before the index overflows. Protip: Rust's iterators are built around pointers and `ptr::offset`, instead of indices, because pointer offsetting is defined to not overflow in Rust.
Oh, yes. I see what you're demonstrating now. Excellent example!
Ruling out their limited affirmative examples shouldn't convince you that it's not permitted at all. Namespaces are good, and not having to fully qualify names is also good.
`mut` variables can be mutated by a reference somewhere, while continuous shadowing will only be "mutated" on an assignment.
&gt; Yeah, same with dynamic languages. The reviewer should've checked that all values makes sense and that there is 100% test coverage. Fortunately statically typed languages exists to avoid that mindless job. Adding rebind would enhance the situation while keeping a desired feature. I wear a seatbelt while driving a car, but no helmet when driving a bike. Likewise I like to be protected from type-errors, but not accidental shadowing. I guess 'acceptable risk' means different things to different people. If full protection is extremely important to you then I imagine you may wish to use a language that allows full formal verification instead. They tend to be a bit more verbose - but so is Rust with a hypothetical `rebind` keyword, and since you don't seem to have a problem with that... Nobody (as far as I have seen) is disputing your right to propose improvements, some are just disputing their necessity / desirability, and pointing out that you'd have to make a *very* good case to make this breaking change.
&gt; we already have a lint that you can turn to deny, and a way to opt-into allowing the lint locally, which AFAICT is what rebind would do Well, picture a codebase where you *do* often want to use shadowing behavior, but also want to prevent *unintentional* use of shadowing. Adding a "`#[allow(...)]`" directive everywhere you want shadowing is surely far less readable and ergonomic than a `relet`/`rebind` keyword. To use an example from elsewhere in the thread, would you rather read: relet x = foo(); relet x = bar(x); relet x = quux(x); or #[allow(SHADOW_REUSE)] let x = foo(); #[allow(SHADOW_REUSE)] let x = bar(x); #[allow(SHADOW_REUSE)] let x = quux(x); I'm not necessarily agreeing with OP that shadowing must be blanket disallowed by Rust, but I do agree with them that the lint is not a great solution. Perhaps a macro would be a reasonable half-way solution, eg: relet!(x = foo()); relet!(x = bar(x)); relet!(x = quux(x)); Though if this lint+macro idiom were used often enough, I would definitely consider adding a keyword to be a lesser evil.
LOL, keep sailing mate.
It was just pseudo code. Maybe you want to filter the vec&lt;u32&gt; to vec&lt;u32&gt;? You don't have to consume the first list and the types would be the same. Anyways that was not the point of the example. &gt; Besides, with that naming scheme you are likely to end up with variables such as manyselected_filtered_mapped_cloned_taken_skipped_list, at which point I'd rather take the shadowing. I showed you very concise variable naming so no you don't have to end up with manyselected_filtered_mapped_cloned_taken_skipped_list
Yes, and everybody who opposes wearing full body armor when crossing the street is basically saying that it's okay to run on highways while blindfolded, at night. On second thought, no I'm not saying that, and your strawman is boring. You want the compiler to check for shadowing? Install clippy and activate the correct lints. Don't come here and claim that people who don't mind shadowing should leave Rust and use Perl.
Not any time in the near future. Rust currently [doesn't have](https://github.com/rust-lang/rfcs/issues/600) a stable ABI. That means that even something as trivial as a security patch can change the ABI, but it's worth it because they're still finding ways to make the language more efficient which a stable ABI would preclude.
Yes, everybody who disagrees with you just doesn't understand you.
In this case, pretty much.
Let me know when your brain is functional again.
My comment was just to add an additional use case to the already mentioned benefits and not to say one way or another on the negative side of shadowing.
At the end of the day many people like to be able to shadow, and I think we're all smart and wise enough to make this decision for ourselves. Those who don't like it can install clippy and disallow shadowing, and various other features that they might dislike.
I really like the idea of your project, and I believe/hope that it will help future newcomers to see how commen problems are solved in rust. Just a few questions: What are your goals for 1.0? Would it be possible to put all projects in one crate, or have you choosen to not do so, and why? Do plan to write a blog/reddit post after the 0.1 release to share your experience with rust?
You can implement FromStr for your enum and call `combo.get_active_id().unwrap().parse().unwrap()`.
There are actually some academic tools out there that can tease out concurrency bugs by keeping track of calls to the various pthread methods (to identify synchronization points), and replay execution while selectively blocking threads to try different execution orders. But as far as I'm aware this hasn't been tried with Rust yet.
Haskell prevents variable shadowing in same scope. But in `do` notation each new line creates new nested scope so you can use variable shadowing there. It caused me some real headache. It boils down to let x = 1 ... let x = 2 // I decide to add this line ... if x == y { ... // this line was already there Was my intention to change definition of `x` or did I miss original definition of it? But what if you do not allow variable shadowing? let x0 = 1 ... let x1 = 2 // I decide to add this line ... if x0 == y { ... // this line was already there Now, what if `x0` held result of some computation and I decided to refine that computation with `x1`? Did I forget to change `x0` in the condition to `x1`?
I only know of the [clippy lints](https://github.com/rust-lang-nursery/rust-clippy/blob/master/clippy_lints/src/shadow.rs).
Started working on an async docker client: https://github.com/wayofthepie/docker-async-rs. Going to clean it up over the week.
&gt; I don't have hardware right now to test code on. Looks like [qemu supports it](https://github.com/qemu/qemu/search?q=ARM_FEATURE_V8_AES&amp;unscoped_q=ARM_FEATURE_V8_AES). It won't be particularly fast, but you can have an [ARM chroot](https://wiki.debian.org/QemuUserEmulation) to play with.
Sounds like a text editor problem. My editor shows me how the path of the file differs from the others I have open.
Looks like discussion is still ongoing: [https://github.com/rust-lang/rust/issues/42327](https://github.com/rust-lang/rust/issues/42327). The current interface doesn't seem to be "basically stable" yet.
I'm building a command-line interface to the [Bear Writer app](http://www.bear-writer.com). It'll let you list/show/(and eventually add/edit) notes all from the comfort of your terminal!
I find myself wishing for dynamic linking in theory, but in practice, I have too many hard memories of the pain of non-portable binaries and other issues with dynamic linking. At the end of the day, disk space is cheap, and I'm fine with binaries in the hundreds of KB to tens of MB if it means that I can compile once and it works everywhere (inside of my platform), or that I can reliably \`cargo build\` from a fresh developer workstation without having to worry about installing \`-dev\` versions of everything.
Ah, I'll clarify. I'm wanting to do away with the `.unitMatch()` method because I want to have the `.get_active_id()` call (or whatever needs to be the replacement) return the enum directly. I don't want the possibility of having typographical errors in Glade be a break point. Is there a way to have gtk return an enum directly instead of dealing with a `String`?
I’m currently learning rust, but don’t have a CS background, so pardon my question: Why would I want this from a programmer perspective and why would I want this from a user perspective?
**Borrow of some variable in match expression followed by move (of the same variable) in match arm leads to problem.** I tried to reproduce the problem using a simple example on the playground, but couldn't cause the compiler to complain: https://play.rust-lang.org/?gist=c6221704da782c6099416872596dbed1&amp;version=stable&amp;mode=debug&amp;edition=2015 In my actual code, I have something like this: https://gist.github.com/bzm3r/a5fd8f821cd231ff2f3ef3ec10ec62cc This causes the compiler to complain: ``` error[E0505]: cannot move out of `instance` because it is borrowed --&gt; src\bin\init-swap-chain.rs:64:28 | 58 | let ldevice: Device&lt;V1_0&gt; = match {create_ldevice_and_setup_queues(&amp;instance, | -------- borrow of `instance` occurs here ... 64 | error_str, instance, None, Vec::&lt;vk::types::CommandPool&gt;::new()), | ^^^^^^^^ move out of `instance` occurs here ``` Am I misunderstanding the error?
I think there's a lot of prior art using the word "task". Python asyncio in particular?
I agree it is editor dependent but i'm sure you can imagine having 20 mod.rs files is a bit of an edge case for any editor.
1) My goal for 1.0 is to have most repeated code put into separate library crates, which the binaries use. 2) I have not chosen to put all projects in one crate because they each have different dependencies and different needs. As an example, the mortgage calculator depends on termion due to its UI but the other apps don't. 3) I don't have a blog, but I will write a Reddit post :) 4) I've been using Rust for about a year now, so I'll sum it up for you: When the code compiles properly, without any warnings, you know your program is rock-solid and will work _exactly_ the way you intended. 5) Please contribute after 0.1! I can't do everything by myself.
How does that work? Does it use an API?
Labels should be meaningful. Do you name your functions foo1, foo2, foo3...? 
When I use `mut` the variable might be constantly be mutated, but when I use `let` the variable is immutable afterwards. So it kind of depends on what your code does.
Also worth noting that tokio and futures 0.1 are longish term releases. I believe the plan is to make tokio 0.1 work with futures 0.3/std-lib futures.
&gt; You would assume that "x" refers to the parameter that is passed in I wouldn't ever assume this in Rust. I would look at the last binding, and continue from there. Too much code in the wild does this for various reasons. So even if we were to change the code in two editions from now, you would still need this mindset for all millions of lines of code that already exists.
Nice. Can you make it available for `cargo install` please :) Thanks!
It does not have an API unfortunately, I have to interact with the local notes database. But luckily all notes are stored as markdown text, so the rich content will just show up as links which I could potentially parse out.
So according to your argumentation people should use C and not bother with rust. Why shall the compiler and borrow checker do all these annoying checks .... I don't get some of the comments in this thread. Some people act as if they are offended by criticism of the language and dismisses proposals to make it better. Isn't rust about preventing preventable bugs? For example why having "let mut abc" and not just stick "let abc" and have code reviewers review the code if it may or may not be mutated? Bugs are rarely intentional or because people are "stupid". The root cause of the bug that is discussed here has been explained in long and large. These are bugs that are introduced as a code base ages and evolves and at times different coders working on it. Shadowing has its use but from an engineering perspective a risky construct that opens the door to subtle bugs. I do support the idea of making it a bit harder to use, just like using "mut" obliges to state intent.
yeah, I think that the cases of shadowing that often lead to issues should be warned on by default
And the programmer gets to decide what is meaningful, possibly assisted by their peers through code reviews. And sometimes shadowing an existing variable can lead to a meaningful name.
&gt; 'm not necessarily agreeing with OP that shadowing must be blanket disallowed by Rust, but I do agree with them that the lint is not a great solution. Sure, but the lint is a start. &gt; A keyword would fix the problem of the lint being annoying. A keyword would fix the problem of writing `#[allow(shadow_reuse)]`, but not really fix the problem of the lint being annoying, which forces you to write relet everywhere. Also, what do you do in patterns? `if let Some(x) = x { ... }` There the `x` in the pattern shadows the outer `x`, so the `relet` keyword isn't barely enough, yet `#[allows(shadow_reuse)]` would work for patterns: `#[allow(shadow_reuse)] if let Some(x) = x { ... }` works
&gt; So according to your argumentation people should use C and not bother with rust. Why shall the compiler and borrow checker do all these annoying checks .... Why do people keep having these insane interpretations of what I'm saying? Do we live in some black and white world where everyone either wants to add every conceivable check that might prevent bugs to Rust *or* should just abandon Rust and program in C? You know what might also prevent bugs? A ban on having bindings in scope that have a Levenshtein distance of less than 3. That way you are protected from all but the most dramatic typo's. I like the borrow checker. I like `mut`, and the default of immutable bindings. Indeed, I think shadowing is one of the things that makes it more ergonomic to mostly use immutable bindings and thus enables good style. The concept of freezing and thawing through shadowing goes [waaaay back](http://smallcultfollowing.com/babysteps/blog/2012/07/24/generalizing-inherited-mutability/). I think adding additional friction to shadowing will result in more variables just being declared `mut` - and I think that'd be much worse.
Welcome! For readability, please format code with four spaces in front of each line. What is your question here exactly? `&lt;SockAddret&gt;Ipv4Addr::new(...)` isn't Rust syntax -- maybe you're trying to do a type cast? You're constructing an `Ipv4Addr`, so why not have the field type be `Ipv4Addr`? You may also be interested in a crate like [`url`](https://docs.rs/url/1.7.1/url/) where you can simply write `Url::parse("udp://1.2.3.4:1234")` and then use the methods of the `Url` type to extract scheme, domain, and port.
Can `Task`s use thread local storage and what guarantees does the `Executor` give about this ?
I haven't been following this as closely as I'd like to, but this syntax looks funny to me: \`mut self: PinMut&lt;Self\&gt;\`, I wasn't even aware that \`self\` could carry a different type than the ones predefined, like \`self\`, \`mut self\`, \`&amp;self\` and \`&amp;mut self\`. I know it's tangential to this post, but can someone explain what's going on with that syntax? Is there an auto-conversion happening for \`&amp;mut self\` into \`PinMut&lt;Self&gt;\`?
Ah, didn't realise people were actually using new reddit ;-)
It's an interesting problem. What you're talking about sounds like a kind of fuzzer for concurrency. Our case consists of a set of processes: the virtual time coordination process, the tester process, the processes under test, and a simulator process which takes the role of the "outside world", all communicating over TCP/IP. There might also be a debugger attached to one of the processes. The virtual time handling is invasive: it needs to hook into the main event loop to handle sleeps, and all time calls must be diverted to return the virtual time (not the actual time). Core code also has to keep track of data-in-transit to avoid jumping time forward before that is processed. With a little bit more invasion of core code, perhaps we could selectively hold off processing incoming data in one process or another. Just choosing randomly what gets to run next would be a start. This is Java and C right now. No Rust yet -- that's planned. It would have to hook in at the level of `mio` I guess.
Gtk and Gtk-rs cannot help here, but Rust can. ``` trait MyComboExt { fn get_active_value(&amp;self) -&gt; Option&lt;MyEnum&gt;; } impl MyComboExt for gtk::ComboBox { fn get_active_value(&amp;self) -&gt; Option&lt;MyEnum&gt; { let id = self.get_active_id()?; let value = id.parse::&lt;MyEnum&gt;().ok()?; Some(value) } } /// ... let value: Option&lt;MyEnum&gt; = combo.get_active_value(); ```
This seems very useful! So with Popsicle one can use e.g. 30 USB SD card readers through nested hubs and flash a Raspberry Pi img to all 30 microSD cards at once? Or would that not work because the GUI can't show so many devices or are there problems with nested USB hubs?
The thing about lifetime shadowing is that it causes compiler errors -- sometimes confusing ones, but still, an error. It's pretty tricky for lifetime shadowing to go wrong in a way that compiles. Clippy only runs well on code that compiles -- we do have some lints that run early in the pipeline, but anything to do with lifetimes will run after all the lifetime checking.
Probably better to post this over on https://play.rust-lang.org/ Much more readable. 
Nice. It's a good idea for bringing Rust to more people and making it more accessible! &gt; it can be a little bit challenging when a screen recorder just crashes during a recording session Will the next video be about rewriting the screen recorder in Rust? ;)
That's the [arbitrary self types](https://github.com/rust-lang/rust/issues/44874) feature. From there: &gt; There's no reason the self syntax has to be restricted to &amp;T, &amp;mut T and Box&lt;T&gt;, we should allow for more types
That's quite a good description of what it is like, concurrency fuzzing. As I recall the tool I have in mind could build a graph of possible thread orderings and systematically explore the graph, but sadly I can't find the webpage about it anymore. Still, such things are possible, and the first one to execute such a tool on a Rust program and write a blog post about it will reap some sweet sweet reddit/hackernews karma ;-) Having said that your testing method sounds pretty interesting as well, and I imagine it can be very helpful when looking for errors, even if you can't replay executions.
yes, and a compatibility shim to make it easier to move piecemeal.
You can run `rustc --print sysroot` to locate the root of your rust installation. When installed via rustup, this will be different depending on what toolchain is active, so you'll want to pick the one that you actually want to use. However, if all you need is `gdb` or something, then rustup does install stubs for `rust-gdb` and `rust-lldb` into your `~/.cargo/bin` folder, so you may be able to use that, and it will automatically pick the correct toolchain.
&gt; const FONT_DATA: &amp;[u8] = include_bytes!("prerendered_font.blob"); Shouldn't it be this instead? &gt; const FONT_DATA: &amp;[u8] = &amp;include_bytes!("prerendered_font.blob"); --- With a normal array (not slice), if it's `const` (instead of `static`), it will be copied onto the stack wherever it's used, right?
And Futures. And Hyper. Which can be required to write web applications. 
I use to love to program in assembly language and was quite good at it. I had all the power and my code was clean and clear. With not too many bugs and I could easily debug them with a low level debugger. Everything was obvious and without subtleties. Back then it was also the only option to have speedy and powerful programs. Later, C gave me a similar feeling but with the ability to express things a bit more abstractly. It also enabled me to develop on more systems as I didn't have to learn a new assembly and OS details with every processor and machine I programmed on. I still consider the initial C as a kind of high level assembly language. With greater coding speed came also the risk of more complex or subtle bugs and required more advanced debuggers. Later I had the chance to do some OS development for one of the big vendors back then. Instead of C they used an enhanced version of Pascal. And boy what a relieve it was when I discovered the capabilities of a language and compiler to prevent silly bugs, like range overruns, improper typing in function calls, etc. Since then I've disliked C as much as I love(d) it. Sadly all the languages that appealed me (Modula's, Oberon and eventually Ada) were used in niches with global no job opportunities. All this to say that Rust got my attention as yet another attempt to have a better language. I dislike it's C like syntax and find that it still lacks features other languages have to offer as a programming experience with less bugs. However it has the same power as modern C++, has some momentum and is still evolving. I'm thinking of things like contract based programming, ranged types, etc. As such I am supportive in people highlighting some aspects that are to easily accidentally misused. In my career I've seen too many bugs introduced by poor programmes or programming practice. The average developer is average and even power developers should enjoy some brain relief when doing trivial programming and focus on the less trivial stuff. But maybe this is pointless and will be replaced by AI and we will all be out of jobs as those systems will not make human errors. With some luck I'll be retired by then.
I'm trying to figure out what it needs, honestly :). While I was waiting for responses I saw someone mention elsewhere using git for windows mingw but even trying to point CLion at that folder (either root or executables). I have a feeling I'm being terribly dense here, but I also haven't used any Jetbrains IDE in years.
[There you go](https://play.rust-lang.org/?gist=ca46ffa809fb89b4e1279e0c55e906ec&amp;version=stable&amp;mode=debug&amp;edition=2015).
If you're looking for something lower level rusttype is pretty good, it is just a rasterizer though.
Just got `Smithy`, a Rust to WebAssembly framework I've been writing in my spare time (who needs hobbies?) into a good enough state to make a todo list app in it! Yay! http://todolist.robertbalicki.com/ &lt;- The components are 100% written in Rust :-D Next up is taking a mental break, and after that I think figuring out wasm-pack, etc., getting the size of that wasm file down to a reasonable size :) and getting a not-completely-embarassing deploy process. And once js-sys and web-sys are ready, moving more of the framework into Rust.
Let’s say you have four programs that all use the same libraries. If they’re statically linked (compiled into the binary) that’s three redundant libraries. If the binaries are dynamically linked, the binary searches for a copy of the library on disk and loads it. That way you only have one copy and a smaller binary. Dynamic linking can also cause DLL hell and missing .so files.
Thank you! That does it. Indeed, it also more closely matches what my actual code is doing. I solved the issue by just "simplifying" things by removing unnecessary Result/Option wrapping.
Ahhh OK. Well then I'd much rather have static linking. Both as a programmer and a user.
I wouldn't mind seeing ranged types and/or contract based programming in Rust either. I hope experimentation with ranged types may begin for real when const generics get added to the language, but we'll have to wait and see. As for contract based programming, there is some interest in the academic world and (as far as I am aware) a lot of work has already happened with regard to formal semantics, even if it isn't complete yet. So hopefully we'll be able to formally prove things about small Rust programs too (especially correctness of modules containing `unsafe`). Sadly my experience in this area is limited mostly to Java, using explicit loops instead of the iterator adaptors that are so popular in Rust, so I have a hard time imagining how hard or easy this would be in practice. I love all these things. I also miss shadowing local variables when I program in languages such as C#. I don't think we fundamentally disagree about the importance of correctness, just about how much of a footgun shadowing is :-)
If there's a bugfix in the standard library, any application you're using that statically links it will have to be recompiled against the fixed version to get the fix. Applications that were dynamically linked to it can receive the fix by having just the globally installed standard library upgraded. So as a user you'd prefer it because you don't have to download so many updates, and as a programmer you wouldn't need to release new versions for upstream bugs. There are downsides as well; version compatibility can be fiddly, older versions may have to be supported for longer, it can be harder to evolve the shared libraries, etc.
I suspect (but I'm just guessing) that the result of `create_ldevice_and_setup_queues` in your code depends on `&amp;instance`, thus ensuring that `instance` remains borrowed while it is alive. Because you assign the `ldevice` in `Ok(ldevice)` to the binding *outside* the match, you ensure that `instance` remains borrowed for as long as `ldevice` exists. But then your other match arm tries to move out of `instance`, even though it is still borrowed! At this point `rustc` starts yelling at you. I suspect non-lexical lifetimes (NLL) might help you out in this case, but it is usually possible to change the code so that the error goes away, as you seem to have discovered. If you have a similar question in the future, providing the function signatures of the functions involved would make it much easier to provide an answer. In this case the function signatures of `create_ldevice_and_setup_queues` and `clean_up_and_panic` would have helped a lot.
C# also uses "task" extensively.
I'd like to build a web application with a Rust backend and a Rust/wasm frontend all in a single repository. Is this sane? What's the best way to do this? Are there any examples to follow?
Well wouldn't you want to have that control over your own application (as a developer). If there's a fix I (!) want to fix it and send out a new version of the app and not having to wait until the distro updates to the newer/est glibc/rustlib/etc..
There is an example of this at https://medium.com/@saschagrunert/a-web-application-completely-in-rust-6f6bdb6c4471
I don’t know about anyone else, but I find the language usage in the Python asyncio documentation terribly confusing. Maybe there’s some kind of keystone document to make the whole thing clear that I missed though. That said, if we are going to call executors “task executors” consistently, I think it’s probably fine.
Looks like the Darcula theme in IntelliJ IDEA, with Fira Code as the font.
One might also define order for such a type by comparing `x * y` of two instances (or some other formula). At that point there no longer exists an order of bytes of `x` and `y` so that sorting the bytes has the same order as sorting the original `Foo`s for all values of `x` and `y`.
That will work, and this was demonstrated at LFNW with flashing a large number of USB drives with our Pop!_OS ISOs: https://twitter.com/system76/status/990627154516959232 As for the GTK3 GUI, devices are displayed with a `ScrolledWindow`, so no matter how many devices are getting their progress bars &amp; throughput labels updated, you can always scroll through the list if it doesn't fit in your window.
Unless I'm misremembering, `Box::new([0; 300_000])` will allocate it on the stack and then move it to the heap. Is there a reason you can't use `Vec::with_capacity` to initialize your memory?
This is just an example. Actually I Box&lt;VSRead&gt; and append to it 300k elements. It stackoverflows anyway.
And to end this thread, in my rust toy game I've one function that uses shadowing extensively (a variable named result) but I do it on purpose and knowingly and I wouldn't mind to add a keyword to silence the compiler as I see value to it. One of my teachers said you write code once, read it thousands of time. This is also why I prefer verbose Pascal like syntax to the more shorter C like syntax. Pascal and Ada saved me a few times during refactoring blocks whereas C like families everything is blocked with a pair of curly braces (not yet as bad as lisp :-P). I still remember vividly the pain of trying to fix my C compilation back then on a RS232 CRT terminal after some "refactoring". Luckily editors and IDE's became so much better in helping lost programmers in those cases.
Rust is a bit stupid in this aspect because it will try to allocate that huge array on the stack, allocate heap memory (for the box), and then move the array into the box. Obviously the first shep in this process will trigger a stack overflow. You can work around this by using a `Vec&lt;T&gt;`. Just allocate it `with_capacity`, fill it with that number of elements, and call `into_boxed_slice` to get your `Box&lt;[T]&gt;`.
As do others like https://monix.io which [sees it as lazy eval](https://monix.io/docs/3x/eval/task.html#introduction).
&gt; providing a keyword won't make things magically good either. No, and "if let" didn't provide anything magically better than "`{ let ...; if ...; }`". It just made code more convenient and intent clearer. What a `relet` keyword would do is communicate the *intent* to shadow this variable, which `let` currently doesn't. &gt; A keyword would fix the problem of "too much typing" with #`[allow(shadow_reuse)]`, but you would still need to write `relet` a lot. It saves typing, is more readable, *and* turns implicit semantics into explicit ones. Maybe it's small, but it's not nothing. &gt; but `relet` won't help with patterns :/ Sure it could, if it was designed to handle them the same way. But I'd argue that kind of shadowing is probably one of the "least bad", since you're creating a new scope anyway. &gt; Finer grained shadowing lints focused on trying to catch particular types of bugs might be more widely applicable than adding a new keyword for a coarse grained annoying lint just to try to make it appear less annoying. The existing clippy lints are [already broken down into three](https://rust-lang-nursery.github.io/rust-clippy/master/index.html#shadow). I imagine that `shadow_unrelated` is the general worst offender in terms of unintentional use, and may have prevented OP's issue - but don't know for sure. I'm all for improving lints, but I can't really think of any other ways to break it down that would make it less annoying. Moreover, sometimes lints aren't sufficient. The borrow checker, for example, *could* maybe be a lint - but it was made into a language feature. Why? So it could have first class support and inform peoples' behavior. To be clear, this isn't a high priority issue for me either, but I do find myself agreeing with OP that shadowing could cause nasty bugs in nontrivial code. I'm not necessarily sold on preventing it as a blanket proposal, but I'm open to considering it, and I'm a bit confused by some of the strong negative reactions in this thread.
Does it stack overflow in its `drop` handler, by any chance? Please be more accurate in your question, that `Box::new([0; 300_000])` is totally misleading if you are using a linked list.
Could you please provide a compilable example that reproduces your problem? Are you using recursion to implement `append`?
Thanks! 
aren't you a kool kid :) 
Yeah, I was wrong using Box::new([0; 300_00]), it was just an example of the box stackoverflowing, but sorry it only made things more confusing. Check the post again, I tried to explain, I create a boxed VSRead and append to it.
Where does`list` come from in your example?
Here https://play.rust-lang.org/?gist=316f2338265df3b39643d7200b9b0b9a&amp;version=stable&amp;mode=debug&amp;edition=2015
You can already `self: Box&lt;Self&gt;` on stable. But yeah, `Pin&lt;Self&gt;` uses arbitrary self types.
Here is the code https://play.rust-lang.org/?gist=316f2338265df3b39643d7200b9b0b9a&amp;version=stable&amp;mode=debug&amp;edition=2015
Talent Acquisition - I recently joined Ticketmaster's Scottsdale office. I'm partnering with SVP to help him connect with Rust folks in the valley :)
The overflow happens when the list gets dropped. Pou can tell by simply inserting a `println!("foo"); as the last line in your test, the overflow happens afterwards. Manually implement `Drop` for your type, and ensure you destroy the nodes iteratively instead of recursively.
Thanks!
I use rust at work and we dont have a single line in c or c++.
Thanks for that. Just because I haven't been able to fully understand [gtk::ListStore](http://gtk-rs.org/docs/gtk/struct.ListStore.html), with making a custom model, there's no way to have an enum in it, is that correct?
Note that part of the issue may be that you've installed MSVC Rust rather than mingw; unless you've already got mingw and specifically ask rustup to install the mingw version of Rust, it will default to MSVC. If you're using the mingw version of Rust, ¯\\\_(ツ)\_/¯, tooling is rough on Windows sadly. I've no extra help beyond "make sure you're actually using mingw Rust" unfortunately.
The "whole body cryogenic preservation" under benefits though. 
In your first code example, what benefit does this have over over simply returning a + 1 ?
One other thing I was thinking about is that the strings that I have in the `ComboBoxText`s are "Imperial (British)", "Imperial (US)", and "Metric". What's the best way to implement FromStr so that `.parse()` will correctly output imperialGB, imperialUS, metric as the enum variants?
I'm working on a new project and I would like for it to utilize a toml config file. Coming from Java, I would normally make the file with default values in source and use maven to copy a resources directory to my target directory when I build my project. Cargo seems to, by design, lack this functionality. What would be the best way to handle this in rust?
I just ran 'rustup which rustc' and it says my gnu version. A total valid question though, and at this point I'm willing to try anything people suggest because clion will be better than my current methodology (notepad++), I'd like the debugger to push it over the top into fully awesome and not just great.
There are some types of applications where this would be ideal, though. IE: system shells &amp; core utilities.
Windows will commit the memory on the first access. It will try to do that even if it means that it has to swap so much that it becomes unusable. My point is that even if it would do that, you can catch the exception (you can implement some cool things on top of this). This has the added effect of having a system of per process memory quotas that are dependent on the user permissions and the process and differ in terms of commited and reserved memory - again, really powerful if you need it. As an outsider, simply killing a process at random (more or less) sounds crazy. But letting a process almost freeze the system when it becomes memory hungry has some drawbacks as well. 
Executors don't necessarily make any guarantees about what threads a task may be run on (provided that the \`Future\` the task is running is \`Send\`). They're free to move them around, so if you're asking if the thread-local storage will be consistent for a task across its lifetime, that's not necessarily the case. If you're asking "can they use TLS" in the "TLS is gross ambient-authority and multiple overlapping expectations around how TLS is used can cause bad program behavior" sense, then I think the specific behavior is executor dependent, but certainly the real-world executors that I know of make attempts not to use TLS in a way that would cause conflicts if, say, an object in a task attempted to access TLS in its \`Drop\` impl.
The C++ standard library also uses the word [task](https://en.cppreference.com/w/cpp/thread/packaged_task) similarly.
As an alternative approach, you could setup a custom build script and have it read from the config TOML file. It would substitute the proper values into the Rust code and the config would be built into the executable, which is effectively no overhead. You might want to look at the `env!` macro for this.
Tbh I don't understand how you can be a developer and not be at least semi-familiar with c/c++. It comes up everywhere. There are so many problems where the answer is "well shit" if you refuse to look into native code. Moreso I'm ranting about people I've encountered who do that, than this thread... But it blows my mind.
Why not have the join iterator collect into a `T`, when the element type is `T` and the separator type is also `T`, and `T` implements `Add&lt;RHS=Self, Output=Self&gt;`? As an example, if we were joining an iterator of strings with a string separator, we could collect it into a string.
GtkComboBoxText has default model. It contains two fields: 'id' and 'text'. get_active_id just takes `id` field from active item of a model. I don't know how your model is filled in. This is in your .glade file. You can have ids like 'us', 'uk', 'normal' ;) and texts like you already have, human readable and translatable to different languages.
Excellent, thanks for the link. 
&gt; It comes up everywhere. There are so many problems where the answer is "well shit" if you refuse to look into native code. True, if you want to fix things yourselves. But much of the time that isn't necessary these days. You can ping the maintainer of your library on Github, or more likely find someone else that has already had the same issue as you on Github or Stack Overflow. Of course, it's great if you can fix these things yourself. And there are indeed problem domains where these issues come up more frequently. But I've been a developer 10 years, and I can probably count on one hand the number of times I've *needed* to touch native code.
I am not very familiar with modern day web development. But the simple todo example has a 1.36MB wasm file, is this an issue? Will there be changes that will result in smaller binaries?
Where do I apply?
Other reasons you want dynamic linking: - reduced network usage (smaller files) - a more secure system (updating a single vulnerable library instead of hunting all users of that library and updating them)
You can use `build.rs` to do any custom build-time behaviour, like copy files into the output etc... Are you talking about using a custom *.toml file or re-using the Cargo.toml file? If it's custom, I would take a look at `serde` and `toml-rs` crates. Defaults can be set with field attributes: https://serde.rs/attr-default.html
I thought ticket agent and thought that maybe that's what they call their software engineer titles to make them feel more "in"!
I edited above, I forgot because I was confusing myself with ComboBox. While implementing FromStr, is the best way with a match statement for `str` and return a Result&lt;MyEnum, Err&gt;?
Yeah, match works well in this case.
Great. In reference to models, is there any good documentation on creating custom ones?
So, how can we get the "fast" behavior back in Rust when necessary? Does it work to do `i = i.checked_add(1).unwrap_or_else(|| unsafe { unreachable_unsafe() })`?
Hey, I'm trying but now things just overflow during Drop, when I deref a node. It currently overflows when I print self as Debug, but if that line is removed it overflows during the first self.node.cell.get() deref. I have no idea why. https://play.rust-lang.org/?gist=b1c73c51a8d625c62d66a432e6f47d5d&amp;version=stable&amp;mode=debug&amp;edition=2015
[`itertools`](https://crates.io/crates/itertools): Do you like iterator combinators? It has more of them. It's like candy, except it doesn't make your teeth fall out or make you fat.^† --- †: These claims have not been medically tested. Consume `itertools` at your own risk, and only after consulting a medical professional.
This is exactly what I was looking for, thank you!
The [`include_str`](https://doc.rust-lang.org/std/macro.include_str.html) and [`include_bytes`](https://doc.rust-lang.org/std/macro.include_bytes.html) macros provide an extremely easy and lightweight way to statically bundle arbitrary resources with your program. They resolve all data at compile time and insert it directly into your program, so you can distribute your program as a single self-contained binary. In your case, you could do something like: ``` let default_config = parse_my_config_format(include_str!("default.toml")); ```
[stdx](https://github.com/brson/stdx): not a crate, persay, but a collection of them. A bunch of useful "batteries" for your Rust code.
Your form's not accessible
[rayon](https://crates.io/crates/rayon): Rust gives you fearless concurrency. Take advantage of it easily! Similarly, [crossbeam](https://crates.io/crates/crossbeam) for more manual parallelism, but in a nicely organized and fearless manner.
You could always do ``` rustfmt --version || true ```
Definitely a bug. This does not occur in older versions
That behavior is supported, in two ways: - `Join` implements `Display`, so you can already do `to_string` on any `Join` with displayable components. - If the iterator element type `T` and the separator `S` both implement `Into&lt;R&gt;`, you can use `JoinIter::normalize` to convert it to an iterator of type `R`. Note that this means it automatically works if `T` and `S` are the same type. I'll also point out, in case you're unfamiliar, that Rust has a trait called `Sum` which is specifically designed for the case where you have an iterator and want to do a sum over it. More generally, Rust has plenty of traits for collecting things out of iterators (`FromIterator`, `Extend`, `collect`, plus adapters like `try_fold`). My iterator is a Rust Iterator, so it automatically supports all of them out of the box!
There are a number of tools (wasm pack, wasm gc, etc) that substantially decrease bundle size, that I haven't integrated yet. But yes, that does point to a problem and I'd be extremely wary if this was being used in prod as it is now :)
Just filed an issue. Looks like it happened [here](https://github.com/rust-lang-nursery/rustfmt/commit/71d3d04270474ae0afdeeb410fdcc168a54714b7#diff-3ed52e1338892b7d63abd1daf724afbeR187)
&gt; very hard to detect Aren't they trivially detectable by linters? Variable shadowing isn't exactly a hard problem to solve, or search for.
Even if I agreed that those uses should share the same lib (which I don't), I definitely wouldn't agree with it being part of the bar install of the distro. Only in very resource constrained environments would the benefits of sharing Rust's stdlib have value, and at that point it can be done manually.
/r/playrust
&gt; There's no reason There's absolutely a reason. Pretending that C++ is the kitchen sink and then dragging any bright idea through committee, simply because "onto the next RFC" is not a recipe for signal to noise.
&gt; let ok_value = ready!(self.future().poll()?); That's the short version? Indecipherable, high cognitive load, difficult to cognitively parse, wordy and overly verbose, terrible signal to noise, adding complexity rather than abstracting it?
Is rustfmt now bundled with nightly? Why does rustfmt-preview give nonsense formatting for the hello world example? Is it beneath open source everyone to work on this, adding actual value to adoption (manager - finally I can quench the time sink style wars on my team) rather than pie in the sky feature additions to put on a GitHub resume? Is it worth my (and everyone else's) time to scour the web to figure out how to get basic tooling working? PS C:\hello_world&gt; rustfmt error: toolchain 'nightly-x86_64-pc-windows-msvc' does not have the binary `rustfmt.exe` PS C:\hello_world&gt; rustfmt-preview rustfmt-preview : The term 'rustfmt-preview' is not recognized as the name of a cmdlet... PS C:\hello_world&gt; rustup update info: syncing channel updates for 'nightly-x86_64-pc-windows-msvc' nightly-x86_64-pc-windows-msvc unchanged - rustc 1.29.0-nightly (54628c8ea 2018-07-30) Yes added to PATH on rust install and new PS cmd window afterwards.
[https://i.imgur.com/ojXd92B.png](https://i.imgur.com/ojXd92B.png)
Because "green threads" is hyped up modern slang trying to coin a new term. Stop trying to make green threads happen Gretchen. User mode threads is understandable by everyone. Irony is the first sentence is spot on - reinventing known terms is typically a bad idea, even if the language strives to be different just to be different.
[nom](https://crates.io/crates/nom) if you need to parse non-standard formats.
Would you tell why you picked Rust to do this ? 
Yes it's a good language to learn to sharpen you skills and grok some novel concepts. But a general purpose programming language that can't even give good solutions for implementing trees and graphs is hardly a great systems programming language for file systems (which use them heavily) or the like - yes it can be done, but then you're either subverting borrow checking or resorting to hacks like passing iterators everywhere instead of a packaged node type. Paradigms which ignore advancements of the past, like OO concepts (but think *packaged* composition instead of inheritance) and exceptions (code tells you where the bug is with full stack traces, none of this panic half-attempts sprinkled here &amp; there without rhyme or reason - it's either a logic error or it is a potentially expected return code, there's not much to argue about w.r.t. exceptions anymore) is destined to simply invent their own mistakes, pretending it's "better" because it's different all along the way. c.f. traits explosion. 
..it's just a macro and calling a few methods? With the error handling `?`. you may want to consider a line of work other than programming if you find methods too complicated to understand.
Why would I be using Rust (8yrs old), with concurrency primitives still in infancy instead of Golang (8yrs old) which has had them production grade for quite a while (even Kotlin [7yrs old] is close to stable for concurrency support) for a project where concurrency is the dominant scaling factor (NodeJS IO intensive space)? And 'once this is fleshed out/stable' has been an excuse here for several years now. Just pull up the ycombinator threads. At this rate C++ concurrency will be in std and so will modules, no rush.
&gt; True, if you want to fix things yourselves. But much of the time that isn't necessary these days. See Linux. The only 2 distros which have succeeded in that are MacOS/iOS and Android - commercial ventures. Pretending open source is going to be polished and mom &amp; pop ready is snake oil. The reason the JVM is so good these days is Google invested in it for Android platform. Likewise story for C#. QED
It's distributed as a component: `rustup component add rustfmt-preview`
Search for a `rustlib` folder. And look around in the `x86_64-pc-windows-gnu` that will be inside of it.
Sorry, just fixed the link. 
Please still fill out the form with your info so we can keep track of all canidates in a single place. Thanks - looking forward to reviewing your application!
You're criticizing Rust for failing to learn from the advancements of the past, while advocating for _go_, the most NIH syndrome driven language of all time. You also don't really understand anything about how unsafe works in Rust, and you're really, really ignorant of how exception handling works in Rust. (It's quite similar to go, actually, but a usable type system makes it a lot more ergonomic). 
Looks like they've [fixed it]!(https://github.com/rust-lang-nursery/rustfmt/commit/ca6b360c8a2c40bec3cf04bb4c9198ad30779309).
Cute! Sewing curves is such a pain &gt;.&gt; Also: `#![deny(missing_docs)]`. I like you. You're good people.
Why are you hiring a contractor and not someone full time?
Ah great to hear from you on this post! Thanks for that link, it looks perfect - if you don't mind, I might have a go at updating bytekey to modern, stable rust today and submit a PR.
Seconding. I do embedded work and use nom constantly for parsing data from devices (normally I2C or UART)
For something that is very used, I too think it's too verbose and should be abstracted.
I'm certainly not advocating for a broken language like Go. That's your inference and podium. I'd advocate for modern C++ over that any day. I don't know that unsafe allows pointer aliasing, subverting the entire point of move semantics by default and verifyable lifetimes? Please do explain, since your retort is so short on specifics. Don't bother to make another appeal to purported authority argument. I already illustrated the problem with panics being used willy nilly in Rust libraries and crates. Go error handling story is even worse. C++ w/ RAII actually got it right (don't bother preaching about footguns, raise you hiring bar as any incompetents will surely tank a project regardless of rails). If red herrings and character assassination is your spiel don't bother replying. Noone's confused, find a better argument. 
Green threads is a pretty old term from early java (1.1) days though..
It's installed as `cargo fmt` rather than a standalone tool.
Relevant username.
We should really have a getting started section in the sidebar. And it should include [awesome-rust](https://github.com/rust-unofficial/awesome-rust).
Hi all, compiler question. Is rust compiler smart enough to optimize away the intermediate \`new\_\` step: let (mut a, mut b) = some_initial_pair; // do some with &amp;a and &amp;b, then: let (new_a, new_b) = some_new_computed_pair; a = new_a; b = new_b; Or should I use something like: let mut a_and_b = some_initial_pair; // do some with &amp;a_and_b.0 and &amp;a_and_b.1, then: a_and_b = some_new_computed_pair; which is less clear and more verbose for the rest of the code
Btw, question regarding stickful vs stackless stance for Rust here - one of the things that I think C++, Kotlin, and many other languages get wrong here is the composability problem. I have no issue with explicit suspension points a la await, but it's really the required Future return type annotations which break the composability of concurrency. It's really the one novel thing about Go and something they got right (but ignore stack resource limitations for the moment). The caller should decide what to call as async vs sync. And this decision should not infect their function signature, since then coroutnies are an all or none proposition (everything needs to return Futures). What's the current thinking here? Based on brief research it seems the power of a C++ model is desired but how is the above deficiency addressed?
&gt; using warn is preferable IMO because deny cascades into dependencies and bites you sometimes In case someone else is wondering, cargo caps the lint level when building anything other than the "main crate", meaning lint failures in a dependency (e.g. due to a new compiler) won't break your own build.
Usually Rust will elide copies, and while this is not guaranteed, you can install and use `cargo-asm` to see if it makes a difference.
It looks like it hasn't been updated in a year though? 
Yeah but the crates listed have been. I don't think any of the tasks solved by the stdx recommended crates have been superceded, have they? (Except maybe error-chain/failure depending on which error solution you prefer)
I'll be publishing to [crates.io](https://crates.io) once all my dependencies merge the PRs I sent to them. ([crates.io](https://crates.io) won't let me publish until then.)
Sure, if your project is a good fit for golang, (pun intended) go for it. Rust *may* however bring other benefits such as easier dependency handling (thanks to cargo), less time spent debugging (thanks to the awesome safety guarantees), easier C FFI (where needed), a very powerful type system you can use to e.g. encode ordering constraints, which you'd otherwise need to document and hope for the best.
Please refrain from this type of comment here. It comes off as gatekeeping ('True developers know C').
IOS is not on Linux, but a Mach kernel. And Google's investment in OpenJDK is dwarfed by Oracle, IBM and RedHat. What was your point?
A kernel does not an OS make. And BSD and Linux are so similar, esp w.r.t. the experts required maintenance issue, the point still stands (it took a commercial party to do the required dirty work to polish things to make them user friendly and mainstream usable). Let's be real, despite Java's beginnings, not many were using it despite cross platform run anywhere advantages, until Google optimized the JVM. C# runtime performance used to always beat Java prior, and now it's the reverse? Is there hopefully more snark?
Thanks for that, my problem is around the ::new operator and setting the SocketAddr to something so I can then populate this with the correct values later on.
Update: Life is good, properly implemented Drop for VSRead and VSReadIter, thanks. Implicit recursion is hard. The Debug trait also bit my ass because it's a natural recursion.
The dependency manager/packaging system and lifetime guarantees are actually what interest me. You'd be surprised how hard it is to sell junior devs on RAII despite it eliminating entire classes of bugs and exploits. Which is why something baked into the language is advantageous. My main issue with Rust is not the initial learning curve (needing to read a book is not a con), but the open source standardization process. Both the C++ standardization committee (and who have accomplished a lot in recent years with their targeted TS tracts) and Linux are much more rigorous and stringent in their standardization process as far as what's accepted into 'main'. What I've seen in this community is a fear of hurting people feelings - so long as something has been in the unstable playground for long enough, way too many additions are accepted into the language. There's a reason why JavaScript The Good Parts and subsequent Trojan horses like TypeScript and Node have done so well. Oh that and the ivory tower insistence on no really ML is better, here's a way to sneak it into the mainstream. Go took one good idea - concurrency builtm in - and added not much more in order to take head in design by committee language development folly. Rust should have just focused on GC free verifyable race-free on an imperative syntax and left out the Lisp/ML/Haskel/choose your own functional programming is so beautiful baggage. Mach kernels typically are only halfway microkernels and companies rightly avoid message passing systems for programming language choice since they are pragmatists not washed up artists. And the argument that C++ generics are flawed due to compile time increases is a weak argument for a language with slow compile times. Constrained true generics would have worked out better than traits do for the type system.
Oh yeah that's discoverable and intuitive. Will anyone ever focus on ease of use or did everyone stop reading Don't Make Me Think after the first chapter?
Right now? No. Rust has failed to deliver on its promise of a safe compiled language. Sure, it has borrowing and some related features, but the Rust ecosystem as a whole fails to deliver on the promise of safety. Currently only toy programs can really benefit from the language features. Any real product that utilises any Cargo crates at all will almost certainly be pulling in reams of C/C++ code as well as Rust libraries of questionable quality. Really basic APIs are not yet at v1.0 levels and it shows. I've been finding lots of bugs just been reading through the sources of various popular libraries, which ought not to be possible given the minimal amount of Rust programming I've been doing. Someone using Rust in production will be tripping over these issues a lot more. It's illuminating to look at the crates that depend on the 'cc' crate, which is what cargo uses to compile non-Rust C or C++ code: https://crates.io/crates/cc/reverse_dependencies Note that the list above shows the first-hop dependencies only! So for example, 'ring' depends on 'cc' (because it contains C/C++ code), and it is in turn used by 'cookie': https://crates.io/crates/ring/reverse_dependencies The 'cookie' crate is then pulled in by a bunch of popular web frameworks: https://crates.io/crates/cookie/reverse_dependencies So when someone says they've written a "Rust" web application, what they're really doing is glueing together dozens of crates, quite a few of which are not written in Rust... I would be confident writing a Java or C# web application and using it for Internet-facing financial transaction processing. Right now I can't say the same about any Rust web framework for even a customer blog, let alone anything serious.
Distros typically do that fast for important bugfixes (especially security fixes). The idea is that they can always handle it quickly, but if there are a bunch of different apps that all need updating, some of those might be single-person projects (or even unmaintained) and not so quickly updated. It's not free from debate for sure, and I'm not really arguing for it; just answering the question of what some of the upsides would be :)
Great points echo chamber. Stillborn? After the peak? Wow, everyone stockpile the lifeboats. You know, just in case.
Haha, Wrocław, Poland, http://anixe.pl. Unfortunately remote job is currently not possible. Maybe some day... 
You may want to consider var a = await func() instead of pretending that library additions are superior to language additions with the false promise (lulz) of being able to change them later - we all know once enough code is built around them - stable / nursery / whatever - that they are set in stone. Meaning language additions are cleaner. C# is actually really nice to program in were it not for being a GC'd lang.
Welcome to the club of people who found out the hard way ;-) Good luck with your project!
That sounds interesting, could you expand on it? What kind of PRs and why does crates not let you publish unless they're merged?
This looks really good! I might look at replacing Alacritty's font code with this once it matures a bit.
Thanks to [rust.cologne](https://rust.cologne) for the layout! Also, if you want, you can find the template at [https://github.com/rust-community/rust-meetup-template](https://github.com/rust-community/rust-meetup-template) now.
The traditional "eat the status-code" is `||:` 
And back in the day Java 1.1 was used by basically no-one and green threads were certainly not taught in many curriculums before Java moved to native threads. The above doesn't make the term very mainstream for typical programmers. Gotta love how strawmen are the voice of reason in an open-minded obviously correct community.
Thanks for the pointer! I don't think I'm ready yet to look at optimized assembly code ahah. I'll just leave that as it is for the moment, and come back to it later then. But just to be a little more precise on the question. I think what I want to ask is: If a returned value (`new_a`) has no other purpose than to be directly moved into another already allocated one (`a`), is the rust compiler optimizing the operations by directly using the memory of the allocated one (`a`) for the value returned by the function (`new_a`)?
Are you poor because you program in a dead language or are you a poet? Really not sure what to expect.
Currently it's not easily possible but possible, I wrote about the current status of `GObject` subclassing before: https://www.reddit.com/r/rust/comments/8zskfw/gtkrs_is_it_possible_to_create_subclasses/e2l7hjx/
I find awesome rust just too much -- also quite a bit of it isn't "awesome" -- libraries with reported bugs with no comments or new commits for over 6 months
It was in my corriculum. The term has been popping up in various discussions for a long time. I'l have regularly seen it over the past 15 years. You're the one using terms "typical programmer". Accusing me of straw manning is a bit of a case of projection.
Ok got it. Thanks for taking the time. :-)
Kept for compatibility - yes. Doesn't mean they can't be superseded by a language construct later. Case in point: the try! macro.
The vast pool of prospective programmers are taught on Python, Java, JavaScript, and C++ and "green threads" is much more language design enthusiast niche than you're willing to admit. Yet everyone has been taught pre-emptive vs cooperative multitasking and has at least heard of userland p-threading library.
Shout-out to the genius for coming up with "Berline.rs" (hard to explain for none German native speaking people, even for those not living in close proximity or used to our vernacular) also love the dish Ferris is holding :)
This looks great! Do you know/recommend a crate for caching the generated glyphs? (e.g. into an openGL texture)
Google doesn't use the JVM in Android.
Interesting!, but $2000 is less than a months salary though.
Pretty cool, I've used Meetup before to keep an eye on Rust events (though I never went to one) and sometimes I lose track of events there. Nice to have a dedicated page for it. Super minor thing: your link to the meetup page of "Binding to Rust from everything" seems to have a '/' too many on the end, so it doesn't load properly. 
&gt; So, how can we get the "fast" behavior back in Rust when necessary? I don't think you can. The following snippet (https://godbolt.org/g/jQ2jhj): pub fn add(x: i32, y: i32) -&gt; i32 { x.checked_add(y) .unwrap_or_else(|| unsafe { unreachable_unchecked() }) } produces define i32 @_ZN7example3add17hcda0c94fe302bc69E(i32 %x, i32 %y) unnamed_addr #0 personality i32 (i32, i32, i64, %"unwind::libunwind::_Unwind_Exception"*, %"unwind::libunwind::_Unwind_Context"*)* @rust_eh_personality { %0 = add i32 %y, %x ret i32 %0 } which means that `unreachable_unchecked` is not enough. To get the same effect, we would need to emit `add nsw nuw i32 x, y` instead (`nsw`: no-signed-wrap, `nuw`: no-unsigned-wrap). 
If you were using it for something else after the assignment, for example (and not returning it), it would allow you to not have to make `a` `mut` for the whole function body.
https://www.parks.ca.gov/pages/22491/files/black_barts_poetry.pdf
You can't publish a crate with unpublished (E.g. git) dependencies to crates.io. All dependencies must also be published themselves.
I really don't agree yet with your arguments. As I see it, `relet` reduces the typing of `#[allow(...)]`, which I agree it would be more convenient. It doesn't solve all the problems that allow does for shadowing just yet, but nobody has proposed anything that would work with patterns yet. At the same time, `relet` is a pretty big language change, and if it would work in patterns it would be an even bigger change. So `relet` adds a lot of cost to the language, if we add it, it has to be worth it. Are there enough people using the shadowing bindings and tired enough of `#[allow]` for this to be worth it ? I don't think so. The shadowing lints were enabled by default, and now they are all disabled by default. Looking at sourcegraph, very few projects actually use them, and it is unclear to me that the current lints, nor the proposed ones, would catch bugs at all beyond just being annoying and something that people would just like to disable, like it appears to be currently the case for most Rust code in the wild.
Usually when you have a value in a struct that you want to initialize later on, you make it optional. pub struct Multicast { ip: String, port: u16, sock: Option &lt;SocketAddr&gt;, } impl Multicast { fn new(udp_address: &amp;str, port: u16 )) -&gt; Multicast { Multicast { ip: udp_address, port: port, sock: None, } } fn fill_in_sock_later(&amp;mut self) { let addr = SocketAddr::new(self.ip, self.port); self.sock.get_or_insert(addr); } } But this is a convoluted setup .. every time you use self.sock you need to see if it's not None by matching on it. Or just assume it's valid and use unwrap. Why not set it directly in `new()` ?
We also own [Berline.rs](https://Berline.rs), and the short term plan is to move to that and redirect [berlin.rs](https://berlin.rs) over there. As a second level troll, the parking page was a picture of a berliner... ehm... pfannkuchen.
[Rewrote](https://gitlab.com/termhn/game/tree/new-renderer-indirect) the Veloren (/r/Veloren) renderer to use gfx-hal to become familiar with both, and now working on rewriting that renderer again to be more flexible and to be able to fall back to the old, gfx 0.17 based renderer.
&gt;Pretty cool, I've used Meetup before to keep an eye on Rust events (though I never went to one) and sometimes I lose track of events there. Nice to have a dedicated page for it. Meetups interface degraded massively over the last months, so having a clean overview is really helpful for us. I'm also thinking about adding an RSS feed. \&gt; Super minor thing: your link to the meetup page of "Binding to Rust from everything" seems to have a '/' too many on the end, so it doesn't load properly. Thanks, I'll check that out!
&gt; hard to explain for none German native speaking people It's just the plural of "I am a Berliner".
What's wrong with using std::time?
Thanks, [fixed](https://github.com/berlinrs/berlin.rs/commit/37384973372d7e337cb57e3befe2f6311820392c)
\[twice\]([https://github.com/berlinrs/berlin.rs/pull/11](https://github.com/berlinrs/berlin.rs/pull/11))
Couldn't the compiler or runtime somehow warn about this? That seems like a pretty annoying failure mode.
Isn't Johan Andersson the CEO of Paradox Interactive? Where did you get teh "EA R&amp;D" part?
&gt; berliner... ehm... pfannkuchen (┛ಠ_ಠ)┛彡┻━┻ on my way to correct this ... ᕕ(ಠ_ಠ)ᕗ definitively need to visit some time if the schedule allows :)
Hi all is it a good practice to have a reference on an impl Trait in argument position? Like this: pub fn cls_id(self, op: &amp;impl AsRef&lt;ObjPool&gt;) -&gt; Option&lt;ObjId&gt; I need this because I don't want this argument to be able to move value or a mutable reference when calling this method. So when I call it like this: 237 | child.cls_id(info).unwrap(), | ---- value moved here using a &amp;mut AsRef&lt;ObjPool&gt; it will not move the reference but borrow it instead.
Oh this is quite cool, wasn't aware there was a Rust group in my hometown. Totally coming by next time!
[removed]
uhm... https://www.reddit.com/user/PleaseRespectTables/?
Ehm, we're the most frequent worldwide and closing in on 100 meetups :). https://berlin.rs/archive/ Also, happy to have new people involved in lightweight organising, it's easier if we share the load.
A really nice post, thanks! Interesting to see how it worked in the end. I probably wouldnt have been so patient and would have given up after ten tries with two drives ;-)
The stackoverflow is your runtime warning :p. Using any debugger that can show you a stack trace (so all of them) will immediately tell you what is wrong.
Yes, this is a pretty huge misunderstanding. The reason the JVM is so good these days is that Sun, and then Oracle, invested in it to keep people using Java. 
rusttype does it if you use it as a rasterizer.
This comment is basically completely incorrect.
Wrong subreddit, you're looking for /r/playrust.
`FONT_DATA` is a pointer (to the .data section of the executable), not the data itself. All that will be copied is a pointer, so no, this isn't necessary.
Nothing, I was porting code to use std::time, since before it was brought into std one had to use [time](https://crates.rs/crates/time)
That's really cool, and excellent use of [exhaustive testing](https://randomascii.wordpress.com/2014/01/27/theres-only-four-billion-floatsso-test-them-all/) to boot!
That looks like a compiler bug. That being said, in case the intention is to iterate an array, `Iterator` is the way.
Just a heads up: Meetup's API is excellent (you can basically do absolutely everything you can do from the website from the API). I've been slowly working on a better interface for meetup (in rust!). Which can be viewed at https://bettermeet.app (currently hardcoded to show events from Bristol, UK, but plan is to allow you to sign in with your meetup account).
Reading the comments about the deprecation of `std::char::decode_utf8`, i come across [a comment from /u/SimonSapin](https://github.com/rust-lang/rust/issues/33906#issuecomment-373906532) which sends me off to learn that `std::str::from_utf8` (which works on chunks and is not deprecated) fails with a `std::str::Utf8Error`, which has a method [`valid_up_to`](https://doc.rust-lang.org/stable/std/str/struct.Utf8Error.html#method.valid_up_to) which tells you how much of the input could be decoded as UTF-8. I believe you can use that to do chunked incremental decoding of UTF-8 using only the standard library. Something like: 1. Read in some bytes 2. Use `std::str::from_utf8` to parse them 3. If that works, you had read a whole number of characters, and you have a &amp;str 4. If that fails, use valid_up_to to work out how many bytes were valid, take a subslice of that many bytes, and parse that (unsafely if you want to avoid parsing it again); you now have a &amp;str 5. Do something with the &amp;str that ends with releasing the borrow 6. Copy any remaining bytes to the start of the buffer, and go to step 1 This seems like something you could wrap up nicely, although i'm not sure what the right API is, given all the borrowing. Could you write something that wraps an `Iterator&lt;Item=Result&lt;u8, io::Error&gt;&gt;` and implements `Iterator&lt;Item=Result&lt;&amp;str, io::Error&gt;&gt;`? 
I personally don't consider myself experienced in a language until I've written a project that took at least 100 hours to complete. But I think you can be useful in rust after a few weekends of solid study. But it does have a higher learning curve than most languages I've learn. 
Your budget is kind of ridiculous. Working in McDonalds would earn more money. If the work took a month, then you’d be breaking UK law. $2,000 is less than the UK minimum wage (which is pretty low to start with). The last item to add tests for existing infrastructure also sounds quite nebulous and worrisome. I’ve seen first hand clients use that tactic as a means to try to demand free work. Personally I would change it to kill the nebulous aspect of it. I.e. you’ll be hired for a month to write tests on existing infrastructure.
That sounds like a huge undertaking! How long have you been working on it? What are your main sources of inspiration and goals for it?
Yeah, I'd personally prefer `?` to be defined as "return on error or not ready" as that will be probably the most common thing to do.
But you will have to rely on something to manage asynchronous code. You could write your own, but it takes time to write, then you have to maintain it, then you have to train other people in your team to understand it. It doesn't seem to be viable.
I think you probably meant to post this to /r/playrust (:
maybe you can also port some of the other fast converters: see [https://github.com/miloyip/dtoa-benchmark](https://github.com/miloyip/dtoa-benchmark)
Ha, thanks, that looks good! W also want to add stuff that is not on meetup, so we currently use the API for import. The GH repository has a folder that holds all of the historical data.
Rust's built-in dtoa is already Grisu3. (The most similar version is doubleconv on your list.)
Yeah, I was unsure myself. I don't know what "lfg" stands for, but there's an /r/playrustlfg.
&gt; That looks like a compiler bug. LLVM expects the front-end to set these flags, so it would be a `rustc` bug. However, `rustc` never set these flags, because there is no operation that Rust programs can requests from it that would require these flags to be set. So I don't think its a compiler bug. If anything, the solution would be to add intrinsics to `core::intrinsics` that call `add` with these flags enabled.
That's really cool! Could this be merged into std and replace the existing, slower code?
Cool project !
https://github.com/rust-lang-nursery/rustfmt#quick-start The "Quick Start" section on the first result that comes up when you google "rustfmt" tells you how to install it. I don't know what would be better ease-of-use than that - maybe the error could say "maybe missing component `rustfmt-preview'" or something.
We can’t just ignore stack resource limitations; stackful co-routines have a lot of drawbacks that we can’t afford. We talked through *all* the options when coming up with this design; we chose the drawbacks we chose, but also the advantages we chose. In my understanding, we’re even *more* optimal, performance wise, than the C++ TS. You can also toss non-async stuff on a thread pool to get a future out of it.
Looking For Game
loooking for group actually
and yea i guess i should have im still pretty new to reddit afterall
kk
I meant not optimizing-away the check. Or rather than bug, it's a missing optimization.
&gt;using powershell
It optimizes away the check for the given example when emitting machine code (at least for that target), but the optimized IR is not "optimized" to contain the appropriate annotations for this simple example, which means that in more complex situations where other optimizations rely on this, those won't trigger. Whether this is a missing optimization is at best debatable. LLVM says that you have to write the flags. Rustc cannot write the flags, so we might argue that LLVM should infer them when possible even if we don't write them. Still, LLVM can say, that's not worth it, and this is working as intended (rustc did not emit the flags). 
Ideas: \-compare existing C/C++ implementations with different compilers(stdlibs)/systems with rust speed on the same system - how do you know that the rust implementation is faster (and keeps stable faster) \-Fuzzy testing?
Ah I see, thanks
I switched back to using the `git` command in the last release.
Yeah, that makes sense.
It's a different Johan Andersson. Check his Twitter bio, he works for EA SEED.
Feedbacks are welcome :)
&gt; Next I tried ripping the second CD 100 times and using the two correction maps to “fill in” uncorrectable error positions in the other disk. This was a failure: each disk had thousands of corrections that disagreed with corrections on the other disk! It turns out you can’t fix noisy data by intersecting it with a different-but-related noise source. I'm not sure I follow this portion. To me this suggests the "corrections" being accepted on a single disk are simply false positives.
It isn't the mini grep that they go over in the book is it?
Looking at the Cargo.toml, the only pcwalton fork that is being used atm is dwrote, pointing at [this open PR](https://github.com/servo/dwrote-rs/pull/9). The other repos have some unreleased changes on their master branch, probably some of them are required to get font-kit published on crates.io as well.
All good points!
I'd honestly like to hear the track. Was it all worth it?
Buying multiple copies of a discontinued cd and several disk readers all to get a quality rip for a \*single\* track? That's dedication. I hope it has been worth it. Anyway, great write-up. Interesting stuff.
You're not arguing in good faith. Cya.
Totally makes it worth it, right?!
There isn't enough work here for a full time employee. We estimated the work to take between 2-3 weeks part time at 20 hours a week.
Yes, but this is a part time gig that's pretty time flexible. We're estimating the work to take between 2-3 weeks part time at 20 hours a week. The big main task is task B, with task C dependent on whether we decide to launch a feature.
&gt; this suggests the "corrections" being accepted on each independent are either false positives I'm not sure about false positives, but there were positions where CD1 and CD2 give two different answers with high confidence. Trying to combine those only leads to conflicts.
The funny thing is, I didn't even want that particular track. I wanted all the _other_ tracks on that disk (piano arrangements), but track #3 was an experimental track on some sort of electronic organ.
I understand your concern, but this is meant to be a part time job with much less time commitment (~20hr/wk). It may be even faster as the payment is milestone based - it might take someone less than a week to build out the main features we need and get the $2000. Will make the unit tests more specific later today. 
quicli, of course! (No, that's not cheating, I swear)
I'm only familiar with `GtkTreeModel` from the gtk-rs documentation and from what I could dig up while searching for the solution above. Am I understanding correctly that implementing a custom `TreeModel` would allow for doing custom types other than `String`? I'm reading through all your work as well. If you have the understanding to sort of lead, I'll gladly work on it with you. From the vibe I get, we really just need gtk ported to Rust. I know libsvg is being actively worked on, but do you know if anyone is progressing the gtk libraries?
I love this kind of deep diving to declare victory on a problem like this. It validates the completionist in me.
I'm looking to get some PRs prepped and help out [awesome-rust](https://github.com/rust-unofficial/awesome-rust) with the list-rework.
impl Trait in argument position is (mostly) sugar for generics, so you can desugar it like this: pub fn cls_id&lt;O: AsRef&lt;ObjPool&gt;&gt;(self, op: O) -&gt; Option&lt;ObjId&gt; There is obviously nothing stopping you from taking &amp;O instead, but are you sure you can't already do that? I know that for AsRef&lt;Path&gt;, I can pass `path` as well as `&amp;path`.
You beat me to it. After reading the paper, I wanted to implement it too in Rust. Excellent work. I'll read over it later and see about reviewing. 
It looks like you should be calling it as a method: use futures::stream::Stream; let reader = reader.chain(eof); or something similar
`chain` is a method on the `Stream` trait, not a standalone function.
Aha, of course, you're right, thanks!
+1 if it is faster then stdlib one it worth to merge. But may be `format!` speed related to memory allocation and so on things, and this new algo speed wil be almost the same?
I did not think I would see touhou doujin music on the rust subreddit, but here we are.
What about benchmark against https://github.com/BurntSushi/ripgrep ?
I would recommend looking at cargo workspaces, and having separate packages for the back-end, front-end and shared code.
Heh, I prefer not to think about that! Hopefully the "low level core" can be a small-ish undertaking, and have well-defined standards so that others can contribute other parts. I've been working on it in various forms for a few months now. It all started to cohere recently. I think the biggest inspiration is React, and the desire to fix things that frustrate me about it :) Yew has been inspirational in that it shows that this is possible, although architecturally they don't have all that much in common.
btw just noticed https://crates.io/crates/built
If I were to be picky, I'd say that it seems redundant to call a file `minigrep_errors` if it's already in the minigrep namespace. I'd call it `minigrep::error` rather than `minigrep::minigrep_error` which is what you have now. If you want to be a bit more concise, the `PartialOrd` impl in `options.rs` can be automatically derived so that can be replaced with `[derive(Debug)]`. In `options.rs`: &gt; // Initializes a new Options. `fn new(...)` is Rust's version of a constructor. If you are writing idiomatic code like that, there is no need to state the obvious. Similarly names such as `get_file()` are self-explanatory so there is no need to comment them. Other than that, well done. Keep it up :)
&gt; there is no need to comment them Unless you have turned on warnings about missing docs. :)
I think its reasonable. If somebody has the skillset and can complete it in a reasonable time, they will take it. Any Rust work available is good imo. I know I'd work for less money to code Rust as my job, personally. I won't be acting on this one because my futures/tokio kungfu isn't quite up to par yet, but I would definitely be interested otherwise. Then again, I am in the US, so maybe my perspective is different compared to UK law.
Really well written! Informative and entertaining :)
&gt; so if you're asking if the thread-local storage will be consistent for a task across its lifetime, that's not necessarily the case. Yes, this is what I was asking. &gt; but certainly the real-world executors that I know of make attempts not to use TLS in a way that would cause conflicts if, say, an object in a task attempted to access TLS in its `Drop` impl. I don't think I understand what you mean here. How is it relevant whether the executor itself also uses TLS or not? It suffices for the executor to move a task between threads to break any use of TLS inside the task right? So if I were to have Tasks that do use TLS, I would only be able to use them with an executor that do not move them between threads.
Was not taken as sincere, but was responded to sincerely. *shrug*
It should be. As is usually the case, there's no need to micro-optimise here: if this is a case where that tiny performance difference matters, then benchmark it, otherwise, don't worry about it. Side note: You could just directly use `let (a, b) = new_computed_pair();`. Probably more concise.
Note from the README: &gt; This is written for the sake of learning Rust-lang. We don't need to benchmark everything. :-)
There are plenty of usages of TLS that don't require a task to be localized to a specific thread, such as caching or storage for reusable buffers. By the second part of my comment, I was referring to the fact that some executors such as tokio and fuchsia-async store a reference to themselves in thread local storage for ease of access. If your task references task-local storage in its destructor, this has the potential to cause out-of-order drops, so executors must be careful to destroy their tasks before TLS values start dropping.
I'm half way through rewriting an old Ruby ZFS snapshot management script. It'll be interesting to see how it turns out what with having a scripted version that does almost exactly the same thing to compare with. Parsing `zfs list` was an interesting exercise - not because it was hard, but because it was actually quite *easy*; by far the biggest difficulty I had was selecting an approach I liked out of the various options I tried. Currently I'm yak-shaving `xargs`-type stuff. Rust's Command interface really leaves a lot to be desired here - it has no conception of length limits and has minimal introspective capability (like, say, retrieving the current argument list), so I'm either going to end up calling out to xargs myself, or reimplementing half of the `Command` front-end just so I can count up how big the environment and argument lists are. Blergh.
Nice write up :)
This request gets posted regularly, which is what prompted Awesome Rust. I think it's very valuable to have this resource, and with you as its target audience, your feedback would be really helpful! For example, you mentioned "too much" and "isn't awesome". It'd be useful to really distill why you think that and to incorporate it into that project. What you're asking here will just repeat many crates that are already in that list, so you won't find too much more useful info here. And if you do, it should get added to Awesome Rust to keep that list relevant.
 ``` loop { let bytes_read = buffered.read(&amp;mut buffer)?; if bytes_read == 0 { break; } locked.write_all(&amp;buffer)?; } ``` Note that you'd need to handle the Interrupted error separately (and retry without returning an error) to be correct; this is what Read::read_all and io::copy do.
Would it be possible to do a rewrite of Ranger at this point or is Rust still changing too much atm? My fear is whatever crate/library(think those are interchangeable) I use will change so much that it will make my project a buggy nightmare. I really don't know what crates exist at the moment. So I might be getting worked up over nothing. Are my fears well founded?
&gt; I haven't tested that, though. On mac OS, the closest thing to splice (and its bigger brother, sendfile) is called copyfile. That's a bit misleading in the sense that macOS has `sendfile` itself *however* it's the original BSD sendfile (so can only target a streaming socket) not Linux's post-2.6.33 version (which also supports non-socket fds).
Ah, that explains the dedication.
It looks like there is a bunch of COM interop / winapi ffi calls going on for this and a lot of unsafes are used (which I'm guessing is necessary). Is there documentation / guidance on how to wrap COM apis safely? I'm considering attempting to do so for a work project but am unsure on where to get started.
Hi, learned rust with book in few weeks, so far it's really fantastic language, not really hard to use, Which is nice. I actually have a few questions: 1) Is there anywhere any up-to-date examples of making parallel(async) http requests. I tried to use hyper without any result - documentation didn't help much. So I did what was easy, used threads with reqwest - [https://gist.github.com/syntheticsh/ef4fa37d64ad71cd4a2264ab92e7a3ca](https://gist.github.com/syntheticsh/ef4fa37d64ad71cd4a2264ab92e7a3ca) here's the code snippet. I find it not particularly good solution for my task, cause making additional threads over some http requests seems like a bad idea. Is there maybe easier solution? Something like threads or goroutines in go - you feed it with function and channel and then just wait for result while doing something else like creating new coroutins? Or should I go deeper and read about Tokio, will it give answers to my questions? 2) Is there a need to define lifetimes? So far I never used them - I just use smart pointers and that's it. Is it just for embedded systems, where you can't use std? Is there a need to avoid smart pointers anywhere else? Should I worry? 3) Can someone give me some tips where I should look for the information: What I look for is basically to create some http-server that reads h265 encoded file or maybe even receiving it through socket from ffmpeg or smth, and stream it to client browser, where maybe wasm app transcodes it in h264 and feeds it to browser js-MSE. I'm looking for something like a proof of concept, which I probably won't even start this year. Where should I start? The hardest part as I see it will be transcoding, as I never done it before in any form.
I have a function that returns `Result&lt;Vec&lt;String&gt;, Box&lt;std::error::Error&gt;&gt;` . In my function body I have used a function call with '?' operator and it compiled successfully. Actually I was waiting something like I had to wrap it using `map_err()` . Does '?' operator automatically wraps the Error type into Box&lt;Error&gt;?
Have you checked if the [cuetools database](http://db.cuetools.net/) has your disc? Cuetools can use the additional error correction data from this database, to fix some read errors.
No: Ryu is licensed under Apache2, while Rust is dual-licensed MIT/Apache2.
Actually i've tried this nice crate [https://github.com/quadrupleslap/scrap](https://github.com/quadrupleslap/scrap) to capture screen. It works pretty well. But I don't know much about how video codecs work. 
it is not `Vec&lt;&amp;i32&gt;` it is `&amp;Vec&lt;i32&gt;` you are holding a **reference** that is a vector(for C# List) of i32s. But if I am not mistaken it does auto dereferencing on v. If I am not mistaken the 'v' in the for loop is equivalent to `(*v).iter()` . Where you first dereference the v and call iter() function which return an iterator to that vector.
ಠ_ಠ 1) That budget is fairly ridiculously low. Look, you keep insisting its a part time role, with milestone based pay. I bet this is really a hedge to avoid having to conform to labor laws. You've created an incentive to put as much time in as possible, while saying its just part time work. 2) This offends the part of me that loves the Rust's community's commitment to doing things *right*. You're creating an incentive to cut corners and take the shortest path possible, with no incentive for consistent, correct, high quality output. 3) This is very poorly defined. As noted by others, task D is very nebulous. But so is task C. You give no scale indications of how big the REST api needs to be, or what kind of performance characteristics you require. Someone can write a fast, stable REST api, but it won't be done quickly. Or it can be done quickly, but it won't scale well. Bite the bullet and hire an actual pair of developers to work on this. This is more work than pay, the incentives are all distorted, and it seems likely you're trying to skirt labor laws. This speaks to a seriously toxic place to work at. I advise everyone else to avoid this place like its Chernobyl. 
This one seems to be working: [https://github.com/magiclen/FFmpeg-Screen-Recorder](https://github.com/magiclen/FFmpeg-Screen-Recorder) 
It's more complicated than it seems. WebRender can do it, but it might be overkill for your needs.
[removed]
Yeah, one of the takeaways from this project is that we need some kind of safe bindings generator for COM, like the one good old VB6 had.
[Not really, it seems.](https://github.com/BurntSushi/quickcheck/blob/master/src/arbitrary.rs#L802)
`valid_up_to` looks like exactly the thing I'd need, though it looks like it will be fairly inefficient. You'd end up needing to traverse a byte buffer twice: once to find out the valid length, and once to decode the valid part. I'll try to play around with this and see if I come up with something based on this.
Yes, I can do it, the problem is that impl Trait will also compile for a &amp;mut Trait as an argument and will move a mutable reference. It leads to "value moved" compile error which is kind of misleading in this case.
PowerShell is pretty great; I use it every day.
As I know, you are right, Rust does dereference for you and it will copy the `el` here because i32 implements Copy trait. There is such a thing in Rust as auto dereferencing.
Yes, it could. The `?` operator generates code like: if res.is_err() { return res.unwrap_err().into(); } And there is a From implementation for a Box in standard library: impl&lt;T&gt; From&lt;T&gt; for Box&lt;T&gt; So it could wrap any value into a Box in this case.
There's no magic done by the compiler in this case - this behaviour happens just because there are both `impl AddAssign&lt;i32&gt; for i32` and `impl AddAssign&lt;&amp;'a i32&gt; for i32`. Therefore both `sum += el;` and `sum += *el;` work in this case.
You're the kind of person that makes private trackers weep tears of joy. Nice work! Good write-up!
Thanks so much 🙏🏻
lol, you complain about character assassination in the same breath that you declare people who aren’t good at c++ as incompents. 
This is amazing! Such a great idea. The only problem I can think of is if you somehow want to log and serialize different fields on the same struct (think avoiding logging PII while also sending it to a frontend or different service), but for structs that will never be serialized but are in a project that has a serde dependency, this is great!
Wouldn't aggressive unreachable code elimination trim down the size of the binaries significantly, or do you have other concerns?
I can agree with network usage, of course, however when talking about a distribution, wouldn't all binaries be re-compiled and thus updated in case of vulnerability anyway?
Indeed, but that's a generic problem - e.g. you might use some logger and also provide JSON API and want to use serde with both, but in different ways. This should be somehow solved on a serde level. Otherwise, I found that more often than not I actually want debug output to use same customisations that I have in JSON, in that case it's still useful even for types that you do already serialise. 
Dude you just said “venture backed” and a whole mess of other stuff. I would get it if you said “I’m starting a small project, tight on budget now, so I can only afford a small number of hours till we get funding”. Which one is it? There’s a reason why you raised money, that’s to get help to reduce the work on you as the founder. Then again I’ve never raised money, so I don’t know 🤷‍♂️.
I am afraid you have very seriously underestimated the budget. Rust developers are generally self-learning/motivated programmers at this stage of the language's lifecycle. This in turn means that in the US I would expect them to earn above $100K per year (aka, 6 digits salary). A consultant is both employer and employee, and therefore submitted to both taxes; my rule of thumb here is that an employee's gross salary is about 40% of what they cost to their employer, which is in line with the recommendation that consultants should ask for 2x/3x what they would earn as an employee. From then on, simple maths give us the daily cost to the employer/average consultant rate as: `$100K / 240 * (1 / 0.4) ~= $1,000`. Budget: - 2 days, full time, $2,000: very doubtful that all 4 tasks can be completed in such a short time, - 3 weeks, half time, $8,000. You are 4x too cheap for your own time estimate. And a consultant will want to provide an estimate of their own, *after* discussing the requirements (and will charge for the discussion time; it's work too). 
Your article doesn't mention, anywhere, that the `compare.rs` file happens to be a Rust program. You should probably mention that, so that your readers can try to run it.
`splice` is a pretty interesting syscall, I'm always surprised it isn't used more.
Looks like a translation for `Normal` gone wrong.
Do it the Busybox way.
Neat! I've been thinking of filing an RFC about adding some attributes to customize `derive(Debug)`, sort of like this does...
Man, that URL... It's beautiful and disgusting at the same time.
You're totally right on the fact that micro-optimization is often counter-productive, specifically if not benchmarked! I guess I was mostly curious, and wondering if the answer would be "no" or "it's possible, you should verify". I can't do `let (a, b) = new_computed_pair()` though. The computation of the new value happens as some part of an iterative, non-convex optimization algorithm. So inside the loop, I'm updating the mutable values to reuse later. It looks more like: ```rust let (mut a, mut b) = some_initial_pair(); loop while condition is true { // do some with &amp;a and &amp;b, then: let (new_a, new_b) = some_new_computed_pair(); a = new_a; b = new_b; } // do something with a and b ```
Interesting, u/dtolnay also ported Ryu to Rust [and compared it to dtoa](https://github.com/rust-lang/rust/issues/52811). In his port, he noted that Ryu performed appreciably worse than dtoa on numbers with *few* digits: &gt; Input f64 dtoa Ryū &gt; 0.1234 47 ns 66 ns &gt; 2.718281828459045 64 ns 40 ns &gt; 1.7976931348623157e308 73 ns 42 ns Does this port also suffer from such issues on numbers such as... `0.1`?
What a beautiful story of devotion! Imagine someone going to this much trouble over your work, it's quite impressive. I used to worry about this kind of thing, using cdparanoia and so forth on Linux to manage my music. When I went Apple I eventually went iTunes, which is a mixed blessing. I feel like it has made me able to appreciate more music more easily by lowering the cost barrier, but it has reduced the amount I appreciate an album substantially. And it's hugely inconvenient when they disable my account for strange reasons or my internet connection vanishes. So I may return to manual management someday.
 unless File.exists?(arg) puts "#{arg}: No such file or directory" This creates a [TOCTOU](https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use) race. Just put an exception handler in the loop. This goes for Rust too - don't check if a file exists before you open it, just try to open it and handle the failure case. IO.foreach(arg){|line| puts line } This will append an additional newline if the input doesn't include one at the end. Line-buffering is also undesirable behaviour for a cat clone. This is both *much* faster, more correct, and is less to write: IO.copy_stream(arg, STDOUT) 
I thought it was about food (pfannkuchen).
Release notes can be found [here](https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1280-2018-08-02)
I partly used rust on android. Java hanlde input and start my code, while the main window drawing and core logic is done on Rust language. The code is closed, but I used this template for start https://github.com/Dushistov/rust_swig/tree/master/android-example
The truth is in the eye of the domain name owner.
Yes this port has the same behavior. Ryu takes longer to format numbers with fewer digits. Right now this port is substantially slower than my unsafe port -- [see benchmark](https://github.com/m-ou-se/ryu-rust/issues/1#issuecomment-409279110). It will be interesting to see whether that gap can be closed without introducing unsafe code.
I honestly didn’t think this was possible. 
&gt; Ryu takes longer to format numbers with fewer digits. Do you have real-life examples of json/csv files which could help assess whether typical usage results in numbers with few or many digits? I tried looking at some of the jsons we have at work and it was a mixed bag: configuration inputs are typically short, but computed values are typically long. So, depending on whether you are encoding the input or output, you have different characteristics, and would prefer either `dtoa` or Ryu, with no overall winner.
I think the standard answer to this question is that async/await syntax will make futures much easier to work with. If that's something you were already aware of, you might need to expand your question with a specific point of comparison or something like that, to get into more detail.
&gt; You'd end up needing to traverse a byte buffer twice: once to find out the valid length, and once to decode the valid part Hence "unsafely if you want to avoid parsing it again" - [`from_utf8_unchecked`](https://doc.rust-lang.org/std/str/fn.from_utf8_unchecked.html) just [blesses the bytes as a string](https://doc.rust-lang.org/src/core/str/mod.rs.html#443-445) without doing any more parsing. Strings in Rust are just newtyped byte slices, so it can do that quite quickly. 
Thanks! I simplified the Ruby code a bit based on your input. Can you check again? :)
Indeed, with `valid_up_to` and `error_len` it is possible to implement streaming/incremental UTF-8 decoding on top of `std::from_utf8`. In fact the documentation gives an example of this: https://doc.rust-lang.org/std/str/struct.Utf8Error.html#examples It doesn’t have to be traverse twice. One key point is that Rust’s `&amp;str` type is represented as UTF-8, so once you know that a bytes slice is valid UTF-8 you can call the unsafe function `str::from_utf8_unchecked` which is basically free. We don’t even need to copy the data. Unfortunately even with the example in docs this is not very discoverable, and slightly tricky to get right. It might be nice to add something else to the standard library, but the API design space is rather large depending on constraints: * Using slices of borrowed input to avoid copies as much as possible * Support streaming/chunking with not all of the input available all at once, but also correctly re-assembly a single code point whose bytes happen to be in multiple input chunks * Lossy v.s. strict decoding (invalid byte sequences being replaced with U+FFFD or causing the decoder to abort) * "Pull" data flow (for example from an iterator adaptor that itself pulls from an underlying iterator) v.s. "push" (calling method with the next input chunk, and a callback for decoded data) v.s. leaving data flow to the user as much as possible Baking in some assumptions allows an API to be simpler and easier to use, but of course at a loss of flexibility. On the contrary maximal flexibility produces an API that can be a bit cumbursome, and maybe too awkward to belong in the standard library. My experiments are at https://docs.rs/utf-8/0.7.4/utf8/. `decode()` is the maximal-flexibility API. After reading your blog post I added `BufReadDecoder` which would work with `stdin().lock()` (and should be efficient). I’d tried previously to do that, but not managed to make it borrow-check before.
And very nice project !
You could use \`io::copy(&amp;mut buffered, &amp;mut locked)?;\` in rust for parity ;)
This is great! I often implement Debug manually, to remove new type wrappers and such, anything to help that is much appreciated. I actually think formats like xml or json are great debugging formats for very large structures, because there exists tools for exploring them. In that case, all you have to do is derive Serialize and the consumer can choose how to, well, serialize the data for debugging. In that way Serialize is kind of like Debug on steroids! :)
Servo has an android build, but both Servo itself and its build is quite complicated so it might not be any good in terms of an example. Also not sure how much of Android it actually uses, besides OpenGL. https://github.com/servo/servo/wiki/Building-for-Android
It's Linux specific.
&gt; Cargo will now no longer allow you to publish crates with build scripts that modify the src directory. The src directory in a crate should be considered to be immutable. I've been using a trick where I write into the `src` directory and then _publish those files_ so that users don't have to have the (large) data files and pay the (notable) time cost of generating them. These files are still considered generated and are as such not checked into source control. The current publish process runs a custom clean to get rid of them and then generating them with a custom script, then doing `cargo publish`. I've been thinking about integrating this into a `build.rs` so building from source just requires `cargo build` again. Can I still follow this pattern now (the build step won't write if it sees the files already there) or is this an unsupported workflow now? I can always just not use `build.rs` for this but it'd be nice to be able to drop the custom build step requirement and automate it.
You would've been a valued member of What.cd
(side note: this crate is actually not published as it's still in the highly volatile experimentation phase.)
The time to launch an application is critical for system shells and core utilities. The larger the binary, the longer it takes for the application to start, and when spawning a lot of shells &amp; external commands in quick succession, you suddenly end up with an unresponsive system. In addition to consuming greater and greater amounts of memory as more instances of a shell are existing simultaneously. Take the Ion shell and Redox OS, for instance. Suppose we use it as Dash is commonly used on Linux distributions. An OS may have contain many hundreds to thousands of scripts, and some of these scripts may be performing nested script executions of their own, which altogether may execute thousands of external commands and nested shell instances. I can understand not worrying too much about binary sizes for most software, but this is one use case where the binary size matters. 
Thanks for the hint. Ended up skipping this part in the article as it was confusing and didn't really add anything to the narrative. Instead, I improved the Ruby code a bit to go straight to native speed and then show the Rust code to surpass that. ;-) Old, unoptimized Rust code is here for future reference: https://github.com/mre/mre.github.io/blob/880d2f2b5e38e3b813eb7c3a5e1bdc057d950793/blog/2018-fastcat.md#making-our-cat-a-little-faster
True. Ended up removing this section as it became confusing when switching between multiple languages all the time. So I stick with Ruby until I reach native speed and then go to Rust and show how to get faster than that. Old, unoptimized Rust code is here for future reference: https://github.com/mre/mre.github.io/blob/880d2f2b5e38e3b813eb7c3a5e1bdc057d950793/blog/2018-fastcat.md#making-our-cat-a-little-faster
Thanks, fixed. Added your clarification to the article and gave you some credits in the footnotes.
Thank you for the explanation. I rarely (if ever) use bash scripts, usually reaching to Python, so I've never had to deal with such a performance issue.
The first thing thing I thought was it’d replace Alacritty’s font handling code
Doesn't mean that it couldn't be used on Linux while providing a fallback on other OSes.
Thanks for your explaination - I appreciate it. This is my first time outsourcing any work so the breakdown is very helpful. We'll be doubling our pay and cutting tasks. 
I tried this a while back in C. It benchmarks well, but in real world use cases it varies from a small improvement to a large pessimization. With GNU grep, splicing is about 0.3% faster: &gt; time cat /dev/shm/stuff | grep beeswax real 0m5.263s user 0m3.865s sys 0m4.764s &gt; time ./target/release/fcat /dev/shm/stuff | grep beeswax real 0m5.247s user 0m3.882s sys 0m3.020s If the receiving process doesn't use a large enough input buffer, all those syscalls are going to hurt: &gt; dd if=/dev/urandom of=/dev/shm/stuff bs=1G count=8 iflag=fullblock 2&gt;/dev/null &gt; time cat /dev/shm/stuff | md5sum aca5ccc6f2cc6df0d315d26ddd85f163 - real 0m16.603s user 0m15.336s sys 0m4.626s &gt; time ./target/release/fcat /dev/shm/stuff | md5sum aca5ccc6f2cc6df0d315d26ddd85f163 - real 0m17.144s user 0m15.740s sys 0m3.044s
We have raised money, but a small amount mainly from an accelerator. We're pretty tight on money when you factor in high rent costs and living expenses. The rest goes into scaling our marketing and distribution as that's one of the hardest parts of edtech B2B. 
Anyone have a place I can listen to the music? Can't find it on youtube or anything.
How are you supposed to see the new error format? `--error-format` doen't exist.
It could but then again… why? If the general-purpose version is fine for other OSes it's generally sufficient for everyone, and it avoids divergences and compatibility issues between systems.
&gt;These files are still considered generated and are as such not checked into source control. The current publish process runs a custom clean to get rid of them and then generating them with a custom script, then doing cargo publish. I am not quite sure I understand you correctly, but if you manually write the code-generation step before cargo-publish, you should be fine. &gt;These files are still considered generated and are as such not checked into source control. The current publish process runs a custom clean to get rid of them and then generating them with a custom script, then doing cargo publish. I think that would work, if build.rs does not overwrite the files needlessly and if you run `cargo build` before cargo publish. Note integrating such code-gen into `build.rs` will require your consumers to needlessly compile it and its dependencies. There's no build-in solution to this style of code generation in Cargo. I personally just commit the generated files to gtihub and have a special test that checks that generated files are up-to-date. 
Looks good. As a style nit, ideally you'd use one of: args.each { |arg| IO.copy_stream(arg, STDOUT) } or: args.each do |arg| IO.copy_stream(arg, STDOUT) end Also your examples have inconsistent indentation.
Hm... sounds more like the other tools are the bootleneck in this case? Would be curious to compare grep with ripgrep and md5sum with a faster hashing tool. In the end, we have to make all our tools faster, because the weakest link in the chain defines performance.
There are ways to work around the added check. It doesn't use a sandbox thus by rice's theorem it's imposible to make a check that can't be worked around. Here, a workaround is easy: you can for example turn off verification during publishing, or you can store the stuff outside of the src directory. But I don't think that this is a good idea anyway. I hold the opinion that `crates.io` should be like source control: only containing source code. IMO generated stuff like wasm files or trained models or compiled windows libraries shouldn't be present. I feel that this pattern of uploading generated stuff is one of the utterly wrong descisions of npm and am glad that it hasn't arrived this much in crates.io yet. The Debian approach is much better: having two repositories, one for generated stuff, a second for source code. If there is need to upload generated stuff, it should be entirely separate from the source code of the crates. `&lt;/rant&gt;`.
This is come up before, I haven't looked too deep into it, but the Wire messaging app is open source and their main messaging library is written in Rust. As I understand it the iPhone and Android apps have the interface written in the platform common language (ie Java on Android) and it calls into their Rust library for the messaging and crypto. Could be worth looking into as an example if that's the route you want to go. If you are looking to code the whole thing in Rust, I wouldn't have a clue. 
A general behaviour is when you call a member function it usually auto dereferences. Because while `*v` is not a big deal to write while `v.iter()` is way better than `(*v).iter()` . I think in this case since for loop calls `iter()` function it also auto dereferences.
The 1.27.2 release notes are not there, even though the link from the 1.27.2 blog post points there.
In this case I'm generating code. The big case I'm thinking about the generate step downloads large data files and then reformats then into a format that can be `include!`ed as a large static array. The difference is multiple MB per data file from cutting out useless extra information. I see no reason to redo that work for every consumer of the library. And another potential use case of writing to `src` (ab)uses it to bootstrap without going through the entire history, but that'd never be part of `build.rs` and would have to be a separate step anyway.
I suggest you read [The Book](https://doc.rust-lang.org/book) and join r/learnrust. From there, you should get your hands dirty with some toy projects and popular Rust crates (libraries). # From there, the sky is the limit.
This can be fixed easily if the author agrees.
[clap](https://clap.rs): Slice &amp; dice your mucky arguments!
But the `md5sum` tool is the same in both cases, they are just comparing `cat` with `fcat` in the pipeline with a different sink.
Yup, thanks. Should be fine now. ;-)
I’m not a Rust expert so don’t take my words too seriously. Rust is quite complex language, there are a lot of everything. It can be very hard to learn it as a first language. Maybe start with C, feel and understand the pain that rust resolves. If rust and nothing else, then I think Rust book is awesome. But the 100% success is this https://github.com/ossu/computer-science plus rust book. This is the long way for sure
He's right though--a sink with larger buffers favors `fcat`, and larger buffers are often a throughput win even with regular `cat`. The catch is a few % time isn't always worth a few MB space.
&gt; If the receiving process doesn't use a large enough input buffer, all those syscalls are going to hurt. Maybe we should try again with a tool that uses a larger input buffer. ;-) Also it looks like in the other example, grep is the bottleneck and maybe ripgrep performs better, all other things being equal.
I have written a very simple webserver. It is only meant to be a toy nothing serious. [https://github.com/bootandy/ports/blob/master/src/main.rs](https://github.com/bootandy/ports/blob/master/src/main.rs) If anyone has any suggestions about how to improve it or what I should add to it next that would be welcome. (eg: Figure out and incorporate Futures) 
Sorry, my reply was a bit harsh. I find awesome rust just too long. I feel it seems to list almost every library, so doesn't really save me much work. Also, a couple of libraries I tried seemed to be quite out of date, bit now I can't find them. Maybe the list has been tidied up recently?
Another use case of interest is for protocol and serialization generation (such as ProtoBuf). Anything that uses a DSL that's converted into Rust, essentially. I'm interested in knowing the best practices there. I'd love something that plays well with RLS/Racer too (since include! does not).
Well then don't spam my reddit start page with 'hello world's
Yes.
It's not worth the struggle
This was 1 google search away: https://docs.rs/ketos/0.10.0/ketos/
Should I delete it😿
[`log`](https://crates.io/crates/log) and [`slog`](https://crates.io/crates/slog): Logging. Get used to it early on. Saves time in long run. [`actix`](https://crates.io/crates/actix): Use actors to build complicated threaded things. Much easier then using locks everywhere. [`serde`](https://crates.io/crates/serde): Anything serialization and deserialization. Specially if you making a public crate even if you don't need it. [`app_dirs`](https://crates.io/crates/app_dirs) ([or](https://crates.io/crates/dirs) [any](https://crates.io/crates/directories) [similar](https://crates.io/crates/app_dirs2)) : To place files into proper places. [`chrono`](https://crates.io/crates/chrono) : To do anything with time. [`nom`](https://crates.io/crates/nom) : To parse anything. I even use it to parse the output of `zfs` CLI. [`structopt`](https://crates.io/crates/structopt) : Sugar coating for [`clap.rs`](https://crates.io/crates/clap) 
then you're not venture backed? VC firms usually are titles designated to larger checks either a really large seed or "series A". Meh this isn't worth it. best of luck !
For Rust: the online book is a great resource to learn Rust even with a programmer background (you can move quickly), then stdx and awesome-rust are great resources to point at high-quality crates recognized by the community. For parsing: `nom` for manual parser combinator control, `pest` for a generated PEG, or `lalrpop` for a generated LR parser. Other than that, it's a matter of knowing how compiler/interpreters work, and it's no different in Rust than it would be in any other language.
Hi, How do you expect to manage the physical units in the drone controller. Will you consider specific physics dimension analysis (to manage unit conversion and avoid addition of unrelated units?
I think the thing to note is that replacing `cat` with `fcat` may be a pessimization in this type of case. So it's not a "drop-in always makes things faster" replacement, and it would be nice if it was ;)
That's my point, if 2 CDs of the same content are giving confident answers and these answers differ then at least 1 of the answers must be a false positive regardless of how confident it was.
Thankfully, it isn't as much of an issue as it used to be in the days when system services were all started &amp; managed via `init.d` scripts. Hence people reporting that boot times were significantly faster with systemd when it first came out.
The ignite std extension! 
Because some people may desire that extra performance on Linux and the code overhead for a simple utility is maybe dozens of lines.
Uh, woops! Thanks for pointing this out! [Sent a PR](https://github.com/rust-lang/rust/pull/52918) to add the notes to nightly/master and 1.29-beta (they won't be on 1.28.0 though, it's not worth doing a rebuild just for this).
On a (kinda) related note. std [uses copy_file_range](https://github.com/rust-lang/rust/blob/764232cb2a8407c72b9fea68835e686240e30ef3/src/libstd/sys/unix/fs.rs#L900) to copy one file to another, which [uses splice_internally](https://github.com/torvalds/linux/blob/b08fc5277aaa1d8ea15470d38bf36f19dfb0e125/fs/read_write.c#L1607)
Maybe look into the LMAX disruptor: https://lmax-exchange.github.io/disruptor/
Thank you so much for replying. I will try using the template. One question, Was the UI created using rust or the sdk? I would assume sdk in that case.
Thank you, I read that as well. I guess I will have to figure out calling the rust library.
Thanks, I didn't know servo has an android build already. As you said, for a learner it's kinda hard to use it as an example, but I will look into it.
I liked [Programming Rust](http://shop.oreilly.com/product/0636920040385.do), but [the official book](https://doc.rust-lang.org/book/second-edition/ch00-00-introduction.html) is good as well. However I don't think either is geared for people new to programming. You can try that route, but if you find yourself overwhelmed I'd first switch to learning Java and then go back to Rust for the following reasons: * Both Java and Rust have static typing. Some languages that people recommend as first languages like Python or JavaScript are dynamically typed and you would miss on getting yourself familiarised with static typing if you started with those. Also, from watching people start with dynamically typed languages, because types are not explicit things sometimes look more magicky and confusing. * Java is still reasonably simple language. * It has features that translate well to concepts in Rust like generics (unlike some other simpler languages, and you can start using them gradually because Java keeps compatibility with previous versions that didn't have them) and interfaces. * Java is a great general purpose language on its own. 
Even faster if you use all 64k of the pipe buffer instead of just 16k! It seems like splice is implemented to prevent deadlock if you write a bytecount larger than PIPE\_BUF, but you probably want to use SPLICE\_F\_NONBLOCK in the first call anyways. The documentation also doesn't guarantee that splice writes as much as possible when it blocks so you should loop around writing to stdout or you could chop bytes off the end of the file.
Llvm has a tutorial on how to implement a language. It's in C but it should be trivial implement all of that in rust (or at least it's a good exercise). I haven't dived deep into it so I don't know how far they go with the implemented language. I really should take another look at this... 
To expand on that, if you don't have any experience, I would say start with Python, as it is really easy to use and understand. Then drop down to C to see what python hides from you, then rust 
I'm writing a bunch of functions that take hashes as arguments, where a hash is `[u8; 32]`. Would it be more idiomatic to take them by value or by reference? Is there some size threshold where folks usually switch from one to the other for `Copy` types?
Happy to cleared the misconception. :) 
Completely agree. The only reason I brought it up is so that others can be aware of that (very reasonable) limitation going in. I believe that serde works best when using it at the edges of your application, and immediately converting from it to a new, more usable, internal representation (a [lowering step](https://stackoverflow.com/questions/20252876/wanted-good-definition-of-the-term-lowering-in-the-context-of-compilers), in compiler-speak). If you stick to that pattern, then `serdebug` would be fully usable, as you wouldn't encounter any conflicts.
&gt; Was the UI created using rust or the sdk? Both. There are one main screen it was rendered with Rust code, all other screen preferences and so on screen was created with help of Java, but Java part was view in model/view paradigma. Model was implemented on rust. And rust_swig takes care about java&lt;-&gt;rust cooperation.
There is a Rust alternative to cat called bat that you may find interesting.
`cargo rustc -- --error-format=short`
There are parts of that code that are a bit slower than they need to be; `decimal_length` for instance can be replaced with bit magic. That said, you *really* don't want to benchmark with constant values when your code runs in the time of only 6 branch misses; you'll hide what could well be most of the cost.
I generally use references if it's not a primitive (int, bool, etc) and I don't need a copy for ownership reasons.
I know I've seen a crate that does that, but I hadn't really considered using it for this until you mentioned it. Do you have any specific suggestions? 
Maybe I'm just grumpy but do we really need to create an acronym for rarely brought up things just because they are more than 2 words long?
Turned it into a temporary subreddit logo, hope you don't mind! :)
Try splitting your publishing process into two parts: a pregeneration step that generates the source files that you run before \`cargo publish\`, and then the \`cargo publish\` step where \`build.rs\` assumes that the pregenerated files are there. This is what (*ring*)[https://github.com/briansmith/ring] does.
I've found it's a bad idea for build.rs to do network I/O. I prefer top have a separate step (separate from `cargo build`) that does any downloading necessary, and then have `build.rs` verify that the right stuff (e.g. latest version) was downloaded beforehand. In particular, if people are doing Docker builds where building your crate is part of the build, they usually would prefer to have the networking done in a separate step which would translate into a separately-cached layer in Docker, making the Dockerfile much more efficient.
It's what I've been doing and what I guess I'm going to keep doing. I've just been wondering if I can consolidate the steps for people trying to build from source using `build.rs` and it seems the official answer is always going to be `src` should not be changed by `build.rs`.
In *ring* the build works differently if you're building from a Git checkout than if you're not (if there's no `.git/` we assume we're building from a crates.io-distributed crate). This way development is convenient and builds from official releases from crates.io are convenient. I don't know if that strategy would help you.
Thanks! Has anyone written a comparison of the error libs?
Then don't look into the full article... 
It's very subjective. At the point I've started I tried to make my own, then found `quick_error` that was doing everything I wanted. I picked `quick_error` because I disliked `error_chain` a lot. Then `failure` become a thing, but it was in an early preview state, so I stuck with `quick_error`. And right now it does a lot of things `quick_error` do, but better (at least my eyes are telling me so) If I started today — I'd work with `failure`, but if I start switching to this library I will spend yet another week yak shaving instead if doing something productive with it. They all support Error trait, so your errors can work with other errors and vice-versa. 
Starting with C is a lot harder than starting with Rust. And sure to end up in frustration with how difficult it is to accomplish anything without prior knowledge of data structures and algorithms.
&gt; I'm interested in knowing the best practices there. I'd love something that plays well with RLS/Racer too (since include! does not). In the case of `prost`, the happy path is to check your source `.proto` files into version control, then use a build script (`build.rs`) to generate Rust sources 'on the fly' at build time. From what I recall, other Protobuf libraries encourage different patterns.
Hmm, I need to try this! I've been having issue a while back with Racer and `include!`, that was with Cap'n'proto tho. This is the Racer issue I found at the time: https://github.com/racer-rust/racer/issues/191
What kind of forms?
Well now I’m doubting myself. I use racer but perhaps completions on generated types do not work. Not at my computer currently so I’m not able to check.
Sounds good! 
Check out cargo-apk if you want to investigate pure Rust app development, also instructions describing how to integrate e.g. a C/C++ library into an Android JVM app via JNI will apply the same to Rust if you make the necessary FFI interface.
Doh, I missed that, thanks :)
Thanks for explaining, I'd missed `error_len` as well in reading the docs, I see how that can be helpful. Your comment on `next_strict` also seems to explain why I was fighting with lifetimes a bit in my `Iterator` implementation: &gt; This is similar to Iterator::next, except that decoded chunks borrow the decoder (~iterator) so they need to be handled or copied before the next chunk can start decoding.
I don't entirely understand your issue.. why is there a need to differentiate between column and row data? Why not store data as it is done in kdb+ with efficient unboxed vectors for homogeneous lists and less efficient boxed vectors for heterogeneous lists? See here for a rust implementation: https://github.com/adwhit/krust/blob/master/src/kbindings.rs
Well, security people do tend to use a lot of acronyms: * CVE * RCE * XSS * TOCTOU ...etc. 
[removed]
I think SFINAE is justified. RAII is a stretch because it describes only half of the paradigm and is just confusing. Also not really an acronym AFAIK since no one I know say it anything other than R. A. I. I.
I love libpnet BTW
Thanks, though it's been years since I contributed. /u/mrmonday deserves your compliments. 
Have you broken the problem down? With which part do you struggle?
And [combine](https://github.com/Marwes/combine). Awesome parser combinator library with better errors at compile and runtime than nom. Less used, but I have found it to be pretty amazing.
Right, this is not possible with the `Iterator` trait. Gankro’s talk http://cglab.ca/~abeinges/talks/iter/ calls this a streaming iterator. You can also see that it calls `BufRead::fill_buf` in the loop to decide what to do, and then again outside the loop to return a borrow. I *think* that returning a borrow directly from the loop is sound, but today’s borrow-checker doesn’t support it. And even the first version of non-lexical lifetimes might not either: https://github.com/rust-lang/rust/issues/51526
Not for a beginner. Most, if not all, educational Rust material assumes prior programming experience, with quite a few assuming knowledge of at least some knowledge on functional programming. However there's a lot of books and tutorials for learning C as a beginning programmer. Not that all of those books and tutorials are \*great\* (I can't count how many "Learn C in X days" books there are), but they do get your foot in the door.
Meh. I'd say C is difficult but not complicated. Python is more complicated than C. It's good to learn about memory and bytes and syscalls. Mistakes will break your code, but it's not like a first time dev is going to be making any applications just yet. There's time to play around with how the computer works.
Nice article. I suggest to you mention \`ripgrep\` in it where you use \`grep\`.
Thats not at all what I said... but okay
I have found [dimensioned](https://github.com/paholg/dimensioned) and [uom]{https://github.com/iliekturtles/uom} but I am not satisfied with both, in particular on ergonomics. Uom looks more simpler but I cannot run the examples; specifically the conversion_unit_.get::&lt;other unit&gt;() do not compile. I also wonder if these introduce overhead in the code. Finally I wonder if those libraries are worth since it makes code heavyweight.
I have found [dimensioned](https://github.com/paholg/dimensioned) and [uom]{https://github.com/iliekturtles/uom} but I am not satisfied with both, in particular on ergonomics. Uom looks more simpler but I cannot run the examples; specifically the conversion_unit_.get::&lt;other unit&gt;() do not compile. I also wonder if these introduce overhead in the code. Finally I wonder if those libraries are worth since it makes code heavyweight.
NOTE: Remember the rule: No zealotry! The author mentions getting some comments from ‘Rust evangelism strikeforce’. I'm sure that every well-informed dweller here knows how negative effect that can have and I want to believe that the comments are not from the people from this subreddit; let's keep it that way. That aside, I think that the author misses an important case in their "Venn diagram": people that write in normally in higher level languages and haven't touched C precisely because they think they wouldn't be able to pull that off safely. Rust enables low-level code for those people. Secondly, I think that a "sufficiently competent C programmer" is a kind of an myth – people make mistakes and that's their nature. I, however agree that modern C++ is a significant step up from eariler times. 
Hi, First thanks for your work. I cannot run the standard example in si.rs. Particularly, the pattern `l1.get::&lt;meter&gt;()` do not compile on rust 1.27.2. Did I missed something? 
That's interesting! I've never heard of using a single ring buffer for multiple queues. Also the cache line optimization is interesting.
The article basically asserts that you can write safe C (and C++), and you can't write Rust with fun. Both assertions are false. In fact, it can't be any more false.
The author already set up language criterias but pretty much ignored most of them until C++ and then added criterias randomly like target audience and fun factor. A recommendation can be biased (it is most of the time) but shouldn't be this poorly structured. I mean where is the expressiveness part, or general usefullness.
Instructions unclear, ended up on 4chan.
Oh nice! Could you paste your code here or, even better, send me a pull request at https://github.com/mre/fcat? Would love to test it and update the article accordingly. 
Yeah, maybe we could send them a PR to use splice on Linux.
“If people are disciplined enough, they’re already writing perfectly safe C, therefore the footguns in the language aren’t a fixable problem”
What about the channels in the `std` library? A deprecation with a message to use crossbeam-channel instead would certainly help new Rust users.
I have restarted my [Chorus Studio](https://github.com/Lisoph/chorus_studio) project (open source, collaborative digital audio workstation). I had spent a lot of time writing a GUI layouting system which I'm now going to throw away due to some major architectural problems and due to the fact that it's kinda overkill anyway. What will be interesting is how I'm gonna do the networking (server2client topology). Currently I'm just using nonblocking `std::io::TcpStream`s on the server and client codebase. It's working well enough for now, I'll see how far it get's me. At some point I'll probably have to switch to tokio for the server, which scares me because I have never done anything with tokio before and it looks complicated.
\&gt; Then you can include!the generated files into [lib.rs](https://lib.rs) or wherever. Unfortunately that doesn't work because of [https://github.com/rust-lang/rust/issues/18810](https://github.com/rust-lang/rust/issues/18810)
It's good to see a modern implementation of something so widely used. That said, what are you doing to address the [many issues](https://blog.cryptographyengineering.com/2014/08/13/whats-matter-with-pgp/) with OpenPGP? What are the defaults for encryption and authentication? Are outdated ciphers supported? 
Good luck with detecting COM files
I am doing a scraping project currently and I have a string that contains some turkish characters. The problem is when I try to print them turkish characters print as '?' character. I thought since rust &amp;str and String is unicode I wouldn't face any problems. If it helps the html page charset is iso-8859-9. How can I get these characters correctly? My console shows these characters correctly when I write them from my keyboard.
Let's go through Matt's major points: - Key Exchange / Key Management This isn't really a problem with the OpenPGP protocol or an OpenPGP implementation. This is inherent to any system that tries to protect you from active adversaries. If you are willing to use centralization, then you can do something like X509 (what is what TLS uses), but there are many, many cases of CAs issuing bad certificates either by accident or maliciously, e.g., the TURKTRUST incident. You can also do something like Signal with its verified key servers. But, if you want to be decentralized, then somehow you have to get the user involved. So, in my opinion, this is more a criticism of decentralization than of OpenPGP. Now, that doesn't mean that OpenPGP tooling can't help. In fact, about 4 years ago, several initiatives began working on mechanisms to make key discovery much easier, and mostly transparent for users primarily concerned about privacy (as opposed to those whose threat model includes active adversaries, like activists, lawyers, or journalists). See, in particular, the work that [pep](https://pep.foundation) and [Autocrypt](https://autocrypt.org) have been doing. - Forward Secrecy As I've [written before](https://arstechnica.com/information-technology/2016/12/signal-does-not-replace-pgp/), I don't think that forward secrecy is actually fixing a problem that most people have. Particularly in the case of OpenPGP where most people are interested in encryption of data at rest (messages stored on an IMAP server), which forward secrecy doesn't help (forward secrecy, because it throws away old key material, only makes sense for protecting data in motion). But, that doesn't mean that we haven't given some thought to the problem. In fact, at the very same gathering, Justus, who is also working on Sequoia, presented a proposal for adding forward secrecy to OpenPGP in a backwards compatible manner. You can [watch the presentation](https://www.youtube.com/watch?v=an6oYjikAPY), or [read an early version of the proposal](https://mailarchive.ietf.org/arch/msg/openpgp/mk8_FSS-n4DVGfh_VwuGtEOS2xk). The short version is: OpenPGP already has mechanisms to mark encryption keys as being appropriate for data at rest or data in motion. Until now, no implementation has bothered with this distinction. We propose creating two encryption-capable subkeys, one for data at rest, and one for data in motion, and rotating the one for data in motion once a week. To ensure that a sender has a non-expired encryption key we pre-generate keys, and distribute them via the keyserver network. - The OpenPGP format and defaults suck It is true that OpenPGP has standardized a number of ciphers that are no longer sensible, includes compression support, etc. But, OpenPGP is over 30 years old. In that time there have been many improvements. But Matt is right that these improvements come slowly. This is partly due to the lack of funding: the industry choose S/MIME over OpenPGP. (Although S/MIME is cryptographically worse than OpenPGP. See EFAIL for a critical example of why.) A major difficult to deprecating old ciphers is that OpenPGP is used for data at rest. And people rightly expect, I think, to be able to decrypt data and verify signatures from X years ago. This means we can't completely drop support for, say, CAST5: people wouldn't be able to decrypt old messages. Matt seems to ignore this bit, and focuses primarily on real-time communication (e.g., Signal), which only needs encryption for data in motion, i.e., the encryption is stripped and only archived on a trusted device (e.g., not an IMAP server). One thing that we are consider in Sequoia is requiring the caller to provide a timestamp when verifying or decrypting a message. The timestamp can be used to choose defaults that are appropriate for when the message was allegedly created. The timestamp can be double checked with the timestamp in the signature. In this way, if someone tries to send you an email using a deprecated cipher, they'll also have to set the timestamp in the email to, say, 1997, which would hopefully be suspicious. Likewise, something like a can be shown when the message doesn't meet the current standard. I hope that helps! If you have any other questions, you're welcome to ask here, or on irc (#sequoia on freenode) or on our mailing list (devel@sequoia-pgp.org). :) Neal
I've struggled with breakpoint debugging. It does work, but Rust often seems to optimize out variables on the VSCode display. I've largely switched to writing excessive unit tests, which are really simple in Rust, that address logic bugs - and even better continue to do so as your code develops. For concurrency/race-conditions, println combined with #derive(Debug) everywhere. I've not really found any tools in Rust (or C++ or anything else) that really help with concurrency issues.
I've followed an article --&gt; https://www.reddit.com/r/rust/comments/5bwfdq/schemers_a_new_tutorial_for_rust_beginners_lets/
Why? mpsc is fine. If the performances are sufficient and you don't need multiple consumers they're not an issue. `chan` is deprecated because both it and crossbeam are MPMC and /u/burntsushi has little reason to keep maintaining chan if they have the same capabilities, a similar API and crossbeam-channel is plain better at the job.
Very cool! There are a few things I'd do differently (or want to solve in a different way but haven't gotten around it), but in general this is very well done! I love that generating shell completions and binary artifacts is already part of it.
Of which parts does your compiler consist? And where do you have Rust specific problems?
Worked on a scriptable input remapper for linux: [https://github.com/t184256/irwir](https://github.com/t184256/irwir). It's far from completion though, and I'm sure it is far from idiomatic Rust either.
Thanks! If you have time can you list the things you would do differently? It's pretty easy to add questions, eg adding an optional `failure` dependency would take ~5min to implement but I don't know what other people would do differently.
&gt; for some ungiven reason. "My thinking was that many existing game developers are familiar with SDL2, and SDL2 is a good example of a well-done Rust C API wrapper."
I'd suggest first starting with python or javascript: they probably have the most abundant beginner friendly resources to learn programming and there's a lower barrier to entry on the number of ideas you have to keep in mind to write a program. Once you're comfortable with the basics of programming (functions, variables) then you can start with [The Book](https://doc.rust-lang.org/stable/book/) which will run you through the rust language. My more general tip is to start building _things_ as quickly as possible and not to get bogged down in learning everything about programming/a language before you start putting it to practice.
So I tried reading the docs, then I tried reading the source, and I could not find even the barest hint of a clue how to actually encrypt or decrypt anything with this. Turns out that code isn't in the "low level" openpgp module, or even in the "high level" sequoia modules, but in the [source code of the `sq` command line tool](https://gitlab.com/sequoia-pgp/sequoia/blob/master/tool/src/commands.rs#L21)!? I kind of get the impression that this is aimed at people who are extraordinarily familiar with the internals of openpgp?
This is really exciting. I watched both talks and subbed to your YouTube. It really sounds like you are looking to take the best of keybase and remove the need for centralised infra. Very cool!
Thank you for the detailed reply! &gt; As I've written before, I don't think that forward secrecy is actually fixing a problem that most people have. Particularly in the case of OpenPGP where most people are interested in encryption of data at rest (messages stored on an IMAP server), which forward secrecy doesn't help (forward secrecy, because it throws away old key material, only makes sense for protecting data in motion). I disagree, forward secrecy is orthogonal to whether the data is at rest or in motion. You can automatically rotate the keys for both. &gt; You can also do something like Signal with its verified key servers. But, if you want to be decentralized, then somehow you have to get the user involved. So, in my opinion, this is more a criticism of decentralization than of OpenPGP. The Signal protocol is carefully designed such that [messages are deniable](https://signal.org/blog/simplifying-otr-deniability). Keyservers in combination with OpenPGP result in the opposite, so I don't think the key management problems are independent of the protocol. &gt; Although S/MIME is cryptographically worse than OpenPGP. See EFAIL for a critical example of why. EFAIL affected both, so how is this an example that OpenPGP is better? &gt; One thing that we are consider in Sequoia is requiring the caller to provide a timestamp when verifying or decrypting a message. I think it would be much safer to provide a *separate* tool to upgrade old encrypted data to a contemporary format. This way you can drop support for old formats and avoid downgrade attacks more reliably, while users are still able to upgrade from old formats. As a bonus, it gives an incentive to migrate from deprecated crypto. IMHO, encryption with deprecated crypto should not be possible, including non-authenticated encryption. What is Sequoia's stance on this?
Unfortunately VB6 and COM are alive and well (maybe not well) at my day job.
Sure, I'll try to write something down in the cli-wg tracking issue -- it's mainly not about adding crates but more about writing crates that so stuff like nicer error output.
&gt;I disagree, forward secrecy is orthogonal to whether the data is at rest or in motion. You can automatically rotate the keys for both. I don't understand: if I rotate my key for data at rest, I can't decrypt the data at rest anymore. &gt;The Signal protocol is carefully designed such that messages are deniable. Keyservers in combination with OpenPGP result in the opposite, so I don't think the key management problems are independent of the protocol. It's not clear to me that anyone cares about this feature in practice. Lack of cryptographic proof isn't going to stop the Russian Mafia from beating the shit out of you. And it's not clear that US courts care much either. See, for instance, this post from dkg who works at the ACLU: [https://debian-administration.org/users/dkg/weblog/104](https://debian-administration.org/users/dkg/weblog/104) Also, it is possible to use OpenPGP without signatures, which gives you deniability with respect to third parties (the same thing you get with something like OTR. OTR just let's your communication partner authenticate the message). &gt;EFAIL affected both, so how is this an example that OpenPGP is better? EFAIL only works against OpenPGP if MDCs (modification detection codes) are disabled. S/MIME doesn't support anything like MDCs. So the fix in OpenPGP is for implications to abort if a message doesn't have an MDC, which is a tooling problem. In S/MIME, the protocol is broken. &gt;I think it would be much safer to provide a separate tool to upgrade old encrypted data to a contemporary format. This way you can drop support for old formats and avoid downgrade attacks more reliably, while users are still able to upgrade from old formats. As a bonus, it gives an incentive to migrate from deprecated crypto. Upgrading archived data is not easy.
Yup! Ideologically, we are against centralization. Thanks for following!
I'm not sure what "Ranger" is so I can't help you with that. However, by using semver in Cargo and crates.io, you can ensure no breaking changes will happen to your crates. As well as that, the crates used are statically linked and included, so versioning shouldn't be an issue.
You may want to look at the [encoding crate](https://docs.rs/encoding/0.2.33/encoding/) to convert to utf8. It has Windows 1254 support which looks like it is mostly compatible with iso-8859-9.
Ranger is a terminal file manager.
The problem isn't about avoiding them, but not having to recreate them from scratch, without generics.
The only thing not mentioned – but probably of interest is, that `chan::WaitGroup` can be replaced with [scoped_threadpool](https://crates.io/crates/scoped_threadpool).
I work in KDB for my day job. The fact of heterogenous collections is just due to the absolute paucity of typing in the language. The good part of KDB is the uniform vector computations and the ad-hoc SQL query engine. I don’t know exactly what you’re trying to build though. But if you’re trying to write your own version of these languages, the equivalent memory representation of a generic vector is a Vec of Boxed trait objects.
I'm trying to learn by following tutorials, I don't have any specific problem right now, I'm looking for a tutorial that I can follow.
I've been using the Sequoia library to build a PGP keyserver in Rust! Thank you so much for the hard work!
Cool! You should come chat on our irc channel (#sequoia, freenode), as we've actually already started a new key server implementation. It would be great if we could join forces.
I am working on my first Rust project, a command-line tool to rename files and directories called [RnR](https://github.com/ChuckDaniels87/rnr). I've added this week: Windows support, directory renaming, and binaries on GitHub Releases among other features. Code review and usage feedback are welcomed!
I'm thinking about the type of forms you get with a c# forms application. Or really I'm interested in any type of a non-browser front end for rust programs. 
you can check the awsome-rust repo on GitHub, or just search for GUI releated posts on this subreddit.
That would be great! I started working on it as a student but never had time to finish it. Github: [sks-rs](https://github.com/srct/sks-rs/) I'll check out the channel when I can.
As a non-C++ programmer, shallow-const just seems broken to me. I don't know of any specifically documented design rationale for the way Rust's `mut`-ness works. It seems like the obviously correct thing to me. However, my intuition tells me it overlaps with the borrow checker. If I can hand you a `&amp;node` and you can get a `&amp;mut node.next` out of it, then `&amp;mut` no longer means you're the only one with a mutable reference to something.
&gt; I don't understand: if I rotate my key for data at rest, I can't decrypt the data at rest anymore. You can re-encrypt the data with the new key. But maybe I misunderstood "at rest": Does it mean it cannot be changed anymore? &gt; See, for instance, this post from dkg who works at the ACLU That was an interesting read, thank you! To me, the point about deniability is that it is similar to traditional communication that is not end-to-end encrypted, so you don't suffer any unintuitive disadvantage due to using end-to-end encryption. This is just being conservative, it is not clear whether losing deniability results in significant disadvantages. The following argument was a bit funny: &gt; Several folks pointed out that most communications-security tools are too complicated or inconvenient to use for normal people. Note that this mostly applies to traditional tools without built-in deniability! &gt; Also, it is possible to use OpenPGP without signatures, which gives you deniability with respect to third parties Does this imply you have to use unauthenticated encryption? If yes, this is not really an alternative. &gt; Upgrading archived data is not easy. I'm not sure that this is enough reason to compromise the security of all users.
`WaitGroup` can also be replaced with channels. Consider the following example: let w = WaitGroup::new(); crossbeam::scope(|s| { scope.spawn(|| { w.add(1); // ... w.done(); }); scope.spawn(|| { w.add(1); // ... w.done(); }); w.wait(); }); The same code using channels: crossbeam::scope(|s| { let (s, r) = channel::bounded(0); scope.spawn({ let s = s.clone(); move || { // ... drop(s); } }); scope.spawn({ let s = s.clone(); move || { // ... drop(s); } }); drop(s); r.recv(); });
&gt;You can re-encrypt the data with the new key. But maybe I misunderstood "at rest": Does it mean it cannot be changed anymore? That's not practical, and that's not data at rest. &gt;\&gt;Also, it is possible to use OpenPGP without signatures, which gives you deniability with respect to third parties &gt; &gt;Does this imply you have to use unauthenticated encryption? If yes, this is not really an alternative. Nope. This is what OpenPGP's MDC system and AE solves: authentication without identification. &gt;\&gt;Upgrading archived data is not easy. &gt; &gt;I'm not sure that this is enough reason to compromise the security of all users. I think you have thought through the problem :D.
I also don't have much faith in shallow const. I can see why C++ has it and Rust doesn't (C++ has historic baggage, Rust was able to start from scratch). \*However\*, I'd prefer to have Rust designers on record talking about why they designed it this way rather than write about my own opinion :) I agree with your intuition, mut must be inherited as exclusive access of \`&amp;mut\` is so important. If \`x.next\` is the same as \`y.next\`, and those are \`&amp;mut\`, that goes out of the window.
Learn Python as your first language so you get the basics like functions variables loops conditions etc. then read the Rust Book and practice practice practice. 
I can't speak for Windows, but I use Rust with gtk-rs at work to create GUI applications for Linux.
Funny, I just read [this post](https://www.reddit.com/r/Windows10/comments/93o89e/why_i_stopped_using_ccleaner_and_why_you_should/e3eu8ul).
Python -&gt; C -&gt; Rust is a good pathway.
&gt;I don't entirely understand your issue.. why differentiate between column and row data? Why not store data as it is done in kdb+ using efficient unboxed vectors for homogeneous lists and less efficient boxes vectors for heterogeneous lists? I don't want to differentiate but it anyway must. A simple example is: for row in Rows a scan of data like this consume a row. So I need to pull values for each column at pos:N for the consumer to read. That is why I have Column/Scalar. The thing is that is necessary to duplicate efforts between the 2, so I wonder if is possible to just have data&lt;Values&gt; and flip things based in what layout is data.
No more rationale is needed - the borrow checker would be useless without this.
[removed]
It works! Here's my repo: https://github.com/royallthefourth/platformsh-rust-rocket
There's only one other reply to my message, and it covered that. But for those tuning in just now, "Oh, I skipped straight to reading the articles and _they_ don't explain why; oh well"
Mut on top leve is just a convenient way to keep track of what might change and what won't, but with move semantics and shadowing, its a pretty temporary one. Mut on references is quite different, is actually a sharability property. It makes you a unique owner. That's the core, the fact that sharing disallows mutation is what follows.
&gt; You can re-encrypt the data with the new key. But maybe I misunderstood "at rest": Does it mean it cannot be changed anymore? Nah, it just means that it arrived at its resting place, it's no longer on a network path towards its destination. The thing is, forward secrecy is a property of exchange. If we are exchanging messages the compromise of one message / session key doesn't lead to the compromise of all messages / sessions. How do you propose that the current schemes for fs work with data on disk? There is no concept of a session, there is no exchange taking place and the data volumes are completely different. What threat are you protecting against? It's not a network threat, it's presumably an offline attack against your message archive. The best you can do with your archive is encrypt different bits with different keys. Where is that keyring going to persisently live? How big can it grow? This is a completely different design space to protecting messages exchanged between two peers over an untrusted network.
For example, VSCode will show the path, but if you quickly do a `CMD+P`-&gt;`mod.rs`, you end up with a bunch of them plus a bunch of paths, and the one you want could be anywhere in that list. So you continue typing `mod.rs mymodname`, and that doesn't work, because VSCode's file path searching isn't very complete. So then you clear it out and say `mymodname/mod.rs`, which does work. But, many clean apis or crud apps will have paths like `repository/user/mod.rs` and `model/user/mod.rs`. So what you really need to do is a graph traversal in your head up to the nearest dissimilar containing folder. Or, just look through the list of search results with their paths. Point being, its the same thing as `index.js` in Node, and it's a manageable hassle. Go's method of doing packages is cleaner.
That's the biggest contraction the article refuses to notice: &gt; The biggest Rust users I know are among the very best and most secure C programmers around. These were not the people writing unsafe code in C.
Even with `UnsafeCell` you may not alias `&amp;mut`.
That was my reaction as well, but there's still an interesting related case that shows the difference in approaches. In rust, a &amp;mut reference, in a struct that does not itself have mutable access, is treated as const &amp;. https://play.rust-lang.org/?gist=b9369cdea52415358b1b97aa5a781903&amp;version=stable&amp;mode=debug&amp;edition=2015
[removed]
Can you provide more details about what is failing? The example is working for me: ``` $ rustc --version &amp;&amp; cargo run --example si rustc 1.27.2 (58cc626de 2018-07-18) Finished dev [unoptimized + debuginfo] target(s) in 0.10s Running `target\debug\examples\si.exe` 15.0 m + 10.0 cm = 15.1 m 15.0 m + 10.0 cm = 0.0151 km 15.0 m / 50.0 s = 0.3 m/s 15.0 m / 50.0 s = 0.0003 km/s ```
The `select!` macro alone is worth the price of admission, not to mention the performance improvements over `std` channels. If both options were equally accessible "out of the box", I don't think anyone would hesitate to say just use the `crossbeam-chan` flavor.
It's been said before, and will surely be said again, but some people prefer to think of `mut` as `unique` as in "this the unique (active)[0] binding to this variable". This makes your original question clearer, since there's no way to guarantee (at least not locally) that the binding you'll give to `self.next` is unique if you can't guarantee that your access to `self` isn't unique. [0] Consider: let mut a = String::new(); let b: &amp;mut String = &amp;mut a; // b becomes active, a is frozen let c: &amp;mut String = &amp;mut b; // c becomes active, b is frozen println!("B is {:?}", b); // Compile error, b is not active
I agree that AV companies are a little sketchy, but this might not be the right time and place for that discussion. ¯\\\_(ツ)\_/¯
Should be able to do something like: use scema::user_adjective::dsl::*; user_adjective.filter(count_of_repeats.gt(1)) .order((count_of_repeats.desc(), user_id.desc()); http://diesel.rs/guides/getting-started/ http://docs.diesel.rs/diesel/query_dsl/trait.QueryDsl.html#method.order
While I like your solution, the discoverability of your pattern could be improved by having it in the docs or by wrapping it into it's own function (maybe something like `blocking_pool`). ... I know... I'm just driving by and throwing some words at you... maybe this has been discussed a thousand times already and I'm user 1001... who knows...
You're welcome. I was very surprised the first time I realized how much my employer was actually paying me (and all the money I never saw).
We have nearly two hundred tests. So, I guess you are blind :). Perhaps you are running 'cargo test' and not 'cargo test --all'. This is necessary, because we are using workspaces, and cargo doesn't automatically recurse into workspaces when running tests.
It is not the case that C/C++ has "shallow" constness. In C/C++ all data is mutable unless declared constant. It is the developers responsibility to properly declare the level of constness that is appropriate. The definition of `node` in your example only results in "shallow" constness guarntees. To achieve the results you describe, you should define `node` as: struct node { std::unique_ptr&lt;const Node&gt; next; int elt; }; As your example illustrates, this can be subtle and confusing to developers, but correcting declaring constness has wide-ranging impacts to security and usability. Rust doesn't have the C/C++ notions of `const` because: * Values and references are immutable unless specifically defined otherwise via `mut`. * The borrow checker obviates the issue since it must be sure that there is only a single owner of data that can modify a value at any point in time. * There are no pointers outside of unsafe code, otherwise the borrow checker could not ensure that there are no aliases to data being mutated. In C/C++ a pointer can have 4 different definitions for consteness (see this [Stackoverflow question](https://stackoverflow.com/questions/890535/what-is-the-difference-between-char-const-and-const-char), or [this one](https://stackoverflow.com/questions/33565163/unique-pointer-and-const-correctness) for reference): * A non-constant pointer (`char *`) -- both the pointer and data it points to are mutable. * A constant pointer (`char * const`) -- the pointer is constant, but the data is mutable. * A pointer to constant data (`const char *`) -- the pointer is mutable, but the data is constant. * A constant pointer to constant data (`const char * const`) -- both pointer and data are constant. C/C++ developers often use `const &lt;T&gt; *` when they should use `const &lt;T&gt; * const` or `&lt;T&gt; * const`. These errors--if they are actually identified as such--are often not fixed because: * Changing an API to use `const &lt;T&gt; * const` can have a large ripple effect on the code base due to fixing the constness assumption everywhere. But that is **the reason** to make the change: you are seeing the effect that the change to the assumption of constness has on the code. * An assumption that "`const` is just a hint to the compiler." It is true that the compiler can make optimizations based on the constness of a pointer. However, there are also security and usability issues. For example, I know that given an API that returns a `const &lt;T&gt; * const` means that I have a string that the API considers immutable. I may be able to break that promise through a cast, but it is clear that I am going against the API design if I do. It is also possible that security systems or where data is placed may prevent me from making changes to the underlying data even after I cast away the `const` portion of the pointers. * Changing a published API that incorrectly used `const &lt;T&gt; *` rather than `const &lt;T&gt; * const` represents a breaking change, and has the same problems as the first point, but in code that consumes your API that you may not control. * Changing the API introduces complexity to the code. In the example that you gave, defining `node` the way you did is the definition a linked list library author needs, since they need to manage the contents of the list. However, a consumer of the linked list library should use the definition I gave above, since the consumer should not update the node pointers directly. That could done using one of the following approaches--all of which add code and intellectual complexity and overhead: * Defining multiple `node` types (and keeping them in sync). * Using a single declaration (where `next` is a pointer to a constant `node`) and appropriately casting away constness within the library functions. * Provide an opaque type for `node` that does not expose the underlying pointer, which completely eliminates the issue. Many C/C++ APIs were defined before const pointers were defined as they are today. Design choices for new code are often made based on existing API for consistency or compatibility without necessarily thinking through the implications of those choices. The C++ standard library is attempting to resolve that for new C++ code, but there is still a large amount of legacy C/C++ code out there. One place in Rust that you do see *similar* issues with constness in C is in `impl` blocks where developers need to decide if methods need to use `self`, `&amp;self` or `&amp;mut self`. But Rust will raise errors at compile time if the developer uses the wrong version of `self` in a method.
[removed]
Have you seen https://www.rust-lang.org/en-US/install.html ? Intellij has a very nice Rust plugin but it doesn't download Rust afaik
You have to install IntelliJ from the official [website](https://www.jetbrains.com/idea) and then go into the plugins section and install the Rust plugin.
Rust has tons of plugins for various IDE's. A simple google search gives you this page: [https://areweideyet.com/](https://areweideyet.com/). If you need help learning Rust, [The Book](https://doc.rust-lang.org/book/second-edition/foreword.html) is a fantastic resource.
Withoutboats has also been working on [a partial implementation of PGP](https://github.com/withoutboats/pbp) in order to [support a signed index](https://github.com/rust-lang/rfcs/pull/2474) for Cargo without having to ship all of GPG to all Cargo users. See also [this blog post about signing commits](https://boats.gitlab.io/blog/post/signing-commits-without-gpg/). Maybe there is an opportunity to collaborate?
&gt; I believe that serde works best when using it at the edges of your application, and immediately converting from it to a new, more usable, internal representation (a lowering step, in compiler-speak). I've also arrived at this conclusion, at least for non-trivial cases. serde is a very convenient way to declaratively specify a schema, but there's no sense trying to contort your internal in-memory data structures to match the ideal schema visible to the outside world.
&gt; Arrays are not Copy. That part is [contradicted by the docs](https://doc.rust-lang.org/std/primitive.array.html): &gt; Arrays of *any* size are Copy if the element type is Copy and Clone if the element type is Clone. This works because Copy and Clone traits are specially known to the compiler.
Don't mind?!?! I'm honored! Showed it to my kid and she lost her mind over it. Thanks!
Thanks everyone for all the love! My kid literally freaked out over all the attention this got. She asked me to thank you all and tell you she's super excited. 
It's not true that Rust special cased the map implementation. Users can and do write unsafe code in Rust
Why? Next week they will be deprecated.
Nononono Use pom if you want any kind of readable code
This doesn't help your actual problem, but - If you didn't know, it's possible to make actual tables (if you're using the re-designed Reddit, it's stashed under the "..." button in the toolbar). In old Reddit they need to be handcrafted in markdown. |id|user\_id|adjective\_id|count\_of\_repeats| |:-|:-|:-|:-| |1|1|1|1| |2|1|2|2| |3|7|70|1| |4|2|11|1| |5|3|3|3| It's also possible to use inline monospace (the &lt;/&gt; option), as well as code block formatting (also stashed under the ...-button): id | user_id | adjective_id | count_of_repeats 1 | 1 | 1 | 1 2 | 1 | 2 | 2 3 | 7 | 70 | 1 4 | 2 | 11 | 1 5 | 3 | 3 | 3 `SELECT * FROM user_adjective WHERE count_of_repeats &gt; 1 ORDER BY count_of_repeats, user_id` If you did already know this and just didn't botherthen never mind me as I exit stage left!
I am parsing some kind of JCL files and wondering if there is a better way of doing this : let my_var: Result&lt;(), String&gt; = if line.starts_with("STEP foo") { call_function_1(&amp;line) } else if line.starts_with("STEP program") { call_function_2(&amp;line) } else if line.starts_with("STEP bar=") { if line.starts_with("STEP bar=tool1") { call_function_3(&amp;line) } else if line.starts_with("STEP bar=extremely_long_name") { call_function_4(&amp;line) } else if line.starts_with("STEP bar=extremely_foo_bar") { call_function_line(&amp;line) } else { Err("Invalid STEP bar") } } else { call_other_function(&amp;line) } My code in itself works but all those "if/else" are making me wonder if I could convert it to a "match" that would leave the code cleaner than it currently is. But seeing as I need to keep the ".starts_with()" because in general, I can categorise a line only by their first x characters that can vary from line to line, I still haven't found how to do it with a match. Does anyone have any pointers as to where I should look for answers ?
haha thanks for correcting
Wow cool, gonna try implementing this in C. :)
If you're on linux using pulseaudio, check out https://wiki.archlinux.org/index.php/PulseAudio/Examples#Remap_stereo_to_mono. I did not find a way to do it on Windows 7, sadly.
The contents look really interesting. Its awesome to see such a wide range of Rust Books. 
But at the same time its not possible to be disciplined enough to get a better understanding of the borrow checker.. It is saying in practice that its easier to write perfect C/C++ than to get a good grip and work with the borrow checker... that is some far fetched logic if you ask me.
Oh thanks, didn't know that!
When I explain/introduce `&amp;` and `&amp;mut` to people learning Rust, I always make sure to always spell `&amp;` as a shared reference and `&amp;mut` as an exclusive reference (although unique is also a nice name). When the newbies sooner or later talk about immutable and mutable references, I make the effort of pointing out that mutability follows from exclusive access, and not the other way around. You can mutate through a `&amp;`, and sometimes it makes sense to use `&amp;mut` to denote exclusive access even if you don't intent to perform a mutation. 
I've used `youtube-dl` and on VLC used the audio option `left` instead of `stereo` it it was all good again
[My Firefox addon](https://addons.mozilla.org/en-US/firefox/addon/soundfixer/) can help too :)
&gt;Couldn't you just disable encryption for insecure keys unless explicitly enabled? That way people could still decrypt old messages but not encrypt new messages with weak encryption. An attacker won't respect that :).
Maybe my eyes are going, but this doesn't look like /r/playrust to me. In fact I'm almost positive the sidebar says that this sub is "A place for all things related to the Rust programming language."
Sorry, didn't realise. Removing now... 
Hi /u/CordlessFLUKE, you posted this to the wrong subreddit. /r/rust is about a programming language. See /r/playrust for discussions about the game.
&gt;rocket, warp, hyper, futures I love this trend of space-y web framework names. It feels like I'm powering on a futuristic spaceship every time I code in Rust. &gt;but the exciting part is the combinators that exist on the Filter trait. These allow composing smaller Filters into larger ones, allowing you modularize, and reuse any part of your web server. Rust's functional combinators, for web server middleware? I love the concept. (Is *monadic* the right term here?) &gt;The more I wrote Rust, and learned how amazing the “fearless refactoring” is, the more I hated working in dynamic languages (in my case, it was a large Nodejs server), as trying to refactor pieces inevitably would remind us (in production) that our supposedly comprehensive test suite still had holes in it. I wanted app-specific types to save me from shipping bugs. Rust's type system feel like guide rails for programming. Like, I'll crash into them when I'm trying to get to compile, but I won't fall off a cliff instead. It's felt really powerful. Keep up the good work!
This looks fantastic, this handles request scoped data in a way that feels much more natural and type safe than I've seen in other rust frameworks, all without the need for lots of proceedural macros. Though I couldn't figure out how to build my own filters from the docs, it looks like in the library the filters are built via `filter_fn` but that doesn't seem to be part of the crate's public api.
I'm really liking the variety of web frameworks popping up. Between Rocket ,Actix and frameworks like this, things are shaping up pretty well. Hopefully once await / async comes around things are gonna become even better. I'm not sure if I would personally use this over actix, since I really like the whole Actor system actix does, but this looks interesting for sure. 
Wonderful to see more new ideas in this space! One thing I wondered -- can you say a little bit about how the filter approach compares to Rocket? At a high level they feel pretty similar, in the sense that they use types to drive the endpoint matching process, and that can include both extraction and various filters/validation. I'm thinking here of things like [request guards](https://rocket.rs/guide/requests/#request-guards). A couple of obvious differences are: HLists vs proc-macros, and the fact that for Rocket everything has to live as an endpoint decoration, whereas with warp I think you have more flexibility?
&lt;3 the function combinator approach to filter construction :)
Totally makes sense! Worth repeating from the post, I didn't want to make *just another* framework, and try to say it's just plain better because I say so. I wanted something different, that I personally hadn't found yet, and know some people will like that, and others won't.
I feel like things that are great about Rocket are how you can use macros and attributes to get rid of a bunch of the "HTTP boilerplate". That said, I've not typically preferred the "convention over configuration" style. But moreso in this case, I think the major difference is that a `Filter` doesn't have to be the end handler. You can define just small pieces that extract just a little bit of data, like Rocket's request guards, but in warp, they are written the same way as any filter. You only need to return a reply at the very end. To me, that makes it easier to understand how to insert predicates at whatever stage I want.
Congratulations, Sean! I like how unique the API is and am curious to see what others can build with it. This is further proof that Rust is ready for server side development.
Hey that is really cool! Speaking of books, there is any heading to the "Learn programming" with Rust as a language? I don't want to learn Python or C++ but I know a little bit of C :|
Is this similar to the "plugs" concept of Phoenix framework?
This is absolutely fantastic. You have up way past my bedtime trying to work out how on earth you managed to implement that! I was trying to work out how to do "generic middleware" that could add parameters to handler functions without needing to be aware of what parameters were already available. I thought it might be possible by round-tripping tuples through HLists (which I think is what you're doing here?), but that was way over my head (and I wasn't even sure it was possible). I also wasn't aware of the call function, which I think is spreading this tuple into normal function arguments? Do you have any idea how the performance compares to other Rust web frameworks / bare hyper?
It's hard to imagine exactly what you're trying to do, but it does sound like going through the hlist system could work. I don't think that stuff is exposed yet, as I've been extremely cautious in areas that were experimental. For HList, I believe specialization will make it even better. But maybe we can expose some building block to do what you want? I regularly compared the performance of warp to just hyper, and the difference seems to be just noise. The Hlist stuff is optimized away at compile time, and `Filter` likewise optimizes similar to `Future`.
I'm actually a bit confused about how this works. Is there a limit to how many and filters you can have? How does the type system know what type of closure to take when you call map? Incredible work by the way. Doing web stuff in rust has never been this easy.
For now, it will work to return up to 16 values (filters returning unit shouldn't affect the limit), as there's a macro generating impls for tuples. When trait stabilization becomes stable, I *think* it should work with any. If people are frequently try to use tuples of more than 16 values, we can add more... But I'd suggest those should become specific types instead of generic tuples :) The polymorphic closure works by having created a new trait, `Func`, which is implemented for all functions that received the untupled arguments. It sometimes messes with inference, but otherwise feels much better!
Funny enough, [warp](https://hackage.haskell.org/package/warp) is also the name of a web framework in Haskell. 
With the combinators given how would I access underlying request struct? For instance at my company services must forward all headers with X-MyCompany as a prefix. 
Looks very nice! Is this working on rust stable?
Yep! Requires Rust 1.26, since `impl Trait` is used extensively, but all stable.
I absolutely adore Finch ([check out this paper if you want to see why](https://monkey.org/~marius/funsrv.pdf)), so seeing this framework paradigm ported to Rust warms my heart.
;_______;
Taking a break from trying to write a 3D renderer from scratch to make a small app to help my Dungeon Master manage the enemies. It may grow to be more expansive over time though. To this end, I'm working on a small GUI library which I wanted to do anyways. Thank goodness for trait objects. 
Ah I see, thank you for the clarification. So if I start using warp, in the future I might be able to further take advantage of `tower`. I'm gonna take a stab at using `warp` for a simple admin panel for a website I manage this week. If I wanted to ask questions that aren't befitting of a github issue, I know the Rusters tend to hang out on IRC, is that an option or should I just go through github issues?
https://github.com/BurntSushi/quickcheck/issues/27
I'm still not clear about this. When you say warp and tower-web will merge, what does that mean when tower-web doesn't exist yet? Which crate will subsume the other? Or will they remain separate but work together in some way? I still find Tower pretty confusing.
Huh? What attacker? This is meant for users, so they don't encrypt with weak keys. I have no idea where an attacker came into the picture.
Anyone at all familiar with Phoenix for Elixir? I haven't really worked with it, except going through the tutorial and trying a very simple server, but Filters seem like Plugs.
For the record, questions like this are more likely to get answered in Diesel's official support channels (discourse.diesel.rs and gitter.im/diesel-rs/diesel). /u/usernamedotxt gave the correct answer either way
This is fantastic and congratulations on the release. I didn’t notice mention of Java, but this looks a lot like Java Servlet filters. Was that an inspiration at all? I only bring it up because I’ve seen it get messy there. Long chains of filters can become confusing, similar to inheritance. It’s hard for me to say right now that’s because of inheritance in Java and so Rust wouldn’t have this problem or not. Any thoughts?
Looking through the examples, Filters remind me of plugs. I think filters are a little more powerful / composable than plugs.
We programming hipsters seem to all think alike!
What would you imagine such a struct looking like? Try writing out its definition.
To my knowledge there are not many resources for "Rust as a first language". My recommendation would be to review some of the example-heavy resources at [rust-learning](https://github.com/ctjhoa/rust-learning).
Yay, it's here! I was checking that empty repo for a while... Congrats on the release!
tower-web does exist, it is being refined in private as there is still a bunch of churn.
Or oink.me.uk Rip 😥
This looks great. It probably helps that I'm a big fan of the technologies that inspired you :)
Awesome! This is a great time to be in the Rust community. 
sadly its not entirely unknown in the haskell world either :( Perhaps something like Osmosis as an alternative for a name, like the filter
Ha! I created the repo but didn't want to announce anything until it felt good. Immediately the empty repo had stars/watchers, so I figured I couldn't publish there while using warp was still painful, as it would get "leaked". First impressions and all that ..
Pretty slick! I just wrote a simple slash command for a Slack channel using warp. Not too many comments from a cursory inspection/usage. Really liked how easy it was to set up and serve a handler using the body::form() filter and reply::json() reply. Can't wait to see it grow past 0.1.0! 
Give me maximum warp, Scotty
What is the version of SDL2 that you have? Below 2.0.4 isn't supportrd and will produce limk time errors.
Structs are equivalent to an "AND" combination of the individual fields, while enums are an "OR" combinator. So here it makes sense to have a message type as an enum, as it logically is either a quit message "OR" a move message, "OR" ... You could write this as a struct: optional information about quit "AND" optional information about move "AND" so on as /u/oconnor663 showed in their post. However that doesn't quite model the message type the same as now you could have multiple at the same time, unlike the enum version which exclusively can only be in one state at a time.
It might be useful to think about some enums the language already has as an example: `Option&lt;T&gt;` is an enum. It's either `Some(T)` or `None`. If you wanted to write it as a struct it would look like this (and under the hood it does): ``` struct Option&lt;T&gt; { exists: bool, data: T, } ``` But now you need to: * Use functions to control access to`data` * Constantly be checking if `data` exists And on top of all that, the compiler can't optimise this or guarantee safety because it doesn't control it. 
Although this arises naturally from how the borrow checker needs to ensure safety and control I feel there's a reasonable argument for it as default. If I had to justify it in a sentence it would be: "An immutable value has no business mutating other state." To expand if I have some state, which cannot change, it's existence shouldn't enable the mutation of other state. I feel this idea is evident in both the borrow checker, but also in Rust's `sync` types like `RwLock` which has mutability as a runtime "switch". That is to say, having a `ReadLock` on a value, gives you no ability to mutate any state visible to that value. But a `WriteLock` provides that ability as part of its type definition. 
Rather than mutability, I think it helps to think of `&amp;mut` as *exclusive access*. Let’s say `list` is a list with two nodes. `let second: &amp;Node = &amp;**list.next.as_ref().unwrap()` would give you a reference to the second node. Now the list is borrowed by `second`, so you can’t get exclusive access to anything in the list while that borrow exists. If you could, then writing `list.next = None` would run the destructor for `Box&lt;Node&gt;`, deallocate the second node, invalidate the `second` reference, and expose you to a possible use-after-free bug. This is the kind of bug that the borrow-checker prevents (in safe Rust). Now, you can have what Rust calls *interior mutability*: instead of `elt: i32`, you could have `elt: Cell&lt;i32&gt;`. Cell is special in that it doesn’t need exclusive access (`&amp;mut Cell&lt;_&gt;`) to mutate its content, its mutating methods like `set` work with "only" a shared reference (`&amp;Cell&lt;_&gt;`). There is a trade-off, of course. To avoid the kind of bug described above `Cell&lt;_&gt;` does not let you get a reference to something inside of it: you have to copy or move the whole value. This is fine for `i32`, but for a more complex type you might want interior references. There you can use `RefCell`, which is more flexible but uses runtime checks to keep things consistent. (It’s sort of like a single-thread `RwLock`.)
Not even a web framework, the mother of haskell web frameworks. A lot of frameworks are based on it.
1. Same name for all three. 2. No. 3. `asset!()` should be fine. 4. `binary_asset!()`?
Yeah, I read people talking how it is hard to understand concepts of Rust but maybe there is a way to teach programming with it and do useful stuff from the start that would take years learning C, C++ and Python.
Warp is a web server implementing WAI, the Web Application Interface. WAI is an interface between servers and applications in Haskell, which allows multiple apps and frameworks to share backends and middlewares. Yesod, Servant, Scotty, Spock, and others are all built on top of Warp. You can write a web application directly against WAI and have it run on Warp, though that's lower level than what most frameworks provide.
https://www.manning.com/livebook-program pBook is probably paperBook? https://www.manning.com/freebook, they don't really explain that well.
They have a note about winit now; thanks.
&gt; A few months ago, I found the Finch library in Scala, and shortly after, Akka, both of which instead just treat everything as a sort of function converting from input to output, and from there, you just chain together these different pieces, and they compose and reuse really well. Going completely off-topic here, but people *might* also want to take a look at [Suave](https://suave.io) for F#. Admittedly, I don't know neither Scala nor those frameworks very well, but this approach sounds just like Suave: Using small functions and then building "pipelines" by combining them (well, sounds just like FP in general, hah). I love this approach, very fitting for ML languages with their ability to easily compose functions in various ways. Rust doesn't really have the *perfect* syntax for that imho, but it's still mostly good enough, and your filter example looks pretty great. So, in that way, it just seems to fit my mental model of handling requests perfectly, I'm definitely gonna take a closer look! 
I certainly like that routing seems to be done without regex. I struggled with coming up a good way for it, and it seems to done it quite elegantly! 
GnuPG's current defaults are strong. The problem with EFAIL was not that people override these defaults, but that GnuPG/Enigmail would show messages with weak protection, which attackers can craft. To protect the user from such attackers, we could disable these weak modes. But, disabling weak algorithms / requiring MDCs (modification detection codes) means that users can't work with old messages.
 grep -R `#[test]` | wc -l Does not count doc tests though
asset! looks very closely to assert! which might be an eye soring. This crate is also very similar to https://crates.io/crates/include_dir which (I think) loads everything in the memory when the app is run.
If you plan to rename "warp", i suggest "warper". It is similar to both "warp" and "hyper" and seems untaken.
Your formatting did not work. &gt; 1.what should be the return type of the 'new' function ? Typically the return type is `Self` (the type of the `struct`). If you use `cargo clippy`, that is what `clippy` will recommend anyways.
Actually liveBook is a Manning-specific web application. It allows you to buy single chapters rather than the whole book. They also provide ebooks (in three DRM-free formats).
Nevermind. sdl2-ttf has been deprecated, just not on crates.io, use the newest version of sdl2, I believe it's a feature flag.
Sorry for the confusion! The pBook stands for "print book". "liveBook" is a Manning web application that allows you to buy chapters (even sections of chapters) without buying the whole thing at once. The URL for Rust in Action's liveBook is: https://livebook.manning.com/#!/book/rust-in-action/
Just looked it up - good to know. I think the ebooks are strictly speaking separate from the livebook (when you buy a book, they list pbook + ebook + livebook). Just bought the pbook + ebook + livebook combo, BTW. :-)
`Vec&lt;u8&gt;` may provide for less reallocations if the callee needs a heap-allocated type I guess. On the other hand, `&amp;[u8]` means much more flexibility for the caller e.g. a `&amp;str` can be converted to an `&amp;[u8]` at no cost so you can use a static string as key, or data you got from the network, or a sub-slice of an existing buffer, … It's usually recommended to take slices or iterators as inputs if you can, as it provides significantly more caller flexibility: lots of stuff can yield a `&amp;[u8]` or an `Iterator&lt;Item=u8&gt;` but only a `Vec` can yield a `Vec`.
&gt;id.and(verify).and(body) &gt; &gt;is actually exactly the same as &gt; &gt;id.and(verify.and(body)) I smell the sweet scent of monads!
&gt; Using unstable interface of reqwest(no thank you) May I ask why?
I think it is irresponsible to rewrite any widely used C library in Rust until Rust's portability story is sorted. For example, if cURL or SQLite got rewritten in Rust, all transitive dependencies of them will be unavailable on architectures that are not x86 or ARM.
It is nice to see more asynchronous libraries being written. Why do you inline so many methods though? Isn't that premature optimization?
There are other bugs which are not due to LLVM.
Porting to other OSes is probably more of an issue at the moment than porting to other processors; the latter is mostly a matter of LLVM support which in this age isn't too much to ask for from an architecture I think.
Hi guys. I'm new to Rust Webdev and I was just wondering how does crates like Warp or actix-web work with Rust Wasm?
:D Really hope that the investment pays off for you! Do let me know if you have any suggestions :)
I'm unfimiliar with both KV storage's and i am assuming you understand the difference between Vec and &amp;[u8]. The rule of thumb is something like: &gt; Don't hide the cost of a function. i.e. Dont have a function where the first line is something like fn test(aslice: &amp;[u8]) { let data = Vec::from(aslice) // make a whole copy of the data ... } 
Does Debian support mips64r6 ISA?
Not yet, work in progress here: https://wiki.debian.org/MipsRev6
Could you post other such bugs, for those not too familiar with the topic (myself firstly included).
https://github.com/rust-lang/rust/issues/52108 is one. The bug links to it if you read to the end.
&gt; For example, if cURL or SQLite got rewritten in Rust, all transitive dependencies of them will be unavailable on architectures that are not x86 or ARM. Except for, you know, the already-existing C implementations which will continue to exist even if a new Rust implementation is created.
Just a thought: I never really got on board with the idea of JSX. Neither in React, nor Angular or any other frontend framework. It would be really nice for me, if a framework like that also had a succinct API without the macro sugar. Something like: ``` let html = div( &amp;[class("widget")], &amp;[ h1(&amp;[], &amp;[text("Hello, World!")]), p(&amp;[], &amp;[text("some text in a paragraph")]) ] ); ``` It seemed to me at first glance, that your non-macro API was more verbose. (I had to focus really hard not to start to write Elm code up there ;) )
This is a widespread misconception, but not true. LLVM port does not automatically lead to Rust port, there are additional works to do.
Outside of qemu, is this ISA used at all? As in: do mips64r6 chips exist? I couldn't find any.
You're looking for /r/playrust RIP though.
This does not help when SQLite users start to depend on Rust version only SQLite features.
Or to continue the Star Trek theme, perhaps "transwarp"? Since it's the next big thing.
reqwest's main goal is its sync interface, not async. So async interface not only unstable and without any guarantess in regards to backward compatibility, there lots of kinda duplication between sync and async interfaces. My goal is to have async HTTP client library, where sync part would be made just through adaptor rather than separate API.
I'd presume that with decent dependency management, that poses no real issue. People have no problem running code from a decade ago, if it's the only thing that fits their needs. Plus, the more the community needs ports, the more pressure there will be to do it. So that's not much of a long-term issue.
I tried them but couldn't get it right. Actually some help at this point would be appreciated. The http library I am using directly returns string of the body that has unicode encoding. Can I just use the underlying bytes and encode it as Window 1254 encoding? I am really confused at this point. 
 Also I prefer to use rustls
&gt; To achieve the results you describe, you should define &gt; node as: &gt; [...] That's not the same; with the node you've described, the tail is now always immutable. What I'm meaning to describe (might've been unclear) is that I can have a `const node` protect not only the node but also its tail from writing, and a `node` (non-`const`) be mutable--including the tail. There's ways to implement such behaviour, even in C++ (for instance using `propagate_const&lt;unique_ptr&lt;node&gt;&gt; next` or using getters like `const node&amp; next() const {..}` and `node&amp; next() {..}`. But the defaults are switched between Rust and C++, which prompted me to ask here. In addition to your comments on const-ness in C++, I'd like to add a few things: - nowadays, programmers should rarely use naked pointers and take references or smartpointers instead. - while `const T * const` is valid, I prefer switching the syntax: `T const * const`. This way, reading the type backwards is the english description of what it means ("a constant pointer to a constant T"). - you say: &gt; an assumption that "const is just a hint to the compiler." [...] I may be able to break that promise through a cast, but it is clear that I am going against the API design if I do. You may be able to break the promise through a cast, but actually modifying a `const` object (even after casting) is undefined behaviour C and C++. You may only pass that pointer around and now have to remember it's actually `const` data. [1] [1] e.g, C99 standard, sec 6.7.3, paragraph 5: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf &gt; If an attempt is made to modify an object defined with a const-qualified type through use of an lvalue with non-const-qualified type, the behavior is undefined. If an attempt is made to refer to an object defined with a volatile-qualified type through use of an lvalue with non-volatile-qualified type, the behavior is undefined.115)
I don't think those analogies are fitting. It assumes that when you're good enough you'll take the training wheels off the bike. In contrast; when you're good enough with a type system you'll start using it more extensively. 
There is a cost associated with running an obscure architecture. Surely users who choose to do so shouldn't be surprised when they have to pay this cost. Supporting many architectures is great and virtuous, but there is obligation nor expectation to do so, especially for architectures where most people couldn't reasonably obtain a machine to test on.
You haven't seen me bowl now that I'm in my thirties ;O
Thank you both, this is all useful input. I think I will use the same names for all three. I also like the idea of using `&lt;name&gt;!` and `binary_&lt;name&gt;!` but I also agree asset is a little too close to assert. I'll keep thinking, and any other suggestions are welcome too. I have seen include\_dir before, and it's a fantastic crate - but this is slightly different, in that include\_dir (from what I can tell) always includes files statically. My goal here is to allow you to switch seamlessly between static include and dynamic loading.
This is the kind of thinking that caused Firefox for OS/2 to end. "Surely OS/2 porters shouldn't be surprised when they suddenly must port Rust", really? Whatever "should" should be, they were still surprised.
I too had this same question. Then the book by Jason Orendorff and Jim Blandy http://shop.oreilly.com/product/0636920040385.do the chapter _Structs_ says: &gt; So the essence of a struct is the word “and”: I have an X and a Y. But what if there were another kind of type built around the word “or”? That is, when you have a value of such a type, you’d have either an X or a Y? Such types turn out to be so useful that they’re ubiquitous in Rust, and they are the subject of the next chapter. And the next chapter is _Enums_.
Fair enough. I was mostly saying two things: * I think Rust's processor portability "story" is not too bad (LLVM + some extra work in rustc), in that the amount of work required to port rustc (assuming LLVM support) is not out of proportion or unreasonable to expect for an architecture that has a decent amount of users. * I think Rust has bigger issues with its OS portability story, since there's still no really clean way to add new ports to `std`, especially if you want to reuse parts of existing implementations. This is okay for traditional OSes but it hinders use of Rust in novel areas like unikernels and other unusual runtime environments. Maybe I was reading too much into your use of the word "story" as meaning the approach is flawed instead of that the work isn't done for all architectures yet (or, I could be wrong about the amount of work needed). Also talking about the OS part is a bit of an unrelated tangent maybe, but I considered it relevant since it's also a problem you can encounter when migrating C to Rust. 
Finally solved the problem using underlying bytes instead of getting the string. I think I should read about text encoding and decodings.
Sounds great, and for the record: I'm really excited about this project. I was just a bit miffed that it took me that long to figure out what the status was, so my suggestion would be to add a note about that on the site or the GitHub README.
The code is hosted at: [https://github.com/quininer/ene](https://github.com/quininer/ene)
Off-topic: &gt; grep ... | wc -l You can also use `grep -c`, which I think looks cleaner than piping through wc—and does not run an extra process, if you find that important.
That's reasonable, thanks for the suggestion.
Is there an email encryption renaissance? Just yesterday, /u/nwalfield posted https://www.reddit.com/r/rust/comments/93mng5/ann_sequoia_a_new_openpgp_implementation/
How about `resource!` or even `source!` If you wanted to go off the the deep end of using synonyms you could use `treaure!` :)
How would tower-web compare with warp? Are they competing somehow?
Yes, really. Otherwise, you get held to the lowest common denominator language that all platforms support; if you're unlucky, that means C89 and FORTRAN 95 as your most "modern" languages. One of the downsides of maintaining ports to obscure systems is that you have to keep up with more than just the thing you're trying to port - you also have to keep the system as a whole up to date with modern software engineering. That can mean porting compilers, fixing codegen, updating frameworks and many other changes, not just taking the latest code drop and tweaking it to work on your platform. Of course, you can avoid that by sticking to old code - if you want to run Netscape Navigator 4.0 on IRIX 5.1, it'll still work today, even though you can't compile Firefox 60 for such an old OS.
OS/2 is an obscure OS in today's world. I think it is unreasonable to expect continuous support for it for all eternity, especially in a project like Firefox. It is an extraordinarily complex software with increasingly complicated features and security requirements. One can still use older releases of course, but eventually people will have to realize that they have chosen a strange OS.
I'd say that if you just need to have a view on the data then just ask for &amp;[u8]. But if you need to be the owner of the data, then you should ask for a Vec&lt;u8&gt;. Don't just ask for &amp;[u8] and clone the data behind the back of your user.
I don't think this approach works well for APIs: you want to keep flexible interface, but at the same time your implementation may change over time or be different for one or another backend storage. It's more about: does it makes sense to take ownership of the data from the API perspective? If you just save data to DB or send it over network it does not.
I like how this looks. I think it's the same direction as I was heading with rustful before putting it on ice (I'm more of a framework user, than a framework builder), but more generalized and simplified. I was never a huge fan of the way many express like frameworks does the routing, because I feel like there is room for "smarter" solutions (especially with such a nice type system), so this is really appealing to me. I'll give it a try! Nice work!
Ha, I am not sure I will get the time to actually read much of it. But I thought at that price point (using the discount code you posted above) I can as well support this project. :D
I wish they would stop haskelling us.
What's so hard about porting rust anyways. OS/2 runs on x86. Rustc supports x86. All that needs to be ported is the libstd. Porting the libstd is not hard - I would know: I maintain a libstd port for the Nintendo Switch. I don't see what's wrong with rustc's portability story. It's slowly gaining support for more architecture. The std is already fairly modular (it could be a lot better, mind you, but it is \*\*vastly\*\* better than, say, the C standard library).
Not exactly. Layout of `Option&lt;T&gt;` doesn't necessary look like you described but *may* so. Size of `Result&lt;i32, i64&gt;` is 16 bytes (128 bits) because of alignment requirements.
Wow, what a beautifully simple syntax!! This is a great project, I'm excited to try it out myself! Congrats on the big release!
You're assuming these architectures would remain broken/unsupported. Rewriting a ubiquitous application in Rust would effectively force Rust/LLVM/God's hands to fix/add support for these architectures. Also, the more people using Rust-based applications on some architecture, the more likely bugs are to be found and reported. There would be short term growing pains, and it would be painful, but it would be resolved quicker. The two projects you've listed aren't going anywhere soon. Stopping that much technical momentum is tough and will crush most mortals who try. More likely, as shown by Firefox, any product that embraces Rust for a rewrite will do it in parts. Swap out the tire with tire-rs, then drive on it for a while, and if tire-rs goes flat on MIPS roads, you still have your original tire in the trunk until tire-rs is as safe and effective in all conditions as tire.
I really like `resource!` and `binary_resource!` :O I also considered `acquire!` but that might be a little vague.
Also layout of Option&lt;&amp;T&gt; is just the size of a pointer, because the compiler knows that the integer value of a valid pointer cannot be zero and so it uses a null pointer to indicate the `None` case.
This is actually an extremely interesting question that I do not know the answer to. As an extension of this question, I asked myself, how do [tuples](https://doc.rust-lang.org/std/primitive.tuple.html) and [arrays](https://doc.rust-lang.org/std/primitive.array.html) impl Copy and Drop? Looking at the documentation it doesn't even show any impls for these traits, indicating compiler magic.
Bootstrapping LLVM and Rust on a system with no cross-compile environment is hard. They don't need OS/2 as a compile target, they need OS/2 as a build host.
Is it possible to setup retry strategy? For example, for each http post/get if timeout expires, retry with other timeout, then another timeout, then return error? I suppose this is important for unstable internet connection like in cell networks.
Yes, I think it might be possible, though I most likely would need to write my own Deadline as the current one consumes future entirely. Though there is a problem that I would need be able to keep Body unmodified which is not a problem when it is bytes, but may be a problem when user would want to wrap Stream(since you can write it only once)
Depends. If callee needs owned version you'd go with a move of Vec to avoid unnecessary reallocation in callee if caller already had Vec, if callee needs just to read you go with slice to avoid unnecessary reallocation in caller if caller already had slice. If callee only sometimes needs owned version you can go with [Cow](https://doc.rust-lang.org/std/borrow/enum.Cow.html). 
What would the potential advantages be?
Or, perhaps more subtily, [Slipstream](http://memory-alpha.wikia.com/wiki/Quantum_slipstream_drive).
Or `warp-rs`. I don't think anyone really minds the library names being reused, we just want to know which one we're reading about (Talking about you, rust port of Criterion).
Oh, Azur Lane… So Why not Shimakaze? Sounds much faster than Yukikaze…
[yes please](https://deterministic.space/hook-into-rustc-errors.html)
I’m currently trying to write a small (haha) typesetting library. By far, the hardest part so far is determining the bounding box of a given utf8 glyph for purposes. Second would be trying to determine whether two characters have a ligature. Does this library help me solve either of those problems? Looking at the documentation, it seems like this may be what I was looking for. 
There's not much wrong with rustc's portability story. It's just that rustc is [x86-only](https://forge.rust-lang.org/platform-support.html), so foundational C libraries which are used on non-x86 (and non-ARM) architectures should not use Rust. What's wrong is that even if Rust is x86-only in terms of Tier-1 support, people talk as if Rust is portable, and fantasize about rewriting SQLite to Rust. Come back when you are not x86-only, sorry.
&gt; Though in most cases TCP should be able to handle unstable connections unless they are just plainly half-dead connections even when you are moving and IP address changes, because of cell is changed?
I don't assume it will remain broken. I am pointing out it is broken right now. Let me quote from the link: &gt; librsvg is now using rustc. We're stuck with an old version for now, but when we upgrade to the rust version, I wouldn't want to have to remove it, along with all the rdeps, from a bunch of architectures. I claim, it was premature for librsvg to use Rust. At the very least, rustc should stop being x86-only, and preferably should be stable on, say, all Debian architectures. Only then it is sane to consider using Rust in libraries like librsvg (or cURL, or SQLite). It still may not be sane to actually do so.
Hard guarantees about optimizations are difficult to make, but you really shouldn't worry about this one. Traditionally, llvm will transform code into single static assignment form anyways (where a mutable variable turns into a sequence of immutable ones) and then does optimization on that. I really wouldn't worry about it.
Copy and Drop are indeed special lang items that the compiler knows about. Clone actually used to be an ordinary library trait, so that only e.g. arrays up to size 32 were Clone. But then in RFC 2132 Clone became a lang item also, so that closures could be Clone where possible, and as a bonus now arrays of any size can be Clone.
&gt; You can bootstrap LLVM and Rust with just a working C++ compiler (which should hopefully be readily available). mrustc is a Rust to C++ transpiler, which is capable of creating working rustc binaries, from which you can then bootstrap to the latest version if necessary. Sure, it's hard work, but then again maintaining a distro is hard work... I'm not saying it isn't possible or the tools aren't there, but for the uninitiated, there's a lot to do. I actually spoke to the OS/2 people, if someone wants to do the port, they'd help out, but they won't do it themselves.
While on the one hand that's technically true, on the other hand if the toolchain exists e.g. the MIPS maintainers can patch in support for the platform regardless of the project's upstream. The onus to keep up with that maintenance is of course on them (not upstream) but it's possible. That's not an option if the software or library goes from having a toolchain for the platform to not having a toolchain for the platform.
Not competing. More than that will need to wait for its own announcement :)