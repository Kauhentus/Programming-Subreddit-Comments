I would love to eventually have an FFI guide in the bookshelf; any interest in maybe doing that eventually? :)
I think that'd be a great idea! This will probably be my third iteration of writing a guide on doing FFI in Rust, so hopefully this time it'll be worthy of adding to the bookshelf. Having some sort of official guide on integrating Rust and other languages like C/C++, Python, Node.JS, etc, is also pretty important for promoting adoption in established organisations and applications.
Awesome, well, we should talk. It's basically "use mdbook" and that's the only real requirement, technically speaking. &gt; Having some sort of official guide on integrating Rust and other languages like C/C++, Python, Node.JS, This is much trickier. We actually used to have this in the book, but the problem because 1. choosing which languages make it and which don't 2. keeping track of their versioning schemes and making sure stuff didn't rot. 
[Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/)
rust_qt_bindings_generator author here. The generator just generates code and you can then use your toolchain of choice to compile it. I recommend you commit the generated code. Even if you stop using the generator, it'll have helped you get started. The examples in the blogs are indeed QML, but the demo application uses QWidgets. The generated code derives from QObject or QAbstractItemModel and you can you is how you like in QWidgets, QML, Qt3D, command-line. I think it's especially nice if you want to port legacy apps to Rust because you can replace one QObject or QAbstractItemModel at a time. QString is UTF16, so you'll need to convert to that to have your Rust strings in the UI. There's indeed no support for QVector at the moment, but there is support for QByteArray. Adding QVector support is not hard, it just hasn't come up yet. Copying data going from Rust to Qt is the best move in my opintion: it's simpler to reason about passing a Vec&lt;u16&gt; to Qt as a copy: QVector&lt;quint16_t&gt; because Qt is not designed with all the strict guarantees that Rust has. What you can do safely and efficiently is pass a large object into Rust and then process it without the need to copy it. 
The simplest approach would be replacing `Box&lt;Cell&lt;T&gt;&gt;` by `Rc&lt;RefCell&lt;Cell&lt;T&gt;&gt;&gt;` or `Arc&lt;Mutex&lt;Cell&lt;T&gt;&gt;&gt;`
Efficient string manipulation. I made some work integrating Rust into a Windows component and that was probably the hardest part. If I wanted clean code, I had to copy the wide strings forth and back to utf-8 representation. I'm planning to blog about it. Also welcome to suggestions. 
Passing C++ structs to Rust should only be done when the struct is a [POD](https://en.wikipedia.org/wiki/Plain_old_data#In_C++). You can check this at compile-time: struct MyStruct { ... } static_assert(std::is_pod&lt;MyStruct&gt;::value, "MyStruct must be a POD type."); 
Did this conversion give a measurable performance problem? There are not many strings visible in the UI, so the total cost of the conversion should not be high.
FYI, https://mozilla.logbot.info/content/20180630#c14957697
If you're willing to be very careful about your code, you could use `Option.take()` to drop each Rc when deleting the cell. You'd also have to make sure you did that to every element when dropping the whole matrix. I think that would stop the memory leak. However, an alternative data structure is probably a better option.
Rewriting code to use SIMD extensions (SSE/AVX/NEON/etc) - instead of operating on single value, you're now operating on a *vector* of 2/4/8/... values at once. Modern compilers usually automatically vectorize suitable code using available extensions, for example summing up two arrays of 32 bit floats on x86_64 should proceed 4 elements at a time using SSE.
I can see how that'd become a problem. You don't really want to start playing favourites with which language to write examples for, and showing outdated techniques isn't great. One thing to keep in mind is that at its very simplest, FFI code is just the practice of exposing a C-style binary interface that another language can call into. A lot of the patterns and techniques are largely language-agnostic (e.g. error handling, exception safety, passing in a pointer to a string), and I think that's the part we'd benefit most by focusing on.
&gt; type safe [...] Is there anything about UB-free codebase? Actually, the very reason Rust strives so hard to avoid Undefined Behavior is that in the presence of Undefined Behavior, anything can happen, which by definition violates Memory Safety. And since Memory Safety is a necessary foundation for Type Safety, there can be no Type Safety in the presence of Undefined Behavior. Thus, by claiming to be type safe, actix implicitly claims to be UB-free. And yes, at the moment, writing UB-free unsafe Rust code is hard, due to the absence of a precise model. The RustBelt project is all about defining unsafe Rust so that such a model can be created and precise rules agreed upon.
I agree with all the points about the video player, and thanks /u/mattieum for pointing out the alternative link. That said: Both talks are excellent and I’ve learned a lot. I was very uncertain of the orphan rule when generics are involved. And I had no idea what "data flow" really means despite hearing of it repeatedly, it’s a really interesting idea and very relevant to Rust. Kudos to both speakers! The *Flutter's Rendering Pipeline* talk recommended by Raph is https://www.youtube.com/watch?v=UUfXWzp0-DU
Absolutely :)
Using petgraph or another array based solution is probably best, but you *can* use reference counting without memory leaks: you just need to use string references for one direction in each axis (right and down) and weak references in the other directions (left and up).
I clicked on that link with my phone and the browser redirected like 20 times and then died, it's actually just not usable on mobile.
Doesn't look like winit supports getting the raw handle. However if you [don't mind some shenanigans](https://github.com/tomaka/winit/blob/047c67baf31cf9bcdc6f0275037bb3b56f2bd268/src/platform/windows/mod.rs#L47): use winapi::shared::windef::HWND; let hwnd = unsafe { mem::transmute(window_id) }; :)
That's weird.... winit is a widely used crate... But it just creates a window. People have to build on top of it to make anything useful. Are you saying everyone just hacks the handle whenever they need to add graphics / widgets on top of the window?
&gt;Actually, the very reason Rust strives so hard to avoid Undefined Behavior is that in the presence of Undefined Behavior, anything can happen, which by definition violates Memory Safety. And since Memory Safety is a necessary foundation for Type Safety, there can be no Type Safety in the presence of Undefined Behavior. &gt; &gt;Thus, by claiming to be type safe, actix implicitly claims to be UB-free. You are wrong about that. Type safety has to do with enforcing correctness of evaluation in terms of structure and semantics of elements involved in a computation, and it only checks that all invariants of all types hold all the time when an expression is being reduced. You can literally implement your type system on a whiteboard, because it's pure logic and it doesn't require knowledge about memory layout and how this memory is accessed at any given moment, because those are implementation details. And Undefined behaviour doesn't mean that anything can happen, it just means that the result of evaluation of an UB expression is not guaranteed to be consistent across all possible versions of all possible language compilers across time. And this is not the same as "anything can happen". If you only have one version (or a subset of versions, say "stable") of a particular compiler and an expression that is supposed to be evaluated a certain way \*actually\* evaluates that way (which could be proved with extensive testing), then this behaviour is no longer undefined. Similarly, the "unsafe" block doesn't mean that anything wrapped in it automatically becomes unsafe, it means that a compiler won't bother to check the block with its type system.
I don't think I even knew about your FFI guide. I just had a read through it and it's amazing. Thank you for writing it!
I'm not familiar with winit or how it is designed to be used sorry. I just enjoy the freedom that Rust gives me to break all the rules, should I so desire :)
Any help would be most appreciated! I've created a [tracking issue] on GitHub listing the different topics and examples we might want to cover. If anything catches your interest, feel free to make a comment on the issue and we can sort something out :) [tracking issue]: https://github.com/Michael-F-Bryan/rust-ffi-guide/issues/64
You just need to use the methods on the `WindowExt` trait corresponding to your platform. Unfortunately docs.rs appears to only document the linux module: https://docs.rs/winit/0.16.0/winit/os/index.html But there is a module for each platform.
Looking at WindowExt for linux.. what function to use to get the Window handle?
I see. The problem is that there is much more Rust in the crates outside of the repo, and a little bit less C++ because of the test code. To address this issue, instead of counting the SLOCs, we can actually compile the firefox executable and count the lines of assembly output for the Rust and C++ parts. I believe this is the most accurate way to measure the C/C++ to Rust ratio. 
&gt;No you didn't *literally* say that, but you *strongly implied it*. I thought that the "so what you're saying" framing has already become a meme on the internet, and it's fun to see how it's being used here, instead of trying to actually understand my words, which, despite all possible implications, have an exact meaning - "your expectations do not match neither the license agreement nor the claims that the library has made, and there is no valid reason for you to feel betrayed". And unless you are willing to stop acting as if you are entitled to speak on behalf of the community and interpreting my words in the way it fits your framing, I have no desire to participate in the discussion any further.
I'm looking at an API that currently accepts `u8` as parameter, but only certain values of that `u8` actually make sense (it's bit depth in PNG decoder). I'd like to make a custom type that only allows the sensible values, with easy conversion to/from `u8`, where conversion from u8 may fail. I've tried to use the [newtype pattern](https://github.com/rust-unofficial/patterns/blob/master/patterns/newtype.md) but ran into the problem of [tryFrom being nightly-only](https://doc.rust-lang.org/std/convert/trait.TryFrom.html). Is there a way to do this on stable Rust? I'd prefer not to use external crates for such a simple thing, it's not a strict requirement.
I don't think it's so much the cost of copying strings around, more the hassle of constantly converting between UTF-8 and UTF-16 or identifying the correct encoding to use. When I first started with FFI, I remember wasting several days just trying to pass strings around. It sounds silly, but it's really frustrating to waste hours trying to figure out why your application is crashing because you've suddenly been passed a bunch of random garbage instead of a valid file path.
Depends on which protocol you're using. There's `get_xlib_window` and `get_wayland_surface` and also it looks like at least partial support for XCB.
My question is if anyone is aware of a Rust equivalent to [numpy's genfromtxt](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.genfromtxt.html)? Overall, I'm really only looking for something that can do the items in the list below: * specify the character of a comment line * skip # header lines * skip # footer lines * use any consecutive whitespace as a delimiter * use # number of lines from file * skip empty lines * specify columns to read I've taken a look at the CSV crate, and it really only supports the first item in the list based on the documentation. If supports others I'd be interested in seeing how. If turns out that there really isn't a crate that can do this yet, I'll probably just role my own most likely inefficient version of it to use at least with the ndarray crate.
&gt; Unfortunately docs.rs appears to only document the linux module: Docs.rs compiles for multiple platforms, so that you can see the documentation for the one you want. However the menu bar that (amongst other things) lets you choose which one has disappeared: https://github.com/onur/docs.rs/commit/4a9cb42b4c9ea8d24e0eaf51290419889117aa03
This is the correct solution. Don't follow the `transmute` suggestion unless you want me to be mad at you. There's `get_hwnd` on Windows, `get_nswindow` on macOS, `get_uiwindow` on iOS, `get_native_window` on Android... as was already mentioned, the method on Linux (or rather, non-macOS unixen) depends on whether X11 or Wayland is being used (ignore XCB stuff unless you know what it's for). You can check which protocol is in use with `is_x11`/`is_wayland` on `EventsLoopExt`, but since the window methods return an `Option` it's easier to rely on that instead. Note that you can cast `*mut c_void` to the correct type using `as` in all of these cases; if you need to use `transmute`, you're *usually* doing something wrong. In the future, feel free to open an issue on winit instead, since it's possible for me to miss reddit posts. Alternatively, you can just ping me here, which will give you the best of both worlds (you're unlikely to hear from anyone other than me if you open an issue).
I wondered where that one went. I know it still exists but I keep forgetting the URL syntax to view it for other platforms. After some looking I found it, put the full target triple right after the version number like so: https://docs.rs/winit/0.16.0/x86_64-pc-windows-msvc/winit/os/index.html
My apologies, I got a bit too excited.
I actually had a similar issue in a proprietary project recently. Unfortunately, I ended up just rolling my own code for it, which I realise isn't much help to you.
Just because `TryFrom`/`TryInto` is nightly doesn't mean you can't write inherent methods that do the exact same thing, or write your own traits.
Someone pointed out [this pattern](http://edunham.net/2016/04/11/plushie_rustacean_pattern.html) to me after I drew my lil Ferris doodle. With the help of my friend (well, they did most of the work since I can't sew) we pushed the pattern to its limits and made a big huggable Ferris! It was pretty fun to make! I'm pretty surprised how well the pattern held up to scaling. I'm gonna take a break from doing silly fanart stuff for a bit... see you guys on internals! =)
How does this differ from the [Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/)?
Since this would end up in external API I'm trying to make this as idiomatic as possible. Would implementing `MyType::from_u8(u8) -&gt; Result&lt;MyType, MyErrorType&gt;` on the object and deprecating it once tryFrom stabilizes a good idea?
https://play.rust-lang.org/?gist=6f86514cfee166f484bbf5aa6ef11baf&amp;version=nightly&amp;mode=debug&amp;edition=2015 &gt; error: Cannot use `#![feature(proc_macro)]` and `#![feature(custom_attribute)] at the same time --&gt; src/graph_merger/server.rs:5:30 | 5 | #![feature(custom_attribute, proc_macro, generators, await)] Code isn't accessible unfortunately :\ is there a specific rustup command / version I should try?
&gt; Would implementing `MyType::from_u8(u8) -&gt; Result&lt;MyType, MyErrorType&gt;` on the object and deprecating it once tryFrom stabilizes be a good idea? You could also include your own `TryFrom` trait (preferably with a slightly different name) and implement that. You can then have a feature flag that makes this trait a re-export of the "real" `TryFrom` for nightly users (and to sanity-check that the re-export works). Then, toss a little version detection magic into a build script, and you could have your library transparently switch over to the real `TryFrom` when it's stabilised. Or, yeah, you can also just have a `from_u8` method, and use that to implement `TryFrom` once it's stabilised. That's also completely fine.
The omnibus is mainly targeted at the nuts and bolts of FFI, so stuff like passing around strings and returning values, then providing simple examples for several languages. I'd think of it more as a reference where I can quickly look up the syntax for doing a particular thing. The Rust FFI Guide is more like *The Book* in that you have a detailed walkthrough of the various applications of FFI, useful techniques and patterns/anti-patterns. I also tend to mention extra details such as linking and how executables/functions work which, while not 100% necessary for doing basic FFI, is very important to know when you're designing an interface or knee deep in a debugger wondering why your code is segfaulting. So I'd say the two resources are designed to complement each other, where one is a handy cheat sheet for FFI and the other is a resource that teaches you the underlying principles.
Sounds like I've got another project to work on for Rust :) I also haven't done too much work in the field of text/file processing, so I'm sure this will be an interesting and educational adventure as well.
Awesome! I did know about SIMD and that compilers use it to improve performance. I didn't know it was called vectoring, sounds logical! Thanks. 
Soon you'll also be able to use an awesomeWM compatible DE written in rust: https://github.com/way-cooler/way-cooler
This is directed at both you and /u/shepmaster, it really feels like the FFI Omnibus and The Rust FFI Guide should be merged! The number of folks doing FFI work is small and having to flip between the two can be confusing. I forked a blog post into a [gist (in Python)](https://gist.github.com/seanjensengrey/f5d73bbdf22cfa1ad463) and then into [rust-jna-example (Java)](https://github.com/seanjensengrey/rust-jna-example). It is on my todo list to create some more examples, but to also show calling into Java, Python and Go *from* Rust. Both directions can benefit a system in terms of performance, maintainability and access to libraries. What do you think about merging the books and having roughly four sections * Low Level Access * Architecture (FFI Design, Best Practices, Debugging, etc) * &lt;Language/Runtime&gt; to Rust (embedding Rust into an existing system) * Rust to &lt;Language/Runtime&gt; (using existing libs) With an appendix on integrating Cargo and Rustc into build systems like Gradle,Maven, setup.py, etc.
&gt; there really isnt any way a human being can understand lifetimes/results/option in a practical way I wonder how many people who program with Rust are alians...
That sounds like a good breakdown. Having a "low level" chapter gives you the basic knowledge for doing stuff like compiling + linking, calling functions, passing around data, etc. Then once you understand the basics you can move onto more advanced topics (e.g. architecture). Working with managed code is actually fairly straightforward. Almost all GC'd languages provide a hook you can use for doing something whenever an object is due to be garbage collected. All you need to do is make sure all wrapper objects have a reference back to the things that own them (e.g. some base `Library` object) and then the GC will make sure things are free'd at the appropriate time. You could probably get away with the last two topics (managed code -&gt; Rust and Rust -&gt; managed code) by stepping through worked examples. People should have a good understanding of the theory from the first two sections, so we should then try to show them real code and the thinking that goes on behind it. I'd also be interested in hearing how you call managed code *from* Rust! The only real approaches I've seen are embedding an entire Python (or whatever) interpreter in your Rust application... Which sounds bloated and painful.
Is it bad that I want to learn to sew now? It looks awesome!
Yeah it's a bit sad that this thread got so much about the player and not the talks, both which were really great.
You could have a type variable AND associated type families.
I like the idea - this is a problem I happen to encounter quite a lot - but isn't the name _Status_ too general? And speaking of naming - is _splop_ an acronym of something? Also, have you considered making that `Status` an `enum` to allow `match`ing on it?
I would buy one of those. That's so cute!
Hey, have you guys settled on one project that you're going to try and develop the library at?
&gt; isn't the name Status too general? Mh... maybe? Any other idea? `itertools` has something very similar called `Position`. But I don't like the word *position* here, because it sounds like something very exact (like an index). Maybe `Region`? &gt; Also, have you considered making that `Status` an `enum` to allow `match`ing on it? Well... did you notice the special case where the iterator has only one element, which is the first and last one at the same time? I mean `enum Status { First, InBetween, Last }` would be awesome, but it doesn't reflect this special case. So I don't think it's really worth having an enum with `LastAndFirst`, `OnlyFirst`, and so on. Well, I guess [this is fine](https://docs.rs/itertools/0.7.8/itertools/enum.Position.html)... I might change it to an enum in the future :P &gt; is splop an acronym of something? I'm the master of project names! So the crate enables you to treat some iterations/repetitions of your loop in a *special* way, right? And then I typed "loop" and had a typo which made it "lop". I chuckled and was reminded of the "snek" meme. So the crate is for special loops, splop. Obviously. And I like the sound it makes. Splop. He.
I think `signalfd` is specific to Linux, but it's the sanest signal handling mechanism that I know of. It should also be pretty cool to use with tokio.
13 or 15 inch MacBook? Unlike a banana, a MacBook is not a standard unit of measurement.
Didn’t see a link in the article so here’s one https://crates.io/crates/signal-hook 
I'll take a look at petgraph thanks :) But the other solution seems to be what I'm looking for. How do you do a weak ref in this case without lifetime problems ?
Not at all! I was busy with `luminance` lately but I’ll need to settle on a decision quickly so that I can release `cheddar`, so thanks for pointing out! :)
Embedding managed runtimes in Rust is both dirty and necessary, exactly where a book is needed. * PyPy and uwsgi, http://doc.pypy.org/en/latest/embedding.html shows the extremely terse method that can be used to embed PyPy. * [Java Invocation API](https://docs.oracle.com/javase/10/docs/specs/jni/invocation.html) but this is very low level, I could see a whole section devoted to specific languages running on the JVM. * [Embedding Node in C/C++ Apps](https://github.com/ivere27/toby) Here is a [shared doc](https://docs.google.com/document/d/1SxHBdsuZYpoWNHFde_ytyhLt5Od4bMcVGCDItn9VzBk/edit?usp=sharing) we can use to build a ToC.
I know very little about kernel design, I was wondering if you have something that describes how drivers would be written for nebulet. And while on that topic, what if any compatibility could we come up with such that feL4, Redox, and nebulet might all be able to share driver implementations. Thanks!
It's not a tutorial, but the [examples](https://github.com/actix/examples/) are quite useful.
what is this thing? is the logo of rust an R plus a gear around it?
Ferris is Rust’s cute little crab mascot. 
so rust has both a logo and a mascot? what a cute luxury :)
Looks great! :)
&gt; Here is a shared doc we can use to build a ToC. I've requested edit access. &gt; Embedding managed runtimes in Rust is both dirty and necessary, exactly where a book is needed. I'm not sure how much detail we'll want to go into, just because it's really easy for that sort of information to go out of date (like /u/steveklabnik1 mentioned). Plus there's a good chance you'll get so bogged down in everything needed to embed a Python VM that we'll lose track of the main purpose. Here's [a worked example][1] I've written up for wrapping a C library (the library behind `file`, `libmagic`). I've also created [a tracking issue][2] on GitHub for topics I'd like to rewrite and tracking my current progress. [2]: https://github.com/Michael-F-Bryan/rust-ffi-guide/issues/64 [1]: https://s3.amazonaws.com/temp.michaelfbryan.com/wrap-libmagic/index.html
First, thank you for any documentation on such complicated topics, greatly appreciated! Want: When interfacing with language $FOO, show not only basic examples of passing ints and strings, but also 1) more complex things like structures and hashes/dicts/hashmaps that contain multiple different datatypes. 2) Passing these things from the Rust world to a) a non-GC language (e.g. C) and b) to GC languages (Python, Java, ...), to explain how to properly pass "memory control" from one language side to the other language, and why it is correct that way. I fear to leak a few bytes on every call or have silent memory corruption that bites much much later and becomes impossible to track down... 
I have looked into it and I noticed there is only one depth format and no stencil support. Is there a roadmap?
As I understand it, it is almost always the case that when something is created in a language, it should also be destroyed in the same language. I guess you can use `libc::malloc` if C is also using the system allocator, but it's risky if someone changed the C compiler to work differently. Most C libraries I've seen have this in mind - they have `free` functions you should use to free things you own once you've finished with them.
Have to say C++ is clearer here.
Is there anything like a compilation option or a linter or an LLVM plugin that can warn us when such things aren't optimized out?
15 inch.
Yeah stencil support must be added. I need to find a way how to add it in an elegant way.
For I second d I thought it was a MacBook for sale...
I'm still working on figuring out how drivers will work. I think I'm aiming for having drivers communicate with each other and with user applications through message channels. The drivers themselves request access to physical memory or io ports from the kernel though privileged ABIs. Driver compatibility between fel4, redox, and nebulet is probably not going to happen. All three have very different kernel interfaces.
Thank you sir! I'd like to ask for your suggestion about something I'm trying to do.. In [your Windows code](https://github.com/tomaka/winit/blob/047c67baf31cf9bcdc6f0275037bb3b56f2bd268/src/platform/windows/window.rs#L1067), the struct `WNDCLASSEXW` gets set to `hbrBackground: ptr::null_mut()` This causes the background to never appear for the Window. I would like to update the background to be some color. I've tried to do something like this, but it doesn't work: winuser::SetClassLongPtrW(hwnd, winuser::GCLP_HBRBACKGROUND, winuser::COLOR_WINDOW as isize); Any suggestions how to get this to work?
I figured it out, for anyone who wants to know, this worked for me: winuser::SetClassLongPtrW(hwnd, winuser::GCLP_HBRBACKGROUND, winuser::COLOR_WINDOW as isize); let mut RECT_COLOR = windef::RECT { left: 0, right: 200, top: 0, bottom: 240 }; winuser::InvalidateRect(hwnd, &amp;RECT_COLOR, 1); You need to know the dimensions of the window to invalidate it to repaint it. The problem with the dimensions is that winit takes LogicalSize as input, not physical size, so you make need to make an adjustment there..
Note that it is not possible to import the `smallstring` crate in the playground so I simulated it with a wrapper of `String`.
You have edit access. How runtimes are embedded would be stable enough and stay valid across that version, say how to embed Python 3.7, which will be used for years to come. &gt; Plus there's a good chance you'll get so bogged down in everything needed to embed a Python VM that we'll lose track of the main purpose. I anticipate that this will be a community effort with the instructions being a seed to get folks started. It can be expanded as people see fit. I thought the three of us could sketch out a ToC, decide where content from both projects would land and then create issues for the unfinished portions. Folks could pickup the issues to create the sample code and someone else could write the docs. How does that sound u/Michael-F-Bryan and u/shepmaster?
Under the topic of API design, I'd strongly recommend a section discouraging the use of lifetime parameters in any struct that models a foreign resource. It's very tempting to model the documented lifetime requirements of a C api by having resource structs borrow from the thing that creates them, but this places pretty severe restrictions no how the API can be used. For example, it makes it impossible to have any kind of "manager" struct that holds all data related to the foreign API, since that will naturally lead to a self-referential type which rust can't handle well. Instead, the resource structs should just use either Rc or Arc as appropriate to keep their parent alive.
Nope, I have no idea. It possibly has something to do with the existing code assuming you'll be handling all rendering (as opposed to Windows painting stuff). It would take some digging to figure out, I imagine. Anyway, `isize` isn't the right type for that. It's the same size, and always will be, but there's no reason not to favor [the types provided by `winapi`](https://github.com/retep998/winapi-rs/blob/3049a3b7dc7a100a56ff774a5ffb5bb426e0561a/src/um/winuser.rs#L5044). In the research I did, it also seems like you're supposed to use [`COLOR_WINDOW + 1`](https://msdn.microsoft.com/en-us/library/windows/desktop/ms633576(v=vs.85).aspx)... that didn't solve the problem, though. If you figure it out, I'd welcome a PR exposing this functionality through `WindowBuilderExt`/`WindowExt`.
I figured out how to get it to work. SetClassLongPtrW did change the background, however the form needed to be invalidated to repaint it with the new color. Here's my code: let dpi_factor = window.get_hidpi_factor(); let dimension = window.get_inner_size().unwrap().to_physical(dpi_factor); let rect_struct = windef::RECT { left: 0, right: dimension.width as i32, top: 0, bottom: dimension.height as i32 }; unsafe{ winuser::SetClassLongPtrW(hwnd, winuser::GCLP_HBRBACKGROUND, winuser::COLOR_WINDOW as isize); winuser::InvalidateRect(hwnd, &amp;rect_struct, 1); } 
Note though, if you want to add this into `WindowBuilderExt`, might as well just initialize `WNDCLASSEXW` `hbrBackground` with the color on `build()`?
I think that having semi-official way to integrate with other languages with examples probably outweighs the potentials downsides, since it will ease the pain for newcomers from other languages. Thanks for doing this.
There's a set of "ground up" pages on the official site: https://actix.rs/docs/getting-started/
Ah yes, forgot about those. I will have a look, thanks!
Thanks for pointing this out. We have contacted the author to correct it.
There's also [wtftw](https://github.com/Kintaro/wtftw).
Thanks for the response!
On Windows you can use OS-provided file locks to ensure that nobody changes the file under you. On other platforms, mandatory file locking is not a thing, so your only option is to do a `memcpy` and install a `SIGBUS` handler in case the file gets truncated in the meantime. So you will need to make a copy no matter what, and you might as well just use normal `read`/`write`. `mmap` is fantastic, but without `MAP_DENYWRITE` (which nobody supports), it is impossible to use safely, unless you know that no other process on the system can obtain access to the file, or you write the code that accesses the buffer in C and use a signal handler to `longjmp` out if a truncation occurs and you get `SIGBUS`. The alternative, of course, is to move the processing into a separate OS process, or just use `read` and `write`.
I always thought that ferris was kind of lame, until a group of Rustaceans invented the rust dance, where you kind of lock arms while making pinchy crab hands and spin in a circle, so now I'm a fan. Anyways, your Ferris is adorable :)
Hey there, this is the subreddit for the Rust Programming Language. To find people who are interested in playing the game Rust you should probably post in r/playrust 
Possibly idioms for writing rust that's meant to be exposed as c libraries? It's one of the features that drew me to rust instead of c (and I'm pretty new to rust) but I had lots of questions. How should I split my code? What should I name the crates? How to expose types? How to use rustycheddar? or bindgen and when you should not use them. It seems basic but I remember spending much time googling and not finding answers. Sorry for formatting, on mobile
but muh unsafe reee UB UB UB UB
vim wannabe editor.
I don't understand?
`actix-web` up until recently had a lot of unsafe blocks, many of which were arguably unnecessary. There was a thread about it not to long ago wherein a lot of people were being hilariously melodramatic about it and acting as though it were some kind of war crime. Nothing you need to worry about, really!
There are no lifetimes involved, you just use the `Rc` and `Weak` types.
Has there been an effort to remove them?
Potentially couldn't you have some level of documentation tiers? Like the compiler has tier 1,2,3 you could have Python 3.6.0 as tier 1 and python 2.7.6 as tier 2. Things can be promoted as you find maintainers. Tiering by version also helps reduce rot. So you say this document is the "Python 3 FFI doc" but only 2 subversions get tier 1 support?
A search for `unsafe {` currently gives me 33 results, whereas there were previously 100+.
Awesome. I'd prefer if that number was &lt;10, but I'm glad it's getting attention.
`signalfd` is [not as sane as you might hope](https://ldpreload.com/blog/signalfd-is-useless). Win32 doesn't have signals in general, but for the specific case of handling Ctrl-C in a console application, it's signal-like: you register a callback with the OS, and the OS invokes it when Ctrl-C is received. However (and this is the crucial thing), the OS creates *a new thread* in your process to execute the callback, so you can use the same concurrency-control primitives (mutexes, etc.) as you normally would. Contrast this with POSIX, where signal delivery interrupts an arbitrary existing thread, which may already have acquired locks, and therefore conventional concurrently-control primitives are useless. I wish Linux had a way to opt into a saner signal-handling system like that.
I've found RPL to be really difficult to absorb. It seems completely out of order to me. I've been working my way through the wonderfully clear Programming Rust, from Oreilly. I'm kind of shocked that they spent money getting RPL printed. 
Bananas vary in size a lot too.
So I don't know if you want to use a higher level api or not but the `rocket` crate has very good support for routing (its like express.js) every route is defined as a lambda function it would probably cut you code down to a quarter of what it currently is. Plus you get special functions that you would have to implement manually with the way you're currently going about it. 
The WG-CLI discussed this briefly but no one has had a chance to look into this. Glad other people are! See [rust-lang-nursery/cli-wg#27](https://github.com/rust-lang-nursery/cli-wg/issues/27) for our notes.
I was reading my copy today at work (got a lot of downtime usually so don't worry). I didn't realize how much I already know about the language until I skipped pretty quickly up to page 120. There were these little things that I had forgotten that made me say "oh, that's cool I can totally use that!" and other things that made me think "many that's unique to rust and totally amazing" basically had me remembering when I got into the pithy parts of python. 
Yeah, hyper, rocket, actix, and more all have routing libraries. This is primarily an exercise in learning Rust. :) 
So what I started with was programming the gpio on an rpi to flash leds to show me the status of my network (I run my own little lan in my college dorm which had spotty connection at best). It helped me learn a lot about gpio, electronics, rust, networking, and administration. Some of the things it did: Using multiple rgb leds with different blink rates(it's amazing how much info you can pack into a bunch of colors and flashing lights): Network speed/connection Pihole status (update pending, up, down, etc) Network load VPN status (have a VPN on the router) Server stats(all server processes on multiple devices monitored for up/down status) All in all a lot of fun. 
Oh my. I love this community
Of course it is. He's a really good developer. It's not a mystery why actix does so well in benchmarks. He just cared a little too much about performance to the partial detriment of soundness. Pretty ridiculous to have all these people who probably spend most of their time coding in something like Javascript come over to the Rust side and pretend like they care in the slightest about things like memory safety/type safety/e.t.c. if you ask me....
for a Rust project? TOML. Almost everyone uses TOML so it makes sense ro keep in consistent.
Also if you need discord PM Me
If you need my Discord Lemme know, PM or comment
Honestly `match` is pretty esoteric and powerful. The only language that has anything that comes close is probably Haskell. 
I'd stick with toml, in my experience yaml parsers aren't all equal. I've had trouble with kubernetes not understanding the output of a yaml formatter for instance.
I don't trust developers, I trust code. If code has a lot of unsafe blocks, that means there's a lot of code that isn't covered by the safety checks of the compiler. These blocks need to be manually checked, and with a highly concurrent project like a web framework, that's a difficult and error-prone task. I don't have the time to manually check 100 unsafe blocks, but 10 is potentially doable. And I'm sure many others feel the same way. What worries me the most is that, allegedly, there's no justification in the code for many of the unsafe blocks. I haven't looked at the code myself, but it's on my to-do list as I consider it for a few projects I'm working on.
As a human I find toml immensely easier to understand, even before things like parsing library quality and ecosystem use come into it. 
But do they chant "One mutable reference at a time!"?
From what I've seen this doesn't often become an issue because most "interesting" types will have destructors that only the original language can call. This means you'll need to expose a `foo_destroy()` method, neatly sidestepping the allocator mismatch problem.
http://intorust.com/ may be a good place to start. There's a [udemy](https://www.udemy.com/rust-lang/) course but I don't know anything about it's contents.
 * In the Rust world, you should use TOML. It's what everyone uses and it's consistent. * At work I personally use JSON, because we use JSON for other config files there. Everyone knows JSON. As easy as TOML is, it's yet another configuration type. * For my own stuff I use whatever I want.
Seems mostly focused on the concepts of Rust and less an actual course teaching the ins and outs of the language like syntax etc.
This is a silly comment. I work in computer security, my background was closer to systems, then moving to web services, then forensics. Never touched JS. It is fair to say that understanding memory safety is at least one component of my job, and at one point was the primary focus (when I was first getting into security and did vuln research and exploit dev). Don't speak for others like this, it's *really* condescending. You don't know who any of us are. You shouldn't presume to understand things better than us. People come to rust because rust is marketed as memory safe. If code is not memory safe it is not meeting a basic, marketed premise of the language. Using unsafe to the extent that actix did was a mistake. It's a cool library, glad it's being worked on, I have a lot of faith in the developer's skills. That doesn't change anything. Calling it melodramatic that people, gasp, do not want to use unsafe libraries in a language that touts safety is... ridiculous.
But spawning a thread is async safe on Linux (not specified by POSIX) so this is strictly more powerful. The reason Windows can always just create a new thread without downside is because Windows has no fork; multithreading really gets in the way of forking so all API's are super careful to not give you multithreading without your explicitly asking for it.
I think your `meet` function wants borrow references to your Person structs: https://play.rust-lang.org/?gist=af4d6c59531e63c3ac9463535b5b9d67&amp;version=stable&amp;mode=debug&amp;edition=2015 
You can do this instead fn meet&lt;T: Talk&gt;(a: &amp;T, b: &amp;T)
Is it sad that I saw this and instantly wanted it because it looks like a coloring book?
Thanks. I think the reason I was confused is because the compiler made it seem like the problem was with the trait implementation, whereas usually when the caller passes the wrong level of access (self, &amp;self and &amp;mut self), the compiler complains about that instead. I didn't realize a &amp;T and T were two different types completely, so a fn foo&lt;T: Trait&gt;(a: T) would accept a &amp;T if &amp;T satisfies the trait, whereas normally a &amp;T couldn't pass as just a T in a fn foo&lt;T&gt;(a: T).
damn you, mine is still on the way :(
Unfortunately, yes, because `Cow` relies on `str`'s implementation of `ToOwned`
First 5 Players who joint, i thank you, Looking for more, Not here for money, but to give experience!
YAML is... [Not all that great](https://arp242.net/weblog/yaml_probably_not_so_great_after_all.html).
Does the [`write!`](https://doc.rust-lang.org/std/macro.write.html) macro flush the buffer it writes to?
Ocaml, SML, Prolog, Scala, F#, Erlang
No.
and i have to wait, 2 -3 weeks :(
„Programming Rust“ is really fantastic!
Yes! I am up to Ch 7 Error Handling, and I'm really enjoying myself! I think there should be more long-form Rust literature like books. About all sorts of different techniques and crates and such. The more the better! There's concepts in Programming Rust that totally click for me that didn't in RPL, and I'm sure vice versa is true for others.
yeah, a very good series to learn rust is from Tensor on youtube. [https://www.youtube.com/watch?v=EYqceb2AnkU&amp;list=PLJbE2Yu2zumDF6BX6\_RdPisRVHgzV02NW](https://www.youtube.com/watch?v=EYqceb2AnkU&amp;list=PLJbE2Yu2zumDF6BX6_RdPisRVHgzV02NW) he has stuff about fundamentals and little projects. have fun and a nice day dude :) happy greetings
is there some trait like `Into&lt;T&gt;` we can use to accept either `&amp;T` or `T`, kind of like how we can type this to accept either a `str` or a `String`: `fn str_or_string(s: impl AsRef&lt;str&gt;) {`fn str_or_string(s: impl AsRef&lt;str&gt;) { println!("{}", s.as_ref()); }` 
This article kind of shows the problem with "anything that isn't C" in how poorly defined it is; it isn't just signals by the way another fun one is the interaction between multithreads and forks were similar restrictions apply after forking from a multi-threaded program. Rust has no concept of "async-safety" and it should probably be a marker trait that is stuck on functions and automatically derived on composite functions or something but there's actually a semantics bug in the standard library. [this function](https://doc.rust-lang.org/std/os/unix/process/trait.CommandExt.html#tymethod.before_exec) is marked as safe due to this but is actually unsafe and the documentation does not do it justice; calling any non async-safe function in a multi-threaded program in that is technically undefined behaviour as far as POSIX goes but in practice a deadlock is mostly what is going to come over you. Rust does not go out of its way to define what is and what isn't async safe or stabilize it in any way. Also one of the reasons why CPython still has a global interprepeter lock or why OCaml has a similar thing (you can turn it off but it makes garbage collection so much slower it's not worth it). 
you got crabs?
Hello I didn't really pay attention to the working group and didn't know about the needs. But I definitely want the crate to work well, so if you have some specific requirements in mind, I'll be glad to hear them or to cooperate in some way :-).
I believe the other reason is that signals are older than threads, but I don't know for sure.
Maybe, I dunno. It’s hard enough to find anyone that wants to work on docs, so that feels a bit moot to me, but maybe I’m pessimistic.
Yeah they are, the article says so. Threads are honestly not that useful on POSIX and their mere existence complicates a lot of things you now need to check for and there is sadly no function which just says "is this process multi-threaded?" Threads are a Windows-ism that were needed there due to the lack of fork and the ironic part is that a lot of the newer thread-models in say Go and Rust basically go back to how multi-processing has always went with channels which are basically using IPC again. Multithreading gives you all that synchronization and lack of data-races for free where the kernel keeps it apart from you. Also a raw libc fork system call on Linux about 100 times as fast as spawning a new thread in Rust because ironically Rust needs to do a lot of things to make it save again. So yes, colour me unconvinced of the benefits of threads. You can even on POSIX unlike on windows just share memory between different processes
You may enjoy: https://hello-rust.show
I see Rust as a data crunching language, so doing the heavy lifting in Rust and then passing results from/to other languages. So really complex data maybe not, but at least structures composed of ints, strings, tuples, hashmaps etc. should be passable, either once/oneway or both ways over language borders? Maybe it makes sense to show examples for every language, what is reasonable and what not? 
A lot of folks have already stated it, but toml is a much better standard than yaml. The spec is much simpler and has fewer issues. The only problem is that the spec has yet to reach a 1.0, but supposedly the 1.0 spec will be backwards compatible with the existing spec so it shouldn't matter.
Awesome! Thank you very much. This looks like what I want.
Great, thanks I'll take a look. Looks like the stuff I want.
Short answer: * `rand` is for random number generation. * `simdnoise` is for generating *graphical* noise that can be used for e.g. procedural texture generation. The long answer is more involved, but if you look up things like "perlin noise" it should give you an idea of what `simdnoise` is for. Put another way: `simdnoise` is *not* for random number generation--it's purpose is much more niche.
Indeed I lost it in many rounds of edits. It should be there now, thanks for pointing it out.
You can do this, but you need to ask the other language to provide you with the space to put your data, at least that's my understanding
So is the paperback book different from the official book you can read for free on the website?
I think I read that before, but preferred to forget about it. So, in summary: * `signalfd` solves the obvious problem of "I can't use arbitrary functions in a signal handler" by integrating into the normal control flow of the program, at least if you use a program based on an epoll or similar loop. * `signalfd` requires masking signals, which requires extra code when spawning processes, but that problem can be solved. * `signalfd` still behaves racy when receiving multiple signals before the first one gets handled, that problem cannot be easily solved. (However, systemd is based in signalfd and should have the SIGCHLD problem from the article you linked, but it seems it solved it somehow).
From my understanding. the content is the same. I am just repeating what I've heard though, so there's a small chance I'm incorrect.
Okay. That’s still cool. I expected it to be the same, but wasn’t sure after hearing some of the comments in this thread.
Interesting! But it's even worse. Looking at your [handler](https://github.com/vorner/signal-hook/blob/fecac5f56e191d80ce2416d0d6324377bfb998fc/src/lib.rs#L228), it calls `catch_unwind`, which can return a `Box&lt;Any + Send + 'static&gt;`...oops. And then you call `eprintln!`, which might allocate and/or panic as well... I can't see a way where signal handlers can panic in a sound way. Which even further severely limits what you can do in them. So, if we start somewhere, maybe it would be better to just provide a few functions, which you thoroughly check that they never panic, like "set a flag", "write to a fd", or "quit the program"? I'd also expect a library like this to have safe abstractions to masking signals.
FYI JSON isnt meant for human editable configuration and shouldnt be used there where possible
There was recently a discussion thread either in Reddit or in the users or internals forum about a lifetime problem where the \`for\` syntax didn't provide enough expressibility for some usecase, and people were talking about future extensions in the type system; higher-ranked and kinded types etc. (For the record, it wasn't [https://users.rust-lang.org/t/expressing-hrtb-like-bound-on-generic-struct/18081](https://users.rust-lang.org/t/expressing-hrtb-like-bound-on-generic-struct/18081) ) I can't find it to save my life! Does anybody have a clue (or preferably a link) which discussion I'm looking for?
you're welcome and it's good if i can help.
It's only sad if you never color in the cover.
Toml is very nice but I dislike the fact that same thing can be expressed in multiple ways. Json seems a bit more clear. I dislike yaml at all.
If you `impl&lt;'a, T: Talk&gt; Talk for &amp;'a Talk { ... }`, `Talk` will be usable behind any number of references.
Actix-web currently contains [rather irresponsible use of unsafe blocks](https://github.com/actix/actix-web/issues/289) that, according to one of the developers, [may take a while to resolve and cause an API change](https://github.com/actix/actix-web/issues/289#issuecomment-398691401). Even if you do not run into the issues caused by that, you will have to change your code to accommodate the new API very soon. So don't learn actix-web just yet. Either come back in a month or so or try another framework, e.g. Rocket.
Didn't know this type, thank you
Huh, after searching for it for over an hour, I found it right after! [https://www.reddit.com/r/rust/comments/8hrjy6/could\_someone\_help\_me\_remove\_this\_static\_lifetime/](https://www.reddit.com/r/rust/comments/8hrjy6/could_someone_help_me_remove_this_static_lifetime/)
Up to 7 players!
Exactly, use xml instead :-D. It has comments.
Suppose T to be a non-clone and non-copy type. Can I anyhow move an element out of an `[T; _]`, while replacing it by another value? like so: `struct A(i32);` `let arr = [A(1), A(2), A(3)];` `let x = arr.replace(1, A(5));` `assert_eq!(arr, [A(1), A(5), A(3)]);` `assert_eq!(x, A(2));`
Turns out there is a better way than newtype pattern - [enum with custom discriminant values](https://doc.rust-lang.org/reference/items/enumerations.html#custom-discriminant-values-for-field-less-enumerations). This plus custom `from_u8` method is [exactly what png crate uses](https://github.com/PistonDevelopers/image-png/blob/master/src/filter.rs). Thanks for the help, much appreciated!
There's [`std::mem::swap`](https://doc.rust-lang.org/std/mem/fn.swap.html), which'll let you do this: struct A(i32); let mut arr = [A(1), A(2), A(3)]; let mut x = A(5); mem::swap(&amp;mut x, &amp;mut arr[1]); assert_eq!(arr, [A(1), A(5), A(3)]); assert_eq!(x, A(2)); 
While PR works better for you, RPL works better for other people. Different people want to learn and discover in different ways. For example some might want to learn the basic foundations early on and then gradually build more complex layers, while others might prefer to start with a larger example that works and then gradually go down into the details. And it is really a good thing that PR and RPL are not redundant copies but go about teaching Rust in different ways.
Not that I know of. Missed optimizations are typically very hard to report, as they may fail after many optimization passes ran which transformed the original input into something having so little resemblance that formulating the feedback into something human intelligible is nigh impossible (not accounting for the slow-down tracking such information would incur).
Thanks a lot for Ferris' channel link.
&gt; human editable &gt; XML Pick one 
Unfortuantely Node chose `package.json` which set a strong precedent for json-as-config, regardless of what any of us may think about that. 
This is why I’m glad we have both books, with more coming!
To be clear, the content is 100% identical. No starch gave us their edits under the same license. Very kind of them. The next release will make this more clear on the main page covering all the various versions of the book; there’s just a small mismatch at the moment since the release cycles didn’t line up.
:D :D :D
I guess I'm an outlier; I really prefer YAML. *Especially* if the config file needs any structured data.
For Vec::with_capacity(0) you can also write Vec::new() because new also does not reallocate. Furthermore, you should try to avoid using unwrap unless you know it will never panic. In url_for you can use instead of Some(uri.scheme_part() .unwrap().clone()) the cloned method if your goal is to convert an Option&lt;&amp;T&gt; to an Option&lt;T&gt;, so it would be uri.scheme_part().cloned() and uri.authority_part().cloned(). However, you should match/check on those to check if those are also Some values and not None, else it will panic. Result types can be converted to Option types with ok. Some(PathAndQuery::from_str(&amp;pq).unwrap()) becomes PathAndQuery::from_str(&amp;pq).ok(). Also remove the println!("hi") before you forget it. As for the builder pattern, you're moving the contents out of the fields. You can avoid this replacing the content with something new (mem::replace(field, T::new()) or you need to use clone or you create a new variable, put the field value into it and return it.
Once I've started to get the hang of a new language my first major project tends to be along the lines of writing a parser and compiler/interpreter/vm for a toy programming language (usually something like lisp or gcode because they're conceptually simple). I've found Rust is particularly good for doing this sort of thing where you've got complex data structures (e.g. an AST or HIR), and need a solid error handling story. You may also want to look into [Chip-8], a system which was actually designed with writing emulators for it in mind. It's also not too difficult to write an emulator for a RISC machine (e.g. ARM) if you want to, with the added bonus that you could (in theory) compile a Rust program and then run it on your emulator. Once you have a basic model for registers and instructions it's just a case of implementing the logic behind each instruction, which is more tedious than difficult. I'd actually argue that Rust is nicer than C for doing this sort of low level programming. [Chip-8]: http://www.multigesture.net/articles/how-to-write-an-emulator-chip-8-interpreter/
&gt; You are wrong about that. Type safety [...]. No, really. When a language/toolchain guarantees Type Safety, what they really mean is that *the produced binary* is guaranteed to enforce the Type Safety (hopefully, with as little memory overhead as possible) and this requires that said binary first enforces Memory Safety, as otherwise all bets are off. This may be a colloquial use, but that's the typical usage. --- &gt; Similarly, the "unsafe" block doesn't mean that anything wrapped in it automatically becomes unsafe, it means that a compiler won't bother to check the block with its type system. Sure. I never pretended otherwise. By "Unsafe Rust" we^1 do not mean "any Rust code in an `unsafe` block", we mean "Rust code which HAS to be called in an `unsafe` block"; and such code does not have formal semantics today, which the RustBelt project seek to correct. ^1 *We as in "most people in the Rust community as far as I know". I cannot recall `unsafe` Rust being used otherwise, but my memory is notoriously unreliable.* --- &gt; And Undefined behaviour doesn't mean that anything can happen, it just means that the result of evaluation of an UB expression is not guaranteed to be consistent across all possible versions of all possible language compilers across time. And this is not the same as "anything can happen". This is too naive an opinion, and unfortunately a dangerous one. Undefined Behavior, by definition, does not specify *any* behavior, so at a theoretical level it really means *anything can happen*. This even includes damages to your hardware (at least, in old computers, tight infinite loops could literally set the CPU on fire). That's how flexible the definition is. &gt; If you only have one version (or a subset of versions, say "stable") of a particular compiler and an expression that is supposed to be evaluated a certain way actually evaluates that way (which could be proved with extensive testing, including tests that deal with type properties), then this expression is no longer UB expression. I wish it were the case. Unfortunately, things are not as rosy, though slightly better in Rust than in C or C++. # Builds reproducibility The first issue is that toolchains typically make no guarantee that builds are reproducible; that is, given the same sources and same compiling options, that the same binary is produced bit-for-bit. 1. Compilers make no such guarantee; a typical issue is using an unstable iteration, where unstability is produced by hashing/sorting pointers or using randomized algorithms (pattern defeating sorts, for example). In rustc, randomized hash seeds are used in hash tables. 2. Linkers, too, make no such guarantee; most notably the order in which object files are passed to the linker may have great influence here. 3. Incremental and Full builds may produce different results, and incremental builds from different "touched" files may also produce different results. 4. The same toolchain version, on different platforms, may also behave slightly differently. An obvious difference being 32-bits vs 64-bits, but even a perfectly identical compiler binary dynamically linked to a different version of libc may produce different results, or a perfectly identically statically linked compiler binary may be unduly influenced by OS calls. # Cross-Binary reproducibility Another issue is that two binaries (libraries or executable) calling the same function may not actually call *exactly* the same function. As surprising as it may be. 1. C++ only: a different header inclusion order may result in two different Translation Units calling resolving overloads differently. 2. A different call site may result in a different translation, due to inlining. 3. Test-specific compiler options result in a different binary. Any use of `#[cfg(test)]` or equivalent is a liability in this regard. 4. A different linking order may result in two different binaries linking a different version of a weak symbol (as typically, the linker picks the first one). C++ is more susceptible to the issue due to its unprincipled generics, however even rustc is susceptible to the issue: - when linking in `no_mangle` functions, - when bugs in the selection of compilation parameters participating in the mangled hash leave out parameters which influence the code generation. 5. A different loading order (when using DLLs) may result in two different executions linking a different version of an external symbol; similar to the previous one, but more insidious. 6. And of course, there's the whole host of filesystem issues. From experience, I do not recommend using a NAS to share files between Windows and Linux machines. I've regularly had cases where the change (made on Windows) was not seen from the Linux machines. And of course any build-system based on file timestamps also has such issues. Not strictly Undefined Behavior (way outside the language); but extremely confusing when two distinct binaries produced by the same run of the build command do not include the same version of an inline function. The combination of the above means that: 1. Test binaries may not be testing the code that ends up in the final (production) binary. 2. Even testing the final binary may not actually exercise the same code, unless this binary is completely static (which is never the case on Windows, if I recall correctly). # Data sensibility Another issue with Undefined Behavior is that it may only manifest in edge cases, and testing is rarely (if ever) extensive enough to actually test all edge cases. 1. For example, imagine a hashing function for surnames which unconditionally hashes the first 4 bytes, before checking the length. Great speed-up. And nobody has surnames less than 3 characters (assuming NUL-terminated strings), right? Until Mr. Li uses the application, that is. 2. On the other hand, long input can also be an issue, such as buffer overflows. 3. Use-after-free on stack variables is also interesting in that regard, as the function ends up reading whatever its predecessor left on the stack. This may be completely deterministic when running tests, but random garbage in production. 4. And of course, there's undefined behavior at the CPU level. For example, the result of calling `popcnt` on 0 is undefined (note: `popcnt` calls the number of 1 bits in a 32-bits integer). In practice, the processor doesn't touch whatever is already sitting in the register. Which means that calling `popcnt` may actually result in 0, or 2048, when the compiler is well within its rights to assume that it can only be a number between 1 and 32. Once again, in tests whatever is in the register may be deterministic, and harmless, but in production... All of this essentially means that all the tests in the world cannot save you from Undefined Behavior. Nope. Not a chance. Calling `popcntl` (the 64-bits version) on the result of hashing a 64-bits integers has a 1/2^64 chance of triggering Undefined Behavior assuming a perfectly distributed hash function; the heat death of the universe will come before you have finished fuzzing this. # Time sensibility Even more insidious is any code depending on *timing*. This can manifest both in single-threaded and multi-threaded code. 1. Single-threaded: imagine a service which asynchronously sends a request to two servers. On reply from server A: use context to do some processing, and on reply from server B: terminate processing and free context. If in your tests you use a single "dummy" server, and replies always come A then B, you won't notice the issue. When in production B comes back before A... (and interestingly, your tests had 100% code coverage). 2. Multi-threaded: there are so many issues it's not even fun. Timing issues abound. And data-races pile on. I've coded my fair share of multi-threaded code, I even dabble enough in lock-free/wait-free code to be dangerous. It's impossible to prove the correctness of lock-free/wait-free code by testing... my latest attempt at stress-testing a lock-free algorithm actually ended up uncovering [a bug in gcc code generation](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=86314) instead of uncovering any issue in my own code oO 
I wrote this over three nights while trekking through the Himalayas a couple months ago! While the crate is fully standalone, I wrote it as a lower-level layer within [nannou](https://github.com/nannou-org/nannou)'s laser control stack. Seeing as we didn't have an actual Ether Dream DAC to use for testing up in the mountains, I also created a DAC emulator in order to test the protocol implementation best I could. To my amazement, when we arrived in Spain to collaborate with our friends [playmodes](http://www.playmodes.com/) and plugged into their DAC for the first time to test, everything just worked! At the time they were currently searching for a C/C++ solution for Ether Dream control, however were running into issues with each library they came across: one would consistently underflow and the stream would drop out, another only worked on one or two platforms, another could not connect to more than one DAC - each of these have been under development for 5+ years. On the other hand, ours seemed to have no trouble with any of these issues! I'd say for sure a testament to rust's reliability and `std::net` module rather than coding ability. I'm hoping to spend another day soon adding a `ffi` module so that the library is as easily accessible from C as it is Rust, as it seems the current state of affairs needs improvement. I'd also like to acknowledge the existing [etherdream](https://crates.io/crates/etherdream) by echelon - it seems to work nicely out of the box for connecting to a single DAC and the examples work as described! That said, looking through the code, it was structured quite differently to how I was aiming to approach the crate. I was aiming for a simpler, lower-level API that did not bake in the concept of a "frame", but rather provided full access to the Stream itself so that a higher-level API could be easily built on top. I knew that I wanted to support "n"-number of DACs out of the box rather than just one. I also found the lack of adherence to the rust style guide a little off-putting. I knew the crate would only take a couple days, so rather than spending the time negotiating these changes with the author I thought I'd just forge ahead and get started.
True, thats why I said where possible. In node you also wanna install using `npm i -–save-dev` but yeah you cant always avoid it
&gt; rust dance http://www.salutcestcool.com/3/crabe/
What is an Ether Dream Laser DAC? You provide no references... :-p
I like Toml, but I have some issues with it. For one that its not possible to mix types in an array. This makes it incompatible with json/yaml structs. So switching from json to toml is difficult. Also from a usability point, the number of allowed characters in bare keys is pretty limited. The only special characters allowed in bare keys are '_' and '-'. I could imagine that some more would be nice to have without switching to quoted keys.
Same for me. YAML just feels the most natural to write and read
&gt; I wrote this over three nights while trekking through the Himalayas a couple months ago! I am surprised you had the energy to do so; I can't begin to imagine how tiring trekking through the Himalayas can be!
Oh damn, good point :) The [Ether Dream DAC](https://ether-dream.com/) is a networked DAC for submitting laser data to a laser projector. The DAC broadcast's its availability over the network allowing the user to automatically detect it, establish a TCP stream and begin communicating. The DAC itself outputs the laser data via an ancient, DB-25 ILDA (International Laser Display Association) connector - an unnecessarily huge port, but has been the standard interface for laser projectors in the industry since forever. For reference, we use these sorts of laser projectors for live AV shows and installations - [here's an installation we did last year called LATTICE](https://www.youtube.com/watch?v=xIfZp3idOtQ).
Instead of starting my own projects that I'd have to maintain later I prefer to contribute to existing open-source projects that I consider interesting and/or valuable. For example, there's the next-generation revision control system called [Pijul](https://pijul.org/) written in Rust. You can read [why existing systems don't cut it](https://jneem.github.io/merging/) and [how pijul solves it](https://jneem.github.io/pijul/). [This blog](https://pijul.org/posts/2018-04-21-pijul-0.10/) lists some things you can improve without a math background. Contributing to [nannou](https://github.com/nannou-org/nannou) is probably a bit over your head at this point, but you can build something cool with it. Just look up interesting Rust projects or popular crates and see what catches your fancy. And there are like five different web frameworks in Rust, so you could grab e.g. Rocket and build your very own web application backend. Although if you're interested in actix-web [you'd better wait for a month or so](https://www.reddit.com/r/rust/comments/8v3p2a/resources_to_understand_actixweb/e1ley2l/).
I guess it depends how much of a rush you're in! We spent between 6-8 hours a day trekking and did The Annapurna Circuit (stopping by Lake Tekapo) in ~3 weeks, stopping for a day or two at a couple of the small towns when we liked them too much to leave so soon. You end up with a surprising amount of time each afternoon/night at the guest houses relaxing with some tasty hot drink (I have to recommend trying the Mustang Coffee ;)) - I found it to be an almost perfect state of mind for coding or writing! Your blood is pumping after spending the day hiking through awesome landscapes, looking at some of the craziest terrain generation you've ever seen, getting inspired and thinking through problems during the day and hacking on them at night in the guest room between meeting and chatting with other trekkers. Will definitely go back and highly recommend!
[Windows question] How do I embed an application manifest in *some* of the final executables? I have a library that interacts Windows Services for which Administrator rights are required. It comes with some executables to implement features of the library. I can manually run the executables with Administrator rights (from an elevated prompt) but it would be nice if Windows UAC prompted the user to run the executable elevated for me. ---- I found that as long as I can pass `/MANIFEST:embed /MANIFESTUAC:level="requireAdministrator" uiAccess="false"` to the visual studio linker I get the desired output. I discovered I can do so through `RUSTFLAGS` however this will cause *all* generated executables to contain this manifest including build scripts and tests which is obviously not desired. I only want these manifest in specific binaries. Further I cannot even compile the project with the appropriate `RUSTFLAGS` set because it'll also apply to the winapi build script which then fails to run because it now too requires Administrator. The final workaround I found was to use an explicit `--target` which seems to ignore the `RUSTFLAGS` for t he build scripts and tests but this isn't very desired... Can I provide `RUSTFLAGS` for only specific binaries in my Cargo.toml? If not is there any way to achieve this manifest from eg. a build script? Thanks in advance.
Which books are which learning styles in your example? I'm the latter kinda person and want to be sure to get the right one 
With that, sometimes it's just being exposed to things multiple times.
&gt; I didn't realize a &amp;T and T were two different types completely Yeah this is quite fundamental. There's all kinds of things that rely on that, for example `&amp;T` implements `Copy` even if `T` doesn't. And of course `&amp;mut T` can *never* implement `Copy`, even if `T` does.
I prefer binary config files edited and created by a dedicated tool, but if I had to choose between those two: TOML. My main pain point with traditional *"config files"* is that they are not at all discoverable and easy to fuck up. But again, if I must, I'd pick TOML between those two, because YAML is too full of anti-features that are at best annoying and at worst dangerous.
I'm not saying it's impossible, but I recommend against it. First, you would have to overcome the following obstacles: 1) An unsupported chip probably also means an undocumented chip. I e, you'd have to reverse engineer it to figure out what commands to send to the chip. 2) Learn the basics of Linux and driver development in general. 3) Learn how the Linux v4l2 subsystem works in detail. 4) How to write Rust kernel modules when the rest of the kernel is written in C. Finally, if you want your driver to go upstream - i e, be part of the Linux kernel itself - and thus help every other person out there with the same chip, C is a must. They won't accept drivers written in other languages. 
May I suggent ron? https://crates.io/crates/ron If you only use for rust project, your config struct can direct serialize and deserilize.
XML or HOCON (JSON + comments + basic types). YAML would be nice but it is nearly unparsable. TOML flattens structures to INI-like files which I see no reason for.
Here's some relevant Actix [documentation](https://doc.rust-lang.org/book/second-edition/ch19-01-unsafe-rust.html).
I will say read both books. I have read full official book but sometimes Programming Rust makes concepts more clear.
Are you going to do a tutorial post to guide us step by step how to build desktop app with Rust and Elm? It'll be nice of you.
Rocket requires nightly, which brings another set of problems.
This makes sense. Thanks!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [look at what arrived today](https://www.reddit.com/r/rustjerk/comments/8v9vxg/look_at_what_arrived_today/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
That was a simplistic example and I don't think the two books fit exactly into it, but my impression is that PR is more like my first case and TRPL is more like the latter. You don't have to take my word for it, TRPL is available for online viewing and you can check it out any time!
I don't think what it's meant for really matters tbh. People don't find it weird if it's in use as a config file, people find it no less readable than most alternatives, and everyone gets it. Even those who hate JSON will still have no issue with it. It's the format that everyone knows.
/r/playrust
[ggez](https://github.com/ggez/ggez) allows you to do this with `Image::from_rgba()`.
/r/playrust
Thats not the point. JSON doesnt allow for comments and trailing commas etc. and was designed specifically for Computer-to-computer communication. This is a clear case of 'if you have a hammer, ...'
I think these aren't pythons, they're underwater (there's a sea star and a sea horse)
The cover is so cute I want to buy the book just for that reason
That works with TOML (and probably a ton of others) too, unless I'm missing something. I do this in a small Rust project: fn read_config() -&gt; Result&lt;Config&gt; { let mut config_str = String::new(); let mut file = File::open(CONFIG_FILE).map_err(|e| format!("{}: {}", CONFIG_FILE, e.to_string() ))?; file.read_to_string(&amp;mut config_str)?; toml::from_str(&amp;config_str).map_err(From::from) }
The config files I made with yaml look like the config files I made with toml. I use yaml because it didn't fail me where toml did in other languages. In Rust, the story may be different, but there's not good reason for me to change, especially just because a token group of programmers (not even close to "almost everyone") is using TOML. 
&gt; TOML flattens structures to INI-like files which I see no reason for It's for readability and familiarity. Personally, I find it easier to look for a heading than an arbitrarily nested map key, and I really like reading through `Cargo.toml` for Rust as compared to `package.json` for Node.js.
Yeah, if I could eliminate the `{}`, I think I would like reading `Config.toml` files a lot more.
The experience reports I've read of YAML have always been... dreadful. The most common complaint being that various libraries (especially across languages) always interpreted the file in subtly different ways. Do you YAML with a schema to alleviate this issue?
&gt; I prefer binary config files edited and created by a dedicated tool About, hum, 6 years ago, I was part of a "sub" team in charge of implementing a new application. The application would be a router, with a projected ~500 links and ~50,000 routes configured between them. As we debated among the team on which format to choose for the configuration file, I heard everything from xml, to json, going through yaml. And I shuddered. I am so very glad that my teammates at the time went with me when I argued that SQLite would be a much superior choice for such a complex beast! And it really was; I can't remember the number of times where a column constraint or relational constraint (which were maintaining as tight as possible) nipped a bug in the making by failing a test.
Discarding a good solution because of ideology is just silly though. Again, everyone knows JSON. Even those on the fringes of programming, like designers and IT managers. Even in lesser areas. It makes sense to use a format that everyone gets. and in practice it is human readable (or no worse than say XML).
Admittedly, most of my experience with YAML is writing Ansible playbooks, not working with parsers myself. If I had major issues working with parsers like you're describing, I might fall back to TOML or some other format just for my own sanity. But I still think I'd prefer the format itself.
http://knowyourmeme.com/memes/banana-for-scale
It is pretty true that because the standard tools use toml for a format that it's the first one people trend towards. One nice thing with Serde is that as long as your config struct is Deserializable you can create it from pretty much whatever you want! You are one of the few people make those specific arguments personally, and they are personally non-factors for me.
Thankfully, the linked library StrictYAML is brilliant and resolves much of the issues with YAML in a readable way I find TOML lacks. 
i had a look through your comments. looks like you get downvoted and called troll quite a bit, just sayin
I like to keep things consistent, so if I'd be working on a rust project it would be TOML since its pretty nice. At work I would pick YAML since we already use it for docker compose, travis ci configurations, and ansible. JSON isn't really a configuration format since it doesn't allow for comments, IMHO.
I've been working on this on-and-off for about a month, and mentioned it in the "What are you working on this week" threads. It's a library that provides functions for generating usual time-dependent point processes (I think I'll make a module for higher-dimensional processes), spun off from some code I wrote for a statistics project. For now, the functions generate process trajectories on a fixed-length time interval (and thus with a random number of events), but I'm thinking of adding event generators implementing the \`Iterator\` trait.
The reason why you cannot use the builder pattern is because your `into_router()` method consumes `self`, and each method of the builder returns `&amp;mut Self`, which cannot be consumed. To fix it, you would need to either: 1. Make your builder methods return `Self` instead. 2. Change `into_builder()` to not consume `self` and clone the fields instead. See this [helpful guide on consuming and non-consuming builders](https://doc.rust-lang.org/1.0.0/style/ownership/builders.html). In your particular situation, I think that option 1 might be the best for you, considering how you intend to use `RouteBuilder` in your example.
Crap, I missed that one. I'll just have to do something about that :-|. I do provide these functions, but I need the „backend“ registration and when it exists, there's not much downside to making it public ‒ it needs to be unsafe anyway. Masking signals ‒ it might be the next step. But honestly, I didn't find a use case for that yet. Sure, if you're juggling the low-level functions from libc, they might come handy. But you already have to go unsafe for that. To design an interface for the masking, a use case would be handy.
Also, wouldn't type ambiguity be less of a problem in statically typed languages?
&gt; spawning a thread is async safe on Linux Won't you need to allocate the stack for the new thread though?
I’ve always gotten a fun loving feel from No Starch Press publications. They’re pretty consistent with the cute mascots and diagrams. Stoked there’s one in Rust!
You just have to assume there were more of them, run \`waitpid\` with \`WNOHANG\` and give up when you get \`EAGAIN\`. That way you know you've handled all of the children. That assumes you're handling all dying subprocesses in one place, though.
I find it obfuscates the hierarchical nature of the document. If it really wanted to be flat, it should use INI syntax with full qualified keys, like `log4j.ini` does it: key1.a.b=val1 key1.a.b.c=val2 key2.d.e=val3 Worse, TOML does not mandate flattening, so you can have different documents containing the same information, which autoformatting will not help you with. 
&gt; I prefer binary config files what's that?
I guess I have to admit that Rust web frameworks are still not really mature. See also: [Are we web yet?](http://www.arewewebyet.org/)
&gt; If it really wanted to be flat, it should use INI syntax with full qualified keys Well, it *sort of* does that with headings: [dependencies.&lt;dependency&gt;] key = value I think this is a reasonable middleground that preserves the flat nature of INI-style syntax without floating keys too much to the right when doing structured data. &gt; everything is XML which gets heavy on the eyes, but at least is consistent in its representation Ugh, XML is the worst for anything beyond markup, and it's even an eyesore for that.
Yes! That last sentence nails what I was trying to articulate! You're good!
Copy that!
You return nothing so everything, that gets allocated in this function gets freed after the function ran.
Definitely! Did you ever write Clojure? If so, did you ever try 4Clojure? It was a really great way to learn. Ruby Koans is another good one. The Rust-For-People-Learning-Rust ecosystem is going to keep doing great things, I'm sure.
Yes and no. You're handed out a YAML file, so you create a struct and annotate it with `serde` to automatically deserialize it. One field contains `1.0`, you use `f64` as the target type. Too bad, turns out in the next iteration of the file it contains `1.0.1`...
you're going to have a much easier time with debug info, so you either need to use a debug build (preferable) or modify your cargo.toml file to set [profile.release] debug = true and rebuild it, then run it again.
Yeah that would be cool. I'll try to find sometime to do it :D 
I have always wondered why pom.xml shuns xml attributes. It makes the xml much uglier than is required.
Steve, that's a pretty good attitude! Have others made similar criticism of TRPL?
The book is a paper version of the documentation here (just in case someone doesn't know): https://www.rust-lang.org/en-US/documentation.html Still, it's good to support the authors for some of the best tech documentation around.
&gt;because of ideology Calling it an ideology and ignoring the points I've put forth does not seem very constructive
It’s hard to say because the parent doesn’t go into much detail. I’ve spent like 30 hours working on the TOC, but there’s many different ways to do it... There’s tons of ways to criticize TRPL; I fundamentally don’t believe one text works for everyone, so it’s fine. Additionally, there’s some extra constraints given that it’s official docs; if I wasn’t doing the book we distribute with Rust, I’d do some things differently too.
It's Laurel, whoever says something else is wrong. 
And YAML is crazy.
Just allow comments and trailing commas, then it's fine. Better than learning yet another config syntax.
Does that happen anywhere outside of version strings? 
Programming cover art is always so... Relevant 🤣
Meh. It has many similarities to HTML, and yet you rarely hear web developers complain about hand-editing HTML, and/or recommend making websites in Word or Dreamweaver. If anything XML is easier than HTML. Now if only whitespace wouldn't be so terrible...
[Stack overflow post on how temporaries work](https://stackoverflow.com/questions/47662253/why-is-it-legal-to-borrow-a-temporary)
Cool. I've added two issues, one for the masking and one that elaborates a bit on my idea to make limited but safe signal handlers.
OTOH for the cost of typing "" in TOML you actually get a string that works instead of needing to reference a state table to decode YAML strings and corner cases of.
Rust does a bit of magic here. Since borrowing a temporary would always result in a lifetime error, Rust automatically creates a location for it in memory, and puts it there, just as if you assigned it to a variable, and then borrowed that variable. // It's similar to this let auto_loc = YamlLoader::load_from_str(&amp;buf)?[0]; let doc = &amp;auto_loc; I don't know if the book talks about it, but there is a section for it in the reference: [https://doc.rust-lang.org/reference/expressions.html#temporary-lifetimes](https://doc.rust-lang.org/reference/expressions.html#temporary-lifetimes)
That doesn't go with Malloc or with Mutexes on Linux on essentially any libc implementation. On Linux there really isn't much difference between forking and pthread_create hence the latter is also async safe. Internally both resolve to the same `clone` system call with a small amount of flags different. A thread is just a fork which you give access to the same address space.
Ok. Trailing commas is a minor annoyance. The lack of a comments is annoying, but it's popularity out weighs that. The part I was referring to as ideology was this reason not to use it ... &gt; was designed specifically for Computer-to-computer communication. I don't see that as a great reason to void using JSON for config files. If anything it's a plus.
Author of SIMDNoise here. SIMDNoise generates noise that can be used for generating textures, maps, geometry (mountains/valleys!), maybe even sounds and narrative pacing. There are lots of neat tutorials about noise on the web, this is a good one: [https://thebookofshaders.com/13/](https://thebookofshaders.com/13/) Games like minecraft for instance, use noise to produce the landscape. Its not entirely random, its got just enough structure that you can make it resemble a lot of natural things by tweaking the parameters, like clouds, mountains, rolling hills, clumps of cells,and so on.
I think it's extremely unlikely that you'd find a USB TV device that doesn't have drivers on Linux.
Binary, as in not a text format. Things like [MessagePack](https://msgpack.org/), or better [FlatBuffers](https://google.github.io/flatbuffers/), etc. If people are not supposed to edit them by hand, and if the software knows which configuration options exist, then there is no need for parsing text with arbitrary, possibly nonsensical, data.
I'm usually a FlatBuffers or Cap'n Proto guy, but yes, SQLite is also a great choice for many use cases, like yours. So good to hear that your suggestion was accepted.
What are the constraints in official docs? Is it legalish stuff like trademarks?
You might take a look at HOCON then. 
Coming from the Scala world, +1 for HOCON. 
But then it's not json, so not everything will parse it properly making it pretty useless for information exchange.
In the rust world almost everyone uses toml, which is a shame, because IMO [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md) is far superior to anything else I've seen.
They're [garden eels](https://en.wikipedia.org/wiki/Heterocongrinae?wprov=sfla1)! 
**Heterocongrinae** The garden eels are the subfamily Heterocongrinae in the conger eel family Congridae. The majority of garden eels live in the Indo-Pacific, but species are also found in warmer parts of the Atlantic Ocean (including the Caribbean) and East Pacific. These small eels live in burrows on the sea floor and get their name from their practice of poking their heads from their burrows while most of their bodies remain hidden. Since they tend to live in groups, the many eel heads "growing" from the sea floor resemble the plants in a garden. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
For the volume of data it was a good choice. Text files are good because they can be versioned, diffed and edited without custom apps. A staged hybrid system where rules are "compiled" to a binary format could have worked. But if you're willing to invest in tooling, binary is cool.
Actix web is very similar to Erlang/Elixer. That doesn't help you much but if you are curious, trying out those languages ( I suggest Elixer ) could help you get into the right mindset.
In my code `NonCopyDrop` does not contain a `&amp;mut` to some other object, but as you mention, if it were to do so, the code would be using `ptr::read` to create two `&amp;mut` to the same object, and that would be UB.
[Yes there is the `Borrow` trait.](https://doc.rust-lang.org/std/borrow/trait.Borrow.html) That is implemented for `T` amd `&amp;T`.
what's the difference?
Reqwest is just a nice wrapper around Hyper.
so what this says is "implement Talk for all references to types that also implement Talk", correct?
Start with reqwest and see if it is working for your use case. The boilerplate is certainly less for the 90% use case. I'm not sure if its async API is stable yet though. 
Use Reqwest unless it doesn't support what you absolutely need. Hyper is complicated, and breaking changes are not fun. I'm still struggling to port `rust-doh` to the latest Hyper version. Reqwest is a good abstraction to have, when you can afford it.
in the bit-vec-iterator code you are iterating from the front to the position you want to access making an usually O(1) access O(n).
Oh, I see, the skip method on the Vec iterator is O(1) but O(n) for the BitVec? Why is that and how could I find that information?
&gt; Why does the iterator on the `BitVec` not allow me to take the element by reference in `.position(|x| x)`, I think it has something to do with then `IntoIterator` trait on the `BitVec` not being implemented for references? Do you understand how a `BitVec` works? How would a pointer to a single bit be created?
That whole theory about "learning styles" doesn't seem to hold water. [It keeps getting debunked](https://www.theatlantic.com/science/archive/2018/04/the-myth-of-learning-styles/557687/?single_page=true).
Correct! It needs to be done explicitly since it's not necessarily a given, and can conflict with some other implementations. For example, `AsRef` has this, but `Borrow` does not- instead, Borrow has `impl&lt;T&gt; Borrow&lt;T&gt; for T`. Makes them useful for slightly different use cases.
There's no such thing as a reference to a bit; the smallest amount of memory that you can have a reference to is a byte (a u8).
Well, there were additional requirements as well. Notably the ability to automatically update the configuration at run-time, since the application was a 24/24 7/7 application with no planned down-time and its routing table was planned to be updated about ~10 per work day. It could have been made to work with a json file or xml file, certainly, but what's the point of human readable if there are ~50,000 routes? You need tools to filter them down anyway.
And when they didn't clarify a use case I just asked Nikolay in reddit/gitter and he made an example showing that and published it within the hour. So if you think something is hard to understand the community is very helpful and active in gitter.
They went from more than 100 to less than 30 that are currently being worked on. So I think we are ok. Things will be smooth soon. Actix still is the best rust web framework around
Just use a debug build. Until your understand the difference, you should be using a debug build.
I understand that there is no underlying bool to reference in the BitVec's memory but the iterator could supply a reference by just creating a temporary bool and passing a reference (consumer can then copy it/do what it wills). Which allows a Vec&lt;bool&gt; to more easily be replaced with a BitVec. But I am realizing now that it wouldn't work because the lifetime would be tied the iterator so it would have to retain those temporaries until the iterator destructs... So yeah, bad idea, makes sense now.
Debug flag in release profile just add debug info to binary, so compiler might optimize away some functions and their debug info.
I understand that, I was hoping the iterator interface could be made more generic by supplying references to temporaries but it wouldn't work without essentially copying the bits into bools due to the lifetime of the iterator.
you will have to assume that any call to next() even if masked by .skip() or .map() is computed. some iterators are able to save that cost. BitVec should be one of them, but apparently it is not. you can read the source code of the iterator and check if the .skip() method was overwritten or if the default/fallback implementation of just calling .next() n times is used.
Since futures are going through some big changes as they land in libstd, the async API is definitely unstable, as it will need to track those changes.
You can run `cargo rustc --bin &lt;binary target&gt; -- &lt;rustc args&gt;`
Me too, i didn't pre-order :(
the difference is that you get line numbers for everything in the backtrace.
Only one program ever reads most config files. That's such a hypothetical non-problem.
OK, after some digging through the code it looks like .skip() defaults to being implemented using .nth() which is specialized for std::Iter::Slice (using random access) which is the iterator type returned by the Vec .iter() method. BitVec does not specialize/override the .nth() method on its iterator type. Thanks for the help.
I got mine too!!!! Weekend plans went out the window.
Ooh thanks, that seems to work. cargo rustc --bin elevate -- -C link-arg="/MANIFEST:embed" -C link-arg="/MANIFESTUAC:level=\"requireAdministrator\" uiAccess=\"false\"" Do you have some more information about how `cargo rustc` invocations work? I never quite understood how it compares to eg `cargo build` or `cargo test`. I also discovered there's an unstable `#![link_args = ""]` attribute. It works it's quite wonky eg. it can't handle arguments with spaces (which turns out is what I need...). Of course it's something the user has to perform manually, not something I can teach rust/cargo to do for building my executable. Should I provide some 'build scripts' with these invocations in it for the users?
It leaves a bad taste in my mouth when projects get de-facto relicensed from copyleft to permissive, by a big company that can afford a rewrite. The paid hours of corporate FOSS devs is so big that usually most of the mindshare flips to the permissive code.
I really dont think thats a good idea. What are you going to do, [write your own parser](seriot.ch/parsing_json.php) with commas and comments? On top of that, even if you found a well maintained and tested JSON-with-commas-and-comments parser, you would still be doing your juniors a disservice as they try to figure out why their editor/IDE is highlighting syntax errors or even worse, as they start including comments in other places where you cant control the clients.
I guess you haven't heard of HJSON or JSON5 or used VSCode.
That sucks. It sounds like you were somewhat shafted. That being said, you should've taken the contract and negotiated for as high of a rate as possible. Then, when the contract was complete, if they didn't want to release the code, you could've just redone corrode in your spare time (it would be relatively easy at that point because you'd have already worked through all the issues once).
I havent, it raises the question though why in earth one would be so determined to make JSON as a config work. Its extremely cumbersome to write out all those redundant quotes.
I should write a blog post about this sometime, but at least three things... Relying on external crates is tough, because we don't want to be perceived as biasing the ecosystem. Imagine a parsing project. Do we pick nom? pom? pest? combine? Is picking one fair? This requirement is really tough, given how much of the Rust experience relies on using external crates. There's a higher degree of obligation to be thorough. We cover 99.99% of the language in the book. This means space is at a serious premium; TRPL is 520 pages already, and it's often pretty light on explanations. Consider a book like [Step Ahead With Rust](https://www.amazon.com/Step-Ahead-Rust-Systems-Programming/dp/0999361805). It pretty explicitly states that it's not covering everything, but its goal is to get you to the point of literacy where you can understand other resources. This means it's much lighter, and therefore, a bit faster paced. Related, I can't assume *anything* about the background of readers, which means it has to be pretty broad. I could write a very different book if C programmers were the only audience I cared about, and same if it were only Ruby/Python/JavaScript programmers. That balance is really tough.
&gt; Still, it's good to support the authors for some of the best tech documentation around. To be clear, we aren't making any money from sales. That said, buying books encourages more books, which is great for Rust!
Very *few?
Not really. How often do you edit a config file. Quicker to write quotes than to learn a new format (especially the disaster that is YAML).
If only rustc could check my comments as thoroughly as it checks my code
Unless they patented it. My boss patented something I did at work last year, it bothers me but at least it was such a common thing that the patent shouldn't hold up.
Why only two choices? What about json or XML?
I created a hybrid permission system and configuration database in http://hsqldb.org/ I believe, but SQLite would do just as well. If I did again, I would use a blockchain running on SQLite. Not only did it provide for config, but it tracked who changed what config when and could provide rollback to a point in time. It could fully serialize the state into an easy to edit config file that could be subsequently read back in. It used AoP to inject permission checking code into the parts of the application that needed authentication and authorization. This was all in Java, does Rust provide a mechanism as powerful as @ annotations? Can I combine [compiler plugins](https://doc.rust-lang.org/unstable-book/language-features/plugin.html) with [attributes](https://doc.rust-lang.org/book/first-edition/attributes.html) to create an [AoP](https://en.wikipedia.org/wiki/Aspect-oriented_programming) style system for Rust? 
This whole comment just boils down to yet another instance of someone positing that nobody ever wrote code that worked at all in any other language before Rust existed.
&gt;Don't speak for others like this, it's really condescending. Maybe tell that to the people making "Rust Hearts JS" illustrations? No, I don't. There's at least as many of us coming to Rust from C++, who don't care in the slightest about all this cutesy PR stuff and who think Javascript is a terrible joke of a language.
He got rid of far more than half of them way faster than anyone else would have, though. There was also zero evidence that any of his original unsafe blocks had ever caused any actual practical issues in the first place, for what it's worth (not that that justifies them.) It was melodramatic though, and I'll stick to that. Rust is just a programming language,`actix-web` is just one in an endless sea of web frameworks. It's not that big of a deal, and as we've established, he's fixing it (and fast!)
The joy of memory bugs is that you often times don't know they are happening, just occasionally small unexplainable problems occur that you ignore. The best case is when the OS notices and kills the process. There were several (more than 10) ways for a user to trigger these UB scenarios, and the compiler wouldn't have caught them. It's hard to know how many deployments have cases where they are triggered. While it's excellent to be fixing these issues, it's also important to note that a couple of the easiest to trigger cases still exist in master, and none of it is yet released to users. So, users must still exercise great caution.
I'm having trouble with cargo dependencies/features. My application depends on openssl with the 'v110' feature as well as on some crate that depends on openssl. The final link step ends up with unresolved symbols. I'm assuming this is because the transitive dependency gets compiled first without the 'v110' feature but I can't figure out how to turn on a feature by default or for a dependency. I tried to figure out what dependency exactly is specifying openssl without with dependency but cargo-tree also fails to build because of openssl symbol issues. A clean project with just openssl works fine (no linking errors).
Who cares? I don't get it. Who could possibly care about something this irrelevant?
&gt; (not that that justifies them.) Why even mention it then? Why even have this conversation? You're being extremely defensive for no reason. No one is saying the developer is bad. For the billion time, no one is attacking the developer.
Uh, what? Did you actually read my comment?
Except all the people who did? The guy who wouldn't stop mentioning how he "wouldn't be able to sleep at night" knowing he was using `actix-web` or something ridiculous like that sticks out in my mind, for one....
Yes? I'm so confused about why you care that other people write js.
I'm not going to go through every post in that topic and justify why people are upset that a web framework used unsafe haphazardly. It's not the point. Your post was unnecessarily presumptive and condescending - that's all.
I really don't understand your argument here. Why throw away safety guarantees the language gives you? If there's a good reason to have an unsafe block, then I don't see why it should be avoided, but I *do* expect there to be a comment explaining why `unsafe` was used and why the code is safe. I expect the same for any other project that does concurrency when safety is not clear (e.g. lockless concurrency solutions). There's also a difference between "working" code and "safe" code. The former may work today but break unexpectedly later (e.g. changes to the compiler or runtime), whereas the latter should *always* work. I've had the former break on me, which is a large reason why I'm interested in Rust (I made a poor design decision because of a misunderstanding of some documentation). "Working" code gets broken all the time, which is why we have lots of security advisories related to memory unsafety (e.g. many of the OpenSSL bugs were due to memory unsafety). I like libraries I use to be as safe as possible, so why is it unreasonable to request it from a language that makes safety a core part of the design?
The code generated by c2rust is ridiculous honestly. It uses `libc` to an insane extent for absolutely no reason.
After finishing the project for a company it would be very hard to argue in court that the redone corrode wasn't based on the project somehow. OP would have been tainted because they would have seen the 'secret' code. 
I say read all [three](https://www.manning.com/books/rust-in-action)!
[Response](https://news.ycombinator.com/item?id=17438854) by one of the people from the c2rust side of things.
I'm a primary contributor to c2rust and I may be the person "stolen" away from corrode. I'd like to apologize if it feels like we ripped off ideas without giving due credit - the project wasn't really supposed to "discovered" so soon. The website was a throwaway idea, a means of easily sharing our work in a limited circle while avoiding both the DARPA approval and the sub-par build process (you have to build a huge chunk of Clang). So here is me acknowledging Jamey's work: I personally did take inspiration from Corrode, and I was expecting to work on Corrode proper when I joined Galois. I've re-read the CFG module of Corrode several times (as well as the Mozilla paper, and some older literature). All that said, I also want to point out that Corrode hasn't had any activity at all since last April - and that's not for want of PRs piling up. I'm not criticizing here, since I understand that managing an open source can be quite time-consuming and stressful, but I feel like this also does need to be mentioned. Also, c2rust can be freely forked. Once the DARPA funding runs out, it is my hope that the Rust community will become the maintainers. Finally, regarding the many improvements that can be automated: that is next up on our plate!
Can you do operator overloading on associated types? If so, how?
and if you want to edit it manually on a server, by hand, how do you do this?
Got mine too! One nice thing I noticed is that I can highlight without it bleeding through to the other side / on the next page. Don't know if it's thicker paper or what, but it seems to be better than other programming books I've read in this regard.
Thanks for doing the research! I submitted a PR for fixing this in `BitVec`: https://github.com/myrrlyn/bitvec/pull/1
https://github.com/immunant/c2rust/issues/9 :)
sea star star = c** = c++?
Yep. Both projects are pretty much useless. What is the point in translating C into entirely unsafe and unusable Rust. You have to rewrite pretty much everything in any case. Instead of going off readable C, you're going off unreadable generated Rust.
Tonight is the night, we can't miss out
The beauty of GitHub is that repos can be forked. If there is more life in the fork, then it gets to take over community patronage by default. Now, Immunant have not in the documentation stated that c2rust requires a contributor license agreement or that 'c2rust' is trademarked. If Jamey wanted to, revenge style, he could fork c2rust and have more life in there. The license is BSD per the LICENSE file in the repo. The first line of that is: Copyright 2017-2018 Galois, Inc., Immunant, Inc. Jamey could (on his first commit to the source), change that to: Portions copyright 2017-2018 Galois, Inc., Immunant, Inc. Portions copyright 2018 Jamey Sharp If his has legs and those commits are really good, Galois-Immunant subject to their DARPA code review rules, can consume the commits back, but have to keep the "Portions copyright 2018 Jamey Sharp" in the LICENSE file. Jamey gets what he wants, but that's a labor intensive and uncertain way to get it. To be clear: Jamey doesn't have to make pull-requests (that could force some copyright grant situation, but do not at the present I don't think) for Galois-Immunant to be able to merge changes back - Git and GitHub's way of working allow you to merge changes from any common-ancestor repo that you can reach without permission of the author. So he could do a PR, or he could not do a PR - whichever he wants. Really he'd only do the "portions are copyright" bit if he could work faster that the team assembled (including /u/newtyped) or had ideas about direction and features that they are not going to think up themselves. He might do that if he can profit from it some how - quits his day job and take support-bucks for working on it (via Patreon ?). For Galois-Immunant to do the same trick again and want to **not** credit Jamey for one or more of the new/separate enhancements that he'd done in his fork, they'd have to rewrite the changes from scratch in such a way that someone couldn't claim "hey that's the same effing code just changed around a little". Copyright also has provision in it for "not copyrightable as it is so simple its the only way to do the thing" - like "The man walked through the open door" as a line in a novel isnt copyrightable. A second use by someone else couldn't be the reason that the original author went after the second autho who's novel also contained that line. I mention that as the rewrite/re-appropriate thing is nuanced. In real life, Apache's Geronimo had a code-theft tussle with the JBoss corporation some 13 years ago. More recently again with Oracle vs Google and the Java used in Android that's consuming $millions of lawyers fees. The Geronimo one was even more nuanced and drilled into "what is granting copyright" and exclusivity. If went there I'd be even more off topic...
You don't have to sign over your rights to ~~Trolltech~~ The Qt Company. You can could fork https://github.com/qt/qt5 and make your own changes to the source marking each in source with the terms of the LGPL exclusively. If you're not distributing object code in any way, you're golden. Sure, you may be fucking over people companies that would want to make object code from that source and distribute it, but that's not your problem. You'd also be fucking over the Qt company if they really liked your changes, and couldn't come up with a clean from-scratch version of the same without that being a copyright issue. They don't get an automatic right to sign a CLA for you when you merely forked their repo. GitHub won't delete your repo if TheQtCompany asks them to, either. The dual license is why Flutter wins (BSD), by the way.
I mean it may be purely psychological, but when I read books I end up reading the same paragraph over and over and I don't retain the information after reading it. I don't really care if science says its debunked if I can personally say it occurs to me...
I have also order the pdf book, but it seems its still not avaiable yet. :(
That's cool. It actually compiles the config as a dynamic library when run? The constant comparisons to xmonad and Haskell reminds me that I wasn't a language who's syntax resembles Haskell, but has Rust-like memory management.
It should be possible to write a function that takes a procedure with a mut argument and returns a value to value function.
&gt; The code generated by c2rust is ridiculous honestly. It uses the libc crate to an insane extent for absolutely no reason. We aimed for semantic equivalence to C99. Eg:`i32` is _not_ the same as C's `int` - `libc` is the glue we need for that (and the other platform specific types). &gt; You're far better off just doing a direct line by line translation to proper normal Rust code. Maybe. :)
&gt; You have to rewrite pretty much everything in any case I think the point is that an incremental rewrite is easier if everything is in Rust, e.g. start with a random function that takes `const T * pointer, size_t length` in C (`pointer: *const T, length: libc::size_t` in Rust) and convert that to a `&amp;[T]`, and then rustc points to all the places that can be updated. This will progressively "infect" the rest of the code-base with safety. Doing this when half the code is C and half is Rust would be much harder, not least because one has to keep the functions with C types for the interface (one can't pass `&amp;[T]` to and from C).
you can do that. look at the versions [dependencies] .... diesel = { version = "^1.1.0", features = ["postgres", "uuid", "chrono", "r2d2"] } versus [dependencies] ... [dependencies.diesel] version = "^1.1.0" features = ["postgres", "uuid", "chrono", "r2d2"]
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/watchpeoplecode] [Live-coding an asynchronous ZooKeeper client library in Rust \[x-post r\/rust\]](https://www.reddit.com/r/WatchPeopleCode/comments/8vfzrb/livecoding_an_asynchronous_zookeeper_client/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Then you still have a Rust library written like it was a C library.
Making cuttlery and water pipes from led was very popular in ancient rome. (and the USA a bit more recently) That doesn't mean the downsides don't outweigh the benefits.
It is so useless that Dropbox used Corrode to port Google Brotli to Rust: https://news.ycombinator.com/item?id=17437609
Just read through [the Discovery book](https://japaric.github.io/discovery) and I have to mention how good it is! Very thorough and it makes sure to explain the little details about developing embedded code which are sure to be useful. I wish I had a book like this a few years ago. (Though I certainly could have bought one...)
Windows has shared memory too.
[The Rust book](https://doc.rust-lang.org/book/second-edition/index.html) is always a good read to get started. I mostly stay away from `Box&lt;T&gt;` types for most code, since most of the containers in the standard library will move the value from the stack to the heap at initialization time. [Here's a handy cheat sheet](https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/edit) to know how the data is stored. Discerning when to use a reference, a mutable reference or a move comes from experience. Most of the time, arguments are (mutable) references. If, in the function, you create some data that you want to return, you return a value. If the function acts as an accessor, you would return a reference instead. `Option&lt;T&gt;` is a nullable `T`. In Rust, null does not exist because Rust guarantees you that everything points to a valid reference. If I have a `&amp;Vec&lt;T&gt;`, it will always point to a valid `Vec&lt;T&gt;`. We therefor need another type to represent the case where something may not be present. Rust is intelligent to optimize the `Option&lt;T&gt;` at compile time. It is in no way slower then using a `null`. `Result&lt;T, E&gt;` is the way to represent an operation that may succeed with type `T` or fail with type `E`. [The `?` operator](https://m4rw3r.github.io/rust-questionmark-operator) is often used to manage errors. I would suggest looking at the [failure crate](https://boats.gitlab.io/failure/) for easier error handling.
I don't think distance between a C library and a Rust library is necessarily that far, assuming it's a library of reasonable quality (e.g. context objects instead of global state, explicit thinking about thread-safety, etc.). There's a tonne of things that make something feel C-ish (for instance, `mylib_object_t *mylib_create_object()`) but have a much more Rust-y version that's just a local-refactoring (that becomes `impl Object { fn new() -&gt; Object { ... } }`) plus compiler-guided replacement, once everything is in Rust. It's definitely true that C is likely to use more aliasing than Rust, and I'm sure there's lots of instances of that where a proper resolution is hard work, but I do think that an important part of any such refactoring includes having the compiler point at all the right places for updates, or else doing incremental updates with heavily intertwined C FFI is too error prone.
You are not supposed to have the .env files on the server - they are for development convenience. I tend to prefix all my environment variables with an app-specific prefixes just to be safe from accidental collisions. But you should seriously run tour different apps in different environments. If you have only one server, consider using containers.
Actually after trying to use this struct with Actix-web, i see a reason: the generics argument declarations need to be spread everywhere which is not so nice.
I think the permissive/copyleft divide is really just a difference of values. I personally prefer permissive licenses - the people who aren't going to contribute back never were, and I'd rather they have some software rather than not. But plenty of others disagree with me, and I admit there is much to be said for using copyleft to push reluctant contributors (particularly corporate "why would I help my competitors" types) toward being more open. I think the strength is in that we have both licensing in the wild. We'll get you hooked with permissive licensing, then lure you toward copyleft and being more open.
It already is, and the compiler work is being tracked [here](https://github.com/avr-rust/rust). There's also a whole bunch of issues using the AVR backend still - e.g. large chunks of the standard library simply don't compile due to LLVM bugs that are slowly being fixed. 
Don't use JSON because lead cutlery? You have not provided a convincing argument that the downsides outweigh the benefits. JSON doesn't poison people.
Casting floats to integers is perfectly defined behavior, so you can cast a float to an integer to index a vector. Now, if you prove that your floats are always in range [0, size()), you can even index the vector `_unchecked`, which introduces UB if the index is out of bounds. If you then change floating-point behavior, everything might still work as usual, or the floating point operations might return different indices that might still work. Or... a +0 might be rounded to -0, and you might get `usize::max_value()` as an index, and boom. Irrespectively of what you think of programmers writing this kind of code, turning a memory safe program into a memory unsafe one is not something that a Rust optimization is allowed to do, which complicates `-ffast-math` even further.
That's gibberish. Re-read my question.
If they each have their own .env file, why would there be any confusion, how would app A even know about the .env of app B?
I've slowly become more in favour of copyleft over time, to me it's not really about contributions, I don't care if people give me back improvements to my code. What I do like to guarantee is that users of my code or it's derivatives can see exactly what's happening on their system. I don't really care if code flows back upstream to me, as long as it flows downstream to users, and the GPL fulfills that requirement perfectly
Well, so is Git. 
I believe the standard nomenclature for that is a “streaming iterator”, and Associated Type Constructors are the proposed solution for expressing them (along with a bunch of other useful concepts).
Honestly, I just use JSON. That or a good ol' fashioned properties file.
mio_httpc is lower level as it runs on just mio.
&gt;edited and created by a dedicated tool That tool can be a terminal thing, using program arguments or a curses UI or whatever to select proper, valid options.
The [Rust API Guidelines](https://rust-lang-nursery.github.io/api-guidelines/) might be helpful to read.
Is this not still the case, at least partially? One of the contributors has also been working on Corrode before.
you can also always use xml
It's not gibberish, I'm trying to be helpful. I re-read your question and have nothing more to say. Expect that you might have an misunderstanding how environment variables work. They are not global, so setting one in one process doesn't overwrite a environment variable with same name in another process. As for .env files, if they have different paths, there shouldn't be any problem with distinguishing them? I'm confused about what you are trying to ask.
&gt; good rules of thumb I found that these rules are explained in a more detailed manner in [Programming Rust by O'Reilly](http://shop.oreilly.com/product/0636920040385.do). The other concepts _Where to use option or result and how to handle errors_ are also explained very well and detailed in Programming Rust. I also liked that it compares the concepts with how they are implemented in C, C++ and Python in some places. &gt; Where to use option or result and how to handle errors. You need to practice and write programs a lot to understand which is best in which cases.
My point is that popularity ist a weak basis for a rational decision.
Yes! There are some good resources at the [rust-learning](https://github.com/ctjhoa/rust-learning) project: &gt;⭐️ [Rust Design Patterns](https://github.com/nrc/patterns) \- [Nick Cameron](https://github.com/nrc) &gt; &gt;⭐️ [Error Handling in Rust](http://blog.burntsushi.net/rust-error-handling/) \- [Andrew Gallant](https://github.com/BurntSushi) &gt; &gt;[Reading Rust Function Signatures](http://hoverbear.org/2015/07/10/reading-rust-function-signatures/) \- [Andrew Hobden](https://github.com/Hoverbear) &gt; &gt;[Good Practices for Writing Rust Libraries](https://pascalhertleif.de/artikel/good-practices-for-writing-rust-libraries/) \- [Pascal Hertleif](https://github.com/killercup) &gt; &gt;[Rustic Bits](https://llogiq.github.io/2016/02/11/rustic.html) \- [Llogiq](https://github.com/llogiq) &gt; &gt;[Pretty State Machine Patterns in Rust](https://hoverbear.org/2016/10/12/rust-state-machine-pattern/) \- [Andrew Hobden](https://github.com/Hoverbear) &gt; &gt;[Elegant Library APIs in Rust](https://scribbles.pascalhertleif.de/elegant-apis-in-rust.html) \- [Pascal Hertleif](https://github.com/killercup) &gt; &gt;⭐️ [Rust API guidelines](https://github.com/brson/rust-api-guidelines) \- [Brian Anderson](https://github.com/brson) &gt; &gt;[Rust Performance Pitfalls](https://llogiq.github.io/2017/06/01/perf-pitfalls.html) \- [Llogiq](https://github.com/llogiq)
Bug it is, yes. https://github.com/rust-lang/rust/issues/28008 And it's closed and recommended workaround is to use "box" keyword.
Thank you!
If I understand correctly you cannot (and do not desire) to overload associated types. Instead you can put trait bounds on the associated that which demand that it can be used with certain operators, eg: use std::ops; trait Foo { type T: ops::Add&lt;T, Output = T&gt;; } Now when a type implements Foo it means you can use the operator + on its associated type. Does that help?
Wrong link I believe? I suppose you meant https://forums.manning.com/posts/list/43665.page
Urgh. Yes I did! Thanks :)
Looks like exactly the book I want to help me take the next step with Rust in the limited time I have for it!
Strong criticism from somewhere is probably a good sign all things considered. It means that people care enough to comment. No single style will impress everyone
Man, you want to lecture someone? Lecture your kinds
Because env. variables are global 
Chill out.
If you ask questions, expect to get answers – usually the better questions, the better answers.
and sometimes good questions and gibberish as an answer
&lt;offtopic&gt; For those who are interested: this page explains pretty well how Cuberite, a Minecraft server written in C++, generates its terrain: [http://cuberite.xoft.cz/docs/Generator.html](http://cuberite.xoft.cz/docs/Generator.html) &lt;/offtopic&gt;
Is the problem that you didn't understand my answer, if it feels gibberish to you? Maybe I didn't understand your question? What you are trying to ask? You talk about environment variables overwriting each others? That doesn't happen since each process has their own set of environment variables. Maybe you could chill out and try to clear up what is it you want to know?
&gt; If I set an env. variable in my "bash_rc" or /etc/environment, for instance, it can be visible globally to many processes in my system Right, in that case you're not working with ".env" files. &gt; If I set 2 of them with the same name, one overwrites the other one And in that case you're not working with a .env file per application, so you might want to rethink your setup.
Rust doesn't guarantee the layout of any structs, even newtypes. You should use `#[repr(c)]` if you want to do pointer transmutes.
bash\_rc and /etc/environment and .env files are configuration files that tell how to set up environment variables – they aren't environment variables themselves. Config files are global (since the filesystem is global), but environment variables are not. When a process starts up, it "inherits" the set of variables, but after that, the variables it has are disconnected from the variables of other processes. So when a process starts up, reads .env file and sets its environment variables accordingly, it doesn't interfere with any other process' environment variables.
Kudos to /u/SimonSapin for taking care as of lately of many of these difficult to move forward issues.
It was not very noticeable from the site but there is a code today for 50% off all MEAPs including Rust in Action: wm070218lt
What happened to the other thread? :P
I think I get it! I'll give it a try, thanks! 
If we're going down that road, then *any* code changes that cause an observable change in behaviour that is unintentional (and part of stdlib code) is a breaking change. Since you could construct an arbitrarily complex function that returns 0 in one case and 1 in another, and use it to index a 1 element array unchecked write. If it returns 1, then it's undefined behaviour.
Environment variables are not global; they are inherited from parent processes to child processes. When your process reads the .env file, it sets the environment values for its own environment. This will overwrite inherited values from the parent, but it will not overwrite them \_for\_ the parent.
Development on my microkernel has had to stop for a while; I’m waiting for GATs to be implemented to write my message passing infrastructure nicely. In the meantime, I’ve gone back to my little keyboard firmware, [teensy_kbd](https://github.com/IsaacWoods/teensy_kbd). I’ve found debugging hardware a lot more difficult than I expected, even coming from OS development, but it has been fun! I’m currently trying to work out how the hell USB descriptors work
Code review, lots of code review of PRs to [`uom`](https://github.com/iliekturtles/uom) (Units of measurement -- type-safe zero-cost dimensional analysis) for `FromStr` and `Display` implementations.
The problem with `type Foo = impl Trait` is that it conflicts with the controversial universal `impl Trait` syntax. It means that type Foo = ..; fn test(a: Foo) -&gt; Bar { .. } Is no longer equivalent to fn test(a: ..) -&gt; Bar { .. } In all cases, i.e. the `type` keyword is no longer referentially transparent. My choice would be to drop universal `impl Trait` but that's obviously not reasonable now.
You mean [last week's thread](https://www.reddit.com/r/rust/comments/8tooi0/hey_rustaceans_got_an_easy_question_ask_here)?
Thanks for sharing. As someone who is learning Rust, and also learning systems programming, this is exactly the book I'd like to read. Is the early 2019 release date on the website accurate? 
Right, but a lot may have changed since 2015.
Great stream as usual. I've already watched it once but I think I'll rewatch it tonight.
And that's precisely my problem with Toml, I wish only the second were legal.
[removed]
It probably is, however, if you aren't familar with Manning's MEAPs they allow early access to chapters that are finished.
I'm working on api bindings for the [Bungie.net](https://Bungie.net) API. You can find it [here](https://github.com/inferiormartin/bungie-rs). 
Slight threadjack: given Rust’s stellar C interop, and the amount of work still required to convert the output from either of these tools into safe, idiomatic Rust, what’s the point? Why not just focus on bindings and avoid the question marks around translation?
Probably [this one](https://www.reddit.com/r/rust/comments/8vfxvy/hey_rustaceans_got_an_easy_question_ask_here/) (All Hail RSS).
I think the reason that the latter syntax is allowed is because it’s hard to represent huge tree structures without it (such as scene graphs, ui layouts, etc)
&gt; I'm a primary contributor to c2rust and I may be the person "stolen" away from corrode. I'd like to apologize if it feels like we ripped off ideas without giving due credit - the project wasn't really supposed to "discovered" so soon. This is why it's good practice to add attributes to the README and all docs as a first thing. &gt; Also, c2rust can be freely forked. Once the DARPA funding runs out, it is my hope that the Rust community will become the maintainers. What strategy is there to make that happen? It's a tough sell to bring a huge funded project into a market of free labor. Yes, c2rust can be freely forked, but no one knows whether Galois holds an internal fork with extensions that they are going to use. Who is going to do maintainership? When is funding running out? Your phrasing sounds like you want (have?) to step back after you are not assigned on that job anymore when that happens. I'm extrapolating here, but does you contract with Galois. Will the effort on turning that into a FOSS project be paid work? This is a problematic outset for making something a working FOSS project instead of a code dump. There's a lot of things unclear here. The reason for Corrode having no activity since last April was clearly stated: it would need to be rewritten.
I pre-ordered mine 23rd of January, and it's not even shipped yet according to Amazon... Temporarily out of stock =( I'm hoping for better luck with the next batch!
It's an architecture that is used by lots of really small, really cheap microcontrollers, including many Arduino models. It's only really a priority for the people working in the embedded space, because AVR is ubiquitous there, and it would be great to have Rust support it.
Very cool, thanks for sharing! I will definitely buy the book once it's ready. My interest in Rust is primarily as a replacement for C, and this is just the kind of thing I have been waiting for.
Will they be similar to F# Units of Measure? Like I could annotate different integers as currency and the compiler will force me to convert them to one another? 
That seems really interesting. I picked up the book and read through it, will check out the code later. 
If it helps, people are confused because your question is equivalent to this: &gt; Say I have a *user account* and in it I have *a ".bash_profile"* file where I have *"PATH=......"* &gt; &gt; If I have multiple such *user accounts* apps on the same server each using its own *".bash_profile"* file, how will *bash* distinguish between them? Each of them will set its own *"PATH"* environmental variable *"PATH"* and eventually the last one overwrite those that have been set earlier?
Continuing work on [`ggez`](https://github.com/ggez/ggez/) a lightweight 2D game framework. Last week I refactored the `gfx_glyph` based text rendering to be the main text rendering method, ditching the previous home-grown solution and it all works startlingly well. I also did a *lot* of work revamping the graphics system to be able to select the screen's color format, which finally makes it possible to work around [The Great Mesa sRGB Bug](https://github.com/ggez/ggez/issues/194). It was bigger than it sounds; not only did ggez have to change all its assumptions everywhere, but it required adding a couple small features to `gfx` and `gfx_glyph` that had been overlooked because nobody had exercised those bits of them before. This is frankly the *fun* part of working on ggez. :D
I was nodding ahead, good solid advice: but I would wait a bit on failure until it really is 1.0. 
Wow. All these responses and not a single comment from the man himself. Disappointing.
The final release date is probably accurate - but there are ~200 or so pages ready right now. I have been averaging slightly under 1 chapter per month and I have 6 to complete. One of the intentions behind these monthly updates is to let readers know if I am falling behind. There have certainly been times where I have taken several more weeks than anticipated to release a chapter. Manning's process is to make sure that MEAP material passes two editorial checks (one general, one technical) before being made public. So there are sometimes quite a few hurdles before content is released - but it will happen!
Thanks for sharing! I am always nervous promoting specials because I want to keep things informative rather than be pure advertising. Its great when other people share these codes though
Thanks. This would be an additional layer between client and TiKV. 
I'm impressed you're watching it twice! I must be doing something right :D Were there parts you found particularly interesting, or skip-worthy? If you could give me a rough list I'd be happy to add them as links into the video description so people can navigate the 5 hours more efficiently :)
There was another question thread posted just before this one, but it got deleted.
Easing maintenance. Nobody wants to bind against a dead library and some projects, such as CVS, exist in a limbo where they have broad legacy use but not enough interest to get more than the most bare of emergency patching, given the state of the C code.
Really excited to see the Rust port of CVS.
QotW? /u/nasa42
I didn't find any part skipworthy. Even the struggle to find the bug with the 'need == 4' comparison was interesting. I'll try to find spots that were particularly noteworthy but like I said it's all interesting to me. I also quite like the internal API you ended up with (enqueing requests along with a one-shot sender and waiting on the one-shot receiver). It feels very clean and I hope that by watching more of your library developement videos I'll get more of a reflex for nice API designs.
[mutagen](https://github.com/llogiq/mutagen) needs another rustup. There also have been reports of errors when running it I want to investigate if possible, but I have precious little time this week...
Adding on to K900_'s answer. One of the [four major target domains](https://github.com/rust-lang/rfcs/blob/master/text/2314-roadmap-2018.md) for Rust this year is embedded devices. By being able to target one of the most ubiquitous microcontrollers Rust is making a large step forward in that direction.
Just got permission to use Rust for a new project at work! Can't talk about it unfortunately, but it'll be the first Rust in the company!
The reason I mention CVS is because, if I remember correctly, it was the primary thing being used to test Corrode's progress.
I tried using toml for a tool I'm using, but with Serde, it didn't handle enums well. So I switched to JSON. There's not a lot of human editing, it's more just a computer generated settings file, but I wanted it human readable.
Honestly, AVR shouldn't be that important to Rust. Current 32-bit ARM microcontrollers are cheaper, much faster and have better peripherals than the AVR series. AVR is mostly inertia at this point. That said, anything done to get 8-bit micros to work will probably make Rust a lot easier to port to other architectures.
You can already target the STM32 ARM microcontrollers with Rust :)
I'm trying to learn rust by writing a neural net in it and experimented with the "if let" syntax. (ofc simplified code here) if let Some(m1) = nabla_weights.get_mut(i) { *m1 = m1 + 10 } else { nabla_weights.push(15); } For some reason Rust won't let me do this saying it's two mutable borrows: if let Some(m1) = nabla_weights.get_mut(i) { ------------ first mutable borrow occurs here ... nabla_weights.push(15); ^^^^^^^^^^^^ second mutable borrow occurs here } - first borrow ends here Even though there is a else statement separating the two borrows, is there a reason for the if let statement scope to stretch to include the else statement? Is there a good solution to get around this?
Hehe, yeah, the `need == 4` was a curious bug. We had a couple of those, and they tend to arise when you do protocol implementation from scratch. Parsing is just a pain in the neck. Normally I'd use `nom`, which can help with these things, but I figured I didn't want to add another external dependency. It also wouldn't have helped us with the serialization side of things, nor with handling the fact that you can get partial or multiple messages (which is where this bug arose). I also don't think `serde` is a great fit here, but could be wrong as I have limited experience with it. I quite like the internal API too! We had to do a couple of iterations, but I think it ended up in a state where it'll be easy to use when extending the higher-level functionality. The biggest question for me at this point is `futures::sync` vs. `futures::unsync`, as the former does come at a small performance cost, but since I don't think ZooKeeper is generally on the critical path for high performance software, I opted for `sync` which gives us futures that are `Send` :)
Why shouldn't it work? There's an inner scope in the `if` branch accessing the outer scope.
There's still value to making Rust work with the huge number of existing AVR devices, even if they're not the best choice for new projects. I mean, people still use PICs for some reason...
Well one thing is for sure they move in Sync
The project has been starred 7 times on github, and based on the blogposts probably doesn’t actually compile. I’m left wondering about the logic behind the idea that abandonware that can barely find enough maintainers to fix existing security bugs is going to be made suddenly relevant and find a new audience because a translation tool can take you to bad Rust that still needs a massive amount of work applied to it to make it idiomatic. Who are these mythical developers that desperately need the legacy functionality, are unwilling to do the work in C, but are somehow willing to use these tools and then put in the extra work to make it maintainable Rust?
mutable borrow question: I've got the following code: [http://play.rust-lang.org/?gist=8d38c18bc74f1498e5c1663a5b1753e4&amp;version=stable&amp;mode=debug&amp;edition=2015](http://play.rust-lang.org/?gist=8d38c18bc74f1498e5c1663a5b1753e4&amp;version=stable&amp;mode=debug&amp;edition=2015) In function \`get\_i32\` mutability should only be required for the duration of the function itself, mutability should not "leak" into the returned reference. How do I communicate this to the rust compiler so that I can write this function without using panics?
Actually if iterating by non-mutable reference, it only needs to yield `&amp;true` and `&amp;false`, so BitVec could have efficient iteration by reference. 
I've worked out a way to embed a reasonable encoding of HKTs in Rust, and I'm using it to play around with a functional programming library in the style of Cats/ScalaZ. The encoding is not perfect (users of the library would be incapable of defining their own "Kinds", which is sort of a big deal), but once GATs show up it should work much better and I'll have hopefully laid the groundwork for more Cats/ScalaZ style explorations. Here's a little demo: /// The `show_off_kind_tupler` fn is clearly silly: we can just use a.product(b) directly, /// however, the point of kind level programming is that we're able to talk about /// these behavior generically: We can tuple a kind as long as that kind implements Applicative. /// /// (F&lt;A&gt;, F&lt;B&gt;) -&gt; F&lt;(A,B&gt;) /// where F: Applicative fn show_off_kind_tupler&lt;'f_, F_, A, B&gt;( // F&lt;A&gt; a: Kind&lt;'f_, F_, A&gt;, // F&lt;B&gt; b: Kind&lt;'f_, F_, B&gt;, // F&lt;(A,B)&gt; ) -&gt; Kind&lt;'f_, F_, (A, B)&gt; where F_: Applicative&lt;F_&gt;, { a.product(b) } #[test] fn test_kind_tupler() { // Type annotations on the left hand side are not necessary, just for illustrative purposes. let a: Kind&lt;OptionKind, i32&gt; = 5.point::&lt;OptionKind&gt;(); let b: Kind&lt;OptionKind, &amp;str&gt; = "rats".point::&lt;OptionKind&gt;(); let ab = show_off_kind_tupler(a, b).reify(); assert_eq!(ab, Some((5, "rats"))); use kinds::IdKind; let a = 5.point::&lt;IdKind&gt;(); let b = "rats".point::&lt;IdKind&gt;(); let ab = show_off_kind_tupler(a, b).reify().take(); assert_eq!(ab, (5, "rats")); use kinds::FutureKind; use futures::future; use futures::executor::ThreadPool; use futures::future::FutureResult; let a = 5.point::&lt;FutureKind&gt;(); let b = "rats".point::&lt;FutureKind&gt;(); let ab = show_off_kind_tupler(a,b).reify(); let ab = ThreadPool::new().unwrap().run(ab).unwrap(); assert_eq!(ab, (5, "rats")) } 
I've worked out a way to embed a reasonable encoding of HKTs in Rust, and I'm using it to play around with a functional programming library in the style of Cats/ScalaZ. The encoding is not perfect (users of the library would be incapable of defining their own "Kinds", which is sort of a big deal), but once GATs show up it should work much better and I'll have hopefully laid the groundwork for more Cats/ScalaZ style explorations. Here's a little demo: /// The `show_off_kind_tupler` fn is clearly silly: we can just use a.product(b) directly, /// however, the point of kind level programming is that we're able to talk about /// these behavior generically: We can tuple a kind as long as that kind implements Applicative. /// /// (F&lt;A&gt;, F&lt;B&gt;) -&gt; F&lt;(A,B)&gt;) /// where F: Applicative fn show_off_kind_tupler&lt;'f_, F_, A, B&gt;( // F&lt;A&gt; a: Kind&lt;'f_, F_, A&gt;, // F&lt;B&gt; b: Kind&lt;'f_, F_, B&gt;, // F&lt;(A,B)&gt; ) -&gt; Kind&lt;'f_, F_, (A, B)&gt; where F_: Applicative&lt;F_&gt;, { a.product(b) } #[test] fn test_kind_tupler() { // Type annotations on the left hand side are not necessary, just for illustrative purposes. let a: Kind&lt;OptionKind, i32&gt; = 5.point::&lt;OptionKind&gt;(); let b: Kind&lt;OptionKind, &amp;str&gt; = "rats".point::&lt;OptionKind&gt;(); let ab = show_off_kind_tupler(a, b).reify(); assert_eq!(ab, Some((5, "rats"))); use kinds::IdKind; let a = 5.point::&lt;IdKind&gt;(); let b = "rats".point::&lt;IdKind&gt;(); let ab = show_off_kind_tupler(a, b).reify().take(); assert_eq!(ab, (5, "rats")); use kinds::FutureKind; use futures::future; use futures::executor::ThreadPool; use futures::future::FutureResult; let a = 5.point::&lt;FutureKind&gt;(); let b = "rats".point::&lt;FutureKind&gt;(); let ab = show_off_kind_tupler(a,b).reify(); let ab = ThreadPool::new().unwrap().run(ab).unwrap(); assert_eq!(ab, (5, "rats")) } 
It would be great if you cover Rust 2018 Edition and cover in depth about tokio/Future/async system once it gets stabilised.
I'm still using v0.10! I recently ported some hyper v0.10 code to chttp, it was pretty laborious though.
this is my preferred approach as well in many contexts. you have to handle the event loop yourself. when it's something important, that's an advantage to me. when it's something quick and dirty, not so much.
Maybe you don't need to. Have a look at [the 'faster' library](https://github.com/AdamNiederer/faster) which is designed to be powerful and easy to use.
I did try that. Ran into some (issues)[https://github.com/AdamNiederer/faster/issues/37] though.
This is a known limitation. You can think of an if-let as sugar for a match statement, and the expression being matched must be alive for all match arms. Non-lexical lifetimes will solve it, but until then you unfortunately need to use a flag. There is a slightly shorter solution, but yeah it's unfortunately still kind of ugly: let mut weight_flag = true; if let Some(m1) = nabla_weights.get_mut(i) { *m1 = m1 + 10; weight_flag = false; } if weight_flag { nabla_weights.push(15); }
&gt; The project has been starred 7 times on github, and based on the blogposts probably doesn’t actually compile. It would be a pretty poor primary target if it worked while Corrode still had a lot left to be done. &gt; I’m left wondering about the logic behind the idea that abandonware that can barely find enough maintainers to fix existing security bugs is going to be made suddenly relevant and find a new audience because a translation tool can take you to bad Rust that still needs a massive amount of work applied to it to make it idiomatic. Who are these mythical developers that desperately need the legacy functionality, are unwilling to do the work in C, but are somehow willing to use these tools and then put in the extra work to make it maintainable Rust? You'll have to ask Jamey Sharp. I'm just paraphrasing what I read.
Getting ready for [Week 03: FOV + Enemy Placement](https://github.com/Lokathor/roguelike-tutorial-2018/blob/master/lessons/week03.md) in the roguelike dev jam. You can see the preview there, and I have to finish it up and get it posted by tomorrow if possible. I wrote a lot of the explanation stuff at like 2am on the weekend, so there are a lot of minor editing fixes to make, but the bulk of the work is completed, and the FOV works correctly.
&gt; That said, anything done to get 8-bit micros to work will probably make Rust a lot easier to port to other architectures. The same might be true of LLVM, too. There have been a few issues in avr-llvm that are simply due to the fact that LLVM wasn't designed for 8-bit processors.
Thanks for the answer!
There isn't really a good reason other than it isn't allowed, other than it isn't - yet (I think [NLL](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/) will fix it, which you can use on nightly with `#[feature(nll)]`). 
Mainly because the amount of embedded hardware for the money. Integrated ethernet. Integrated USB. So many options. Makes dealing with the annoying PIC architecture worthwhile if the end design reaches a certain number to be produced. For smaller number of projects, it is easier to use a more sane architecture, like AVR. 
&gt; I mean, people still use PICs for some reason… Please, please tell me we're not going to try to port Rust to PIC. [starts sobbing]
I bought the book for Christmas, and it is a good to see it is progressing well. Do you think you could add a section (maybe an appendix) explaining how to build libraries for use with iOS and Android, and maybe also WASM? There aren't many up to date tutorials on the web covering the former two.
&gt; could provide rollback to a point in time. Actually, one of the interesting parts of the projects was developing "revert" functionalities, when the patch to be reverted was a few days old (and thus a good few dozen patches had been applied on top). Before the project, reversal was manual (and changes non-transactional), so I leave it up to your imagination how quickly it could go wrong. For our SQLite configuration, the patches were limited to add/delete/update commands on a number of tables linked together with foreign keys. The software could therefore trivially generate a "negative" patch: just take the queries in reverse order, and replace add by delete, delete by add, update by update (old state), etc... For safety's sake, the software would also automatically dump the config (C0), apply the patch, dump the config (C1), reverse the patch, dump the config (C2), apply the patch again, dump the config (C3) and finally ensure that C0 == C2 and C1 == C3. Only if that went well was the patch approved (and later applied). Of course, between applying the patch and reverting it you could easily have conflicting patches applied. So deletion/update was keyed on the expect state of the row, and any failure would lead to the patch as a whole to fail. The operators of the system were pretty impressed, by what was just a simple "revert" auto-deduction scheme and an ACID database :p
&gt;AVR is mostly inertia at this point. Although AVR might not be developped anymore since Microchip bought Atmel, it’s still an interesting platform as most AVRs are available in DIP (easy to integrate onto a breadboard or a stripboard, easy to solder, etc), whereas most ARM are SMDs. It’s also useful when you have a small amount of I/O, or you don’t absolutely need speed — and even there, most (all?) AVRs can still run at a speed of 20 MIPS, which is more than enough for a lot of applications. Don’t get me wrong, I love working with ARMs, but they’re no silver bullet.
I got the impression that's not straightforward, though. Your .rs file gets compiled, but the rest looked like a kludge to me.
That's not going to work - debug mode disables pretty much all optimizations and will change the performance characteristics of your code _dramatically_.
The advantage is AVR requires no support circuit for basic operation. It has 5V support, so you can just run it with a usb power supply. If I wanted to build a keyboard I would use an avr. My logitech keyboard has an atmega32u2 in it. And many atmegas are available in the DIP package.
Two questions. (1) is wrapping X in a newtype the best way to implement trait Y for type X when both are from external crates? (2) I've assumed *yes* for (1), and I end up with this. It seems super hacky; am I doing it wrong? I understand that `SeqReader` shouldn't outlive whatever the `A` can't outlive, but how to express it without the fluff? `PhantomData&lt;&amp;'a ()&gt;` is just awful. struct SeqReader&lt;'a, A&gt; where A: SeqAccess&lt;'a&gt; { src: A, phantom: marker::PhantomData&lt;&amp;'a ()&gt;, } Thank you.
Thanks, I'll try reading those.
Thanks for the reply, but that doesn't help me all too much. I was trying not to learn the 'hard way' and learn from someone else's expiriance :)
But ... why?
Thanks, I'll try reading it.
I've read that book, didn't help too much I'm afraid. But thanks!
That was generally true until 1.27 was released. I generally work on nightly with ARM micros so I've been without Xargo since early May. The only thing in std that doesn't work with stable right now is panic_fmt! of which [a PR has already been merged](https://github.com/rust-lang/rust/pull/50338) and is generally required for any embedded development not just ARM. When that milestone was crossed there was a pretty good [write up done](https://users.rust-lang.org/t/cortex-m-library-development-now-possible-on-beta-and-the-path-towards-stable-embedded-rust/17420) which I highly recommend if you're interested.
First take a look at `std::arch::x86_64` [docs](https://rust-lang-nursery.github.io/stdsimd/x86_64/stdsimd/arch/x86_64/index.html). As you probably work with `f32`, you'll mostly use `__m128` or `__m256` types. (depending if you'll be able to use AVX only, as AVX/SSE transition [can be costly](https://software.intel.com/en-us/articles/avoiding-avx-sse-transition-penalties)). Next step is to open [Intel Intrinsics Guide](https://software.intel.com/sites/landingpage/IntrinsicsGuide/) and find intrinsics (maybe with some google help) which will help with your problem. As Rust SIMD intrinsics mirror C/C++ ones you will be able to use exisiting answers for those languages. Also do not forget to enable used `target-feature`s when compiling code, otherwise intrinsics will not get inlined, which will result in a severe performance penalty. Ideally you'll need to have something like this in `lin.rs`: #[cfg(not(target_arch = "x86_64"))] compile_error!("crate can only be used on x86_64 architecture"); #[cfg(not(all(target_feature = "avx", target_feature = "avx2")))] compile_error!( "enable avx and avx2 target features, e.g. with \ RUSTFLAGS=\"-C target-feature=+avx,+avx2\" enviromental variable." );
Sure, but I'm ok with that. As I tried to explain, I'm not using it as a benchmark, but rather an additional test.
Zero copy initialization.
Thanks. I missed that.
Why do you need the phantom at all? You already have the bound `A: SeqAccess&lt;'a&gt;`
SIMDeez - a simd library similar in spirit to Faster, but which builds on stable rust, and can be used easily with runtime feature detection: [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez) I am currently experimenting with operator overloading, so that may be upcoming.
I think this is similar: [https://github.com/rust-lang/rfcs/pull/1617](https://github.com/rust-lang/rfcs/pull/1617)
ARM Cortex-M processors also have all those integrated peripherals. You can get an M0+ with USB for like $3 a part, no external PHY.
&gt; And in that case you're not working with a .env file per application (unlike what you stated in your question), so you might want to rethink your setup. yeah, but in both cases I'm working with something what sets them
Many ARM chips are available in SOIC packages, those are just as easy to solder as through-hole. You only need an adapter if you want to breadboard with them. A lot of people have an irrational fear of surface mount soldering for some reason, it's just as easy if not easier than doing through-hole.
That's exactly &amp;mut MaybeUninit&lt;T&gt; (RFC 1892), right?
&gt;Eg:`i32` is not the same as C's `int` Yes it is? Take this C code: int add_ints(int a, int b) { return a + b; } And link it with this Rust code: #[link(name = "test", kind = "static")] extern "cdecl" { fn add_ints(a: i32, b: i32) -&gt; i32; } fn main() { unsafe { println!("{}", add_ints(5, 5)); } } I think you'll be hard pressed to find a modern C compiler that generates incompatible code with the default settings.
Interesting point. Any particular chip you'd recommend?
Just bought it! (Thanks /u/Elession for pointing out the coupon). This book is perfect for the next step as someone who's built some CLI tools in rust and is learning systems programming. 
I'm still waiting for mine from no starch :( "Pre-order awaiting shipment"...
How is this functionally different than just returning something and having the compiler turn the copy into a pointer to the stack as necessary?
&gt; Current 32-bit ARM microcontrollers are cheaper, much faster and have better peripherals than the AVR series. AVR is mostly inertia at this point. This is generally true, but I think that AVR is still nice choice if you want to build something extremely cheap and not necessary fast
That's sort of the inverse of what I'm talking about. Both have a requirement to do something before the reference leaves scope, but &amp;move requires a move *from* the reference, where `&amp;out` would require a move *into* the reference (im calling it `&amp;out` because it would make sense for out parameters. but `&amp;init` or `&amp;uninitialized` or something might be more clear)
I feel like this can be accomplished with coding style rather than adding a keyword and special syntax to the language. At the end of the day you'd just create an uninitialized variable and passing a mutable reference to it into a function while checking at compile time that its written at least once before its read, right? I feel like that could be accomplished with an extra lint for variables assigned by `std::mem::unitialized`. 
`&amp;out` pointers have been discussed to the exhaustion by the language and compiler teams. No formal RFC as far as I know, though. The `placement-in` is probably closest to that, but the goals of the syntax were slightly too ambitious and led to its eventual failure. Also, something similar exists at a MIR level to the best of my knowledge.
Can’t wait for this book! Keep it up! :)
Oh, I agree once we get into 32 bit processors. Even for prebuilt Arduino style, the Nucleo boards have tons of I/O and run a fast STM32. For hobbiests trying to full board from scratch, ATTiny or ATMega are much easier barriers to entry for PCB layout and external components.
This is a stronger guarantee than `MaybeUninit&lt;T&gt;`, and isn't intended to replace `mem::uninituialized` in all cases. As long as the `&amp;out` reference exists, the compiler can assume that the referenced memory is not initialized
AVR is pretty ubiquitous, but it might be more advantageous to focus on embedded ARM where Rust might be more of a consideration. Then again, AVR microcontrollers are cheap and the industry probably won't stop using them, so it needs to be a focus eventually. I think we have already put a lot of focus on ARM embedded, so AVR might need more attention at this point.
On 1.27.0 stable I get Error: unused type parameter
I'm not super knowledgeable here, but a cursory look on Digikey tells me that you can get a [PIC with USB for $1.24](https://www.digikey.com/product-detail/en/microchip-technology/PIC16F1454-I-JQ/PIC16F1454-I-JQ-ND/5033392). If I understand the datasheet right, then, because its a 5V chip and has internal pull-up resistors, you can just solder it to a USB jack, which saves on complexity there.
Your attitude is pretty awful. The answers people have provided are correct. It is your own failing that instead of trying to understand it, you try and belittle the people who try and help you.
the lint wouldn't cover cases where you pass it into another function, or if you had an `&amp;out` member of a struct, or something like that. And the lint would also have to make sure you used `ptr::write` or something so that you effectively forget whatever the uninitialized memory is instead of dropping it Also, if you had them as a reference type, you'd be able to do it in safe rust, instead of unsafe
Does the compiler _guarantee_ that said optimization will happen?
Looks like the title was wrong (missing week number) and you can't edit titles. 
Spoiler: It’s fun to write bindings/extern définitions :-].
thanks! this is helpful.
Very similar idea, but different implementation. See the [si.rs](https://github.com/iliekturtles/uom/blob/master/examples/si.rs) example for some very simple usage. You change your type from f32, i32, f64, ... to a quantity such as Length or Time. The compiler then enforces correct usage of those types. Currency isn't included with the built-in SI but you could always make your own currency system.
What is the syntax for apply trait bounds in the following situation: I am implementing the Index trait for a type: impl Index&lt;usize&gt; for I32x4 { type Output = i32; fn index&lt;'a&gt;(&amp;'a self, i: usize) -&gt; &amp;'a i32 { debug_assert!(i &lt; 4); let arr = unsafe { mem::transmute::&lt;&amp;'a I32x4, &amp;'a [i32; 4]&gt;(self) }; &amp;arr[i] } } I try to add a trait bounds for this like so: Index&lt;Self::Vf32, Output = f32&gt;; But it doesn't match up, presumably because of &lt;usize&gt;. Sticking &lt;usize&gt; after index doesn't seem to work.
What about long? Linux has that as 64 bits, Windows has it at 32.
It happens when you post to the wrong subreddit. /r/playrust 
5V is another reason that hobbiest stay in the AVR/PIC world. Interfacing with 3.3V, 2.5V, or 1.8V gets trickier. 
The chapter's title is probably obscure, but that was my intention behind the "Beyond the Server" chapter in part 4. I wanted to demonstrate how to take a library crate to the web via WASM and down to microcontrollers or mobile via cross-compilation
I've been breaking out some utility crates from a cryptocurrency-related project I'm working on, and polishing them to publish. I've just released the first, [simble](https://crates.io/crates/simble): string interning without all the interning, for strings 8 bytes or less. It's probably pretty niche, but my use case is I have to work efficiently with all these different currency tickers (storing, sorting, comparing, using them as map keys a lot), and I wanted to do it without allocations and indirections, or the global state and mutexes usually needed for interning. The really fun part was a feature I just finished: I wrote `const fn`s to validate and create these objects at compile time. It sounds trivial, but given the current state of `const fn`s this required more witchcraft than you might expect; it reminded me of climbing out of the `constexpr` Turing tarpit when that first came out in C++ (or, God forbid, the template games that preceded it). Coming soon: a crate that does runtime dimensional analysis (for when you can't use uom because the types of quantity aren't know at compile time; notice a theme?).
Actually SMD is easier in sane sizes than through hole soldering. Much easier to use hot tweezers to swap caps and resistors. That is until you start doing 0201 passives under the microscope. 
Sorry
Or you want something with [fully static operation](https://electronics.stackexchange.com/questions/1069/can-microcontrollers-be-run-at-arbitrarily-low-clock-frequencies) or whatever.
This is what made me think of it: placement seems overly complex. `&amp;out` is relatively simple (from my limited perspective) Digging through the reasons why `placement-in` was removed, it seems that aidanhs is referring to `&amp;uninit`, which seems to be the same as what I'm calling `&amp;out`. Is that something at the MIR level? (https://github.com/rust-lang/rust/issues/27779#issuecomment-378416911)
Yes, it's called RVO and there's a section on it in the first edition of the book.
Already guaranteed by the RVO provided in rustc automatically
With `long`, I'd say it doesn't matter because the translated Rust code should ultimately not be using platform-dependent primitives at all anyways. You could just as easily translate any instances of `long` to a type that doesn't even exist but stands out in a way that lets the programmer know "hey, this was specifically a `long` originally, you're gonna need to restructure the code" (maybe `LONG_DEF` or something like that.)
Ooo I would really love this. One thing that's really important is best practices when wrapping a C library. I've seen so many instances of bad implementations (ranging from inefficient / inaccessible to plain incorrect) and I think a big reason is that it's really hard. I've been working very hard on making wlroots-rs the best wrapper for wlroots there is (and to ensure a situation like rust-wlc and wlc.rs doesn't happen again).
I'm not aware of any guarantees, but my impression was that any argument or return copy larger than a given size (3 pointers?) got turned into a pointer, even before it hit LLVM(?). Rust doesn't have an ABI so the compiler is free to do whatever it wants. Including inline a function and elide arguments/returns entirely if it can. I'm not a compiler dev, but I've seen rustc inline recursive math functions down to a constant value, so the bar for justifying this sort of special case in my mind is pretty high. Side answer: Copying a small structure that's completely in registers or cache is going to be *way* faster than following a pointer resulting in a cache miss. Where the tipping point lies depends on the CPU and RAM, I suppose. Though dealing with values on the stack it's probably a safe assumption that it will be in cache most of the time.
Thank you, just bought the ebook version. Sadly, the shipping is really expensive to the EU and I'd have to deal with customs if I would have chosen the combo with the printed book.
simble looks cool! Any particular reason for using it over `smallstring`? I suppose not needing to upgrade to the heap ever makes life simpler...
That or just let the user choose what width and signedness is chosen by default for all the C data types. Default to the current platform, maybe leave a comment saying what it was if it's ambigious. Recognise things like uint32_t as just a u32, that's obvious. It would be valid to pick the shortest possible widths, though. (16 bits for an int, 32 bits for a long).
I made a simple service I use for my own purposes using [Rocket](http://rocket.rs) and thought the whole process was fantastic. Rocket is a great framework that made it super easy to just get something running.
Thanks! Did you run into any gotchas or undocumented snags during the process? Also, can you tell me what database you used (if any)?
You know, I don't think I ever searched for the right keywords to find that. `smallstring` totally would have worked for my purposes. With `simble` I went to extremes optimizing for efficiency (more than my project needs, really), so I couldn't support such a general String-like API: the Lexical type supports single-instruction lexicographic comparisons on 64-bit platforms, but that can't be done in a type that also can be borrowed as a &amp;str (except on Big Endian platforms, which are of course superior).
The biggest gotcha with Rocket is that it is Nightly-only for now. But aside from that I thought everything was fairly straightforward and their onsite docs were good. For that project I didn't need a database, but I am currently working with rusqlite which provides a nice SQLite wrapper. I've also heard Diesel is great if you need something more powerful.
I made a simple API server using `rouille` and `diesel` backed by SQLite and Postgres. It went great but I'd probably use something with more API-oriented tools now than `rouille`. Diesel was okay and the devs were very helpful but it took some frustration before I realized that it wasn't really designed to abstract differences in databases, more to allow you to build backend-specific queries in Rust.
I don't think that is the correct crate. They linked to `bit-vec`, which is found here: https://github.com/contain-rs/bit-vec The crate that you fixed is this one: https://crates.io/crates/bitvec
Update to this: users actually will be able to define their own kinds, provided they can stick them in an Any!
From the parser point of view there is no difference. It got inlined though.
Among other things we've built in rust here at [Threat X](https://threatx.com) we have a RESTful API for management and configuration. It has been an absolute pleasure to develop in and work with in production. The language itself is amazing, easy to work with and blazingly fast. The framework landscape has a ways to go but is completely usable today if you are okay with hitting small breaking API changes every now and then. I found some other libraries aren't as mature as I'd like them to be though. Last I looked there isn't a mature library with support for AMQP 1.0, only AMQP 0.9. Of libraries we use, the quality is usually fairly high despite the ecosystem's age. Also every maintainer I've worked with has been amazing. The friendliness and professionalism of everyone in ecosystem is just as big of an advantage as any technical feature. Depending on how bleeding edge you and your team are and what other services you are using, I'd say it's ready. There is nothing wrong with being risk and adverse and waiting until it gets even better though.
I might have to shelve ggez a little while after 0.5 gets released and work on `wasm-bindgen` before all the *cool* bits have been done already...
Aggressively placed my recently received copy of "The Rust Programming Language" in the sight of my CTO at work hoping he catches a hint :)
Ok this was very helpful and I got things working. I got stuck when trying to work with the Index operator, as it needs to be bound as Index&lt;T&gt; where T is the type of the index parameter. I can't figure out syntax to provide &lt;usize&gt; to Index and still specify the associated types. any idea?
I'm a bit out of the loop, what is WebIDL?
It's easier to ask for forgiveness than it is to ask permission.
What is Rust single/2 player like?
I’m on mobile and vacation, so excuse the brevity of my response. Right now (and perhaps through to December when DARPA funding ends) development occurs on a private repo. We get monthly approval from DARPA to update the mirror. The only reason for this setup is to be in compliance with DARPA’s regulations - we all agree this is suboptimal. I’ll see if we can explain this when we write a blog post about c2rust. I joined Galois in large part BECAUSE of corrode/c2rust. This is a project I care about on a personal level so no, I won’t drop off the project once I stop getting paid. However, I don’t expect I’ll work on this forever - I hope someone will come along and want to help maintain (just as I spend my free time now maintaining and contributing to FOSS I didn’t write). On a professional level, we’ll be doing our best to help transition the project.
AVR isn't really very popular in the embedded space at all *except* for Arduino and those are only used by beginners. Everyone else uses Cortex-M. Even Arduino is moving to that (e.g. the Arduino Due). I think the only reason the AVR Arduinos are still used is because of momentum and the fact that they are 5V, though most parts are 3.3V these days so that is really a disadvantage at this point.
You're looking for /r/playrust. This sub is about the Rust programming language. 
Hey everyone, new to rust, but I have a problem with generics. I currently have: `use std::collections::HashMap;` `use std::hash::Hash;` `pub trait AbstractComponentList&lt;IdType&gt;{` `fn RemoveComponent(&amp;mut self, ID:IdType);` `}` `pub struct ComponentList&lt;IdType, ComponentType&gt;{` `components: HashMap&lt;IdType, ComponentType&gt;,` `}` `impl &lt;IdType : Eq + Hash, ComponentType&gt; ComponentList&lt;IdType, ComponentType&gt;{` `pub fn new() -&gt; ComponentList&lt;IdType,ComponentType&gt; { ComponentList{components:HashMap::new()} }` `pub fn AttachComponent(&amp;mut self, ID:IdType, Component:ComponentType) {self.components.insert(ID, Component);}` `pub fn GetComponent(&amp;self, ID:IdType) -&gt; Option&lt;&amp;ComponentType&gt;{self.components.get(&amp;ID)}` `}` `impl &lt;IdType : Eq + Hash, ComponentType&gt; AbstractComponentList&lt;IdType&gt; for ComponentList&lt;IdType, ComponentType&gt;{` `fn RemoveComponent(&amp;mut self, ID:IdType){self.components.remove(&amp;ID);}` `}` And I want to do: `let abstractlist : AbstractComponentList&lt;i32&gt; = Componentlist::new();` With the goal of being able to create a list of abstract component lists with the same id, regardless of their component type, allowing me to remove components with a specific id from it. However, as you can see I cannot make this list for two reasons: 1. Size is unknown, possibly fixable with some kind of box, but thats not the issue 2. There is seemingly no way to specify that I want to create a new componentList, as it requires the type of the component, but there is no way to give it. I tried things like new&lt;i32, bool&gt;() like in C#, but that does not work. Anyone know the solution to this issue?
Thank you sir. Should I take this post down then?
I currently use Rust in production for a variety of (mostly stateless) microservices. The only real pain points are that Rocket, the best suited to microservices in my opinion: 1. Doesn't really support any kind of sane logging config yet (per [#21](https://github.com/SergioBenitez/Rocket/issues/21)) 2. Can't compile on stable (which I solve with a pinned version in CI)
https://www.reddit.com/r/playrust/
AVR still has heaps of inertia behind it. I know lots of people who use it because that's what they're used to, even despite the fact ARM chips can do way more under the same constraints. 
It looks from the example like your shell strings are actually running in a shell, but when I read the code it seems like you're parsing out individual commands and executing them manually. That means shell features like pipes and redirects won't be supported, and will actually be interpreted as positional arguments. You might want to clarify that in the docs / examples.
Does Rust perform RVO if you're for instance copying a returned value to a Box?
It's not very popular but it certainly isn't *not at all used*. But yeah, ARM is the big deal nowadays
I'm working on a Haml library in Rust. I'm learning Rust and so this is my first real project. I am planning on use this library on a static site generator I plan to make next. 
Many of them are taken from "crates of the week". I keep on adding to the list crates I find interesting. The policy is inclusive - better to list something dubious rather than omit something worthy. --- Please suggest your additions, updates or removals. Alternatives to already listed entries are OK too.
The downvotes mean that this is the Rust Programming Language Subreddit. You're looking for /r/playrust
The point is that everything still works and passes all your unit tests the whole way through and each step of the process is small and easy to follow. If you're porting things constantly across the C-&gt;Rust boundary that is harder. It's much nicer to have a correct automated translation to Rust to start with, even if it is just ugly C style code.
I agree with that, I meant more in the sense of, when compiled, does it look the same/act the same as a function call? I guess if it's always inlined then it doesn't matter.
I wonder if there are still plans for https://aturon.github.io/apr/
Yes please, it's not relevant to this community
It's a definition language for web APIs, showing which types APIs accept. It's not strange if you haven't heard of it though. It's pretty much only used in web specs.
I'm currently looking at Actix-web, whose documentation is excellent (at least, compared to Hyper). Still, if anyone is able to help me migrate rust-doh from 0.11 to 0.12, it would be appreciated: https://github.com/jedisct1/rust-doh/issues/7 
Good to know. Is there any reason for me to actually learn about it? Or can u remain blissfully ignorant?
`Componentlist::&lt;i32, bool&gt;new();` suit your needs? 
I am using rust for the backend of a [web-based semantic file system](https://www.schoolbench.com.au/), with the frontend written with typescript/react/redux. Currently sitting at about ~6000 lines of code. 
No, in Rust return value optimization isn't guaranteed. Placement was supposed to help with that.
I have smth like: struct P1 { // some fields } struct P2 { // some other fields } // ... struct S1 { // yet more fields } struct S2 { // totally different fields } // ... enum Prefix { P1(P1), P2(P2), // etc } enum Suffix { S1(S1), S2(S2), // etc } struct Thing { prefix: Prefix, suffix: Suffix, } So, now I want to make a function that returns a collection of a certain subtype of `Thing`, e.g. a `Vec` of `Thing` whrere only `P1` and `P2` are valid for `prefix` and only `S1` is valid for `suffix`. I could just return `Vec&lt;Thing&gt;` but then I'd have to do like `unreachable!()` for every variant of `Prefix` and `Suffix` that I don't expect to receive, which is not good because it's a runtime error. Any advice on how to handle and model smth like this?
The shell macro uses an actual shell. The not-shell macro doesn't use a shell.
Would a major benefit not be that you could pass the reference around? Even store it in a struct if you wanted. You could safely create uninitialised memory anywhere, and pass the ability to initialize to whatever wants it.
`let abstractlist: Box&lt;AbstractComponentList&lt;i32&gt;&gt; = Box::new(ComponentList::&lt;i32, bool&gt;::new()) as Box&lt;AbstractComponentList&lt;i32&gt;&gt;;`
Maybe [https://github.com/Amanieu/atomic-rs](https://github.com/Amanieu/atomic-rs) if you are looking for a library to operate on values, or crossbeam's AtomicOption if you're comfortable with boxed values.
Blissfully ignorant. The only place I've ever seen WebIDL is in codegen for Servo and other browser engines. 
"at all" is probably too strict. It depends where you learned. There are ESP fans, there are AVR fans, the are PIC fans, and ARM is of course popular too. People often start with what their local groups use.
What you're describing, to be safe, would need to be a guaranteed unleakable value. That would add a bunch of complexity, that you don't list there, to work: * The `?Leak` bound to ensure out references don't get put into `Rc` loops * Handle the case of panicking with an unhandled out reference, either preventing it or crashing safely on it * Handle impl Trait. This is a bit hard to describe, but you know what this does? fn do_something() -&gt; impl Iterator&lt;u32&gt; { ... } Well, I want to be able to do that with an out parameter. How can the function's body determine what the concrete type of one of its parameters is? Rust doesn't support that yet.
Cheers! I knew there would be a way to do this.
Hmmm, I'm not really sure I'm understanding your logic around `SIGBUS`. If you don't install a signal handler, then your process should abort upon receipt of a `SIGBUS`. Therefore, there's no memory unsafety there. What's more interesting is what happens when the buffer is mutated. But a `SIGBUS` itself seems like a red herring, no? &gt; tl;dr you cannot use mmap safely, just use read and write and eat the copy. Well, we need to find a way. Not being able to memory map files safely is kinda bad.
You appear to have a few serious misconceptions. First, `new` is not special. Rust doesn't *have* a `new` operator, just functions that happen to be called `new`. Second, Rust does not have interfaces. Traits *look* like them, but behave differently. Important in this case is that you can't have a value of a trait type (these are called "object types", which is unfortunate because they don't behave like objects in languages like C# at all). You should really read through [the book](https://doc.rust-lang.org/book/second-edition/), which should hopefully address some of these issues. In general, remember that Rust is not C#. Trying to write C# in Rust won't work very well.
I know rust does not have a constructor. I wrote the "new" function in my own code. I also know that a trait is not an interface. You dont need to be so condescending, I just could not figure out how to give the type parameters to a generic function that could not infer them from use. The other guy did help me by just showing me how they go (all the things I tried to find in "the book" over the 1.5 hours i spend did not show this).
There's nothing in the language for subsetting enums. If you want to enforce type safety, you'll need to create different enums for each set of variants.
Wrong sub. You want /r/playrust This is the sub for the Rust programming language by Mozilla.
Oh hey! You did global game jam 2017 with a friend of mine. Small world. Glad to see `ggez` is still in use (and thriving!).
Hence why I said "appear". The problems I pointed out are commonly caused by people jumping in and trying to use Rust as a minor syntactic variant of whatever language they're most used to.
Right now I'm following along with [this](http://nercury.github.io/) set of OpenGL tutorials. Completely new to OpenGL and graphic programming - if anyone has any more complete beginner OpenGL tutorials (especially at the "opengl concepts" level) I'll gladly take them.
I run an advertising server using Rust (Iron) and Cassandra, primarily the biggest problems I have at the moment are related to features that are still being worked on for the cassandra driver.
thx dude misscliked
Can I do that via macro somehow?
As u/DannoHung mentions, this would be a case where I'd fall back to using `sh_execute!` and invoking the shell manually. I actually [did have to do that where I need pipe support](https://github.com/tcr/edit-text/blob/master/x.rs#L492). But the docs should definitely mention that special characters from the shell are not special here, and the library should require that characters must be quoted if they appear in the script. Your comment that "anyone using more than the bare minimum features of the shell will have trouble converting their code" is correct, and there are some possibilities here to improve that. For example, I doubt emulating shell subprocesses or functions would be practical (or useful), but basic support for piping and indirection with [os\_pipe](https://crates.rs/crates/os_pipe) could cover a lot of expected usage. As long as it maps directly to a Rust API underneath.
This is probably going to sound like a stupid suggestion, but why not just translate it to a normal test then? Benchmarks shouldn't really be doing any sort of assertion or checking function outputs.
I doubt it would even be possible for the 8-bit PICs. I do a lot of PIC development at work and I don’t even get to use C++, just C through Microchip’s xc8 compiler.
PIC still has a lot of very useful peripherals you don’t tend to see in the ARM world, although they have been closing the gap. It’s been a while since I’ve looked but I don’t remember seeing an ARM with something like a numerically controlled oscillator or complex waveform generator or configurable logic circuits like PIC has. 
I am struggling a bit with ownership when I want to own an object, but at the same time use it to register as an event-handler. For example, I have a `Client` object and want to register it with the `Orchestrator` so I can get a callback at some later time. What is the ownership model I should follow? trait EventHandler { fn handle(&amp;self); } struct Orchestrator { handlers: Vec&lt;Box&lt;EventHandler&gt;&gt;, } impl Orchestrator { fn call(&amp;self) { for h in &amp;self.handlers { h.handle(); } } fn register(&amp;mut self, h: Box&lt;EventHandler&gt;) { self.handlers.push(h) } } struct Client { } impl EventHandler for Client { fn handle(&amp;self) { println!("yay!"); } } fn main() { let mut orch = Orchestrator { handlers: Vec::new(), }; let client = Client{}; orch.register(client); orch.call();
Also note that AVR is one of the few architectures that (a) could plausibly support Rust (unlike PIC), and (b) is only useful in embedded (unlike ARM) - it's thus a great place to work if you want to force yourself to concentrate on embedded use cases, rather than drifting back to desktop/server.
Why is rocket better suited for micro-services than actix-web for example?
Soldering largish surface mount is easier, but getting a board to solder on is not. I know, people keep saying it's so easy and cheap to order a circuit board, but that's really only true when you're planning to make multiple boards, and you have a real budget for things. If you're just noodling around, then a week of downtime waiting for the board kills your momentum. And getting a single board will cost more than the rest of the project combined. For hobbyists, through-hole is still just plain easier to interface with. 
It seems I was mistaken. The section of the book that I read was a bit too hopeful it seems. I don't think any optimization of this kind of done right now.
Come back when you're done. Coffee is for closers.
Cffi deserves a book of its own. How do you prioritize what a single chapter should cover?
Sure, it's possible, but macros can only generate code you can otherwise write yourself, and only from input you explicitly provide. If your code is actually as uniform as your example, it shouldn't be too hard to do.
If you've got multiple references to something, that's shared access. Shared access means `&amp;`, `Rc`, or `Arc`. If you need shared *ownership* (or want to avoid lifetimes), that's `Rc`, or `Arc`.
Why not tho?
Why?
I use pemmican for my own bookkeeping and a few of my own personal websites. I doubt anyone else uses it. I've also written and used a closed-source webserver library based on hyper 0.10 for several client projects, but I regret it's architecture and don't use it for new projects. I have yet to use one that I didn't invent myself.
Rust's ABI isn't yet stable, so statically linking all Rust code into your build output should be the default behaviour. The symptoms you describe are similar to someone I helped who turned out to be using `crate-type = ["dylib"]` rather than `crate-type = ["cdylib"]` with rust-cpython. As a "please double-check that it's plugged in" question, you *are* using `crate-type = ["staticlib"]` in your `Cargo.toml`?
Exactly my thinking. I've been deferring the decision repeatedly. I think that if the chapter goes ahead as originally intended, it will be some stateless extension module that's a small collection of functions. That approach suffers though because it's slightly artificial and avoids lots of complicated issues that people actually want help with.
Thanks. My problem is that Rc will not work as the callback needs "mut" `fn handle(&amp;mut self)`. I think I need RefCell? Is that right?
How would you represent the lifetime of the value though? This would require a binary split of the lifetime for each stored out reference which, to the compiler, is two entirely different types if the lifetimes are different (hence why Any is a supertrait of the 'static lifetime bound, the compiler can't provide a typeid for the type if it has a non-'static reference since that makes it an unnamable type).
Going with Rocket is a tradeoff of less performance for a gain in ergonomics and being tied to nightly (for now). It's personal preference and both projects are young (Actix-Web more-so). They have pretty different focuses so it depends what you need.
Do you mean the binary or the source? On my machine my default toolchain is about 300 megs.
this subreddit isn't about the game. that's /r/playrust, and they would probably just tell you to Google it. the internet says maybe 1.5GB. Please delete this and post it on a more appropriate subreddit after reading the rules of the subreddit and finding one that it applies to.
Just asking because you said it's the best so I was trying to understand how. But yeah, personal preference is personal preference, the trade-offs end-up being very subjective.
My code is indeed as uniform as in the example. What I tried to do was to define a new enum by concatenating names of all variants I care about, e.g. `enum P1P2 { ... }`, but I couldn't find a way to define a new identifier in a macro. Also, even if I could, I imagine there would be a name clash if I were to call the macro twice. I also couldn't find a way to just generate a random identifier. So yeah, that's why I'm here.
Hi! Thanks for taking the time to reply. &gt;As a "please double-check that it's plugged in" question, you *are* using crate-type = \["staticlib"\] in your Cargo.toml to generate the .lib file and using #\[repr(C)\]and extern on the data structures and functions you want to expose to C++? Sure, I'll show you what I have currently since the test code is very simple. My rust project looks like so: extern crate rand; use rand::Rng; #[no_mangle] pub extern fn make_some_noise() -&gt; f32 { let num = rand::thread_rng().gen_range(-1.0, 1.0); num } and my cargo.toml file looks like this: [package] name = "rust_random" version = "0.1.0" [dependencies] rand = "0.5.3" [lib] name = "rust_random" crate-type = ["staticlib", "cdylib"] If I remove the rand::thread\_rng().gen\_range(-1.0, 1.0) call, I can get this code to call without any problems.
https://github.com/Lokathor/retro-pixel-rs/blob/master/src/u32_ext.rs#L439 and also elsewhere in that module. It's a basic software render in SIMD.
Go out of here bloody lecturer. 
https://learnopengl.com/ http://opengl.datenwolf.net/gltut/html/index.html Note that `winit` is a lot better than using `sdl2`.
I'm actually kind of curious as to why you don't think PIC could be a reasonable target. The only real problem I see is that to date there is only the incredibly poor quality closed source commercial C/assembly compiler for PICs. A no-std stripped target that actually does some minor things on the arm targets can be in the hundreds of bytes so program size isn't going to be an issue. Someone would need to make the compiler but even the lowest end should be capable enough.
Macros can't generate identifiers. You could probably do it with a custom derive, though. The simplest way is to just *give* the name of the generated enum to the macro.
If you're using `Rc`, yes. If using `Arc` you'll want something like `Mutex` or possibly `RwLock`.
I have a lot of variants for each enum and I'd use the macro in a lot of contexts so passing an identifier isn't really an option. I'll look into derive macros tho, thought it was a bit too advanced a feature, but I guess that's what I need, ty for advice.
Could you explain why you discounting the `&amp;MyTrait2` versus `&amp;S` difference? Those two are the same as `fn my_func1(var1: &amp;MyTrait2)` versus `fn my_func1&lt;S&gt;(var1: &amp;S) where S: MyTrait2` outside a trait. The first is a [trait object](https://doc.rust-lang.org/book/second-edition/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch), while the second is using [monomorphized generics](https://doc.rust-lang.org/book/second-edition/ch10-01-syntax.html#performance-of-code-using-generics). In future Rust, the type of `var1` in the first one will have to be written something like `&amp;(dyn MyTrait2)` emphasising that it is a dynamic object.
I've done several commercial products using the STM32 series of chips, in varying sizes / complexities from the F0 series up to the F7. 
On the STM32s you can use the onboard timers as NCOs. Most of them have an onboard DAC, sometimes up to 3 channels, if you need to do waveform generation. Not aware of any with configurable logic, but given the high clock speeds you can just do that with GPIOs at pretty high rates.
The first example is dynamic dispatch because the type being referenced is a trait, while the second example is static dispatch because the type parameter `S` will be monomorphized by the compiler. In the first example, any object you put in will be treated as a reference or pointer to `MyTrait`. Pretty simple so far. However, in the second example, the compiler will generate implementations for each version of `S` that is used in your program. See the snippet below for an extremely simplified explanation of static dispatch: ``` // Static dispatch trait MyTrait { fn my_func1&lt;S&gt;(&amp;self, var1: &amp;S) where S: MyTrait2; } struct Consumer; impl MyTrait for Consumer { fn my_func1&lt;S&gt;(&amp;self, var1: &amp;S) where S: MyTrait2 { var1.do_it() } } trait MyTrait2 { fn do_it(&amp;self) {} } struct Payload1; impl MyTrait2 for Payload1 {} struct Payload2; impl MyTrait2 for Payload2 {} fn main() { let consumer = Consumer; consumer.my_func1(&amp;Payload1); // Compiler generates `my_fun1_Payload1` method implementation consumer.my_func1(&amp;Payload2); // Compiler generates `my_fun1_Payload2` method implementation } ``` By contrast, see the also extremely simplified explanation below for dynamic dispatch: ``` // Dynamic dispatch trait MyTrait { fn my_func1(&amp;self, var1: &amp;MyTrait2); } struct Consumer; impl MyTrait for Consumer { fn my_func1(&amp;self, var1: &amp;MyTrait) { // ... } } trait MyTrait2 { fn do_it(&amp;self) {} } struct Payload1; impl MyTrait2 for Payload1 {} struct Payload2; impl MyTrait2 for Payload2 {} fn main() { let consumer = Consumer; consumer.my_func1(&amp;Payload1); // Compiler doesn't generate anything consumer.my_func1(&amp;Payload2); // Compiler doesn't generate anything } ```
That's why you buy a dev board first to noodle around on. STM32 has an excellent series of boards called NUCLEO that break out all the pins on the chip and are also arduino compatible. Once you've got a hardware design settled then you can order a PCB. They're pretty inexpensive from places like OSHPark.
What is the **exact error message** that you get? What compiler and version are you using (gcc, clang, msvc, other)? What compiler flags are you using? What operating system are you on (I assume Windows because of .lib) - Windows might get problematic, since some compilers (gcc) [have problems linking Rust code on Windows](https://stackoverflow.com/questions/43866969/how-do-i-create-a-static-library-in-rust-to-link-with-%D0%A1-code-in-windows). Or it sounds like [this issue](https://github.com/rust-lang/rust/issues/31233) (if you are using MSVC) - in your C++ code, use: extern "C" { extern int32_t make_some_noise(); } instead of just: extern int32_t make_some_noise(); Can you maybe make an example repository of how you are trying to link them from the C++ side (like a hello world repo), so that others maybe reproduce the issue? I'm not an expert in this topic, but to me it seems more an issue with the C++ side than with Rust - since you said that you can generate the static library. If others could reproduce the issue, that may be helpful.
I didn't know it was possible to borrow/reference literals like that, I guess they have static lifetime? That seems like it would work in this situation and allow the BitVec to more easily replace the existing use of a Vec&lt;bool&gt;.
https://www.mayoclinic.org/healthy-lifestyle/adult-health/in-depth/anger-management/art-20045434
I do use devboards (no way I could ever solder, say, a BGA by hand). But I also need to build my own circuits. That's where the problem usually arises. &gt; Once you've got a hardware design settled then you can order a PCB. That's what I'm talking about: Once I have a design settled - I have the device I want. I have no need for or wish to order a PCB just to redo the design I already have working. Especially if I used a very inexpensive devboard (think Arduino-level) that's cheaper than ordering the PCB in the first place. 
LOL well fuck me
You can take a reference to any expression, and when needed stuff like `use(&amp;expr)` is compiled as let x = expr; use(&amp;x); And due to [rvalue static promotion](https://github.com/rust-lang/rfcs/blob/master/text/1414-rvalue_static_promotion.md), when possible it's compiled as static X = expr; use(&amp;X);
MIR has a specific representation for the return value. Which is independent of the ABI because MIR handles generic functions and thus doesn't necessarily know if the return value goes in a pointer or not.
I've created proc macro for test cases similar to nunit. We use it a lot in company when I work: https://crates.io/crates/test-case-derive
https://github.com/dtolnay/proc-macro-hack is the main way to do a `function_like!()` macro using the custom-derive machinery today. Hope it works well!
I have built something similar a while back [run_script](https://github.com/sagiegurari/run_script)
I tried your scenario, and it worked for me. Here are my notes: \-Visual Studio 2017 \-I'm pretty sure I have cargo/rust set to compile with x86\_64-pc-windows-msvc target triple. \-Used same rust source file and Cargo.toml \-Here's my c++ program: #include "stdafx.h" #include &lt;iostream&gt; using namespace std; extern "C" float make_some_noise(); int main() { float noise = make_some_noise(); wcout &lt;&lt; L"Hello!\r\n" &lt;&lt; L"The noise is: " &lt;&lt; noise &lt;&lt; endl; return 0; } \- In Visual Studio project property pages... \-- Linker --&gt; General =&gt; Additional Library Directories: I added the path to the .lib file. For me it was $(ProjectDir)..\\rustlib\\target\\debug. \-- Linker --&gt; Input =&gt; Additional Dependencies: I set it to the following, or else I too saw linker errors: `rustlib.lib;userenv.lib;ws2_32.lib;%(AdditionalDependencies)` Built the Debug/x64 configuration. My guess is you're missing userenv.lib and ws2\_32.lib, and that explains the errors. I assume the rand crate has functions that call into functions in these Windows libraries, and the linker needs to be able to see them, even if your program never ultimately calls into any of them.
\_Is it\_ a high priority for the rustverse? I don't get that impression.
On the flatbuffer rust support, is there some ongoing work? And would datafusion requires read only to arrow scheme or read/write access?
I bought their digital copy as an encouragement.
 pub enum List&lt;T&gt; { Node(T), End } I'm not sure that this does what you're expecting it to. This is basically the `Option` type, just with different names. I assume that what you want is this: pub enum List&lt;T&gt; { Node(Node&lt;T&gt;), End } The second problem, which is what the compiler error is talking about, is that you're constructing a `List` with the variant `Node`. However the arguments you're supplying and your use of braces instead of parentheses means that you're trying to construct a `Node`. The correct way to construct a node is as follows: Node { data: t, forward: Box::new(List::End) } But your `new()` function needs to return a list, so you then need to wrap it in one: List::Node(Node { data: t, forward: Box::new(List::End) })
Are you sure you want to use the linked_list Node structure. And not the structure Node above your code. Or is that code just for demonstration. Maybe the structure out linked list module does not content those fields.
Thanks so much for the quick response ! I was getting confused with all the syntax =/ Indeed that's what I wanted !
Really cool!
Looks nice!
Thank you, that will do nicely. :)
He should post on /r/playrust instead. Read the fucking sidebar my guy.
The predict function takes as ndarray &amp;Array1 and &amp;Array2 as input. Are the arrays arbirtarily sized? What is the difference between those types? 
 function callee () { // TODO: Implement me } function caller (callback) { // TODO: Implement a task callback(); } caller(callback); I think you meant `caller(callee);` here. let status: bool = true; while true { // add some case that can set `status` to false } I'm pretty sure you meant `while status` here.
I am currently trying to use Actix-web but struggle with integrating state/database: `Cannot move out of captured outer variable in an `Fn` closure`. Unfortunately many examples provided by web framework are stateless. I like Rust, but it's a bit sobering. In other languages it's a matter of minutes. :(
I would like to say that: saying that it is like X is cool for X users but if you don't know what X is, you need to search X to now what it is talking about. That's being said, this looks to become a really great tools in the future.
Oh, I didn't say that. If we're picking sides - strictly for microservices - I would pick Actix. They're both great though.
Wow there's a bunch of great responses here! I don't think I can reply to everyone directly so I'll just leave this here. I'm delighted to hear your feedback and I now feel confident enough to try Rust on the next project I do. I'm coming in from a Python (Flask+SQLAlchemy/Django) + PostgreSQL background so I guess it should be fun. Thanks again for the responses! 
Because it's a benchmark, and I'm using it as such. Locally, that is. But I'd want it running on CI, too, since it's kind of involved, and the fact that it compiles and runs without errors is meaningful. I could just run it as a benchmark on CI as well, but I kind of figured I wanted to save up on resources of a free service. I could also just duplicate the code into a test properly, but DRY and stuf...
I don't understand what you mean. What are both cases, what are you working with and what is set?
I gotta say with this approach that unexplained `"foo".to_string()` really sticks out like a sore thumb. For someone well-versed in Rust it's easy to say "well duh it's to make an owned heap copy of the literal stored in the `.rodata` section of the binary" but for someone coming from a language with automatic memory management this will just seems like a redundant, magical incantation. To them `"foo"` already *is* a string, and now you have to make it a... double-string or something???
Maybe `to_owned()` makes more sense for a beginner, because it helps you understand that you don't own an &amp;str and thus cant modify it.
There's a production quality AVR backend for LLVM that the Rust compiler can use - it's maintained upstream, so there's nothing needed to keep it working when rustc moves to a new LLVM version. In contrast, none of the PIC backends are maintained, so as well as the improvement to rustc and the core library, they'd have to maintain a PIC backend.
Agreed. I think `to_string` is really rather misleading and gives a newcomer the impression the language is so poorly designed you have to actually tell the compiler that strings are strings instead of there being a deeper meaning to it.
toString can and is used as a 'stupidly named' clone in string implementations of several languages that just jam toString in the upper part of the object hierarchy. But yes, i rather think it was a mistake for this to happen in rust.
&gt;This site uses HTTP Strict Transport Security (HSTS) to specify that Firefox may only connect to it securely. As a result, it is not possible to add an exception for this certificate. I think if you're using HSTS, you should make sure your certificate stays up to date. Otherwise, people will start posting work-arounds, thus diminishing the positive effect of HSTS.
Looks like they're using Let's Encrypt whose certificates need to be renewed periodically (at least every 3 months). Maybe the renewal automation or something failed?
Someone opened an issue on their github page: https://github.com/onur/docs.rs/issues/215
 [profile.bench] opt-level = 0 Or maybe use level 1 instead, for a good compromise between compilation time and performance. 
Some questions I had when reading this: 1. How close is this to being used in Servo? (Also, I'm assuming this approach is not suitable for Firefox because it relies on Rust's type system for soundness?) 2. Is there any experience with the ergonomics in practice? If I'm reading this right this system completely excludes having a mutable reference to more than one JS managed object at a time, and it has all native data associated with JS objects managed by the JS garbage collector. This seems like it might be overly restrictive but it's hard to get a feel for it. 3. What are the tradeoffs compared to having the Javascript garbage collector walk Rust stack frames, for example using LLVM's GC support? Not expecting people to hand me answers to these, I could certainly find answers to some of these using Google, but right now I don't have the time and maybe people feel like answering :)
Sound easy enough, thanks! Any good idea how I can have `opt-level = 0` on CI, but not locally? Can I maybe use a command line switch? The [book](https://doc.rust-lang.org/cargo/faq.html#does-cargo-support-environments-like-production-or-test) makes it sound like `--opt-level=0` should work, but it is not clear to me if that needs special treatment so it's passed to rustc...
If you're playing with generic lists, you may be interested in this series of articles (not mine): http://cglab.ca/~abeinges/blah/too-many-lists/book/ It deals with implementing proper linked lists in Rust, you may find some hints and ideas when you're stuck.
It can't be deprecated (easily). It's a convenience method for all types that implement `Display`, which includes `&amp;str`/`String`.
By curiosity, what do you mean by API oriented?
I guess consistency for the Display type uses is worth the confusion, but i really can't say i'm thrilled about it.
And what are the work arounds you've found for HSTS? Change your system time?
If you talk about JSON-like structures I kinda expected you to tell the reader about serde :)
Don't know much on the topic to contribute something myself, but have you looked into how Rust playground does things ( [https://github.com/integer32llc/rust-playground](https://github.com/integer32llc/rust-playground) )? Might be a good starting point
Rust's safety guarantees are about protecting you from yourself, not from others. Hackers are already finding ways to break out of JavaScript sandboxes, and those aren't even directly running native code. I imagine breaking out of a Rust "sandbox" would be significantly easier and faster. You could use a prohibition on `unsafe` code as an extra defense-in-depth layer, but I wouldn't rely on it. If you want to run code you don't trust, use something specifically designed for that purpose.
I don't work around HSTS. It's a security feature where websites ask the browser to make certificate errors non-overridable for the user.
Exactly, hence why I'm wondering why you're saying having your cert out of date would make people find workarounds... For which there aren't really any.
HSTS only works if you've been to the site before and it's let the browser know that it wants to enforce HSTS for X amount of time. You can bypass the error on incognito, since there shouldn't be any history there of visiting a valid https version of the site that sets the HSTS header.
&gt;For which there aren't really any. ctrl(command)+shift+h, find site, click forget this site in popup menu. tadam
`Array1` and `Array2` are one- and two-dimensional arrays, respectively. They are new types from `ndarray`. Unfortunately, I cannot link the documentation right now, because docs.rs is not available (certificate expired). It is probably prudent to `assert!` somewhere that the arrays have certain dimensions, but `dot_impl` from `ArrayBase` is doing that. The predict function is probably going to be a bottle neck. `dot`, `t`, and `map` are all allocating, I think.
Absolutely this. Limiting customer code to nostd means they won't have access to a *lot* of useful stuff, e.g. `Box&lt;T&gt;`, `Vec&lt;T&gt;`... and without `unsafe` they won't be able to implement those things themselves. Just very aggressive sandboxing instead, like the playground. Or pick a language more suitable for this purpose such as Lua.
You're not bypassing HSTS, which requires you use HTTPS with that website, you're removing your browser's remembering to just go directly to HTTPS without checking HTTP. You still have to accept the (expired) certificate, and can't use HTTP.
From my comment below: You're not bypassing HSTS, which requires you use HTTPS with that website, you're removing your browser's remembering to just go directly to HTTPS without checking HTTP. You still have to accept the (expired) certificate, and can't use HTTP. Also, that seems like a FF shortcut I'm guessing? Chrome doesn't work.
For a workaround, you can use IE if you are on Windows. It allows you to ignore the certificate error - other browsers don't seem to have an option for doing so. I never thought I'd say this one day, but: This website is better viewed in Internet Explorer.
To start with Rust I'm working on a Chip-8 emulator. Hopefully it'll work well. I'm using gtk+cairo to do the rendering and input, both of which I've also never used. (Well GTK a tiny bit when C#, but not much...)
Please don't post work-arounds for security features. :(
 for i in range(0, len(myStrTokens)): print("%d: %s" % (i, myStrTokens[i])) This reads more like C. This is more idiotmatic Python: for (i, line) in enumerate(myStrTokens): print("{}: {}".format(i, line))
rustc imposed jails aren't really possible, there are at ton of soundness holes. These are the known ones: https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22 Just use good sandboxing, like via virtualisation or such.
Let's use \`dyn Trait\`
Agreed. I had just used the same syntax as the OP for illustration purposes. Ideally, one should be migrating to `dyn Trait` everywhere.
Would you consider replacing this chapter with one on error handling?
What is it that you are interested in Rust when switching from Python/Django? It seems to be an industry standard web development system with all bells and whistles. I am asking because I am looking at different web development options these days, and Rust/Haskell interest me most because of their promises of static typing. Actually, I find Haskell even more interesting, but the developer tooling/teaching situation seems to be not as well developed, and the language seems to have an even steeper learning curve. 
Make sure to sandbox the compiler as well, not just the resulting program.
This weekend I released the new English language version of Encycolorpedia (https://encycolorpedia.com/); I used Rust + Hyper for the colour pages (https://encycolorpedia.com/93c572) other more trivial pages and the backend API are Golang. Rust really excelled in performance for colour transformations and sorting paints by visual similarity - SIMD landed just in time to super charge some conversions!
It is indeed currently missing, see [related issue](https://github.com/lalrpop/lalrpop/issues/382). I had no issues just `use`ing the module directly, so perhaps try that.
I'd recommend itertools
It's not a feature if it requires a workaround; the workaround here seems to be for a harmful restriction.
IMHO all syntaxes to guarantee optimizations are terrible; it is the compiler's job to optimize code, and if an optimization isn't applied, it should be because it isn't useful or applicable in that situation.
I guess that works for hobbyist stuff, I'm mostly interested in making things I can give or sell to other people. Having stuff just hanging off a dev board isn't really the best way to do that.
That has already been covered fairly extensively in ch4 iirc :)
This has been fixed.
Didn’t the performance discrepancy get fixed a while back? Actually, I don’t remember which was faster.
Or `"%s: %s" % (i, line)` or even `f"{i}: {line}`. There's (not) just one way to do it, any more. Jokes, aside, I think you raise a good point: the Python can be written to be essentially identical to the Rust (by `i` -&gt; `line_no` in your code), which is cute.
The article is from 2017. I agree that a sentence &gt; Well, Rust has no built-in support for JSON objects, but before you let that throw you off, Rust structs are ~ 99% identical to JSON objects written today, should be replaced with a hint to the [json!](https://docs.serde.rs/serde_json/macro.json.html) macro.
Maybe also talk about the lack of iterator invalidation.
Placement isn't just an optimization, if affects also correctness. Returning a very large array in the heap might crash the program with stack overflow, because the array may need to touch the stack first. With placement this doesn't happen. It's just that, in the absence of this feature, currently this is done as an optimization, on a best effort basis. (and no, if an optimization isn't applied, we can't assume it's not useful or applicable; current compilers are very dumb)
Known in Java as `ConcurrentModificationException`.
Something is seriously wrong if an open source browser vendor takes away fetaures from the user because they think they know better.
Correct, SIGBUS does not mean memory unsafety. However, it does generally rule out the use of `mmap` in library code (libraries should not crash the process). Furthermore, you are basically limited to expose the buffer as a `&amp;[Atomic&lt;u8&gt;]`, which is virtually useless as no library functions take that type. That is why I say that you cannot use `mmap` in safe Rust: because the only way to get something you can actually *use* (like an `&amp;[u8]`) is to take the copy.
FluffySupreme's answer about the number of dimensions is exactly right. The types are defined [here](https://github.com/bluss/ndarray/blob/master/src/aliases.rs), although a bit of digging is required to follow the type aliases. Where *N* is the number of data points and *M* is the number of features, `ws` is an *M*-length vector and `xs`is an `N x M` matrix.
Ok, so what's the lowdown with bitfields in Rust? Honestly, for a language that insists on being called a systems language, the lack of native bitfield support is quite shocking. I have seen a couple of crates that kind-of-sort-of provide the behavior I'm looking for, but not in an elegant way like in C using bitfield struct members. For reference, I'm writing a kernel, and I fear that lack of native struct level bitfield support is going to be a major PITA when it comes to device drivers. So what's the community's feelings here?
Polishing \[doryen-rs\]([https://github.com/jice-nospam/doryen-rs](https://github.com/jice-nospam/doryen-rs)), an Ascii console for roguelike developers with GLSL accelerated rendering and native/wasm-unknown-unknown support. I still have to figure out how to design a virtual key code API as right now, it only supports scan code based keyboard input.
Yeah compilers are dumb, I know that, which is why I consider it a big in LLVM
&gt; you're removing your browser's remembering to just go directly to HTTPS without checking HTTP How is that different than bypassing the HSTS directive?
FYI most of those unsoundness holes are on unstable features, which is why they are unstable. 
How does this compare to duct?
* Java-like nulls are simply nonexistent outside raw pointers, not just avoidable * Real const references, no "defensive copying" or hacky UnmodifiableCollections needed * No unexpected mutating of an object through a reference by someone else even in the same thread * Affine typing let you write stateful types where every state statically only gives access to operations meaningful to that state * The `#[must_use]` attribute to prevent ignoring of important return values * Pattern matching must be exhaustive, statically enforced
That's a very good point. Perhaps I could preallocate some space to put the results of the dot product and map operation into. I'm not certain of this, but `t` probably shouldn't allocate because it returns an array view instead of actually creating a new array.
There is a list of websites (maintained by chrome) that are "always use hsts" but it doesn't look like docs.rs is on it. (Some entire tlds are on, particularly google owned ones).
Ah yeah, fair point, you're right. But the difference is still that the browser _doesn't let me continue with an invalid certificate_ when it remembers the HSTS header, while it does let me go on if I remove the browser's to go directly to HTTPS. This makes me wonder, for a normal user, if you'd ask them to just use incognito (or they get used to it), would they realise the difference between a screen like that that tells you that the certificate is expired vs the certificate is self signed or for another source or something like that? I guess it's a pretty particular situation, but just a thought.
There are a few macros that can do this sort of thing in the `bitfield` crate. If arbitrary sized integers ever become an RFC and land, then it could be done with that. The RFC for bitfields is still open , https://github.com/rust-lang/rfcs/issues/314 , but pretty inactive. I don't think there is anyone working on bitfields in Rust at the moment.
These are all really useful (stateful types especially is one I love but had completely overlooked). For some reason I had it in my head that Java switch statements were exhaustive too. Just tested this theory and felt a chill wash over me.
Would it be possible to accept or a slice, so that arrays of arbitrary dimensions can be accepted? Or is there another way to accept stack arbitrarily sized stack allocated arrays, since Rust still lacks integer generics I think.
They're equivalent nowadays, yes.
As always, I'll gladly add this important piece of context: &gt; Rain is an open-source distributed computational framework for processing of large-scale task-based pipelines.
How about using `String::new("foo")` ? I which `Cow&lt;str&gt;` was more pervasive, language-integrated and used by default for strings, that would be way easier to newcomers.
Send/Sync are definitely the most amazing tools, mainly because no other language that I know provides something similar.
&gt; No, in Rust return value optimization isn't guaranteed. My understanding is that it's still supposed to. For example: https://godbolt.org/g/DTMQM5
My understanding is different than the above thread; RVO and NRVO are supposed to happen, as far as I know.
Compiler's a bitch and will outright refuse my dirty hacks. So I trust it that if there's no `unsafe` in imported code, it should be sane.
I mean, it definitely doesn't "rule out" memory maps in libraries. I've been doing it for quite some time with the `fst` crate, which also has production users. They seem happy and I haven't heard any complaints. I suspect there is a bit of "perfection is the enemy of good" going on in your comments. :-) I don't altogether disagree with you, but I really think we need to find a way to make it work, or at least provide advice on how to manage memory maps in library code. It sounds like the library must always expose something that requires the caller to utter `unsafe`, which seems pretty miserable.
The bitfield crate just feels hacky. I have no problem shifting and masking bits over a standard data type; I just thought with the systems-level focus that this would have either been included by default, or that more people would be clamoring for support. Thanks though.
AFAIK, `1e300 as i8` is still undefined behavior.
For us (me and my team), the primary reason is switching to a typed (yet sane!) language.
What are the intentions behind HSTS? Do you agree with them?
- Newtypes as ways to represent things like EmailAddress or UserId as statically validated without an extra indirection/allocation like Java would require (if you had an EmailAddress class) - Enums and Traits as a better way of representing either A or B *objects*. (better than sub-classes which imply substituability, and also are restricted to having a single parent).
Someone seems to have fixed this as of 0910 Eastern US time on 3 July.
I don't get why so many people post release announcements while leaving out the most useful piece of information. Thanks for your service, /u/killercup. 
Thank you for the comment, /u/killercup! I added the line to the post as well.
The amount of UI research that goes into how to display HTTPS errors is staggering. Some of the tiniest details are actually features, like how security message popups overlap the URL bar, to make it harder for malicious pages to fake those popups. Browser vendors know quite a lot.
I would say Traits are equivalent to Java Interfaces, Rust doesn't really have anything like Class inheritance (by design).
&gt; and it can help us design better metrics for evaluating the human impact of language features and tooling. Damn! People doing sensible research!
My biggest criticism of the second edition of the book is the order of the chapters. I think the Ownership &amp; Borrowing chapter should have a much stronger focus on lifetimes (make it clearer that the lifetime of an object is tied to the ownership of its binding, gets dropped when the binding goes out of scope). I can see why lifetime annotations (naming lifetimes) are introduced later along with generics, but I believe the concept of lifetimes should be introduced much earlier on. I also think the Generics &amp; Traits chapter is far too late into the book. I think understanding these concepts is very fundamental to Rust and it seems nonsensical to teach the module hierarchy and collections before it. I would move chapter 10 in between 6 and 7 and I would swap the order of 8 and 7. I personally prefer the structure of the first edition of TRPL. Even though the first edition is not as well-written, less detailed and probably less clear for beginners, I think its structure makes a lot more sense. It nicely goes through the various syntax and features of the language in a straightforward way. I am personally a little sad to see the first edition being sworn off as a historical artifact, never to be updated again and being actively recommended against. I personally really like it. I recommend it to people due to the more logical structure. I encourage people to read it under the premise that due to Rust's stability guarantees, the knowledge there is just as valid, so they don't have to worry about reading outdated stuff.
You can pass extra compiler options through cargo using the `RUSTFLAGS` environment variable. `RUSTFLAGS="--opt-level=0" cargo bench` or whatever
Good questions! 1. Quite a way off I'd say. We have had experience with using similar ideas in Servo, in particular hooking rooting into Rust's lifetimes. This still uses interior mutability though, and the refactoring required to avoid that is pretty significant. Servo uses a per-thread global variable to store the JSContext, and we'd need to replace that by a scheme of explicitly passing round the JSContext. This would be quite a refactoring, and we'd need to work out a transition plan for doing it gradually. 2. Only on small examples, I'm afraid, where it wasn't too bad, comparable to using Rust's interior mutability. Measuring ergonomics is hard. 3. The implementation is pretty agnostic about where it gets its rooting information from, either by explicit tracing code, or by something like llvm stack maps. Stack maps would help to avoid the pinning that Josephine has to do, to stop Rust from moving rooted data. Thanks for reading the paper!
Yes, work is happening on this fork: https://github.com/rw/flatbuffers/tree/2018-02--rust DatFusion needs to be able to serialize and deserialize data so that it can be streamed between nodes.
Traits are a bit more powerful than Java interfaces - for example you can implement your own trait for types that already exist. Traits can also have associated types and other fancy things.
Thanks for this! I’ve already started on the next edition; I’m not making major changes like this at the moment, but I am considering them. We’ll see!
Sorry OP said that, I thought you were them.
Ahhh that's good to know, thanks!
Looks like it's Rust code is here: https://github.com/lunemec/rust-birkana-http
With uX, it actually stores the numbers in the next largest integer type, so your struct would end up larger than necessary. It probably won't be an issue but you should keep that in mind.
Hmmm. Thanks for the heads up.
This looks really cool! I've been looking for something like the `execute!` macro for a long time now. The automatic escaping seems especially nifty! Are you aware of the conch-parse project (https://github.com/ipetkov/conch-parser) ? It might be a fun (but a very large) project to plug something like it + rust coreutils into `execute!`, so that it works as a real cross-platform shell, with pipes, `cp` and such. Using `cargo-script` to enable `./x.rs` is also cool, but unfortunately that requires that the user has `cargo-script` installed, and that the OS understands `#!` :( I wonder if there's some actually good way to provide such command-launching utilities in a cross-platform way... I know a couple of options, but they all have drawbacks. * Abuse `cargo run` for this, like the "make your own make" blog-post did. This assumes that Cargo is present (which is OK for rust-specific project), and either has ugly syntax, or ugly alias-based workarounds. Hopefully, [workflows](http://aturon.github.io/2018/04/05/workflows/) will make it better though. * Provide two bootstraping scripts, like `./x.rs.sh` and `./x.rs.bash`. This is how things like gradle wrapper work. The problem here, besides two scripts per se, is that you'll need to do some-kind of bootstrapping of more powerful language anyway. For example, when using gralde wrapper you commit a jar file as well, and that jar actually does all the heavy-lifting. * Provide a script in a widely used language. This is how `x.py` works, and again this requires the user to have a python installed. 
Treating code in doc comments as tests has been an amazing feature for ensuring documentation stays in sync with code.
Java-like nulls: Is non existent correct? If you call unwrap on options carelessly you get an equivalent result right? I agree that having to take an extra step to get a null error is a good and important thing though.
Coming from Python I remember using Java's StringBuilder as equivalent for Rust's String. Super wonky analogy I know, but I kind of got a feeling when to use which, and later realized what was really going on.
I am interested in * Macrology * [Compiler Plugins](https://doc.rust-lang.org/unstable-book/language-features/plugin.html) * [Attributes](https://doc.rust-lang.org/book/first-edition/attributes.html) * [AoP](https://en.wikipedia.org/wiki/Aspect-oriented_programming) If anyone has info on how to combine those, I'd love to know them. I made a list of [Rust Units of Measure](https://www.reddit.com/r/rust/comments/8antcq/does_rust_have_distinct_type_aliases/dx14d4f/). There is also the property based testing tools * https://github.com/BurntSushi/quickcheck * https://github.com/AltSysrq/proptest 
You can't really do better. If a programmer wants to do something unwrap-like, they're going to do it. Rust just makes null values an explicit part of the function signature and culturally discourages lazy use of unwrap/expect. Any turing complete language would let you implement pseudocode like this which is worse: if variable == arbitrary_value: send_signal(get_own_pid(), SIGKILL)
You should probably post a playground link to the actual code so folks can see specifically what's happening
I usually make this the core point of my "Rust for Java programmers" talks. While the distinguishing feature of Rust is memory safety, Java has it for free because of the GC. Features like sum-types, controlled mutability, pattern matching and modules/libraries are nice, and a missing in Java, but they are not specific to Rust. Performance might be a tough sell: it's true that Rust programs can be faster than Java, and that they generally use much smaller amounts of memory but a lot of people think that Java is pretty darn fast for most use-case, and I don't think those people are actually wrong. In contrast, thread safety is definitely a major every-day problem in Java. Questions like "should this field be `volatile`", "should I take some mutex to access these data" are everywhere, and are not fun to deal with. It's really liberating that in Rust you can say "ok, this stuff is **not** thread safe" and be sure that several months later you won't accidentally close over it with some lambda which is sent to the other thread. 
&gt; How about using String::new("foo") ? Seems to still suffer from "why am I telling the compiler that this string is a string" whereas "to_owned" is "ah, im telling it it is an owned string". As for Cow, that would be painful I think? Though I've started throwing T: Into&lt;String&gt; and T: AsRef&lt;str&gt; on a lot of my code, much to the benefit of caller ergonomics.
And i alone know how i want to use my computer. So they can fuck right off, if such "i know better than you" attitude persists all sane people will switch away from the browsers that have become too commercial in thinking they can deny the right to choose.
Forcing the use of a match statement would be a little better (safer, maybe not better) but of course you could still just None =&gt; panic!("null pointer exception") Having unwrap save you a lot of typing when experimenting so I'm not arguing that it shouldn't exist. You could always disallow it via lint in something critical 
The difference isn't just an extra step - it's that you can see the risk, or lack of risk in the type of something. In Java (and most languages) `Object x = f(); x.call_method()` might throw a null pointer exception. Even `Optional&lt;T&gt; x` might *still* be set to null. In Rust, if you have `x: Object = f()` you *know* that it can't be `None` because it's not an Option type. In Rust, you can trust arguments and return values not to be null based on their type.
good point. 
good idea, I'll chop it down to size and do that in a bit. 
That's what the `result_unwrap_used` and `option_unwrap_used` clippy lints are for, though there doesn't seem to be anything equivalent for `expect` yet. Also, it's not just for experimenting. They do have a defined purpose. For example, this is from one of my `lazy_static!` blocks: pub static ref FNAME_WSPACE_RE: Regex = Regex::new(r"(\s|[_-])+").expect("valid Regex from string constant")
You shouldn't use `.env` files in production. As others have said, it's a development convenience. Diesel doesn't actually care how you're storing your database URL -- I'd use app specific environment variables instead of `DATABASE_URL`.
In terms of most *interesting*, I'd say the guarantees around zero sized types. If a type is zero sized, it is guaranteed to be optimized away by the compiler, and can enforce that all the work you're doing is at compile time rather than runtime
Perhaps the most problematic issue with nulls in Java is that you simply cannot statically enforce that a function parameter or a return value cannot be null. With Rust, if you need nullability you need to explicitly advertise it in the type of your function. It’s less about Optionals still having a runtime ”escape hatch” and more about simply using plain T instead of Option&lt;T&gt; in the vast majority of cases where nullability is not desired. In Rust, T is T and not T|null like in Java.
funny i wrote [this](https://gist.github.com/polypus74/eabc7bb00873e6b90abe230f9e632989) code yesterday (caveat: i'm still a bit of a noob) and was going to ask literally the same question on here this morning :)
What I love about Rust is how much you can read from a signature. It's also easy to explain. For example: fn push_vec(vector: &amp;Vec&lt;u8&gt;, onto: &amp;mut Vec&lt;u8&gt;) { } Says a lot, especially that `vector` and `onto` _cannot be the same_. Here's another fun example: fn iterate_over_vec(vector: &amp;Vec&lt;u8&gt;) { } fn push_onto_vec(vector: &amp;mut Vec&lt;u8&gt;) { } Guarantees that both of these functions _do not run on the same vector at the same time_. This is quite an interesting property and easy to explain just with borrowing.
My approach has been to use [just](https://github.com/casey/just) and mention in the README that users will need to install it, but then provide `just` tasks for everything. (Up to and including providing one that will use cargo and `sudo apt-get install` to install my development tooling on a Debian-family distro if that's what the user wants.)
Another advantage of traits is that you can mix them ad-hoc, where in java everything must be in one interface (or one of its superclasses)
I've show a much shorter version of this when giving a talk on rust's type safety: https://insanitybit.github.io/2016/05/30/beyond-memory-safety-with-types
In some recent work I was removing a dependency on `futures-mutex` (which is now deprecated) and I wondered if I could get away with using `std::sync::Mutex`s instead. This would only be okay if I never held the mutex over an asynchronous operation. Fortunately `std::sync::MutexGuard` is not `Send` while future callbacks all have to be `Send` so if I make the change and the code compiles then I'm never referencing the guard after an async operation so the new code is sound! One quick refactor, no compiler errors, ship fix, confident that the new code is correct :).
`unwrap`s and `expect`s are grepable though, unlike missing `catch` or lack of defensive code.
You *are* bypassing HSTS. It'll allow you to fall victim to a MitM attack with SSL stripping just fine, which is exactly what HSTS is meant to protect you from.
Yeah I did! Your friend was really cool about some random guy saying "hey let's write this in Rust!" Didn't have time for GGJ 2018 unfortunately.
replacing `a + b` with `Add::&lt;S::Vf32&gt;::add(a, b)`makes it work but I am not sure what the issue is. 
It's very easy to be blind to things you work with every day. Humans are weird.
Working on getting the rust-enabled lldb into the build. Probably this will be macOS-only, at least at first.
I don't know how many people are aware of this, but when you download Rust using `rustup`, you normally download a TON of useful documentation that's accessible locally. You can access all of it simply by running `rustup doc`. Take a look! u/steveklabnik and the docs team have done a fantastic job of making Rust coding offline possible. :)
In low-level programming it definitely is a problem; your data type layout must exactly match whatever the thing you’re interfacing with gives or expects.
When the author provides this example: // Rust fn divide_list(l: Vec&lt;i32&gt;, n: i32) -&gt; Vec&lt;i32&gt; { if n == 0 { // do something? return panic!("Divide by zero"); } else { return l.into_iter().map(|x| x / n).collect::&lt;Vec&lt;_&gt;&gt;(); } } Would it be more idiomatic to use the [unimplemented macro](https://doc.rust-lang.org/std/macro.unimplemented.html)? // Rust fn divide_list(l: Vec&lt;i32&gt;, n: i32) -&gt; Vec&lt;i32&gt; { if n == 0 { // do something? unimplemented!() } else { return l.into_iter().map(|x| x / n).collect::&lt;Vec&lt;_&gt;&gt;(); } } 
1 book is enough Then you can code and ask experienced people in irc
The reason that's the case is probably because you never visited the page in IE before.
struct Miles(pub f64); struct Kilometers(pub f64); When people say newtypes like the above are 'optimized away' or 'zero cost', does that mean the following: During compile time all the new types are type-checked against each other, but the final resulting code is *identical* to what you would get if you used the underlying type directly? Or is it just that the run-time cost is negligible (but present)?
I'm personally a big fan of lifetimes. Here's an excerpt on this from the Dust documentation: &gt; Lending out a reference to a resource that someone else owns can be complicated. For example, imagine this set of operations: &gt; I acquire a handle to some kind of resource. &gt; I lend you a reference to the resource. &gt; I decide I’m done with the resource, and deallocate it, while you still have your reference. &gt; You decide to use the resource. &gt; Uh oh! Your reference is pointing to an invalid resource. This is called a dangling pointer or ‘use after free’, when the resource is memory. &gt; To fix this, we have to make sure that step four never happens after step three. The ownership system in Rust does this through a concept called lifetimes, which describe the scope that a reference is valid for. The documentation provides this example: // explicit fn bar&lt;'a&gt;(x: &amp;'a i32) { } Which says that for fn bar() to be called for some lifetime 'a, the i32 reference x must live at least as long as 'a.
mention that RAII helps manage resources automatically—locks are automatically released, files are automatically closed, etc. as soon as they go out of scope, and you can implement this for your own types with `Drop`.
Affine types. 
Agreed. Other languages have linear types, but they're research languages. Rust is something unique among mainstream languages. 
The official book is available online for free! https://doc.rust-lang.org/book/second-edition/index.html Beyond that I just google things when I get stuck (same as any other language really).
Yeah I do realise that could be an issue. Ot was brough up in the RFC discussion as well. But given that OP was saying that they're writing a kernel, I'm assuming they have control over all of that. The issue was more of memory usage and more stuff needs to be moved to and from caches, leading to more misses, and minor performance issues.
The author says that implicit sum types are not type safe but as far as I can tell they are. It's just another form of type inference -- eventually you're going to pass your object into a function or something that is explicitly annotated and get a check.
I presume a kernel needs to interface with various hardware devices, using bit-level protocols. 
I don't think so. It isn't that the code is unimplemented, it is that division is not defined in this function for 0. There shouldn't be any need for the 'return' statement though, in either of the cases.
The trick would be to make Cow&lt;str&gt; special and easy to use for strings, with help from the language so it can be the default string type. But I must admit I didn't think about this very much.
The Rust Book, the integrated documentation, and SO at the start.
&gt; a major source of friction in statically typed languages is an impedance mismatch between a programmer’s mental model of her program and the mental model imposed by the programming language Reminds me a bit of: https://ieeexplore.ieee.org/stamp/stamp.jsp?reload=true&amp;tp=&amp;arnumber=8226852 
Yes, if "do something?" carries an expectation that there's something reasonable to do, I would use `unimplemented!()`. It's basically a TODO marker. I don't know what that code would be for a divide-by-0 though...
There’s at least five or six Rust books at this point! And I mean like, full paper books, not just the ones that come with Rust.
This definitely looks like a bug in Rust. I'd open an issue there with this playground link, and use the workaround in the other comment
You can't. This is what's known as an orphan impl. Neither the type or trait come from your crate. If this restriction didn't exist, upstream crates could never implement any trait for any type backwards compatibly. Consider for example if you implemented `Buffer` for `Vec&lt;u8&gt;`. If the standard library decided to add `impl BitAnd for Vec&lt;u8&gt;` in the future, this would conflict with your library, so it'd have to be a major breaking change even though it's just implementing an existing trait for an existing type. This restriction is in place to allow upstream crates to add new implementations backwards compatibly at their discretion.
Exactly why I love Rust. I can write code that I feel comfortable with and I only have to use `catch_unwind` on calls to 3rd-party crates to feel safe.
The sum type is also explicitly written in that example: `HashMap&lt;Integer, Integer|String&gt;`. So I'm not sure what #5 is trying to say at all. 
Obligitory warning: Calendars are \_hard\_. Those who value their sanity avoid writing them at all costs. Are you restricting your calendar to the (32-bit) UNIX epoch? That may save you some headaches but make sure that will work for your use case. (One mind-bending headache to watch out for: The calandaring system has changed in the past. You can run Gregorian calandars back before the 1750s but that becomes inconsistent with what was in use \_at the time\_) Now that that's out of the way I'm cooking up an example for you on the playground. I'll update this when it's ready. I'm thinking I'll "iterate" through weeks using chrono's time arithmetic. 
As far as I'm concerned, this is similar to the government outlawing heroin. Are there potentially legitimate usecases for it? Yes. Is it a violation of freedom to outlaw it? Yeah, I guess. Is it worth banning? Yes, yes, yes. But also it's not even that strong. If you care that much, find a browser that will let you do whatever you want.
The text says &gt; I want to remember to hit the `n = 0` edge case later, but don’t want to implement the error handling logic quite yet. It's likely going to require changing the return type of the function (to, say, `Option&lt;Vec&lt;i32&gt;&gt;`) or the documentation (to say that it panics) but the intent of the example is a good fit for `unimplemented!`. 
A little late to the party but I wanted to chime in. We are using Rust with actix-web for a stateless API that takes requests in a standard format and adapts them for the layer below. I initially did most of the work and was able to iterate very quickly. My team has been coming up to speed, in Rust and on the Project, and so far the experience has been great. They have dealt with the learning curve a bit but overall it has been a good experience and they have been delivering enhancements and new endpoints with very minimal slowdown. Most of our prior work was in Scala with Play 2 so it is nice to have most of the same guarantees that Scala gave us via Rust but without the overhead of the JVM.
For me what make dynamic languages a more approachable experience is the REPL and introspection. Most of the time I do not remember how to use this XML library, so I can `dir(my_var)` to see the interface, and `help(module)` to read the doc string.
Can you delete this post?
No examples. Great link...
LE also emails you if you don't "check in" in a timely manner so there's really no excuse for a failing cert. Someone dropped the ball in honesty. The email signed up should be a mailing list and there are third party services for monitoring cert health
I understand the importance of HSTS for a bank or email service, but for programming documentation site? It could be served with HTTP no problem.
Sounds like something that can be usefully handled by an IDE.
Thanks for the reply. I don't actually need to know if it was in use at that time. I just want to make sure, that say according to "todays" gregorian calendar all four years the february gets 29 days. I am currently at this stage, and I guess it's basically working for my limited use case. However, there's a small error because of slices and usize : fn is_leap_year(year: f32) -&gt; bool { ((year as f32 - 1852 as f32) % 4.0).eq(&amp;0.0) } fn main() { let now = Utc::today(); let year0 = Utc.ymd(1804,1,1); let mut num_of_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]; let leap_distance = now.year() / 4; let years_ahead = 1; let months_ahead = 4; for year in now.year()..(now.year() + years_ahead) { if is_leap_year(year as f32) { num_of_days[1] = 29; } else { num_of_days[1] = 28; } for month in now.month()..(now.month() + months_ahead) { if month &lt; 13 { for day in 1..num_of_days[month] + 1 { // ERROR HERE : ^^^^ slice indices are of type `usize` or ranges of `usize` println!("{:?}-{:?}-{:?}", year, month, day); } } } } } 
And clearly they are not targetting your use case in the software they write, which is perfectly fine as they are under no obligation to. On the other hand it is perfectly fine for you to pick a browser that is targetting your use case, or to fork and modify the browser to your heart's content.
This. For example, you can't do sh*t without bit-level access to certain hardware registers, and that's before you get into device specifics. See here: https://wiki.osdev.org/CPU_Registers_x86-64
This makes sense indeed, but the REPL and the introspection are independent of the IDE used (emacs, vi, vscode, notepad...), and makes also the experience independent of where you develop (locally or remote). But this is true, and is why lsp and rls are so important. Is sad that I am not able to configure them properly in my emacs. 
Except it could still occur on first visit and the connection never upgraded. HSTS only protects previous users during the TTL of HSTS, the initial upgrade header could be stripped and all subsiquent packets downgraded.
I'm cleaning up the PR for DNS-over-HTTPS in TRust-DNS. It's taken a while as I've decided to refactor a bunch of internal interfaces. I think I'm on the last thing before I can merge in... hopefully the next day or two. [https://github.com/bluejekyll/trust-dns/pull/520](https://github.com/bluejekyll/trust-dns/pull/520)
Did you look at my playground link? I really think you will want to avoid re-implementing all the complex logic that we call a human calendar. The code I linked should handle leap years and all the rest without any work from you.
He was interested in Rust a little before anyway so I'm sure he was happy to do it, haha
Your brain ignores your noise which you see all the time and I think it's for the best for everyone to not see our own noise all the time. ;)
Just looked at it. I guess I can use that, so I know how to sort the calendar in a 7 days x{4 or 5 weeks}-Matrix. I need to display all days. Looks, complicated however. I have to take baby steps towards that :)
More idiomatic would be to use an assert or debug_assert: fn divide_list(l: Vec&lt;i32&gt;, n: i32) -&gt; Vec&lt;i32&gt; { assert!(n != 0); l.into_iter().map(|x| x / n).collect() }
You're right, it's not a perfect solution. That's irrelevant though. Clearing the HSTS cache is still bypassing the protection and exposing yourself to that risk even though it's not your first visit.
So the basic idea is: 1970-01-01 is a Thursday. With my code you can find the day-of-month, month, and year for every Thursday ever, in order. Once you know where all the Thursdays are and what their day-of-months are, it should be super straightforward to lay out the rest of the weeks around them. If you want, you can change it so that it iterates every day instead by changing the line where it adds one week to adding one day.
Most of the time the best workaround is to create newtype wrapper and implement foreighn traits for it.
Some more things that dynamic languages tend to abstract away (even at non-zero-cost): 1. Caring about specific primitive flavors, e.g. i32 vs i64. You usually just work with an "Integer". Often you don't even care if it's fixed-size or auto-growing (bignum). Same for fixed-size arrays vs. vectors. 2. Caring whether the data is on the stack or the heap. You just assume everything is (or may be, it's not exposed to you) on the heap, all dispatch is dynamic dispatch, everything is passed (or behaves like) it's passed by reference (except, perhaps, for certain atomic primitives like ints or booleans). Auto-box and auto-unbox everywhere, pointers are invisible and not exposed to the developer at all. 3. Needing to deal with edge cases such as integer overflows/underflows and other optimizations lower-level languages do for the sake of performance. You just assume every operation will have a run-time check that ensures consistent behavior, even if it's costly to do. In short, most dynamic languages just let you assume, "everything is auto-growing", "every edge case is checked at runtime to avoid errors", "all allocations will be taken care of". No need to care about how data is physically stored, laid out, or accessed. Just write your code at the semantic level you, the application developer, care about, rather than how the machine needs to deal with it. Whether or not this approach works obviously is based on how much you care about performance. Optimization of such high-level code to actual physical machine representation is limited to what the VM can do behind the scenes. Still, removal of entire layers (not just compile time vs runtime, but static dispatch vs dynamic dispatch, pointers vs. values, lack of "type tetris") significantly simplifies the mental model the programmer needs to deal with, allowing more time to be spent at the application layer. Some languages go into the direction of remaining dynamic (and thus slower at the micro level), instead opting to be more scalable at the macro level (e.g. Node, with it's async/await). If your code is on a scalable architecture, may need to throw more boxes to solve the same problem, but at least you *can* solve it with more boxes, rather than being completely blocked once you've reached a certain load.
The trick would actually be to let String store &amp;'static str for free. This can be done by encoding it as capacity being 0, while still pointing to the &amp;'static str and storing the length in the length field. This however isn't completely backwards compatible as the invariant len &lt;= cap isn't true anymore, so this is something that could potentially land at some point, but isn't without problems. https://github.com/rust-lang/rust/pull/46993
So cool to hear this! We did consider Scala for quite a while but we don't have too much experience with JVM tuning and didn't want to gain that experience in production so we decided to not go with it.
Biggest win for me has been an hardly mentioned feature. The ease of writing unit tests in Rust. It's so simple to write and run them, for the first time it doesn't feel like a pain. The *largely functional* and immutable types lead to easily testable functions that are largely *pure*. Combine that with data oriented programming style, makes complex types easy to set up and test. It's not Haskell level pure, but from an practical perspective it is. This contrasts with C++ where, once you get deep into a code hierarchy, it's tough to set up an object to test the behaviour usually leading me to either give up or just find it really tedious.
at last. You have multiple app. You'd store your *multiple DATABASE_URL*s, each named DATABASE_URL, in whatever places -- bash_rc, /etc/environments, bash_profile.... you're saying that this cause no problem in terms of them overwriting each other?
&gt; at last. What does that mean?
&gt; You'd store your multiple DATABASE_URLs, each named DATABASE_URL, in whatever places No, that's not what I said. I said don't call it `DATABASE_URL`. Call it whatever you want.
His answer makes sense and is legitimate, why are you being so hostile? 
Diesel requires them to be called - guess what?
OP is also missing the `i32::MIN / -1` edge case.
who are you? fuck off
I have a crate that depends on [`phf`](https://crates.io/crates/phf). My crate also indirectly depends on [`postgres-shared`](https://crates.io/crates/postgres-shared). `postgres-shared` depends on `phf=0.7.21` but I need `phf 0.7.22` for my crate. How do I allow postgres-shared to get 0.7.21 and me to get 0.7.22? Neither crate exposes its phf objects so it should be possible to import both at the same time.
Diesel doesn't require them to be called anything. The CLI will *conventionally* look for that, but the canonical way is to pass `--database-url=` at the command line. That is the only place we ever use that convention. No part of Diesel cares or enforces how you handle configuration, and we always have you explicitly provide us the database URL as a string. We don't care where that string came from.
My understanding is limited, so maybe someone can correct this... but from what I understand, I agree with HSTS. Even if it was impossible for the user to disable, then I'd still agree on the basis that it allows websites more control over security — in that case, any ‘workaround’ would actually be a severe security flaw. But if the user's browser is the thing standing in the way, that's a completely different issue. For these websites, Firefox says an exception can't be added, and if there is a workaround then that message is just lying to the user.
&gt; a major source of friction in statically typed languages is an impedance mismatch between a programmer’s mental model of her program and the mental model imposed by the programming language I don't like sounding negative, but after many years of seeing people using dynamic languages sometimes I wonder if what they like is just being able to avoid having any mental model of their program at all.
[removed]
i don't want to pass `--database-url=` at the command line. I'm not using .env files and I have mulitple apps. then using the environmental variables is the only option. how will diesel handle this?
I looked at duct initially and decided I wanted a different solution for these reasons: 1. duct's macro syntax `cmd!(...)` and `cmd(program, args)` aren't flexible enough to let you inline Option&lt;String&gt; types (include the argument if Some, skip if None) or easily splice a Vec&lt;String&gt; into the list of arguments. commandspec handles these, and also doesn't require you to individually quote arguments up front. This is a matter of preference, but I find it makes maintenance much easier. 2. duct operates on an `Expression` object it includes in the library, where commandspec operates on Rust's own Command API. (`os_pipe`, the foundation library for duct, does operate on Command though). However, commandspec does not have a built-in piping solution. 3. duct breaks out shell scripting into its own crate `duct_sh`, whereas commandspec includes `sh_execute` and its ilk. 4. Not really covered in this article, but `commandspec` also offers a form of job control to ensure all subprocesses are killed when your process ends. I'm keen on seeing a solution emerge that enables multiple scripting paradigms. That might start with building a common base on libraries like os_pipe.
Likewise... and I was working from the first edition of TRPL which I'm told is harder for people to grasp. (I had no problem with it but then it seemed to line up quite well with my "Python programmer who understands things like stack vs. heap" preconceptions and I'd also been lurking in /r/rust for a year or so waiting for 1.0 to come around.)
Yes, the fact that newtypes are the exact same size at runtime as the type they wrap is great!
https://github.com/datafusion-rs/datafusion/tree/master/examples
Not necessarily. It could be that what you're doing with them uses only near-universal interfaces like "get string representation" and you wind up with unwanted cruft leaking into a website template that would have been caught if you specified an interface stricter than "can call`to_string` on it".
also https://www.datafusion.rs/guides/getting-started-docker/ (was linked to from the post) 
Not being able to access websites can cause major problems occasionally. Browsers are expected to make users safe, but not have restrictions built in. If users find a restriction is preventing them from doing something important, they might resort to Internet Explorer. Not being able to get a heroin fix can result in horrendous withdrawal symptoms. Governments are expected to restrict liberty, but not put citizens in danger or promote violent drug cartels. If addicts find a prohibition is preventing them from getting high/alleviating withdrawal, they might put their lives at risk and fund violence. So that's definitely a no from me.
FWIW, "only one mutable value at a time" is not a very onerous restriction when working with data structures with lots of pointer chasing (after reading the initial ideas about Josephine I shamelessly stole them for one of my own projects). Passing around the token is a bit of a pain if you need to refactor a large codebase, but once it's done it is really easy to maintain (usually I find that I already have a context object I'm passing around, so I can often just stick the set in there; mainly you just have to watch out for threading the set through any closures and write some convenience methods to delegate to traits like Clone or Debug). The reason that the actual mutable aliasing restriction isn't too onerous is that you can easily copy shared references out of the mutable cell, as well as other Copy types like GC references (which is pretty much how mutable state works in many GC'd languages, e.g. OCaml). You only run into major ergonomic issues if you were planning on storing more "Rust-y" data structures, like owned vectors or mutable references, inside the GC'd cells. Ideally even those would work well, but since using types in that way is not an option in most GC'd languages I can't complain too much. In the meantime, I've found that combining Josephine-style cells with arenas (which these days provide options like allocating contiguous slices at a lifetime, so you can use them instead of vectors as well) works really well, since almost everything you'd ever need to access is both Copy, and has a long enough lifetime to escape the Cell.
Python developers would never define a type like that (using Java style conventions).
Ah thank you, that makes sense
`--database-url=$YOUR_ENV_VAR`
Any time
Oh, yeah that's fair - unimplemented makes more sense, and they should change the return type.
A good example is spawning a bunch of threads that they all modify the parent thread stack frame concurrently (without heap allocation). Explain everything that can go wrong (e.g. threads outliving the parent's thread stackframe and corrupting whatever is there, data races, etc.). Now show how to do the same using `crossbeam::scoped_thread`s. 
I tried to write what I needed, ask question on irc, and read articles on reddit.
Ownershiop guaratnees destruction. No more leak hunting or APIs with resources passed as argument to a providerd closure, just to make sure destructor is being run.
This sounds like the kind of problem that Clippy is supposed to solve. Could there be a lint against calling `to_string` on something known to be a `&amp;str`?
IMHO the author is misusing the term "JSON" a bit; JSON is a serialization format, not a kind of data structure. Maybe "JavaScript-style objects" would have been better?
I think my time slot will be too short for this, but I'd love to do something like this at some point. I like the idea of that direct comparison.
Aha... I'm not particularly familiar with low level implementation of systems, and I think you're correct about that.
&gt; inline `Option&lt;String&gt;` types (include the argument if `Some`, skip if `None`) or easily splice a `Vec&lt;String&gt;` into the list of arguments You could do this by building your arguments list with `Vec::extend`, and then passing the final vec to `cmd(prog, args)`. The standard `extend` method lets you splice in a sub-list of args, and also optional args. (`Option` implements `IntoIterator`, such that iterating over `None` doesn't yield any elements, which makes this case pretty convenient.) But in general, yes, duct leaves it up to the caller to build a list somehow. &gt; duct operates on an Expression object it includes in the library, where commandspec operates on Rust's own Command API I've been considering adding an `Expression` constructor that would just take a `Command` from the caller and invoke it directly. My worry with this API is that it leads to an inversion of priority: You might expect that your command's `stdout` or `env` settings would override whatever duct is passing down from "outer" parts of the expression, but duct has no way of knowing that you've set anything, and it will probably stomp on your values. On the other hand, if the contract is that duct doesn't touch your command _at all_, then none of the features of the library would actually work. I'd be curious to get people's thoughts about this. Maybe what I should actually do is provide a hook that lets callers modify the Command just before it's executed?
Depends on implementation. If it's done via Type Erasure (like exceptions in Java, it becomes `HashMap&lt;Integer, Object&gt;`). 
thank you. I will have to look at it in more detail. For now, I have this: http://play.rust-lang.org/?gist=27d5213f0a478404e2a084df13d3ceca&amp;version=stable&amp;mode=debug&amp;edition=2015 I have wrapped the thing into a MonthlyCalendar struct and also the days into a Month struct. Not sure if that's good coding style :) 
I'm adding multidimensional processes to my [`point_process`](https://crates.io/crates/point_process/) library. I had a couple time-dependent point processes (Poisson processes and Hawkes processes) done already, and I've been adding `structs` and `traits` to represent measurable sets in the API, so one can define measurable subsets of d-dimensional space on which to simulate point processes. It's a bit of work, I've just started learning how to use the `ndarray` crate for this!
It's surely not as critical as a banking website, but TLS is still important for a documentation site, or any website for that matter. With plain HTTP, anyone standing between the server and you can inject anything into the page. This means your ISP can inject ads or anything else they so wish. If docs.rs were served over plain HTTP, it would also mean that while you're sitting in your café of choice, hacking on your favorite Rust project, the guy/gal two tables over could be injecting a cryptocurrency miner - or much worse - into your documentation page.
I only gave the commandspec library a skim, but here are my impressions of some of the differences: - Commandspec prioritizes keeping the syntax similar to a shell script, or invoking the shell directly. Duct uses its own syntax and expression model, and tries to avoid the shell. (As /u/timcameronryan mentioned, there used to be some functions for running shell commands, and those got moved out into the `duct_sh` crate.) - Commandspec includes convenience features for formatting command arguments. Duct expects each of your arguments to be a separate string. - Duct prioritizes complicated pipeline expressions. Commandspec is more about executing single commands.
Unless it used like this \`let foo: fn(Bar) -&gt; Foo = Foo;\` Then calling \`foo(bar)\` might not be inlined.
It would be rejected because that is the standard idiom. You want a String? Use the ToString trait.
So you're not supposed to call `to_owned` on `&amp;str`?
At compile time they are checked as types, in the compiled code it's just a f64.
Many people *do*, but many also do not. This is probably the most controversial idiom choice in Rust.
winit is definitely easier to add to your project due to being pure Rust but SDL2 has much more functionality and supports more platforms.
How is that made any more likely by this feature?
This is very heavily dependent on the language. For example, JavaScript does not use big numbers (and has a bunch of primitive numeric types nowadays), and doesn't care about overflows. It's true that JavaScript doesn't make you care about stack vs. heap (usually), but that's because it's garbage collected, not because it's dynamic. I think the fact that garbage collection is an ergonomic win is *relatively* uncontroversial nowadays.
Winit is only the window, that's true, so if you want the 2d drawing you need a second crate. However, for OpenGL they have basically the same features as far as I know. What platforms are you after that sdl2 has and winit doesn't?
Code of conduct is right in the sidebar. 
Super simple one. I want something with the functionality of both `std::mspc::{Sender,Receiver}` and `io::{Read,Write}`. I want to write bytes into one end and read them out the other, concurrently. What's the go-to thing for this?
Aside from the fact that the `is_leap_year` function confuses me greatly (why is `year` a float? why subtract `1584`?) it is also very likely incorrect, because leapt years aren't as simple as `year % 4 == 0`: If a year is divisible by 100, it is **not** a leapt year, except when it is divisible by 400. 
Well, in the second example theoretically push_onto_vec could call iterate_over_vec on the same vector (it is unlikely, but you can't *guarantee* it doesn't from the type signature alone). What's really nice, though, is that even if that does happen push_onto_vec can't modify the vector at all while iterate_over_vec is being called :)
To be clear: I really need it/them to implement `{Read,Write}`. I am using it to simulate a remote Tcp stream :)
Yes. From the description I understand roughly what it does not not why. What are the use cases? I guess it doesn't make any sense to have consistency guarantees when your data is coming from multiple sources. I'd love to understand better
I forgot to mention dcode. Searching for "dcode rust tutorial" on youtube and you will see a very good video tutorial + programming a hangman game with a lot of skill. He is a very good programmer i think.
Does that need to involve iterating over the weeks if you're just doing a simple next date step? https://play.rust-lang.org/?gist=05706c91e0aa2f860f218a2ee25de39f /u/detached_protector
I’m new to the world of distributed computing. I have recently been using a cluster of nodes. I access the mainframe via ssh, and then can easily assign a node to run a bash script. How much of the above functionality is provided by rain? Just trying to get a handle on what exactly the package does. 
Interesting! Is there a comparison to Dask available?
I really like that using assignment (=) instead of equality (==) within if/else/etc checks won't compile.
Prototyping a replacement for serde/bincode that fixes the deserialization performance problems we have in WebRender. https://github.com/jrmuizel/fast-serialization Finish polishing up a cycle collector https://github.com/fitzgen/bacon-rajan-cc for a new release that makes it mostly usable.
The [OpenPowerlifting](https://www.openpowerlifting.org) project finally deployed our Rocket-based server after a little under a year of work. With the new server, initial page load times dropped from ~20 seconds to ~89ms, a 225x speedup. The ridiculous prior slowness was mostly a property of our website being hosted on GitHub Pages -- which is static-only, so we shipped the whole database as a JSON file. That worked well when we had a small amount of data and no funding, but quickly became unsustainable when we had unexpected growth in community data contributions. The Rust backend is extremely fast; there is no caching layer. Even with still-unoptimized algorithms, we can dynamically compute whole-sport rankings for every page request, which is good, since there are too many combinations of filters to cache everything. We initially started out using Diesel, but it was a little difficult to translate what we were looking for into SQL/ORM language. Even with SQLite, which is supposed to have good read performance, we couldn't figure out how to do a sort in under 100ms, which was our goal. (They tended to be closer to 130ms). Copy overhead showed up in benchmarks. Since our "database" is read-only at runtime, we just ship huge CSV files, and use serde to load them into structs. Then there is zero copy overhead, and we can express our search requirements directly in Rust, which leads to very understandable code. The primary benefit we've found of Rust is stability -- even with Rocket based on Nightly, we have never had a single crash (except once, locally, in testing -- an array index out-of-bounds that was quickly fixed). It is very easy to write tests, and so we have a good test suite, so we're confident in stability when we deploy. Overall a very good development experience, and very happy with having chosen Rust.
There are things unsafe Rust is allowed to rely on, and things that it isn't. For example, if you decided to make optimizations based off the specifics of the implementation of a vector method above and beyond what it is defined to do in the documentation (e.g. taking advantage of the way it breaks ties during unstable sorting), I don't think anyone would have much sympathy for you if it changed. Floating point math working correctly, however, is something that unsafe Rust is allowed to rely upon.
Wow, didn't think about that one. What does that produce in Rust? A panic?
Haven't looked into Rain specifically but normally these systems (attempt to) take care of: * distributing data to workers * scheduling computation to minimize communication and keep workers working * providing a monitoring system * service discovery (esp dynamically adding/removing nodes) * fault detection and recovery ( perhaps a node dies and still has tasks queued.. maybe send those tasks to another worker?)
You’re right about the lack of stack and heap distinction being a gc thing. For example Go the language doesn’t differentiate between stack and heap allocation and it’s statically typed. If you want to dig into the runtime specifics you can optimize allocation though. 
Not limited to dynamic languages. Haskell has a pretty powerful REPL that I use a lot when developing 
It counts as integer overflow, so panic in debug builds.
Use `Utc.yo(year, ordinal)` instead. Then you only need to use a max value of 365, 366 in leap years. That way the month/day calculations can get lost. 
I'm glad that Jim is back on the podcast, I really enjoyed the previous episode with him.
All of these things. This is where Rust is strong with static typing.
I used the existing *extensive* Rust documentation, and learned as I wrote a program that I wanted.
any sane person always has a backup plan.
I'd just replace "sane" with "competent person who knows what they're doing and actually needs it". The point of banning it and not allowing an easy override is not to make it more difficult for people who actually know what they're doing to do what they need to do. It's to make it so 14 year olds can't just go out and ~~buy heroin~~ put their parents' credit card into an insecure website. It's obviously imperfect, just like a sweeping heroin ban is imperfect, but it's still a good thing on the whole.
I could add these easily to the `Buffer` type in [my `buf_redux` crate](https://crates.io/crates/buf_redux).
Your feelings mirror mine. It’s *extremely* nice to sit at the REPL and bang a few little snippets out to figure out more or less how one or a few APIs compose together. It’s like a little sketch pad for a bigger program. The type system can replace a fair chunk of that, but it’ll probably never be a complete replacement. Especially considering the need to check that values are also flowing through correctly.
Though stability guarentees for nightly is basically "lol nope", right? So allow ffast-math behind a feature flag? Maybe by default (obviously if you enable the optimisation) only apply it to floating point operations in modules that contain no unsafe code? That wouldn't cause any unsafety, as safe code can never cause unsafety by itself, it needs to violate some invariant that an unsafe block relies on. If it does get stablised it'll probably be an attribute where you can apply it on a function (or maybe even block?) scope. It's on you if you add it to a function that relies on reliable floating point for safety. And besides, doing that seems like a kinda bad practice anyway. If optimisations can break your code, what if *you* re-order or otherwise change it accidentally? I think if you have unsafe code that uses floating points and relies upon exact behaviour for memory safety, *and* you see an optimisation flag that breaks strict compliance and enable it, then your program breaks... that's your fault. You found the gun, trained it at your foot, and fired it. Rust can't be expected to protect you from being stupid with optimisations that would be clearly marked as "can break unsafe code, use with care". Isn't repr(packed) just *broken*? Where you can cause memory unsafety with that. That's on stable. To be clear, i'm *not* talking about this optimisation being on by default or at any standard optimisation level. It would be a level that clearly designates it can break strict compliance.
Beyond what all others have already mentioned, keep in mind you can also use [`from_ymd_opt` which will return an `Option&lt;NaiveDate&gt;`](https://docs.rs/chrono/0.3.0/chrono/naive/date/struct.NaiveDate.html#method.from_ymd_opt) [which will not `panic`](https://play.rust-lang.org/?gist=509b9784e20ce0dc1a45d08988d457bf&amp;version=stable&amp;mode=debug&amp;edition=2015).
You could [use a pipe](https://docs.rs/os_pipe/0.6.1/os_pipe/). (Full disclosure, that's my crate.) Those behavior very similarly to a TCP socket.
Shots fired. :O (I am *so* using this in future conversations about static vs dynamic typing.)
The main difference is that Rain provides a build-in integration of external programs into pipelines and possibility to write own task in Rust and C++.
Switch to pony.
I prefer toml/json/xml but not yaml. The primary reason - I don't really like that invisible characters impacts to the file content. Configuration files should be able to be edited outside of the development environment. That's why we have just plain text configuration files instead of binaries. And there is a problem with YAML format: 1. Text editors abilities somewhere in prod server or at customer workstation can be really restricted. I prefer not to fight with these editors spaces formatting settings to save edited config with appropriated spaces. 2. What if it's not me? In case of phone customer support The person who I ask to edit configs might be not very familiar with this tricky spaces stuff. I wouldn't really explain that by phone.
You define tasks (external programs, python/C++/Rust functions) and their dependencies in sequential Python code. All other things are handled by framework; Rain distributes tasks to working nodes, executes tasks and transfers data between nodes when necessary and informs you when tasks are completed.
`#[repr(packed)]` is a bug and is being dealt with (see https://github.com/rust-lang/rust/issues/46043). It's being turned into a hard error in those cases where it could cause memory unsafety. That's not a reason to break existing correct behavior. &gt; Maybe by default (obviously if you enable the optimisation) only apply it to floating point operations in modules that contain no unsafe code? That wouldn't cause any unsafety, as safe code can never cause unsafety by itself, it needs to violate some invariant that an unsafe block relies on. I kind of like that idea (especially since it would force people to stop skirting the line and actually keep all their memory-safety sensitive code in the module with the unsafe blocks!), but it would go against lots of existing precedent in Rust that safe and unsafe code should not be treated differently during code generation. However, I think an on-by-default lint for unsafe modules in the presence of fast math might be a good start (it would be similar to something we discussed a while back with regards to Drop and Unpin). &gt; I think if you have unsafe code that uses floating points and relies upon exact behaviour for memory safety, and you see an optimisation flag that breaks strict compliance and enable it, then your program breaks... that's your fault. Sure, I don't disagree with that, as long as the optimization is something that can be constrained to a particular module (which it necessarily has to be for you to be using invariants relying on floats, probably). The concern is *other* people's code. Hopefully, it is not like panic=abort, where if your crate insists upon it it tends to be somewhat infectious. &gt; And besides, doing that seems like a kinda bad practice anyway. If optimisations can break your code, what if you re-order or otherwise change it accidentally? That's always a risk with unsafe code, since the compiler doesn't check your work. It's why ideally your unsafe code is kept as modular as possible with precisely defined invariants (I think refactoring things into unsafe traits that explicitly assert invariants is often more maintainable than just trusting a few scattered blocks of unsafe code to "just be correct."). But there are still *some* things you can rely on. For instance, I write a lot of unsafe code that relies on the fact that certain primitive Rust operations can't panic (e.g. non-overflowing arithmetic on primitive integers), and I would be very displeased if the language suddenly changed its mind about that. In general, optimizations *do* have to preserve observational equivalence to the original code (modulo undefined behavior), in the sense that the program should have some set of allowable behaviors and should never behave in any way that conflicts with those behaviors. That is precisely why ffast-math isn't really a correct optimization; it changes the space of *legal* observable behaviors for code with no undefined behavior. It would be different if there was no explicit guarantee to Rust code that floating points follow correct IEEE semantics, but there is. &gt; To be clear, i'm not talking about this optimisation being on by default or at any standard optimisation level. It would be a level that clearly designates it can break strict compliance. I don't object at all to adding a feature like what you're suggesting, as long as it is scoped to a module or something. I'm just saying that it's unlikely to be something you can flip on for an entire program (including dependencies) like you can with -ffastmath in C (nor should it be, I suspect). It might be nice to allow people to mark their modules as "insensitive to floating point correctness" or something, but someone would first have to precisely define what that actually means.
Speaking in terms of the execution of the program, the second function would give control to the first at that moment though and would not be the one executed at that time. They are not running concurrently.
For a moment I thought this was yet another re-post of the episode from back in May. What a pleasant surprise! 
To be fair, there's an unprecedented ton of different libraries in dynamic languages that model their own paradigms/frameworks, so I wouldn't discount those programmers in generalization. In theory, it makes for more advanced models. Unfortunately, some of those do tend to cater towards mindless rapid coding, and there's naturally plenty of that. It's more of an *economic* model issue overall I'd say. Open source software tends to be much better, go figure.
Types aren't ensuring your system works, there constraining it. They have a price, and in many situations the cost isn't worth it. If your looking to find an answer to the question, static or dynamic, your asking the wrong question. 
Isn't that conceptually a Cow ?
&gt; It might be nice to allow people to mark their modules as "insensitive to floating point correctness" or something, but someone would first have to precisely define what that actually means (clearly it doesn't mean "anything can happen when I use floating point operations", but for instance is something like "floating point operations will only write to the same bytes they would have written to under IEEE semantics" sufficient? I don't have a good intuition for what people expect from ffast-math). Three ways I can think of to define it is that 1\. The results of any floating point operations are undefined, but obviously the compiler will make a best effort to be accurate. I don't know if undefined is the right word. Basically your code shouldn't *rely* on any specific value for safety, the compiler is free to do whatever optimisations it wants to try to improve performance. At what point the compiler is optimising too much would be kind of a judgement call, like should x + (x * 1.00001) be equal to x*2, and if ever, at what point is it deemed close enough? 2\. The compiler is free to carry out optimisations that are mathematically sound and would be valid if we were operating with infinite precision with real numbers. So the above example would never be allowed, but assuming associativity, for example, is fine, as is rewriting a*b + c to a fused multiply-add. (I don't know if the compiler is allowed to do this, but that seems like a nice feature that might actually increase precision. I know there's a function to do it if you want it explicitly, but it looks cleaner to just write it out). I like this option more as it gives tighter bounds on what would be allowed. I'm not a compiler writer so I don't know what could go wrong with that definition, but at first glance it looks useful. Alternatively 3\. Some combination of the two, there are some bounds given on what valid results are for each operation.
You can do no mental model in a static language as well. This usually results in random and unhelpful additions throughout the code. In other words, spaghetti. The difference is that in a dynamic language the fact that your Foo record has a reference to the "Bar" item only to be passed in 20 calls down (because some method has access to a foo and wants a bar but doesn't want callers to know about it). Seeing this happen is mostly transparent. Nobody will know about it until someone is debugging and says "WTF? Why is Bar on Foo?" In a static language, Bar is added on Foo for all to see and, hopefully, the WTF is triggered sooner before more damage is done.
As someone coming from dynamic languages, I like Rust because it allows me to use many of the same patterns I use in JavaScript. Unlike say Java, where representing "A or B" is not a simple task. Having less to think about is also good for beginners who want to make something high level quickly.
its a simple one, but `mut`. For java people, its having `final` placed everywhere by default. I always have a hard time justifying my use of `final` every where in my code, but its about documenting your intention. Also, in cases of being returned a reference, you can always see if you will be able to edit the value, allowing you do add read/write permissions to return values while keeping the performance benefits of using references. This, with the safety checks of send/sync, allow you to be super confident that you will not run into weird concurrency issues with competing writes. I find w/ rust, and compiled/checked languages in general, is that its all about eliminating entire classes of run time bugs. For performant or critical software, that is a huge benefit.
This is correct, and precisely why I feel that marketing a language, *any* language, as "productive" is fundamentally biased, because different roles have different perceptions of what productive means. Any construct, abstraction, or restriction the language provides makes it *more* productive if you need it for your workflow, and makes it *less* productive if you don't need it (but are still forced to deal with it). A systems engineer (low-level networking, OS development, core algorithms like cryptography, etc) would swear that manual memory management, exact control over layout, pointer arithmetic, explicit types, etc. are very important for *their* productivity, and Rust's requirement of using them makes the language more productive, not less. Meanwhile, a web services developer doesn't care about most of these things, but cares about other aspects of performance and scalability, e.g. how well does the language support streams, or actors, or async. These things make the language more productive to that developer (otherwise they need to reinvent the same patterns themselves, often less well-optimized and less standardized). Meanwhile, a user-facing application developer which doesn't have a lot of load, many not care about either of the above. They just want a very expressive, high-level language that allows them to say *what* they want, and leave the *how* completely buried away, even at a performance cost. "Productivity" is so subjective I don't really buy it when a language markets itself as "productive" in general. Heck, even the rustc repository uses a lot of python scripts internally for high-level management tasks which aren't performance-heavy, rather than writing everything in Rust. "Productive" for a specific use case? Sure, now we're talking, and a developer should compare the advertised use case to their own to determine how good of a fit a language is.
PBX management interface used by ~50 people using Rocket and deployed as a containers. No late night calls as of now ヾ(⌐■_■)ノ♪
Ahhh yeah, I identified that issue as well. I thought you saw a hardware issue that would cause trouble. A solid compiler is missing, but if that existed PIC would be a great target and would actually make those things worth working with.
I'd love to hear how this is similar and different from Apache Spark. I've done zero research into Rain, but I'd absolutely love to use Rust over the JVM for my own project and can only imagine what that would look like.
Types constrain the programmer and his colleagues, not the system.
I honestly agree with this as someone moving from JavaScript to TypeScript.
Upon consideration I guess I mean more support for JSON schemas and such. That said, I admit I haven't looked at `rouille` in a year or so and I know there've been some updates, so maybe I should double-check it before I jump on Rocket or such. Someday this year I'll update my web-server shootout for 2018.
Similarly, all the CLR languages have a REPL now
You don't need to special case integers or booleans. You can pass them by reference just fine. It's just that they need to be treated as immutable values when you do.
The newcomer needs to learn the difference between `&amp;str` and `String`. If they get the impression that the language is poorly designed from this, they need to learn to not reach hasty conclusions as well. 
I think that's because the available tools in static languages have been so poor due to lack of investment. Now that we've seen the power of dynamic languages, future static languages are developed with features that provide those same benefits. Even so much as having `Serde` and other derives is a huge step forward, especially once proc macros are stable and rustc figures out a way to make type information available to them. Remember that all the dynamic libraries have a 10-20 year communal development history behind them that ironed out the kinks. I.e., it took React about 20 years after JS was implemented to arrive, despite the fact that the core idea (virtual dom diffs) is very simple and the tech could have been built prior to jQuery. It took over a decade of jQuery for that solution to emerge.
Just a public service announcement: you can use inclusive ranges now using `..=`! So your month and day loops can become" ``` for month in 1..=12 { for day in 1..=31 { unimplemented!() } } ```
/r/playrust
Wrong subreddit. [https://www.reddit.com/r/playrust/](https://www.reddit.com/r/playrust/)
I think you're looking for the /r/playrustservers subreddit. This subreddit is about the programming language of the same name.
Sorry I’m new to this
`cargo new find_correct_sub --bin`
You can't do that. You can do an existential return type via `impl Calendar`, but it still won't let you return two _different_ types, or you can use dynamic dispatch via `Box&lt;Calendar&gt;`, or you can make `Calendar` an enum instead of a trait and return one of its variants (probably the best option here).
By the way, some advanced statically typed languages do support these kinds of heterogeneous dynamic-ish maps, and they are called records. For instance, there is at least one implementation of them in Scala's [shapeless library](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#extensible-records), and a more experimental implementation (but prettier api) [here](https://github.com/scala-records/scala-records).
Calendars *are* hard, like others are saying. I'll just leave this here: https://youtu.be/-5wpm-gesOY
This. It's why Let's Encrypt exists and why browsers are moving towards labelling all "http" sites with "Insecure" in the near future. It turns out people really don't think about what it really means when you can't trust *anything* sent over HTTP. Maybe there's a link inserted in the docs pointing to a install script? Maybe there's a bitcoin donation address added? Either of those could be done by a fake Starbucks WiFi access point and there's not a single person who would reasonably suspect a thing. And that's not even considering the headaches when you get websites that insist on mixing HTTP with HTTPS because "we thought about it and it's fine for our use case". But then you do the security audit, and surprise surprise, it's actually extremely *not* fine because they forgot about something because as soon as you introduce unencrypted HTTP *anywhere* your security analysis becomes a lot more complex.
`push_onto_vec` could spawn a thread and call `iterate_over_vec` from it.
As someone who dabbled with learning Rust by implementing a simple JSON webservice a while back (although with a complex record type, to approximate a future project I wanted to attempt), let me just say that as soon as it dawned on my how many extra record update functions (or extra crazy login in one function) I would have to write to deal with Diesel with the different record update scenarios, I sort of withered in despair and ran back to Perl, DBIx::Class and Mojolicious. I still plan to use Rust for some critical path parsing stuff in the future, but I may have accidentally started out on worst case for a strongly typed language, and consider myself suitably humbled. Really, if I'm takign a request, making a data structure out of JSON, possibly doing some fixups to it, and passing to a database which is already very strongly typed and constrained with check conditions, in *that* specific scenario, what is strong typing giving me besides a lot of pain?
The Rust book is actually where I learnt about the Stack and the Heap!
Yup. If a language is Turing complete, then it doesn't impose any constraints on the functionality of a system.
Did you mean \`HashMap&lt;Object, Object&gt;\`?
The "unexpected mutating" bullet above might be especially interesting to a Java audience. Big libraries like Guava provide immutable collections as workarounds for that sort of bug, which for the most part simply doesn't happen in Rust, because of the distinction between mutable (unique) and immutable (aliasable) borrows.
Maybe as a single programmer it's not helping you very much. But if you're designing the same system to be worked on by numerous developers, potentially over many years, and with the ability to grow to a much larger size, static typing will greatly help ease the maintenance burden. It's a way of encoding that mental model into the codebase itself and helping ensure that only operations that are valid within that model are allowed. That way when a few years from now, potentially after the original author has left the company, another developer can come along and make sense of the code without having to rebuild all the implicit assumptions about the types of things in their brain. There is definitely a higher up front cost, especially for this seemingly trivial data munging style of code, but it does reap benefits down the road. 
Oh cool, that's news to me. I will have to check that out next time I'm developing in Windows world.
1584 is a leap year. I think the % is from an old attempt it works basically without the modulo operator. 440 = 2024 - 1584 110.0 = 440 / 4 .0 tells me it's a leap year. 110 tells me 2024 it's the 110th leap year after 1584 441 = 2024 - 1584 110.25 = 440 / 4 .25 tells me there are three years to the next leap year 110 tells mme the last leap year, the one year ago was the 110th leap year after 1584 14 = 2022 - 2008 3.5 = 14 / 4 .5 tells me, in two years is a leap year (or two years ago was a leap year) 3. tells me, the last leap year was the third leap year after 2008 :) However, I am not sure if that is correct for all the next thousands of years.. :) 
&amp;Calendar also works.
Yes I'm a little confused at what DataFusion is exactly. As someone with zero knowledge in databases, DataFusion seems to be a database like PostgreSQL or MySQL, but written in Rust. Is this correct /u/andygrove73 ?
I suppose we should say \_they\_ inform others of some aspect of your system. OP's comment was that people programming in dynamic languages don't create mental models of there business problem. For many people, the problem is that many static type systems, get in the way if thinking about the business problem. 
That's part of why I personally liked the idea of using `@Trait` instead of `impl Trait` back when the discussion was being had. Basically and `@Trait` is a type, with abstract semantics (much like `mut` or `&amp;` can change the semantics of an instance). Then doing something like `type Foo = @Bar` is an error, but `type @Foo = @Bar` is not and leaves things clear. In that view all abstract types should have `impl` before them. As you've this is ugly and noisy, since we assume that anything after `impl` is a trait, we've done a semantic overloading of `impl`. We can't do `type impl Foo = impl Bar` because `Foo` is not a trait, but `impl` implies it is (because it happens to syntactically be identical to something with different semantics). &gt; It's too late to go back on it now though so we have to find another solution to this referential transparency problem. I don't think so. That's what Rust epochs are about fixing. This wouldn't be a dramatic change, since the issue is that doing this shows that `impl` is being used with different semantic meanings, changing it to two things is just a syntactical change. It may be that some time to really understand the consequences of impl types and see what seems more natural once `dyn Trait` becomes the one way to make dynamic types. It may be clearer what will be the best way forward.
You can add a dependency to `phf = "0.7.22"` to your crate as normal. Cargo can handle multiple versions of a crate.
That's a fairly standard reply, but I can't help feeling it completely ignores the actual details of the question I posed in lieu of the more general "what does static typing give me", which wasn't the question I posed. In the case I have a very highly typed and constrained database, what is the strong typing in this scenario, where the language is mostly a shim to convert JSON to a database record, giving me? I get data validation and special record behavior out of constraints and triggers. The schema *is* the typed record. Strongly typing above that is another place to mismatch the model to the schema, in this case, and I think there's a lot of places where this might apply. Put another way, it's not so much a lack of strong typing, but a lack of strong typing in the the *programming language*, because it's already handled in the data store.
it's called "Visual Studio C# Interactive Window" if you want to google for it. This is news to me, and interesting.
One of the crates (package_d) in my (cargo-)workspace (package_a) depends on 0.7.22, that crate is depended on my packages in my workspace. Updating registry `https://github.com/rust-lang/crates.io-index` error: failed to select a version for `phf`. ... required by package `postgres-shared v0.2.0` ... which is depended on by `postgres-service v0.1.1` ... which is depended on by `package_b v0.1.0 (file:///PATH_TO_PACKAGE_B)` ... which is depended on by `package_a v0.1.0 (file:///PATH_TO_PACKAGE_A)` versions that meet the requirements `= 0.7.21` are: 0.7.21 all possible versions conflict with previously selected packages. previously selected package `phf v0.7.22` ... which is depended on by `package_d v0.1.0 (file:///PATH_TO_PACKAGE_D)` ... which is depended on by `package_c v0.1.0 (file:///PATH_TO_PACKAGE_c)` failed to select a version for `phf` which could resolve this conflict (With my package names anonymized).
thanks. it works now. I am using enum variants: #[derive(Debug)] pub enum Calendar{ Yearly(YearlyCalendar), Monthly(MonthlyCalendar), Weekly(WeeklyCalendar) } pub fn render&lt;'a&gt;(by: By, start_date: NaiveDate, epochs: i32) -&gt; Result&lt;Calendar, &amp;'a str&gt; { if by.eq(&amp;By::YEAR) { Ok(Calendar::Yearly(yearly(start_date, epochs))) } else if by.eq(&amp;By::MONTH) { Ok(Calendar::Monthly(monthly(start_date, epochs))) } else if by.eq(&amp;By::WEEK) { Err(FUNC_NOT_IMPL) } else { Err("ERROR: Unknown") } } thanks
I think I did it last time differently. Maybe with a &amp;. But can't remember. 
&gt; You can do no mental model in a static language as well. We call that "dependency injection" these days.
You can fix the issue by changing the ordering of the traits: type Vf32: Copy + Debug + Add&lt;f32, Output = Self::Vf32&gt; + Add&lt;Self::Vf32, Output = Self::Vf32&gt;; It seems to be a [known bug](https://github.com/rust-lang/rust/issues/47897) though there's other candidates that could be the cause.
Is integration with Apache Arrow part of your plan? I'm just beginning to learn these things but one of Arrows goals is to provide very efficient transfer of data over the network. This is, of course, very important to systems like rain. Does rain define it's own formats or would one be able to use Arrow with rain as it is today? I guess what I'm asking is, is integration with Arrow possible today or would it have to be built in by the rain developers (in which case are there plans to do so)? Datafusion, for example, is built on top of Arrow. Thanks 
Or, in C#, an InvalidOperationException with the message "Collection was modified."
Expecting something about message-passing channels based on crossbeam... :(
&gt; Some more things that dynamic languages tend to abstract away (even at non-zero-cost): &gt; 1. Caring about specific primitive flavors, e.g. i32 vs i64. You usually just work with an "Integer". Often you don't even care if it's fixed-size or auto-growing (bignum). &gt; Whether or not this approach works obviously is based on how much you care about performance. Optimization of such high-level code to actual physical machine representation is limited to what the VM can do behind the scenes. In many cases, I think this happens because dynamic language interpreters are bundled with a JIT compiler that can effectively do runtime type inference. This saves the user from needing to declare number sizes manually, while still offering similar performance under the right circumstances. In principle statically-typed languages can be compiled for a runtime with a JIT too (e.g. Java for the JVM), but it seems like most of them are not.
This isn't so far off. IMO, dynamic languages shine when you haven't figured out the mental model yet, or when you can derive value from the program without having either the model or the program fully fleshed out. There's lots of legitimate business cases for that sort of project.
It doesn't affect me personally so I won't complain about this decision (if other people like it, so be it), but I would like to make the obligatory complaint about Discord not really being that great on top of being proprietary. Been trying to dump Discord for a while now but people won't adopt anything else.
I laughed and somehow concur. But we have to admit that common lisp programmers are often a different breed than JavaScript programmers :)
I realize these are just my grumpy opinions, and others may really like Discord, but I wish "official" chat wouldn't move from IRC. IRC is slightly difficult to get started with, but there's new web clients that are quite nice, and is open. Since the net-wg moved over, I just haven't followed along, when IRC was working perfectly. What I do with hyper is there is both an IRC channel `#hyper`, and a Gitter room, and a bot is setup to ensure communication in either is mirrored.
Do you just store data in your app ? Where does the data come from ?
You said... &gt; eventually you're going to pass your object into a function or something that is explicitly annotated and get a check. I gave an example where that wasn't the case.
Proprietary.. Electron What's not to like?
True, yet the most popular dynamic languages don't have first order bignums, so maybe we should judge dynamic languages from Lisp, which does lots of things right, not Python or js :) For the record, I love type systems but I do some dirty scripting on CL or Python. In my experience of system programmer, type safety is a real complexity management refactoring tool. I wouldn't do a 500kloc app in a dynamic language.
So where is the actual application that does something with the data? is it written purely as stored procedures?
The "immediate window" in Visual Studio has supported this since at least 2012. If you're using .Net Core, Visual Studio Code treats the Debug pane like an REPL if you have the C# extension installed too, though sometimes it can take a beat (if you're asking it to unroll an IEnumerable for instance). 
Could Rust have a dynamic language subset, or some sort of easy mode, within Rust, so one could do fast prototyping and other quick and dirty type work? Maybe where everything is autoboxed and you can just put any datatype on any struct. Not that you should do that all the time but it might be handy to avoid having to switch to a dynamic language.
Immediates are not the same as a REPL, though similar. With a REPL, you can actually build up a program line by line. With an Immediate, you're basically limited to that one line. Even if you can hack around that limitation, it still doesn't compare.
It's fairly common in backend systems to change the structure of data. The nice thing about having a static type system in your other systems (front end, server, other services, etc.) is that you can update the structure of the corresponding type and let the compiler errors guide your refactoring. I've seen the argument from fellow engineers that "well, if you have tests, you don't need types," and that's true - good tests can obviate the need for types. But then I have to maintain tests to check for the structure of my data. I'd rather declaratively say what my data looks like and then continue on my merry way writing my business logic and tests for actual functionality.
Non Rust related anecdote. [`tridactyl`](https://github.com/cmcaine/tridactyl) developers have a similar setup. They have a Matrix channel which is synced with IRC and Gitter. That made it easy for me and other new users to communicate with them. I had questions timely answered, and even managed to send a couple of trivial patches within 48 hours of using the extension. Furthermore, the positive experience encouraged me to install [weechat-matrix-protocol-script](https://github.com/torhve/weechat-matrix-protocol-script), and Riot.im on my mobile phone. If tridactyl chose Discord for communication, I would have never attempted to contact them, and I wouldn't be still using the extension today.
Ruby does it automatically (of course, in Ruby numbers are immutable, so it doesn't resize the original but rebinds the variable to a new value): number = 2 puts number.class # Fixnum puts number.size # 8 (bytes on 64-bit machines) number = number ** 64 # 1208925819614629174706176 puts number.class # Bignum puts number.size # 11 Fixnums are stack-allocated and Bignums are heap-allocated, but since both types are immutable, this is invisible to the end user.
**But why Discord and not [Gitter](https://gitter.im)?** * Guest users can read Gitter chats, without login. But **on Discord, you have to register to read chats.** * **Gitter is open source** https://gitlab.com/gitlab-org/gitter but Discord is proprietary * I am a fan of dark UIs but even for me Discord dark UI is bit awkward, too many components. I know it has a white theme. But Gitter UI is simpler and easy to use. * https://gitter.im/rust-lang/rust was really active even on weekends, compared to IRC. So it proves it can replace IRC support channels. Is it still buggy?
Doesnt matter to me that much as I only chat on occasion. I will say that I never really used discord seriously for anything outside of games. Even for games I preferred using teamspeak/mumble. Unfortunately most gamers seem to be moving to discord probably due to ease of use/cost. I would expect most people that can figure out how to work an irc client (hopefully every developer) will prefer that over Discords' desktop app. I suppose it is nice to have voice and text in one place though. If the team needs discord to be efficient then so be it.