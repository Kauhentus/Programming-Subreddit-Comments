I don't think this is true, I asked around and it seems like they're still far from making a decision here. (Haven't got this answer firsthand though) Looking at that table we're closer to repro builds than I thought. Update: Someone working on it confirmed that they still haven't made a decision yet.
You could read it as a `&amp;[u32]` with some unsafe code and some care. Trying to make a Vec&lt;u32&gt; would be a worse idea, but is also possible (You'd have to make it back into a Vec&lt;u8&gt; for deallocation afterwards, and you'd have to be very careful to avoid triggering any undefined behaviour)
Really? That seems like a good way to get into trouble. Parser libraries make things a lot better. 
I'm curious about how the multiple cursor support will end up comparing to what [kakoune](http://kakoune.org/) does.
Looks pretty awesome! Seems like this would be great for debugging different settings in programs without having to either include file watching for reloading config files or restart the program.
what framework or library should I use to create a simple or not really simple android application?
Any links?
While interesting, I can see one obvious flaw: struct SafeAbstraction { ... } impl SafeAbstraction { fn new(arg: Arg) -&gt; Option&lt;Self&gt; { if arg.satisfies_invariant() { Some(...) } else { None } } #[launch_code="..."] fn do_dangerous_thing_safely(&amp;self) { unsafe { // Something that is OK if invariant checked by new holds but terribly wrong if it doesn't. } } } If someone changed `new()` to omit checking, your signature would still be valid.
&gt; Multiple people have told me that ed25519-dalek might be the best ed25519 lib out there. Interesting. What makes it better than other implementations?
Please avoid `unwrap()` where you can!
for programming languages, even if people use parser libraries, they soon outgrow them. But keeping good quality is hard when you get at that scale :/
&gt; it would be nice to be reassured that they actually intend to be competitive with C in having the abilities desired by the specialist security programming community, Most people I've talked to do want Rust to support these kinds of uses. &gt; locking memory from swap, constant time operations, and so on. These are not facilities provided by C, and they are already available to Rust programs by various libraries.
Awesome! I've been wanting to do something similar in elm, but now I'll just use yours. I think something like this could become a fairly important library, considering how few good GUI crates rust has.
When a program uses `unsafe`, it's not just an `unsafe` block location where crashes can happen, but an entire file. Consider a `Vec`. It has invariants like capacity &gt;= len, you need to have space allocated for the capacity, accessible elements must be initialized. For instance, having a following method in Vec API would be unsafe (as it would break assumptions of actually unsafe code in it), even if it technically doesn't use `unsafe` (assuming Vec has private `ptr`, `len` and `capacity` properties, in a real implementation there is `RawVec` struct and so on, but the argument still applies). pub fn cause_explosions(&amp;mut self) { self.ptr = std::ptr::null_mut(); self.len = 42; self.capacity = 3; }
Ah, got it. Yeah, Python tuples are a combination of "tuple" and "immutable list" depending on interpretation. TL;DR scripting languages are strange. ;-) (Not you, Lua, you're my one true love. :-x )
This is amazing! How has nobody ever thought of this before?!
For what it's worth, if through-hole is important to you, there's the [LPC810M021FN8](http://www.nxp.com/products/microcontrollers-and-processors/arm-processors/lpc-cortex-m-mcus/lpc800-series-cortex-m0-plus-mcus/low-cost-32-bit-microcontroller-mcu-based-on-arm-cortex-m0-plus-core:LPC810M021FN8?fpsp=1&amp;tab=Overview) by NXP. It's available for [2,92€ at Mouser](http://www.mouser.de/ProductDetail/NXP-Semiconductors/LPC810M021FN8FP/?qs=sGAEpiMZZMtmz9NzafXQyhIvAjwTEyrk). Rust runs great on it, but with only 8 pins it's severely limited I/O-wise and it doesn't have an ADC. I'm currently using the [LPC822M101JDH20J](http://www.nxp.com/products/microcontrollers-and-processors/arm-processors/lpc-cortex-m-mcus/lpc800-series-cortex-m0-plus-mcus/low-cost-32-bit-microcontroller-based-on-arm-cortex-m0-plus:LPC822M101JDH20?fpsp=1&amp;tab=Overview), which is cheaper ([1,41€ at Mouser](http://www.mouser.de/ProductDetail/NXP/LPC822M101JDH20J/?qs=%2fha2pyFaduiBvmT3%2fNSxeNpZ9k3t1M3FAWm6CYKimZt6U3WLiAyKdQ%3d%3d)) and more capable, but not through-hole and therefore harder to solder. Let me know, if you're interested in any of those. I have some code for them that I haven't released yet (working on it). I'm not aware of any other through-hole ARMs. There was another one by NXP, but it doesn't seem to be sold anymore. I guess most hobbyists just use development boards.
Hmm, I was thinking more of the higher end ATMegas such as the 328 and 2560. As for development​ platforms, it is much more difficult to start from scratch as virtually all new chips are surface mount​, but you can get preassembled dev boards with USB programming and debugging for $20. Still, they are not as easy to use as AVR.
Coursera has a good recommender system course [here](https://www.coursera.org/specializations/recommender-systems). If you look up the individual courses, 'enrolling' has a free audit option.
This would of course be logical. And we would all then have equal difficulty writing programs. But better the devil you know how to type, as they say
Dammit if we can have emoji identifiers we at least deserve to have Unicode keywords! Even if they're just aliases. Brb making a macro suite for this. ---- nvm, &amp;and; (`\u{2227}`) is not a valid identifier. I'm gonna have to learn how to make a parser and write a Rust skin aren't I.
That's probably because `v[..6]` is the equivalent of `v[5]` as far as assertions go: it will fail if `5` is not a valid index, and "proves" that other indexes lower than 5 will not fail it if succeeds.
Well, that's a problem - you need to figure this out, put it in your build script and hope Android does not change build process too soon so that it keeps working. By the way, this is great! Thanks for figuring that out, if you don't mind I am going to steal it because my old version which I did a year ago no longer works :P
Often forgotten fact about `unsafe`: the *least* possible boundary of unsafe behavior is the **module** containing `unsafe`, not the function.
To get single page HTML, you can use the print view-- there's a little printer icon in the upper right that will get you [here](https://doc.rust-lang.org/nightly/book/second-edition/print.html) :)
I was thinking that with raw C code, you could compile that C code on a new system build a rust compiler. I'm guessing I'm missing something, though.
Besides just gamdev you might be able to get normal guis with a Rust backend working with QML
For a small project I wrote, [ppbert](https://crates.io/crates/ppbert), I initially used nom, but I quickly ended up ditching it and using a hand-written parser. I found the macros difficult to use (and Emacs really can't indent them correctly), the error messages when I used macros incorrectly undecipherable, and the documentation on how to have custom errors was lacking—I thought it was telling that the majority of examples I found online had a `// TODO: improve error handling` comment. I'm sure nom could generate code that is faster and more robust than my little hand-written parser, and if the format I was handling wasn't as simple as it is, I would probably appreciate nom more. However, for the time being I am extremely happy that I removed that dependency from my project.
I also type dvorak, but I'm a touch typists so I haven't bothered buying a special keyboard. :-) Regardless, I don't have the space on my keyboard for those extra keys, and I'm not willing to sacrifice any of my current keys, so I don't expect those keys ever to turn up on keyboards.
I've used word2vec in the past but I have no idea how it works. But yeah if you also feel adventurous we can start working on item2vec or gloVe. However I don't know if this should be on this crate, maybe it should be in a new crate and use it here as a dependency? I'm using sprs right now, it seems to be the most popular library for handling sparse matrices. I don't really know how fast it is. However I feel like quackin needs a little more work covering basic collaborative filtering stuff, probably SVD++ is too much, but it would be nice to have an implementation of SVD. 
Yes, `println!()`. In all seriousness, it's fairly easy to show process output in real time on a web page. Do you have anything more complicated in mind?
Sweet idea.
Great find! Thanks for sharing.
You probably meant to post this on /r/playrust
Have you tried rebuilding it in rust?
One of my big problems with Open and FreeBSD is how much of a C-or-shell culture it is. Those are basically the two languages everything seems to be written in and those who are well supported. The whole cultural idea of syscalls-over-files isn't helping much either where you need to FFI to the respective libc for things which on other systems just work rather easily by using normal filesystem operations on a virtual file.
Is there a way this could use custom derives instead of wrapping a macro around my struct? These kind of macros are always annoying to deal with because they make it harder for tooling to work on the contents (I believe rustfmt doesn't touch anything inside these macros). In general I think these wrapping macros should have as little code as possible inside of them.
Just follow the badge in the README over to docs.rs :) https://docs.rs/debug_stub_derive/
Ah, I'm not used to finding docs that way! TIL, thanks! :) 
That the assembly has been carefully verified to be CT. (Of course, this can change, but I think it's the only one out there that's done this)
I'm using Nucleo-F303RE bord and I'm trying to walk trough the post but I'm getting the following error in the openocd terminal: undefined debug reason 7 - target needs reset. Please help.
Honestly I feel there is sometimes a phobia for unwrap that is unjustified. Yes a bug can cause a panic but so can any index of anything and I don't see people advocating `vector.get(4).expect("this should be inside of the bounds")` with the same zeal instead of just `&amp;vector[4]` In the end if you have `if x.is_some() { ... x.unwrap() ... }` you just know it's not going to panic just as much as a lot of indexing we do because other parts of the code know it's inside of the bounds.
No, but I imagine it's more involved than the form template.
JMX?
The [LPC1114FN28](http://www.nxp.com/products/microcontrollers-and-processors/arm-processors/lpc-cortex-m-mcus/lpc1100-cortex-m0-plus-m0/scalable-entry-level-32-bit-microcontroller-mcu-based-on-arm-cortex-m0-plus-m0-cores:LPC1114FN28) which is also a DIP-packaged Cortex-M0 is still available. It has more IO than the LPC810 but I think it is a bit harder to source. 
Ah thanks, I wasn't aware of that project. Too bad what it generates doesn't look very good. As far as using it for a full GUI library, some people have thrown around the idea of using servo's webrender component for that, but I don't know of any initiatives in that space.
can you elaborate on that?
Not that I know of.
I can try to take a look at this. I've built gradle plugins in groovy in the past. You need both github sources and the online docs and have to fill in the blanks. I would love to build for Android without so much boiler plate.
It might be possible to use the native apk functionality and bind to the c++ libraries, but the API is very limited and you'll still need to render from the Rust side. It's been awhile since I looked at android_glue but that's probably where you need to start.
&gt; undefined debug reason 7 - target needs reset. I had messed up memory.x file. ram was 80k but tried with 64k and the hello world example works now !
This looks great. I'm a bit sad it doesn't support serialization of things like Vec or BTreeSet/Map. For my use case I'd love a no_std supporting format with optional support for alloc/collections. Currently I'm hacking up bincode to support that.
https://github.com/White-Oak/qml-rust You can build it for Android the way you build most Rust software, and use the build.rs to bundle the qrc resources and QML into your binary.
I will write you a PM saying that you can find me on #rust irc channel and my nick there is "nercury", as well as some background info.
I believe you are looking for https://play.rust-lang.org/
Yay for opening things in a tab and getting back to them days later! (this one was actually pretty quickly as things go) I think there are actually two traits lurking, not just one. Old comment: https://www.reddit.com/r/rust/comments/4l4wjl/a_report_on_regions_and_linear_types/d3lygjn/ I agree that panics are the mortal nemesis of linear types in Rust, and that destructor bombs are the only good solution. And that `&amp;out`/`&amp;uninit` is like the "canonical" example of such a type. (There's been at least one RFC I think, I assume you've seen it/them?) &gt; Almost every type in Rust is Clone (or, at least, could be without any issue). ...like how `&amp;mut` is the "canonical" example of a non-cloneable type. ;) &gt; 2.3 Usage Examples This is really interesting. Can this be framed as the checker not being as smart/sophisticated as it should be? I mean, you're correct that the way you've presented it would be entirely consistent with how the existing checker treats `Copy`. On the other hand, if I have a `x: (T, ())`, it lets me copy `x.1` no problem without it counting as a move of `x` as a whole, and if I have `y: (T, T)` it even lets me move one of them without it counting as having also (potentially-)moved the other. *Why does the borrow checker get to have special knowledge of product types but not sum types?* It feels to me that's what needed here (to make the examples not suck) is for the borrow checker to be able to treat different variants of an enum "independently of each other" (to *know* that actually, `None` doesn't contain a `T`), in a way that's analogous/dual to how it already treats fields of a struct independently, but it's not like I've thought it through or anything. 
What other traits would come to your mind here? :) Personally I could imaging `Hash` being useful in a few places, since it does not interact with other values and a previously non-hashable value might not always be relevant for actually distinguishing its containing struct or enum. `Default` could also be a candidate, if you allow for arbitrary expressions when stubbing out. However, most of the std derives would seem rather complicated.
Just bought your iOS version. I'm learning rust and hopefully will be able to jump into game dev soon. Would really appreciate a write up of how you made the game :)
But then you can't publish to crates.io, can you?
Tokio doesn't exist at the same level of the stack as goroutines do, so it's always going to get blown away in terms of ergonomics. In order to improve in this area you might want to implement a coroutine library on top of Tokio (though maybe the futures crate is supposed to be at that level of abstraction? I haven't used it), and for maximum effect you might want the proposed async/await syntax on top of that.
You can implement it yourself if you import `libc` and call `setsockopt` with `SO_SNDBUF` option. It'll require an unsafe structure but it'll work. 
There is also [corepack](http://github.com/jrasky/corepack) which is a `no_std` implementation of [MessagePack](http://msgpack.org) based on serde and already supports serialization of more complex types. An upcoming release will support serde 1.0 (work already done in a branch).
Yep, I was considering doing that next, along with multithreading. I should probably write a more practical server first before I start getting into performance tuning though.
I feel like the naming could be a little better. `then` vs `and_then` is confusing but I get that it's trying to follow the convention of existing adapters for iterators and Options. Timer code needs some love too. You can run into weird runtime behavior if your tickrate isn't set right, like if you try to run an interval below 100 ms on a default tokio-timer. After writing this code though, I feel more confident in how to structure Tokio and Future-based programs. So it's probably just a case of getting more familiar with the existing combinators and adapters, and knowing what the error messages *really* mean when you do something wrong. I don't know to what extent a crate can influence what the compiler outputs, but having better error messages would be incredibly helpful in getting you through your problems. Like kibwen said, having an async/await syntax would probably work wonders but I'm not sure how easy that is to implement. But really, having this extra difficulty is not a terrible tradeoff for getting a performant and reasonably safe server at the end of it. I'd probably reach for Go at my day job but if I wanted a game server that could fit as many processes as possible on one machine, I'd definitely write it with Tokio.
I could see that leading to a lot of "Surprise" among consumers of libraries that use it, though?
For stdlib, `rustup doc`, assuming you've installed via rustup. For a project and its dependencies, `cargo doc --open` will build then open them as llogiq said.
I haven't done advanced error handling in nom, but `do_parse` will return `IResult::Error` and abort whenever one of its sub-parsers returns an error. It will not continue parsing.
Very interesting. Just a few days ago, I wondered how a hash table for building a custom in-memory key value store could look like, especially with regards to high level of concurrency and many clients. &gt; Several ways to get there exists, unfortunately they all have their trade-offs. Just for the sake of completeness, could you name the most popular approaches so that I could do some more research?
&gt; Just for the sake of completeness, could you name the most popular approaches so that I could do some more research? There are so many, it's impossible to take the "most popular" one. I'll name a few anyway: - Cliff Click's lock-free hash table - Hashing with chaining (e.g. Treiber stacks) - Striping (probably the most popular, but it's scalability story is meh) - Designs similar to [chashmap](https://docs.rs/chashmap/2.2.0/chashmap/) (not sure if this particular design has a name)
I always find that colored outout, classified by severity level, makes it much easier to follow the output. You can see a screenshot of colog in action on the github page: https://github.com/chrivers/rust-colog As I mentioned, this is my first crate, so feedback is very welcome. I hope you find colog useful!
You can't do that. Default trait method bodies have to apply to *all* possible implementations of that trait, meaning they can only access things defined (or required) by the trait. Traits can't define fields, so you can't access them. **Edit**: to put it another way, just like all generics in Rust, default trait method bodies are checked at definition, *not* when they're substituted.
I wonder how many people participate in the survey after the first few days. And I wonder if their answers changes meaningfully the statistics. If there are no significant changes, the next survey could be open for a period much shorter than 40 days.
In today's Rust, you will need to use associated types, and add accessor functions to the trait definition. [This RFC](https://github.com/rust-lang/rfcs/pull/1546) proposes a solution to this limitation.
&gt; ~~When implementing both `Hash` and `Eq`, it is important that the following property holds:~~ &gt; &gt; k1 == k2 -&gt; hash(k1) == hash(k2) &gt; &gt; ~~In other words, if two keys are equal, their hashes must also be equal. `HashMap` and `HashSet` both rely on this behavior.~~ &gt; &gt; ~~Thankfully, you won't need to worry about upholding this property when deriving both `Eq` and `Hash` with `#[derive(PartialEq, Eq, Hash)]`.~~ ~~https://doc.rust-lang.org/nightly/std/hash/trait.Hash.html#hash-and-eq~~ Edit: Actually, this only ensures surjectivity, so you're right, that is an assumption made. I can't really see any actual case where you would ignore something in the `Hash` impl, like you only shoot yourself in the foot and get more collisions. Maybe I should have my own extension of `Hash` (`InjectiveHash: Hash`) which has this property... Either way, it doesn't really change the nature of the algorithm, only implemenation details.
Thanks, this is perfect, just what I wanted. This also should be much more available 
`&lt;= size_of::&lt;T&gt;()`, how is this possible in the face of `usize`? Is the serialization simply platform-dependent? Or do you just ban `usize`?
Thanks for the feedback - I discovered that the readme file really needs an update most of all :) I'm already using the [colored](https://crates.io/crates/colored) crate for coloring, but I forgot to update the readme. I will take a look at changing to termcolor + atty, because I don't think colored works on windows. Btw, thanks for making ripgrep awesome :)
As in 'more documented / easier to find'?
It should work in `do_parse`, but the `alt*` macros are problematic, and for example `opt` would probably eat the errors by default.
I recently wrote the [`build-helper`](https://crates.io/crates/build-helper) crate to help with this. It basically just defines functions to read the stuff Cargo exposes to build scripts, and to emit the information Cargo will read back.
&gt; Maybe I'm being pedantic here (if so, sorry :)), but I would say handling this is a significant change of the algorithm, and not just the implementation. I'm really not really getting what your point is? If we add the assumption (perhaps invariant) to our trait `InjectiveHash` that the written bytes of `a`'s hashing are equal to the bytes of `b`'s hashing iff. `a == b`, that'd solve the issue. It's not really any different from how `HashMap` in libstd relies on the fact that `a == b ⇒ hash(a) == hash(b)`.
No, that's in the algorithm to make that impossible due to the bijective hashing.
Oh yeah, definitely true. But the assumption is really an implementation detail. If you ignore the code and only look at the post, it should be pretty clear that the data written in reflects the data of the key (like a string). Maybe I should make it more clear.
Also I wish there was a standard way to say you want to link with C libraries statically. As it is you have to read the build script, and hope there is an environment variable that isn't ignored on Linux or whatever.
If everything implementing `Timer` will have fields like `cr1`, you could put getter and setter functions in the trait (or in another trait), and use those in the default implementation. Then, you'd only need to implement the getters and setters.
do you know if/when the RFC is likely to be "approved"/implemented? More in general: how can I know if/when an RFC is expected to enter the final comment period?
Thanks, this was the way to go: //! Periodic timer use core::u16; use cast::{u16, u32}; use stm32f103xx::{Rcc, Tim2, tim2, Tim3}; use frequency; /// Specialized `Result` type pub type Result&lt;T&gt; = ::core::result::Result&lt;T, Error&gt;; /// An error pub struct Error { _0: (), } pub trait Timer { fn init(&amp;self, rcc: &amp;Rcc, frequency: u32); /// Clears the update event flag /// /// Returns `Err` if no update event has occurred fn clear_update_flag(&amp;self) -&gt; Result&lt;()&gt; { if self.get_sr().read().uif().is_no_update() { Err(Error { _0: () }) } else { self.get_sr().modify(|_, w| w.uif().clear()); Ok(()) } } /// Resumes the timer count fn resume(&amp;self) {self.get_cr1().modify(|_, w| w.cen().enabled());} /// Pauses the timer fn pause(&amp;self) {self.get_cr1().modify(|_, w| w.cen().disabled());} fn get_cr1(&amp;self) -&gt; &amp;tim2::Cr1; fn get_sr(&amp;self) -&gt; &amp;tim2::Sr; } impl Timer for Tim2{ /// Initializes the timer with a periodic timeout of `frequency` Hz /// /// NOTE After initialization, the timer will be in the paused state. fn init(&amp;self, rcc: &amp;Rcc, frequency: u32) { // Power up peripherals rcc.apb1enr.modify(|_, w| w.tim2en().enabled()); let ratio = frequency::APB1 / frequency; let psc = u16((ratio - 1) / u32(u16::MAX)).unwrap(); self.psc.write(|w| w.psc().bits(psc)); let arr = u16(ratio / u32(psc + 1)).unwrap(); self.arr.write(|w| w.arr().bits(arr)); self.dier.write(|w| unsafe { w.uie().bits(1) }); self.cr1.write(|w| w.opm().continuous()); } fn get_cr1(&amp;self) -&gt; &amp;tim2::Cr1 { &amp;self.cr1 } fn get_sr(&amp;self) -&gt; &amp;tim2::Sr { &amp;self.sr } } impl Timer for Tim3{ /// Initializes the timer with a periodic timeout of `frequency` Hz /// /// NOTE After initialization, the timer will be in the paused state. fn init(&amp;self, rcc: &amp;Rcc, frequency: u32) { // Power up peripherals rcc.apb1enr.modify(|_, w| w.tim3en().enabled()); let ratio = frequency::APB1 / frequency; let psc = u16((ratio - 1) / u32(u16::MAX)).unwrap(); self.psc.write(|w| w.psc().bits(psc)); let arr = u16(ratio / u32(psc + 1)).unwrap(); self.arr.write(|w| w.arr().bits(arr)); self.dier.write(|w| unsafe { w.uie().bits(1) }); self.cr1.write(|w| w.opm().continuous()); } fn get_cr1(&amp;self) -&gt; &amp;tim2::Cr1 { &amp;self.cr1 } fn get_sr(&amp;self) -&gt; &amp;tim2::Sr { &amp;self.sr } } got rid of a lot of the boiler plate. The only reason this worked in this case though are the registers were built from a template, so they are all tim2::whatever types. edit: if they weren't the same return type I could have gone with associated type I guess
I'd say that if you feel that an `alt*` should return an error, what you actually need is to do a lookahead to commit to a particular path or return an error.
Why not use SipHash instead of your bijective sponge homebrewed impl? 
Hmm so my fork of `bincode` does exactly that, but the issue with using `core_io` is that it's limited by the latest compiler version that `core_io` supports.
But then my `alt` combinators need to be aware and manage the structure of the subcombinators. This also doesn't work when things are nested. As soon as the parser function returns, the caller can't discern between "would be an X but isn't well formed" and "not an X". One could probably get away with a custom error signalling bailout and various guarding short-circuits throughout the constructed parsers.
Are you saying that you hash the key before you feed it to the `Sponge`? It doesn't say that in your post. Otherwise it seems like you may allocate as many tables as there are bytes in the key.
Yep. Jvm has had this for a decade....
No, because hash tables only use the hash value modulo some number.
Peace of mind from a secure implementation is more valuable than additional efficiency. I know we all want get as much speed as we can out of our code but the security of a system comes first and speed needs to take the back seat if our definition of security is not being met. It is something to think about anyway.
You could imagine `any` acquiring an optional parameter to tell whether the error returned by the child parser is fatal.
I'm very confused. Was I correct when I said: &gt;i.e. the worst case memory usage scales quadratically with the size of the keys. 
Can you give me an example to test and can you tell me what information you expect the debugger to show you?
It's interesting to me that the `gst::Pipeline` `add_*` functions all return `bool`: fn add&lt;E: Into&lt;Element&gt;&gt;(&amp;mut self, element: E) -&gt; bool fn add_and_link&lt;E: Into&lt;Element&gt;&gt;(&amp;mut self, src: E, sink: E) -&gt; bool fn add_many(&amp;mut self, elements: Vec&lt;Element&gt;) -&gt; bool fn add_and_link_many(&amp;mut self, elements: Vec&lt;Element&gt;) -&gt; bool In Rust, I'm so much more used to seeing `Option&lt;T&gt;` or `Result&lt;T,E&gt;` that these jump out a little at me. If an add fails, does gstreamer generally not know why? It seems like it might be useful to say "these elements aren't compatible with each other" or whatever, if that information is available. Let's assume for the moment that we do want to stick with `bool` in cases like this, though. After all, both `Option&lt;()&gt;` and `Result&lt;(),()&gt;` look weird, and having a Success/Fail enum is less ergonomic to branch on. This gets me thinking about the forthcoming `Try` trait. Is there a planned implementation for `bool`? It seems reasonable that if we tell people that `bool` is a reasonable way to return status, then we should support that use case with `?`. `true?` would then evaluate to `()`, while `false?` would early-return `false`. On the other hand, that seems like giving a bunch of semantic meaning to `bool` beyond what it really deserves.
My guess is that there's some FFI reasoning behind it and keeping the Rust signature closer to the normal bindings would make it easier for normal GStreamer devs to understand what's going on and less what the correct way to do it in Rust is.
In addition to your statement: &gt; In other words, it relies on the correctness and quality of the underlying hash function, which we would like to avoid. May actually be desirable if I understand correctly the discussion in the issue. You can't rely on a secure hash function in a hash table. Additional countermeasures need to be accounted for. Just because a a strong hash function is being used does not mean the hash table is secure.
The current bindings aren't fully idiomatic. You bring out very good points if how much more idiomatic they could be. We are working on it. More soon to come.
It took me a pretty long time to find out how to scroll this page. Normal scrolling doesn't work. You tab until you select an element inside of the page and then you just press down. At least on Chromium.
I just want to get rid of the scrollbar (Chromium on Linux show a white scrollbar, which is bad on my dark theme). Just fixed the scroll and styled the scrollbar, works well with vimium now :D 
And for Vec you may want to use `Box::into_raw` on a boxed slice.
&gt; I can prove its security (contrary to classical hash functions) Could you point me to any resources or related information that demonstrates its security so I can learn about it more? Having a more formal writeup for your hash function would be helpful but really any information you could link is helpful :)
Is there a way to guarantee alignment of a variable within a `[repr(C)]` structure? I'm trying to interface with the Linux kernel packet buffers. The C structure is roughly (in hybrid C/Rust). #[repr(C)] pub struct Timestamp { tsec: uint32_t, tnsec: uint32_t } #[repr(C)] pub struct BlockHeader { bock_status: uint32_t, packet_count: uint32_t, offset_to_first_packet: uint32_t, valid_bytes: uint32_t, __attribute__ ((align(8))) // gcc and clang syntax seg_num: uint64_t, first_packet_timestamp: Timestamp, last_packet_timestamp: Timestamp } C code [linky](http://elixir.free-electrons.com/linux/latest/source/include/uapi/linux/if_packet.h#L186) --- Intuitively shouldn't `seg_num` already be 8bytes aligned as the proceeding 4 values are 4 bytes each? 
Yes. Easier to find. I also like the Elixir language and in the very first page with the main features and a few examples, they already teach you how to get to the documentation of the functions. I think makes sense as that's kind of first thing a novel user will need.
I'm thinking about how would we bring it back to Rust to deallocate it. In this case, should we create a function like 'ffi_dealloc' in Rust that takes a pointer, convert it back to a CStr and bind it to a variable, then let Rust free it? 
Since you are using lldb, you might also want to check out my [CodeLLDB](https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb) extension.
So it's a 100% replacement of try! ?
Hm, I've always used the lldb extension with `"sourceLanguages": ["rust"]` in the debug configuration. Does the Native Debug extension work well?
Is your system up to date and do you have the ca certificates packages (including the Mozilla one) installed?
I asked mostly because that's viewed as idiomatic I think. I will need some form processing soon but it doesn't have to be real-time, so I don't know whether I'll use this crate. I'll keep an eye on it though. :)
Bought! I like it. 
When I needed to bridge Rust with C++ I solved strings by creating: #[repr(C)] struct RustSlice&lt;T&gt; { ptr: *const T, len: usize, } Then I created same struct at C++ end and added conversion functions from actual rust slices (`&amp;[T]`). Worked very well, not just for strings (which I passed as `&amp;[u8]`).
I'm aware of it, yes. But I'm working with/on gir from the gtk-rs project as that is actively maintained and seems to have the most traction currently: https://github.com/gtk-rs/gir
almost always. one time use, or internal non customer facing tools, may not matter at all. and it isn't like the jvm is idiotic. 
&gt; let alone do any sort of good error recovery Concur completely. &gt;There's a reason just about every major language parser is hand-written. With the notable exception of [ghc](https://github.com/ghc/ghc/blob/master/compiler/parser/Parser.y), however.
You are welcome :)
&gt; `Result&lt;(), ()&gt;` would seem like the best choice for now, but is really weird as you say. I'd rather use something like `Result&lt;(), GstError&gt;` so you could extend it or add an error message. Opaque “GStreamer error” is still better than ``called `Result::unwrap()` on an `Err` value: ()``.
https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy
Thank you!
Just convert back, Drop should run anyway I think? No need to bind to a variable…
Hopefully this doesn't steal social thunder from the official 2-year announcement. I wish this could have waited.
I don't think this is true. You need to understand type theory for a really tiny portion of it. And even then, not really. Yes, it is complicated, but all big projects are. One thing folks often do is contribute to clippy first (we have a ton of mentored easy bugs) which lets them understand the internals, and then try the main compiler. But really you don't even need to do that, plenty of folks have easily contributed to rustc directly. Rust does mentored bugs too. As with any large codebase, you don't need to understand all of it to get anywhere. I don't understand all of rustc, but I've done lots of contributing, even back when I didn't know much Rust.
`FnBox` stabilized: I completely disagree. There needs to be a more general solution; I prefer `&amp;move`, although nmatsakis prefers rvalue DSTs.
Note that `static` has rather undesirable behavior. Specifically when you're building an rlib, `rustc` will be responsible for finding the library instead of the linker (thereby completely ignoring all the paths that the linker would search in), as well as bundling the static library into the rlib which will sometimes break things (most notably msvc libraries compiled with `/GL` but it affects other platforms too). I highly recommend using the newer `static-nobundle` instead, either immediately if you use nightly, or as soon as it stabilizes otherwise. https://github.com/rust-lang/rust/pull/38426
Is there any way to debug this behavior? I want to see it in action.
I'm all for better solutions if they're around! It's more because of a smaller project I'm working on that it came up. Also thank you!
Why does this pass the borrow checker? let mut it = "Hello World".chars().peekable(); match it.peek() { _ =&gt; { it.next(); } } If I do the same thing but bind the peek to a name: let mut it = "Hello World".chars().peekable(); let c = it.peek(); match c { _ =&gt; { it.next(); } } I have two mutable borrows at the call to next. When you match over something that requires a mutable borrow, does that borrow end after matching if you don't bind it to a name? Where is that behavior defined? EDIT to add: And how can I get this behavior if I have a predicate on a match (is it possible)? I'd like to be able to do something like: let mut it = "H3110 W0RLD".chars().peekable(); let x = match it.peek() { Some(&amp;' ') =&gt; Some(it.next()), Some(c) if c.is_alphabetic() =&gt; Some(it.next()), _ =&gt; None } but this doesn't work because the peek mutable borrow lasts through the arms in this case (it seems like). I don't need the peek bound, in fact, I need it not bound to let the borrow end if I'm understanding this correctly.
You're looking for /r/playrust
`pub(restricted)` is stable in 1.18. Not saying you need to cover it, but it's not just a proposal anymore.
Using the `&amp;` ampersand means the value `c` is copied (because chars implement `Copy`) instead of borrowed.
Excellent work guys. As someone who has not played around with media streaming applications before, this code looks approachable, understandable, and (most important maybe) fun to write!
Obvious in hindsight... thanks!
I'll be helping [land the latest PR for shattering the Rusoto crate](https://github.com/rusoto/rusoto/pull/641) (mad props to mthjones for his great work on that!). I'm also working on a blog post walkthrough of using Rusoto to create a Postgres database on AWS and interacting with it in a Rocket site, using Diesel as the ORM. Lots of learning to write it, as I haven't used Rust for any database interaction before.
io::Result&lt;T&gt; is equal to Result&lt;T, io::error&gt;. I think. Correct me if I am wrong.
It's common to specialize [`std::result::Result&lt;T, E&gt;`](https://doc.rust-lang.org/std/result/enum.Result.html) to ease the use with specific libraries. [`std::io::Result&lt;T&gt;`](https://doc.rust-lang.org/std/io/type.Result.html) for example is actually an alias to `std::result::Result&lt;T, std::io::Error&gt;`, and it's obvious that you will frequently want the [`std::io::Error`](https://doc.rust-lang.org/std/io/struct.Error.html) for I/O tasks. Since this will immediately collide with the general `Result` type, normally they are not directly `use`d and referred via an indirect path like `io::Result&lt;T&gt;` (given that you have `use std::io;`) or `serde_yaml::Result`.
Thanks! This is just what I needed today. :) Does anyone have experience using the rust-lldb pretty printer from within VS Code?
It seems really silly that they didn't name it `IOError` so that you could just have `Result&lt;T, IOError&gt;` and be a lot clearer.
Gotcha, thanks!
Or `IoResult&lt;T&gt;` (your logic doesn't preclude it :-). I think namespaces exist mainly to *allow* the external name collision, however, so that you can have a massively shorter name when the use is super clear while having a longer name when it becomes ambiguous.
Back when I tried to use LLDB it didn't support x64 on windows properly. Does it now?
Yeah, it's confusing at first, but it's grown on me.
I mean, if you really care, `use std::io::Error as IOError` is an option.
It's a relative path. I mentally substitute '/' for '::' and then I'm clear.
Still working on my GUI framework, which, hasn't really made much progress from last week. Reading resources of ways to render 2D vector stuff via GPU, learning algorithms and trying them in other languages where it's quicker to prototype these things. As I said last week, it's a difficult project and that's definitely showing up as I'm digging into it. My backup plan is to eschew the GPU accelerated side of it, but that'll only be the case if I really can't figure this stuff out. If it *does* comes to that, I'll have a look at trying to design the internal API in such a way that it can be added in later. Only wish was, I wish papers were less of dry read :P
Working on bluepill board support (STM32). Have most of the basic functionality I want. Think I'll write a driver for the uln2003 so I can play around with some steppers.
Yeah but if it's in a dependency I have to work out what magic I need to do so that their `build.rs` script prints that. There's no standard way to do it. 
Ah, I see the gotcha! Thanks!
Now we just need to put these explanations in the book and all will be well. Thanks for the article! ♥
Thanks for the response. That helped me narrow down the problem for sure. Do you mean that works because `MyDuration` is local, or because it's a concrete rather than parameterized type? I was under the impression it was the latter. In my case, manual `impl`s over every type that `impl Note` is preferable to doing the same for `Durational`. Specialization will indeed make life much easier when that lands. [Here's the code I ended up with](https://github.com/andrewcsmith/scritto/blob/master/src/scrittore.rs) in case you're curious.
"security" is probably the wrong term in this case. I thought we were talking about collision-resistance. As for security, if we're talking about hash-flooding, there is literally no countermeasures in the function. So, yeah it's attackable. I'm looking into replacing it.
:))
&gt; I'll hopefully be able to write my beets alternative. Sounds interesting... any plans you can talk about? Different features? Compatibility with beets?
This is [not](https://i.imgur.com/xCPcX1e.jpg) that [complicated](https://i.imgur.com/gw3cMin.jpg).
Easier then writing gpu stuff yourself. Webrenderer can be used, its a lib written to be embedded and they have an example how to do it. I think people quickly get discouraged when they realize what a mountain of work they have ahead of them.
Working on multi protocol version support for [CDRS](https://github.com/AlexPikalov/cdrs), Apache Cassandra DB driver. The plan is to make it extensible via features in order to support multiple Cassandra binary [protocols](https://github.com/apache/cassandra/tree/trunk/doc). So far 3-rd (works for ScyllaDB) and 4-th version are supported.
This is a follow-up from [last week's post](https://jneem.github.io/merging/), where I talked about VCSes from a math point of view. This time, I start looking at pijul itself, and what its mathy foundations imply.
Interestingly, I can't find anything on crates.io, so it looks like you might need to roll it yourself if you really want it. The tricky part in any such iterator is handling the boundary conditions correctly. That is, if you read `N` bytes into a buffer, it's possible that the last few bytes represent a *partial* encoding of a codepoint, so you'll need to keep some (constant amount) of state between reads. The closest out of the box experience I see is in the [`utf-8` crate](https://docs.rs/utf-8/0.7.1/utf8/), which provides a streaming `LossyDecoder`. But the closure oriented API is bound to be a bit awkward. If it were me, I'd probably hand roll an iterator myself. You could also try copying the existing implementation out of `std` (`src/libstd/io/mod.rs`), although looking at it myself, it's decoding a single codepoint at a time. I suppose it's a nice convenience, but it ain't gunna be fast! Instead, if I hand rolled it, I'd use some fixed size buffer and amortize the cost of reads and the cost of decoding.
I'm looking for something to do, mostly! I just sent a pull request implementing From to two enums in the serde_cbor crate (Compact Binary Object Representation, similar to JSON but binary), fairly simple. I'm considering trying to implement zero-copy deserialization for that same crate.
Thanks! Looking at the std implementation, decoding seems pretty straightforward. I'm going to attempt to hand roll this one.
&gt; I managed to write a compiler error that was finally released in Rust 1.17 and was prominently featured in the release notes. That took me a second. At first, I thought you meant you introduced some kind of bug into the compiler.
Couldn't agree more, I have a total mental block when I see foo/bar etc they're just so meaningless, I'd prefer almost anything to it. I've seen comments like yours come up plenty of times before (not just in /r/rust but in /r/programming / hackernews etc as well) and I really wish this was the last time I saw it.
I was in the works of creating a "how-to" with Rusoto and a MySQL backend with Diesel, but you will probably beat me too it!
Ownership. Map and fold can take ownership of n because it isn't used afterwards. Map returns an entirely new array, vector etc. fold returns a single new value. Take_while and filter need to be able to return the original values afterwards. 
To be fair, the rust book does it Lokathor's way. https://doc.rust-lang.org/book/error-handling.html#error-handling-with-a-custom-type 
&gt; #[infer(Type)] &gt; fn foo (id: u32 ) -&gt; Type; AFAIK, that is part of the [`impl Trait` feature](https://github.com/rust-lang/rfcs/pull/1951), which is currently available in *nightly*.
Part of the Libz Blitz is getting stuff like this written down so people can pitch in. Until that happens for each crate, nowhere, really. With rand it's just an old crate that hasn't seen a significant update in a long time; it was originally pulled out of std.
This is in a way true but still does not give you a concrete type. The compiler should yield something like `Map&lt;_, _&gt;` and not `impl Iterator`. But in the end, for the respective uses of foo it probably wouldn't matter that much which one you used. Personally, I'd actually prefer `impl Trait`. I didn't think about that. 
There's some discussion in [this RFC thread](https://github.com/rust-lang/rfcs/pull/722), during which it was decided to split `rand` out into a separate crate and not include it in the standard library.
I really wonder if the *pijul way* of doing things through automation is able to introduce unintended vulnerabilities that git would have protected against. Or if git did the same that svn, cvs protected against. It seems more efficient, but I wonder if it enables people to machine gun into their own feet too easily in hard to foresee ways.
I am having problems with creating an iterator for reading a file by 4192 byte chunks. It complains the the borrowed chunk ref error[E0495]: cannot infer an appropriate lifetime for borrow expression due to conflicting requirements Some(&amp;self.chunk) outlives FileChunks but it doesn't; it should live for the same time as FileChunks! How can I fix it? #[derive(Debug)] struct FileChunks&lt;'a&gt; { file: &amp;'a File, chunk: Chunk, pos: usize, len: usize, } impl&lt;'a&gt; FileChunks&lt;'a&gt; { fn new(file: &amp;'a File) -&gt; Self { let n = file.read_u64_at::&lt;LittleEndian&gt;(0).unwrap() as usize; FileChunks { file: file, chunk: Chunk::new(), pos: 0, len: n, } } } impl&lt;'a&gt; Iterator for FileChunks&lt;'a&gt; { type Item = &amp;'a Chunk; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { if self.pos == self.len { return None; } let i = (self.pos + 1) * PAGE_SIZE; self.ile.read_exact_at(i as u64, &amp;mut self.chunk.buffer[..]).unwrap(); self.pos += 1; Some(&amp;self.chunk) } }
I personally hate anatomy/car examples like that, and feel that the names often end up implying more than you intend. I tried giving the modules better names, but foo/bar flow well in text. Not everyone thinks the same way :) The way I see it is that in the wild modules are not really going to have some naming scheme behind them anyway, and using foo/bar/baz forces you to look at the structure again, which you need to be able to do anyway. ------ This post is not teaching you the basics of modules. In that case teaching by problem solving is great. But teaching by problem solving is exactly how bad mental models get formed. Nothing wrong about that; it's a natural part of the learning something, and most of the time it's harmless. But this post is explicitly teaching a mental model; so it can't do the same thing. You're right that this makes this post more like a spec; that's the intention. It intends to be precise. If you just want to be able to use modules the book chapter should suffice :) --- I might try to work in better module names here, but I can't guarantee it, because there's a major trade-off here.
I think that in both cases there's a potential for a problem. E.g two people change same function in such way that it's merge-able but automatic merge would create non-sensical code. Consider this: unsafe { dealloc(ptr); // Some stuff // Other stuff } One developer changes it to this: unsafe { // Some stuff dealloc(ptr); // Other stuff } Other developer changes it to this: unsafe { // Some stuff // Other stuff dealloc(ptr); } After merge: unsafe { // Both removed this line, so keep it removed. // Some stuff dealloc(ptr); // Non-conflicting change // Other stuff dealloc(ptr); // Non-conflicting change } The merge succeeded silently[1] and now the code contains double free. Two developers changing invariants of a type would be even more difficult to detect. This is why I like the idea of semantic merge. I think that such changes should always be hard conflict. To be precise, if two developers change the same Rust module, it should be a conflict unless at least one of them did a change that provably never affects the code - e.g. renaming an item or changing a comment. Maybe this kind of thing would be nice for underhanded contest... Edit: [1] Disclaimer: I didn't tests whether such change is actually silent.
I started a little prototype to do something similar. Would you be interested in some help?
Thanks for pointing that out! I can't fix it right now, but I will later today.
It's really important to note that if you mem forget something that it is leaked memory, the memory needs to be properly dealt with. This would likely mean bringing back into rust and letting it drop. https://github.com/viperscape/stratis/blob/acda6ca119b526cb741044c721d81b6afb11b064/ffi/src/lib.rs#L50 
I can totally see how my post might have given that impression, but it isn't actually the case that pijul shows *less* conflicts than git. There are some situations where pijul shows a conflict but git doesn't -- I might try to edit that post to add one. In general, I don't think there's any merge algorithm (even fancy language-dependent semantic ones) that can get everything right, so humans (and automatic test suites) ultimately need to be in the loop. I think the main benefit of pijul is this: there are some workflows where git adds lots of friction in the form of obviously extraneous conflicts. By doing better in these cases, you open up the possibility of new workflows.
Wow, that's the hair of Arthurian legend
The point of `impl Trait` is also that it intentionally hides the exact type to the consumer. You can safely change the type returned without making a breaking change. Consumers only see it is a `Trait`. Personally I'd like to see a module level `impl Trait` like : type FooInner = impl Trait; pub struct Foo { inner: FooInner } You don't have to name the exact type (so it works for complicated types or closures) but the abstract type becomes nameable, unlike the current `impl Trait`
The issue here is that your lifetime `'a` refers to the lifetime of `file`, *not* the lifetime of `FileChunks`. That is, in your `next` method, when you return a `&amp;self.chunk`, the lifetime of that chunk is tied to `FileChunks` and not `'a`. This is problematic for an iterator, because the iterator can't express a return value that borrows from the iterator itself. Depending on what problem you're trying to solve, I think you probably want to do one of two things: 1. Create a new allocation for each chunk and return an owned chunk rather than a borrowed chunk. 2. Don't use iterators.
Isn't that the exact point of newtypes? Just wrap the real type in a newtype, then only implement the traits you want to expose (perhaps some automatic way to forward the impls?). I still think `impl Trait` is too high level and instead lower level building blocks should be exposed. Newtypes form an excellent basis for this construction. For your example: pub struct Foo(FooInner); impl Trait for Foo { ...forward the impls to inner... }
Forwarding can be painful. There's an RFC open for improving it. It's called "Delegation of implementation".
http://www.aristeia.com/hairpoll/
Thanks for responding. I didn't consider that applying a real life model may imply more than intended. A fair point. Perhaps a little extreme (but I really do struggle with this convention). Oftentimes a foo/bar/baz example reads like so to me: pub mod 75da8a33 { use d1f01f4d::ba9b90a2; // this won't work // use ba9b90a2::inner(); // this will use self::ba9b90a2::inner; // or // use d1f01f4d::ba9b90a2::inner pub fn 75da8a33() { // but this will work! ba9b90a2::inner(); } } pub mod d1f01f4d { pub mod ba9b90a2 { pub fn inner() {} } } Maybe my brain just isn't wired the same way as the majority of programmers but it's good to hear that others share my concerns. With meaningful names and a numbering scheme applied I can build a mental model much easier. For example: pub mod mod_1_0 { use mod_2_0::mod_2_1; // this won't work // use mod_2_1::inner(); // this will use self::mod_2_1::inner; // or // use mod_2_0::mod_2_1::inner pub fn foo() { // but this will work! mod_2_1::inner(); } } pub mod mod_2_0 { pub mod mod_2_1 { pub fn inner() {} } }
No, my point was exactly that it *doesn't* lead to less conflicts, just different ones. In particular, it isn't any *more* automatic than git, just differently automatic.
i want to read a file in chunks of a disk block size of 4192 bytes and i would like to wrap it around other iterators so that read strings/ints from the file without touching the buffered chunk. the chunk struct is just a wrapper of `Vec&lt;u8&gt;`. I don't want to allocate a chunk per iteration as it would be too costly. How can I get around this so I can still use a borrowed chunk iterator?
&gt; This means if I try to `create_foo().collect::&lt;Vec&lt;_&gt;&gt;()`, the compiler is able to pick a specialised, optimised, implementation of collect which allocates a vector of the right size. Really? This is surprising to me. You promised your `create_foo` returns some type implementing `Iterator`. Nothing here says you promised to implement anything else. This is important because you could later change your mind without breaking client code. EDIT: Oh I think I see what you mean: the point is that during trans the compiler is allowed to peek behind the abstractness and use information about the exact type for optimization purposes. That still wouldn't be incompatible with newtypes should they be marked as such to the compiler. At that point however the newtype just becomes a different syntax for `impl Trait`. Not sure if good or bad.
Frankly I just gloss over names like that. Like I said, trade-off. Named modules would be better but coming up with names that don't imply anything is hard. Ultimately, that's what foo/bar/baz do. Hashes and numbers are harder for me to keep track of.
Yes, this is a "guaranteed compiler optimisation". Consumer can't use methods of `ExactSizeIterator`, but when picking a trait to dispatch the compiler knows about it. This was just one example of how `impl Trait` is more flexible and succinct than newtype, but of course it can always be done explicitly, depending on how you delegate the trait. Not having to name the type remains the big advantage of `impl Trait`.
Thanks, this has helped me to better understand `impl Trait` and its interaction other Rust features.
There are also plenty of places to contribute to the Rust ecosystem that *aren't* the compiler! I'm always looking for more hands on crates.io, I'm trying to keep some well-defined issues in the [E-mentor label](https://github.com/rust-lang/crates.io/issues?q=is%3Aopen+is%3Aissue+label%3AE-mentor), please feel free to ask me any questions about any of those!
Let a thousand birthday posts bloom.
I find that I can write some programs extremely fast in Haskell, but mostly that I end up getting bogged down in making it as elegant as possible or fighting complex type errors (since a lot of Haskell libraries are very generic and you can pack an extremely complex type equation into a small number of characters). Rust, however, is more productive for me than any other language I've used, while having better guarantees than even Haskell for a lot of code. I think that affine types (Rust's borrow checker) make writing correct code quickly easier than it is in Haskell, even with Haskell's more expressive type system and pervasive laziness. The only language with similar productivity for me is Python, and that's only when I'm very sure that I won't want to refactor it.
I'm working on a Markdown GUI editor that is WYSIWYG like GitBook but without any kind of embedded web engine, instead using GTK's built-in text editing facilities. It's reallllly early in the process but it supports all the essentials, it just needs some tuning.
I think you mean **_Fearless concurrency._**
There's some detail in [this internals thread](https://internals.rust-lang.org/t/rand-crate-brainstorming-minimal-api-in-std/3731) as well.
Iterators cannot yield elements that borrow from the iterator. Full stop. There's no work around. It's even worse than that: you can't even define an alternative iterator API that lets you do this. There's a limitation in the language. (There's attention to fixing this, but it ain't happening any time soon.) Iterators (as currently defined) and amortizing allocation don't mix.
&gt; 284 library stabilizations; How is publishing a 1.0.0 version of your library a "stabilization"? I mean you are always free to publish 2.0.0 next, aren't you?
It is a transition from a pre-1.0 state of no stability guarantees, where semver is largely meaningless, to a state of post-1.0 semver-consistent stability.
Hey thanks for the code, I'm trying to find a real world example (that other than what I have in mind, to verify) for demonstration this behavior, you saved me a lot of time! I'm will update this to the post.
Huh, I'm on Firefox and don't see this. Weird.
Oooooooh yess I love hand-editing SVG XML! 1 min! Edit: I replaced Calibri with Times New Roman and it looks ok to me in Firefox and Chrome on OSX but I'm too lazy to set up a Windows VM to check there. I'm assuming you're on Windows? How does it look now? I still don't know what's up with the [keming](http://ironicsans.com/2011/11/keming_revisited.html), it was weird before and it's still weird and I'm not sure what part of the SVG XML is doing that. [I'd love a PR if anyone knows!](https://github.com/rust-lang/blog.rust-lang.org/blob/gh-pages/images/2017-05-Second-Birthday/incremental-compilation.svg)
I fully understand that there is such a convention, _but_ the rustdoc generated for files does not preserve the partial path like that, which is what makes it seem poor to me. Example: https://doc.rust-lang.org/std/io/trait.Read.html it simply says `Result&lt;usize&gt;` not `io::Result&lt;usize&gt;`. It's one extra little bit you have to keep track of when reading docs spread across many modules (eg: piston and std, or tokio and std). For an expert that breathes rust it might seem like nothing, but it's not really beginner friendly. I have almost never read another crate's source files, usually just their generated documentation files. Perhaps rustdoc could be improved to allow for the partial path to be displayed in the documentation output, then I wouldn't care about `io::Result&lt;usize&gt;` vs `Result&lt;usize, IOError&gt;` at all.
Haskell has libraries that have gone through this arc. The `time`/`old-time` library being a notable example. `base` (basically, all the libraries that ship with GHC by default) now has an oversight committee that tries to keep things moving since there isn't really one person in charge of all the individual libraries that make up `base`. Also, `base` is complicated because it's essentially part of the language. I guess the most analogous thing for Rust would be `std`. I think the lessons (not that I've paid close attention) has been to have proactive people leading the charge, do the RFC thing with discussions, moderate, and make sure to over-communicate and over plan for breaking changes.
Fireflowers 2: Birthday Posts in Bloom
I would love to see some rust programmers on twitch.
So last week I continued working on [tarpaulin](https://github.com/xd009642/tarpaulin), and I completed my goal for last week of getting my ptrace code working! And then managed to push out my initial 0.1.0 release. Still finding areas where code coverage is a bit off but on small simple projects it works perfectly. I managed to get rid of one significant issue with coverage, where as tests in the tests folder are compiled as their own crate, the code that has to be covered is in a different compilation unit. So I had to tweak my DWARF parsing code. Started working on reporting formats and tidying it up which lead to the release of my third crate ever [coveralls-api](https://crates.io/crates/coveralls-api). This is basically a client side implementation of the https://coveralls.io web API. So I managed to implement it and get it fully working and integrate it into tarpaulin so now you can send your coverage reports to coveralls and get a swish badge for your repositories This week. Track down more issues that stop it working perfectly on every codebase I test it on for line coverage. If I get it working perfectly on all of them I'll start downloading projects which report coverage and testing I get the same results. If anyone can link me rust projects which report code coverage on the repo that would be great :)
Now it looks good in Chromium! The font in Firefox is too large, but that's probably my own fault; I have a high DPI screen, so I have messed around with font scaling on my entire system, which causes stuff to look weird all the time :P I wouldn't look more into it, unless someone else are experiencing the same. Thanks for the help anyways :) 
There was one, for a long time: https://github.com/murarth/rusti As I Understand Things: It was actually officially part of Rust, once upon a time, but it didn't meet quality requirements and was kicked out. Murath maintained it for a long time, but it never got the support or features needed to come back into the fold of the official distribution. So, this is not a novel concept. It just needs someone (like you!) to develop it and work with the Rust maintainers to make it happen. I would love to have a REPL, but not because Java is getting one. Rust isn't "[keeping up with the Joneses](https://en.wikipedia.org/wiki/Keeping_up_with_the_Joneses)". That's a non-goal.
Also, the link called "last post" is broken.
Politely disagree. Rust doesn't *make sense* on a line-by-line basis, unless you want to heavily, heavily annotate types as you write.
It depends on your coding style. I can think of a lot of useful REPLy stuff where the inference would have enough information purely based on inputs and annotations you'd have to add anyway, like the `collect()` turbofish.
&gt; git also allows you to mess with the history (using `git reset`) How does `git reset` change history? It doesn't ever touch commits, only branches, the index, and the working tree. You could use it as part of doing a rebase by hand, but that doesn't modify history either, it just creates a modified copy of it. Though take this comment with a grain of salt, I'm not sure I even understand what /u/est31 is referring to here.
Good questions! First of all, Pijul is based on a mathematical theory, and its authors are extensive users of a number of other distributed and non-distributed version control systems, as well as computer science theorists. Our choices are not totally arbitrary or "deliberately wrong", it's actually quite the opposite. One property we want to guarantee, as theorists, is that any operation you can do in Git can also be done in Pijul, at least as fast. Currently, the only thing we cannot simulate is when 3-way merge randomly shuffles your lines around (more on that below), and that's actually a feature. &gt; From a question earlier I've heard that this was to enable editing of history, but to be honest I don't want the history to be edited, or if its done it should be detectable. This is actually a mistake both on what Pijul can do, and what Git can do. Git users spend a significant amount of time editing history via the *rebase* command. In contrast, in Pijul, everything is immutable. Rebases are not needed in Pijul because the patches (which really are patches, not "commits") **commute**. &gt; You literally don't have to trust them at all, not even for the order of your commits. This is actually not quite true, and is one of the issues in Git that Pijul (and Darcs, actually) tries to address. Git is not associative. This means that if Alice and Bob are working together, Alice reviews a commit by Bob and accepts it, then 3-way merge (the merge algorithm used by git) might merge Bob's commit in a place of the file Bob has never seen (i.e. that Alice wrote separately). More details here: https://tahoe-lafs.org/~zooko/badmerge/simple.html This is actually pretty terrible from a security point of view, as it allows you to write code that can bypass review. Has anyone exploited this? How can you know? &gt; Excuse me if I'm wrong, but with pijul it seems to me it won't work. if you revert a patch in pijul, it would just be removed from the branch and there would be no proof of its existence. I definitely excuse you. A branch in Pijul is a set of patches ordered by dependencies. You can edit it as long as you don't break the dependencies. The theory has a simple set of axioms: 1. Patches are associative: if Alice merges A and B from Bob, and then later merges C, she gets the same repository as if she first merges A, and then B and C. This is not the case in Git. 2. Two patches A and B either (1) commute, or (2) A depends on B or (3) B depends on A. 3. Patches are invertible: for any patch A, there is a patch A^-1 doing the opposite on the contents of the repository. Using Axiom 2, you can indeed edit history: most people make mistakes (I do). If you ever make one, you will be allowed to remove a patch. Using Axiom 3, you can create the inverse of a patch, and send it to your coauthors, which is different from dropping it. Most "good practices" in other DVCS (including Git and Darcs) I've heard are trying to compensate for the lack of these axioms, or the lack of an efficient implementation thereof. &gt; it seems pijul isn't either, at least not unless you build a layer on top of it that creates these assurances. This is not yet implemented at the moment, but a naive version (about as efficient as Git) is already in the patch and repository format, and we've done some successful experiments in libpijul (no CLI yet). We have ideas for a fancier solution, but the theory for that doesn't work yet. 
I love watching every single talk of him, he has such great charisma. I hope – one day – he visits a rust conf that i am able to be part of :) 
I too believe Pijul has different conflicts, and I strongly prefer Pijul's conflicts. Here are some examples: - I don't want to see Git's extraneous conflicts where I've cherry picked from a remote branch, and later cherry-picked again. - If we've done the same thing at the same place in the file, I do want to see a conflict. Example: we've worked on different features, and both changed `const NUMBER_OF_CASES: usize = 99;` to `const NUMBER_OF_CASES: usize = 100;`. Git doesn't see a conflict, I'd love to see one (and resolve it to `const NUMBER_OF_CASES: usize = 101;`). &gt; In general, I don't think there's any merge algorithm (even fancy language-dependent semantic ones) that can get everything right I totally agree with Joe's point here, although I'd love Pijul to be slightly more configurable in how it displays conflicts sometimes. As an example, as part of my job, I sometimes have to do all-nighters during which several people write a lot of LaTeX together, with no good automated tests (there is peer-review, but it takes months). I'd love Pijul to display conflicts using a special LaTeX macro: \conflict{ First side }{ Second side } And even if it's 6:55am, five minutes to the deadline, it still compiles and chooses one side ;-) This is possible, just not yet implemented. &gt; one being preferential to the other in terms of the unintended vulnerabilities each of the mechanisms could encourage. As noted in another answer, Git allows you to bypass code reviews, because 3-way merge is an optimisation algorithm, with no guarantee on the uniqueness of solutions. Example: https://tahoe-lafs.org/~zooko/badmerge/simple.html I do not thing anyone really wants that.
You just need to put `T: X + ?Sized` in the function signature.
&gt; I find that traits tend to make Rust APIs look complicated. The core idea of this cheatsheet is to pretend Future to be just an ordinary data type instead of a trait. Do you think this will be alleviated with `impl Trait`?
Aside from the post talking about std, this &gt; pre-1.0 state of no stability guarantees, where semver is largely meaningless is dangerous: Cargo actually assumes that 0.1.0 is compatible to 0.1.42!
/u/mgattozzi your item on the `std::sync` module should be ticked within a few weeks in theory (unless I have some unplanned thing that falls on me) :)
Note that there's a project called [miri](https://github.com/solson/miri), which is an interpreter for MIR, rust's "midlevel intermediate representation", which is different than it's HIR (highlevel intermedia representation, which is roughly equivalent to an AST), and LLVM IR, which is the lowlevel intermediate representation used by LLVM for low-level optimization passes and code generation. MIR is basically like Rust with all of the type and borrow checking already done, inference done and inferred types substituted in, drops and moves added in explicitly, and so on. So, it's a much simplified, straightforward, and unsafe version of Rust. miri is an interpreter for MIR, which rather than translating MIR down to LLVM IR and then passing it along to LLVM to optimize and generate native code, will just interpret it as-is. I'm sure someone with more familiarity with the compiler internals, like /u/eddyb, will find something wrong in my description, but that's the basic gist of MIR. This is being developed for doing things like compile-time function evaluation. But it would also be useful as a component of a Rust REPL. Once miri exists, it may be possible to use that and the Rust compiler front-end to just compile every line to MIR and then execute that within a persistent process. I believe that [rusti](https://github.com/murarth/rusti) works by compiling each line with the Rust compiler, wrapping it with a default `main` function that also adds any variable definitions created by previous lines. `rusti` is thus a bit of a hack, though it works well enough for something that simple-minded.
I watched some of the new DConf videos, and i've found [a part where Rust was mentioned](https://youtu.be/Lo6Q2vB9AAg?t=28m3s), I'm interested in the community's oipnion on this topic.
Good writeup! A table of contents would be nice for linking people to this.
The images look fine to me. Here's the thing: even when you pass `ColorType::Gray(16)` to `PNGEncoder`, which is what I'm doing, it still requires a `Vec&lt;u8&gt;`.
I see now, it can handle the color depth, it's just got a hardcoded requirement for `&amp;[u8]` for the data. Seems like an API design problem to me, it should probably be using typenums for bit depth so `PNGEncoder::encode()` can be parametric over it. I'd open an issue on the repo.
I didn't know about this ? modifier, thanks!
The other answer is correct but I also want to say that struct fields can not be mutable themselves. They are made mutable rather by having the struct itself be mutable. More info can be found in the [book](https://doc.rust-lang.org/book/mutability.html#field-level-mutability). P.S. This is also a good reference when you inevitably have more Rust questions :)
Don't know if people here are aware of it, but there is a [REPL for C++](https://root.cern.ch/cling) developed at CERN. One of their learnings seems to have been that in order to be usable interactively, C++ needs some language extensions. [Here's the paper](https://www.researchgate.net/publication/256082045_Cling_-_The_New_Interactive_Interpreter_for_ROOT_6) with details.
It does improve the documentation, but at the cost of giving you a type you can’t name. It also doesn’t ([yet](https://github.com/rust-lang/rfcs/pull/1951)) work for argument types.
Andrei appears to have no familiarity with Rust whatsoever if he claims that it can't link C code and can't call into C code and back. :P Also, Rust took 90% of C's syntax, but sure Andrei, Rust doesn't look like C at all...
Maybe with cargo incremental compilation, things can be easier and faster. Just put user input into a buffer and let cargo compile it incrementally and run it. 
If your faster than std, than it may be time for a pr? If not why?
The author here is also responsible for a sizeable improvement to Ion's performance.
No, I specifically wanted to ensure that I had exactly the same behaviour right down to the error handling, since I don't think you should have to give up functionality for the sake of speed (looking at you, git). I just haven't got around to writing the PR.
More information: if I create a `hello.rs` containing a hello world program, compile that with `rustc -g hello.rs` and run `lldb hello`, and then run `source list`, it works. However, if I create a new cargo project with `cargo new --bin hello`, compile with `cargo build`, run `lldb target/debug/hello` and then run `source list`, it doesn't work.
Aha! I meant that like a post-mortem of the tool's development, rather than the tool itself. I think that's a common way to refer to articles like that, but it's entirely possible that I'm mistaken 
Okay, mystery solved. LLDB can't find the debug info, which on macOS is saved separately in a directory with extension `.dSYM`. This directory is not saved in `target/debug/` along with the build artefact with the crate name, but in `target/debug/deps/` where is another build artefact with a hash appended in the name! Therefore, to be able to use LLDB normally, you must point it to the binary saved in that directory.
There is always racer for autocompletion, it is far from perfect but it helps. If you have a recent version of vim (or neovin) you should ​be able to use rust language server (RLS), the rust implementation of language server protocol. I haven't tried it so I may be wrong.
Man, I wish I had come up with that pun. Maybe "pre-mortem"? The patient is kicking and screaming on the table but you're cutting their chest open anyway?
That's exactly why I wrote this! I think Rust brings optimisation to the masses. You don't need to write all your code to be world-beatingly fast, but you can at least notice when some code is clearly slow.
Thanks! Both problems should be fixed now.
Ownership: I think `&amp;T` could be in the same row as `Rc` and `Arc`. "Shared ownership" doesn't make sense statically; what makes the ownership shared is the inability to statically determine from which context the value will actually be read last. `&amp;T` is aliasing `T` when you actually know what the final accessor is. Though this connection is probably not clear to Strings You missed CStr, and there are `&amp;'static Path`, `&amp;'static OsStr`, etc. (You can get a `&amp;'static Path` by applying `Path::new` to a string literal for example.) Similarly `&amp;mut Path` et al could exist, though I don't know if any APIs actually expose them (they'd be just as useless as `&amp;mut str`).
Why isn't this the official playground?!?!?
`&amp;'mut str` is an immutable borrow of a `str` that lasts as long as the lifetime called "mut". `&amp;mut str` is a mutable borrow of a `str` with an unnamed lifetime. You probably want a `String` though, since you can only mutate a `str` if it doesn't change its length in bytes.
Maybe you should change the article to say "...about 30% faster than the one in the Rust 1.17.0 standard library", to give people the clue that the standard library implementation is likely to change in the future. :)
You mean like manually implementing the null pointer optimisation? This isn't something that could be exposed in an API, right?
Looks nice! One thing though: I think it'd be a bit more clear if `String` and `Box&lt;str&gt;` had "capacity/length _bytes_" heap size, rather than just " capacity"/"length". I know what size they are, but it isn't directly obvious that capacity and length are quantities of bytes. Besides that, great guide! Will be using this in the future if I ever want to show to someone.
Yeah, an old LISP 1.5 on a IBM mainframe was my first interactive experience. Was seriously impressed. Learned using an old copy of the McCarthy book in the library
i heard that neovim has a working RLS integration
Why not for every version of rust release (including beta and stable)? :)
&gt; If we enable the panic-over-semihosting feature of the cortex-m-rt crate, we’ll see the panic! message appear on the OpenOCD console when the program is executed under the debugger. I have no Idea how to do that. Please help !
Yes, it's easy to make a throw-away remark, but `rustc` has to chase a hectic trinity of goals: robust, correct, and producing competitively optimized code. I think there's promise in miri (cut out the LLVM build step) but it's definitely a big job, not for a single developer. (I did a C++ interpreter and it nearly drove me mad)
Hey, great article! :) I just want to say that, if you need inspiration for branch prediction, there's an interesting case in our [sort implementation](https://github.com/rust-lang/rust/blob/892be3f30791aeec6ca408446b4505696eb21212/src/libcollections/slice.rs#L1669). Basically, you have two options when merging two sorted arrays... First array: `input[0..end_a]` Second array: `input[end_a..end_b]` Output array: `output` First method: while a &lt; end_a &amp;&amp; b &lt; end_b { if input[a] &lt; input[b] { output[c] = input[a]; a += 1; c += 1; } else { output[c] = input[b]; b += 1; c += 1; } } Second method: while a &lt; end_a &amp;&amp; b &lt; end_b { let min = if input[a] &lt; input[b] { a += 1; &amp;input[a - 1] } else { b += 1; &amp;input[b - 1] }; output[c] = *min; c += 1; } If the input arrays have predictable patterns, the first method is faster. The branch predictor works very well and simply executes one of the two if-branches. It can start decoding instructions for one of the branches even before comparison finishes. However, if the input arrays are unpredictable, the second method is faster. That is because the second method is actually branchless! First, a reference to the smaller number is stored into `min` using the CMOV instruction (no branching!). Then, we just copy from `*min` into `output[c]`. One might ask: Why is the second method not faster even in the case of predictable input arrays? The reason is that the overhead of branch misprediction becomes negligible, so the overhead of data dependencies becomes more significant. In the second method `output[c] = *min` depends on the computation of `min`. But in the first method we just compare `input[a]` and `input[b]`, and just go straight to the appropriate branch. This is not hypothetical - it significantly affects performance. :)
I like this idea. Those types should also be non-`Clone`, and the extraction method should consume `self`. This way, you have no way of accidentally feeding the same number to several methods expecting random numbers.
&gt; Living in or near the Bay area would be a plus. There are a lot of potential candidates out of the US. They could probably even work remotely. Is it something you'd consider?
Yes, the product sort of lends itself to remote work. :) The most important thing at this stage is just showing that there are good developers out there that want to work in Rust. If you're in the area, please do mention it, but if you're just interested in part- or full-time remote work, go ahead and let me know anyway.
Great guide overall, but I thought that `#[inline]` only tells the compiler that it should allow this function to be inlined across crate boundaries (which slows compile time, and also doesn't guarantee that the function will be inlined--only that the compiler will check whether inlining would be beneficial). `#[inline(always)]` is probably what you meant?
I could implement it, was only made as someone requested it on twitter
Nice article, thank you! Where is your PR on `from_str_radix` ;-)?
There are many integrations on github but https://github.com/autozimu/LanguageClient-neovim is the real deal. I don't think neovim actually has an LSP client built-in
`*self` seems to work: [playground](https://is.gd/taYloE). You will have to show more context or compiler messages to explain why this doesn't work.
I tried switching it and it seemed to work. Is this what you mean? https://is.gd/KWmEuc
Make sure you tweet [@ThisWeekInRust](https://twitter.com/ThisWeekInRust) to get some more eyes on it!
Huh, thanks to you both, I must have made some typo previously, because, yes it does work! 
Really good article! One thing I'm curious about is why your `from_radix_str` implementation panics if the input is greater than 36; I mean, I can see it's what the [stdlib](https://doc.rust-lang.org/src/core/num/mod.rs.html#2689) does and you're just being compatible, but isn't this a clear case of a panic which should be an error instead?
I probably should have clarified that I was referring to the Playground's format, not that exact installation. A local copy which takes the "top 100 crates" https://play.integer32.com/ offers and expands it to "any crate you want" would be better than a REPL in my opinion and integrating Rust into [Jupyter](https://jupyter.org/) would make me consider REPL users to be the ones with Stockholm Syndrome. Because of what a hassle it is to translate anything non trivial from "session log" format to "usable code" format, I never use REPLs for anything less trivial than interactive API exploration and, as a result, in languages which lack Python's `dir()`, `help()`, and `type()`, I don't really have much use for them outside of what the Playground and Jupyter do better. In languages without Python's REPL or Jupyter, my "REPL" is a copy of Vim configured with "generate a Hello World project" and "Save, compile, and execute" commands. I consider it more comfortable than having to clean up the session log afterward.
One thing you could also note is that for arrays it's often a good idea to use vec![x,y].into_boxed_slice(); rather than Box::new([x,y]) at the moment. Box::new() tends to not be optimised very well for array types at the moment and can carry some unexpected performance penalties as it can end up putting stuff on the stack and then copying it into the heap rather than putting stuff on the heap directly, even in release mode. [1](https://github.com/rust-lang/rust/issues/41160)[2](https://github.com/rust-lang/rust/issues/40862). The vec! macro avoids this. The downside of course is that you lose the length information in the type which can help the compiler avoid bounds checks in some cases. This isn't an issue when using box syntax, but that's still feature gated.
The use-case I was thinking of here was variable-size heterogenous collections, for which you can often substitute `Box&lt;Trait&gt;` with `&amp;Trait`/`&amp;mut Trait`. I don't use `Box&lt;Trait&gt;` for returns unless I have no other choice, I work on nightly to get access to `impl Trait` and in the worst-case scenario I'll either write out the whole type (actually, I'll write `-&gt; ()` and then copy-paste from the error message) or, for closures, use some internal struct that emulates the closure. I don't usually write libraries so I don't run into this issue as often as library authors do.
That's very niche, if I ever follow this up I might include it as part of some "Miscellany" post. Admittedly, the `assert!` trick is niche too, but at least it speaks to a wider lesson about LLVM being able to elide redundant calculations.
I'd suggest this, yes. I'm pretty sure this is what `perf` displays by default. You need to run the benchmark on a representative sample, of course, otherwise you might have skewed results (too small a sample will make the one-time costs seem overwhelming, too homogenous will exercise all the same codepaths, etc).
It is not a part of the standard library, but rather the `rustbuild`, the build system used to build Rust. Hence my theory. This would be my first thought, given I tend to have about a bazillion of rust checkouts at any given time :)
I just can't wait for bounded integer types...
What functionality did git give up?
I like how your one argument is "Java is doing it".
I guess not _functionality_, per se, but it's much more complicated to do any individual operation than something like Darcs because all its choices are made in order to improve performance instead of correctness. That's not a complaint as such, I use git every day and that article is hosted on GitHub. Pijul is an attempt to have both simplicity and speed.
Should I directly apply to the company if I'm interested?
Mhmm. My first project at the job i'm at now was using Go, Thrift, MongoDB, and AngularJS. Technologies that I had not used before, but I figured it out just fine :)
`#[inline(always)]` is a complicated issue 1. You can squeeze out 5% extra performance easily with just adding some annotations 2. This actually harms your ability to profile correctly because everything is inlined - but that's why it improves that performance, because I noticed that even short functions weren't inlined by the compiler when I profiled. But notice that NOT inlining those functions harms performance. 3. When I had LTO on, I think it inlined more, I think. I am thinking maybe I should inline conditionally based on whether I'm doing a profile build or a release build.
It's extremely thorny, yeah. It's a dark art at best and a complete crapshoot at worst. I guess it's a very easy thing to try, at least, certainly a simpler transformation than loop unrolling.
I initially thought "huh, someone with that username would surely recognize this term", but then I remembered gamer != game_developer. This is a term commonly used in game development to analyze a project after it's completed. In fact it's common in general project management - game development is a subset of that. Another term could be "project retrospective". Here's a link that includes old Game Developer Magazine post-mortems I used to love to read: https://blog.codinghorror.com/game-development-postmortems/ 
From experience, these are the kinds of functions that you should look at inlining: pub fn to_index(&amp;self, board_size: u8) -&gt; usize { (self.col as usize-1 + (self.row as usize-1)*board_size as usize) } it does something trivial, but for some unknown reason doesn't get inlined every time then you can benchmark both ways and see which one is faster - it's a very easy way to get a small increase in performance
Pretty sure there was a blog post a while ago going into deeper and deeper optimizations, which culminated in an almost 100% inline assembly program xD.
I had like a dozen small functions like this, and enabling `#[inline(always)]` on all of them gave a 5% improvement on benchmarks I guess sometimes it just decides not to inline it on purpose (cache/code size reasons?), but it's wrong. When I turned on LTO, the advantage of the annotations all but disappeared, though. It seems it inlines more aggressively with LTO on. The release build would also take like 2 minutes, though. Also, profiling builds didn't work correctly with LTO (something messed up when I had debug info turned on), but maybe that's fixed now.
My case story, had an half million line ADA83 codebase from embedded system that needed to be simulated in software. Had some fairly complex hardware that needed to be software emulated. Zero experience. Only source code given. Managed to get it running after 12 months. Learned a lot!
I see speedups with LTO, for sure. Maybe cross-crate inlining allows more internal functions to be inlined somehow.
I almost decided to write this bot just to give it the handle @MoarRustNow. I'm glad you decided on a more appropriate handle.
It is awesome, but I'm not sure that it fits with the book, which is laregely to teach you syntax and semantics, mostly. Maybe some other spot?
You mean a different binary completely? Most of the Kafka logic is in the sub-crate `stream_delimit`. I'd like pq to be a one-stop protobuf shop so I want to keep everything in a single binary.
I appreciate your enthusiasm but I totally agree that it's not suitable for the book proper. You're right that blog posts and articles are an integral part of learning a young language like Rust, it might be nice to have a curated list of "further reading" on the website so you don't have to trawl through /r/rust's backlog or ask on IRC. A post like this might fit in better there Thank you so much for the kind words though, this is my first Rust article so it's great to have such positive feedback.
It's absolutely great and I really look forward to seeing more!
I feel strongly that Rust should have a website gathering all kinds of resources to help cope with post-book depression: Articles, tutorials, guides such as this one, ideas for simple projects to build (and their implementation), maybe a more permanent version of TWiR's calls to participation, etc. Briefly discussed it with u/steveklabnik1 at RustFest. This would be a great place to give all these resources better discoverability (a 2017 goal) and make sure great stuff like this doesn't get lost after a month. Beginners are never aware of the amazing [RipGrep code review](http://blog.mbrt.it/2016-12-01-ripgrep-code-review/), or [Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/). I'd love to work on this but it's a lot to do alone; if anyone out there would like to get something started together, let me know!
Tracking file location. Conflicts involving file moves or directory renames can be extremely difficult to deal with, whereas they were a breeze with Bazaar. 
The point about bounds checking ellison is important you should add a point that it combined with borrowed buffered via the slice notation `&amp;x[a...x.len()]` is *extremely* powerful for performance. You are avoiding * Bounds checking if you use fixed variables * Copying * Re-allocating. This is everything C programmers ever want, and Rust just gives you it by default as a powerful quirk of syntax :D 
Although they easily could, I'm glad they don't. Video games crawling through my filesystem, even without malicious intent, gives me the creeps.
Yes, but this isn't just the static stuff, it's what the differences in guarantees and restrictions from the POV of the user are. Borrows and Rc are different in that aspect.
https://github.com/ctjhoa/rust-learning is probably a good place for articles like these.
I'm using Intellij IDEA with Rust plugin. But don't take it as the best, I'd say choosing an IDE depends on what the user prefers and is familiar with, so just try them out. Here are other IDEs I've tried: * VS Code * vim * neovim * a very minimal wrapper... it was called something like SolidOak * Eclipse As for my experiences with vim... I have to admit, I didn't really use it much before, but I didn't quite feel comfortable with it. You might like it, though. There is a `rust.vim` repo, which provides syntax highlighting (but I think it's already included by default). I also installed linters and racer autocompletion, but I forgot the names of these plugins. Good Luck finding your IDE! 
&gt; Converting Rust's compiler into a proper incremental compiler will be hard work. It is, but it's already a work-in-progress. Incremental recompilation needs it, IDE support needs it.
It should be noted they become run time checks not compile time checks.
Need to poke /u/shepmaster :)
No, IIRC the thing in the Box has the lifetime of the Box. https://doc.rust-lang.org/std/boxed/
Much agreed, rust-learning is a great initiative. But being hosted in github repo is limiting in a few ways and doesn't incentivize the community to link and contribute to it as much as a more structured effort might.
Small typo spotted: &gt;since any optimizing compiler worth its bits will do this kind of optimization without having to mangle your code and pissing **of** future-you. should be &gt;since any optimizing compiler worth its bits will do this kind of optimization without having to mangle your code and pissing **off** future-you.
Fun fact: The implementation of `Path::new` is literally just `mem::transmute`
Well, I figured you were talking about machines that aren't on the local network...
I guess this is the paradox part: &gt; the language to learn, if you want to get a good job, is a language that people don't learn merely to get a job. It of course breaks down if you'd started learning brainfuck and present it proudly on your CV... On the other hand it would stand out if you have a hobby webserver written in brainfuck, yeah maybe I would hire that guy.
Its all aliasing. References are for statically determining the end of an alias whereas RCs are for dynamical determining the end of the alias.
If you want to set a variable in a higher scope don't use "let mut", do "let match" and you can return from the lower scope.
I haven't heard of anyone using VS Code *on Windows* :D It's an [Electron](https://electron.atom.io/) based editor that has nothing to do with the original Visual Studio (except some of the design aesthetic). Also there's now Visual Studio for Mac which is actually just MonoDevelop which is also not related to the original VS. Microsoft Naming! :) neovim works with RLS using https://github.com/autozimu/LanguageClient-neovim Everyone is working on LSP stuff now http://langserver.org but a lot of it is still work-in-progress.
Thanks! This is a learning exercise, so I thought I'd implement a stack (been a while since I last did that, yawn). Returning the stack from pop (and push) seemed like a nice way of signaling that this is a new value. Thanks for the error handling advice!
[Here is a vimeo video](https://vimeo.com/131637366) that is a nice example of how F# (around as type heavy and type-inferential as Rust) can be used in an interactive environment to good effect. You can google for uses with canopy (web scraping) and other frameworks, but in my experience it works nicely. 
Oh wait I misunderstood your comment, thought it was proposing putting them in the same _cell_. Sorry. I agree.
Ohhhh, I just realized that toml-rs does not yet have the wonderful indexing stuff that serde_json and serde_yaml added (where indexing doesnt panic but return the null variant of `Value`)! We should fix that :)
Have you taken a look at [Clippy](https://github.com/Manishearth/rust-clippy) yet? It's a great set of extra lints to catch unidiomatic rust code. It's a great learning tool. Besides who doesn't like the compiler yelling at them?
I don't have any checkouts of Rust on my gaming PC.
While it might be a fair bit of work, if you only need to support windows you could always directly use the win32 APIs to create your window
What platform(s) would you like to target?
Did you actually mean 2D graphics library (like skia) or GUI library (like native-windows-gui)?
Mainly linux! Should have said. Gonna edit the post.
It works nicely and compiles quickly too. I couldn't find out how to draw a dot at mouse position though, is that possible with cairo?
[There are quite a few](https://www.quora.com/What-are-the-best-tech-companies-in-Orange-County) that I can think of. I don't know of any specifically looking for Rust but perhaps you can find one [here](https://rustjobs.rs/) or [here](https://www.rust-lang.org/en-US/friends.html).
Yes! The cargo subcommand is awesome. cargo install clippy cd ~/code/mysuperawesomeproject cargo clippy That's all you need to install and run clippy on mysuperawesomeproject :D
Wait, does that work without nightly on the project/rustup?
Oh, sorry I only use nightly so I didn't even realize it was a requirement :/
Is there way to update cargo 'apps'? AFAIK you have to "reinstall", which is problematic since I don't know of way to list which ones I have installed.
No, since it needs to reach into the compiler internals.
&gt; cargo +nightly Wait, since when is this a thing? I've been doing `rustup run nightly cargo ...`. I can't find this documented anywhere, do you have a link by chance?
It's part of rustup, since that installs stub programs for cargo, etc. Been there almost as long as rustup has been recommended. https://github.com/rust-lang-nursery/rustup.rs In the readme under examples
See https://blog.acolyer.org/2017/05/05/efficient-memory-disaggregation-with-infiniswap/ for a mildly alarming post about a network-based swap system. Turns out it's faster to swap to your neighbor's ram than to your own disk, if you live in a datacenter. 
What do you think about a CLI version that simply prints the found value or resulting error? It could potentially be useful for using TOML in a shell script.
A good introduction to the topic: https://blog.codinghorror.com/the-problem-with-urls/ This library tries very hard to "do what I mean". It's a port of [autolink-java](https://github.com/robinst/autolink-java), which is used in production. It's my first crate, feedback on anything very welcome :)! The API is inspired by the `regex` crate with regards to lifetimes, naming, and using an iterator.
I used Eclipse for years and loved it in a Patty Hearst sort of way. But there are so many better, free options now. Intellij and Visual Studio both have awesome Rust plugins, and the experience on lighter-weight editors is getting better and better with the language server. From the archaic project management to the absurdly complex architecture and confusing product packaging, from the lackluster releases of recent years to the hideous outdated design: It's time to let Eclipse go.
One could use the codebase to write a generic version of this for all serde formats... But that'd be too much work for me, personally. I wrote it because I would love to have this library for my other project. If you want to do a serde format agnostic version of this, feel free! Would need to rename it then, though.
&gt; Besides who doesn't like the compiler yelling at them? My main squeezes are rust and Haskell so this is definitely me. 
You and me both!
Ditto for "not in the area but interested"!
Wow, that's a lot of regexes :). Does it detect plain domain names, such as example.com? My crate doesn't currently​ do that, but would be interesting to add.
Why doesn't gtk-rs work well with MSVC.
"And people don't learn Python because it will get them a job." 2004 was a weird time.
I don't know what the underlying technical issue is, but the [gtk-rs requirements](http://gtk-rs.org/docs/requirements.html) makes it pretty plain that only the GNU toolchain is supported.
In the case you posted, `y` will always be `&amp;String` (coercions don't happen in let bindings without a type annotation). Deref coercions like this were added to improve ergonomics [See RFC](https://github.com/rust-lang/rfcs/blob/master/text/0241-deref-conversions.md) - before they existed you had to manually dereference a String to get `str` - e.g. `&amp;*some_string`, which got quite complex when you had the String in some other container (e.g. Rc)
Does Rust have a refactoring tool yet? :)
Haskell has *much* more sophisticated type inference algorithms. And it doesn't require lifetime parameters and such.
As long as something gets destroyed, I'm happy. 
I came at approximately the same time, true to stereotype, from Haskell. I was concerned I was getting myopic. It turned out to be incredibly fast and the ergonomics have only improved, so I am happy to say I stayed. 
You're not running a julia/Idris backend/nim for your web service? Fools. 
I used Rust back before `Deref` coercion was a thing. I *do not* want to go back. Unless you've lived through that period, you don't know how much of a PITA it was. I'm generally against magic myself, but this is a case where the language is just worse long-term without it. The benefit provided dramatically outweighs the added complexity.
Terminology: s/pragma/attribute/
I agree with the other replies, but I'd also like to see if there's some way the compiler or documentation could help avoid the kind of confusion you're worried about. That is to say, it looks like the community as a whole has decided the treatment is preferable to the original ailment in this case, but maybe there's still something further that could be done to alleviate those nasty side effects. Can you think of some complete examples where code has done something other than what you expected (so maybe a lint might help), or where the compiler rejected it and a more sophisticated error message might have helped? Otherwise maybe the documentation could be more explicit about deref coercion earlier on?
Does it cover panics and Errs? 
It covers anything you want it to cover. If you want a generic catch-all that will log a panic and then keep on trucking, please don't do that, that's a terrible idea.
No I want it to log a panic and then panic as typical: For example: return Err(Error::new(ErrorKind::Other, "Not supporting ipv6")); or panic!("whatever"); or whatever.unwrap(); In all of these cases there is an associated text message, is it possible to have them logged naturally, or do I need to wrap them somehow, or add additional logging code? I want them to function the same as ever, I'd just like to log their error messages to a file somehow. I'm not sure if this can be done automatically somehow, if I should wrap the functions to include logging through some logging system, or if I can do it some other way. 
looks like all you need is triangles, textures, and clipping. [Here's](https://github.com/ocornut/imgui/issues/244) a discussion about it. They mention that the majority of what imgui is rendering are actually axis aligned quads, so if you can detect those it should be faster to render. There's also a neat example of streaming the render data to a remote client [here](https://github.com/JordiRos/remoteimgui).
o_O
just add 'a to the &amp;Texture
lol Now that you're here, I'll ask nicely. Compile for me please? 
On the `new` definition? impl&lt;'a&gt; Entity&lt;'a&gt; { - pub fn new(texture: &amp;Texture, x: f32, y: f32) -&gt; Self { + pub fn new(texture: &amp;'a Texture, x: f32, y: f32) -&gt; Self { If I add that I get a similar build error, so I think I had to add this to Screen: - pub fn display(&amp;mut self, texture: &amp;Texture) { + pub fn display(&amp;mut self, texture: &amp;'a Texture) { Then I just get more here: error[E0495]: cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements --&gt; src/game.rs:39:46 39 | self.screens[self.screen_i].display(&amp;self.textures[0]); ... note: ...so that types are compatible (expected &amp;mut screen::Screen&lt;'_&gt;, found &amp;mut screen::Screen&lt;'a&gt;) --&gt; src/game.rs:39:37 | 39 | self.screens[self.screen_i].display(&amp;self.textures[0]); ... so I just took out the screens and textures vectors to get rid of that complexity to see if anything changes. New branch: https://bitbucket.org/johannestaas/dodheim/src/f3da388ed1ae9d68b4228ee13bea64b48b441974/?at=game-screen-c And now I get this error: https://bitbucket.org/johannestaas/dodheim/src/f3da388ed1ae9d68b4228ee13bea64b48b441974/BUILD_OUTPUT?at=game-screen-c&amp;fileviewer=file-view-default Even when it's just a simple Texture in the Game class, I still can't pass a reference? Does it think that the Sprite will outlive Game for some reason?
&gt; If we're on a 64-bit CPU with 64 byte cache lines like the i7 I don't know what the cache line size is for other CPUs, I imagine it's the same. I kinda buried that "64 byte cache line" comment in the middle of a sentence about word size, sorry about that.
Rust really doesn't like structs with internal borrows. What I usually do is define the resource containers outside of the main "game state" struct, and let it borrow them. Something like [this](https://gist.github.com/crumblingstatue/660b7fca73136774dc357701cb1b98ba), in your case. One workaround would be using `Rc&lt;Texture&gt;` instead of `&amp;Texture`, but rust-sfml doesn't support Sprites that take `Rc&lt;Texture&gt;` instead of `&amp;Texture` right now. I've been thinking about adding support, but not sure how to best implement it.
It *doesn't matter* where you write `&amp;expr`, it will *always* have the type `&amp;typeof(expr)`. The coercion happens *after*. You can think of it as (in the `String` case) "you can use a `&amp;mut String` or `&amp;String` where `&amp;str` is expected". It has nothing to do with where the `&amp;` (or indeed `&amp;mut`) is, it's not syntactical, it's type based. And before we had it, non-trivial codebases were littered with `&amp;**x` and `&amp;x[..]` (or worse, `x.as_slice()`.
Ohhh, okay. This is starting to make sense. So in your patch, you're making Textures be defined and live at the same scope as the game state instead of being another field in the gamestate struct. I could do something like create a GameResource container that lives next to GameState and have GameState borrow the resource from it instead of one value in the Game struct borrowing from another value. I'll play around with it and try to separate out GameState from GameResource and see if I can get this working again. I didn't Thanks for your help!
Don't new TLDs get added all the time? It must be annoying to keep maintaining that crate.
What about URLs without the `https?://` part? Some applications don't show them by default, easily copied without, and others even don't care to add them back when copying.
Are you sure the rust windows api integration is in a good enough state to do GUIs?
I started thinking about this because I had a C course in my first year of university and would have really liked traits and enums/pattern matching (even if i did not know they had real names back then). 
Why would the following program take such a long time? It's very unusual pub fn main() { let mut n : i32 = 0; for i in 1..2_000_000_000 { if i % 3 == 0 &amp;&amp; i % 5 == 0 { n += 1; } } println!("{}", n); }
1. How did you compile your program? `cargo build` produces a debug build that is faster to compile but the program will generally be slower. `cargo build --release` produces a build with optimizations enabled, which takes longer to compile but the program will generally be faster. 2. You're doing 2 billion iterations, so what do you mean when you say "a long time"?
Glad `eprintln!` landed, it will make these quick scripts much nicer to write.
[Corrode](https://github.com/jameysharp/corrode) is a project to build a tool that can convert directly from C code to unsafe Rust, which you might find interesting. There are several blog posts and (I think) presentations floating around, but I don't personally have time to track them down right now. Honestly, the main reason I don't advertise unsafe Rust is that Rust itself is just really nice to use. It's a true systems programming language, so you will have to concern yourself with making low-level decisions, but the compiler does a great job of keeping you from shooting yourself in the foot as long as you stay away from unsafe. I wouldn't _want_ to use unsafe Rust if I can just use normal Rust for something, but it is certainly an option.
&gt; i'm not sure whether it is really ok to post just out of curiosity, but i have been thinking about this topic for a while :) Of course it is ;) To your point: unsafe rust is a good automatic conversion target for C, but for manual porting most can be done in safe rust. I would argue that most things in C programs that inherently go against rust safety and ownership rules may be problematic anyway (modulo some data structures).
https://github.com/nlfiedler/magick-rust
&gt; The primitive types are bool, char, i8, u8, i16, u16, i32, u32, i64, u64, isize, usize, f32, f64, (), str. These all have the lifetime 'static, as they will be with the program (and the language) forever. That's not my understanding-- I'm going to be pedantic for a bit in hopes of making things clearer for /u/BackspaceShift and others reading this. *Types* don't have lifetimes, since they're just concepts. *Values* of those types do have lifetimes. *Literal values* of these primitive types, and other types too, have the `'static` lifetime. For example, the value 10 of type `i32`is a literal value if your program contains `let max_len = 10;`. That 10 is part of your compiled program, it's stored in with your code that's stored as data. When your program is running, that 10 can't possibly change to a different value at that spot in memory, and *that's* why its lifetime is `'static`-- for the entire time your program is running, the value can't be anything else or go out of scope. In contrast, this snippet shows some `i32` values that *don't* live forever: pub fn calculate(x: i32) -&gt; i32 { let y = x + 1; let z = y * 3; println!("y is {}", y); z } The literals `1` and `3` *do* live forever, since they're literals. The value `y` lives from the line where it's declared until the end of the `calculate` function where it goes out of scope. The value `z` lives from the time it's declared until... we don't know when, because it's returned to the caller, and we don't know how long the caller is going to keep the value around just by looking at this function. The value `x` goes out of scope at the end of `calculate`, but we don't know when it started living, since it comes from the caller. If we got the value `x` from a user entering a number sometime while the program is running, it can't possibly have the `'static` "forever" lifetime, because from the time the program started until the time the user entered it, the value doesn't exist and we can't possibly know what it is since the user hasn't entered the value yet. This has nothing to do with the type of the value. These are all *concrete lifetimes* I'm talking about here. I think we need to do a better job as a community, when we talk about lifetimes, to distinguish between *concrete lifetimes* and *generic lifetime parameters*. Concrete lifetimes are the actual lengths of time that values live at runtime, and the only way to change those is to change the structure of your program. Generic lifetime parameters are the `'a` things we can specify, and *specifying generic lifetime parameters doesn't change the concrete lifetimes of any value*. Generic lifetime parameters serve to relate the lifetimes of multiple references to each other, so that we can tell the compiler which lifetimes are guaranteed to outlive which other lifetimes. This distinction between concrete and generic is why the [lifetimes section of the second edition of the book is in the generics chapter](https://doc.rust-lang.org/nightly/book/second-edition/ch10-03-lifetime-syntax.html), and I didn't really start understanding lifetime parameters until I started thinking about it in this way. I'm going to stop writing now, because I think everything else I'd want to say is in that section of the book :)
My intention is to do a basic UI with several buttons and a loading bar, but I will need to customize the appearance 100%. 
I ported a C library to Rust in an incremental fashion, one function at a time. My process was: - Move a C function to Rust code, adding `unsafe` anywhere and changing the function just enough to get it to be valid Rust - Run the tests to make sure I didn't break the behavior of the function - Once all the places this function is called have been moved to Rust, try to make the function more idiomatic (which usually involved changing the signature) and try to get rid of `unsafe` code - Repeat Eventually I got the whole program ported to Rust and was able to get rid of all of the `unsafe`. I did a talk about the process, my slides with speaker notes are [in this repo](https://github.com/carols10cents/rust-out-your-c-talk) and the code with the history of the process is [over here](https://github.com/carols10cents/zopfli).
No, it would have the same size as `FooInner`. With `impl Trait`, you can do the following today : fun evens() -&gt; impl Iterator&lt;Item = u8&gt; { (0..).map(|x| x * 2) } But the return type of `evens` cannot be stored in a struct. What I'm talking about (and has been proposed by other people, see https://github.com/rust-lang/rfcs/issues/1738) is allowing this : type Evens = impl Iterator&lt;Item = u8&gt;; fun evens() -&gt; Evens { (0..).map(|x| x * 2) } struct Foo { inner: Evens } The compiler infers the real type of `Evens` based on the implementation of `evens`, but hides it from the user. `Evens`, and therefore `Foo`, has the same size as a `Map&lt;RangeFrom&lt;u8&gt;, Closure&gt;` (so probably just one byte, the size of RangeFrom), where `Closure` is the unnameable type of `|x| x*2`
Yeah, but honestly I haven't been keeping up with what's been added since I finished the initial port. They update twitter-text in batches, including the list of TLDs, so it's a matter of mirroring their changes across. And even if my crate doesn't catch up with their changes, they still do the same validation on their end when they receive new posts.
Excellent! Thanks!
&gt; Maybe they should have chosen &lt;&gt; instead, but that ship has sailed :). For me, the train has never sailed! I'll make my own format, with angle brackets and… well, that's about it! :-)
Yes that'll introduce a lot of false positives, as I've already seen in the WeChat app (this one even doesn't require it ends at word boundaries!). But it will be useful sometimes, e.g. for users to click.
I think it should be possible, all the pieces are there (with cast::transmute , I seem to remember), but I recall it being significantly more verbose and annoying to write. C's syntax is uniquely optimised for unsafe code; Rust is designed to be used safely, with unsafe there for completeness. What I was trying to do was mimic my C-like practice of loading 'blobs' (a pre-compiled datastructure navigated with pointer-arithmetic), ... and it was possible, but painful. I seem to remember you had to go annoyingly far with casts.. having to write a separate cast for each piece of information being changed (I haven't used it in a while. Last time I tried there was no inbuilt pointer-arithmetic , but functions to offset i think?) I seem to remember interoperation being seamless, it's fine to keep legacy C in a project and just export functions both ways. In retrospect what I was doing was a mistake; it's best to use Rust as intended, with unsafe as the exception rather than the rule. 
If we didn't have `&amp;` do `Deref` coercion we would just need something else that did. I'm neither for nor against the idea, particularly, but I've seen people complain about the number of sigils in Rust already. ;-)
What is the `description` message on `std::error::Error` actually for? I always set it to some generic description, but I never use it. I always have the actual informative error message available via `std::fmt::Display`.
&gt; Even packaging for vim is a significant amount of effort. Even moving the existing plugin upstream took a long time https://github.com/vim/vim/pull/1356/
You might also try cairo. It's leaner now (doesn't require glib), also a bit lower level than imagemagick, but very flexible.
It was just a design mistake IMO.
File issues! Maybe I'll get to them at some point.
Okay, but what was the intention of the function? I still have to implement it, so I'd prefer to do that sanely :) I'm currently using it like "`description` describes the error type, and `Display` describes the error value."
For those who don't know these guys up on the stage: They are rather well-known among C++ programmers. Walter Bright (2nd from right) is a C/C++ compiler writer, Andrei Alexandrescu (1st from right) achieved fame with his "modern c++ design" book and entertaining but enlighting talks. Scott Meyers (2nd from left) wrote "Effective C++" (among other books) which is often recommended as a kind of style guide (what you should do) and gives excellent talks as well. Bright and Andrescu worked together on D and since Meyers stopped focussing on C++, he appeared twice at a D conference.
Yeah, I guess it is just supposed to produce a short static description of the error. Its lifetime requirements basically prohibit it from returning anything but a literal string, which is why nobody uses it.
I really like Andrei and he is a very smart guy but i cringed a bit at [this section](https://youtu.be/Lo6Q2vB9AAg?t=28m3s) where he is talking about rust ;)
&gt; And before we had it, non-trivial codebases were littered with `&amp;**x` and `&amp;x[..]` (or worse, `x.as_slice()`. Yup. In some crates, [my tests are still littered with `&amp;x[..]`](https://docs.rs/regex/0.2.1/regex/bytes/struct.Regex.html#examples) because the type of a byte string literal is not [`&amp;'static [u8]` but rather `&amp;'static [u8; N]`](https://github.com/rust-lang/rfcs/blob/master/text/0339-statically-sized-literals.md) where `N` is the number of bytes in the literal. (Not necessarily the same problem, but having to write that extra bit of syntax is really annoying.)
Those annotated slides are very nice, thank you. I've often ported legacy code to newer languages, and my strategy was different from yours: after having a golden master (and smoke tests and/or unittests) I create a version of the code (in the original language) that's as much similar to the destination language as possible (silly example: in the C code I differentiate some zeros with C++11 nullptr). And only then I start the true porting to the target language as you have done. This step sounds like a boring waste of time, but it usually saves me from some maddening conversion bugs later :-)
I don't really understand the link. He asked the question and answered himself in 20 minutes. What's the problem?
I agree. Sometimes I have to disagree with Andrei.
The default allocator also got updated, from jemalloc 4.0 to 4.5. Nothing noticeable for most though.
Wow, yeah that seems totally oblivious. Andrei Alexandrescu is a really smart dude and I'm a huge fan of his talks, and it's a shame that he clearly knows so little about Rust above the surface qualities because I think it would really appeal to him. He seems to be into down-to-the-metal optimisations and memory safe systems programming, both of which I'd say Rust is better at than any other language.
I don't think any of the three languages come out looking good in that comment, to be honest, but he seems to utterly miss the point in admitting D's main problem is GC and then saying Rust's main problem is that it doesn't have a GC
I was so happy when the `+toolchain` syntax got merged. I remember seeing it come through in one of the changelogs. [July 29, 2016](https://github.com/rust-lang-nursery/rustup.rs/pull/615) was a good day.
I remember there being discussion about putting this in `cargo`, but the response was to just use `rustup`, so that's what I've been using. I'm glad that this is a thing now though :)
There's this: https://github.com/PistonDevelopers/imageproc/blob/master/examples/font.rs Pretty basic, but we could add more features if you need them.
Looks like effort is starting to enhance `impl Trait`, such as allowing it in argument position, etc. I've always wondered, though: why is the `impl` necessary? Don't we already know the thing named is a trait rather than a concrete type and can handle it appropriately? fn iter() -&gt; impl Iterator&lt;Item=u32&gt; { ... } Why can't this be fn iter() -&gt; Iterator&lt;Item=u32&gt; { ... } ? This seems clean and unambiguous.
I cringed when during the Toyota lawsuit an expert commented on the code he had been auditing: functions of thousands of lines, tens of thousands of global variables, ... I think before even getting rid of C, all hardware/software that handles *human lives* should be held to a much stricter standard of quality. I don't care how it's achieved: it can be opening the code to 3rd parties (auditors/everyone), creating a "profession" so that programmers are held to some standard of quality, ... but given how software is going to hold the lives of more and more people in its hands, we really need *something*, because clearly most private companies cannot apparently be trusted.
Excellent! This is the kind of experience that makes me hopeful that our little community can grow successfully, it's really nice to see new members jumping in, and it's really nice to see them welcomed with open arms. By the way, if you are interested in a repeat experience, the Libs Team is organizing a [Libz Blitz](https://blog.rust-lang.org/2017/05/05/libz-blitz.html) to polish existing crates toward their 1.0. It's a good way to get involved and mentored :)
A "bare" trait name means a trait object, which uses dynamic dispatch through a vtable because the concrete type is not known at compile time. `impl Trait` means that the concrete type is known at compile time, but you don't want to (or cannot, in the case of closures) name it, and any caller only uses the trait's API on it. There have been requests to change `Trait -&gt; dyn Trait` and `impl Trait -&gt; Trait`, but obviously that would be a major breakage in the language, to be preceded by long periods of transition or even a cause for Rust 2.
I really don't think that's fair. Yes, the learning curve is focused on safety, but the language design effort really isn't, and never has been. Rust proponents _talk_ about memory safety quite often so it's easy to get this impression, but it really isn't true. I like Andrei, but I don't think he knows nearly enough about Rust to make a qualified statement there. The leg day statement to me sounds like something someone would say after seeing one talk about Rust or something -- it matches up with how we _market_ Rust, but not with the actual reality of what Rust is. I mean, I could make a similar comment about D and metaprogramming. I know it's false (because I've played with enough D and like it), but on the surface it sounds like it could be true.
Just to note the new `impl Trait` RFC is specifically designed so that you could spell `impl Trait` as just `Trait` in some future backwards incompatible rust.
Consider a context where it's OK to be unsized, like returning `&amp;Trait`. That's a trait object with dynamic dispatch, and could dynamically be any number of implementations in the background. Whereas `&amp;impl Trait` would mean a reference to one particular unnamed type that implements the trait. So you'd have to special-case somehow when to interpret it as a trait object or an impl-trait. Maybe that could be done based on size requirements, I don't know. This is just my understanding of why it isn't done your way, because I remember that did come up in the RFC discussions.
The strategy of having the owning struct and then having references seperate from it is the one I usually adopt as it is easiest to manage. There is also [owning-ref](https://github.com/Kimundi/owning-ref-rs) which can be useful for some cases. You may also want to look at the discussion of self referential structs [here](https://internals.rust-lang.org/t/improving-self-referential-structs/4808).
The only thing I can say to defend that is that it was apparently written right around the time of the 1.0 release: &gt;The realities of 1.0 ended that honeymoon and marked (by my measurements and estimates) a stark decrease in general interest. This is clearly untrue. &gt; Rust's syntax is different, and there's no apparent advantage to the difference. It has a match statement, and uses the word let before variable declarations. impl's a little different than other things I've seen, but not drastically so. Did I miss something major? I kind of thought the syntax was specifically chosen to make an ML-like type-centric language look more C++ like. &gt; Rust ends up expending a disproportionately large language design real estate on this one matter (memory safety). I used to think this might be true, and that rust might end up being a useful stepping stone to a future language that offered the same guarantees, but was more developer-friendly. I don't believe that anymore. I'm coming to believe that most the friction rust introduces for dealing with memory safety is the inherent friction of handling memory safely, and that once you get used to the relevant patterns, the compiler actually becomes more friend than foe. I think rust is going to have a long and useful life as a major systems language.
That trick for figuring out types is something I use extensively in both Haskell and Rust. It's awesome to see you leveraging it! I really like seeing posts like this describing the learning experience and documenting something like this. Keep it up! These perspectives are a necessary and important thing to read.
When's the last time you tried to write [MISRA-level](https://en.wikipedia.org/wiki/MISRA_C) code? I never have. :/ You're right, of course, but we need to develop better rules and methods and teach them constantly and rigorously to even start to be able to do this. (MISRA is closed source, for instance.)
Indeed it works. Could you help me understand what is "this case"? (and btw, would this deserve an issue on the book?)
/u/steveklabnik1 or another solution could be adding a `use`, right? /// Adds one to the number given. /// /// # Examples /// /// ``` /// use mycratename::add_one; /// let five = 5; /// /// assert_eq!(6, add_one(five)); /// ``` This mirrors more how an end user would use this crate, yeah? /u/thetablt the reason is that doc tests are compiled as if they are in a separate crate, so the visibility/module rules apply. This definitely deserves an issue on the book, would you like to file it please? :) &lt;3
Yes, it should be noted that the kind of code that gets into cars is held to a *much* more rigorous standard than Rust gets you. Rust's advantages wrt those standards is basically "we got rid of basically every single C footgun you had guidelines to avoid". After that Rust is basically a big *shrug* in terms of the issues they care about. Globals are in many respects much better design for these systems because they're statically allocated and named, as opposed to the dynamic allocations of stack/heap, and the anonymity of pointers. This makes analysis and verification much easier.
"...doesn't play well with C, can't link well with C, can't call into C code and back..." Ouch.
Ah, so more of an interpreter? That I agree would be quite good. 
That is correct &gt; This definitely deserves an issue on the book, would you like to file it please? :) &lt;3 This text is in the old book, right? so we don't have tracking issues. I can't remember just now. 
&gt; This text is in the old book, right? nope https://doc.rust-lang.org/nightly/book/second-edition/ch14-02-publishing-to-crates-io.html#documentation-comments
&gt; This is clearly untrue. At the time there was some google trends search or something people were using to justify this; I don't think it really counts, but there was some kind of meme at the time. &gt; Did I miss something major? You'll find people saying both things; "wow this is so familiar" "wow this is so alien." I find it very interesting.
&gt; future backwards incompatible rust Why does it have to be backwards incompatible? `impl` could just be an optional keyword without affecting anything.
A more constructive discussion of real issues would be: - How could we catch and prioritize these sorts of issues as a community? - Are there ways we could help each other with security audits? - How are security audits fitting into the libz blitz? Shaming the authors (and people who recommended the crate by proxy) for making a mistake that, at some point, we will all make, isn't helpful, nor does it prevent these problems from happening in the future. That's the real discussion to be had here, which can absolutely be made in a polite way.
[Issue filed](https://github.com/rust-lang/book/issues/704). Thank you and /u/steveklabnik1 :)
ok this seems like it could work, thanks. That such a high profile project gets abandoned (5th position when I search "rust" on github) is a bit worrisome tho since also the whole game engine Piston seems to rely on it.
Ok. It just seems odd since *most* naked types are a fixed size (struct, integers, etc), so if there's going to be special syntax, it should be on the dynamically sized types. It seems that that's the going argument right now, but it would require a backwards incompatible change to do and IMO it should probably affect `str` and any other dynamically sized type that I may be missing. I suppose it's not the worst syntax though, I just feel like `impl` is a bit odd in this context.
It actually makes sense from the perspective your coming from. Remember traits are not types themselves, theyre constraints on types. Trait objects are I'm returning a specific object that dynamically dispactches to the real object. `impl Trait` is in return a specific un nameable object. It's also likely rust will get more tools for working with DSTs in the future so it makes sense to treat them like value types. Though in the context of traits that also makes a good argument for `dyn Trait` because returning an dynamically sized trait object is something you probably want to avoid in general even if rust can handle dynamically sized rvalues. Edit: also I think there's pretty widespread agreement that naked Trait would be better, this is one of those hindsight is 20/20 things. There's a reason the new impl Trait rfc is written like it is. 
&gt; this is one of those hindsight is 20/20 things Agreed. It sounds good and consistent in theory, but using it is kind of odd. If this is the worst wart of Rust, I'm definitely okay with that.
It basically means more granular lifetime checks, allowing you to do stuff like `some_vec.push(some_vec[0])` where now you have to write let value = some_vec[0]; some_vec.push(value); Which is identical semantically but passes the borrow checker because lifetimes are checked per statement.
You might like this [blog post](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/) by Niko Matsakis one of the Rust compiler devs. He covers the whole topic and his blog posts are generally nothing short of informative. Hopefully this helps you out.
It's not equivalent semantically. Let `a` be an expression of type `A`, and `b` be some other expression. Then `a.method(b)` is actually equal to `A::method(a, b)`. Which means `a` is evaluated *before* `b`. In your working example, with the `value` temporary, `b` is evaluated before `a`. This order of evaluation is usually not noticeable, but it could be if `a` derefs to something else (say, `c` ), and its `Deref`/`DerefMut` implementation has side effects (e.g. print a log message), then changing the order of evaluation could observably change your program. Which is incidentally why I don't believe non-lexical lifetimes will be as great as predicted, and will add complexity to the language in exchange for little gain.
I assumed `some_vec` was, well, a `Vec`, in my example. There's definitely lots and lots of edge cases in there.
Thank YOU!!! &lt;3 &lt;3 &lt;3 Great catch!!
Coincidentally the next crate in the Libz Blitz schedule is `reqwest`! There are [plenty of contribution opportunities](https://internals.rust-lang.org/t/crate-evaluation-for-2017-05-30-reqwest/5248) even for inexperienced contributors.
[This comment](https://www.reddit.com/r/rust/comments/6bqkmd/my_first_pr_for_a_rust_project/dhp1j6v/) implies that it's not a security issue. Have you confirmed the behavior that you suspect?
Cheers for the advice, but I'd already tried that and the suggestion [here](https://www.reddit.com/r/rust/comments/691zxs/canonical_list_of_idiomatic_rust/dh453sx/). It installed okay, but anytime I tried to run it (using something along the lines of `rustup run nightly cargo clippy`, `cargo +nightly clippy`, or `rustup run nightly-2017-04-29 cargo clippy`) I got errors about missing dlls (5 or 6 of them each time, looked like parts of the rust std lib, but don't remember exactly). I assume it was some sort of path/envvar issue, but didn't have the time to investigate further.
&gt; In your working example, with the value temporary, `b` is evaluated before `a` Really? let value = some_vec[0]; // --&gt; let value = Index::index(some_vec, 0); some_vec.push(value); // --&gt; Type_of_some_vec::push(some_vec, value); `value` is evaluated before `some_vec`? But then how is `Index::index(some_vec, 0)` called?
Mod note: What /u/aturon said (can't really word it better than that here) Not going to delete the comment, but please, let's all be more constructive when criticizing things. Even potential security bugs.
I've found a pretty interesting thing recently: [Github stars over time](http://www.timqian.com/star-history/#rust-lang/rust). You can clearly see that after the release of 1.0, the exponential growth changed to linear, but it meant that rate of growth decreased almost instantly after 1.0, so at the time it was reasonable to think that Rust started to fail.
When you say &gt; Then a.method(b) is actually equal to `A::method(a, b)`. Which means `a` is evaluated before `b` could you link me to where argument evaluation order is defined? I only see [this rfc](https://internals.rust-lang.org/t/rust-expression-order-of-evaluation/2605). The lifetime of borrows from argument expressions always ends before the function call, regardless of evaluation order. There's no underlying reason the current restrictions should exist. Wouldn't you need to understand the semantics of evaluation order in either scenario? It seems like non-lexical lifetimes don't really impact this, and only improves the vast majority of cases where this isn't even relevant. I'm asking because I see non-lexical lifetimes as fixing an edge case and am curious why you think they add complexity.
That's interesting, but for another crate! :)
I see, but how can Rust determine that the value contained will outlive the container itself? It needs to associate the lifetime of the container to that of variable `s`, for which it knows will go out of scope on line 4 (i.e. at the end of "scope SS"). Then it will do the same for the reference `x` inside the container: It knows that it references a variable that lives in a scope that ends at the end of the program ("scope S"), and it also knows that it itself lives until the end of "scope SS". Finally, it knows that "scope S" outlives "scope S". And only with all of this information together can the compiler decide when the borrow ends, and that the struct lives long enough for its contents.
Nice post. It's really great to see people pushing for AVR support. About your mini core crate, I think you may be able to use [Xargo](https://github.com/japaric/xargo) to build your fork of core as if it was the real core and Xargo will put your fork in the sysroot. That way you should be able to use `#![no_std]` instead of `#![no_core]` and avoid doing the prelude imports by hand. For that I think you would have to use a Xargo.toml that more or less looks like this: [dependencies.core] git = "https://github.com/gergoerdi/rust-avr-libcore-mini"
No yeah, I agree with you there! As for knowledge about the project, I've never used reqwest myself, just hyper - never felt I needed anything on top of it. I just found about the no cookie thing myself by a comment here then looking at the docs.rs for reqwest - cookie handling is all marked TODO I guess?
Yeah, this is something I always really hate Java for. It teaches people that types are annoying, boilerplate, and it doesn't do a great job at showing how they can provide safety.
I agree, and you're right that my comment glossed over this; it could've been handled better from the outset. And it's particularly important that Rust leadership be held to the highest standard -- you should absolutely call us out when that seems not to be the case, which indeed does happen! Thanks for doing that here. That said, the main thing that moved me to write a comment in the first place was the sentiment of "superficial politeness stifling discussion of real issues". This is a common perspective in some technical communities, and is used to argue against codes of conduct, or otherwise to suggest that the way to reach the best technical decisions is to "speak your mind" without regard for people's feelings. I really don't want that kind of thinking to take root in the Rust community, because it has the potential to be very damaging, and to threaten the welcoming culture we've worked hard to build. As I said, I also think it goes against a core *design* philosophy for Rust too: Rust's design is all about the intersection of technical *and* human aspects, recognizing that humans are not robots and we shouldn't ask them to be. That might sound a bit woo-woo, but I mean it in a very serious way that informs design decisions. I wrote about this a bit in a recent blog post (https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html) and hope to do more soon. Anyway, thanks again for raising the point you did. The last thing I want to encourage is Rust leadership "circling the wagons" and considering themselves beyond criticism; humility should be our north star.
Thanks!! And yes I did see Libz Blitz. Hoping to get involved with that effort.
You'd want [this crate](https://crates.io/crates/cairo-rs). By convention, crate names ending with `-sys` are purely bindings to a C library, and the crate without `-sys` wraps it to make a more 'Rustic' library.
Currently lifetimes are (generally) extended until the end of a block (the area between two curly braces). This is a very strict rule that makes a lot of common patterns impossible. It is a simple over-approximation of how long the lifetime needs to be. Non-lexical lifetimes would use more accurate analyses to determine when a lifetime ends. For example, liveness is a property that a value is still in use (live) at some location since it's current value will be used in the future. If a value is not live, i.e. the current value will never be used, it's lifetime can be ended at that point while still preserving guarantees about usage. Please let me know if you have any more questions. I wrote this really quickly on mobile so I couldn't add examples. Good luck!
&gt; Allowing me to remove the explicit reference to the source of core in chip8-engine's Cargo.toml? Yes. With Xargo you don't need explicitly depend on the core crate. OTOH, if you use Cargo then all your dependencies and their dependecies and so on need to explicitly depend on the core crate. This rules out the possibility of using crates from crates.io as most of the crates in there don't explicitly depend on core. With Xargo, you can use crates from crates.io without problems.
I know I've used it in the more trickier type situations. The fact you tried it out naturally is fantastic. Please do write more. It helps me write more beginner oriented posts for Rust and I really enjoy the viewpoint since I've lost it now.
OK, thanks, I'll have to try that.
Looking at the [examples](https://docs.rs/nom/3.0.0/nom/#example) it seems you need parens around your results, i.e. `&gt;&gt; (Command::Wait { level: level, duration: dur })`.
&gt; wow this is so alien. See, when I first started out with Rust one of my first gripes was about how Rust actually looks too much like C++! You can't please everyone :)
Another common case where you would box fixed size data is to reduce the size of an enum where some variants are much larger than others. 
With the caveat that some of the shortest and most crucial functions won't show up at all due to being inlined everywhere. 
`impl Trait` is about letting you avoid naming a type. That's pretty much orthogonal to whether you need to box it or not. The only cases that would change are cases where you want to return a non-boxed type but it is currently impossible or prohibitively verbose.
Another niche optimization tip: If you have a small Copy type, explicitly copy it before taking a reference. Taking a reference inhibits compiler optimizations because the compiler doesn't know that the value won't change. https://medium.com/@robertgrosse/how-copying-an-int-made-my-code-11-times-faster-f76c66312e0f
I would argue borrows are a direct result of ownership, and lifetimes follow from borrowings. These concepts can be used for many things _beyond_ memory safety, especially state control like iterator invalidation and mutability checking.
I have two crates that use build scripts. They generate code, documentation, and tests. I don't commit the built files or check if they exist before building them. Cargo is smart enough to know not to rebuild them. For the circular dependency issue, I would be inclined to separate the part(s) needed by the build script into a module. Then, that module could be included both by the build script and by the crate itself.
It's not really *instead of*, right? I just read the RFC and that seemed to be listed as assumption 1 under the Core Assumptions, that a fully expressive syntax for existentials is something that rust will definitely eventually have, and then the syntax that's sketched in the appendix is the abstype syntax. I'm asking though, because I haven't actually followed the impl type progress up until this point. I was really excited about the fully expressive version once I read that sketch so I'm curious. It's still the plan to eventually allow that, right?
If you're a business doing something fancy with GPUs, essentially it's keeping tabs on their health and performance + controlling various aspects of them. If you're just a plain ol' person like me, gathering GPU stats. A long term goal of mine is to eventually use this as a piece of a cross-platform GPU / system monitoring utility, written in Rust. I figured I might as well wrap the whole thing while I'm at it, even though well over half of the library isn't applicable to that. ¯\\\_(ツ)\_/¯
My humble opinion is that impl Trait syntax should not ever exist (because such typed are not easily addressable), only abstypes should. In that sense impl Trait is not the first step, but a step in the wrong direction. Well, there's a chance that impl Trait syntax will be removed later.
It will. Wanna cry is the latest example in a long string.
You should be able to just install rust through rustup on bash and be able to use it just fine. You might need to also install some build util packages as well though
Thanks I will take a look at corrode! I am a mathematician so I was interested whether it exists, I understand why safe rust should be preferred :-)
Interesting. I installed the build-essential tools or whatnot, and also installed rustup, and restarted my bash window, but rustc and rustc --version do nothing still. 
[cairo-rs](https://crates.io/crates/cairo-rs) is the one I'd go for.
Wow! That's amazing! It would be really difficult to do it, but I'm open to it once we implement telemetry :) The main issue I see is that we film at 1080p 30fps, at 17 Mbps and our link is of 200Kbps at best. We would need to change the. Ideo aspect ratio and quality before streaming it down, which I guess it can be done with ffmpeg, but not sure how. Also not sure how would the Raspberry Pi handle it.
There actually are two main reasons for it: I don't have almost experience with microcontrollers, so it would be a big challenge. Also, the Rpi has a camera that perfectly integrates with its software and hardware, and a good GPU to handle it. Would that be possible in a microcontroller? In any case, that would be really great, of course! Better power consumption, more control on the operation and so on.
I'm sure everybody is wondering what the error messages look like. [In Rust:](https://play.rust-lang.org/?gist=6004a479009b8294c06fe637be57c579) error[E0502]: cannot borrow `vec` as mutable because it is also borrowed as immutable --&gt; &lt;anon&gt;:5:5 | 4 | let first = &amp;vec[0]; | --- immutable borrow occurs here 5 | vec.push(4); | ^^^ mutable borrow occurs here 6 | } | - immutable borrow ends here ***** Equivalent code in C++: borrow_vec.cpp:14:13: error: no matching member function for call to 'push_back' vec.push_back(4); //- error ~~~~^~~~~~~~~ ./borrow_checker.hpp:39:21: note: in instantiation of function template specialization 'main()::(anonymous class)::operator()&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, detail::ref&lt;const int&gt; &gt;' requested here -&gt; decltype(l(object, ref&lt;Expression&gt;(expression))) ^ ./borrow_checker.hpp:54:13: note: while substituting deduced template arguments into function template 'call_lambda' [with Lambda = (lambda at borrow_vec.cpp:11:5)] call_lambda(0, l); ^ borrow_vec.cpp:11:5: note: in instantiation of function template specialization 'detail::borrow_lambda_invoker&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, const int&gt;::operator=&lt;(lambda at borrow_vec.cpp:11:5)&gt;' requested here borrow_expr(ref, vec, vec[0]) ^ ./borrow_checker.hpp:166:37: note: expanded from macro 'borrow_expr' #define borrow_expr(Name, Obj, ...) _borrow(Name, Obj, __VA_ARGS__) ^ ./borrow_checker.hpp:160:46: note: expanded from macro '_borrow' _borrow_lambda_invoker(Obj, __VA_ARGS__) = _borrow_lambda(Name, Obj) ^ /usr/bin/../lib/gcc/x86_64-linux-gnu/5.4.0/../../../../include/c++/5.4.0/bits/stl_vector.h:931:7: note: candidate function not viable: 'this' argument has type 'const std::vector&lt;int, std::allocator&lt;int&gt; &gt;', but method is not marked const push_back(value_type&amp;&amp; __x) ^ /usr/bin/../lib/gcc/x86_64-linux-gnu/5.4.0/../../../../include/c++/5.4.0/bits/stl_vector.h:913:7: note: candidate function not viable: 'this' argument has type 'const std::vector&lt;int, std::allocator&lt;int&gt; &gt;', but method is not marked const push_back(const value_type&amp; __x) ^ In file included from borrow_vec.cpp:4: ./borrow_checker.hpp:54:13: error: no matching member function for call to 'call_lambda' call_lambda(0, l); ^~~~~~~~~~~ borrow_vec.cpp:11:5: note: in instantiation of function template specialization 'detail::borrow_lambda_invoker&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, const int&gt;::operator=&lt;(lambda at borrow_vec.cpp:11:5)&gt;' requested here borrow_expr(ref, vec, vec[0]) ^ ./borrow_checker.hpp:166:37: note: expanded from macro 'borrow_expr' #define borrow_expr(Name, Obj, ...) _borrow(Name, Obj, __VA_ARGS__) ^ ./borrow_checker.hpp:160:46: note: expanded from macro '_borrow' _borrow_lambda_invoker(Obj, __VA_ARGS__) = _borrow_lambda(Name, Obj) ^ ./borrow_checker.hpp:38:14: note: candidate template ignored: substitution failure [with Lambda = (lambda at borrow_vec.cpp:11:5)] auto call_lambda(int, const Lambda&amp; l) ^ ./borrow_checker.hpp:45:14: note: candidate template ignored: substitution failure [with Lambda = (lambda at borrow_vec.cpp:11:5)]: no matching function for call to object of type 'const (lambda at borrow_vec.cpp:11:5)' auto call_lambda(short, const Lambda&amp; l) ^
Piston does not rely on Glium. You can also use it with OpenGL and Gfx.
I also checked pyo3 and the issue about class syntax. Great work! I started working on rust to improve my main language, python and your repos look fun! 
Like this: https://github.com/cedenday/rshare/blob/8d301eadd72dc43de817249451eada7a34665a88/src/client.rs#L246-L249
You've come to the right thread! Just give us a link to the code you want reviewed.
That makes sense, we were trying to do it cost-effective by using the Raspbery Pi camera, that embeds perfectly with Raspberry Pi's software and hardware. We can try other approaches in the future, though :)
Well, the good thing about a side personal project is I don't need to sell me using a microcontroller, even if it's not ready for production :) The current approach is multithreaded, a thread is in charge of changing from recording to taking pictures and not much else. That way the control and telemetry have their own threads, and even if something fails, it's not a big issue. Same goes for GPS, currently doing polling, but would like in the future to be able to do async I/O with the serial, maybe with futures?
Yes, some clever person on this subreddit said that what distinguishes scripting languages from others is that they're optimized primarily for writing. By reducing the boilerplate it's easier to write little test programs, and by optimizing the build people get responses faster (human perception of time is non-linear). And encouraging easy use of `?` is good, because the `unwrap` habit can get harmful.
https://codereview.stackexchange.com/ might be good!
Clearly the C++ error message is superior, it must be giving more information because it's longer. /s Now if only the various template-based scientific C++ libraries I use would get rewritten in Rust. The CPU cycles saved from printing the template errors alone would probably power a small town for a year or so.
`static_assert` helps ~~a lot actually~~. Most compilers do not stop at an static assert failure to print a clean error message. Instead, they keep on compiling code beyond a static assertion failure to provide the user with multiple error messages at once and speed-up the edit-compile cycle. However, code beyond a static assertion failure is typically completely broken, so other multiple errors occur, and these are reported mixed in with the backtrace of the static assertion that failed. Furthermore, some of these errors might be other static assertion failures that are completely irrelevant (they might become correct once the first assertion failure is fixed), but these also get reported, making it hard to find out which of them failed first. Given that `static_assert` is a C++11 feature and on 2017 this is still an unsolved problem, I am starting to doubt that producing _good_ *error messages from `static_assert`s is even possible in C++. * the error messages with `static_assert` are less bad than without it, but IMO far from "good".
I've started work on this now: https://github.com/gtk-rs/glib/pull/169 Once the gtk-rs people are happy with that, I'll add support to the code generator and then the GStreamer bindings benefit from that too.
Great idea !
Show the app!
In your case it just so happens that `a` is a subexpression of `b`, but in general that need not be the case :). Of course I agree that `some_vec` is evaluated in the index expression.
Yeah, I really want an editor that shows me every inferred type inline. I'm sure it'll come in time.
&gt; Andrei did mention earlier that learning Rust means you'll have to retrain everyone to rethink how they code (which is pretty par for the course when you pick up a new language). Interestingly, it's a very good hook when talking about Rust. It is sufficiently far away from other languages to merit learning it (it's not a different syntax), while not going all in - it still is an imperative language with a very classic syntax and vocabulary.
No, enums are sum-types. You mean pi-types? (Not so sure tbh)
.lib files are DOW/Windows's static libraries, whereas dll are dynamic libraries. Once you got your .dll, you just need to tell your compiler to link on it.
Okies, right now I am going with what whatever builds :)
The compiler actually hints at the issue: ``` = note: values in a scope are dropped in the opposite order they are created ``` Which is to say, `bar` gets destroyed before `foo`. But because you pushed references into `bar` into `foo`, `bar` musn’t be destroyed before `foo`. Hence the Doesn’t Live Long Enough error.
This is why I set my build variables to stop after 1, or 2 if I'm in a good mood, errors.
Yeah, I figured as much. I should probably have just asked about the "correct" way to do this is in Rust. This seems like a common enough pattern that there has to be a simple way to do it.
Yes, as I understand it, the borrow checker compares scopes-- I just don't think the statement: &gt; Let's say the compiler knows the root scope as "scope S". For the expression Container { x: &amp;mut local_x } the compiler will instantiate lifetime parameter 'a for the type Container with "scope S" is exactly what is actually going on.
Don't know if this will notify everyone, but I wanted to give an update. We got more positive responses than we expected over the last couple of days and are deciding how to proceed. Thanks for the continuing support. :)
Well, of course something hacked together in 30 minutes during lunch does not compete with a language built around that. I just wanted to see if it is possible - it is, and it was fun to do. You're not actually supposed to use that, if you need sucha feature, you should use Rust.
Well the issue says the .lib should be present in the deps directory, so look there. I think they fixed cargo so it copies the .lib next to the .dll now, but that fix is probably in the next version. I haven't actually used rust with C++, and I haven't used MS C++ in a while. But generally to use a dll in MS C++, you need the .dll, the import library and a header that declares the exported functions. The declared functions also need to be decorated with __declspec(dllimport) attributes or they won't link properly.
If you really do want a list of lists of strings, using owned strings is probably the easiest way (so, use a `Vec&lt;Vec&lt;String&gt;&gt;` and `bar.split(',').map(String::from).collect()`). If you only need to process the data once (even if that is just parsing into into a more concrete structure), it is likely a better idea to do that directly atop the iterators and avoid all the allocations.
IDK how much this would help but perhaps check what's at 0x2E0 in your dll? I'm not a MSVC person and haven't googled why that error is but can't hurt. 
yes
I find it quite hard to write Java these days because having to repeat the type of locals everywhere is so annoying. Even having something like csharps `var` would go a long way.
I thought it was a pun too... :)
&gt; it might be nice to have a curated list of "further reading" That would be great!
Enums are sum types, Rust already has those. But yes, I meant integers as template parameters.
Both `String` and `Vec&lt;_&gt;` mean allocations which may be unnecessary. If you, say, convert the items returned by `split()` into integers right away, the allocation would be useless. Having `collect()` be generic over some type that knows how to construct values from an iterator (aka `FromIterator`) makes it possible to plug things neatly together without having to have intermediary allocations. Obviously, I don’t have a useful and impressive example right now. But it happens …
And if you care, the order from left to right is: * interviewer (not sure who that is) * Scott Meyers * Walter Bright * Andre Alexandrescu I'll have to read Meyers' book. I have Code Complete, which is similar, but I'm interested I'm what Meyers has to say.
Given the weight of words anything spoken by respected and well known people like Andrei carries, one would hope they would be more humble and admit not knowing much about Rust rather than speculating like he did. If you haven't used Rust or Go or some language for a real project, it's unprofessional and some might say inexcusable to conjecture on something you don't really know.
Not disputing your general sentiment, but Microsoft does a lot of verification and static analysis of their code and they still manage to let bugs slip through into the hands of exploit developers. It's inexcusable that the Windows team hasn't incorporated any of the three (IIRC) C# for systems/kernel development projects that ran successfully in MS Research. They wrote at least 2 kernels in C# dialects suitable for the job and at least one was also aimed at better utilization of many core architectures (Barrelfish?).
why is that
You could also move the declaration of foo below the declaration of bar https://is.gd/AaHCd1
GNU is generally unreadable past the first message without -Wfatal-errors. It's the -ferror-limit=1 equivalent. The same is true of more than templates -- a compiler can't resolve variable's specifics so displays further errors as if the variable didn't exist. MSVC is my favorite here, paraphrasing "no return type given, C++ doesn't support default-int". All workarounds notwithstanding, it is necessary to pipe standard error to less(1). With or without template usage. If we're to complain about the compile error experience, let's not blame it on templates. The problem is general.
There's a lot of concepts in Rust that I personally had very little experience with beforehand so I remember experiencing frustration with it similar to the frustration I experienced when I was first learning to program at all. I don't have that frustration anymore, experience cured it and I feel it was worth the effort to learn. Furthermore some libraries are better documented than others and sometimes library authors make some very non-obvious decisions with their API. Rust standard library also employs some exotic data structures but personally I think every one of them is worth having and beneficial to the language. 
I heartily endorse this post or comment. I used to love writing log files from inside my application, but then i spent some time as a sysadmin/platform engineer, and now i am completely convinced that all applications should just write to standard output and let some kind of supervisor handle logging - whether that's init, a user-level process monitor, a wrapper script, etc. Let the application do its job, and let some context-specific glue handle the logs. I admit that the situation is less clear when the program is something a user runs directly, rather than a server, particularly if it's something which writes real output to standard output. I think i'd still suggest writing logs to a standard stream, and optionally providing a wrapper script to copy or redirect them to a file. If the application writes real output, then use standard error instead of standard out. 
Oh, sorry! I didn't read carefully enough. I thought the code block in your post was your current version. Do you have the current version somewhere? There's probably a way to do this without a clone. If you care about slightly more idiomatic code, that is; I don't want to impede you if you've already moved on to working on something else.
A *bare* trait name, without an &amp;, isn't a valid type name, is it? I can't write: fn foo() -&gt; SomeTrait { ... } Can i? it has to be one of: fn foo() -&gt; &amp;SomeTrait { ... } // trait object fn foo() -&gt; impl SomeTrait { ... } // an unspecified implementation of a trait fn foo&lt;T: SomeTrait&gt;() -&gt; T { ... } // a specified implementation of a trait 
&gt; the infrastructure those applications are based on is usually written in C or C++. Or COBOL! I worked on one payment processing project, for a major bank. Part of me couldn't quite believe that the code the team was writing was going to go to production in the state it was in, but that is apparently really going to happen. 
Rule #2 in the sidebar. &gt; #### Constructive comments only. &gt; Criticism is encouraged, but ensure that your criticism is constructive and actionable. Throwaway comments are just noise. 
Don't get my other comments wrong - I totally agree with you and I'm seriously impressed you got this working.
I'm all for talking with critics! It's a healthy thing to do. I was letting you know that in this case it's probably not worth it :)
Eh. Even with C it's quite slow. Moving to pure rust for data science tasks yields quite a nice performance improvement.
The lang team believes we'll have an implementation in nightly before the end of the year.
It's in the works, but there's no fixed timeline.
I'm very excited to hear that! :D
Check out LoadLibrary and GetProcAddress on MSDN if you don't need to do compile time linking
Great, I'm looking forward to it too.
Pff. I once got 500 lines of error messages
They ran on .net and weren't particularly fast kernels. 
I used the [gnuplot crate](https://crates.io/crates/gnuplot) for plotting with some homework assignments. It worked quite well. Edit: sorry this was supposed to be a new reply
Okay thanks, I thought that since I would be able to return the vec no problem in this case I should also be able to return the slice. I don't see why the compiler doesn't copy or have a function to copy the slice to a higher lifetime
The problem is that the Vec needs to be deallocated at some point, and in rust, the "owner" of the data is responsible for doing that. If you just return a slice, the callee does not take ownership of the data, and thus does not know it needs to be deallocated. The data (Vec with pointer/capacity) lives on `i32_rand_array`'s stack, and since `i32_rand_array` owns the data, it deallocates it when it is finished: thus invalidating the slice you were going to return.
Static mut ref logfile?
This is probably stupid because you're apparently doing a toy example, but it'll run a lot faster if you just sum up all the multiples of 15, or get even more clever and use the formula for the sum of a series and calculate it outright.
I think "this" is a pattern to do a something like a global variable that can mutate. You have Rc&lt;T&gt; and Arc&lt;T&gt; for mutithread to share the ownership of a resouce. Basically you clone the Arc instance which is not mutable, and it create a new pointer to the owned resource. Isn't it ? 
Uhh, well... Trying to build your crate fails when running the build script for openssl v0.7. On stable as well as nightly. I think this problem doesn't exist in later versions of the openssl crate, because I'm pretty sure it is used in other crates that build fine on my system. But apparently there's no later version of the discord crate available, which is what (indirectly) pulls in openssl. So I guess the only thing I can do at the moment is recommend [clippy](https://github.com/Manishearth/rust-clippy), in case you're not already using it. It might have some tips for how to make your code more rusty. Just `cargo install clippy`, then `cargo clippy` in your project directory. EDIT: Looking at this version of the code though, I'm pretty sure you can remove line 124 and 125. If that doesn't work, I'd be curious about what the error message is.
It is "abandoned" but in reality that just means no one is working on new features for it. The author is still definitely doing bug and any vulnerability fixes - just not actively working on new features. The headline is 'abandoned', but it's more like 'feature stalled'.
I'm not saying they should have replaced the whole operating system. They already have compartments of stuff and virtualization. Running the sensitive services as managed code, like CIFS or malware scanner, would have worked. I agree performance would be a hurdle to overcome, but I think it'd be easier than trying to ensure the C and C++ code running in privileged mode with network facing sockets be trustworthy.
It was mentioned in comments several times. It is something like: abstype MyIter&lt;A, B&gt; = impl Iterator&lt;A&gt;; fn foo&lt;A, B, C&gt;(...) -&gt; MyIter&lt;A, B&gt;; 
The main thing that's unidiomatic about your code is that you've written your `Stack` type as an immutable, FP-style data structure. Rust generally embraces the imperative style for handling data, and permits mutability where it makes sense. A data structure like your stack is definitely such a case. Your `pop` method, for example, should simply take `&amp;mut self` and return just `Option&lt;T&gt;` rather than consuming the entire stack and returning it w/o its top element. TL;DR: Don't write your Rust like you do your Haskell :)
If Rust is expression based, why can't I do this: let result = if condition { "yes" } else { "no" }
Hm? That's not in the code.
ah; yes, it's not built into the compiler, it's a convention we call "interior mutability". https://doc.rust-lang.org/nightly/book/second-edition/ch15-05-interior-mutability.html and https://doc.rust-lang.org/nightly/book/second-edition/ch16-03-shared-state.html are the latest docs on this topic.
You can; you need a `;` at the end, because `let` requires it. let result = if condition { "yes" } else { "no" };
That's why I brought up the whole "shove it in a VM" approach to running old-school Windows apps. It's pretty much the only way to get the Win32 subsystem out of the privileged domain without breaking backwards compatibility. And, as I already said, they've done it before and can do it again. The hard part of this is that backwards compatibility is as important in UI as it is in API. And the "shove it in a VM" approach won't work; they tried that with Windows 8 and it sucked.
There shouldn't be anything keeping you from returning the actual vec. All you'd need to do is change the function signature to `fn i32_rand_array(len: usize) -&gt; Vec&lt;i32&gt;` and then return `res` instead of `res.as_slice()`
No idea why the openssl thing fails. It's used by a dependency, so I can't really control the version Yeah, I'm having some problem running `cargo +nightly clippy`, so I kinda gave up on Clippy.
I wanted to return an array not a vec, but the compiler says "the trait `std::marker::Sized` is not implemented for `[i32]`" or "expected lifetime parameter" if I say `&amp;[i32]`, which now makes sense to me
It works with the current nightly, try `rustup update &amp;&amp; cargo install -f clippy` to update both.
One issue is that `command` takes a full `Vec`. This means that every time `command` is called, a `Vec`is given as sacrifice. Maybe the tokens could be reusable? `command` in turns sends the tokens to `::commands::execute`. Maybe this one could also be satisfied with a `&amp;[String]` (a "slice")? For instance, `command.rs:113` could be `let tokens = &amp;tokens[1..];`: instead of _actually_ removing the first token, you just ignore it.
You (and all the other folks who organize the RustFests) are doing a stellar job. Really looking forward to https://rustfest.ch
Why did you want to specifically return a *slice*[1] instead of the owning vector ? [1] : notice that's what `as_slice` gives you: in no case you have an array involved in you code. 
Ah yes - glad it works now! `[i32]` itself doesn't have an actual representation on the stack, since it can be any length - it's only ever usable behind some kind of indirection :)
`"C"` is the default and is often left out.
Been working on a serial port websocket server. Like serial port Jon server, but less sucky and cleaner. All messages are Json. Internally uses threads to handle requests until async is more stable. But with a few ports and clients is more than sufficient for the normal use cases. Would love to see this as a start of 3d printing initiative on rust. 
Thank you so much for this. I haven't checked it out yet, but trying to work with tokio and error-chain was a major headache, eventually I just scrapped the async part. It was just a hobby project so it didn't really matter, but it's nice to know that I can try and use your crate in the future.
Can windows users invoke `cmd.exe`, type in the path of your binary, and run it, or are there extra steps they need to go through? I'm trying to figure out the cross platform story for an in-progress project, so I'm wondering if I can just rely on WSL for windows support, or if it's too much of a headache for an end-user to get working.
https://github.com/sfackler/rust-openssl/issues/637 This crate doesn't support openssl 1.1 quite yet, which I suspect you are using.
Rust userland support in Tock is in beta! Awesome!
Yeah I was expecting something like that. Thanks for pointing out the bug report though.
I'm not sure developers will eschew C. But the managers and customers of software will demand it, as they are the ones who pay the bill for memory safety bugs.
But yes, having discord update its openssl crate to `0.9` (dropping the need for `openssl-sys-extras`) is the main solution.
Apparently. Now I get when it's trying to compile `cookie` use of unstable library feature 'splice': recently added (see issue #32310) | self.rows.splice(affected_rows, replacement_rows); = help: add #![feature(splice)] to the crate attributes to enable
/u/japaric's posts about the rtos he's writing got me pretty motivated to start working on this. Psyched that it's only taken a few days to get another chip working using his framework. These blue pills are so cheap, and the framework nice to work with, I don't see why you'd want to use an arduino anymore (well maybe lack of libraries). If you want to give it a try the repo is [here](https://github.com/etrombly/bluepill). I'm planning on building a zen garden with ball bearing and magnet for my first project. There's been a couple different takes on it posted before. edit: The program running in the video is under examples/stepper.rs, just a quick proof of concept. Planning on making a generic stepper driver later.
Uh... You get an error in a dependency when running `cargo clippy`, but not when running `cargo build`?
I don't really want to use all that low level libaries. Think of a calendar or a countdown-timer application with a (preferrably portable) window GUI. Haven't found a suitable one so far. Thanks for the link in any case.
&gt;return an array not a vec The size of the array has to be known at compile time, and you are creating it based on the value of the function argument. You need [constant generics](https://github.com/rust-lang/rfcs/pull/1931), which is not yet implemented. With constant generics, you will be able to write something like fn generate&lt;const N: usize&gt;() -&gt; [i32; N] {...} let myarray: [i32; 16] = generate(); Keeping the values in a Vec may be the easiest solution.
Very nice. Some possible bugs: `update_room_topic`, `update_room_noindex`, and `update_room_tags` use a URL path with `"/rooms"` but probably want `"rooms/"`.
&gt;liveness is a property that a value is still in use (live) at some location since it's current value will be used in the future. If a value is not live, i.e. the current value will never be used, it's lifetime can be ended at that point while still preserving guarantees about usage. But it is applied only to references, right? IIRC, if the compiler assumes that a value can be dropped before the end of the block (even when it is not used anymore) it can break RAII.
Andrei is a big fan of metaprogramming, so it understandable that he is not that interested in Rust.
Yes, I know. This sort of stuff is why I love contributing to TWiR. I get to look at all the cool things we got last week.
Nop. AFAIK, it is still under discussion, but I'm not following the feature too close, so it is possible that it is already in development.
Great, C++ gets non-lexical borrow scopes before Rust does: vec.push_back(42); func_borrow(borrow(vec)); func_mut_borrow(mut_borrow(vec)); func_borrow(borrow(vec)); func_destructive_move(destructive_move(vec));
Thanks. It still needs a lot of work, first and foremost there aren't a whole lot of modules avaliable yet... Also, there are rough edges all around since this is my first public rust project. Any help is greatly appreciated!
What's the basic situation where moving ownership (is that even the right expression?) is necessary, and a reference (mutable or not) won't do?
Looks like [non-lexical lifetimes is blocked on moving the borrow checker to MIR](https://github.com/rust-lang/rfcs/issues/811) (mentioned in Dec of last year, so likely still accurate), so it might be a little while until this is resolved. I'm definitely looking forward to it. I've had lots of code that have required throwing in temporary variables or extra scopes to get working.
I won't say MISRA is used *everywhere* within the automotive industry but it is fairly standard. For instance, my employer requires it even though our modules are non-safety-critical. And if we tried to drop it, I have a feeling our customers would complain.
I looked briefly at the serial driver. It has lots of `unsafe` blocks. Doesn't that kind of defeat the purpose of using Rust? Not trying to snipe. I'm really interested in real time driver safety. I thought RTFM was the concurrency model we want, but you're not using it?
I'm using QtCreator for C++ and Kate for rust programming... if kdevelop gets good at doing rust, perhaps I can switch to just use one. So, thanks for your effort and lets hope it can get there!
Completely off topic, but whenever I see "Talking Tock" mentioned, I think about "Talking Cock", which is a Singaporean idiom meaning idle chitchat / talking nonsense, and also the name of a (now defunct) satire site: https://en.wikipedia.org/wiki/TalkingCock.com
So let's try overriding `PATH` and setting `XARGO_RUST_SRC`: $ PATH=/home/cactus/prog/rust/rust-avr/build/build/x86_64-unknown-linux-gnu/stage1/bin/:$PATH XARGO_RUST_SRC=/home/cactus/prog/rust/rust-avr/rust/src ~/.cargo/bin/xargo build --release -v + "rustc" "--print" "sysroot" + "rustc" "--print" "target-list" + "cargo" "build" "--release" "--manifest-path" "/tmp/xargo.121ZGMbVq6qh/Cargo.toml" "--target" "avr-atmega328p.json" "-v" "-p" "core" Compiling core v0.0.0 (file:///home/cactus/prog/rust/rust-avr/rust/src/libcore) But this is very much NOT what I want; I want `libcore` to be compiled from the source that I've specified in my `Xargo.toml` file. Is it possible that Xargo simply doesn't support this use case, and it's a solution to a slightly different problem?
Unsafe code isn't always evil, in this case it is probably the only way to get anything done without using C
But you can't argue that there's a huge barrier to entry that - let's be honest - 95% (possibly higher!) of programmers simply are not capable to conquer. The problem with rust in my experience is that you require a team of experts... I don't know about you, but all the teams I've ever worked on have 1-2 experts, and 5-10 average/junior programmers. D's safety story makes is much easier for those average programmers to get their work done, and let the few experts do the hard bits. Rust's story requires everyone to be an expert, and they're not. Rust has a place, and it's a great place, but I don't think it can scale out in a practical sense. Edit: ...at least not in my workplaces. I would never be able to motivate a shift to Rust. With D on the other hand, existing C/C++ programmers can mostly learn by osmosis with zero training while on the job.
I think it's more that he's interested in carefully balancing practical design and rigid intellectual design. Rust's safety implementation is explicit, and very well defined, and that's a good thing from the perspective of Rust, but it comes with a lot of language machinery and baggage, and it's very unwieldy for new users. What D is attempting, on the other hand, is something very similar in effect, but with a simpler design and reduced impact on the language. D's solution is still work-in-progress, so we can't really comment on the relative success yet, but the intent is to do most of the work via inference, requiring a lot less explicit management and wrangling. It's also important for D, since meta-programming is so fundamental to the language, that templates inserted into gaps with different safety requirements are able to infer their contextual state and adapt the instantiation appropriately. FWIW; I was extremely skeptical about D's approach, and I argued in favour of Rust's explicit design for... years. I am starting to reconsider my intuition on this matter, and I'm prepared to give D's design a red-hot go before I can call the safety story one way or the other. My feeling is developing that, because rust is so explicit, it will make eventual deployment of comprehensive meta-programming so much harder. I think Rust will have to relax and move towards D, or simply accept that Rust is not intended to have an amazing meta-programming story.
Even if your code is littered with unsafe, you can get a couple of other benefits over C: Pattern matching, closures, opt-in raw pointer handling, Cargo, checked arithmetic, method call syntax, portability via LLVM, immutable-by-default, RAII, etc...
Nice! I will definitely use this myself which means I should probably contribute! Would you mind opening a few issues for things that you want help with? Is there more than creating more blocks? (not that that isn't a large thing already.) I'm not always great at figuring out what needs to be improved in a new codebase.
I though Xargo was working fine on Windows even before LLVM 4.0. You should have sent me a bug report and I would had looked at it.
&gt; I looked briefly at the serial driver. It has lots of unsafe blocks. Doesn't that kind of defeat the purpose of using Rust? Not really. The key point is building safe abstractions. It's very likely that those abstraction will be implemented using unsafe code at some of their lowest layers. After all the compiler can't reason about everything. "Is it safe to write to address 0x4000_0000?" The compiler doesn't know but you know so *you* tell it its safe by writting an `unsafe` block. That's what `unsafe` is for: code that the programmer must audit because the compiler can't prove safe. Once a library provide safe abstractions then application can be written using only safe code and that's what's shown here: the [stepper](https://github.com/etrombly/bluepill/blob/master/examples/stepper.rs) example has no unsafe code. (As to why unsafe code is required in the serial code: the code being used to write the safe serial abstraction was automatically generated using svd2rust from a SVD file. The SVD file contains information about which values can be written into a register but *not always*. When the SVD file doesn't provide enough information for a register then only an `unsafe` API is available for that register.) &gt; I thought RTFM was the concurrency model we want, but you're not using it? They are using it in the application code. The IO / HAL library doesn't need to know anything about the RTFM framework. The layers are decoupled: RTFM provides synchronization (data race freedom), and the IO library does memory safe IO once something else (it doesn't has to be RTFM) has guaranteed proper synchronization.
How can I stop THE warmup assetment?
Hi, a Tokio question. I'm processing a stream, and I'm trying to do make `core.run` complete when the received element is of a certain value. Something like this, but I'm not sure `for_each` is the right function: let f = myStream.for_each(|element| { if element == 12345 { /* What do I return here to make myStream complete? */ } else { /* do something with element */ Ok(()) /* returning Ok makes the stream continue as normal */ } }); core.run(f).unwrap(); I could return `Err(())` but then `core.run` panics, I just want `core.run` to return normally.
Wait so this is a dependency in my application? Sorry - I don't keep track of them since there are so many sub-dependencies. Anyways that's interesting. Maybe some code detects nightly and runs alternative code? IDEK!
I tried something similar to this, but the borrow extends to the end of the function in that case. Some short reading leads me to believe that using `return` to return early from a function causes borrows to extend until the end of the function. This is what I tried (and I agree, it's ugly): pub fn query&lt;'a&gt;(&amp;'a mut self, query: &amp;str, params: &amp;[&amp;postgres::types::ToSql]) -&gt; Result&lt;postgres::rows::Rows&lt;'a&gt;, Error&gt; { match self.internal_conn.query(query, params) { Err(postgres::error::Error::Io(io_err)) =&gt; match io_err.kind() { io::ErrorKind::ConnectionAborted | io::ErrorKind::ConnectionReset =&gt; { if self.cur_retries == self.max_retries { self.cur_retries = 1; return Err(Error::Io(io_err)); } }, _ =&gt; { return Err(Error::Io(io_err)); } }, Err(other_pg_err) =&gt; { return Err(other_pg_err.into()); }, Ok(res) =&gt; { return Ok(res); } }; self.cur_retries += 1; self.reconnect()?; self.query(query, params) } The error is now: error[E0502]: cannot borrow `*self` as mutable because `*self.internal_conn` is also borrowed as immutable --&gt; src\resilient.rs:85:9 | 71 | match self.internal_conn.query(query, params) { | ------------------ immutable borrow occurs here ... 85 | self.reconnect()?; | ^^^^ mutable borrow occurs here 86 | self.query(query, params) 87 | } | - immutable borrow ends here Edit: Some basic research leads me to this [RFC](https://github.com/rust-lang/rfcs/issues/811) about "non-lexical borrows"
Something similar, they can do bash.exe -c 'path of my binary inside the linux subsystem'. You should look at WSL. It's fucking cool. Steve Klabnik is on WSL full time.
The simplest reason to need ownership of something is if you want to destroy it. For example, the drop function: fn drop&lt;T&gt;(_x: T) { } Similarly, moving a field out of a struct requires ownership (if you only have a borrow, you have to use `mem::replace` so that something remains behind).
Oh you mean I could just add a mut to the first example and it would become mutable? 
Actually I think lazy_static only lets you create immutable statics, so wrapping it in a Mutex is the only way to make it mutable.
Care to share them? :)
Sure. [Rust Angry](http://i.imgur.com/3v2a9rk.png) [Rust Sleepy](http://i.imgur.com/GrSGLnk.png)
The thing about static variables is they must be immutable in order to be safely shared between threads. What `Mutex` does is add a lock on top of your `File` structure - any thread trying to access it while another thread has it locked will be blocked until the first thread unlocks it. It uses an `unsafe` interior to achieve this mutability, but it still guarantees correctness and no data races by blocking threads which try and access the data at the same time. See https://doc.rust-lang.org/nightly/book/second-edition/ch16-03-shared-state.html as steveklabnik1 linked above :)
&gt; It's inexcusable that the Windows team hasn't incorporated any of the three (IIRC) C# for systems/kernel development projects that ran successfully in MS Research. You haven't been paying attention I guess. Both the .NET compilation model to native code on Windows 8.x (MDIL) and the one adopted for UWP (.NET Native), result from those efforts. Also the C# 7 improvements for ref variables and the C# 7.2 planned features for memory spans and regions are also related to those efforts. The biggest problem at Microsoft is political, because C++ used to belong to Windows Dev and .NET to DevTools. You can re-structure the units, but if the persons don't change, politics carry on. Even getting the Windows team to leave C behind and focus on safer code practices with C++ has been a multi-year effort, in spite of the VC++ goal of not updating C support beyond what ANSI C++ requires.
Considering KDevelop uses Kate as its editor, it's already as good as Kate. And even for languages without semantic support, you still get some niceties, such as * the project tree view (you can open any directory as a project) * find/replace in the whole project (just `grep`, but when you click on a result it opens the file in the editor) * git integration (along with other VCS's) * templates, both for individual files and whole projects. None yet for rust, though, and since Cargo generates a project it's not really needed. * everything in this plugin. Even if you don't have it, can be configured manually with some hassle. 
FWIW, I think all of those work in Rust too (that is, `f(&amp;v); g(&amp;mut v); f(&amp;v); h(v)` compiles), since the various borrows aren't being stored in locals and so are restricted to a single statement that only has a single use of `vec`.
Would there be any way to get this to work on amd cards?
&gt; Getting rid of Xargo Is merging [RFC 1133](https://github.com/rust-lang/rfcs/pull/1133) and getting rid of xargo *that* way still on the radar? That effort seems to have stalled quite much. I think producing std binaries for all combinations of kernel, libc and processor is just a too gigantic task, especially with ARM platforms involved, where processors differ so much from each other.
+1M
No, because it generates PTX, which is nvidia specific. It is, however, related to LLVM (as far as I know), as is SPIR, which is a sort-of equivalent for OpenCL. If someone made a SPIR backend in the same vein as this one you could run Rust on AMD cards.
Well, it's not a direct dependency, like you said. But it's still a dependency it has to compile.... right?
thanks, nice, looking for more. as a feedback you could refactor main file and separate tests from the program.
Hey! If you want you can try to implement dzen2 support into i3status-rust. It's quite generic at this point and still adaptable for new bars etc.
i feel like i may steal those for our mattermost group :)
Very interesting project (and choice of algorithm (vr, not raft) as raft has tons of momentum right now).
For my nefarious purposes, I need a dylib for `regex`. Furthermore, the result should depend dynamically on libstd. So I cloned `regex`, added `crate-type=["dylib"]` in the `[lib]` section, and set `RUSTFLAGS` to "-C prefer-dynamic". _However_, the resulting .so still has unmet dependencies. So, how to force `rustc` to give me a libregex.so statically linked with its dependencies, yet dynamically linked to libstd?
Could you tell me more about your last remark? I was under impression that function calls always include "sequence points" so that the side-effects of the argument expressions are guaranteed to be finished before the side-effects of the function begin. What is gained by explicitly storing `len` into a variable? Or do you mean the case where there is multiple calls that don't actually change the length, and `.len()` is called multiple times, but the optimiser can't prove the length hasn't changed so it can't cache the value?
Is the problem in those backends, LLVM or rustc?
I could be very wrong, but...it does not look like they're using Raft. In fact, both the README.md and why.md both mention that they're using "Viewstamped Replication", which is a different consensus protocol. At any rate - this is super exciting!
Can you link me that commit / pull request? We should be able to apply mostly the same fix for WebAssembly, which also doesn't get copied out correctly.
I meant the other way, I probably used broken english. Hopefully it's clear now (after edit).
Thanks!
&gt; foo is now a global function because it has the .entry directive instead of the .func one.
LLVM chokes when you ask it to lower a function that has a 128-bit integer in its signature so this is an LLVM bug. rustc could be smarter though and never ask LLVM to lower those functions in the first place if the final application is not going to use 128-bit integers. In theory, something like [MIR-only rlibs](https://github.com/rust-lang/rust/issues/38913) would let us do that but it hasn't been implemented yet.
There's an AMDGPU backend in LLVM so maybe with a different target. [Someone was working on it](https://github.com/TheAustinSeven/rust-on-gpu/pull/12) but I think they never got it working to the same level of functionality of the NVPTX targets. A SPIR-V backend is another option but I don't think is in upstream LLVM yet.
Not just threads, but multiple mutable borrows altogether.
&gt; That said, the main thing that moved me to write a comment in the first place was the sentiment of "superficial politeness stifling discussion of real issues". This is a common perspective in some technical communities, and is used to argue against codes of conduct, or otherwise to suggest that the way to reach the best technical decisions is to "speak your mind" without regard for people's feelings. You are, I think, being very one-sided in your view of this; the stock reply of "you don't like this? well it's not like you've done anything better" has the primary function of shutting down open critique by calling personal scrutiny on whoever speaks out. I really hope it's not something that you consider to fall under your umbrella of 'politeness'.
Well that issue was closed with [this](https://github.com/rust-lang/cargo/pull/3951) pull request. Although, looking at it now, it seems it only removes the hash from the file name, it doesn't seem to touch any copying code. I looked around the source code, and this seems to be the code that decides which file is copied/linked into the target dir: [Context:link_stem](https://github.com/alexcrichton/cargo/blob/e6e6f10e95906d5d01087239984c9c63f63e3bdd/src/cargo/ops/cargo_rustc/context.rs#L458-L471) and [Context:target_filenames](https://github.com/alexcrichton/cargo/blob/e6e6f10e95906d5d01087239984c9c63f63e3bdd/src/cargo/ops/cargo_rustc/context.rs#L502-L518). So maybe look there.
I like just going to /r/dailyprogrammer and solving some challenges.
I don't think that RFC will get implemented in the short term so thumb binaries are the fastest way to make an improvement in the development workflow. &gt; I think producing std binaries for all combinations of kernel, libc and processor is just a too gigantic task Even with std-aware Cargo I don't think we can't (ever) stop producing those binaries. Yes, the user would be able to compile std but std contains C code so they would need a cross toolchain to compile that even if they are just doing `cargo check --target $T` on a library; fetching the std binary is easier. Also the official std binaries are more portable (lower glibc version requirement) so they are going to be preferred when producing binaries for distribution. Finally we will produce std binaries as a byproduct of producing rustc binaries and people need both when they install the Rust toolchain on their computer. So yes it's a gigantic task but I don't think that std-aware Cargo will liberate us from it.
Ok, you are right: for an option this works fine. But if you want to use an enum with more than two variants, you run into a problem there.
Using `is_none` and `unwrap` is not the idiomatic way to do this. Rather, use a `match` statement: fn square(arg: Option&lt;u8&gt;) -&gt; Option&lt;u8&gt; { let val = match arg { Some(val) =&gt; val, None =&gt; return None, }; Some(val*val) } EDIT: Just to clarify, you can generalize this over anything you can pattern-match, not just option. struct Chips; struct Soda; struct Wine; struct Cookies; enum FoodContainer { Bag(Option&lt;Chips&gt;), Can(Option&lt;Soda&gt;), Bottle(Option&lt;Wine&gt;), Box(Option&lt;Cookies&gt;), } let mut loot = FoodContainer::Bag(Some(Chips)); // I only care about chips. let _chips = match loot { FoodContainer::Bag(ref mut contents) =&gt; contents.take(), _ =&gt; return, // What a disappointment, I'm outta here. }; // You can also use if-let, if you prefer. let _soda = if let FoodContainer::Can(ref mut contents) = loot { contents.take() } else { return // Nope, don't care. };
same
Ah, gotcha. Yes - it's clear now after the edit.
First of all, thank you for the initiative! What I think Rust embedded ecosystem needs: * backends for AVR (in progress, fortunately) and Xtensa (at least ESP8266) * crates for popular MCUs (ARM, AVR, ESP8266) * traits and crate for various peripherals. Ideally it should be easy to write project that runs on both OS and bare-metal. (So people can switch RPi/Arduino/Whatever.) * crates should be idiomatic, statically preventing mistakes where possible (I once spent ~40 min finding out that I wrote `if(pin)` instead of `if(digitalRead(pin))`. Arduino is designed badly, I believe.) * high-quality tutorials * Arduino-like experience for relevant hardware (write code, choose board, choose port, upload) * Async! (RTFM seems great but I didn't have enough time for studying it well.) BTW, I don't think getting rid of Xargo is a priority. It works fine with it.
How would your proposal above work with multivariant enums?
Thanks I will
Turning Rust source code into PTX code (GPU assembly)
An option is to implement your own future for this, which can be done relatively quickly: pub struct DrainUntil(MyStream); impl Future for DrainUntil { type Item = MyStream::Item; type Error = MyStream::Error; fn poll(&amp;mut self) -&gt; Poll&lt;Self::Item, Self::Error&gt; { match if try_ready!(self.0.poll()) { 12345 =&gt; Ok(Async::Ready(12345) item =&gt; { // Process `item` here Ok(Async::NotReady) } } } } 
I mean if you are just interested in one variant and want to early-return for the others.
The thing is that all the intrinsics in nvptx-builtins are defined in the Rust compiler. If we want to follow that approach for the warp shuffle intrinsics we would have to modify rustc. But there's an alternative: you can declare the function in an extern "C" and add a `#[link_name = "llvm.intrinsic.name"]` attribute to it as it's done in the [llvmint](https://github.com/aweinstock314/llvmint/tree/eecbfb981b2edfddfd420c2c60aa59590d7582b6) crate. I think [these](https://github.com/rust-lang/llvm/blob/1ef3b9128e1baaed61b42d5b0de79dee100acf17/include/llvm/IR/IntrinsicsNVVM.td#L3731) are the name of intrinsics. Their signature is there as well: `Intrinsic&lt;[llvm_i32_ty], [llvm_i32_ty, llvm_i32_ty, llvm_i32_ty],`. Gotta run now. I'll take a closer look at it later.
https://www.reddit.com/r/rust/comments/64t251/mozilla_awards_50000_to_the_tokio_asynchronous_io/dg62o0a/
*cough* http://math.andrej.com/2015/08/05/provably-considered-harmful/ There's almost nothing "provable" about this. The implementation isn't tied to the model. Yes, this is a good technique for increasing assurance. But you still wouldn't call something using this technique "a verified implementation" of anything. As an almost-expert in this field, that word is one of my pet peeves ;) This is good though. I'm looking forward to seeing this mature.
So what you're saying is that there is no existing combinator (or combinator combo) for doing this? I tried combining `take_while` with `into_future` but I didn't get it through the compiler.
Meanwhile, I solved it with an extra `oneshot::channel` but it would be nice to know the "recommened" solution, if any.
You don't even need the return keyword here, so it could be even shorter! :D
Typo: let val = arg?; Would this get optimized properly? Some(arg? * arg?)
FWIW, the two protocols are similar. In [this thread](https://groups.google.com/forum/#!topic/raft-dev/cBNLTZT2q8o) on the Raft mailing list, Diego (the Raft author) compares the two a bit. There is, culturally, a faction of folks, particularly from the MIT cohort, that have been championing VR instead of Paxos for a few decades. A lot of the VMWare folks came out of MIT, so I wouldn't be surprised if that's just the the algorithm they are most familiar with.
No.
Is there an idiomatic way of doing this in Rust? Or do I have to wrap the `cargo install` command and others in a Makefile or something?
Yeah, I would make your install instructions recommend something other than `cargo install`, or a second step after it. Or you could have a special mode, like `your-cli-app --init-completions`, that the user is supposed to do on first run (I guess you could even check every time whether it's the first run and do it automatically, but that might be too much magic).
`Box::new` is more like `std::make_unique`. Rust doesn't have a direct equivalent to `malloc` and `new`, in that you can't directly get an allocation *without* some kind of ownership semantics in place. In fact, you generally allocate by just creating whatever kind of owning pointer has the behaviour you want. `Box::new` for single-owner, `Rc::new` for shared, ref-counted ownership, `Arc::new`for thread-safe, shared, ref-counted ownership.
&gt; The new book 2.0 has a tutorial on writing a web server, check it out, it seems good. [Link to said chapter](https://doc.rust-lang.org/nightly/book/second-edition/ch20-00-final-project-a-web-server.html) :) /u/jaroslaw-jaroslaw, I'm not sure if this is interesting to you or not, but there's [a project working on rewriting all the GNU coreutils in Rust](https://github.com/uutils/coreutils), and there are lots of small parts of each utility to work on.
Your docs are great! I use i3 and have never really been satisfied with my bar so this will be super useful. And I'm looking for a rust project to work on. I'll definitely see if I can do some work on this over the weekend.
Great! Well, the docs are not great yet. Widgets aren't documented yet (but usage is trivial) and a lot of the inner workings have to be inferred from the other implemented blocks, like how to use the "push" update feature. If you want to work on something, I'd appreciate work on new blocks most. But just look into the issues and pick.
I *wish* it was used everywhere :(
You will be able to implement the new trait for your type like with what you can do with Carrier AFAIK 
Yeah, that's what I was saying. But direct or not, I haven't seen a `cargo clippy` run fail on a dependency when everything is fine with `cargo build`. That's not something that is supposed to happen AFAIK.
I'll just answer here, as I see you being active here. We have some custom-developed board for which it would be interesting to run Rust-based firmware. It is equipped with an Stm32F427IIT6. We currently use C++ based firmware, but I would love to investigate running Rust on both the electronics hardware as well as the PC communicating with it. The one big thing that has kept me from looking into it (apart from my lack of time) is the fact that I have not yet heard anything about how to use the microcontroller as a USB device. Currently we're using the CMSIS-based USB stack for that. But the code of this does not look very clean, and I would love to see a cleaner framework with similar capabilities emerge in Rust. The recent blog posts about embedded devices made me quite confident that Rust has a bright future in that area.
Yes. That's not a concept isolated to 128 bit integers, its already done when you are using 64 bit integers and the target doesn't support them, like on x86. That works without issues, and on most if not all target platforms. The reason for that is because C mandates support for 64 bit integers in the standard, while it has support for 128 bit integers only on some few targets. Those targets which had no 64 bit support therefore emulate it, as C is usually one of the first higher languages being ported for a new platform.
Awesome, I agree with all of your points. Especially avoiding the explicit update - it felt wrong when writing it, using drop is super elegant and I hadn’t even considered it. Thanks, I appreciate the feedback, this is exactly the sort of thing I had in mind. It’s really easy to miss this stuff (for me) when you’re both new to the language and porting C.
I think it should or at least it's an easy optimization to perform, but since it hasn't been implemented yet who knows. I think it should be though. Only one check for IR output should be needed 
Lol, my crate. I plan to deprecate it once `?` works for `Option`.
Thanks for the explanation, always excited to learn more!
It would be nice to have. In general, we don't expect _most_ systems to use a full-on file system, but makes sense for those that have, for example, and SDCard. The Signpost (a project from U. Michigan and Berkeley using Tock) folks will likely [start using FAT32 in userspace](https://github.com/lab11/signpost/tree/master/software/apps/storage_master/fat_test) based on a C library, but if there it's possible to do in Rust, in the kernel, that would be potentially really nice as well. So, yes, we're interested :) We have a pretty reasonable in-kernel SDCard driver implementation, so doing something on top of that would make sense as a place to start. Does your current implementation live somewhere online? 
I'd love to have this syntactic sugar – just using `?` doesn't necessarily cut it, if you have to do some other teardown or you need to control more carefully the return value. Having a diverging conditional pattern-matching block that introduces bindings to the code following it would be so neat; stylish, concise, and anti-rightward-drift.
I'd be interested to hear your thoughts on how the book (specifically [the second edition's chapter on smart pointers where `Box` is introduced](https://doc.rust-lang.org/nightly/book/second-edition/ch15-00-smart-pointers.html)) could be improved so that you'd feel confident about your understanding of the Rust way of managing memory after reading it :) Either here or in an issue on [the book repo](https://github.com/rust-lang/book) would be amazing if you have ideas and time to write them up!
Abstract models produced alongside of but not computer checked to be formally equivalent or automatically generated make me feel anxious and uneasy too.
There is much more to the world of programming than web development. Web development just happens to be the big shiny thing that is being sold right now. The key is specialization which takes time and requires you to try many things to find what you don't want to do (in my experience).
Why is this different from the case where you have a 64-bit integer on a 32-bit architecture? (Also, can you use extprim or something?)
These are awesome!
Just so you know, the formating in your first pragraph is really confusing and it looks like you got off with the backticks. Good summary though :)
The Rust world is small :) I too hope the ? operator will support Option soon, but last time I checked the RFC was bogged down in some contentious details :/
a vimtutor-like experience for learning rust would be cool
I think [Helium](http://foswiki.cs.uu.nl/foswiki/Helium/Features) is the current gold standard for beginner-friendly error messages. Of course, to get there they also had to simplify Haskell (in particular, get rid of typeclasses, either completely or custom ones). It shouldn't be too hard to carve out a similar subset for Rust, given that like Haskell it's just System F on steroids (just different steroids).
I think many of those are neither feasible to check mechanically nor ultimately useful. I'd rather have something like: * write your first non-elidable lifetime annotation * remove a deprecated item from your code * `#![deny(missing_docs)]` while still compiling at least three items * your first failing doctest * your first use of `?` * your first `cargo deploy`
Added, thanks.
Since everything is a expression in Rust and it has implicit return: fn square(arg: Option&lt;u8&gt;) -&gt; Option&lt;u8&gt; { match arg { Some(val) =&gt; Some(val * val), None =&gt; None, } }
There are quite a few, though it certainly still is quite rare. For instance, Amazon works with TLA, Mitsubishi with FramaC, Airbus with Astree, Facebook developped their own tool, Infer, and so on... Some companies even have formal method at their hearth, such as Prove &amp; Run. At least in France, and as far as I know, these posts are usually occupied by people having done a PhD in Formal Methods and wishing to leave the academy.
Is is possible to write a macro which returns `Option&lt;(TUPLE)&gt;` if all passed values to the `ok_tup` macro are `Some` values? macro_rules! ok_tup { // can be turned into varadic args ($($x:expr), *) =&gt; ($x1:expr, $x2:expr) =&gt; { // how to convert ↓ to generic code of N Some values? if let (Some(a), Some(b)) // generic version = ($($x,)*) = ($x1, $x2) { // how to use the inner value of the generic Some values? Some((a, b)) } else { None } } } let a: Option&lt;(i32, i32)&gt; = ok_tup!(Some(1), Some(2)); // works How to write a generic version of the above code, a solution, a no-its-not-possible or code-hints where to learn more would be appreciated.
I'm glad to hear that. Our electronics development team is currently producing the prototypes of the next revision. Once I got the current CMSIS-based firmware running, I'll happily contact you for further information. I assume it makes sense to have a clean design of the USB stack so that it can share code among different device types easily, and in the best case efforts can be shared with usage in Tock OS. We're using serial port emulation only, but if something emerges, it would be good to have it in place for other device types as well.
That's the Java way of using mutexes. In the JVM, any object can be a mutex, and you can acquire the lock using `synchronized`. For example, synchronized(map) { map.put(key, value); } 
Heck yeah it is, and intentionally so. Thanks for the analysis.
Only issue I have with rust is the occasional rightward-drift issue. nesting = bad. it should be avoidable whenever possible.
If you use the RES (Reddit Enhancement Suite) plugin for Firefox or Chrome, you get a live preview. I highly recommend it :) And thanks for the edits, it's much easier to read now :)
Thanks for sharing this! &gt; Rust gets many more commits than Go, but Swift is moving faster I find this part misleading or not meaningful. It is a matter of convention what granularity commits are broken into, and it can't be used as a comparison of progress across projects.
Does cargo publish optimize crates to crates.io? Because I'm about to attempt to publish a binary crate (my first!) and every time I run `cargo package` I get a long build that ends with "Finished dev [unoptimized + debuginfo] target(s) ...". The [documentation](http://doc.crates.io/crates-io.html) doesn't seem to mention this, and this particular crate really does need a release build. `package` doesn't seem to take any sort of `--release` flag or anything, so I'm pretty confused right now. EDIT: Spelling
I've noticed a *very big* push to make getting involved in the project easier. I know it must be draining on the core team to go out of their way to help people when it takes real time away from other projects, but I very much appreciate it. Keep up the good work. :)
&gt; you can't directly get an allocation without some kind of ownership semantics in place To be needlessly pedantic, it's that you can't *use* an allocation without some kind of ownership semantics.
Crates.io stores source code, not binaries, so it doesn't matter. I guess `cargo package` is just testing to make sure your code compiles. `cargo install` does a release build.
Very, very impressive! That's a hell of a lot of formats you've got there... Will definitely try it out when I can find the time.
But that 2-3 months will be going toward full time employees producing little work... although I suppose the new employees wouldn't start working on the main application until they were familiar with the previous code base, which could take a few months. Either way though, the amount of time needed to learn Rust would be difficult for anyone managing hours to determine. I've had experiences where a particular employee would take a 32 hour task in an agile setup - and realize it'd take maybe a day - but still manage to stretch the time they took to do it to get some lighter work for a week. In that situation this person was creating a demo in a web framework no one else had experience in. Yeah... eventually they were let go. That situation might be a bit excessive, but that employee just took advantage of a variable-length task and the teams lack of knowledge on the subject (since hours in this case were determined by the team working on the given project). Managers, even on a relatively nice budget, would certainly fear the prospect of having multiple full timers working on multiple variable-length tasks. The *potential* cost is higher than it needs to be. And the benefits aren't really clear until the project is further in development. Still open for debate though, if you wanted to follow up. 
&gt;Rust gets many more commits than Go, but Swift is moving faster A large proportion of Rust commits are bot-made derivatives of other commits. For example: Auto merge of ... Rollup merge of ... I'm actually not quite sure what these auto/rollup merge commits are for, they do make changes a bit harder to track. Also, individual commits can be quite low-level and not indicative of meaningful units of change, especially as some projects and contributors prefer to squash commits, and others do not. I think a better metric would be merged pull requests, although it's also hard to compare to Go as Go doesn't accept pull requests via Github.
&gt; I know it must be draining on the core team to go out of their way to help people when it takes real time away from other projects It can be, but the key to remember is that the effect is greater, in the end. I used to say that I liked being a teacher because even if I could write a ton of code, if I taught 30 people how to code each week, the code they wrote would be far, far more than I ever could. Docs are very similar, IMO. It's the same with encouraging contribution and mentoring new people. Yeah, it slows *me* down at first, but if that means that the person I'm working with contributes too, now there's two of us. Then three. Then four... far more can get done than if I just said "nevermind I'm gonna do this work."
It may be was not a bug, right. Just on first try by unexperienced user the same sequences of commands did not have same success/failures on Windows vs Ubuntu. 
Looks great! I would strongly urge you to define your own error type (that impls `std::error::Error`) instead of returning a `String` for an error in your `decode` function: https://docs.rs/rawloader/0.32.0/rawloader/fn.decode.html --- Even if the error type is just a wrapper around `String`, so long as you keep that private, you'll be able to expand your error type in the future without any breaking changes.
The RFC has officially re-entered its final comment period (the previous one having been belatedly cancelled after receiving so many comments... which is part of the point of having final comment periods!): https://github.com/rust-lang/rfcs/pull/1859#issuecomment-302066445
It's not really different. It's just that the people that developed the PTX backend probably didn't write the logic to handle 128-bit integers. &gt; (Also, can you use extprim or something?) No we don't necessarily want to use 128-bit integers; it's the core crate what's using 128-bit integers and all programs link to that crate. And core won't use extprim because it's already using the native / rustc implementation.
6) Double check you're posting on the correct subreddit. You want /r/playrust 
`cargo test` builds a bunch of different targets. Are you just trying to see some expanded code in some tests inside your crate? If this is the case you can do `cargo rustc -- --test -Z unstable-options --pretty=expanded` (notice `--test` is after the `--`) which has rustc build the tests in the crate as well.
That's the x-axis (I think). The y-axes can be described by the graph headers.
&gt; let val = if let Some(val) = arg { val } But why? I'd rather early return a bunch in the beginning of the function. In fact, I'm surprised there isn't sugar for this already.
I've been thinking about setting up Diesel with Rocket so this is really helpful, thanks! I'm wondering - is there any standardized way to host documentation alongside Rocket? Like, in the Python world, we have Sphinx (among others, ie, Swagger) which loads endpoint docstrings and mounts it to /docs with custom formatting which is really nice for developers to use. Something like rustdoc but instead of focused on rust code it'd be oriented around Rocket endpoint metadata (method type, content-type, parameters, URL, etc)? Edit: Put in a feature request for it: https://github.com/SergioBenitez/Rocket/issues/297 :)
Haha, you are right! I will delete this and instead post a link!
`malloc`. The heap. Allocating means reserving and using space on the heap. That's not the magic part, that's just how smart pointers like Box work.
Oh, thank you for you reply. Your advice looks for me pretty well. I will improve 'docs' and think about "generalizing" the API as you suggest. 
It's worth noting I'm running `cargo +nightly clippy`. Otherwise it's complaining about a missing .so file.
Also consider using the errorchain crate to make your errors.
Yeah if nightly isn't your default, that's what you should be running. Although.. Have you tried `cargo +nightly build` too / is that what you're already doing?
I'd go a step further and use Terraform.
That by itself didn't seem to solve the problem, but I've now fixed the CSS to use flexbox instead of trickery to do the columns -- it should be better if you refresh.
LGPL was not designed with Rust in mind, where all the crates are usually linked statically. That's why LGPL is less popular in Rust than elsewhere. In open source work is usualy considered not derivative if it is not line-by-line translation from other language. Otherwise any kind of work would have a good chance to copy someone elses idea and we would not make any progress with this kind of beurocracy.
[removed]
* you can `let` multiple bindings with parenthesis, e.g. `let (mut x, mut y) = (y_amp.0, y_amp.1 - 1)` * your `color_mix` method suffers underflow (at the `-`) and truncation (on the `as u8`). Using wrapping methods may be a good idea (and would let you stay in `u8`, too).
&gt; I haven't heard of anyone using VS Code on Windows :D I use VSCode on Windows :) ...and linux and macOS. It's replacing vim for me as my default cross platform editor/IDE.
That's in fact not what I'm doing - and that gives me the same error as clippy. EDIT: [Image](http://imgur.com/CgLWy9D)
Aren't macros better suited for compile-time "evaluation" be it integers, floats.. shouldn't really matter imho.
Seems like an obvious thing, but thanks.rust-lang.org still doesn't do this for some reason.
&gt; Chances are it already supports whatever camera you care about (and plenty that no one does) as it currently supports 442 different camera models across 17 different manufacturers. oO This community is mad ;)
&gt; In open source work is usualy considered not derivative if it is not line-by-line translation from other language. Otherwise any kind of work would have a good chance to copy someone elses idea and we would not make any progress with this kind of beurocracy. Sadly that's not the way lawyers and judges see it. Just look at the mess oracle has brought google in and this was just for API headers. 
Actually, "0.5" matches all 0.5.X versions ;) Anyways, yeah. `cargo update` did it! Thanks a lot :D
Golang crosscompile is better than being tied to LLVM ? really? Go requires a runtime you know, so you have to implement it in any platform that you want to port it..(not just a compiler backend) C compiles on platforms where the compiler backend is available(gcc/llvm). Since it is easier to work with llvm people prefer to use llvm to provide the backend.
This is awesome, and I hope it makes rapid progress. This would finally bring together the best of both worlds for my current server languages of choice (C++ and C#) and be a tipping point for my personal RoI estimation on using Rust in production. On the C++ side I use stackful coroutines as a stopgap measure while waiting for `co_await` to land in production compilers, but the stackless and potentially alloc-free execution model combined with useful borrow semantics would yield the holy grail of safety, usability and performance.
&gt; Actually, "0.5" matches all 0.5.X versions ;) I know, but you probably want cargo to pull `0.5.1` for everyone else who tries to build your crate, so they don't run into the same problem. (I'm not actually sure when cargo uses the cache instead of trying to pull the latest version available, but I think at least sometimes it should make a difference)
That's a valid reason. Any way to make it every version 0.5.1 or higher?
Is async/await planned to be a feature unto itself or built on coroutines like python? Coroutines are what have me really excited: easy iterators, state machines, and async/await.
Interesting. Any idea how this compares to &lt;https://github.com/erickt/stateful&gt;?
Yes, Boost.Context and a custom scheduler, with some additional utilities like a custom coroutine-blocking interface over `libpq` non-blocking mode for database access, one for protobuf-based rpc etc.
Colleague already did disk usage earlier but still needs to update it to the current interface version. If you still want to work at battery, take a look at how to calculate remaining time. I thought it'd be nice to switch between remaining time and percentage left by clicking, but remaining time calculation from the kernel interface depends on what units the kernel provides (energy_ and charge_ apparently differ). Always try to read directly from the kernel, e.g. /sys/class/power_supply/ in this case. I'll be idle today btw, so don't worry I won't get ahead of your work for now.
Awesome, thanks for the pointer (heh). I'll try it out with my BMP and see if it goes smoothly.
Good job on going the extra mile and taking sRGB correctness into account as well.
Seconded on Terraform. 
1. Compile: In the `target` subdirectory of your project 2. Download dependencies: In a user-specific dir, e.g. `$HOME/.cargo` on Linux 
Sorry, but I removed this comment. We don't want negative drive-by criticism of other language communities here.
Looks like nice and readable code. There are repeating patterns with Result/Option that you can simplify a lot using the right combinators: let height: f32; match matches.value_of("height").unwrap().parse() { Ok(h) =&gt; height = h, Err(e) =&gt; return Err(format!("Invalid height: {}", e)), } can be written as let height: f32 = matches.value_of("height").unwrap().parse() .map_err(|e| format!("Invalid height: {}", e))?; Similarly, let examplename = if matches.is_present("example") { Some(matches.value_of("example").unwrap().to_string()) } else { None }; is just let examplename = matches.value_of("example").map(|s| s.to_string()); And finally, in main() you just need if let Err(e) = ArgValues::from_cli().and_then(|av| runner::run(&amp;av)) { error!("{}", e); } 
Thanks
I come from a C# background where I've used async/await extensively. Lately I've been building some code in rust that very heavily uses futures and tokio to the point where everything is just the composition of futures and streams, until you reach the entry point of my application where the combination of multiple futures (each one representing a distinct "process" within the application). While I'm happy with the code in general, the rightward drift is an issue I'm constantly combatting. Having this as a part of the language in some way would be fantastic in cleaning up my code and making it easier to read. The other real advantage I see here is that it looks like it makes unboxed futures for you. Right now, without something like this or ` impl Trait` I either have to resort to boxing futures (especially with combinators) or writing my own concrete future types. I've resorted to writing a bunch of macros to ease the creation of boxed futures and macros, while only writi my own concrete futures in very specific scenarios. Needless to say, seeing that this exists makes me really excited for the future of asynchronous rust. Edit: Looking at it, looks like it relies on `impl Trait` to work. So it's using that as an underlying portion of the macros to do unboxed futures.
Thanks for sharing! I'm not sure there are guys only here though. Be inclusive :)
A good question! This implementation gets to cheat by [using a custom branch of Rust that implements generators](https://internals.rust-lang.org/t/post-rfc-stackless-coroutines/5021/11?u=alexcrichton). I believe @erickt's branch is a manual implementation of generators (state machines) via a procedural macro, but this implementation leverages the compiler do to all the heavy lifting. The `#[async]` implementation itself is actually quite small! So in essence they're built on the same fundamentals and are achieving the same goal, but `futures-await` cheats with a custom compiler leveraging the work of @Zoxc to make it much easier to implement `#[async]`. This also means that it's quite usable as-is today!
Where can I find the RFC for generators? I want to see if instead of using the `fn*` syntax to indicate that it's a generator, we could use `gn`.
I was wondering about generators and whether or not if they'd make their way into the nightly version of rust. I've been avoiding nightly because I want my project to compile on stable, but this is something big enough to make me reconsider that decision.
Ah thanks! I love these kinds of minor improvements.
The "runtime", is packaged into the executable. It's had more first class Citizens than rust. That's just reference compiler. Gccgo is much more portable than rust since you can easily bootstrap it either a cpp compiler. In GO, all the bsds are a first class Citizens​. I can build BSD executables on my windows box. Maybe in theory rust us more portable, but in reality that is not the case. &gt;C backend Yes but LITERALLY every architecture and every OS has a c compiler. No hacks like rust. 
I hope Zoxc's fork can just be merged into rust-lang/rust as fast as possible, even under the knowledge that it is a temporary solution.
[This](https://github.com/rust-lang/rfcs/pull/1823) is the original RFC but the discussion there has pretty much died out. The discussion of that RFC is continuing [in this i.r-l.o thread](https://internals.rust-lang.org/t/post-rfc-stackless-coroutines/5021/18).
Map isn't heavy. Map is light. Map is bread and butter. Don't fear its use.
As far as I can tell, translation of programs from one programming language to another is handled the same as translation of other copyrighted works from one language to another, like books. So you do need a license from the original creator of the program.
A few comments: * I would make the `decode` function take an `R: io::Read` instead of a path, and rename the current `decode` to `decode_file`. * For maximum performance, don’t buffer internally if possible. Require `io::BufRead` instead, because the user might provide a buffered reader already, and then the double buffering is pointless. * [Cargo-fuzz](https://github.com/rust-fuzz/cargo-fuzz) is a great tool to make a crate like this more robust. I created a fuzzer target and found an index out of range crash already when seeding it with a NEF file. I’ll submit a pull request with the fuzzer target.
&gt; A few comments: Thanks a lot for looking at this in such a detailed fashion, I really appreciate it. &gt; I would make the decode function take an R: io::Read instead of a path, and rename the current decode to decode_file. This already exists internally it's just not exported yet in the public interface. &gt; For maximum performance, don’t buffer internally if possible. Require io::BufRead instead, because the user might provide a buffered reader already, and then the double buffering is pointless. Also true, I assume you mean have a single interface that takes io::BufRead? Note that what I will always do anyway is read until the end into a buffer. All the parsing is based on a memory region not a stream for performance and clarity and also because I need a few extra zero bytes at the end added on (currently 16) so that I can just not handle the special case of the end of the buffer in the bit pumps. Instead zeroes are read which work correctly. &gt; Cargo-fuzz is a great tool to make a crate like this more robust. I created a fuzzer target and found an index out of range crash already when seeding it with a NEF file. I’ll submit a pull request with the fuzzer target. This is deliberately the case and I probably will not accept a PR (edit: for the bugfix the fuzzer target is awesome thanks!). This is a contentious point though so let me go into it in more detail. What you got was almost surely not a crash if you used the normal interface, only the message that there was one and a correct return from the binary. Binary formats are extremely complex and guarding against all possible out-of-buffer reads, overflows and so on makes for really ugly code. I've gone down the path of fuzzing in C++ and it's a very long rabbit hole. It is almost surely impossible to fully fix all cases as there are too many combinations of paths and inputs. So my solution is the following principles: 1. Hangs are bugs and fuzzing for those makes perfect sense (and I haven't yet) 2. Camera files can't crash because they're then broken and you don't get an image so they're regular "camera X not supported" bugs 3. Artificial files that cause a panic are not a bug So that 2 and 3 are handled gracefully the library wraps panic, unwinds and returns an error. See here: https://github.com/pedrocr/rawloader/blob/master/src/decoders/mod.rs#L438-L450 I know this practice is far from consensual, and I've discussed it on #rust before. From my experience of fuzzing C++ and the resulting code uglyness I'm convinced this is the correct solution. In this case there is a very well defined point to unwind to (did this file work or not?) that works for all callers. The alternative is to try to solve all bugs, fail because that's impossible, and thus have a library that will in some cases take down your whole program on a bad file. You can't cause memory unsafety but you can cause denial of service. Instead solve all that at once.
Looking at the example on http://gtk-rs.org/docs/gtk/struct.DrawingArea.html, it looks like you `connect_draw` on the `DrawingArea`, and use the passed Cairo context to do your drawing. Seems pretty low-level. Something like https://developer.gnome.org/goocanvas/1.0/ is probably easier to use, but doesn't seem to have bindings yet?
That is what I am doing I think, however the function I connect runs only once?
You can take a look [here](https://github.com/GuillaumeGomez/process-viewer/blob/master/src/graph.rs) as an example.
Because it's hard and not usable. Integrating into nightly would mean that the ecosystem could foster while a proper solution comes up.
thanks a lot!
&gt; In that case, would it be possible to take an &amp;[u8]? If the data is in memory already, a copy can be avoided. It might be worth handling end of buffer for that. I know, and I struggled with that for a while but I couldn't think of a good way to take advantage of that. The benefit of not having those extra checks in the hot path is too high to not be worth just doing a memcpy which is extremely fast. It will probably make sense to have that API anyway for convenience and just do the copy. &gt; I’ve done it for Claxon. Of course fuzzing for a long time is no guarantee for the absence of bugs, but it did find many bugs that I fixed. Yep, been there, done that :) &gt; My experience was that many panics came from nonsensical length values in headers, causing index out of bounds, and putting a check on those was not too bad. Yeah, catching those is probably not too painful, I just haven't bothered (see below). &gt; Another source of many panics was arithmetic overflow. In a few cases these were legitimate bugs, in many cases the files were invalid and I replaced them with wrapping arithmetic, which is indeed a bit uglier than the regular operators. (Flac has embedded checksums, so producing garbage rather than an error is ok, because the checksum verification will fail before the garbage is returned.) This is the real kicker. Raw formats are incredibly finicky and diverse in the way they implement compression. A lot of them are extremely poorly designed (compress poorly *and* decompress slowly). If your start adding checks everything slows down. If you do wrapping arithmetic at best you get garbage but in a lot of cases you will just cause a weirder panic elsewhere because the decoding path is very data dependent. &gt; I understand your point, and I think catching panics it is reasonable in this case, but it might still be worth fixing the low hanging fruit to distinguish actual bugs from invalid files. Totally agree. For TIFF parsing for example I was expecting to actually need it as a usable tactic is "just parse whatever you can and as long as the tags you really care about are caught if other stuff is pointing to INT_MAX just error out and ignore the tag". As it turned out valid files are surprisingly well behaved in that respect so I didn't need to catch those specific errors explicitly so far.
"Guys" is usually either sex nowadays: http://www.dictionary.com/browse/guy
In a sense, yes, you could call that "do notation for continuations", but the implementation actually allows all of Rust's control-flow, in a way that would be very cumbersome to do with callbacks - just imagine expanding `await!(...)` in a `for` loop to `.map(...)` - you end up reproducing the state machine transform that generators do.
Oh! Cool!
I don't really understand what the big deal is with async/await. Lots of people, here and elsewhere, mentioned how it's a big show-stopper for official take-up of Rust in their day-to-day workflows. Why? What are the alternatives to async/await? Why aren't they sufficient?
My plan is to let you set an Environment variable $GITHUB_API_TOKEN
It basically boils down to ergonomics in my mind. The async/await syntax does not fundamentally enable any new feature that was not previously available, it's just making it way more ergonomic to use what's already there. It may help, though, to try to draw an analogy. If you're familiar with error handling in Rust you're probably also familiar with the `?` operator. Can you imagine a world with out `?`? It may actually not be that hard because you've still got `try!`. In many ways the world with `try!` is *very* similar to the async/await world. An "async" function is just one that returns a `Result`, and `await!` is just `try!`. Now as a thought experiment, imagine that you don't have `try!` or `?`. Not only you don't have both of these but you *can't implement them yourself* as well because they're impossible (ok, impossible for futures, not impossible for results). This means that when you're working with `Result` your *only* recourse is combinators like `map`, `map_err`, `and_then`, etc. You could manually write a bunch of `match` statements as well but things get very verbose very quickly! So in a sense, `try!` made error handling at all bearable in Rust, and `?` is like a supercharged `try!`. The async/await notation is very similar. You *could* use combinators with futures today and get by (also writing manual state machines), but it gets pretty unwieldy pretty quickly. Small examples are fine but larger functions really show their age. An example of this is [this sccache function](https://github.com/mozilla/sccache/blob/48f1196f490b3f01a63fe2fba2f40144b51aaba2/src/compiler/compiler.rs#L99) which I later [translated to async/await](https://github.com/alexcrichton/sccache/blob/927fe00d466ce8a61c37e48c236ac5fe82cb6280/src/compiler/compiler.rs#L110). The former hits a lot of rightward drift, and while still somewhat readable was relatively difficult to write. The latter, however, has no rightward drift and is much easier to write/understand. The best part about this is that the latter form is also faster! (no boxes, etc). My best advice to understand the need for async/await is to basically try to get as far as you can *without* them. If you're not working with futures you can emulate this with `Result`s in Rust by forbidding yourself from using `try!` and `?`. It's not the exact same but is relatively close.
Yeah, but that's just a simplified example. Cases I've seen in the wild like this when helping out are not always so.
You can statically link to LGPL libraries. You just have to provide a method for the user to re-link your software with updated versions of the LGPL libraries. This usually means providing .o files (compiled object files) for the non-LGPL parts and a script or documentation to do the linking.
Sounds like calling this a "proof of concept" wasn't sufficient to show it's a sample and not production code. I recommended Cloudformation in the `Demo vs longer term infrastructure` section of the post. Any thoughts on how to make that more visible? Maybe a note near the beginning calling out this is a sample walkthrough and to see the `Demo vs longer term infrastructure` section for more information for a production-ready setup?
Sure, sure, it's a nice idea too! Nice symmetry. I just put forth why I personally don't prefer it :)
Actually I took care to only write mechanically checkable achievements. * The first four are easy. * Unsafe code can be minimised line by line similar to automatic source code reduction, there's a tool for C that minimizes segfaults. It's only heuristically, but... * 6 essentially boils down to use `#[repr(C)]` and finding bindings in elf, which is rewriting the linker. This is a lot of work for a stupid archievement. * This one I find interesting. It changes the API significantly but not an application. Mutate the AST by rewriting `borrow_mut()` to `get_mut()` and adding mutation. Remove all `borrow()` and `get_mut()` cals and remove the `RefCell` wrapper. * Easier: mutate and fix typing error until fixpoint. If this stops, don't reward the archievement. * There are standard code metrics that can be copied from C/C++/Java. I don't think achievements should be useful. There should, however, be a lot of achievements. Are they global or specific to a project (or both?). Let's write some more: * Use an external crate, use it locally. (I just needed this) * Use a specific crate (quickcheck)? Use the crate of the week for x weeks? Useless on it's own, useful for exploring the ecosystem. * Add your own build steps to build.rs * Implement operator overloading (one archievement per operator?) * Use wrapping addition. * Order floats / sort floats. Don't know if this one is possible. 
omg I can't believe I didn't make that association. I had static in my mind as being like const in C, and const in Rust as being like define in C, but static in Rust can be used like static in C too lol. Hm, but yeah it does introduce thread unsafety which is what I was thinking may happen in my use case, but in Rust it just makes it explicit that it isn't safe. Thanks I feel kind of dumb that I even asked this question now though heh. 
It seems like it will work similar to static in C if it is used inside of a function, but it is thread unsafe. 
I just put them in lib.rs. I suppose if you only use an extern crate in a single module, you could put it in that module's file instead, but I think it's better to have them all defined in one place.
Yeah usually you'd have them all in `lib.rs` between crate documentation (`//! ...`) + crate attributes (`#![...]`), and your `mod`s + `use`s. I don't think I've ever seen tests being at the top of a file. Aren't they usually at the bottom (if they're inline at all and not in a `tests` directory)?
I'm trying to build a little lib to handle datasets and glue external data sources (i.e., CSVs, so [rust-csv](https://github.com/BurntSushi/rust-csv)) to ML libraries, i.e., [rusty-machine](https://github.com/AtheMathmo/rusty-machine). I'm using [this dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income) during development for testing/sanity checking. I define a struct ala struct Person { age: i64, education: String, ...etc } and then `impl` my fancy new trait and add all the data to the `Dataset` struct, which just holds a `Vec` of implementors of that trait. `Dataset` has a `sample` method which returns a new, smaller dataset. However, when I try to test with let dataset = Dataset::new(items); let sample = dataset.sample(0.1); println!("{}", dataset.size()); println!("{}", sample.size()); my code won't compile because `dataset` was moved when I made the sample. It doesn't seem like I can `derive(Copy)` on `Person` because it has a `String` field, but if calling any method on this struct nukes the old version, my code doesn't seem like it could be very useful. Also, it would apparently be fine if the `Person` struct only had `Copy` values. What's the right way to handle this? Edit: so changing it to let sample = dataset.clone().sample(0.1); works but this feels less than ideal... I wish I could handle the cloning in the lib. But then I guess implicit cloning is of the devil? So is this the rusty way to do it?
Well, BSDs not being first class citizens is about the CI setup in rust. In reality all i need to is write a compiler backend and the rest will run on my hypothetical architecture(i don't need an os). You can't really run Go without an os unless you put considerable effort into porting runtime. LITERALLY every architecture does that because gcc has been around forever. llvm is not a hack... it's relatively new hence less supported platforms. And btw newer architectures also have llvm support.
&gt; The value `x` goes out of scope at the end of `calculate`, but we don't know when it started living, since it comes from the caller. `x` is a value, not a reference, so its lifetime strictly begins when `calculate` is entered and ends when it goes out of scope. The object that was copied (or moved, in the case of non-`Copy` types) into `x` when `calculate` was invoked is an entirely separate object whose lifetime is orthogonal to `x`.
As long as your RNG is vaguely good, then 2 UUID's would work fine. Would mean you don't need to keep track of any state. Or maybe one UUID and the system time to as high precision as you can get it, so even if the RNG completely fucks up, as long as your time doesn't repeat or you call quick enough to do the same interval it works fine.
This is a cool paper from the recent HotOS XVI conference. I especially liked the information flow control portion. Hooray for strong type systems!
&gt; I know, and I struggled with that for a while but I couldn't think of a good way to take advantage of that. The benefit of not having those extra checks in the hot path is too high to not be worth just doing a memcpy which is extremely fast. It will probably make sense to have that API anyway for convenience and just do the copy. Taking a `Vec&lt;u8&gt;` would be the "perfect" middle-ground: the decoder can still push the bytes at the end as appropriate, and it doesn't need to restrict itself to only reading specific files from the filesystem (which, if you're going to stick with, might be better to either take a `File` directly, or at least take a `AsRef&lt;Path&gt;` like [`File::open`](https://doc.rust-lang.org/std/fs/struct.File.html#method.open)). It seems to me that a library for decoding RAW data doesn't need to be doing I/O, especially if the only I/O is just reading directly into a buffer. &gt; If your start adding checks everything slows down. Note that the panics for bounds checks already come from runtime checks. I suspect the fastest way to parse will probably actually to *disable* panics (with `-C panic=abort`) and do error-detection/failure-recovery the non-panic way, because that is more understandable to the optimiser. Additionally, two smaller points: - avoiding panics for error handling also means fuzzing works better for finding bugs in the mishandling of *valid* files, - using panics for error handling means the library can't be used in contexts that disable panics.
They're right that guys is mostly​ gender neutral, but I appreciate you fighting the good fight.
Agree so much. I didn't have a lot of experience doing low-level programming prior to learning Rust (know minimal c++) but I wanted to try. Everything is so great.
It's also static. Answering your confusion in the comments: C static means two things (more like 10 actually). On variables, at the top level, it means "give this global variable or function a file-local mangled name". Rust has an actual module system so this isn't a problem. At the function level, it means "this is a persistent local variable" (usually placed in bss). In C you can also have a top-level variable which you don't need to mark static. That will be a persistent global variable. You can mark it static if you want it to be file local mangled, as mentioned before. Const is an orthogonal axis, just means you can't mutate it. #define gives you compile time substituted constants. In Rust, "persistent variable" is done uniformly with `static`, be it function local or global. We have a module system so the file-local problem doesn't exist. Things are constant by default but you can opt in to mutability via `mut`. References have a built-in constness, C just does it the opposite way (mut by default). So Rust doesn't need C's const keyword. Rust's const keyword is what C defines do, compile time substituted constants. But typed. So rust const is C define. Rust static in a global context is a C global variable. Rust static in a function local context is a function local C static. Rust does not need C's const, it uses mut. 
I hope this turns out to be an easy question! I'll give the motivation, in case I'm deep in X-Y problem territory. Motivation: Using error-chain, I wish to inspect my error chain, identify errors of a certain hue, and handle them differently from other errors (specifically, only print certain kinds to the console if the program is explicitly flagged as verbose mode). Approach: I'd like to use downcasting to inspect the type of error I have on hand and make my decision that way. I haven't been able to come up with any other approach that lets me get something useful off the `&amp;std::error::Error` I get from the iterator. Problem: All downcasting operations are defined in terms of having a `'static` thing. Given an instance `e: my::Error`, the references returned by iterating are not `'static` and so I can't `downcast_ref` to inspect if it's got my property of interest.
It's no better in C++.
This is awesome! Thanks for posting this -- I'm excited to show this to some friends I have that until now have been skeptical of Rust as the "new kid" on the block.
There were numerous discussion on the topic of monads and rust. Yet I have not seen anybody talking about continuations although they are much better fit for imperative programming. If you are **not familiar with monads** you should watch the [video mentioned in the article](https://m.youtube.com/watch?v=449j7oKQVkc&amp;time_continue=9) first. You might also find [some examples](https://philipnilsson.github.io/Badness10k/posts/2017-05-07-escaping-hell-with-monads.html) interesting. If you know monads but you wonder how can they be useful in imperative programming language you should watch the video anyway ([start at 9:48 instead](https://youtu.be/449j7oKQVkc?t=588)).
Hi! I've been using conrod a bit - I'm by no means an expert, but I can try and answer questions. For a tutorial, I don't think there is anything great yet. There is code though: I learned from the ones in the repository itself, in the `examples` folder. Any one of the ones in here should work with the latest conrod: https://github.com/PistonDevelopers/conrod/tree/master/examples. I started out just by copying the `canvas.rs` one into a new cargo project along with the `support/mod.rs`, then tweaking it until it compiled again outside the directory. My current code isn't too advanced either, you can see how the structure of https://github.com/daboross/conrod-testing looks if you want. Hope this helps! Again, feel free to ask for more info on anything, I hope I can be a useful resource.
there is a RFC on stackless coroutines, which is a form of delimited continuation. So it seems there is some work in the progress already.
I am using Conrod for a major project and started out as a Rust beginner as well. I have no regrets. So there are 2 major sections of conrod from a practical sense. The first section is the window setup and event control. This has recently undergone some major (IE breaking) changes under the hood. Winit Glium is the preferred backend and works down to OpenGL 2.1. I basically used the example code and my graphic thread is not much different from the example even with the extra commands and channels. The second part is the UI building. In the examples this is all contained in the support/mod.rs. This is the part that has all the widget builders and is where the magic happens.
They are definitely not just syntactic sugar. If `Iterator` had `Item` as a type parameter, you could have two `impl Iterator`s for the same type (e.g. `impl Iterator&lt;u8&gt; for MyType` and `impl Iterator&lt;char&gt; for MyType`). &gt; But we could always replace associated types with generics and write a bit more code to achieve exactly the same. You might actually be right about this, I'm not sure. I'm no type theory expert \^\^ &gt; We can omit to bind certain generic types if we don't require to know them in the using code. I think you misunderstood something here (or maybe I did). But you can refer to an associated type of a generic type very easily as `Trait::AssocType`. For example: fn foo&lt;I: Iterator&gt;(it: I) -&gt; Bar&lt;I::Item&gt; { ... }
You get a guarantee that for every type that implements the trait, there is *only one* type for the associated type. In other words, if trait methods are functions overloaded by impls, associated type definitions are functions over types, also overloaded by impls. The transformation you've found (like many others before) has nothing to do with associated types or really even type systems and their underlying theories. Instead of having `f(x)` use `g(x)` internally, you *totally can* replace the definition with `f(x, gx)` and all the calls with `f(x, g(x))`, and use the new `gx` input instead of `g(x)`. If you do this across all functions using `g`, consistently, you *will* get the same results. This aplies to pretty much any notion of "function" I can think of. You can even repeat this, until all calls to `g` "bubble up" to a point where they can be fully evaluated. You have now gotten rid of `g`. This way you can remove *any* kind of associated item - i.e. not just types but also methods. But note that `f` is now more general. This can be desirable in some situations (e.g. `T: From&lt;U&gt;`) and undesireable in others (each iterator type always having exactly one specific element type). So associated types are as much sugar as passing down methods instead of obtaining them from a trait impl for a type would be, in that, yes, you can do that transformation, but the resulting *abstraction* is not equivalent to what you started with, even if any instance that worked before still works after.
&gt; Taking a `Vec&lt;u8&gt;` would be the "perfect" middle-ground: the decoder can still push the bytes at the end as appropriate, and it doesn't need to restrict itself to only reading specific files from the filesystem (which, if you're going to stick with, might be better to either take a File directly, or at least take a AsRef&lt;Path&gt; like File::open). It seems to me that a library for decoding RAW data doesn't need to be doing I/O, especially if the only I/O is just reading directly into a buffer. Reading from a file is just a convenience. A `mut Vec&lt;u8&gt;` is also an option but you don't always have that when you have a `&amp;[u8]`. Maybe another extra entry point to add. &gt; Note that the panics for bounds checks already come from runtime checks. I suspect the fastest way to parse will probably actually to disable panics (with -C panic=abort) and do error-detection/failure-recovery the non-panic way, because that is more understandable to the optimiser. The problem with that is that I would have to make sure I replicate every rust bounds/underflow/overflow/etc check. It's way too error prone. And rust will add those checks anyway. &gt; avoiding panics for error handling also means fuzzing works better for finding bugs in the mishandling of valid files, Valid files are surprisingly regular in their construction, once they work they rarely have too many other issues. &gt; using panics for error handling means the library can't be used in contexts that disable panics. Well it means it will panic with broken files but still work fine with valid files. Not ideal I agree. I haven't seen a case where disabling panic makes sense though. When does it make sense to do it?
:p It's pretty annoying though. They mention *session types* in the paper, which are a way to encode state machines. Encoding state machines using one type per state and one function per transition is a good way of leveraging a static type system to avoid applying the wrong transition to a given state. Most static languages support it. With its affine types, Rust goes one step further: you are guaranteed that after transitioning from `a`, you cannot transition a second time because `a` is consumed, which is pretty neat. What Rust *doesn't* solve, however, and which would require linear types, is that you have no guarantee to reach a final state. From the type system point of view, all states are final. The work around is to manually implement `Drop` for the non-final states and panic; but it's a bit of a bummer :(
Just FYI, this one of the clearer explanations of "why Rust's affine types are good for state machines", AND it explains the drawback vs linear types. This should be prominently available somewhere else, because it also gives people enough information to start doing their own research (i.e. "Oh, OK, it's about not accidentally repeating transitions! I wonder where that has caused problems before" / "can I write a toy example demonstrating this".
Thanks a for a great explanation, but I am sill a bit unsure about the precise role of associated types in Rust. Are there any other semantical differences than the single-`impl` restriction? Is this restriction useful? Is the type `Iterator&lt;Item=u32&gt;` any more useful than a hypothetical `Iterator&lt;u32&gt;`? The Rust book mentions a single reason for associated types: we don't need to mention type parameters all over the place. A distance function on graphs with type parameters mentions `E` twice and unnecessarily: `fn distance&lt;N, E, G: Graph&lt;N, E&gt;&gt;(graph: &amp;G, start: &amp;N, end: &amp;N) -&gt; u32 { ... }` but this seems to be just a syntactical difficulty. If type parameters didn't have to be explicitly listed (as is the case in Haskell), the function no longer seems awkward: `fn distance&lt;G: Graph&lt;n,e&gt;&gt;(graph: &amp;G, start: &amp;n, end: &amp;n) -&gt; u32 { ... }` So are associated types used pervasively only in languages where all type parameters are explicitly listed in angled brackets as a type parameter elision mechanism? You mentioned that `g(x)` is defined in different places but in the majority of cases, `g(x)` is a simple type (as opposed to associated functions) and the placement is most of the time shifted by just 1 line: it doesn't seem to matter.
Rust-Intellij at least has simple refactorings already built in.
In the rent a server cloud computing era, no one can afford a garbage collector. C++,rust,and swift will dominate the server space.
It may be that that that implementation is the wrong way to go, at which point it would have been better to leave it out, as opposed to the churn of adding it to the compiler codebase and then ripping it out. Maybe the solution is to have rustup understand multiple custom channels in addition to 'nightly' and 'stable'; at that point you could build this hacked-up rustc and distribute it using the standard toolchain under the 'async' channel.
&gt; Is the type `Iterator&lt;Item=u32&gt;` any more useful than a hypothetical `Iterator&lt;u32&gt;`? You mean like in a trait object? They're equivalent in those situations (since you have to specify all the input/output types). &gt; but this seems to be just a syntactical difficulty. Perhaps ["functional dependencies"](http://web.cecs.pdx.edu/~mpj/pubs/fundeps-esop2000.pdf) (from Haskell) is a better way to come at this. Informally, you could get the same abstraction as associated types by declaring some of the trait type parameters as "output" (as in, they have to be uniquely determined by the combination of "input" type parameters). And sure, you could allow leaving them off in bounds, so `T: Iterator` stays the same and `T: Iterator&lt;Item=U&gt;` becomes `T: Iterator&lt;U&gt;`. This *might* have actually been the first proposal for *something like* associated types in Rust. Anyway, once you have a scheme like this, the syntactic sugar argument disappears. If you extend the omission of type parameters to *all* type parameters, *all* programs valid with output type parameters are still valid when all type parameters are inputs (assuming the "one impl rule" - i.e. if a type is specific enough such that only one `impl` of a given trait applies to it, that `impl` is taken for granted even if it's *even more* specific than the type, and the type gets inferred from it to the necessary restriction). What you're left with the uniqueness property: when you mark a type parameter as output, you're disallowing impls that overlap on *everything else*. That seems like simply a restriction, perhaps useful to unsafe code, but doesn't generally allow you to do anything *more*. In fact, AFAIK (/u/nikomatsakis might prove me wrong), *right now* you can't have *more* flexibility with associated types than with type parameters. If associated types are functions, then doing the `f(x, g(x))` expansion I mentioned earlier is equivalent to a Datalog encoding - e.g. if you're doing crazy computation with associated types, instead of `&lt;A as Add&lt;B&gt;&gt;::Output == C` you'd have `A: SumIs&lt;B, C&gt;`, and if `C` is unknown it can be inferred (not 100% sure here, there could be implementation limitations - but a Datalog implementation should be able to do it). A potential future example of *more* flexibility arising from associated types being uniquely determined by "input" types is [RFC 1672](https://github.com/rust-lang/rfcs/pull/1672) (postponed, hopefully not for long). What that RFC lets you do is, e.g. have two `impl`s of the same trait for the same type, one `where T: Iterator&lt;Item=u8&gt;` and another `where T: Iterator&lt;Item=char&gt;`. *Because* `T::Item` differs, and *because* of `T::Item` being uniquely determined from `T`, that implies `T` *also differs*, which means the `impl`s *can't overlap*.
For me things finally clicked when I read [this StackOverflow answer](http://stackoverflow.com/a/32065644/859279)
&gt; What is the policy on documentation for new features? Will the merge commit come with documentation in the book already, or will that come later, if at all? Features without documentation cannot be stabilized. There's no particular policy while things are unstable. 
Thanks! :)
Thanks for explaining, I wasn't aware of it!
Roughly speaking, `Iterator&lt;Item=u32&gt;` easier to infer than `Iterator&lt;u32&gt;`, because in the former case any type can have at most one `Iterator` implementation, whereas in the latter case a type might have a any number of `Iterator&lt;T&gt;` implementations each with a distinct `T`. Hence the latter is more likely to cause errors such as [“type annotations required”](https://is.gd/C7KVc9).
C'mon. You've been on Reddit for six years. This is [not](https://i.imgur.com/xCPcX1e.jpg) that [complicated](https://i.imgur.com/gw3cMin.jpg).
Thank you! This is actually what made it clear for me too! :) So the key difference (apart from syntactic simplifications) is the uniqueness-constraint!
What exactly do you mean by "another program"? Are you looking for a process with a specific name?
Thanks for your elaborations. Sadly, I cannot really follow all your arguments, because I am just a complete newbie when it comes to Rust. What I understood so far is the uniqueness argument (a type can implement a trait only once). What I don't understand is your explanation/analogy using`f(x)` and `g(x)`. I know about referential transparency of function applications, i.e. for pure functions, we can always replace a call with its value. And I see that when `f(x)`'s definition involves a call to `g(x)`, we can as well take the result of `g(x)` by argument into `f`, like so: `f(x, g(x))`, which effectively makes `f` more general, but not necessarily more useful, because it would also allow for `gx` that were not computed with `g(x)`, which would render the meaning of `f` useless. But what it all has to do with associated types, I simply could not understand... ;)
Well, I mean any program such as Firefox, Skype, or whatever.
Okay. Now the question is, how to get the list of running processes?
In the meantime, I think I spotted a potential analogy to **existential types** (see wildcard in Java). Associated types do not appear in the name of a trait. So if in Rust it *would be allowed to use traits as types* (which to my knowledge is not possible -- only as generic constraints), then we could have something akin of a list of values of mixed types all implementing a common trait, but with different associated types each. Statically, we would not be able to determine the associated types, all we know is their constraints (as defined in the trait), making them "existential types" (i.e. we know they refer to some *concrete type*, but we don't know which one). Still, we could retrieve values of these types, do something with them (as long as the trait and/or the declared constraints allow for it), which would effectively make the type system strictly more powerful than having named generic parameters only.
Okay. I'll check that. Thank you!
In Linux you'd probably list `/proc` and keep anything that's a number, and those will be the process ids. Each of those is a directory, so you could look in each to find things like program names. I'd probably be too lazy and I'd just use `pgrep`, which already does stuff like that (or perhaps it uses syscalls). I'm not sure how to do it on macOS, Windows or any of the BSDs (much less more niche systems like Solaris, Haiku or BeOS), but I'm sure looking it up online would be pretty easy. So no, I don't think you're going to find a nice cross platform way to do it, especially since it's a very niche thing to do.
That's an interesting thought! Thanks for sharing! There are two things that I don't quite get though: &gt; [...] and at every step I would know exactly what type everything is. Really? How would the compiler do that? Somewhere, you would have to add the nodes to the list, and use a different type for every node. The compiler statically only knows that the nodes are of the trait type, not the concrete type used, right? And secondly: Is it really possible to use trait names as types in Rust? I thought they are only allowed as contraints...
Ah, apologies. The analogy was that `f(x)` is like `f&lt;x: Iterator&gt;` with `g(x)` being `&lt;x as Iterator&gt;::Item` so after the conversion `f(x, gx)` is a lot like `f&lt;x: Iterator&lt;gx&gt;, gx&gt;` and`f(x, g(x))` can be considered to be the explicit `f&lt;x, _&gt;` where `x: Iterator&lt;_&gt;` (that last bit makes `g(x)` involve inference - could also be a concrete type written explicitly). 
Ah, now I see it! Thank you! That's basically a compile time function application that produces a concrete type from another concrete type by looking up the associated type in the input type. And now I also see the uniqueness argument, since a function will always produce the same output given the same input, and if we were to make it explicit, we would decouple the output from the input. Can you maybe also look at my self-comment about the analogy to "existential types"? Maybe I am completely wrong there, but I need some expert insight into this...
Nice example! I think that's a kind of meta programming you are doing here. ;)
I got into that in [another of my comments](https://www.reddit.com/r/rust/comments/6cfh2h/associates_types_just_a_syntactic_convenience/dhuftxg/?context=10). *However*, at the end of [this other comment](https://www.reddit.com/r/rust/comments/6cfh2h/associates_types_just_a_syntactic_convenience/dhumt3q/?context=10), I end up realizing that due to our lack of coinduction, you *may* be able to write impls with associated types that are cycle errors without.
Is this relevant to the (current) discussion about /u/acrichto's MVP async/await?
Since the link is a PDF, I'll quote the abstract in its entirety here: &gt; Rust is a new system programming language that offers a practical and safe alternative to C. Rust is unique in that it enforces safety without runtime overhead, most importantly, without the overhead of garbage collection. While zero-cost safety is remarkable on its own, we argue that the superpowers of Rust go beyond safety. In particular, Rust’s linear type system enables capabilities that cannot be implemented efficiently in traditional languages, both safe and unsafe, and that dramatically improve security and reliability of system software. We show three examples of such capabilities: zero-copy software fault isolation, efficient static information flow analysis, and automatic checkpointing. While these capabilities have been in the spotlight of systems research for a long time, their practical use is hindered by high cost and complexity. We argue that with the adoption of Rust these mechanisms will become commoditized.
You can use trait names as types. They need to be behind a pointer. `Box&lt;Iterator&lt;Item=u8&gt;&gt;` and `Box&lt;Any&gt;` work. These are called trait objects. They don't get used as much as static dispatch.
Thanks for the example code. But if we would like to make use of a `NonRoot` struct, we would instantiate its type arguments first. And for the `Tail` type argument, we would again need to specify a (maybe different kind of) `NonRoot`, and so on, effectively producing again a long sequence of nested generic types. The only advantage I see here (by using associated types instead of generic type arguments) is that each such arbitrarily long sequence conforms to a `Node` constraint, which would not be possible without associated types. Is this a correct analysis?
Note that if you want to control other programs, at least for Firefox I seem to remember that you can send commands to running instances via the `firefox` binary (like `firefox -url http://example.com`). Skype might have something similar.
I was just giving examples but it's always good to get a tip, thanks.
Oh.my.god.
Knowing that there's exactly one impl may become an additional benefit in the future, if we ever get disjointness on associated types.
Oh certainly, it's really a patch on a wooden leg :(
You can sometimes work around the lack of linear types (and `mem::forget`) by requiring a return or argument of the final state type, though that depends on how your API is set up.
Isn't Idris garbage collected though? (which means Idris code will be written that assumes GC will ork) But yes, Rust is "more optimizeable" than C/C++ in that sense. Though you can use `restrict` to get similar aliasing guarantees in C/C++ for a sufficiently omnipresent programmer.
&gt; In the rent a server cloud computing era, no one can afford a garbage collector. What does this mean? What does a garbage collector do that ruins things in this case?
To put it a little less theoretically than eddyb, associated types allow you to drop type parameters. Here's a very simple example, let's say you want to write a function that just returns the first item in an iterator, generically: fn first&lt;I: Iterator&gt;(mut iter: I) -&gt; Option&lt;I::Item&gt; { iter.next() } If we didn't have associated types, that signature would have two parameters: fn first&lt;I: Iterator&lt;T&gt;, T&gt;(iter: I) -&gt; Option&lt;T&gt; For a simple function, not such a big deal. But as you build increasingly complex &amp; generic code, this becomes unmangeable because you can never get rid of a parameter. Every type that is 'abstract' in your code has to have its own parameter. This becomes especialy obvious when you have a trait with multiple associated types, like tokio's `Service`. To be abstract over any service, we'd have this: fn foo&lt;S: Service&lt;Req, Resp, Err, Fut&gt;, Req, Resp, Err, Fut: Future&lt;Resp, Err&gt;&gt;(service: S) { } That's totally unwieldy. There's one more important way to look at this: because there can be only one associated type, we can always determine that type from the receiver of the trait. So if I know I'm dealing with `vec::Iter&lt;'a, T&gt;`, I *know* that `Item` is `&amp;'a T`. With generics this is only sometimes true, and then only because of a complex set of rules in type inference.
Easy peasy, the compiler just needs to prove garbage collection is the most performant allocation strategy or infer lifetimes for all heap-allocated structures. It is sufficiently smart after all ;)
The disadvantage of such a method would be that you can't keep anything inbetween the connections. So say goodbyt to DB pool, MQ pool, network conections, etc. _Edit: moreover, you have to fork nginx to start your rust executable at each request, which is expensive in terms of time._
How?
[This](https://github.com/Ophirr33/conrod-hello-world) is what I did to get the hello world example to compile and run.
The usual way to do that is through CGI scripts. It's basically an interface that specifies how an executable can receive the request parameters through environment variables. I'm not sure nginx supports CGI scripts directly; often, you end up going through an intermediary like FastCGI: https://www.nginx.com/resources/wiki/start/topics/examples/fcgiwrap/ Note that this is entirely independent of the language the script is written in.
&gt;Also i mean optimizable as potential to be faster in the future You are assuming compilers are good and constantly get better. They really aren't. The general advancement of compiler theory has *far* lagged behind language development. What will/won't be optimizable when compilers do academically exhaust everything they can do is a tough question to ask because compilers are *barely* scratching the surface. 99% of compiler optimization are fundamentally just find/replace pattern matching. Modern chips like Itanium with near infinite speculation and register windows from an academic and engineering standpoint *should* have been a huge win. But compilers that could full utilize and optimize to these constraints never materialized. 
Yes, Idris requires a GC, but there is support for [uniqueness types](http://docs.idris-lang.org/en/latest/reference/uniqueness-types.html) which could potentially eliminate some allocations.
There's a list here: https://community.rs/meetup-map/ (though it only lists meetup.com) and also the Rust Community Calendar to check: https://calendar.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc@group.calendar.google.com I wouldn't know of any in Raleigh. If you want to start one, please ping community-team@rust-lang.org for getting you set up with calendar access and promoting you.
You can do your update in a single query. You'll need to add `numeric_expr!(hits::hits_so_far)` to your `schema.rs` to enable numeric operators on that column. (http://docs.diesel.rs/diesel/macro.numeric_expr.html has details) use schema::hits::dsl::*; diesel::update(hits).set(hits_so_far.eq(hits_so_far + 1))
&gt; No: `&amp;[u8]` and `Vec&lt;u8&gt;` are equally usable (given that the library is using Vec internally), using the latter removes the compulsory allocation from the library, but someone with only a `&amp;[u8]` (that's not a `Vec`) just needs to add a `.to_owned()` at the call site. Ok, but in that case if you're not careful you'll do two copies. First `.to_owned()` will clone and then when I push the extra 16 bytes the `Vec` may resize and thus copy again. &gt; The mutability of arguments isn't part of the signature of the function: `fn f(mut v: Vec&lt;u8&gt;)` and `fn g(v: Vec&lt;u8&gt;)` both have signature `fn(Vec&lt;u8&gt;) -&gt; ()` and both get called in exactly the same way. It's a little confusing, but the only things that callers of the function see are the types (i.e. right-hand side of the `:`s), not the names/mutability (i.e. left-hand side of the `:`s). I was assuming the mutability would be on the right hand side as `fn f(v: &amp;mut Vec&lt;u8&gt;)` to be able to avoid the copy. But now that I think about it I don't see a way for using a `Vec` to not result in resizing and thus copying once you push the 16 extra bytes. But maybe `Vec` usually leaves some room and so usually we won't trigger that? &gt; If it is actually faster, I suspect people may, but... maybe not. It's obviously up to you, just as long as the choice is made with "eyes wide open" about the conventions and tooling that will be lost/broken, rather than accidentally. I've thought about this quite a bit and having gone the way of full fuzzing in C++ I've concluded it's at least worth a try to not do that. I'm definitely still open to suggestions though.
i was thinking of how feasible it would be to build go and swift implementations (maybe rustc plugins) that compile to mir 
Respectfully, I think this comment misses kmc's point. I don't think kmc is requesting that crate authors must fix a bunch of issues, even if it's a 0.x crate, but rather that we can't do both of these things: 1. Advocate 0.x crates as production ready. 2. Shrug off problems in 0.x crates *because* they are 0.x. Both of these things are setting expectations, but the expectations they set are diametrically opposed to one another. Now, I personally don't have a good feel for how much we're actually engaging in said double standard, but it's not that hard to believe that it happens. I tend to agree with /u/desiringmachines here. Beyond semver, version numbers are mostly just a matter of marketing. So to understand what version numbers actually mean, you probably need to ask the crate author to clarify whether said crate is intended to be put through the gauntlet or not.
Yes, versioning shouldn't be the focus IMO. Is also very hard to build conventions around versioning, as different people may have different ways of understanding it. Also, a lot of people relies on "mature" libraries on other languages, and security loopholes are found (and patched) every day for those libraries. Unless you are following some tight protocol or standard (like for example the automobile industry), which is expensive, is hard to guarantee anything (and even then, we are just humans, so "shit happens"). For critical dependencies I think there won't be any other way around code inspection and auditing. Thankfully the language provides some guantees and some good practice may be to see how panics are handled, usage of unsafe code, and proper implementation of critical algorithms (mathematically probed in some cases/areas) plus extensive test coverage. A lot of technology is built on trust that things will work, for the good or for the bad, and it works until it doesn't, so this kind of discussions sometimes derive on a kind of a red herring: A lot of what we consider safe in software and technology is because experience has told us is that way (until we are proved otherwise), and because group thinking, not because we took the actual time to double check. Thankfully most of those dependencies are open source so they can be audited and inspected, but someone has to do the work in the end if you don't trust the source (and you should do that work in case of critical code, even if you do trust it).
I find the "0.x = don't use" rule very simplistic, and I don't really understand why people give so much importance to 1.0. Whether a crate is "ready for production" depends on a lot more factors than whether it has reached 1.0. The Rust team, who are behind the compiler and the standard library, have made a big commitment to stability after the 1.0 release of the language, and have held up to it (with a few exceptions). This commitment means nothing about what crate others do. Should serde, which has just reached 1.0 be considered "ready for production" ? Probably. Was serde "ready for production" a month ago when it wasn't 1.0 yet ? Probably Should log, which is still pre-1.0, be considered "ready for production" ? Probably Should hyper, which is still pre-1.0, be considered "ready for production" ? Probably Should diesel, which is still pre-1.0, be considered "ready for production" ? Maybe If I, a random person, publish a crate as 1.0, should it be considered "ready for production" by others ? Definitely not. As you can tell from the quotation marks, I also dislike the term "ready for production". In my opinion whether something is "ready for production" depends on how much experience you have with it. I would use serde in production because I've had a good experience using it. I would not use diesel in production, not because it is a bad crate, but because I have no experience with it. I would use tokio in production somewhere I can afford it to be broken for a couple of days. In the end, the question I ask myself is "will I need to wake up in the middle of the night because I've used this crate". &gt; 0.x crates are not expected to handle security issues in a timely manner. In my mind semver has nothing to do with the handling of security issues. &gt; "nothing in rust is secure yet above the memory safety level" (exact quote) Yup, Rust doesn't magically make the ecosystem safe. It only makes sure code is memory safe if it doesn't use unsafe code, and you trust the compiler. If you *really* care about security and stability you should write everything yourself. My old employer did that and it's not always fun.
Assembly is basically the most unoptimizable language, by the definition of the OP. The assembler isn't allowed to do even the most basic optimizations.
... so is it like zookeeper?
No, I think brainfuck is too low-level to be a good target for optimization. I believe the OP is talking about languages that optimize well, i.e. those where compilers can help people the most. Compilers of high-level languages can have a better view of the problem than those of e.g. Brainfuck which comes with no optimization annotations at all.
You can use `io::Result&lt;T&gt;` instead of `Result&lt;T, io::Error&gt;`.
Brainfuck optimizes excessively well *relative to its starting point*. This isn't hypothetical; huge gains have been produced from effectively trivial optimizations, and there's a lot more one could do if you (for some insane reason) decided you wanted to fund the effort. 
I don't know whether the documentation should write out the obvious, but for me crates on crates.io are code published by other people and may have vastly different quality settings from the main rust codebase. I go at them with a notion of distrust. It would be nice if all 1.0 crates were trustworthy and 0.x crates weren't, but its sadly not as simple as that. You can't have both, a language package marketplace where you can trust each and every package to be of high quality, or one where anyone can just simply publish a package.
Sorry I don't know what that means. You're referring to the return types of the `read_stdin` and `read_file` functions? 
I think this post is related to a recent discussion that came about [reqwest](https://www.reddit.com/r/rust/comments/6bqkmd/my_first_pr_for_a_rust_project/?st=j2zc7emr&amp;sh=3180ca1b), where there was a known large security hole that took a few months to get fixed by a new random contributor. In that case there was debate about whether a library with a known issue being left unfixed for so long should be the de facto recommendation being made by the community Unfortunately the comments getting into this were shouted down &amp; have been deleted
&gt;But that makes it a pretty silly question indeed. Then let's discuss more interesting questions. I tried to take OP in good faith. :) Not sure what you're trying to do – trying to show that a question is not well-worded? Brainfuck doesn't look like it's interesting to the author of this thread. Sounded more like they're asking whether C or some other language can be optimized.
Ah thanks for the context! I wasn't aware of that case and the discussion that followed.
That's why I started by saying assembly rather than Brainfuck ;). Every time you step away from the end result, you lose efficiency. The only optimum is the one that avoids lossiness, and the only language I know that (*almost*) manages that is assembly. 
If you write some number crunching stuff in Numpy (!), chances are that your hand-rolled assembly will run faster on today's CPUs, but the Numpy version will be able to run on older CPUs and even newer ones without changing the code, it might even become faster once there are new CPU features – something that assembly cannot provide.
&gt; The nightmare scenario is that some big company will invest heavily in Rust, hit a devastating security hole, and then be told "tough shit, it's your fault, you used a 0.x crate". This just isn't how companies operate. Any company using open source without an explicit support contract knows what they're getting themselves into (the ones that don't are the exceptions that prove the rule, and learn quickly). The world is full of shitty free software, there is zero uniqueness to Rust's situation here. Actually, I take that back: Rust at least acknowledges that some aspects of the ecosystem aren't ready for prime time yet. Compare this to, say, Node, or Scala, who routinely ship 0.1s with 1.0 labels.
It might be possible to not use GC for some variables when the compiler can prove that the variable is only used locally, or to prove that a variable has an "owner" (even in the absence of uniqueness types). For example, [Ur](http://www.impredicative.com/ur/) is compiled to code that doesn't use a GC. If the compiler can't make the no-GC optimization, it just fails the compilation (but it could just fallback to using a GC)
Yes `T` means any type in Rust.
I think there is a real *energy* here to be production ready. Everyone wants it, some think we are ready others think we have to re-implement Boost (C++ lib) and have it battle hardened in order to be ready. Being a python programmer in my day job, I'm on the fence a bit... python is such a "non production ready" *language* that you feel like rust must be "production" ready by default. Additionally, there are many python libs that are extremely well documented and supported... but many that are simply not. Heck, just look at the state of [mypy](http://mypy-lang.org/) -- the defacto "static type system" of python is still considered "experimental" -- and it's been in [development for almost 5 years](http://mypy-lang.org/news.html)! Not having optional typing in the current field of terrific typed languages (rust, golang, swift...) shows how slowly python is changing for production needs. (Don't even get me started on how only python2 is *really* ready for any kind of "production", because I feel like python3 probaly has *fewer mature libraries than rust*). So yes, rust is "production ready" but it completely depends on your use cases -- like it does for almost EVERY language except C/C++, Java and Javascript. If your definition of "production ready" is that it has the same support and maturity of the big three, then no langauge *except* the big 3 is going to be production ready for a very, very long time.
I'm not arguing that assembly is portable! Though if you allow for speed upgrades when moving Numpy to a newer BLAS, you should allow for speed upgrades when your assembly gets linked to a newer BLAS.
The description "large security hole" is from the OP, but was not actually the case. The entire incident happened due to the manner of exclaiming FUD without all the facts, instead of respectfully showing concern.
I'm pretty confused with the first loop... there is a `while` loop on `bytes.len()`... but the length of bytes never changes... does it? I notice `bytes` is mutable, so theoretically `read_u32` could be mutating it. If that IS what is happening, I wouldn't be surprised if the `if` statement is faster than attempting to convert to a `u32` and failing when the length of `bytes` is 0 (i.e. it is exhasted). That could easily be the cause of your speedup. Edit: *theoretically* `read_32` could maybe be inlined to make the performance equivalent -- but that might have other performance penalties (i.e. increase in compiled binary size). As it stands it probably causes at least a function call and return, which would increase the while loop by 2 clocks/loop.
Great thanks!
&gt; associated types allow you to drop type parameters Isn't this the premise they started from though? I show how the associated type parameters can be converted to type parameters (effectively "dictionary passing" for types), in a way that's so general it can make a lot of features "look like syntax sugar" then point out at least one situation where uniqueness interacts "positively" with other language features (coherence, if/when we allow impls based on associated type disjointness). Perhaps in too many words, but it really isn't "just a convenience". As for inference, it *doesn't have to be* complex in the situations analogous to associated types, `foo(in, out)` is after all how Datalog expresses `foo(in) = out` "functions".
BTW, while Rust may get stackless coroutines (a limited form of scoped continuation), it won't get full scoped continuations. Those mandate a [spaghetti stack](https://en.wikipedia.org/wiki/Parent_pointer_tree), which would work pretty terribly since every stack segment would need to be big enough for C to run on (or you'd need a separate C stack, which would be slow).
That's interesting. I guess I imagined that failing to convert to a `u32` for an insufficient buffer would've been nearly equivalent to an `if bytes.len() &lt; 4` statement, but maybe you are right. It is modifying `bytes` when `read_u32` is called. This caught me off gaurd too when I first tried. See [this gist](http://play.integer32.com/?gist=118c7d593db680dad31cdf5b382e00b9&amp;version=undefined) to see it in action.
I think that this post comes from an impulse I understand and sympathize with - the desire to have clear standards of evaluation. It sucks to have to take a close look at every single library you use - the source, the maintainer(s), the community - and make a judgement call about whether you can accept the risks that it imposes. In a perfect world, we wouldn't have to do this because there would be clear established standards that denote "ready for use", and a plethora of options that meet or exceed those standards. Unfortunately, that's not how things actually work in any context. What we really have is a mushy consensus that because other people did it, or we've done it in the past, it's probably okay, for any value of "it". And sometimes we disagree with that consensus, and it can be quite a shock - for example, I can't believe anybody thinks Python modules are anything but an absolute train wreck, but I frequently see people proposing to make Rust's module system even more like Python's. That sucks, too, but it's the price of doing business. The last thing is that it's hard not to think of "the Rust community" as speaking with one voice. I'd be willing to bet that the people saying "tough shit, it's your fault, you used a 0.x crate" and the people saying that certain 0.x crates are ready for production are not the same people. Maybe we as a community can try to establish which of those attitudes we want to promote, and try to call out people who use the other attitude, but different people will always have different ideas about what "0.x" or "ready for production" means. Again, sucks, but unavoidable.
&gt; If you really care about security and stability you should write everything yourself. My old employer did that and it's not always fun. Actually, it is usually *safer* to use open-source software, which has been tested by thousands if not millions of users, than to write your own software, which will have new bugs, because nobody writes perfect code the first time, even in Rust. There are exceptions--some bugs just go undiscovered for a long time, and some (I would imagine a minority of) open-source maintainers are hostile to bug reporters. But in general using a popular open-source library is the safer route.
You seem skeptical of the ability to do that at all. how come?
&gt; inference from coherence What does that mean? Sounds insightful! ;) I don't quite get your point about inference complexity. Even with generics, it should just be a bunch of restriction rules for which the compiler needs to find a solution. That cannot be *that* hard, can it? Thanks for the simple example though, appreciate it!
&gt; I definitely do not feel that /u/kmc_v3 [+7] has given a fair representation of the actual comments made by other users, and I think misrepresenting other people this way is basically trolling. I actually disagree wholeheartedly. I had at least one snappy comment that I wrote in response to one of these well-regarded members of the Rust community, but I rapidly deleted it when I realized that I was being just as unhelpful as those core members. You can downvote me into oblivion if you want, which is what I expect since /u/desiringmachines has so many upvotes right now, but as someone who was actually present when the discussion was happening, and as someone who saw the original comments from both sides, my opinion is identical to /u/kmc_v3's, and that's not good. KMC is being charitable, and he is correct about the quality of the comments. Now, whether we can expect great security from hobbyist crates is a whole different discussion. But, core members of Rust made **very** poor comments on that thread, and seeing their poor comments defended ex post facto makes me a little upset. Everyone should be held equally accountable, not just relatively unknown members of the community like me.
From my reading of the thread, tempers were high and folks were basically talking past each other. Core members did make unhelpful comments, and this was mostly because they misinterpreted what was going on, which just made the situation worse. kmc's analysis of the comments about security make sense if you assume that the comments made by the core members were replying to what kmc meant. From my analysis of the thread, I don't think kmc's actual point was being read, which makes those statements in-context wrong, but unintentionally. ----- Folks, this is why _be nice_ is a rule, when there are heated tempers everything goes wrong. I mean, besides being nice being the right thing to do.
I want to distinguish between two claims: * Those comments were rude. * Those comments were accurately summarized by the original post of this topic. I also want to set aside the first for the moment, I don't feel qualified to make that judgment (especially without the context of what they were in response to). I do not feel they were accurately reflected by the summarizations I quoted. No one said anything that could be fairly characterized as either: &gt; You have no right to criticize the handling of a bug unless your own crates are bug-free. or &gt; Users who are affected by bugs should shut up unless they're willing to find and fix the bugs. What I think distinguishes these comments from what was actually said (which is available at the link my previous comment) is how *absolute* they are. These statements are *edicts* about what users can and can't expect, and what they ought and ought not say. The statements in that thread were contextual &amp; responsive, not general statements or rules. Misrepresenting them as such is dishonest. Moreover, the context they were made in - and what they were in response to - has been deleted by kmc_v3, the same user who is now misrepresenting them. This feels frankly slanderous to me. I believe kmc_v3 is acting out of a genuine feeling of anguish over what they perceive as a serious problem, but the best word for the way they've processed that feeling is, in my opinion, shitstirring and flaming, and I think they should seriously reflect on how they could more constructively approach problems like this in the future.
 let username = match env::var("GITHUB_USERNAME") { Ok(username) =&gt; username, Err(_) =&gt; panic!("Github username and password required.") }; isn't this the same as `.expect("error message")`? I usually clean up a lot of pattern matching with combinators
I'm not asking for "zero effort", that is uncharitable. I'm asking for people to not simultaneously gush about these libs are OMG awesome, and then when there's a problem it's like "DUH, it's 0.x, what did you expect". I need to know where I stand and where I do need to focus my own efforts. If maintainers don't feel they have the bandwidth to provide reasonable security, they should state that clearly and not hide behind a version number.
How would you write that? 
I read that as saying nobody has any right to be rude and demanding about bugs. The allusion there carries the connotation that *nobody* has a bug-free library and thus making judgements about maintainers is unwarranted.
I figured that if I mentioned anyone by name, I would be accused of making a personal attack and would get another five paragraph lecture on empathy. You can call it passive aggressiveness but I wanted to share my concerns about what I heard, not who I heard it from. I thought calling anyone out by name would distract from the point and get me in hot water, maybe even banned. Anyway these comments came from at least 3 people. Obviously I am not demanding perfection or free support. People are repeatedly missing the point both here and in the original reqwest thread. I'm asking people to stop gushing about the Rust ecosystem and then hiding behind a version number when it turns out things are broken. If 0.x crates are unreliable then that's understandable, but maybe we should be more upfront about that.
I'm asking how do you get the `username` from `std::env::var` without the `match`?
Parfait!
As far as giving information to the compiler is concerned, that would be Rust. Although the compiler currently ignores most of that information.
This looks really cool! I was hoping for another high-level Lua wrapper, as I've always found hlua to be too restrictive (still a great library though). Have you thought about writing some benchmarks? It would be great to see some numbers on how it performs compared to hlua.
I definitely should write some benchmarks. I'm not *personally* worried about the overhead of luaL_ref / luaL_unref, but my justification is not a scientific one, more just experience writing the lua bindings system for starbound. There definitely will be some overhead though, I wonder what the right benchmarks would be? I think the only place where it might be realistically a problem is in the ToLua / FromLua implementations, but I'm not sure exactly how to change those to push / pop directly from the lua stack and also be completely safe. I think it might be possible though. If I could eliminate the overhead of the registry with ToLua / FromLua, I think the overhead in comparison to hlua would be negligible. Edit: I should add, my personal definition of "safety" here is not JUST rust safety, but also additionally that you cannot cause a panic by writing a bad implementation of ToLua / FromLua. I mean, I guess you could always cause a panic with unwrap, but more that it is not EASY to cause a panic by say pushing or popping one too many values.
If /u/Matsumada's background is anything like mine, then their experience is probably in languages like Python, where something like a Global Interpreter Lock makes the language actively hostile to true parallelism, despite offering threading APIs.
Not really - the key word here being "sufficiently smart". A "sufficiently smart" rust compiler should be able to do something fairly similar - but we're still a large way away from either compiler doing that. In practice, Rust and Idris are both fast languages, and at this point _what you write_ matters more than how optimizable the language is. In the future, if we come up with a perfect Idris compiler, then yes, you'd be missing out on huge performance gains. We don't have that yet, and the perfect optimizing compiler is a long ways off for any language (as others have said).
I think you'll get way better results with [a cache-friendly layout](http://cglab.ca/~morin/misc/arraylayout/) than by writing non-generic asm.
I agree with this, when I read the comments on that thread I was actually really surprised, because I did not expect such comments from people that are both important to the Rust ecosystem, and often its first public face. It made me feel slightly uncomfortable, especially since /u/kmc_v3's initial comment was not particularly incendiary, while the replies were ... dismissive at best.
very true... not sure i can do that in my case though
Could it be perhaps faster to mmap the file? You can ensure you have the extra zeroes by specifying the length to be 16 bytes more than the actual length of the file. The only problem is that it's unsafe if another process is writing to the file while you're reading from it.
The key point is this: when checking coherence, we have to be conservative about the possibility that other code exists. However, in inference, we are not so conservative. So let's say that iterator was `Iterator&lt;T&gt;` instead of having an associated type, and `vec::Iter&lt;'a, T&gt;` only implements `Iterator&lt;&amp;'a T&gt;`. And we have a function: fn foo&lt;I: Iterator&lt;T&gt;, T&gt;(iter: I) -&gt; T { ... } And we've called it like this: foo(vec.iter()) In type inference, we are allowed to use the knowledge that there is only 1 impl to infer the second type parameter of `foo`. However, in coherence checking context we can't use the same knowledge, because what is std added another impl in the next version of Rust? Your code would break if we did that. What this means is we have to maintain these two different versions of trait resolution, one for type inference and one for coherence. We still do this today even though we have associated types, but if we didn't do this you would have to specify that second parameter every time, because we could always add a second impl of `Iterator` for `vec::Iter`.
Well I'm all for safety over speed (especially since working with raw Lua is enough to cause an aneurysm). It would just be useful to make sure there aren't some operations that become magnitudes slower as a result of using the registry (like reading/writing many values in a table at once). I'd imagine the overhead isn't enough to make a significant difference in most real-world cases though.
I guess my issue with that is that *tons and tons* of production software is built on open source stuff that's at the same level as something like tokio. Remember when that guy pulled his stupid little left-pad JavaScript library from npm and broke everything? That's arguably a bad thing that needs addressed, but it's a *software* thing, not a rust thing.
&gt; but the best word for the way they've processed that feeling is, in my opinion, shitstirring and flaming I think its pretty clear that multiple people do not share that opinion. Raising the issue here has been quite constructive, and its hard to read your comments without feeling uncomfortably like you'd just like the OP to shutup and go away. &gt; ...and I think they should seriously reflect on how they could more constructively approach problems like this in the future. Like how? If a reasonable and moderate post (heck, even if it *is* in some technical way factually wrong, or a misrepresentation) about the issue to draw attention to it is 'shitstirring', what's the right way to handle the issue? Telling people to reflect on their behaviour isn't constructive without pointing out what the meaningful alternative is. Something *clearly* went wrong in that discussion; how should it have been handled? Where should it have been raised? Pedantic technical criticism ignores and distracts from the actual issue being raised. 
The drop order matters because a type may use one of its fields in its destructor ;) It's basically why Finalizers are always a pain in GC'd languages
Do you accept pull requests?
A lot of the comments are responding to the latter part of the post, which is fine. But the parts about some insiduous "senior members of the community" making these terrible pronouncements is just BS. Meanwhile he's deleted all of his posts and is now able to present what he had said in whatever light he wants; he's admitted that they were rude, but in what I find to be a tactically diminishing way. And he's emphasized that in one, he praised the maintainer of the crate he's concerned about - a convenient thing to emphasize for him now, but did his posts overall present the impression that he was praising the maintainer? This is all very manipulative. If he had referred in an honest way to the previous discussion as raising these concerns for him without trying to reconstruct how *we* are able to read that conversation, I would have no problem with this thread.
Ahhh okay... This makes more sense now. I will definitely be paying more attention to the order in which I declare variables, even if it's in main. Thanks again!
Is there a BTreeMap/Set equivalent of ArrayVec/SmallVec?
what's a built-in Rust library for that?
Far too true, and at least with hobbyists and open source stuff, if they can't/won't then you can step in yourself and implement it, with companies it's at their discretion, which is "never" more often than not.
Thanks for the replies everyone, really cool stuff. Out of interest, how does AWS Lambda get away with it? If I've understood correctly when using javascript Google Cloud functions start an express.js router for each endpoint you set up, and keep it running for at least 5 minutes. Edit: I wonder how easily I could 'proxy pass if this application is running, or start this application and then proxy pass' with nginx.
I am talking about what kmc is doing right now in this thread, and I do not think it is irrelevant. There are plenty of other comments about the state of the crates.io ecosystem. But I am going to consistently call out manipulative and trollish behavior when I see it because I cannot tolerate a community where people do that to one another. The premise of this thread is that Rust's community is taking a relaxed attitude to security, but the basis of that is a conversation in which no one actually took that position, because no one actually does.
Fair enough; I'm not going to argue with you; I have no real interest in kmc, what they said, or what anyone else said (allegedly or not), compared to what I actually care about (ie. the state of rust). ...but I think it's clearly misrepresentative to suggest there's no issue here worth discussing (clearly there is) or that the way it was raised was significantly inappropriate. I'm not trying to take a shot at you; I fully appreciate the point you making and I consider you a valuable community member, but I think you're taking a bit of a hardline stance over what is basically a 'he said - she said' kind of thing which I appreciate you consider trolling... but really, I just think of as a fuss about nothing. I guess opinions vary. 
Yes, definitely. Uh, actually we're doing a bit more than exploring, but I haven't made any official announcement yet because the project is not really.. public just yet. It will be though, and I'll try to make some official announcement then.
I guess that I could advertise the rust cookbook here which has relevant example https://brson.github.io/rust-cookbook/net.html#ex-rest-post
And delimited contunuations are limited form of scoped continuations. 
Well there is a pretty good chance those libraries come with a disclaimer that looks a lot like: THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. So really they have only themselves to blame. If you don't get a support contract you may have to fix things yourself. Wouldn't a more interesting question be "on average, how does the quality of popular rust crates compare to that of similar libraries in other languages?"? That would also set a more reasonable standard than 'bug free'.
I think HR just sent me a response with "Sorry, we aren't looking to hire interns right now" or something, but no worries, that's exactly what I expected when I applied! I think I would have been more surprised to receive a different answer. If you will still be using sdl2 with Rust, I would *love* to assist you to use [rust-sdl2](https://github.com/AngryLawyer/rust-sdl2), help you land a PR if you find a feature that's missing or even hear about feature requests that you might have. Some companies find it hard to request features to us open-source folks, but I would actually love to do this, because a feature that you need may actually be a feature that everyone else needs! I will admit that right now I just want more people looking into gamedev with Rust, and I feel like supporting existing companies that want to commit all the way to use Rust is one of the first stepping stones necessary for such a long-term goal, so please go ahead and ask us anything!
As the quote in the sibling says, this isn't true for small amounts of data: in this case, the entirety of the data is 8 contiguous cachelines, and it's likely that most layouts/search patterns will have similar cache behaviour (loading ~4 cachelines out of L1, if the function is called repeatedly). The [associated paper](https://arxiv.org/abs/1509.05053) has a nice graph of page 30 (figure 17).
I *am* using rust-sdl2, I see now that you're one of the primary contributors to rust-sdl2. That's just excellent, thank you so much for your hard work! &gt; Some companies find it hard to request features to us open-source folks, but I would actually love to do this, because a feature that you need may actually be a feature that everyone else needs! I am definitely that person. In fact, I have found it pretty hard to request / contribute back to open source in general, which is part of the reason I'm trying to break that habit by releasing this. I think I might be THE most boring user of SDL2 though, because my entire use right now is keyboard / mouse / joystick input and.. an OpenGL context. That might be too soon to tell though, I think Starbound used.. maybe a tiny bit more of SDL2, mostly stuff to do with windowing events and fullscreen. I promise I'll keep you posted about feature requests but I don't even think I've had a single problem with rust-sdl2 yet. It's just been there and worked perfectly.
Nope, absolutely not sure :) Borrowck does it's own thing, in its own compiler pass. I'd be very interested in the correct answer for this.
I believe this is allowed for `&amp;mut` because the function can't "do" anything with the reference after it's finished. This is a usability sugar, mutable references specifically are "reborrowed" when moved to a function. The statement is desugared into this one: move_ref_into_nirvana(&amp;mut *reference); I know there's a reference explanation for this "reborrowing" sugar somewhere, but I haven't yet found it. -- This was added for usability though, since mutable references, while unique, can't be destroyed. This "reborrow" sugar is different from move semantics, but it isn't like an `&amp;mut` reference can be made invalid by the function. The borrow checker has ensured you aren't modifying it in more than one place at a time, and this is at least safe.
&gt; And how would you actually do this? I'm confused; do *what*? Explicitly re-borrow references when passing them to functions? Because the compiler already does that, which which was my point. You can't do it explicitly because you can't *not* do it in the first place to have to do it explicitly.
\**rubs face*\* Ok, so assuming you're using a different language that is *exactly* the same as Rust, except that it doesn't reborrow arguments... `&amp;*r` / `&amp;mut *r`. But there's no reason to do that in Rust, because even if you do, the compiler should just re-re-borrow the argument anyway.
Ah, now I see what you mean by "re-borrowing". You mean this: `&amp;mut *r`, if `r` is a mutable reference. So the compiler can keep track of which borrow is the current one, and sort of maintain a stack of borrows. This way, it knows that right after the re-borrow, the first reference is no longer the current one, but when the re-borrowed reference goes out of scope (which in this case is when the function `move_ref_into_nirvana` returns), the previous borrow will be active again and can be used again. Is this correct?
But isn't this exactly what I said? :) What does the "And no" part apply to?
Cool. I'll get started on it then.
&gt; Currently (at least AFAIK), Rust supplies more aliasing guarantees than LLVM can optimize for, because LLVM's original targets (C/C++) are usually not that strict. Isn't that why FORTRAN is often faster than C, that it provides much better aliasing strictness? (also that a lot of work has gone into its compilers for pretty much the entire duration of electronic computing).
&gt; That's a reality of open-source projects Well, it's even more true for hobbyist's closed-source projects and therefore has nothing to do with open-source in particular.
No problem! Hope that was helpful. Quxxy is much more knowledgeable than I am about this sort of thing though :). If you're still interested, I had part of a reply typed up to your last comment about it being multiple mutable borrows: --- I wish I knew enough about the internals of the compiler to explain how it reasons about this, but I'll at least try to explain why it is safe: The function does take a mutable reference to your variable, but that mutable reference lasts _only as long as that single function call_. The function can't store it anywhere, or do anything that would mutate it later, since it's being passed in an `&amp;mut` reference. In a sense, you are "loaning" it your `reference`. You can use it, then you pass it to `move_ref_into_nirvana` to use it, then you can use it again - this is safe because only one thing ever has the ability to mutate `capsule` at any given moment.
Do we really want use NPM/JS quality standards as a reference for anything ? Honestly most of the NPM stuff is PHP level garbage - incomplete, unmaintained, full of glaring flaws (not even security, just not implemented correctly) but since we use it for front facing stuff only it's not relevant as long as it mostly works. I would never use Node/JS/NPM for anything that needs to be reliable. 
Thanks for the tip! It's not so much that it's necessarily a small collection (what's the definition of small?), but rather that I like seamless the Heap &lt;-&gt; Stack transition that occurs in SmallVec whenever the data starts off small. This has bought me some performance improvements in a project I'm working on, but I'm working in an environment that's a) heap constrained b) might not have the best allocator. So I'd like to keep data structures on the stack for as long as possible, and that's where the motivation for my question. I was thinking of trying to convert [FlatMap](https://github.com/toffaletti/flat_map) to use SmallVec, but I require some extra features (like Serde support) that would make maintaining a fork difficult.
Thank you for your edit! I've never heard of those two things before, but they sound very interesting.
`&amp;T` is Copy, `&amp;mut T` is not.
Yes! That is definitely possible - but it has to be communicated in the function signature. This is where lifetimes come in! Here's a function that takes and stores a reference: fn takes_and_stores(opt: &amp;mut Option&lt;&amp;mut IntCapsule&gt;, t: &amp;mut IntCapsule) { *opt = Some(t); } Rust will complain about this, since we haven't given enough information _in the type signature_. If we modify it, it's allowed: // 'a is the lifetime of the inner reference. // 'b is the lifetime of the Option, and must strictly be "smaller" than 'a. fn takes_and_stores&lt;'a, 'b: 'a&gt;(opt: &amp;'b mut Option&lt;&amp;'a mut IntCapsule&gt;, t: &amp;'a mut IntCapsule) { *opt = Some(t); } This gives Rust the information about what needs to be valid for the function to work - and with this, the following is no longer accepted: let mut x = IntCapsule { i: 4 }; let mut opt = None; takes_and_stores(&amp;mut opt, &amp;mut x); x.i = 4; What we've done is tell rust that the `&amp;mut IntCapsule` it takes must live longer than the `&amp;mut Option`. Since it must live longer, the borrow 'lifetime' is extended to the life of `opt`, and this will error: error[E0506]: cannot assign to `x.i` because it is borrowed --&gt; src/main.rs:18:5 | 16 | takes_and_stores(&amp;mut opt, &amp;mut x); | - borrow of `x.i` occurs here 17 | 18 | x.i = 4; | ^^^^^^^ assignment to borrowed `x.i` occurs here --- One more additional thing! At function boundaries, _everything is encoded in the signature_. Any function with the same lifetime signature will require the same thing of the caller. For example, this fails exactly the same way: struct IntCapsule { i: i32, } // 'a is the lifetime of the inner reference. // 'b is the lifetime of the Option, and must outlive the inner reference. fn does_not_take_but_still_requires_lifetimes&lt;'a, 'b: 'a&gt;(opt: &amp;'b mut Option&lt;&amp;'a mut IntCapsule&gt;, t: &amp;'a mut IntCapsule) { } fn main() { let mut x = IntCapsule { i: 4 }; let mut opt = None; does_not_take_but_still_requires_lifetimes(&amp;mut opt, &amp;mut x); x.i = 4; } // error[E0506]: cannot assign to `x.i` because it is borrowed I just wanted to add that to ensure you can see where Rust is getting its information: Rust never infers past function boundaries - it just forces function signatures to accurately represent what they need.
Last week I got my database project, Sucredb into a shareable state, I'll continue to fix the rough edges this week. Link https://github.com/arthurprs/sucredb. Description from readme: Sucredb is a multi-master key-value distributed database, it providers a dynamo style tunable consistent and causality tracking. Any node that owns a partition (replication factor) can serve both reads and writes. The database tracks causality using vector-clocks and will NOT drop any conflicting writes unlike LWW (last write wins) and other strategies. Conflicts can and will happen due to races between clients and network partitions. note: better name suggestions welcome
Might be useful to edit your post with a TL;DR so that people stop getting the wrong point. Assuming he's right... I think Burntsushi summarised well in the comments &gt; Respectfully, I think this comment misses kmc's point. I don't think kmc is requesting that crate authors must fix a bunch of issues, even if it's a 0.x crate, but rather that we can't do both of these things: &gt; &gt; 1. Advocate 0.x crates as production ready. &gt; 2. Shrug off problems in 0.x crates because they are 0.x.
It is similar to FastCGI, in that the process is kept running. Of course it does not use any standard protocol...
Thanks so much! This was really helpful!!
Do you have any interesting examples of stdc++ bugs?
&gt; I think it is widely understood that 0.x means "rough around the edges, APIs may change". I think it's​ less widely understood that it means "no security, we don't care about bugs until users fix them". At least, that's news to me. Per semver definition : &gt; Major version zero (0.y.z) is for **initial development**. Anything may change at any time. The public API should not be considered stable. 0.y.z crates are *work in progress* crates, which means : - the current API can be dramatically far from the eventual release one. but also : - important features may be missing - some parts of the code may be untested - many bugs can exist in the code (included security-related ones) Since the crate is in a WIP state, the project maintainer may want to give **priorities** that are not what a production user would favor. For instance, he may want to favor the development of new feature, or fix usability bugs in critical parts of his library instead of fixing security holes in some nice-to-have feature. And since the project is marked as WIP, you can't blame the authors for the development trade-offs they make. Before using a 0.y.z crate[1], you should definitely get in touch with the crate author and ask him if he thinks his crate is ready for production. If he says yes, and then doesn't pay attention to security fixes, maybe you can get annoyed but certainly not before. This is absolutely not a Rust-specific problem, nor an indicator if a language is «ready for production», it's an open-source problem in the github / language-package-managers era. The Rust core team made this issue a priority though, and the the 2017 road-map explicitly tackles this issue in two steps: helping important crates to reach production-readiness, and making high quality crates more discoverable. [1] and that's probably a good idea for any crate which is not already widely used in production by the industry. 
Linear-typed programming language from Microsoft, with a very interesting take on reliability. Looks pretty damn cool!
[removed]
I'm actually still hacking on my [meme server](https://github.com/Xion/rofld) project that I wrote just to [evaluate asynchronous Rust](http://xion.io/post/programming/rust-async-closer-look.html), because it turned out too be _way_ too fun :) I tried making it support animated GIFs last week, but it was super slow: decoding and encoding 50+ frames takes a long time even with Rust. So this week I'm planning to try and rewrite the captioning code to work without decoding the animation, directly on the GIF palette-indexed images. Quality may suffer a little but at least it should complete within reasonable time. Soon it shall be production ready ;)
Lambda is indeed the new CGI. I too missed the times when unused applications did not take up RAM, because I do have many services that don't get requests every *day* even. So I made this thing: https://github.com/myfreeweb/soad It's a tiny C program that listens on a unix socket, spawns your app when there's a request and passes it the socket (via normal inheritance that happens on fork — and some env variables to indicate that, using the same variable names systemd does). And… `TERM`s your app after there were no requests for a given time period! It's really simple. Unfortunately it's often not easy to use with current Rust web frameworks because some of them don't even give you an interface to pass raw sockets into, just "give me an address/port and I'll open a TCP socket" which sucks. Maybe the situation has improved somewhat already. Maybe I'll need to contribute some fixes.
I think the key point here is one of perception. If we set expectations high but fail some rudimentary test, then it's easy to see how that causes problems. Regardless of whether our security practices are standard or not, if some percentage of folks *perceive* a mismatch between expectations and reality, then they're going to be upset because they're going to feel hoodwinked. To clarify: I am trying to take the most charitable interpretation of kmc's point here. I think that kmc went through that perception problem themselves, and I think this post is an attempt to bring awareness to that problem. To further clarify: I don't know whether we have a problem or not. Perception is hard to gauge. :-)
It can become true again when you use SIMD, if you think of SIMD instructions as costing in the same way that cache line loads cost at higher levels of the memory hierarchy. Figures 9 and 10 in http://openproceedings.org/EDBT/2014/paper_107.pdf have measurements for `popcnt` as compared against branching implementations (this pre-dates the paper you linked, which avoids SIMD to keep the evaluation general).
What is the current status to support self-referential structs? Something like struct S { a: Vec&lt;String&gt;, b: &amp;'self str, // ⇐ 'self refers to the field a } I know that there are alternatives like [rental](https://docs.rs/rental/0.4.10/rental/) or [refstruct](https://github.com/diwic/refstruct-rs), but they require (IMHO) too many boilerplate. 
&gt; I don't want to debate the technicalities of SemVer. The fact is that people are using these 0.x crates, some have over a million downloads, and we encourage that practice every time someone raves about the ecosystem in the context of Rust in production. This is exactly what you are doing. SemVer has nothing to do with any implied "fitness for production". It's only about API stability (the semantic part) not the implementation and any sort of quality one might imply from that. The whole "Libz Blitz" is making sure that a lot of common building blocks (the crates with lots of users) are at a point where semantic versioning can be used to signify API breakage and hopefully be more or less future proof so simple changes won't cause all sorts of upgrade mayhem. And have all the basic things covered with a reasonable maintenance model. None of this is about the presence/absence of bugs. Only that we're in a position to deal with them. But for the rest crates.io is an open software repository. Every package should be viewed on it's own merits and risks. And every package has their own goal, priorities, philosophies and support model. The reason cargo and crates.io are selling points, is not that all crates are perfect, bug free, secure and great pieces of software. That is not the case now, tomorrow or ever. No other language has that. Most crates will always be mediocre/unfinished/unproven. The reason they are still selling points is: - one can use them if they are good enough for your purposes - one can be inspired by them or fork them if you need more - updates by the maintainer won't unexpectedly break ones build - one chooses when to update their dependencies - in many cases crates have their own "private" dependencies and multiple version of the same crate can coexist (which means that in many cases one doesn't have to use the "common ground" version with possible issues, but each part uses the version that is "good enough" for their intends and purposes) - you can see which version of crates are used and not have major parts have old "vendored", often untracked, versions copied into them with - (Probably many other obvious reasons I'm forgetting to mention here) But this is all related to dependency management. Not the quality of the introduced dependencies. Not the quality of the people maintaining the crates or the fitness of their use. Every dependency is one you have to consider, no matter where you get them from. You have to weigh the risks and benefits. And you might have to do some research depending on the risks and possible impact. And you might be perfectly fine with a 0.x unmaintained library for some specific use case, but at the same time find that some big supported library at 3.x doesn't fit your requirements.
The efforts are greatly appreciated! I've recently started committing; the help and attention from the core team and other contributors is absolutely amazing. I can tell everyone's passion for the project right away. It really inspires me to help the project and community any way I can. 
I'm slightly surprised Rust gets to be faster than C# for very long lists, might be nice to do some alloc/dealloc profiling, I assume the C# GC is a bit hammered having to traverse all those references. It might be possible for C# to stay in front by tuning the GC.
Can confirm, primary language has been ruby and js. Def need to fork and submit prs for stuff if you're on a schedule.
[removed]
1.0 of my [CrateDB driver](https://github.com/celaus/rust-cratedb) including Blob support and a few other adjustments!
It's not at all.
Without the numbers for Rust and C# being side by side, or plotted, it's actually incredibly hard for me to read those results, but benchmarks are always interesting!
Do you know how much garbage collection work is happening in the C# version? One of the things GC does is allow very fast allocation, at the cost of having to spend time collecting later. However, whilst the allocation happens on a mutator thread, the collection doesn't. This means that you can get mutator threads going really fast, but the system as a whole not going correspondingly fast, because there is so much GC work to do. Could that be happening here? 
Forgive my ignorance. But is this like a messaging queue? (I.e. rabbitmq) or something else?
They definitely have a bee in their bonnet about Jetbrains, comparing them to the Illuminati (!), claiming that they destroyed SBT (newsflash: SBT did that fine all by itself - it's the slowest build tool I've had the displeasure of using), and that they destroyed Scala (how? by building the most functional Scala IDE out there?)
I would say SQL because it's a declarative language. So you write what you want, not how to do it. That's gives the optimizer the most freedom. `select max(some_column) from some_table where foo &gt; 1` It's entirely up to the db engine how to run the search. It might use indicies. It might have a precomputed cache. It might spawn multiple threads and scan the table in parallel. These are called domain specific languages. They are designed for or grow from a specific set of problems. Regexs are an intrinsic of perl. Matlab is used to make difficult math and computations faster. In VHDL, you write how you want the circuit to function, not how to lay out the transistors. 
You don't have to like it for it to be *very* popular in production.
Yes but what kind of production ? Rust value proposition is security/safety/performance and people want to use it for systems level programming. Node is code reuse/rapid iteration/low barrier to entry and it's used as a front end/presentation layer. Quality standards are very different for their use cases.
&gt; If could not convince the compiler to use `cmovge` so I had to add one line of assembly. Here's a version which generates a `cmp` + `cmov` chain :) let middle = start + half; unsafe { let pivot: u32 = *block.get_unchecked(middle); start = if target &gt;= pivot { middle } else { start } } half /= 2; [Playground](https://is.gd/uZMaGt) It also shows a slight bug in your impl, as you should use the `ae`, not `ge` condition when doing unsigned integer comparison.
I'll be working on v0.0.6 of [Gutenberg](https://github.com/Keats/gutenberg) and a documentation site for [Tera](https://github.com/Keats/Tera) built with it. The site is pretty much there, it's just a question of styling now.
&gt; Rust started with much more code commits and technically had a year or two more work done. I don't understand what you mean by this. &gt; This author also forgot that Swift only got open sourced recently. So it has less people following / contributing to the project where as Rust build up more followers. I didn't forget that, I simply believe it's not so relevant to this article. You can clearly see a curve up in the author graph for Swift (as well as an earlier curve up in the commit graph, I'm guessing when Apple started to take the project more seriously internally). &gt; He forgot that Swift there Foundation is a core library. I wrote in the post that this is a crude analysis, and then highlighted this same concern: "Repositories may not all contain the same depth of components (like compiler, standard library, documentation)". Anyway, it's clear from my post that Swift is getting new commits at a significantly higher rate than Rust right now, and has been for a while. On the other hand, this does not appear to translate to a similarly increasing number of unique contributors.
There are also others like PostgreSQL which neither has a single company backing it nor a non-profit, but still ships timely security patches. There are just a bunch of companies with a vested interest in PostgreSQL that employ people to work on it.
&gt; So really they have only themselves to blame. I don't agree with that. Yes, they don't have any *legal* leg to stand on, but if I'm a company that uses an open-source package that claims to be ready-for-production and it turns out the package is totally broken and insecure, I'm going to be pissed, and it's going to count as a black mark against open-source in general. It doesn't matter if they have a "right" to complain. Products being not-as-advertised will always look bad.
Do you feel that your choice of GPL will inhibit corporate adoption of rofld? (Just kidding. Cool project.)
I just pushed a crate for working with https://jsonfeed.org feeds, https://crates.io/crates/jsonfeed . I've got a mostly-working version up now, it's just missing a few more tests and a feature or two.
One bug in C++ standard libraries I ran into is that `std::uniform_real_distribution&lt;float&gt;(0, 1)` can return 1 ([gcc](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=64351), [clang]( https://llvm.org/bugs/show_bug.cgi?id=18767)). This can produce nans if you use the random number to calculate `log(1 - x)` or similar. 
That is the current status.
awesome thank you! I tried to get the compiler to do that but somehow failed