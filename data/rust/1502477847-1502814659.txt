I can't speak for the core team, but I would guess that involves some combination of: * lack of interest from the community, and/or * lack of knowledge about the platform among contributing rust devs, and/or * lack of build/testing/automation resources for that platform It takes a certain amount of knowledge about a platform in order to make a language compatible with it, and if there isn't anyone in the community that is both knowledgable, and more importantly, motivated to do the work, then it won't get done. I hope this doesn't come across as a dismissive "PRS WELCOME" response, because I don't mean it that way, but it seems like the most likely reason for no rust support on the platform(s) you mention.
Yes! Totally agree. Safer than C/Go-style error handling, and more straightforward than java/python/c++-style exception handling.
Cargo's package management is first-rate. That is, it's as good as anything else out there, and there are a few other tools that are as good as it. I don't think it's significantly better than Gradle/Maven in Java. There are a few things you can do with each that you can't do with the other. For instance, Cargo has platform-specific dependencies, which are much more important in Rust than Java. It also has conditional features, which i haven't fully grokked, and am a bit dubious about. Maven has the ability to have multiple, tagged, artifacts in a dependency, so you can ship a library, source, tests, documentation, etc together. None of those are killer features. The stuff they have in common is 90% of what you need, and it works much the same way. Rust's build system isn't integrated into the language. The build tool is developed and distributed along with the compiler, which means they work perfectly together, but i don't believe they're actually integrated. And that's a good thing: there is no reason to couple those two things tightly. Anyhow, the user experience is much the same as with Gradle: check out a project, run a single command, get everything done for you. Gradle has its wrapper, which i think is rather nice, as it lets you build a project without having to install Gradle yourself, but it wouldn't be too hard to build that for Rust. 
The biggest thing for me is a strongly typed language. No null pointers!
I think the Gotham, Rocket, Nickel, gerust, etc folks are doing **amazing** work. It's super exciting to watch our ecosystem grow. Ultimately, from my perspective, Iron is something from a past era. We now have workspaces, better macros, new design paradigms, new teachings to share. Personally, I'd prefer to see a successor to Iron, even if it is a fork, or drawing from it's idioms. It still works, there are PRs open for trying to integrate async, and it still has great ideas. It's [MIT Licensed](https://github.com/iron/iron/blob/master/LICENSE) and could be republished. Alternatively we could put in some effort to fixup the permissions problem, but I think we'll have a large number of breaking changes coming if we want iron to be truly modern and up to date.
`&amp;str` is a pointer and a length. `String` is (pointer, length, capacity).
amongst other things, would allow code generic over pointer types
&gt; You say you love Rust, but it doesn't sound like you really do. I am fascinated by it, i enjoy writing it, and i want it to be successful. Perhaps your definition of love is more intense. &gt; I also don't agree that Java has better tools than Rust. Java has build tools with flexible, general-purpose mechanisms, able to work with many resources beyond code, in arbitrary topologies, and huge arrays of plugins. Remote debuggers. Interactive profilers you can use at runtime. Monitoring and management built into the runtime. Multiple static analysers. Code coverage. Various intrusive APM tools that i personally wouldn't touch with a bargepole but that some people swear by. Hot code reloaders. Package servers, so you can host your own packages internally. I imagine Rust has some of those, and i've missed them. But it doesn't have the breadth and depth that Java does. Not even close; in fact *not even* not even close! I honestly do not understand how you could dispute that Java has better tools. &gt; Java has better IDEs, for now, but with the upcoming RLS, Rust is going to have a pretty great IDE experience. JetBrains also announced that IntelliJ Rust is now officially supported, so that should be seeing even more development now. It took decades for Java's IDEs to get where they are today. Yes, decades plural, because the story started with Smalltalk IDEs that predate Java (VisualAge for Smalltalk -&gt; VisualAge for Java -&gt; Eclipse). Despite that, they still have flaws and limitations i encounter every day - some automatic refactoring that works 90% of the time doesn't quite do what i want this time, the type i want is only fifth on the list of suggestions, etc - and are still improving. Rust's IDE support is developing rapidly, but i don't see any reason to think it will catch up with or surpass Java's any time soon. 
_Amongst other things,_ _Would allow code generic_ _Over pointer types_ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^dobkeratops ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
I agree and `Wrapping(123u16)` seems much more readable to me than `123wu16`.
&gt; Is it possible to have the loop execute outside of the GameLoop, and in an outer function instead? Though this struct would just be a Game by this point. I was thinking of that, but then the core purpose with `GameLoop` is you set up the `SceneManger` (with a base scene) and then the loop runs, as it does it updates the Scene's inside of SceneManager. is there a better way to do what I am doing? &gt; The observer pattern typically requires some reference cycle, which is arguably not desirable. An alternative is to have a Command enum like this: `enum Command { DoNothing, AddScene(Scene), RemoveScene, }` Is this a pattern? Is there docs on it so I can better understand what your saying here? 
Thank you for targeting `stable`! At a first glance, the API seems to be quite nice, and I'll definitely keep an eye on it.
I've done a bunch of rounds of developing simple event loops akin to game loops for lighting control (it turns out that a lighting controller and a game share a lot of general code structure). Turning your event loop inside-out will make the code more clear, so that rather than having your game loop literally run in a loop, it just acts as an infinite stream of events that can be queried in a loop. This solves your testability problem as well, as your tests can make assertions about the next event you expect the loop to emit. https://github.com/generalelectrix/wiggles/tree/master/event_loop
I might have missed this somewhere but I can't find documentation about data validation, say if we want to enforce a username is alphanumeric. Are extractors only for query strings? Do you recommend using an external library for validation? 
About your second question, I was thinking along these lines: trait Scene { fn update(s: &amp;State) -&gt; Command; } impl SceneManager { fn update_children(&amp;self) -&gt; Vec&lt;Command&gt; { // collect commands for all scenes, and return them } } impl GameLoop { fn update(&amp;mut self) { for c in self.scene_manager.update_children() { // handle each command } } } So that the `Scene` has the ability to change the behavior of the `GameLoop` without actually needing a mutable reference to it. My knowledge of design patterns are pretty poor, so this may very well be another pattern.
Observer is just one method of creating a chain of event notifications. Using an enum to perform lightweight message passing is a more explicit, functional approach, and also extends beyond domain boundaries much more cleanly than using Observer here. Observer basically performs message passing using a bunch of synchronous API calls. Using a Command enum means that you set up some messages queues; the main queue is drained by your event loop which periodically pops the next message and takes an action based on it. This is nice as you can extend these messages all the way out to the edges of your application and potentially serialize/deserialize them to perform communication between a control application or between threads/processes. Observer has its place, but I've found that I rarely need to reach for it in Rust, at least not in the classical GoF/OOP form.
utf8 by default. In the short term this creates mild head aches, in the long term it will be a good decision. 
Further, here's what it looks like using that event source in the core of an event-driven application: https://github.com/generalelectrix/wiggles/blob/master/console_server/src/reactor.rs#L322
Loving a language and thinking that it's ready for prime time in all possible situations are two very different things. Rust can have the best package manager in the world, but since we lack the actual packages to fill it in, we're simply not fully there yet 
I was not aware that Rust had a way to say "this doesn't touch globals".
ah not quite, but I'm alluding to the fact that rust globals require an *unsafe block*, so you can control access to globals (I should phrase it better). Any access to globals is either through an easily visible unsafe block, or an through an abstraction layer.
But you can't even see from outside a function if a function contains an unsafe block or not. You can ultimately only rely on reading the source. Rust should develop a way to flag a module as having zero unsafe blocks anywhere in the entire module, and rustdoc should mark such modules in it's output. Then we could start to develop a little more confidence about things.
I second that! Most notably Affine Types allow you to model State Machines in code and catch invalid state transitions at compile time. Catching a lot of Bugs besides invalid Memory. The `hyper` crate is probably the best known example for this. C++ can not do this, because its Move Semantics are not destructive. Since Affine Types are not quite Linear Types sadly we cannot make the user stop at a final state. Well, I guess there will always be some room for an even better language...
I agree, (i would actually like both options, unsafe modules (only callable from unsafe of course) and 100% safe modules/crates / import), see this idea [https://users.rust-lang.org/t/crates-io-search-by-traits-safety/12226]
I think you have to use `git@github.com` dependencies for that to work.
I think this is one tiny huge thing. Finally text programming done right 2017. This in combination with Result is a great way to hide away old sins (I'm looking at you win32).
It might be a small thing but I love [Deref](https://doc.rust-lang.org/std/ops/trait.Deref.html). If I have some kind of a wrapper type in C# or Java I often have to do something like `wrapper.getContent().callMethod()` while Rust allows me to do `wrapper.callMethod()` directly. It's a tiny thing but it adds up over time. Some may claim that it's magical, but in practice the variable name usually reflects what's actually inside the wrapper anyway, and the whole thing remains readable and uncluttered.
Yes good. Haskell lets you tag a module as Safe, and then you can't even import other things that aren't themselves Safe, or a lesser level called Trustworthy, where you can import anything and do any crazy computation but you're making the claim that the public API won't explode on your users if they read the docs. Unfortunately it's a language extension that's not as popular as I'd like it to be, so many packages don't participate in it.
...though you can use `#[must_use]` on the intermediate states to make it harder to accidentally fail to reach an intended terminal state.
This point is actually so important. This is one thing I wish C++ did. Warning: incoming rant on naming things. C++17 brings a `std::optional` type, but it misses the point of an optional type by so much that I'd say there's barely any point in using it as-is. Its biggest flaw is how unwrapping is named. You know how you've learned to be careful around code that contains lots of `unwrap` in Rust? The `unwrap` of `std::optional` is the dereference operator `*` (except using it on an empty optional is undefined behavior, so even worse than unwrapping a None in Rust). Why does the most dangerous thing you can do with the type have the absolute shortest and least visible name? The unwrap that throws is called `value`. C++17 also introduces `std::string_view`, which is like Rust's `&amp;str`, except takes 3 times as long to type. The more expensive, heap allocated string type, `std::string`, is almost half as long, so changing all your function signatures from taking `const std::string&amp;` to the more general`std::string_view` will barely make them any shorter or more readable. It's a great type, but has a terribly long name. Though, my absolute favorite has to be `std::mem_fn`. I asked a few people at my workplace if they had ever seen it used, and if not, what they thought it did. No one had heard of it, and no one could guess what it did, since "mem" usually is short for "memory" (memcpy, memmove, etc). In this case it's short for "member" (of course!), and is used to get a callable wrapper around a member function pointer (which honestly could be pretty useful if it worked for constructors, kind of like how you can pass a type name to a function taking a function in Rust). What's even better is there's also a (in C++17 removed) function called `std::mem_fun`, but there's nothing fun about it. It also has the friends `std::mem_fun_ref` and `std in::ptr_fun`. Like, why is the rarely used `mem_fn` so much shorter than the to-be widely used `string_view`? Oh, and also, references can't be stored, since they are more like aliases than pointers like in Rust (i.e. `sizeof(T) == sizeof(T&amp;)`). The way to store references in a vector, for example, is through the conveniently named type `std::reference_wrapper`. Though, to be fair, they did have the decency to name the constructing function `std::ref`. Following the naming convention for constructing functions would have led to `std::make_reference_wrapper`. In Rust: fn foo(bar: &amp;[&amp;'static u32]) In C++: void foo(const std::vector&lt;std::reference_wrapper&lt;const uint32_t&gt;&gt;&amp; bar) Sorry about the rant, but I just want to really highlight how important naming is from an ergonomic point of view. C++ does quite a few things right, but naming things is not one of them. C, on the other hand, actually kind of manages to get naming right, since the standard library is so small, and some function names are so well known that they even become standard jargon even when talking about other languages.
Rust isn't going to displace Java and I don't necessarily think that is a good thing if it did. I *do* think that Java will get more Rust-like features. Lots of folks use * [Immutable Collections](https://github.com/google/guava/wiki/ImmutableCollectionsExplained) * [`Option&lt;T&gt;`](http://www.oracle.com/technetwork/articles/java/java8-optional-2175753.html) I'd love it when a Java programmer needs to go low-level that they use Rust. There is a ton of stuff we can steal directly from the JVM ecosystem. For those not versed in it, it would be important to listen to people like /u/tomwhoiscontrary who can help use build the Rust ecosystem faster.
How do you mean? I get an error: &gt; invalid url `git@github.com/username/repo`: relative URL without a base Btw, it used to work with https urls (verified by trying to build old projects that successfully used https urls for my private repos which now fail to build). EDIT: This seems to be accepted `git = "ssh://git@github.com/username/repo.git"` but it also fails with the error in my OP post above. Why does it even say &gt; failed to authenticate when downloading repository attempted to find username/password via git's credential.helper support Why does it even try to find the username/password, instead of trying to get the ssh key? Now when I change it to `git = "ssh://git@github.com/username/repo"` (without `.git` at the end) I get a different error: &gt; Caused by: failed to authenticate when downloading repository &gt; attempted ssh-agent authentication, but none of the usernames `git` succeeded &gt; Caused by: [23/-1] error authenticating: failed connecting agent Why does it only try to use ssh-agent now, but with username `git`? Why does it fail to connect to the agent? Btw, I tried that url format after reading [this SO answer](https://stackoverflow.com/a/42982632/7488353). It seems someone had the same issue on Mac OS and solved it with ssh-add but what is the equivalent on Windows? I don't even have a file named `config` in my `.ssh` folder.
It's "her" btw. Thanks. I would like to have done a better job promoting a constructive direction. So I'm thinking of opening a discussion like this every week or two. Maybe "what part of Rust did you notice felt unpolished? - newbies especially welcome." And if it reveals things that could be RFC'd or further explored, brilliant. 
Thank you too. I didn't feel bashed.
`git@github.com:username/repo` Might be worth filing an issue for the https thing
TL;DR: Resources and the fact that these platforms are *incredibly* niche in the grand scheme of things these days. (Don't get me wrong, they may be great technically, but they're just mostly irrelevant for practical purposes... and you have to make choices in where you spend your resources.) EDIT: Actually, re-reading that last parenthetical reminds me how ironic it is (in a way) that Haskell (GHC) is *still* relevant, but people are asking for support for an (almost) obsolete platform for a sure-to-extinct-soon language? What's going on? ;)
Thanks for understanding :)
&gt; It's "her" btw. Ah, sorry. I got my OPs of discussions crossed there. &gt; Thanks. I would like to have done a better job promoting a constructive direction. So I'm thinking of opening a discussion like this every week or two. Maybe "what part of Rust did you notice felt unpolished? - newbies especially welcome." And if it reveals things that could be RFC'd or further explored, brilliant. Something like that sounds like it could be helpful. Maybe the weekly questions thread could sometimes have a "let's collect rough edges" theme. I could also see that as useful for collecting ideas for small documentation additions.
error_chain needs to be in core because otherwise doing proper setup of everything by hand is a huge chore with lots of boilerplate.
I am bringing Rust into two startups (FinTech and Cloud Services) as a core piece of the tech stack. The jobs will come.
Still: &gt; error: failed to parse manifest &gt; Caused by: invalid url git@github.com:username/repo &gt; relative URL without a base
huh. perhaps `ssh://git@github.com:username/repo.git`? I don't know otherwise.
&gt; invalid url &gt; invalid port number
+1 on using ownership for things other than safety. I Go or Python I often miss simple guarantees like "no one else but you is going to write to this map" or "the contents of this slice will never change no matter what functions I call".
With `git = "ssh://git@github.com/username/repo"` I get: $ cargo run --verbose Updating git repository `ssh://git@github.com/username/repo` error: failed to load source for a dependency on `repo` Caused by: Unable to update ssh://git@github.com/username/repo Caused by: failed to clone into: C:\Users\me\.cargo\git\db\repo-e7b8224aff10c420 Caused by: failed to authenticate when downloading repository attempted ssh-agent authentication, but none of the usernames `git` succeeded Caused by: [23/-1] error authenticating: failed connecting agent Why does it fail to connect to the agent?
It has to be a colon before username, not a slash, as I mentioned before. But this seems to be a wider issue on your system, which that won't fix.
Regardless of the platform support below, https://github.com/rust-lang/rust-www/blob/master/_includes/rustup.js#L12-L27 is how that page detects what you're on, so that always may or may not be buggy.
A lot of people are pointing out reasons Rust is better than C++, when /u/icefoxen asked for something different. Here are a few things that come to mind for me: There is **no runtime,** so Rust is happy to run just about anywhere. Lack of a runtime makes it easier Rust code into existing projects that use other languages. Eg Mozilla adding rust code into FF or the VLC folks adding rust code to their video player. Java/C# is probably going to have a much harder time integrating into existing software. **Type inference** built in from the start. Java doesn't have this. C# has `var`; I don't know if it is pleasant to use. **Pattern matching**. Enough said. **Optional types**. More languages should use this kind of construct rather than using "null" or "none". Works well with pattern matching said above. **Easy build and dependency management**. Adding dependencies to a rust project is trivial for novices compared to C/C++/Java (can't speak for C#).
No integer promotion is not an advantage, at least not entirely. It makes it very hard to compare to integers of "unknown size". So have fun comparing an isize to a c_long. You don't know which is larger, so you can't cast one to the other. Casting to i64 could solve it, but then again there's future additions like i128, which one of these could theoretically be (especially if one of them is a typedef). So you have to cast to the possibly largest int type, just to be safe, but they may not necessarily be fast to evaluate, so you either opt into a possibly slow comparison or you are risking cutting off some bits.
with a colon it says `invalid port number`
I found [this thread](https://users.rust-lang.org/t/problem-using-ssh-urls-for-external-crates-with-cargo-on-windows/7928) where someone had a similar problem. It says: &gt; I checked that ssh-add.exe -l contains the proper key I also checked that, and it prints the proper key. So the main issue is that cargo fails to connect to ssh-agent.exe for some reason: &gt; [23/-1] error authenticating: failed connecting agent
I don't know of any crate which implements BufRead for channels, but if you provide some more information I may be able to help you. Can you explain more about how you are using channels? Why not read directly from the S3 reader into the FTP writer? Which S3 crate are you using?
&gt; Not that long time ago we've seen malware in cargo repo (crates.io)... Hm? What are you referring to here?
The way I use channels — setup buffered channel between thread that downloads chunks from S3 and thread that uploads to FTP. Feed byte-by-byte from downloader to uploader. rust-ftp has put method that takes `T: Read`. For S3 I use aws_rust_sdk. 
I am quite surprised that no one mentions data race freedom... While there are a lot of popular memory safe languages, all of them either single threaded or "concurency-unsafe" (the only exception that I know being Erlang). Really, data race freedom is as awesome from the Java dev perspective, as memory safety is awesome from the C one :) Just today I spend quite a while fixing a nasty concurrency bug in IntelliJ Rust, and I was very lucky to have found it in the first place! We as a community should probably market fearless concurrency more :) 
&gt; However, upon inspection, this is mostly NOT about Rust-the-language-itself. And that's important for me. The ecosystem around the language is just as important as the language featuers themselves in my opinion. C++ was the first language I learned, and I hated it everytime when I had to deal with dependencies and various build systems, trying to get it to run cross-platform. The reason that I went away from low level languages weren't the languages themselves, but the toolings around them. They just were way worse than what higher level languages offered. Rust is already doing a very good job in this regard, and was one of the reasons I decided to try and learn it in the first place. And there's still a lot of ongoing work to make it better.
Are there any benefits to using this over Rocket (My go to framework since its launch)?
I think lifetime based destruction is pretty cool. `Drop` beats explicitly freeing resources or using a language construct like `with` to put the resource into its own explicit scope.
Rust made it easy for me to *get it right* the first time. Once I survived the gauntlet of compiler errors and wrestled with the borrow checker, there was an extraordinarily good chance my code *worked*. In other words, Rust made *program correctness* easy. In most any other language I've used (Python, C++, Java, etc.) I've hit some kind of brick wall when getting my programs to work: NoneType errors, TypeErrors, segmentation faults, NullPointerExceptions, ConcurrentModificationExceptions, memory leaks, and on and on. These kinds of errors are nigh impossible to track down, and have wasted countless hours of my time. I can't pinpoint a single feature of Rust that avoids these (Options instead of nulls, forced Result handling, borrow checking, explicit referencing with &amp; and &amp;mut, immutable by default, documentation that I actually like looking at), but the sum total of all of these tiny design decisions is a language that makes correct code easier. My experience with Rust has been building a Lisp parser [(link for the interested)](http://github.com/jzhu98/telescope), and it's been nothing but amazement for me. I've refactored it more times than I can count and every time I did so fearlessly, knowing Rust would have my back on error handling and clear, explicit compiler errors. (Lifetimes is perhaps the one thorn in my side.)
Without seeing the code, my main suggestion is to paste both into godbolt.org, add the appropriate optimization flag (eg. `-C opt-level=3` for Rust) to each compiler's options field, and compare the colour-coded assembly-language output. * **Rust:** https://rust.godbolt.org/ * **C/C++:** https://gcc.godbolt.org/ (Optimization flags matter much more to Rust in this case, because, without them, not only will you get unoptimized code, Rust will generate a big pile of boilerplate to panic on things like over/underflow.)
Impossible to truly say without seeing the code.
&gt; So have fun comparing an isize to a c_long. &gt;You don't know which is larger, so you can't cast one to the other If you have to solve such problem often, why not create separate crate with cast to biggest and compare functionality? This crate may use `build.rs` to find suitable `biggest` type for each pair of types, or `#[cfg(target_pointer_width =`. Any way, I can not see technical problems with that, while in `c++` you can not disable integer promotion.
Thanks, I just tried that. But somehow -C opt-level=3 does not work with my code. It just displays nothing at all. Without the optimization, the resulting asm code is 10880 lines, while the unoptimized C code is just 306 lines (both with all settings default). But I guess that's the boilerplate you were talking about ^^
You're right, I apologize. I am speaking from my own experiences, here: I feel a definite hesitation when I face a problem and I recognize a non-std solution or a use for `unsafe`. It is a common feeling within the Rust community, I believe, and it has merit. My point is that that feeling is driven by a desire to avoid something *real*, but if someone would rather use C than `unsafe` or user libraries... then all the justification for that hesitation is lost, and it really does become an irrational choice. There are good reasons to use C, but an unwillingness to use `unsafe` and non-std code are not among them.
Unoptimized Rust is pretty ... suboptimal, much worse than unoptimized C. Rust uses a lot of abstractions that get easily optimized away but that will only happen if they're on.
I'm not angry. I have been told I have a very condescending way of speaking, even amongst those who love me, so perhaps some of that is bleeding through? &gt;I'm not talking about "every earthly conversion function". I'm specifically talking about this one, memory compatible function. I see no reason why this conversion is more important than every other memory-compatible conversion. (Of which there are many.) I don't think Rust's high-level (i.e., safe) semantics are attempting to form a good model of the machine representation of various kinds of data, but rather a strongly typed representation of the processes of algorithms. The `unsafe` keyword exists precisely to allow people to build high-level models of low-level data. One does not do high level programming under the consideration of the equivalence of memory representations. Either way, I disagree that this is damning of Rust's standard library. I think it may convince a few people to not like Rust, but I'm not even convinced everyone *should* like it.
*Update* I just realized, that the main function needs to be public for rust.godbolt.org. However, after using the optimizations (-C opt-level=3), the code is still 3055 asm lines which is pretty much 10x the C code.
It's a slash when you use ssh:// It's either ssh://git@github.com/user/repo.git or git@github.com:user/repo.git 
ohh, that makes sense. TIL.
Honestly, the boilerplate for doing errors *properly* is quite large, but i do prefer something like [derive-error](https://github.com/rushmorem/derive-error) to error_chain. Adding a derive to an error enum just feels a lot nicer than the way error_chain works (imo).
I've been working on a little script as a way to learn Rust, but am stumped on a lifetime issue. The program takes two file paths and then calls a *word_set_from_file* function for each file path, which opens the file and creates a **BTreeSet** of its words. words in a file are separated by commas with possible white-space. I got a first version working only by creating new Strings and returning **BTreeSet&lt;String&gt;**, which avoided ownership/lifetime issue. In this version, I want to avoid creating new String objects and just create a **BTreeSet&lt;&amp;str&gt;** with a lifetime tied to the file contents String. I thought if I contained both the String and BTreeSet&lt;&amp;str&gt; in a struct, this would work. struct FileWords&lt;'a&gt; { contents: String, // references to slices of contents String word_set: BTreeSet&lt;&amp;'a str&gt; } But I still have a lifetime error related to the *contents: String* https://play.rust-lang.org/?gist=be8af3865a5c5760d02d563c244f3230&amp;version=stable How do I fix this? Also, is it possible to get rid of the FileWords struct and just return BTreeSet&lt;&amp;str&gt; from *word_set_from_file* or is the struct necessary in order to own the String? 
Awesome! I somehow couldn't find it on the website -- is there a minimal "hello world" example?
What I'd suggest is to use a [sync_channel](https://doc.rust-lang.org/stable/std/sync/mpsc/fn.sync_channel.html) with a small bound to keep the S3 thread from getting too ahead. Have the sync_channel actually send the S3 response (whatever implements `Read`) to the ftp thread. Something like this pseudocode: let (sender, receiver) = sync_channel(2); thread::spawn(move || { while let Ok(reader) = receiver.recv() { ftp::put(&amp;mut reader); } }); for url in urls.into_iter() { let response = s3::get(&amp;url); sender.send(response); }
Fixed some layout bugs and added support for margins :) [here's another screenshot](http://imgur.com/a/b78i6)
`extern crate "oxidated-iron" as iron` looks cool
Just started looking into it. I once used Cap'n for message passing on a web server, but didn't realize it was being used for RPC.
There's probably a way to return the ownership from the function like you wrote it, but I don't know what it is. Self-referential structs are hard. It's easier to just separate the two operations so that it's easy to move ownership of the file buffer into main(). https://play.rust-lang.org/?gist=5e99316ca7bb10386cacf27a339043a9&amp;version=stable
Pedantic comment: &gt;Before your browser connects to a website, it performs a 9 step handshake by means of which it makes sure that your connection is secure and the parties involved in the communication *are not malicious*. This is not the case. [Malicious websites can and do use TLS](https://www.helpnetsecurity.com/2017/05/19/number-https-phishing-sites-triples/). TLS just ensures that you're connecting to the right server for the domain (or company for EV certs).
A short summary of the conversation I had with the author last Saturday is basically "even in CubeSats, which are fairly exploratory, there's still a fair amount of institutional inertia and constraints that are hard to push. That said, if Rust gets into orbit anywhere, I would expect it to be in this market first." I am in position to use a Rust application on the ground that will be an important link in the telemetry processing chain for one of our missions; we'll see if that actually lands. My company is very interested in Rust's potential and if I ever cook up a decent introductory powerpoint/demo for it I have at least some audience ready to go.
Looks perfect, thanks!
That's really not pedantic at all as it's a very common misperception. What it *does* guarantee is that there's no man in the middle (provided the TLS certificate signing checks look good).
casual uses of `.unwrap()` in production code are an antipattern, and one that the community is working to push out from examples. Any function that uses `.unwrap()` often should be returning `Result&lt;T,E&gt;` or `Option&lt;T&gt;` instead, or otherwise appropriately handling the failure. `return Err(_);` is Rust's `throw _;` statement. `fallible().unwrap();` and inducing a panic is ... I don't know what its parallel would be in exception-throwing langs, as I don't think libraries can unconditionally exit the program except via the standard exit mechanisms.
there's really no way to help without seeing the code. Rust is absolutely as fast as C under normal circumstances. I know in the code you posted before, you were limiting the number of threads to 8. You might try 16 for your R7 1700. You should also compare Clang and GCC. Clang is based on LLVM like Rust is, so it will allow you to eliminate one more variable. GCC sometimes magically finds some optimizations that LLVM does not (and vice versa, depending on the problem at hand). If the performance gap is still there with Clang, then there's something suboptimal in the Rust code you wrote, which we can't help with without seeing the code.
Even a lot of C++ programs don't use exceptions because of the code bloat and performance that may arise from using them (this is probably less true with modern compilers, but still enough to turn people off from using them). The worst thing about exceptions is that as soon as you introduce them your whole codebase becomes a minefield such that you can't easily determine which functions might throw an exception and which won't. It just leads to odd anti-patterns such as C++'s STL stack class having to be read from and then popped separately, rather than the pop function returning the top element, which can't happen due to exception safety.
Line counts don't tell me much, so all I can suggest is to use the "highlight corresponding source/asm blocks on mouse hover" functionality to narrow down which bits are so much bigger, then ask about those specifically. Also, as /u/coder543 [said](https://www.reddit.com/r/rust/comments/6t4mx2/rust_way_slower_than_c_in_calculations/dli1ori/), try compiling the C version with Clang to see if the C code runs more slowly when exposed to the set of optimizers Rust relies on rather than GCC's.
Er, that's not quite true. The operations that are valid for integers, unsigned integers, and floating point numbers and the effect that they have on the data stored in memory are different. It's been awhile since I studied floating point, but I'd actually expect it to be different value even for the form you posted. Whereas for the forms of T you posted, it's entirely possible that the only difference that will ever exist is at compile-time no matter how you mutate the value.
I was playing Mass Effect: Andromeda, and got stuck on one of the harder decryption puzzles, which are basically sudoku. So I wrote a super user-friendly helper. First, you write a text file that looks like this: -- Size 5 -- Tile Def 1 2 3 4 5 5 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 2 0 -- Block Def 1 1 1 2 2 1 1 3 2 2 4 3 3 3 2 4 4 3 5 5 4 4 5 5 5 Where 0 in the tile def is an unknown. Then you just pass in the file path to the program, and you get the most gorgeous, easily-readable [output](http://i.imgur.com/NjNGLzc.png) possible. Naturally, to update the grid, you just update the tile def in the text file and re-run.
Uhmmmm no. It's one large file that needs to be uploaded as one large file. S3 response is usually lots of meta data + body as Vec&lt;u8&gt;. I need to have one stream of bytes that get's populated from multiple S3 responses. I can't keep entire file in memory because it's 200Gb and AWS Lambda would kill this function when it reach limits. I will publish what I've wrote tomorrow. It works on small files, trying to figure out why it doesn't work on big files. 
I think the "parties involved in the communication are not malicious" is refering to an alice and bob style situation. The malicious-ness of websites happens on a different layer that is out of scope in the article.
Sum types killin it
I'm not sure you actually intended to leave `Result` to the side, but what's your opinion on `Result` versus panicking?
Amen!
I don't know what it's like on Windows, but on Unix applications find the SSH agent via the `$SSH_AUTH_SOCK` environment variable. It doesn't matter if `ssh-agent` is running if apps don't know where to look for it.
I haven't got time for that. But it's definitely in my TODO list. 
I don't think `tokio` can assume a single sane default here, so a utility method would be nice. Something like: fn handled_spawn&lt;E: Debug&gt;(core: Core, task: Future&lt;(), E&gt;) { core.spawn(task.or_else(|e| Ok(eprintln!("{:?}"))) } (Untested code, on mobile - but something like this is what I would do)
This looks cool! I am excited for this... but also I have at least 2 confirmed Aussie Rustaceans and I don't feel so alone :P (I am aware there are others I just don't see many!)
First off, ssh-agent is only useful if you actually passphrase-protect your keys. If you don't do that, you shouldn't need the agent or any credential helper at all, and you can just rely on your `~/.ssh/config` instead: Host github.com IdentityFile /north-pole/github_rsa I don't know how ssh talks to ssh-agent on Windows. On Unix-like systems it's done through socket files, which don't exist on Windows. But in any case there's usually a couple environment variables needed to tell where the ssh-agent is listening on (`SSH_AUTH_SOCK` and `SSH_AGENT_PID` on *nix). When you run `ssh-agent` in the terminal, it should print a few lines of shell script. You have to copy-paste and execute that mini-script to set up this environment, and then all descendant processes will be aware of the ssh-agent. (At least that's how it worked back then. It's been a while since I've used ssh-agent, and it was annoying to set up on Linux and probably worse on Windows. These days I prefer to use multiplexing + ControlPersist.) &gt; Btw, when I do git config --global credential.helper it just prints an empty line. An empty line, or nothing at all? I don't have anything configured, so it prints nothing, not even an empty line. If you have it set to an empty string that might confuse Git. Try `--unset`ting it?
When I start the git shell from GitHub Desktop, it has in its environment the proper env vars: &gt; SSH_AGENT_PID=13648 &gt; SSH_AUTH_SOCK=/tmp/ssh-2UtmuWi7yael/agent.62968 And when I check with `ssh-add.exe -l`, it can connect to ssh-agent and it prints my proper key file. (Compared to when I kill ssh-agent, then it fails.) But why can't cargo/libgit connect to ssh-agent via these env vars?
Btw, this example is now part of miri's test suite, making sure it will always detected to be UB :) &lt;https://github.com/solson/miri/blob/dca1be68ffd210b8e5fd75ece221f2733eb9991a/tests/compile-fail/validation_buggy_split_at_mut.rs&gt;
I meant it prints just a newline character. After I `--unset` it, it's the same. And I never set it before, so that's not the problem. Yes, when I run ssh-agent, it prints e.g.: SSH_AUTH_SOCK=/tmp/ssh-sNX7RW0mgs5u/agent.30440; export SSH_AUTH_SOCK; SSH_AGENT_PID=49612; export SSH_AGENT_PID; echo Agent pid 49612; But that starts another instance of the ssh-agent.exe. When I start the Git Shell from the GitHub Desktop app, it ensures that ssh-agent.exe is running in the background, and starts powershell with those env vars (and I see them when I print the env). And that works, when I check with `ssh-add.exe -l`, it can connect to ssh-agent and it prints my proper key file. (Compared to when I kill ssh-agent, then it fails.) So the issue isn't with ssh-agent not being reachable (because `ssh-add -l` can talk to it) but cargo/libgit not being able to talk to it for some reason. And btw, I don't have a file named `config` in my `.ssh` folder, and cargo/libgit wouldn't use that file anyway.
I suppose, but the server can still be compromised, but seeing that little lock on a website make people feel too secure. Yes, it's not really the same thing, but I try to make that s clear as possible since TLS is so visible that it's easy to get a false sense of security.
Yeah, that all looks pretty sensible. Just to double-check I understand correctly (again, I'm not very familiar with Windows): - you launch a git shell from GitHub Desktop - from within that shell, you can "git clone ssh://git@github.com/your/repo" - from within that same shell, "cargo build" can't clone the repo. One thing that occurs to me is that the SSH agent socket is (on Unix) a Unix-domain socket on the filesystem, which is not a thing that Windows (or NTFS) supports. Some people run SSH on Windows via Cygwin, which does some clever hackery to emulate Unix APIs like Unix-domain sockets on Windows; your `SSH_AUTH_SOCK` value suggests some kind of Unix-emulation layer like this. On the other hand, some versions of SSH are actually ported to Windows. Those must use a different rendezvous system, since real Unix domain sockets aren't available, and they don't want to re-implement all of Cygwin's hacky emulation layer. If GitHub Desktop is giving you a Cygwin-ish environment, and Cargo is looking for some kind of native Windows environment, that might explain the mismatch.
Yeah, I'm well aware of what Result and panics are. I'd rather have exceptions. The reality is that while panics are for unrecoverable exceptions you *do* want to recover. Rust makes no difference between an unrecoverable bug and a recoverable bug. [edit: remove oom statement] When you write Java services it's *very* common to propagate 'unrecoverable' errors all teh way to the top level. You kill the thread, clean up, start over. Rust has catch_unwind for this. It is *nowhere* near as good. You lose all context - I can't say "retry this payload" or "giveup on this payload". It's just "fuck something happened owell".
&gt; casual uses of .unwrap() in production code are an antipattern, and one that the community is working to push out from examples. It vwill always exist. There will always be a dependency with a bug. &gt; return Err(_); is Rust's throw _; statement. No i tisn't. It's a checked exception. I want *runtime* exceptions, in some cases.
Result is checked exceptions but way better. Panicking is... a terrible runtime exception. It's "terrible" from the perspective of a Java developer, it's wonderful from the perspective of a C++ developer.
In addition to the "inertia and constraints", the development lifecycle for aerospace products are looooong. So it takes a long time for new technology to gain momentum and get introduced into new projects. Plus decision maker's can be afraid of new technology because of the risk of failure. Easy to get fired if you picked some "new/trendy" language for a new satellite (big or small) and it failed for some unforeseen reason (versus the "tried and true" C++ or Ada). That being said, I'd love to see Rust be used in future Aerospace programs. But it'll take time for ground or flight adoption and I think it'll happen as long as Rust stays strong for the next 10-20 years. :)
Hm, yeah I was imagining that the S3Response would block on read() and fetch the next multipart chunk... but then you're back to just having a single thread essentially.
A cursory inspection of https://github.com/libssh2/libssh2/blob/64ebfd8182a9b6e637e65c3059e3798e199274b3/src/agent.c shows that on *native* Windows platforms the only supported SSH agent implementation is Pageant (from Putty). Therefore, if Cargo is built for native Windows (non-Cygwin/MSYS2) then it probably does not support anything other than Pageant. Perhaps set up Pageant and see if that works?
Curious about the reasoning behind returning state and response separately.
You could just ask, is `sizeof (isize) &gt; sizeof (c_long)` and then cast one way, and if not cast the other. The optimizer will take care of this branch for you. In C++17 we have static if, and then even the frontend will take care of it for you.
I didn't know what the big deal was about null pointers until I started working professionally in C#. It's the source of so many runtime errors and all completely avoidable if the language went the direction Rust did.
Here is what I have — https://github.com/andoriyu/glosh/blob/master/src/downloader.rs. So S3Request allows specifying Range header so this what I use to split file in chunks. 
I'm very surprised by the performance results. We ran into [huge performance issues](https://github.com/ctz/rustls/pull/85) when using `rustls` in production. And apparently, the benchmarks were made with the current version, which I believe it does not include this fix. I believe more benchmarks are necessary.
If it helps: I published the `iter-read` crate a while ago, which provides a `Read` type for iterators over `u8`, `&amp;[u8]` or `Vec&lt;u8&gt;`, and channels provide `::iter()` to turn them into an iterator.
It looks like that was merged in. Does that mean your perf issues were fixed?
A ring buffer should perform well for this use, like this: https://github.com/mattico/glosh Can't actually test this, but you should get the idea.
Another pedantic comment :) &gt; Ring is a fork of BoringSSL which is written in Rust. I'm not sure that's quite accurate. Ring includes some C and assembler crypto implementations from BoringSSL, but it's a small subset, and it exposes its own API.
Why is the compiler not on the list?
Please !!!!!BRING ON THE EFFICIENCY
&gt; The integration works for WPT’s but does not work for Android. We need to check on that WPT? 
I use the Microsoft credential helper installed with Git for Windows. That could be what it's looking for when it says: &gt; failed to authenticate when downloading repository attempted to find username/password via git's credential.helper support
That should be solved by a crate that keeps track of sizes and offers comparisons.
Sounds like there's still an unbounded buffer in there with no backpressure, which is a problem by itself.
As /u/valarauca8 mentioned: Proper UTF-8 handling. Haven't yet seen any other programming language doing that job as well as Rust does. C++ does... acceptable now with a somewhat proper `char32_t` types *(Lookin' at you both, Java and C#...)* and a byte-based `std::string` that might contain proper UTF-8 by accident. Why somewhat proper `char32_t`? You can still easily put invalid code points into it. In addition to that, by far my most beloved feature of Rust is `cargo`. Packaging and project management hasn't been this well-done and easy in any other language I learned. Especially compared to C++. Really, comparing it to C++ would neither be fair, nor interesting. C# has Nuget, which does okay. The only complaint I have now about `cargo` is that it is possible to have two different minor versions of the same crate linked into your Rust project, because of some ridiculous version restrictions in some of your direct or indirect dependencies.
deleted ^^^^^^^^^^^^^^^^0.2771 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/20003)
I finally managed to figure it out: let func = move |(some, arguments, ...)| report_errors!({ ... }); Core::spawn(stream.for_each(func)); macro_rules! report_errors { ( $func:expr ) =&gt; {{ let func = || $func; func().or_else(|e| { println!("error: {}", e); for e in e.iter().skip(1) { println!("caused by: {}", e); } if let Some(backtrace) = e.backtrace() { println!("backtrace: {:?}", backtrace); } ::futures::future::err(()) }) }} } 
web-platform-tests
Would #![allow(unknown_lints)] help here?
&gt; Rust makes no difference between an OOM and a bug. Well, OOM gives an instant abort in Rust, not a panic. (At the moment, but fallible allocation is a hot topic.) &gt; Rust has catch_unwind for this. It is *nowhere* near as good. You lose all context - I can't say "retry this payload" or "giveup on this payload". It's just "fuck something happened owell". If you reserve panicking for only outright programmer errors, what context could you even store? If you've encountered a bug, then by definition something has happened that you didn't think *could* happen. So how are you going to write code that makes a smart decision? How can you make sure that your decision to retry or give up is the sensible one, when you don't even know why you're here and what state your program is in? `catch_unwind` is great as an unintelligent, last resort recovery. Maybe send a generic HTTP 500 message, log a critical, and then start over on a clean slate. Maybe even throw a controlled core dump, and let systemd restart you. It's not intended to be the Rust equivalent to exceptions, it's intended to be the Rust equivalent of C-style Undefined Behaviour or `assert`. And I'll take panics over UB any day. 
This is really great work! I am immensely happy to read of your progress. Also I think having ways to relax the rules in a more fine-grained way around unsafe code would be the best way forward, allowing for both experimentation and improved safety at relatively little cost. As you know, I'm looking for ways we can augment your dynamic analysis (via miri) with static checks (via clippy). I wonder if this would be better served by a third lint pass, this time on MIR (perhaps `TooLateLintPass` 😁). Maybe /u/Manishearth has an idea here?
How mature is ring at this point? Last I checked, it hadn't been verified by third parties, but that was some time ago.
deleted ^^^^^^^^^^^^^^^^0.5396 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/29389)
When I create a scalar/literal binding such as let x = 5, or let x = "foo", am I correct in thinking that 5 or "foo" would be stored in the program at compile time, and then allocated to a region of the stack in the relevant scope? If so, from an internal point of view, if I create another variable: let y = 5 or let y = "foo", both bindings are looking at the same area of memory holding the appropriate value? If so, then is it the case that if I make: let mut c = 5, it will also look at the same place as the variables x &amp; y until it is changed, at which point it will look at some other place in the stack that holds the scalar / literal (e.g. if it was changed, c = 7)? Finally then, when shadowing a variable, is it the case that let x = 5 will point to some fixed scalar value on the stack, and when let x = 6 comes along, a new binding is created looking at the exact same place, but the original x's information is stored somewhere so that when x = 6 goes out of scope and is destroyed, the original x = 5 is brought back into the picture? I guess I'm just trying to understand so I can build a mental model of how shadowing / assignment works for stack-allocated variables.
I agree with you that too many things panic in Rust (indexing is essentially a worthless footgun for anything except constant indexes) but I don't think that adding "proper" exceptions is the right answer. Exceptions are not zero-cost, they impose a global cost on the program if you want to use them anywhere. If a single library decides that it wants to use exceptions for error propagation for a non-fatal condition because the programmer can just catch them then you have no choice but to have a global size and speed penalty on your program or to use a different library. You have to choose between forcing Rust to be slower than C (unacceptable) or having an exceptions/no-exceptions split in the ecosystem. If your software panicks, that is a bug. It sucks but it's better than the alternative.
Is there a way to configure Clippy lints outside the code itself via a config file? That would suit my usage better than `cfg` lines.
I asked for this on GitHub once and the answer is no. I do hope it implemented at some point 
Yes.. It would work. I doubt there's a better way available. What is everyone else doing? 
You can use `cfg_attr` to conditionally activate lints in certain environments. (Have a look at some of my crates, they either have a `lint` feature and a pinned clippy version or install `cargo clippy` on CI.)
[removed]
Github Desktop is not using Cygwin but Msys, that I can be sure. 
Folks either use `#![allow(unknown_lints)]` or do `#[cfg_attr(clippy, allow(foo_lint)]` or something like that (the clippy readme has more on this)
I will test it tomorrow and get report back.
That's kinda what I was looking for originally. Thanks!
I think I've missed the part about conditionally allowing using `cfg_attr`. Thanks! I'll take a look at the readme once again
Completely independent of any considerations of memory management or concurrency, I absolutely *love* how Rust's ownership and borrowing rules can provide robust guarantees about data sharing and various forms of immutability. The reason that languages like Haskell, OCaml, Lisp, Elm, etc make such a big deal about "functional purity" is that a language with pervasive immutability guarantees you can never have an object "in two places at once," change it in one place, and have that change be visible from another place -- in other words, the whole *purpose* of functional purity is that it eliminates aliasable mutable objects. Since aliasable mutable objects are basically the data-flow equivalent to a `goto` (an action in one "part" of a program jumps in a completely unstructured, invisible, unrestricted way to another far-flung "part" of a program), it turns out that removing them can have *awesome* benefits for readability and maintainability in complex codebases. Unfortunately, it's difficult to make languages based on immutability performant, and some tasks are more naturally expressed in terms of *local* mutability. What's incredible about Rust is that it takes a completely new approach to the alisable-mutable object problem: instead of restricting *mutability* and allowing aliasing, like traditional functional languages do, it restricts *aliasing* and allows mutability. You get all the same benefits with regards to maintainability and ease of analysis -- a change to an object "over here" can't subtly propagate "over there" -- but you also circumvent many of the downsides of traditional functional programming -- performance is as good as it would be with unrestricted mutability (or better, if the compiler is smart enough to take advantage of clever optimizations!), and most algorithms requiring mutability can be written just as naturally as they could be without the aliasing restrictions. Functional purity was never primarily about performance or eliminating the need for garbage collection, but it's been popular for *decades* anyway *purely because of the architectural improvements it provides by restricting mutable aliasing*. Rust's ownership and borrowing system, which was AFAIK created primarily for its wonderful practical benefits regarding memory management, concurrency, and other low-level considerations, turns out to *also* provide all the same great architectural benefits that have long been considered good enough justification *on their own* to adopt a functional programming paradigm. I can say from experience that there are projects where I've "fought with the borrow checker" for a long time trying to get an algorithm that I thought required mutable alisable data to work, only to realize that if I cooperated with Rust instead of fighting it the compiler would lead me to *better designs* that were clearer and simpler *because they didn't require mutable aliasing*. A compiler that will catch not just obvious, critical errors but also *subtle design flaws* with your code is an almost magical tool, and I miss the borrow checker enormously when working in other domains, like Webdev, for reasons completely unrelated to performance, memory management, or concurrency.
That is until you throw CJK fonts into the mix, which is of a different height system, which isn't even mature yet since it's too costly to make a font in CJK. Then there's the problem that they include annoyingly bad monospace alphabet glyphs which prevents fallback. The best people can get is a hack called Source Code JP. 
&gt; Since Affine Types are not quite Linear Types sadly we cannot make the user stop at a final state. Well, I guess there will always be some room for an even better language... There are several work-arounds for that: 1. Absolute (but constraining): Introduce a `ProofOfWork` final state, and have a final transition from the "real" final states to `ProofOfWork`, then have the functions using the state machine forced to return a `ProofOfWork`, 2. Flexible (but no absolute): Use `#[must_use]` + a crashing/warning `Drop` for the non-final states.
error_chain is quite powerful, yes, but not that difficult to use if you already know the manual way to handle errors IMHO. A bit simpler (without type aliases, backtraces, and ErrorKind types) is the quick-error crate.
I'd seen Cargonauts but only in as much as I had previously read the blog post you linked here. I'll reach out to @withoutboats once we've recharged a little after the 0.1 push and find out more. Look forward to hearing any feedback you might have.
&gt; If you reserve panicking for only outright programmer errors, what context could you even store? If you've encountered a bug, then by definition something has happened that you didn't think could happen. So how are you going to write code that makes a smart decision? How can you make sure that your decision to retry or give up is the sensible one, when you don't even know why you're here and what state your program is in? This 100x! Whenever I see arguments for exceptions, they blithely ignore that error recovery is **hard**. If you were not attentive to prevent the exception from occurring in the first place, why would you *assume* that you have any idea as to what state is corrupted and what state can be reused? Exceptions are easy to throw, but nigh impossible to handle correctly.
I look forward to seeing some code or a blog post on how you find it!
To be fair, the awkard interface of `stack` has more to do with legacy: pre-C++11 did not have move semantics. There is few classes that are movable but for which the move may throw (and I wish there were **none**), and this property can be detected at compile-time. I'm still not sure why the standard library so desperately cling to consider throwing move constructors/move assignment operators first class when they are so rare, and is willing to cripple APIs/torment implementers to make it happen. It's one of the those case where I'd like a harder stance: "Look, if you want to use such awkward types, just write your own containers."
Great suggestion, I've captured the tutorial idea as https://github.com/gotham-rs/example-app/issues/2
Let's get in touch, I would be really interested to hear about your experiences in this space.
I'd rather we wait a bit here; Rust's error handling is still very new and very much unexplored, there's no reason to settle on "the" way to handle error now, when we know least. Rushing things in the `std` then leads to Python's situation where the standard library is regarded as "where libraries go die".
Please reach out if we can be of any help.
deleted ^^^^^^^^^^^^^^^^0.7741 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/43014)
To be honest, `char32_t` is horrible. Nobody wants to pay a 4x overhead for mostly ASCII strings which sometimes happen to contain something else.
We've thrown around a few hand wavy ideas on this but we don't have a concrete direction yet. There are a few challenges, such as those mentioned below, to overcome. Is your current solution on GitHub somewhere so we could take a look?
Totally understand where you're coming from, though for me it is often a case of "write routing code once" and then forget about it so it hasn't been problematic. That said we can do better here, I believe a lot better so do keep an eye out for 0.2!. You might also find the [Router setup in the example app](https://github.com/gotham-rs/example-app/blob/master/src/boot/router.rs) a little easier to read/understand as it carries a lot more comments.
Like the other folks here we worked on this late at night and on weekends whilst juggling full-time work and families. Very much a case of building the web framework we want to use ourselves. We make no money from Gotham at all. If one day we figured out a way to support ourselves/families whilst working on Gotham and other Rust open source full time then that would be fantastic.
There is an answer to this but I need to think about the structure a little bit more. Any chance you could put an issue in on the [Gotham repository](https://github.com/gotham-rs/gotham/issues) documenting your use case so I don't forget this? 
[There sure is](https://github.com/gotham-rs/example-app) however in this case it is less "Hello World" and more "Hello Izzy"....
Poor relative font-size spec which now no one uses. 
I was thinking of offering a jar of Vegemite, posted anywhere in the world, for the best usage of Gotham folks open source before the end of September. We'd have to point out [the proper way to eat it](https://www.youtube.com/watch?v=P_sUhTWtvG4). I wonder if that would be a positive or negative thing on uptake?
[clippy](https://github.com/rust-lang-nursery/rust-clippy) has your back! When trying something like your code out in the playground, clippy produces this: warning: operator precedence can trip the unwary --&gt; src/main.rs:5:17 | 5 | let label = num &lt;&lt; 32 + ty; | ^^^^^^^^^^^^^^ help: consider parenthesizing your expression: `num &lt;&lt; (32 + ty)` | = note: #[warn(precedence)] on by default = help: for further information visit https://github.com/Manishearth/rust-clippy/wiki#precedence
&gt; A different Shaun (https://github.com/smangelsdorf) And now /u/smangels as well.
Both projects have had a lot of hard work put into them and we wouldn't want to make direct comparisons, there are simply different design decisions that have been made, both of which have their place in the ecosystem. I can say that we're really proud of our usage of stable Rust, our async types and the way we've implemented Pipelines and Middleware. We're also really happy with how our Handler concept has worked out. Another aspect of Gotham we really like is our Router. It is backed by a Tree data structure and can solve some very complex routing needs including delegating routing decisions to secondary Routers to allow for what we call "modular applications". I think of this as being half way between microservices and monoliths, combining the best of both. The Router will be a big focus for 0.2, leveraging macros and/or builders to make route definitions much more along the lines of what you'd see in Rails or Phoenix. We look forward to feedback from the community, I am sure there is a lot we could be doing better or haven't thought of.
Coming from Haskell reading this my reflex is "oh Rust still doesn't have monad and return"
Thank you. An initial version is already there: https://github.com/sunng87/handlebars-gotham 
I took another look at ErrorChain, it turns out it was exactly what I wanted. Thanks!
We've kept `State` distinct from `Request` on ingress and `Response` on egress because that felt like the clearer choice. The types prove that the `Request` and `Response` values exist when they should exist, so the compiler forces you to return one. The other alternative, I suppose would be to have the `Request` and `Response` values stored in `State`. It would make the function signatures more simple, but could (in my view) confuse the separation between the two. 
One thing I want to highlight is security, but not in relation to memory safety. There are two aspects of this: how easy is it to craft a usable exploit, and how valuable will that exploit be? For ease of crafting, Rust has several advantages over Java. First, there are a number of features in Java that, while seemingly nice to have, also have great security risks associated with them. Things like dynamic loading of classes, reflection, and the ability of all classes to be (de)serialized, all make it easier to manipulate the code into doing something malicious at runtime. [This paper](https://www.abartel.net/static/p/ccs2016-10yearsJavaExploits.pdf) has a great overview of the security issues in Java. At the same time, the Java runtime is *massive* with a ton of complexity in it. So inherently there's a much greater risk of the developers behind it not having caught some corner case that's ripe for exploitation. In terms of how valuable the exploit is, the fact that Java is cross platform makes it a juicy target because these exploits will work regardless of OS. While Rust is also cross platform, it's only in the sense that it can easily be compiled for different platforms, not that you can take the same binary and run it on different platforms. At the same time, since Oracle has decided to make the Java update process thoroughly unpleasant ("No, I don't want your stinking toolbar!"), it's guaranteed that there's a bunch of old Java installations lying around, waiting to be exploited, making Java even juicier. Now, Java does have an easier time with for example sandboxing, where you can limit untrusted code to run with fewer privileges. To the best of my knowledge, Rust relies on the OS for this control, but that makes it hard to work with in a cross platform way. Unless someone were to build it into their application manually ([some work](https://github.com/servo/gaol) does exist!). Of course, Rust code can still have security issues, in which case it's important you push out an update. But that's the same situation you are in with Java. And right now, Rust also benefits from being much younger than Java, and hence also more obscure for hackers to work with. But I still have a certain feeling that Rust is simply much safer than Java by design.
It works on stable rust
I do not quite get your point. Rust's `char` is a 32-bit type as well. I was not writing about strings of `char32_t`s, but about having a proper type for single code point operations like parsing. The wide string types `std::wstring`, `std::u16string`, and `std::u32string` are a waste of memory, yes.
Have a look at my project [json_typegen](https://github.com/evestera/json_typegen) which does code generation from JSON samples, with one of the interfaces being a lot like a type provider. I'll do a more complete write-up with the upcoming 0.2 release, but for anyone interested, [my just delivered master thesis](http://erik.vestera.as/thesis/) briefly looks at what it takes to implement a type provider, contains explanation of the algorithm used in json_typegen (adapted from F# Data) as well as a simplified version of the source code, for anyone looking to create something similar for other formats, or contributing to json_typegen.
A TLDR of my thoughts on "can we have type providers in Rust?": Yes and no. There are two kind of type providers. Type providers that provide types for a "reasonably sized" type space, say based on a JSON sample, and type providers that provide types for very large or even infinite type spaces (the most common example is [F# Datas WorldBank Provider](http://fsharp.github.io/FSharp.Data/library/WorldBank.html)). The first kind can be made in Rust with procedural macros. We are still missing autocomplete based on code from procedural macros, but I think this will come with time. For the second kind, some kind of delayed evaluation of generated types is necessary. This would likely require major work in the compiler, and may be impossible without making breaking changes. So I would not be too optimistic with regard to this kind of type provider in Rust.
As you're running with multithreading, could you see what cachegrind says. As always when trying to optimise, you should profile your program. It will tell you where you what's hurting performance.
[Try the `clippy` button!](https://play.rust-lang.org/?gist=7a6cb061da7aa6a07d728baf5f746293&amp;version=stable)
What is a soon to be extinct language?
Compared to Java : - no null pointer exception bullshit (this is actually huge) - Startup times - memory usage (Java boxes all kind of stuff, imagine the overhead of an ArrayList&lt;Integer&gt;. UCS2 strings are expensive too) - generics sucks - unsigned ints - UCS2 sometimes sucks (takes more space, decoding utf-8 requires copy) - RAII (though try-with-resource helps a lot) - No GC: GC is ok for throughput but if you want a constant low latency then it is a nightmare. - Cannot munmap in Java (Yes I am not kidding. You are supposed to wait for the GC to kick int some JVM allow it though) - An actual culture of (most runtime exception is evil) in the community, so that you do not have to be too scared of your dependencies. - The final program to deliver is smaller. linking will removes the useless stuff, whereas a Java might end up pulling the world and ship the world. - crates &gt;&gt; maven &gt;&gt; ant
Right, I said elsewhere that if you're looking at rust as a C/C++ dev panics are ideal. Exceptions have a cost. But if you're a Java dev you just want your runtime exceptions back.
I am somewhat amused that GCC is considered the gold standard for suggestions, given how pretty awful its error messages are compared to Clang :) In any case, the Rust compiler (rustc) purposefully shy away from warnings such as this one which may be right or wrong; instead, it features a plugin architecture (on nightly) such that linters, stylers, simple static analyzers, etc... can be developed independently and emit such warnings. Unfortunately, as mentioned, this is nightly only because the compiler interface will remain unstable. The good news is that everyone's favorite linter (Clippy) will soon become part of the rustc distribution so that you'll be able to benefit from it on stable.
&gt; If you reserve panicking for only outright programmer errors, what context could you even store? If you've encountered a bug, then by definition something has happened that you didn't think could happen. So how are you going to write code that makes a smart decision? How can you make sure that your decision to retry or give up is the sensible one, when you don't even know why you're here and what state your program is in? Generally I want to do one of two things. Requeue a message and try it again later or no longer try to process it. With a panic I lack all context to make that decision. What kind of bug was it? One that would get triggered again? Many times? Was it transient? This is a fairly common pattern for Java services. We're left to use catch_unwind, which is pretty painful in order to discourage its use.
please see my updated start post for code
Added code to gist
please see my updated start post for code
Two thing stand out 1. The rust code takes a FP squareroot, the C++ code apparently takes the integer squareroot. (Unless there's an implicit conversion) 2. Rust increments `i` by 1; the C++ adds 2. If your speed difference is almost exactly 100%, this sounds like the problem.
Rust is designed to allow abstractions without runtime cost, the tradeoff would be a global penalty to essentially all Rust code forever. It's not quite that dramatic, but it would be akin to `#![no_std]` to turn exceptions off once they were enabled (in terms of difficulty to work around it). I personally hate exceptions for error handling since it's a hole in the type system and means that I can't work out how to handle problems without reading the source, but my argument against having them in Rust is a pragmatic one.
I should clarify - I am not proposing rust add runtime exceptions. I am saying I would rather take the cost and have them. If I were to start rewriting Java services in rust, I would miss them. &gt; I personally hate exceptions for error handling since it's a hole in the type system and means that I can't work out how to handle problems without reading the source, but my argument against having them in Rust is a pragmatic one. The only difference between a runtime exception and a panic would be that the runtime exception would provide a name/ an actual type. Rust's panics provide an Any interface.
What sort of non-logic bugs are you imagining that you'd respond to with catch_unwind? Keep in mind that virtually all of the places you'd use an exception in Java instead use Result in Rust. 
&gt; (indexing is essentially a worthless footgun for anything except constant indexes) Even that can be avoided if you use `slice::get`. I can't think of many situations where you _have_ to do something that might panic, without having either a variant which returns some sort of error type or otherwise avoiding it.
Transient bugs. For example, maybe some library I use improperly assumes that an IO call won't fail and it panics. Retrying the call would succeed (since the bug is on IO error, which may be rare) so I'd like to catch the panic somewhere, likely a thread boundary up at the top level of my service, and retry. But it's a panic, I don't know what to do with it. Maybe it was actually a JSON parsing bug and this payload is invalid, and retrying would just be a huge waste of resources since it will always fail. I have no context because catch_unwind gives me virtually nothing to work. So I have to retry blindly. This is a contrived example, but hopefully it gets my point across.
Thank you!
GCC has improved a lot since version 6 in the area of error messages and is quite on par with Clang.
[C gcc](https://godbolt.org/g/w7i1Y7) [C clang](https://godbolt.org/g/LepKMH) [Rust](https://godbolt.org/g/ZEj7Bp) The only part worth comparing is the loop-- albeit it's interesting that something as simple as how to convert an int to a double to sqrt &amp; back to int is disagreed on between gcc &amp; clang OH you're doing +=1 in Rust, not +=2 Fixing that issue, the code output for Rust still looks a bit subpar. I changed the code to just the loop, no sqrt, looping from 3 to number, &amp; Rust appears to do an extra test instruction compared to clang &amp; gcc. OH it's checking if the modulos's 2nd param is 0 in case it needs to panic
`slice::get` isn't so helpful for constant indexing since if you know that it's inbounds `.get(...).unwrap()` is just line noise. I would love the indexing methods to be enforced to be constant functions and fail at compile-time (with some form of static assert, I guess) if the indexes are OOB. That's obviously a Rust 2.0 thing though.
Implementations are pretty much the same except - time functions - sqrt functions The latter is probably the reason why rust version is slower. I'd compare sqrt functions (generated assembly, or function definitions) of rustc and gcc. One difference I'm seeing is you're passing an integer to sqrt in your C code, but passing a float in rust.
There is an implicit conversion for #1
If you have a constant index that you know is in-bounds, just do `[]`. I specifically meant that, if you wanted to be sure you avoided potential panics, you could use `get` when you don't have that guarentee. (And then handle the potential None rather than just unwrapping) And how would your suggestion be feasible, since the size of the container might only be known at runtime?
oh man...how embarrassing. You are absolutely right. It was just the increment. I was looking for something like that, but I could not see that error, even though it's so obvious. Thanks. Speed is now about the same!
yes, /u/garagedragon also just pointed that out. I don't know know why I did not realized that before, but that was of course the reason, thanks!
Only support indexing for constant-size containers, pi types and suchlike can be used for that. It's not feasible right now but it's on my next-epoch wishlist.
in C the int is implicitly converted to double, in Rust however this is not the case, so I had to convert it manually. But this should not make a difference.
If we think of stack/heap alone, it is a simplified model, but let's use that now first. In `let x = 5`, the value 5 is "on the stack". In `let y = "foo"` the value of `y` is "on the stack", but the value that is on the stack is a `&amp;'static str`. It's a reference, and the data it is pointing to is indeed in static memory, compiled into the library or binary. "on the stack" is a simplification. When we compile the program to x86, the compiler can use the actual stack, but it can also transform the code into anything that works the same way ("as if" principle). For example, the value 5 will probably not be on the stack. It will be an immediate value or maybe optimized out, or optimized in a way that compiles in the actual final values as constants in the program (For example if `x + 6` turns into an immediate `11` somewhere in the program).
If a user id is always an integer, I would go with `400 Bad Request` for `/users-with-id/not-a-number`. Same with `POST` or `PUT` where the endpoint expects the body to have a certain format - e.g. certain fields must be present, and they are missing or invalid. But it is debatable and contextual. Anything but blanket `200 OK` is a good start. [As pointed out here](https://www.reddit.com/r/rust/comments/6t07dv/announcing_gotham/dlh7awh/) for a public api you might even lock it down to just 1 `4xx` code for all cases in order to prevent enumeration. 
For major projects, yeah there's an extremely long lead time. The CubeSat project for which I have a Rust ground project began two years ago and launches on the 25^(th). So I'm hopeful that CubeSats will be a testbed for experimental processes both in the science payload and in the manufacturing/development.
Took them long enough, though :)
- string and byte literals ...are stored in a segment of the executable's memory image. The generated machine language language instructions contain a reference to the location. - other literals ...are embedded into the machine language instructions. - Also note that there's a difference between the logical local storage you use (let statement, `&amp;mut( ... )`) and the actual size of the stack frame. The compiler only allocates as much stack as it needs after optimization, but you can ignore this detail. For understanding the logic: let msg = "Some string."; - the utf-8 encoding of the message is loaded into the process's virtual memory when it is being used by the OS - at the point of the let statement, the virtual address and length of the string (the reference) are loaded into a local variable (in machine code: one or more CPU register or stack location) let n = 5; - at the point of the let statement, the number 5 (of whatever type the compiler chooses) is loaded into a local variable.
In general len() returns a run-time value, but for fixed size arryas its result is known at compile-time. So is there hope to specialize len() for arrays to allow useful code like this? fn main() { const V: [u32; 3] = [1, 2, 3]; const N: usize = V.len(); }
For my bona-fides: I studied Computer Engineering in undergrad and am currently employed as a low-level software dev in aerospace. I wrote embedded, freestanding C for my college work and I write systems C for my job. &gt;Coming from assembly and C, it's so obvious to me that any reference (to a sized type) can be a len-1 slice. They're the same thing to the CPU! You are correct; in assembly, a pointer to a `T` is a pointer to a `[T; n] where n &gt; 0`, because pointers are magical integers and the code operating on them is free to read `sizeof(T)` bytes from memory at the address indicated by the pointer. I'm going to stop you right here, though, and say you're incorrect about Rust: `&amp;[T]` is a `(*const T, usize)` tuple, not a raw pointer. With that out of the way, let me continue against the spirit of your argument. However, your argument "they're the same thing to the CPU" is, assuming I'm reading you correctly, *extremely* missing the point of type systems both Rust-specific and in general. Types *do not exist* to the CPU. The CPU executes on register contents and memory addresses, and nothing more. Its one and only job is to follow a finite set of rules to flip switches up and down. What those switches mean is not intrinsic to the signals flowing through the CPU; that is information that only exists in the human mind. In the human mind, at least according to Rust's theory of type, a single `T` is a distinct type from a `[T; 1]`, because `[T; n]` is a group and has group properties such as `group.len()` and `group[index]` that single items do not. It makes no sense to index into a single item. C has syntax sugar where `ptr[idx]` is just langage sugar for `*(ptr + idx)`, which itself is secretly `*(ptr + (idx * sizeof(typeof(ptr[0]))))`. This is an example of C's type system failing. In C, let's declare a pointer to an int. int* a = malloc(sizeof(int)); C's type system makes this *indistinguishable* from a pointer to an array of ints. This will compile: int b = a[5]; Even though this is obviously, to you and I, invalid. It works in the C Abstract Machine, and it works in the CPU, so it is a permissible instruction. Its failure exists only in the human mind, or if the operating system decides it should segfault you. This is the main reason `&amp;T` does not coerce to `&amp;[T]`: it's a wildly incorrect behavior because collections are not the same abstract type, in human space, as single elements. &gt;I want to believe that there are still people who care about raw on-the-hardware coding I do care, and I in fact do this for a living, and would like to continue to do so for decades to come. I cannot agree with `&amp;T -&gt; &amp;[T]` implicit conversion, because it is a violation of the mathematical type system that governs Rust's safety guarantees. If you need to do these *unsafe, likely incorrect* things, you can: unsafe fn foo(a: &amp;T, idx: usize) { let pa: *const T = a; let pi: *const T = a.offset(idx); } The `std::ptr::ptr::offset` method is generic and will correctly adapt to the width of sized types on which it is invoked. If you wish to construct a `&amp;[T]` from a `&amp;T`, you can use [std::slice::from_raw_parts](https://doc.rust-lang.org/std/slice/fn.from_raw_parts.html). ---- Everything you mention being disappointed is absent, is present. They have to be present in order for Rust to do its job. They're unsafe and use of them is error prone, so they're marked as `unsafe` and tucked out of the way and used as foundation code in safe, checked, work that you can choose to reimplement.
&gt; the ability to go from &amp;T to &amp;[T] seem like they are exactly in Rust's core domain. The ability to magically convert a `*T` to a `(*T, usize)` seems like it is exactly as far away from Rust's core domain as it is computationally possible to get.
Slices have an invariant that their length parameter is correct, and all the memory contained between their pointer parameter and the address at (pointer + (length * width) + 1) is logically initialized and valid. `&amp;T` doesn't carry a length parameter; you could coerce to a `&amp;[T; 1]` but that's the only slice type available for implicit coercion. I wouldn't mind having a general `as_slice()` method that converts `&amp;[T] -&gt; &amp;[T; 1]` so that you can stick &amp;T in functions that expect slices, but that's the only step in that direction that should be permissible in safe Rust.
Nitpick: the C string-handling functions arguably do not get naming right since `strcpy` is unsafe and the safe versio~s have longer names. 
Thanks, that's clear. In the case of shadowing, then (e.g. something like this): let n = 6; { let n = 7; }; Do both variables, despite having the same name, have a different internal representation that the program can keep track of (so as to restore the outer variable once the inner block is destroyed)? So actually, under the hood there are two seperate variables holding different values here?
&gt; You can open this project in VS Code by using `File -&gt; Open Folder...` Note that you can also use `code .` in the terminal to open a new VSCode window set to that directory. If this is the first window of VSCode you've opened at all, it might not be able to go fullscreen (a bug I've been seeing on my machine). If VSCode is already running, even with no windows at the moment, then the CLI invocation will work fine. You can also run `code -r /path/to/dir/or/file` in the VSCode terminal to open a new file in the current window (if file) or replace the current project dir with the new dir (if dir).
Yeah, they are fixed, but it doesn't mean there's nothing else to improve.
Do you want to use websockets to keep one connection per user open, so you can quickly send updates? Most frameworks currently available for Rust don't offer that at all. If you are doing this to learn Rust, cool. If you are looking to get productive quickly, I'd probably write it in Erlang/Elixir right now.
No doubt. But only more use will uncover that. I would hate for people to take the comment to imply that they shouldn't use the library.
Yeah, shame on those lazy hacks without billion-dollar company backing.
Please post the updated timings in the question so that we can see that they are comparable.
That is not what I want either: I would like to see a safe implementation to be used widely. However, people should be aware that it might not be ready yet. It was somewhat difficult to find out that our performance issues came from this crate.
&gt; No i tisn't. It's a checked exception. I want runtime exceptions, in some cases. I'm very curious about where you think runtime exceptions are that valuable. (aside from memory allocation failure, where I admit they could provide a simpler way to allow it to be handled.)
Yeah, that was a big "a-ha!" moment for me in Rust: The enemy is mutable aliasing. OCaml, Haskell etc. slay it by controlling mutation, Rust slays it by controlling aliasing.
Another error message from gcc that I saw recently was: main.c:4:1: error: version control conflict marker in file &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ^~~~~~~ main.c:6:1: error: version control conflict marker in file ======= ^~~~~~~ main.c:8:1: error: version control conflict marker in file &gt;&gt;&gt;&gt;&gt;&gt;&gt; br2 ^~~~~~~ I don't know if it is really useful, but Rust could have it.
Sure. I wrote an example use case above, but basically unexpected bugs that propagate their way up to the top of the service. Imagine you pull in some third party library, and it has a bug that occurs once in a while under some transient condition - network failure, maybe. Simply retrying the call would likely work, but the library panics (bug). This is a bug I'd like to 'understand' at the top level, to some extent. If it were some network related bug, at the top of my program I could say "Yeah, catch all those network exceptions and just retry later". But maybe it's a bug in a serializer, and my data hits that edge case. It's not transient, but it is unexpected - the bug propagates up and I say "oh, deserialization error, just log the error and move on". This is not atypical in a Java service, runtime exceptions propagate to the top level where it's safe to just restart or move on. I much prefer *not* having runtime exceptions actually happen, but there needs to be a sane way of dealing with them because they *will* always happen. Bugs exist - thankfully in rust those bugs are just panics, and not memory safety violations, but that isn't really meaningful to a Java developer. Right now a lot of what Java's runtime exceptions are get handled as Result, so this isn't a huge deal - instead of something that should be handled at the error site getting propagated way up, we can almost always handle it right there, where we have the most information. Panics are the exception, and, if there were a way to do this without cost (again, in the context of being a Java dev, I don't care about costs like these) I'd rather have more context and machinery around my panics.
I mean, Vegemite is like $12 a jar at Woolies nowadays so that sounds like a pretty decent prize to me :)
Heh, I was just telilng a friend how much time I just saved because rustc told me that I had a typo ("did you mean &lt;X&gt;?"). Without that message, I would have spend an unbounded amount of time trying to figure out why the library I was using didn't expose that method properly, not knowing that it was really just spelled with different capitalization.
You've got a fair point; I wasn't intending to come across as criticising them. It's just something that didn't really happen until llvm did it first (unless I'm missing something, which is possible). I do deeply appreciate the work that GCC does, despite some of its "weaknesses."
Thanks for the reminder about other languages! I love F# and wish it got more use. Clojure I probably should love but dear Eris is it a pain to get going sometimes.
Thank you to everyone who gave an answer! This definitely gave a lot of material to work with, so now I have to figure out how to chop it down to size rather than bulk it up. A much more useful problem to have!
Rust can't let you do what your code asks because mutations to the `String` could cause its backing storage to be moved for reallocation or other shenanigans. In Rust's understanding: the existence of the tree requires a borrow of the String. The tree is temporary to its 'a lifetime. You need to prevent these shenanigans (easier) and prove it to the compiler (a little harder, but not much if you use indices instead of references). The simpler way to do it: - yes, you do need to return a structure. - It should have a `Box&lt;str&gt;` (like a `String` but doesn't allow further mutation) - And whatever container type you use. (Should almost certainly be Hash, but I don't know exactly what you're doing.) This container will store *index ranges* into the Box&lt;str&gt; - except the ranges need to be defined as a new type that implements the appropriate ordering or hash. However, this is probably the best simple way to do it: - `HashSet&lt;Box&lt;str&gt;&gt;` This is because the size of `Range&lt;usize&gt;` and `Box&lt;str&gt;` is the same. (They are both start, length pairs.) Use cases for BTree are pretty limited. Even if you're preparing an alphabetical word list, HashSet followed by a sort is likely faster. 
&gt; Is your current solution on GitHub somewhere so we could take a look? Haha, my current "solution" is *control-c*; *up-arrow*; *return*. I took a look at [cargo watch](https://github.com/passcod/cargo-watch) a while ago but wasn't able to get it to work. Lots of changes have happened since then, so it might be a reasonable place to start. It does teardown the process, so no magic there.
That's good to hear, and of course there's also truth in that competition is good for "business" :)
This was https://github.com/ctz/rustls/issues/35, released in 0.6.0. It does need a little cooperation from other crates to enact, because rustls is a IO-agnostic.
So, basically, better support for catching panics in "just this bit of code", assuming that any mutable state it had access to is poisoned and, if necessary, propagating the failure upward as a `Result`? I can get behind that.
Not really, it's more about when you catch the panic what information you have available to you. Currently you get an Any type, typically a string. With runtime exceptions you get a whole bunch of types that convey how to handle that panic.
Author here.
run*
I think the answer here is always. `std::mem::uninitialized` is broken in a world where types express contracts.
added the results from the fixed code.
What did you work in before C# that null pointers were not a problem?
While Rust is great, I would use Erlang or Elixir for this. That is the right technology for this use case. 
I already started implementing it in Haskell, but seem to run into performance issues
I currently have it as prototype in Haskell, but find myself trying to optimize too often.
That, I can't agree with, because it sets up a situation where, once again, you're trying to guess what could go wrong beforehand and relying too heavily on the judgment of the author who provided the library. I still think that the only reasonable exception-like behaviour is "Something unknown went wrong in this blob of code. Anything it touched (or, failing that, could have touched) is now poisoned." with the specificity of the catching block being the determining factor. If you can recover with greater specificity than "some panic happened within this catching construct", then either you're catching and translating to `Result` too high in the call stack or the library is mis-designed in a way that the language should not bend over backwards to support.
Do you actually need those optimizations? 
What kind of performance issues? Any CPU intensive stuff, mostly database queries, or too many allocations?
Yes. Each block may have its own local variables. 
Generally the issue of poisoned state is irrelevant in this situation - you have some thread handling a connection/ message, and it shares no state, so killing and restarting it is completely safe. Currently I imagine this is how every rust service works, either using catch_unwind or relying on the thread boundary. The issue is what to do *after* you catch the panic. Do I retry the same message? Do I give up? Runtime exceptions provide you an answer - you can, with some fine grained control, determine which 'bugs' can be handled. I can panic and say "Hey, idk what to do, this probably isn't locally recoverable" and retry elsewhere if necessary.
A dynamically-generated type would be a lot less capable than one present at compile time. 1. It couldn't be Sized. 2. It couldn't be used with static polymorphism (`fn thing&lt;T: Trait&gt;(x: &amp;T)`), only dynamic (`fn thing(x: &amp;Trait)`). 3. It couldn't be optimized well, since nothing could be inlined.
CPU / allocations . The state currently only lives in memory
well, it's too slow, so yes
Try with just hyper then. 
Good point, it's kinda vague. I didn't have libraries in mind. I was more thinking GC and JITs and such, as you described. Also, any system the expects **its** main function will be run. Is it possible to compile rust without the c library by compiling without the standard lib? 
You need to set the executable subsystem to `windows` instead of `console`. That should now possible with `#![windows_subsystem = "windows"]`.
Thank you, it did the trick! By any chance, do you know how to get rid of the menu bar from pancurses window (on Windows, it has "Font" and "Paste" entries)? 
Toy projects.
No, sorry. I don't even know what `pancurses` looks like, or how you're using an `ncurses` clone with `gtk` :D. Do you have a screenshot at hand?
https://github.com/w3c/web-platform-tests/
If a function wants to look at `records: &amp;[Record]` and a caller has one record to show it (Record or &amp; Record), then: - In C, if the interface is (pointer, n) you can call the function with a pointer to the record and a literal 1 as the number of records. - Rust won't do this. You can write a trivial `unsafe` block that supplies that literal 1 - as I did - or pull in the "as_slice" crate. But there is no ready-to-use solution, which makes the operation (lending a function that expects zero or more records exactly one record) seem unsafe by nature. The existence of an &amp;T reference guarantees that there is one valid `T` at the specified location. I want that compile-time knowledge of "one valid value" to be expressed at run-time when appropriate, i.e. when a coercion site expects &amp;[T] What makes this proposal unsafe? 
Your example of unsafe behaviour shouldn't and wouldn't compile. Although `a` could coerce to a slice, the index operation `a[5]` is not a coercion site. This compiles to defined behaviour, a panic when the index is out of bounds: let a: isize = 2; let b: &amp;[isize] = &amp;a; let c = b[5]; However, `b[0]` is `2isize`.
Ah. I assumed you meant that you switched from another language to C#.
Does anyone have examples of non-micro benchmarks/programs where the overhead of checked RefCell is significant?
This is my first post about Rust and first retry on writing after a long time. All feedback is appreciated, will try to improve anything as necessary. (Already fixing mobile view, sorry for that). Thank you.
Nifty. I love how Rust let's you build stuff like this if you *really* want to. You should probably say more up front about the security implications: checked/unchecked could be the difference between attacker crashes your software and attacker pwns your software. The existence of something like this allows for testing the memory and performance overhead of RefCell.
I'm not using GTK at all (too cumbersome). `pancurses` is an abstraction over `ncurses` and `pdcurses` so it works on *nix and Windows. Here is a screenshot: https://framapic.org/9B7UR16DUB4d/pFDbhPvzy3Q1
I just tried using RLS on VSCode, I followed the instructions on the extensions page, and I have the little "RLS analysis: done" thing in the bottom left. But I get none of the features listed here. At best it recognizes a variable I've used already and that's it.
How do you set it to use that? Can I use Git for Windows alongside GitHub Desktop, so that Git for Windows uses my existing ssh key `C:\Users\me\.ssh\github_rsa`?
It has improved, but I've generally found Clang better anyway. It seems I can trigger *walls* of errors much more easily in GCC; a simple `auto x = mispelled();` will lead to errors about `int` not having methods wherever `x` is used... and it's not always easy to tell when an error starts and ends when there are backtraces and notes interspersed. rustc's is much better, and I hear Elm (which inspired rustc) is another step further. Of course, neither has to cater to C++ horrid grammar :x
Haha, I was looking at the wrong branch. I couldn't figure how you're using `pdcurses` together with `relm` and `gtk`.
But then why did it use to work before? GitHub Desktop always used ssh-agent.exe. But I'll try Pageant. How can I tell Pageant to use my existing SSH key at `C:\Users\me\.ssh\github_rsa`?
I totally forgot I was on another branch x)
[removed]
Yes, those steps/assumptions are correct. I'm not sure which git distro is packaged with GitHub Desktop, when I do `git --version`, it just says: &gt; git version 2.11.0.windows.3 How can I figure out which underlying git distro this is? GitHub Desktop always used ssh-agent.exe, and it used to work.. And when I run `ssh-add -l` it can connect to ssh-agent (via SSH_AUTH_SOCK, I checked by opening a normal cmd.exe where ssh-add can't connect and then setting `SSH_AUTH_SOCK` to the value from the Git Shell, then it succeeds), so the problem is not with the rendezvous mechanism but with cargo/libgit not using it properly.
Since adding a `CARGO_INCREMENTAL=1` to my bashrc, I'd noticed my VM running out of space frequently, and every time, relearning the exact `du | grep` incantation I needed to find where I've forgotten to clean up.
Huh, that's actually pretty neat! I don't know that it adds much since it's usually pretty obvious (e.g. syntax error, unexpected &lt;), but it seems pretty easy to do so the cost isn't too high.
When would I care about disk usage vs file size? Hard links and sparse files?
What features of nightly are you using and why? Just curious.
I think you want /r/playrust this sub is for the rust programming language.
&gt;Where is the executable crate of on it? I am not completely sure what you mean, but it is just another member in the workspace. Have a look at this https://github.com/MaikKlein/ash. `examples` is just another member in the workspace that results in a binary. 
Mainly integer atomics, which are necessary to pass large integers between threads. I don't expect that API for them to change too much, but who knows?
Sparse files but also minimum file size. In general, I've found that they're not usually too different, which is why I refrained from implementing anything related to disk usage until I'm more confident in the results on every platform.
Wow thanks for sharing that. I never used Ruby, but I love seeing these moments of humanity in tech and open source. It can feel really distant and disconnected when you are focused on your little corner of the open source world, and it's nice to see examples of people collaborating on a more personal level than issue trackers or mailing lists. 
https://github.com/MaikKlein/ash is a lib crate, any idea about how we can use workspaces on a binary crate. (⭐️ especially for main.rs + multiple lib crates) 
\#1: Install Linux. /s
Not necessarily. You are using workspaces if you need to develop multiple crates together. For example if you would want to create a game engine, you could put everything into one crate or you can split your game engine into many different crates like a renderer, input, networking, etc. But developing many crates is a bit tedious and that is where workspaces make your life easier. Workspaces allow local paths, see this example https://github.com/MaikKlein/ash/blob/master/examples/Cargo.toml#L9 Edit: Seems like you have updated your question: &gt; https://github.com/MaikKlein/ash is a lib crate, any idea about how we can use workspaces on a binary crate. (especially for main.rs + multiple lib crates) Nothing changes, I just have only one lib. See https://github.com/tomaka/vulkano for another example. 
&gt; as long as sufficiently done testing has empirically verified that the borrow and borrow_mut function don't panic on run-time It's one thing to verify that your program doesn't panic under normal input, but it's much more difficult to prove something like "no malicious input can possibly crash this program, no matter what". The security risks of UnsafeCell require you to prove that second, harder thing. I know this is obvious to you as the designer, but it might be worth some big scary warnings :)
sorry, didn't saw your answer before updating it. Okay I understood a bit. root Cargo.toml having [workspace] members = [ "examples", "ash" ] cargo take 1st crate on member list as root, so `examples` on Cargo.toml on examples having [dependencies] ash = { path = "../ash" }
Wow I didn't even notice that `CARGO_INCREMENTAL=1` uses that much space. Every project that I have is over 6GB big.
Yeah, normally I start by saying that, but then I end helping people over windows anyway :P
There is no root crate, `examples` is just a 'binary' crate that uses `ash` as a library. You can have many more 'binary' crates if you want to.
This is actually my favorite lint. It's very simple, it shows code that may be easily misread by the unwary, and it once even found a real bug in some low-level code.
ex. I am using main.rs and lib.rs on same project. I need to move lib.rs into 2 directory crates. We can not use one Cargo.toml for both workspace and root package, so we have to move main.rs into separate directory crate. Am I correct on all above statements?
but examples having src/lib.rs. so its a lib crate, right? 
No it produces executables, https://github.com/MaikKlein/ash/tree/master/examples/src/bin The lib.rs part is just for boilerplate code. 
ok https://github.com/rust-lang/rust/tree/master/src/bootstrap also having /bin directory. let me check about bin directories on doc :)
You can build and run them like this cd examples cargo run --bin triangle
deleted ^^^^^^^^^^^^^^^^0.9527 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/16698)
Point. I was thinking of catching panics with significantly more granularity than entire threads, where the knowledge you're talking about would be available simply by combining what's available outside the catching scope with the yes/no result of whether said scope panicked. That said, I still think exceptions are the wrong solution since it'd be too easy for the same bad actors who are over-eager to `panic!` to instead prefer them over `Result`. If you're going to work with panics, I'd prefer a solution that can't cross crate boundaries, where the *calling* code can specify that panics should be augmented with metadata as they unwind. That would have the following two characteristics: 1. Anything intended to cross a crate boundary would have to be converted to a `Result` if the crate's author wants to provide supplementary information, disincentivizing using them as a generalized exception mechanism. 2. Within a crate, you can say "If a thread panics within this span of code, annotate the panic with metadata X so the thread-level panic handler can know where things went wrong." (Essentially, providing a cleaner equivalent to wrapping each stage which should have a different behaviour on panic in its own catch block.)
Right - it's important to underscore it.
&gt; Even with compiler support (e.g. MemorySanitizer), detecting access to uninitialized memory is far from being a solved problem in practice and, with the current techniques we have, probably impossible to solve. True, but... how is that related? &gt; I think that std::mem::uninitialized is actually a fine way to obtain uninitialized memory. &gt; If before a function exits (returns, panics, ...) all uninitialized memory obtained by calling std::mem::uninitialized is either initialized, or behind a type that expresses that the memory is uninitialized, First of all, `mem::unininitalized` is itself a function. According to my current model, calling that function at any non-ZST is insta-UB: `mem::uninitialized::&lt;i32&gt;` claims to return a valid integer, where really it returns an uninitialized value. Furthermore, if we assume we have a function returning `MaybeUninitialized&lt;T&gt;` for any `T`, what reason would there even be to still have `mem::uninitianlized`? The rules for `MaybeInitialized` would be such that the moment you read or take a reference to the `T` in there, you are promising that things are now initialized.
Thanks for the write up and powershell script. There are a few windows developers left out there after all... 
deleted ^^^^^^^^^^^^^^^^0.6222 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/20505)
Are there any efforts to do randomized testing of the Rust compiler? (Context: I was reading these [slides](https://gcc.gnu.org/wiki/summit2010?action=AttachFile&amp;do=get&amp;target=regehr_gcc_summit_2010.pdf) [PDF] which talk about Csmith). Since Rust doesn't have an official spec and exactly one implementation, many of the points that apply to testing gcc vs clang vs other compilers don't apply here but you could still check for unexpected crashes for programs that ought to run fine. However, there is one thing though -- one could hook up Csmith with Corrode to get an effective "Rustsmith"; has anyone tried doing that?
If you mean the Programming language, very probably. Otherwise you'll likely want to repost at /r/playrust
Try /r/playrust
You may want to try recruiting in /r/playrust
It actually works quite well if you have binaries (to build and use current nightly); I'd recommend bootstrapping using the SmartOS binaries and then Go from there. But lack of official support is mainly because a) it's still being worked on, and b) the rust community relies on contributors.
Then you can already do it with a Cargo build script, or maybe macros. Procedural macros would definitely be able to, but they're not available yet.
Well if you want to use Elixir you can implement some functions in Rust, or run a Rust application as an Elixir process or an Elixir node. That way you would be able to have a fast network easy to implement, and fast code in Rust.
Nice! I'd like to see [ncdu](https://dev.yorhel.nl/ncdu) functionality as well…
What are the benefits of Elixir / Erlang over e.g. Haskell? No static typing is basically a no-go for me.
&gt; But then why did it use to work before? GitHub Desktop always used ssh-agent.exe. Either Cargo was linked to a libssh2 library built for MSYS2/Cygwin target, or Cargo used a different Git/SSH backend back then. &gt; How can I tell Pageant to use my existing SSH key at `C:\Users\me\.ssh\github_rsa`? https://the.earth.li/~sgtatham/putty/0.58/htmldoc/Chapter9.html#pageant-mainwin-addkey ?
(Small note: I think your assumption about VS Code only having official 32bit builds is no longer true.)
deleted ^^^^^^^^^^^^^^^^0.0633 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/64581)
Last I checked, LLVM's translation and optimization was the slowest part by far, so adding more steps before getting to that point would be on the happy side of Amdahl's law.
deleted ^^^^^^^^^^^^^^^^0.3317 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/95137)
&gt;* No macros: There is no `select!` macro. Dynamic selection is just as easy as static selection. Do you have an example on how to block when a thread is waiting on multiple queues?
Reading "shared mutable state", I immediately thought of of a multiplayer gamer. If so, Elixir and Phoenix offers the best tool for a fast API with heavy load of requests per second. Erlang is the opposite of Haskell in some way : message passing is a very important thing in this language, and it prevents strong typing and is impure in essence. So if it's a no-go, dont go then (at least for the game, but Erlang or Elixir are worth having a night of hacking-for-fun). Or you could use a simple REST API written with Elixir/Phoenix and just decode/encode JSON and let Rust do everything else. That was my idea actually. Received message would go in a Rust job queue maybe ? (edit : and rust json codec would be faster anyway so Elixir would just accept and reply json strings) I was working on a prototype (full Elixir) with shared state (well, it's Elixir so let's say "concurrently updatable state") where I would lock a key on the mutex before altering the state for a specific player. Each request about the same player would wait for the mutex to be free, request for other players would not be blocked by this key. And if you need to update 2 players at once (let's imagine a trade of goods between the players), you just lock both keys at once. I have very poor experince in rust or java, C++ so I could not say how it should be done with them, but I believe that in a browser game you want a request to update a specific portion of the game state, and you want to finish this update before accepting any other change for the same portion.
[removed]
Isn't this completely unsound? That is, it sounds like from the readme that you can cause undefined behavior in safe code using this library in the intended way. That sounds like a job for unsafe code, in which case you might as well just use UnsafeCell.
So what will this show up in my node_modules folder ... 
The code in the [tutorial](https://doc.rust-lang.org/book/second-edition/ch02-00-guessing-game-tutorial.html) is `let guess: u32 = match guess.trim().parse() {`. You're missing an important `match` keyword.
well i feel dumb. thanks
It's unfortunately expected that `izip!()` from itertools is not so great. `.zip()` from the standard library has a specialization that makes it compile to much better code, **if** both the inputs are slice iterators or a composition of that and a few select other adaptors (at least `.map()` and `.zip()`). `izip` is implemented in stable Rust and does not have access to neither specialization nor slice iterator internals. `izip` has the rather simple and straightforward implementation of asking each iterator of its `.next()` value and putting that together into a tuple, if they all have a next value. The compiler doesn't manage to make that into something great with the regular `.zip()` in std either, hence the special case code, and it doesn't get easier when there are more components to check.
Thanks, the information helps. The "problem" I'm working on isn't important; it's just something I would normally turn to Python for, but I figured I knew enough Rust to try it. Not sure why I used BTreeSet initially, switched to HashSet. Here's a simpler example: https://play.rust-lang.org/?gist=95272d6c09d99fac865c309b7da3bfc1&amp;version=stable However, I'm still stuck. When I split the String, how do I get owned `str` types instead of `&amp;str`? let s = String::from("a,b,c"); let words = s.split(',') .map(|word| Box::new(word)); HashSet::from_iter(words) Also, I haven't read about Range yet, so it's not clear to me how it's relevant, but I'm only about 1/3 into the Rust book. 
It's been a while since I used GitHub Desktop, but I seem to remember an installation option about installing git system-wide... You might be able to just remove it from PATH. I just installed Git for Windows, ticked the box to use the Microsoft Credential Helper and it pops up the first time connecting, I gave it my SSH key, ticked the box to remember it, done.
Thanks, I thought about that, but I wanted to just have one thing completely own the `String` and `Set` or just have a Set that owns the underlying String. Why doesn't my self-referential struct work? Did I annotate lifetimes wrong? Or is this just not possible? https://play.rust-lang.org/?gist=be8af3865a5c5760d02d563c244f3230&amp;version=stable Is this an anti-pattern (bad idea) in Rust? I still need to learn and try Boxes, so maybe it'll be more clear how to deal with this sort of thing when I get there. 
Looked through the pdcurses docs and I didn't see a way to do it programmatically. It did say you can turn it off in the system menu. (top left corner maybe?)
Unless you wrote this in Rust (the programming language), you'll have much more success posting this over at /r/playrust.
Thank you for the explanation :)
Good catch, until few days it was still "preview". Will fix that, thanks. (UPDATE: Fixed, but will always download 64bits for now)
Dumb question, how are traits different from interfaces?
This library simply exposes unsafe functionality without making it clear that it is, in fact, unsafe. [Allowing mutable borrows without a check](https://github.com/da-x/czc-refcell/blob/master/src/cell.rs#L84) is the epitome of unsafety and is one of the things a properly designed library must never do. If it's not clear what I mean, I'm happy to elaborate so you don't make this mistake again in the future :)
I tried lifetime-annotating part of bookv2's first example project. As it looks in the project: struct Config { query: String, filename: String, } fn parse_config(args: &amp;[String]) -&gt; Config { let query = args[1].clone(); let filename = args[2].clone(); Config { query, filename } } As it looks now: struct Config&lt;'a&gt; { query: &amp;'a String, filename: &amp;'a String, } impl&lt;'a&gt; Config&lt;'a&gt; { fn new(args: &amp;'a Vec&lt;String&gt;) -&gt; Config { let query = &amp;args[1]; let filename = &amp;args[2]; Config { query, filename } } } It works, but I have absolutely no idea why it works. `Config` is declared with two reference properties who have (should have? live longer than?) some lifetime `a`. Then, in the constructor for `Config`, which is an implementation generic over some lifetime `a`, we accept a vector reference with a lifetime `a` (is this the same `a` as the impl's? What's the relationship there?). Because we're constructing a Config with reference properties as slices of the vector with lifetime `a`, those slices have lifetime `a`, so it's safe because...lifetime...`a`....dude, I don't get it. At all. Time to go read that doc for another 3 days. 
Very exciting!
Interesting, I did search around on the web but it seems my request was not good enough. Where did you read that? 
The type system doesn't support self-referential things, right now (in safe rust). The problem is that if the String is moved in memory (when returning or resizing/reallocating), all references to it are invalidated. This isn't usually a problem since anything that can cause the String to resize requires &amp;mut, so there can't be any other references to it when those happen. If you create references to the String inside a function, those are invalidated before returning, so you can still return the String. But if you return it inside a self referential struct like that, there's no longer anything tying the lifetimes of the references to the lifetime of the String. Note that `struct FileWords&lt;'a&gt;` declares a struct with a generic lifetime parameter 'a, it does not declare that the struct itself has lifetime 'a. If rust had some way to create [immovable types](https://github.com/rust-lang/rfcs/pull/1858), you could create self-referential structs in this way, since the references would never be invalidated. I'm not an expert, but that's how I understand it. There's ~~two~~ three ways I've heard to work around this the other times it's been asked about: 1. Create the buffer in the outer scope and give the creating function a reference so the ownership stays in one place. https://play.rust-lang.org/?gist=5dbc6cf9785a59b634660f5f68843361&amp;version=stable 2. Use indices instead of references. You need to write some boilerplate to implement whatever BtreeSet functions you need using indices, but it should generate similar assembly to references. There are probably crates on crates.io that do this sort of thing for you, but I don't know what to search for. 3. Use a crate like https://github.com/Kimundi/owning-ref-rs or https://github.com/jpernst/rental which lets you create self-referential structures. You have to use smart pointers to access the data so it's a bit cumbersome, but then so is Rc&lt;RefCell&lt;T&gt;&gt;. 
Thanks!
https://www.projectpluto.com/win32a.htm not the official pdcurses project, but search for menu on that page and he mentions trying to extend it so you can disable the menu.
Interesting, I think I'll just create new Strings for simplicity. fn create_string_set() -&gt; HashSet&lt;String&gt; { let s = String::from("a,b,c"); let words = s.split(',') .map(|word: &amp;str| word.to_string()); HashSet::from_iter(words) } Avoiding the extra allocation doesn't seem worth the code complexity. Hopefully Rust makes this simpler in the future. 
Im a big fan of doing debugging work in visual studio(not code) and my programming in vs code or vim. In visual studio when i need to debug something big(not doable/too much effort with println!) i just open the rust project folder and set the debug or release executable as project startup item. Haven't tried the cpu, mem etc profiling options yet in visual studio.
On what OS? You definitely can't do it with `std`. With what window active? You can't do it globally on Wayland.
I tried to run this on a Mac (El Capitan), but it failed with a "fatal error: 'windows.h' file not found" I also tried removing the "#![windows_subsystem = "windows"]" line in main.rs, but got the same error
Yes, we need a blacklist of crates which have a safe interface, but don't keep the safe "contract".
Most languages don't work like JavaScript^[1]. You don't get events you can listen to - at least not out of the box. What you get is the [standard IO streams](https://en.wikipedia.org/wiki/Standard_streams) - STDIN, STDOUT and STDERR. You read your input from STDIN, write the output to STDOUT, and print errors to STDERR. This feels more like CMD(I assume you use Windows?) than a graphical application. In Rust you get that input with [`std::io::stdin()`](https://doc.rust-lang.org/std/io/fn.stdin.html). In order to have more "graphical" IO, you need to either: * Use the [windowing system](https://en.wikipedia.org/wiki/Windowing_system)'s event loop. The windowing system is the OS component responsible for handling raw input from keyboard/mouse/etc. and for drawing graphical stuff on the screen. It's low-level API provides actual events that you can listen to. But you usually don't want to work with the low-level API, and prefer to do it with a GUI library. * Terminal emulators support special keycodes/APIs that allow you to do things more interactive than just "input goes here, output comes from there". They allow you to print characters anywhere on the grid, use different colors, receive keys directly(instead of receiving the entire string when the user press `Enter`) etc. This type of interface is called [TUI](https://en.wikipedia.org/wiki/Text-based_user_interface). Again - you usually don't want to work with the terminal keycodes/API directly, and instead use a library. Some of these libraries offer something that feels like events-based input(though behind the scenes it isn't) * The third option is mostly used in games. You use a library, like DirectX, that talks with the hardware outside the windowing system(the windowing system only provides it with a window to draw it's stuff on). You run your own loop(or use some library that runs that loop for you) and poll the events in each frame(instead of depending on them). Unlike the previous two options, here you busy-wait on the event instead of getting notified when it arrives. You can find libraries for all 3 options in [Awesome Rust](https://github.com/rust-unofficial/awesome-rust#gui) [1]: Actually, JavaScript doesn't work like that either - when you run it in the terminal you use standard IO too. It's just that usually you run it in the browser, and it get events from the browser.
`onkeypress` is a function of the browser API, rather than JavaScript itself. (eg. You won't find `onkeypress` in Node.JS) We need more information to answer your question because how you listen for keypresses will depend on what API you use to get access to the keyboard and that will depend on what kind of GUI or text interface you want to present to the user.
Where are you hoping to run this code? &gt; `onkeypress` event handler Keypress events like this in JavaScript are from the browser. Rust won't run in the browser in that same way, so it makes less sense to talk about this kind of event handling. If you want to check key press events from the console, you can probably just read character by character from `stdin` and check if the character is the one you want. If it's in a GUI window, it'll probably be framework specific.
Hello NSA
Same here. I used to run Linux in a VM and Windows natively but now I don't even run Linux in a VM, I just use WSL. It's working great.
&gt; When I split the String, how do I get owned str types instead of &amp;str? There is a built-in conversion from `&amp;str` to `Box&lt;str&gt;` (`impl&lt;'a&gt; From&lt;&amp;'a str&gt; for Box&lt;str&gt;`) and you can use that just by calling `into`. let s = String::from("a,b,c"); let words = s.split(',') .map(|word| word.into()); HashSet::from_iter(words)
It's easier for me to understand if I write it as a free function: struct Config&lt;'b&gt; { query: &amp;'b String, filename: &amp;'b String, } fn create_config&lt;'a&gt;(args: &amp;'a Vec&lt;String&gt;) -&gt; Config&lt;'a&gt; { let query = &amp;args[1]; let filename = &amp;args[2]; Config { query, filename } } Config&lt;'b&gt; is a struct with the *lifetime parameter* 'b. create_config is a function with the *lifetime parameter* 'a. Since `query` and `filename` are references to `args`, they have the same lifetime as `args` which is 'a. The function returns a Config where the lifetime parameter is equal to 'a. So lifetime parameters work just like generic type parameters. The above code is analogus to: struct Config&lt;A: Sized&gt; { query: A, filename: A, } fn create_config&lt;T: Sized + Clone&gt;(args: Vec&lt;T&gt;) -&gt; Config&lt;T&gt; { let query = args[1].clone(); let filename = args[2].clone(); Config { query, filename } } 
all I want is to listen when a user hits esc or some other key in a terminal on ANY os (linux, unix or windows) and then from there basically say: Oh you hit esc - what would you like to do (code wise). The pseudo code is simple: if user presses escape do x, else do y. Is there any library that handles all this for me and allows me to say what x and y are.
all I want is to listen when a user hits esc or some other key in a terminal on ANY os (linux, unix or windows) and then from there basically say: Oh you hit esc - what would you like to do (code wise). The pseudo code is simple: if user presses escape do x, else do y. Is there any library that handles all this for me and allows me to say what x and y are.
all I want is to listen when a user hits esc or some other key in a terminal on ANY os (linux, unix or windows) and then from there basically say: Oh you hit esc - what would you like to do (code wise). The pseudo code is simple: if user presses escape do x, else do y. Is there any library that handles all this for me and allows me to say what x and y are.
all I want is to listen when a user hits esc or some other key in a terminal on ANY os (linux, unix or windows) and then from there basically say: Oh you hit esc - what would you like to do (code wise). The pseudo code is simple: if user presses escape do x, else do y. Is there any library that handles all this for me and allows me to say what x and y are.
Could you not have `State` stored in `Request`/`Response`? Most non-Rust frameworks tend to just return a response.
&gt; Mainly integer atomics, which are necessary to pass large integers between threads. Why not [`AtomicUsize`](https://doc.rust-lang.org/std/sync/atomic/struct.AtomicUsize.html)? It is available in Rust stable. In a 32 bits system the value is limited to 4G, which can be too small for a tool like a tin-summer. However, I guess that most 32 bits (nowadays) are for special purposes (like embedded devices), which will not have a big hard drive anyway. 
what does `CARGO_INCREMENTAL` do?
I look forward to fixing this, of course, once specialization is stable.
&gt; in a terminal on ANY os There's what I was looking for. Normally, terminals only give programs data on a line-by-line basis, so you need to specifically switch them into a mode that doesn't wait for users to press Enter. How to do that differs between Windows and POSIX (POSIX being the standard followed by Linux, UNIX, macOS, etc.), so you'll need a crate which hides that difference if you don't want to write two different versions of the code. [pancurses](https://github.com/ihalila/pancurses) can do that for you and there are a couple of examples in the README at that URL. If you ever feel like going fancier with a TUI (one of those "GUI in a terminal" things), [Cursive](https://github.com/Gyscos/Cursive) builds on top of pancurses (or several other backends) to give you a widget library. (Example screenshots in the linked README.)
- Is `rustup component add rust-analysis` no longer necessary for RLS? - If you've installed nightly anyway, you may as well use `rustfmt-nightly` rather than `rustfmt`, as the latter is no longer updated AFAIK. - If you're actually building with nightly(/beta) rather than stable, you should use that toolchain's `.natvis` files instead of stable's. Also, it seems silly to me to install an extension rather than just setting `debug.allowBreakpointsEverywhere`, but I don't really see any downsides I guess. :-P
The menu-bar is provided by the terminal emulator (on Unix) or console app (on Windows) that's running your program, there's nothing the application inside can do about it.
The library is safe with its default build flags. It's only unsafe if `unchecked_refcell` is passed. How do you suggest to communicate safety based on build flags alone?
Not a dumb question. The main differences I notice (coming from C#) : * Traits can have static members * Traits can refer to the implementing type in any position (eg `fn foo(self) -&gt; Option&lt;Self&gt;`) * Traits can have Associated types. (This is the feature I miss most in C#). * Trait implementations are separated from the types they apply to. So they can be added to std types or types from other libraries. (The restriction being that it must be in the same crate as either the type or the trait) 
Tells `cargo` to run `rustc` in incremental compilation mode. Only works for nightly rust.
Thanks, updated with the missed analysis component and rustfmt-nightly. The .natvis should be stable, nightly is there only for clippy (and now rustfmt-nightly) but not suggested as a default setup. The extension is the easiest way of changing that via script, but also to avoid teaching where and how to change the user config to set that flag. So, less attrition, even if not optimal. The .natvis is the missing part here that there isn't a way to make it easier to the user. But, soon I will improve the script to do it.
It is ok, but too heavy for the needs considering we have already vscode up and running. Also, not available on Linux, so going with vscode may help the user in the eventuality of the need of using Linux.
&gt; but also to avoid teaching where and how to change the user config to set that flag It's just `ctrl`+`,` in VSCode. :-] EDIT: Regarding the `.natvis` files, they're sensitive to data structure layout changes, so they need to match the actual stdlib that you've built with/are debugging.
Feature request. Readme
In my opinion, this library has it exactly backwards. What it should do is have additional checks by default, but mark any interface that is *potentially* unsafe (under some combination of build flags) as unsafe. Otherwise, the library is just giving people a way to write unsafe code without having to write `unsafe`. At that point, you might as well just not use Rust.
So it looks like you're using [this version](https://www.projectpluto.com/win32a.htm) of PDCurses, as /u/iggy_koopa found out in your other thread. The UI you're seeing is not the Windows terminal emulator, but the `Win32a` backend of PDCurses. Looking at `pdcurses-sys`, that's what it seems to use: https://github.com/ihalila/pdcurses-sys/blob/master/build.rs#L51. You should maybe file a feature request on that side to allow building with the classic (`Win32`) backend instead.
All right, see here: https://github.com/Bill-Gray/PDCurses/blob/18404de78edbc62220899a60902d3f3b44759d86/win32a/pdcscrn.c#L1740. The only way to disable the menu bar is from the system menu (click on the icon). The setting will be (presumably) saved to the registry so next time you run your app it will be hidden. To hide it programatically you would have to send the window a `WM_SYSCOMMAND` message. PDCurses doesn't seem to expose the window handle, but it's stored in a global variable here: https://github.com/Bill-Gray/PDCurses/blob/18404de78edbc62220899a60902d3f3b44759d86/win32a/pdcscrn.c#L97. You can use Rust FFI to read it and call `SendMessage` after you initialize the screen. If you want to try this and have troble feel free to ask me to look into it. EDIT: Actually, it's harder than that. The `WM_TOGGLE_MENU` command toggles the menu, so you'd have to know whether it's visible or not; moreso, it looks like hiding it actually sets an empty one instead of `NULL`. I assume Windows won't draw that, otherwise `adjust_window_size` wouldn't make sense. You can't set a `NULL` one as it would break the client coordinate calculations (see `adjust_window_size`). So you probably have to: 1. retrieve the current menu of the window using `GetMenu` 2. check whether it's empty, presumably with `GetMenuItemCount` 3. if it's not empty, send the window a `WM_SYSCOMMAND` message with `wParam` set to `WM_TOGGLE_MENU` which is defined as `WM_USER + 3`.
Did the first three exercises in the Rust book, I was wondering if anyone could highlight any areas where I could be more idiomatic / better approach (not so bothered about algorithm, they're all naieve, just want to be more idiomatic at this stage) https://gist.github.com/anonymous/56bef367835bf2490d4b2410f3ed24b2
I haven't tried the natvis stuff, I just have the microsoft symbol server listed in my launch file ("symbolSearchPath": "https://msdl.microsoft.com) which seems to work for basic type information. Any idea how the two compare? Thank you for the write up, this is exactly the setup I use (pieced together from multiple articles over the last year or so). It'll be nice having an updated guide that I can point people to.
I kinda hope it doesn't come to that...
Or in Rust lingo, it's "unsound."
In honesty, make the methods `unsafe` when their behavior is unsafe. Anything less makes the library unsound. I can understand the want for something like this, but this is what `unsafe` blocks in consumers of libraries like this are for. It's the _built in way_ to say "yes I know this can be unsound if I don't do it right". Anything that allows unsound behavior without entering unsafe is circumventing rust itself, and is not sound for usage. 
I have a function for `du -had1 "$@" | sort -hk1` in my `.profile`.
Whenever I care a lot about performance I add this to my Cargo.toml [profile.release] lto = true panic = 'abort' On my machines, that shaved off about 85% of the runtime for the unsafe examples. It looks like somehow `lto = true` makes LLVM realize it can emit vector instructions?
Cheers, I'll try this asap :D
Does this need fixing for NxM possible combination of iterators with zip? If Rust ever has variadics doesnt that blow up?
Done!
&gt; However, I guess that most 32 bits (nowadays) are for special purposes (like embedded devices), which will not have a big hard drive anyway. Not really. According to the Steam [hardware survey](http://store.steampowered.com/hwsurvey/?platform=combined), 6% of Steam users run a 32-bit OS (notice the difference between "Windows 7 64-bit" and "Windows 7"). So there are still a lot of 32-bit machines out there. Besides, a DVD ISO file could take more than 4 GB of space (and DVDs have been a thing since at least the early 00's). You do need to cover that use case as well. This means there's simply no excuse not to use 64-bit integers for file sizes even for a 32-bit OS.
Thank you!
I think it's possible to make class-per-command beautiful https://github.com/ioquatix/samovar
i'm still a little sleepy and i'm unfamiliar with Rocket. But i believe you can send a Sender through a Sender to create a bi-com system
We need crates io to warn loudly when a crate is unsound by design 
I don't like this. In Rust, safety related things are never a feature flag or a debug-mode thing. For example unchecked indexing _always_ panics. Integer overflow is silent in release mode, but all APIs that rely on overflow not happening for safety will explicitly panic. It's not very Rusty to have an API that you can make unsafe by turning off the safety checks. In general Rust will go the _reverse_ way, where you have an _unsafe_ API that you can _add_ checks into (but will still stay unsafe so that there's no difference from an API perspective). As /u/Quxxy says, mark an interface that is _potentially unsafe_ as unsafe. At the very least, name that feature flag as `unsafe_unchecked` or something. It's a convention in Rust that if something is unsafe to use but isn't a function (e.g. a macro, an attribute, etc), put "unsafe" in its name so that it's clear to the user that they are doing something unsafe. This isn't a zero cost RefCell; if it were it would have the same guarantees.
Your README says: &gt; Note: Both macros support multiple arguments and are not restricted by the recursion limit. But you have recursion in your macros, so it seems incorrect. However your macro recursion is strange: ($label:ident; $x:ty, $($xs:ty),+) =&gt; { #[allow(dead_code, non_snake_case)] fn $label() { assert_eq_size!($x, $($xs),+) } }; Is it the `fn $label` creation that allows you to overpass this limitation?
The APIs should be marked unsafe. Just because they are safe in some build configuration doesn't make them safe. Rust tries to keep these things fine grained. Let the user use an `unsafe` block and be forced to decide when they think it would be sound. They can compile it without the flag if they want to fuzz it or something. There are invariants of the user's program involved that you don't control, when you mark something as safe it is a guarantee that it is safe no matter how it is used. If you cannot achieve this, then it must be marked unsafe (or private, if it's a local bit of unsafety, but still, be careful), and then it's the user's responsibility for it. Marking sometimes-unsafe APIs safe is you giving a guarantee that you cannot possibly uphold. If you _really_ don't want to do that (I don't recommend going down this route, folks highly frown on not-actually-safe APIs) then at least have `unsafe` in the feature flag name and warning signs all over the place. (In general this smells highly of a premature optimization, `unsafe` shouldn't be used that way)
I don't think Elm errors inspired those of rustc, they've been there for a while, and there's always been a segment of the community caring about diagnostics (I'm one of them). Elm has been a recent inspiration for folks wanting to improve rustc even more.
Awesome!. I'll set some time aside later this week to experiment with this.
It recurses once in the `$label` branch, but not in the main one. You can see in [this diff](https://github.com/nvzqz/static-assertions-rs/commit/fb29c6a0077c7b920ade330b3bb34e3d41c909fe) that previously the macro called itself again for each extra argument. If you have _a lot_ of arguments, you may hit the recursion limit. The current implementation doesn't call itself for each extra argument. Instead, it just expands the extra arguments out directly. The `fn $label` aspect doesn't really have anything to do with it.
I use [`watchexec`](https://github.com/mattgreen/watchexec) for my web-dev server reloading. It works pretty nicely. A solution within the framework which doesn't require restarting the executable would be more awesome tho. 
deleted ^^^^^^^^^^^^^^^^0.4340 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/07394)
I see. Thanks for the explanation!
The post rails on the compiler a bit, but Rust just uses LLVM, and similar C/C++ code should be optimized the same in clang (and usually GCC). Would be interesting to see if that's really the case, and if not, why we're losing out.
Sure, take a look at this function that waits on a receive and a send operation: https://github.com/stjepang/channel/blob/master/examples/csp.rs#L55
Wasn't Elm at the root of the new layout for Rust error messages (pioneered by [Dybuk](https://www.reddit.com/r/rust/comments/3totkg/dybuk_the_elmlike_rustc_error_pretty_printer/))? I am not saying that rustc error messages were not good before that (they were at least as good as Clang's, with additional goodness for not having levels and levels of template instantiation stacks); but I think that the Elm-inspiration presentation is a whole other level of goodness. I hadn't even *thought* error messages could be that significantly improved before I discovered Dybuk!
Oh, this looks pretty useful. Sure with unit-tests it's easy enough to check that *your* code assumptions hold; but since the tests do not run for the dependencies you rely on (AFAIK)...
We're exposing Hyper's powerful `Request` and `Response` types directly, rather than creating our own. To store our `State` there, we'd need to introduce our own types here, and then we'd have a piece of complexity where the `State` value needed to be moved _out_ of the `Request` and into the `Response`. I agree that the need to return both values is different to most frameworks. After spending a little time with it, I haven't really found it to be a pain point -- just a difference. I'm hopeful that others will have the same experience.
That makes sense, thank you for the clarification.
I'm not familiar wiht GitHub Desktop, but some searching brought me to [the Git for Windows SDK](https://github.com/git-for-windows/build-extra), whose documentation says: &gt; ...Git for Windows uses MSYS2, a project providing a minimal POSIX emulation layer (based on Cygwin)... ...and it [includes a copy of OpenSSH](https://github.com/git-for-windows/build-extra/blob/master/ReleaseNotes.md#new-features-4). So, you've got Cygwinized SSH (for git and GitHub Desktop to use) and Cygwinized ssh-agent (for storing passwords) and all of those things work nicely together. Cargo isn't Cygwinized, though, and it can't talk to your Cygwinized ssh-agent. Digging through source-code, it seems that Cargo uses libgit2 for its git interactions, and libgit2 uses libssh2 for its SSH interactions, and [libssh2 only supports PuTTY's ssh agent Pageant on Windows](https://github.com/libssh2/libssh2/blob/64ebfd8182a9b6e637e65c3059e3798e199274b3/src/agent.c#L365). I believe Git for Windows *does* let you use PuTTY and Pageant instead of its bundled copy of OpenSSH, so if you want an SSH setup on Windows that works with both Cargo and GitHub Desktop, I suggest switching to that.
IIUC, the loop is consuming CPU until it gets a message, right? 
How do you compare yours with [multiqueue](https://github.com/schets/multiqueue)?
What's your take on [structopt](https://crates.io/crates/structopt)?
Using cargo features makes this really unusable for libraries, because cargo features are designed to be additive. This means that if any library anywhere in my project's dependency chain enables the unchecked flag, then it will be enabled for my project &amp; all other libraries depending on this crate as well.
Hm, can not compile simple code on 64bit machine: #[macro_use] extern crate static_assertions; fn f() { assert_eq_size_val!(u64, usize); } 
First of all, you shouldn't need that `.clone()` there. `Path::file_name` only needs to borrow its argument, it doesn't need to own it. As for cutting down on `unwrap`s... well, you don't return a `Result` type from that function, so you can't really do any proper error handling anyway. You might want to read [the book chapter on error handling](https://doc.rust-lang.org/book/second-edition/ch09-00-error-handling.html). As a general note, you can replace "do thing, unwrap, do thing, unwrap" with something like: path.and_then(Path::file_name) .and_then(OsStr::to_str) That gets you to `Option&lt;&amp;str&gt;`, at which point you might use `.ok_or(SomeError)?` to fail out if something goes wrong. The need for `to_str` is because not everything implements `Display` (which is what `{}` relies on). In the case on `Path`, this is because paths are OS strings, which aren't "real" strings since they can contain arbitrary data. Thus, the API forces you to explicitly deal with the "I can't turn that into a string" case. That said, you could use `Path::display` instead, which... I don't know how it handles the non-Unicode case, but it does.
I'm not sure what to recommend, but I can explain why you need all of those (expect the `clone()`, not sure what's up with that). Rust strings are UTF-8, but file names generally don't have to be. Linux, for example, allows any byte string that doesn't contains slashes and NULLs. Rust uses `OsString` and `OsStr` to represent filenames. You can use `to_string_lossy` to get a `str` from an `OsString`. It will replace bytes invalid in UTF-8 with something else. I don't really do Python, but I think it Python 3 has a similar situation w.r.t. strings and file names and people hate it for that.
Any plans to merge https://github.com/istankovic/cargo-book into `cargo` repo, and supply it with other `rustc` documentation?
Your code will essentially abort on all edge cases: 1. Glob_with could fail, it probably does filesystem queries. 2. Race condition on opening the file. If the file is deleted/moved/renamed after glob_with found it but before you open the file unwrap will fail. 3. Rust strings are UTF-8 however the filesystem has no such restriction. If any files you touch are not UTF-8 the program will crash. The other unwraps seem legit. However the code could be structured better like moving the repeated queries on `path` right at the start of the for loop. You should still handle these edges gracefully though.
Under the intended use, libraries should never enable this flag by their own, but they should allow any users of the library to enable the flag. Meaning that in order to be useful it needs to be propagated upward from the libraries to the binaries that use them directly or indirectly. In other words, for a program build where there is a large dependency tree where `czc-refcell` is used sparingly or plentifully between libraries in an invisible or visible manner to the top level Cargo, I would expect that by convention there would be absolutely no such thing as a default `unchecked_refcell` activation between the libraries, and only allow this feature to be propagated and activated when 'cargo build' is being executed for the binary itself. As mentioned here, it is useful as a mechanism to check `RefCell` overhead in a program as a whole, and give the developer the choice to take risk and produce faster binaries with reduced run-time guarantees.
cc [/u/acrichto](https://www.reddit.com/user/acrichto)
That seems horrible abuse of the `include!` macro! Why couldn't you just create a `handle_some_long_command` function in your some_long_command.rs module and just call it from the match case?
Languages and tools, tend to evolve according to their widespread use. If Rust ever achieves a widespread adoption such as C/C++'s, I can see a point in the future where 'safe' as it is now would be feature dependent (and expectedly, very hopefully, remains the default), especially if more users decide that 'safe' in a long-term systemic rigorous development process is more what thoroughly and empirically tested and less what the compiler or extra runtime checks suggest is safe. This is, because we still have to trust each and every 'unsafe' keyword use in the libraries that we choose to use, and the soundness of the compiler itself, to result in total run-time safety. However, I understand the concerns, and I'm willing to rename the feature to include 'unsafe', or even 'unsafe_as_safe', if it appeases the older Rustaceans :) And yes, `Conditional Unsafe Zero Cost RefCell` could be a tiredly longer description of it.
No local variables or macros would be kept. Besides, what *is* the correct use of `include!` if not this?
Looks nice! Wouldn't use it myself because of extra dependencies, but still, cool!
As for local variables, just pass them to the handler function as arguments. I believe the primary reason for the `include!` macro is for code generation: [build.rs](http://doc.crates.io/build-script.html#case-study-code-generation) You can generate code and write it to build artefact folder from which it can be `include!`ed in your source.
No, it's smarter than that. Calls to `select` update a hidden thread-local state machine that keeps track of the cases, and sometimes they decide to block the current thread until a case is ready.
Passing all local variables to a function would make a loooong function definition. Sure, structs exist, but why make structs only to pass some data to one single function
multiqueue is: 1. Always bounded. 2. Never sacrifices performance. 3. Can broadcast messages. 4. Doesn't support selection. My channel: 1. Can be bounded or unbounded. 2. Sacrifices some performance for ergonomics and flexibility. 3. Cannot broadcast messages. 4. Has very powerful selection. To put it shortly: * multiqueue is for high-performance computing pipelines. * My channel is a kitchen-sink channel you'd use every day.
Just pass the ones you need
`assert_eq_size_val!` is for comparing the size of variables, not types. Correct line would be `assert_eq_size!(u64, usize):`.
No offense but the error message `not a value` should have probably been a good clue. Either take the route /u/Pseudofailure provided or use complete literals like `0u64`, `0usize` etc. edit: formatting
`word.to_string().into_boxed_str()` The first conversion allocates memory for a copy, the second trims the memory allocation to fit. 
You should try [gumdrop](https://crates.io/crates/gumdrop) then. It looks similar to structopt, but has no dependency.
&gt; unsafe_as_safe That seems really really harmful, should the function that is potentially unsafe not just be marked unsafe?
I tested it and it gives an impressive boost to the unsafe variants (making one of them 4x faster than [the C version](https://paste.rs/Pwm) built with clang4 with -O3). lto Runtime unsafe PT0.539604008S Runtime unsafe 32bit PT1.643463621S non-lto Runtime unsafe PT2.449106398S Runtime unsafe 32bit PT2.254137954S C, clang4 -O3 Runtime C 2.097054 (yes I pinned the cpu to another clock this time :P)
I tried some more things and compared it with [this](https://paste.rs/Pwm), if you have time to dig a bit deeper or guide me, I should be available on IRC :) PS: Do not confuse me with Kostya, we aren't the same person :) 
`sudo dnf remove rust` I guess
Idk, it depends on what's in it. Go and find out!
I am not quite sure if I understood what the effect of `select` on *sending* is supposed to be: - is it waiting for the message to be queued, - or waiting for the message to be received at the other end? --- Beyond that, I am not too fond of the `loop { ... }` API proposed. It seems rather... *obscure*, to say the least. Maybe it's a matter of learning the idiom but I would really favor a higher level of abstraction in the API. Maybe a: fn foo(a: Dummy, tx0: &amp;Sender&lt;T&gt;, tx1: &amp;Sender&lt;i32&gt;, rx0: &amp;Receiver&lt;T&gt;, rx1: &amp;Receiver&lt;String&gt;) { select(&amp;[ &amp;selector(tx0, T::default(), || { println!("T sent to {}", a); }), &amp;selector(tx1, 1, || { println!("1 sent to {}", a); }), &amp;selector(rx0, |t: T| { println!("received {}", t); }), &amp;selector(rx1, |s: String| { println!("received {}", s); }), ]); } I am not clear whether: 1. It is easy/fast to select on multiple channels, 2. The syntax is palatable enough (the lack of variadic arguments hurt... and point toward macros). However, it seems higher level than the proposed interface; and can easily enough be implemented with `loop` under the scenees. --- Another source of concern is scalability. Is there really no better than to poll? I am somewhat afraid that scalability to 10s/100s/1000s of queues will necessarily suffer. Ideally, I'd be ready to pay a cost for *establishing* the select (such as registering a callback on each queue, which could require allocation, hopefully amortized), but afterward I'd wish for the latency between the push on one of the queue and the pop in my select to be as low as possible.
thx, man. It worked. I'm so fucking noob at linux
&gt; A constant expression can be ensured to evaluate to What counts as a constant expression here? Not everything deterministic counts, I'm guessing.
Oh, lol, I mean the actual structopt itself
Can't pass macros though
The downside is this: imagine that you merely want to check the performance impact of using the standard `RefCell` in a large project tree. Massive editing would be needed, because all calls to `.borrow()` and `.borrow_mut()`, normally residing in safe scopes, would need to be surrounded by `unsafe {}`, which means `czc-refcell`could not serve as an easy drop in replacement where the only edits required are the `use` imports and `extern crate czc-refcell`, and some `Cargo.toml` tweaks.
I assume it refers to `const` variable bindings and expressions comprised only of literals (and maybe operators) since AFAIK those are compile-time evaluated and therefore constant at runtime.
Can you give an example of a use case? If it's a constant, you already know what it's going to be, right? The only thing I can think of is a constant variable, like for example `MAX_CUSTOMERS` changing and this assertion making sure that a function does not break. But isn't that basically what unit tests are supposed to do?
If there was a standard mechanism for that behind a flag on nightly then it could be useful. Maybe even worth and RFC, doing it via ad-hoc cargo flags seems like a recipe for a disaster in production and reputational damage for rust.
I can't figure out if that's elegant or a little crazy, but it seems to work. I modified my code to be [something like this](https://gist.github.com/superlou/3b362a8fc5bcf1f287b2b54517fad7b3), and I'm able to pass messages back. I don't need to use SyncChannel again in the route, so at least there's a bit less overhead in the creation of the next channel. In some ways, this feels really nice because it means there's no potential for any kind of data mix-up to multiple clients since the channel is created specifically for a single HTTP request. If it's not fulfilled that request hangs, but everything else can continue working. [Lines 24-26](https://gist.github.com/superlou/3b362a8fc5bcf1f287b2b54517fad7b3#file-main-rs-L24-L26) seem like a lot of boilerplate that will get repeated over and over, but I may be able to wrap those in a single call.
I see. I find myself constantly wondering what is, and what in principle could, be evaluated at compile-time.
&gt; I am not quite sure if I understood what the effect of select on sending is supposed to be: Waiting for the message to be queued. Selection blocks until any of the operations can succeed. And a send operation might not succeed immediately because the queue might currently be full. Regarding your `select(&amp;[...])` idea, how would you do the following? let tx1: &amp;Sender&lt;String&gt;; let tx2: &amp;Sender&lt;String&gt;; let mut foo = "foo".to_string(); 'select: loop { for tx in [tx1, tx2].iter() { if let Err(s) = tx.select(foo) { foo = s; } else { break 'select; // success! } } } The problem is that as soon as you put lambdas and references into the equation, Rust's ownership system starts getting in the way. How do you return the ownership of value given to an unsuccessful send case? This is why I believe the *loop-and-poll* approach lends better to Rust than *subscribe-and-block* (what you're proposing and what `std::sync::mpsc` uses). I think looping gives you the most freedom while still being ergonomic and performant. &gt; Another source of concern is scalability. Is there really no better than to poll? Technically, looping and polling (with some magic behind that blocks at the right moment) is not that much different than subscribing and then blocking... But perhaps this question should be better addressed in the follow-up post. &gt; Ideally, I'd be ready to pay a cost for establishing the select (such as registering a callback on each queue, which could require allocation, hopefully amortized), but afterward I'd wish for the latency between the push on one of the queue and the pop in my select to be as low as possible. Excellent remark. I personally wouldn't be willing to pay for allocations, but the point stands. :) The looping mechanism I described in this post is a bit simplified from what I actually want to implement, so I think the problem can be alleviated in some ways. But again, a complicated story for another post...
I think Fedora also has a GUI for package management as well, though it's been years since I used Fedora so I'm not sure.
Unit tests catch errors in constants at runtime whereas this is at compile-time. This falls more in line with Rust's philosophy of ensuring safety and correctness before the program even runs, such as with the borrow checker.
You ever find the answer? 
Why are you against adding extra dependencies?
It's GNOME Software. And it doesn't work for all packages, it's really for GUI programs for people who don't use the command line.
No idea actually. ¯\\\_(ツ)_/¯
Termion
'Fraid not, I've been at this for 5 days now. Not even reinstalling solves the problem, and I really don't want to wipe PC at the moment. 
After looking throuhg the cargo apk code, it's because the gradle command for wiindows is actually a .bat file. Unfortunately, changing this to gradle still doesn't work. I made a test crate an tried to run the code myself. This is the command the cargo apk crate uses: Command::new("gradle").arg("-v").stdout(Stdio::null()).status(); When it's `gradle`, it fails and says file couldn't be found. If you change it to `gradle.bat`, assuming the gradle/bin folder is on your path it works fine. I've pulled and will hopefully be merging with an option for customising the gradle command!
What's the reason why `izip!(aa, bb, cc, dd)` doesn't just create something like: IntoIterator::into_iter(aa) .zip(bb) .zip(cc) .zip(dd) .map(|(((a, b), c), d)| (a, b, c, d)) Does the `Zip` structure exist so the return type can be named?
I just checked, and it looks like there's something called "apper". I haven't used it, but it seems to not be installed by default but does include non GUI packages.
Having more dependencies mean longer compile time, more possibilities of bug, more code to read before adding the dependency.
Having a Rust implementation of Go-like channels could be a big win to the whole threading discussion currently taking place. Channels might not be a solution to all threading problems, but it covers most use cases. It is also easy to learn and use, specially on top of Rust's guaranties.
The canonical URL is https://forge.rust-lang.org/platform-support.html
It exists to be named. Before, izip used that solution, and I think we should go back to that. Edit: It wasn't exactly that smart before, it was flattening tuples after each zip. If you can implement exactly that as a macro, you should PR it to itertools. I'm unsure how to accomplish it in one `map` in a macro.
And these should never be considered by themselves - they should always be compared to the extra work, complexity, and possible bugs when you implement something similar yourself.
It allows you, for example, to make a function which takes any struct which is less than some number of bytes in size safely. I've personally needed something like this in an embedded context.
I've been fiddling around with the Tokio and Futures to implement a very rudimentary handshake between a client and a server. I'm able to get the client to send a "handshake" message, and then wait for a "handshake" message from the server. But for the server, I can't get the inverse to compile (receiving a handshake, and then responding in kind). [client](https://gist.github.com/anonymous/9fa2fec61bdae7de1399ce69bfad4e4d) : This compiles, although is probably not the most idiomatic/well-written way to do things [server](https://gist.github.com/anonymous/9fb8b027de79196f71dd7702a1ff0c61) : This doesn't compile, and *only* after adding the `.and_then(...)` on line 38. The entire error message is quite, umm, verbose, but essentially boils down to &gt; note: expected type `futures::stream::SplitSink&lt;tokio_io::codec::Framed&lt;tokio_core::net::TcpStream, async_practice::MyMsgCodec&gt;&gt;` found type `()` On line 25 of server.rs.
I've heard stories where, if printing out a bit of debug information stops the race condition from happening, the developers simply keep the debug information there and move on. Thanks for hanging in there! 
This seems useful for generic code.
&gt; Having a Rust implementation of Go-like channels Note that such an implementation has existed for quite some time. See the [`chan`](https://docs.rs/chan) crate. The OP mentions the chan crate, but wants to improve on it, which sounds great. But `chan` itself works today.
Note that Rust also has first-class support on Windows and Mac, if that's more to your liking.
I guess you are binding a new name, but `let` isn't present in a normal `match` arm. Is the creation and nature of *state* (variable in this example) in a `if let` different from when it's in a `match`?
Is that possible with this library? I only see equality checking, not inequalities.
Thanks for emphasizing that, I didn't pay attention to that detail. Taking a look at that crate right now.
When `mem::size_of` becomes a `const fn`, size inequality can be asserted via `const_assert`.
I see. A little bit magical, but I can see the improvement on ergonomics :)
Wow, which file is this line located in? I admit that I've only installed through Rustup and didn't look through the rust install directory... I'm still pretty new to Rust, so this help is much appreciated. :3 
Unfortunately, `mem::transmute` can't be called on generic types. A `const fn` `mem::size_of` would be required for use in a generic context.
OOP is not that bad. **Java** is the one that's that bad. Making everything an object can be an elegant design choice(design-wise! Performance-wise it depends on how well the common degenerate cases can be optimized away), but Java's verbose syntax, combined with the mindset that every class, even if it's role is just boilerplate, must obey every general OOP best practice anyone ever thought of, results in that overcomplicated abomination known as _Enterprise Java Code_. Java 8 changed things drastically, making Java code infinitely more elegant - though still behind... well... any other modern language. If we look at the example from the blog post(with some syntax errors fixed): public interface CommandHandler { public String[] acceptCommands(); public int minArg(); public int maxArg(); public void handleCommand(String cmd, CommandArgs args); } public class EchoCommand implements CommandHandler { public String[] acceptCommands() { return new String[]{"echo"}; } public int minArg() { return 1; } public int maxArg() { return Integer.MAX_VALUE; } public void handleCommand(String cmd, CommandArgs args) { System.out.println(args.join()); } } Now, if I add a lil bit wrapping: import java.util.function.BiConsumer; public class SimpleCommand implements CommandHandler { private String[] acceptCommands; private int minArg; private int maxArg; private BiConsumer&lt;String, CommandArgs&gt; dlg; public SimpleCommand(String acceptCommands, int minArg, int maxArg, BiConsumer&lt;String,CommandArgs&gt; dlg) { this.acceptCommands = acceptCommands.split(" "); this.minArg = minArg; this.maxArg = maxArg; this.dlg = dlg; } public String[] acceptCommands() { return acceptCommands; } public int minArg() { return minArg; } public int maxArg() { return maxArg; } public void handleCommand(String cmd, CommandArgs args) { dlg.accept(cmd, args); } } Now, an object equivalent to `EchoCommand` can be created like this: new SimpleCommand("echo", 1, Integer.MAX_VALUE, (cmd, args) -&gt; { System.out.println(args.join()); }); And this is Java! With languages that provide decent reflection it can be even simpler: Python: @command def echo(cmd, *args): print(' '.join(args)) Ruby: command :echo do |cmd, *args| do puts args.join(' ') end Of course, with dynamically typed languages that heavily support metaprogramming these kind of things is easy. But even with Rust without macros we can have: command("echo", 1, u32::MAX, move |cmd, args| { println!("{}", args.join); }); And it can still create an object that can be manipulated with OOP comfort. (with macros we can get something similar to the Python and Ruby examples) So, what I'm trying to say is that OOP can be elegant - it's the Java culture that makes it verbose, ugly, and difficult. 
&gt; Between the let and = it looks like assignment is happening within an if statement. That's because it *is* happening! You can use the names bound by the `let` within the `if` block, just like for standalone `let`s.
Yes, they may be sensitive to changes, but in pratique that does not happen often. Anyway, this shouldn't be a problem anymore. A recent commit now makes natvis embedded in PDB files (nightly), it should land sometime soon in stable.
&gt; The `select` methods access a hidden thread-local state machine to track the current state of selection. So selection actually works as a behind-the-scenes state machine whose input are calls to `select` methods. &gt; &gt; In the first iteration of the loop, the state machine remembers the first case and counts how many cases there are. All cases return errors. &gt; &gt; Then, in the second iteration, it goes around again and attempts to fire each case, essentially by calling `try_recv` and `try_send`. &gt; &gt; If all tries fail, then in the third iteration all cases return errors again, but cases get registered along the way into the state machine’s conditional variable. After completing the last call to `select` in the third iteration, the current thread is blocked. &gt; &gt; As soon as the thread is woken up, in the fourth iteration, all cases return errors, but channels get unregistered from the conditional variable. &gt; &gt; The fifth iteration is the same as the second case - we attempt to fire each case in order. If all cases fail, we continue by registering them again. &gt; &gt; That’s it. Obviously, there must be some rules one must follow when enumerating cases in a selection: &gt; &gt; * All cases must appear in the same order. &gt; * As soon as a case succeeds, the loop must be broken. &gt; &gt; Violating the rules would not lead to code unsafety, but might cause deadlocks, and similar kinds of weirdness. But I think this is not a big concern since the rules are easy to uphold. *Please* don't introduce APIs where ordering of statements matters but there's no way for a reader of the code to track this as dataflow (and the compiler to check it with types). How would this API interact with reentrancy? Is it a problem to have a function inside one of these `select`-loops internally run its own `select`-loop? I would much rather see an API that explicitly returns a "SelectGroup" object and passes it to the various `select` calls; I'd also rather see the `loop` control flow hidden (whether with a function accepting a `SelectGroup` and closure capture, or just with a macro); the programmer shouldn't have to think about the fact that their select calls are pushing along a state machine under the hood and need to be surrounded in a loop as a result, especially if the state machine itself isn't made visible. Either make all the complexity explicit or package it up into a robust abstraction, but don't give users an interface that's "simple as long as you follow the rules (which the compiler can't check for you)". 
Good news, soon you'll not need to care about natvis as a recent commit on rust makes it embedded in the debug information file (pdb), this is already working on nightly. The symbolSearchPath and natvis are different things. Natvis helps the debugger to show in a clear way the contents of a type. The debug symbol helps the debugger to name things and to know which type things are, but not how to show the type info. So, for better debugging capabilities, both are required.
Uhm... this seems useful in a macro then, that could be used on many types but at each use site is not generic.
Could we add this under a nightly-only feature flag in the meantime? Would allow us devs to play with it &amp; give you free test coverage – win-win 😀
`if let` syntax is mostly copied from Swift. There is no deep reason for it, except that Swift already used it.
To add to the other good advice, if you are OK with installing nightly, you could try running [clippy](https://github.com/rust-lang-nursery/rust-clippy) over your code. (Actually, you'd need to either pin Friday's version or wait until we fixed the recent breakage because the lint API changed)
If you find the android-rs-glue, it's under cargo-apk/src/ops/build.rs. The command takes a string which is defined in cargo-apk/src/config.rs. I managed to get through the gradle error! But now i have mingw gcc errors *sigh* 
It works now :) Apparently, rls was having issues with file I have been testing with. When I switched to other files in the project, everything works.
Thanks for the thorough reply. Indeed, the ownership issue is a concern, since returning from the lambdas would be complicated. I guess this could be solved by: 1. Having a `Lambda&lt;Env, Args, Result&gt;` trait, which allows consuming the lambda to recover the `Env`, 2. Variadics However this is far far away, so I agree that it would be better to create a convenient API with today's capabilities in mind. After all, nothing precludes evolving the API when the language's expressivity improve. Regarding the scalability, I suppose that there is no way to "park/unpark" an OS thread without involving the OS for signalling, which could add overhead. On the other hand, I am also concerned about active polling solutions which consume CPU slice times to do... nothing; it seems that you have to pick between: - either you want low-latency, and can do nothing than polling as fast as you can (not CPU friendly), and even time you introduce an average delay which corresponds to the average time it takes to make a full loop, - or you implement a back-off mechanism to "sleep" between the polling rounds, which also introduces a delay. *This is one of the things that I am not to sure off about the polling mechanism in futures.* I am looking forward to further posts and seeing how you plan to address those issues.
Excellent point about hidden information; I agree I'd rather have state be explicit, many of the libc functions are plagued by thread-local (in the best of case) global state and it has always proven to be a pain in hindsight.
&gt; Wasn't Elm at the root of the new layout for Rust error messages The layout yes, I'm thinking about the content and spirit behind it.
I'm skeptical of that -- having unstable features in itertools takes us further from 1.0 rather than closer. That said, I have pondered if the crate maybe needs to stay off 1.0 so that it can adapt for libstd hopefully stealing its best features. A crate that is not used for its traits and types should not need to be 1.0 as much. As I said, I'm very wary of unstable features -- it makes the versions useless. Sooner or later the crate breaks and user and maintainer has no real control over that. I think “unstable itertools” just should have its own crate, then the problem is isolated.
Ah! Guess it explains why we had so different opinions :D I agree with you that the content has been great from the beginning, and has only improved over time!
Sure, elegant. But lightweight? I wouldn't guess so, but perhaps most is optimized away
If it's just to check the perf impact, make it a git-only dependency (i.e., don't publish to crates.io). This way folks can play with it but won't publish crates that use it. If it's a tool it should be like a tool; usable locally but not something you make possible to bake into the package.. If it's not
Is there a fundamental difference in how name binding works between `if let` and `match`? Or are they equivalent? I think I'd amend my statement to... The syntax difference between `if let` and `match` seems to imply that `if let` does something different in terms of name-binding/variable-creation when in fact they both are equivalent, which makes it confusing. 
I guess nobody clarified this to you, but _nobody_ runs the full WPT suite locally. You either run specific folders, or ask the build servers to run it and report results (ask someone with review access to servo to do a "try" for you if you need this)
Hey! Yes, I meant running the full suite takes almost an hour on CI, that's why it's a good idea to run the relevant tests locally before trying on CI again. I'll edit the post to clarify that, thanks! :)
[I gave it a try](https://github.com/bluss/rust-itertools/pull/212)
&gt; How would this API interact with reentrancy? Is it a problem to have a function inside one of these select-loops internally run its own select-loop? Yes, that would be a problem. Select loops should simply enumerate a list of select cases, for example like this: let mut event = loop { if let Ok(x) = self.port.select() { break FromScript(x); } if let Ok(x) = self.control_port.select() { break FromConstellation(x); } if let Ok(x) = self.timer_event_port.select() { break FromScheduler(x); } if self.devtools_chan.is_some() { if let Ok(x) = self.devtools_port.select() { break FromDevTools(x); } } if let Ok(x) = self.image_cache_port.select() { break FromImageCache(x); } }; This example is actually taken from Servo and adapted to use my API. The original looks like [this](https://gist.github.com/stjepang/1ef9d96709b5c3fa571cfc6c5fef87fb) (31 lines of code!). You're allowed to do anything you want within a successful if-branch, but not much within the actual loop. &gt; Please don't introduce APIs where ordering of statements matters but there's no way for a reader of the code to track this as dataflow (and the compiler to check it with types). Completely fair point. I'm not left with anything else other than to argue: 1. That all other solutions are even worse. 2. That *loop-and-poll* is not that bad. :) First, here's one alternative using a lambda that hides the loop: let mut name = "Alice".to_string(); let peer; select(|sel| { if let Ok(p) = rx.select(sel) { // Success! peer = Some(p); // PROBLEM: We cannot execute a FnOnce here because who says that // this line will be executed just once? } if let Err(n) = tx.select(sel, name) { name = n; } else { // Success! peer = None; } }); // PROBLEM: is peer initialized or not? Something similar matthieum proposed a few hours ago. But the problem here is that the control-flow graph doesn't guarantee that a successful case will be executed at most once. Therefore, you cannot execute a `FnOnce` within a successful case. Also, you cannot initialize `peer` like this because it's not mutable. And the control-flow-graph doesn't guarantee that it will be initialized at all so you can't use it after selection. Now let's try again with the *loop-and-poll* approach, but this time hide the loop in a macro: let mut name = "Alice".to_string(); let peer; select! { p &lt;- rx { // Success! peer = Some(p); } // Here, mut indicates that name is mutable and we should // write back to it on a failed attempt. tx &lt;- mut name { // Success! peer = None; } } // Good, peer is now initialized. But now if you write `break` within `select!`, that will be very misleading and probably wrong because it will break the hidden loop! A programmer reading the code might think a bigger outer loop surrounding selection is broken instead. Unfortunately, there is no easy way out. We have to get back to: let mut name = "Alice".to_string(); let peer; loop { if let Ok(p) = rx.select() { // Success! peer = Some(p); break; } if let Err(n) = tx.select(name) { name = n; } else { // Success! peer = None; break; } } It's not *that* bad, is it really? I mean... yeah, it's definitely not perfect and I'd *love* some support from the language to encode more precisely what is going on here, but the language already guarantees a few things. It guarantees that: 1. Exactly one select case will succeed. 2. The successful case will be executed exactly once. This is the important part - dataflow is in fact *more* rigidly constrained like this than with other solutions! &gt; Either make all the complexity explicit or package it up into a robust abstraction, but don't give users an interface that's "simple as long as you follow the rules (which the compiler can't check for you)". Before I settled with the current API, I did expose the state machine and it had to be instantiated explicitly and passed into `select` methods. But honestly, it just felt like boilerplate that isn't worth it, so I removed explicit state machines... *shrug*
I agree with a lot of this. For my use cases I see rust as a tragic waste of potential - the language engine is amazing, but for the sake of a few options they don't want, the potential productivity gains are wiped out. The frustrating thing is: currently C++ is better, but it would take far fewer additions to Rust to make 'something near perfect' compared to forking C++.
mio implements asynchronous I/O operations, while `std::net` blocks until its operation is done. Before I give a shitty explanation, you can google for "async io", "event loop", "non-blocking io" :)
There are other ways with different balance between elegance, performance, flexibility and maintainability. The point is that enterprise Java code should be taken as example for OOP, because it tends to value flexibility above all else. Enterprise Java developers stretch the flexibility quality to the point where adding a tiny extra bit of flexibility will take a huge toll on elegance and performance - and they'll do it anyways, and dare to call their mess of result "maintainable".
 % clang -O3 hello.c &amp;&amp; ./a.out Runtime C 1.075020 % clang -O3 -march=native hello.c &amp;&amp; ./a.out Runtime C 1.104412 % clang -O3 -flto hello.c &amp;&amp; ./a.out Runtime C 0.536147 % clang -O3 -march=native -flto hello.c &amp;&amp; ./a.out Runtime C 0.334876 % gcc -O3 hello.c &amp;&amp; ./a.out Runtime C 0.478893 % gcc -O3 -flto hello.c &amp;&amp; ./a.out Runtime C 0.481079 % gcc -O3 -march=native hello.c &amp;&amp; ./a.out Runtime C 0.266739 % gcc -O3 -march=native -flto hello.c &amp;&amp; ./a.out Runtime C 0.264118 Compiler flags matter. The memory access pattern of the code is a bit weird as well, and not every place in the array seems to be written into. Oh well. As for the rust code, for reference, Runtime reference PT1.710139094S Runtime reference 32bit PT1.462054804S Runtime unsafe PT1.302068650S Runtime unsafe 32bit PT1.184229016S Runtime chunks PT1.491127316S Runtime chunks 32bit PT1.446181355S Runtime zip PT1.291256356S Runtime zip 32bit PT1.141380748S Runtime izip PT1.465849122S Runtime izip 32bit PT1.307360400S and with lto Runtime reference PT1.192102245S Runtime reference 32bit PT1.064664985S Runtime unsafe PT0.184809270S Runtime unsafe 32bit PT0.727893115S Runtime chunks PT1.322044538S Runtime chunks 32bit PT1.315775705S Runtime zip PT1.168974569S Runtime zip 32bit PT1.044452997S Runtime izip PT1.361310665S Runtime izip 32bit PT1.282682126S finally with lto and RUSTFLAGS="-C target-cpu=native" Runtime reference PT1.068374854S Runtime reference 32bit PT0.984880740S Runtime unsafe PT0.178434878S Runtime unsafe 32bit PT0.344185039S Runtime chunks PT1.197957251S Runtime chunks 32bit PT1.256171533S Runtime zip PT1.119079110S Runtime zip 32bit PT1.048644560S Runtime izip PT1.265377696S Runtime izip 32bit PT1.271459673S Which is to say that the unsafe rust is indeed faster. The generated asm also looks better at a glance, so I wonder why C is getting stuff wrong here. I didn't bother checking if the slight differences in coding style might have anything to do with it; I assume the codes are indeed doing the same things.
The syntax of `if let` may make more sense if you think about it as a conditional `let`. `let` allows irrefutable pattern matching only: let (fst, snd) = (15, 42); While `if let` allows refutable pattern matching only: if let (19, snd) = (15, 42) { ... } else { ... }
In my opinion this is a fundamental misunderstanding of the nature of safe, and is exactly where the "I can write safe C++"/"Nobody can" debate comes from. Safety isn't static. It's not a goal you achieve and dust your palms. It's a very dynamic property. Because _code_ is dynamic. If you write code once and then forget about it, it may be safe when you test it, but it may not _stay_ safe when others (or you) modify it. Rust is about making this no longer a problem. Safe Rust never has to worry about breaking anything. Unsafe Rust is supposed to be written so that it exposes a safe API _no matter how it is used_. This shifts burden to unsafe code, but it's relatively rare so that's ok. I'm all for having more ways to verify safety, hell, I wrote `cargo-fuzz`. But that doesn't mean we should care _less_ about the compile time checks. I see the evolution you describe as a step _backwards_. Just because C and C++ have widespread adoption doesn't mean they're right about everything. &gt; This is, because we still have to trust each and every 'unsafe' keyword use in the libraries that we choose to use, and the soundness of the compiler itself, to result in total run-time safety. Just because you have to trust each and every unsafe keyword doesn't mean Rust's safety approach is futile and you should stop caring about it.
Yeah, Vec::retain was a "mistake". There's [retain_mut](https://docs.rs/odds/0.2.25/odds/vec/trait.VecExt.html#tymethod.retain_mut) in the odds crate though, and soon there might be [Vec::drain_filter](https://github.com/rust-lang/rust/pull/43245), both of which are workarounds for this.
How'd such thing even work?
Thanks for writing such an elaborate blog post, and going in depth about the tools you used and how you used them! I don't read fiction books but I would read a book full of such stories!
awesome, thanks
If you enjoyed this, you may want to read articles posted to https://lobste.rs/t/debugging.
That really depends on the language, but in ways a lot of people forget to take into account, so you really need to write some code and test it. You don't just have to take into account how smart the compiler's optimizer is, but whether the language's semantics are inherently more lightweight and whether the overhead is even worth quibbling over compared to the greater task. For example, Java does quite a bit of indirection that both fills up space with extra pointers and interacts poorly with CPU caches. That ability to do runtime reflection also doesn't come free. By contrast, Rust `struct`s not only pack everything together without extra framing, there was recently an optimization added for non-`#[repr(C)]` structs which reorders the fields during compilation to minimize the need for padding. That's why it's convention to create newtypes using single-element structs. Once the compiler's done with them, the struct has vanished and they have the same in-memory representation as if you'd used the inner variable directly. And, that aside, parsing command-line options is going to happen once per process run and is going to operate on a tiny amount of data. If I can ever justify the time to figure out how to do it properly, I'd like to see how long various option parsing implementations take compared to the syscalls like `fork` which *can't* be avoided, given that "minimize the number of syscalls" is one of the classic pieces of advice for performance optimization.
Why does everyone think I am making a command-line option parser? I'm taking about command interfaces in general. Including everything from gdb to Minecraft commands. Similar thing. Split spaces, check first value.
Thanks!
Oh, point. I should have made it clear that my curiosity about the "overhead from `fork`" was somewhat separate from the rest. (Not to mention that I did say "syscalls like". I'd also like to compare to lighter syscalls like `read` which *would* be called repeatedly within the process.) I actually have some experience of my own in *using* things like Python's `argparse` for internal shells like that. (One of my long-mothballed projects is an IRC fserve for Linux that doesn't suck.) The point remains that you really want to get some solid data on whether this is *worth* worrying about before you worry about it. It's a very low-throughput I/O-bound process, so I'd look at the memory footprint before the CPU overhead.
I hardly think that Rust safety approach is futile. On the contrary, I like and care about it very much. However I also like to make sacrifices to squeeze out every bit of performance in order to beat the competition, preferably with ease. I find the approach I've taken for it quite ergonomic for this purpose, and there may be others to accept this trade-off, with respect to those who not. To each his own. As for widespread adoption, as it increases, people are free to take open source projects and use them as they please, even if it violates the ways the authors and maintainers have intended for their use, as long as it does not violate their assigned licenses. It's actually a factor that indicates the high degree of success of these projects, to mean no offence, but the opposite.
&gt; However I also like to make sacrifices to squeeze out every bit of performance in order to beat the competition, preferably with ease. Feel free to do what you want to your code. My concern is that other folks will misuse this; it's really important to have lots of warning signs on it (and to rename the feature which you already said you would, thanks). &gt; people are free to take open source projects and use them as they please, Sure, I'm just saying I think _this particular case_ is harmful.
Thanks! &gt; First of all, you shouldn't need that .clone() there. True, I went a little overzealous with the clones after `File::open` stealing the value (BTW why does `open` want to own the value? I would think it's just as fine for it to borrow as it is for `Path::file_name`). &gt; you can replace "do thing, unwrap, do thing, unwrap" with something like Thanks, that looks much nicer. 
Thanks for the explanation. I did not need the `clone`, I was just a bit overzealous after hitting the borrow checker on `File::open`.
I'm quite a noob at Rust and never tried to compile any Rust on Mac :-/
All good points, indeed. 
Thanks, it's good to know this exists. I'm actually on the nightly because I could not get RLS to work in vscode otherwise. It still doesn't really work for completion, sadly. 
Thank you for confirming the data :) And yes, I'm quite surprised lto is giving such boost (and such boost on unsafe itself). For the memory pattern, I made a random larger than needed array just because I couldn't be bothered to be precise, I doubt it would make a big difference.
Ah you need to pass `&amp;path` to only give it a borrow. I'm not sure if this is an oversight in the standard library or done on purpose because people complain they can't pass a `PathBuf` to `File::open`... Your example is a clear downside of trying to cater to newbies trying to make the language "easier", creating a different set of problems instead :/ 
On my iphone, after the first paragraph, there is a semitransparent black overlay that makes it really hard to read
Why would you need to read the code (apart from taking the chance to learn something new)? The docs are good, and it's simple enough to just try it following the examples.
Ah, alright. So you can do it right now in nightly.
 fn reverse_words(str: &amp;str) -&gt; String { return str.split_whitespace() .rev() .collect::&lt;Vec&lt;_&gt;&gt;() .join(" "); } I don't exactly understand what's happening here on the collect line. Anyone has a simple explanation whats happening and where to start looking?
When the crate author loudly advertises that it won't follow safe/unsafe API conventions, maybe some mods could manually tag the crate as unsound 
But how'd you detect such thing automatically (if not automatically, I envision great controversy on the management e.g. disagreement about details of the nonexisting memory model)?
Let's start with looking at the signature of [`collect`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect): fn collect&lt;B&gt;(self) -&gt; B where B: FromIterator&lt;Self::Item&gt;, From here, we can see that `collect` is a method that takes a generic type argument `B`, and returns a value of that type `B`. Notice that there is also a trait bound on type `B`, which must be satisfied. So by using the turbo fish syntax `.collect::&lt;Vec&lt;_&gt;&gt;()`, we supply this type argument to the method, to specify that the generic type argument `B` should be a `Vec`, and therefore this method should return a `Vec`. Note that the `_` in `Vec&lt;_&gt;` means that we are letting the compiler to infer the rest of the type signature, and can be also written out explicitly like `Vec&lt;&amp;str&gt;` in this case.
&gt; Unfortunately, there is no easy way out. We have to get back to: I think the situation would already be improved if, instead of using some thread local state, one would create a `SelectState` outside the loop and pass it to each select call. --- &gt; But now if you write `break` within `select!`, that will be very misleading and probably wrong because it will break the hidden loop! A programmer reading the code might think a bigger outer loop surrounding selection is broken instead. I don't think this would be a problem: (ab)using the control-flow analysis performed by the compiler, one can trigger a compile error if an unlabelled `break` or `continue` is used in the user code. For example, instead of generating this code: // outer user loop loop { // macro-generated select loop loop { if let Ok(p) = rx.select() { { /* some user code which maybe breaks or continues */ } break; // macro-generated select loop break } } } The macro inserts an additional loop and some clever assignments to trigger `E0384` if the user uses an unlabelled `break` or `continue`: // outer user loop loop { // macro-generated select loop 'select: loop { let _dont_use_an_unlabeled_continue_or_break_in_select; loop { if let Ok(p) = rx.select() { _dont_use_an_unlabeled_continue_or_break_in_select = (); { /* some user code which maybe breaks */ } break 'select; // macro-generated select loop break } continue 'select } _dont_use_an_unlabeled_continue_or_break_in_select = (); } } 
a few links from the near past to cross read if you're interested https://www.reddit.com/r/rust/comments/6qr11b/are_we_crossplatform_native_gui_yet/ https://www.reddit.com/r/rust/comments/6psav3/rust_library_for_declarative_nonnative_guis/ https://www.reddit.com/r/rust/comments/6l5c94/can_we_crowdfund_a_crossplatform_gui_lib_for_rust/ The short story is, there is nothing comparable yet. You can get away with some approaches but its not very close to a full experience you might expect. 
Ahh, I see, so collect can be used to collect into other container types as well? What other things than Vec do people use?
&gt; When would you use transform instead of mutate? I would have expected transform to take &amp;self instead of self, so that you can make a transformed copy while keeping the original. If you don't need the original, then wouldn't mutate be more efficient? In general, your intuition is spot on here. First, I was following the paper's structure, and it starts `transform` because that's the Haskell-y thing to do (there wouldn't even be a `mutate`). Second, I could imagine some scenarios where you needed to call some method that consumes `self`, do things with the results, and then construct a new `self`. But yeah, that would come up muhc less often than places where you could just use `mutate`.
You can see stdlib implementors of `FromIterator` (which is what powers `collect`) [here](https://doc.rust-lang.org/std/iter/trait.FromIterator.html#implementors).
My suggestion is not to seek a single mentor - those are incredibly hard to come by, and in my experience aren't really something you just find. Instead, I'd suggest you mess around with Rust, talk to people on IRC about questions you have, or ideas, and try to treat the community as a mentor. You'll probably find it far easier to jump into an open source project when you're talking to a ton of people who build them.
Also, you will want to comment on an issue first saying you would like to work on it. You may get chastised if you open a PR without commenting on the issue first, even for very easy issues. This kind of left a bad taste in my mouth when I was trying to contribute to Servo.
Works for me. 🖒
Even if you could get std::net to be non-blocking, there's no mechanism to pend on two (or more) sockets at the same time and wake up when any is readable/writable. mio offers that, abstracting the different OS-specific APIs available on Linux, mac OS and Windows. 
The closure passed to `Stream::for_each` [is expected to produce a future with an item of type `()`](https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.for_each), but [`Sink::send` returns a `Send&lt;S: Sink&gt;`](https://docs.rs/futures/0.1/futures/sink/trait.Sink.html#method.send) which [has an item of type `S`](https://docs.rs/futures/0.1/futures/future/trait.Future.html#associatedtype.Item) (so that you can use the sink again, because `send` takes the sink by move). The simple fix in this case is to add a `map(|_| ())` after that `and_then` (assuming you don't want to use the sink again).
Very nice trick, I didn't realize this was possible! :) I'll definitely consider this for a macro. Thanks.
I disagree with the idea that 'rust for servers' has been a mistake. I think the premise put forward is faulty. &gt; During the last year I have gotten the impression that Rust is only targeting a niche of a niche, that is, the tiny amount of developers writing high-performance Http servers. &gt;Most developers doing web/http stuff are using Javascript, Go, Ruby, Python, Java, … and they do not care enough about performance to use Rust. How do I know? Because those that do are already using C and C++, and that’s a tiny fraction of the group above. Essentially "Well, if people cared about performance they'd be using C/C++" - while this is sort of true, it misses something. The reason people use Java, at least the Java devs I know, is so they *don't have to use C/C++*. It isn't that they don't care about performance, or other things. It isn't that they love Java, or Go, or Python, or Node - it's a matter of priorities. No one wants to deal with memory corruption issues on top of everything else. &gt; For this web/http-dev audience that doesn’t care that much about performance Rust is not better than the languages they are already using, so why would they use it? Even though they might like Rust, they do not need it. I think we can look at Go here - Go makes concurrency simple, lots of us server devs have very concurrency-driven problems, therefor Go is a great choice. I disagree that Rust provides nothing on the server side over these other languages other than performance. The ability to reason about code is nothing to huff at - and one can argue that Rust is easier to reason about by virtue of its powerful type system. I don't think every server dev is going to care, I have found most developers don't really see too much power behind types, but that's a matter of education. We would *never* put C/C++ on our edge servers. Disaster waiting to happen - if someone planned on doing this I would be talking to project managers about it. Rust? Whole other story - feel free to put it in an attacker's path. I think perhaps the fear of C/C++, the disdain for segfaults etc, is being underestimated here. edit: That said, I do see their point - it's worth considering where rust can be successful. The obvious spot is as a C/C++ replacement where C and C++ are already popular, not where they sometimes get used.
&gt; &gt; During the last year I have gotten the impression that Rust is only targeting a niche of a niche, that is, the tiny amount of developers writing high-performance Http servers. Hardly. Async is important for any high performance application that does more than simple number crunching, and as pointed out on that thread, a large portion of applications expose either a web interface or a networked API. If anything, what was quoted was a long rant against async, with no clear suggestions for what to focus on that actually matters. &gt; &gt; That is, in 2018, Rust should run everywhere where C can run. We need at least a GCC backend, and way better would be to have a C89-backend. We need alloca, inline assembly, SIMD, CUDA, etc. Cargo should be able to easily compile C code, so that people can port C libraries from Makefiles and autoconf to Cargo, and cargo should be able to easily spit Makefiles. a GCC backend... let's be real, needing to target platforms that GCC can target but LLVM can't is *far, far* more of a niche than web servers. Inline assembly needs to be a high priority for microcontrollers, and there has been some attention given to microcontrollers in the past few months, so I'm hopeful there. SIMD is already promised for the end of the year on nightly as something that can actually be stabilized, unlike what we have now. CUDA is nVidia proprietary tech... so, unlikely to ever be a focus. Supporting LLVM GPGPU backends with function attributes would be nice, and someone did it experimentally years back, but GPGPU is extremely niche. Cargo can compile C code easily using the GCC crate with a build script. No, Cargo does not need to be able to "easily spit Makefiles." Everyone would want a different kind of Makefile. That's why there is no standard "make new" command like there is with Cargo. Someone can write a cargo plugin if they want to make a particular kind of Makefile. I could go on, but really, I don't see much actionable material in that post. Maybe I'm short-sighted. I'm just a random community member after all. I believe that GUI should be a medium priority for 2018. It seems to pop up like once a week on /r/rust alone. It's clearly in demand.
I'm not an expert, but I see no problem with `futures` and `tokio`, regarding selection.
No, I totally get it and this is more or less what I am trying to do now. There's still quite a bit of a learning gap for me to conquer before I feel like I will *readily* be useful to most organizations (sans walkthrough of code, etc). I asked this ? purely because I was seeing if there maybe was a particular IRC group, project looking for help, or (very unlikely) individual I could readily work with. 
I mean it makes sense so that multiple people don't waste their time trying to implement the same thing independently.
Yes, it does make more sense thinking about it that way, thanks.
One of the top posts in /r/rust right now talks about how great the experience was contributing to servo. It sounds kind of like what you're asking for, check out the article posted here: https://www.reddit.com/r/rust/comments/6tgfy1/my_experience_contributing_to_servo/
I just did this and I just discovered that within the Servo project, they have a [repo entirely dedicated to new entry level problems.](https://github.com/servo/servo-starters) I will definitely be checking this out later for something I can pick up.
Have you considered adding an `unstable` feature?
Andy Wingo has been working on a [new concurrency mechanism](https://wingolog.org/archives/2017/06/29/a-new-concurrent-ml) for Guile (GNU Scheme implementation), inspired by _*C*oncurrent *ML*_ ([whole blog series](https://wingolog.org/tags/concurrency)). He suggests, that _Go_-like _channels_ are actually not very good basic building blocks for concurrency and that _CML_-like _events_ are more suitable. Also, Aaron Turon, one of Rust authors worked on [Reagents](https://github.com/aturon/ChemistrySet), a generalization of CML 
`mio`, in essence, lets you wait on an unlimited number of different connections in the same thread. `std::net`, being blacking, limits you to either waiting on one connection per thread, or inefficiently switching between connections to poll rather than wait. `std::net` is fine for most everything, until you have a server that wants to accept 100+ connections at the same time. `mio` can then handle thousands or more.
See also: [Manticore](http://manticore.cs.uchicago.edu/), which I've always interpreted as the successor to CML.
Everyone here has said it, mio lets you do stuff 'asynchronously'. This doesn't really mean anything though, without some extra knowledge about how you'd do it with std::net. Obviously when you try and read a socket or something using synchronous io (i.e. std::net), the thread will block until you get a result. This may sound like you're fucked if you want to listen to 2 connections at once, but you're not - you can just spin up multiple threads. With synchronous I/O, you just spin up 1 thread per connection, and have each one wait on the socket to read some data. The problem comes when you have many, many threads. Normally, if you have multiple cores on your CPU (let's say you have a quad core machine), the OS can just assign each thread to a core and all is fine and dandy. However, when you have, say, 8 threads, what happens then? The OS needs to effectively assign 2 threads to 1 core. But if 1 core can only execute 1 instruction at once, how can it cope with this? The answer is something called 'context switching'. The thread essentially saves all of its state, and the core can execute another thread whilst the previous thread is still waiting on something. Sounds great, but with many many threads you start to get a really big overhead, and processing becomes less efficient. For the most efficient performance, what you want is a way to wait on ALL the sockets at once, then once one of them is available for reading, read it immediately. That way you can just spin up however many threads you have cores (i.e. 4 in this case), and have them all waiting on ALL the sockets. This is effectively what mio lets you do - you register a load of sockets with something called a 'poll', then you can wait on the poll. The poll WILL block the thread, but will unblock it as soon as 1 socket is ready for reading. When people say 'asynchronous', they actually mean more abstractions on top of this model. mio handles it in a very 'low level' way, meaning you basically code in a synchronous way, but you get this cool Poll object that lets you group stuff together. If you have a look at something like tokio, you'll start to see what people mean when they say 'async'. A key concept is 'futures', which are wrapper objects that are like a promise of a result. This way, you can define a function which returns a 'future&lt;String&gt;'. Even if the function blocks, it'll return immediately, and you have this `Future&lt;String&gt;` to move around. When you want to get the string out, you can choose to extract it by waiting for the computation to finish - because a future isn't actual data, just the promise that the data will eventually be there at some point in the future. With this abstract, you can do cool stuff like make loads of async requests to a database, like mysql, which all return results as futures. You can then do some processing on the CPU, and only when you need the data do you need to wait for the futures to finish. Useful for I/O bound applications.
I am working on an effort, but its nowhere near done. The way I do it is using a procedural macro to define a UI using a JSX like syntax. There's actually two DSLs I've come up with RSX (a JSX like UI description language, and another one that's for defining CSS like styles) It is a very experimental type thing which may never see the light of day, but its been great fun :). I have a two pass layout system inspired by WPF/XAML frameworks. [here's a screenshot](http://imgur.com/a/JTVhC) The style system needs work (explicit styles can override implicit styles, but property inheritance isn't there yet). Events aren't implemented yet (I'd like to figure out how to integrate the event loop with low level Tokio/futures bits). Oh, and it renders using WebRender which is really cool :-). I've got a few basic properties working (Some border styles, margins, padding, solid background/foreground) I post in the what-are-you-working-on-this-week threads every once in a while 
https://github.com/rust-lang/cargo/pull/4220
&gt; The reason people use Java, at least the Java devs I know, is so they don't have to use C/C++. It isn't that they don't care about performance, or other things. It isn't that they love Java, or Go, or Python, or Node - it's a matter of priorities. I would like to politely disagree with your point here. Many different popularity rankings have these languages at the top. If people were not enjoying using them, this would not be the case. &gt; It isn't that they don't care about performance I agree with the sentiment here, but again, performance isn't king for most of the web development world. I would argue that there are many things more important than performance for these companies and, the languages you cited, have performance characteristics that are good enough for them. In my opinion, Rust seems like the perfect language to write programs that would otherwise be written in C or C++, and taking any resources away from this goal seems like wasted effort. Let me program my Arduino in Rust and I will be a happier man.
My point is not "People hate Java" my point is "People really don't want to use C/C++ for web servers". And yeah, as I said, it's about priorities - performance is one of them, but not a huge one, which is why people choose other languages, not C/C++. That's why I commented on Rust's other attributes, like reasoning about code. That's one of many other attributes rust has over C/C++ that would appeal to server devs. As for wasted effort, I don't really agree. If it were the case that all effort towards servers were effort taken from non-server usage, maybe, but I think many people in many areas will benefit from the improvements to the language.
Most projects I have been involved in do not do this though, they only expect you to say anything once you have something concrete, presumably because they would rather risk duplicate work than features not being implemented because the guy who said he would do the job never got around to actually doing it. I understand how being chastised for doing what other projects want you to do can scare some people away. 
&gt; BTW why does `open` want to own the value? It doesn't. As per the docs, the signature for [`File::open`](https://doc.rust-lang.org/std/fs/struct.File.html#method.open) is: fn open&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;File&gt; As in, you can pass any type `P` so long as it can be turned into a `&amp;Path`, so you can pass `String`, `&amp;Path`, `&amp;str`, *etc.*.
&gt; My point is not "People hate Java" my point is "People really don't want to use C/C++ for web servers". Sorry for misrepresenting your point, I didn't mean to convey the "People hate Java" idea either. I should've made a more elaborate response. What I'm trying to say with the popularity rankings is that there are many people out there who actually love these languages, and they don't want to use C/C++/Rust, because they are already happy with what they got. The people who like Javascript but want a type system will use Typescript. This is the general idea behind my point, you can use any popular language as an example here (even C++ which started development because people wanted to write object oriented code in C). &gt; As for wasted effort, I don't really agree. Re-reading my post, I agree with you here. Wasted effort was a poor choice of words, what I should've said is that the resources are not optimally allocated in my opinion.
&gt; is far, far more of a niche than web servers. but it's a *C* niche, whilst writing web servers has many dedicated languages. Rust is presented by some as a language to eliminate C and C++.. if this is true, the C and C++ niches matter. I agree there would be higher priorities than a GCC backend though
Even for C, LLVM-unsupported targets are just not a common niche to be concerned about, outside of microcontrollers, but the microcontroller market has been overrun by ARM Cortex-M and Cortex-R over the last 5 years, basically from top to bottom. Cortex-M0 micros are dirt cheap. If you're using a non-ARM platform, it is *usually* because of legacy code that already works, in which case it doesn't matter if Rust is an option anyways. Another common case is where you're using the cheapest microcontrollers in existence as glue-logic, and in such cases you're writing like 20 lines of code total. There are much bigger fish to fry right now than a few obscure targets, even *just* in terms of C and C++ niches. Down the line, I would definitely love to see a GCC backend because it would provide more diversity to the Rust infrastructure and because GCC sometimes optimizes better than LLVM. The additional targets are way down the list.
Yep that's a good tip, I'm adding that to the post too, thanks.
Exactly. Pretty much all common command line applications (in linux/unix) use the exit status of 1 to indicate fail.
&gt; What I'm trying to say with the popularity rankings is that there are many people out there who actually love these languages, and they don't want to use C/C++/Rust, because they are already happy with what they got. Yet, [Rust *is* the *most* loved](https://www.reddit.com/r/rust/comments/60toqc/rust_was_voted_stack_overflows_most_loved/) language. I personally don't think these surveys matter that much. Certainly, people are passionate about Go and Python, but if Rust provided a similar webdev experience with measurably greater performance and noticeably improved protection from crashing, I think a lot of people would switch. Even so, async is about so much more than webdev. Any application that uses something slower than the processor has the *potential* to benefit from async. Even SSDs are unbelievably slow compared to the processor, not to mention hard drives, network sockets, or databases. Solid async support enables many things to be done more efficiently in Rust than they would be in a language without proper async support.
As a new comer to programming (6 months into my first dev job on a Rails app) how do you recommend tackling learning rust? Maybe even good enough to the point of taking some easier issues on servo.
Ya I literally cannot read it ;(
You honestly don't need to know a lot about Rust to work on Servo issues. You just need to know how to study a problem and spend some time to solve it. If you want to start learning Rust, the straightforward way is to read [the book](https://doc.rust-lang.org/book/). You'll also get a copy of the book, the Rustonomicon, and other nice stuff if you install [rustup](https://www.rustup.rs/) and go `rustup doc` in your terminal.
Everything looks pretty good! If I was writing a *serious enterprise Rust temperature converter* I'd probably do something like this: https://play.rust-lang.org/?gist=d3c1415430b3447bc67e5d6d21d73067&amp;version=stable
&gt; if Rust provided a similar webdev experience with measurably greater performance and noticeably improved protection from crashing, I think a lot of people would switch. The problem here is that it's hard to provide a similar development experience to Go, Python, Java, Javascript. Rust would be playing a hard game of catch-up against the vast numbers of Javascript libraries alone (and it would be a losing game against Go, as it's internally used by Google). Web development is a big area with established (or heavily sponsored) technologies. The Rust target audience there would be always a niche one, so why not focus on the places where people actively want change (C/C++). There are game developers out there that would love to use a language that fixes many of the C++ quirks, so much so that there is genuine excitement behind a game focused language that isn't even available yet. As it was pointed out by staticassert (sorry don't know how to link a user): &gt; The reason people use Java, at least the Java devs I know, is so they don't have to use C/C++. There are many C/C++ developers waiting for their chance to use a language that also offers performance like C++ does, but has more safety guarantees, features like `Option&lt;T&gt;` already baked into the language, and many more things which Rust offers.
Thankyou for taking the time to write out these feelings. I've written a response, from my perspective as a member of some of the Rust subteams, on the users forum: https://users.rust-lang.org/t/on-rust-goals-in-2018-and-beyond/12336/5?u=withoutboats
I don't have a lot of trouble believing folks at Mozilla agreeing to verifying your code contributions but this obviously would not be as "ironclad" per se as having a manager irl overseeing your work. Before throwing that idea out, I would recommend you just talking with the chair of your dept (or the prof if its just a class). Github itself would also provide the "documentation" of work. 
You need to read the code of a library to know if it is coded properly. You cannot assess the quality of a library without reading its source code. I wasn't doing that until very recently, but I learn to my expense that reading the source code of library is a necessity.
If you have to choose between two libraries, with equivalent features, why would you possibly even think about using the one with more dependencies? Having more dependencies means extra complexity by itself and more possibility of bugs, to use the terms you used.
Thank you for the great post. I just started my first project using Tokio and has not run any extensive tests yet. It is good to know what to look for in the tests. And I am yet to run my program in the release mode even once yet - totally a lesson learned from your post is to do it regularly now.
I'm just learning Rust recently. Is it also good to pick a "Good First PR"? Thanks.
Clearly, array indices should be `f64`. I mean, unless you're dealing with some pathologically huge array, precision is just never going to be an issue in practice. Then, you can make all arithmetic operate on `f64`, and you no longer have to worry about different numeric types at all! Choosing types to fit the data is just silly.
I mean, it worked for JS…
So, from what I've read, it looks like my choices may be using ImGUI, or Relm (which wraps gtk-rs)?
Whoa thanks. That really cleared up a lot of things. 
If libraries A and B provide the same thing, but library A depends on well-supported crates while library B reimplements the content of those crates, I would choose A.
&gt; you'd only need unsigned if its a char array filling over half of memory on a 32bit system.. it just does not come up in practice This ignores the case of running 32-bit code on a 64-bit system... potentially for greater space-efficiency. (After all, that's why the [x32 ABI](https://en.wikipedia.org/wiki/X32_ABI) gained enough interest to be implemented.) That said, I do agree that it's likely to be very uncommon since, as mentioned, you'd basically need to be working with multiple gigabytes in a single byte-indexed blob of memory.
**X32 ABI** The x32 ABI is an application binary interface (ABI) and one of the interfaces of the Linux kernel. It allows programs to take advantage of the benefits of x86-64 instruction set (larger number of CPU registers, better floating-point performance, faster position-independent code, shared libraries, function parameters passed via registers, faster syscall instruction) while using 32-bit pointers and thus avoiding the overhead of 64-bit pointers. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
It's worth noting that, to a degree, [the hardware folks agree](https://github.com/riscv/riscv-gnu-toolchain/issues/102). In that ticket, the people responsible for the RISC-V ISA say, pretty clearly, that the preferred array index types are: - `size_t`, which on RISC-V is the same as `uintptr_t`, aka `usize` - Signed integers (in that order)
I have nothing to add, I just want to say that I'm incredibly impressed with this concept and I can't wait to see it completed!
I've tried playing with QML in Rust ([crate](https://github.com/White-Oak/qml-rust)). I've found it to be a constant uphill battle, so I wouldn't recommend it unless you've used QML in the past. I have nothing to add. I'm just saying that you should avoid QML with Rust for the time being.
Heading into week 3 of [my Gameboy emulator](https://github.com/simon-whitehead/chemboy) (Please note: Its very rough in parts while I learn how to make it work. I'll clean it up as my understanding of Gameboy programming becomes better). Implementing opcode after opcode. Last week I got sprites rendering correctly (after many attempts) and also Joypad emulation started working last night. This means [I can render the Tetris main menu, and move the menu selector between the menu items](https://media.giphy.com/media/3o6vXIVIKAlrt2CGfC/giphy.gif). Once I got the Joypad working I added `Start` button support and pressing `Start` on the main menu [results in this screen being rendered](http://imgur.com/gwMq3AQ) before crashing very shortly thereafter with an `Unknown opcode` error. So I'm making lots of progress!
See other reply
Rust democratizes systems programming. Where before only ~~long-bearded fake-turtleneck-wearing~~ half gods could (on a good day) write low level code with any chance of surviving the first attack, now even ordinary folks can churn out code that, while perhaps not as fast as the fabled hand-optimized C/assembly combo, is consistently fast *and* safe enough to be put in harm's way. So not only do we get the C/C++ programmers (who like the lack of headaches), but also a whole lot of people formerly writing Python, Ruby or ECMAScript (vulgo JavaScript), as last year's Rust Survey showed. Those people *care* about web programming, so it's natural to have a look how we can help them be even more productive. After all, expanding a new niche once you get a foothold is a proven business strategy. Now we get this rant I'd like to paraphrase as 'please think about the C programmers already, caring about what the script kiddies want is going in the wrong direction!' – it strikes me as more of the same exclusionary [insert random swearword here] we've seen from systems folks over the years. So, yes, we should invest in a stable SIMD subset, in better performance, more targets (though this is largely done by LLVM) etc. All Rustaceans will benefit. But let's not stop innovating in the new niches we find. 
You cannot detect this automatically. You might be able to detect when this happens by mistake (e.g. Using Miri on the tests), but I am not talking about unsoundness by mistake. I am talking about unsoundness on purpose.
if you use a windows 10 theme gtk actually looks pretty decent on windows, and it's nice to work with. I haven't been able to test on Mac though, it's been a huge hassle trying to set up a VM to do builds on. At the bottom of [this](http://gtk-rs.org/tuto/cross) tutorial you can see how to set the theme.
I have a very "QWidget APIs come hell or high water" approach to ensuring my creations fit into my desktop, so my approach for Rust+GUI so far has been to split my applications into a backend written in Rust, a frontend written in Python using PyQt, and then connect them using rust-cpython. Whether that would make sense for you will depend on how well your use lends itself to being split up like that. (eg. a little utility that's mostly GUI would probably be best done fully in the frontend language, while something like my heuristic "generate launchers by walking the filesystem" code is both something other applications may want to reuse and something that can benefit significantly from a stronger type system.)
I would suggest to just jump into the cold water and put it in a public git repo. No need to release it on crates.io. I know that feeling that you consider to release it into the public but it needs to be in a better state - either cleaned up code or more features etc. And especially you don't want other people to question your decisions at least in the "early" stages because you have a rough vision that you want to at least have a rough prototype of. At least this is how I feel about it for that matter. But I have been proven wrong multiple times that I consider this behavior wrong for myself. The input I got from the point on I released something was extremely helpful and it helped to overcome certain obstacles. It's also a great motivational boost and if you're lucky some one joins in full with great ideas which can skyrocket the project tremendously. We want to protect our pet projects from the bad outside world but it needs to stand on its own feet and we realize the outside world isn't that bad ;) Never the less, it sounds very cool and most parts (like webrender) sound like a way many people want to go but I haven't seen too many projects using it. I wish the best for your project however the outcome is. At least you learned something on that journey! 
I am a newbie in rust too and am looking for projects to continue learning. Let me know if you come across something. :D
Do you have an open repository? I'd like to peruse your code, seems like a cool project.
&gt;Now we get this rant I'd like to paraphrase as 'please think about the C programmers already, caring about what the script kiddies want is going in the wrong direction!' – it strikes me as more of the same exclusionary [insert random swearword here] we've seen from systems folks over the years. &gt; I don't believe the author meant to be exclusionary, only to voice a concern. I also don't see why you had to call system folks "long beards with fake turtlenecks", the only thing it does is alienate​ people who come from a system level programming background. It feels like a setup of a "us vs them" scenario, which is toxic. EDIT: At the same time, I do agree with you on most points. I believe most of these concerns can be solved by simply exercising patience. Rust is young! Thank you for your hard work!
If you're going to cross-post, you should [link to the StackOverflow question](https://stackoverflow.com/questions/45668153/when-does-a-broken-pipe-occurs-in-a-tcp-stream).
Yeah, I thought about it, but then I thougt many may not click on the link just because they have to leave reddit. I will add the link though.
There's a sidebar on the right if you're on desktop reddit with good links for learning resources -&gt;. I recommend doing some rust learning exercises. Then build a small project. Then build a little bit bigger project something involving networking and strings, maybe threads. If you learn about Rust you'll learn about strong types, ownership, and low level coding. A higher level language like Ruby let's you do all kinds of fancy things that require more thought in a language like Rust. It's a great thing to do become a better programmer. Rust also has fancy features fwiw, but it's a lower level language. Lower level basically means that the language isn't going to do a lot of magical stuff for you the way a language like ruby does. Magical stuff includes automatic type conversion, easy mutability, and generally not having to worry about a lot of stuff as you code. Rust's compiler though helps you out with coming to grips with the difference with really great error messages. You'll feel pretty good once you figure out how all that stuff works. It will make you a better programmer. 
It's more about making sure that if the question is answered on StackOverflow, and someone who is having the same issue finds *this* post, they can follow the link to the answer. You don't want to inadvertently [979](https://xkcd.com/979/) someone.
To add to your example, many threads is not a problem, in fact, you may get away with up to 128 or more threads (if they do nothing but wait), it's just not as efficient.
Right. Those are awful. 
I'm getting errors like this without the `clone`: error[E0382]: use of moved value: `path` --&gt; src/main.rs:61:85 | 51 | let file = fs::File::open(path).unwrap(); | ---- value moved here ... 61 | datetime.month, path | ^^^^ value used here after move | = note: move occurs because `path` has type `std::path::PathBuf`, which does not implement the `Copy` trait 
Right, because that's transferring ownership; just pass a borrow: `&amp;path`. If that doesn't work due to generic type inference, try `&amp;path as &amp;Path`.
You're parsing input, it could be written in VBA and it would still be more than efficient enough. Unless you've used a reflection based language, you're way too paranoid about methods. 
Precisely. Especially for a CLI, dispatching commands is not something that needs to be optimized. The person doesn't notice the difference between microseconds and nanoseconds.
Depends on the library. If it's something small and unknown, sure. If it's something proven there should be no need. I doubt you've read all the source code of all software you're running as well. 
deleted ^^^^^^^^^^^^^^^^0.8919 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/63983)
Whilst I also don't think that 'Rust for servers has been a mistake' necessarily, I do think the author is exactly on point with: &gt; For this web/http-dev audience that doesn’t care that much about performance Rust is not better than the languages they are already using, so why would they use it? Even though they might like Rust, they do not need it. This describes me perfectly - I write http services with Python and Go and the things I really value are the ease and speed of development and the fact that there are lots of other Python and Go developers out there I could delegate to. Performance doesn't matter at all since I am not really limited by the number of machines running the code - I can just add more servers to improve performance. Therefore I'm in a position where I would like to write Rust - I often feel very frustrated with the restrictions of Go - but I know that it would take me longer and risk isolating my code from the mainstream development community if I did, with no appreciable benefit. So I agree with the sentiment that Rust for servers is not really a compelling primary use case for Rust, and so the focus should be on what the author talks about. 
Awesome work! Swift's a really impressive piece of software engineering. Hope that the writing is going well for you :)
For a certain value of "worked".
the issue is array indices resulting from calculations, or vica versa needing to do calculations from array indices. thats also a huge straw-man. I'd never suggest using floats for indices because of the huge problems moving between pipelines.
&gt; This ignores the case of running 32-bit code on a 64-bit system... potentially for greater space-efficiency. (After all, that's why the x32 ABI gained enough interest to be implemented.) it doesn't they do say, in the 32bit address space case, its still only an issue if you have a single char array filling over half the address space, which almost never happens. nonetheless my preference is a **parameterized index**, so you can also have 32bit array indices on 64bit systems (to save memory), or go the other way and have **typesafe indices** (e.g. distinguishing a VertexIndex from an EdgeIndex, etc) almost always, my array indices have well known upper ballpark size limits, and ditto on a 16mb machine you know a 32bit index of 16byte objects can fill the whole machine.
For me, outside of the core feature of memory and concurrency safety, rust just gets so many things *right*: - Catching all sorts of things at compile time - Algebraic data types/pattern matching - Cargo and base tooling - Rustc's error messages - `Mutex&lt;T&gt;` locks data rather than relying on the programmer to keep track of what data is locked - Refcounting exists, but is opt-in and discouraged - Macros done right - Procedural macros - Very good type inference - Painless threading - Fast closures - Iterator and other functional patterns, generally without sacrificing speed - `Option` instead of nullable pointers - Error handling in general - Good library design - Well designed and easy generics - Traits - Integer types distinguish clearly between architecture dependent integers (for pointer offsets), and integers with specific size - No automatic type coercions (except for `Deref`) - `Deref` - Best operator overloading system I have ever seen - `fn x(a: i32) -&gt; 32` instead of `i32 x(i32 a)` (it's a small change but I like it *way* better) - Good module system - Embedding macros and generics in the compiled library files - The rust community One idea might be to write a program and then compare it with an equivalent C++ program and point out where the rust version gets things better than the C++ version, and where it doesn't (because Rust isn't perfect and if you don't mention these situations, it comes off badly).
deleted ^^^^^^^^^^^^^^^^0.7139 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/25155)
deleted ^^^^^^^^^^^^^^^^0.7787 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/18774)
Rust 2018 - Proper cross platform GUI lib. No GTK wrapper, no Qt magic, just Rust and a true Rust-y API. There are however, three points of concern about this: - Can we put a nice, performant API on top of OS-native ones, e.g. WinAPI, Wayland, X Windows,...? I feel like we could do this with Wayland, but especially X Windows is an ancient beast breaking apart by the slightest mention of multi threading. - Or would we rather only rely on OS-native APIs for creating an OpenGL/Vulkan canvas and handling input events and do UI rendering with buttons etc. ourselves using GL/Vulkan? If yes, then we will need someone who'll make this DIY GUI library look pretty by default. - Will we do a frontend/backend approach? I.e. will we have the GUI library being split in two halves, one for the API and one for actual "rendering"? Think about that single-header C GUI library called [Nuklear](https://github.com/vurtun/nuklear). This would propably be the best approach, having a frontend library people actually use, and a backend library to forward all the things we do to WinAPI, Wayland, a GLFW context, etc., and propably even things like GTK-rs. I feel that this is missing most right now, and Reddit seems to agree with all the occasional posts about Rust+GUI.
Be ready to spend a huge amount of time on it, frankly. I'm not sure I would've been able to understand important fundamentals of Rust 6 months into my career.
If I could get it to build on Windows, at all, ever, I might try to contribute to it.
&gt; What happens if company X delivers the killer microcontroller CPU next year, but you have to use their custom version of GCC to target it for the next 2-3 years? Good thing the Mill CPU will come with an LLVM-based tool chain. :) But back to your point: What you want then is an LLVM-backend producing GIMPLE *(GCC IR)*. There was an LLVM backend generating C code, but IIRC it got thrown away because C simply cannot represent all the things the LLVM IR does. Work on it, merge it into the LLVM code base, and Rust will automagically be able to do what you want it to do.
At the moment, just simple maths, plus constructing and deconstructing datatypes. You can't do anything like loops or iteration or use unsafe code. [`miri`](https://github.com/solson/miri) will increase the set of possible instructions.
Out of curiosity, I decided to make a level with Python-level construction conveniences. The code is nowhere near as pretty as Python (as Rust favors explicitness), but it works. If it's fine to explicitly write `tree(value, None, None)` it's possible to use `Into` trait instead of creating a new one, as it allows for conversion of `T` into `Option&lt;T&gt;`. pub type TreeNode&lt;T&gt; = Option&lt;Box&lt;Tree&lt;T&gt;&gt;&gt;; #[derive(Debug, Default, Clone, PartialEq, Eq, Hash)] pub struct Tree&lt;T&gt; { pub value: T, pub left: TreeNode&lt;T&gt;, pub right: TreeNode&lt;T&gt;, } impl&lt;T&gt; Tree&lt;T&gt; { #[inline] pub fn new&lt;U: IntoNode&lt;T&gt;, V: IntoNode&lt;T&gt;&gt;(value: T, left: U, right: V) -&gt; Self { Tree { value: value, left: left.into_node(), right: right.into_node(), } } } pub trait IntoNode&lt;T&gt; { fn into_node(self) -&gt; TreeNode&lt;T&gt;; } impl&lt;T&gt; IntoNode&lt;T&gt; for T { #[inline] fn into_node(self) -&gt; TreeNode&lt;T&gt; { Tree::new(self, None, None).into_node() } } impl&lt;T&gt; IntoNode&lt;T&gt; for Tree&lt;T&gt; { #[inline] fn into_node(self) -&gt; TreeNode&lt;T&gt; { Some(Box::new(self)) } } impl&lt;T&gt; IntoNode&lt;T&gt; for Option&lt;T&gt; { #[inline] fn into_node(self) -&gt; TreeNode&lt;T&gt; { self.and_then(IntoNode::into_node) } } // Cannot directly assign `Tree::new` as `tree` due to lack of // support for higher-kinded types fn tree&lt;T, U: IntoNode&lt;T&gt;, V: IntoNode&lt;T&gt;&gt;(value: T, left: U, right: V) -&gt; Tree&lt;T&gt; { Tree::new(value, left, right) } fn main() { let t = tree(15, tree(12, None, 13), tree(22, 18, 100)); println!("{:#?}", t); } 
I think the point is that the exclusion is happening in reverse: the places where C and C++ are used are where Rust can already Excel with just a little help, but the focus within the community seems to be on promoting uses of Rust for async webdev. I think this feeling can certainly be justified given the slow movement on some key features like const fns, ATCs, type level integers, etc. All of these features would make basic C++ kind of programming much cleaner today, but progress has been (perhaps understandably) slow.
I believe we have a big problem showing people 'unwrap' before showing the IMO better alternative. When i just want to quickly write code to test stuff , ill go fn somefn(args) -&gt; Result&lt;SomeType,Box&lt;Error&gt;&gt; // Error is a trait { let tmp : Option&lt;SomeType&gt; = sometest(); tmp.ok_or("Missing returnvalue from sometest()")?; // Error impl From&lt;str&gt; ( i think ) etc... } 
Yeah of course, that's what they're there for.
I suppose you've already seen this, but just in case: https://github.com/servo/servo#on-windows-msvc
I always love debugging war stories. I did notice a problem with the site's CSS, though: according to Firefox's debug tools, the CSS for the screenshot sections says: font-family: 'Hack', monospaced; I suspect that second item is supposed to be `monospace` (without the "d"), the CSS keyword for "whatever the user's favourite monospace font is". Since I don't have a font called "Hack" installed, nor a font called "monospaced", I was getting proportionally-spaced text until I used the debug tools to fix the CSS.
well, yeah. I didn't wing it.
I had a similar problem, maybe it will help you. Drop the enum&amp;state and instantly create and store a [Shared future](https://docs.rs/futures/0.1.14/futures/future/struct.Shared.html). And then simply don't poll/use it. The first time you actually compose the future and it gets run in your event loop is also the first time the underlying future is polled / executed. Then the next time you use the future it will just use the previous state. 
I don't understand the problem. From what i gather , their complains are originating from a lack of strict typing. Something which rust doesn't really suffer. From a logical/mathematical perspective i believe the use of types should be a close fit to its use. When i tell you i have a list of items , i don't want you to be able to ask me whats on entry -9. From a syntax perspective you could (ab)use negative indexing to quickly access stuff from on the end ( but i would rather you make a call to some function that takes an signed value ) 
Aren't winit and gfx-rs a good start to build stuff on? Abstracting the window management and drawing away is essential for a cross platform toolkit.
Maybe you could try searching for windows build related issues, maybe you'll find something: https://github.com/servo/servo/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20label%3AP-windows
While we're talking about implementing interactive CLI interfaces, any recommendations? I have a few ideas, but would like to know if there's already some prior work.
In my 7 year career writing embedded aerospace code, I think perhaps one of the microcontrollers I used is now supported by LLVM. There are targets out there which suit low power, I/O, cost, SEU, radiation resistance requirements which take priority over "which is best to program for". Maybe I'm just being touchy about my work being considered an uncommon niche.
Perhaps you should have posted this on /r/playrust/?
You are looking for /r/playrust , this is the subreddit for the rust programming language.
I am kinda digging what you've got going on here. Any chance the library is out there if someone else wanted to hack on it? 
Very nice! Note that you can even get rid of the (inner) explicit calls of the `tree` function by implementing `IntoNode` for triples: impl&lt;T, L: IntoNode&lt;T&gt;, R: IntoNode&lt;T&gt;&gt; IntoNode&lt;T&gt; for (T,L,R) { #[inline] fn into_node(self) -&gt; TreeNode&lt;T&gt; { tree(self.0, self.1, self.2).into_node() } } Now you can construct a tree as follows: `let t = tree(15, (12, None, 13), (22, 18, 100));`
Likewise on desktop Safari, but "reader mode" seems to work, for what that's worth.
It works quite differently in Swift and Rust though: in Swift, it's specialised for Option types but you can have multiple "matches" and further filters. In Rust, it's a general refutable pattern-matching structure but only allows a single pattern (per branch). So this Swift: if let foo = bar, let baz = qux where baz &lt; 3 { corresponds to this Rust: if let Some(foo) = bar { if let Some(baz) = qux { if baz &lt; 3 {
Would NLL solve this?
A proper cross platform GUI library, written in scratch in Rust from the ground up that competes well with other GUI libraries, would take several years to build. Being realistic, it's probably better to start with solid bindings to an existing GUI library. &gt; but especially X Windows is an ancient beast breaking apart by the slightest mention of multi threading Not sure what you mean by this, but I've written an X11 client that has no problem with multithreading. All X11 requires is a socket.
This seems like the wrong way to go about offering this functionality. I think it would be better if it didn't exist rather than existing as it does now
This is just silly. Indices should be `String` so that the programmer can use the representation most appropriate for their application.
&gt; Not sure what you mean by this, but I've written an X11 client that has no problem with multithreading. All X11 requires is a socket. Unfortunately you can't use OpenGL or Vulkan to draw on top of it unless you use the official Xlib library. 
Ah, I see. Last time I looked into that (many years ago), there was a recursive dependency. Is that still true and is that still the issue?
Agreed. Rust targets systems programming and my company can't really consider Rust atm because of the limited processor support. I was dreaming of a C transpiler last night. &gt; Ideally, we would be able to transpile MIR to C, but this is thought to be a tougher problem to solve than actually implementing a GCC backend. What would be the challenges with a C transpiler?
Note that [the OP said they don't want dependencies for their own project](https://www.reddit.com/r/rust/comments/6tdnia/article_how_i_want_my_command_inputs_but_nobody/dlk6vbu/). So it's not about structopt with more dependencies vs gumdrop with less dependencies - it's about adding another dependency to the OP's project vs the OP implementing it's functionality by itself. Now, to answer your question: assuming I use a package manager(like, say, Cargo) I don't see why I should be alarmed by the number of dependencies my dependencies use. Any problem created by adding dependencies is already encapsulated by qualities of the library that I should already care about: * Dependencies can increase compilation time? I'm already taking the library's compilation time as a whole into account. Why should I care if the compilation time of that functionality is because of the extra code in the library or because of it's dependency? * Dependencies can have bugs? But the library I add can also have bugs! The same potential bugs that can happen in the dependency can also happen in the extra code that library would have to add if they implemented that functionality themselves. * More code to read(do people actually read the source of every piece of software they use? Was the Linux kernel a good read?) - without the dependency, that extra code will be in the library itself. And, few more considerations not yet mentioned: * Dependency may be platform-specific? So does the library. The supported platforms of the dependencies should already be taken into account when the library author announces the platforms it supports. * Dependency may have breaking changes? So does the library! In matter of fact, if the dependency has breaking changes, it's the library's author's problem to make amends to their library, not yours. Generally, problems arise from the amount of code, not the amount of libraries it's split into. Splitting the same codebase to multiple libraries that depend on each other actually reduces these problems, because it's easier to think in smaller modules. Breaking your code to smaller, separately-compiled modules also improves build time - whether it's split into different libraries or just different modules in the same library. Also, having your libraries use dependencies has other benefits: * The dependency's scope is usually more common - which can mean a larger userbase. For example, [rustfft](https://crates.io/crates/rustfft) has 5,469 downloads, while it's dependency, [num-complex](https://crates.io/crates/num-complex), has 656,495. Because FFT may be common - but complex numbers are even more common. This larger userbase has implication on the development - num-complex has 135 issues and 192 pull requests, while rustfft only has 11 issues and 15 pull requests. This differences does not mean num-complex is buggier - the larger userbase means that more bugs are **discovered**. If rustfft would have rolled their own complex numbers types and functions, they could have been prune to the same bugs - but their smaller number of users would mean less bugs would be discovered. By using num-complex they take advantage on more than half a million users that can open tickets on bugs in complex numbers code. * Dependencies can be shared. For example, if you need both FFT and linear algebra, [nalgebra](https://crates.io/crates/nalgebra) also depends on num-complex - so it can share complex numbers code with rustfft. If each of them rolled their own complex numbers implementation, each of these implementation would have increased the compile time separately, had it's own bugs, and worst of all - their API will be using different complex number types. This means that you'd have to read two separate documentations, take extra care to use the right complex type in different places in your code, and if you want to pass complex numbers from rustfft to nalgebra or visa versa - you'd have to write conversion code. So... all else being equal, I'd take the library with more dependencies. More dependencies is only bad if you need to manually follow the instructions and install each dependency. We have progressed way behind this point - certainly in Rust, with Cargo at our disposal.
Yes, semantics was adapted for Rust, but that's where syntax came from. As [RFC 160](https://github.com/rust-lang/rfcs/pull/160) itself states, "it is based on the precedent set by Swift".
A "proper cross platform GUI lib" will take years to write and years to polish. Look at QtWidgets, which is 12 years old (starting from Qt 4.0), - they still have a lot of bugs.
&gt; that's where syntax came from At no point do I deny that.
I'm not sure what you mean by "recursive dependency". OpenGL and Vulkan work by dlopen'ing a dynamic library provided by the graphics card manufacturer (which you can't control), and then passing a pointer to an object that was created by xlib (or libwayland, or xcb). The dynamic library you load is also linked itself to xlib/libwayland/xcb and will use these libraries' API with the object you provided. That's unfortunately how it was designed, and I don't see how we could properly introduce Rust in it. There are probably good reasons for this design, but I don't know enough about the linux graphics stack to know which. 
&gt;If you are writing modern generic heavy C++ code using a Rust library of any quality feels like using an antiquated C library. It does. But what the alternatives? C ABI is universal and a lot of languages support it. There are no reasons to create a new ABI just for Rust&lt;-&gt;C++ inter-portability. It's too niche. &gt;C++ interfaces perfectly with native GUIs in all platforms, and on top of that it has Qt. While I'm a Qt fan - it's not true. Qt is far from perfect and there constant runts about it. And C++ doesn't really helps here. winapi is C, cocoa - Obj-C, X11/Wayland - C. &gt;cargo should be able to easily spit Makefiles It's just ridiculous. We no need yet another cmake/qmake/etc. This is build.rs tasks.
Nice! I faced similar problems using binary tree for Huffman algorithm: https://www.reddit.com/r/rust/comments/6j0vls/my_attempt_to_implement_huffman_coding_using_rust/
Still a lot of enjoying the summer. A tiny bit of work on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) to convert from supporting just `f32`/`f64` as the underlying storage type to using the `num` crate. Changes in the [`dev-num`](https://github.com/iliekturtles/uom/tree/dev-num) branch.
**Edit**: I was wrong. Please ignore my answer. :) Thanks for the hint sanxiyn. If I understand your question correctly, you are asking if non-lexical lifetimes would make the implementation easier. Since Box&lt;&gt; and Rc&lt;&gt; are not affected (they are heap-allocated), probably you mean lifetime parameters for the borrows. So instead of ``` struct Tree&lt;'a&gt; { root: i64, left: &amp;'a Tree&lt;'a&gt;, right: &amp;'a Tree&lt;'a&gt;, }``` it would be this? ``` struct Tree { root: i64, left: &amp;Tree, right: &amp;Tree, } ``` Don't think so. The RFC mentions this case at the very end (https://github.com/nikomatsakis/nll-rfc/blob/master/0000-nonlexical-lifetimes.md#appendix-what-this-proposal-will-not-fix): &gt; Self-referential structs. The final limitation we are not fixing yet is the inability to have "self-referential structs". That is, you cannot have a struct that stores, within itself, an arena and pointers into that arena, and then move that struct around. This comes up in a number of settings. There are various workarounds: sometimes you can use a vector with indices, for example, or the owning_ref crate. The latter, when combined with associated type constructors, might be an adequate solution for some uses cases, actually (it's basically a way of modeling "existential lifetimes" in library code). For the case of futures especially, the ?Move RFC proposes another lightweight and interesting approach. 
No time to watch the video, but for example `if (pos-1 &lt; start)` doesn't work for unsigned integers, in the case that start or pos is 0. So a whole bunch of gotchas waiting there for the unwary. Not sure if this is what they're talking about though.
&gt; The select! macro is sort of defacto deprecated nowadays in the sense that “selection over a number of events” is best done with the futures crate outside the standard library. That's kind of... :/
&gt; When i tell you i have a list of items , i don't want you to be able to ask me whats on entry -9. the issue is generating computed indices.. sliding windows, neighbours .. intermediate lookup tables; and computing other things from the indices. as such I've always found it far more useful to use a signed type, and have never in 30 years needed &gt;2billion chars :) any large problem tends to be divided up. 
our of curiosity, how much effort would it be to do LLVM-IR -&gt; C89 ; and would that be a viable way to bypass this problem (kill N birds with one stone, if there are other uses for that)
May I suggest the [`ncdu` tool](https://dev.yorhel.nl/ncdu/scr) to you?
 they're conflating *uncommon* with *unimportant*. 
I think GUI is problematic because GUIs are usually heavily tied to languages, https://users.rust-lang.org/t/current-state-of-gui-development-in-rust/11643/7?u=dobkeratops 
^^^^ THIS &gt; want to pursue a job in systems programming they then have then to jump into C++ because the industry doesn't see Rust fit for their niche. it is wildly unrealistic to expect to replace C++; Apple are handling their transition well: their *frameworks* are inter-operable between legacy Objective-C and Swift.. swift is built to run those. You can mix swift and objC in the same application, using the same interfaces. I definitely like the way that Rust handles vtables but there still might be a case for supporting some of the C++ embedded-vtable use-case for better interop, in the name of widening the language's reach (e.g. writing plugins for C++ applications, or vica versa) &gt; not a single C++ developer is satisfied with C++. agree, thats why i'm so frustrated here after such a promising start to find so many decisions that seem to consider the C++ niches as less important. Rust is absolutely suitable to build on , it would only take a few tweaks to make it better in every use-case.
&gt; There are no reasons to create a new ABI just for Rust&lt;-&gt;C++ inter-portability. It's too niche. One small suggestion I have is to enable a C ABI export of simple member-functions e.g. imagine extending C++ and rust to handle this class Foo { extern "C" void bar(...) }, struct Foo {} impl Foo { extern "C" fn bar(&amp;self){..} } ... both generating a simplified name mangle approximating the common prefixing naming convention of OOP-y C libraries .. Foo_bar(Foo*). and even if embedded vtables are inferior, it might be nice to have a clean way to represent a subset of C++ embedded vtable classes (for interop) &gt; winapi is C .. i dont think people build windows guis in C though, they'd be using C++, C# with more elaborate interfaces
LLVM used to have a C backend, but they removed it, because even though people imagine that C can fully represent any set of instructions... it can't. It's an extremely difficult problem to solve for something more powerful than C like LLVM-IR. A language like Nim which is designed around the limitations of C is one thing, but it's a common misconception to think that any program can be successfully compiled to C. An *easy* example (which doesn't yet apply to Rust, but seems to be in the plan) is tail-call optimization. C doesn't guarantee tail-call optimization, so reliably compiling Haskell to C is *difficult*, or eventually Rust to C, just based on this one feature alone. It is *possible* to convert TCO to a simple iterative loop in the C output. C also has *tons* of undefined behavior which makes it really hard for auto-generated C code to behave predictably. One example of how this applies directly to Rust is with Checked Arithmetic. It is not possible to efficiently implement Checked Arithmetic directly in C. At the level of machine-code, overflow typically just sets a flag in a register that you can branch on after the operation is complete. In C, you have to attempt to *anticipate* the overflow, which requires doing additional math in advance of the actual calculation, and branching there, rather than just doing the calculation like normal. A C backend would be one giant hack -- as emphasized by its removal from LLVM -- but it would certainly be interesting to see it attempted.
&gt;the places where C and C++ are used are where Rust can already Excel I'm not sure thats true, I'm not finding rust a win yet; low level code is more pleasant to write in C++
it's got precedent in swift; i think if in doubt , given that syntax choices have many POVs, the path of minimum resistance is to go for familiarity.. swift already has a large user base due to iOS/the mac platform
The only problem is that `usize + isize` isn't implemented; and even that, eh... Complaining about these limitations is right up my alley, but in this case, Rust is saying that when computing indices, you should start from a base and only go in one direction. *I don't think that's wrong*, necessarily. The vast majority of base+offset operations don't expect a negative offset, and this could even possibly be a security vulnerability. *Because of this security aspect, composing subslice operations may be the right way to go.* If there's a case where you really do need `usize + isize`, define a function `offset`. 
I read the source code of libraries that were not small and unknown and I've been disappointed by some of them. For instance, this [performance issue](https://github.com/ctz/rustls/pull/85) in rustls was discovered by reading its source code.
&gt; and this could even possibly be a security vulnerability the safe path uses bounds checking anyway , so I think this doesn't matter. &gt; If there's a case where you really do need usize + isize, define a function offset. this is where I find myself wanting to give up on Rust .. the bloat in vocabulary to do simple things, compared to composing basic operators (I like the concept of unsafe blocks, but not the extra bloat within them because the syntax space is taken up by safe.. i wonder if it would be possible to 'use' on operators to switch what style is easier to read and write in specific modules..)
Do you think a large percentage of engineers around the world who deal with software are working on software for embedded aerospace electronics? Never mind whether software developers in general are working on software for embedded aerospace electronics... full-blown engineers. It's not a bad thing to be in an uncommon niche. In that case, it's actually a really cool one to be in! But, the point still stands. It's not a scenario many people find themselves in. With limited development resources, should Rust prioritize that over the other, more common problems at hand? Just out of curiosity, what microcontroller architectures do you deal with? ST's RPC5 microcontrollers? Those are POWER-based, and I'm having trouble finding out whether LLVM supports the "POWER Book E" instruction set that RPC5 uses. LLVM does support *some* POWER stuff.
`if !(start &lt;= pos)` is the standard way I'd phrase it because `start &lt;= index` and `index &lt; end` are the standard bounding checks. Everything else looks weird and makes me think too hard.
There are already some tools for this, like `cbindgen`. But after some point of complexity it's easier to write C++ wrapper around C-API manually. &gt;they'd be using C++, C# with more elaborate interfaces I'm talking about Qt and other crossplatform GUI libraries. They can't use C#.
In rust, would signed indices incur an additional bounds check? edit: I guess the compiler would just treat it as unsigned for the purposes of the bounds check.
You can always use alternatives like QML, HTML, etc, which are backend agnostic (QML not there yet, but it's possible). There is also PyQt, which works fine.
I never said *unimportant*. Are you saying that embedded aerospace electronics should be the highest priority of Rust? The Rust development team has *very* limited resources. Prioritizing *this* would mean other things not getting done. Something can still be important while other things are *more* important. Safety-critical industries like embedded aerospace are *highly unlikely* to adopt Rust in the near future, even if it were an option, due to being highly regulated. So, it would be an interesting allocation of resources. It is absolutely an *uncommon* requirement, and while it is important, realistically it would be a fruitless effort to try to support it unless someone has a lot of political capital they're willing to expend with the FAA and the aerospace industry to make them consider Rust a viable option. Regardless, I'm sure that one day all of these platforms will be supported by Rust, as long as Rust continues its slow, steady advance.
I tried Conrod, not enough widgets. I tried GTK, too cumbersome, I tried Relm, promising, but heavily WIP ~~and need nightly~~ I tried Imgui, didn't like the logic (stacking parameters to change a widget size was not logic to me, and before any troll begins, it's only my opinion ;) ) I ended using pancurses as my app is really lightweight. From all this, my conclusion is that there is a lot to be done in the GUI domain for Rust. Your best take is maybe Rust for all the logic in a lib and some other language for the GUI (C/C++/C#/whatever)
What's the best way to pass trait objects around? Is taking ownership possible? Is it okay if I use Box (or other smart pointers) excessively for that purpose? I'm using trait objects a lot for abstraction but it is both annoying and hard to define lifetimes for everything. And I have the suspicion it's not even possible for what I want to do (a list/vec of pointers that constantly changes).
&gt; Rust can already Excel with just a little help Oh, if Rust can Excel, then it can take over the entire financial industry straight away.
I'm basically still learning Rust. It's starting to sink in. I'm writing a simple, YAML configurable HTTP proxy using Iron/Hyper as a learning exercise. I can use the configuration to generate a handler for path-based routing although all it does is print the URL it's routing to at the moment.
`Box&lt;Trait&gt;` is the normal way of taking ownership of a trait object, yes. I'd consider it perfectly okay to use them. Do you mind elaborating on the abstractions being built? There might be a better solution than using trait objects.
I don't yet since its so incomplete and my only target right now is to get Tetris running. Literally no other games are on the radar for the moment so most people trying it out would have no success. Its in a private GitHub repository though so I could just open it up. If people are interested in watching it as it progresses I could open it up I guess - bearing in mind how rough some of it is :)
I'm messing around with how a gui lib could be structured (I have not yet written more than snippets to see what would work). I want to abstract Widgets and Events away with traits, but I obviously need to pass them around, too. I've seen the approach with enums for events used in Conrod and others, but the cool thing I have in mind is that it should be possible to define own Events and Widgets that are first class. I couldn't really find a way to use enums for events, since the user can't add new ones easily. Then my approach is to downcast events to see if they're appropriate. I know this screams horrible design but honestly it's better than the alternatives I thought of. It's mostly a learning and software design (with rust) experiment and I already learned a lot about Rust by just trying out what works and by thinking about the design.
&gt; printing out a bit of debug information stops the race condition from happening This is 100% real. I've recently run into something very similar with LLVM. In my wrapper, when I'd create a certain object, `cargo test` would return `Ok(_)` when it should have been an `Err(_)`. `cargo test test_name` would always rightfully return `Err(_)`. Oddly enough, in the test, if I add `obj.as_ref().unwrap()` *a line after the creation function* then `cargo test`(and the individual test) will indeed panic when trying to unwrap the expected `Err(_)`. It's totally bizarre and incredibly frustrating
Your arguments are completely insane... You take every issues of having a lot of dependencies and say this is a *good* thing. It's a complete nonsense. Also, antoyo didn't say that you shouldn't have any dependencies but that any dependency should be considered carefully, and the less the better the quality/safety/performance can be ensured. Also, even if we should always read a dependency source code, we don't and it's a bad habit, but I understand it (I only do it when I require something particular and check if I can provide it in the dependency or do it in my own crate). However (and I repeat myself), between two crates providing the exact same features, picking the one with the most dependencies is insane and potentially dangerous.
Trees are an interesting problem when you're trying to learn rust because it requires you understand more about the different kind of pointers and where to use which one. For example, a mutable BST requires Box as you pointed out, but then an immutable BST requires using Rc's. Implementing each of those taught me a lot of things. Links for the curious (probably not the best code in the world though, fair warning): https://github.com/keeslinp/binary_search_tree https://github.com/keeslinp/immut_bst
I know we've always used aliasing XOR mutability, but I still think we should refer to it as a NAND. 
What is there to be solved here? This is all working as intended, at least it seems so to me.
Yeah I've definitely noticed this. It's a recipe for a panic to just unwrap everywhere. We should be encouraging safer coding practices in example code.
I guess another option is to make macros for constructing trees. --- So, what about deconstructing trees? Can we make it correspondingly nice?
I don't think using `match` in the way you proposed would be an improvement, because it introduces an inconsistency in what follows the `match`: a pattern rather than an expression being matched. This saying, I do agree that `if-let` _is_ an awkward construct in Rust. It only supports a subset of the patterns that `match` does, doesn't support pattern guards (`Some(x) if x &lt; 5`; often leads to ugly nested `if`s), and has occasionally annoying borrowing semantics (the entire expression is borrowed not just in "then", but also in the `else` clause).
ok *crossplatform* gui would still use a cross platform language beyond C (e.g. Qt in C++). something C++ from the ground up is just going to be slicker. I'd probably prefer the reverse approach, C++ code with a C wrapper for FFI as a fallback for inter-language interfacing 
Personally I'm still having hope for something WebRender based that is simple, but extendable by the community via crate releases. A nice first step could be a UI friendly framework geared towards widget toolkits using it to implement a UI.
I feel that would be a larger project than Rust MIR -&gt; C89 since LLVM-IR can express things which MIR cannot.
Honestly, I think there shouldn't be any decision about which operator has precedence in these cases. I say it shouldn't compile whenever you're mixing up semantically different (as in arithmetic vs. bitwise, for example) operators without parentheses.
Noob question: why do you have U and V when they both represent the same type? Isn't that redundant?
Very nice, and it's important for rust to have good explanations for its core concepts. I'm a big fan of the ownership explanation that aturon has given in talks a few times. (~~I am on mobile, so no link handy~~ I'm really handy with links actually: [**aturon on ownership**](https://youtu.be/C6dNx9pY7p8?t=852)) A nitpick is that Cell uses no runtime checking at all, it changes aliasing information given to the compiler and disallows references to the interior (=no aliasing *except the aliasing with `Cell` around it*), at compile time.
Eh, no. Self-referential structs mentioned there is nothing like Tree. Tree is type-level self-referential, problematic is value-level self-referential.
I said proven though, rustls is anything but proven at this point.
My opinion is that we should use language terms instead of logic gates. In spanish you could say "O aliasing O mutability" but in english the closest you get is the ugly "EITHER aliasing OR mutability". Therefore we shall abuse the word xor until it becomes part of the daily language. Edit: Or just "no aliasing with mutability".
Rust could potentially allow code like you wrote it, but the borrow checker would have to be much smarter, currently rust doesn't understand that you aren't referencing the same node in each iteration of the loop. You can do [this](https://play.rust-lang.org/?gist=4617c23405d68ae473c725af2c8aa3c1&amp;version=stable) instead. This works because now the problematic borrows can only live as long as the end of this iteration of the loop, as we *move* the current node reference into the loop, rather than referencing it.
While U and V have the same trait bounds, they are not necessarily the same type. For example, the following function accepts any two values as long as their types implement `Debug`. fn print_two&lt;T: Debug, U: Debug&gt;(t: T, u: U) { println!("{:?} {:?}", t, u); } If we remove the U parameter in favor of T, this function will now only accept two values of the *same* type: fn print_two&lt;T: Debug&gt;(t: T, u: T) { println!("{:?} {:?}", t, u); } So `print_two(17, 42.1)` will no longer work, as these two arguments have different types.
You left out the end: &gt; with a little help I think the things I mentioned would enable much better ergonomics.
You seem to either miss or ignore the point I'm trying to make. Yes - adding a dependency that does X adds complexity, potential bugs, compilation time etc. to the code. But that's not because you added a dependency - that's because you added X! The alternative is not "don't add anything" - the alternative is "implement X yourself". So, by saying that "add a dependency that does X" is the bad option, you are saying that "implement X yourself" is the good option. Basically you say "_I can roll up, in a couple of hours/days/weeks, a better implementation than this third party solution that was polished, tested and refactored by a team of other developers, tens of contributors, and tens/hundreds of thousands of users for a couple of years now_". Now, I don't say you can't - there are reasons why, in specific cases, in-house solutions are better. But this should be the exception - not the rule! The idea that a single developer with less time to invest in a module is always better than a team of developers with more time to invest in a library that does the same thing is mathematically wrong. **Edit:** And, maybe it's not as obvious as I thought it is, but the authors of the libraries you use are subject to the same reasoning. So, just like Alice is wasting time and ending up with inferior product when she decides to roll up her own module instead of using Bob's library, Bob too - when needing to use a certain functionality in his library - will likely be wasting time and ending up with inferior product if he decides to roll up his own instead of using Carol's library.
Thanks, that worked! I have plenty of warnings now &lt;_&lt;' and my error has transformed into "a bin target must be available for 'cargo apk'", but that counts as progress, and it makes me happy. :3 PS: is it possible to just recompile one crate executable? When I run 'cargo build' in the cargo-apk directory it rebuilds all the things into their respective /target directories, which can take upwards of 5 minutes.
I'm not very familiar with either of those. Can both do the same things? What are the concrete differences in usage between the two (besides the declaration of errors)?
I do believe software engineers working in embedded or safety critical systems are underepresented on the internet. Of my colleagues (40 or so) I only know one person active in open source programming community. Because they don't post online or respond to stack overflow surveys doesn't mean they don't exist. Saying that, I agree that the vast majority of software work is not in this domain. I just think the ratio is perhaps closer than it may appear. I'm biased in that I think the guarantees that Rust provide can do a lot for the industry I work in. I don't want to miss out on that. The processor I'm using currently is a PowerPC which is an e200 core, like you say support is rough. I have dabbled with getting LLVM to generate some machine code but had very little success. 
is MIR likely to be a stable representation? (i.e. all future evolution of Rust possible between source-&gt;MIR) I suppose rust might still do optimisations which are MIR-&gt;MIR, then the final MIR-&gt;LLVM backend is more trivial? Or conversely would LLVM have details that MIR might need to account for eventually?
form other POVs, removing the symmetry of + &amp; - also requires thought; there's an issue of tracing things back.. 'at this point the value is used for indexing' ... 'but up until here, we're just manipulating a list of ints..' 
&gt; A nitpick is that Cell uses no runtime checking at all, it changes aliasing information given to the compiler and disallows references to the interior (=no aliasing), at compile time. ping /u/matthieum
I just got the change merged this morning, so you can hopefully just reinstall from github! When you're building something it has to compile all the dependencies, but once you've built once subsequent builds should work fine. You can run `cargo install --force` instead of `cargo build`if you want to actually install it as a tool. That way when you run `cargo apk build`, it'll be the version you just compiled instead of the version you installed earlier. Careful, the --force flag will remove your previous install!
I think it's _super_ reductionist to put servo in that bucket, FWIW. Every production browser out there is in C++. It is pretty impossible to do a production ready browser in any other language, aside from _possibly_ Rust. Browser engines take a lot of systemsy work, they're one kind of software that basically _does everything_. Putting Servo in that bucket ignores the fact that Servo is a really good argument for Rust's suitability as a C++ replacement. The fact that it deals with the web doesn't make it "web only".
No pressure. I'm not a programmer by trade so I certainly don't judge rough code... and I've been known to have private repositories to hide my most offensive spaghetti code too
&gt; When I take a look at Rust's friends page almost every single company there is doing web-related stuff. This is false. I only had one out of the top nine being webby. Tried refreshing (the order is randomized) and had similar numbers. &gt; While C and C++ developer communities are huge, we are only attracting very few developers from this communities I also think this is false, I perceive Rust to have around 50% folks from existing systems communities.
Thanks! That makes sense.
So if I want to mutate the boxed value, the best way is to use RefCell with Box, right?
Continue working on the uavcan library for rust. Yesterday I finished up my suggestion for the [design goals](https://github.com/UAVCAN/uavcan.rs/pull/3) for the project. The upcoming week I will focus on supporting multi frame transmissions. Uavcan is a protocol running on top of CAN. It's open source and makes an effort to standardize communication between units in unmanned autonomous vehicles. You can find more information [here](http://uavcan.org/)
The reason I said it ignores that case is that I got the impression they were estimating the rarity of the circumstances based on the probability that you'd have a single process taking up more than half the system's RAM. If you've got 32-bit processes on a 64-bit system, it's possible to have multiple processes taking up more than half of their address space on a single system. That's all I meant. Hence my ending with "That said, I do agree that it's likely to be very uncommon..."
If you want mutation through &amp; references, then yes.
If you own or have a mutable reference to a `Box`, you can mutate the value. Use `RefCell` as a last resort if you can't model your program to follow the borrow check rules.
I've just started to work on [proxy-config](https://github.com/mattico/proxy-config), a library to read proxy configuration from the OS. I primarily want this for rustup, since there seem to be a lot of people that have trouble getting that to work with proxies. It's also a problem that the Rust ecosystem should have a good solution for. If anyone wants to help, it's only a few dozen lines of code per platform to get it working. I especially need help on macOS, since I don't have a mac.
You're just completely avoiding your own point stating: &gt; So... all else being equal, I'd take the library with more dependencies. From this point, I think there is no more place for debate...
By the way, just because we are curious, itertools has already hosted very marginally successful zip experiments. They were all removed at a point where std got a better zip, and to get the crate into a presentable and neat Rustic shape.. - https://github.com/bluss/rust-itertools/commit/3fc09d0de2ed53f71514ee060f109dc4acba4225 - https://github.com/bluss/rust-itertools/commit/d06e1a98ce9306ccc0e36c1220d5520d93f442ae (ZipTrusted was a no-specialization take on "iterators of trusted length", except the optimization stopped working some time after it was developed) [Here's the critical](https://github.com/bluss/rust-itertools/commit/d06e1a98ce9306ccc0e36c1220d5520d93f442ae#diff-646a813c6e698ecc44e005942f4f343aL124) line from the optimization in ZipTrusted. And yes, `assume` is way more powerful than `unreachable`. 
Generally writing linked lists and trees is much more fiddly in Rust than in other languages - you might want to take a look at [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) to understand why. However in this case, I think your confusion is about what exactly you are mutating. You don't need to mutate the `Link`s themselves, you are only trying to mutate which `Link` the variable `current_link` is assigned to. Therefore you don't need to borrow the `Option` value mutably. You can fix it by removing a bunch of `mut`s. See [this playpen](https://play.rust-lang.org/?gist=11c82796095adb523a01a32dfea9c33f&amp;version=stable). EDIT: OK, now I see you are trying to grab a mutable reference to the leftmost node. There is a pretty similar Q/A on [stack overflow](https://stackoverflow.com/questions/28767108/borrow-pointer-errors-recursively-traversing-tree). The solution looks pretty confusing/magical: impl&lt;T: Ord&gt; BinarySearchTree&lt;T&gt; { fn leftmost_link_mut(&amp;mut self) -&gt; &amp;mut Link&lt;T&gt; { let mut current_link = &amp;mut self.root; loop { let tmp_link = current_link; match *tmp_link { Some(ref mut current_node) =&gt; { current_link = &amp;mut current_node.left; } None =&gt; return tmp_link }; } } }
Fixed, thanks for the ping ;)
Ignoring ggez in favor of Slime Gang Murder Simulator. Mainly turning "yes it is possible to load these assets and put them together" into "here is how you actually define objects in the level editor, now let's build some levels".
I would use the match as an expression to return the next state: fn update(&amp;mut self, input: i32) { let next = match self.state { State::State1(ref mut state) =&gt; { // modify State::State2 } //... } self.state = next; // you may be able to combine these lines, though that probably needs non-lexical lifetimes. } The other thing you can do is take the value out of the state and do your modifications locally: let mut next = State::State2; std::mem::swap(self.state, next); // next is now the previous state (which you now own), modify it freely. Here's a good [article](https://hoverbear.org/2016/10/12/rust-state-machine-pattern/) about making safe state machines in Rust. It doesn't cover your questions specifically but is a good resource in general.
No, because those things aren't even remotely related? There isn't even a single lifetime in this blogpost and I'm not sure what the problem is that you wonder if it can be solved
Which processors are missing for your company? 
That article is great and is actually what made me want to try this. However I need to have those Links borrowed mutably too, since what I'm trying to do in the end, is to insert a new node somewhere. The go_left function wasn't a good example, I'll edit a bit.
So technicaly it was not "race", it is just problem with handling of fragmented packages? What about usage of something similar https://github.com/BurntSushi/quickcheck to send package of different length to reproduce this problem ?
The problem is the *one direction* though :( It's pretty common to want `x - 1` (aka `x + (-1)`), but that's going backward. Interestingly, it's where overflow checks can get annoying: you would expect a compiler to optimize `4 + x - 1` to `3 + x`, however now the domain of the expression changed subtly.
I would note that your `IntoNode` trait is really just `std::convert::Into&lt;TreeNode&lt;T&gt;&gt;`. I would therefore suggest NOT introducing a new trait, and instead implement `std::convert::From&lt;T&gt;` for `TreeNode&lt;T&gt;`.
I used to think that unsigned types were a great idea, since they more closely encoded into the type the invariant that indices cannot be negative. In C++, I now agree with Stroustrup that they are a mistake. The problem is not necessarily unsigned types in abstract, but: - implicit bitwise casts between signed/unsigned, - and the lack of overflow checking. This can result in completely out-of-there indices with no clue as to how such a value could be derived, and because of the implicitness it's pretty hard to spot. This is especially inconvenient seeing as `0`, the most used index, is just 1 step away from MAX (the least used index)... when off-by-one errors are so common. Rust doesn't suffer from the former issue, but still suffers from the latter in Release mode. While for `u64` it should not be an issue too often, for `u16` or `u8` it is relatively easy to fall back into a valid range of indices after overflowing or underflowing. And this is not accounting for all the computations performed on signed integers and cast to unsigned just for indexing. As a result, I am now not convinced that unsigned indices (or integers) are really pulling their weight compared to the complexities they introduce for the users.
I did not took "all else being equal" literally, but if that's the problem, allow me to amend my claim: all else being I equal, flip a coin. Because if you find a reason to prefer one over the other, that's not "all else being equal". If, for example, you think the library with more dependencies has more bugs, then pick the one with less dependencies - not because it has less dependencies but because it has less bugs. and it's no longer an "all else being equal" case - because one has more bugs than the other.
SIMD is huge for what I want to be using Rust for. I've said it before, but I want Rust to eat Fortran's lunch. I'd love for it to become a first-class member of the HPC toolset. As with all things, I want it done right and I can wait. If it takes 'til 2019 fine. But I think getting those significantly low levels details squared away upfront is more important that people realize. Part of Rust's selling point is it's speed. If we can improve our story on enabling library writers to craft performant code, then that will percolate up into the web domain.
If you are OK with destroying and recreating the vector -- which may or may not be optimised by LLVM -- you can use `into_iter`, filter out the pending futures, and `collect` everything back into new `Vec`.
&gt; I'm biased in that I think the guarantees that Rust provide can do a lot for the industry I work in. I don't want to miss out on that. As a *user* of safety critical systems, you have my support for wanting to write your software in a safer language :)
I set up Pageant and converted my github_rsa key to a ppk file, and that seems to work with the url format `git = "ssh://git@github.com/username/repo"` But a few months ago it worked with the url format `git = "https://github.com/username/repo"`. Is there any way I can make it work with that with Pageant?
I tried, trait coherency rules seem to prevent this.
&gt; The only way to target them at the beginning is to use proprietary forks of GCC 4.x if you are lucky. Wait a minute. How can one have a proprietary fork of a GPL software? Any user *should* have access to the source, that's the whole point of GPL.
&gt; Rust is absolutely suitable to build on , it would only take a few tweaks to make it better in every use-case. Out of curiosity: which tweaks are you thinking of?
The Programming Rust book has a binary tree example using enums instead of structs. It takes much less code than using structs, albeit less flexible. It was cool to see that approach though. I haven't seen examples online using enums. Some other helpful articles I remember when looking into Rust trees: - http://cglab.ca/~abeinges/blah/too-many-lists/book/ - https://manishearth.github.io/blog/2015/05/27/wrapper-types-in-rust-choosing-your-guarantees/ (this was really helpful) - https://aminb.gitbooks.io/rust-for-c/content/graphs/ There are others I can't find right now. Has someone collected articles/guides/tutorials about Rust trees yet?
I tried that before, you still can't filter because filter takes a non mutable reference into the closure. retain_mut ended up working.
The trick is to use `filter_map` which gives you the ownership of the item (at the cost of having to return an `Option`, but this actually works well in your case).
As a C++ developer, working with a C++ codebase daily for the last 10 years, there are few things that Rust lack to be fully suitable as a language, certainly: - wider `const` support, - non-type generics (at the very least integrals), - SIMD. However, by far, the most annoying issue is one of *migration*. There is no smooth path for integrating Rust in a heavily templatized codebase; and no smooth path for cross-language optimization. The former is a really hard problem: D has a shallow support, but cannot deal well with templates. Only Nim has good support, and that's when it transpiles to C++... The latter is probably solvable: Clang produces LLVM IR, rustc produces LLVM IR, combine and optimize. It's also rather pointless without the former. It's not clear to me how Rust could cleanly interact with C++ code. Overloading is hard enough to solve, but templates add a whole other level of difficulty, between the mess that is specialization, selection of overloads on lvalues/rvalues, and all the intrinsics available for C++ types (`std::is_nothrow_move_assignable`?). I am afraid that C++ is too complex to ever hope good interoperability.
If it's any consolation, you apparently [aren't the first](https://github.com/rust-lang/rust/issues/17462) to be bitten by this!
In other words, in Rust, signed indices would be a way of using the sign bit as a more efficient way to detect over/underflow by folding it into the bounds check rather than running it on every mathematical operation. Not perfect, since you could underflow, then overflow back into validity or vice-versa, but I can definitely see the benefit.
What about applying APIs like `mmap` to DVD ISOs or the big 4GiB+ installers that sites like GOG.com and Humble Bundle Inc. offer for platforms not expected to be running FAT filesystems? 32-bit systems are still kicking around, as people on the GOG forums complain about when a game goes 64-bit only.
That's because you made an alias, not a proper type. See https://play.rust-lang.org/?gist=cb2b60d26a761110b9c9341fcf321a32&amp;version=stable
Another thing to try if your state is cheap to copy is to have update return the new state: enum State { State1(State1Struct), State2, } impl State { pub fn next(&amp;mut self, input: i32) -&gt; State { match self.state { State::State1(ref mut state1Struct) =&gt; { State::State2 }, State::State2 =&gt; { ... // omitted }, } } } 
Is anyone working on a Rust port of TLSH? https://github.com/trendmicro/tlsh I know of a Rust port of Nilsimsa https://github.com/z1mvader/nilsimsa Sometimes one is better, sometimes the other...
I do a lot of HPC work, and I'm currently working on a new HPC codebase in C because I'm tired of Fortran after working on it for years. Rust is a language that constantly interests me, but it's just not there yet on the numerics side of things. If it starts getting decent support in that area such as SIMD support, GPGPU and other accelerator support, and decent linear solver libraries I'll definitely give it a shot and maybe even port this new codebase over to Rust if the speed is there.
Thanks, didn't notice that filter_map took ownership.
Still learning. Still need to cover Errors, Traits, Generics, and things like Box. (Working through the book V2) To aid learning I'm working on a Matrix bot using Hyper and serde and building a SOM and rendering its results using piston.
&gt; While I'm a Qt fan - it's not true. Qt is far from perfect and there constant runts about it. I've been having trouble trying to find it again, but this reminds me of a great blog post I read maybe a year ago which cast Qt as the best of a bunch of bad (open-source) options with the intent being to encourage the Qt ecosystem to catch up with some of the comforts offered by proprietary solutions.
You just deepen your nonsense...
Who's gonna suggest a nice macro-based shortcut syntax? :-)
&gt; [re: security] If you're servicing a client request, accessing an array by index arithmetic, a bug in that arithmetic could expose or modify data that the client shouldn't see or touch. But since that data is in the same array, bound checking passes. You're protected from undefined behaviour - which is huge - but otherwise index arithmetic is as fallible as pointer arithmetic.
It would be awesome if there was a layer in Servo we could use. Servo without JS would be a great platform as it already implements a great deal of what is required. WebRender is still quite low level.
Are you trying to clone over HTTPS protocol, or over SSH protocol but through port 443? In the former case, you can't use Pageant since it's not even SSH (no SSH keys are involved). Instead, you'll need to set up [credential.helper](https://help.github.com/articles/caching-your-github-password-in-git/). If you want to use SSH protocol, but through port 443 (because, say, your organization blocks port 22), then look at: https://help.github.com/articles/using-ssh-over-the-https-port/
You might be interested in reading https://github.com/rust-lang/rfcs/blob/master/text/0160-if-let.md , which explains everything.
Still working on [tarpaulin](https://github.com/xd009642/tarpaulin), and also a bit of nix-rust. Last week I nearly cleared another issue. It mostly works just a bit patchy although it fails gracefully. This week I'll aim to revisit that issue, implement cobertura reports so people can use tarpaulin with codecov and get my nix PR past the finish line. 
&gt;&gt;otherwise index arithmetic is as fallible as pointer arithmetic. there's only so far you can go &gt;&gt;"a bug in that arithmetic could expose or modify data that the client shouldn't see or touch." wouldn't the answer there be to make more abstractions over the arrays, until you aren't using indices. the times you really do need indices, you usually need to calculate things.
There are a lot of concepts that being a ruby developer doesn't force you to learn. It's been an interesting challenge though.
&gt; What about applying APIs like mmap to DVD ISOs or the big 4GiB+ installers that sites like GOG.com and Humble Bundle Inc. offer for platforms not expected to be running FAT filesystems? 4gb *plus* is what you say there So in that case, you'd need 64bit, or you'd need to build some sort of paging/segmented mechanism within 32bits. &gt; 32-bit systems are still kicking around, as people on the GOG forums complain about when a **game** goes 64-bit only. No game will fill all of memory with byte one array. Seriously. 80+% of the memory in games goes on textures and vertices. vertices are usually 16+bytes, models are cut into chunks. textures have to be above a minimum size, but you wouldn't fill the whole of memory with one, and even if you did it would be graphics memory beyond the scope of the main game logic (perhaps inside some necaserily unsafe streaming system). My take on indexing *does come from experience in games*, spanning multiple generations. By far the most pressing requirement is the need to shave off every last byte (where size doesn't matter, compression still saves cache-space) as such reducing index bits helps. there's actually a synergy between small indices and locality. As I explain my ideal is for the index to be parameterised, so you can override it per situation. my most used case would be i32, probably dropping to 16bit or even 8 bit indices for a lot of cases. I'd probably never have to use i64 but I wouldn't preclude the ability.
I have to apologize here. I was a bit triggered by what I perceived to be an exhortation to make Rust just as exclusionary as the low-level langs before, and the coffee machine broke down before I could get my caffeine fix. Not a good morning that. Still, not an excuse for the language I used. That said, SIMD is in the works, const generics are being prepared, so a lot of stuff is already on the way.
Thanks for the advice. I've definitely already learned the wonders of type safety and memory management, not having to rely on a GC etc. It's pretty cool so far.
I was very afraid of the modules system rework. When the first draft was posted a few months ago I even had a small meltdown and was convinced that this was a step in the wrong direction. Turns out the result is quite nice. I don't have any bad feeling about any of the proposed changes, and while I personally don't have any problem with the existing system I like some of the improvements. 
Ahh interesting. I might just go ahead and hop on and take an issue and just see what happens. Thanks for the advice
Personally, I would've started from Haskell: ` data Tree a = Nil | Node (Tree a) a (Tree a) ` and worked my way to a Rust version of: ` enum Tree&lt;T&gt; { Nil, Node { left: TNode&lt;T&gt;, val: T, TNode&lt;T&gt; } }` `type TNode&lt;T&gt; = Box&lt;Tree&lt;T&gt;&gt;;` Your use of Option, to me, just shows that your base type needs to have variants. Also acceptable would be like, data Tree a = Nil | Leaf a | Node (Tree a) a (Tree a)
I feel like you might almost expedite it by learning C before going into Rust to get an idea of the problems its trying to solve and why.
Seems like a large undertaking. I dabbled with C a bit (working through learn C the hardway). I suppose I'm not against the approach but it does seem like a very intense path 
Can we get this in the stdlib docs? It's easier to understand than the current documentation for the cell module.
&gt; Out of curiosity: which tweaks are you thinking of? various ideas on multiple fronts , perhaps some of them might tip the balance such that it feels less 'oppressive' and more productive:- - traits are a shock when you're used to adhoc overload, - how about the haskell situation where you don't repeat signatures in instances/impls.. so it's clearer that 'the cost of declaring/referencing the trait' is immediately paying dividends in streamlining what you write. I've done an [RFC for this](https://github.com/rust-lang/rfcs/pull/2063) but it got -9 vs +2 thumbs .. which makes me despair that I'm in the wrong community here. - or enabling global type inference - module wide type-params might cut down on the heavy anglebracket use. c++ has nestable classes which I do like, but parameterised modules would handle their use cases whilst eliminating C++'s irritating asymmetry between classes &amp; namespaces - .. or just enabling adhoc overload to recover the situation c++ has (you can still gather in traits, but the same name function must be used with different arg types to bind to different meanings in traits.. ```Cowboy::draw(&amp;mut self, w:WeaponId)``` vs ```Cowboy::draw(&amp;self, c:&amp;mut Canvas)``` :) ) - the loss of operators e.g. ```[]``` for unsafe code, the signature of ```[]``` implies safety. *you seem to have to constantly look up named functions to do simple things in rust*,which can be done by composing basic operators in C++. - what if the operators were rebindable (some easy way of providing a default), just like 'use' can rebind any other symbol so you could switch between unsafe_index / index or whatever - references: we lose the middle ground of C++ ```&amp;``` (whilst not safe, it is safer than ```*```), so we must go to 2 extremes (verbose safety or verbose danger..). ideas like the ```'temp``` lifetime (easier to read and write than the for&lt;&gt; stuff which requires creating a label and reading aside to see what it means, or even another class of 'unsafe reference' (same implication that its 'probably not null, and definitely not passing ownership).. the syntax space is gone, but again what about rebinding. ( I guess we could make an unsafe smart pointer but then you're getting more verbose) - 2 pieces of syntax sugar that I dearly miss:- - sigils made the equivalent of 'modern c++' look absolutely superior to use, and I think ```@``` combined with global inference would have been enough to replace the use of a 'game scripting language' (the use cases where you combine C++ with C# / Python / Lua or whatever. I just watched a talk describing how ubisoft built their own in-house gameplay language that compiled to C++) - do notation was great, making internal iterators look as natural as inbuilt constructs (again accelerating past what you can do in c++).. it might sound irrational but removing the extra nesting level is so nice, maybe for the same reason people don't like to make an if!{condition {}else{} } macro etc.. The other things are probably on the roadmap already (i know eventually the generics could be both more capable and more comfortable than c++)
You might even define a [**`fn stride_offset(self, s: isize, index: usize) -&gt; Self`**](https://docs.rs/rawpointer/0.1.0/rawpointer/trait.PointerExt.html#method.stride_offset) : separating the stride and the index.
Can't argue with such an elaborate claim...
&gt; And this is not accounting for all the computations performed on signed integers and cast to unsigned just for indexing. thanks :) that's exactly what I'm saying. a rare case of agreement in this forum. The times when you can't use iterators and you resort to indexing, it's often because you do want to do some calculation. I would personally suggest making the index parameterised, which would allow overriding it, whilst retaining compatibility by defaulting to usize. At some point I might cut paste vec.rs and make a crate that works like this ... I know it's within our cability to complement the std::lib for things like this. 
Since there doesn't seem to be a lot of support for the server devs I'd just like to say that I, for one, am very excited to explore use cases for Rust on servers. I hope coroutines and async/await make it into the language to make my life easier and I think Rust can do well in that arena. I understand all these systems devs see Rust playing in this area that C/C++ don't usually get used for and maybe they see that as a needless distraction for the language, but I don't think it is. I hope the area continues to get explored so I can make use of it later and push for production use of Rust on the backend.
&gt; In C++, I now agree with Stroustrup that they are a mistake. ... and now you know one of several reasons I resisted using ```std::vector``` for a long time, preferring to roll my own collection classes. I like the power of the C++ language engine but I've always found the standard library really, *really* annoying
Thanks for your feedback! I did not know, it possible to use something like `#[repr(u8)]`. Also thanks for enums, I'll give them another try!
Interesting... does that mean that `Cell` is a purely compile-time abstraction with no runtime representation? (Actually I just glanced at the source code and that is indeed the case.)
&gt;Has such a feature ever been discussed? Yes, `Type::AssocType` should work in the same way as `Type::assoc_fn` and `Type::ASSOC_CONST`, it's just not implemented. IIRC, there were some complications with resolving `Type::AssocType` in (function) signatures in general case, cycles maybe. This implementation issue also blocks inherent associated types impl Type { type A = u8; } &gt;Should I just accept that my signatures will have monstrous types? I'd suggest to accept this, yes. There's no guarantee that it will be implemented in the nearest future (but who knows).
Thank you! This is pretty constructive feedback and there is number of things I can learn just from your comment. I did not use `trasmute` for the bindings, I just use is a tool to investigate data layout in the memory. Regarding all the rest, looks like there is a number of issues to fix for me) 
Yes, I agree. It's maybe possible to carry defensive programming too far, but I'd like to see folks *try* to take it too far.
&gt; It's much harder to compete with Unreal and Unity. I can't say which is the harder competition, but I'm not suggesting to compete with established game engines. Many game developers create their own engines, as you can see [here](https://80.lv/articles/unity-dominates-game-engine-market). And this is not counting the tooling that goes with developing games. I'm not a professional game developer, so these are just my observations. There seems to be genuine interest behind C++ replacements in the game dev space (take a look at the community following JAI language development, or even nim). 
Might this be something the [non-lexical lifetimes RFC](https://github.com/nikomatsakis/nll-rfc/blob/master/0000-nonlexical-lifetimes.md#problem-case-4-mutating-mut-references) will fix? 
I am at a major decision point on how my data structure representing objects such as bezier surfaces will work. Currently, my programming style is to use enums (with each different variant having different associated data to store different types of objects I need). I once looked at how enums are actually stored in memory, and it appears that they consist of a tag and multiple bytes after the tag (the number of bytes being determined by the variant with the most data associated with it). The problem is that some variants will have only a few bytes associated with them, while some will be 384 byte monsters (and the minimum size of the enum will be very large and waste much memory for small objects). Are there optimizations that happen later that fix this, or do I need a better alternative? Edit: I know of a workaround involving pointers to slices, but I want to be sure that there is not something I am not aware of.
The book has https://doc.rust-lang.org/book/second-edition/ch15-05-interior-mutability.html The book _used to have_ https://doc.rust-lang.org/book/first-edition/choosing-your-guarantees.html , which is adapted from a blog post of mine. I think the second book is missing something along these lines, I get a lot of questions about exactly what all these types _mean_. cc /u/steveklabnik1
Cell has no *memory overhead* or *indirection overhead*, but it changes aliasing information, so the compiled code can be slightly different. It can for example allow fewer optimizations, since we don't have the strict guarantees of holding a shared reference of the actual data we're reading. With that, I don't think it's the whole story to say it has no runtime representation. Here's an example where `&amp;i32` and `&amp;Cell&lt;i32&gt;` produce different code; even though the example looks weird it demonstrates a simple case: reading through a pointer before a function call, and then again after the function call. https://play.rust-lang.org/?gist=4517e7d9204d3542afae689069ecc9f0&amp;version=nightly 
I like the `export` addition and the path changes. But I'm still not a fan of submodules appearing out of nowhere.
https://doc.rust-lang.org/book/second-edition/ch15-05-interior-mutability.html is the closest thing; we used to have both Cell and RefCell, but ended up going with just Cell. That said, I would like to work on `std::cell`'s api docs more.
Old comment, but whatever... Have you considered selling [via Massdrop](https://www.massdrop.com/diy-tech/drops)? They organize group buys and also do lots of small run electronics. If interested, [How do I become a vendor or sell through Massdrop?](https://helpdesk.massdrop.com/hc/en-us/articles/212496208-How-do-I-become-a-vendor-or-sell-through-Massdrop-) or just email them at vendor@massdrop.com I only know them because of the ErgoDox keyboard.
Right, I linked to that. I assume you meant "just refcell". The thing I'm talking about is one place to understand how all these things provide guarantees/costs and how they compose. This is one major confusion I see for folks starting Rust, even those coming from C++ (somehow, especially those coming from C++), where they have trouble parsing `Rc&lt;RefCell&lt;T&gt;&gt;` or `Arc&lt;Mutex&lt;T&gt;&gt;` or `Rc&lt;Cell&lt;T&gt;&gt;`.
I'm not very much involved in this, but I _think_ that this may make it harder to distribute packages that use Rust code. A very helpful user at one point went through all of the sources of nonreproducability in rustc and documented them, along with the tooling used to look for this. https://users.rust-lang.org/t/testing-out-reproducible-builds/9758 If you can help knock out these sources, that would be great. It doesn't have to be knocked out by default, but there should be a way to remove it if you want a reproducible build (i.e. `-Zstrip-build-path` will use a dummy build path, or whatever)
… what's ugly about that?
Again, I didn't think before I wrote and was unclear. &gt; 4gb plus is what you say there I was merely providing a counterbalance for your "and have never in 30 years needed &gt;2billion chars" statement with an example of byte-addressed 4+ GiB files in common use. Nothing to do with native word size in this case. &gt; No game will fill all of memory with byte one array. Again, irrelevant to my point. My point was that there are still 32-bit systems kicking around. I only mentioned a context that involved games to back up my claim of their non-trivial presence. (For example, maybe you want to write a tool for working with DVD ISOs which `mmap`s the image and needs to run on 32-bit systems.)
After shipping [Gotham](https://www.reddit.com/r/rust/comments/6t07dv/announcing_gotham/) this past weekend I'm taking a break from the feature/bugfix grind for a week or so. Instead, I'm writing a blog post that walks you through recreating the Gotham [example app](https://github.com/gotham-rs/example-app) starting at `cargo new` and going from there.
Recommendations... for what?
`relm` works on stable Rust: look at this [example](https://github.com/antoyo/relm/blob/master/examples/buttons-derive/src/main.rs#L50). It is true, however, that it is a WIP, I'd even say a proof of concept.
"Choosing your guarantees" was indeed a useful chapter for me. I could imagine it having even more examples, too. Even with the general guidelines provided, it's hard to figure out how to construct wrapper types for more common scenarios, or how to figure out, for example, whether you want `Rc&lt;RefCell&lt;T&gt;&gt;` or `RefCell&lt;Rc&lt;T&gt;&gt;`.
Putting the final touches on my RustConf talk for this week. Really excited to be presenting! I'll probably also be throwing the related material for it up soon as well.
I've had pretty much the same reaction to each revision of these ideas, including this RFC: It doesn't really add anything for me. Seems like it will create a lot of transitional pain, and I just don't see the new system as any better than the old one. It's still a bunch of rules to remember, just a different set of rules, and now we have to remember two sets of rules. That said, I really never had much trouble with the module system, so I accept that the work here is just not something I'm in the target demographic for. If this is significantly easier to understand and use for the people that have trouble with the current system, I guess it's worth it.
That ownership explanation really cemented things in my head for me. It really is very good, if you are having trouble I recommend watching it! 
Yes, that's a known shortcoming (heh) of enums. There are multiple ways out: * `box` the large parts of the largest variants * or just store a pointer and put them elsewhere (e.g. in a `TypedArena`, look at the crate with the same name). * or even create different places for different variants and only store pointers when you need polymorphism. What tradeoff works best for you depends on your application.
Same here. I was initially very skeptical if it was really necessary, but this looks quite good. The only thing I am still a bit afraid of is that Rust is picking up too much syntax to do essentially identical things, which can also be very confusing for newcomers. I remember when I was learning React, I read 10 articles on it, and every one of them had a completely different syntax for doing what was essentially the same thing. Some used good old vanilla Javascript, some used ES6 classes and JSX, some exported with a `export default`, others with a `module.exports`, and a mixture of all of those. Before I was able to do anything productive, I didn't just have to learn the current correct way of doing it, but also the legacy way (and the future way to some degree). ~~I know that the RFC provides a migration path, but realistically that migration can only be completely finished in a potential Rust 2.0, right?~~ I must have read over the reference to https://github.com/rust-lang/rfcs/pull/2052
I should add, this `Type::AssocType` *sometimes* work. If `Type` is `Self` in a trait or a type parameter, then you can use `AssocType` with the shorthand syntax. use std::ops::Deref; trait Base { type A; } trait Derived: Base { type B; fn f() { let x: Self::B; // OK let y: Self::A; // OK too } } fn f&lt;T: Derived&gt;() { let x: T::B; // OK let x: T::A; // OK too } fn main() {}
x86_64? And SPARC Solaris?
Thanks for this comment, its very encouraging. :-)
Yes, unfortunately, it's hard to cover everything; the book is already ~400 pages. We have to make hard choices.
SPARC Solaris isn't listed on that page, although sparc64 Linux and Netbsd are. It may work if you build it yourself, but it is evidently not well tested. There do seem to be a couple PRs related to SPARC Solaris, : https://github.com/rust-lang/rust/pulls?utf8=%E2%9C%93&amp;q=sparc%20solaris I guess you can ping those people to ask how well things are working.
In the OC one can see that at some point in the future they plan to change policy from "should" to "must" (RFC 2119 applies here). That means that if this isn't solved, in the future Debian will start purging the packages from the archive because they have bugs of severity "serious" that aren't being solved.
I like the new system. It removes some of the verbosity and much clearer. It is good to do this while the ecosystem is still young.
It also won't change that much for me now, except that I will have to write a tiny bit less code. However when I started with Rust I struggled with the module system and I see this as an simplification.
I don't like how you still have to list your exports in the `lib.rs`. Would be easier to just have export on structs/functions/... and cargo pick up which (sub-)modules contain exported items. Otherwise it seems like an huge improvement 
This is exactly what I was looking for. I have decided to use boxes for now, and perhaps later I will know how often different types are used so that I can do a refactor.
Hey, I took a short look over and I like the level of documentation -- pleco looks pretty promising, good job! I was wondering if you'd implemented UCI yet, as I see uci.rs is empty and I'd like to test it out. I wrote my own engine https://github.com/Johnson-A/Crabby so I'd be interested in trading feedback when I have more time to take a deeper look. As a side thought, I wanted to create a parameter optimization engine to optimize the many constants in my chess engine. I wonder how useful a generic optimizer would be and what solutions already exist in rust. I'm interested in your thoughts on parallel search, especially the singly linked list you've implemented. I tried to keep certain features simple, i.e. generate all moves at once instead of incrementally and simple bitwise board copies at each branch. Do you have perft results?
cargo can't just pick up which modules contain exported items, because you may want to hide the real location the items are defined at &amp; re-export them elsewhere (for example to make a module with submodules look like a flat module). For this reason, you have to mark the modules you want to be in your external API as `export` also. But if you have an `export`ed module with `export struct`s in it, those are exported w/o any more commentary.
I'm not a beginner, but still struggle with the module system in the sense that I just mindlessly pepper `mod`, `pub mod`, `pub`, `pub(crate)`, `extern crate` all over the code until it compiles. `pub(crate)` is particularly annoying - it easily gets viral and usually there isn't much logic to whether types are `pub(crate)` or not - it's there just to make the compiler shut up.
I didn't really understand: fn new(root: i64) -&gt; Tree { Tree { root: root, ..Default::default() } } Firstly it seems poor form to use the same method parameter name as the structure member name - that had me initially wondering what `root: root,` meant, but I figured that out. But what is `..Default::default()`?
Thanks for taking a look over it! I'm glad to see that another Rust-based Chess Engine already exists, the only other one I could find was [cicada](https://github.com/mkyl/cicada). Giving your code a quick glance, seems very thorough! BitBoards, Magics, UCI, etc, you seem to have alot of awesome features! I'll be happy to give it an in depth look in a while, I think both of us can learn alot from each other's projects. uci.rs is empty right now, it's one of the things I'm currently working on implementing. Things get weird when they run in parallel, I'm still figuring out how to easily transfer messages to / from the Engine to the Searcher. I think a parameter optimization engine would really be useful here as well... so many different parameters have to be checked mid-search, It would be useful to have these be inline, or somehow passed around more easily. I've been experimenting with using Atomics rather than passing around parameters to see if that speeds things up, but it isn't looking promising. I currently do not have perft results, but I'll look into implementing that in the bots I have. If you want to see how much faster the parallelization makes the board, I would check out the benchmarks I have. The `bot_parallel_minimax` is a parallel version of `bot_minimax`, and the `bot_jamboree` is a parallel version of the `bot_alphabeta`. Running all of these up to a certain ply is pretty good indicator of how well the parallelization speeds things up.
My biggest worry is that too much is changing too fast. I think more time needs to happen for things to settle so a wider consensus is found on what's specifically wrong with the language that's needed to be fixed rather than constantly changing things without letting them settle. Especially as someone learning this language right now still, I feel like I'm constantly chasing a moving target. This has me worried.
I was trying to be charitable, both to the team members and community that have been working on this, and to the users who have had trouble with the existing module system. From my own perspective, of course I agree that the changes proposed in the RFC are not worth changing from what we have now.
Great, feel free to message me on GitHub. Looking over my code I realize I can make a lot of improvements in documentation and in evaluation.rs. Move generation can be quite error prone, especially when creating an optimized solution. I verified my implementation using perft so I'm quite confident in its correctness - however, there are many other components which are equally as complex that I have spent much less time verifying. I'd like to write a test suite to squash out bugs in these areas. I'll think about making it interface to more than just my engine so that others can use it.
Yeap you won't regret it!
I know everyone dislikes the idea of having the dependencies and modules explicitly stated in code, but that's one of my favorite things about the current module system. edit: also, shouldn't this be like rust 2.0 with the breaking changes? What isn't this going to break?
Yes, same for me. For the breaking changes see [this RFC](https://github.com/rust-lang/rfcs/pull/2052) about epochs. Those basically mean you can lock your crate to an older version of the language.
There's also a github issue [here](https://github.com/rust-lang/rust/issues/34902).
About Rust in the browser (and isomorphic rendering), there's [domafic](https://github.com/cramertj/domafic-rs).
I think "Rust should be a good language for writing high-performance async servers”very right. rust need killer ecological chain, rather than just killer application. I have C / C ++, PHP, JAVA engineering experience. PHP, python and other dynamic type language is very suitable for start-up, easy to use, easy to find developers. But "add more servers to improve performance" is very wrong. When the entrepreneur to form a stable business, the machine to a certain size, then you need a very good architecture and design to ensure stable operation of the business. In large-scale machine clusters and complex volatile business logic environment, the dynamic type language is too easy to bug, find and solve the problem of high cost. At this time JAVA come into play. JAVA has a mature architecture, performance is not bad, but consume too much resources, especially when you have thousands of micro-service at the same time running, it is difficult to plan and control the rapid expansion of resources. At this time C / C + + will be very useful, resource consumption can be reduced several times, and can be linear planned. Application cluster management is one order of magnitude lower than java. But c / c ++ too easy to shoot yourself, write the correct C + + is not a simple matter. This is the space and chance of RUST.
Same here, and one of the reasons I haven't liked all the proposals. Automatic modules seem like an anti-feature.
Even with the epoch RFC, I'm worried about the scope of the changes. It seems like a lot of upheaval.
I agree. I'm also worried because the epochs basically open Rust up to any possible change, including disappearance of features that aren't mainstream.
If you read the RFC you'll see that it does not open Rust up to "any possible change" but only surface level changes having to do with syntax, name resolution, and macros.
Can new or re-used syntax not be used for new features only available to the new version? Can a new epoch not take things away and make features unavailable? What is an example of things that epochs can't be used for? Edit: I've quickly reread the RFC (but not the discussions, as it's 400+). It seems the only things epochs can't do is change some specific features working across multiple crates, but it can still remove them and introduce new ones.
I truly think changing pub and mod to public and module would go a LONG way.
I see what this means for getting the associated type of a parent trait, but what does this mean for getting an associated type of an associated type? I see what you're saying, but I'm not connecting all the dots.
I think I mostly agree with the redesign, but using `pub` to mean "visible to this crate" feels odd. Public seems like it should mean world visible. I do, however, think that it would be good to have a more concise way to write "crate visible" than `pub(crate)`. Would it be possible to use `crate` by itself as a visibility, or would that introduce too much ambiguity into parsing?
&gt; thats also a huge straw-man It's not a straw man; it's a parody.
This looks really interesting! I've been working on a Rust chess engine on and off since the very beginning of this year. I'm hoping to make it public in the near future once it's more complete feature-wise. A chess engine deals with a lot of low level interfaces, which Rust can handle without a problem. It definitely has many powerful features that can make a program like this blazingly fast while ensuring safety and correctness.
I would love to help on any issues (I can manage)! I am fairly new to Rust but am trying to pick up as much work/experience in it as I can with whatever projects I can find (typically converting C++/Java assignments into Rust ones haha), so I'm not the most experienced as of right now. That said, I would love to help with anything I can! I'm [ejmg](https://github.com/ejmg) on github.
... well it could be neither aliasing nor mutability...
I don't like any of the PDF libraries that are out there, so I decided to [write my own](https://crates.io/crates/pdfpdf) (the description on Github explains the name). Ideally I'll use this to either add PDF output to one of the existing plotting libraries, or write one that's entirely my own.
&gt; [...] but I've written an X11 client that has no problem with multithreading. [...] Perhaps things have changed, but last time I tried using X11's API directly, there were lots of things demanding that they should only be called from the *"main thread"* or that I should ensure proper synchronisation as X11 doesn't. Might also be that I just remember incorrectly. &gt; A proper cross platform GUI library [...] would take several years to build. That's why we should start rather early. Perhaps even start building on nightly as all the nightly stuff will eventually be stable. We have GTK-rs and some Qt trickery *now*, which work pretty well, but not a Rust-y thing. Besides: We might have a little development boost thanks to existing projects providing us with their years of experience.
This is a huge new release of relm. The [web browser titanium](https://github.com/antoyo/titanium) is already using this release: it is actually a good test for relm. Hopefully, the API will stay more stable from now on (though some breakage is still to be expected). As always, any comment or suggestion is appreciated!
I'm trying to make cargo accept HTTPS urls for private repos (which used to work before). Does wincred remember username &amp; password across PC reboots? What should I set for the value of credential.helper to make it use my github_rsa file?
Yes, multiple ways to do the same thing takes away from the readability/simplicity of code tremendously. There was a reason that Perl was often joked about as write only -&gt; [TMTOWTDI](https://en.wiktionary.org/wiki/TMTOWTDI) or, ironically, [TIMTOWTDI](https://en.wiktionary.org/wiki/TIMTOWTDI#English). Some wikipedian has a wry sense of humor.
feel the same, although i feel little discomfort cause it would be breaking change and i need to update code :p. also i wonder if this simplified system is ok for bigger projeects.
Isn't *"either... or..."* just English XOR? I think we could absolutely call it *Aliasing NAND Mutability*. Both, because it is correct, and because propably most people using XOR also know what NAND is.
this. maybe depreciation system is a solution but on the other hand depreciation may creat python23like mess...
Sounds good - except these execute on a thread pool (`futures_cpupool::CpuPool`) and as far as I understand will begin executing upon future construction/the call to `spawn`. I wonder, if I wrap them in another `futures::lazy`, will that prevent?
&gt; pub is public to both your library and other code. .... only if all the parent paths are also `pub`.
&gt; may creat python23like mess... It's designed to not do this, explicitly, as you can mix and match code across epochs without problems.
See here https://github.com/aturon/rfcs/blob/epochs/text/0000-checkpoints.md#constraints-on-opt-in-changes &gt; As such, the RFC proposes to limit checkpoints changes to be relatively "superficial", i.e. occurring purely in the early front-end stages of the compiler. More concretely: &gt; &gt; * We identify "core Rust" as being, roughly, MIR and the core trait system. &gt; * Over time, we'll want to make this definition more precise, but this is best done in an iterative fashion rather than specified completely up front. &gt; * Checkpoints can only change the front-end translation into core Rust. 
&gt; we've chosen to prefix crate-local paths with crate:: rather than some of the more radical syntaxes proposed in recent iterations. What were the radical syntaxes that were originally proposed? 
Out of interest, in what situations would you want to have a rust file in your source tree and not have it loaded? 
I had very similar thoughts about the first proposal. I perceived it as a very "grass is greener on the other side" thing, where it had (to me) obvious complexities that ended up making it (to me) worse than the current system. Language-design isn't just problem-solving; there's a holistic component to it as well. Anything can _solve_ a problem, it's just hard to get something that can both solve a problem and not cause a million of its own. The old proposal _tried_ to do this right, but IMO fell short. It also was addressing the (IMO) wrong set of problems, and had a bunch of other issues. Which I discussed with /u/aturon . I think this new RFC has none of these issues. It does have complexities, but not nearly as bad, and IMO better than what we have. Of course, this is just what I felt from trying to simulate from different angles how newcomers would feel about it, so I may have missed something. But I tried _hard_ to take it apart, since I felt the bar for changing something like the module system should be pretty high. And didn't manage to come up with much. I think my main bit of feedback for the second proposal was just that I was slightly concerned that the transition period may end up leaving a lasting imprint of confusion on the ecosystem (Python has this problem wrt imports and in general as well, though they don't have the epoch system). That's something that will happen regardless for any proposal, so basically my perception of the new proposal is that it's as good as it gets :) &gt; That said, I really never had much trouble with the module system, so I accept that the work here is just not something I'm in the target demographic for. Neither have I, but I've had to explain it to beginners so many times that I even [wrote about it](https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/).
Well, little frameworks for doing _interactive_ console applications, like a REPL.
`io::stdin().read_line(&amp;mut output);`
Naturally - tho I'd go for rustyline or some similar crate to provide command-line editing and history. Just occurs to me that there's some repetitive patterns (particularly when parsing typed arguments to commands) that could be factored out.
Oh yeah, right. Rustyline for anything serious
Great work, I can't wait to use Rust for web frontends... &gt; The component! macro is used to define a custom element. Is this actually creating a custom element as defined by the web component standard? Is that lib just a proof of concept or intended for serious use? I'd really like to have a framework that allows writing PWAs in Rust using custom elements, kind of like a replacement of the Polymer framework. Can this be used to write a js lib that provides custom elements that can be used in normal html+js code? So that one could write a web framework in Rust, to be used by normal web devs.
Great! Any and all help is 100% appreciated. Over the next week or so I will be writing some in-depth on GitHub Issues about the problems Pleco.rs currently faces, or things that need improving! One of the biggest problems is implementing a multi-threaded search, in a way similar to that of Stockfish. A large part of Pleco's source code is a direct translation of Stockfish (written in C++), so perhaps looking at the Stockfish code to look of similar ways to implement threading might be useful!
deleted ^^^^^^^^^^^^^^^^0.0822 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/65340)
&gt; but what does this mean for getting an associated type of an associated type? Nothing, associated type of an associated type falls under the unimplemented common case `ArbitraryType::AssocType`.
How can you mix and match code across epochs?
Isn't that how it works in other languages too, without problems? (C# IIRC)
deleted ^^^^^^^^^^^^^^^^0.6414 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/24531)
Too verbose, frequently occurring keywords should be short according to Huffman.
Yeah, I've discussed this a few times with people, and I still believe that changing pub to public would make Rust code easier to read, even though it makes signatures a few characters longer. I'm just glad we changed ret to return before it was too late. 😁
How can you do data-binding with the inline html in custom elements? Do you plan to integrate something like Maud/JSX? Will there be a way to auto-mount all custom elements implicitly?
You can't mix them in a single crate, but you can compile crates from every epoch together.
You're using a bad library in that case. Complain to the author, fork it, and make it return or send a Result instead of panicking.
It would be really nice to see a real life library ported to this new system. The consequences of major changes like this are hard to understand.
Isn't there at least some software that you wish existed but doesn't? Write that! In the process you will learn a lot by looking at projects on github, asking question on IRC and using a lot of existing crates and then you will naturally start contributing to those crates... The strongest drive comes from necessity.
For the macros I use, there will be a lot of hand code need to be done for that. But it can be done via the `html!` macro. Which will end up required building the whole templating engine like handlebars, I think.
It's more like a proof of concept than the final design that will become a fully working framework, and it's not a standard web component, there will be a lot of works ahead. I'm still trying to find time to finish it up.
My favorite part about this framework is that it focuses on sticking to the Stable branch.
Personally, I use Rust because it has a monopoly on safe, static memory management. There's no background runtime running just to clean up my pointers, and yet it's as safe as if there was. My biggest complaint with Rust is that it's a monopoly. I want more options for safe static memory management! That and the fact that LLVM doesn't support RISC-V. :(
I've been working on a [serial key generator](https://github.com/whostolemyhat/serial-key-generator) - it creates a serial key from a seed which can then be verified or partially verified (it's a port of [this article](http://www.brandonstaggs.com/2007/07/26/implementing-a-partial-serial-number-verification-system-in-delphi/)). Any thoughts on the code would be appreciated! My next step is to move the functionality into a library crate and stick it on Crates.io.
Have to agree with you, but citing huffman is really funny! He's mostly famous for writing dense bit sequences that are quite hard to read at glance.
https://github.com/Lokathor/dream-delver Roguelike stuff. Using collections in Rust is a pain. Right now I'm not exactly in a direct fight with the borrow checker... it's more like I know exactly when it's going to say "no" ahead of time and I'm not even going places that I know its going to lurk. I think my way forward is to write something like the following: /// Makes a HashMap of mutable references to all the values pointed to in the mapping by the keys specified in targets. /// /// If any key at all is missing, you get None instead. fn grab_keys&lt;'hm,K,V&gt;(mapping: &amp;'hm mut HashMap&lt;K,V&gt;, targets: &amp;Set&lt;K&gt;) -&gt; Option&lt;HashMap&lt;K,&amp;'hm mut V&gt;&gt; { // TODO: unsafe code involving get_mut and casting into *mut and back to kill the lifetimes goes here } And once that's working, generalize it to slices as well via some sort of CanLookupKey&lt;K,V&gt; trait that [T] implements for &lt;usize,T&gt; or something like that.
I love the Elm approach and Rust. So what's not to like about this? :)
And what is 'the infamous borrow mut error' that the article refer to?
You're acting like there's a world in which bugs won't exist.
One large one for me would be input for a pre-processor. Right now I can have an `src/in/` directory with files named `*.rs` for editor highlighting. None of these files are of course included in the project, only read by `build.rs`, output, and included via `include!()`. I think it's a fairly common practice for "fake" compiler plugins using `syntex` for running on stable rust.
Could be, but I'm not a "good student". Instead of meticulously reading the book, I just started writing code and reading only when I hit the wall. 
deleted ^^^^^^^^^^^^^^^^0.9286 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/08907)
I think my main concern with this is that it really makes the module system more complicated, rather than simpler. I'll try to write out a full comment once I've read everything already commented, but this is my main reasoning: Right now, there's a bit of convolution. Yes, `use` statements are absolute, and code is relative. Yes, we explicitly list modules. But everything's consistent, and everything has one purpose. `pub` exposes things to parents, and treats modules and crates equally. This RFC will add a large rift between modules and crates. Maybe it's justified, but in current rust it's _nice_ to be able to say "hey, when you want to publish your first crate, just think of it as a module in someone else's code - visibility works exactly like the module added to your code". It's _nice_ to know that pub is always "expose to parent". Yes, it makes it harder to tell exactly what a crate's public API is - but that's why we have `cargo doc --open` and http://docs.rs/, both with extremely accessible searching. With relative/absolute stuff, there's a learning curve - but it's a simple concept. Imports are absolute, code is relative. With this, we have `export` added, which is.. an import? or export? and even though it's listed with `use` and other absolute-things, it is relative to the current crate? I feel like this RFC is sacrificing simplicity and consistency for a better experience for the "average user". Perhaps that's a good thing, but I can't help but feel sad for the slow death of purity rust had at 1.0.
deleted ^^^^^^^^^^^^^^^^0.8675 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/14658)
deleted ^^^^^^^^^^^^^^^^0.9931 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/73342)
&gt;C++'s middle ground is still not safe, and doesn't really buy much over raw pointers to make this worth the trouble. I never said it was safe. I said it was *safer* than ```*```. you should only have to think about lifetimes if you're doing something complex , storing temporaries or passing them in a nontrivial way. Most of the time C++ references are not a problem. they're for passing arguments in. In rust it still takes extra syntax to acheive this in some scenarios. In time the tools might improve such that you don't have to manually think about lifetimes so much (e.g. imagine something that would figure out what the annotations should be from given use cases). Most of my lifetime use is simple (I explain this in another post). &gt; unsafe operations are not default and have long names but someone still has to write the unsafe code. It's like we'd keep C as a language optimised for unsafe code. It should be possible to have both scenarios supported equally easily, because we are already explicitely marking a point where you switch. &gt; ad-hoc overloading: this is basically the origin of C++ bad template error messages I have another idea to tame error messages- using version control (which all serious people use). Filter the errors by the lines you actually changed. ('this line causes this error ending here ...'). (and yes I would actually like an IDE that automatically commits a temporary version as you're working.. many tools have a form of 'autosave') if the error is still too difficult to comprehend, *go back and put more types/bounds in*. I never said I wanted to *eliminate* the bounds or types, just make them *optional*. I find myself needing to write a lot of single function traits, and I think that points to room for improvement. I've tried to translate the kind of templated maths code I'm used being able to doing into Rust, and the bounds become **unmanageable** - you get to a point where you're basically re-writing the program an arcane angle-bracketed form, and it's literally a 5:1 ratio between the bounds and the implementations. In the C++ scenario, we can write our code with a concrete type (getting full error messages), then stick 'template' infront of it to generalise. we can even use a #define to switch back and forth. &gt; At some point, you know those names, a Doesn't matter how experienced someone is, learning names takes time. People are going to have to go back to C++ or other languages (rust will never be the one language for everything); carrying around more names for the same things in your head is an impediment. The job of computers is to save us time with intellectual tasks and that should apply to the tools we use within computing equally. I find heavy name use within a language is also an impediment from the problem domain. It's distracting. (again jonathan blow makes a great point that wrapping the pointers in with the 'type that you're thinking about' inside brackets costs a lot more than you might think. The sigils were **PERFECT**) &gt; but I doubt that they will remove much angle bracket usage because lifetimes parameters but they will definitely reduce the amount that goes in each angle bracket, again especially at the moment with the *bounds*.. &gt; global-type-inference: Rust is designed so that one can reason about code locally, global type inference breaks this. There's times when you write code that works, then you extract a function and name it, but it's still not used by other modules. *Why shouldn't this scenario allow global inference?* There's cases where they say 'use a macro' but it's less ergonomic because the macros have a different syntax. Jonathan Blows videos explain very well the concept that code has a maturation cycle, you move things between scenarios, and requiring syntax changes wastes time for no benefit. &gt; It is normal for newcomers from C++ to find things like these annoying at the beginning, but as their experience with Rust grows I wrote stuff with rust back in 2013. I launched into it with great enthusiasm; Then I ran into these frustrations but worse than that, they removed the sigils and do notation. I've looked at it on and off. I've come back to it to see what has changed. If the long and short of it is "safety is achieved through greater markup" there's no point switching. We can do that in C++, and we can retrofit static analysis. (even lifetimes could be annotate with a 'smart reference'). Yet I know it should be possible to improve on C++, with greater elegance *through* features like the better type inference and various syntactic tweaks.
When you write MyStruct { field1: value1, field2: value2, .. otherStruct } it initializes `field1` and `field2` with given values, and uses remaining values from `otherStruct`. `otherStruct` must also have type `MyStruct` and is consumed. In this case `..Default::default()` is used to initialize fields `left` and `right` to `None`.
sorry for the confusion on stable usage, been a while since I tried Relm :D Keep up the good work, for me Relm has the best approach on GUI for Rust!
Is ... is this essentially a blog bulit as rustdocs? &gt; Yes, this is a slightly crazy way of building a show notes site for a podcast. See e001: Document all the things! for more details. I'm impressed. I have toyed with the idea of a blog as a repo on Github, with issues for comments, but this is a whole other level.
I used to be one of those who had problems with understanding the module system. My issue was that instead of reading the manual, I tried to learn my usual way - by writing code and poking around. And since things weren't quite like I was used to, a lot of confusion emerged. But in the end I read the book and everything was crystal clear. I think the current module system is perfectly logical and simple, even though a little bit verbose and repetitive. At the same time it is also very flexible. I am not sure whether this new system is simpler and as logical as the current one. I can certainly see its ergonomic advantages though.
The https://news.kipalog.com/ looks great and looks to be a clone of hackernews but without the comments?
This would be great
Thanks. It’s kind of hacker news with automatically RSS crawler. And yes, without comment :D 
Great post! How do you compare the experience with Golang for the web? Is there any benefit of using Rust over Go for web development?
I'm guessing that's when [borrow_mut panics if the value is currently borrowed](https://doc.rust-lang.org/std/cell/struct.RefCell.html#method.borrow_mut).
Thank you. Go is easier to get started, especially for the web. But Rust is more fun to use. I personally prefer the crates eco system. The only thing I missed from go is the great design of goroutine. 
deleted ^^^^^^^^^^^^^^^^0.8827 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/35609)
&gt; Perhaps things have changed, but last time I tried using X11's API directly, there were lots of things demanding that they should only be called from the "main thread" or that I should ensure proper synchronisation as X11 doesn't. Might also be that I just remember incorrectly. You need to jump down a layer of abstraction. :-) When I said I wrote a client, I meant that I wrote it from scratch. There's no dependency on Xlib or xcb, for example. You can see it here: https://github.com/BurntSushi/xgb --- At that level, the only restrictions on multi-threading are the restrictings that you yourself build into the client. For xgb, you can freely use an X connection from multiple threads simultaneously. &gt; That's why we should start rather early. Perhaps even start building on nightly as all the nightly stuff will eventually be stable. We have GTK-rs and some Qt trickery now, which work pretty well, but not a Rust-y thing. &gt; Besides: We might have a little development boost thanks to existing projects providing us with their years of experience. I'm not arguing about whether some group of people should or shouldn't build a pure Rust GUI toolkit. I'm arguing about what should be the official objectives of the Rust project. The OP of this thread said, "GUIs in 2018." That *ain't happening*. No way no how. :-)
`Default::default()` is a call to the [`default()` method](https://doc.rust-lang.org/std/default/trait.Default.html#tymethod.default) of the `std::default::Default`trait in the standard library. You'll notice `Tree` derives from `Default`, among other traits. This is why. Rust is able to give you a, well, *default* implementation of this method if you don't provide one yourself. The `..` is the so-called [update syntax](https://doc.rust-lang.org/1.6.0/book/structs.html#update-syntax) which says "assign all the other fields I'm not giving you by copying from this other struct". So basically you are telling Rust to use, for fields you haven't specified, the values of a fresh instance returned from `Default::default()`.
I'm confused about future-rs. I would like to convert a function into a future that is run later (lazy), so that I can control how many instances are computed at the same time. How to convert `do_something` into a lazy future? fn do_something(user: String) -&gt; String { use std::{thread, time}; thread::sleep(time::Duration::from_millis(500)); format!("hello, {}!", user) } ... I hope I understand it correctly, that a lazy future is needed here.
`KeyCell` has undefined behavior when one calls replace or set while a borrow from get exists Nor is it threadsafe to impl Send/Sync for CoalescingRingBuffer Unsure why you feel compelled to have so much unsafe code
&gt; It means that any "general" model that wants to check access to uninitialized memory by tracking memory access at the byte level at run-time doesn't really work in practice. We don't have a solution for doing this in compiled binaries (though TBH I don't know if there's a deep reason for this). However, in miri, this works just fine: We track for every byte of memory whether it has already been written to (and hence initialized) or not. &gt; Is this enough to be able to check for UB at run-time? E.g. if an ABI boundary returns a MaybeUninitialized&lt;T&gt;, an interpreter has no way of knowing whether accessing its contents is UB or not, or what am I missing? (I would expect MaybeUninitialized to be an enum, not an union, to allow such a check. I need to reread arielb post again. The interpreter knows not just the type, but also the value passed around. I don't see the problem here. If a function gets a `MaybeUninitialized&lt;T&gt;` from somewhere, and then returns the inner `T` to somewhere else, that outermost caller will detect the problem when validating if this is really a `T`, which in particular checks (not yet completely implemented) whether all non-padding bytes are initialized.
deleted ^^^^^^^^^^^^^^^^0.7159 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/80039)
I need an explanation of what is a bound lifetime parameter and a concrete lifetime, I search it online but couldn't find a proper explanation just examples that are hard to read. The error I'm having is the next (probably is a common problem): the requirement `for&lt;'de&gt; 'de : ` is not satisfied (`expected bound lifetime parameter 'de, found concrete lifetime`) --&gt; src/handlers/warehouses_handler.rs:26:23 | 26 | warehouse_handler.create(req, Warehouse::create) | ^^^^^^ | = note: required because of the requirements on the impl of `for&lt;'de&gt; serde::Deserialize&lt;'de&gt;` for `models::warehouse::NewWarehouse&lt;'_&gt;` = note: required because of the requirements on the impl of `serde::de::DeserializeOwned` for `models::warehouse::NewWarehouse&lt;'_&gt;` ) 
Yeah I saw Rust is a little bit hard to understand. Do you think that node.js (with it scripting nature) is more expressive &amp; productive compare to Rust and Go (strong typed nature) in web development? eg JSON is natural to Javascript. I would agree Rust/Go is a clear winner in the area where performance is critical though
deleted ^^^^^^^^^^^^^^^^0.9083 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/11319)
The update mentions that models have been moved inside the `Widget`. Is that true for all Widgets? The [relm intro](http://relm.ml/relm-intro) and examples still seem to use separate models. Any chance you could make a quick checklist of what someone using pre-0.10.0 should need to update?
deleted ^^^^^^^^^^^^^^^^0.4882 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/18024)
[removed]
deleted ^^^^^^^^^^^^^^^^0.2754 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/87653)
As a tool-o-holic, you have my thanks for making this :D
I'm playing with domafic at the moment and would recommend it. I combine it with the webplatform crate for things like access to localstorage. 
I can see LLVM being hard to turn into good C. For reference on the [removal](http://releases.llvm.org/3.1/docs/ReleaseNotes.html#whatsnew): &gt; The C backend has been removed. It had numerous problems, to the point of not being able to compile any nontrivial program. It looks like Julia did some work to [resurrect it](https://juliacomputing.com/blog/2016/03/10/j2c-announcement.html) but its been [stagnant since then](https://github.com/JuliaComputing/llvm-cbe). I imagine the better approach would be to convert MIR to C. That might also make the C code more human readable / debuggable. Someone else [brought up transpiling in the past](https://internals.rust-lang.org/t/should-it-be-possible-to-translate-transpile-a-rust-program-to-c11/3183). The only concerns discussed are aliasing.
The relm intro was the first blog post written a couple of months ago and was not updated. Could you tell me which examples still use the separate models? (By the model is moved inside the Widget, I meant that there's a field for the model inside the Widget, but the Model struct still exists.)
I decided to open it up. Its very rough in some parts. I also was halfway through attempting a custom boot rom so I wanted to finish that before opening it up. Anyway, its here now if you're interested: https://github.com/simon-whitehead/chemboy Hope that is interesting enough for you :) It's still highly a work in progress! :)
Ah, this touches on something I've been thinking about. I worry a little bit about how the development of rust being so "democratic" interacts with overrepresentation of certain groups. In particular, as a reader of HN and reddit, a web dev, and someone originally interested by the "ruby crew" of Steve and Yehuda, the aspects of rust that would be most directly interesting and useful to me are the async server stuff and Diesel and Rocket/Gotham and what have you. And I think there's a lot of us here, simply by virtue of who reads HN/reddit. However, the thing that *most* excites me about rust is the potential of *other* people replacing low level C/C++ code with a safe language. But I don't know anything about that really. As such, I'm reluctant to participate in any aspect of rust development: RFCs, the rust user survey, even commenting about it here for the most part. I worry that any change that makes things better for *me*, might turn off the "real" intended users. Even little bikesheddy things like tabs vs. spaces; as a ruby programmer, I'm accustomed to 2-space indents, while I think a lot of C programmers are used to maybe 8 spaces? What should `rustfmt` do? Or my experience with modules and package managers leaves me comfortable with bundler, npm, or elixir's hex; so I'm fine with listing my dependencies in cargo and then `use`'ing them right in my source files. But maybe C/C++ programmers *expect* an `extern` and are confused by not having it. If that's the tradeoff, I think we should be favoring the C/C++ folks' expectations. Or what about the JS ES6 syntax for objects with the same key as variable name: `{foo, bar, baz}`? I could have sworn there was an RFC for something like that in rust, but I can't find that now. _I_ like that, since it's something I'm used to, but I imagine more explicit low-level programmers might not like it. Of course, I just notice all the changes that resonate with me, since I'm looking out for them. Maybe there are other changes that resonate strongly with C/C++ folks, and I just don't realize it since I'm not sure what to be looking out for? Off the top of my head, I think "placement new" (whatever that is), is a change like that, but I'm not sure I've seen any progress on that front. Maybe others?
How does cargo use the `~/.cargo/registry/index/github.com-.../` repositories? I thought it would pull the latest changes every time you call `cargo update` on a project, but a `git log` inside these directories shows they're months behind the actual crates index. Yet `cargo update` still finds the latest versions of the dependencies.
Yup! RefCell moves borrow checking from compile to run time so if you're not careful and have two mutable borrowed the whole thing will panic and crash.
little off topic but i when i saw the title i was hoping for pleco app for other languages... there is a chinese learning app with same name
It's mostly the same as in rust, since you still need wrappers.
That doesn't sound like any concrete limits to me. But anyway, with the ability to remove and add syntax, there's the ability to add and remove features. Like with this, explicit module specification is no longer allowed. I'm pretty sure at this point that `ref` will at some point no longer be allowed and patterns are going to change. There's some plans in the works to complete change lifetime and reference syntax. My worry is that in 10 years, Rust could look and work quite differently to what I was really happy about in 1.0.
Webplatform looks cool! Is the [js! macro](https://docs.rs/webplatform/0.4.2/webplatform/macro.js.html) something like inline js?
Thank you for the explanation. This sounds *way* too complicated, am I imagining it?
I do it constantly during prototyping and refactoring. I comment out lots of things, structs, implementations, parts of code, and whole module trees. In one toy project, I had a submodule that itself had around 10-15 submodules in a nested fashion. While working on another part of the tree that this one uses, I just comment out the root module, iterate until the tests pass again, then go through the deep module tree. It's one of my very basic workflows. This makes for a fundamental change in how I develop Rust, and makes it more unergonomic to me. Edit: Another one, during initial development, I work on some module tree, but notice I'll need something else, and the current tree doesn't work yet. So I just comment out the module tree, work on the other stuff, add tests, and when I finished take the in-work prototype tree back in and continue witht that.
Unless I'm missing something, looks like [the button example](https://github.com/antoyo/relm/blob/master/examples/buttons-attribute.rs) at least. Are you looking at a similar updated intro? The original was very helpful when I was trying to understand Relm. Edit: I'm dumb. There's still a model struct, but now it's inside the Widget struct?
[This poll](https://internals.rust-lang.org/t/poll-which-other-crate-relative-path-syntax-do-you-prefer/5744) lists pretty much all of the ones that came up.
/u/nasa42 QOTW in the "I can program Rust while drunk" paragraph.
So I haven't used Rust for the web, but I have used both JS &amp; Go. JS tends to have a lot less friction. So you need to be more diligent on how you structure your code, writing solid tests, etc. But it does allow you to move quickly. Node while not having a true concurrency model, does things pretty quickly. Some folks I work with had to change a client's rails app to be re-written in Node due to a lot of memory consumption issues. With Go, it does have fairly minimal friction to do small things in. You can be pretty productive there as well. What I found challenging though was working in a large project with it. We had to do a code generation in order to reduce manual duplication of our code that implemented database models. This really came down to the lack of generics in Go. We also got bit by the lack of versioning a couple of times in the go dependency management.
Yes, it is now inside the widget struct, as you can see in [an example](https://github.com/antoyo/relm/blob/master/examples/buttons.rs#L55) not using the attribute. When using the attribute, the difference is that you don't need the model argument anymore, since it can be accessed from `self`. For the updated intro, you can look at the updated readme until I update it.
I was excited to see a new episode. I found New Rustacean (as a new rustacean) just a few weeks ago. Listening to the backlog gets you spoiled when the reality of real time episode release schedule becomes the norm. :)
A very interesting article. The only part I take issue with is: &gt; After all, everything is more readable than assembly I've seen well commented assembly that was an absolute *joy* to read. True, it sure took considerable effort to write, but it's not impossible, as the article suggests. On the other hand, I've seen Java code that would lead you on wild goose chases with delegates over delegates of proxy objects, untold horrors lurking behind the façade objects (this was roughly a month before I quit my consulting job). Moral of the story, it's the code, not the language that determines if it's readable.
Interesting read. Why do you think a mutex for sender makes more sense for sharing? let (tx, rx) = channel(); let tx = Mutex::new(tx); Server::http(addr).listen(move |req, res| { tx.lock().unwrap().send("request!"); }); It typically is cloned when necessary. According to the general consensus, Copy is only for things that have no computational overhead. I agree that it's annoying, and I think something should be done about it on some level. let (tx, rx) = channel(); let tx_ = tx.clone(); Server::http(addr).listen(move |req, res| { tx_.send("request!"); });
deleted ^^^^^^^^^^^^^^^^0.4520 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/46316)
 #include &lt;cstdio&gt; #include &lt;vector&gt; using namespace std; struct Node { int w; Node *p; }; Node* get_root(Node *n) { if (n-&gt;p == NULL) return n; else return get_root(n-&gt;p); } int main() { vector&lt;Node&gt; nodes; for (int i = 0; i &lt; 5; i++) nodes.push_back(Node { i, NULL }); for (int i = 1; i &lt; 5; i++) get_root(&amp;nodes[0])-&gt;p = &amp;nodes[i]; for (int i = 0; i &lt; 5; i++) printf("%d", get_root(&amp;nodes[i])-&gt;w); } we declare simple node struct, it has weight and parent. a get_root function to get the root of a node. the output of the printf of course `44444`. how to implement the code above in rust lang? thanks
Redesigned a bit of the backend on [lichen](https://github.com/viperscape/lichen), an interactive story DSL. The code was unmanageable from my point of view and so I had to remove the quasi ffi I built up, and as such the rust traits are now defunct. I'm still investigating a better way for the script to interact with rust data, but for now it exists as function [closures](https://github.com/viperscape/lichen/blob/master/tests/state.rs#L48) that you submit to the environment before evaluation, which makes it possible to manipulate [external data](https://github.com/viperscape/lichen/blob/master/tests/state.rs#L144-L153) directly-- albeit in a tedious fashion. Ultimately, I want to use this in a MUD of sorts, where anyone could upload stories to be played interactively.
Hello I had some problems running relm 0.10.0 . First I cannot run the examples using stable rust, it seem that you haven't removed the `#![feature(...)]` line in `relm-attributes` Then I tried to move the `clock` example to a separate crate. It compiled fine but then crashed: "thread 'main' panicked at 'Glib has not been initialized. Call `futures_glib::init` first.', /home/qwe/.cargo/registry/src/github.com-1ecc6299db9ec823/futures-glib-0.2.0/src/interval.rs:19" My configuration, using `futures-glib 0.1.0` is fine, but 0.2.0 broken: relm = "0.10.0" relm-derive = "0.10.0" chrono = "0.4.0" futures-glib = "0.2.0" gtk = "0.1.3"
I thought the idea was it uses an existing protocol, so you could in theory drop in something like [this emacs plugin](https://github.com/emacs-lsp/lsp-mode).
Well, if you want to use `relm` on stable rust, you cannot use the `relm-attributes` crate: you instead need to setup your code like in [this example](https://github.com/antoyo/relm/tree/master/examples/buttons-derive) if you want to use the `view!` macro syntax. I'll look at the issue with the clock example. **Edit:** The clock example works for me. Try running it with `cargo run --example clock` from the repository. From what I can see from your error, it looks like you're missing a call to `futures_glib::init();` at the start of your `main` function, but it should not be needed since it is called from the `run()` method.
What does blockchain have to do with the web? Or MaidSafe? Or SSH host signature verification? All three of these are crypto at the core. Not "web". Chef/Habitat are infrastructure. Faraday is also crypto and infra. You're talking about where the code ultimately gets used. I'm talking about the _type_ of code, which is far more relevant to this conversation. You're categorizing "anything that makes network connections" as web. Guess what. The majority of things out there do now. 
from the article: #![no_std] #![feature(lang_items, compiler_builtins_lib, core_intrinsics)] use core::intrinsics; #[allow(private_no_mangle_fns)] #[no_mangle] // rust-lang/rust#38281 #[lang = "panic_fmt"] fn panic_fmt() -&gt; ! { unsafe { intrinsics::abort() } } #[lang = "eh_personality"] extern fn eh_personality() {} As someone who has been following the push to make Rust viable for microcontrollers, I would like to submit this as further evidence to the Rust core team that we **need** to stabilize more low-level features. Inline assembly should also be at the top of the list. This `rustgo` effort is really great, but there is a zero percent chance I could convince my Go-oriented company to depend on Nightly Rust. I know the article itself says not to use this for production, but I would say that `rustgo` looks to be over the 50% mark on its way to production usability, even with lots left to do.
In that case I really can't take your arguments seriously at all, because you seem to be classifying things on whether they touch the internet at all, which has nothing to do with the _kind_ of code being written. I _highly_ doubt this is the impression C++ devs have of Rust. I can understand folks getting that impression around all the talks about Tokio, but not from this absurd metric of yours.
`internal`? That's how it works in C#.
deleted ^^^^^^^^^^^^^^^^0.4722 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/92917)
Interesting, I get the same 404 when using `curl`, but it works fine in Firefox (and probably Chrome). It looks like it assumes JSON when `Accept: */*` is given. A quick check shows that it works on Edge and IE, so it may have been a temporary problem that is now resolved, or perhaps it still happens on one of the hosts. I can reproduce this pretty reliably by going to crates.io in Firefox and using "Copy as cURL" to paste it into the CLI. Unmodified it works fine, but if I replace the `Accept` header with `*/*`, it gives the 404 JSON response.
&gt; Nobody knows what most C++ devs do, I used to be a C++ dev. &gt; you are basically excluding anybody who doesn't work on anything web/internet related. No, I'm not. I'm not excluding anyone, but I'm choosing a "works on non-webby things" set much larger than yours (which includes yours), because I'm looking at the _kind_ of code involved (which is the actually important metric). You are excluding at least three startups who do crypto work just because it also touches the web; and crypto is a _major_ bastion of C. Anyway, I'm not really interested in continuing this discussion further, because you seem intent on phrasing it as an us vs them thing I don't want to get involved in.
I think the problem here is that the lambda passed to `listen` must be `Sync` because it is shared among multiple threads in Hyper. You can put blame on Hyper and claim that it must provide a better API, but that is debatable. In any case, if `Sender` implemented `Sync`, issues like this one would be trivially solved.
So this is happening already. The short version is that `#![no_std]` is great if you're building a regular rust lib. It is not great for `staticlib` or exe crates. Which you kinda need at the end. So yeah, not great right now. https://github.com/rust-lang/rfcs/pull/2070 fixes this. &gt; Inline assembly should also be at the top of the list. This is tricky. The exact syntax for inline asm (including supported instructions, clobbers, etc) is not stabilized in _any_ compiler, just that rust doesn't ship unstable things. We could define a syntax but there's no guarantee llvm will keep supporting it. But it could be done, even just stabilizing what we have (or one layer of abstraction above it) would be nice, and reasonably good because clang won't really break itself. 
I have to admit to having worked on a recent Rust PR while drunk, and promptly produced a typo. It was easy enough to fix while sober, though. 😌
I also think that you are much less likely to underflow/overflow if you have a signed index. I mean, on a 64-bits platform, it takes some effort to underflow/overflow `isize`! However, underflowing `usize` is a walk in the park: `current - 1 + offset` will underflow if `current` is 0 regardless of how big `offset` is :(
First, it “just” arrived a new excellent sharp and versatile tool for crate organization: the `pub(crate)` and `pub(`et. c.`)`. We should try to use that for the most possible. I'd rather get less features in excange for more backwards compatibility when it comes to module redesign. I'd like to have a system that - Uses `pub(..)` and `use` for everything - Introduces no new keywords - Deprecates at least `mod`, maybe `extern crate` too - Lays out the module tree automatically - But only if they are `use`d; don't pull in files that are not used - Is backwards compatible to a high degree. Obviously such a thing needs working out, and I understand that the real proposals have been worked out, so that they actually work. An RFC is the time to find the best possible solution that ticks as many boxes as possible. Asking for the impossible is a consequence of asking for an excellent solution... Just have to dream, try to build it, and find the best compromise.. 
Thanks for the answer. It's interesting that I actually disagree with most of the proposals, I wonder now if it's because I have been brainwashed :D
Will do! I already peaked around what/how chess engines work and I can definitely tell they are quite the task to take on. I'm super interested in helping where I can.
People keep saying 'be explicit because code is read more than it is written'.. But when code is read , we have the additional benefit of tools that can assist. We're not reading things on plain paper printouts anymore. I like the fact Rust hs CFG which should allow *better* tools than we have in C++. Overloads don't worry me because I take 'jump-to-def' for granted. Some overloads got abused due to other limitations (e.g. few operators so they use + for concatenation, &gt;&gt; for streams.. yuk), but new language features provide assistance (e.g. now we have variadics, we could easily have an n-ary "```concat(...)```", "```file.write(...)```". I would probably like a haskel-esque binary ++ . Can't be as shocking as suddenly associating bit shift with streams. (I might accept the loss of overloading more if we got currying) Surely having the internet enables building consensus on the meaning of function names. module based name spacing is still 'hierarchical'. overloading is giving an open graph-like organisational ability. I do actually like the way traits are shared between generics and 'external vtables', but I think you should still be able to use types to identify things. (leveraging the naming work you already did) It Might be worth me waiting for C++ Concepts, because retrofitted withe backwards compatibility I'll get the best of both worlds. I dont get why people object to the haskell-inspired idea ('if we write the trait name we can elide the types') Make better tools to locate the repeated information (and in turn expose other emergent structures in your codebase)