I tried to look for the writer used to write on stdout, but struck out. It's abstracted away and I could not find the caller (probably somewhere in the runtime...).
I agree there is no shame dropping Windows XP support. But dropping Windows Vista support seems a bad idea to me since it is still supported by Microsoft. 
`rustc` already doesn't work on Windows XP. However support for running programs built by `rustc` on XP was recently added, although a few fallback implementations need to be added for some of the concurrency stuff.
&gt; And if there's a use case for that, can't you rely on the usual null-pointer optimization to make sure Option&lt;Shared&lt;T&gt;&gt; and Option&lt;Owned&lt;T&gt;&gt; are represented as nullable pointers? Having thought about this for another five seconds, the problem is that if `Atomic` is non-nullable by default and you do `Atomic&lt;Option&lt;T&gt;&gt;`, you won't end up with `Option&lt;Shared&lt;T&gt;&gt;`, but `Shared&lt;Option&lt;T&gt;&gt;`, which is *not* null-pointer optimizable. So it seems like you'd need separate `Atomic&lt;T&gt;` and `OptionAtomic&lt;T&gt;`. Whether the API duplication is worthwhile is open to debate.
That's *could* for you. ;-)
Couldn't you just map the input indices to lie on a range with no gaps? (if you ever need the original indices again you can map them back, since the map would be a bijection)
There you go (`allocator` is still experimental, mind): https://github.com/economicmodeling/containers ^ A company using D in production has made a small collections library using one of the experimental allocators.
Was actually released two weeks ago (17 Aug 2015) but I only saw it just now and thought it might be of interest to you since Rust uses jemalloc by default. This looks like a nice feature for example: &gt; Refactor huge allocation to be managed by arenas, so that arenas now function as general purpose independent allocators. This is important in the context of user-specified chunk allocators, aside from the scalability benefits.
That's what the hash map is for.
Is it the jemalloc part that makes rust incapable of generating non-sse2 code on 32-bit x86? 
Huh? Why would you not want SIMD?
Well it kind of does, it's a very open data structure to allow all kinds of graph use cases. You can add the required number of nodes up front, and then address them directly using `NodeIndex::new(usize)` if you want to. But sure, it can't have any holes in the range of node indices. Edit: By the way, it would be cool if there was some way to use a Node label map automatically with the Graph, without making it mandatory.
This release adds sized deallocation, but that's something rust has used for a long time now. Checking history, turns out a long time is exactly 1 year. Strcat contributed it to jemalloc in august 2014. Nice.
For example for running on pre-SSE2 systems?
Nope, it [uses](https://github.com/rust-lang/rust/tree/0dbbab904916236d59446b9f51944a057e7b9966/src) a fork of version 3.6.0 which was [last updated](https://github.com/rust-lang/jemalloc/tree/e24a1a025a1f214e40eedafe3b9c7b1d69937922) in March to add some additional patches.
Periodic dump to disk: it's easier to do this with a serialization libraries (serde, rustc-serialize, capnproto, etc). Regardless of the data structure you use to store the data (this would work with a STM library but also with your current scheme). That's because those libraries can auto-derive the serialization/deserialization implementation, saving tons of effort.
Async file I/O doesn't exist in robust ways on most platforms, which is why it's out of scope for mio. You need to do it with sync I/O in a threadpool to not drive yourself insane.
This is the same realm as Rust having Windows Vista support: small market share. Pretty much every x86 computer sold in 2004 or later has SSE2 capability. (Intel Pentium 4 and AMD Athlon 64 were the first products for each platform). 
Let it go. :P
Windows 8 is the first Windows OS to require SSE2, so as long as Windows 7 is supported by rust SSE2 will have to be disabled.
No, that's a conscious decision on our part - the default 32-bit x86 targets assume the presence of SIMD. You can add a custom target (using [target specifications](https://github.com/rust-lang/rust/blob/master/src/librustc_back/target/mod.rs#L11)) which doesn't use SIMD.
Without a stage0 snapshot (non-SSE2) provided exactly for that purpose it won't work. What would the target triple need to be to build such a cross-compiler?
Why not use TOML instead of YAML?
Windows 7 support doesn't mean it has to support all Windows 7 targets.
But it is a compelling reason.
I assume there's nothing stopping us to jemalloc-upgrade when there's enough man-hours available.
&gt; Spring framework for Scala I think Spring is mainly targeting java, and is itself written in pure java. More scala-ish frameworks are `liftweb`, `playframework`, `scalatra` etc.
So to really support Linux you also have to support [all of these platforms](https://en.wikipedia.org/wiki/List_of_Linux-supported_computer_architectures#Releases)?
I suppose it's a matter of priorities. Maybe enabling sse2 would be the right decision.
If I remember the RFC about this correctly, that's because `!` defaults to `()` in these contexts, which doesn't really make any sense. The fact that the middle line doesn't compile seems right to me: there's no way to tell what the type is (playpen is timing out for me but I bet it would compile with an annotation for `_y`---ETA it does). The fact that the third line *does* compile strikes me as pretty weird.
This reminds me of parts of cap'n proto. I was looking for people who have done FFI using XDR as an intermediate but it does not seem very popular. It may be convenient for defining common interfaces. I made a [project](https://github.com/waynenilsen/capnp-ffi) a while back doing FFI with Cap'n Proto defining the interface. I think that I will try the same concept with XDR
http://manishearth.github.io/rust-internals-docs/syntax/ext/base/enum.SyntaxExtension.html#variant.MultiModifier is about all there is. Syntax extensions are possibly the hardest thing to be anywhere close to stable, so there's essentially no documentation at all.
My point of reference is C++ templates where nothing needs to be set in stone until concrete instantiation.
Also, the Pentium M and Pentium III-M are two different sets of processors, separated by two years. They were released in about 2003 and 2001 respectively, so I'm sure they don't get much testing.
How would `K` be picked? If someone calls `pancake` on a `Thing&lt;Vec&lt;u8&gt;&gt;`, will it be `usize` or `RangeFull`? Should rustc pick the one with the lowest hash value? You must provide a way to figure out the values of the impl parameters from the requested trait reference. Even if impls were dynamically-typed, it would just mean you would get a C++ error message when you actually tried to use it. You should make `K` a parameter to the trait or the method.
That [was on the to do list](https://github.com/kbknapp/clap-rs/issues/81), but when I wrote out an example `cli.toml` it was super clunky because TOML (IMO) just isn't set up to nest very well like YAML does. So it's not that it's not possible, its just that it's limiting and awkward. If someone comes up with an implementation and wants to submit a PR, I'm more than willing to take a look and merge if it works! 
In the version where pancake calls index on [0] it would be usize and if pancake accepts a variable of type K it would use whatever K client code uses (at compile time). If it's not exercised enough for the distinction to matter, it shouldn't matter.
If pancake just calls sizeof? Anyway, that's not how Rust works. function bodies are type-checked independently. Generic function in Rust are type-checked generically - no assumptions on the type parameters are done other than these encoded in the function's signature. When the functions are compiled, the type parameters *in the checked code* are simply substituted with the values you specify. This can't cause type errors. This is how Rust works and is *very* unlikely to change.
I'm happy to answer questions about this project here. I'm very interested in helping people contribute to and use *ring*.
My interest in this driver is mainly historical. Back in Rust 0.7 the MongoDB folks made what was possibly the first Rust database driver ever: http://blog.mongodb.org/post/56426792420/introducing-the-mongodb-driver-for-the-rust . For language historians like me it's simply fascinating to read through each and see how far the language has evolved in its features and idioms (if nothing else, take a look at the code examples in that link and marvel at such long-lost gems as `do spawn` and `for 25.times`).
&gt; What features of BoringSSL were excluded from ring? The major things I removed were the SSL/TLS support, the X.509 certificate support, and the ASN.1 support. I also removed many other smaller things. You can get a good sense for the stuff that was removed by looking at the commit log: https://github.com/briansmith/ring/commits/master. &gt; Also, what plans do you have in store for future versions of the Rust API? I've already replaced the certificate verification logic with [libwebpki](https://github.com/briansmith/webpki), which is a separate crate of 100% pure Rust code. In order to do that, I had to expose the signature verification and hashing functions from *ring* with a Rust interface, which is documented at https://briansmith.org/rustdoc/ring/. In the future, as I do more work that requires more crypto operations, I will expand the Rust API to provide those crypto operations. My goal with designing the Rust API is to create a Rust API that follows Rust idioms and that is easy to use correctly. I'm planning for the API to be designed such that the programmers using it do not need to know or care that it has BoringSSL underneath. I encourage people to file issues to document proposals for additions to the Rust API that they can then implement with a high likelihood of getting a pull request accepted. That way, all the work isn't gated on me.
 https://twitter.com/rustlang/status/639199916544401408?s=09
`p.map_or(def, |t| t.parse().unwrap_or(def))` is another option.
Gotta love this team!
I hear that Strcat only codes on solar powered ChromeBooks. 
Do you plan on merging changes made to the corresponding code in BoringSSL, such as security fixes? (Though I don’t know how often vulnerabilities involve crypto code, rather than just protocol handling.)
I tend to agree that starting by porting some piece of software that you already know well is probably the best starting point because that way yo can focus on rust only.
Missed opportunity for a sink/sync pun...
What have you ended up using at the end? I am looking for the same thing. 
Its true that it has to be done in triplicate but that point is moot as doing unaligned operations is slow on most hardware and the alignment is still required (you could do duplicate by aligning, SIMD and a bitmask). Explicit sizes also limits what the compiler can do (as in vectorizing to a larger size)
&gt; Though I don’t know how often vulnerabilities involve crypto code, rather than just protocol handling. I'm confused. Isn't the protocol part of the crypto?
Also we get the bson crate for free.
RIP headphone users... Anyway, I watched it, and it is a decent introduction, but doesn't contain anything interesting for anyone familiar with Rust.
XPost Subreddit Link: /r/programming Original post: https://www.reddit.com/r/programming/comments/3jdih9/in_1987_a_radiation_therapy_machine_killed_and/
There's also a [talk](https://www.youtube.com/watch?v=0wDSjpx1Wz0) on session types in rust in the same channel which you might find interesting. I just didn't want to spam up /r/rust with a load of links or with the generic ICFP channel link.
I [posted it](https://www.reddit.com/r/rust/comments/3jhd56/session_types_safe_internal_communication/).
May a kind soul come and lift the veil of non-understanding?
Port nanovg
https://www.reddit.com/r/rust/comments/3erjl8/session_types_for_rust/ might help
Cryptographic algorithms like SHA-256 are building blocks for the SSL and TLS protocols, but I meant that vulnerabilities seem to be more often in other parts of the code rather than in the low-level crypto. For example, the first item in https://www.openssl.org/news/vulnerabilities.html is currently: &gt; An error in the implementation of the alternative certificate chain logic could allow an attacker to cause certain checks on untrusted certificates to be bypassed, such as the CA flag, enabling them to use a valid leaf certificate to act as a CA and "issue" an invalid certificate. The patch to fix this probably doesn’t touch the subset of code that is in ring. If that’s the case more often than not, maybe there won’t that many relevant BoringSSL patches to merge into ring. But I’m only speculating.
&gt; The patch to fix this probably doesn’t touch the subset of code that is in ring. That's right. &gt; If that’s the case more often than not, maybe there won’t that many relevant BoringSSL patches to merge into ring. But I’m only speculating. Initially, BoringSSL was mostly removing or refactoring code. Lately, BoringSSL has been adding functionality that was originally removed, in order to be more backward-compatible with OpenSSL, to help in their efforts to replace OpenSSL with BoringSSL internally. However, IMO, they were right the first time when they removed that functionality. So I've usually been reverting those feature additions when I merge, and I'll generally continue to do so. To ensure that the *ring* code and the BoringSSL code is easy to compare, I *will* merge most other patches from BoringSSL, even if they aren't strictly necessary. And, there are certain kinds of refactorings/removals I have been avoiding purely to keep *ring* consistent with BoringSSL.
His thesis has a ton of background info and was very informative. http://munksgaard.me/papers/munksgaard-laumann-thesis.pdf
That's a very good and easily overlooked point. Rust wasn't just passed down to us mere mortals on stone tablets from pcwalton, nikomatsakis and the other gods, it was iterated on time and time again, and we haven't even glimpsed its final form (though many things will stay as they are now for the foreseeable future). Also what Andrei overlooks is that the "bulging muscle" actually enables some really desirable features that otherwise simply wouldn't be possible. In that sense, Rust has a currently unique position as the first high level low level language.
/u/Munksgaard is also here on Reddit.
&gt; OOC, is there a use case for dynamic unloading? That's an excellent question. We use it at work: a "shell" binary is launched which opens/closes a library on command. I think that the idea, at the beginning, was to have "dynamic code swapping". The dynamic code swapping is no longer used (too many issues), but the dynamic open/close is still used. I don't know if there are other users/test cases, though I suspect that maybe for plugins it could make sense.
&gt; In general, I think Rusts affine type system has many interesting applications and this is just one of them. My favorite "toy example" is encoding state-machines: struct A; struct B; struct C; impl A { fn apply(self, e: Event) -&gt; Either&lt;B, C&gt; { match e { 0 =&gt; Left(B), _ =&gt; Right(C), } } } // etc... The fact that the state is consumed ensures that you cannot accidentally apply two events to the same variable. Of course, it's silly and I haven't yet seen a practical use...
What's wrong with "closing" the library silently being a no-op? Are you relying on some side effect of closing it (destructors, freed memory, etc.)? It's definitely useful to prevent the library's symbols from being accessed any more, either via explicit `dlsym` or implicitly from some other library's dependency, so you can load a new library that provides the same symbols. But the old library can stay mapped in memory to preserve `'static`, right? (If it's just immutable statics and functions, it shouldn't even take up any memory, since it's a mapping of a file on disk.)
Haha it took a minute for this joke to land.
The talk mentions that there's no observable impact on Servo's runtime performance, but how does it affect compile time? In particular I'm skeptical that the whole encoding-numerics-at-the-type-level scheme doesn't impose a large burden on the compiler.
The problem would be with all the "static" variables, which may have allocated memory (or other resources) which has to be cleaned up... and of course if you clean them up when they were labelled `'static` you might suddenly encounter issues. Regarding not really unloading the code, the trick works on 64 bits, but on 32 bits you may not be able to afford the address space waste.
/u/aturon, in your remarks at the end you mention a concept you call "destructor bombs" which I'm curious to hear more about. Are these being used in the stdlib anywhere?
I'm pretty sure they didn't, because I checked last month and they didn't have it.
I was giving [this](http://doc.rust-lang.org/getopts/getopts/struct.Options.html#method.parse) a look. Was going to implement something like: if matches.opt_str("d") { // Use the parse func } Will see if that works better; in all honestly I think I'm rushing the language a bit too much but anyway. Additionally, I did not quite get your approach; would you be able to elaborate a bit on it?
The video for the talk at ICFP has been posted: https://www.reddit.com/r/rust/comments/3jhd56/session_types_safe_internal_communication/
Thanks a lot for the response, I have worked around the code and almost got it working it seems; there is a rather odd stacktrace I'm receiving related to some macro: &lt;std macros&gt;:5:8: 6:42 error: mismatched types: expected `()`, found `core::result::Result&lt;_, _&gt;` (expected (), found enum `core::result::Result`) [E0308] Which does not provide me the line in main.rs that is causing this so I am not sure what is occurring here. I'm not explicitly using core::result::Result here so I'm wondering where it is coming from. Edit: after running rustc main.rs --explain E0308 I understood that the issue is however will have to go through every line to see what is causing it. 
Hmmm what about that try!() macro in path_exists? It uses a result type and if you accidentally forgot a semicolon you might be receiving this error. Especially if you've modified the function since you put it up here.
&gt;In the pattern-matching section[2] , I use to_string() to convert my literals to Strings before pushing them. Is there a better way to do this? There might be a better way, but there are tradeoffs. Firstly, since you are building formatted strings dynamically, you'll be allocating them as the scanner runs. (The non-`format!` ones are being allocated unnecessarily.) This means that you can't use `&amp;'static str` in your `Vec`, but you could use `&amp;'a str`, but that would involved pinning the lifetime of your scan to something else. I've done this before, because it makes perfect sense to attach your scan to your input text, just so long as you aren't going to discard your input after scanning. 
&gt; however will have to go through every line to see what is causing it. One of the following messages from the compiler should be an "expansion site" note which leads you to the point where the macro expansion started.
Oh great didn't notice that; that indeed shows that the issue is with utils::path_exists(path: &amp;str). Thanks
Would opt for that however even the docs mentions that you should use `std::fs::metadata` as it is more stable it seems. Issue is--the docs all use try!() in their examples, however as mentioned by /u/Zarathustra30 will only work if the return type of my function is a `Result&lt;T,E&gt;` which isn't quite what I want as I haven't worked with that yet. It's seems awfully complicated to simply return a boolean whether a path exists or not.
Hopefully someone else will see it as another way to promote Rust.
Output: answer: we have CompileBot support [^source](http://ideone.com/wE61Jj) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20https%3A//www.reddit.com/r/rust/comments/3jii6y/ideone_now_supports_rust/cupnk6f%20Include%20your%20reason%20for%20reporting%20here.) 
Interesting! I'm expecting to make a lot of changes especially to the output, since we'll likely be building an AST following this. So I don't expect I'll get too hung up on the output being a `Vec&lt;String&gt;`. That being said, I'm curious about potential benefits of the things you mentioned. I saw `&amp;'static` a lot when I was looking at the `tiny-http` source, and its repeated usage seems a bit counterintuitive to me. I guess what I suspect is that if you can guarantee a reference to the same object throughout the execution of the program (that is what `'static` implies, right?), then you know you're managing your memory well. However, `&amp;'a str`makes sense to me, but I'm still not sure what the benefits might be.
Well what's happening is that data_file isn't a type here. It's just (), meaning it has no type. Think void. you could do if data_file.is_some() { utils::path_exists(&amp;data_file.unwrap()); } else { panic!("Data file path is invalid, cannot proceed"); } If it is an option type it should work. If not it should spit out what type data_file is and you can go from there.
Glad I could help! I remember starting out all this seemed really complicated and weird. It'll get easier the more you use it.
&gt; data_file isn't a type here. It's just (), meaning it has no type. Sorry, that's not correct. `data_file` is an Option value. And even if it was `()`, it still has a type, which is (also) called `()`. The solution you give is much less idiomatic Rust (`is_some` and then `unwrap`), and changes nothing about the types. It just works because of the added semicolon, which discards the boolean result - but you could just as well do that in the `match` version. The actual compiler errors comes from the fact that the `match` is the last expression in `main`, which must return `()`. Rust complains that the match expression returns `bool` instead.
I can't find much truth in this statement. GPL-2.0 _can_ be used from more liberal licenses, as long as the complete set is distributed fully as source. The GPL itself is not viral. It's distribution requirements are. Poison, I find a very harsh word. If it's the express wish of the author that this implementation is only used in FOSS programs, the GPL is the right choice.
&gt; Try is just a way to throw panics and errors No panics involved.
_My name is Ogeon, Programmer of programs:_ _Look on my works, ye Mighty, and despair!_
No, you'd better use a real language supported by gcc. The issue seems silly but it's surely a portent of more crap to come. 
The only problem with that approach though is that you already have some preconceptions on how the final design might look, rather than having a completely open mind.
In the thesis, they claim that linear types can't be properly implemented as a plugin, and I think it sounds like they lament the lack of them. Did you see that?
That's funny, I actually just started working on something like this. Ended up using glium and started learning OpenGL... it escalated quite quickly
&gt; True linear types are Not Very Useful in practice. I beg to differ. We certainly have a use case for them. The purpose of session types is to provide compile-time guarantees for communication safety, and we simply cannot do that correctly without linear types or some way of synthesizing the same behavior. All destructor bombs does is blow everything up at runtime. This makes itclear that something is wrong, but you still have to actually touch those edge cases.
Only very occasionally I'm afraid. Thankfully, people are kind enough to notify me when something happens :-)
That's a good question, and we haven't actually done any testing on the compile time performance of our code. I think /u/sebzim4500 is right though, it is, in our experience, unlikely that you'll have more than a handful of nested recursion scopes.
Thank you both!
The `&amp;'a str` would be more efficient for two reasons: * Right now you are creating a string `"Modulus operator: %"`. You're creating a new one each time you encounter a modulus operator. If you just let each of these point to the same string, it would save memory. (But then you couldn't easily mutate the string later.) Of course, your dynamically generated strings have to be allocated, (unless you wanted to pre-allocate them) so you can't use `&amp;'static`. * When you pass references around, it is faster than passing strings, which would be copied in memory every time you used them. (I think. I'm not fully sure how the Rust compiler actually does it, or if this is optimized out.)
~7 seconds out of ~20 before trans for a rustc compilation from a while back when the parallel rustc update came out, but could be remembering long.
There are usecases, I just meant that they're rare. That is, the standard library has found no real use for them (although of course, the absence of them means there isn't a big hunt for their use). However what I don't really get about linear types is: programs/threads can hang, leak, or crash. How are linear types even useful in the face of that? One end of the connection needs to deal with the other side mysteriously disappearing, regardless of what your types claim.
The lack of linear types prevent us from guaranteeing some properties, in particular (some form of) progress: We'd like to ensure that once two parties have opened a session typed communication channel between them, they run the protocol to completion, ie reach the Eps protocol, and call close(). With affine types we can "only" ensure that aliasing of channels cannot occur, meaning that all interactions will happen according to the protocol, but we cannot ensure that any interaction happens at all.
&gt; There are usecases, I just meant that they're rare. That is, the standard library has found no real use for them (although of course, the absence of them means there isn't a big hunt for their use). &gt; However what I don't really get about linear types is: programs/threads can hang, leak, or crash. How are linear types even useful in the face of that? One end of the connection needs to deal with the other side mysteriously disappearing, regardless of what your types claim. How are affine types helpful, or even types at all? Obviously we can never make any absolute guarantees, the halting problem still exists, but I think that linear types is a natural extension of Rust's capabilities that'll provide additional security with little or no downsides. You might disagree and argue that this isn't enough to justify the inclusion of linear types, and you'd be in your right to do so. After all, language design will always be dominated by trade-offs between safety and expressibility.
I think I'm close with [this](https://play.rust-lang.org/?gist=b69d24bb44a9a4ac22dd&amp;version=nightly). I recall hearing recently about a bug where that compiler error gives false positives, which it appears to be doing in that case. I'll see if I can dig up more information about it. Otherwise, you could just do `impl HasLen for EverySingleContainer`, maybe with some macro magic to speed things up a bit.
Laugh it up fuzzball, but someone's trying to achieve just that (and it's not I): https://users.rust-lang.org/t/cross-compile-target-i386-architecture/2601
Hey, just a few remarks: * The error as an integer annoys me too, and someone [suggested a better solution](https://github.com/Geal/nom/issues/69). Unfortunately, it will have to wait until default type parameters get more stable :( * The performance issues for the file producer comes from the buffer manipulations. Larger buffer sizes help a lot * about exposing internal states: I had a lot of internal fight about this, and the decision boiled down to "perfect formats are rare". I want to handle most binary formats, and that means annoying stuff like look-ahead, making a stream from a linked list, tag-length-value (hello context sensitive grammars), tokens of variable bit length (spanning multiple bytes). I want to make the ugly stuff easier, less error-prone.
I think this does it. We don't need `U` since there are associated types. [It seems that the lifetime parameter is needed](https://play.rust-lang.org/?gist=d39c6f1a0eb37b0761aa&amp;version=nightly).
Not sure if I'd call this a problem with serde or a problem with the json spec with respect to rust code. At least, serde treats `Some(None)` the same way rustc_serialize does.
&gt; I use to_string() to convert my literals to String To convert string literals, you should use `to_owned()` or `into()` since `to_string()` is generic over all `Display` implementors and involves the heavy formatting machinery.
Awesome advice! Thanks!
That does actually make a LOT of sense know that I think about it that way.. thanks alot for the great post!
I did not know that. Thank you!
Ideally we should have a `[src]` link to the corresponding impl, but we don't have it yet ([#12932](https://github.com/rust-lang/rust/issues/12932)). The second best bet would to search for "PartialEq Vec" from the source code but it does not work either, since it is currently [implemented](https://github.com/rust-lang/rust/blob/1b908be/src/libcollections/vec.rs#L1276) via a macro named [`__impl_slice_eq1`](https://github.com/rust-lang/rust/blob/f76d9bc/src/libcore/cmp_macros.rs). Fortunately a search for "PartialOrd Vec" correctly leads to [the implementation](https://github.com/rust-lang/rust/blob/1b908be/src/libcollections/vec.rs#L1304) which delegates to [slices](https://github.com/rust-lang/rust/blob/1b908be/src/libcore/slice.rs#L1564) and then finally [iterators](https://github.com/rust-lang/rust/blob/1b908be/src/libcore/iter.rs#L1039). It does what you expect---run two iterators in parallel and stop at non-equal `Ordering`. Now I really hope #12932 is fixed.
I still haven't found anything. I am hoping for odbc at some point
&gt; but it infects the project so that it’s not truly MIT/ASL2 I'd even disagree with this: your project is MIT/ASL2, it's distributed in a fashion compatible with the GPL. Once you find a replacement component for the GPL component that is API compatible, you can just take the rest and do whatever you want with it, under the rules of MIT/ASL2, without asking anyone. &gt; your closed-source thing can depend on MIT/ASL2 code but not on MIT/ASL2 code that depends on GPL code. Which is exactly what the GPL is intended for and that's a valid wish.
Now, now don't let's get too hasty. They're probably going to fix the situation for the sake of prestige. https://github.com/rust-lang/rfcs/pull/131
Doesn't _not_ impl'ing `Drop` for a type effectively make it Linear in Rust (since you can't drop it explicitly mid-way (except by falling to the end of the function without using the linear values))?
[racer](https://github.com/phildawes/racer) is great. It's improving steadily recently too.
&gt; However sometimes it seems to me like a premature optimization sort of thing or YAGNI sort of thing. The good thing with static checks/proofs is that you can reuse their result without paying for it in runtime. Once someone has done the proof, its truth is there for all to make use of. That's not to say you don't hit diminishing returns at some point, but there are certainly use cases where it's worthwile – especially in aeronautics/military/medicine/banking and other security sensitive areas.
This is ultimately more along the lines of what I'll do as the project progresses. I should work on it a bit now. 
There's a few different ways to do this, and the "right" way is contentious. * String::from("foo") * "foo".to_string() * "foo".to_owned() * "foo".into() They all mean something slightly different, semantically, even though they end up with the same thing. I personally use one of the first two.
Apparently so, my first attempt was using Metric::Output directly, but the compiler instructed me to use &lt;Self as Metric&gt;::Output after this complain: &lt;anon&gt;:8:20: 8:34 error: ambiguous associated type; specify the type using the syntax `&lt;Type as Metric&gt;::Output` [E0223] &lt;anon&gt;:8 fn test(self) -&gt; Metric::Output; ^~~~~~~~~~~~~~ error: aborting due to previous error playpen: application terminated with error code 101 See http://is.gd/1LYlV8 The hints from the compiler are great
Ah, I can hardly believe I didn't try that before... Thanks.
The new [rustfmt][1] is advancing rapidly. [1]: https://github.com/nrc/rustfmt
I know, but the gists aren't saved in your account, so you still have to bookmark them, and you can't run code directly in a gist.
I've never noticed that before, sorry.
It's not only you, but it is a matter of taste. You can tell where the body begins by where the correct indentation starts. (Over-indented stuff is always just extra detail for the last correctly indented line.) Though, if I wrote it, I'd intent to the open-paren: impl &lt;'l, 'tcx&gt; DumpCsvVisitor&lt;'l, 'tcx&gt; { pub fn new(tcx: &amp;'l ty::ctxt&lt;'tcx&gt;, analysis: &amp;'l ty::CrateAnalysis, output_file: Box&lt;File&gt;) -&gt; DumpCsvVisitor&lt;'l, 'tcx&gt; { let span_utils = SpanUtils::new(&amp;tcx.sess); DumpCsvVisitor { sess: &amp;tcx.sess, 
Oh... right. Sorry. I always MS SQL almost always confuse me.
A language is neither low-level nor high-level, but usually covers a *range*, and even there the range is not uniformly covered. So, I'll use the following levels: - low-level: memory twiddling, disregarding types if necessary - mid-level: type-safe, explicit code - high-level: syntactic sugar on steroid, such as closures For example, C++: - low-level: good, with its ability to twiddle raw memory at the bit level - mid-level: good - high-level: good, with its lambdas and the ability to transform the code (see the Eigen library for a demonstration of Lazy Evaluation and al.) Where does Rust stand? - low-level: good (personally), some users (kernels/embedded) have reported in the past that some operations could require lengthy code and I don't know where we stand on that - mid-level: good - high-level: good, with closures, iterators, and the latest demos in session-types see how Rust-encoded state machines are all kind of awesome Personally, I do not see any reason why Rust cannot cover from low-level to high-level equally well. There is no reason why Rust cannot grow in both directions. It might, however, remain a bit too verbose compared to what scripting languages or Haskell (say) but I do not see this as an issue (explicit is valuable too).
Haha, wow, I had no idea. What're the chances? :P Anyone have fun suggestions for a new name?
As many other things, this can be configured to your personal liking. For this particular behaviour, set `fn_brace_style = AlwaysNextLine` in `rustfmt.toml`.
What a coincidence; we've recently started running clippy on rustc (and servo too!). [1](https://github.com/rust-lang/rust/pull/28188) [2](https://github.com/rust-lang/rust/pull/28191) [3](https://github.com/rust-lang/rust/pull/28163) [4](https://github.com/rust-lang/rust/pull/28152). Doing it incrementally, mostly because clippy outputs lints and sometimes suggestions, but doesn't actually replace code (so I pass clippy output through imperfect bash/sed/awk scripts which _usually_ get it right).
Other languages can abstract from the representation of types and typically do this by defaulting to heap allocation and garbage collector. Rust is designed for abstractions without overhead. There will be features that allow more powerful abstractions but there will be always more code than in other languages that are directly built with high-level-code in mind. At least until someone implements a complete language with a syntax extension.
Indeed, it is a matter of taste. A lot of people (myself included) don't like alignment with the open paren, both because it complicates refactoring and leads to extra verbose diffs and (in my case) because I find a consistent double indent for hanging lines more appealing than having different indents for different functions.
To be fair, it was indented as yours where I picked it from; it's just that getting the indentation right on reddit is... frustrating.
I don't want it "always next", I am used to have it "inline if following a single line, next line otherwise"... call me indecisive?
The lengthy code could in part be because of some very unfortunately named functions. ::std::mem::uninitialized() and (some_indexable).get_unchecked_mut() come to mind. For example, *array.get_unchecked_mut(i) = *array1.get_unchecked(i) * *array2.get_unchecked(j); is something I have seen which in C would have been written array[i] = array1[i] * array[j]; Unchecked indexing in particular might deserve its own syntax. Maybe array~i or array\^i. 
Krillin?
It looks like this requires a signup to read. Can you describe what this is?
Read_line also gives you a new line. Use trim to chop it off before you print.
I ended up using the second option, actually. I made a newtype over Vec called UnsafeVec and just impl'd Index{,Mut} over it to use get_unchecked on the wrapped vector.
The need for a One True Format is overrated. Anyone can have their own parameters defined locally and run a formatting tool on code before they read it. I'm sure that rustfmt will have sane defaults, but there's no need for us to get dogmatic about them.
Where are all these configuration values listed?
They currently aren't documented, but you can look at `src/config.rs` to get an overview of all the parameters.
I disagree. Designing a language with the high-level-code in mind means making implementation decisions for the user that he or she may have not wanted to make. For instance, you get closures for free in most other functional languages and in haskell it's the norm to write some higherOrderFn :: (a -&gt; b) -&gt; result, but that's because those closures are boxed. Boxed closures in Rust are higher_order_fn(f: Fn(a) -&gt; b) -&gt; result, which is almost exactly the same as the haskell version, but you also get unboxed closures for just a little bit more code. If you're talking about garbage collection, then you can newtype over some Rc&lt;Representation&gt; and impl Copy. Want mutability? Multiple mutable references are not concurrent safe, so you shouldn't be allowed to do that, anyway. How easy is it to do multithreaded programming in Python without resorting to C? In Ruby? The amount of code I write in Rust is about on par with the amount of code I write in Haskell, except for when it comes to Higher Kinded Types (I can't write any of that code in Rust) and treating value and reference types uniformly (which I hardly ever do anyway). But I get all this flexibility from the language in return and I still have a language 10 times safer, twice as abstract, and just as fast as C++.
Will it be able to destroy the moon?
You may be interested in this thread: https://internals.rust-lang.org/t/adding-16-bit-pointer-support/2484 TLDR: LLVM backend and port of Rust for AVR exist in some form and are maintained by @dylanmckay
This. Go is overall a simple syntax (not just limited to function declarations). Rust has generics, lifetimes, and a whole host of things which complicate everything. One True Format for some things is okay (tabs vs spaces, semicolon after return or not, splitting imports), but certainly not for the entire space of formatting normalizations that rustfmt can apply.
Yes, perhaps do something along [these](https://gist.github.com/anonymous/945d102a14ca519644f4) lines.
No, because what would happen if `dependencyA` required `cookie 1.2` and `dependencyB` required `cookie 2.53`?^1 Which one should Cargo pick for your project? What I would love to have, though, is something like [dependencies] hyper = 0.6 cookie = hyper.cookie and have Cargo pick whatever version Hyper is using. ^1 Note that his is a totally made up scenario, but it may happen with other crates.
any time
Yes, I meant "in the absence of a version specified manually, and in the absence of conflict, cargo should pick one transitively".
There's a FAQ if you click on the title: http://www.devdraft.com/faq Looks like LinkedIn mashed up with a coding competition.
&gt; high-level: good, with closures, iterators, and the latest demos in session-types see how Rust-encoded state machines are all kind of awesome I'd say that Rust has some potential here but is still sorely lacking some features to make it a great high level language. The lack of higher kinded types, the lack of non-lexical borrow scopes, very crude borrow tracking\*, every function defined with a closure syntax is treated as a closure even if it's not a closure - these are the things I have to work around practically every day that I'm working with Rust and it's a significant productivity drain (for me) which prevent Rust from feeling like a high level language. \* - if you pass a `self` to a function the compiler assumes that the function uses every member of `self` even if it's only a simple accessor for a single member; in some extreme cases this has even forced me to use macros (!) instead of functions since otherwise I'd have to either copy and paste the same code everywhere or suffer a performance penalty and/or crappify the design by using a `RefCell` 
You would. :p &lt;3
&gt; even in the worst case scenario code in the wild would be no more inconsistent than it is today Right, but we're talking about two possible future outcomes. One may be not worse, but if the other is better... ie, they're both at the very least an improvement, but if one improves more than the other, that counts. &gt; Why should I care how other people are formatting their code? Code isn't only viewed in the context of your editor, it's viewed in blog posts, it's viewed on GitHub, on slides, all over the place.
Ah, yeah. I seem to remember that there was some problems with that... I don't remember if it actually does that in all cases or not. Some else can most certainly give a better answer than me.
Rust will certainly gain additional features enabling more abstractions. That process will naturally wind down over time because there is a limit to how much you can reasonably put in a language. Of course, Rust could be like C++ and totally ignore that fact. However, gaining more abstractions will not make Rust into a high level language like C#, Java or ML. It already has at its core the requirement that the developer consider and track the low level nature of things. I'm not referring to the borrow checker. Rather things like explicitly tracking what is on the stack and heap. Also, the use of Box and Cell rather than built in lighter weight features for it. Most high level languages put everything on the heap, or determine that when the type is declared rather than when it is used. I think we will see a true higher level language that uses a borrow checker become popular. In fact, I am already starting on creating a language like that. I'm really just starting to design it, but plan on talking about it soon. If your interested, watch my blog for an announcement soon http://www.walkercoderanger.com/blog/ 
I appreciate where you are coming from. It is possible to create very complex advanced things in C++ or Rust. However, I have to disagree on what high level really means. To me high level means that many of the low level details have been abstracted away from the programmer so that they can focus on the problem domain rather than the machine. This greatly improves programmer productivity. Given that definition, both C++ and Rust are not and will never be high-level.
Wow! Talk about above and beyond. Thanks for reminding me `Iterator.peek()` exists...I should be able to use that for the 'quit' requirement as well. 
Not crazy at all. This is what I do and I love it for all the same reasons you stated.
&gt; more elision of lifetimes is quite improbable medium-term, because more complex rules will necessarily lead to changing behavior, thus break back-compatibility What do you mean? Elision is just making an assumption in the absence of specifying notation; additional elisions (such as on structs) can be introduced which are not breaking changes because the code they will enable currently doesn't compile.
It sure could, though only nrc would be able to tell you how much is left to do before that's feasible.
First of all, this depends on your definition of high-level. Some possible definition of high-level programming which came to my mind are: 1. High-level in the scripting language sense - ability to write concise code without much boilerplate. In extreeme cases most programs are one-liners. 2. High-level in the type theory sense - higher-level types/traits, higher-order functions, etc. This gives you the ability to write extremly generic code at such level that no one understands it any more. This direction usually leads to the category theory. 3. (My favorite) Ability to reason about code at high-level. E.g. Haskell guarants that all functions are pure while Rust guarants that there are no aliasing mutable pointers, no data races, etc. In this sense C++ is not higher level than C while safe Rust is. 4. ...
Nice to see that I'm not alone :) It looks like rustfmt has a lot of knobs to tune, so I hope this style can be achieved. It would be nice.
&gt; I hereby propose that we move to three-space indents to solve this problem forever. A non-power-of-two indent?! Heresy! The bikeshed should be chartreuse!
Two-point-five-spaced indents, and that's my final offer.
I agree. Python isn't a high level language because of metaprogramming and `eval`, it's a high level language because it doesn't ask you to think about the stack, allocation, garbage, data layout and so on. How one defines a high level language is of course a matter of opinion, and in any case modern C++ and particularly Rust do build somewhat up to my definition. However, all of C++'s standard tools are very transparent to the user, in that their abstraction is more of a thin veil than a leaky bucket. Rust is closer, but to get higher level it should focus not on building new abstractive tools but patching up the holes in the current ones. YMMV.
&gt; Unchecked indexing in particular might deserve its own syntax. Maybe array~i or array^i. Wasn't that exactly why the Rust authors moved away from using `~T` instead of the more explicit/verbose `Box&lt;T&gt;`? The rationale being, with a lighter syntax, people are more willing to use such *unsafe* features, which contradicts the philosophy of the language to begin with.
We're changing to the MIT license: https://github.com/Munksgaard/session-types/pull/24 :-)
My solution to this is to have the fields chunked out into groups with their own types, and then just calling methods on those fields (but some holistic things as methods on the root type). Personally I feel like methods talking about borrowing of subfields would be a bit much to deal with.
I will be satisfied with a `U+2000 EN QUAD` followed by a `U+2006 SIX-PER-EM SPACE` characters per indent level. It should be a compile error to reverse the order or use anything else. I smell an RFC brewing... fn main() { let a = "Virtuous EN QUAD and SIX-PER-EM SPACE"; println!("Sinister triplet of SPACE"); }
I'd love to see this as a syntastic plugin some day
Thank you!
Yeah, pesky recursion limits. It wasn't a [criticism](https://github.com/durka/macrolisp)!
Try running the program straight from explorer (*i.e.* **not** from a command prompt) and see if you get a dynamic linking error. Also note that you're more likely to get useful help if you supply minimal code that reproduces the problem and list what version of Rust you're using and what command you're using to compile. Otherwise we basically have to take blind guesses.
I think the lossy encoding should be a runtime error whenever possible. (I of course would prefer to have a different encoding scheme for such cases, but I agree that they are releatively rare and cannot be easily fixed.)
To be fair I also wrote the code for `rustc_serialize`, so I'm the common factor here :)
You're massively overcomplicating things. use std::collections::LinkedList; fn main() { let mut cells = vec![LinkedList::&lt;usize&gt;::new(); 5]; for (i, cell) in cells.iter_mut().enumerate() { cell.push_front(i); } } You also seem to be confused about how pointers work in Rust. All I can really recommend is to read [The Book](https://doc.rust-lang.org/book/), specifically the chapters on [Ownership](https://doc.rust-lang.org/book/ownership.html), [References and Borrowing](https://doc.rust-lang.org/book/references-and-borrowing.html), and perhaps [The Heap section of The Stack and the Heap](https://doc.rust-lang.org/book/the-stack-and-the-heap.html#the-heap).
But by using a vector, won't look-up be slower compared to an array? I've read all these sections (seriously!) and I still don't understand why the last error I've mentioned comes up. Moreover, it is really not possible to have an array (not a vector) of linked lists? Edit: Tbh, initially I thought of the vector solution. But my actual problem does not require a variable length object, so to show the correct semantics, I thought maybe using an array would be most optimal.
No, lookup will be as fast as in array. Only difference is that `Vec` use dynamic allocation while array use static. Dynamic allocation is a little bit slower, but has greater capacity. In this case, if it isn't in tight loop (and it isn't), it makes no difference.
In your last example, `a` will get destroyed before `cells` which would lead to a dangling pointer in `cells[0]`. It's difficult to give guidance without more context but you're probably better of using `Vec`.
It's always so much fun to read those reports... The warm feeling in my heart that every second I breath, Rust is getting more awesome :`3 
Only slightly related question, what happens on Windows if you just use a bare line feed? Does it start a new line anyway? Is a carriage return required or is it just ignored? 
~~https://gist.githubusercontent.com/james-darkfox/9acb0bcfce6a62bf929f/raw/2d0746d7e87b553c33bb563f55b2e9503c4ec955/paste~~ **EDIT**: Updated version in the gist page So pretty :D
Oh Rust is lacking a good number of features I would wish for, especially in the meta-programming and compile-time evaluation area. I just think it's already quite good, personally, but I hope it aims for excellence.
Ah interesting, I am certainly glad I explained what I meant by high-level then. Would you think that having a `Gc&lt;T&gt;` type in Rust, thereby freeing you of thinking about memory (de)allocation would help? Personally, I still think that Eigen demonstrates high-level programming in C++: - if you use BLas, you have to decompose the operations you wish to do in BLas primitives - if you use Eigen, you express the operations you wish to do, and it optimizes them behind the scenes isn't that a linchpin of high-level programming? Of course, you will have to think about resource ownership, etc... but if you were using Python bindings for BLas you would have to think about translation to BLas primitives instead, so it's not a free meal either.
I think it cuts down a bit on diff noise should something be added.
I'm not sure what why you're trying all those things. What is wrong with `let cells: [LinkedList&lt;usize&gt;; 5] = [LinkedList::new(), LinkedList::new(), LinkedList::new(), LinkedList::new(), LinkedList::new()];`? 
If I have understood the error correctly you cannot use `[value; n]` to initialize the array because this syntax copies `value` and LinkedList must be cloned. So how do you build an array of non `Copy` items?
Alternatively, `std::iter::repeat(LinkedList::&lt;usize&gt;::new()).take(5).collect::&lt;Vec&lt;_&gt;&gt;()` or something along those lines, because `repeat` uses `Clone`.
It seems to use its own implementation, and nicely done too.
&gt; since GC-unsafe wrappers are only unsafe if you put a GC in them and then put the wrapper inside a Gc (e.g. Gc(RefCell(Gc))) Interesting... &gt; Mutability is the whole issue, really. Immutable GCs only have to worry about stuff being passed into a ctor, and it's easier to handle that. But immutable GCs don't really cover new cases over Rc, really. While that's true, I think the kind of mutability I was talking about is different in kind -- it's not about creating cycles inside the GC graph, just mere moving things around so they are in different places at different times. If you have a scheme where rooting a `Gc&lt;T&gt;` gives you a `Root&lt;T&gt;`, and that in turn gives out `GcRef&lt;'a, T: Trace&gt;` values (instead of, and opaquely wrapping, `&amp;T`), and you use that to traverse the graph (presuming that a way to do `&amp;foo.bar` with them is figured out), and find another `Gc` which you `root()` as well, then if you don't consider mutation, I think that actually works: by reaching the second `Gc` from the `Root` using only `GcRef`s (which can only pass along `Trace` paths), you've proven that the GC can also trace the same path from the root and see that that `Gc` is live, without relying on lints. But even simple language-level mutation like moving a `Gc` from a non-`Trace` location (`struct` field, eg) to a `Trace` one breaks it, I think, without even implicating things like `DerefMut` or `RefCell`. (I *think*. But I'm often prone to misthink around here, which is why it's good to have a second set of brain-lobes thinking at it.)
SCC is hard to do in parallel. It is one of the examples for differential dataflow: https://github.com/frankmcsherry/differential-dataflow/blob/master/examples/scc.rs but this will use about 16GB for a 10m node, 100m edge graph (just tested!). On the plus side, it automatically updates its output in a few milliseconds if you change the graph. :)
Yeah, I want to convert the screaming to @ (nit: it's still used in an obscure corner of pattern matching syntax). There's also some things that can be cleaned up if I drop strict 1.0.0 compatibility. The main thing I can't support is recursive lambdas, I think (as far as I can tell a Y combinator is prevented by the borrow checker). But there should be some other things I can add. Struct definitions and impls should be on the list for instance.
Sorry if it was not clear; I was just trying to give a MWE. In practice, the 5 is replaced by a variable which is calculated at runtime.
I haven't tried rust-bindgen yet. If you have experience with it I would be really interested in collaborating with you on it. I think it would be fairly usable, but i don't know how much of ChibiOS Api is implemented using C preprocessor rather than real functions.
LIFO order of declaration, not simultaneously.
Also he doesn't use an editor, but imprints the byes of the code directly into the SSD. With his teeth. ;-P
Paging my resident neighborhood Atarian to port Rust on the Falcon...
Just a hobbyist,no experience in rust. but i'm curious about rust and mcu and where it's going.But have you tried talking with job vranish , or other people who work on rust/mcu , for example the zync.rs community ? And Chibi uses #define quite often. 
&gt; Just a hobbyist,no experience in rust. but i'm curious about rust and mcu and where it's going.But have you tried talking with job vranish , or other people who work on rust/mcu , for example the zync.rs community ? &gt; Haven't talked with the zync community as it was more of a two evenings hack than a "real" project. I would also try this project: https://github.com/robertknight/rust-cmacros to generate bindings from #defines. Haven't had a lot of time to do it yet.
If that's the case then you certainly need a `Vec`. Arrays can't have dynamic sizes. 
The trouble is that recursing closures with captures are apparently [unsound](http://smallcultfollowing.com/babysteps/blog/2013/04/30/the-case-of-the-recurring-closure/) (unless things have changed since April 2013). That doesn't stop there from being an [implementation](http://rosettacode.org/wiki/Y_combinator#Rust) on Rosetta Code, but it's quite old syntax (from before the removal of pointer sigils) and I was not able to port it to current Rust.
Rust supports compiler plugins which allow you to perform arbitrary code manpulation at compile time. This is currently only available on nightly but later it will be on stable. As others have said, serde provides automatic [de]serialization and somehow manages to work on stable.
Notepad bundled with Windows does not recognize such line endings but there are no other issues that I know about. \r\n is not the Windows-only thing, this line ending is also used in HTTP.
One of my favorite little things about rust is the hanging commas in lists. It makes my day every time I see it.
I'm not sure defines is enough, there are also conditionals, and doing it half automated don't really help, right? 
BTW , job vranish did manage to generate mcu bindings using rust-bindgen(for stm32f4 CUBE libs) and i think those libs use preprocessor. Maybe he's the guy to ask ? http://spin.atomicobject.com/2015/05/21/generate-embedded-rust-bindings/?utm_source=twitter-ao&amp;utm_medium=social&amp;utm_campaign=embedded-rust-bindings
Wrong sub: /r/playrust
Oh, right. That's me missing the obvious again. But it shouldn't matter, since that dangling pointer will never be mistakenly accessed, right?
I was honestly excited. A programming clan sounds cool.
[removed]
On [github](https://github.com/serde-rs/serde), it says serde is failing to build.
On nightly. It's fine on stable and beta.
I think it should pretty much be possible to build a Rails clone in Rust through heavy use of macros. So I guess the sky is the limit :-).
I agree with this comment &gt; This is the worst kind of breaking change: It's subtle and isn't easily caught at compile time Why didn't the Rust team introduced a new function and deprecated the old one? Is there still time to introduce a new function name and avoid having a breaking change?
I'm talking about the special case of `{}` not needing a comma after it.
Happy to help. i'll be following your blog !
Hopefully. I still have to actually implement it, this is just the shell.
While there is a timed competition for a prize, it's more of a challenging opportunity to showcase skills.
This time I compile [clippy](https://github.com/Manishearth/rust-clippy) with rust and then the other way round. Are you using clippy? If so, please share your experience here!
Have any clippy lints been merged into the Rust compiler? I feel like many of them should be default in Rust eventually.
Speaking of lisp. The updated version doesn't use repeating as much, but instead has become a direct lisp S-Expression. :-)
I find it hard to imagine that there's sensible code out there that actually relies on *::lines() not recognizing \r\n. In fact, I would argue that such a program is already buggy in practically all realistic cases.
Unless the program purposefully uses a Linux-only API. Or: the program reads Unix config files (the stuff in `/etc`) whose regular tools don't recognize `\r\n`. Or, more generally, you're writing an Unix tool. This command: printf 'a\r\n' | sed 's/^a.$/x/' Prints `x` here (GNU sed). A program that used the new `.lines` to build a sed clone would be the buggy one!
I've updated `power-assert` to use plugin arguments to override builtins. Thank you!
Ah, no, the parallelism was completely unrelated to SCCs. I'm curious about a simple parallel bidirectional Dijkstra implementation, where you want to go from `k` to `v`, so you can start the search in parallel from `k` and `v` and then use channels to communicate the status of the search. Differential dataflow looks interesting. Most of it goes over my head still. But I do wonder if it would be possible to implement CH using it...
Our general position on lints is that we're not super interested in adding more of them right now. For a lint to be in `rustc`, it has to be important enough to matter to every Rust program, and to have a very, very small false positive rate.
Would have been interested to see a breakdown of the kind of errors found/fixed. Especially if any bugs were found.
Manish had a few links in a [recent comment](https://www.reddit.com/r/rust/comments/3jn34s/nrc_starts_running_rustfmt_on_the_rust_codebase/cuqo9ll) here. Also we have two clippy issues to keep track: [Servo](https://github.com/Manishearth/rust-clippy/issues/164) [Rust](https://github.com/Manishearth/rust-clippy/issues/278).
[removed]
:+1: The unit_cmp ones sound scary!
[removed]
 gtk::init().unwrap_or_else(|_| panic!("Failed to initialize GTK.")); Can be written more simply as: gtk::init().expect("Failed to initialized GTK.");
We'll update the example when Rust 1.4 comes out.
The home page example doesn't work. Where are the docs? Are they hosted somewhere? It isn't listed on the webpage, on crates, or on the repository. [EDIT] Ah, found the [problem](https://github.com/gtk-rs/gtk-rs.github.io/pull/2) [EDIT2] The example works now
You can use `.ok().expect("blah...")` for the time being which is slightly better.
You don't need to specify the end, just do `&amp;question[3..]`. ... but then, why am I complaing when this snippet uses byte indexing for UTF-8 strings. ^^
The end was specified to remove the `?`. The answer would otherwise also be a question. Regarding indexing in general; it's all within the ASCII range, so it should not be a problem. It's also just for fun, so I didn't bother doing it properly ;)
Thanks for pointing this out, we do need to get the docs into shape.
I wonder if it wouldn't make more sense to just let `gtk::init()` panic itself if it doesn't work. In which case would you want to still do something if you can't even initialize gtk in a gui program?
&gt; have a very, very small false positive rate. Do you mean zero false positives? Or are there any lints in rustc enabled by default with false positives?
Is there an equivalent for gtk2?
I'm not sure if there are, I think all of them have none. Not 100% sure on that, though. It's not a hard and fast rule, just something important to consider.
Not as far as I know. Gtk-rs targets gtk-3+.
I don't think msys should be involved in running Rust on windows at all. It's better not to have multirust than to have a multirust that needs it. Until that thing is native it's better for docs to assume multirust does not generally exist.
If you have the time, those difficulties sound like material for a great second blog-post. :)
Of course it's not the case that Rust should *require* MSYS, and it currently doesn't - the MSI experience is fine for anyone who doesn't want to use it. I don't see, however, why willfully *not* supporting MSYS in multirust is a good thing.
I just switched to vectors after reading this: cglab.ca/~abeinges/blah/too-many-lists/book/#an-obligatory-public-service-announcement
[This works if you add another scope.](http://is.gd/WltPVN) You're right that ptr1 is done and that the data is still borrowed. Right now, data is borrowed until the end of the scope, even if the variable is never used again. This should get fixed in the future once lexical borrows arrive.
As I understand it, this is basically a limitation in the current implementation of lifetimes, which can only shape itself to certain kinds of code region. In this case, I believe there's no way for it to "truncate" the borrow to where mem::forget happens -- it has to go to the end of the scope of `ptr1` (in some sense this makes sense, the lifetime is part of the type of ptr1, and you can't have a variable outlive the lifetime it claims to be valid for). The "proper" way to do this is to declare `ptr1` inside a temprorary scope like you do for fake_death (so just move that open brace up 3 lines).
Borrows have lexical scoping. This means that from the point you created the borrow until the end of that scope, that borrow will effectively lock down that `Vec`. If you want to create a second borrow you will have to restrict the first borrow to a smaller scope like so: use std::mem; let mut data = vec![1,2,3,4]; { let mut ptr1 = &amp;mut data[0]; *ptr1 = 5; println!("{}", ptr1); } { let mut ptr2 = &amp;mut data[1]; } If you want to have multiple mutable borrows at the same time, you can use `data.split_at_mut(index)` to get a pair of mutable slices and you can split them down further as needed. Another option is to have a `Vec&lt;RefCell&lt;...&gt;&gt;` so you can very easily have a borrow on each element at the cost of runtime checking. If you're working with simple primitives you can use `Cell` instead of `RefCell`, which has zero overhead but is also restricted to just getting and setting the value, it cannot be borrowed.
Aside from the answers that everyone's giving you about how to make the borrows not active at the same time, there's a way to allow multiple mutable borrows. The secret is to use the `split_at_mut` function to inform the compiler that yes, the indices are definitely disjoint. [Example](https://play.rust-lang.org/?gist=e95af9e3e421093dc414&amp;version=stable) fn main() -&gt; () { let mut vec = vec![1, 2, 3, 4, 5]; { // New scope is only so I can print the vec at the end let (head, tail) = vec.split_at_mut(1); head[0] += 1; tail[0] += 1; } println!("{:?}", vec); } The compiler isn't detailed enough to deduce that `vec[0]` and `vec[1]` are disjoint, since custom `Index` implementations don't guarantee that `a != b =&gt; &amp;v[a] != &amp;v[b]`. The `split_at[_mut]` functions encode the special knowledge that for slices in particular, different indices give references to different objects, so there's no aliasing danger.
Time for macro magic! macro_rules! init_array { (@void $n:tt $expr:expr) =&gt; { $expr }; ($expr:expr; $($n:tt)*) =&gt; { [$( init_array!{@void $n $expr} ),*] }; } `init_array![LinkedList::new(); 0 1 2 3 4 5 6 7]` which initializes a `[LinkedList; 7]`
Thank you! That actually solved my problem, though I've been thinking for a while about a solution when no such void * parameter is supplied. Could it be possible to write a macro for it, perhaps?
I think your problem is you do: for chunk in key.as_bytes().chunks(4) { // Pass `chunk` instead or `&amp;chunk[..]` let mut buf = Cursor::new(&amp;chunk[..]); Here's a [playpen](https://play.rust-lang.org/?code=fn%20printer%28s%3A%20%26[i32]%29%20{%20println!%28%22{%3A%3F}%22%2C%20s%29%3B%20}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20v%20%3D%20%26[1%2C%202%2C%203%2C%204%2C%205]%3B%0A%0A%20%20%20%20for%20win%20in%20v.chunks%282%29%20{%0A%20%20%20%20%20%20%20%20%2F%2F%20win%20has%20type%20%60%26[_]%60%20%28uncomment%20the%20next%20line%29%0A%20%20%20%20%20%20%20%20%2F%2Flet%20_%3A%20%28%29%20%3D%20win%3B%0A%20%20%20%20%20%20%20%20%2F%2F%20%26win%20has%20type%20%60%26%26[_]%60%20%28uncomment%20the%20next%20line%29%0A%20%20%20%20%20%20%20%20%2F%2Flet%20_%3A%20%28%29%20%3D%20%26win%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%2F%2F%20Don%27t%20add%20the%20extra%20%60%26%60%20since%20you%20already%20have%20a%20reference.%0A%20%20%20%20%20%20%20%20printer%28win%29%3B%0A%20%20%20%20%20%20%20%20%2F%2F%20%28I%20think%20this%20is%20correct%29%20Doing%20this%20passes%20a%20reference%20but%0A%20%20%20%20%20%20%20%20%2F%2F%20immediately%20forgets%20what%20that%20reference%20is%20called%20because%20it%27s%20not%0A%20%20%20%20%20%20%20%20%2F%2F%20tied%20to%20a%20name.%20This%20can%20cause%20problems%20later%20if%20the%20function%20tries%0A%20%20%20%20%20%20%20%20%2F%2F%20to%20return%20that%20reference.%0A%20%20%20%20%20%20%20%20printer%28%26win%29%3B%0A%20%20%20%20}%0A}&amp;version=stable) attempt at solving your issue with some commentary. [EDIT] I couldn't test it without the whole problem listed in playpen but that seems like it could be the issue.
Not sure about the brace style (don't think so though, given what I see in the configuration), but I've sent a PR enabling tabs for indent, spaces for alignment style: https://github.com/nrc/rustfmt/pull/290
EDIT: The struckthrough text is wrong. The actual problem is this: The problem is that final_bytes doesn't "live long enough," in the sense that it is allocated after `cursor` is assigned. This makes `Cursor::new(&amp;final_bytes[..])` have a different, shorter lifetime from `cursor`. If borrowck were sufficiently smart, it would be able to tell that this doesn't matter, but it isn't. The solution is to declare `final_bytes` before you declare `cursor`. Incidentally, every time you create a reference to `chunk`, it's unnecessary because `chunk` is already a reference. ~~/u/mdinger_ is correct.~~ ~~`chunks( )` returns an iterator of `&amp;[u8]`s, so `chunk` is already an `&amp;[u8]`; every time you pass `&amp;chunk[..]` or `&amp;chunk`, you don't need to, because its already of the correct type.~~ ~~A `Cursor&lt;&amp;'a [u8]&gt;` will have a lifetime of `'a`, because it holds a reference of lifetime `'a` inside of it. But the lifetime of the reference in `Cursor::new(&amp;chunk[..])` is only as long as the `new()` call, so the `Cursor` cannot live long enough to be returned by `new`. On the other hand, `chunk` itself is a reference that lasts for the length of the block inside the for loop, so a `Cursor` taking `chunk` _will_ live long enough.~~
Currently different styles of braces are only configurable for functions. It would be easy to add an option for block expressions to and I'd be happy to take such a PR. The configuration options are not well-documented. They are lsited here: https://github.com/nrc/rustfmt/blob/master/src/config.rs#L105
I thought it was something like that but when I present an explanation like that I like to give a counterexample which fails as expected but my first attempt at a misbehaving example compiled.
The merits of not making an additional reference notwithstanding, in this case you can eliminate the error by initializing `buf` after `final_bytes`, so that the former lexically outlives the latter. A slightly mutilated rearrangement of you code [here](http://is.gd/1u9Yis) (switch to the Nightly channel to compile it.)
Best of luck to you!
* Last week, I wanted to work on Turbine, but other stuff got in the way. It's still on my list * ~~I have another PR for Rust based on clippy suggestions. Perhaps I'll also try some other projects~~ (DONE) * ~~I'd like to extend my shadow_unrelated lint in clippy with a note showing the previous definition~~ (DONE) * Perhaps I'm going to write some more lints, too * Keep up the "Crate of the week" effort I started last week * Work, work, work
I always read it like that ):
Nothing until non-lexical scoping is done :P As soon as it is, though, I'll port https://github.com/makoConstruct/termpose (flexible markup language, basically s-expressions with a third of the parens) over and we can start making termpose parser/typer combinators with macros and never use Json again ~
I'm trying to write a parser for a configuration syntax. I had great fun putting together a lexer the other week, so now I've got an iteration of tokens that I want to convert to a parsed iteration of events, on top of which I can build whatever public API I like. I'm really enjoying it - it's the first time I've ever attempted to right a parser that isn't just a line-based regex-y hack - but as a Pythonista I'm missing a lot of Python's sugar, particularly the yield statement, when it comes to putting it together in Rust. Writing iterators that keep track of their own state so explicitly has been a learning experience!
I was a bit late contributing to the last thread, so my goals for now are essentially the same: become more familiar with the Rust, look into the feasibility of developing a single-user web-based IRC bouncer - primarily for my own personal use. Yesterday, I contributed two simple/small Rust programs to Rosetta Code. I plan to add another couple today.
Pausing my gamedev stuff to rewrite an existing website in Rust. In my opinion the express-like design used by Iron and Nickel is not adapted to Rust, so I'm also working on the f[r](https://github.com/tomaka/rouille)amework.
Copied-and-pasted: I've published [Chrono 0.2.16](https://crates.io/crates/chrono/0.2.16) yesterday. I'm slowly working towards the initial `TzRule` time zone implementation for keeping with daylight saving time (DST).
- Regular job (non-Rusty) - Work on [Octavo](https://github.com/hauleth/octavo) + finish block cipher modes of operation + add AES + Salsa/ChaCha + reimagine module tree + maybe start RSA implementation - Work on Mort (our deployment tool in Rust) - Work on Anarres (our provision tool in Rust)
That's more about the ease-of use of the libraries though - since BLAS is very low level you're forced to do 'low level' stuff in pyhton, but on the other hand in Python you would just use numpy which deals with all of that for you. I think what makes Python high level in this case is as much 'how high level can you take it' - Python+numpy lets you do advanced vector operations very very fast with a few lines of code without ever thinking about memory, primitives, etc etc. I don't have much experience with C++ but i get the feeling you never can totally ignore the low-level stuff. As for Rust, the language as it stands probably lacks a few too many libraries and syntactic sugar to make it really high level, but I get the feeling it could definitely get pretty close - although since it will always have this focus on safe memory management it's hard to see it ever being as high level as Python since there's always that extra thing to learn. What I like though is the emergence of smart API patterns which make it very straightforward to do things in the right way (and I'm learning to write other languages better thanks to this)
Yes, this looks much better.
That was exactly my main argument. :)
Huh, I thought that aarch64 can run 32-bit binaries (provided that you have 32-bit libs installed). Although, I've never used aarch64, so maybe it's not that simple. But still, you could probably adapt ruststrap (linked in forementioned post) to aarch64.
Does not compute.
The docs [are up now](http://gtk-rs.org/docs/gtk/) but since the project is far from being finished they've not been polished at all and there're some unresolved questions having to do with automatic generation and rustdoc limitations...
Thanks for the help! What if I were to declare `Cursor` but not assign it, though? I tried that initially and the borrow checker still complained about the lifetime of `final_bytes`.
Out of regular job and some experiments not yet ready for public release, I am improving my super-small utility to search crates from the terminal: scrutch https://github.com/mseri/scrutch 
`split_at_mut()` isn't all that special, it's just this: fn split_at_mut(&amp;mut self, mid: usize) -&gt; (&amp;mut [T], &amp;mut [T]) { let len = self.len(); let ptr = self.as_mut_ptr(); assert!(mid &lt;= len); unsafe { (from_raw_parts_mut(ptr, mid), from_raw_parts_mut(ptr.offset(mid as isize), len - mid)) } } (ie, it just checks that `mid &lt;= len`, there's no compiler magic or anything)
Yeah, when I said "encode the special knowledge" I was trying to get at the fact that the function can't be written without unsafe code, but the way it's written guarantees that it still doesn't violate the aliasing rules.
This just converts an option into a result though, it won't panic which is what the example code wants.
This last weekend I published my first crate: [couchdb](https://crates.io/crates/couchdb), a CouchDB client library. Now comes the long, long task of making it better.
&gt; although since it will always have this focus on safe memory management it's hard to see it ever being as high level as Python There are plans to have a Garbage Collectors as libraries, for those situations (graph-like structures, notably) where it's easier. I think that it would be easy to highjack those for scripting in Rust.
If you indent each line with 4 spaces... // like so fn main() ... You can get formatting like you want.
You do not need `pub mod xml` in your `xml.rs`. Whole file is "wrapped" in that by default. Remove it and everything will work as charm.
You're making another `mod xml` inside your xml module. In that case it would have to be accessed via xml::xml::read() and xml::xml::write(). Get rid of the extra module definition and you'll be fine. Remember, these are identical: ###### main.rs mod thing { // code } and ###### main.rs mod thing; ###### thing.rs // code
Oh my god, you have no idea how long I have been fighting with this. Thank you so much! Also, you guys were on that *fast*.
Indeed they are!
I starred this as soon as you pushed the repo up, I think you're right and look forward to the results
Been busy working on [VNDF](http://www.vndf.de/home) this week. We implemented mouse and keyboard controls to a degree, camera easing to follow ships, some visual queues like ship paths and selection, and other tid bits/fixes. Hanno has also been busy building a cli based ide to help with development, since the project structure is quite large at this point. The idea being that this will help where scripting may not, since we're both developing on different platforms, it's proving very useful.
The community is really good at answering questions, if you're stuck on something, don't wait too long to ask your question!
Function argument lists are patterns too... struct Point { x: i32, y: i32 } fn foo(Point { x, y }: Point) { println!("{} {}", x, y); }
Tried this for fun: fn foo(e @ 1 ... 5: u32) { println!("{}", e); } It returns this error: **error: refutable pattern in function argument: `_` not covered** Can you actually cover it?
It is a part of [binding pattern](https://doc.rust-lang.org/book/patterns.html).
I'm not sure you can restrict the possible values of a type in a function signature. For instance, you can't know at run time that only the specific values allowed in your pattern will be used in the function call. It might be interesting if you could have separate functions that took different ranges of values but that would would be much more simply obtained by using the if let pattern you mentioned in a single function.
You forgot 0...
Right, thanks for pointing that out.
Even easier: let x = 2; if let 1 ... 5 = x { println!("got a range element {}", x); }
Chipping away at this relational query engine - https://github.com/jamii/imp
Nice. Can you put a link at the top of the readme and tell crates where the docs are? They aren't discoverable as it is. It's fairly typical to put the docs at the top near the travis icons like [here](https://github.com/rust-lang/regex)
well, x
The next crate versions ought to have the good documentation link, yes. As to the repos, I'm considering moving various consumer docs to the site.
Awww... Though to be fair I can't think of a single case in which this would be useful.
Well that example could be expressed with a regular `if` block. A pattern match *and* a guard? No, unfortunately. I've tried. You could do it with two nested `if`s, but that's more verbose than using `match`. 
For every `Cursor&lt;T&gt;` you assign to the `cursor` variable, if the `T` is a reference, it must be a reference to something that exists for the entire lifetime of `cursor`, meaning it must be declared before it and dropped after it. Borrowck determines lifetimes based on declaration, not initialization.
I had originally started writing my chess engine in C++ but after looking at rust decided to write it in rust instead. I'm really impressed with the language and the community! Rust has a refreshingly modern and capable build system with cargo and rustc, all of the design feels well thought out and any questions/complaints I have are either being addressed or are quickly explained by the community. Thanks for taking a look at Crabby!
You're actively working on non-lexical scoping? Sweeeeet!
Congratulations on your release. I was seriously thinking of rewriting my chess engine, Hakkapeliitta, in Rust for a while but decided against it due to a few problems with the language which in my opinion make it a bit unsuitable for developing a top 20 engine, at least for now. I do hope Rust works out for you. Oh yeah, why haven't you made a thread on TalkChess already? I think there would be a few guys who would be interested in this there.
You should try out using abomonation too! At least to see if you like the feel better than Capn'proto (direct structs and stuff). It has limitations surrounding portability, but always keen to get feedback! https://github.com/frankmcsherry/abomonation
Thanks! I'd be interested to know what problems you encountered with rust. I was holding off posting to TalkChess until I had finished implementing a better time management system. This is my first attempt at writing a chess engine so all feedback would be greatly appreciated! 
Not that I expect the compiler to be this nearly this smart, but matching on eg. the value of a three-bit flag, it's annoying to write the `unreachable!()` case.
There's no easy way to do this unless the SafeCallback happens to be ABI compatible with the unsafe callback, which AFAIK, can never be relied upon in rust. Another way is to dynamically generate a new unsafe-callback on the fly for each SafeCallback provided. You do not want to be doing this, as it's all architecture specific, and may fall fowl of data execution prevention. Finally, in some circumstances you can use a [scoped] thread-local to store the SafeCallback. This is only possible if you have full control over when the callback will be called, and on what thread it will be called. (For example, this would work for the EnumXXX style functions in the windows API). A truly general, portable, safe solution is not possible: really if the API doesn't less you pass in some kind of user-data, then that API is broken and should be fixed.
I am not sure how well the rust type system would support this (it would probably require specialization, overlapping trait instances, negative traits, or something similar), but maybe use the normal "enum" serializer for any of these wrapped cases? // pseudocode from 5 min look at serde code impl&lt;T&gt; Serialize for Option&lt;T&gt; where T: Serialize { // existing code } impl&lt;T&gt; Serialize for Option&lt;Option&lt;T&gt;&gt; where T: Serialize { fn serialize&lt;S&gt;(&amp;self, serializer: &amp;mut S) -&gt; Result ... { match *self { Some(ref value) =&gt; { serializer.visit_newtype_variant("Option", 0, "Some", value) } None =&gt; { serializer.visit_nothing () //... dunno the api here } } } } Or, maybe you can just hack it and use unsafe to check if the value is a null pointer, but having a serializer depend on optimiziation behavior of rustc is probably a really bad idea.
Yeah I think I'll just build one on my own. It should be easy to do in a lockless way using atomic indices.
There's always the potential for overhead but a parallel map shouldn't actually require a mutex over the entire array. I think what you can do is use an atomic index that each thread acquires and increments, then have each thread insert their results into the new vector at that index. This should be threadsafe, works with pooling as well.
I have nothing to do with it, but [it is being worked on, and it's expected to be done at some point in 2016](http://blog.rust-lang.org/2015/08/14/Next-year.html). Just thought I'd brighten everyones' day by reminding them that there are developers out there whos' support for Rust is entirely conditional on this getting finished, heheh.
Yes, the mutex is the main thing I have in mind when I talk about unnecessary overhead, and why crossbeam is interesting (it allows for very high-performance lock-free queues, see the linked blog post). If you specialise to a single container the question is different, as you say, retrieving elements from a vector simply involves bumping a pointer which can be done atomically. However, this isn't possible for general iterators: the `next` function can be arbitrarily complicated/thread-unsafe. `simple_parallel` is aiming to handle general iterators. (That said, there's some questions about when the memory, e.g. a vector, gets cleaned-up/destroyed that need careful handling in concurrent settings, again, part of why crossbeam is so interesting. This means it isn't necessarily as easy as you're implying to get even the vector case to work well.)
Having an unexpected index out of bounds panic in a function that was generic over Index, I wanted to know for debugging purposes what the bounds actually were as a first step to figuring out why they went outside. For the moment its moot, since that function was part of a larger dead end in my ongoing battles with lifetimes.
Regarding the `is_token` change, how does a `match` expression compare? It might be more readable but still compile to efficient code.
I'm getting `thread '&lt;main&gt;' panicked at 'arithmetic operation overflowed', src/util.rs:39` when I try to run it with `cargo run` BUT when I try to run it with `target/release/Crabby` I uses up all my 8GiB of ram... I'd really like to try it. I'm running Arch linux, rustc 1.3.0 if it helps
I found a nice [article](http://www.cjqed.com/blog/rust-pattern-matching-performance/)/[discussion](https://www.reddit.com/r/rust/comments/2lk58q/on_pattern_matching_performance_in_rust/) from about a year ago. It looks like pattern matching has similar gains.
The fact that this is works, as is, today, makes me excited and optimistic that impl trait for abstract return types is closer than most people realize :)
Another way of expressing it is using `Deref`: struct Ray { ... } struct DifferentialRay { parent: Ray, ... } impl Deref for DifferentialRay { type Target = Ray; fn deref(&amp;self) -&gt; &amp;Ray { self.parent } } 
Some of the arithmetic to generate moves relies on overflow for correctness, you'll need to run with cargo run --release to allow overflows (If this was unclear I can update the building section). I really don't know why it would use up so much memory, it shouldn't use more than around 300 MiB. I've only tested on the latest nightly compiler, if it wouldn't be too much trouble for you to update to the latest nightly that would probably solve your problem. Thanks for testing and let me know if you run into any more problems!
If you need wrapping behavior you should probably be explicit and use [Wrapping](http://doc.rust-lang.org/std/num/struct.Wrapping.html) or the [wrapping_* methods on integer types](http://doc.rust-lang.org/std/primitive.usize.html#method.wrapping_add).
A RSA implementation? Wonderful! `rust-openssl` interface leaves a lot to be desired, IMO.
Sure. 1. The multithreading algorithms used in chess engines usually have very unlikely race conditions in them, and getting the code past the borrow checker would be hard. The race conditions are left there because fixing them would cost a lot more than it would gain. 2. One of the key components of a chess engine is a multiple-reader/multiple-writer fixed size hash table. Seems like I would have to use unsafe quite liberally to get it past the borrow checker. This is slightly connected to the last item. 3. When I last checked, overflowing arithmetic was pretty badly supported. Seems like this is solved according to the posts above. 4. No type level integers. Can't have arrays of size 64 with proper support for operators, can't have some other nice stuff (without lots of duplication) like two evaluation functions, one using hardware POPCNT for newer machines and one using normal instructions found everywhere. 5. Last time I checked, you couldn't initialize a global struct with some sort of a function. It's very annoying to have to pass an immutable reference to some struct around everywhere when it could just as well be an immutable global. There were some others but I can't remember them right now. Probably nothing important. I couldn't find anything immediately wrong with your program, except perhaps the fact that you might not want to do null move when there are no pieces left. And possibly that your LMR-code is a bit broken. Usually we do a reduced depth null-window search first, then a null-window search if the score of the last one was &gt; alpha, and finally a full window search in case a new PV was found. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell] [\[x-post /r/rust\] Parser Combinator Experiments: "80% faster compared to Attoparsec"](https://np.reddit.com/r/haskell/comments/3k2cvn/xpost_rrust_parser_combinator_experiments_80/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I hope we get self in functions patterns somewhen as well: struct Point { x:i32, y:i32 } impl Point { fn increment(Point{x, y}: self) -&gt; Point { Point { x: x + 1, y: y + 3 } } } That would be sweet
Aren't ADTs applicable here? 
It costs the overhead of a Differential structure. If that's a problem you can replace the field with: differential: [Differential] This will make Ray a DST, so it will only be usable via a pointer unless you know the concrete type (this is the same limitation that the C++ code has). However, it will have zero space overhead (possibly even less that the C++ version if it has a vtable). In your case, the slice would only ever have either 0 or 1 elements in, so you can treat it a lot like an Option&lt;T&gt;.
Encountered this from crates.io. I haven't tested but the basic server functionality seems to work. Given the amount of prior works, I guess this project would benefit from more visibility and thus I've posted it here.
As /u/DroidLogician noted, function arguments and `let` can only contain *irrefutable patterns*, that is patterns which always match. `if let`, `while let` and `match` arms on the other hand can contain *refutable patterns* which only match some of the possible values of their domain. Consider this: what would happen if somebody called `foo(0)` or `foo(6)`? Rust can't just not call the function as it might return something, but it can't call the function either because the pattern doesn't match so you would get an unexpected value for `e`.
I was thinking about this the other day and ended up writing the following snippet: https://play.rust-lang.org/?gist=521de2600b2e106fe308&amp;version=stable It returns two mutable references into a slice/vec using split_at_mut.
And just barely at that at position 50.
I'm sure we'll beat Ladder Logic soon enough :P
I'd be content if we beat Go within the next year. Not because I dislike Go, but: * It came up at a similar time as Rust * Both are often compared (if you like it or not) * It is _doable_ Friendly competition, mind you.
Would it be more rustic to use `as_ref` here? * https://doc.rust-lang.org/book/borrow-and-asref.html * https://doc.rust-lang.org/std/convert/trait.AsRef.html
Indeed! *click* I always forget stuff like that.
I would be very surprised if Rust beat Go in the next three years.
Still 17 places behind _Prolog_. Goodness.
When i see cobol in top 20 i'm like 〴⋋_⋌〵
Have you programmed something in COBOL?
&gt; Google is weirdly bad at pushing into developer communities Just look at Dart. That was all over the programming subreddits a couple of years ago, but how long has it been since you've heard anything about it? 
A struct size/alignment checker might be useful for lots of FFI bindings.
I'm keeping that one in mind. That is something I was planning to integrate in nom :)
You can either use the http://doc.rust-lang.org/stable/std/ search, or you can grep the source code using `grep -r 'enum Ordering\&gt;' src/lib*`.
Prolog is very popular in some scientific communities and often on the curriculum in many universities. I'm not surprised. That field might be out of our filter bubbles, but it is vast.
Mathematica dropped out.[ref 1] Note the mention for languages in the range between 51- and 100 though: &gt; The following list of languages denotes #51 to #100. Since the differences are relatively small, the programming languages are only listed (in alphabetical order). That probably applies to fringe languages as well. 1: http://web.archive.org/web/20150815091839/http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html
&gt;Seems like the function requires the address to the variable (I'd like to know why) Probably because some comparable things can be large and not cheap to copy/not copyable, etc, see the implementors of Ord: http://doc.rust-lang.org/stable/std/cmp/trait.Ord.html
First, you may want to check if your editor of choice has a [racer](https://github.com/phildawes/racer) binding – this gives you autocomplete. Also the docs are usually quite helpful. Regarding references vs. values, you may want to read the [chapter on borrowing](https://doc.rust-lang.org/book/references-and-borrowing.html) for some enlightenment.
Legacy code is legacy code in any language.
Oh my, this looks delightfully scary! I'm already running into instances of node-specific local state that I don't want to encode to toml (e.g. the user has no reason to modify it) but it'll never be sent over the wire...I think that would be a perfect use-case for Abomonation. Fast serialization without having to jump through hoops to use non-native structs. Thanks for the suggestion! I just read your [article about Abomonation](http://www.frankmcsherry.org/serialization/2015/05/04/unsafe-at-any-speed.html) and really enjoyed it, very clear and enjoyable writing style. I'm now slowly ingesting the rest of your blog :D
Prolog is like magic when it is the correct hammer to use.
Golang development (and funding) began in 2007, Graydon started working on Rust in 2006, funding started in 2009. They are about the same age and were in private for about as long. Looking back at how Rust looked in 2010, when it was first announced, I would also say that it looked a lot like Go back then, also explaining many of the changes in Rust (there is just no need for a second golang). 1.0 or not is of academic interest if you speak about community building. Node is a very unstable piece of software that still has ways to go towards 1.0, that doesn't stop the popularity of the ecosystem. I know the history of both languages a little. FWIW, I've been around here since mid-2013.
I think the Go and Rust communities are pretty different, as are the languages. Most developers come from dynamic languages and maybe C to Go, and I expect that Rust attracts developers using strong static typing. The question is, whether Rust attracts more developers of its potential user base than Go does.
Part of the issue is that it takes A LOT MORE in the JS world because of the popularity and sheer volume of stuff to choose from. While it is a BIT overblown, there is some truth to the meme that if you don't like today's JS frameworks, wait a few hours.
&gt; True - at that time, Go was more popular and many people didn't have that much of an interest in Rust. In that case - to extend a little - I'd say their community work track record is not the best. They had five years and are not that far ahead. If Google were serious about building Community, I'd expect there to be a Google-run conference or event on every continent. Which fits my argument that Google considers that a by-product. &gt; I disagree. Before 1.0 (at least far before 1.0), Rust was known as "that language that constantly changes syntax" and that constantly breaks, and that prevented the community from building and from people building things on top of Rust. When Rust announced 1.0 (and a little while before then), the community exploded and now it's a lot more active. That doesn't really fit Rust filling rooms in many places even before release. Sure, it was new and not to be used _productively_, but that doesn't bar people from picking it up before 1.0 and start running things. Building communities is surprisingly detached from the quality of the software. Rust might have been a plaything for a long time, but a lot of peoples _favourite_ plaything. My comparison to Node was obviously a jump, I just wanted to mention that stability guarantees are not necessarily the topmost thing. Also, Node doesn't shy away from API breakage (there's a reason why they are sub-1.0), that's why I mention it. &gt; As do I, and I've been around here for around the same amount of time as well. I haven't done anything official, mostly just lurking, but that shouldn't make my argument invalid. It doesn't, and I didn't want to imply, just providing context.
Really sorry for missing that out. I'm on Ubuntu , using Sublime text, installed using package installer Here's how my racer's settings file looks: { // The full path to the racer binary. If racer is already // in your system path, then this default will be fine. "racer": "racer", // A list of search paths. This should generally just // be the path to the rust compiler src/ directory. "search_paths": [ "/home/git/rust-lang/rust/src" ] }
My primary interest in Rust is whether it will be a realistic language to use for embedded in the future, which is something Golang can never be.
This is where I'd suggest using `git grep` instead, and then someone else will suggest using `ack` or `ag` as well. 
- Adding support to [conrod](https://github.com/PistonDevelopers/conrod) for composing widgets from other widgets (useful for custom widget designers). - Writing a testing and live performance GUI for my generative music engine (using conrod). - Release some stable bindings around [liblo](http://liblo.sourceforge.net/) for OSC (all the other OSC crates seem to be unstable or unfinished and abandoned). - Putting together some slides for an upcoming creative coding workshop (with plenty of sneaky rust mentions).
Works is a bit of an overstatement. I can get it to compile and run, yes, but only if I hack the compiler and circumvent a part of the memory-region code (lifetimes) related to `impl Trait`. This seems to make all undecided regions for `impl Trait` default to `'static`, and I have not yet come to any conclusion about the implications of this but I imagine that it is not good. I am currently looking at this to see if I can help and fix it properly, but there is a lot of material to read on this topic. In the code I use it works and is probably sound since the scope of the input is longer than the parser used, both only operate inside of the `main` function, and the input outlives the parser itself and the lifetime of both is essentially for the whole run-time of the program. But in a general situation the `'static` lifetime default is probably not sound. At least this post managed to spark some life into the [RFC](https://github.com/rust-lang/rfcs/pull/105) :)
I just want to say that you *are* a Real Rustacean-- the only barrier to becoming one is deciding to call yourself one :) We're really welcoming here, of people of all levels, and your programming ability does not define your identity. I would encourage everyone to think of these kinds of questions as "How could *this rust code* be more idiomatic" (where the code has the attribute) not "How could *I be more of a real programmer*" (where the person has the attribute) &lt;3
You can also use http://doc.rust-lang.org/stable/core/nonzero/struct.NonZero.html to make this optimization kick in...
&gt; (The difference being that &amp; lets you share it with lots of functions at the same time, whereas &amp;mut only lets you share it once at a time.) To add on. Its useful to think of `&amp;` as the borrow operator, not the 'address of' operator. Some types don't `&amp;` to a single address for instance `String` `&amp;`'s to `&amp;str` and `[T]` `&amp;`'s to `&amp;[T]`. These borrowed types are fat pointers that contain a pointer to the data and a length. And can be thought of borrowing a view into the data. Using `&amp;` with a Trait in a signature will allow access to a trait object which contains a pointer to the data and to a vtable. And can be thought of borrow access to the trait methods.
Does not seem to be directly usable as a replacement since the signature is `u8 -&gt; bool`, and the number of allowed/disallowed characters are way more than 16. Additionally the parser filters are currently only operating on one byte at a time which is also a problem. But this is definitely interesting, SSE instructions like those could probably help a lot as a specialized variant of eg. `take_while`, `take_till` and similar parsers to quickly consume input.
The racer config looks normal. I'm on LUbuntu, so this shouldn't be out of the ordinary. I use RustDT or Atom with racer, though, so I cannot tell if Sublime does something strange.
Ooh, I like this. Thanks!
Someone posted [this](https://www.reddit.com/r/SublimeText/comments/2q816e/sublime_creating_new_temporary_files_on_each/) earlier, and it was suggeted that they add the full path to racer. That is "racer": "full_path_to_racer" so I changed it to `"racer": "/home/.local/bin/racer"`but that doesn't help either.
It's a completely meaningless leaderboard of how many results turn up using a selection of search engines (like e.g. Google, Bing, and the like). Still, despite TIOBE's own claim of meaninglessness, some people view it like the Magic Quadrant^TM of programming languages.
Have you seen https://github.com/jwilm/chatbot? It is a platform like Lita or Hubot for building chat bots in rust. Depending on what your goals are, it might make building your bot easier.
You sure have strange paths.
Technical commitment is something very different from community commitment. Their reasons for keeping openjdk strong are completely self centric: they use it a lot and they need it for independence from Oracle. Also, their track record of stopped projects that need community building shows that you shouldn't fear Google there, but sternly look in their eye. It's all synthetic. Mind that ability doesn't come with money. Even if they would throw money at a project, I'd assume that they can't muster enough personnel and internal support for many of those endeavors as a company.
I do? What's strange about `/home/.local/bin/racer`?
I'm continuing to develop a debugger in Rust: https://github.com/joekain/rusty_trap. Yesterday I refactored some of the code used to wrap ptrace.
I agree, that's why I said that I want to use it as a benchmark, nothing more. With the current growth of the sector, Go and Rust will still be pretty well off if they only get a fraction of the cake. I did a lot of community work in the Ruby space, which was always considered a fringe. A fringe with half a million developers or so and a couple of high-profile companies starting off with it :). I just consider Go a good benchmark because of similar size, similar outset and comparable age.
It's a way of estimating the [popularity](http://www.tiobe.com/index.php/content/paperinfo/tpci/programminglanguages_definition.html) of different programming languages. There's some statistics involved, but it basically boils down to looking at how many hits different search engines get when looking for "_____ programming language".
&gt; Oddly enough, I've seen this a lot more in the AngularJS community, where there are some conferences (or... at least one conference). Angular is not an original Google Project, which might play into that. It didn't enter the minds of many people that it has that name attached to it.
It's coming.
It's actually /home/username/.local/bin/racer. Removed the username for privacy reasons. Forgot to add a placeholder.
Yes, from what I see, it should not be too hard to add it
 - Great point, will be updating that. - I was thinking on ways to implement it, this was more of a base of getting something to work, I will most probably be renaming `Tag` to `Element` and adding the `Vec&lt;Node&gt;` as mentioned so that you can have number of `Element`s branching correctly. - I removed those, does make sense to keep them as is. I cannot test the first point right now however it does make sense they way you are putting it; I'm just so used to being able to freely cast things back and forth (regardless of the safety implications). Greatly appreciate the input.
Ah, I see. Since you are on UNIX, you could lsof to find out whether racer or sublime creates the tmp files, then open an issue.
So, I improved nom a bit, and added `take_till`, `take_while`and `take_while1`implementations. I needed to add them anyway, and that way the nom version is closer to your own. My test was to load the `http-requests.txt` file and parse every request, for your parser and nom, in a Bencher. Here are the results: * your version: 90,508 ns/iter (+/- 8,461) * nom 0.3.11: 127,902 ns/iter (+/- 24,186) * [nom 0.4.0](https://gist.github.com/Geal/74723635420d8adc8031): 59,022 ns/iter (+/- 22,236) There were a few inefficiencies in my iterator usage ;) Anyway, your work is great! This is definitely something I would have liked to do when I started nom, but the type system was not as flexible a year ago.
More like spark some ire from Nagisa :P I think I simply disagree with Aturon. Abstract return types really are orthogonal to other features, and you have code using it, that works! So there should be discussion and comments on minor details like syntax. Get it out of the way now so people don't have to do it later.
If you make the fields public (which I think it ok because immutable-by-default etc), you can get rid of all your "new" functions. Also, I tried replacing the build() function with implementing the Trait ToString but I'm not sure I improved anything... My "solution" in play.rust: http://is.gd/jz1B1y
Interpret with a big grain of salt, sure, but *completely meaningless*? No, of course not. Edit: I must have been reading you too literally because you were even making predictions about the future rank above so it must mean *something* to you. Even if it's just a fun proxy for a real number that's impossible to measure.
I was of course exaggerating. I keep forgetting that this is easy to overlook in written text...
In fact it's only almost as meaningless as Gartner's Magic Quadrant^TM :-D
That's great! I completely understand the desire to build bots from scratch - they're fun!
Well, I am impressed by what is already built! The list of features is big for a first shout-out!
&gt; you'll need to run with cargo run --release to allow overflows Please do note that running in release does not guarantee wrapping overflows; it just happens to work right now, but there's hope that overflows will be detected (maybe only partially) no matter the compilation mode at some point.
Correct.
You can see how the WebSocket Library uses channels on top of mio by looking at InternalReader, InternalWriter, and the code in WebSocketServer::ready related to input_rx and output_tx.
You can't argue about the history of node.js by mentioning a event that has only happened over the course of less then a year.
Blindly overwriting a file in `/etc` is a bad advice. Also the path is wrong.
racer also supports jump to source perfectly, which is also so useful for exploring a codebase. 
&gt;I made the announcement on my [blog](http://words.steveklabnik.com/the-rust-programming-language-will-be-published-by-no-starch-press), but here's the text too: &gt; &gt;I'm happy to bring you some news: ["The Rust Programming Language"](http://doc.rust-lang.org/stable/book/) is going to be published, in physical form, by [No Starch Press](https://www.nostarch.com/). I am really excited to work with No Starch on this: they've published some of my favorite programming books, like ["If Hemingway Wrote JavaScript"](https://www.nostarch.com/hemingway), ["Ruby Under a Microscope"](https://www.nostarch.com/rum), and ["Ruby Wizardry"](https://www.nostarch.com/rubywizardry). &gt; &gt;Another reason I'm keen to work with No Starch on this is that they believe in publishing freely available material: we're going to take the existing manuscript, whip it into shape, make a nice paper book out of it, and merge the changes back into the official documentation. So the improvements will get back to everyone, even those who can't afford a physical copy. &gt; &gt;Oh, and one last thing: the profit from the book won't go to me, it will go to [OpenHatch](http://openhatch.org/), "a non-profit dedicated to matching prospective free software contributors with communities, tools, and education," to use their words about it. &gt; &gt;I'll let you know when we're closer to actually shipping! 
You are correct. A single `Handler` implementation per `EventLoop` instance is technically a callback. I was not precise enough. I should have said that I do not like specifying a callback per operation (aka, libuv / nodejs style). When writing non-blocking IO code, I take a state machine like approach. Events, in this case readiness notifications, enter the system at a single point vs. spread out throughout the entire system. Each event enters the same location, takes the current system state, and transforms it.
Yeah.. that's a bit confusing!
That's one very interesting blog! Thanks for sharing.
Another useful approach: there's actually a src link in many of the std docs. Look at the top right of the page. Steps: 1. Use your bookmark to the [std docs](http://doc.rust-lang.org/std/) 2. Hit s to activate the search box and search for [Ordering](http://doc.rust-lang.org/std/?search=Ordering) 3. Click top [result](http://doc.rust-lang.org/std/cmp/enum.Ordering.html) 4. Click link on top right to the [src](http://doc.rust-lang.org/src/core/cmp.rs.html#104-114) (Ideally you would also have a good jump to source setup in your editor. I haven't done this yet myself though so I can't recommend one.)
*sigh* And here I was deluded into thinking that if we didn't do it that way (/u/nrc even had a RFC for `&amp;` always changing the type), nobody would assume it's done that way. `&amp;` on a value of type `T` produces, *always* and without any doubt, a value of type `&amp;T`. However, a value of type `&amp;T` is automatically converted (aka "coerced") into a value of type `&amp;U` if there is a chain of `Deref` implementations from `T` to `U`. As an example, if you call a function that takes `&amp;str` with a `&amp;Rc&lt;String&gt;`, it will use `Deref` to go from that to `&amp;String` and from `&amp;String` to `&amp;str`, and the call will work.
IIRC, modules are already out of C++17, though they should be de-facto standardized shortly after, so it's expected that you'll be able to use them, even if they won't be offiical till 20.
Hi everyone, it's my first post on r/rust! I've also put my first rust repo: https://github.com/rednum/interval_trees Feedback very much appreciated. Some things that concern me: * where to put examples? I put something in tests/ but it doesn't seem like a great idea * I'm not sure if my structure should take ownership of things (should I use refs more/less?) * it probably makes sense to improve the documentation - I'm not sure what would be more useful (besides adding doc comments in source) * I think my tree should implement some "standard" traits, but I'm not sure which yet I'll also probably generalize this to some other data types/operations (in fact I wanted to use num::traits::Num instead of i64, but then to add nums I would have to use add method from Add trait, which is in core, which is unstable - and I think I'd stick to stable right now - unless I'm misunderstanding something here?). 
Well, the title of the repository is rust_parser_experiments. If I did not try different approaches I would not be experimenting :) Hopefully I can create a proper library from this at some point.
 trait AssLice { fn associated_license(&amp;self) -&gt; License; }
Exciting stuff! I love that the authorship credit isn't going to a particular person. While of course /u/steveklabnik1 did a ton of excellent work getting the book written, there were a number of other people that contributed too. Congrats to everyone who contributed! I look forward to buying a copy (or three) to give to friends.
If you're looking for something in the standard libraries, use DXR: https://dxr.mozilla.org/rust/source/ Ordering is at https://dxr.mozilla.org/rust/source/src/libcore/cmp.rs#105 You can click on names to find references, impls, etc.
Thank you, I will be sure to pop my head in there one of these days. It didn't even occur to me to look for an IRC.
Will the book be exactly the same thing with the official documents at a certain time stamp? And will it follow any updates? Rust is rapidly growing language, so I'm worrying it become stale soon.
This is something we definitely took into consideration. &gt; Will the book be exactly the same thing with the official documents at a certain time stamp? Yes. &gt; Rust is rapidly growing language, so I'm worrying it become stale soon. While it may be *growing*, it's not breaking anymore. So the stuff that's in the book should still be valid long into the future, though obviously idioms may change. We won't be putting out "every six weeks" releases like the actual language, but depending on how popular it is, will refresh it in the future. Most books on things like languages change yearly, we'll have to feel out what the right way to do this is. 
There's already a thread: https://www.reddit.com/r/rust/comments/3k4rcb/the_rust_programming_language_is_going_to_be/
Can we see some examples of the code you'd use RayDifferential and Rays in?
Will No Starch Press also be selling DRM-free ePub format eBook versions of the book?
While I think donating the money to that particular charity is awesome, I'm sure you also thought about donating it to the mozilla foundation. What were the arguments that played a role in taking the decision to go for that charity?
same here
Absolutely, we'll make it very clear. Thanks!
For `impl` inheritance one can just implement `Deref`, but I don't know if this is the most rusty way to do that. 
Same, Firefox on Linux.
You might be looking for /r/playrust.
Perhaps the posters are on mobile.
I just thought I'd add to this that Rust's syntax was designed with grepability in mind; if you know what category of thing an item is, you can always easily grep for its definition (e.g. if its a struct, its `struct Foo`, if its a trait its `trait Foo`, etc). This is true even for functions - `fn foo` - whereas the syntax of many languages (e.g. C, Java) make grepping less convenient.
I published a simple library today: [termsize-rs](https://github.com/nicokoch/termsize-rs) It is very useful for TUI applications (I plan to follow up with a terminal-progressbar library)
I'm confused as to how you can make a server in Rust. Don't you need the ability to kill a thread (which I can't find any support for).
I'm not sure where to start. I've never bothered with fetching fonts. Why not let the browser use whatever the default is? (Ah... Probably because you're trying to mimic rust-lang.org.) rust-lang.org works. If you tell me something else I can try, I'll do it! I just tried removing only `Fira Sans` from TWiR, and that fixed things too. But you're right, `font-family` on rust-lang.org appears the same to me too. I'm running Chrome `47.0.2498.0 dev (64-bit)`. This issue also happens on my system with Firefox `40.0.3`. (I'm on Linux.)
Oh, geez, thanks. :) I corrected two small typos. I didn't give the RayDifferential a Ray field in the third implementation, and I accidentally had "differential_ray.bits" instead of "differential_ray_bits" at the end. Silly typos, should have caught them. In any case, I'm glad you liked the examples, but the last two are not very good ones of the concepts they're trying to represent. This is important! Even when you try to make the code more abstract, it all still looks like the very first example with composition. The simplest way to do it was really the best way. In a language with carefully considered, orthogonal features, you will not accidentally use the wrong abstraction because it will be obvious which one to use. ...Rust is sometimes not that language. Especially when you do very complicated things with lifetimes and associated types. But more often than not, it is well designed. In c++, I think there are a lot more things to take into consideration. Do I use inheritance, or composition? Multiple inheritance? Templates? Half of the reason why I responded to you is because I think there is a dearth of material on how to write code in a systems language that is not object oriented. The designers of Rust were obviously very opinionated. But unfortunately I have not necessarily seen a lot of help for people coming from those kinds of languages and easing into a relatively functional paradigm. If someone can prove me wrong on this point I would actually be quite delighted.
I'm using Fira Sans, because that's what rust-lang.org uses (and few other Rust official sites). Also, CSS lists multiple fonts ("Fira Sans", "Helvetica Neue", Helvetica, Arial, sans-serif) so browser is free to fallback to other fonts if it doesn't understand Fira Sans. If you go to https://fonts.googleapis.com/css?family=Fira+Sans in your browser, what is the format of the font that Google is giving you? (To me it is "woff2").
Coming from a primarily C++ dominated background, some of Rust's functional-ness has been a bit of a challenge. In general, I think I can see the appeal, and its functional tendencies promote things that I admire, such as an expressiveness while still being performant. If anything, my C++ coding has been taking a slightly more functional turn as of late, approaching what I hope to be a happy medium. The height of my OOness occurred a few years ago, when I first had to pick up Java for a project. It was a rather mind-blowing experience. Interfaces for everything! No one knows what the future holds! Don't lock yourself in to any implementation! Swap them out at runtime for giggles! As I came down from that high, I realized that, while a very clean way to think, it was often unnecessary, as in many cases, more than one implementation of an interface never needs to exist in the code at one time. And so I began to ween off the virtuals, and sprinkle in more data-driven functionals; where appropriate, of course. There's a happy medium in all things, including the coexistence of OO and functional programming in the same codebase. I suspect Rust will help me understand that a little better.
More worrying is that it's on on the rise. With double arrows...
Holy crap this is honestly what I need; I've seen it once in the Rust book I believe but I completely forget about it.
Thank you so much for the batch of code; going over it right now!
&gt; New RFCs &gt; Add Mutex::into_inner(). "Wow, someone already created an RFC for the issue I opened!" *clicks link* "Oh.." Is it a mistake in TWiR, or are issues considered as "RFCs" as well?
But any modern language(C,C++) legacy code won't make my eyes bleed
The nominations are done in the open. So if you know a little known crate, please tell us at [rust-users](https://users.rust-lang.org/t/crate-of-the-week/2704).
It's a good question. The corruption has a pretty easy answer I think: Abomonation checks the length of data, but not its contents, so corrupted utf8 would mean undefined behavior. On the other hand, a corrupted `Vec` length field should be ok (well, you'll fail to deserialize, but not sure what you do next). It isn't so hard to validate `utf8` data (just validate in the `String::exhume` method), but I haven't thought of a decent performance / bit-corruption-resilience trade-off interface. Also, what are the other bits that need validation (enums, bools, other things I don't realize and aren't spec'd anywhere... :))
I'm pretty interested in this and what if any conclusions you have towards how it might be fixed.
That rust-lang is still thriving, and there'll always be some people who find our reddit when they wanted /r/playrust instead :).
This is definitely odd, but there a precedents for that. Elasticsearch - the definitive guide is freely available on their website and continuously edited, but there is a printed edition for the 1.0 time. "There's books about it" is still a benchmark and many people still like paper for reading about new stuff. It can be put in university libraries (although this is mostly due to weird copyright concerning ebooks).
Excluding a bunch of Chinese companies I haven't heard of (of which there are many, [considering that China is most likely Go's largest adopter](http://herman.asia/why-is-go-popular-in-china)): Walmart, Apple, Intel, Google, Microsoft, Baidu, Qiniu, Cloudflare, Twitch, Cisco, Verizon, Dropbox, Adobe, New York Times, HP, Ubuntu, CoreOS, MongoDB, Rackspace, Iron.io, Heroku, Square, Spring, Tumblr, VMWare, Symantec, Comcast, CBS, SendGrid, Pivotal, Couchbase, Linden Lab, SolarWinds, IMVU, EMC, Teradata, and I'm sure many more which I'm unaware of, are all using Go to some capacity. It's nuts.
That's a good idea, I'll work on implementing that soon!
I believe that's their policy for all books, yes.
Add Mozilla. Still, adoption does not necessarily convert to a healthy and growing community buzz in a long run. For example, if all companies who are actually using Ruby somewhere (mind you, huge deployment systems are written in Ruby!) were vocal about it, the community perception would be upgraded significantly. I don't want to belittle Go in any form, but I'm not really buying into these kinds of absolute arguments. I especially can't find a striking reason why things shouldn't be ported Rust instead of Go. "X, but in C" is still a thing and often the reason is just a matter of taste. We know for 20 years now that C is problematic.
Thanks for the great answers folks. This was exactly what I needed to know.
i don`t know: http://www.oreilly.com/programming/free/why-rust.csp author: https://twitter.com/jimblandy
Great stuff!
I think for Rust to make it to the next level in adoption, there needs to be focus on development tools surrounding it. In the IRC channel the same borrow checked and type error questions come up from experienced programmers. I think for Rust to become less niche, an ide that visually shows borrow and type errors live will be a huge deal, just as live syntax checking was a huge deal for C#, vc++, and visual basic before them. It isn't enough to have a better designed language any more, the language needs to be better to use. All the most popular languages have this in common. The advantage though is the ability to both use and create libraries in Rust, and hopefully use them easily from within the ide with cargo. The holy grail is to need something (like a priority set for example) and be able to read descriptions, examples, and reviews from the ide, then click, wait 10 seconds, import it and compile. That experience with Julia (just using Pkg.install) is already pretty incredible. 
My usual impression with those sorts of comments/complaints is that the commenter needs to diversify their language experiences. Many of the of the 'new' conventions rust introduces can be found in either 19th century math textbooks or 70-year-old programming languages... I get the sense that there are a *lot* of programmers out there who are afraid of mathematics.
Meanwhile, the description talks about `&amp;mut Read` the trait object.
It's a bug with Arch. I think they have a bad font some package.
Thought I'd chime in (I'm one of the coauthors on the Definitive Guide). The Guide has been something of a grand experiment for us and O'Reilly...the idea of an OSS book was very new to them. But it has worked out very well so far. We get tons of small PR fixes (typos, grammar, missing punctuation, etc), and occasionally someone pointing out buggy or incorrect information. We'll run through the repo once a month or so and review changes and merge The community feedback has been awesome. People love the fact they can buy a physical book (I also enjoy physical books for technical material), and they love that it's also available for free online. Or that they can download a copy for a flight We were/are worried about information going "stale", but outside of large breaking changes, you'd be surprised how much remains constant between versions. All the details about low-level data structures, best-practices, etc are basically relevant from version-to-version. We'll need to do an overhaul of some sections for 2.0, but much less work than writing a whole new book. So basically, I'm super stoked Rust is going down this route too. It benefits the community immensely, physical books add a lot of credibility to a project (which is sorta silly, but there it is) and it helps push the idea that OSS books are not crazy fringe ideas, but something that more publishers should accept.
I'm not sure. If you or anyone tries it or anything else and finds something, please disclose responsibly. http://www.rust-lang.org/security.html
Ever heard of [Cyclone]? [Cyclone]: https://en.m.wikipedia.org/wiki/Cyclone_(programming_language)
&gt; As of this month, the TIOBE index uses an improved algorithm to calculate the popularity of programming languages So it's being compared to data that was gathered using a different algorithm, so I wouldn't bet on COBOL actually being more popular than it was last year.
This project is going to change the Internet. If I were able to code, I'd jump on this project just to be part of history.
Was there a specific reason that passing different Chains as handlers for routes wasn't working?
True. I think split_at_mut() would work for this. A single atomic index would be unnecessary.
&gt; Rust’s enumerated types are a departure from C and C++ enum types, but users of functional languages will recognize them as algebraic datatypes. Why no one calls tuples algebraic types, but when talking about tagged unions it is always mentioned that they are algebraic types without explaining what is algebraic type? This is stupid. I wouldn't be suprised if most people who use the term *algebraic types* don't even know why they are called algebraic in the first place.
I'm knot sure I understand the cover art.......
&gt; Would accessing an intrinsic be okay? Here's how to implement a PopCount trait based off them to get a popcount() method on all of u8, u16, u32 and u64 that returns the result. You don't need that; it's exposed as the `count_ones` method on all integer types.
Internet is always changing anyway :)
One justification might be... that tagged unions are almost always for both sum and product types, thus "algebraic." (I've never seen any languages whose tagged unions are *purely* for sum types.) Having said that, I sort of understand your frustration.
In the meantime, can you just remove the bogus font? Style is good, but content should really come first. And most people can't see any of the content right now.
Thanks for the help debugging the website issue. For now Fira Sans is just disabled.
I would use square brackets for type parameters, like `Result[Ok, Err]`. The reasons for this decision is that the parser sometimes stumbles on the symbol `&lt;`. A detailed explanation can be found in my [issue](https://github.com/rust-lang/rust/issues/22644)
Iterating by-value is supposed to return the values in the collection, but you're trying to return references. Note that the IntoIterator::into_iter() method should take self by value. You can instead implement the trait for references to your struct: impl &lt;'a,T&gt; IntoIterator for &amp;'a SlithyTove&lt;T&gt; { type Item = &lt;std::slice::Iter&lt;'a,T&gt; as Iterator&gt;::Item; type IntoIter = std::slice::Iter&lt;'a,T&gt;; fn into_iter(self) -&gt; Self::IntoIter { self.gyre_and_gimble().iter() } } For iterating by-value, you could forward the call to Vec::into_iter(), which returns a std::vec::IntoIter&lt;T&gt; (there aren't any lifetimes in that case).
No, that worked fine! And basically that's all this under under the hood. This is just a small abstraction to make things a little cleaner.
&gt; The design/art department decides what animal get's associated with each book, etc. Or knot, in this case...
Not really sure. One thing I miss from python is simple list comprehension like: vec![x for x in y where x % 2 is 0] or something. We're close to that with iterators, but it's not quite as clean as haskell/ python list comprehension.
for, if, while, and match expression for i in 0..5: println!("{}", i) if i % 2 == 0: continue elif i % 2 == 1: println!("odd") else: break # while is_good(): println!("yes") # use while true for looping forever while true: do_something() let y = match x: 1 | 2 =&gt; println!("one or two") 3 =&gt; println!("three") e @ 4 ... 5 =&gt; println!("got a range element {}", e) _ =&gt; println!("anything") let y = match z: Some(data) =&gt; data None =&gt; 0 match x: ref r =&gt; println!("Got a reference to {}", r) let origin = Point { x: 0, y: 0 } match origin: Point { x: x1, y: y1 } =&gt; println!("({},{})", x1, y1) my imagination run wild!
&gt; A Rust array type is written [T; n], designating an array of n elements of type T. When a Rust program indexes an array a with an expression like a[i], the program first checks that i falls within the array’s size n. Sometimes the compiler recognizes that this check can be safely omitted, but when it can’t, Rust generates code to check the array’s index at runtime. If the index is out of bounds, the thread panics. AFAIK this paragraph isn't that accurate. For one, indexes don't bounds check at all in release builds, correct?. And Rust doesn't do anything to optimize away bounds checks unless LLVM does, does it? The rest of this section is gets closer to the heart of it: Rust doesn't really do anything about buffer overruns as much as it is packed with idioms (mainly iterators) that discourage you from using the index operator.
Thanks. It would not have occurred to me to implement the trait for the *reference* type. It's doing what it should in my actual non-minimal case now too.
camelCase, ternary operator, pipe operator (`|&gt;`) 
I don't understand why some keep bringing up Google as a catalyst for Go's success. They aren't pushing it at all from what I'm seeing. They pay the salary for Pike and others and that's about the extent that I see Google doing anything for Go. About the only other thing it has done for the language was give it an initial boost because of the name behind it when it was launched. The community has grown along with its usage because people like the language and find it useful. I highly doubt you're going to find any of these companies that have bet the farm on Go doing it because... Google. Rust will enjoy the same sort of growth IF people find it useful in practice. This will take a few years to shake out just as it did with Go once it hit 1.0. This is why I'd agree that it would be surprising if Rust was able to pass Go sooner than that. But if its found to be useful it very well could.
Get rid of curly brackets. Use "do"/"end" (some of them being legal to omit in places if they're "mandatory" anyway... e.g. an "else" could be defined to also mean "end else" if there's no preceeding "end" to close off the innermost block). Or maybe "beg"/"end" so it makes more sense for structs. I feel this would make the language less line-noisy, and open up curly brackets for other, less common, things (e.g. life times to avoid the ugly tick syntax, or generics to avoid the more visually conspicuous angle brackets, etc. etc.). "Do"/"end" is just as fast to type (if not faster - closer to the home row), and discourages flame wars on bracket placement (since there's no silly symmetry argument to be made - who cares if "do" is on a new row or not?). See also: http://sebastiansylvan.com/2015/05/21/brackets-are-awesome-dont-use-them/ 
Surely it would stumble on these parameters in pretty much the same way with `[]`? 
`Index` is meant to borrow from the object and return something it contains. It's not surprising that while trying to write this code you run into walls with lifetimes: the index() function needs to borrow an `EntityData` from the `ComponentData`, but `ComponentData` returns an owned `EntityData`. Further, there is no point to borrowing Entity if it's Copy and especially if it's u32 (which means it's no bigger than a pointer). edit: my recommendation is to store `Position` within `EntityData`, store `EntityData` within the `HashMap` inside of `ComponentData`, and if you need to do some crazy other stuff build on top of `EntityData`.
[ always comes with ]. You never have just one of them. With &lt; and &gt; as binary operators, you can have just one, and you need to do something like [the lexer hack](https://en.wikipedia.org/wiki/The_lexer_hack) to choose correctly in all cases.
The problem is that we're in fact turning it into chained if statements, and letting LLVM put it back. MIR even makes this explicit, by turning all match statements into two fundamental structures: "if boolean, then jump here, else jump here", and "here's a jump table with an entry for all variants of an enum". We could turn the second one into my new match variant quite easily, but I want to be able to do the first one too. Even Java can do string switch nowadays.
wrapping_mul is no different from normal multiplication, it just omits the overflow check that we insert for the `*` operator
Thanks, I compared them and they are identical!
It depends on the architecture and surrounding code (since LLVM's assumptions about overflow are what'll change behaviour), I suppose, but it's probably not any different ASM-wise. Why don't you just time it? ASM is easily seen here: https://rust.godbolt.org.
We use the "jump table" approach right now (a LLVM switch) in certain cases (you can look at Debug mode IR on the playpen).
&gt; I'm surprised with this one. To my knowledge, Real World Haskell and CouchDB - the definitive guide were written in a similar way and are both O'Reilly Ah, didn't know about these. I'm extra surprised as well then, we spent *ages* wrangling with their legal department before we started working on the book. I wasn't directly involved in the legal process, but it was my impression that meshing OSS was proving difficult. Perhaps I just misunderstood what the holdups were. &gt; I'm consulting in the ES space for a living since 0.14 (I've been running the Elasticsearch Berlin UG for while it was fun to do community work for you) and while that might be true in some regards, the details change quite a bit, though. Having such a book around does point towards commitment to stability though, I agree with that. Oh my, yes, if you've been around 0.14 then things have changed *a ton*! It's basically a different piece of software today :) One of the main reasons we held off until 1.0 is similar to Rust...it was the first point we felt relatively confident we could uphold guarantees of backwards compatibility. It didn't make sense to write the book before that, since things were apt to change so quickly
There's a macro for that, [rust-iteratorcomprehensions](https://github.com/bsteinb/rust-iteratorcomprehensions). Edit: and the Reddit post, https://www.reddit.com/r/rust/comments/229fze/rustiteratorcomprehensions_nest_filter_and_map/
I think people (me included) tend to make that logical jump when *talking* about Rust, even though it is not equivalent (bound type vs. trait object).
Right but that would be true of any bounds-checking indexing function on an array in a language that compiles via LLVM; nothing about Rust's type system particularly enables it. Also, the index operator in Rust is just syntactic sugar for a function and the definition of Index&lt;usize&gt; for [T] bounds checks, but you could link against an alternative libcore that doesn't and your program will still be written in Rust. I read the text as suggesting a comparability between this feature and borrowck, and I don't think that's accurate. The actual awesome thing in Rust is that Iterators are implemented in a way that will make them compile down to really tight code. The section pivots toward that, but I think it would've been more educational for that to be the entire thrust: Rust discourages indexing and has amazing iterators.
I think that Rust is ready for ARM and only thing missing are official builds ;) You want to compile *for* ARM, not *on* arm, right? (just wanted to make sure). Then it's quite easy, you need to: * Install a cross-linker (I guess you probably did it already) * You also need to provide standard libraries (`std`, `alloc`, ... (`.so` and `.rlib` files)) for the target architecture and put them in `&lt;rust-installation-dir&gt;/lib/rustlib/arm-unknown-linux-gnueabihf/lib` (the architecture name may be a little different for you). One way to get these libraries is to build Rust from scratch and pass `./configure --target=&lt;your-host-target&gt;,&lt;your-arm-target&gt;`. You can also compile these libraries from source without recompiling whole compiler, but (apart from libcore) it's not really easy, since it depends on libc, jemalloc etc. And there's also third way to do it: download it from someone else! There are [builds from](https://www.reddit.com/r/rust/comments/37wat6/unofficial_rustcargo_nightlybetastable_builds_for/) /u/japaric (there are also some useful links about building for arm there. **edit**: they seem outdated, but there's a comment in that thread pointing to up-to-date builds from /u/warricksothr). I'm also [hosting](http://212.47.231.40:12314/) some. But beware, both mine and /u/japaric builds require ARMv7, so they may don't work for you. * When you have the libs and the cross-compiler ready, `cargo build --target &lt;arm-target&gt;` *should* work!
Rust doesn't need anything like the lexer hack. In the one context where angle brackets would be ambiguous, which is expression context, Rust requires `::&lt;&gt;` instead of just `&lt;&gt;` to resolve the ambiguity. Something of this nature would be required even if square brackets were used, so you'd still be typing `::[]`.
[Ruststrap is a good starting place](https://github.com/japaric/ruststrap) but /u/krdln already summarized it nicely. There are hosted binaries for rustc-1.0 and rustc-1.1 which work out the box on ARMv7 (using scaleway + debian 8.1). 
Interesting. Rouille looks low-level and simple. What are the advantages of using it instead of using Hyper directly? (Link to repo: https://github.com/tomaka/rouille)
That's not a bad example but you could word it: "give me the square of every even number in the range 1-100". Then the other syntax isn't that far off.
Why does rust use ruby style syntax for closures? Why not reuse the fn keyword? 
But it *is* less performant. It's not as expensive as bounds checking in, say, a null-terminating C string, because the length can be accessed in constant time, but it does introduce a cost. The good thing is that Rust has a more performant alternative to bounds-checked indexing which has a number of other advantages as well. I think we're talking past each other. I agree with everything you're saying, but my point is that the text sells borrowck and bounds-checking as how Rust enforces memory safety and they're not comparable. Borrowck is a whole compiler phase and type system feature which pervasively impacts everything you write, boundschecking is a few assert statements in the standard library. In my opinion the truth is that Rust doesn't have a 'solution,' for out-of-bounds accesses, which is why collections stuff has to use so much unsafe code. But its also my opinion that Rust doesn't *need* a solution for out-of-bounds accesses, because if you're using someone else's data structures and the data structures are Good (which imo C arrays are not), the API presented shouldn't allow you to read outside of its bounds. Use-after-free on the other hand is a pervasive problem, which is why Rust provides a pervasive solution.
https://github.com/warricksothr/RustBuild up-to-date armv7 and armv6 builds
Does that mean Rust is used within Google enough to warrant being included in their build tool?
If I were to get rid of brackets, I certainly wouldn't replace them with do/end. I'd replace them with indentation rules. Do/end is just too overtly imperative and really clashes with the prevalence of expressions.
List comps are readable for small things but when you start nesting them it gets to harder to read than something that would be evaluated left -&gt; right. There was this example once in a talk about Python vs Ruby: ```'\n'.join(obj.name for obj in (repo.retrieve(id) for id in ids) if obj is not None)``` ```ids.map{ |id| repo.retrieve id }.compact.map{ |obj| obj.name }.join '\n'``` (doing this from memory and my py or rb syntax might be off)
yes. I mean space. Also block statement feature like nim is needed to create explicit scope for lifetime. def main(): let i = 3 block: let borrow1 = &amp;i println!("borrow1: {}", borrow1) block: let borrow2 = &amp;i println!("borrow1: {}", borrow2) 
[GCC Statement Expressions](https://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html).
&gt; Can such a dependency be compiled for Arm or am I dependant upon all libraries not needing the standard library? Are you talking about compiling Rust programs for bare-metal ARM systems, or for 32/64-bit ARM systems running Linux? The two are an entirely different proposition. The Linux on ARM option is reasonably straightforward: it may take some effort to get set up, but you should have all Rust libraries available to use. /u/krdln already covered this with some detail. If you're talking about running Rust on bare-metal ARM systems then you'll want to look at [zinc.rs](http://zinc.rs/). Note that support for bare metal ARM is incomplete, and I wouldn't recommend using Rust for this purpose _at this stage_. This option will mean giving up the std crate, and therefore also most third party libraries, including nalgebra.
That almost happened https://github.com/rust-lang/rfcs/pull/483
&gt; Why does rust use ruby style syntax for closures? It happened a long time ago, so I can't tell you. &gt; Why not reuse the fn keyword? We try to make costs explicit. Closures and functions have very different costs. We've wanted to keep them syntactically distinct.
I'm guessing that distinction made more sense when closers were boxed. Aren't unboxed closures very low cost? 
Right, the problem is that with { }, a LOT of people get passionate that you need to start the block on a new line so they line up. Nobody gives a crap about do/end, so you can save space OTBS style without people starting arguments. 
Indentation is just too fragile IMO. Too easy for a space/tab issue to sneak in and cause weird issues. I like not having whitespace matter. 
What kind of text editor do you use that can't solve that issue in one second flat, and why are you writing code in it?
They aren't as high as they used to be, but "has an environment" and "doesn't have an environment" is still a big difference.
I really don't get the craze with implicit semicolons. Seems like you're just asking to get bitten in the ass. Omitting curly braces for single-expression functions is a little more palatable.
Being able to substitute `=` for `{}` for single-expression functions.
&gt; #Should I use this &gt; No. Use the default rust syntax. I'm not sure why it exists.
C switch statements are not guaranteed to do selection in constant time (edit: in the sense that you mean), and LLVM doesn't even implement them that way.
That's actually pretty good, if not for the unholy indentation.
We also recently added preliminary Rust support to Buck, one of our build tools at Facebook: https://github.com/facebook/buck
Yes, but on another platform they might not be identical, and you specifically want wrapping mul and not the (potentially) overflow-checked mul.
I don't like to visualize space/tabs. It clutters stuff up. And I don't like my text editor to do anything automatically either. So bottom line is that I'll spend a ton of time scratching my head before I realize there's an inconsistency. 
Interestingly, in spite of Rust being 50th of the languages listed in [TIOBE](https://www.reddit.com/r/rust/comments/3k29g5/rust_has_made_it_into_tiobe_top_50/), of only 4 listed, Rust is included.
No idea why you replied to me since I didn't reply to you, I was simply commentating that the amount of adoption and support it has received was astounding. &gt; Still, adoption does not necessarily convert to a healthy and growing community buzz in a long run. For example, if all companies who are actually using Ruby somewhere (mind you, huge deployment systems are written in Ruby!) were vocal about it, the community perception would be upgraded significantly. What _do_ you think converts to a healthy and growing community buzz, and why do you believe community buzz matters at all? I'd rather people use a language, rather than simply speak about it. Ruby has a gigantic _and_ healthy community so I don't fully grasp what you're attempting to convey, although a very large portion of them are now starting to use Go as well. Go has more conferences than Rust, more subscribers on Reddit, more IRC users... what exactly do you think Rust is doing better in this regard? And don't forget, that's _with_ Rust having people such as pcwalton answering every single post that mentions Rust on Hacker News, and multiple people from the project on Reddit doing so as well. It seems as if you're simply not involved with Go, so you don't see any of the community buzz from that side of the fence, which is completely understandable. Oh, and a lot of these companies are extremely vocal about their usage, sponsoring and doing conference talks/blog posts about their experience with Go. &gt; I especially can't find a striking reason why things shouldn't be ported Rust instead of Go. * Ease in hiring (it takes a couple hours to learn everything you need to know about the Go language, due to its simplicity) * Legibility/maintainability which helps greatly when working with a team (you can jump into the vast majority of code bases, and understand what's going on) * Gofmt forcing style * Single knob tuning for garbage collection * Statically-linked binaries by default (which uses a completely custom libc implementation) * Advanced tooling such as Gofix, allowing Go to make syntax changes, while keeping old code working. You want ABI stability? This is how you achieve it without compromising future changes. * A brilliantly designed stdlib (nice balance between abstraction level, and coverage) * Goroutines * Simpler channel structures * Proper reflection * Cross-platform and cross-compilation out of the box (including mobile) * Compile speed &gt; We know for 20 years now that C is problematic. C is powerful and simple, not problematic. If you actually try to understand C and read what each function does, it's extremely simple. Developers are problematic, not the languages themselves (outside of bugs). I'm not sure why you're trying to compare Go to Rust, instead of comparing Rust to D or C++. Go and Rust serve two completely separate use cases.
Yeah I was surprised to here a suggestion they were. It didn't sound... *totally* impossible though. Just... unlikely.
I'm just saying that what I think is going on is a honest mistake, *unless* I'm missing something that justifies the apparent mismatch.
Considering that I spend 95% of my day writing in COBOL, I won't add any suggestions based on my professional experience. =P However, I've never been a huge fan of the sized array syntax: &gt; let arr: [u8; 5] = ... Coming from a Java and C background, it just feels *weird*. I can see why this form was used, but that doesn't mean I have to like it. I'd much prefer something like: &gt; let arr: u8[5] = ... However, I can see how that syntax could be considered confusing.
Trait objects are actually quite simple. You can always use static dispatch when you're dealing with simple cases like `fn draw&lt;T: Renderable&gt;(renderable: T)`, however if you want to draw more than one thing, this ends up falling short: `fn draw&lt;T: Renderable&gt;(renderables: &amp;[T])`. In that case, I could draw rectangles, I could draw squares, but I can't have a list of both circles and squares. Trait objects are how we solve that problem. Ultimately your value now gets hidden behind a fat pointer, containing the data, the size, and the method table (since static dispatch no longer applies, as we do not statically know the type).
I get my indentation instincts from Lisp! FWIW, rustfmt doesn't touch it :)
`|x| ...` is one character shorter than `x =&gt; ...` and 3 shorter than `(x) =&gt; ...`. The other syntaxes I've seen are even more verbose, although we'd be closer to C++11'd `[](x) {...}` if we used `fn(x) ...`. In my opinion, Rust's syntax for closures is slim, easy to read once uou know it, and it really doesn't get in your way (God knows we don't need another language where you *have to* write `function(x) { return x * x; }`).
&gt; let arr: [u8; 5] = ... "An array of u8's with a size of 5." &gt; let arr: u8[5] = ... "An u8.. oh no array of u8's with one element that is a 5... er has a size of 5!" I think [u8; 5] is a much better compromise. Having said that... COBOL??!?? My grandfather used to work in COBOL. One of his last projects before passing away was y2k related stuff. What do you do, if you don't mind my asking? 
I like that a lot. I was going to say "why not indentation without block?" but then I looked at your example. To be honest, I like your theoretical code the best.
I really do not mean any offense by this... but does it really matter? You use the code style of the project you are working on. If you are starting the project, then you decide. 
You don't need any visualization to fix the issue. These days nobody really uses tab for indentation at all. I've not had this kind of issue for many years now. 
Yes. See [std::raw::TraitObject](https://doc.rust-lang.org/stable/std/raw/struct.TraitObject.html) for how it's represented. The Wikipedia article on [vtables](https://en.wikipedia.org/wiki/Virtual_method_table) might be helpful too, though it's focused on C++ which stores the vtable pointer in the object rather than in the reference.
No, it's a workaround to a problem that shouldn't exist. Spaces are harder to navigate around than tabs (one cursor press rather than two). Sure maybe an IDE can fix it, but most IDEs support both so they can't just make the cursor jump 4 spaces or 8 when you move the cursor, they have to assume you may want to move a single space. 
Yeah but even that is more verbose than Haskell which would simply be: let squared = [x^2| x &lt;- [1..100], even x] I love Rust and Python, however, I believe Haskell has the cleaner syntax overall, mostly because it's functional rather than iterative.
That's an idea, for sure. And there are other macros as well, such as [try_opt](https://crates.io/crates/try_opt/) that can help in some situations, maybe I should have added something about that. That said, personally I try to refrain from making my own macros unless it's *a lot* of typing saved, due to the increased difficulty to read/understand the code at a later point.
That's true. Like I said, I understand why the language designers made this choice, but I wouldn't have done the same. I guess I just got used to how Java and C define their syntax! And I work as a programmer for a large investment company that specializes in mutual funds. I'd be lying if I said that I hated my job, or even that I hate using COBOL. As verbose as the syntax is, and how it promotes spaghetti code, it's interesting to use. Even though the language has had Object Oriented extensions, basically 99% of the COBOL code out there uses only stack-allocated variables. That means you can do a LOT of optimizations that allow your code to be super efficient. Along with that, given how the language is business-oriented, SQL integration is dead simple, and fairly powerful (if a little complex). For better or worse, it's all built into the language and not as a library. In my opinion, that makes things a lot easier to use.
I don't know much, but I think Ninja is not something you'd use directly, rather let it be generated by, say CMake, now Bazel seems to be what you would replace CMake/SCons/... for.
Please recall that no parametric polymorphism is allowed for global variables/constants unlike functions. Not much "inference" is required.
Yeah I can totally understand that! At least the context here describes itself better given the first element is a type and not a value.
Conscious choice on my part to limit inference to locals-only, not between module items. Been like this since the beginning. I think it improves readability to have a certain level of mandatory declarations, and this was as easy a place to draw the line as any. It means you can typecheck items in parallel / without having to do anything global. In practice rustc doesn't do that currently, but it could.
Bazel began its life as a stripped-down version of Google's internal build tool called Blaze and they are two different softwares now.
Pattern recognition is a terrible curse, especially when the pattern is _wrong_.
Not really, but having support for Rust in their build is a first step to getting it adopted.
Design? How about [implement](https://github.com/durka/macrolisp/blob/master/tests/test.rs)! I have not addressed all the syntactic constructs yet, but there is an escape hatch to just stick in a block of regular Rust syntax. TLDR: Lisp.
Oh, and one more thing. If I didn't have to repeat lifetime and type arguments everywhere, that would be good. If I have already declared: struct Foo&lt;'a, T, U&gt; (U, &amp;'a T); then I don't want to write impl&lt;'a, T, U&gt; Drop for Foo&lt;'a, T, U&gt; I can just write impl Drop for Foo ...and should I, for some reason, need to reference the `'a`, `T` or the `U` maybe I can write them as `Foo::'a`, `Foo::T` and `Foo::U`. And besides, `struct Foo&lt;'a, T&gt; (&amp;'a T)` can just be elided to `struct Foo&lt;T&gt; (&amp;T)` anyhow - needing more than one lifetime in the same struct seems like very much of an edge case to me (I've never needed that myself, at least).
If there's one reason to use it, it's [the `router!` macro](http://tomaka.github.io/rouille/book/route-params.html)! The biggest design change compared to hyper is that the `Response` is an object that you build from scratch and that you return from the handler instead of being passed as parameter. This makes it easier to test your routes (you can also build fake requests), pass the response around, and you don't have to worry about some parts of your code erroneously modifying your response. Other than that, it should ultimately provide support for everything commonly needed in a framework: static files, sessions, etags, a reverse cache, etc. But everything is still being figured out for the moment (that's why I'm not really talking about it).
Actually, this is semantic. Rust will eventually get better bound inference but for now, it does not have it.
Actually, vertical bars was not a good idea for unsafe. I have no idea what to put there.
Just because the inferred type is comparatively simple, doesn't make it any less inferred. The idea is that code benefits, comprehension wise, from having types written down here and there. Less implicit meaning, more explicit. Parameters on items are never inferred either. It's an aesthetic call, but one we made on purpose. I'm not claiming my aesthetic calls are universally superior or anything, but sometimes they crop up in the design, and this is one such case. You asked why, this is why. It may not satisfy your preferences but I think it's good to be clear when something is a logical necessity vs. an aesthetic design choice. This is a case of the latter.
From the [Bazel FAQ](http://bazel.io/faq.html) on why Google doesn't use X: &gt; Pants, Buck: Both tools were created and developed by ex-Googlers at Twitter and Foursquare, and Facebook respectively. They have been modeled after Bazel, but their feature sets are different, so they aren't viable alternatives for us. 
"here's n ways to hang yourself"
Trying to port and/or bind the micropolis engine, unfortunately written in C++, to rust.
There is still some cross-item type inference in Rust in the form of variance inference for type parameters.
http://stackoverflow.com/research/developer-survey-2015#tech-tabsspaces - a lot of beginners use tabs.
Please no.
Also interesting, no mention of Go. Seems like an obvious inclusion for a Google project.
Does [this ppa](https://launchpad.net/~hansjorg/+archive/ubuntu/rust) work?
Isn't the syntax `Iterator&lt;Item=Self::Item&gt;` an assignment (to a "keyword type parameter" called `Item`)? Then it makes sense to use different symbols...
Just to address your last point: I believe Python gives a Sytax Error since the indentation is inconsistent. I guess we'd do it similarly.
That's great to know, thanks. [I just uploaded a crate to convert from PEM to DER](https://crates.io/crates/pem-parser). It's a bit hackish (uses a regex to strip out the headers, notably), but it works so may as well push it if it can help someone :). Contributions welcome!
[This](http://www.hashmismatch.net/2015/05/18/pragmatic-bare-metal-rust.html) might be close to what you're trying to do. As I said previously, you won't be able to use any library that needs the Rust std lib/crate. Embedding inside an RTOS might be tricky, but if you can compile the rust code correctly for the architecture then linking it to/calling it from a C program should be _relatively_ easy.
Do you mean IDE?
The quote was taken (a bit) out of context; and probably relied on his knowledge of early 1.0 stable Rust – which as we know left room for improvement – improvement we already see in current stable Rust (I'm on nightly, so I see even more improvement :-D). And I fully agree that it was the right choice for Rust to solve that difficult problem first. We have enough time to train the other muscles until they're as "bulging" as borrowck.
I was just reading it on the browser. I went into my editor and typed it out (`Vec\Type/`). I feel like it's still not as clean cut as angle brackets. I do agree that in monospace `::` is a bit heavy, but `~` meshes too well with the text which makes it harder to read (So yeah, too *quiet* instead of noisy). `^` on the other hand is not too bad.
How are tagged unions product types? Tagged unions are never empty (a tagged union of unit is not empty). Tuples OTOH can be empty. So to me enums match with sum types perfectly while tuples do so with product types.
`fn len(&amp;self) -&gt; usize = self.len;` vs `fn len(&amp;self) -&gt; usize { self.len }` ? I think the type `usize` followed by a `=` is a bit jarring. That said, I would like to be able to assign function compositions to names, `fn rot180 = rot90 . rot90;`. Given that I'd still have to give the signature though, it might not buy us all that much.
Heh, to me `&lt;` and `&gt;` are the noisiest of them all, *and* they make the text harder to read, due to the lack of space between the word and the separator (which I think is what you mean when you say it "meshes too well with the text").
Huh thanks for that. Have never heard of the SMAWK algorithm before, but it seems useful in multiple places. If I were the author I'd have tried using some form of beam search, which is probably suboptimal as well if I understand correctly. I think his interacting rules might make be the reason he couldn't apply dynamic programming, but I haven't checked if it's true. Perhaps the constraint that if the element of a list has a line break internally, all the elements of a list must break is one of the causes. I'm not sure how one would handle that in dynamic programming
They mention Go &gt; Looking ahead towards our 1.0.0 release, we plan to provide Windows support, distributed caching, and Go support among other features.
Could you not also approach this with an enum wrapping the different shape types?
I feel like this should be an option: const thing = 1u8; versus const thing:u8 = 1;
How about this? use std::mem::size_of; enum X {} enum Y { Y0, Y1, Y2 } enum Z { Z0(i32, i64) } fn main() { println!("{} {} {}", size_of::&lt;X&gt;(), size_of::&lt;Y&gt;(), size_of::&lt;Z&gt;()); } http://is.gd/0FxYA5 (`size_of` are irrelevant, I just wanted to use `X`, `Y` and `Z` in `main()`)
I personally find haskell's much harder to parse than the python or iterator version. 
I'm learning Lisp at the moment. That implicit return is just like Lisp, right?
A massive +1 to named parameters, I find it often makes things much more obvious. 
&gt; Bazel, an open source build system designed to support a *wide* variety of different programming languages and *platforms*. &gt; Supported platforms: Ubuntu Linux (Utopic 14.10 and Trusty 14.04 LTS), Mac OS X So.. two?
&gt; collect\Vec\T//() or even collect\Vec\T() - as types cannot have parentheses, you can omit the ending /s. Are you being serious or is that a very cleverly placed sarcasm mark? 
The weird mix between statements and expressions. One of the things I love about languages like Scala is the "everything is an expression".
I seriously think that `collect\Vec\T()` looks both visually better, and is easier to read, than `collect::&lt;Vec&lt;T&gt;&gt;()`. At least on a fixed-width font, and that is what most of us use for coding. Quicker to type, too. Do you think otherwise, and if so, why? Again, the only argument I can think of is that C++ programmers might be used to similar styles.
Thanks for the support! The report is free for everybody. However, the author is also writing a longer book, Programming Rust, to be published by O'Reilly next year. http://shop.oreilly.com/product/0636920040385.do
Compiling a match on strings (or other orderables) into a sorted list that was binary searched could be pretty neat. I suspect it'd be the same number of instructions too. If people really need that hot path they should code for it by hand. 
And you'll basically never go out of work, and pay (should) only go up...
&gt; enum X {} I did not knew that this was valid Rust. There is a proposal for a C++ std::variant type and the latest proposal won't support this because then it won't be an Sum type.
Thanks - edited/fixed. 
This is incorrect. The lexer hack requires conflating parsing with typechecking. Rust code can be parsed without typechecking. This was a conscious decision on the part of the Rust devs from the very beginning. If we were already doing something like the lexer hack, then having `::&lt;&gt;` in the grammar wouldn't be necessary.
&gt; ML/Haskell/Rust's full-fledged type inference Careful, I've come across many ML and Haskell fans who are quick to denounce Rust's type inference as stripped-down as well. :P
&gt; Further, there is no point to borrowing Entity if it's Copy and especially if it's u32 (which means it's no bigger than a pointer). But `Index` is also meant to enable the `a[b]` syntax sugar.
That's correct. A* is for when you know where you want to end up but not how to get there. With formatting, you don't care about the path, you're just trying to find the "nearest" solution that meets some criteria.
"His" is my preferred pronoun, but I and my trans friends thank you for not assuming that. :)
It is possible, but then again, it would be even more inconsistent because that doesn't happen anywhere else in the language.
My argument is that they should take a block instead of an expression, like a named function does. This is just a pet peeve of mine when it comes to Rust syntax, I'm no language designer and I'm sure that there are lots of people who would disagree.
I'm happy with the brackets. If I had to change things I would : * put the return type inside in the parameters list for functions and closure : `fn foo(in : |i32 -&gt; i32| -&gt; bool) { ... }` * use `@` for immutable reference and `~` for mutable reference * use `'lt@Foo` and `'lt~Bar` for lifetime notation * use `Ptr&lt;&gt;` and `ConstPtr&lt;&gt;` instead of `*mut` and `*const` * use CamelCase everywhere instead of weirdly mix Camelcase and underscores * `unsafe` blocs can be only be used in unsafe functions unless they are prefixed by `trusted` and maybe : * use `[` for generics and `(` for arrays
I think the intent is good, but then there is a lot of very obvious cases where the amount of noise is just too high: const COOKIES: &amp;'static [ (&amp;'static str, &amp;'static str) ] = &amp;[ ("areaCode", "..."), ("nearestPostalCode", "..."), ... ]; maybe there's some other way to declare static strings that doesn't require explicitly saying "&amp;'static str" dozens of times?
Not true: see the "Is it a fork?" portion of http://bazel.io/faq.html &gt; Bazel shares most of its code with the internal tool and its rules are used for millions of builds every day.
It seems to me that you gave this some thought. Do you plan to actually implement a parser for this?
Oh! I search for `popcount` but didn't think about searching for `count_ones`...
Do you like it enough that you would use it?
I really love to read terse, white space sensitive code (love F#), I find it beautiful. I don't know how practical this would be:) According to my fairly limited understanding of parsers, the error messages would suffer a lot because the compiler would have a harder time to figure out what the user actually wanted. I asked if you actually want to implement it because I am curious whether it works in practice and how good/bad it is:) I would definitely try it. 
I think you're right (though the size definitely lives somewhere. I think it's a fat pointer to a fat pointer where the inner contains the size in this case?)
At the risk of disappointing you: it's not like you have a choice... Rust (the language) does not guarantee the result of a regular multiplication if it overflows, and `rustc` will insert a runtime check in Debug mode (for now, hopefully at some point a fast implementation will be available in Release mode as well). That being said, I could easily imagine LLVM optimizations having a different behavior based on the presence of overflow checking (or not). Optimizations can be surprisingly finicky.
If your data is a sized type, there's no need to store the size - the functions in the vTable already know it. So for something like a `Box&lt;&amp;Trait&gt;`, it'd be `{data: *Instance, vTable: *vTableForTraitForInstance}`. With `&amp;[T]`, you don't actually know the size of the slice, so you will also have to have a size parameter, but then the size is in the slice, not the trait objects.
Go on...
You also do not know the size with `Box&lt;Trait&gt;`, which is what I'm referring to here.
How do newtype structs with a single field look? Wouldn't you need `forall 'a` too, just like Rust needs/wants explicit `&lt;'a&gt;`? What if I want to match or loop over a thing that takes multiple lines to write down? The argument-less function call syntax might need a better plan. :( At least for declaration you could just drop the ~.
That's not currently possible. There've been proposals to make it be, but they haven't been adopted, and it doesn't seem like they will be (but who knows). Are you referring to the redundancy with the `Foo: Iterator&lt;Item=Bar&gt;` syntax? I think of that as syntactic sugar for `Foo: Iterator where Foo::Item = Bar`, much like `foo&lt;T: Baz&gt;()` is sugar for `foo&lt;T&gt;() where T: Baz`. (I believe the longer form in each case is also more powerful and can express more possibilities.) Another similarity is that in both cases, the shorter form was implemented before the longer one. ;)
It actually does, although it's just another field of method table. IIRC the layout looks like that: +-----------------+ +-------------+ | Box&lt;Trait&gt; | +--&gt; T: Trait | +-----------------+ | +-------------+ | data +--+ | vtable +--+ +--------------+ +-----------------+ | | vtable | | +--------------+ +--&gt; drop glue | | size: usize | | align: usize | | method1 | | method2 | | ... | +--------------+ [Relevant piece of code in rustc](https://github.com/rust-lang/rust/blob/250679e/src/librustc_trans/trans/meth.rs#L666-L677)
That's right, [the alignment and size info are in the vtable.](https://github.com/rust-lang/rust/blob/250679e20d04104d6ff2888a3486d02a9f490248/src/librustc_trans/trans/glue.rs#L462-L469) You can look up the size dynamically using `std::mem::size_of_val()`.
Array access always has closing bracket, but binary operator `&lt;` hasn't. So the ambiguity is solved at the level of priority of operators (if we assume that the type parametrisation `T[A]` is operator too). So the true reason of the problem is that we can use single `&lt;` as a binary operator. Look at this code: a as T &lt; b ... And: a as T [ b ... In the second case, the parser expects a closing bracket in any way. It does not depend on what they are: array access or type parameters. The question "what it is?" is about agreement, like operators priority between `as` and `[]`, we just agreed that some operators have a higher priority than other. But in the first example the parser *does not know* whether it will meet closing `&gt;` or not. And that affects of what `&lt;` is: comprasion operator or a start of type parameters. The answer to this question requires deeper lookahead than it is now.
Great stuff! Are you planning to also bind to existing sparse matrix libraries? Implementing fast sparse matrix codes is quite difficult. Guys like Tim Davis of SuiteSparse fame have been working on this their entire life. The state of the art algorithms can easily be orders of magnitude faster than the naive sparse algorithm.
This is all unambiguous and maps very cleanly to Rust. Do I plan on writing this? Maybe, but only if enough people say "yeah, I would prefer to write this".
My biggest issue with lifetimes is the single quote character throws a lot of IDEs and editors off and they want to pair it.
This was something that surprised me, too! I expected the term "algebraic types" to refer to, you know, product and sum types, including tuples. What clinched it for me was the [Haskell definition](https://wiki.haskell.org/Algebraic_data_type) of the term, which is extremely close to Rust's. If that's how people use the word, that's what it means. I think the key thing to notice is that, because each variant of an enum can carry *several* values, an enum definition is actually a "sum of products" construction: it's got both in a single type. If I say: enum Color { RGB { r: u8, g: u8, b: u8 }, YCbCr { y: u8, cb: u8, cr: u8 } } then there are two product constructions here, the "r:g:b:" and the "y:cb:cr:". The overall type is, of course, a sum. So, algebra in one package.
(as flatline has already said, sorry)
Rust's original designer, Graydon Hoare, has always been devoted to making himself familiar with the literature. He's read as much and as broadly about programming language design as anyone I know. The first time that Graydon talked with me about Rust, he said he'd chosen the name because he wanted to dredge up great ideas from research that had never gotten taken up by industry: the name was an explicit reference to the avoidance of novelty. Originality is risk, so it stands to reason that Rust would borrow extensively from other languages. (I know there are other explanations for the name. Graydon has, I suspect, made a bit of a game of coming up with a different reason for the name of the language each time someone asks him.) Of course, as the language evolved (and it evolved a *lot*), some of these great ideas began to show their limitations, and got taken out. So not everything old is suitable. And then the borrow checker, as far as I can tell, is to a large degree novel. So not everything new is forbidden. That guiding principle of eschewing originality didn't entirely get held to (which is fine by me). 
Yep! :)
Rust has zero runtime metaprogramming capabilities. It's just not possible. There isn't any runtime interpreter or anything, Rust compiles to native machine code. 
That's another error. The code should read: // Read the first four bytes from `stream`, and return true if they match // `magic`. fn check_magic(stream: &amp;mut Read, magic: &amp;[u8]) -&gt; Result&lt;bool&gt; { let mut buffer = [0; 4]; if try!(stream.read(&amp;mut buffer)) &lt; 4 { return Ok(false); } return Ok(&amp;buffer == magic); } This is my fault. In discussing some formatting issues with the editor, I supplied new text without noticing that I'd been playing with the static dispatch / dynamic dispatch distinction, and flipped the code around.
Changing priority doesn't solve the problem. Consider the expression `foo[bar]`. Is this an index operation or a function with a specified type parameter? In the former case the parser must treat the contents of the brackets as expression context, while in the latter case the parser must treat the contents of the brackets as type context. The fact that it's impossible to determine this without doing further semantic analysis is exactly the reason for the lexer hack, which ultimately involves adding more responsibilities to your parsing phase than is desirable. In any case, this all presumes that `[]` is good notation to use for generics, but I disagree with that. Personally I like D's solution best. :P
Ok, I see. Well, you can still use syntex to do AST stuff, but I'm not sure if it can be printed, but there is [aster](https://github.com/serde-rs/aster) for that purpose. It has a different API that may be nicer to use. You can also interface with LLVM, but that is an even lower level. There is also at least one parser generator library out there, that may be helpful, but I suspect that you will have to do a lot of your own work when it comes to that.
thanks again :)
Yes, I'll probably add bindings to Suitesparse. I'll have to figure out the licensing though, I think some algorithms are GPL so I'd have to make their compilation optional. Meanwhile I plan to also implement naive versions of most algorithms too. Mostly to learn, but also to have the functionality available regardless of licenses such as GPL, even though that will mean slower code. By the way, watching Tim Davis' courses on youtube made me want to do that library. That's really a nice topic, and I feel rust is a great language for these kind of algorithms.
understood... so even though it's built on LLVM, there's no runtime-oriented packaging of the build-chain, correct? At the risk of pushing my luck, if I were to generate full (oh, I forget what the packaging tool's called, "crate"?) projects as libraries, does Rust have any facilities to allow dynamically loading said libraries, assuming that they're implementing statically defined/understood trait classes?
Yes, well, it's either perfect or people won't use it. So nitpicking is a favor, and what you call nitpicking I call constructive criticism! I feel so awkward about match-in / for-do style that I don't know if it's worth it. Oh, you know what? Backlashes work, too. Just tells the parser to ignore a newline. for little_city in \ big_world.cities.collect self.try_to_make_it city Looks even worse than the do. At the end of the day, it's just syntax. For a C-like language, Rust is still quite clean to read. ... I just look at Haskell code, and get a little envious again. (And then I remember I don't have to be envious because I can use Haskell whenever i want.)
We got a crab for the book cover, though! I was sort of hoping for a pennyfarthing bicycle, but a crab is pretty great.
http://doc.rust-lang.org/std/dynamic_lib/index.html
I'm glad it was helpful! But... you'll notice that I punted on the semicolon issue. I just wanted to help people read code written by others; explaining everything necessary to *write* code just wasn't in scope. To see the kind of thing I was avoiding dealing with, consider that *this* is syntactically correct Rust: fn oneplus(x: i32) -&gt; i32 { ({ 1 }) + x } but *this* is a syntax error: fn oneplus(x: i32) -&gt; i32 { { 1 } + x } Since the report is only meant to give a sense of what's important about Rust, not serve as a specification, I decided that glossing over the details here was probably for the best.
The main advantage is if your repo also contains code written in other languages. Then, you can use the same build system for the entire project, whereas Cargo is optimized for Rust only. AFAIK, there aren't that many large projects that contain code in both Rust and other languages yet, but the type of project that I am referring to are projects such as [Cloudera Impala](https://github.com/Cloudera/impala)
The code I was talking of is much worse than anything you ever wrote.
Perhaps for sum types, but not others.
if I were building standalone applications that would be kind of sensible, but I'm aiming at something that works in-process (essentially wrapping it up in the equivalent of a state monad). 
If I understand correctly, you're worried about the performance implications of having some kind of AST-walker or bytecode interpreter at the heart of your SQL engine, instead of something more modern like a JIT compiler? As far as I know, every production-quality RDBMS, from SQLite up to PostgreSQL and SQL Server and so forth, is based around an interpreter. Something like Python's bytecode is slow because each bytecode-instruction takes several-to-many machine-code instructions to run and usually only represents a simple operation like "add two numbers". On the other hand, an interpreter is quite fast enough for SQL, because each bytecode-instruction typically represents a gazillion I/O operations like "find row-offsets in this index", or a gazillion CPU operations like "sort these results": that is, they're just calls into statically-compiled, re-usable library functions, and dynamically-compiling those function calls into machine-code-level function calls isn't going to make them execute any faster.
I believe if you pass in the responses as `&amp;mut [Option&lt;Response&gt;]`, then you should be able to loop over `responses.iter_mut().enumerate()` and match on `Some(ref mut r)`. In response to your question, the `Read::read` method takes `&amp;mut self` because it may need to mutate the reader's internal state. For example, reading from a Cursor will advance its position.
You have saved me. Thank you.
Yes, they do. The 5 here has a type i32, because that's the default and any type would work: ``` println!("{}", 5); ```
It would be nice to have a section that compares (explains the relation between) the ownership and borrowing concept to references and pointers in c and c++. I think it could clarify a lot of things for programmers who are already familiar with c or c++ as they can link some concepts to what they already know. I remember that it took me some time to make the link.
I meant that by "value-only inference" doesn't happen anywhere, [here](http://is.gd/2F5FY4) for instance, `5` will be inferred to `u8`, because more than just the value was used to infer the type.
Sorry, I should have specified that this struct will be on the order of GB. I can't even afford to have copies at all
All on the stack? Or in something like `Vec` or `HashMap`?
It will be in a Vec. Does Vec own the data it contains? If so then a struct with a Vec inside will be constant sized with only a reference to the Vec data. My question might not be relevant to what I want to do then, but I would still like to know if it's possible
I don't know the size, but the vTable does know. See krdlin's picture below. The vTable and data are coupled in that the vTable knows the data's actual size and shape.
Yes, `Vec` owns its data in a separate heap allocation. Moving the struct into the closure will be an insanely cheap copy, just a pointer and two `usize` values. There was the `std::thread::scoped` API which allowed a closure with a shorter than `'static` lifetime (basically allowing the new thread to reference data on its parent's stack) but it was found to be unsound and subsequently deprecated. A revised version is in the works but I don't think much progress has been made on it.
As you've figured out, the overhead will be minimal since only the Vec (a few bytes) will be moved, not the data it contains. As for whether it's possible to pass stack data without copying: not at the moment. This used to be what `thread::scoped` did, but that was found to be unsafe. However, that was an implementation issue: there's nothing inherently unsafe about it, as long as you can *guarantee* that the child thread will terminate before the parent pops the current stack frame.
If you need the struct to be shared, you could wrap it in an Arc&lt;Mutex&lt;MyStruct&gt;&gt;, or you could send it back over a channel when the work is done. EDIT: Example with a channel: http://is.gd/cfzRWh
- Why was Rust created when there's modern C++? - Why is it so slow to compile programs written in Rust? - Things changed a lot since last time I checked (pre 1.0). Would 2.0 be completely different language? Is Rust just an experimentation project? 
Make `proc` an `Option&lt;JoinGuard&gt;` instead. When you want to `join` it, use `mem::replace(&amp;mut proc, None).unwrap().join()` or similar. However, the way your code is written does not necessarily ensure that the thread is only ever joined once. Maybe wrap the join guard in a promise-style API to make things simpler?
Aside from Arc, you can just move it back when the thread joins by returning it from the closure. This will work spectacularly well when you have a mostly-linear execution plan that you want to parallelize: let x = huge vec; let jg = thread::spawn(move || {do_work(x); x}); // do other work // uh oh, I need x again let x = jg.join() // it's all good, we got it back. Note that this will block // use x // ... let jg = ... // repeat if necessary // ... 
I don't understand why we need a `mem::replace`, it works with a simple reallocation to None. What is the benefit ? use std::thread; fn do_work() -&gt; u32 { 1 } fn main() { let mut t_ops = Some(thread::spawn(|| do_work())); for i in 0..10 { if i == 5 { if let Some(t) = t_ops { if let Ok(result) = t.join() { // use result of do_work println!("{:?} -&gt; result: {:?}", i, result); } t_ops = None; } } else { // do other things that don't rely on do_work println!("{:?}", i); } } }
I don't know if that should be reassuring or somehow even more disturbing...
* How do I build a Windows binary that doesn't show up the console window? (Windows binaries are either console mode or windows mode binaries. Console mode binaries always pop up a text console window along with any graphical windows. Current hack for this is to set up `.cargo/config` that specifies a custom linker .bat file for Windows platforms. The .bat file has something like `gcc -mwindows -static-libgcc %*` in it. Is there any more native way for this?) * When I got the console-less Windows binary running, the program just silently crashes whenever there's a panic. How do I make the panic generate an error message the user can see? (Trying to print to stdout silently crashes Windows Mode binaries, there was a feature being worked on for redirecting panics but I'm not sure if it's done yet.) * What's the idiomatic way to specify OS platform specific behavior in Rust crates, eg. a constant look-up table that needs to have different values on OSX, Windows and Linux? * I want to write a desktop GUI application. What's the recommended crate to use? Any advice on good architectural idioms? * I want to learn how experienced people write modern Rust, which project's source code should I read through? * Writing `use` declarations is annoying. Why can't the compiler do it for me? (Because ambiguities, but most of the time you can guess correctly, so maybe there should be [an IDE](https://www.reddit.com/r/rust/comments/3dy7u5/developer_wish_ide_tool_for_autogenerating_use/) that makes the best guesses.) * My Option::unwrap tripped somewhere, and the binary not-so-helpfully reported that a panic was triggered in `src/libcore/option.rs:362`. How do I know where the crash site was in *my* code? (Run with `RUST_BACKTRACE` environment variable set to 1.) * Something about getting in a terrible soup of `Result` value checking conditionals, which is where you should break out the `try!` macros. * Are there specific rules about when to use `self` or `&amp;self` receiver for methods that depend on the size of the self type? Should I just use `&amp;self` all the time unless the method specifically consumes the self value, or should I also use `self` when I have an immutable type that's close to a single machine word in size? * Should I use `f32` or `f64` when I don't know anything beyond "I need floating point here"? * `gofmt` is great. Where's `rustfmt`? * I have this really complex set of optional configuration parameters for my thing, and in Python I used to do this with named default parameters... (The standard way is to use [the builder pattern](https://aturon.github.io/ownership/builders.html). You can also put the parameters in a struct, implement `Default` for the struct and do something like `SomeOptions { foo: 42, ..Default::default() }` to emulate default arguments, though the struct literal syntax adds some verbosity.) * Why can't I overload the same function for different sets of parameters like I can in C++? What should I do instead? * How do I do the equivalent of C++ template specialization with Rust generics, where there's eg. a moderately effective generic case and then an optimized special implementation for the `bool` type for some generic container? * Can I do actual programming with the libstd-less Rust or is it only good for a "Hello, world" gimmick? What are my chances on making a Rust program that actually does something interesting and fits inside 10k? Are there any existing examples I can look at? * How do I do global variables in Rust? (thread-local storage) * I do mobile programming for Android / iOS. Can I use Rust? Should I? * Can I run my Rust program in the browser? (There's a proof-of-concept for emscripten, but no toolchain yet I think) * I want my vanilla macro to synthesize identifiers, eg. I write `macro!(foo)` and get code that has identifiers `foo1` and `foo2`. I don't seem to get this to work. (This was a known limitation at some point in the past.) * What are higher-kinded types, why should I want to have them and why don't I? * Who should use Rust? Should embedded programmers use it instead of C? Should scientific computing people use it instead of Fortran? Should game and desktop application developers use it instead of C++? Should backend and enterprise developers use it instead of C#, Java and Go? * Can you write an OS in Rust? Should you? * How do I random-access characters in a string? (I think it's UTF-8 internally, so you can't tell where a character starts without walking the string from the start. Convert it to a `Vec&lt;char&gt;` if you really need random access.) * How can I set compile time constants that are defined procedurally, like hash values computed from string constants, a look-up table for fixed point sine function values or color constant values converted from sRGB to linear RGB (I actually needed this one and wrote a Python code generation script for it)? I can do this in C++ with `constexpr`. * Why do I need to type the explicit array size in the type when I define a compile-time constant array? I'm defining the array from a macro that just takes a variable number of inputs. How can I make the macro derive the number from the input count? (There's a hacky macro that turns a sequence of inputs into a (1 + 1 + ... ) expression, but it craps out at around 100 elements, so I still need to maintain manual element count. Is there a more robust solution?) * I'm trying to write a game in Rust, but am running into a lot of trouble with the world data structure... (Pretty much everyone with an entity model more complex than `Player | Alien | Bullet` seems to end up implementing an entity component system to work around the lack of OO. Also, you probably want to have an indirect way to refer to your game entities instead of passing around references to their raw struct data all over the place, or you'll get into trouble with the borrow checker.) * So there are these garbage collection smart pointers, but people don't seem to be really using them. When *should* you use `Rc`? And what's the situation where `Rc` won't cut it and you'd need the full-blown `Gc` pointer? * I'm still fixing borrow checker errors pretty much by trial and error instead of figuring them out in my head. Is this normal? How can I learn to consistently figure out what passes borrow checker in my head once I become aware of a problem instead of having to just tweak things and see if they pass? * I want to define an enum and associate some data with each enum item. I don't want to repeat myself. (In C, you'd use [X-macros](https://en.wikipedia.org/wiki/X_Macro). With Rust, write a macro that takes the enum name and the data blob, expand this to an enum and a static array. You can cast enum values to `usize`and use them to index the static array to get the data.) * I want my crate to run initialization code before the program enters the `main` function, like `init` functions in Go. (You can't run anything before `main` in Rust I think. Look into thread-local storage for data that initializes itself the first time it's accessed.) * I'm not talking about just data initialization. I want my modules to automatically register themselves to a global structure at the start of the program they're included in, without being called from the `main` code, like a self-inserting unit test framework in C++ or a source code based plugin mod system for a video game. That doable? (As far as I know it isn't.) * Speaking of plugin systems, how do I compile Rust code into a dynamic library, then use another Rust program to load that library at runtime and look up functions to call from it with string names? * What's the type reflection story with Rust? Say I got structs of parameters in a game and I want to pop up a GUI that uses reflection to figure out the fields in the struct and shows up widgets to adjust them at runtime. (Syntax extensions that generate code for each type you need this for at compile time are your only option afaik.) * Should I always use the no-semicolon implicit return on the last statement of the function, or should I use an explicit return everywhere in long functions and functions that have at least one early explicit return? * I'm writing a 2D GUI and need 2D vectors and rectangles all over the place. Is there a standard crate that provides them? What about 4x4 matrices for some 3D stuff? (There are some established libraries for more complex stuff, but I ended up just writing my own Vector2 and Rect types for simple 2D stuff.) * How should I write an OpenGL app in Rust? (Look into glium and gfx-rs crates.) * Why can't I have floats in my `HashMap` keys? (Rust is being mathematically correct and declaring that since the floating point type doesn't implement the mathematical equality relationship, it doesn't have `Eq`, which `HashMap` requires from its keys. Of course in this case you could just compare the bit patterns of the float values instead of values with math semantics and `HashMap` would be just as happy. Maybe you can cast the values into some bit blob type with trivial `Eq` semantics before indexing the map with them?) * How do I interoperate with a C++ library from Rust? (Besides writing an interoperability layer that uses C calling conventions, you don't. C++ is foreign function interface poison.) * I'm certain people 30 years from now will be desperate to compile my Rust program they found on an USB stick during an archaeological excavation. They might have the Rust toolchain, but I worry about crates.io still being around. Is there a standard solution for neatly packaging all the third-party cargo dependencies with your own source code for archival? * What's the deal with the named type parameters in some generic types? Why do I say `Iterator { type Item = Foo; ...` instead of `Iterator&lt;Foo&gt;`? * Could the crab beat the gopher in a fight? What about if the gopher had a gun?
Both. But let's get back on topic.
Hi, I hope this isn't too OT! A lot of Rust is focused on low-level coding, and many people using it come from C/C++ backgrounds. But I think this will scare away a lot of people who normally develop in high-level languages and have only ever had awful experiences with C/C++ and think it is 'impossible' to get into. So a 'Is Rust easier to learn than C/C++?'' discussing the fact that it is _roughly as complex as C++_ but _ easier to work with because errors are caught at compile time and the language focuses on safety_ would be amazing for people coming from high-level programming languages.
It's fine for old-school OLTP databases where hitting the disk disguises all other costs, but modern in-memory databases are much more sensitive to the overhead of interpretation. Code generation is pretty standard for any new database. I benchmarked some database code this week where just sorting a table was 50% slower if the key was not known at compile time - https://github.com/jamii/imp/blob/master/diary.md#operators. The problem is that even though each bytecode instruction represents a huge chunk of work, the parameters to that instruction often end up being accessed in the inner loop which can be costly.
Sorry, I should have said, "emit Lua and call LuaJIT directly from your program." Embedded LuaJIT would run in the same address space as your current process. Because the Lua API is controlled via an `env` structure. You can have multiple simultaneous Lua VMs running on different threads without interference.
&gt; You mention implementing the SQL standard, but could you explain the jump from that to metaprogramming/code generation? Code generation is very common for modern databases (see eg http://www.vldb.org/pvldb/vol4/p539-neumann.pdf or http://data.epfl.ch/legobase). Especially for in-memory databases, interpreter code often ends up being the bottleneck. I'm working on a database in rust and I have already found places where very basic code generation would give me drastic improvements.
Why are the keywords / smart pointer names so short? (Graydon answered this to some extent on Reddit IIRC.)
It's already Friday and we only have a few nominations. I'd like to bump this topic so that maybe others may join with both votes and other nominations.
Build it with "cargo build --release". This enables optimizations. Rust is slow without optimizations. The other mistake is that your palette is a Vec and you're looping over the entire palette for every single pixel in the image. To make things worse, you're not terminating the loop even after finding that the palette already contains the given pixel. You can solve this nicely by cloning the image, sorting, and then deduplicating. 
How do you write a linked list in rust? (a play link to both a single (Option) and bi directional (Rc) list?) How do I get help? (#rust, users.rust-lang...) How can I try rust? (play.rust-lang) Why are the answers on Stack Overflow wrong? (theyre for old versions) What should I do when I find an answer on SO which is accepted but out dated?
&gt; You can solve this nicely by cloning the image, sorting, and then deduplicating. You can also probably try to store the palette in a `HashSet` To build the image, you can probably also use one of the [`from_...`](http://www.piston.rs/image/image/struct.ImageBuffer.html)
The algorithm you are using is very inefficient: the same algorithm in any language will suffer similar problems. A quick and easy speedup is to use a `HashSet` instead of a `Vec` to store your palette. This will make `is_unique` run in constant time, and the algorithm will then be optimal. If you need your palette to be in some kind of order, just convert the `HashSet`to a `Vec` at the end and then sort it. Alternatively, if you need it to match the order of colours in the image, you can maintain both a `Vec` and a `HashSet` during the algorithm, but only use the `HashSet` in `is_unique`.
Yeah, one thing I liked about the Mozilla release page for rust 1.0 was 'Here is how you do this in Javascript, and here is rust'. Side by sides can be very helpful.
I don't really know what the frequent asked questions are. I'm sure people who spend time answering questions in the IRC probably see tons of dups. Most questions I get are "does it have a library for _____? is it a scripting language?". A link to awesome-rust in the FAQ seems like a good idea. I also think that crates.io can be confusing - I still have trouble understanding the rustcserialize/serde situation; I end up using both because the csv library I use uses rustcserialize but I prefer the serde API for other operations. Seems less than ideal.
* initial runtime for a sample image: 16.809 ms * after returning early in `is_unique`: 11.431 ms * after caching the result of `length.sqrt().ceil()` in `gen_palette()`: 6.904 ms I'll try optimizing it further later.
Thank you everyone for your help. I've decided to switch from Vec to HashSet. The first code, on a sample image it took 45 seconds (with Vec and --release flag). I ported it to HashSet and it now takes 6 seconds! However, the best part is I've learned what HashSets are :) Also, thanks for pointing out I didn't end my loop, after finding a duplicate pixel. I completely missed that. I've updated the code on github: [https://github.com/Haggus/monarch/blob/master/src/main.rs](https://github.com/Haggus/monarch/blob/master/src/main.rs)
Why cache the result of *length.sqrt().ceil()* ? *gen_palette()* is only executed once, at the end.
Because _why not_? Square roots are expensive to compute, so if you're going to use one twice, you may as well copy it.
I haven't tried it yet but check out Kuckiki https://simonsapin.github.io/kuchiki/kuchiki/index.html https://github.com/SimonSapin/kuchiki
Nice! Nominate for crate of the week?
Itertools is a pretty dope crate. Does this count as a nomination or should I comment on the linked thread?
An other thing that _may_ affect the performance (I haven't tested) is the progress printing. The progress is printed for every pixel, which is 10 000 times for the 100 x 100 px image and 1 000 000 times for the 1000 x 1000 px image. It may be cheaper to, for example, only print the progress if the percentage has changed (i.e. only 100 times). Outputting to the console can sometimes be surprisingly expensive.
When I removed println completely, it reduced the entire procedure to half a second. This is amazing. Thanks!
Perhaps together with how to use `std::env::args()` http://stackoverflow.com/questions/15619320/how-to-access-command-line-parameters
- He is a seasoned C++ programmer who has been using (multiple!) inheritance a LOT to tackle complex design problems. He heard Rust would be a good alternative to C++, but I found it doesn't have inheritance. He has no idea how to go beyond toy programs (&lt; 1k LOC.) Look at this post, https://www.reddit.com/r/rust/comments/3k1yl2/how_would_a_real_rustacean_handle_this_situation/ Which is the way to go? He wants to know the most widely accepted design principle for Rust which scales up to 100k LOC. - More about porting `try`/`catch` design to Rust - Debugger, break point, stack trace, call tree, profilers such as perftools - Cross compiling from x86 Linux to Windows or ARM - All questions posted to Stackoverflow and tagged as "rust", in the order of upvotes - http://stackoverflow.com/questions/tagged/rust?sort=votes&amp;pageSize=50 
I count it.
I can see that this is more Rust-like, but what is it exactly that is "not adapted" to Rust in Nickel and Iron?
But the `Box` *is* the pointer. You probably want this: `Rc::new(*b)`. This takes value out of `Box` and puts it into `Rc`. EDIT: Ok, to clarify a bit: both `Rc` and `Box` store values in the heap, so they already act as kind of pointers. EDIT2: Eh, missed the words "without copying" in the title and misunderstood the question :)
For example: - The `AnyMap` that stores the services and the route parameters means that you will get a runtime panic instead of a compilation error if you make a typo. Note that databases and templating have the same problem, that's why we need plugins to be stable eventually. - All services must be `'static`, which can cause trouble (for example with `postgres::Transaction`) and usually forces you to uses Arcs instead of simple pointers. - The fact that various functions (routes and middlewares) are stored as `Box&lt;Fn(...)&gt;` means that the compiler can't inline them. - Again, in my opinion passing a `&amp;mut Response` around, that every middleware can modify, can lead to obscure unhandled corner cases. What if a middleware erases the work of the previous middleware for example? You may say that such a situation never happens, but for me saying this is similar to when C++ programmers say "I don't need Rust I code perfectly". - The fact that the libraries are extensible reminds of the ocean of small undocumented libraries in the Javascript world. I want stable monolithic well-documented crates with a well-defined scope, not a collection of plugins that break all the time. This isn't specific to Iron/Nickel though. Of course the express-like design is well-established, so you can't blame anyone for preferring something is known to work to something experimental. 
I tried that as well, and also tried building core.o (using `--emit obj`) and linking that, and that led to...tons of problems.
Yeah, I'd like to see recommendations for HTTP (client) libraries, for example
I wrote [select](https://github.com/utkarshkukreti/select.rs) which uses html5ever to handle the parsing. Instead of using CSS selectors, it uses structs to create queries. There is no documentation other than one example and a comprehensive test suite right now. Here's how the code to do what you want would look like: extern crate select; use select::dom::Dom; use select::predicate::Name; fn main() { let html = "&lt;html&gt; &lt;script&gt;some script&lt;/script&gt; &lt;script&gt;other scripts&lt;/script&gt; &lt;/html&gt;"; let dom = Dom::from_str(html); for script in dom.find(Name("script")).iter() { println!("{:?}", script.text()); } } Output: "some script" "other scripts"
Implied comparison to C++? "If C gives you enough rope to hang yourself, then C++ gives you enough rope to bind and gag your neighborhood, rig the sails on a small ship, and still have enough rope to hang yourself from the yardarm" -- The UNIX-HATERS Handbook
Having done all of my string munging in Python for the past 16 years, I ended up converting my strings to `Vec&lt;char&gt;` "hello".to_string().chars().collect() and doing slicing and matching from there.
Sounds very sensible. Another example of Rust code that uses abstractions only Rust has, I think. For the first point though I suppose affine types would work, which I see your implementation is doing. Is it possible to layer routers on top of each other using this approach? If you have multiple end points like /{a,b}/[c,d,e,f}, the `router!` statement will quickly look rather massive.
Love may be too strong a word. But thank you.
An extremely easy way to test this is to direct stdout to a file, e.g. `./application &gt; some_file`.
Wrong link?
You are going to need to provide more information here.
Have `rustc` emit a static library (.a). This will include the relevant bits of libcore. See the build system of [my kernel](https://github.com/krzysz00/rust-kernel/) for an example of this. 
Also, did you define `panic_fmt` and friends? You need those three lang items when using just core 
Yep! `stack_exhausted`, `eh_personality`, and `panic_fmt` are all in the code sample up there. I've tried to build with `--crate-type staticlib`, but I thought that only mattered if you did `--emit link`? Either way, it tries to pull in `compiler-rt` and I haven't figured out how to either turn that off or pull it in.
Check out https://www.reddit.com/r/rust_gamedev/
We're exploring using Bazel at Dropbox for projects that include Python, C++, Go, and Rust.
Thanks a bunch! I didn't realize there was a specific sub for rust gamedevs =P
I will, thanks!
If you don't know what you want, you probably want graphemes. These are the things the user would identify as character. If you're lazy, you could also take code points (aka `char` in Rust) as a poor man's approximation of graphemes.
Perhaps you should count in the suggestions from the previous week(s) as well. That way a crate doesn't need to be posted over and over again.
Even that still generates syscalls which deschedule the process.
I would actually say that functions should take an expression instead of a block because a lot of functions are a single long line
&gt; It works fine, but talking to the "regular" SDKs is obnoxious. For those curious what is obnoxious: the entire iOS API is in Objective C, and likewise Android API is in Java. You basically have to write a C wrapper to whatever you want from the Obj-C/Java API, and then make Rust bindings to that C wrapper.
I'm not too familiar with mobile cross-platform dev, but iirc dropbox got [automatic generation](https://youtu.be/ZcBtF-JWJhM) of c api going for their cross-platform c++ codebase. Maybe we can do something similar for rust
You have to define `start` at this luck of freestanding, I think. 
`car` and `truck` aren't identifiers, they're part of the macro syntax, or marker tokens. `car` entries and `truck` entries are used in different ways by different parts of the macro.
&gt; It seems like the macro system should be roughly as powerful as a regex parser. "should be" and "is" are two *very* different things. &gt; Are either of these possible? `macro_rules!` is incapable of expressing alternation like that. You have to do it yourself using recursive matching. Without knowing what you're trying to do, I can't really give much useful advice, as there's a reasonable set of things that need to be explained to do this, none of which is really written down anywhere (yet; working on it). [`error_type`](https://github.com/DanielKeep/rust-error-type) does something similar to this, with its clause parsing. You basically want that part.
I'm aware that "should be" and "is" are different. I'm being prescriptive, not descriptive. I suspect that the functionality I want is missing, and I think it would be beneficial to add it. The way `error_type` is implemented looks promising. I'll try that.
They *are* identifiers. You can do whatever you want with them then—pass them to another macro, for example.
&gt; For your game entities, wouldn't it make sense to use a GameEntity trait? The problem with using traits is that you can make everything use one trait, but a complex game will have a subset of entities that you want to implement other traits for, like `Vehicle` or `Ammo`, and what you'd want for these is a function that downcasts entities to a trait object for those if the entity implements the subtrait or `None` otherwise, and Rust doesn't seem to have this. The `Any` trait can downcast to concrete types, but as far as I can tell there's no way to downcast to trait objects. If you're playing OO, you'll want concrete objects that implement several trait objects, and you'll probably have several concrete objects with a different trait object loadout that map to the same trait object you'd want to operate on. (Also you run into the usual OO inheritance style patterns you'd want to use to cram the behavioral diversity into a single root type and how Rust doesn't have affordances for eg. base reuse for a derived type, like Go does with struct embedding.) Another thing to note is that entity component systems are the preferred approach to robust game engines in OO languages as well these days. Rust just forces you to go straight to them when you start having anything like an open/closed principle style need to have your game entity set open for extension beyond its initial specification. Something like a Tetris or a Space Invaders is pretty much a closed design, you know the small set of entity types there is, so you can just use a concrete enum. Then again make something like Minecraft, and pretty soon someone will want to mod in an autonomous woodcutting drone that doubles as a resource teleporter wired to a manufacturing base and has an AI for defending itself against random mobs, and you can also throw rocks at it to bring it down and loot its engine compartment for fuel cells. That's going to need a system where you can just configure entities with an arbitrary set of complex capabilities, and probably do the configuration at runtime. This is obviously getting too involved for a basic language FAQ, though I imagine the game development question is getting asked pretty frequently. &gt; Another semi-clunky way to use float keys in HashMaps is to wrap them in a struct and define Eq etc. on the struct. Yeah, this is probably a good answer. Wrap standalone floats in a newtype struct and if the float is a part of a larger struct, implement `Eq` by hand for that struct.
They are, but a specific set. You can't use `humvee`, for example. I edited my post to be more clear.
Thanks for the response. I understand I could have put it in a function, but it still kind of baffles me that it's necessary. I mean, couldn't I do the same thing in C? It just seems that the only difference between the languages is that Rust *forces* you to do error checking.
Nothing stops you from having the `Vehicle` trait extend the `Entity` trait. Or if you don't know at compile time if something is a vehicle or not, you could have something like: trait Entity { fn as_vehicle(&amp;self) -&gt; Option&lt;&amp;Vehicle&gt;; } or maybe trait MaybeVehicle { fn as_vehicle(&amp;self) -&gt; Option&lt;&amp;Vehicle&gt;; } and then take a `Entity + MaybeVehicle` parameter. If you want to be really, really dynamic, you could always do something like store a map of strings to functions. It's slow and clunky, and you're basically hacking a dynamically-typed language into a statically-typed one, but it's possible. No perfect solutions, of course, but there is no perfect language.
It does. That's a good thing.
Rust doesn't force you to do error checking. It gently warns you if you don't. You can just write `io::stdout().flush()` if you want to and ignore the warnings. Edit: like so: use std::io::prelude::*; use std::io; #[allow(unused)] fn main() { let mut name = String::new(); let mut age = String::new(); let mut username = String::new(); print!("Name: "); io::stdout().flush(); io::stdin().read_line(&amp;mut name); print!("Age: "); io::stdout().flush(); io::stdin().read_line(&amp;mut age); print!("Reddit Username: "); io::stdout().flush(); io::stdin().read_line(&amp;mut username); println!("\nYour name: {}\nYour Age:{}\nYour Reddit Username: {}\n", name.trim(), age.trim(), username.trim()); }
I'd stick with what you have. The increase in complexity to allow for optional or repeated sections is just *not* going to be worth it. To do it, you'd need a full `error_type`-style recursive pushdown parser.
&gt; It just seems that the only difference between the languages is that Rust forces you to do error checking. You're from the school of C programmers who don't check `errno`, aren't you? If you write your example in ideomatic C, checking `errno` as you go, and setting every single parameter on `stdout` and `stdin` (*as you bloody well should!*) then C is at least as long if not longer.
Your invocation of `Result::and` should be `Result::and_then` instead (otherwise it will read input before `stdout` is flushed): fn prompt(expected: &amp;str) -&gt; String { print!("{}: ", expected); let mut input = String::new(); io::stdout().flush() .and_then(|_| io::stdin().read_line(&amp;mut input)) .unwrap_or_else(|_| 0); // handle your errors here input.trim().into() }
Yes, of course. But the NDK doesn't provide anything except really an OpenGL window and input events. If you want a UI you'll need to write Java, or take the Rust-&gt;C-&gt;Java path. No getting around that.
The former, which parses `NaiveDate` then converts to `Date&lt;Tz&gt;`.
Not knowing rust, I wonder what does print("Your name: {}",name) does when name is a io::Error
First of all, I don't believe order of evaluation is entirely defined for Rust. Secondly, your code is *badly wrong*: it totally ignores whether or not an error has occurred. fn main() { test_err(1).and(test_ok(2)); } fn test_err(i: usize) -&gt; Result&lt;(), ()&gt; { println!("err {}", i); Err(()) } fn test_ok(i: usize) -&gt; Result&lt;(),()&gt; { println!("ok {}", i); Ok(()) } // err 1 // ok 2
I have had the same kind of feeling about Rust, its a great language, but it very verbose, and it can be very hard for a beginner.
Yeah, rust is kinda explicit, but I'm starting to like that actually. One small thing to note is that your code is a _little_ more verbose than it might be in "real" code because you're doing it all in `main`. Rust doesn't have exceptions, and you don't really want to panic, so error handling is built around using data types like `Result&lt;A,B&gt;`. However, `main`, of course, isn't allowed to return `Result&lt;A,B&gt;`. So `main` is kinda where all your chickens come to roost, making it more verbose. In practice, when you're writing real code in some function somewhere (not `main`), where you have the freedom to indicate the possibility of failure by the function's return type, you have some niceties like the `try!()` macro to keep the verbosity down. So `try!(io::stdout().flush())` either returns the happy value `Ok(())`, or calls `return Err(...)` with whatever went wrong. But, again, you can't use that in `main` since `main` isn't allowed to return `Err(...)`. Can I ask what you were expecting, that this verbosity was a surprise? It seems like you just kinda want to ignore errors, and yeah, rust won't let you do that in `main`, but if you push everything down a little so you can use `Result` and `try!`, I think you can make it more like how you want: use std::io::prelude::*; use std::io; fn main() { match main_but_i_dont_care_about_errors() { Ok(_) =&gt; { println!("have a nice day!") } Err(e) =&gt; { println!("{}", e) } } } fn main_but_i_dont_care_about_errors() -&gt; Result&lt;(), io::Error&gt; { let mut name = String::new(); let mut age = String::new(); let mut username = String::new(); print!("Name: "); try!(io::stdout().flush()); try!(io::stdin().read_line(&amp;mut name)); print!("Age: "); try!(io::stdout().flush()); try!(io::stdin().read_line(&amp;mut age)); print!("Reddit Username: "); try!(io::stdout().flush()); try!(io::stdin().read_line(&amp;mut username)); println!("\nYour name: {}\nYour Age:{}\nYour Reddit Username: {}\n", name.trim(), age.trim(), username.trim()); Ok(()) } I'm still at the beginner level, but this kind of error approach has worked for me so far. I understand that as you get more sophisticated there is some complication in changing between various error types, though. I think [this](http://blog.burntsushi.net/rust-error-handling/) is the current de facto standard guide on error handling in rust.
True.
i've read that &gt;Rust's fork of llvm diverges little from upstream LLVM, only doing a few optimaztions that upstream doesn't want. do you happen to know more about this?
Rust makes you aware you need to do error checking but you can ignore it if u want. What you have done in your sample is to try to be as verbose as possible, but the fact is you could write it with as many lines as you would in C.
I've updated [my bunch](https://github.com/hashmismatch) of `no_std` libraries for embedded projects to compile with the latest Rust nightly. Much work to do before I update the executable as well, with the latest allocator changes and that.
Well, honestly, I wasn't *trying* to make it look big. I could have made it a function. The result is what came from looking at examples in the rust book and the references.
This is a bit incidental, but I recently read [an article](http://www.aaronblock.com/thoughts/2015/8/21/why-i-want-swift-to-be-your-first-language) about the desired qualities of a programming language for teaching programming with (focusing in particular on Swift), which mentions: &gt; That being said my biggest complaint about Swift is that it lacks Python's simple input() and read() commands. (If you haven't use Python before: input() prompts the user for an input and returns a string, and read() will take the contents from a file and return it as a string.) Having access to simple user/file input dramatically expands the set of examples and assignments I can present in the first month of intro. Being a good programming language to use in "intro to programming" courses is probably not one of Rust's many ambitions, but it's good to know about all the same.
Yeah, I get the idea. I'm not new to programming by any means, it's just that, because of how "new" Rust is, I'm having trouble finding standardized examples. The program in the OP was based off the way the book did IO. I figured there had to be a better way, so I asked.
How obnoxious?
(I also found some formatting errors in the books. I'll write some PRs after lunch. We should _really_ generate these ebooks on the build bots…)
`try!` macro or `unwrap` on a `Result` are two ways to circumvent detailed error handling but `unwrap` is not recommended unless you're testing/debugging or you're sure the `Result` is an `Ok()`
Oh, no worries. Thanks for the comments.
I'm sorry but to me it seemed that way. The way I see it is, in a real application you wouldn't write code like that. If you need to read alot of input you will write specialized functionality for that which integrates nicely with the rest of your program. Like if you start to do error handling in C, your code can quickly turn into a mess if you're not carefull. Sometimes you will need to get creative to write elegant code but I think this is true in any language. 
&gt; Failed to download […] from https://crates.io[…] &gt; SSL connect error There have been some DNS-related SSL problems with crates.io before. IIRC they were solved by… waiting at bit.
I find that the easiest way to understand `try!` is to look at its definition: http://doc.rust-lang.org/std/macro.try!.html
I'm sorry that you were unable to download my crate. Hopefully the connection problems get fixed so you can download it. At least you're on Windows, so your download of `winapi-build` was necessary, unlike all the people on Linux or Mac.
It was `loop`.
I don't mind `std\cell\Cell` visually, but the idea was to introduce a new form of matching brackets (i e, we don't only have `( )`, `{ }`, `[ ]` and `&lt; &gt;` but now also `\ /` - where `&lt; &gt;` is a bit problematic because `&lt;` doubles as a comparison operator. Using `\ /` instead would make things easier for the parser, hopefully. And perhaps also for humans to read.
I like how you in the HTML version you put everything on a single page. That way one can do ctrl+f ... I miss this in the default rustbook configuration.
https://github.com/Marwes/embed_lang
&gt; like building catwalks with no guard rails An example can be found here: http://www.youtube.com/watch?v=BHVnULaKHAU (Huashan trail, in China, and yes the locals go there in flipflops)
You're right; my mistake.
Same thing in F# for comparison: let read prompt = printf "%s" prompt stdout.Flush() stdin.ReadLine() do try let name = read "Name: " let age = read "Age: " let username = read "Username: " printf "\nYour name: %s\nYour Age:%s\nYour Reddit Username: %s\n" (name.Trim()) (age.Trim()) (username.Trim()) printfn "have a nice day!" with e -&gt; printfn "%O" e You have a lot of code duplication in your Rust which you should factor out into a function. 
What I would love is to to have it change the URL on the address bar as you scroll the page. For example, scrolling [here](https://killercup.github.io/trpl-ebook/trpl-2015-09-12.html#complete) would change the address bar to add the `#complete` anchor. This makes sense even in the current configuration with one page per chapter, because there are anchors within a chapter ([example](https://doc.rust-lang.org/book/testing.html#the-tests-module)). But, if one decides to present the book as a single HTML file (which IMO is the right decision), to not make it too overwhelming, perhaps there sould be a "lock" to hide other chapters (or other sections). I'm not sure how the UI on this should look like, but it could combine both interfaces (single page and "multi page") in a single HTML file.
I wonder if we could publicly expose the `RcBox` type for niche use cases like this. You could have things like (but with better names): fn try_unwrap_rcbox(self: Rc&lt;T&gt;) -&gt; Option&lt;RcBox&lt;T&gt;&gt; fn try_into_box(self: Rc&lt;T&gt;) -&gt; Option&lt;Box&lt;RcBox&lt;T&gt;&gt;&gt; and in the other direction: fn new_from_rcbox(rcbox: RcBox&lt;T&gt;) -&gt; Rc&lt;T&gt; fn from_box_rcbox(box: Box&lt;RcBox&lt;T&gt;&gt;) -&gt; Rc&lt;T&gt; with these two resetting the reference counts to their appropriate initial values upon receipt of the `RcBox`. Edit: Or... I guess you could expose `RcBox` but keep the reference count fields private and then they don't even need to?
Yup, this is featured in [How to Design Programs: Teaching Languages](http://docs.racket-lang.org/drracket/htdp-langs.html) for Racket. It goes beyond just libraries though, it exposes different dialects of the language. As the student progresses, more and more of the language becomes available. AIUI, it's all integrated as part of the Dr. Racket IDE. (Which also has really great built-in support for running tests.) (I'm not suggesting someone do this for Rust necessarily, but just wanted to point out that there are people doing this with success.)
There's not really anything directly equivalent in rust, the hypothetical `&amp;own` pointer is probably closest, in that it has move semantics, but is still a reference type. An rvalue reference in C++ is a reference to something that you can move out of. This still differs from rust in that destructors are still called on moved values in C++, so what gets left behind must still be a valid object. They exist as an optimization - things like temporary variables created by the compiler won't be accessed after use, so temporaries will automatically convert to rvalue references, and by providing a function overload which accepts an rvalue reference, you can steal the contents of that temporary.
I thought it *did* have to be valid, since C++ needs to run destructors.
Valid but unspecified. http://stackoverflow.com/questions/7027523/what-can-i-do-with-a-moved-from-object
You're looking for /r/playrust. This subreddit is for folks interested in the [Rust programming language](https://www.rust-lang.org/).
Probably would be an absolutely positioned option to 'see all' or 'current chapter', and would hide/show text accordingly. The tricky part is having "something that indicated which section you're looking at". One you have that, the rest is easy.
[The usual list,](http://freegamedev.net/wiki/Scripting#Scripting_languages) ~~most~~ some of those have a C API.
What you describe does not seem to be far away from how Rust handles things. Especially regarding `struct`s and how methods are defined for them. There is for example no implicit `this` parameter. Idiomatic Rust is however quite different from C/C++ if you ask me. Error handling for example is done through more complex return values and usually involve pattern matching at the call site. Quite similar to Haskell. This is a very superficial description of Rust, I suggest you dive into the [book](https://doc.rust-lang.org/book/) and see for your self. You can also try out Rust here on the [playground](https://play.rust-lang.org/) instead of installing it. Apart from the language itself, there is also the ecosystem around it to consider, meaning available libraries and so on. I'd say, for scientific computing, Rust still has a long way to go, compared to what C/C++ and Python offer today. Gamedev is another matter. There are very good libraries (glutin and glium come to mind) that handle all sorts of things for you, like window creation, input, OpenGL..
C API interfacing tends to be neither simple nor safe, unfortunately.
There are multiple axes... &gt; Would you understand Rust? Certainly, coming from C++ ownership should be at least partially ingrained and you know what `const` is about, so Rust should be a breeze (at the conceptual level). Of course, you'll still take some times before you can write things right from the get go, but it's true of any language you delve into. &gt; Could Rust be used in your domain? Certainly, Rust is low-level enough to satisfy the most stringent requirements and is one of those very rare language which encode concurrency at the type system level to help you out. &gt; Should you use Rust? I don't know. On the one hand I personally greatly appreciate its type system; and especially for concurrency it could really help you out. On the other hand, Rust' constant focus on ownership (no GC) and explicitness (some verbosity) mean that some people would prefer Go or Python as long as their performance is sufficient. Also, the available libraries might not suffice depending on your field; it'd be great if you then contributed, of course, but it would take time. Ultimately: try it out, see if you like it and whether YOU think it's a good fit.
Also, Rust has probably better opportunities for a nice integration API, I'd guess. Luckily, there is at least one interpreter written in Rust on the way, according to /u/yaskhan.
Author of that article here. In the meantime, I've managed to hack together a Rust FreeRTOS API wrapper (with a bunch of intermediate C functions, since FreeRTOS really likes C macros). This is just so much nicer than plain old C: Task::spawn("sntp", 1024, TaskPriority::BelowNormal, || { wifi_sntp_sync(); }); I've got similar helpers for mutexes and queues. I'd love to release this some time, but it requires a lot of components to get going at the moment. FreeRTOS shims, memory allocator, the wrappers, etc...
&gt; I've been moving much more to just encapsulating state in POD structs and providing the required struct to whatever function needs it Rust is totally about POD structs (with methods): that's why it doesn't have constructors! Rust also doesn't have inheritance and the more problematic OOP patterns (you can *simulate* inheritance right now, abusing some techniques that shall go unnamed, and Rust might gain at least some form of virtual structs in the future, but Rust is opinionated on the side of *"composition over inheritance"*). More importantly, Rust *does not have subtyping* (with a small exception due to lifetimes), so there is no implicit upcasting! Generic code in Rust employs [traits](https://doc.rust-lang.org/book/traits.html), that are like Haskell's typeclasses and the upcoming C++ concepts. You can define methods in a trait and "bound" a generic parameter by a trait. For example, if you have a generic type `T` and say that [`T : Debug`](https://doc.rust-lang.org/std/fmt/trait.Debug.html), meaning it can be printed for debugging purposes, and if you have a variable `a` of this type, then you can call: [`println!("Printing an 'a' of generic type 'T' {:?}", a)`](http://is.gd/nEoWoV) Which is composable: you can say `T : Eq + Debug` for a type `T` you can use the equality operator (`==`) and can be printed, etc. On the functional side, I think you should look into [iterators](https://doc.rust-lang.org/book/iterators.html): they give some high-order, generic methods like [`.map`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map) and [`.fold`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.fold) (called [iterator adapters](https://doc.rust-lang.org/book/iterators.html#iterator-adapters)). But they are only for sequences, unlike, say, Haskell's `Functor` that can map over arbitrary structures, like trees. One cool property of iterators is that, if you are careful, LLVM can optimize an iterator chain to a single pass. So, for example, `a.map(|x| f(x)).map(|y| g(y))`, when compiled with optimizations, does a single traversal on `a`, and doesn't allocate an intermediate structure (it's allocated only when you call [`.collect`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect)). I mean, a code [like this](http://is.gd/Tru3Dg). (In the Playpen, you can see the LLVM IR output, or ASM, by clicking the buttons on the top. Clicking "Release" enables optimizations)
Can't wait for rust to get do notation..
Playing with Rust cross-compiled to JavaScript: https://github.com/tcr/rust-webplatform I was thinking of porting some tricky algorithms from Rust to a typed JS variant, but then thought, hell, let's just port DOM bindings to Rust instead.
My first impression was that the point of Cargo is mostly dependency managing. The build tool functionality seems like a bonus, so that you're not left alone without a default build tool for smaller/throw-away/test projects. But that interpretation might be wrong.
If you are interested in this kind of thing, there are two/three linear algebra libraries (scirust, and sprs are new, I don't know nalgebra very well) providing matrices and some algorithms on them, very different in style. I think sprs is more idiomatic but still very new, so there is a lot to help out on.
&gt; There's not really anything directly equivalent in rust, the hypothetical `&amp;own` pointer is probably closest, in that it has move semantics, but is still a reference type. Nope - this is quite suggestive due to the naming (moving references in each case), and for a while I thought the same, but *actually* rvalue references correspond most closely to `&amp;mut`. The "what gets left behind must still be valid" aspect is now completely consistent. "Moving out" of an rvalue reference is most like `Option::take` in Rust (with nullability re-implemented separately for each type, rather than factored out). See the post I linked from another comment for more.
I have to say I disagree; most of these criticisms of "Iron/Nickel" are not aspects of Iron at all! - `Plugin` exists to serve exactly this purpose, when you have "extension" data that requires no configuration and instead just needs to process the request or response, and will not lead to a runtime error due to a typo in most cases. - Services being `'static` is a temporarily limitation coming from hyper, eventually we will enable non-`'static` `Handler`s. Also, looking at `rouille`s code, the server currently has the same restriction. - Subnote: it's entirely possible to integrate postgres transactions into an Iron server, all you need to do is stick a r2d2 postgres connection pool in your handler or request extensions, then create transactions from it when you need them. - Virtual dispatch via trait objects is only used within Iron when necessary to store a list or map of `Handler`s. If you use only `Handler`s directly and define your own that do not store lists or maps containing `Handler`s, you can have entirely static dispatch. For instance, the "hello world" example uses only static dispatch. - Iron already follows the return-a-response philosophy, and only passes `&amp;mut Response` around to `AfterMiddleware`, which is entirely opt-in and only for dealing with small, repeatable changes to a response. - Iron's concept of middleware is entirely opt-in and defined via the `Chain` type, which is not special in Iron's eyes in any way, it is just a struct which implements `Handler`. If you would like to use a different middleware strategy, you can easily implement it and use it with Iron.
Although by that definition, C++ doesn't have subtyping either.
In Rust, moved-out objects are not required to be safe to assign to or destroy (currently, as an implementation detail, they are, but that is going away).
It might be obvious but don't actually use this for anything yet. Although it is "working", it has ~500 lines written in it and everything about it should be considered unstable and laundry eating. I am hoping to get the time write something soon-ish about what it is about and what it still lacks before it can get into usable shape.
I had to use a little C code for socket timeouts, let's hope we don't get crashes or anyt &gt; Segmentation fault
Then, what is required of them?
The language doesn't specify, but an API can specify. For example, a string class might specify that once it's moved, it will be in a state identical to a default-constructed one.
Nothing. Unlike in C++, a moved-out value in Rust doesn't exist any more.
&gt;`a.map(|x| f(x)).map(|y| g(y))` I know you may have written it like that on purpose, but I'll mention it anyway. That's equivalent to `a.map(f).map(g)`
Oh, I was confusing with unitialized values (PS: they seem to introduce a lot of complexity and corner cases and I'm not entirely sure why they exist).
That was a very good overview, thanks.
Lua is probably the best known one. I really like Tcl for scripting though, especially if you want to do some special domain-specific stuff, for which you can make great use of Tcl's flexible syntax.
Sure. Maybe reserve :: for type hints then. Any comment on for, match, and blocks?
Hey! My code doesn't have segfaults. I manage my memory in a completely safe wayfLhrKLeH1SVYbj\x00 &gt; Read uninitialized memory at 0xDEADBEEF.
Or Scala-like `for` comprehensions.
As a general observation - the stricter and more verbose the type-system, the more annoying it is to use for quick iteration and prototyping; of course that comes at the cost of more bugs in your code. The more lower level language the more performance you can get, at the cost of having to deal with the lower level details. Basically, where you lie in that spectrum determines what languages you will enjoy using. If you want to prototype/research new ideas -- probably Julia/Matlab/Python/R will fit you better. If you want a high-performance implementation -- Rust/C++ will probably work better. Somewhere in between those two and want easy cross-compilation, then Go might fit you. *I do both and often end up prototyping and trying out new ideas in one language, and later writing production code in an other language. This makes sure that I throw the first prototype away, resulting in better code.* If you are doing gamedev as a hobby, pick a language that you have fun with. There's no point in frustrating yourself with a language you don't like. Here I would suggest C/C++/Rust/Python/Lua/Unity/JavaScript/... depending on which part of gamedev you like. If you like building engines, pick a lower level language. If you like building games more, pick a prebuilt engine. Do you want to sell it; use tried and proven tech. And so on... Finally, I would suggest the same as several other people, try few languages. Pick a problem/algorithm that you know and try to write it in a few languages. It should be a real-world example. Facilitated examples can give a wrong impression. Ask people from respective community to review your code; this helps to get a better understanding how the language can and should be used. It's very easy to unknowingly bring old habits and patterns from your previous languages to new languages.
Say you have a `macro_rules!` macro defined somewhere in a crate called `foo`. Inside the right-hand side of that macro, `$crate` expands to nothing when the macro is used in the same crate, and to `::foo` when it’s used from other crates. This is useful for a macro to refer to things defined in the same crate as itself. Using relative paths is unreliable as you (probably) don’t know where the macro is gonna be used, so you may want to use absolute paths (that start with `::`) instead. For example, the absolute path for the standard `Result` type is `::std::result::Result`… except from within `std` itself, where the `std` name doesn’t exist and the `result` module is at the top level. So `$crate::result::Result` works everywhere. For `Result` specifically you often don’t need any of this since it’s in the [prelude](http://doc.rust-lang.org/stable/std/prelude/), but `try!` is designed to work even even if the prelude is disabled (for example if you’re using `#![no_std]`). **Edit:** it’s documented at http://doc.rust-lang.org/book/macros.html#the-variable-$crate
[removed]
I didn't know that, thanks. :)
Actually it allocated precisely enough memory: primarily this is because of evaluation order. It has to create the new vector before it can assign it. It's also because of the need to handle panics: if the new vector was constructed in place of the old, then any panics during construction would result in the vec being left in an unexpected or invalid state.
Oh, I think I might have figured it out use std::mem::drop; fn main() { let mut v = vec![0; 100_000_000]; drop(v); v = vec![0; 100_000_000]; }
Rust itself maybe? https://github.com/murarth/rusti
Yes, so at some point in the control flow I'll need to allocate again to setup the start to an initial state. v wouldn't need to be mutable if I use another binding.
Note on this: chars should work without to_string as well.
Loved this. Thanks for sharing!
I suspect you already know this, but I thought it would be a good idea to share for other interested people who might not know how to build rustc that can target musl: https://doc.rust-lang.org/nightly/book/advanced-linking.html#linux 
On #![no_std] and OSes - yes: https://github.com/thepowersgang/rust-barebones-kernel
As I said in the /r/programming discussion, I find it interesting that JB does not desire the `x.&lt;autocomplete&gt;` syntax... [Even haskellers want it!](https://ghc.haskell.org/trac/haskell-prime/wiki/TypeDirectedNameResolution) 
It even has a fancy math name: eta conversion. 
&gt; Oh shit, the name is already taken on Crates.io. This has happened to me so many times but it never fails to completely demotivate me. Why not call it Verdigris. EDIT: Oh, well, too late.
From 2012 but still insightful.
I think that the trait system in Rust nicely circumvents the problems he mentions. It's open-ended so everyone is free to implement their own methods, if that's the need.
Might be worth opening a suggestion on the bug tracker, but it would probably require the MIR: this optimisation can not be applied in the case of v = foo(&amp;v); so the compiler needs to be smart enough to realise that there is no reference to the target name in the rvalue and the lifetimes of `v` essentially ends before the assignment (then a new lifetime is created) while the general case is for the lifetime to end *after* the reassignment (and with lexical lifetimes I believe the old lifetime will extend through the lifetime of the new assignment)
This is similar to how I feel. How do you decide which methods to include and which ones to leave out? The only honest way to do OOP is to allow monkey-patching or some moral equivalent.
Xamarin do that too for their C# cross platform framework.
[**@Jonathan\_Blow**](https://twitter.com/Jonathan_Blow/) &gt; [2015-09-12 19:04 UTC](https://twitter.com/Jonathan_Blow/status/642775771342204928) &gt; For readability purposes I just condensed that long series of tweets into a post on the Witness blog: &gt; http://the-witness.net/news/2015/09/a-note-about-programming-language-design/ ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
&gt; isn't that completely equivalent to methods? Yes and no. If you look at Java or C++ as (bad?) examples of OO, then a class has methods defined once and for all, and the user of the library cannot add any others. I think C# has a way to extend classes, allowing this, and of course Rust has the trait system for it.
And [Nim's](http://nim-lang.org/docs/manual.html#procedures-method-call-syntax).
What /u/matthieum said. That is how methods are *compiled* but its not how you are actually able to use them without UFCS. I read his rant as being about having specially blessed functions called *methods* being bad for universally useful types such as `Vector3` you can never know all the functions that a user wants. The method call syntax is not bad in itself its just that the way languages like C++ uses it is bad as it isn't extensible. The other way of reading is that having UFCS at all is just unnecessarily complicated as you could only have the normal calling syntax. I think there is a good argument for this for simple languages but as an autocompleter can use the type of the object in a method call to limit the number of usable functions it can definitely make autocompletion better. Methods still sort of have a use in C++, Java, etc as only functions/methods declared in the class have access to private members. Unfortunately I feel that is a poor solution as it often leads to classes being larger than they need or having a larger public surface than required (it also leads to things like `protected` which is basically a longer way of writing public).
I'd agree with this though with an asterisk on nicely. There is small bit of annoyance with traits used only to add methods to types which is that the trait needs to be imported as well. I do not think this is really solvable though, at least not in a simple way. From what little I know about D I guess that solution might be simpler from a user perspective (but then you need function overloading as well). (With combine I have gotten a couple questions which where rooted in the person not discovering the [ParserExt trait](https://marwes.github.io/combine/combine/trait.ParserExt.html) so it may also hurt discoverability).
No, that would a) unduly benefit older nominations and b) increase my amortized time to seek the best nomination to at least n*log n.
Forcing you to check for errors is a good thing, it means you have the compiler telling you about potential errors instead of figuring them out at run time. The whole null billion dollar mistake is because many mainstream languages don't force you to check for null before calling methods.
Its working now, it seems to be a firewall problem on my side. Sorry and thank you :)
Note that there are some issues with automatic coercions that make that transformation not always work. See [here](https://play.rust-lang.org/?gist=9cccaf7dbe874637edc0&amp;version=stable).
Thanks for all the replies everyone. I never expected such a good response. I am very much a systems programmer in my way of approaching problems, which is one of the reasons the idea of Rust appeals. Like a fair few of you suggested though, I'll have a go working through some materials for a few different languages and see if any of them click more than the others.
&gt; That is how methods are compiled but its not how you are actually able to use them without UFCS. But go has UFCS *and* you can use methods that way (if you choose to do so). If T has a method Foo(), then T.Foo evaluates to a function of type func(T). There is no real restriction, you can make it possible, if you want. &gt; I read his rant as being about having specially blessed functions called methods being bad for universally useful types such as Vector3 you can never know all the functions that a user wants. True, but you can also not know every function the user ever want. That's why you let them add your own. Why not let them add their own methods? &gt; The method call syntax is not bad in itself its just that the way languages like C++ uses it is bad as it isn't extensible. But we don't talk about C++. We talk about the design of a *new* language. You can do whatever you want and use methods however you choose. I'd also argue that not the method implementation of C++/Java is the problem, but the visibility. C++/Java encourage making pretty much *everything* private or protected, which of course discourages reuse and extensibility. &gt; The other way of reading is that having UFCS at all is just unnecessarily complicated as you could only have the normal calling syntax. Yes, that's the argument, but this argument makes no sense, IMO. UFCS has very specific technical advantages (for example name spacing and the auto completion argument) and the counter arguments he gives (and are given in this thread) are mostly completely fabricated. They show a lack of imagination, by conflating different problems of languages like C++ and Java and randomly assigning them to one specific feature of these languages. &gt; Methods still sort of have a use in C++, Java, etc as only functions/methods declared in the class have access to private members. Yipp, and *that's* the real problem. Restricting visibility in this sense obviously counters extensibility and code reuse. I am fighting with this in my current (not for long) dayjob everyday :)
Was hoping for a pre java1.0 VM but in Rust :) How does this compare to other parsers like nom? (I know nothing about anything involving parsers)
Good question! This is something I want to develop in the "Related Work" section of the manual but here a short preview. Parser combinator libraries (like nom or combine in Rust) are another approach for building parser in a programming language. They are built upon existing language features which have advantages and inconvenients, here what I can think of: * (+) No new language to learn. * (+) Very flexible because a function is a parser. * (+) Easily extensible and re-usable. * (-) No global static analysis on the well-formedness of a grammar. * (-) No global optimization of the code. * (-) Depending on the language, it involves more or less boilerplate code. * (-) Can be hard to understand, the grammar is a bit hidden. A parser generator takes the problem at the other end, it tries to integrate seamlessly host language features (here Rust) into a grammar language. Ultimately, I think that parser combinators and parser generators may converge to an unified framework to get the advantages of both. If I must say something specific about nom is that it seems to be more suited for binary format/protocol while Oak is more text-oriented. However, I tried to design Oak to be extensible with bytes-oriented parsing later.
Actually, I like the approach where you can use different parsing systems in the same code. Something like a parser generator for a well defined language, but parser combinators on the edge of the system, where you have to bend the rules a little. Since a lot of formats and languages are layered, nothing prevents you from mixing approaches (that's in part why nom can use regular expressions, while it could directly parse a regular language). Of course, it complexifies everything, and it can introduce ambiguities.
It's... practically the same thing? It's not like you could choose a conflicting version of an overloaded function to pass the arguments to it (in a lang supporting overloading), so they're practically namespaced by the types of their arguments. But still, you *could* write in Rust `&lt;OneType as Trait&gt;::func(DifferentType::new())`, so...
Rebar is also a build system for Erlang FYI.
As you've found we do indeed currently have MUSL support, so there's nothing really much left to do on the front of getting the distribution being able to build an executable which links against MUSL. The more relevant point now is how we're going to enable easily acquiring this support and making it easy to use! The plan here is to: * Split out a new "rust-std" package as part of the main build process for the standard library for a particular target triple. * Get rustup.sh working with this new "rust-std" package * Setup nightly/dist builders for various platforms like MUSL, Android, ARM Linux, etc. * Add support for installing multiple targets to all of our installers (e.g. rustup, pkg, msi, exe, etc). This will likely involve many of them turning into online installers. Once this is all said and done you'll basically just check a box saying you want MUSL support and voila, you'll have it! One day we may event hook into Cargo to make the process even easier, but we still have to design this through a bit. --- As to why we don't use MUSL by default, [I've commented in the thread](https://internals.rust-lang.org/t/static-binary-support-in-rust/2011/20?u=alexcrichton) pointed out by /u/choychoy, but the main points are: * Once you link to musl your story with C interop isn't so great, all libraries you link to must be built statically and against MUSL (e.g. finding an OpenSSL built against MUSL would likely be quite difficult). * Building custom C shims is difficult because you need the MUSL headers installed (e.g. `musl-gcc`), which are often not found by default. * With MUSL currently we don't support dynamic loading, so `dlopen` and friends don't work. Overall linking to the system C library (e.g. glibc) works for many more use cases than linking against MUSL, so it's still an appropriate default even with MUSL support. Of course, however, MUSL support is *very* useful so that's why I want to make it even easier to get a compiler that can target MUSL :).
I have a [`cbor` crate](https://crates.io/crates/cbor) as well. As far as I can tell, the big differences are: * My crate works on stable Rust. * My crate goes to great pains to use `rustc-serialize`, although there [is a PR to add `serde` support](https://github.com/BurntSushi/rust-cbor/pull/5). (But it causes the crate to require nightly, so it will take some work to fix that.) * My crate supports custom tags. Did I miss anything?
Generated code in Oak depends on a runtime and if you look at the code (for example [ParseState](https://github.com/ptal/oak/blob/master/runtime/src/parse_state.rs)), it looks a bit like code used in parser combinator libraries. Indeed, I got inspired by your library (combine) and geal library (nom) to write this runtime part. I think we could rely on this runtime library to let the user write its own parser combinator for extending Oak. It could be similar to semantic action calls. I don't really know, it is just an idea.
Just to note, I've now integrated this into my code and it works exactly how I wanted it to. Thanks.
In my experience, using the nightly compiler is pretty safe. After 1.0, I've never had major compatibility breaks. Sure, some unstable functions have been renamed or removed, but there's generally a clear alternative for those. So yes, if you don't mind having to fix a few things every now and then, I can recommend the nightlies.
Actually, I think he's saying that this is an IDE feature and doesn't have anything to do with language syntax. E.g. if you have a value of 'x', you can just type x in a new statement/expression and the IDE will show you things you can to do to x and insert foo(x) if you choose that. While I think that's sort of correct, it's not at all "obvious" to me how to make that nice. I mean, every time I put an 'x' as an argument to something I also have to deal with auto completion popping up for all functions that take an x? Probably too annoying. So then what, you introduce non-language syntax, like I type x. (even though this isn't a thing in the language) and get auto completions that will then *rewrite* my code to foo(x)? That seems jarring and weird - every IDE might have a different special symbol to trigger that, and worse I have to write in "code" that isn't actually code to get auto completion. So what next? Have a Command+Space type thing do the auto completion? I mean that's probably the lesser evil, but at the same time it's possibly ambiguous (do you want functions that operate on x, or do you want info on whatever the surrounding context of x is?), and also more work to get autocompletion (it doesn't just come up in *natural* positions when typing, you have to ask for it with extra key strokes). 
One perspective of `impl` blocks is that they are simply describing an anonymous trait that's only applied to a single type.
Actually I think Rust is one of the languages which has a really great [set of](https://github.com/kbknapp/clap-rs) [argument](https://github.com/docopt/docopt.rs) [parsing](https://github.com/rust-lang/getopts) [libraries](https://github.com/zcdziura/pirate). 
...!? But why? Everything I know is shattering around me...
Many established astro libraries already have package wrappers available in Julia - https://github.com/JuliaAstro. You could probably do the same with Rust's C FFI without too much trouble.
You won't have to fix things every now and then if you don't actually opt into using unstable APIs yourself. The stable APIs will be as stable in the nightlies as in the release builds. The API-breaking bug fixes will appear in the nightlies first but will propagate to the stable releases eventually. The dependencies which pushed you to use the nightlies might briefly become broken of course, they're the ones who use unstable features after all.
It felt pretty intuitive to me. Because I was trying to read Rust syntax before completely getting the semantics, the similarity was influential on the intuition I got.
+3 int for characters below level 10.
As long as you are OK with some breaking changes when you upgrade libraries or rustc version independently. The only time you will run into breaking changes is when you, or a library you use, uses `#[feature]` attributes. Features which require the `#[feature]` attribute may break at any time in nightly builds, so when using them, you may have to upgrade/downgrade rustc/libraries to find the right version to match. By using any of these features, you make upgrading to a newer version of rust significantly more work. Besides that, nightlies really won't be that much more buggy than stable rust, with the exception of some features as /u/arielby mentioned.
Hmm, yeah, there's also a caveat that the libraries which work perfectly well on 'stable' might get ideas once they detect a nightly build ;)
Seems to be better now. One of the times I tried to launch it I managed to switch to a different tab in the GUI. I can read it without crashing now.
Hi @dabross. I don't know any reason why racer wouldn't work with other rust versions, it (currently) doesn't have a dependency on the compiler that compiled the binary. I use the same binary for multirust stable and nightly projects. What issues were you getting?
Still the same thing, deep refactor of `wayland-client`. I find it surprisingly difficult to find some time to dedicate to this. :(
Writing a blog post about what is needed for a general `Monad` trait. It is not just higher-kinded types which are needed if people are interested in having anything more complex than the `Option` monad implementing the `Monad` trait (no, `Result` will not actually work with just HKTs). The monad types I have looked at so far are: `Option`, `Result`, `Iterator`, `Vec`, my own `Parser`, `State`. And I am planning to look at a hypothetical `Future` monad too. All these requirements are pretty diverse and currently it looks like the `Monad` trait needs to be generic over the type, the `Fn`* type and the lifetime signature of `bind`. Hopefully I will have the blog post ready later this week.
Back to work on my old hexagonal turn-based strategy - [Zone of Control](https://github.com/ozkriff/zoc). Abandoned my attempt to port [poly2tri](https://code.google.com/p/poly2tri) to rust :(
Same as usual, working on Windows things, landing pull requests, and procrastinating. A couple days ago I added `ENUM!` and `FLAGS!` macros to `winapi` to better represent C style enums. Rust enums have the annoying behavior of UB if you have a discriminant not represented by a variant, which is annoying when you can get an enum via FFI, but it's even worse for enums that are intended to be used as bitflags. Still need to refactor all the existing definitions to use them, but we'll get there eventually.
why abandon the port of poly2tri?
Connection timeouts are notoriously difficult to do. Read timeouts are often implemented in libraries but with no customisable connection timeouts. Consider Perl - which has been around forever - how do you implement connection timeouts there? According to [this article](http://blog.booking.com/socket-timeout-made-easy.html) you can use a select loop or use operating-system specific setsockopts. I'm personally used the select approach myself.
Yeah I used setsockopts with C. If it was a server with multiple connections I would definitely use select.
I am a heavy proponent of using stable nowadays if you have no intent of actually building something that is fundamentally built on a nightly feature (e.g. implement a custom `#[attribute]` or a compiler plugin). I wrote my thoughts down here. https://users.rust-lang.org/t/please-avoid-the-cookie-jar/2109 Some time later, I still hold the same opinion. Most "requires nightly" libraries are trivially portable into stable Rust, if it weren't for laziness of the developers. Also, nightly doesn't tell you how far certain features are from release. Some will even never be stabilized (e.g. compiler intrinsics). Rust 1.2 is very well usable and gives you a good oversight of what Rust actually is, not what it might be. It also is a platform to build and distribute a project in, which nightly isn't. Nightly is, in some regards, always "better" in some fashion. But it also doesn't give you any guarantees, many of the things are not documented and you need to be following Rust development very closely to understand many aspects of it.
Hi AnachronGuy, I had a lot of work recently so the development of treasure was slow.. I have separate branch where I am working. So the development didn't stopped. In nex weeks I will do more for treasure. Thank you for your interest.
In libraries that I maintain I’ve used a [Cargo feature](http://doc.crates.io/manifest.html#the-[features]-section) to allow users to opt into unstable stuff (like `NonZero` or `#[unsafe_no_drop_flag]` to save memory), not detection.
It may be inspired by lua but that is not a mistake I intend to make :).
If you use nightly without abusing `#[feature]` you get most of the benefits of stable. The "stable is buggy" problem was mostly in 1.0 and 1.1, so now there is less incentive to use a newer version.
Lua has one of the most efficient implementations of any scripting language (LuaJIT).
Rusti is not really an interpreter. Every command recompiles everything.
This is awesome, thanks for sharing
Neat trick I discovered yesterday... basically, you get graphs with arbitrary pointers, regular (non-interior) mutability, and no overhead over regular pointer accesses. I am hoping it is safe!
Why not develop on nightly, test on stable (and/or beta)? This strategy works very well for me.
I tried to play around with it, but I fail to see how I can match a literal `"`. Using `"\""` tries to match `\"` instead of just `"`.
Really nice! It looks like I can retire my WiringPi bindings now. The only thing I'm missing is a way to do multiple writes to a pin without the synchronization overhead on each write. Preferably through some kind of `.lock()` method. I would also recommend that you write some descriptions in the documentation. Not everyone will know the difference between `set`, `write` and `digital_write` :)
What's stopping you from using Rust itself? I've also been wondering about scripting language integration on the assuming that, like C++, Rust is too complicated to use for rapid prototyping or is too difficult for new programmers. But I'm becoming less convinced of that over time. Are there any technical limitations that keep you from using Rust?
I've peeked into the repo's tests, and it seems the API takes Strings. It's probably fine, but a (most?) common case is using &amp;str. This seems to be a recurring theme, the lack of direct compatibility of these 2 string types, causing the code to be polluted with .to_owned(). I know there [are some solutions](http://hermanradtke.com/2015/05/06/creating-a-rust-function-that-accepts-string-or-str.html) but they may not be applicable e.g. when building structs (as in the example). Is this something that is in the radar for Rust's future? I confess I do not know what would be a good solution.
Yeah, I suppose I do consider it a problem, but mainly because of what "classic" OO is. I feel that in most circumstances state and functions do not need to be mixed into these arbitrary "objects". In the case of things like containers it works pretty well. In other cases I feel that visitors and friend classes are often just hacks that could frequently be transformed to code that is simpler to debug and to understand for someone new to a project. One of the main ideas of OOP (from what I know) is that classes can be worked on independently of each other and their implementation can be considered independently. It seems very rare that this is the case. Most of the time I need to go and inspect how a class is doing this or that because I need to know specifics. If I need access to a certain piece of data from outside the class, well that's another getter/setter. Oh look, now half my code is becoming boilerplate. When state is encapsulated simply as state, it can be copied and thrown around the program to wherever its needed. If one function outside of a "mental class" needs the state of the object, then just hand it over. No massive refactoring to do, no friction, fast data copying due to POD-type structs - and in my subjective opinion far easier to debug. My most recent project did use classes for its subsystems because it made sense in the event loop there. It also had a couple of RAII data readers/writers. In fact I just went and counted, 13 classes in 30k LOC (some of which were going to be factored out), most things were namespaced free-standing functions that operated on POD structs. IMO, it was this way of working that allowed me to succeed that project (which had some very tight deadlines) as refactoring a data struct meant changing a couple of functions that worked with it, rather than changing how my classes communicate. I do think that interfaces are a pretty decent feature (from what I've read) but I've never done more than small projects in languages where they exist. The only place where I use inheritance now is if I have two items that I want in the same container where it makes sense for them to share virtual methods. 
That's odd. This example is working on my (linux+multirust) environment, and multirust shouldn't stop it finding your rust source code (it wont need to interrogate the cargo directories under .multirust). Are you saying that the first line completes ok, but the second doesn't? So to confirm, this does not work for you?: use std::env; fn main() { let args: Vec&lt;String&gt; = env::args(); args. &lt;--- complete here } Could you get the latest master of racer and git pull the latest rust sourcecode and try again, just so we're using equivalent versions? Thanks!
Sure! I first spawn as many threads as there are CPUS. Each thread computes the palette for `(height / num_cpus)` rows, and returns that palette, incrementing an atomic integer for every pixel it processes. Meanwhile, the main thread goes on to keep checking that atomic integer, reporting progress every so often until it sees all the pixels are processed. It then gets the palettes from the child threads, and merges them into one palette. A few notes: * ideally, we shouldn't need the `Arc`s, because we know the child threads won't outlive the main thread, because we join them. Hopefully rust will figure out how to safely do `thread::scoped` someday. * Because the image is shared immutably, we don't need to use a mutex, or any sort of shared mutability. * I let the main thread sleep for 10 milliseconds after each print, but used `thread::park_timeout_ms` to do so, and each child thread unparks the main thread when it finishes, so we hopefully won't ever wait too long after everything is complete. * I have to flush stdout after each write, because ttys are usually line buffered, and we're not outputting a newline
I would love to read a comparison of how the code generated by LALRPOP would compare to Rust's current handwritten recursive descent parser. For example, how do error messages that arise from parsing compare between a generated parser and a handwritten one? Also, if (hypothetically) this replaced the current parser, but then we wanted to extend the grammar to allow infinite lookahead to solve the `::&lt;&gt;` wart, would that be possible?
Great, now for Raspberry user how do you compile Rust programs ? Do you cross compile on your Linux box or do you compile on the RPi ? I am using MacOs, I have read several cross compile tutorial for mac but they seem very complex and out of date, I am not sure it worth the pain, compared to build on RPi.
No. Stable is for serious deployments and testing.
The link to the tutorial is broken. Here's the proper [link](https://github.com/nikomatsakis/lalrpop/blob/master/doc/tutorial.md) until it's fixed :)
As a rule of thumb, hand-written parsers will beat generated parsers when it comes to error messages. The tradeoff is that generated parser are (arguably) easier to program in and also guarantee that your grammar is not ambiguous.
Writing [intro material for timely dataflow](https://github.com/frankmcsherry/blog/blob/master/posts/2015-09-14.md). I have to explain it to a bunch of people this week, and I thought I'd try and do a decent job of it. We'll see. :)
I liked this stickied post until it turned into a weekly reminder that other people are working on cool gaming projects and I'm not. :-)
Hmm. Doesn't `IndexMut` here let you get simultaneous `&amp;` and `&amp;mut` references to the same `T`? If I'm seeing it right the idea is that the `&amp;`/`Link` you index with is just an opaque handle (you can't actually do anything with `&amp;Node` directly through the public interface), and all "true" access is only through the `Root`, but this still seems like it would be undefined behavior technically(?). 
huh
While this is historically correct as an observation of parser generators in common use, I don't think it is true in general. One simple technique that is rarely used (Go's parser is the only production use I am aware of) is to process pairs of erroneous input and error messages to find the LR parser state that corresponds to that input and build a table, so that when you get a parser error at runtime you can find the closest match. It's nice because it separates your error handling from your code entirely, and someone can add better error messages without even understanding the full extent of the grammar. There is a lot of work in the parsing literature on the problem of error recovery for the purposes of finding multiple errors. Back in the days when compilation was a batch job and your compile/edit cycle might be a day, it was fairly important to get multiple errors. One of the most intriguing ways of doing this is to use a substring parser for your language (a parser that parses the language of substrings of L rather than L itself), which lets you give multiple errors without generating any spurious errors. It turns out (perhaps somewhat surprisingly at first) that substring parsing for LR languages can be done in linear time. Writing a substring parser by hand (and maintaining it in the face of grammar changes) is probably untenable, so parser generation would be the only way to use this technique. It's unfortunate that practical parsing tools lag so far behind the state-of-the-art.
Table-driven parsers will have less code than directly executable parsers in general, but LALRPOP will generate particularly large executables because it doesn't do any minimization of the LR automaton (as far as I can tell). That is fixable without affecting the accepted grammars, though.
That's really cool! I may start learning Racket, just 'cause. And *who knows* what the future may hold for Rust in that vein...
&gt; Doesn't IndexMut here let you get simultaneous &amp; and &amp;mut references to the same T? Nope. You have the `&amp;mut` reference to the `T` (which is protected by `UnsafeCell`, so the transmute from `&amp;` to `&amp;mut` is legal according to my understanding of the rules) and the `&amp;` reference is to the `Node`. If this were UB, so would be types like `Mutex` and `RefCell` that work in essentially the same way. (I actually think there's probably an argument to be made that even the `UnsafeCell` is unnecessary here, but I prefer to be conservative with stuff like that).
I am working on getting my game engine's [container format](https://github.com/whiske-rs/hairball) working. After witch I plan on reviving some of the work @kvark has done in [`claymore`](https://github.com/kvark/claymore/blob/master/src/load/mesh.rs) to create a flexible mesh format for gfx (and maybe glium). The hope is to create something that people can reuse in their game that avoids a rigid vertex format. 
&gt; If this were UB, so would be types like `Mutex` and `RefCell` that work in essentially the same way. I guess that's a good point :)
Still working on my relational language. I got join-only queries and dataflow working last week and ran some [very simple benchmarks](https://github.com/jamii/imp/blob/master/diary.md#plans) against sqlite. I want to finish the parser and update the diary today, and then start thinking about aggregation which never worked quite right in Eve.
Nice writeup. I see that timely is closure based and supports multiple processes. Are you serializing the closures somehow or just forking the process and reusing them? How will this work in a multi-computer distributed system?
The main disadvantages (at least with the current implementation) are that all values that cyclically reference each other have to be immovable and rooted at the same location in the Rust program (and that location has to be within the closure). When it comes to intrusive lists many of these properties are par for the course, but it would still be nice to be able to do something similar within a structure; eddyb mentioned that he thought he could use this to construct "existential lifetimes" like we've occasionally discussed in the past.
Outside of work, this week I am answering as many questions as possible for the [new Rust FAQ](https://github.com/rust-lang/rust-www/issues/181), I am barely starting a [Rust-based implementation of R7RS](https://github.com/andrewbrinker/ruse) (with the eventual goal of being an embedded language in Rust, similar to the way Lua works with C), and I am working through reading Aaron Turon's thesis: ["Understanding and Expressing Scalable Concurrency."](http://www.mpi-sws.org/~turon/turon-thesis.pdf)
Very cool. I must have missed that.
I thought we already did infinite lookahead because raw strings can be any amount of `#`s? r##########################################################"hello world"##########################################################; [playpen](http://is.gd/KVbh4X)
&gt; The shortest path is not easily verified I think that's the problem. You still have to take *every* fork in the road to exhaustively ensure you find the best solution.
i think its because im using koding.com and its a docker 
woops
Cool thanks. That actually works. So what is the work around to Box::into_raw ? :.:.: &gt;Also, why is as_ref()being removed? [Its bug report](https://github.com/rust-lang/rust/issues/27780#issuecomment-139923038). I commented against it.
To quote Raymond Chen on the [history of `TerminateThread` in Windows](http://blogs.msdn.com/b/oldnewthing/archive/2015/08/14/10635157.aspx): &gt; Originally, there was no `Terminate­Thread` function. The original designers felt strongly that no such function should exist because there was no safe way to terminate a thread, and there's no point having a function that cannot be called safely. But people screamed that they needed the `Terminate­Thread` function, even though it wasn't safe, so the operating system designers caved and added the function because people demanded it. Of course, those people who insisted that they needed `Terminate­Thread` now regret having been given it. Insofar as I'm aware, there is no safe way of forcibly terminating a thread. If you go the `TerminateThread` route and just kill the thread immediately, you run into the problem of threads dying while holding locks or in the middle of mutated shared state. The problem is that there is absolutely no way of knowing when a thread is in such a state, so you can't avoid this. It's vaguely akin to having the program shoot itself in the head and hoping *real hard* that it misses everything important. On the other hand, you have the trick .NET pulls of injecting a `ThreadAbortException` into the thread. The problem with *that* is that suddenly, all code can panic, even unsafe code that is only correct assuming it can't possibly panic. Also, at least in .NET languages, the above can be trivially subverted by just placing an infinite loop inside a `finally`; in Rust, you'd just need to catch the panic and ignore it. Insofar as I know, the "solution" to this is to explicitly check for abort requests in your code where you need it, and don't run code you don't trust in the same process.
Evaluating Rust for a new game company's first title. Is this madness?!
 - Finish up my `cargo rustdoc` PR - Work on a course project on GCC plugins (and also a graphics project) - Try to get github's JS to work well in Servo, by hook or by crook. 
So how is blocking IO done in Rust? What if the thread can never respond to a request to terminate?
I'm afraid this is just that racer doesn't resolve via the 'for' construct yet. 
I'm a bit puzzled about what your goal is here. Are you trying to design a trait to be used generically or are you trying to implement methods for a specific type? Or are you trying to something via dynamic dispatching?
I see. I was changing too many things at one (switch from stable to nightly, switch to multirust, switch to racer git master) and at one point racer did not work at all (missing the nightly rust sources) so after I fixed that I thought I screwed up something else too. Thanks for the help!
Inside the methods of a trait that is object-safe, `Self` can be an unsized type. (It’s accessed by reference only, so that’s OK.) Thus, inside `RedTrait.do_red`, `Self` does not implement `Sized`. Generics, on the other hand, are required to be sized unless the `?Sized` constraint is added—yes, that is the opposite of traits, where the `Sized` constraint would need to be added to make it reject unsized types. Thus, `B` and `R` *must* implement `Sized`. Thus, when you try to specify `Self` as `R` in the `bluitude.do_blue(self)` call, you have a problem: the method requires that `R` be sized, but you’re providing a type that is not sized. This could be fixed in one of two ways. Firstly (and more usefully), allow `R` to be unsized; because you only use `&amp;R`, that’s fine. This constraint is loosened by replacing `&lt;R&gt;` with `&lt;R: ?Sized&gt;`: trait RedTrait { fn do_red&lt;B&gt;(&amp;self, bluitude: &amp;B) where B: BlueTrait { bluitude.do_blue(self); } } trait BlueTrait { fn do_blue&lt;R: ?Sized&gt;(&amp;self, redness: &amp;R) where R: RedTrait { // Do something blue. } } The other approach would be requiring that a type implementing `RedTrait` be a sized type: trait RedTrait: Sized { fn do_red&lt;B&gt;(&amp;self, bluitude: &amp;B) where B: BlueTrait { bluitude.do_blue(self); } } trait BlueTrait { fn do_blue&lt;R&gt;(&amp;self, redness: &amp;R) where R: RedTrait { // Do something blue. } }
If the string is going to be written, `&amp;str` should be fine.
Thanks! You are expected to run the same program on multiple computers, which just causes the same closures to be produced in each of the processes. It's a restriction, for sure, but maybe a different way to think of it is that "serializing the closures" happens in rustc. 
That was actually a co-production between nasa42 and me, he did most of the work, and I thought up some nice titles. ;-)
&gt; I suppose I could create one large vec (or one large boxed array) and add an API for translating multidimensional access into linear access Exactly that. Either implement `Index&lt;(usize, usize)&gt;` or have some `get(a: usize, b: usize)` method. (A chained `Index&lt;usize&gt; -&gt; &amp;[T]` would work too.) You might be able to find an appropriate crate for this on [crates.io](http://crates.io).
From my experience with writing a parser for rust's syntax, it's not quite LR(1) (Handling `fn method(&amp;mut self)` requires looking two tokens ahead of the `&amp;` to distinguish it from `fn method(&amp;mut ref bind: ...`)
Also if you want your structure to be generic over the kind of storage you could have an implementation like this: pub struct NdArray&lt;N, Storage : Deref&lt;Target=[N]&gt; { data: Storage, strides: Vec&lt;usize&gt;, shape: Vec&lt;usize&gt;, } That's a pattern I've been using a lot in [my sparse matrix library](https://github.com/vbarrielle/sprs) and I find it to work pretty well. That way you can have lightweight views into your array while sharing most of the code with the vec based structure. With type level integers this pattern would be better as there could be a compile-time enforcement of matching shape and strides lengths.
Someone on the IRC channel proposed this to me, as an alternative to the unstable box syntax: let mut v: Vec&lt;bool&gt; = Vec::with_capacity(GRID_HEIGHT as usize * GRID_WIDTH as usize); for _ in 0..(GRID_HEIGHT as usize * GRID_WIDTH as usize) { v.push(false); } let v_slice = v.into_boxed_slice(); let boxed_array = unsafe { let v_raw : *const [bool] = ::std::mem::transmute(v_slice); let v_raw : *const [[bool; GRID_HEIGHT as usize]; GRID_WIDTH as usize] = v_raw as *const _; ::std::mem::transmute(v_raw) }; Basically, you allocate a vector of size x*y, then unsafely cast in into a pointer to a 2d array. Now you can use `array[x][y]` as usual.
I can relate a lot with this article. I get the exact same excitement from rust as I did when I started with Python. Rust has become my go-to language for hobby projects and scripts.
Great work! I have been meaning to write an abstraction layer over hyper for some time now but you beat me to it :). I love seeing these helper libraries pop up for rust. It makes it feel much more "high level" and makes prototyping much easier.
LLVM is currently unable to generate guaranteed constant time code, and that's probably the biggest issue for such things. ([rust-lang/rfcs#847](https://github.com/rust-lang/rfcs/issues/847)) If you are interested, there was an experimental [nadeko](https://github.com/klutzy/nadeko) plugin for producing constant-time code out of `asm!` though.
Of course, and I am intentionally not using it because I like to do things my way, and that would give `bitflags` extra downloads. EDIT: To further clarify, `bitflags` is a much more general crate, not particularly suited for FFI. My needs are extremely specific, and I can make a lot of assumptions that `bitflags` cannot. Therefore, by using my own macro special tailored to my situation I can reduce the verbosity of defining such enums, as well as having functionality identical to how they'd be used in C/C++. The downloads thing is a joke, although considering how often `winapi` is downloaded, avoiding yet another dependency does help prevent dependency tree clutter.
If a language has an LR(k) grammar (for any finite k) then it has an LR(1) grammar. This can be seen by the fact that any LR(k) grammar defines a deterministic language, and any deterministic context-free language can be described by an LR(1) (or LALR(1), or SLR(1), or even more restrictive) language. But it's also possible to derive an LR(1) grammar via fairly simple grammar transformations. However, the issue you mention is not a problem for a natural LR(1) grammar, at least if I understand your objection correctly. In the particular example you quote, you might naively start with a grammar somewhat like this: args -&gt; '(' args-list ')' args-list -&gt; ε args-list -&gt; args-list-nonempty args-list-nonempty -&gt; arg args-list-nonempty -&gt; arg ',' args-list-nonempty arg -&gt; pat ':' type arg -&gt; self-pat pat -&gt; pat-mut pat -&gt; pat-no-mut pat-mut -&gt; 'mut' ident pat-no-mut -&gt; ident pat-no-mut -&gt; 'ref' ident pat-no-mut -&gt; 'ref' 'mut' ident pat-no-mut -&gt; '&amp;' pat-no-mut pat-no-mut -&gt; '&amp;' 'mut' pat self-pat -&gt; 'self' self-pat -&gt; 'mut' 'self' self-pat -&gt; '&amp;' 'self' self-pat -&gt; '&amp;' 'mut' 'self' Note that I had to split `pat` into two nonterminals, one potentially beginning with `mut` and the other not, so that the grammar would not be ambiguous on the input `(&amp;mut a...`. This is grammar is a perfectly fine LR(1) grammar. It avoids any conflicts because in the input string `(&amp;mut` it only shifts tokens, and then the next token is either 'mut', 'self', or an identifier, which provides enough context to disambiguate before any reduction occurs. Of course, this grammar is *not* an LL(1) grammar, illustrating why LR grammars are often more natural than LL grammars. An LR parser can move through multiple parts of the grammar at once, and it only needs to disambiguate its actual position when a reduction may occur, whereas an LL parser's state is always associated with a single position in the grammar. This property, combined with more restrictions on the use of empty productions, characterizes the LL(1) grammars amongst the LR(1) grammars.
We even have more specific docs than that: http://doc.rust-lang.org/book/rust-inside-other-languages.html#python
AFAIK, Go is a bit hard to unify with python, because Go's GC wants to take care of all objects whereas python wants all objects RC'd. On the other hand, as /u/steveklabnik1 has already linked to, it's very easy to link Rust code to python code.
&gt; Along the same lines, how easy is it to integrate Rust and Python? It's fairly easy. If you're distributing a package, there can be some complexity. /u/SimonSapin has been working on this: https://www.reddit.com/r/rust/comments/3kvifv/whats_everyone_working_on_this_week_week_38_2015/cv10gok &gt; In the past I either use ctypes or more often just write a C program and execute it and read the output, but if Rust could take the place of C easily here I'd definitely consider putting some time into learning it. Yup! This is one of our goals, to be easily usable where C is. &gt; Would writing concurrent or parallel programs in Rust be difficult? The major difference between writing such things in Rust vs Go is: 1. Rust uses 1:1 threading by default. 2. Rust uses blocking IO in the standard library, but libraries like `mio` give you the option to do non-blocking as well. 3. Rust gives you significantly more guarantees about the correctness of your concurrent code than Go does. &gt; If I'm looking for something high performance to glue together with Python, would Rust be a better option than Go? Given that Rust has "no" runtime, and no GC, it should be a better option generally speaking.
After fighting with the compiler a lot I too fell in love with Rust for similar reasons. No more dealing with malloc and free, more expressive (compared to C), and overall fun to work with. Errors were easier to fix and the option and result types force you to deal with the possibility of a function to return None before you can do something with the type wrapped inside it. Error handling dare I say it, became fun.
/u/warricksothr maintains [unofficial rust binaries](https://github.com/warricksothr/RustBuild) targeted at ARM-based computers. They allow you to compile on the Raspberry Pi and avoid linking problems. I assume those builds would work with this library although I have not tried it out.
I totally agree. I would prefer another format like JSON over XML any day but so many legacy API's still use it. This has come at a perfect time as the project I am working on needs to handle XML data.
They could, but overall requiring a `Sized` bound for generics was found to be more common than not requiring it. This is because dynamically sized types can only be accessed indirectly, through a reference or pointer type. Any `generic_method&lt;T&gt;` would be unable to use T directly without first adding the `T: Sized` bound. Traits are different because each trait declaration also declares a trait object (which is a dynamically sized type) so having an implicit `Self : Sized` bound would make all trait objects unusable by default.
I expected to see this in the `fn work` section: https://www.reddit.com/r/rust/comments/3k5jit/maidsafe_bounty_program_is_really_taking_off_20/
I'm not sure I would recommend building on the Raspberry Pi. My simple library took ages to compile, when I was testing the ARMv6-armhf binaries on my Raspberry Pi B. (Raspberry Pi 2, would probably be okay though) With that said, you could use my compiled std libraries from the rustc binary packages to get the arm-unknown-linux-gnueabihf std library available for Cargo to cross compile. It doesn't take all the steps out of the process, but it does save you from having to cross compile a full rustc for just the std library. /u/japaric has a [great guide](https://github.com/japaric/ruststrap/blob/master/1-how-to-cross-compile.md) on crosscompiling using this method.
&gt; You basically have to write a C wrapper to whatever you want from the Obj-C/Java API, and then make Rust bindings to that C wrapper. Why such thing is not possible writing it directly with Rust?
Actually, talking to a haskeller into linear algebra, he made the argument that type level integers for matrix sizes don't make sense, because most data gets read from a file etc. I'm completely convinced. Instead, I think we should use smart index types where the type system helps us verify that we are using the right kind (without caring about the actual cardinalities of the ranges). In a sense this is safer; just because the cardinality is equal does not mean the index is of the right kinds. Sometimes, n_dimensions == n_samples, but the indices to them are still different things. The nice thing is we can do this right now!
&gt; &gt; The shortest path is not easily verified &gt; I think that's the problem. You still have to take every fork in the road to exhaustively ensure you find the best solution. No, you don't need to take every fork: you just need to take enough to know that the best path you've found is better than any you have not yet visited, the same as any other path-finding algorithm and the same as the one in the article. Of course, this isn't much different that what's specified in the article: * the "rules" and "constraints" in the article are simply codified ways of determining where the forks are and aren't, * "spans" tell us how much "distance" each "choice" costs us, * "Avoiding dead ends" is similar to (and possibly equivalent to) A* always expanding branches with the lowest *heuristic estimate* of its cost, not just "best cost so far", and * "pruning redundant branches" is equivalent to finding the shortest path to a non-goal point and then ignoring all other unvisited paths that go through that point. In this case, a "point" would be defined by where the last split is; any other way of splitting everything before it is simply a different path to the same point, but with a different cost, and does not need to be explored if we know we already have the "best" split up to that point. I think, in fact, the algorithm in the article could actually fairly well be recast as A*; I don't think it would be much different, as all the code relating to spans and rules and constraints remains, it would just be a more "formalized" way of doing it.
Regarding Python - and I say this coming from a C++ perspective: With all the ~ and @ clutter removed from 1.0-Rust the language would be even more visually pleasing if the logical **! &amp;&amp; ||** tokens could be replaced with **not**, **and**, **or**. Optionally, of course, so that C et al migrants are not alienated. And going further, since `for x in set ...` is already supported I hope `"something" not in set` can be translated into `!set.contains("something")` internally. These seem like the logical continuation of no longer requiring parenthesis after if/for, making return implicit etc.
I've done this, specifically to pass numpy arrays to rust. I use the ctypes interface to numpy, then interpret those from rust. I wish I'd been able to make bindgen work for this, but never managed to get it to run at all. Anyway, the manual version works fine. Also calling rust from R, which has annoyingly somewhat different requirements (cannot pass ints directly, just pointers to). Be warned, working on these interfaces (and passing the wrong number of arguments, for example) is the best way I've found to get rust code to segfault ;) Overall: not too hard.
I don't suppose you could link to where this takes place within the Go parser? I'm not sure I fully understand how this works.
While I agree it would be nicer, I would dislike having both options.
It's possible to build shared libraries as of [Go 1.5](https://golang.org/doc/go1.5#link). [This](https://blog.filippo.io/building-python-modules-with-go-1-5/) blog post details building Python modules in Go, and [gopy](https://github.com/go-python/gopy) "generates (and compiles) a CPython extension module from a go package" although it currently only supports Python 2.
Interesting. Thank you.
* C libs: So you either bind them and use them somewhat awkwardly, or take the time to wrap them with a nicer rust interface (if there is no such interface available yet). The latter may take some time, but lead to better code * 6 months is an ambitious target. Depending on what platforms you intend to run on, you may face networking issues (e.g. lack of mio Windows support as of yet). Good luck from this side... * When I want a debugger, I reach for RustDT, which has a fairly usable implementation. Granted, it's not VS, but Eclipse-based, but works for me. That said, I haven't debugged much in Rust yet; my code usually just runs once I get it to compile. Mind you, I don't work on games, just on a [lint collection](https://github.com/Manishearth/rust-clippy) and a few small libraries [here](https://github.com/llogiq/optional) and [there](https://github.com/polyfractal/Turbine). * Ok, so you'll have some threads for input and game state, one or more rendering threads, the works. No issue with moving to Rust from this side. All in all, it sounds like you'd follow a risky path with Rust. That said, the potential benefits are not to be dismissed either. My verdict: Not madness, just calculated risk taking.
Using the VS debugger is coming. Microsoft recently open sourced some stuff that makes it finally possible to hook in.
Because they're the other new kids on the block and are often compared to Rust. The point of the comparison was to say that I liked how Rust opened the door to system programming in a safe manner, something that GCed languages don't offer. Would the comparison yield different results with Haskell/OCaml/F# instead?
This is really neat. Frank McSherry's dataflow work is some of the coolest stuff happening in Rust right now. Can't wait for the next one!
I'm curious how the memory management works. Looking at the package source didn't really help. What if you have a Go object that references a Python object that references a Go object?
Nomicon claims that &gt; Transmuting between non-repr(C) types is UB Is this statement correct? It's missing from `transmute` docs. And if it's that simple should there be a lint for this?
It appears that the honor of crate #3,000 goes to the [volume](https://crates.io/crates/volume) crate, courtesy of /u/mitchmindtree. :)
&gt; I don't think Go and Nim are particularly well suited to system programming Yes, that is precisely my point. I ask myself "why am I enthusiast about Rust and not Go/Nim? Because I don't think Go and Nim are particularly well suited to system programming".
Sure. We're not disagreeing, I was just mildly surprised you didn't use languages more similar to Rust as a comparison.
I suppose in case where you have a large array and you need to access every element in a given distance from a coordinate. The reason I even know about this stuff is I searched for an efficient way to simulate many actors on a grid, where the actors make decisions based on their surroundings. Think Dwarf Fortress. I have no idea what is the threshold where this becomes efficient. I suppose the best way is not to divide your grid all the way to individual elements, but rather into small chunks fitting into L1 cache, which are grouped in bigger chunks fitting into L2 cache.
There may be people (students perhaps?) Interested. There's also a servo position open still I think.
I'm still kinda disappointed that we don't support patterns in parameters for trait methods :(
Knowing it just works is so gratifying.
Not sure I understand your proposal. The way I understand /u/veedrac's post and Luthaf's code, Index&lt;usize&gt; is defined to specify the slowest varying remaining free index. So in a contiguous column matrix, mat[2] gives a view of a particular col (hence, still contiguous) and then mat[2][1] gives an element, and changing the latter index fastest is cache friendly, and mat[2] can be hoisted out of the loop. I like this a lot. This seems to be incompatible with the way I understand your proposed convention, but can you give more detail?
The article was posted some time ago in r/programming: https://www.reddit.com/r/programming/comments/3ieijy/building_python_modules_with_go_15/ The short of it appears to be: the GCs can work alongside each other, but they should not share data (ie, data should be marshaled at interface boundaries).
This reminds me of efficient matrix multiplication algorithms, which pick block sizes that fit into the L1 and L2 caches, and copies the matrix into those blocks, ordering the multiplication to make the most efficient use of the blocks. I wonder if a matrix multiply algorithm with an ordering of space filling curves would have those nice caching propertices without needing this explicit blocking.
&gt; I wonder if a matrix multiply algorithm with an ordering of space filling curves would have those nice caching propertices without needing this explicit blocking. The thing is, space filling curves and blocking is conceptually the same thing. Z-curve basically divides your matrix into 2x2 chunks, which build larger 4x4 chunks, which build larger 8x8 chunks etc. But you don't really need so many levels of block hierarchy for cache locality, if you only have 2-3 levels of cache.
Added to the calendar. Have fun!
What are your interests and background? If you're into graphics and gamedev, Piston and its surrounding ecosystem (https://github.com/PistonDevelopers) seem like a fertile place for contributions.
Forgot to mention interests. Mainly I have developed backend applications and libraries. I don't have any experience with graphics or gamedev. And also no cryptography.
An OpenGL wrapper, because there's not enough of those, and because I ca...well, because I want to know *if* I can.
https://www.youtube.com/watch?v=3CwJ0MH-4MA
By backend do you mean web development? If so, then any of the following could use contributions: https://github.com/carllerche/mio (asynchronous IO) https://github.com/carllerche/eventual (futures) https://github.com/hyperium/hyper (http) https://github.com/iron/iron (web framework) 
Yeah `ref mut v` makes sense, it's how you pattern match to get an `&amp;mut v`, but I have no idea what the additional `&amp;mut` could be here. It might make sense if it were outside and you had something like: match x { &amp;mut Some(ref mut v) =&gt; *v = 42, &amp;mut None, } because the `x` you got was a `&amp;mut Option`, but even then not for Option as `.as_mut` would be simpler and clearer: match x.as_mut() { Some(v) =&gt; *v = 42, None, }
Not only web. Actually mostly not web. More like different APIs. Actually this is my previous place of work where I used Rust: http://nptv.com I have contributed a little to mio and iron. But right now and I don't have actual experience to make a valuable contributions. But I guess I need to look into their issues and maybe find something that I can fix myself. Thank you.
And most of those are by /u/retep998 ;)
If we go down the `ref mut v` way, then we need to write : Some(ref mut v) =&gt; **v = 42, (note the double dereferencing) In a sense, the additional `&amp;mut` allows us to remove one level of dereferencing.
Unless I overlooked something `&amp;mut ref mut v` is nonesense. `&amp;mut` is part of type destructuring, so you get the inner value of the reference. Then `ref mut` is applied that says, take the value not directly but as a reference. It does not make sense in this case but a similar pattern is helpful for more complex types. `&amp;mut (ref mut a, ref mut b)` destructures a reference of a tuple into references of the individual elements.
It's also not just a grammar problem. The equivalent problem is C++ requires that semantic analysis happen at the same time as parsing in order to resolve the ambiguity. 
Er… no? Not unless you're using `ref mut` to match against an `Option&lt;&amp;mut T&gt;` (and so take a mutable reference to a mutable reference which is not very useful).
My response to [last week's parser combinator post](http://m4rw3r.github.io/parser-combinator-experiments-part-3/)... got myself nerd sniped!
This project is looking for contributors https://github.com/pistondevelopers/redox.
You pose a good question! The answer is yes -- it's possible with Rust. My answer should have instead been: You have to write a Rust wrapper to the Java Virtual Machine API, then write a Rust wrapper to whatever you want from the Android Java API. It's still not very simple or easy, and you'll end up working a lot with Java and not Rust in general :(
I can relate. I found my self lately using `and`, `or`, and `not` way more often than `&amp;&amp;`, `||`, and `!` in C++. It is more typing, but to me it reads better, which matters more.
Hi, and nice post! I tried to eliminate branches in the library, but wasn't too careful with the bench-code itself. Good to see that there is always room to improve! Btw, did you try using a `match` statement and see how that compares? According to [this reddit-comment on my blog post](https://www.reddit.com/r/rust/comments/3k0d0d/parser_combinator_experiments_part_3_performance/cuu3lc5) it optimizes well. I tried it and it seems to be a slight improvement over the branch-heavy version. Also, you can get some nice ASM from the rust playground too: [match-expression](http://is.gd/5cPkh3) You add #![no_main], #[no_mangle] and pub extern, then select Release and press ASM.
There is at least rustbox, but I think there might be other
It _is_ pretty much just a slice, but because of the padding, there's uninitialized memory in the middle, so it is unsafe to export the slice. You can easily access the elements by index, but it's a bit slow because you'd have to do some arbitrary offset each call. Additionally, that is *really* un-Rusty. Iterators provide a safe, fast, and convenient interface.
What is an example of code that shouldn't panic in the middle? The only problem would be `Sync` structs, and those (should) get poisoned by panicking threads.
Relatedly, this is why I advise people not to overfocus on bounds checks. They're virtually always predicted correctly in correct programs, so their overhead is usually extremely low.
There's more information in the comment threads from when it was originally posted: https://www.reddit.com/r/programming/comments/3ieijy/building_python_modules_with_go_15/ https://www.reddit.com/r/golang/comments/3ieiiu/building_python_modules_in_go_thanks_to_15/
&gt;Rust has a very specific focus on ensuring your concurrent code is safe without data races That's a great selling point alone. I know rust can't solve all design issues like deadlocks, no programming language can, but I do like how rust keeps you from shooting your own foot in many ways regardless.
That makes a lot of sense, thanks. It sounds like Rust will give you a lot more control over how exactly you want your code to execute in parallel, and that's one reason I'd want to resort to C in the first place. I think it boils down to for me that Rust could be a great replacement for C, and Go just wasn't designed for that. I'll give Rust another shot. Everyone has been very helpful. Thanks!
I just used rustbox to make this: https://github.com/cgag/hostblock Code might be terrible since it's the first bit of rust I've written but it might be useful.
You're welcome! If you need any help, don't hesitate to ask.
Yup, this just seems to be a bit over-complicated. An issue would be great, /u/swatteau , as I'm about to be on planes for a day, and I don't want this to get lost in the shuffle.
I'm not good at html, css, js but I hope I can help with server-side code. Thank you.
I think in this case you probably *want* the branch in there. They're very likely to be predictable (numbers go one way, alphas go the other way) so being able to skip half of the instructions for free in e.g. 99% of the cases is good stuff. Also, you'd *really* want the bit field to be stored in register outside the main parser loop, but I'm not sure that's something you can hint the compiler to do easily. 
Honestly this was way more true in the past than it is now. Cache sizes is one of those "diminishing returns" things. They keep bumping up the sizes, but the resulting wins are smaller (mainly because many cache misses are extremely non-local and won't be touched again for a long time... so you have tons of "mandatory" misses no matter how big your cache is). All that is to say that if you can get a *guaranteed* win by storing a few hundred bytes (or even a few thousand) in the cache, it's very often going to serve you better than those bytes would be able to help you reduce cache misses *by chance* elsewhere. Now, if only we could get a way to "reserve" cache space to keep it around for next time. Who's going to miss 128 bytes of L1? Just leave it alone CPU, I know I'll need it later!
Perhaps it makes more sense to say `Rc` is to `&amp;` as `Box` is to `&amp;mut`.
I see. Depending on your padding pattern, this might be representable with stride information. eg if every odd element is uninitialized and the storage is row major, this can be represented by a row stride of 2.
There is interesting optimization work in my [twig-rs](https://github.com/Nercury/twig-rs) library. Basically, I wrote the lexer by directly translating the code from PHP (mostly to cover all invariants). However, it is horribly inefficient for various reasons, but the tests pass. I was planning to do the optimization later and write a blog post about it, but anyone can grab this work if they wish. Draft blog post [here](https://github.com/Nercury/Nercury.github.io/blob/master/_drafts/twig.markdown).
I just opened a [new issue](https://github.com/rust-lang/rust/issues/28431) for that.
What I meant to say is that you either write `Some(ref mut v) =&gt; **v = 42` or `Some(&amp;mut ref mut v) =&gt; *v = 42` and, rather conter-intuitively, the language allows you (for some obscure reason) to remove one star in the notation.
Yes: https://www.reddit.com/r/rust/comments/3l2a2p/open_source_project_to_work_on/cv390l0
The problem is that I don't have much time right now for my own project. That's why I am seeking some project with well defined scope of work. Alternative option is great actually. Thanks, I will monitor that thread from time to time.
&gt; What I meant to say is that you either write And as I said that's if you're using `ref mut` to match something which is already an `&amp;mut T`, in which case the `ref mut` isn't necessary to start with, you can just match against the item directly.
Because superoptimisers are very expensive, we're [literally talking order of magnitude increase over normal compilation times](https://github.com/go-llvm/llgo/pull/185#issuecomment-62162453), and souper's probably a bit too large and young to add to the standard llvm toolset (if that's even a goal of its creators) Souper's from the regehr lab and he's posted a few times about it: * http://blog.regehr.org/archives/1109 * http://blog.regehr.org/archives/1146 * http://blog.regehr.org/archives/1192 * http://blog.regehr.org/archives/1252
I have to admit, when I wrote the `is_token` code with all the branches, I did not look that far :D I just profiled the iterator based version and saw that the code spend its time iterating in `is_token`, and choose a version that was easier on the CPU while still being readable.
Do you have any task that can be done without any knowledge of GTK? :)