On this note, I would recommend introducing a modest benchmark suite in order to track the effects of any changes made for the sake of optimization over time.
Maven is *not* declarative: You have to write slews of XML, to add a plugin, just to remind the build tool that the project needs to be able to compile Java code.
Could you explain why it is using a cow for the string? 
A bunch of people asked what I meant when I said that the ABI of a type affects how it's passed by-value, so I wrote this to try to make it clear. Hopefully I didn't get the final examples totally wrong!
This seems like a possibly useful tool. I get that the irreverent tone of the library's current documentation derives from its *Rick and Morty* namesake. Fun tone is perfectly okay. However, the negative wording will probably prevent at least some people from giving the tool a shot. The air of arrogance is just too similar to real negative stereotypes about Rust's community that folks here are trying to counteract. Thus, both thoughtful users of the old tools and fans of Rust's open, noncombative atmosphere could be turned off. I say this because I **want** more Rust-based tooling to succeed, and want to reduce preventable sources of failure.
This is fixed now. Thanks!
This blog post does a great job of explaining that https://chrismorgan.info/blog/rust-fizzbuzz.html#main
&gt; I can't use include_bytes! because the file system is too complex. Do you mean you want to include all the files in a directory recursively? There are at least 4 crates that do this, the last time I checked. The one I ended up using (for embedding the yew wasm frontend files into my standalone rust exe) is `rust-embed`. It preserves the file paths so it can be used as a drop-in replacement for file reading (e.g. use it with actix-web to serve the embedded files). But if you plan to embed a huge amount of data this way, it may not be the best idea to install it with cargo because of user expectations that the installed executables are small tools. 
That looks like a fantastic resource, and I didn't know about it. Thank you!
From the SIMD article &gt; In particular, creating a value of a particular SIMD implementation is an unsafe operation, as it depends on runtime detection of SIMD capability. Can this fail or something? Like, what's the unsafety?
Yes, and that's fine because the tool is targetting Rust programmers.
Yep, someone contributed [benchmarks](https://github.com/dguo/strsim-rs/blob/master/benches/benches.rs) recently.
May I suggest a lower hanging fruit along those lines? We have two crates that allow embedding a web browser view for a GUI, the `web-view` crate uses webkit on mac and Linux, and IE11's engine on windows. Unfortunately IE11 doesn't support wasm, so it can't be used for wasm frontends but there is the `tether` crate which usrs Edge's engine which supports wasm. But it only works when Edge is installed (e.g. I'm running windows 8.1 and don't have Edge installed). Maybe it would be useful to unify both crates into one, so that a wasm frontend could be run in Edge when that's installed and when Edge is not installed, it will fall back to IE11 and run the frontend compiled to asm.js (either translated from wasm (I forgot which recently announced tool does this)) or from Rust. Then we could use Rust to write the embedded GUI, too.. 
The files themselves are pretty small, it's just that they are a lot of template text for which the FS placement is important. I did not know about rust-embed! So that means I may have to change my FS calls, but it might not be too hard (walkdir might create issues however, but I guess it may be okay). Thank you!
Do you mean just returning early once the distance hits a maximum?
Very cool! I definitely have uses for this. 
Hi, I don't want to make this feel like a pile-on, so I don't want to comment on the tone of the README (all has been said). My biggest problem is that it spends a lot of time about that other tools are bad, but not quite about what tinyrick does and what it does well. It feels like you got a lot of frustration out of the other tools and that had to go somewhere. That isn't quite as interesting for people reading the README as figuring out why you should use _this_ **amazing** _tool_! If I were you, I would delete it and write anew and try not to mention any other tool by name :).
Thanks! Yeah, someone else suggested and contributed the normalized versions, and I didn't consider that "ratio" could work as well.
Actually it is declarative: nowhere in your `pom.xml` do you need to specify what order to build things in, how to build things, etc. You just say that this is a Java project. Maven is also incredibly verbose, painful to use, badly factored, and slow, but none of those make it any less declarative.
That's interesting. Do you have any details on the improvement? 
Thanks for the suggestion!
I'm a German speaker and I don't think I would have understood what ratio means in this context. Normalized is the way to go, imho.
I'm not sure the language you come from is what really matters but how quickly you grasp lifetimes and are able to connect it to the syntax. Like the stuff I've done that doesn't involve lifetimes is super satisfying but as soon as they get involved and cut through too many layers, I start to struggle super hard.
I believe these two parts of the System V x64 ABI cover what you're interested in: \&gt; \*\*Passing of Values:\*\* If a C++ object has either a non-trivial copy constructor or a non-trivial destructor, it is passed by invisible reference (the object is replaced in the parameter list by a pointer that has class POINTER) \&gt; \*\*Returning of Values:\*\* If the type has class MEMORY, then the caller provides space for the return value and passes the address of this storage in %rdi as if it were the first argument to the function. In effect, this address becomes a “hidden” first argument. This storage must not overlap any data visible to the callee through other names than this argument. On return %rax will contain the address that has been passed in by the caller in %rdi.
Interesting, I was under the impression that C++ permitted RVO but did not guarantee it, but this seems to be well-specified. Maybe it's just that Rust implementations are obligated to mark all return types as MEMORY class, and C++ implementations aren't (or maybe sometimes can't)?
SysV x64 is But One ABI Also normal rust fns are not obligated to follow any particular ABI
Sure, I'm just curious about what Rust fns do currently do in practice. :) I don't know if our RVO semantics are documented anywhere. It used to be a major selling point of ancient Rust, but it seems to be relatively forgotten these days.
Maven certainly is declarative, as opposed to _imperative_. A Maven POM is not a script of sequential steps to take that can easily scope out to perform unrelated tasks. You need to go out of your way to make Maven do stuff outside of the realm of building software. It's a fairly constraining framework which is why some people dislike it, but the flip side is that all projects look the same which makes it much easier to understand and manage, and less likely to deviate from the original intent in the long term. Also, Maven is actually hardwired to compile Java. A six-line file giving the project a group, name and version should be enough to compile a simple project with no dependencies. The latest version (3.5.4) does requires extra lines to bump the compiler version for it to work on the newest JDK (9+), which I agree is definitely retarded, but it is not inherent to Maven itself - I'm looking for a bug report on this and if there is none I'll file one. And while I personally don't mind XML's verbosity, it's usage is no longer mandatory with the polyglot extension.
I agree with the author that Haskell syntax is the cleanest and simplest, followed by Rust. That said, because in Haskell data constructors may share their names with type constructors, expect to get confused reading someone else's code at one point or the other. 
This is really cool. Thanks! =)
I've been waiting years for a 4.0 version to come out that would include Takari Smart Builder and Polyglot extensions. But it looks like the Apache maintainers are comfortably sitting on their collective behinds, keeping it hard maintenance mode. Sigh.
Oh hai. Yes. I am very much aware that there is a very popular MUD with the same name. However, that is the -only- other product I could find with the name, compared to the loads of other choices we came up with. Soo... yeah :D
You have a bunch of macros called `shell*!`, with a warning that you shouldn't use the shell. But they don't actually invoke a shell. They just run a command directly with `std::process::Command`, which is a much more reasonable thing to do than shelling out.
To put it simply: - I cannot return a `&amp;str` because the result of `format!` is a `String`; - I do not want to return a `String` because I'll need to allocate some memory unnecessarily for the literal strings; So I return a copy-on-write type. It behaves like a `str`, but internally it is either owned or borrowed. This is a micro-optimisation that don't worth it most of the time. In my personal projects, I return a `String`, and that's all. 
tbh I don't really know or care about (N)RVO in Rust because the only semantic impact it can have for us is whether a huge value can blow the stack, and that's what box/in/&lt;- is for. (N)RVO is much more important in C++ because non-trivial types are assumed to have significant addresses (a notion Rust has so far rejected), requiring the copy-ctor and destructor to be run over and over in a return chain. the places where i've run into performance issues with return values i just [rewrote the code to use explicit out-pointers](https://github.com/serde-rs/serde/blob/1b45e5766a30db85010112ea6d2d2638eddd9b12/serde/src/de/mod.rs#L534-L562)
Have you checked the rustc flags -Z flags? 
&gt; we won’t go into details here, but trust me that without the Box this code would not compile, with a compiler complaining about possible memory leaks. If you remove the box, the compiler complains about the type being infinite, I don't think it has anything to do with memory leaks.
Calling architecture-specific intrinsics in hosts that do not support them is undefined behavior. Some projects encapsulate the unsafety behind types that can only be created if the host supports the features at run-time. 
Long term we would like to add PixelFed ([https://pixelfed.social/](https://pixelfed.social/)), and PeerTube ([https://joinpeertube.org/en/](https://joinpeertube.org/en/)) for photo/video sharing. They all use the same ActivityStreams/ActivityPub-like specifications so we should be able to connect across platforms with API's. But again... that is long-term roadmap.
Something like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=f436ce7cf7fec6035d47045307109b34). I'll try to write some benchmarks.
C++ guarantees RVO in some circumstances: https://en.cppreference.com/w/cpp/language/copy_elision But I am not sure how that relates to FFI.
You could have done typescripts definition structurally: type Tree&lt;T&gt; = { left: Tree&lt;T&gt;, val: T, right: Tree&lt;T&gt; } | null; It's pretty concise
What edition are you on?
Well, that's rather complicated. Maybe you have some more ideas if I explain the problem I am applying this to: I want to write a plugable TUI. That is, a core component which is started, searches automatically for "modules" and loads them. Each module is a library, of course. All this is written using the (btw really awesome) `Cursive` crate. The libraries would provide not only `View`s but also would be able to add menu entries, register handlers for actions and so on and so forth. I have not yet started this project, as it is only one component of a larger application ([imag](https://imag-pim.org)) - a TUI frontend for it. Of course there are a lot of details to figure out before I can write this, also the base functionality for all the modules has to be implemented first. But I'm always thinking about how to build such a "pluggable TUI" for imag. Because of the infrastructure being basically a `Cursive`-App, I would expose a lot of interfaces from Cursive itself - libraries must implement the `View` trait from cursive for their stuff, must use the Cursive interfaces for menu entry creation, etc etc etc. That's why I cannot simply expose a C interface for this. Maybe you have some ideas on this. If not, sorry for wasting your time. :-) And thanks for that detailed answer, btw!
It's nice to see a number of small improvements to rustdoc!
I had similar situations and ended up writing custom macros to generate all my ORM structs for diesel and all the Json API view structs and the CRUD rocket handlers.. 
I prefer to group the struct definitions together at the top of the file, since it gives a nice overview of what's in the file. It also protects you from not noticing a little struct nestled between long impls somewhere in the middle of the file.
Sorry, I'm on 1.29.2 stable.
I think you are mistaking RVO and calling convention here. Whether a C++ function receives a pointer to storage or returns its result via registers is orthogonal to whether it uses RVO or not. RVO is a semantic difference: whether a copy (or move) constructor is called.
That example was very helpfull, I somewhat understand now what you mean. I'll try to set some time aside for thinking about the application to my situation, thanks :) &gt; your task involves reducing the complexity of accessing the data in the Rust programming language Right now, accessing is very easy, I was just afraid I'd been overlooking something :) Thanks again for your ideas!
Hmm... I wonder if the model with ID case could be solved with a type like: struct Record&lt;Id: SqlType, T: Insertable + Queryable&gt; { pub id: Id, pub content: T, } I guess that might not be that convenient to use though. Perhaps it would be possible to allow the never type for struct fields? Then use a MyType&lt;u64&gt; for structs where the id is known and MyType&lt;!&gt; for cases where it's not known. I suppose MyType&lt;()&gt; could also work...
The keyword is going to be reserved, so it will still be in Rust 2018, just not in rust 1.31.
Nice write-up. You might want to consider renaming "type-kind" to something else, as the "kind of a type" has a defined meaning in type theory, so a more unambiguous term would perhaps be better.
Then you still need to use extern crate and macro use at the top of your tests. What you're doing will work in the 2018 edition which is currently on nightly.
I am doing that. #[macro_use] extern crate serde_derive; extern crate serde; #[macro_use] extern crate serde_json; Is at the top of my test file. And if I keep all of my code in that test file, everything works. It is when I move structs that derive Serialize and Deserialize to a submodule under tests that everything breaks. If I put those extern crate lines in my mod.rs as well then I get this error: &gt;an `extern crate` loading macros must be at the crate root
There is also the `amber` tool, installable via cargo. 
This is one place where Idris improved upon Haskell by sheer necessity of merging the data constructor and type namespaces since that is needed with a full spectrum dependently typed language. The syntax is the same tho, this is valid Idris code: ``` data Maybe a = Nothing | Just a ```
I wanted to ask for an easy code review (&lt;100 lines) for tiny tool I made for myself 
One solution is to compile your code with [non-lexical lifetimes](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/) enabled. This makes the compiler smart enough to compile your preferred code. This feature should become stable in early December when Rust 1.31 is released. For now, you can try it in the beta channel with the [2018 Edition preview](https://rust-lang-nursery.github.io/edition-guide/) enabled: https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018&amp;gist=4ccb6c0cbb6be6d46f8579f8d2c2a3a9 Another solution is to structure the code so the return happens after you break out of the loop so the iterator is no longer in scope. This may be easiest if you replace the loop with an `Iterator::find` call: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=d1763f3fefffc59dd4d486d97b2e90c7
Do you have a second file in your tests folder that doesn't extern crate serde, but does have `mod common`? Or for that matter do you have `mod common` in ANY file that doesn't import serde? `tests/common/mod.rs` should not be compiled by itself, only when `test/x.rs` and `test/y.rs` use `mod common` to include it, making x and y the crate root which imports serde.
The better example of that is: https://github.com/serde-rs/json/blob/master/src/value/mod.rs 
We are planning to build out very granular privacy settings (snippet below). It would be to the point where you could have an 100% private "journal-style" account where no one could find you, search or read your posts. The default settings will be "reasonably private" in the sense that the user must approve followers. [https://github.com/Aardwolf-Social/aardwolf/blob/master/doc/development/notes-feature\_set.md](https://github.com/Aardwolf-Social/aardwolf/blob/master/doc/development/notes-feature_set.md) I would be very open to adding Aardwolf-Social to the Wikipedia page, although we are kind of in a pre-alpha stage, so I am not sure if it would be very fair. &amp;#x200B;
Well son of a gun. That fixed it. I didn't even think of that as I'm porting over from one test file to another. Thank you for your help!
A lot of people are complaining about the theme and the tone, but don't get discouraged. [To Be Fair, You Have To Have a Very High IQ to Understand This Tool And Its Documentation](https://knowyourmeme.com/memes/to-be-fair-you-have-to-have-a-very-high-iq-to-understand-rick-and-morty)! Jokes aside, you totally missed the chance to name it Pickle(Rick)! Actually jokes aside, this is actually a great idea and could become really popular `make` replacement. The library could contain a lot of utility functions that would make common make-like functionality easy and compile-time checked, with a possibility of using any Rust-library out there. I am definitely considering using it. I think a shorter, and less thematic name might be better (more handy): Can I suggest: `trick` or just `rick`? I agree with /u/radix that `shell!` should probably be named `exec!` or something. 
Nice quote of the week :) My respect for panics have grown significantly recently while trying to implement a somewhat unusually complex data structure, compared to what I'm used to at least. There are so many situations where early return or rollback would be impossible or extremely impractical without leaving behind a corrupted state.
There is also https://github.com/casey/just More like make in it syntax but task oriented unlike make...
Hmm, that makes the problem a lot harder. This is one area where Rust compiling to native code is not a benefit. Here are the only (safe) solutions I can see: - Use something like the approach I describe above, so that you can pass Rust types back and forth between main and plugins. Pros: easy to use. Cons: plugins must be compiled with the same versions of everything, and with the same version of rustc. Any time something changes, everything needs to be recompiled. - Design a C shim API around Cursive and anything else plugins need to interface with. Pros: will work forever, plugins don't have to be written in Rust. Cons: a large amount of effort and very imag-specific. - Require plugins to be implemented in a scripting language, which can be executed by the main app. Good languages for this might include Lua, Wren, Gluon, or Dyon. Pros: will work forever, no compilation needed to add/remove plugins. No risk of ABI/API unsafety. Cons: Like the above, a custom shim API must be made (though much easier than doing it in C). Plugins can't be written in Rust. All of these solutions make traedoffs unfortunately. :(
Thank you for taking the time to solve my problem and writing this explanation! Impressive how much smarter Rust is with that feature enabled.
`add_entry` should probably be just method on `Stats`, and you could `impl Default for Stats` as a constructor. Actually you could move most of the code to be `Stats` methods, IMO, and leave just to reading from a file as outter-code that calls. `stats.process_line(&amp;line)`. Add couple of simple tests then. Other than this couple of suggestions for better structure, it looks very reasonable to me.
When majority do stupid thing - it doesn't make it right. We have to be very careful what we adopt as a common practice. Whistleblower in this case is right. He's trying to educate you.
So what's the deal with futures? Which version should I use? Is there a table for the differences between the different version? Are there beginners tutorial?
Next time you can use \`cargo doc --open\` to see the docs offline.
A whistleblower would tell me a secret. Programs are downloaded and executed with user permissions every second, this is not different.
Related: [not-yet-awesome-rust](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust)
Yep. And I was looking for a reason to use all of the Esperanto letters with diacritic marks :-)
thanks for your input!
Jenkins on a home server. I'm in a process of building jail and zfs library for freebsd, so I have no other choice.
Good to know!
Good to know!
Good to know!
I am working on a pair of crates for parsing JS into an AST \- \[Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS)) (RESS) \- \[Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) (RESSA) &amp;#x200B; My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
I am working on a pair of crates for parsing JS into an AST - [Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS)) (RESS) - [Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) (RESSA) My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
I am working on a pair of crates for parsing JS into an AST - [Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS)) (RESS) - [Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) (RESSA) My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
I am working on a pair of crates for parsing JS into an AST - [Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS)) (RESS) - [Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) (RESSA) My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
I am working on a pair of crates for parsing JS into an AST - [Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS) (RESS) - [Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) (RESSA) My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
I am working on a pair of crates for parsing JS into an AST - [Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS) (RESS) - [Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) (RESSA) My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
The link is returning a 404 :(
I am working on a pair of crates for parsing JS into an AST - [Rusty ECMAScript Scanner\]([https://github.com/FreeMasen/RESS](https://github.com/FreeMasen/RESS) - [Rusty ECMAScript Syntax Analyzer\](r/https://github.com/FreeMasen/RESSA) My primary focuses are going to be to try and squeeze some more performance out of RESS and increase the overall documentation.
Closest I could find is https://github.com/rust-lang/rust/issues/44732 and https://github.com/rust-lang/rfcs/pull/2320 But if the string is public, I _think_ it shows up in the doc? (I'd check but the examples I can think of are all private.)
In fact, the Rust compiler doesn't complain at all about memory leaks. `Box&lt;T&gt;` [literally has a `leak()` method](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) and it's perfectly safe
In fact, the Rust compiler doesn't complain at all about memory leaks. `Box&lt;T&gt;` [literally has a `leak()` method](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) and it's perfectly safe
In fact, the Rust compiler doesn't complain at all about memory leaks. `Box&lt;T&gt;` [literally has a `leak()` method](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) and it's perfectly safe
In fact, the Rust compiler doesn't complain at all about memory leaks. `Box&lt;T&gt;` [literally has a `leak()` method](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) and it's perfectly safe
In fact, the Rust compiler doesn't complain at all about memory leaks. `Box&lt;T&gt;` [literally has a `leak()` method](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) and it's perfectly safe
In fact, the Rust compiler doesn't complain at all about memory leaks. `Box&lt;T&gt;` [literally has a `leak()` method](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.leak) and it's perfectly safe
That's neat; I did not know that. If I am not wrong it also does not have the "types should begin with a capital letter" restriction.
How I would have done this: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=d5230728c5b0a48696243751116091a6
Yes they are! However, the examples repo shouldn't use the "gtk2 style" as far as I'm aware.
Yeah, it has the same issues with size, just meant to point to it as a library in the same space, sorry!
I agree with most others, generally struct + impl together. Don't take it as dogma, but a (strong) general rule in software is to group related things as close together as possible. However, if the structs are more closely related than their impls, or their impls are more related than the data itself, that might be a reason to group them the other way. Variables should be introduced in the narrowest scope that they can be, and as close to their use as possible. Dependency graphs should be clustered as tightly as possible. Related data and functionality should be as near to each other as possible. All of this has the effect of reducing API surface area and compressing context.
Yes, but is this "some" enhancement tiny in real programs? Or big enough a win to bother?
I am working on a pair of crates for parsing JS into an AST. - `RESS` - [scanner](https://github.com/FreeMasen/RESS) - `RESSA` - [parser](https://github.com/FreeMasen/RESSA) Primarily working on performance improvements and documentation
That's also what I concluded so far. Point 2 or 3 are the ones which are mostly what I will do, if I come to the point where a TUI would make sense. I guess 2 is the best way, as plugins can be written in any language. Thanks for providing your brain power! :-)
I really did like what you did, the functions are separate, and you implemented on the objects the methods to "do" the functions. And as far as the &lt;- Make sure you really need this line. I'm pretty sure I do. I want to make a database, and I am not worried about system level metadata, I just want to flush and read data as fast as possible.
This is, really, my first world problem in Rust. I never know. Especially, I never know whether I should put the `impl Type {` first or `impl Trait for Type {`. Then I realize that kind of decision is really irrelevant and I just move on. :D
There are a lot of things on crates.io that would be very useful except they're either Linux-only or require external dependencies. The Linux-only stuff is mostly Linux-only for "good" reasons, but it's a headache. The entire mini-ecosystem built around fuzzing Rust crates is completely Linux-specific. Any work to improve this would be very helpful. As for external dependencies... I'm of the opinion that if you can build a new project correctly, you should already have the maximum amount of external dependencies required to use every crate. The ecosystem is, however, nowhere close to this. Again, this is for "good" reasons... mostly the infrastructure doesn't exist to say... build a C or C++ library that depends on cmake in a pure-Rust way. We have the gcc crate which can be (and often is) used for smaller libraries, but nothing approaching cmake. As a result, an external cmake install is a "soft" dependency for using Rust, and this is an area where there is a lot of room for improvement.
Haven't finished yet, but seeing that platforms must have 8 bit bytes hurts the possibility of writing a DCPU-16 backend.
I'd recommend just looking through the [game overview](https://halite.io/learn-programming-challenge/game-overview), [Rust starter kit](https://github.com/HaliteChallenge/Halite-III/tree/master/starter_kits/Rust), and possibly the [tutorials](https://halite.io/learn-programming-challenge/tutorials), although it seems like they're only supporting Python 3 for those currently. There's also a very active [Discord channel](https://discord.gg/tm2kwue) with many top players and Halite staff if you have questions! 
[Here you go. :)](https://gist.github.com/phaazon/b01f4c0e0a324dd7f05eb44aeccd7d50)
Just describe what you want to do and people will try to help you. :)
Let me have a look! :)
--nocapture disappeared from my tests. Any way to turn that back on?
I’m answering directly on the gist. :)
This pattern here (`pub Trait` in `priv module`) is informally called the private-in-public hack. What you've effectively done is create a public trait that is unnamable by the outside world. You are required to avoid using private types in a public interface because the consumer of that public API has no information about that trait with which to use your API. Unnamable traits are sometimes used for "sealed" traits, where the user cannot implement the trait without permission, but in this case the trait referred to in your API should still be viewable from the outside world. If you want to formalize the use of the pattern, the typical formulation is something like: pub(crate) use self::priv_in_pub::Sealed; mod priv_in_pub { pub trait Sealed {} } [playground example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=60e64f43293f1b047bfe58317c2c849a) pub mod other_crate { pub mod sub_module { pub(in ::other_crate) use self::priv_in_pub::Sealed; mod priv_in_pub { pub trait Sealed {} } } mod other_module { impl ::other_crate::sub_module::Sealed for u16 {} } } impl other_crate::sub_module::Sealed for u8 {} 
Please submit a PR renaming all the shell macros and examples to exec!
Are you looking for r/playrust?
I tend to use a file per type, so I put that types impls in that file. I've definitely developed this habit because I use vim-fzf, which makes it super easy to quickly switch between files. Before I got more fluent with it, I tended to have files with tons of types.
I have a feeling my answer isn't going to be very satisfying. My entire schema/model is in the db crate. I kept that model separate from the rest API contracts. I think this is a good idea because often your API will receive or return objects that aren't exactly structured in the way your database is. A good example is if you have two tables: products &amp; receipts, you'll have a third linking table between them because it's a many to many. But when doing a GET on /receipts/1234, you may want a receipt object with just a list of products on it without the linking table as a struct. Another nice thing about keeping the db stuff separate is that your API code can then focus on the business logic and have all the db stuff abstracted. In fact, if needed, you could switch diesel out for some other tech and your api won't know, since it just uses the db crate.
I started running into this question, and the answer was 'I should be using more files'.
Oh god why
I'm not really familiar with -Z flags, but running `cargo -Z help` only gives me: ``` Available unstable (nightly-only) flags: -Z avoid-dev-deps -- Avoid installing dev-dependencies if possible -Z minimal-versions -- Install minimal dependency versions instead of maximum -Z no-index-update -- Do not update the registry, avoids a network request for benchmarking -Z offline -- Offline mode that does not perform network requests -Z unstable-options -- Allow the usage of unstable options such as --registry -Z config-profile -- Read profiles from .cargo/config files Run with 'cargo -Z [FLAG] [SUBCOMMAND]' ```
You might have the best success returning a concrete type for your iterator, making it an [associated type](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html#specifying-placeholder-types-in-trait-definitions-with-associated-types) of the trait.
What's the benefit of calling `use crate::foo` inside a function instead of the top of the file? Just to keep namespaces more clear, or are there other benefits? Example, the third code block here: https://actix.rs/docs/databases/ calls `use self::schema::users::dsl::*;` inside a function.
BECAUSE IT'S AWESOME. :3
This comprehensive list of [Rust books](https://reactdom.com/rust) should be helpful.
I’m internally conflicted. I love it when programs support Unicode correctly. I have a special hard-on for Swift’s Unicode support, especially their Strings since Swift 4 - their implementation is simply beautiful. On the other hand, introducing the risk of confusables is like opening a can of worms and I do believe most code should remain English and ASCII-only.
You're looking for /r/playrust! /r/rust is for a programming language of the same name.
Any example you have laying around?
I'm confused. Steve Donovan is the author of the website [*A Gentle Introduction to Rust*](https://stevedonovan.github.io/rust-gentle-intro/readme.html#a-gentle-introduction-to-rust). I like Donovan's website a lot and use together with [*Programming Rust*](https://www.amazon.com/dp/1491927283/) and a few other resources in teaching. *Step Ahead with Rust*, the linked book by Jonathan Creekmore and James Miller, doesn't seem to have anything to do with Donovan's website?
Doing this (`impl Trait` in traits) is not currently supported. We need "existential" support in order to do this, unfortunately, and that's not yet stable (or built?). You can either return `Box&lt;Iterator&lt;..&gt;&gt;`, or make the return type an associated type as /u/raphlinus mentioned and leave it up to the implementation whether to return `Box&lt;Iterator&lt;..&gt;&gt;` or something else. This is essentially what we had to do before `impl Trait` landed, and it's still needed here since `impl Trait` is not supported as the output of trait function signatures.
dammit lmao &amp;#x200B;
Well, you can always move \`requestAnimationFrame\` to the JS and make JS call Rust's \`update()\` and \`draw()\`.
Additionally - it'll be more convenient if you replace your local variables with a structure (just like they did here: [https://rustwasm.github.io/book/game-of-life/implementing.html](https://rustwasm.github.io/book/game-of-life/implementing.html)).
In this case I'd probably just use the `Vec` in the loop and rely on the optimiser to catch and reuse it. (I'm trying so hard currently to avoid spending time writing code where the optimiser can do good enough on its own for less developer time.) If the collect is a fixed small length (up to 4) in the real situation, consider [`Itertools::collect_tuple`](https://docs.rs/itertools/0.7.8/itertools/trait.Itertools.html#method.collect_tuple). Otherwise, this exact pattern can't work, since you'd be changing the type of the Vec each loop.
that's a good point - possibly the end result is as if it were using the same vec. I put the example in compiler explorer [here]( https://rust.godbolt.org/z/f4qHCX), but I'm just beginning to read assembly and can't tell if the vec is reused. I don't understand your point about the type changing in each loop though. Isn't the type `Vec&lt;&amp;T&gt;` every loop iteration?
/r/monica_b1998 The linked book "Step ahead with rust" might be good but the title you choose "Introduction - A Gentle Introduction to Rust" is totally wrong. Better delete this post and re-post this with correct title.
Good idea... I'll join..
The lifetime is (effectively, from one point of view) part of the type, that's why there's an error. As you're re-borrowing from the original collection each loop iteration, each loop iteration has its own short lifetime. And the compiler errors because it can't unify them into the same lifetime type to put them into the same container. That said, typing that gave me the solution to this formulation of the problem: don't do that! Specifically, borrow `xs` _outside_ the loop, then `.iter()` on that borrow. Then the lifetime is tied to the outer lifetime due to how iteration works in Rust, so all iterations use the same lifetime.
You can use NLL as the other comment suggested, but then you won't gain understanding about how to solve this problem in more complex cases. For example, if I do something silly and re-compute `value` in the return statement (i.e., [this code](https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018&amp;gist=35e478ff8bca7dbc4231aed577d85399)) NLL no longer helps. The general solution is to refactor the code so that `add_log` only borrows what it needs; i.e., the `log` variable. The general way to do this would be to make a type wrapper for `Option&lt;Vec&lt;MemoryAccess&gt;&gt;` and implement `add_log` as a function on that. Or you could skip having a whole type wrapper and just write a function on `Option&lt;...&gt;` instead of a method: note that methods are only syntactic sugar for functions. Or you could just use `Option`'s built-in functions to shorten the code, although this arguably does "inline" `add_log`: `self.log.as_mut().map(|log| log.push(MemoryAccess::Read8(addr, value)));`.
It’s even worse. The safe methods are not #[target_feature] and that can result in horrible code generation if one is not careful with inline(always).
Yeah all the SIMD stuff I've done is the "huge batch of work" style where you pick your computation path (8 wide, 4 wide, or no SIMD) and then it jumps to the right call internally and then does all the work without ever thinking about it a second time until that batch is over.
Awesome. Thank you. I was hoping for something in serde-derive, but that was probably to much to hope for, and this is great. 
You aren't missing anything- this is a deficiency in the borrow checker relying on the so called "lexical lifetimes" (lifetimes always lasting the lexical scope they were created in). If you're using nightly, you can opt in to the new (unstable) checker which has non-lexical lifetimes. It's pretty usable, there haven't been bugs in a while, but it hasn't been stabilized. Putting `#![feature(nll)]` at the top of the main file (`main.rs` or `lib.rs`) enables it as /u/reddit123123123123 mentioned.
&gt; I do believe most code should be written in English, ASCII-only How do you handle words not existing in English or specific business terms? I'm ok with writing generic libraries in English but using English doesn't make sense for a pretty huge number of projects.
[tried](https://play.integer32.com/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=40f1077b766d5090a22cc9985c005d75) to follow what you were saying, but without success. 
_Step ahead with Rust_ is a really good quick primer into Rust. It's much shorter then _Programming Rust_, but perfect for people that know programming and just want to know quickly how the language works.
How about `#[feature(non_ascii_idents)]` for those cases? 😉 Mind you, I'm not advocating for this solution - my mind is not set on either direction at all. 
initially I was very excited - as it did solve the playground example! however it did not resolve my real-world code issue, which seems to overwhelm the nll logic with complicating factors (separate struct members borrowed, etc.). glad this is coming along though.
The final example is interesting when it comes to struct field ordering. It implies that `i32, f32, i32, f32` might be less efficient than `i32, i32, f32, f32`, since in the latter case the floating point values are already in the xmm registers, where they can be worked with.
that is definitely a good workaround! the problem is, my actual code is hideous compared to the nice example. it turns out I am trying to do [this](https://play.integer32.com/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=bb8bf6e4caf7a9d95c380d14592965a3), placing references to `xs` in `ys` in an inner scope inside the loop body, then, in the same loop body (but after the scope), mutating `xs` again.
I might call the error type `HammingError`, since it seems to only apply to hamming distance.
bash has similar warts, but they were the right things at the right thing with the right level of pre-installation. * how do you deal with a function that returns a list of things separated by newlines that you want to pass to another function or command as args? * if you've chosen `readarray -t &lt;&lt;&lt; "$(cmd)"`, did you know that it swallows errors from `cmd`, even if you have `set -euo pipefail`?
HCL and TOML are hardly even in the same category given what HCL does in comparison to TOML. I'm not saying HCL is better, I'm saying it's a billy silly to compare them. Any place I've seen HCL, it wouldn't make sense to use TOML and vice-versa.
I can't really think of a situation where they're not broadly substitutable barring date/time stuff that TOML has type support for.
I really wish we would have some standardized way of making titles of posts so it is easier to decipher what is it about. Currently it's a collection of random words for me.
Can't wait for identifiers that use looking-similar but different characters.
This sounds useful. Can I ask a couple of quesstions- 1) do you also have a way to reverse a transaction using your code as mandated by law I believe? 2) I am not asking you to open source your hard work but if you already have them is there a link? 
As usual, some links in the release notes will be broken until the actual release is out.
Ahh darn, yeah. I don't know of any trick to do that since y's signature will always have it borrowing from x even when empty. Might be possible to avoid it by keeping `y` around as something less typed between loop iterations, but unless a safe wrapper exists for this kind of "keeping around an empty allocation used for pointers without a lifetime" thing, it would be unsafe. I'd probably just bite the bullet and make new vecs each iteration. It should be pretty fast with just a vec of references, and it can always be optimized later if need be. If it is really a bottleneck, it should be sound to turn the inner vector into "raw parts"- a capacity and a ptr, then turn it back into a vet with length=0 at the end of each loop iteration and after the loop to do the final drop. Ideally there'd be an `EmptyReferenceVec&lt;T&gt;` wrapper to manage that but I don't know of any such structure.
1) Haven't even thought of that (yet), basically its the graduation project for my school, we are a group of 3 and decided to make a Bitcoin vending Machine. Still thanks for the though, will probably included that. We plan on renting a space to put the vending Machine though. 2) I will Open Source it (either under GPLv2 or WTFPL) but its still just testing, so the code is not polished enough yet. Will release it probably somewhere in December though.
I doubt that the optimiser can reuse memory allocations.
Did you tried macros? 
Here's the first in the series, hope that helps https://www.reddit.com/r/rust/comments/9ozaut/shifgrethor_i_garbage_collection_as_a_rust_library/
Would it be possible to declare a `root` in `lazy_static`, meaning you have a garbage collector for the whole runtime of the program? That way it'd be possible to have `GcBox::new&lt;T&gt;(T)` without the `root`-context, because the static root is just used. This could make for an interesting library where you always get `'static` references, allowing you the full experience of a GC in Rust.
Managing of rust versions by rustup seems a bit wasteful. Currently, downloading "stable" and "1.29.2" creates two downloads.
Will the link for the macros chapter be fixed when the release is out? I'm asking because the link [works with `/nightly`](https://doc.rust-lang.org/nightly/book/2018-edition/ch19-06-macros.html) inserted in the url, but [still fails with `/beta`](https://doc.rust-lang.org/beta/book/2018-edition/ch19-06-macros.html) inserted in the url.
The idea isn't to reuse the memory created within the loop, but to move the Vec-creation out of the loop. This might be possible by [LLVM's Loop Invariant Code Motion pass](https://llvm.org/docs/Passes.html#licm-loop-invariant-code-motion) in some cases.
Thank you for your input. Note about `f64::from` vs `as` - it was like that [initially](https://gist.github.com/Shchvova/e1a0d766ef01f1b564c53a4347e70778/revisions#diff-97c1bfe1a9dd341372fc37f899b74e84), and Clippy [told](https://i.imgur.com/f6QNFtU.png) me to change it to how it is now.
If i don't misunderstand what you said, this would lead to garbage never being collected, since the rooted pointer never goes out of scope.
Is it really? Can you provide an example?
Can you elaborate where Rust's syntax is hard? It's really hard to argue without an example.
It's very heavy on symbols. LOTS of brackets and angle-brackets. I wish it were lighter in that regard but they come in time. The `?` operator already removes a lot of brackets and I think that will soon apply to Option types too. I think someone proposed an "and"/"or" keyword to do away with the nesting of brackets with Result/Option type methods "and"/"or".
A real-time, optionally GPU-accelerated, grid based fluid dynamics system for realistic atmospherics, gas, fire and explosion effects simulation.
BTW you can keep indices instead of pointers, e.g. like [this](https://play.integer32.com/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=fc3ed498ae09f14a46a90f62b590ed2a). Some see this approach as effectively "turning off" borrow checker.
&gt; The nix crate runs their own buildbot instance. But one has to host these oneself right? As in, there is no free CI service that hosts these? 
please check my reply on [K900_ comment](https://www.reddit.com/r/rust/comments/9r93t7/why_rust_syntax_is_quite_complicated_or_hard/e8f2so4/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=rust)
Check a standard C library implementation of printf. Varargs.
The Hungarian algorithm is also implemented in the [pathfinding](https://docs.rs/pathfinding/1.0.3/pathfinding/kuhn_munkres/fn.kuhn_munkres.html) crate.
Isn't this because `stable` will always be the latest version (well, the stable one), whereas `1.29.2` will stay on this exact version?
You mean this? Let Some(value) = get_option() or return; 
&gt; most modern languages (Java, Kotlin) I'm sorry, but what in your opinion is a "modern" language? Rust is quite modern, last I heard...
You're probably right. My assumption was that objects, that aren't referenced from the `root` anymore, would still get collected. Although that way for example if you have an `Option&lt;Gc&lt;_&gt;&gt;`, from which you `take` the value, that value would be freed even though you might still have reference to it. So I guess that's not really possible.
A crate for the particular `Rc`/`Arc` pointer would be very useful, I think. Does anyone know if that exists? 
I didn't see it as excluding Rust. I interpreted that as "comparing Rust to other modern languages, most of them..."
Good point. But I still wonder what other languages the OP is very good at, they mentioned "I have very good knowledge in other languages like Java and Kotlin", which implies they're very good at other languages too.
Unlike domain names etc, there is not any reason for someone to do that in a program. Quite a few programming languages support non-ASCII idents, I've yet to hear about an actual problem from it, have you?
I’ve not written much Java or any Kotlin, what would be the idiomatic way to write these in those languages?
I don't want to be rude, but (for me) C syntax is the best syntax i have ever seen.
Thanks for your suggestion. I did as you wrote to no avail unfortunately. pub trait DatabaseBackend { // I didn't manage to get type working properly without even more lifetime issues fn transaction(&amp;self) -&gt; Result&lt;Box&lt;DatabaseTransaction&gt;, Box&lt;Error&gt;&gt;; } impl DatabaseBackend for Postgres { fn transaction(&amp;self) -&gt; Result&lt;Box&lt;DatabaseTransaction&gt;, Box&lt;Error&gt;&gt; { let transaction = self.conn.transaction()?; Ok(Box::new(PostgresTransaction { transaction })) } } pub struct PostgresTransaction&lt;'a&gt; { transaction: Transaction&lt;'a&gt;, } impl&lt;'a&gt; DatabaseTransaction for PostgresTransaction&lt;'a&gt; { ... } Compiling gives the following error... error[E0495]: cannot infer an appropriate lifetime for autoref due to conflicting requirements --&gt; src/database/db_postgres.rs:14:37 | 14 | let transaction = self.conn.transaction()?; | ^^^^^^^^^^^ | note: first, the lifetime cannot outlive the anonymous lifetime #1 defined on the method body at 13:5... --&gt; src/database/db_postgres.rs:13:5 | 13 | / fn transaction(&amp;self) -&gt; Result&lt;Box&lt;DatabaseTransaction&gt;, Box&lt;Error&gt;&gt; { 14 | | let transaction = self.conn.transaction()?; 15 | | 16 | | Ok(Box::new(PostgresTransaction { transaction })) 17 | | } | |_____^ note: ...so that reference does not outlive borrowed content --&gt; src/database/db_postgres.rs:14:27 | 14 | let transaction = self.conn.transaction()?; | ^^^^^^^^^ = note: but, the lifetime must be valid for the static lifetime... = note: ...so that the expression is assignable: expected std::result::Result&lt;std::boxed::Box&lt;(dyn database::database_transaction::DatabaseTransaction + 'static)&gt;, std::boxed::Box&lt;(dyn std::error::Error + 'static)&gt;&gt; found std::result::Result&lt;std::boxed::Box&lt;dyn database::database_transaction::DatabaseTransaction&gt;, std::boxed::Box&lt;dyn std::error::Error&gt;&gt; error: aborting due to previous error For more information about this error, try `rustc --explain E0495`. And to let it sink in: » rustc --explain E0495 error: no extended information for E0495
Yes, currently they are considered to be entirely separate toolchains. Fixing this is non-trivial: it’d involve adding a concept of toolchain aliases (stable would currently be an alias for 1.29.2) and tracking "explicitly installed" v.s. "installed through alias X". For example, when `stable` upgrades to 1.30.0 this week, rustup would need to remove 1.29.2 unless you have also installed it specifically, or another alias refers to it. This is all doable, but it’s a fair amount of design and implementation work.
Thanks for responding. I look forward to looking at it. !RemindMe 2months
I will be messaging you on [**2018-12-25 12:56:53 UTC**](http://www.wolframalpha.com/input/?i=2018-12-25 12:56:53 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/9qco2k/whats_everyone_working_on_this_week_432018/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/9qco2k/whats_everyone_working_on_this_week_432018/]%0A%0ARemindMe! 2months) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
If you understand the underlying concepts, the syntax becomes less hard. The syntax is only there to represent the underlying concepts, and I guess it's the Rust concepts that you're unfamiliar with that you're really complaining about. In which case, all you can do is keep studying and asking questions until it all makes sense.
Thanks :)
What I mean is that there's no point downloading twice because of that. If stable has already been updated to 1.30 and you do "rustup toolchain install 1.30" you get a second download when you should just do a symlink.
Can you please provide those two examples also in kotlin and swift for comparison?
It seems simple to do: - When installing/upgrading stable/beta/nightly install it to a named version toolchain and add a map entry "stable -&gt; 1.30.0" - When uninstalling a stable/beta/nightly check if the named version is also explicitely installed (key is in the map), if not delete it. You don't need full general purpose aliases to handle this, just a single "stable/beta/nightly/number -&gt; version number" map. That should be simple enough to write as a text format.
Well part of your confusion is probably because the first example isn't even valid Rust. Where did you get that?
Since we don't have the Option class already exists so I had to include it in the code Kotlin Code:- sealed class Option&lt;T&gt; { data class Some&lt;T&gt;(val value: T) : Option&lt;T&gt;() class None&lt;T&gt; : Option&lt;T&gt;() fun &lt;U&gt; bind(f: (T) -&gt; Option&lt;U&gt;): Option&lt;U&gt; = when (this) { is Some -&gt; f(value) is None -&gt; Option.None() } fun unit(t: T) = Some(t) }
Will stabilizing `proc_macro` and `use_extern_macros` allow developers to document their API using external files? Something like: ` doc_file!("./func_a.md"); pub func_a.md() {} `
here: https://m4rw3r.github.io/rust-and-monad-trait 
The game of life example is precisely what I'm looking for. Thanks!
&gt; It's an accident of history that this is the case, and the fact that this is the case now doesn't mean that it should be so in the future. How dismissive. "Well you're right, but we're idealists and don't care" It may not be nice, but thats how it is. Just like you need C for cross language compatibility, you need english for programming, and *good luck changing either*. Even if you succeed, all you've done is limited their resources, because the vast majority will *always* be in English. &gt; Is it? Because the compiler is already dealing with unicode identifiers, even if it is rejecting them with an E0658. Detecting non ascii in idents is quite a different beast than properly understanding unicode, is it not? &gt; Confusables already exist even within ASCII, and the lints are to make sure we don't introduce undesired interactions with other parts of the language. Fonts solve that, those are unintended confusables, whereas the unicode ones ,as far as i understand it, are supposed to look like that, a font changing that would be *wrong*. &gt; Emphasis added. You don't see it being useful in the "real world", but that doesn't mean that it won't be useful for people. Whether they can use it is also a different question to whether it *should* be used, for all the other reasons i mention. &gt; Why shouldn't an open source project that's intended only for people on a single locale (think a specific's country's tax preparing, for example) be in that locale's language? dang u got me there. &gt; There are lots of people with languages well served by Latin-1 who program on their native keyword layout. Shouldn't be up to people in other locales to decide wether switching between layouts is too annoying? Source? &gt; I don't know if you've seen bilingual/multilingual people interact among each other, but they usually switch languages pretty free-form, depending on what they're talking about. On some cases, they will talk in one language, use a single word or phrase in another, and switch back. Or continue in the other language. This is all very context dependent and, more importantly, seamless for everybody involved. dang u got mt there. &gt; That is IMO a bug that no-one hasn't had the bandwidth to deal with. Which means until theres the bandwidth to translate it and every version of it, now and for the future, and the book and the reference and the nomicon, they need English anyway. &gt; That is a value judgement that seems to me to, again, betray lack of imagination or experience outside of your own culture. It is also a sentiment I do not understand, as no-one is forcing you to implement or even use this new feature. Well, alternative rust implementations will have to support it, and god forbid it's ever used in a public project intended for the wider world. &gt; An accessibility feature only affecting a number of people doesn't mean it shouldn't be done, for the same reasons that curbs should be wheelchair accessible. You can learn english, and have to to be in this field anyway, you can't learn to walk with broken legs. Like it or not, English is the lingua franca of programming. You can try to change it as much as you want, but good luck with that. In fact, changing it only makes it *less* accessible to everyone else who already knows the lingua franca. &gt; And even then, on Earth, only ~20% of the people speak english at any level. That may be ["true"](https://en.wikipedia.org/wiki/List_of_languages_by_total_number_of_speakers), but is also incredibly misleading because that ~20% puts English at the *top* of languages by total number of speakers, with Chinese the only one even coming close.
Here's a direct translation of your code to Rust: enum Option&lt;T&gt; { Some(T), None, } impl&lt;T&gt; Option&lt;T&gt; { fn bind&lt;U&gt;(self, f: impl Fn(T) -&gt; Option&lt;U&gt;) -&gt; Option&lt;U&gt; { match self { Option::Some(x) =&gt; f(x), Option::None =&gt; Option::None, } } fn unit(t: T) -&gt; Self { Option::Some(t) } } Declaring the enum / class is more concise in Rust and the rest looks pretty much identical to your Kotlin code. I see your code in a comment above used `F: FnOnce(..)` which can now be shortened to `impl` as shown in the code above.
For those that are interested, a non-bipartite graph matching algorithm is provided in the [mwmatching](https://crates.io/crates/mwmatching) crate.
I'm having a hard time understanding what your goal is , and i get the feeling the problem comes from translating a pattern from C or something. From [this](https://play.integer32.com/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=bb8bf6e4caf7a9d95c380d14592965a3) you can just [remove the vec](https://play.integer32.com/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=280ae40e93ee7a00624f5e288414d762) all together. 
Obviously not or we'd already have a PR to that respect :-) - let's see if that'll change when Rust gets used more in embedded development in a more serious fashion than "hey it works, let's experiment with it". (My point was more to: If someone needs this, lack of perfection of a good-enough-for-this-case solution will not stop the Rust community from adopting it, and the author of a first PR will hopefully not be expected to find an optimal solution for the general case.)
It has its upsides, but it also has some things I strongly consider to be warts. Here are a few examples of my pet peeves: * The [Clockwise/Spiral Rule](http://c-faq.com/decl/spiral.anderson.html) and how essential it is to reading function pointers. * I can never get used to the way `*` binds in pointer declarations. (ie. Intuition sees "pointer" as part of the type, so either `int* foo, bar;` should produce two pointers or it should be `int foo*, bar*;` so what's going on is unambiguous.) * It took an inordinate amount of time for me to get it to stick in my memory that `*` declares a pointer but `&amp;` creates one from a value. (ie. Something like `int&amp; my_ptr = &amp;my_int;` or `int&amp; my_ptr = my_int&amp;;` would have been more intuitive... if it weren't for the "&amp; takes the and-dress" mnemonic, I might still be having to check my notes every time I use pointers.)
Hey, why not create an RFC and start working on an implementation? I'm sure that would make a LOT of people happy. :)
According to Rust naming convention, getter/setter APIs should be named `foo` (getter) and `set_foo` (setter). But what should I then name the actual private struct field, because the name `foo` is already taken by the getter?
This is more my own thoughts rather than anything official, but: `use` can bring traits into scope, i e, bring new methods to ordinary structs. Given that Rust doesn't mind easy names on things, these methods can often clash if you have many traits. E g, if both trait `A` and trait `B` have a method `read`, calling `something.read()` makes it easier to understand what will happen if only one of `A` and `B` are in scope at the same time, and that `use` that brings it into scope is close to the method call.
I remember reading another thread regarding how much space `cargo` uses, and I believe the answer is related to your question too. When you compile a crate, the resulting executable will depend on features you’ve selected, flags passed to `rustc`, etc., so you can’t assume that two binaries compiles from the same crate will be the same. That said, it looks like there are ways to cache builds using other tools like `sccache` (from Mozilla): [see here](https://users.rust-lang.org/t/sccache-for-caching-rust-compilation/10960).
&gt; I do believe most code should be written in English, ASCII-only. [I agree.](https://www.reddit.com/r/rust/comments/9oyzci/this_week_in_rust_0x100/e83pk8h/?context=3000) Like it or not, English is the lingua franca for a lot of things internationally, including programming.
I believe that the two big points of confusion (at least to me) were enumerations and lifetimes. Understanding and using them correctly was always a bit difficult early on. I think the use of borrowing and ownership forces you to use these things and that makes starting more difficult, but you will come out a stronger programmer. As far as syntax is concerned, I think most of it is just familiar to different people. Most syntax in Rust is based on another language to increase familiarity. Templates resemble Java and C++, return types resemble typescript, pattern matching resembles scala, closures resemble Ruby closures, etc. This means Rust's syntax will be somewhat familiar to a broad range of people, rather than particularly familiar to a few people.
You're forced to use the nightly compiler in this case.
It not work: pub trait Relation { fn read_value(&amp;self, start:usize, col:usize) -&gt; Iterator&lt;Item=usize&gt; { vec![1, 2].into_iter() }. }
That link does say &gt; Of course this is not a full proposal — and most of this does not actually make sense as a proper feature or syntax in a programming language — but it is more of an exploration of what would be needed to properly implement a generic Monad trait. Hopefully this article can serve as some kind of start for a discussion about a real RFC.
https://github.com/rust-lang/rust/pull/55325
&gt; The following methods are a replacement methods for `trim_left`, `trim_right`, `trim_left_matches`, and `trim_right_matches`. Which will be deprecated in 1.33.0. I think -- but I'm not entirely sure -- that the originals are being deprecated because the names "left" and "right" are confusing with respect to right-to-left-rendered languages. So the new methods are doing the exact same thing, just with new names. Is that right? If so it might be worth adding a sentence or two to the release notes.
The names of methods and fields don't collide, so they can both be named `foo`.
impl Iterstor&lt;Item=usize&gt;
Please look at the error messages. 
No `type Reader: Iterator&lt;Item=Scalar&gt;`
Here's a link to the source if you're impatient like me and want to read it: https://github.com/rust-lang/book/blob/master/2018-edition/src/ch19-06-macros.md
What happens when `stable` is 1.29.2, and you download `1.29.2`? Should 1.29.2 symlink to stable? If so, then when you update stable to 1.30, does 1.29.2's symlink break, or do 2 versions get installed at that point? &amp;#x200B; Alternatively, should rustup see that your symlink's going to get broken, and try move stable to 1.29.2 before installing a new one? There might be an easier way, but a symlink approach seems complicated. &amp;#x200B; Actually, installing versions somewhere common, and linking stable, beta, nightly-YY-MM-DD and specific versions via symlinks could work, now that I think of it.
What is the Java / Kotlin equivalent to macros? Dynamic bytecode generation? That isn't any simpler! Macro syntax is always going to be a bit weird since you are writing two syntaxes at once (the macro syntax and the language syntax), but I think Rust does it in a really clean way. It's not something you should be using a lot anyway... it's part of the language for enabling use cases where using real Rust syntax just isn't nice enough. It used to be needed for tidy error handling and async/await, but it is no longer needed for the first because of the ? operator and it will likely go away for the second use case with the async/await keywords. It's still used to simulate user friendly variable-argument functions but there will probably be a time where it gets replaced there as well. Then it's only for pretty serious alterations / extensions to the language, which in JVM languages is done by bytecode mangling libraries. 
What is the reason why Rust uses static linking by default? It makes buildtimes longer, wastes space and will be huge problem if Rust becomes more popular and bugs in widely used libs need to be fixed. Sure it makes it easier to build your first project or to deploy application but in my opinion the advantages are not worth it. 
Thanks
Have you managed to build and run `i686-pc-windows-gnu` ?
So I don't want to beat a dead horse here but this actually isn't a translation of the above pseudo code. The above code implements Option for a typeclass called Monad. Your code doesn't do that and there's no way to do that operation in either Java or Kotlin (or Rust currently for that matter). As a beginner, I'd recommend just focusing on the core language before you try dabling with proposed syntax extensions.
What you need is a Cargo workspace. Place a Cargo.toml in the root with with: [workspace] members = [“sub_crate”, “sub_subcrate”] Remove *.lock from sub crates. Use cargo build and it will build into a target folder in the root of your workspace. This way you don’t get the recompiling behaviour you see.
The ABI is not stable enough for dynamic linking to be useful; differing compiler versions are enough to break compatibility between two binaries.
here is the 2nd time: I think C syntax is very nice as well. Part of this is no doubt that I am used to it, but also because it is a relatively simple language spec. &amp;#x200B;
You can start by asking in the correct sub (/r/playrust) :)
Why do you need the parent map to stay mutable? Having references into a collection and having it be mutable is simply not possible (without another layer of indirection somewhere). When a collection has reached its limit, new memory is requested and everything inside it is moved. So your pointers are invalidated. Rc, Refcells , and indexes instead of pointers are obvious candidates , but depending on what you can know upfront , relatively unknown tricks like [Cell&lt;T&gt;; size] are also possible.
Both approaches have advantages and disadvantages; DLL hell vs some wasted space, among others. The general industry trend is static linking, for a variety of reasons, and dynamic linking’s greatest advantage requires so much work that basically only C has ever really had it. We may get there, but just like it took a few decades for C, it will take us a long time too.
For derive macros, macro output is added to the input. For function-like macros, input is discarded and output is used instead. But for attribute-like macros it is unclear from the documentation what happens with the input. If I want the original item to be present after my macro invocation should I write it myself to the output or will this happen automatically? &gt; derive only works for structs and enums It also works for unions.
Personally I keep code for the same project in many seperate crates, and not under one workspace, but as independent projects with their own repos. It works pretty well,but it would be much nicer if I could set up a private crates.io to use dependencies by version. Currently I list them with a local path, which creates some headaches. I can't get the git functionality to work with a private gogs (like github/gitlab) server I run. At least with this approach I can work on one part of the codebase without compiling all of it. I do end up using `pub` a lot, as you can imagine. 
I believe you must output the whole thing.
nice troll
Well, step 1 is to understand the borrow checker
Please [read the book](https://doc.rust-lang.org/book/second-edition/)
Feature suggestions are wonderful. When you start estimating the amount of (someone else's) work involved, and acting like there's no good reason it hasn't been fixed already, then you cross the line from helpful to demanding. Your words become hurtful to the people who have already contributed a lot of time to this project. There are a lot of things that need fixing. This seems like a pretty minor one. If it's not minor to you, PRs are welcome. 
The filter/sort part is used to inform how I update the objects in the map. The references are created and destroyed inside an inner scope. There's no soundness issue, the compiler just doesn't understand that clearing the vector ends the borrow. 
it's trying to do more. JVM languages andSwift lean on the runtime to manage memory (garbage collection). Rust is like C++, i.e. there's no runtime and you must guide memory management through compile-time mechanisms (RAII hence greater detail in references and containers), and more complex still by trying to add safety. The combination of safety and the efficiency of not needing a GC doesn't come for free - you pay in language complexity, and extra annotations. It's not for all use cases - for many people's real world work, a runtime GC is fine; but there are important niches where runtime GC is 100% unsuitable, hence the ongoing need for languages like C, C++, and Rust.
&gt; Why does Rust uses static linking by default? Historic reasons: static linking is easier to implement on all platforms, easier to get cross-compilation going, etc. so it basically was there first, and is the default because it works reliably. Without going into the trade-offs of dynamic vs static linking, dynamic linking is harder to implement correctly on all platforms.
Without going into the trade-offs of dynamic vs static linking, dynamic linking is harder to implement correctly, so static linking was working reliably first and became the default. I don't know how good does dynamic linking work for Rust. 
woops sorry about that man lmfao i just made a reddit account i don't know how this works x)
What do you mean that git doesn't work? Do you mean specifying git repositories hosted on your gogs instance? If they're public repositories it should work just fine, I haven't had any problems with this. It's worth noting that you can run a private crates.io, although I don't know how easy it is to setup. It might be easier to write your own server that just implements the basic functionality.
That’s correct, and the blog post as well as the deprecation messages say this more explicitly.
The source code is stored globally, but the compiled outputs are stored locally. Each project may have different code gen settings and so you can’t assume that they’re actually identical. In the future this may be fixed.
&gt; When uninstalling a stable/beta/nightly check if the named version is also explicitely installed (key is in the map), if not delete it. You also need to do the reverse of this check when uninstalling a named version. And you need to decide whether it's possible for stable and beta to ever refer to the same toolchain. If so, uninstalling stable means you need to check two things. You then have the recursive version of the same problem when you consider installing and uninstalling new components for a toolchain. These aren't horrible insurmountable problems or anything, but like most things in software, I think it's more complicated than it sounds.
Finally, I can use `Iterator::find_map` on stable. It always felt silly to do `v.iter().find(..).map(..)` or `v.iter().filter_map().next()`.
The gogs ssh url format breaks Cargo, iirc. I spent hours on it once, then decided it wasn't worth spending more since a local path is not that bad. 
Note that C++ did a thing were vector&lt;bool&gt; is overloaded as an array of bits instead of an array of bools (char). While a cool idea in theory, in practice it causes so many issues since you can no longer take pointers to elements of the vector. This causes a lot of confusion and frustration, especially for generic code taking type T which could suddenly fail to compile if T=bool.
You can share the same target dir by doing: export CARGO\_TARGET\_DIR=/tmp/cargo\_target That will reuse the compiled crates. &amp;#x200B;
`cargo` doesn't have a global system-wide compilation cache, but you can just use `sscache` for that.
Oberon, Eiffel, Ada, .NET, Java, Limbo, Modula-3, Delphi and component systems like SOM and COM are all examples of dynamic linking in production.
[https://crates.io/crates/bit-set](https://crates.io/crates/bit-set) [https://crates.io/crates/bit-vec](https://crates.io/crates/bit-vec) works for you
"The large size of these executables slows down builds and creates problems for our Gitlab CI as they have to be copied over the network between build and test phases. But I don't know what to do about the problem." Would `rsync` help? I mean - I guess there's a chance that most of these binaries are almost exactly the same most of the time, no?
 One other reason that hasn't been mentioned is there's no way to dynamically link generic functions, because they're monomorphised, and the library can't know all the generic parameters the function will be called with when it itself is compiled. You can still link to libraries with generic functions and call those generic functions, but it isn't actually dynamic linking. What actually happens is the dynamic library is compiled with the AST of the generic function, which is then compiled whenever you link the library. The subtle downside to this is that if you change the implementation of the generic function and recompile the library, the implementation won't actually change in binaries unless you recompile them as well, aka it's basically just static linking. Also static linking has some significant performance benefits.
Problem is not using static linking as such. That was our only option on MS-DOS real mode and it was quite fast. The biggest difference to how cargo works is that we weren't compiling the whole world from scratch, including dependencies.
🎉🎉🎉 Stable proc macros are a huge deal! A huge thank you to everyone involved in making this happen, and congrats for finally shipping it. I look forward to all the wonderful ergonomic APIs that emerge.
Small typo &gt; Rust expands on this by adding the ability to define two other kinds of advanced macros, “attribute-like procedrual macros” and “function-like procedural macros.” 
I can write code in French/Italian in ascii without too much trouble. Non ascii idents are nicer for languages with non latin alphabet like Japanese. One of the issue of having it opt-in is discoverability: JavaScript for example allow non-ascii idents but many people don't know that so I have seen codebases where variables were written in romaji with the kanji as a comment above, which is kind of silly.
This looks like a huge update! Thanks Rust people 🎉🎉🎉
I'm coming from Python as well. And the book is the best way to learn Rust. Rust is a lot harder than Python. There's no real way around it. You just have to stick through it. There's no other way. And you can of course look on Youtube. You should find more than enough videos for all the basic concepts.
What was the motivation for the raw identifier syntax? It's a simple thing, but strikes me personally as unnecessary (and hence one more thing to trip up beginners).
Ah thank you, I guess I naively assumed it was "simple" to reuse crates like that.
proc macros must still be in their own crate.
Thanks!
;( Is there a plan to change this or will it be that way for the foreseeable future?
We’d like to change it but I have no idea when it may happen.
This means I'll be able to use the js_export attribute from stdweb on stable, right? 
I won't miss macro_use
Mostly to keep namespace clear and unpolluted. It's especially useful for bringing in enum variants in a function which only deals with that enum. Like `use self::MyError::*;` makes sense in `MyError`'s display implementation, but anywhere else it would be super confusing to have a type `Io` (`MyError::Io`) in scope.
Allright then, thank you 
In the release notes https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1300-2018-10-25 the link ' new chapter available ' is 404.
Yes, there’s an open PR to fix it but it hasn’t landed yet, thanks.
Have you tried [Rust By Example](https://doc.rust-lang.org/rust-by-example/) and [Rust Cookbook](https://rust-lang-nursery.github.io/rust-cookbook/intro.html)? My background is C#/Python and these two books really helped me getting started.
That would be absolutely wonderful. I've gotten a few people at my job interested in Rust thanks to wasm, being able to call functions written in Rust from JavaScript without using nightly will definitely help my friendly evangelism.
I don't use `stdweb`, but I looked at the implementation to give you that answer. You should still try it. I do know that wasm-bindgen and wasm-pack both work on stable as of this release.
I can see it being useful for automatically generated identifiers, to avoid keyword differences between languages
I disagree that it's a problem. And by that I mean, a distribution or project will pick *one* version of the compiler and be able to distribute uniform DLLs within their scope. There are other factors for favoring static linking; the ability to copy/paste a single file (executable) from one machine to another and have it run without issue for example.
Well, I'm currently traveling home and will probably have some dinner before deciding if I'll write more code today. When I say this thread I thought I should ask because the possibility made me feel enthusiastic.
I have an idea for a custom-derive that I want. The problem is that it would derive a marker trait with no methods, but it's only safe to derive this trait if it is also implemented by all values inside the structure/enum. It's similar to the Copy traits in that it must be implemented transitively. Is it possible to do type-checking like this in a custom derive? I don't see how it could be done, since the derive macro doesn't have access to type-checking information. I can think of a few possible hacks to work around this but none of them seem very elegant. Is there a common way to do this?
Not sure, but shouldn't it be "Rust *1.30* expands on this..."?
Sure, that'd be helpful too. Care to send in a PR?
I thought that the leading `::` for absolute paths was aesthetically pleasing, but the other consistency improvements more than make up for it.
Now that `proc_macro`s have landed, how close is Rocket to working on stable?
Looks like not quite yet: https://github.com/SergioBenitez/Rocket/issues/19 Never type can use a crate. The hygiene and error APIs aren’t going to be stable soon. In theory it looks like rocket could use that package and accept worse error messages and build on stable. Sergio would have to weigh in on that, though, I could be wrong.
I'm having fun with this now: [https://www.snoyman.com/blog/2018/10/introducing-rust-crash-course](https://www.snoyman.com/blog/2018/10/introducing-rust-crash-course) Unfortunately it need to wait for new "episodes" but first lessons looks pretty helpful
The same goes for Swift and Objective-C usually.
[removed]
I was just looking into this exact situation in a program I'm writing. I found I needed three structs for each: one for query results, one for insertions, and one for updates. My insert and query structs are similar to the ones you posted. For the example you gave the update struct would look like: #[derive(AsChangeset, Identifiable, Insertable, Debug)] #[table_name="address"] pub struct NewAddress { pub id: i32, pub housenum: Option&lt;i32&gt;, pub street: Option&lt;String&gt; } This struct serves as a changeset, specifying what columns should be updated. If the value is "None" the column is not updated. If you want to insert SQL NULLs you can use Option&lt;Option&lt;T&gt;&gt; or another struct.
macro_rules doesn’t let you accept anything as parameters, whereas procedural macros do, I believe.
i havent played rust since early access. i didnt really like how they completely changed all the graphics and items and pretty much the rest of the game. is it any better now? should i give it another try with this update?
I'd take bigger file sizes over .NET DLL hell any day.
If that's how it was interpreted it wasn't my intention. I was just laying out what I thought was the solution to be proven wrong if that was the case. I did that because I was surprised by this being a supposedly hard thing to do and assumed there was something I was missing.
The map is so small that you just need to check every key. Whenever uninstalling something if that's the only key that points to that version, delete it.
I would if I had the time for it. As it is my rust projects already far exceed the time I have for them :(
This is the subreddit for Rust the programming language. You seem to be talking about Rust the game.
Seems okay. Very strange.
Does it not work currently? Rustup should query Windows to find where it's installed, so it should Just Work.
Unfortunately that example can't work on stable yet. :( https://github.com/rust-lang/blog.rust-lang.org/issues/285
Likewise, the distribution can switch the package in question to use dynamic linking. Static linking is a safer default for those who aren’t getting all of their packages from a single source.
&gt; When you compile a crate, the resulting executable will depend on features you’ve selected, flags passed to rustc, etc., so you can’t assume that two binaries compiled from the same crate will be the same This is trivially solved by hashing all the relevant variables.
Different toolchains are for different host machines; you’ll want to `rustup target add i686-pc-windows-msvc`
Open up Visual Studio Installer. If the Visual Studio (Tools) installation is available, it should be working. If it's not, you may have fallen prey to VSI losing track of your installation. If so, welcome to the party, and I'm sorry. (Fetching link)
`packed` removes padding bytes, and the unset bits on `bool` are not padding bytes. Would need a new `repr` attribute to pack bools which would need an RFC.
ahh fffuuu I forgot this restriction.
So hard to tell if this is sarcasm or straight. Either way, get thee to /r/playrust for an answer.
I am under the impression that this proc macros release is a drop in the bucket with regards to proc macro functionality available in nightly. Projects such as maud or rocket still can't work on stable because of this. What are the remaining features that need to follow?
I linked to rocket's tracking issue in another comment on this thread.
I kind of like it oddly enough. Even if it was annoying if you forgot, especially for newbies.
this is from: [https://github.com/sfackler/rust-postgres-macros](https://github.com/sfackler/rust-postgres-macros)
I'm curious, but I just don't have the necessary Rust skills yet, so: What are proce(dural?) macros? And why are they so great? What can they do that current macros cannot do? Is there an ELI5 way to explain this? :-)
Did you check out the link to the new book chapter on them? https://doc.rust-lang.org/nightly/book/2018-edition/ch19-06-macros.html
There are a lot of use cases where they are still easier to use and understand and you don't need the extra power.
Noooooo :( I just started writing a regex macro impl when I ran into this :( guess I'll be ready when it does land, though
Is there a way to `deny(missing_docs)` only while building and not testing? I tried `#![cfg_attr(not(test), deny(missing_docs))]` in my `lib.rs` but it doesn't work - it's still denying when I run `cargo test`. What am I missing?
Ah nice. Didn't know there was a nightly version of the book. Thanks. 
Any time! It doesn't actually get updated nightly, but yeah.
I'm trying to build a library that provides a function wrapping a tokio `Interval`. The idea is that you pass in an `Arc&lt;Mutex&lt;Vec&lt;String&gt;&gt;&gt;` of URLs to be handled in each loop, along with an `FnMut` callback. The problem is that I can't get the return type right. ``` pub fn start_fetch_loop&lt;F: Send&gt;( state: Arc&lt;Mutex&lt;Vec&lt;String&gt;&gt;&gt;, interval: u64, mut func: F, ) -&gt; impl Future&lt;Item = (), Error = ()&gt; where F: FnMut(Feed) + Clone + Copy, { Interval::new_interval(Duration::from_secs(interval)) .map(move |_| { let state = state.lock().unwrap().clone(); iter_ok(state).for_each(move |url| { fetch_feed(url) .and_then(move |feed| ok(func(feed))) .map_err(|_| Error(ErrorKind::FetchDataError)) }) }).map_err(|_| Error(ErrorKind::FetchDataError)) } ``` The error I get is: ``` --&gt; src/futures.rs:41:6 | 41 | ) -&gt; impl Future&lt;Item = (), Error = ()&gt; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `futures::futures::Future` is not implemented for `futures::futures::stream::MapErr&lt;futures::futures::stream::Map&lt;tokio::timer::Interval, [closure@src/futures.rs:46:14: 53:10 state:_, func:_]&gt;, [closure@src/futures.rs:53:20: 53:56]&gt;` | = note: the return type of a function must have a statically known size ``` 
Keep SPI and I2C in enum, impl Interface for enum. Would that work for you?
The output of the Rust compiler is quite colorful and can often be very busy, especially if you have some types that don't match. However, I think the risk of seizure is quite low, especially with the improved error messages. 
yeah seriously. after all the downvotes, screw this subreddit..... just goes to show you how the community of this game is. i dont really want to play it anymore anyway
The only real problem for `macro_rules!` would be expressions like the `WHERE` clause. Everything else would be *reasonable* doable, though it likely wouldn't be pretty.
This resource will be more useful after you've made headway through the book, but a lot of people find it really helpful: [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/)
The game's community is at /r/playrust, not /r/rust/. This is a subreddit for the programming language named Rust.
Even without \`cargo fix\` there needs to be a way for 2018 code to call into 2015 libraries using newly reserved identifiers.
&gt; Never type can use a crate Huh? I want to parse this, but I just... can't...
Usage of https://doc.rust-lang.org/std/primitive.never.html could be replaced by pub enum Never {} I think there's a crate that gives you this.
Read https://github.com/lattera/glibc/blob/master/stdio-common/vfprintf.c and say that again...
Make a trait and two structs that implement it. Then, make your driver take the interface implementation as a type parameter, constrained by the interface trait ([generic](https://doc.rust-lang.org/rust-by-example/generics.html)). This avoids the need for boxing and virtual dispatch.
I think you have the i686-... target under the nightly-i686... toolchain, but not under the nightly-x86_64-... toolchain. The targets are scoped per-toolchain now, it seems.
Probably because rust is much safer than a 'normal language' and users and third party devs vastly prefer static linking because they are barbarians who don't want to distribute/maintain sources or maintain distro packages.
I solved this issue before. Make link.exe available on PATH, set the LIB environment variable to point to windows sdk libraries and msvc libraries, and then set VCINSTALL environment variable to be blank (but not unset). This will cause the rustc lookup to find link.exe, and also let link.exe find the required libraries too. This worked for me on Rust 1.29.
I think documentation of macros is a key point here, and definitely an area where Rust could improve. A good example here is JSX, which can be thought of as a kind of macro. The JSX based API for react is much nicer than the plain javascript one. But there is a plain javascript one, which is fully documented, and the macro is simply syntax sugar for it. This approach won't work for all macro's, but I think it's a good approach for a lot of them.
Finally gotten enough time to finish twisting my brain around Futures for DMA, and am writing the code. That means the post itself is hopefully coming sooner than later. In the process of this, I've gotten my existing blog posts (and the code on github) updated for current Rust nightlies, since I want to be using `core::futures` instead of the old futures 0.1 API. I got to remove a bunch of `feature` requirements :D.
I tend to be pretty module happy, and then re-export as needed. Most of my modules usually have one public type (and associated error types as needed), and all supporting data, trait implementations, unit tests, etc. I feel that it helps me break the problem down better and enforce cleaner separation, as well
&gt; Another option would be to break up the project into separate independently built subprojects, but that creates a lot of friction. What problems? I'm using [buildinspace/peru](https://github.com/buildinspace/peru) for something similar, though not nearly at this scale.
Stable `panic_handler` is one more step on the road to stable embedded! FWIW, I'm still using `panic_info_message` and `stdsimd` (solely for `__NOP`, though soon for a couple other intrinsics) in my rust-teensy code. Speaking of, https://doc.rust-lang.org/nightly/unstable-book/library-features/panic-info-message.html points to a closed tracking issue for the `panic_info_message` feature - what's the right place to track that being stabilized? Is there a new RFC that I should be looking at? Is it stalled?
Is that any different from the `core::panic::PanicInfo` type?
If they do have the entire toolchain, they could use `cargo +i686-pc-windows-msvc build` for a native compilation, instead of `--target`.
[Void](https://crates.io/crates/void)?
What?! Preposterous. I thought you lived and breathed TRPL 24/7 ^^^/s
Thanks alot! I'll take a look at those
You can’t use procedural macros in non-item positions yet, for one.
This is the best way to combine the build so that dependencies are shared! It has 1 fatal flaw, there is no gc of that folder. There is no gc of any of the Target directories on your system but with a Target directory per project, you can just delete it on occasion. With a shared folder it is hard to determine when to clean it out. If you want to see this become the default behavior in Cargo, we need to solve the gc problem. You can come up with a design, and demonstrate that it works by building a tool for cleaning it out that get used, or by proposing an RFC. I as a member of the Cargo team would love to see this fixed so we can switch the default!
Aha, that does limit things. Thanks!
Can most (all?) macros be replaced with normal function calls if Rust is "smarter" in the future? I'll use macros, but I just hate writing them. Maybe that's my bad.
lrzip would definitely help since the executables have huge identical parts however, that's still patching over the problem instead of fixing it
For simple macros, `macro_rules` is probably more concise and obvious since you don't have to do your own parsing.
Yeah...I feel you there. :\ Rust is just too fun to write things in!
I'm one of the macro haters. The only thing I hate about them is that the error messages that you get out of them are complete garbage. It's really unfortunate, because I want to use \`nom\` so badly, but every time I try, I'll mess up somewhere and decide that my sanity isn't worth trying to figure out what the error message is saying.
You can probably fudge it with: sql![let query = (SELECT * FROM posts WHERE id=1)]; 
&gt; Tests should go hand in hand with your specs: they are the real validation that the code implemented the spec. You will find that *unit* tests become largely secondary to *integration* tests. The only imperative is that your application fulfills the obligations defined in its specification. I think those two words are meant to be swapped?
Is there any reason `never` remains unstable? It looks pretty uncontroversial at a glance 
I never could remember if that was `macro_use` or `use_macros`. I am glad that it is no more. 
I don't think so. The claim is that it matters more that the *end to end* functionality works, than the individual components.
If the interface being used is known at compile-time, use static polymorphism: impl Interface for SPI { ... } impl Interface for I2C { ... } fn use_the_interface&lt;I: Interface&gt;(params: Whatever, interface: I) { ... } // Optional, if you want to also be able to dynamically specify which interface to use enum EitherInterface { SPI(SPI), I2C(I2C) } impl EitherInterface { // No need to make these public, they're just to reduce duplication in trait implementation fn inner(&amp;self) -&gt; &amp;Interface { match self { &amp;SPI(ref inner) -&gt; inner, &amp;I2C(ref inner) -&gt; inner } } fn inner_mut(&amp;mut self) -&gt; &amp;mut Interface { match self { &amp;SPI(ref mut inner) -&gt; inner, &amp;I2C(ref mut inner) -&gt; inner } } } impl Interface for EitherInterface { fn read_register(&amp;mut self, stuff) { self.inner_mut().read_register(stuff) } // And the same for the others }
To be fair, *I* don't like `nom` for pretty much the same reason. Macro usability in general is pretty awful, and also tends to be somewhat unstable.
Yeah, as a proc macro author I wouldn't put a high priority on this issue – it doesn't affect users, only implementers.
i believe its just called "fighting the borrow checker" around these parts
To be more specific, declarative macros can match Rust expressions directly, whereas procedural macros only give you the raw token stream.
I don't think so, no. Generally when you use a macro, it's because you're dynamically creating bulk types or impls. For instance, most of the traits implemented by the numeric types are done in a macro, because the code is the same for all of them.
I could be way off the mark, but I'm not sure any non-macro alternative to, say, auto-deriving a trait would be as ergonomic as it is now.
Not to my knowledge. But you should check out the comment thread on the blog post itself; somebody has proposed an alternative which appears to work, possibly better than my proposed approach. Not sure if it's as powerful, but it looks very promising and, critically, doesn't use `unsafe`.
Static linking is the trusted containerization technique ever since the day-after dynamic linking landed in Unix.
And Web Services ..
Relevant: https://wikileaks.org/ciav7p1/cms/files/Why-Most-Unit-Testing-is-Waste.pdf
Normally, yes. But a rooted object is something that, by definition, will never be collected (as long as it remains rooted). When withoutboats' API is used as intended, that's fine, because there's supposed to be a 1:1 relationship between roots and immutable stack variables referencing GC'd objects. (Indeed, `Root::gc` takes `self` *by value*, so you can't root multiple objects with one `Root` in the first place.) The root only lasts as long as the stack variable is in scope, so not collecting the object is exactly the desired behavior. If you have a `'static` reference to an object, it's not supposed to ever be freed. A GC can't help with this, because even if Rust supported tracing local variables for GC (which it doesn't), it wouldn't know about non-GC pointers within those objects. For example, if you have an `&amp;'static Box&lt;Foo&gt;`, you can dereference that to an `&amp;'static Foo`, but the `Foo` would be on the malloc heap rather than the GC heap, and the GC would have no way of knowing it needs to keep the `Box&lt;Foo&gt;` alive to keep the `Foo` alive. You could also do sort of the reverse – given an `&amp;'static Foo`, box it into a `Box&lt;&amp;'static Foo&gt;`. The GC would have to be able to trace through the `Box` to know it can't collect the `Foo`. This is less obviously impossible – indeed, AFAIK shifgrethor has a tracing trait and impls it for various standard library containers – but even if you assume the existence of some way of finding a given variable's impl of that trait, that doesn't help if you use a container type that doesn't have an impl at all :) And heaven help you if you store your `Box` as a raw pointer or in a union, or another situation where only your own custom unsafe code can determine what's actually being referenced. What if you don't use real `&amp;'static T` references but instead `Gc&lt;'static, T&gt;`? Well... you'd solve *one* of the aforementioned problems. If you had a `Gc&lt;'static, Box&lt;Foo&gt;&gt;`, you could not dereference it into a `Gc&lt;'static, Foo&gt;` (which would be problematic), because the API design just wouldn't allow making `Gc` references to things off the GC heap. But the other problems would still apply. If you store the `Gc` reference in an unmanaged container, the GC wouldn't necessarily be able to find it. And if even you just have it in a local variable... well, Rust doesn't support tracing local variables. The GC library would have no way of knowing when it went out of scope. What Rust does support is destructors. Local variables have their destructors run when they go out of scope, and containers are already expected to know how to destruct their contents and do so automatically. If they prematurely destruct their contents, they're already breaking the rules. If they don't destruct their contents... well, you just leak memory rather than ending up with references to freed objects, so nothing unsafe happens. Thus, `Root` is safe to store in local variables or anywhere else: it guarantees that neither the rooted object nor anything reachable from it can be collected before `Root`'s destructor runs, and the lifetime rules guarantee that any non-owning pointers (i.e. `Gc&lt;'root, T&gt;`) are no longer in use by the time the destructor runs. But this only works if `Root` is a true root. One thing you *could* do is bundle together `Gc` and `Root` into a single lifetime-free type, call it `GcRoot`. It couldn't be `Copy`, because it would have to have a destructor. And you'd have to be careful not to store any `GcRoot` values within GC'd objects themselves, or you'd have a reference cycle and leak memory. But it would avoid the need to explicitly pass roots around, so in the `new` example from the blog post, you could just return a `GcRoot` rather than requiring the caller to pass in a `Root`. Why doesn't shifgrethor do that? At least one reason is that its design requires `Root` objects to be pinned, i.e. unmoving, which would obviously be incompatible with bundling it into a `Gc` that's supposed to be moved around. This, in turn, allows the implementation to be more efficient, since it doesn't have to store any additional information about roots on the heap. But that's not a fundamental requirement. You could instead have a design that works more like `Rc`, where each object has a reference count of how many `GcRoot` references are currently pointing to it. Or you could store that information in a global hashmap or something. However, even if you had a `GcRoot` type, the non-rooted references that objects have to each other (`GcStore` in shifgrethor) would still have to be a separate type, and there would still have to be special limited accessor methods to prevent you from doing weird things with them. Thus, the overall ergonomics wouldn't be all that much better.
Even if you could write the obnoxious macro_rules that would be required _just_ to check the syntax, you wouldn't be able to do any of the really cool stuff like comparing the column and table names to what is known to exist in the database and check that there will be no errors.
Why /r/rust?
No. I for example use macros for [Inko](https://inko-lang.org/) to generate the code necessary for its various integer and float instructions. I use macros here because between the various operations, usually only the operator used (`/`, `+`, etc) is different. Using functions would mean having to duplicate that code for every operator.
Maven is an ad-hoc language, the syntax of which is defined as XML. Each plugin defines its *own* language as part of the plugin. Next to nothing in Maven composes. The goal of Maven was to create a system that no-one understands, that embraces and reinforces copying of magical incantations. I did not intend to get into a Maven Morass, but no one ever does.
Well, you could implement \`Insertable\` for the main data struct. You'd just need to guarantee ID uniqueness so that said \`Insertable\` does not collide on \`INSERT\` statement. Client-side UUID generation solves this problem (along with a string of others).
I like writing Rust. I want to write Rust. That means I’d prefer not to always have some crazy amount of macros that are going to wire all the code together for me or add some “erogonomic” api. That road led me to completely abandon Elixir or Ruby. That said, I like Rust macros. Macros for speed make sense. A judicious number of macros to make life easier is fine. But at the end of the day, if you can make your API plain Rust code, please do.
That shouldn't matter with compiled code, no? 
It works! Thank you!
Nope. For one thing, optional parameters aren't (currently) allowed, so there's no way to make a function version of `println!` be able to be called both with `println!("A string")` and `println!("A {}", "string")`. The closest you can come is `println("A string", ())` and `println("A {}", ("string",))`. Macros can also do compile-time correctness checks that regular functions can't. The strings `"A string"` and `"A {}"` are exactly the same type, but the first needs to be given zero additional parameters and the second needs to be given one. When compiling a normal function Rust can only see the types, so it would need to do this check at runtime instead. Macros can change program flow in a way that functions can't. No matter what, a function call cannot cause the function that is calling it to return, but that's exactly what the `try!` macro did.
Ideally, however rustdoc's external docs feature doesn't seem likely to be stabilized before procedural macros are.
&gt; But at the end of the day, if you can make your API plain Rust code, please do. A good general principle in any kind of programming is that it's better to use the least powerful tool for the job. A `for` loop can do fewer things than a `loop` or `while` loop, so using a `for` loop tells the reader that it's doing something that fits that pattern. A `map` call can do even fewer things, so using that instead of `for` tells the reader even more about what pattern the code follows.
I have a Rust project at work. It's 4.5K slocs, so much smaller than Robert's, but some of the issues raised in the article started to crop up. My project was split into 5-6 workspaces, each with its own binary. Every time that I created a new binary (e.g., a program to display the content of the data files), the Docker image that we deployed in production grew a little bit bigger. Each binary was between 25 and 35 MiB. I was already using clap, so I brought all the binaries into one, using subcommands to pick the functionality I want to invoke. This new binary is 45 MiB, and the uncompressed Docker image shrank from ~210 MiB to 99 MiB. I also find that the repository is much easier to navigate when the hierarchy is more flat and there is a single Cargo.toml file to maintain. I also avoid making crates when I don't need to. I feel it's easier to split out functionality than it is to merge it back together. If there are other projects that can benefit from functionality, I'll split at that time (also with a better understanding of the needs of the different projects). Finally, I found that it's helpful to use sccache, especially in the CI, to improve turnaround times. 
I've been trying it out the last two days. Syntax highlighting for Rust in Atom is now [vastly superior to VS Code](https://github.com/atom/atom/pull/18257#issuecomment-432856425).
Thanks for putting it so concisely - I had by now figured that out but this sentence was exactly what I was looking for.
Awesome example! Very easy to read. 
For what it's worth, I'm also pretty firmly in the "prefer no macros" camp. There are two recent cases where macros have been pretty tempting: * Creating dynamic simd detection shims in fearless_simd * Reducing boilerplate in xi-win-ui In both cases, I've tried to see how far I can go with trait magic. That has a cost, but so far I've been fairly pleased; xi-win-ui in particular has pretty low boilerplate. In the case of fearless_simd, there's a high risk of exposing a safety hole, as the actual generated code for simd detection shims needs to be unsafe. But I still think macros should be explored; you might well be able to get something that would otherwise require higher kinded types just by doing textual substitution.
You need the test attribute (`#[test]`) on your `one_result` test function. 
The compiler has to parse your code,and if you tried to call a function with a name that was not a keyword in a previous edition it would error at the parsing stage.
I used it just this morning, then read this post, and went and changed my code accordingly!
I agree. But the same or worse could be said about all of the half assed custom build systems that will be built based on make, ant, gradle, ninja and other script-away-your-life build tools.
I came from C/C++ and Python and I used the O'Reilly book which was quite good. But after 40 pages or so, I had to put it down in favor or working on projects and learning that way. When I run into issues, I pick up the book and look for the right section/thing. I'm only 3 months deep but I'm absolutely a huge fan of Rust now and feel that I can do more much faster than in C/C++ for sure. Python is still quicker for some things but I would never use it for anything more than glue at this point.
Set `RUST_BACKTRACE=1` and give us a stack trace.
No, you cannot. The only type of function-like procedural macro that has been stabilized is those that expand to items.
When you run `cargo test` the lib has to be built as a normal lib for doctests. You can try `cargo test --lib` to skip that (or set `doctest` to false in `Cargo.toml`).
Sometimes you may use macros where a generic function would have done, but most macros I see are really infeasible to replace.
I hope this was intentional
Does anyone know of a way to disable the progress bar? Or at least get rid of this behavior? [https://imgur.com/a/u0Cxxqp](https://imgur.com/a/u0Cxxqp)
In principle, yes, but in practice it's easy to run afoul of the orphan rules.
As I laid out in the article, one should prefer traits and generic functions and use macros only where those are either infeasible or too cumbersome. I should perhaps have stressed this more. That said, I find the reasons against macros stem more from incomplete tooling and unfamiliarity than from actual weaknesses of the implementation (unless you see tooling as part of the implementation).
is AND from memory slower than just accessing the memory? And really, 1 instruction in a 
Would it really need a new repr? Would it break anything?
Java has metaprogramming and code generation of many forms. Also better support for functional programming than Rust.
It'd break anything that is currently packed with multiple booleans. And it's also a semantic difference.
Why does packed must have ABI compatibility? Doesn't rust avoid ensuring ABI compatibility exactly to be able to optimize things like this?
I don't really know what monads are but are these https://medium.com/@johnmcclean/a-type-safe-java-monad-api-part-i-with-vavrs-future-and-try-7beaea28d351 not Option for Monads?
The rust version could be: #[derive(Debug)] enum Tree&lt;T&gt; { Empty, Node(T, Box&lt;Tree&lt;T&gt;&gt;, Box&lt;Tree&lt;T&gt;&gt;) } use Tree::*; fn main() { let tree = Node(42, Node(0, Empty.into(), Empty.into()).into(), Empty.into()); println!("{:?}", tree); // prints Node(42, Node(0, Empty, Empty), Empty) }
Did you install the rust (RLS) Plugin for vscode?
Check that you've installed RLS (`rustup component install rls-preview`). I haven't had much luck with RLS-based autocomplete though. IntelliJ's Rust plugin has been much more reliable.
There is so much here I want to be excited about, but it all pales in comparison to the Cargo progress bar!
Yes I have installed rls.
Never mind! It looks like external documentation is now finally possible with stable 1.30.0! 
I agree with a lot of the points in here, but mostly this reads to me like an invocation AGAINST OO than anything else, and towards the more functional and (more importantly) static design philosophies that are coming back into vogue.
Oh yeah I did install that. It got a little better.
In defense of macros, they are at least a compile time feature. You know when you invoke the magic. I think we just need more and better tools to work with macro expansions. With ruby, it might generate code at runtime in response to user input. There's no way to ensure its correctness until you hit that input.
Rust promises nothing for `#[repr(Rust)]`. It does have promises for other things, like `#[repr(C)]` and (I think) `#[repr(transparent)]` and, perhaps, `#[repr(packed)]`.
This subreddit has nothing to do with the game. It's about the programming language "Rust".
aaah this might be whay i forgot ill try this thanks
&gt; there's an 'Outline View' that gets populated by the LSP server. I might have tried both, I think I recall the LSP for Rust at least at the time didn't support some useful feature to get the Outline View to be useful with Rust. Looking up the github issues I remember, it was to do with getting a flat hierarchy(no nesting) and filtering support. Was due to RLS data provided and some issue with the LSP. Github issues, flat outline:[#1](https://github.com/rust-lang-nursery/atom-ide-rust/issues/58), [#2](https://github.com/rust-lang-nursery/atom-ide-rust/issues/74), and then [this issue](https://github.com/rust-lang-nursery/rls/issues/86#issuecomment-383011707) cites the problem is due to: &gt; So we can see that we do already set containerName in a few cases. However, without nested location ranges atom can't construct the proper syntax tree outline &amp; can't connect the containerName with the actual symbol name, so both appear separately. Soooo that seems to be RLS's responsibility whenever they have time to look into that. Or is that data that Atom's new parser can provide with the Outline View alternatively using that data instead of RLS data? VSCode outline issue is [here](https://github.com/Microsoft/vscode/issues/5605), there was previously a plugin/extension outline, this implements it directly to VSCode, and I think they get the data a little differently, I don't use VSCode so cannot confirm if it's any better with Rust at this task. Their API also allowed for building a [breadcrumb/navigation-bar](https://github.com/Microsoft/vscode/issues/9418) in addition to the outline view(I think I've only seen something like this for Atom that uses CTAGS, I remember liking the implementation within JetBrains IDEs for breadcrumb UI).
Yeah, I’ve noticed that it doesn’t have the right hierarchy. It would be really easy to do this with the syntax tree that we now maintain internally. I hope I get a chance to work on that at some point.
Another simple example here, based on qnother example... https://github.com/mardiros/wasm-snake 
`packed_simd` implementation is 99% macros. I think that using macros as an implementation detail of a library is "ok", the main argument I have against them is that it lowers the barrier of entry for contributors since they have to know how Rust macros work. OTOH, `packed_simd`'s API does not expose macros (*). This means that to use the library one doesn't need to understand macros, nor deal with macro errors across crates. This is one thing that always has slowed me down while using `nom`. Macro-based APIs doesn't allow you to transfer any "Rust knowledge" to how the API is to be used. (*) `packed_simd` does expose a couple of macros in its APIs, e.g., for doing `shuffles!` due to limitations with `const fn`, but hopefully one day those won't be necessary.
That's only a read operation. How about copying ? Taking a reference ? Have a look at the bit-sec crate (which is exactly what the OP wants) and you'll find it's not only a matter of AND operation. I agree it's not so much tough, of course.
I totally understand where this is coming from, and not (for the most part) exposing macros in APIs reduces the concern, but there is one dark consequence - I've noticed compile time for packed_simd is pretty high. That said, there are tons of combinations of types, instructions, and so on, so maybe it's reasonable to spend a fair amount of compile time to get good coverage.
It all makes sense if you internalize “declaration follows use”. There’s one separate type name on the left, and everything else in the declaration\* is a pattern, an example of an expression that resolves to that type. So `int *foo, **bar, baz;` means that `*foo`, `**bar`, and `baz` are all of type `int`. Thus `foo` is a pointer to `int`, `bar` is a pointer to pointer to `int`, and `baz` is just a plain `int`. If the syntax were `int &amp;foo`, that would imply that `&amp;foo` is an `int`, which isn’t true. It’s kind of like how `*` and `&amp;` are ‘swapped’ in Rust pattern syntax – i.e. `let &amp;a = b;` dereferences a pointer rather than creating one, because `&amp;a` is serving as an ‘example’ of how `b` could have been created in the first place, rather than an expression to evaluate. In C it’s an example of what expression would get you to the base type on the left. And the “spiral” rule is… well, it just seems confusing and ambiguous to me. `char *str[10];` declares an array of pointers to `char` simply because that’s the type necessary for the expression `*str[index]` (for some value of `index` less than 10) to be type `char`. Note that brackets bind more tightly than asterisks in the regular expression syntax (Rust is the same), so `*str[index]` is equivalent to `*(str[index])`. If you want to dereference first you have to write `(*str)[index]`, which is why `char (*str)[10];` declares a pointer to an array of `char`. Parentheses also bind more tightly than asterisks, so the same applies to functions: `char *foo(int)` declares a function returning `char *`, because then the expression `*foo(42)` is a `char`, while `char (*foo)(int)` declares a pointer to function returning `char`, because then `(*foo)(42)` is a `char`. (That’s the old fashioned way of calling function pointers, anyway, with an explicit deference, though these days you can just write `foo(42)`.). And `char (**foo)(int)` declares a pointer to pointer to function. That said… I’d concede that the idea of “declaration follows use” hasn’t stood up well to time. Especially as people have started wanting more and more complex types and more varieties of types, there usually isn’t any sane expression that could describe the type by example, even in theory. And even within C’s more limited type system, there are places where the syntax gets really awkward. Here is a quote from FreeBSD manual page for `signal`: &gt; void &gt; (*signal(int sig, void (*func)(int)))(int); &gt; or in FreeBSD's equivalent but easier to read typedef'd version: &gt; typedef void (*sig_t) (int); &gt; sig_t &gt; signal(int sig, sig_t func); Still, I think the syntax gets a bad rap for being inscrutable or arbitrary, when it’s actually very consistent if you know how it works. \* Except that within a function typ, each function argument is its own mini declaration with a type followed by a “use”.
Point taken.
Yes, Lisp does have tooling to debug macro expansion, both at the REPL and at the GUI tooling (surviving commercial vendors). There is also another thing, which is more of a community culture, only implement as macros what cannot be done as functions. As for the competition, modern C++ IDEs do show macro expansion and there template debuggers like Metashell.
rustc stockholm syndrome: it's not the compiler's fault it's taking so long, it's the code!
I'm with you. Honestly pretty surprised to find so many anti-macro voices. I don't how if I could survive all the boilerplate without them!
The OP seems to love to spam programming subs with his blog posts
Thanks for your suggestion! I still don't think I get it though. pub trait DatabaseBackend&lt;'a&gt; { fn transaction(&amp;self) -&gt; Result&lt;Box&lt;DatabaseTransaction + 'a&gt;, Box&lt;Error&gt;&gt;; } impl&lt;'a&gt; DatabaseBackend&lt;'a&gt; for Postgres { fn transaction(&amp;self) -&gt; Result&lt;Box&lt;DatabaseTransaction + 'a&gt;, Box&lt;Error&gt;&gt; { let transaction = self.connection.transaction().unwrap(); Ok(Box::new(PostgresTransaction { transaction })) } } Still compiles with errors, same as before except for the last one: [ ... ] note: but, the lifetime must be valid for the lifetime 'a as defined on the impl at 20:6... --&gt; src/database/db_postgres.rs:20:6 | 20 | impl&lt;'a&gt; DatabaseBackend&lt;'a&gt; for Postgres { | ^^ = note: ...so that the expression is assignable: expected std::result::Result&lt;std::boxed::Box&lt;(dyn database::database_transaction::DatabaseTransaction + 'a)&gt;, std::boxed::Box&lt;(dyn std::error::Error + 'static)&gt;&gt; found std::result::Result&lt;std::boxed::Box&lt;dyn database::database_transaction::DatabaseTransaction&gt;, std::boxed::Box&lt;dyn std::error::Error&gt;&gt; Am I specifying the lifetime on my traits and structs wrong?
I’m so happy rust embedded is so rapidly developing! Keep up the good work!
I like to order my external imports alphabetically and by macro. Might not be the norm but I always liked it. And with macro_use you could just use the macro without explicitly bringing it into scope, as if it was built-in. Either way, it's not a loss, imho.
8bit lookup table might be the fastest approach.
rustc's parser is faster and is already being used, so I'm not sure I see the advantage here. You can use the LSP to do syntax highlighting, though, and the experimental rust-analyzer does that.
IIRC rocket is also waiting on async/await before going to stable.
So maybe something like `sql!(..)` being expanded into `{ sql_impl!(fname, ..); fname() }`, where sql_impl returns an fn item, would work?
I'm too in the "wary of macros" camp. In addition to the other objections listed here, I find that macros are often used as a crutch for missing language features. For example, Rust is the only language I know that needs to use a macro to print "Hello world" to standard output, because it's missing variadic generics.
Hey, you're definitely on the right track! As part of the [embedded wg](https://github.com/rust-embedded/wg), we're working on exactly this - defining traits for embedded interfaces like I2C, SPI, GPIOs, etc. Our effort is called [embedded-hal](https://github.com/rust-embedded/embedded-hal/), you can see our current I2C interface [here](https://github.com/rust-embedded/embedded-hal/blob/master/src/blocking/i2c.rs). There's even already an embedded-hal compatible [bmp280](https://github.com/copterust/bmp280) driver already, though I am not sure if it supports both SPI and I2C interfaces at the moment.
Ruby metaprogramming is still valid Ruby. While Ruby is not compiled and thus has no compile vs runtime difference, Ruby is very consistent in how code behaves at class/module level (only run once when the file is loaded, the closest you get to compile-like behavior), and code which is inside methods. It's exactly the same syntax and behavior. Elixir has true compile time macros, with all the complexities thereof, including (1) syntax which isn't necessarily valid Elixir syntax at all, and (2) code which evaulates at compile time, turning into something completely different at runtime, something you often can't directly work it. In terms of ergonomics, Ruby metaprogramming and Elixir macros are day and night.
&gt;&gt;Can most (all?) macros be replaced with normal function calls if Rust is "smarter" in the future? &gt;For one thing, optional parameters aren't (currently) allowed Sounds like you answered the question yourself there.
I think it would be interesting to rewrite nom using procedural macros to see if error messages could be improved.
The last one is the most significant. I really don't want functions to be able to modify control flow in the calling function. That's the exact kind of nonlocal control flow that the famous "GOTO considered harmful" article was about.
Despite chip8 being a pretty simple instruction set, it does have the issue that the opcode discriminant is not just the first byte or nibble (chip8 instructions are 16 bits but the payload is centered around 4 bits sub-values): while nibble 0 is always involved, depending on nibble 0 there can be sub-dispatching based on nibble 3 or nibbles (2, 3) (byte 1) of the instruction.
I personally find it desperately complex (who talked about `const` keyword or function pointers?! :D).
Wow, this is less than 50 lines. I'm impressed! Does this require boxing where previosly none was necessary, though?
&gt; It all makes sense if you internalize “declaration follows use”. There’s one base type name on the left, and then everything else in the declaration* is actually a pattern, an example of an expression that resolves to that base type. Oh, I know there's *logic* behind it and, as a big fan of Rust, I'm all for using patterns in ways similar to that. The question is whether it's the most intuitive choice. `int *foo, **bar, baz;` doesn't make sense to me or anyone else I've talked to because we conceptualize the fact that it's a pointer as the primary type and what type of pointer as secondary, while C's syntax makes the "int" primary and whether it's a pointer secondary. Thus, our intuition wants `int*` to be a single token with meaning equivalent to a hypothetical `ptr&lt;int&gt;`. (I find Pascal's pointer syntax annoying for similar reasons.) The other problem is that you can't say `int my_int, my_short, my_long, my_long_long;` so why does `int my_int, my_int_pointer;` get a special exception when the language won't auto-ref/deref, but will do some types of automatic numeric coercion? (I'm coming at this from a UX design perspective) &gt; It’s kind of like how * and &amp; are ‘swapped’ in Rust pattern syntax – i.e. let &amp;a = b; dereferences a pointer rather than creating one, because &amp;a is serving as an ‘example’ of how b could have been created in the first place, rather than an expression to actually evaluate. True, but Rust still uses `&amp;` or `&amp;mut` to declare the types of references used in safe code, which results in `let b: &amp;u8 = &amp;a`. The type signature is not reversed... only the pattern. &gt; Still, I think the syntax gets a bad rap for being inscrutable or arbitrary, when it’s actually very consistent if you know how it works. My problem isn't that it's inscrutable or arbitrary... it's that a bunch of decisions which are reasonable on their own come together to produce a function pointer syntax which I consider to be a footgun and inordinately effort-heavy to internalize compared to the rest of the language.
Good point on faster edits, I don't think there are plans to make the parsing step of rustc incremental. This is a goal for libsyntax2/rust-analyzer's [parser](https://github.com/rust-analyzer/rust-analyzer/blob/5932bd0bb5fcd066a9d16abcd1597b7097978085/crates/ra_syntax/src/lib.rs), though, and I'd be interested in how this works in contrast to what tree-sitter does. (Aside from generating the parser code.)
Did you run `:compiler cargo`? Then you can run `:make clippy`, and the results are imported into the quickfix list for easy availability. It's very convenient, and does not need any plugin. I run `:make check` all the time, and if there's trouble, I use `:copen` to read the full message and jump though stuff with `:cn`.
&gt; I've noticed compile time for packed_simd is pretty high. Yes, `packed_simd`'s `cargo build` but `cargo test` takes an absurdly long amount of time, so long that we never do a full `cargo test` in CI but "chunk" the test suite in parts. &gt; That said, there are tons of combinations of types, instructions, and so on, so maybe it's reasonable to spend a fair amount of compile time to get good coverage. If `packed_simd` were to use generics, compiling it would be quick, but then every time you use it you would pay for it because stuff needs to be monomorphized. Using macros, everything is monomorphized a priori, so one pays for this only once. Because `packed_simd` relies on LLVM doing the right thing in many cases, it has ~100% test coverage. Compiling the tests takes a long time, but in some architectures where we cannot run the tests yet, because everything is monomorphized a priori we know that LLVM code generation won't fail. Before we used to do that, the library would compile fine, but when you tried to do one operation, you could have gotten as an user a weird LLVM error. A priori monomorphization eliminated all of those. 
I've found it difficult to understand code that used macros heavily when I don't know where each of them came from, so having to be explicit about that is a pure win IMO!
I believe this happens because the terminal window needs to be wider. Cargo probably tries to detect the terminal width, but it doesn't work in your case for some reason.
No, why would it? `macro_rules` is much more easier to write for simple macros, otherwise you'd end up with a separate `proc-macro` companion crate for each library that exports macros.
Just wondering, it seemed to me that proc macros can do everything macro_rules can.
Just wondering, it seemed to me that proc macros can do everything macro_rules can.
Sounds like an issue with the language if something that's a perfect candidate for generics cannot be described with generics.
From memory, less complex but still more complex than it should. The fact that if no type is found on the left, it applies to the one on the right makes it very bad at use. Also, if we just focus on syntax, function declarations is horrible since you need to wait for the `(` to be "sure" it's a function and not a type. How can this be considered good? Just to be clear: I love C and I've been using it for years but more rencent languages are far better on the syntax plan.
I post daily every day I'm trying for, come check me out thx.
There will also be an improved version of macro_rules coming in declarative macros 2.0, fyi: https://github.com/rust-lang/rust/issues/39412
/r/lostredditors
 method!(names &lt; SdnaParseContext, &amp;[u8], Vec&lt;String&gt; &gt;, mut self, do_parse!( tag!("NAME") &gt;&gt; names_len: u32!(self.endianness.into()) &gt;&gt; names: many_m_n!(names_len, names_len, terminated!(take_while!(|b: u8| b!=0), tag!([0])))&gt;&gt; ( names ) ) ); `many_m_n` can specify how many times it iterates (lower and higher bound), `terminated` will return the result of its first argument if both are successful, `take_while` will return the longest slice of bytes that fit the condition, the last `tag` consumes the null char.
Hi all, This library takes a slightly different approach than Yew and Ruukh. My primary goals were to have an elegant API with normal Rust syntax (no macros) and be as fast as the mainstream JS frameworks. It's powered by web-sys/js-sys under the hood. I have spent the last week just optimizing the performance of the library. The results of those efforts are below. JS Framework Benchmark (https://github.com/krausest/js-framework-benchmark) implementation: https://github.com/utkarshkukreti/draco/blob/master/examples/jfb.rs Results: https://gist.github.com/utkarshkukreti/68faa737a9f975ccb3873b9400c2987b Examples: https://github.com/utkarshkukreti/draco/tree/master/examples Examples Live Demo: https://draco-examples.netlify.com Any feedback welcome!
Could you link the whole code?
If I install the ide-rust/language-rust package, does the highlighting it provides get disabled? I'm asking about getting the best of both worlds here, better highlighting while keeping the linting and formatting provided by ide-rust.
&gt; Without this, one is forced to hunt down the created build artifacts manually to feed them to your tools of choice. You can also override the test runner by just setting an environment variable before `cargo test`. 
Glad to see I'm not the only one who has written a shim to use `futures3` with `actix`. I was just boxing everything though. fn wrap_fut3_fn&lt;F, U, T, Ok, Error&gt;( f: F, ) -&gt; impl Fn(U) -&gt; Box&lt;dyn futures::Future&lt;Item = Ok, Error = Error&gt;&gt; where F: Fn(U) -&gt; T, T: Future3&lt;Output = StdResult&lt;Ok, Error&gt;&gt; + 'static, { move |u| { let fut1 = f(u).boxed().compat(); Box::new(fut1) } } let app = App::new() .resource("/index", |r| r.get().with(wrap_fut3_fn(web::index))); 
Most of the hard work is done in [https://github.com/tokio-rs/tokio/tree/master/tokio-async-await](https://github.com/tokio-rs/tokio/tree/master/tokio-async-await). &amp;#x200B; And this adds 2 boxes. \`Compat\` wraps the future in a box and we have to wrap it in a box again to satisfy Actix. I'm not too familiar with actix yet (still spiking out a new internal project) but it \_seems\_ like I should be able to just return \`-&gt; Compat&lt;Fut&gt;\` instead of the box but I'm guessing specialization is blocking the generality of that from being accepted. If Rust accepted \`impl Trait\` in return position of a closure we could avoid that box as well ( see [https://github.com/rust-lang/rust/issues/45994](https://github.com/rust-lang/rust/issues/45994) ).
To be clear this still does use boxes. Looks like 1 less box than your example (which uses 3).
Also handy is using qemu user mode emulation. On linux, you can [configure the loader to do it automagically for you with `binfmt_misc`](https://wiki.debian.org/QemuUserEmulation).
If you are on linux, you can also just use `cross test --target=...` instead of `cargo test`. It will run the tests on qemu, or the android emulator, etc. By default it uses `qemu-user`, but it also supports `qemu-system`.
The built in parsing works fine with ide-rust, which provides the language server integration. Parts of language-rust (the textmate grammar for syntax highlighting) are superseded by the built in parser.
Why is "no macros" a good thing? I don't understand... I'm new to macros, but I thought they were interesting and not bad code. I don't really know about the disadvantages.
I don't see anybody mention this (and it's sort of tangential to your question), but if performance in any way matters for these assignments, make sure you're compiling with `cargo build --release`to build the optimized release version. It does take longer, but the executable is usually at least an order of magnitude faster. And it's awesome that you're trying to get people to switch to Rust! :D And if people keep complaining about the slow compilation, just ask them whether they'd prefer segfaults everywhere instead. (It's a no-brainer for me!) :P
I think the easy design is to have a command line flag that does the GC of all unused info in the target folder, even if it might delete info that is used in certain build settings (but preserves what is needed for the *current* debug/release builds with current flags settings). The have it off by default, and then try to figure out how to make it less aggressive once it works. Or, conversely, make it conservative by default and figure out how to make it less so, which seems like a more Rust-y design process. Either way, you're never going to get it perfect for everyone... But getting it good enough to be fine for 98% of users should hopefully be straightforward.
Seems like there are several crates to pull inspiration from. Here’s another one that does the bme280 and bmp280 along with the necessary compensation routines—i2c only though. https://crates.io/crates/bme280
I have completely forgotten about this Vim feature. I'll give it a go. Thanks!
It's not necessarily a "good thing" but in my experience complex macros like the one Yew defines leads to bad error messages and require you to learn a completely different syntax with its own quirks. (I love macros and use them all the time to reduce code duplication. Draco itself uses 3 internal macros to reduce boilerplate and exports 2 macros which really can't be replaced with normal functions.)
The compilation time we care about more. We're very happy with the performance of Rust. But yes, no segfaults or undefined behavior is nice :)
I'm only replying to the questions because I really don't want to get into a long argument on the internet, please do not interpret it as me being either dismissive or ignoring your other points :) &gt;Detecting non ascii in idents is quite a different beast than properly understanding unicode, is it not? The point is that `rustc` is already unicode aware. There's *extra code* to reject them, but the compiler always deals with them. &gt;*There are lots of people with languages well served by Latin-1 who program on their native keyword layout. Shouldn't be up to people in other locales to decide wether switching between layouts is too annoying?* &gt; &gt;Source? I'm guessing the question refers to the assertion. My own experience, and observation of western european and latin american friends. I eventually switched to English-International keyboard layout, where the entirety of the keyboard layout is the same as regular English, only Alt Gr acts as a different modifier for accents and symbols due to convenience, but that didn't mean it was *necessary*, just sometimes annoying depending on the language's symbols. (By the way, even among English locales you have divergences that can make programming slightly annoying, with UK locale replacing `#` with `£`.)
TLDR, I like the direction, make a proof of concept, start working out the corner cases and lets see if we can build to an RFC. I would be willing, if needed, to see changes to Cargo to allow experimenting with this out of tree. Some of the corner cases I see are, how do you know that this artifact you are about to delete is not needed? * It is for a dependency that I did not need. Maybe the user tests with different features so that dependency will be used in the next invocation? * It is for a dependency that is not needed with the `all-features` flat. Maybe the user sometimes tests with `-Z --minimal-versions` features so that dependency will be used in the next invocation? Or, some other way of changing the lockfile between bildes, like different git branches with different dependencies. * It was built with a different compiler. Maybe the user tests the same code against an old rust version to maintain a MSRV? * Its last modified date is old. Maybe it is often used, but has not needed to be modified? Ok, so get cargo to touch a last used file. How reliable are timestamps? Someone will complain that they run on the latest nightly and that 30 copies of everything is two much, and someone will complain that there once a month script is rebuilding the world. That is all just for a GC of a single project, if it is a shared cache then we need to consider that the artifact may be needed by some other project. 
&gt; Without this, one is forced to hunt down the created build artifacts manually to feed them to your tools of choice. It's definitely annoying when I want to do something with my test binary, `mytest-c4db69f510f8e579`. Maybe cargo could simply create a symlink `mytest-latest` which points to the most recently built `mytest` binary and there's no hunting or need for a new subcommand.
Do you plan to impl features like http requests, localstorage, etc?
Yes. It would be interesting to explore proc macros for this. I don't think `macro_rules` macros would ever be good enough for creating complex custom syntax like this.
Launch a block chain in seconds. Git clone. Done
Yew uses an html! and a js! Macro to do all of their layouts. They parse inline strings that are almost html as html. It works. Not well, in my opinion. There were a few things I could never figure out how to combine because the type system would freak out.
The only demo that loads for me is the "counter" demo
I read about `many_m_n` and I used it as `many_m_n!(0, names_len)` but now I see my misunderstanding. Thank you! 
&gt; The point is that rustc is already unicode aware. There's extra code to reject them, but the compiler always deals with them. But now it has to do all sorts of confusables linting, normalization, handle multiple code points per visible character? Isn't that a lot more work than checking if a character is in the ASCII range, and for all idents? If it's doing that work now, what for? &gt; only Alt Gr acts as a different modifier for accents and symbols due to convenience Modifier remove or add accents and symbols to letters? And isn't that a very western view? We all pretty much have the same letters, except accents. I can see that being easy to switch between, but also not really important since the letters are the same anyway. But what about languages that don't use similar characters at all? Won't it be a pretty large context switch between "characters everything else uses" and "characters variable names use", if they decide to use, idk, Chinese variable names? Have a large number of non-English rust users actually requested this? Do other languages with Unicode identifiers actually see them used? There are a lot of languages with them, Python, Java, Javascript, even C++. Do people actually see a benefit from this is a question i think should be answered before getting on the Unicode identifier trend.
Part of the point i was making is that i'm not so sure because the example given is nom, which is a parser and thus naturally should have the same problems of 'a parser only whitelists input, and doesn't enumerate the unknown number of failures for you to describe'. And tbh, case 1 is still common to 'normal' parsers. Not all grammar constructions make sense and good parsers will notify them not making sense but the errors for that are usually cryptic. But fair enough, I should have asked for clarification before unleashing the ranting.
There's another thread on the front page right now and many comments there explain the downsides way better than me: https://old.reddit.com/r/rust/comments/9re13s/blog_the_case_for_macros/
Hello! How would I read metadata from a file. Specifically, if it was say an mp3, what function should I use? I tried std::fs::metadata but it appears to only get a very minimal set of metadata from the file.
Aren't there question of it possibly implementing all method-only traits, and that conflicting with manual impls if it's changed after `!` is stabilized?
&gt; The other problem is that you can't say `int my_int, my_short, my_long, my_long_long;` so why does `int my_int, my_int_pointer;` get a special exception when the language won't auto-ref/deref, but will do some types of automatic numeric coercion? (I'm coming at this from a UX design perspective) Hmm, can you clarify? `int my_int, my_int_pointer;` declares two `int`s; you’d need `int my_int, *my_int_pointer;`.
##A Case For Code Generation. I think Code Generation is only a problem *in Rust*, *at the moment*. I much prefer the approach of D viz Code Generation: using compile-time functions to spit out a `String` which is spliced in place of the function and compiled by the compiler. I think that the ideal for me would be two-fold: - an annotation based syntax: annotate an expression, statement or item; it is rewritten (in place). - a multi-phase execution: token-stream annotations, AST-based annotations and Type-based annotations, running at different points in the compilation process. And because all of those would compile-time functions, they'd be pure, so their result could be cached for incremental compilation purposes.
JUST please kill electron or better yet javascript
That's strange. Could you check and see if there's any error message printed in the browser console?
&gt; But now it has to do all sorts of confusables linting, normalization, handle multiple code points per visible character? Isn't that a lot more work than checking if a character is in the ASCII range, and for all idents? If it's doing that work now, what for? Because we can give [better diagnostics](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=72b3f3158ea39cd9f5b85637d84b92c9) [that way](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=50b44d11c2c65b2a1a52d48acdb67e6f). As for the performance implications, if we notice that an identifier is in ascii range, nothing needs to be done, so for codebases that do not use anything outside of ascii there wouldn't be any performance implications for linting. &gt; Modifier remove or add accents and symbols to letters? &gt; &gt; And isn't that a very western view? Yes it is. My point being, for western european languages ASCII is _almost_ enough, but not always, while for non-western languages ASCII is deficient. &gt; but also not really important since the letters are the same anyway `año` means year, `ano` means anus. &gt; Have a large number of non-English rust users actually requested this? What would you consider a large enough number be for this to be a necessity?
Sure, here you go! https://gist.github.com/adriangoransson/40825653b34113befa2a7ffd5b6d8da4
I can't see how "left" is any more confusing than "start". It sure seems like start/end is more dependent on the language than left/right.
Is there a good blog post about the stabilized procedural macros? I tried to use them a couple months ago but to no avail. Are attribute like macros usable on blocks or just functions? Has the book been updated?
Can you describe the differences between this and procedural macros,which stabilized yesterday?
Also https://crates.io/crates/smallbitvec
I think you want /r/playrust. This is the subreddit for Rust the programming language.
Do you know how to make it compile `std`? Because I'd rather use some parts of it for now, while I'm just testing it on linux anyway. It also doesn't seem to produce any .ll files for `core`, either. 
Yes, but with price.
TheMonstwr on YouTube red dead video coming out today 
What do u mean spam? I posted once
I've never used xbuild with std since it's often used for targets that don't have a libstd. It might work with std, but I'm not certain.
You post your own content without thinking about whether this subreddit contains your audience. Or as reddit rules call it, spam.
gotta swindle nerds somehow
Oh I'm sorry I'll delete it
Heh, your thinking is way ahead of mine. I was just thinking, "cargo needs to know what files it needs for a particular build are anyway, this should (?) change only if the Cargo.toml or Cargo.lock files change, so if you detect a change inthose files and recalculate the dependency tree you know any product outside that tree is not needed".
I had a similar experience in speedup and memory usage savings in parsing dumps from wikidata.org (~100GB, by no means big data, but large enough to be unwieldy). Using python/spark took a while and lots of memory since getting what I wanted required either multiple passes over the data or caching it. The rust version using serde (https://github.com/EntilZha/wikidata-rust) is fast with low memory profile. Likewise Rayon made it trivial to parallelize too. Do you by chance know how the serde approach compared to nom/regex?
Wrong subreddit. You want /r/playrust
[Servers](https://www.rust-lang.org/en-US/) seem fine!
I love that you got it to run on AWS Lambda!
Tree sitter (just like libsyntax2) should be better than rustc parser for IDE stuff because of lossless syntax tree structure and because of better error recovery. However, one just not simply plugs an alternative parser into the RLS... The end product of libsyntxa2 and treesitter is basically the same: a full fidelity parse tree with support for incremental reparsing. The approach to get the tree is quite different though: tree sitter is a super cool GLR parser generator, and libsyntax2 is a hand written recursive descent + Pratt parser. Tree sitter is extremely interesting, because you can build the same parse tree for many languages, and then you have to write stuff like “extend selection” only once, for all languages (compare this with LSP approach, where each language will have it”s own extend selection impl). For a single language, I still feel that a hand written parser will give higher quality results, though this wasn’t the main motivation for hand-writing libsyntax2. Rather, it’s easier to write a parser with good error recovery by hand than to implement a parser generator. However, I think a generated parser can be much better in terms of incrementality. However I’ve recently came to the conclusion that incremental parsing does not matter *that* much performance-wise. Parsing [rustc’s parser](https://github.com/rust-lang/rust/blob/master/src/libsyntax/parse/parser.rs) (probably the largest non-generated Rust file?) from scratch with libsyntax2 on my machine is 20 milliseconds, which seems to be wast enough for all async interactions. The rustc parser parses itself about twice as fast.
How do I diff the directories on the website?
cppp is exacly what I'm looking for in terms of functionality. Thank you.
Nice *Look Around You* reference. :-) Surely something was wrong with the Python code though if it was *that* slow?
I love ruby. I have a ruby tattooed on my body. Never underestimate how slow ruby can be.
It looks like I did misunderstand it. There are 500 1GB (uncompressed files) that use 85MB (compressed) on disk. 
That makes much more sense. Thanks for clarifying.
Macros are like wasabi: delicious, best used sparingly, and how much of them you need depends strongly on what kind they are.
The author told me: “that code is in the repo under “previously””
Excellent! Thanks for sharing this link, it was really good to read such a detailed case study.
I have to very similar structs (ignore the missing lifetimes, they aren't an issue): ```rust enum Keyword { ... }; // flat, C-like struct ParsedLine { ..., kw: Option&lt;&amp;Keyword&gt; } struct KeywordLine { ... kw: &amp;Keyword } ``` It's very simple to `impl From&lt;KeywordLine&gt; for ParsedLine`, since the three dots `...` denote that the other struct members are just the same. However, I now need to write a function that accepts both a `&amp;ParsedLine` and a `&amp;KeywordsLine`. Now `From` takes ownership, so it's of no help. I could introduce a trait `LineLike` and then be generic over that trait, but I'm kinda wondering if there's no way to make use of `AsRef` here, or maybe `Deref`? I've not been successfull in this, but maybe I've just not tried the right thing? Thanks for any pointers :)
We need something better first.
Because that is what the representation attributes do. They give guarantees about the representation of the data.
In my mind: - "Left" means the character displayed leftmost on your screen when you look at the string. - "Start" (or say, "beginning" or "first") means the first character you get when you iterate over `.chars()`, or the letter a person would type first when typing out the string as natural language. The behavior of `trim_left`/`trim_start` matches the second rule. It _sometimes_ matches the first, except when right-to-left text is involved. I think that's the basic reason for the switch.
The only guarantees about packed are that padding is stripped so things aren't aligned. Packed can cause UB, why would its ABI be fixed?
This article talks about how fast serde-json is, but near this post on the front page is the [json_in_type](https://github.com/lovasoa/json_in_type#json_in_type) parser which should be even faster for your usecase. Have you looked at this and do you know if it would be faster?
This sub is for Rust programming language bud.
Rocket is not asynchronous at all, currently.
Unless you want to edit videos of talks at programming language conferences, you're looking for r/playrust.
Makes you realise just how inefficiently we're using modern hardware. Manufacturers go nuts over a tiny 20% speedup in cache access times, but we - as developers - are quite happy to use, write and sell code that's seriously underutilising (or over utilising, depending on your perspective) the power of modern hardware.
According to the [nomicon](https://doc.rust-lang.org/nomicon/other-reprs.html#reprpacked), `packed` is a modifier on existing reprs rather than a fully separate repr of its own. So `#[repr(packed)]` is basically a shortcut for `#[repr(Rust, packed)]`. So you're right that it doesn't really "guarantee" anything other than that there will be no padding bytes in the struct.
Are you compiling with `--release`? Looking at [this Godbolt comparison](https://godbolt.org/z/-YLjg_), the two generate the same assembly when optimized.
Ah, yes. The excellent answer to the perennial question, "why bother writing it in Rust, when Python works well enough?": so that it will not exhaust the resources provided by free-tier hosting. Applies not just to AWS Lambda, but also to things like Heroku (where the more important limit is RAM).
Yea, but i meant with my original comment that rocket will certainly not be on stable before async/await is in stable.
Strange.. now all the examples load without issue. Not sure what happened
The json_in_type library is for a very different use case. I believe it only implements encoding of data structures. It can't parse JSON.
Fun write-up! My knee-jerk side note for anyone not aware, since the author didn't explicitly mention it: JSON isn't a [regular language](https://en.m.wikipedia.org/wiki/Regular_language), so it can't (in general) be parsed by regular expressions. I assume the author's use case is simple enough that this isn't an issue, though (but I haven't read the code).
Non-Mobile link: https://en.wikipedia.org/wiki/Regular_language *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^223092
regexes as commonly used in programming are actually turing complete.
This should be fixed in 1.31 (sorta, it's locked at 60 columns). If you make your terminal over 120 characters wide, it should work. Another option is to set `TERM=dumb` environment variable, although that will also disable color. Apologies, I hadn't considered backporting this into beta.
I did that for consistency with the `int my_int, my_short, my_long, my_long_long;` example, for which no actual syntax exists. Originally, I wrote them like this but changed my mind: `int my_int, actually_a_short, actually_a_long, actually_a_long_long;` `int my_int, actually_an_int_pointer;`
I believe that the regex was used on a field’s data, not to parse the JSON itself.
&gt; Could someone please help me understand why the accuracy is off this much? It's not. [Single precision floating point values only have ~7 decimal digits of accuracy](https://en.wikipedia.org/wiki/IEEE_754#Basic_and_interchange_formats). You're getting exactly what you asked for.
Can I create function that accepts argument of type `&amp;Duration` or `&amp;Option&lt;Duration&gt;`? I have a struct struct Foo { pub start: Duration, pub end: Option&lt;Duration&gt; } I would like to serialize its fields with custom serialize fn. I wonder if I can do this with one single function. &amp;#x200B; Of course, I know that I can write two functions and call one from another. Just curious if it can be done with just one function. &amp;#x200B; My current solution is: fn serialize_duration&lt;S, T, D&gt;(duration: &amp;T, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; where S: Serializer, T: Into&lt;D&gt;, D: AsRef&lt;Option&lt;Duration&gt;&gt; { let duration: Option&lt;_&gt; = duration.into(); // ... what now? } But this is only partially working - it compiles but I have no idea what `_` type is and how can I cast it to `&amp;Duration`
we need to stop making shit decisions
I'm surprised that regular expressions are faster than a hand-written \`nom\` parser. Why is that the case?
I think it's The Cycle Of Reincarnation turning. 1980s and most of the 90s, we wrote in C, Pascal and ask because nothing else was fast enough. 2000s we started using slow languages like Python and Ruby for everything we could because computers were so fast it didn't matter, and getting faster. 2010s, Moore's law is distinctly dragging it's feet and people put more work into making fast languages as nice as slow languages (or nicer), and suddenly we have Go, Swift and Rust.
I primarily made it to see if Rust's memory constraints could work in a situation that requires monadic IO. I very often see that functional programming as we see in Haskell requires a runtime garbage collector, but I see the fact that most of the behavior could be implemented in Rust as evidence to the contrary. It's less as a suggestion for Rust itself and more of an idea of what's possible with Rust's memory model. Something that future languages could look at and see that pure functional programming and static memory management aren't mutually exclusive. There are even crates available to provide lazy evaluation if you want it. Pretty much the only real block is the fact that you'd need a more complex definition of Monad than Haskell. See [this](https://m4rw3r.github.io/rust-and-monad-trait) excelent blog post. It's possible that such a type wouldn't even fit the definition of a monad due to the implementations being *trait* constructors rather than *type* constructors. But as that post states, such a type can be defined with a powerful enough type system.
The simpler-*looking* the language, the more work the runtime does to cover up the complexity of the machine. Python is not a simple language. CPython heap-allocates every integer you use.
Good point about the non-public functions. Typical [conventions](https://doc.rust-lang.org/cargo/guide/project-layout.html) for Cargo mean I usually only end up benchmarking public methods anyway.
/u/burntsushi, that’s why.
👏
So how do we create no_std binaries on stable using panic_handler? I tried it and it still says it requires the `eh_personality` lang item https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=cb59f140c3d31977984bc1f3df901004
I am NOT an expert, but the deal with futures as far as I know is "use version 0.1.x, tokio has some tutorials and they're good but not exhaustive, and there's maybe some articles about it too". Futures will be moved into the standard library Real Soon Now, along with language support for async/await, and everything will be incrementally less awful. Again I don't know details, but futures 0.2 was released earlier this year, hailed as awesome for about 10 days, then yanked with the instructions to go back to using 0.1, so I assume there's some deep and complicated mis-design there.
electron is a prime example of ram cancer
There's also a very long arc of productive languages catching up with programming language research.
When I was playing around with Diesel previously I found this blog post in which the author does exactly this. &amp;#x200B; &gt;However, we’re going to make a small change so that we can leverage the same model for Queryable and Insertable object. The Diesel author expressed [fair reasoning](https://github.com/diesel-rs/diesel/issues/1440#issuecomment-354573185) for separating our object into two models but, I prefer the convenience and less code pollution. So for that, we edit `src/schema.rs` &gt; &gt;`table! {` &gt; &gt;`heroes {` &gt; &gt;`id -&gt; Nullable&lt;Integer&gt;,` &gt; &gt;`name -&gt; Varchar,` &gt; &gt;`identity -&gt; Varchar,` &gt; &gt;`hometown -&gt; Varchar,` &gt; &gt;`age -&gt; Integer,` &gt; &gt;`}` &gt; &gt;`}` Source: [https://medium.com/sean3z/building-a-restful-crud-api-with-rust-1867308352d8](https://medium.com/sean3z/building-a-restful-crud-api-with-rust-1867308352d8)
&gt; I very often see that functional programming as we see in Haskell requires a runtime garbage collector, but I see the fact that most of the behavior could be implemented in Rust as evidence to the contrary. There's more to functional programming in Haskell than the I/O monad. 
Ah... 32 bit floating point... I must have something hard hitting my head recently. Thanks a lot for the pointers and the detailed explanation!
Yeah in some ways it’s better for the hosting companies when you write in a less efficient language as you need to pay for more resources and in turn more income for them.
It's true that most languages provide regex libraries that are strictly more powerful than (mathematical) regular expressions, but Rust is not one of those languages, so knowing the difference is especially important if you're using Rust.
sad how a program uses 1 gb of ram to display some text some images and some ui, not long 1 gb allowed you to make fullblown 3D games
Is it possible somehow to have a generic chain in an `impl`? Something like this: use std::borrow::Borrow; trait Foo { } impl&lt;T: Foo, B: Borrow&lt;T&gt;&gt; Foo for B { } Basically I want to be able to treat anything producing a `Foo` reference as `Foo`, but I really don't want to implement every `Borrow` in existence manually; the above doesn't compile, Rust complains that `T` is not constrained by anything.
Loved the zero-overhead addition of support to rust by rust-aws-lambda : pretending to be a Golang binary is funny! Shows the flexibility of Rust: be it WASM, be it AWS, Rust can infiltrate into any environment. 
So, I had similar problem recently. I had to process something like 7.5GB of logs with over 40M entries. Of course, bash did the job, but it was kinda slow, and pain to modify. Then I wrote my [first Rust program, code available](https://www.reddit.com/r/rust/comments/9r1my5/code_review_request_for_small_log_aggregator/) and after I made it nice it now parses those logs on my laptop in 40 seconds. I find it quite amazing, to parse over 40 000 000 JSON entries in 40 seconds. Friend wrote similar parser in his language of choice (optimized mix of C &amp; C++), and it does in same 40 seconds. Rust FTW.
The IO monad is a solution to a problem that comes up as a result of a separate design decision, namely purity. If a hypothetical language wanted Rust-like memory management while maintaining purity, this shows that it's conceivable that such a combination might work.
&gt; simd algorithm or aho-corasick Sometimes at the same time. ;-)
&gt; I was able to port my parser to accept an AWS S3 Event, and output a few lines of JSON with counters in them. From there, I can read those tiny files out of S3 and import the counts into a database. If they are reading big gzip files, they should try [`cloudflare_zlib_sys`](https://docs.rs/cloudflare-zlib-sys/0.1.2/cloudflare_zlib_sys/). The crate is bit low level, but the improvement is huge. YMMV
This is pretty much the main reason why I think of electron and similar js apps to be examples of the golden hammer antipattern
Language features in not the most exciting thing about rust. Borrowing checker is. To understand better where it is coming from, you might be interested in reading Rust's creator overview of languages research state of affair: [https://graydon2.dreamwidth.org/253769.html](https://graydon2.dreamwidth.org/253769.html)
Seriously what is wrong with you. You can play a game but can’t read? 
r/playrust
is there a way to benchmarch functions in binary crates with critierion?
It's better to write the widgets yourself in Rust. You're going to bed to know how to do this, anyway, if you want to be able to dynamically create and remove content effectively at runtime. I do recommend using the cascade crate though. Makes working with the GTK API easier than Vala.
I really think --release should be the default. I've lost count of how many times people haven't realized that default builds are slow.
And then everyone say "wasm is not meant to replace Javascript". People - wasm is the solution to this slowness - why not let it replace Javascript?
Didn't [Tokio](https://tokio.rs/) already proved that concept?
But then we'd end up with even more people that don't realize that and have even more people complaining about compilation speeds.
Do you have any idea how monads are going to deal with borrowing? The main thing that killed my desire to use futures for me is the fact that you can't borrow local variables,which will be fixed by async-await.
i think the overhead even on a small website is insane we need to replace js
So \`#\[macro\_use\]\` is no longer needed... but how can I use \`use\` to import custom derive? If it is impossible to do so, maybe it should be mentioned in the release note or so, it's a bit confusing.
&gt; Unfortunately, gzipped JSON streams in S3 are super hard to query for data. I bet you could do even better if you changed file formats. A binary format would cut down on parsing overhead. A columnar format like [Capacitor](https://cloud.google.com/blog/products/gcp/inside-capacitor-bigquerys-next-generation-columnar-storage-format) or [Parquet] (https://blog.twitter.com/engineering/en_us/a/2013/dremel-made-simple-with-parquet.html) night he particular good if you're filtering or selecting a small number of columns.
It's a long-running joke that the League of Legends client, written on Electron, is laggier and uses more RAM than the game itself (written in C++). It's really only half a joke, because it is laggier than the game, and uses 600+MB of RAM just sitting at the home screen.
Looks like I just need to use the trait name...
I appreciate your good taste in cat names, but please keep comments on-topic.
Please see the rules on the sidebar; no language zealotry.
Let us resist the temptation to let /r/rust be the sort of sub where "x is cancer" is the baseline level of discourse.
Is a "dropping pointer" actually a thing? I think that only values are auto-dropped; the referent of a pointer won't be.
Quick update. I just made trivial changes to my app to multithread it, and now it parses 40m records in 12 seconds. Mind. Blown.
&gt; If a hypothetical language wanted Rust-like memory management while maintaining purity But... ATS has had an effect system for years.
Thanks! But really, I'm parsing about 40 millions of lines, and outputting about less than thousand.
This is safe because `ManuallyDrop` is `#[repr(transparent)]`. It is safe to cast between a type and a `#[repr(transparent)]` container of that type because `#[repr(transparent)]` guarantees that property -- that the types have identical layouts. (And if I'm being pedantic, it's perfectly safe to do the cast no matter what, it's using the pointer that's unsafe and potential UB.) That said, I don't think this is what you want. You won't drop something behind a pointer unless you do so manually. Why do you need to use a pointer? You shouldn't for most use cases.
For return pointers it's typically fine to just use `mem::uninitialized()`: unsafe { let mut find_data: WIN32_FIND_DATAW = mem::uninitialized(); FindFirstFileW(..., &amp;mut find_data); } For Windows APIs it's typically fine to pass uninitialized memory for return pointers as it will initialize the whole struct but you may want to prefer `mem::zeroed()` for other libraries (since you don't know what kind of memory access bugs they might contain or if they'll overwrite the entire struct).
This looks pretty neat. I'll give it a spin over the next few days and see how it goes. Thanks for sharing!
Futures suffer from causing problems with borrowing,which required async-await to fix. Anyone trying to add monads to Rust will have to figure out some way to allow borrows across and\_then/bind calls if they want them to be usable.
Haskell is pure because it is lazy. While purity is a really nice property to have (and now Rust can also enforce it with `const fn`...), strict languages like SML and Rust don't have to have it. A more elaborate explanation is found at https://stackoverflow.com/a/31483875/1063961. If you want to learn about the History of Haskell, I recommend [A History of Haskell: Being Lazy With Class](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/history.pdf) by Wadler et. al. and [the associated talk](https://www.youtube.com/watch?v=06x8Wf2r2Mc) from Simon Peyton Jones himself.
See my explanation above for details and resources that go into great detail.
I mean, yes, historically in Haskell purity and laziness go hand-in-hand — it didn't compromise on purity where other functional languages did because it couldn't while maintaining laziness. But fundamentally the IO monad exists to solve the problem of modeling effects in a pure language. The fact that Haskell's laziness led to its inception is a historical accident; it could just as easily have been invented in a strict language. More importantly, strictly evaluation does not obviate the need for some way of modeling effects if it wants to maintain purity. So saying that Haskell needs the IO monad *because* it's lazy is misleading at best, and used as an argument against its usefulness in strict languages it's flat-out wrong.
24 hours worth of data, 16 hours parsing time - almost real-time 
It's *not* a historical accident that `IO` and monadic handling of effects was invented (afaik) in Haskell. As we both agree, the language simply couldn't be impure and lazy at the same time, and so it needed to find a way to model effects. Meanwhile, a strict language isn't forced to do this, so it is convenient to just let side effects into the language; thus, for social reasons (and due to Eugenio Moggi's work on monads happening roughly concurrently), this led to Haskell (Wadler) inventing monads for handling effects. That being said, I 100% agree that strict evaluation doesn't obviate the need for modelling side effects, and doing so is immensely useful. In fact, if I had to redesign Rust today, I'd make it pure by default (invert `fn` and `const fn`...).
I typically do `Into&lt;Option&lt;[inner type]&gt;&gt;` but in this case because it's a reference you have to give it a lifetime: fn takes_duration&lt;'a, D: Into&lt;Option&lt;&amp;'a Duration&gt;&gt;&gt;(duration: D) { let duration: Option&lt;&amp;Duration&gt; = duration.into(); }
This sounds like an XY problem. What's the bigger problem you need to solve?
I think you read a stronger meaning into my use of "accident" than I intended. Haskell is lazy, and laziness forced it to be pure, and purity spawned the IO monad. From that point of view, I can see the "laziness causes IO monads" argument. What I was really arguing against in the first place was the tacit assertion made by the first commenter that monadic effects would not be useful in (a pure subset of) Rust because it is not lazily evaluated. Which I think you agree with me on. I didn't intend to get into a philosophical debate about the role of the design of Haskell in the history of functional programming patterns :)
(While we are having a philosophical discussion, though, I would also argue that a language really should not be called functional if it is impure, no matter how much it superficially resembles function application or concatenation. Since procedures are a superset of functions, I think a language that blurs the line between the two should simply be considered procedural, since IMO syntax is less important than semantics in language classification.)
In a cloud setting more efficient can be translated in to saved money.
yes
Wrong sub?
I answered here: https://www.reddit.com/r/rust/comments/9rrcsf/is_it_ub_to_cast_mut_t_to_mut_manuallydropt/e8ja3cq
You can encode monads in terms of futures since they are roughly continuations and [the continuation monad is the mother of all monads](https://www.schoolofhaskell.com/school/to-infinity-and-beyond/pick-of-the-week/the-mother-of-all-monads), and get borrowing across binds through async/await
Ah, I also happen to be of the opinion that partial (mathematical) functions are similarly misnamed :) Partiality is super interesting. It's really ugly, but that might just be because (as was once the case with side-effects) we don't have the right frameworks for reasoning about it yet. It does seem to throw all sorts of wrenches into math, though. And while it seems at first glance to offer a compelling framework in which to model lots of things that don't classically fit into the domain (heh) of "functions", it... doesn't really deliver on that promise, does it? The world of partial algebras seems pretty anemic when you get into it, at least compared with the rest of universal algebra. Much of the work that does take it seriously seems to have come out of computer science rather than pure mathematics, and computer scientists tend to have a hard time separating the math from what it models (_cf._ every blog post ever about *Hask* and bottoms). It seems mathematicians just aren't as interested in studying partiality and its implications as they are in admitting a bit of it here and there where it makes their lives easier and otherwise sweeping it under the rug.
I think from a practical programming POV, being principled about purity is currently easier than it is to be principled about partiality; While panics are rather easy to statically reject, you need to make dealing with it easier and ergonomic for it to be viable. For example, if the syntax for addition is `x.checked_add(y)?.checked_add(z)?` it will get old, fast. If instead we had `x +? y +? z` or something similar, it would be more enjoyable. But if we are to get rid of all partiality, then we need to prove termination of loops... that gets tricky and will involve sized types, positivity checkers, more manual annotations, etc. Idris does something interesting here. Instead of being total by default, it is partial by default and allows you to explicitly require totality with `total` (as a matter of semver); furthermore, if a function is used in a type expression, then totality is required (either inferred or explicitly stated with `total`). I think this may be the right default currently. It would be interesting to see what could be done in Rust. With respect to partiality, one thing Rust does better than Haskell is to have exhaustive pattern matching.
Would be nice to see how does things fit in with the library.
Truth be told I've written more Agda than I've ever written Idris, primarily because the former was invented at Chalmers University of Technology ;)
If you need a pointer that doesn’t own or extend the lifetime, then maybe consider using a [weak reference counted pointer (rc)](https://doc.rust-lang.org/std/rc/struct.Weak.html) I might be misunderstanding your problem though or the weak rc itself lmao. 
You'd still have to write something that gets them into that format, though I like that idea. Whenever I get large CSV files, one of the first things I do is to put them into a parquet format for faster subsequent reads.
great, I'll check it out. Thanks!
Rc is not thread-safe and a Weak from a Arc won't help me since it's not a Arc, it's basically self referential.
If you take ownership of something you can move it to something mutable. The old immutable value can't be used anymore afterwards: let foo = "foo". to_owned(); let mut foobar = foo; foobar += "bar"; //println!(" {}", foo); // compile error println!(" {}", foobar); So the immutable `foo` is never changed.
This is the reddit for the programming language rust, not the game.
that makes sense now thanks
You are right and in this case that would mean either C# or JavaScript which are both first class citizens (which means it gets new features and integrations quicker/at all). JS is a great choice for that kind of thing for simplicity, but it could be too slow on some parts or the dev prefers Rust so WASM is a way to meet in the middle. Clearly the language interop aspect is part of working in a highly managed environment like Functions as a Service. I thought it was interesting since I couldn't always predict what was going to be faster.
so basically you create a new variable here 
A dozen? My good sir, as a fulltime Javascript dev I can assure you the ONLY way to write sane frontend browser code involves using Typescript or Flow (or similar transpiled Javascript-targeting language variants), and assembling an insane Rube-Goldberg machine of bundlers, transpilers, linters etc, and importing a ton of libraries that provide actual safe-to-use data structures &amp; algorithms. Or, ya know, stuff that is in the base language of every other language, like for example a proper module import system. And every component of this madness is notorious for random &amp; barely documented breaking changes that destroy the entire dependency tree (I don't even read a tutorial or Stack Overflow entry over 6 months old anymore)! Not to mention the &gt;9000 polyfills required to ensure that the oh-so precious 7% of the population STILL on IE-whatever from 1998 don't have it all break on them. So a dozen libs slowing things down? That's so positive of you to say! Glad you're appreciating how performant it is! /s I wish I was even exaggerating about my toolchain, it's just a ludicrous situation. And that's just the front end, don't even start me on Node. The only "advantage" is that at least you can pop out a crappy Electron-based desktop version and a Mobile version using 99% of the same codebase &amp; charge the client for 3 products - which Rust is making possible anyway. I can't wait for just a few more bits in Rust nightly to be in stable (like async/await) so the various web dev frameworks can be truly production ready and I barely ever touch JS again. But yes, let's not turn this into a JS-hate circlejerk, I just need to vent on occasion. 
Personally I've had a lot of luck speeding up critical sections by writing custom parsing. Most times there's big advantages to be had by knowing what you're expecting to see, which something like serde can't possibly use. obviously it's not the first thing you turn to.
I'm not familiar with this and there's very little to go on in the crate docs - can you explain a bit more about what this is, and when it would be useful? 
are you reading parquet files in rust? or something else? I'm currently in the market for an improvement over csv. I had long used hdf (with python) but there doesn't seem to be a good rust library to use for that yet. actually my problem is not reading csv files in rust, it's reading csv files in python in jupyter notebooks - ha. but they need to be readable in rust as well in my case. 
The repository says it's a binding to cloudflare's fork of zlib, which they claim is significantly faster than normal(?) zlib. 
I don’t know if you solved this yet but the problem is line 22 of db\_postgres.rs. You have to change fn transaction(&amp;self) -&gt; Result&lt;Box&lt;DatabaseTransaction + 'a&gt;, Box&lt;Error&gt;&gt; to fn transaction&lt;'b&gt;(&amp;'b self) -&gt; Result&lt;Box&lt;DatabaseTransaction + 'b&gt;, Box&lt;Error&gt;&gt; This has to be changed as well in the trait definition of `DatabaseBackend`. This will make the lifetime annotation of `DatabaseBackend&lt;'a&gt;` unnecessary. I think with these changes the code *should* compile. # Some general remarks wrt to lifetimes You should think about, what lifetimes mean (read the book again if necessary). It does not make a lot of sense to make the trait `DatabaseBackend` dependent on a lifetime because the implementors of that trait won't have a lifetime dependence. The idea of your `transaction` method is the following: *Borrow* self (the Database backend aka Connection) and return a Transaction. The concept of *borrowing* is necessary to prevent anyone from closing the connection while it is still *borrowed* by the transaction. So while the transaction exists you won't be able to close the connection. The lifetimes are necessary to communicate to Rust *which borrows should be kept alive for how long*. Let me explain: The ampersand in `fn transaction(&amp;self) -&gt; …` means that self will be borrowed inside the function definition. You want to return a `Transaction` from this method which requires `self` to remain borrowed (remember we don't want to destroy our connection). Therefore you introduce a lifetime to make this crystal clear to the compiler: `fn transaction&lt;'b&gt;(&amp;'b self) -&gt; Box&lt;'b + DatabaseTransaction&gt;`. Here we see the lifetime `'b` both in the reference to self as well as in the return type. This means that the borrow of self will be *kept alive as long as the returned value exists*. And this is exactly what you want. However since the `Transaction&lt;'a&gt;` type of Postgres has a lifetime (it borrows from the `Connection`, see above) it could make sense to make the `DatabaseTransaction` trait generic wrt to lifetime (make it \`DatabaseTransaction&lt;'a&gt;).
First bikeshedding change request: domain-owner can conflict with something that the domain must host for some other purpose, preventing the use of the cleanest possible domain. The filename should be something specific for rust/cargo/crates.io. For example: crates-io-domain-owner
the nom parser had a few unnecessary allocations, and some redundant whitespace parsing, and that can kill performance easily. Honestly I would have probably used regexps directly too, they're often a good tool (and it's actually possible to use them in a nom parser if needed)
The best idea is really to introduce the trait \`LineLike\`. You cannot implement e.g. \`impl AsRef&lt;ParsedLine&gt; for KeywordLine\` as you have already noted since you cannot produce a reference to \`ParsedLine\` from \`&amp;KeywordLine\`. \`AsRef\` really only makes sense if one type \*contains\* the other (e.g. \`Box\`). You could implement \`impl&lt;'a, 'b&gt; From&lt;&amp;'b ParsedLine&lt;'a&gt;&gt; for Option&lt;&amp;'a Keyword&gt;\` and similar for \`KeywordLine\` (see [Gist](https://gist.github.com/rust-play/bcec69c5c31db1026715b7785d419093)). But from a semantic point of view this does not make too much sense, since you can't \*convert\* from a \`ParsedLine\` to a \`Keyword\` in the usual sense of the word. I think here you would be just misusing the \`From\` and \`Into\` traits. In conclusion the best and easiest way is to create a new trait (or simply have your function take an \`Option&lt;&amp;Keyword&gt;\` Parameter ;) ).
Been doing TypeScript professionally for the past several years. Can confirm every word.
&gt;embedded As someone that is interested to test rust with embedded (ARM Cortex-M), I was under the impression that I could use stable rust 1.30. Is that not possible? Or is \`PanicInfo.message\` a convenience?
Perhaps your app is using a different GTK theme from the rest of the desktop. Could you post a screenshot of a native app for comparison?
No, I don't use rust for parquet, although there's a crate for it. I'm reading hundreds of CSV files from a directory, then saving them to parquet (so I don't keep re-reading them in CSV format). I use Apache Spark, pyspark specifically. I don't see the benefit in using Rust for that, although it'd be a bit faster than my current workflow. &amp;#x200B; The Apache Arrow project's working on a faster C++ csv parser, and with pyarrow, pyspark and pandas now tightly integrated; your Jupyter Notebooks solution should be sufficient. Python's only getting better in this field.
Does it not already? I'm the founding developer on /r/veloren, and it can run using less than 20M of memory on lowest settings.
Yup, the second screenshot (of the terminal) is how native apps look.
An effect system is another solution that has been devised to solve the issue of side-effects. I'm personally fond of side effects being encapsulated as ordinary values which is why I'm drawn more to the monad side of things.
If you believe this is useful, please send a PR to rust-mode, it is desperately needing for maintainers and upgrades (better RLS / Racer support, etc.).
Oh trust me, the people smart enough to cut costs are not hosting companies targets. Even if you make software readily available and easy to use, 95% of the IT workforce are pretty incompetent and won't make use of it. The prime example I use is PHP. To get a massive boost in performance and security all you need to do is swap from PHP 5.x to 7.x and people are still running on PHP 5.3 because they can't afford to spend a few hours for a developer to run some checks on their code to make sure it's compatible (I'm not referring to full codebase, more frameworks which *publish* compatibility)
I think you need panic = abort in Cargo.toml A working no_std embedded firmware : https://github.com/TeXitoi/blue-pill-quickstart
FYI the book has an "Operators and Symbols" appendix: https://doc.rust-lang.org/1.30.0/book/2018-edition/appendix-02-operators.html
I think that section is nice from a purely syntactic perspective, but I am missing a "middle ground" between the book's tutorial-style, and this rather "syntactic" appendix. The Keyword section looks like it's delivering that, which is why I'm so happy about that. I would love them (and "Sigils"), target mid-stage developers who know the basics (possibly coming from another language), and need a concise refresher how in Rust these particular concepts work out. 
There's also the [syntax index in the first edition](https://doc.rust-lang.org/book/first-edition/syntax-index.html) which actually links to the relevant parts of the book.
Hah, thanks for the link! I remember I used it when I started but completely forgot about it since the 2nd edition came around. Personally I wouldn't want to see all of that ending up in the std docs front page, but primarily the ones that are common and have "interesting" behavior in Rust relative to other languages. 
I think that some sort of structure should occur
That is a marvelous idea, definitely will save me from having to package it up! 
Mind elaborating on how you implemented multithreading? I'm guessing you used Rayon which is praised all the time around /r/rust.
AWK instead?
Use the rust musl builder docker if you want to be able to cross compile distros. It is pretty easy to use, and you can add static libraries easily. But having said that musl has its faults. I've seen segfaults and infinite loops that I haven't seen any resolution for
I found myself wanting the same thing. The first edition was more like this, but the second edition was much more conversational, whereas I wish that there was a more reference like section that showed me somethung like the syntax example, BNF definition, and an explanation of modes and associated semantics in a list. The second book involves more ctrl-f as a result. I would especially like that for the control structures (if/let/else/loops), closures, import statements, trait and struct definitions. Actually just give me all of it in EBNF in a syntax section and I'd be much happier. Since I jump between languages so often, sometimes I need a reminder of how things work. 
It's 500 GB of data for 24h, in 500 1 GB files. Still, 500 GB in 16 hours is really slow. I usually use Python for this ad-hoc analysis of logs, and manage to parse ~1GB in a few seconds when here it seems it parsed ~1GB in 2 minutes.
It's also true in your own data-center. In my previous company, an application was running distributed on 500 servers. Some low-level finicking with message serialization/deserialization shaved off 10% of processing time; that's 50 servers that won't need to be added in the coming 2 years as traffic picks up!
wouldn't static `T:Copy`ies qualify?
I used `crossbeam_channel`. Never heard about Rayon. I think I'll post code for a review, because I tried doing same on `Arc&lt;Mutex&lt;mpsr::Receiver&gt;&gt;` and it works much worse than cloned unbound `crossbeam_channel` Receiver. Even worse than single threaded app.
Thanks for your answer. Seems `AsRef` was not the right idea, alright! I've kinda found a third way that looks promising: I'm converting the function I wanted to write into methods on `ParsedLine` and `KeywordLine`, which seems to fit very well (mostly because while their definition is very similar, they're pretty different semantically, so there isn't a lot of code duplication in the methods). 
First of all, this is an absolutely terrific answer. Not only did the code compile. I also think that I managed to understand most of your explanation, which was great! A great trouble I've been having is where it is ok to insert lifetime annotations. I'll read the ownership chapter in the book again I think. Specifically regarding lifetime elision because I don't understand how things are laid out by the compiler unless specified. Like this struct that the compiler requires me to specify lifetimes for. pub struct PostgresTransaction&lt;'a&gt; { transaction: Transaction&lt;'a&gt;, } Is it possible to say right away what the compiler tried to infer here? And just one more question!: with the fixed code, how do I close the connection from the callee? Do i first need to manually close the transaction in some way or will rust understand and just drop the transaction, then the connection?
With great power must come whitelisted responsibility.
Huh, I didn't even know we had a spam filter.
&gt; you use it to work around something which, if supported by the language itself, would be just as (or more) concise, as well as easier to understand and debug. To be honest, compile time string sum representation is pretty transparently done when the string components are static with macros, which probably takes some compiler special case shenanigans if the same was to be done on plain functions. On the other hand those special cases might very well be more broadly applied than a macro metaprogramming (for instance all String.format calls).
may be later... For now I'm trying to figure out my mpsr is so slow. I'll ask reddit :)
This subreddit is for the Rust programming language
I have added a Local Storage example here: https://github.com/utkarshkukreti/draco/blob/master/examples/local_storage.rs Live Demo: https://draco-examples.netlify.com/local_storage/index.html Let me know if you have any questions or ideas for more examples that would be useful!
I looked at Rayon, I don't think I can use easily in my code... It is mostly designed to work on vectors, slices and arrays, while I have a Reader. Probably could look into using lower level things in that crate.
I'm glad I could help! The compiler will currently not allow you to elide lifetimes in type definitions. The compiler doesn't strictly need this information but it can be helpful for programmers to know, that the type you defined may have a non-static lifetime. Since \`Transaction\` is generic over lifetimes so must \`PostgresTransaction\` be as well. In this case there is really no difference to the case where you have type parameters: pub struct PostgresTransaction&lt;T&gt; { transaction: Transaction&lt;T&gt;, } Lifetime elision will only work on some kinds of functions. If both the connection and the transaction go out of scope (get dropped) then the compiler will automatically drop the transaction first and then the connection. You will not be able to manually drop the connection (e.g., using `std::mem::drop`) while a transaction is still in scope ("value is borrowed"). 
For the dot, see [this](https://www.reddit.com/r/rust/comments/9rnj61/is_it_better_to_use_glade_with_gtkrs_and_how_do_i/e8jop1i/). For the menu bar looking slightly different, set padding to the one you like. I believe negative values are also supported but I'm not sure. Check out the excellent [elementary Human Interface Guidelines](https://elementary.io/docs/human-interface-guidelines#human-interface-guidelines) that describe padding and all that jazz, and are designed for GTK.
I have a feeling the code for my menu bar is wrong. I don't know what, but I think it's wrong. Could you please verify?
As the person who added the new keyword docs, I fully support the idea! Making sure every weird aspect of Rust's syntax is easily findable is a noble cause.
Hey, thank you so much for this! Can you outline how I should move forward making this happen? I started a post on internals already; but that's about it. I'm willing to put some time into this, but would like to avoid wasting time if it doesn't fit the general docs vision. 
For the benefit of *others*, younger to the project, reading the parent comment or Centril's other comments here or elsewhere (as I assume you know this piece of history already). Interestingly enough, Rust did have an effect system: pure was the default, and impure functions were `io fn`. This was later removed, and the polarity inverted to have impure functions as `fn` and pure functions as `pure fn`; the use of pure fns was then *also* removed years ago. All this was removed for reasons which still hold up. (And I say this as a fan of Idris, ATS, and effect sytems.) As a note: the view that `const fn` are pure or similar to the old `pure fn` is not the consensus among the lang team.
I have to run my code on CentOS 6.9, which is hard, so I use not-a-dynamic binary build against musl library. I'm using docker to build it: ``` docker pull clux/muslrust docker run -v "$PWD":/volume --rm -t clux/muslrust cargo build --release ``` Very happy with results - I'm getting single static binary, no need for dependencies (like new libc). Also, allows me to build binaries on mac. Doesn't really helps you much, may be will help someone else, who'll try to run Rust on CentOS6
Here, I shared my code with some questions: https://www.reddit.com/r/rust/comments/9rubi1/
You cant cast 0u32 to NonZeroU32, even though NonZeroU32 is transparent. If not all bit patterns are valid values, extra care must be taken.
No, that is doing the same thing as `window.set_title("title");`...
I have saved https://twitter.com/stjepang/status/1006202765499125760 for just this occasion ;)
The solution mentioned in the comment you link isn't working for me...
In my experience trying to escape unsafety in the middle of a complex data structure is just a recipe for headaches and subtle problems. I recommend just sticking to passing around *mut's, or building your own wrapper around *mut that provides exactly the API you want. For instance even though `Box&lt;ManuallyDrop&lt;T&gt;&gt;` can't run destructors, it does potentially inform the compiler that several invariants hold that you may not want, especially in a concurrent data structure. Notably Box is intended to be semantically similar to `&amp;mut`, and `&amp;mut` tells the compiler that the referent is completely unaliased and definitely allocated, which allows the compiler to reorder/insert non-atomic accesses as soon as you materialize the pointer (so extract it from the Option).
&gt; as I assume you know this piece of history already I do; and the language was highly different back then and `pure fn` was not likely the same thing as `const fn` is now (at least from the information I could glean from history). &gt; All this was removed for reasons which still hold up. (And I say this as a fan of Idris, ATS, and effect sytems.) I'm interested to know of those reasons. What I am saying is that `const fn`s are pure *right now* (which is true, but might not be in the future...).
Reddit has one spam filter whose rules are opaque and inscrutable, and we also have automod rules that automatically filter out posts whose title have common keywords like "clan", "pvp", etc.
`src/grammar` is not used for parsing Rust code, it's an obsolete piece of code that used in attempt to formalize the grammar, but now its only purpose is to confuse people.
So, the answer is no, Rust compiler is not written in C/C++ in general. The only exception is the LLVM backend.
I had a similar experience parsing a few GBs of JSON on a scheduled basis. I was using jq to do a very simple task, but it involved deduplication, which I guess it doesn't optimize very well. I wrote a 12 line main function and parsing went from 2 minutes and 2 gigs of ram to 8 seconds and 10MB of ram. unbelievable. That moment made me want to write my own JMESPATH runner. 
Thanks! Was really confused about that. &amp;#x200B; I assume \`src/libsyntax/parse\` is the parser directory, right? Does this mean that they manually wrote the whole parse logic? So they just implemented the Recursive Descent Parser, or?
Thank you for your reply! I seen that picture before. According to it mpsc and crossbeam should be about same in performance. About mutexes - I don't know any other way to make multiple consumers out of mpsc. I just used what I learned from a \[book\]([https://doc.rust-lang.org/book/2018-edition/ch20-02-multithreaded.html](https://doc.rust-lang.org/book/2018-edition/ch20-02-multithreaded.html)). I'll try Rayon. I didn't par\_lines at first. Will try. 
You could modify the application to directly write a better format. Although probably not a columnar one; those require buffering the whole file before writing anything, which is inappropriate for direct logging.
&gt; I seen that picture before. According to it mpsc and crossbeam should be about same in performance. Not exactly – you should probably look at the "unbounded channel &gt; mpmc" section, where mpsc doesn't show up (this is what you're building with your own mutexes after all). &gt; About mutexes - I don't know any other way to make multiple consumers out of mpsc. Yep: mpsc is not optimized for this case at all, and you have to build around that. In addition to the system-provided mutexes that std gives you and that the books teaches you about, one can also implement mutexes in pure Rust, with different trade offs. The "parking lot" crate is one such implementation – and crossbeam-channel uses it internally which is why I remembered it. (Indeed, if you [search](https://crates.io/search?q=parking_lot) for it on crates.io, the second entry right now even is an experimental parking_lot_mpsc crate!) &gt; I'll try Rayon. Cool! Let me know how it goes :) Ideally, it should lead to simpler code with similar performance.
Unfortunately I didn't find how to use Rayon with stdin reader :(
Wrong subreddit guys! :) Have fun though!
It feels like it would be easier to write BISON/FLEX in rust, rather than the whole parser in rust. So much code O\_O &amp;#x200B;
Other languages don’t have this stuff built in though. So as another full time TypeScript dev, I disagree. It leaves out a long list of advantages you do *not* get in other languages. When most languages allow you to combine with another language, it’s basically `fopen` and dumped as a binary or text blob. That’s it. Most languages that allow you to write say C or SQL embedded in the language are actually just having you write a text string that they check at runtime. So again it’s a text blob. What if the C can be optimised? This will not happen at build time for your application. It’s sent to the user unoptimised, and optimised there on demand. When all of your content is shipped via a network connection, this is a waste. With web dev the mass of linters, transpilers, optimisers, and so on allow you to import and bundled in an optimal way. What’s more is it allows different things to have awareness of each other. For example in JavaScript you can write `import loadLib from ‘lib.rs’` it’ll go off and compile the Rust project on demand, and then import it. You can also have the type definitions generated allowing it to be used from TypeScript. Being able to also do that with SVGs, images, CSS, and other media, allows us to not care about if we wish to manually inline the media or not. Webpack can handle it for you. It’ll also apply other optimisations too. Tl;dr you make a `main.js` file and import CSS, images, SVGs, audio, video, libraries, rest of the site, and on the other end a website comes out. That’s pretty cool.
The owners icon on the cascade crates.io page misled me to think it's a crate from the Rust team.
The reasons Graydon listed are in the [classic post](http://permalink.gmane.org/gmane.comp.lang.rust.devel/3855). I do not read those as being solely dependent on the language itself, or how different it is today. &gt; What I am saying is that const fns are pure _right now_ min const fns are also so limited _right now_ that they're effectively not usable in practice to do anything beyond a one-line expression const fn. Indeed neither of those facts might be representative of the near future. As soon as the edition ships, it could be interesting for the team to hash out this space, as I'm sure you all plan to already anyway. Niko was definitely there at the time of `pure fn`, its possible extensions and later removal, and will easily be able to tell you if it was the same as `const fn`:)
Can I play a song on linux via rust? I found out rust-mpd but I don't understand exactly what it is.. [https://github.com/kstep/rust-mpd](https://github.com/kstep/rust-mpd)
FYI, there is the [rustc guide](https://rust-lang-nursery.github.io/rustc-guide/), an in-progress community-written book on the compiler internals. It's quite interesting, the section on the parser is quite short, though.
It's an entire browser and a language runtime (Node), plus the actual code you're running.
**doesn't implement \`std::fmt::Display\`,** **doesn't implement \`std::fmt::Debug\`** &amp;#x200B;
The fastest way to parse is to not parse at all https://www.google.pl/amp/s/blog.acolyer.org/2018/08/20/filter-before-you-parse-faster-analytics-on-raw-data-with-sparser/amp/. So in this case, if the log records are stored one object we line, then maybe the Bette rest is to filter it before using for example `grep` crate and then parse lines that matched. It should remove need for parsing irrelevant lines (or at least some of them). 
Sure. No problems with that whatsoever. The point was about automatically generating parser code, rather than write it manually. I'm by no means compiler specialist, nor was it intended as a pun on Rust. I just used to use BISON/FLEX for SQL parsing and will never go back to manual parsing again. Except for small things
You have to implement those traits to print the variable... How is the program supposed to know how to print it? It's just like C++, you need to override `ostream::operator &lt;&lt;` to print to stdout. For trivial structs though you can add #[derive(Debug)] Or if you don't mind adding serde as a dependency you can derive the Serialize trait the same way. 
I'd rather rust not cater to the lowest common denominator and spam the output with basic stuff like that. Pretty much every compiled language works this way. Even web languages like javascript have a separate optimization phase, where you minify everything for page size and performance. I doubt debug web servers are using minified JS, i'm sure people want errors more helpful and readable than `line 1 column 4712` Debug builds are for debugging, and people don't write perfect finished code by default. if someone has trouble getting that, well.. don't confuse new users into thinking they should be using `--release` all the time, and then they have trouble getting debugging to work. `--release` isn't a "fast mode", it's a release mode. For the final product.
I dunno, how does PHP, python, perl etc. know how to print stuff? they all have a dump function. I'll try to add that derive thing if I can - it's not my code, but i can probably work it out. &amp;#x200B;
Runtime introspection. Rust builds print logic at compile time. Debug's derive has source code access; you have to do Display yourself because only you know how best to print nicely
As someone who's written a parser using parser combinators and regex, it's really not that bad
Writing 8k lines of code just to parse data sounds like a lot. Not talking about ease of extension/modification/bringing new people to the project or just understanding what is going on
It didn't like that directive, some field inside the thing I was trying to print, also couldn't be printed. No worried tho, I made my own fmt::Display to just print some bits. Thx for your help.
Nope. &gt; Therefore kinda confused what does this mean? It is a consequence of the Rust source tree containing old/obsolete code.
It depends on what you're planning to learn and/or achieve. For example, if you're planning to go into mobile development and don't care much for the back-end, you could probably go with Firebase. It's got some caveats, but I hear it's pretty easy to get started with. On the other hand, learning some sort of SQL might be more useful to you in the long run, because it's immensely more applicable and used, both today and in the future. Cloud-hosted services, NoSQL databases and ORMs seem fun in the beginning, but there's an entire universe of things they cannot express as well as SQL can. Consider this: if you invest your time in learning Firebase today, you'll know Firebase. You won't know cloud-hosted database X that's going to be the hottest thing in a year from now. If you learn SQL, you will be able to reuse that knowledge in projects that use Postgres, MySQL, SQL Server, SQLite, Oracle, and others. There are some differences between the implementations, of course, but maybe 75% of what you learn about one database will also apply to every other one. If some time down the road you'll find yourself working on a [GIS](https://en.wikipedia.org/wiki/Geographic_information_system) application, you'll probably encounter Postgres/PostGIS or SQLite there. A CRM or other kind of business app? It might run on SQL Server or Oracle. Administer a web shop or CMS? It's probably going to run on MySQL. &gt; For the Database I was deciding between: Firebase and Postgres? (I have never setup a db before) I'd say Postgres or maybe SQLite, but it's your career path :-). &gt; Does cloud base add much query response delay Most likely not. &gt; Does cloud based make setup/development any easier? Not having to be tied to one machine etc? It probably depends on your experience. Firebase is easy to get started with on e.g. mobile (disclaimer: I never used it), but is there a (mature) client library for Rust? I'm not sure. &gt; Are these packages trying to solve the same problem, or do they have specific goals in mind? They're both web frameworks with different APIs. Nickel might be simpler, Rocket has more features. Both are using an old version of `hyper` with no support for asynchronous handlers. Async support is important when you have a lot of clients, but -- realistically -- I'd expect both to handle maybe tens of thousands of them. Rocket only works on nightly now, which makes it prone to breaking with compiler changes, and that can be annoying. The author is planning to make it work on stable, and to introduce some form of async support. That might take a while, though. Other alternatives would be `tower-web` (async, reasonably easy to use, less mature, based on `hyper`), `warp` (async, weird-ish API, based on `hyper`) and `actix-web` (really popular, async, not using `hyper`, and there were some concerns about its code quality, more or less alleviated by now). I've used Rocket and Tower Web myself, but only a little. I also tried to look at Actix Web, but the examples and documentation seemed really opaque to me (other like it, as I mentioned). If you don't have much experience with the language, or get annoyed easily when something doesn't work, you should probably pick something that works on stable Rust (not Rocket). Then, if you want the simplest thing, maybe pick Nickel. If you want something more flexible, pick Actix Web or Tower Web. If you want something you can contribute to, pick Tower Web, as it's less mature and you can make a difference. If you don't want to learn how cookies and sessions work, maybe pick Actix.
In Go I can use "switch" to determine the concrete type in an interface: package main import "fmt" type I interface{} type Foo struct{} type Bar struct{} func main() { var a I a = Foo{} switch x := a.(type) { case Foo: fmt.Println("Foo:", x) case Bar: fmt.Println("Bar:", x) } } How can I do this with a Rust trait?
This is great advice, thanks for your time. Rocket not working on a stable build is definitely a concern. I'll be learning enough without trying to keep Pace with everyone else. I'll look more into hyper as well if many things are based on it
This is an excellent question, I had the same questions a while ago, and perhaps still do.
\`#\[derive(Debug)\]\` for a struct you are trying to print out.
If it's an open source project you may want to submit a PR/issue to support Debug/Display for user-facing types. Enough people rely on print debugging that it should be a given. 
Seems like it's trying to simplify the job of crates.io moderators at the expense of simplicity. That seems contradictory with the goal of reducing the friction to adopt the language and its ecosystem.
Any link, article or more details are warmly welcomed :)
... I obviously meant derefing the casted pointer
Seriously how hard is it to interpret text? If you call Box::from_raw on the pointer it will be dropped. 
In my experience, having written quite a few recursive descent parsers by hand for complex grammars, it’s really not that bad. I also find it much easier introduce to people not familiar with parsing.
Do you have an example of a serious compiler built with bison/flex? 
Here is the explanation why the author wrote a hand written C parser for GCC. https://gcc.gnu.org/ml/gcc-patches/2004-10/msg01969.html . You will be surprised to read the author said the hand written parser is actually easier to maintain and to add extensions. I don't know what you meant when you said GCC is not a standard for clean project. My impression is it has very good code quality.
just to repeat my curiosity, if you do make a custom OS for the R-Pi .. would you consider implementing virtual-memory across a network for pi-clusters to appear as 1 giant machine (albeit with network delays whenever pages must be copied) .. this might play well with rusts concurrency and immutability features (i.e imagine rust programs with lots of immutable data copied cleanly across nodes)
I guess we'll know that once the lang team decides what is "pure" in CTFE holistically (or what is "reasonably pure if you squint a bit" as you put it and which I like), what's acceptable with those annoying floats where systems disagree (and whether apfloat is enough), what's acceptable with loops, recursion, `!` and divergence (or taming LLVM's optimizing away a side-effect free infinite loop), whether `include_str!` and the likes are ok or not, etc. Adding `&amp;mut` *is* a potential impurity unlocking important use cases :) I'm glad we agree it is important to have, even if impure, because it makes sense in the context of Rust. I don't think a lot of people are arguing for non-determinism between const eval and runtime eval as an example of cool side-effect to have, but maybe IO is one that will be interesting to hash out. And it seems that you're arguing more for determinism and a kind of principle of least surprise, and not purity per se, which 1) I had not understood as clearly in the comments of yours I've read before (and from what I can tell, others didn't seem to as well, so it will be nice that this is cleared up) 2) I wholeheartedly agree :)
Given that the [generate the exact same code under `rustc -O`](https://godbolt.org/z/_BoTOH), I don't see a reason why they would be reliably different. If you look carefully, the variance in each is about +/- 6,000 ns, and they're about 10,000 ns apart, which is within the range of statistical variance for both of them. If your results are stable this way, it's possible that there's just something arbitrary introducing bias; some unlucky conflict in the branch predictor or instruction cache based on how the two functions happened to have been laid out in memory. You could double check that they are generating the same code on your system by disassembling the result. You might also want to try [criterion.rs](https://github.com/japaric/criterion.rs) instead of `cargo bench`, which is more statistically rigorous in how it does its sampling. See [Migrating from libtest](https://japaric.github.io/criterion.rs/book/user_guide/migrating_from_libtest.html) in its docs, and also [Comparing functions](https://japaric.github.io/criterion.rs/book/user_guide/comparing_functions.html) for comparing two different implementations of the same function. Anyhow, the fact that these are generating the exact same code tells you that you probably shouldn't worry too much about this difference.
Tracking issue opened: https://github.com/rust-lang/cargo/issues/6229
They do, but they're still on the heap AFAIK.
Nice reading material Im wondering if your write ups about Rust OS are a good reference for doing such a project on a raspberry pi as well? &amp;#x200B;
i see hope
I looked into CS140e once also. That's from the guy who created Rocket, no? I think there were some files on the official course page. Have you checked that out yet?
Using Macros. This is one example: [https://github.com/rdeioris/impostor/blob/master/src/mos6502/mod.rs](https://github.com/rdeioris/impostor/blob/master/src/mos6502/mod.rs)
I can't remove nightly. `rustup self update` doesn't seem to do anything at all. And yeah, I do have a space in my username. The computer isn't tied to any account.
I rarely write Rust code that's optimized unless I'm really bored. I focus on correctness, getting it working, etc. &amp;#x200B; The nice thing is that it just \*is\* faster.
If I'm not missing my guess, most of the code isn't concerned with the mechanical parsing, it's unescaping tokens, creating the syntax tree, checking rules not enforceable by the grammar, providing much more on-point error messages than "expected one of 100 possible tokens here", and suchlike. All of which are things you need to do by hand even if using a parser generator. (Still, not sure why people feel the need to downvote you so much.) 
Yeah I would definitely switch to criterion if it was possible to bench functions in binary crates.
By the way, `std::fmt` has some [goodies](https://doc.rust-lang.org/std/fmt/index.html#structs) to help write custom Debug impls.
Not everyone. My experience with Tcl during early 2000's teached me to only use such languages for scripting, for anything else a JIT or AOT based toolchain is a must, ideally both. Others like Twitter also learned the hard way.
Given that \`cargo check\` is a thing, why would this matter? When do you really want debug builds? I'd say 99% of the time it's for test/typechecking. So those would be --debug by default. But build would be --release by default.
\&gt; Does this mean that they manually wrote the whole parse logic? 8k lines, OMG ... &amp;#x200B; That is what you need to do if you want to get the best performance possible. 
tbh the bigger motivation for hand-writing parsers is better error-handling (not that it's impossible otherwise, but it's just not common in practice to have good error handling with generated parsers aiui)
There are many reasons why dereferencing a pointer can be UB. Maybe what you meant to ask is whether: fn foo&lt;T&gt;(x: T) { let y: ManuallyDrop&lt;T&gt; = unsafe { mem::transmute(x) }; // y gets dropped here, but because y is not drop, the // contents of x won't be dropped } is UB ? If so, the answer is no, it is not. Not dropping a value a.k.a. leaking a value is defined behavior.
Are there any major compilers that actually use those, though? I've always found proper error generation to be basically impossible with parser generators.
Why? Very few mainstream compilers use a parser generator. For small and medium compilers they are great, and they are great for having a standard definition.
I tried using musl, but it was giving me a hard time with reqwests mandatory dependency on openssl (even though I don't plan on using https yet). I could have used the musl docker containers, but then I'd need to install packaging tools there; at that point it was easier to build using Docker containers for the target systems (e.g. it's very easy to build a Debian Stretch package on Debian Stretch, etc.). &amp;#x200B; musl looks great if you need to deploy a single binary, but I also wanted to deploy the systemd service file, so using distro packages was attractive.
\*\*Update\*\* Changed some of the language in the README per discussion. Fixed some bugs and improved the API. Also released common predefined tasks in a separate project, tinyrick\_extras. Added more exampes. tinyrick! &amp;#x200B; [https://github.com/mcandre/tinyrick](https://github.com/mcandre/tinyrick) [https://github.com/mcandre/tinyrick\_extras](https://github.com/mcandre/tinyrick_extras)
I got it working somehow. For whatever reason the error I got when I tried to remove nightly in the past didn't occur this time around. Everything works now...
Rust doesn't really have a runtime type system by default (though you can opt-in to a limited one as I'll demonstrate below) so you can't really do this without modifying the trait somehow. I've come up with a couple options, but first can I ask what you're trying to do? More than likely there's a much more idiomatic approach but your limited example doesn't really give us anything to work with because you can just do that in a trait method and let Rust dispatch it for you: trait I { fn print_identity(&amp;self); } impl I for Foo { fn print_self(&amp;self) { println!("Foo"); } } impl I for Bar { fn print_self(&amp;self) { println!("Bar"); } } fn main() { let a: Box&lt;I&gt; = Box::new(Foo {}); a.print_self(); } A more direct translation of your example would be to redefine the interface as an `enum` with `Foo` and `Bar` as variants, but you can't add more variants later without changing the definition of the enum: enum I { Foo(Foo), // contains an inner `Foo` struct Bar, // contains nothing } fn main() { let a = I::Foo(Foo {}); match a { I::Foo(ref foo) =&gt; println!("Foo: {:?}", foo), // if `Foo` derives `Debug` I::Bar =&gt; println!("Bar"), } } Otherwise, if you *really* want some kind of runtime type dispatch, you can either add default methods to your trait that return `Option&lt;Foo&gt;` or `Option&lt;Bar&gt;`, or have your trait inherit from `Any` and use the downcasting it provides: trait I { // because these methods provide a body in the trait definition // they're optional for implementers to define // in docs they're called "Provided Methods" fn as_foo(&amp;self) -&gt; Option&lt;&amp;Foo&gt; { None } fn as_bar(&amp;self) -&gt; Option&lt;&amp;Bar&gt; { None } } impl I for Foo { fn as_foo(&amp;self) -&gt; Option&lt;&amp;Foo&gt; { Some(self) } // default body of `as_bar()` is inherited } impl I for Bar { // default body of `as_foo()` is inherited fn as_bar(&amp;self) -&gt; Option&lt;&amp;Bar&gt; { Some(self) } } fn main() { let a: Box&lt;I&gt; = Box::new(Foo {}); if let Some(foo) = a.as_foo() { println!("Foo"); } else if let Some(bar) = a.as_bar() { println!("Bar"); } } Or, changing your trait to inherit from [`Any`](https://doc.rust-lang.org/nightly/std/any/trait.Any.html) basically provides these methods for you without having to define them for every type, but `Any` is restricted on the types that can implement it (namely it can't be used on types containing references that are not `'static`): use std::any::Any; trait I: Any {} fn main() { let a: Box&lt;I&gt; = Box::new(Foo {}); if let Some(foo) = a.downcast_ref::&lt;Foo&gt;() { println!("Foo"); } else if let Some(bar) = a.downcast_ref::&lt;Bar&gt;() { println!("Bar"); } } 
It's not about being written in Rust, it's about the fact that hand-written parsers are far superior to generated parsers for the purpose of informative and useful error reporting. Formal grammars are great for specifying a grammar unambiguously and serving as a standardized reference, but in practice I see no chance that rustc will ever use a generated parser, because error messages are so important.
`Arc&lt;Mutex&lt;mpsc::Receiver&lt;_&gt;&gt;&gt;` is really bad. Think about it. `crossbeam_channel` is a top notch, high speed implementation. One day maybe it will just replace the stdlib one (which is OK right now, but not as good).
Even small websites nowadays use JQuery/Angular/React/whatever the current hip Javascript framework is. These frameworks do most of the heavy lifting - so if they along get ported to wasm we should see a huge speedup, even if the website itself still uses Javascript.
&gt;I dunno, how does PHP, python, perl etc. know how to print stuff? Well for python, it just displays the address by default: &gt;&gt;&gt; class foo: ... def __init__(self): ... self.bar = 4 ... &gt;&gt;&gt; print(foo) &lt;class '__main__.foo'&gt; &gt;&gt;&gt; f = foo() &gt;&gt;&gt; print(f) &lt;__main__.foo object at 0x7ffa1f562550&gt; If you want to do that in rust, you can use [the pointer formatter](https://doc.rust-lang.org/std/fmt/trait.Pointer.html)
&gt; Was I that unclear?... To me at least yes, because then I answered your question correctly the first time. There are no dereferences in the example that you just posted :/
I had kind of the opposite experience as everyone here where I was expecting incredible speed from JSON processing in rust but it was basically the same speed as my elixir version. Elixir is much faster than ruby, but not what I would consider a particularly fast language. In both languages I was seeing about 5ms to parse a 50KB JSON file into a list of structs, and doing some light processing. Is that what I should expect? I was assuming it should take on the order of 10s of microseconds. Code is here: https://github.com/losvedir/hawkeye
Yes but you cast a pointer to deref it and I explained in the text... but ok It's not that hard to understand what I wanted to do... I'm not casting the pointer for fun.
Thanks! Great explanation, much appreciated. I'm learning Rust and was wondering if I could define functions on traits that aren't modifiable, for example if the trait is in another crate. While I can define functions on the concrete types of such a trait, it looks like although I can define a function on the trait itself, it isn't too useful. This comes up if a struct implementing the trait recursively refers to the trait. This "visitor pattern" is one such example: // Multi methods example // http://nice.sourceforge.net/visitor.html #![allow(unused)] // legacy objects in separate crate mod exp { pub trait Exp { } #[derive(Copy, Clone)] pub struct IntExp { pub val: i32, } impl Exp for IntExp { } pub struct AddExp { pub e1: Box&lt;Exp&gt;, pub e2: Box&lt;Exp&gt;, } impl Exp for AddExp { } } // pretty print visitor use exp::*; trait PP: Exp { fn pp(&amp;self); } impl PP for Exp { fn pp(&amp;self) { print!("???"); } } impl PP for IntExp { fn pp(&amp;self) { print!("{}", self.val); } } impl PP for AddExp { fn pp(&amp;self) { print!("("); self.e1.pp(); print!(" + "); self.e2.pp(); print!(")"); } } fn main() { let a = IntExp{val: 3}; let b = IntExp{val: 4}; let e = AddExp{e1: Box::new(a), e2: Box::new(b)}; let e = AddExp{e1: Box::new(e), e2: Box::new(a)}; // pp the legacy objects e.pp(); } Its `impl PP for Exp` where the trouble arises. Any particular reason that Rust doesn't allow run-time type dispatch for traits? Type info could be stored with the vtable couldn't it?
Fork-join parallelism, like what Rayon uses, is not really suited for unbounded input like reading from stream.
Is there any language feature this response does not apply to? Do you think rust has any advantages over a macro assembler with an equally powerful macro system?
That's somewhat terrifying.
[https://github.com/rust-embedded/rust-raspi3-tutorial](https://github.com/rust-embedded/rust-raspi3-tutorial)
True, but it doesn't particularly matter in terms of allocation cost for small integers. There is cost in terms of pointer chasing, abstractions, operator overloading, and the like.
 I think CS140e will have another session in December. They'll probably have some more of the kinks worked out the second time around.
You are right, even ensuring I did not mutate or drop the Box&lt;T&gt; it doesn't make it safe if I do not own it. I kept as a raw pointer (wrapping it with NonNull) and now the UB is gone. I need to better understand variants. It's taking some time to set it.
&gt; are you just picking the next syntax node, or are you do something smart with white space? To simple and useful rules are We don't have nodes representing the whitespace itself; we just have gaps between non-whitespace nodes. So right now, we just find the next larger node that contains your current selection / cursor, with no additional logic. I think there is room to refine the experience though. I should take a more detailed look at what IntelliJ IDEs do. I'll take a look at the logic you've linked there as well.
Yeah, the faster your parser is, the less important incremental parsing is I guess. But that file is still not that huge, and 20 milliseconds is fast, but not fast enough that you'd want to do it on each keystroke, so it does make for a different user experience than incremental parsing. With incremental parsing, the vast majority of the time, we can update syntax highlighting on the very next animation frame after you type a key, instead of having the highlighting *switch* after a perceptible delay. Another way in which incremental parsing is *indirectly* helpful is that it makes it easy for downstream code to determine which portions of the syntax tree have changed. As a really simple example, the code for rendering lines in Atom and VSCode is somewhat expensive, so you don't want to update lines whose highlighting haven't changed. With Tree-sitter, we "diff" the old and new trees very cheaply, because they share internal nodes, so we can "short-circuit" a lot of comparisons due to pointer-equality. On the other hand, I can imagine that there might be other more domain-specific shortcuts that you could take when diffing two trees in libsyntax2, if you wanted similar functionality for identifying changed regions. And one other thing is that memory consumption of concrete syntax trees can be significant, because they contain so much detail. It's nice that with incremental parsing, when you respond to a change, your new syntax tree can share structure with your old one, just to have less spikes in memory usage.
I have been following the cs140e course assignments and there is more than enough information on the site to do the assignments. Some of them are tricky, but it's totally doable.
It's necessary for your panic handler to be able to access the panic message. If you're fine with your panics containing no details, you don't need it. You also probably won't get far without inline asm or intrinsics, so while it's "possible" to do embedded stable now, I wouldn't say it's "easy" or "fun" yet.
I've heard proponents of parser generators say that things are much better now, but once burnt twice shy... (I don't have infinite time).
This would actually work really well with wasm. Wasm pages are quite large (64 kb).
AFAIK table based parsing algorithms like LR(k) are generally faster than recursive descent. Of course, the most important optimization in parsing is probably just designing the grammar to be easy to parse.
Have you heard of redox before? They have a branch on their gitlab that adds support for arm. With the goal of supporting the rpi and other arm devices. https://gitlab.redox-os.org/redox-os/redox/merge_requests/1193
&gt; and require you to learn a completely different syntax with its own quirks. It's HTML. That's mostly what you are using. As someone who does a lot of front end work, I would not use Rust for web UIs unless it had an equivalent to JSX. We had the library driven UIs in the past and not supporting JSX, or an XML based template language, feels like a step backwards.
Yeah, that's cool! I hope at some point creating distro packages will be as simple as creating multiplatform binaries with musl. It would be a pretty attractive value proposition for Rust, although I think nowadays native packaging is losing mindshare.
I used to run an entire browser (Opera 5) on a 486 with 16 MB of RAM… :(
OK, good point, so allow me to clarify: The `do` notation basically introduces the concept of _statements_. A statement is a pure expression that returns an `IO` value - which is basically a combination of a "command" and a function. This `IO` is handled by an executor, which executes the and then calls the function (potentially with some "result" of the command as argument). The executor may be something impure - like the runtime - and then the command may be doing side-effects. Back to Rust - generators seem very similar to this concept. A generator `yield`s something - which is similar to returning an IO to the external executor that can do whatever it wants with it. Then, instead of calling the function - which in Haskell means running the next statement - the executor `resume`s the generator, which again means running the same statement. There are small differences (like `do` notation's partial match, or the ability to vary the argument type for the function), but these can probably be replaced with macros - like the `try!` macro that solved the same problem partial matching was solving. So, instead of "generalizing async/await syntax to a do-notation", I say we can use the underlying generators mechanism to do whatever we would have done with a `do` notation. Unless there are some problems that `do` notation solves and can't be solved that way?
&gt; Given that `cargo check` is a thing, Because thats static analysis, "does this compile", and completely unrelated to debugging? &gt; When do you really want debug builds? ...for debugging? with debuggers? at runtime? every language does this?
Goodbye failure!
In my experience, pandas degrades rapidly (ie non-linearly) as the data size increases. Opening a 10-15gb csv is slow and uses a lot of memory. 
binary crates are just library crates with a `main.rs` file, what is preventing you from benching the library parts of the crate?
https://www.reddit.com/r/rust/comments/5penft/_/dcsgk7n
I don't know what performance hit it's causing, but you don't need to wrap the receive handle of your channel at let r = Arc::new(Mutex::new(r)); You can just clone+move the clone directly, which would then obviate locking the Mutex.
I have multiple workers. I can move it only once.
&gt; But it looks like there can’t be any breaking changes to it, because at this point failure is too big to fail I don't understand that point, since semver allows breaking changes. Major crates likes `serde` have had breaking changes, and that has not been a problem. &gt; Also, I’ve seen people (including myself) getting confused by the failure documentation wrt. the ErrorKind pattern and the Context API. I've been confused as well by the documentation, and after a few hours trying out the various patterns I realized I actually needed to implement a [new pattern](https://github.com/rust-lang-nursery/failure/pull/260). I think the doc lacks examples that shows where each pattern may be appropriate. But that's pretty hard to do that without throwing a lot of code to the reader's face, so I don't know... If you have idea about how to improve the docs, please open an issue, I'd be willing to help with this. &gt; So, while it’s not unreasonable to use it, failure today is probably not how Rust error handling will end up looking in a year or two. For those un-aware, I believe you're referring to [this RFC](https://github.com/rust-lang/rfcs/pull/2504)
I did a lot of work on this in C. I wrote [a tutorial] (jsandler18.github.io) on it, and a lot of it can be carried into rust. 
Yes. You may also be interested in libsyntax2, which is not currently being used by rustc, but may be in future (and is also designed to be suitable for use by the Rust Language Server) https://github.com/killercup/libsyntax2
&gt; I don't understand that point, since semver allows breaking changes. I legitimately don't know, but can a single project include multiple versions of the same crate? If I want to use libfoo which requires failure 1.1 and libbar that requires failure 2.0, does it all work?
&gt;ameters needs its lifetime specified even if you're not using any of the fields that have lifetimes. &gt; &gt;Since it doesn't look like you're using those fields, you might be able to get away with updating your struct to draw\_params: DrawParameters&lt;'static&gt;. Obviously if you ever DO need those fields, you'll need to give your struct a lifetime and properly thread it through your new function and the DrawParameters struct. So I would need to put the DrawParameters initialization outside of the new function? is there no way to avoid that even if the DrawParameters struct and all of it's child structs are inside of the function?
It's not the initialiser that has the lifetime, it is the `DrawParameters` struct itself which has it - therefore whenever you use that type, and the lifetime cannot be inferred, then you need to specify it. In this case it is when you are storing an instance of `DrawParameters` in your own struct. If you only used `DrawParameters` in your `new` function but didn't actually store it in the struct then you would not need to specify a lifetime.
&gt;In this case it is when you are storing an instance of DrawParameters in your own struct. If you only used DrawParameters in your new function but didn't actually store it in the struct then you would not need to specify a lifetime. I thought that by putting it in my struct it would transfer ownership to it though? I think that's what I'm misunderstanding. By transferring ownership, I would think that it would take the lifetime of my Renderer struct. Could you explain why that isn't the case?
Wow I had not realized how popular it was. Impressive. But also kind of worrying given how [uncertain](https://github.com/rust-lang-nursery/failure/issues/209#issuecomment-425670120) its future seems to be.
8k lines isn't a lot. There was a project that I wrote 1k lines in a single day. And a small calculator that I wrote for my Data Structures class is 3k lines already.
I use the `vorbis` crate along with `alto` (OpenAL for Rust). Basically, open the song.ogg with `vorbis` and stream the PCM buffer to OpenAL with `alto`. There might be simpler crate for that, though. Maybe have a look at the SDL, fmod, etc.
`le_foo` French pun. :)
&gt; I'd rather rust not cater to the lowest common denominator and spam the output with basic stuff like that. We're talking one additional line of output. Hardly 'spamming'. Also I'd like to know why you want Rust to *not* cater to new users. Gatekeeping is not a tenet of this community. &gt; Pretty much every compiled language works this way. Even web languages like javascript have a separate optimization phase, where you minify everything for page size and performance. Historically, the Wirth languages (Pascal, Oberon) had no separate optimization phase. I even remember many single-pass compilers. Also just because other languages do something doesn't mean Rust has to do it. We can and regularly do blaze new trails.
Both dependencies will include their own different versions of the crate, and be fine. The problem is that failure specifically is about using the `Fail` trait, and if one library expects `T: Fail_11`, and another libraries types implement `Fail_20`, they don't match. Better yet, the compiler error is pretty confusing, since it doesn't distinguish the versions like I did.
A `DrawParameters&lt;'a&gt;` struct doesn't have a lifetime of `'a`, it has a lifetime that must be specifically less than `'a`. If your struct has a `DrawParameters&lt;'a&gt;`, then it has to prove that it, too, doesn't survive longer than `'a`, because your struct has ownership of it and thus the lifetimes are bound. The reason that `DrawParameters&lt;'a&gt;` has that lifetime bound appears to be that it can potentially contain references to external entities (like `transform_feedback`, for instance.) As Branan said, if you aren't using those, you can safely have `draw_params` be a `DrawParameters&lt;'static&gt;`, but if you are, you have to prove to the borrow checker that your `Renderer` (and its `DrawParameters` member) will not outlive those references.
For the record, it looks like this probably caused OP (/u/pleurplus) to delete his post. (Which is bad manners, IMO.)
I am king of the scoreboard! (For now.) Are you sharing the code at all? What framework was it written with? Any Rust-related info you'd like to share?
posting this question is looking for the answer 
This post is really amazing thanks. Now I think i understand the concept more solid
How do you mean, not standard? Can you provide supporting link(s) for that statement?
thank you!
A 400-element matrix is really small by computer standards. Spawning and joining threads and sending the results back to the main thread take the same amount of time no matter how much data there is, so when the data processing is already very fast it more than cancels out the speedup from parallelism.
You're the one asking for help; don't be a douche and start demanding "SAUCE!" for every statement from the very people you're asking for help from. My source is over three years of programming Rust and participating in its community. If anything idiomatic Rust errs too much on the side of monomorphized generics; i.e. static dispatch. Dynamic dispatch is supported but it's not the tool which Rust users reach for, or indeed using trait objects at all. You should read [this](https://doc.rust-lang.org/stable/book/2018-edition/ch10-00-generics.html) to learn the idiomatic way to use traits, which will answer your question about why Rust doesn't need to work the same way Java does.
The title make it sound like he used extension traits to replace failure. In reality these were two entirely unrelated changes he made.
&gt; without a space in its name. That's sometimes an issue. It's 2018 AD. Is space still really a problem in paths? 
Just remap your cargo and rustup directories to a different path with `CARGO_HOME` &amp; `RUSTUP_HOME`.
You're correct, \`DrawParameters\` struct is owned by \`Renderer\` struct, it's lifetime is the same as that of \`Renderer\` struct. The problem is that \`DrawParameters\` struct has a lifetime parameter, this parameter doesn't describe lifetime of \`DrawParameters\` struct itself, instead it is used to describe a lifetime of some references (potentially) stored inside this \`DrawParameters\` struct. Take a look at [definition](https://docs.rs/glium/0.22.0/src/glium/draw_parameters/mod.rs.html#345).
So is there no way for me to say that the lifetime of the references in the DrawParameters struct have the lifetime of the Renderer struct? &amp;#x200B;
From the docs : &gt; Crate write_ref &gt; &gt; Write-only references. &gt; &gt; Many functions in Rust's standard library, such as char::encode_utf8, take a mutable reference that they only ever write to. &gt; &gt; This crate provides a way to express this guarantee
&gt;AFAIK table based parsing algorithms like LR(k) are generally faster than recursive descent. Recursive Descent Parsers are way easier to implement than bottom-up LR(k)/LALR(k) parsers AFAIK. &gt;Of course, the most important optimization in parsing is probably just designing the grammar to be easy to parse Sure. Left-recurseive grammars for LL parsers are a no go :)
The game is based on simple JavaScript. If people are interested, I can share the code, just need to load it into Github. It would be two part - client side Javascript and a node.js server for the High Score. The main teachings of the game is that the "doubling-up" strategy works best. At least as far as I have tried - perhaps you can share how you got to 2K? :D
Not understanding what this JS app is doing in /r/rust. Maybe you wanted /r/playrust instead? Got to 2K the obvious way. :|
I don’t know your experience level to properly interpret what you have described, but that doesn’t sound any easier just because of rust. Rust give you language level guarantees, which means if user code uses rustc, compiles against your API and doesn’t run unsafe code it won’t be able to make bad things happen. And hopefully your kernel code is internally memory safe. But rust as an OS dev tool doesn’t actually have any concurrency features. There is no such thing as threads when you don’t have a scheduler yet. You can’t use any existing concurrency-multiplier crates beyond instruction level. Immutable data is just data you have Rust-level access to, but it’s only actually immutable if you tell the page table it’s read only. Your immutable borrow means nothing to me, a C program compiled against your API. In a nutshell - there are no shortcuts. But at least it is nice to write.
Nice. Can this be used to count substrings(case insensitive) in a large text file?
So I figured it out. For any other beginners if you come across the same problem, I found out that you can append a lifetime to a non-reference parameter like this: draw_params: DrawParamaters&lt;'a&gt; I hope that helps you!
Ooh, thank you! That should simplify things a bit.
hey u/elession, I'm trying out jsonwebtoken, It panics on decoding. I thought I had some wrong code but both of the repo examples are also panicking. any Ideas?
My guess is that GCC has a reputation for being a monolith with poor internal abstractions, compared to LLVM's more modular design.
You can try https://crates.io/crates/par-map Feedbacks welcome.
I have a lot of music I'd like to use in mp3! Or I convert everything to .ogg... Thanks by the way, you helped me a lot, I'll go to find a way ;)
&gt; Borrowing across yield points We want to get that regardless of `do` notation. &gt; `.and_then()` sugar-syntax Isn't that what the `?` operator does?
The repo examples are panicking because I am using `panic!` and I forgot to update them for validation of `exp` for example. The lib itself should not panic, can you open an issue?
Maybe you're filling an [uninitialized buffer](https://docs.rs/tokio-io/0.1/tokio_io/trait.AsyncRead.html#method.prepare_uninitialized_buffer)?.
I think this is a pretty poor proposal. 1. I don't want to buy a domain to be able to upload crates. Others can't afford to. 2. Why do this in the first place? It doesn't decentralize anything (we're still relying on a central crates.io), and now we've added the complexity of domain names for no apparent reason other than to throw our hands in the air and proxy the issue to some other system we have zero control over.
Currently it's all custom code. But looking at the tempo of my progress I think I'll give Amethyst a try. I was about to use specs crate as a core part of the engine but it looks like Amethyst is built on top of it, which is great.
Maintaining extra 8k lines of code is some work. \+8k lines of code or -8k lines of code to maintain makes a difference, IMO
What did you use to benchmark your site?
Well, that was my first thought, as this may help with code optimisation by skipping of the initialization step. But then, this does not give you a gurantee, that buffer was actually initialized by the function. So as a result you would have a *probably* initialized buffer, which does not sound good enough to me.
I agree, such a function should be marked as unsafe.
This is great. However, the repo seems empty to me. Is there any problem? And please inform me about whether people liked the workshop or not.
Well, the never type is already coercible into any other type already, isn't it?
Because there's no reason to disallow it (since a such a value can never actually materialize, it's actually perfectly safe to convert it to anything). Also, such impls being present can make some code more convenient. [See this part of the docs](https://doc.rust-lang.org/std/primitive.never.html#-and-traits) for more information on the matter.
You can find a pretty good explanation in the docs: https://doc.rust-lang.org/nightly/std/primitive.never.html#-and-traits
&gt; I don't want to buy a domain to be able to upload crates. Others can't afford to. You don't need to.
Yea, it's pretty obviously safe. I just don't know why the compiler allows us to write this, or in fact why it forces us to write this. Since all possible implementations have the same behavior (if you can call it a "behavior" when the method will never be called), why not just have the compiler accept any method call at all?
That is a nice way to write it, but possibly a little obscure.
Honestly, reading the other comments I'm still pretty confused. What's there to prevent two different implementations of \`impl From&lt;!&gt; for u64\`?
what are you even saying? do you want us to scrap the whole parser of rust so we can use a parser generator? to what benefit are these arguments you're making?
Presumably the same rules that prevent you from having two `impl From&lt;u32&gt; for u64`.
An interesting comment on the current state of SIMD in Rust can be found in the PR implementing this change: https://github.com/llogiq/bytecount/pull/44#issue-210971118
Ex contradictione non sequitur quodlibet &amp;#x200B; By which I mean that it's commonly understood in format logic that if you start from a false assumption (in this case, the assumption is that a value of type \`!\` exists which it cannot), then you can reach any conclusion: [https://en.wikipedia.org/wiki/Principle\_of\_explosion](https://en.wikipedia.org/wiki/Principle_of_explosion)
After updating to the latest version of rust (1.30), the terminal doesn't output colors. What should I do to fix this?
Agree on all points! To clarify libsyntax2 parser is incremental, and it's syntax tree has structural sharing, but this incrementality is just two special cases: * when an edit changes a single token, we don't run parser at all * parser is written in such a way that it preserves pairs of `{` `}` even in the presence of syntax errors, so we only need to re-parse the enclosing braced block, if the edit haven't changed the curly-braced structure. 
Maybe. However, current rust compiler has about 330k loc, 8k is just 2% of it. As some have pointed out in this thread, manually written parser has the advantage of speed and better error diagnostic. In this case, it's clearly more important than maintainability. 
Yeah, because the type system is how you avoid malware!
I see. Sorry, I don't have time to waste on internet trolls. Farewell 
The empty mach is necessary for other uninhabited types like empty enums, but for the never type you don’t even need that since it’s coercible to anything: #![feature(never_type)] fn from(v: !) -&gt; u32 { v } https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=24ef9d60d427ea5bacd72d95febbd751
The compiler has no way to know what the length of the \`Vec&lt;i32&gt;\` variable is. If you don't need vectors and instead use arrays, the compiler can catch these kind of accesses: &amp;#x200B; \`\`\`rust let v = \[1, 2, 3, 4, 5\]; v\[22\] \`\`\` &amp;#x200B; This leads to a compile-time error
Indeed, the code in OP causes `error[E0117]: only traits defined in the current crate can be implemented for arbitrary types` https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=a70b7150d2ac7af7eae59aa279440378 I think this thread is mostly about why defining unreachable functions is allowed. (A function that takes a parameter of an uninhabited type can never be called, since that argument can never exist.)
Thank you. 
It certainly is a really good way to model *only* the desired effects.
*Taps head* Don't need to worry about the behaviour of your code if it can't possibly be called. 
The RFC for the generic version was submitted half a year ago but it seams dead.
I think your logic is flawed :)
I always like to bump the version number once more to the next pre-release. For example, I'll bump the version number to `0.5.0`, tag a release, and then immediately bump to `0.6.0-dev`. That way, there aren't multiple variants of the same version in the history.
[removed]
https://www.npmjs.com/package/loadtest
&gt;If you want to search for a single case insensitive substring What about searching for several substrings? Could SIMD be used to speed up `aho-corasick` or is that crazy talk?
This is great! I wrote out the steps I use for the turtle crate a while back because it's actually a pretty complicated process with many steps. I think I would benefit from adding some of these. For the curious: https://github.com/sunjay/turtle/blob/master/RELEASE_CHECKLIST.md
It's so that you can do things generically with `!` in exactly your situation. Another really great example is [`Termination`](https://doc.rust-lang.org/std/process/trait.Termination.html) from the stdlib. It's currently unstable, but `main`'s return type must implement `Termination`. By providing an implementation for `!`, even though the `self` method is uncallable, this lets you use `!` as the return type for a main function which never returns. It's also so that if you substitute `!` into a generic function and the result is uncallable, you don't get an error right away. That would break generics a lot, because e.g. you couldn't create a `Result&lt;T, !&gt;` since the constructor `Err(!)` is uncallable.
Thank you!
On an unrelated note, isn't it strange to use such a terse notation for something as arcane as a never type? Couldn't it have been called `never`?
Thank you for your feedback! What do you mean by "multiple variants of the same version in the history"? That there are multiple commits with a given version in the `Cargo.toml` file? Does this cause any problems? I don't think you can accidentally publish the same version twice. I'd only consider the `git tag`ged version to be the true release with a given version. I also wouldn't know how to bump the version number. What if I need to release a `0.5.1` bugfix release? What if I decide that the next version will be the first `1.0` release?
Cara, que? Who uses accents in their code?
You have to use tuples (they are fixed) let t = (1, 2 3, 4, 5); let fail_to_compile = &amp;t.22; assert_eq(t.0, 1);
&gt; why am I able to do it at all? If you're curious, you might look into the principle of explosion and the Curry-Howard correspondence. Basically, it is well known that if you have a value whose type is uninhabitable, then you can have a value of any type at all.
It's not that uncommon to have diverging functions in systems programming. While ! is certainly spooky black magic in general it's original and most common use as the return type of a function that doesn't return isn't realy arcane. Calling it never or something would mean you'd need to explain the concept of uninhabited types before you could explain how to write a function that always panics or loops forever.
Oh cool! that seems like a good solution.
Rust had the special notation `-&gt; !` expressing a diverging function long before `!` was promoted to a real type, so it made sense to continue using the same symbol. 
I feel like tokio and futures is probably the best place to start searching if you're going to be handing packets on many ports at once.
This seems directed specifically at binaries, not libraries?
Probably https://crates.io/crates/chrono or https://crates.io/crates/humantime.
.... [https://www.reddit.com/r/rust/comments/9s3gxf/my\_release\_checklist\_for\_rust\_programs/e8ly1cj/](https://www.reddit.com/r/rust/comments/9s3gxf/my_release_checklist_for_rust_programs/e8ly1cj/)
SIMD might kick in for a small number of case insensitive literals. Aho-Corasick is your traditional finite automaton. You can use SIMD (e.g., memchr) to find the starting byte if applicable. Otherwise, I think you need to go down the icgrep path, but I don't too much about it, but they do take advantage of SIMD if I recall correctly.
I came across redox, it looks awesome. but its not "teaching" or anything, its just a ready-made project to use, no? My goal is to find something like a set of lectures/sessions with small tasks that guides me through this, from the start. &amp;#x200B;
Thanks, I will keep an eye on the next opening and see if the reading material and exercises have improved
Thanks!! SecondaryMap were very necessary and TypedKey are very welcome too. Very nice crate, it is helping me to speedup code replacing lots of hasmaps.
oh I mean it panics in the examples, and errors out in mine with \`Error(ExpiredSignature)\`. Is there anywhere I can have a look at a working example?
should be "sequitur" not "non sequitur"... otherwise it's "from a contradiction doesn't follow anything you like".
I just pushed updated examples and README to take into account the `exp` parameter. In short, `decode` will try to validate whether the token is expired by default. If your token doesn't have an expiration, you need to change the `Validation` struct passed to `decode`.
From the top of my head: - https://doc.rust-lang.org/rust-by-example/index.html - https://github.com/rustlings/rustlings - https://exercism.io/tracks/rust - Think of small example programs you'd want for yourself (that's how I came up with [this example](https://killercup.github.io/quicli/thumbnails.html) for instance)
A lot of that magic happens inside LLVM. It would also be strange for a program to compile or not compile depending on the optimization settings.
More generally, it would make sense to have a warning for functions that always panic and does not return the `!` type. If done after optimization, the provably non-reachable control flows would be pruned and would make it easier to test for.
You can fake it by putting the methods as inherent to the type, then having the trait impl delegate to the inherent impls.
Oh definitely. It would be fine if it just turned that code into an unconditional panic at runtime. A warning or lint might be cool perhaps.
IIUC, the intent is that `!` should grow up to be fairly common of a type in function signatures for deleting an enum variant. The most common showcase is `-&gt; Result&lt;_, !&gt;`, where you're declaring that this specific fallible operation cannot fail. The intent is for it to replace most occurrences of an empty enum. (And `extern type` replaces most of the remaining chunk.)
I'm not sure I follow
impl Vector2 { } And put the trait methods there, and when implementing the trait you just call them.
oh, gotcha
Thank you, I'm glad you like it. Good luck with your project - Let us know when you have something to show!
\&gt; Because thats static analysis, "does this compile", and completely unrelated to debugging? Not really entirely unrelated, given that the code is compiled in debug mode... I'd say the vast majority of the time code is compiled in debug mode it's probably for type checking, followed by code compiled in debug mode for running tests. Actually using a debugger being a minority of the time. For the case where you explicitly want debug mode \*for debugging\*, passing --debug seems fine. This is probably something you'll do significantly less often than other use cases where the only reason you compile with debug is because it's faster.
Can I suggest another step? Use [cargo-deadlinks](https://github.com/deadlinks/cargo-deadlinks) to check if you have any dead links in your documentation because you renamed or moved some type/function.
[Relevant xkcd](https://xkcd.com/704/)
I have been reading the code implementation for Futures. There is one part that got my attention. The join function. It seems like there is a bunch of join functions named join3, join4, join5 https://docs.rs/futures/0.1.25/src/futures/future/mod.rs.html#715 Is that actually a decent implementation? Why 5 maximum joins? Isn't that basically code repetition? Isn't it possible to use an array/vector of sort and have the coder put as many joins as he wants?
I would be also interested in comparison of this with `rsync`. 
I just used the title of this paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.107.70 
Repo link on crates.io requires a login. Is this intentional?
Thank you for the feedback. This sounds really useful. Unfortunately, it currently `panic`s for my binary projects (because there is no `target/doc` folder). It's certainly useful for library crates, though. Unfortunately, it doesn't seem to check HTTP links (yet) - only local links within the documentation.
5 is more than likely an arbitrary decision to avoid too much code bloat. The thing with using an array or a vector is all the futures have to be the exact same type whereas the tuples can have any kinds of futures as long as they all resolve to the same type. It'd be possible to have something like [frunk](https://crates.io/crates/frunk) for heterogeneous collections but I'm not sure what an implementation using that would look like. A macro based solution might be better but it would have to produce an `impl Future` that's just a mess of combinators. The advantage of the current approach is that the futures types are nameable so they can be put in datastructures without boxing. Although, a large enough combinator chain might be better off boxed anyway so moves are cheap. 
Like in their original example, `T` is only used in the trait bound on another type.
1. Never used it but search brought up https://github.com/Technolution/rustig 2. `#![deny(unsafe_code)]`
humantime is pretty great for RFC3339 date/time parsing too. Around 5-10x the speed of chrono.
That's exactly what I did
Also allocation panics. It shouldn't in any normal situation on modern desktop hardware, but it's still a possible panic compiled into your code.
Good point! I'll put together a minimal example that shows where I am having trouble.
Useful tip. Thx
Sorry didn't change the permissions correctly. Should be visible now.
Why does this compile? `type A = (str, str);`
Can't be as easy as grepping the used function for panic and unsafe and display the error? I see what you mean that unsafe have to stop somewhere, but for panic? Yes some integer math panic, but I want to know when I may panic, is not like addition can, and I want to be warn about possible division by 0
&gt; for example, in another post a guy created a Vec and then access it out of bound with [], clearly the fix was to use get() I'm not sure I agree with that assessment. You shouldn't access indices you don't know for sure to be valid. In their case, the index was clearly invalid, and that was intentional.
Small nit: I think some of your benchmarks use "x" (multiplier) instead of "s" (seconds).
Is there anything at all I could do with this A? I mean, this does not even compile: fn foo&lt;T: ?Sized&gt;() {} type A = (str, str); fn main() { foo::&lt;A&gt;(); } &amp;#x200B;
And then there's the possibility of the underlying OS using overcommit, meaning that your allocations won't fail but your program can get killed randomly at any time for using the memory that it has successfully allocated. Or, because it's random, it can even be triggered from another program accessing memory.
Yes, integer addition _can_ panic (in debug mode): `255u8 + 255` will panic from the overflow. (Though just writing that as is will error since Rust can see the unconditional overflow; consider instead taking two unknown integer values and adding them.) Any allocation can panic if an Out Of Memory error occurs. _Calling any function can panic_ (from stack overflow). And think about it this way: if you really did handle every single potential panic explicitly, what would it look like? I'd argue that for a majority of replaced panics, you'd just bubble the error up to `main`, print what went wrong, and exit with an error code. That's exactly what panics already do for you. The space of panicking functions that offer a non-panicking variant that you'd actually be able to locally handle the error condition is relatively small; Rust APIs tend to prefer to return a `Result` (or `Option`) and let you `unwrap` it if that's what you want. It's pretty much only indexing and other operators that use panics in this way. See the other linked "check for panics" tool for why a simple "grep for `std::intrinsics::panic` isn't enough.
What are your requirements? Do you need to deal with calendars except the proleptic Gregorian calendar? Do you need precise support for leap seconds? etc.
It's obvious for people coming from C, it's not so obvious for people coming from languages with interpreter. 
`cmp` is provided by the `std::cmp::Ord` trait
I love that questions seem to find an answer after you ask them. I found it in the traits of str: https://doc.rust-lang.org/std/primitive.str.html#method.cmp So it looks like str has the "Ord" trait which implements cmp. I'm guessing that "traits" are like interfaces. A type can declare that it implements zero or more traits for things like, "I'm orderable", "I'm hashable", "I'm printable", etc. Very neat.
Thanks for the detail. "Standard Prelude" is something I didn't discover on my route through the intro docs. Very helpful to read about and understand that.
Author here - excited you found this and hope it's useful to you all! I am aware the docs aren't super good yet, but am happy to take both PRs and experience reports! 
yup, that's basically crossbeam crate. Much recommended. Also, I think it's mpmc, in fact.
Quick scrolling the api did say nothing about panicking for overflow, so I assume it would automatically wrap around. See? Having a warning in this case would have help a noob like me. I see there are some panic intrinsics to the system, and those should be excluded, but hopefully are not many and can be blacklisted.
Oh you meant an existential then. Those are different semantics.
Thanks, I was checking for it here: https://doc.rust-lang.org/std/primitive.i32.html And here it say what and why panic, so it is an important thing to know... Why not automate it with warning?
There is no mechanism by which binaries can be controlled by `Cargo.toml`.
My binary is generated by Cargo.toml, installable via `cargo install`, and the lib and binary are published together on crates.io. I don’t understand why the lib, but not the bin, is installable using ordinary `Cargo.toml` dependencies, unlike just about every other package manager.
&gt; My binary is generated by a Cargo.toml, installable via cargo install, and the lib and binary are published together on crates.io. All irrelevant. You can't depend on binaries. End of story. &gt; I don’t understand why the lib, but not the bin, is installable using ordinary Cargo.toml dependencies downstream from my project, unlike just about every other package manager. Libs are *not* "installed". They get downloaded, compiled and linked implicitly as part of the build. That's Cargo's primary job: managing libraries to be linked into the final output. `cargo install` was an after-thought added when it was realised that you could upload crates with executable outputs to `crates.io`, but you couldn't do anything with them. It's not an integral part of Cargo's design.
Thanks, good eye. I've fixed in the repo.
In related news, I'm helping out the UNSW Rust group. Looks promising!
Ty
`use std::fs;` will just import the module, so you'll have to write `fs::File` and `fs::create_dir_all`. If you don't want to do that, you can write `use std::fs::{File, create_dir_all};`. Import statements don't affect binary size - they're just for name resolution.
&gt;Import statements don't affect binary size - they're just for name resolution. Ah interesting. Thanks! So does that mean the all of std::* is imported FULLY into every Rust binary/program?
Ha, this is hilarious. The CI detection could potentially be useful if it could pul out environment variables and normalise them somehow though... e.g. `volkswagen.git_commit_hash()`
Shall it also detect Crater runs?
Something along these lines would be really nice. Especially for something like `rusoto` which has every useful method implemented on a trait which corresponds 1:1 with a struct (not quite sure why, possibly for testing purposes?)
`core` is **linked** into every program. `std` is linked into almost all programs. Most programs will link any more third party crates. Linking combines compiled libraries into your program; removing stuff you don't use is an optimisation up to the linker (which isn't `rustc`). Linking and importing are unrelated. Importing doesn't do anything to affect final size; it just changes which names are visible from a given location in the source.
Remember to check [cargo-release](https://github.com/sunng87/vargo-release) to automate some of these steps.
Two solutions that are considered idiomatic (from what I can tell): * have the actual code as inherent methods on the struct and the trait impl calls those methods * have the actual code in the trait impl methods and have the struct impl call the trait impl methods
- Side effects include: behaving like `rm` does when specifically passed the `-rf` flag. Honestly not sure how that one happend
Thank you for your help, I'm nearly done with the second part of the tutorial
Check out the `built` crate, upon which this is built
I'd argue one should simply omit such tests
Good point. We may want to lint types with multiple unsized parts.
&gt; I say we can use the underlying generators mechanism to do whatever we would have done with a do notation. Unless there are some problems that do notation solves and can't be solved that way? ["Iterator" isn't the basis of all monads. It's continuation-passing (CPS).](http://blog.sigfpe.com/2008/12/mother-of-all-monads.html) So the answer is anything that CPS can do but List cannot.
I have researched the problem and I know you're right. Its still the biggest hurdle to using Rust on a daily bases for me. I love Rust. If Rust could compile to interchangeable libraries with C++, I'd never write another line of C++ again.
Hilarious
 Oh okay this is a learning moment. Are you saying that just because Foo implements a trait and I have a reference to Foo, I can't actually call any of the traits unless I have `use foo::TheTrait` in the file?
Great that you ported it to Rust +1 Out of topic question - I am curious why would anyone allow a failing test to look like it is passing.
It is late and I don't think I fully understand the question, but it sounds like you don't want to have external state being mutated by the user wide configs and data of `cargo` ? If this is the case, I'd work on some containerized workflow so that each project would have its own compilers, cargo, crates tree, etc.
Yeah, there's more info on how the prelude works [here](https://doc.rust-lang.org/std/prelude/index.html). There are also a lot of libraries that make their own module named "prelude" that you're expected to do a blanket import on to easily get all of the needed types and traits in scope, like [`futures`](https://docs.rs/futures/0.1/futures/prelude/index.html), [`tokio`](https://docs.rs/tokio/*/tokio/prelude/index.html), and [`chrono`](https://docs.rs/chrono/*/chrono/prelude/index.html). Part of the reason it's like that is because you can implement any trait on any type as long as one of the two was created in your crate. So I can add `trait MyLittleHash { fn hash(&amp;self) -&gt; u8 }` and `impl MyLittleHash for u64` to my library, which would immediately make code using the standard library's `hash` stop compiling because of the name ambiguity.
Sounds like it's satirizing https://en.wikipedia.org/wiki/Volkswagen_emissions_scandal
Favlors?
You ever find a solution for this?
You need to add "compliance innovation" to the skills section of your resume, op. 
Probably :)
Could you explain more about the intended use case for this? 
For the moment, I am developing this for my study.
If you want precise date and time calculations for scientific applications, I would recommend [hifitime](https://crates.io/crates/hifitime). It handles leap seconds, Julian dates, and moving reference frames (i.e. time dilation). Disclaimer: I'm the author and maintainer of this crate. I wrote it specifically for my [astrodynamics toolkit](https://crates.io/crates/nyx-space) which is validated against NASA software.
The nightly book has a section at the end of chapter 19. It just hasn’t reached stable yet.
I never realized how lucky I was for all of my software's users to be in the same reference frame.
Is this compatible with Diesel?
I'd count a panic as much better than implementation defined behavior, and especially better than undefined behavior, but I can understand the concern. Functions and accesses which panic from incorrect inputs have warnings in the documentation, and the only functions which do this are generally indexing ones. There are general patterns, and the general idiom in everything except integer indexing is to return a Result on incorrect indices. As other's have mentioned, `get` always exists. --- And as a last word - panicking isn't the end of the world. It can be caught, and it is very well defined. It'll run up the stack, running destructors properly, and very deterministically kill the thread it's in. There's nothing undefined nor inherently bad about panics! They're a good way to fail early if there's a logic error in the program.
I disagree. You will pretty much run into trademark issues with that.
I am currently working on finishing the [calculator demo](https://raw.githubusercontent.com/maps4print/azul/master/doc/azul_calculator.PNG) and the [table demo](https://raw.githubusercontent.com/maps4print/azul/master/doc/azul_table.PNG) using [azul](https://github.com/maps4print/azul)... still a few minor problems with the text layout, but yeah, otherwise it "works". I also discovered some new webrender bugs while making the calculator, but yeah... Other than that, I'll hopefully be able to do scroll frames properly, and then maybe build a node graph editor widget, which I'll need later on in an application.
I can't see them wanting to draw any attention to it! 
This looks really clean. I like the App trait with Action and State associated items — it's instantly familiar as I also use ReasonReact.
How do you not avoid trademarks with a library named that?
thx! Exactly. It's strongly affected by ReasonReact and Elm.
I mean it's interesting from an exploit perspective. A scary number of places will blindly accept code that passes tests.
If you instead made a trait that only let you access the array through getters and setters (like C# does indexing), that would still be safe. You wouldn't be able to use the existing index syntax unless you used some macro to rewrite it.
I see you use copy_file_range internally. On certain file systems, this will internally reflink instead of copy. Which might not be what the user wants :)
GCC and Clang have -Warray-bounds. So I'm not sure what kind of claim you're making.
GCC and Clang have -Warray-bounds. So I'm not sure what kind of claim you're making.
Why?
As mentioned in other comments, cargo doesn't manage binaries. I'm sure there is an RFC/discussion somewhere about adding it. Now, if you wanted to have **now**, you could write a cargo subcommand. It sounds like a nice side project: I'm imagining a rather simple tool that reads a special section of the Cargo.toml file and calls `cargo install $name --vers $target --root ./target/bin`. Once you have that, try and detect changes/updates, and a way to run these easily. 
&gt;DCPU-16 A fictional CPU in a cancelled video-game seems like a rather pointless target for standard Rust to support. Make a fork if you want to support it. 
I'm not say that is UB, but in my case I'm doing microcontroller (flight controller), I would like to have to manage result everywhere instead of having panic, or at least have fine control about WHAT can crash. Also debugging is not as easy as PC, especially in flight.
&gt; I don't think you can accidentally publish the same version twice. The issue is that if you release 0.5.0 and you continue to develop, you now have two versions that are "0.5.0" so the name isn't unique. &gt; I also wouldn't know how to bump the version number. What if I need to release a 0.5.1 bugfix release? You should have a branch at 0.5.0 so you can backport fixes to it to form a 0.5.1 from your master branch which would be 0.6.0-dev. &gt; What if I decide that the next version will be the first 1.0 release? Then you change it from 0.6.0-dev to 1.0.0-dev without releasing a 0.6.0. Though ideally you should release the 0.6.0 or put it on a branch and have master move to 1.0.0-dev and work on two branches if you can't release 0.6.0 immediately.
Ah, makes sense! That's definitely a use case I haven't used yet. If it's supported on your platform, I'd definitely recommend a top-level https://doc.rust-lang.org/std/panic/fn.catch_unwind.html. But in any case, yeah, fine control is good. The main problem's with functions which use panic or unreachable to handle cases which should never happen if other private code upholds its guarantees. There isn't necessarily a better way to model things, and the panics only show up with library bugs. The main gotchas with panicking in regular code are arithmetic and `[]` indexing, as you've seen. Everything else will be clearly labeled - it's pretty much guaranteed for standard library stuff (`Panics` function documentation header) and well-built libraries adhere to the same policy of documentation.
It would be possible for Rust's compiler to track this, in specific circumstances. It would need to look at each vector's declaration and see if it's a constant size, then look for places where it's used without modifying the size and indexed with a constant that is too big. I don't think it's a particularly high priority to add a warning or error for that, since it's not a common circumstance.
I think the idea is that even if Volkswagen became aware of this project, they wouldn't risk making a fuss, because that could very easily blow up in their face by drawing attention to their emissions testing scandal again.
So has it happened in Java or JavaScript to name just two languages that allow it already? Just like 0 and O can be used to fool people (depending on font), a and а, can be used (for example). If that is a concern, I'm sure clippy (or a fork of it) can be expanded to normalise similar looking characters and warn about it.
I wrote a [toy log-structured merge-tree implementation](https://github.com/stuglaser/rustlsm) (like leveldb or rocksdb or cassandra's storage layer), just for the fun of playing with Rust and for learning the underlying algorithm a bit better. It turned out pretty well. Rust's error handling mechanisms made it surprisingly fun to write robust code (just keep fixing things up until the "unused" errors go away), and cargo is a dream after working in C++ for so long. The only frustrating part was needing to use `owning_ref` to implement a tricky iterator, and not being able to use a `Condvar` with a `RwLock`.
You make good points, especially for projects that see lots of contributions (mine don't, yet, so the design is definitely informed by that). To provide a bit of context on the reasons why this does some of the things it does: * The steps allowing failure are all from when clippy didn't reliably install on all nightly versions, and I was tired of the noise, and was checking the build page for every PR/push I made. (Not anymore, thanks to the clippy-preview component!) - but today, it might still be useful for some projects to allow failure on the benchmark step (if only I could figure out how to make it upload artifacts somewhere useful - contributions welcome/requested! * Your warning about the 3 parallel build processes on OSS is very important for speed. I think it's fine for most projects to skip all the versions that aren't stable, and fill the 3 parallel build slots with it and the "utility" builds like cargo fmt/clippy.
I've been writing the second part of the actix-web tutorial here is part one https://hgill.io/posts/auth-microservice-rust-actix-web-diesel-complete-tutorial-part-1/
Vaguely remember writing a Chip8 emulator in C# few years ago. I think I just wrote an automated decoder with attributes that extracted the arguments and called the appropriate function
It's just a German word, applied in an entirely different field.
Does `-Warray-bounds` work with `std::vector`? Because the referenced thread is about the compiler not giving such warnings for `Vec`. Rust can figure it out just fine for arrays and a constant index. My point was that I disagree with the OPs statement that "clearly the fix was to use get()". Sure, `get` gives you bounds checks without panics, but that's got no relevance to the thread about whether the compiler can warn when you're using an obviously incorrect index.
Can't access the blog because firefox claims security technology is outdated and vulnerable.
After a little break, I'll try to see if I can get XChaCha20 done for [orion](https://github.com/brycx/orion). I'm aiming to get this and a lot of other smaller things done so that I'll be able to have an audit scheduled for late November or start December.
Was there any manufacturer that didn't cheat? I read (or listened?) to someone reverse engineer his (non-VW) car's ECU-code to figure out the rules of its adBlue usage. It turned out it followed the testing parameters, not when it was actually needed from a reduced NOx pollution point of view. :( 
Are you sure? We're using an up to date certificate and it is working fine for me on Firefox 63.0.
&gt; Does -Warray-bounds work with std::vector? Because the referenced thread is about the compiler not giving such warnings for Vec. Rust can figure it out just fine for arrays and a constant index. &gt; &gt; Well gcc arrays aren't vectors, so AFAIK no it doesn't.
Finishing and polishing up a PR to bring histogram functionalities to https://github.com/jturner314/ndarray-stats - a crate on top of `ndarray` dealing with statistical routines.
&gt; Well gcc arrays aren't vectors, so AFAIK no it doesn't. Then Rust and GCC/Clang warn in similar cases, so I'm not sure about your point wrt. `-Warray-bounds`.