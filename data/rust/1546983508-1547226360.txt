I'm using IUI which has worked for my test in creating a cross platform app with native controls. Having trouble working out key events though... :(
Could you try to remove the unnecessary Option? Maybe have a function call that takes the 'n' and the 'Board' and no other parameter and one that takes the parameters and hard-code a 0. I believe the packing and unpacking with Option is slowing you down.
stackoverflow != reddit, Stack overflow is for about create question and have answer, duplicate is very nice to have and no one should be shame about have their questions closed, if you think your question is not a duplicate talk about it, we often look more closely when there is not a consensus, we have this case sometime, and sometime we agree to reopen the question. Shep is one of the most useful user of stackoverflow. A lot of other tag language don't have a shepmaster and that very bad for them. Shep can solo close rust question but he do it only when he is sure or after suggest a duplicate that everybody agreed. In too many tag (C and javascript for exemple), we have lost hope because 90% of questions have very low quality. We try to avoid that in Rust, as the main goal is to create something reusable and useful to all peoples. We have some experience, if we tell you your question have a problem and you deny it, you should ask question about yourself. I have already answered hundreds of questions, and read thousands. With time you instantly see what a question need. If shep tell your question is duplicate 95% of time he is right. So, instead of complaining on reddit, please share your point about why your question don't have a problem or is not a duplicate. This would be more useful. Also, search for duplicate is a LOT OF WORK, a lot of people don't do it and just answer question because there are lazy and this is a big problem that we try to avoid in Rust tag. We try to regroup answer where there are the most useful. We try to make things good. Stack overflow is not here to teach a language, but to answer practical or theory question **after** you learned the language. If you come and probably ask as a new rustacean a question about borrow checker, you really think this question doesn't already have answer in detail before ?
Given an iterator, I'd like to first iterate over the first n items, and later over the rest (in two separate loops). What's the most straight-forward way to do this?
Have a look at the example further down the page, you can just put `Json` in your function argument: #[macro_use] extern crate serde_derive; use actix_web::{App, Json, Result, http}; #[derive(Deserialize)] struct Info { username: String, } /// deserialize `Info` from request's body fn index(info: Json&lt;Info&gt;) -&gt; Result&lt;String&gt; { Ok(format!("Welcome {}!", info.username)) } fn main() { let app = App::new().resource( "/index.html", |r| r.method(http::Method::POST).with(index)); // &lt;- use `with` extractor }
Is there a difference between `#[allow(dead_code)]` and `#[allow(unused)]` ? Both work and suppress the compiler unused code warnings, but do they work the same way? In real projects, does the compiler eliminate the code followed by both each one during the optimization process? 
Does a vector of booleans not get optimized to 1 bit per boolean?
.take(n) ... .skip(n)
I tried that, but \`take\` (understandably) consumes the iterator.
It doesn't. AFAIK C++ (which I believe you're comparing Rust to) has some problems stemming from such optimization, I just can't remember what they were right now.
 
No, and using a bit vector can be slower. I suspect in this case that's slower than a flat Vec&lt;bool&gt; as it fit in cache, and you don't need bit arithmetic to extract/update the value.
Maybe collect() the iterator into a vec first? If you don’t want to do that then maybe make a custom iterator that could be resumed? Sorry, if not much help. Couldn’t tell what you were after with the initial question. 
I found [this](https://stackoverflow.com/questions/33306844/using-an-iterator-how-do-i-skip-a-number-of-values-and-then-display-the-rest) 
Of course I'm not suggesting that `catch` is useless, just provided a solution until it's implemented. If you have too much rightward drift, maybe you're breaking the 15-line rule of Clean Code. :) But it's not hard to believe that there are situations where `return` in `catch` block would be helpful.
Does the official linux binary not work? https://github.com/ashleygwilliams/cargo-generate/releases/tag/v0.2.2
Out of topic, but here it is: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c5da06be6564dc023af84ea9c89b7ea4](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c5da06be6564dc023af84ea9c89b7ea4)
No worries, I guess I could use `try_fold` for the first loop and the iterator itself for the second loop.
I feel like I don't need it. I can just create the project template in my desktop and then transfer the result to the VPS. 
See `rustc -W help` for a list of lints and their groups (not at a computer or I would post actual content)
Or clone it before you start iterating. I don’t believe iterator clones are expensive. 
Registered in [my crates list](https://users.rust-lang.org/t/list-of-crates-that-improves-or-experiments-with-rust-but-may-be-hard-to-find/17806?u=vi0).
For a normal vector you can get a pointer/reference to an element and pass it around to code that knows nothing about vectors, but this is not possible with that kind of optimization. This means that C++ code generic over \`vector&lt;T&gt;\` is frequently usable with any T \*except\* \`bool\`.
If your iterator is on a vector, slice it and just return back all the values in one go (ie: return back slice\[0...mid\]).
Write a CLI tool for finding excuses!
I left out that I want to consume the elements of the iterator, sorry about that!
Upvote for historical facts I would've loved to have known a month ago
I'd like to consume a vec and return its argmax, but I'm getting a lifetime error (I was hoping to avoid references by using `into_iter`, since I don't need the vec afterwards). Even clippy's thorough explanation isn't helping me wrap my head around what I'm doing wrong here. If I change it to use `iter` and accept a reference in the closure it works fine: fn argmax(foo: Vec&lt;u32&gt;) -&gt; u8 { foo.iter().enumerate().max_by_key(|(_idx, &amp;n)| n).unwrap().0 as u8 } I figure this is probably just as good, but why can't I get it to work with `into_iter`? Is there a principle I'm misunderstanding here? [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f1fedccfea2dd7d274701c4ffb2b1e96) fn argmax(foo: Vec&lt;u32&gt;) -&gt; u8 { foo.into_iter().enumerate().max_by_key(|(_idx, n)| n).unwrap().0 as u8 } fn main() { let foo = vec![40, 50, 1, 7]; println!("{:?}", argmax(foo)); } 
a bit more idiomatic: [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=b60bd51aeadc19d39274f4eab514ce15](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=b60bd51aeadc19d39274f4eab514ce15)
Thanks, that's perfect!
Honestly it could just have been bad luck and stress that time. Now I am looking at TLA+ but I do plan to go back to ocaml in the near future, I find the language very compelling :-)
Usually, 'native GUI' implies GUI made by the OS vendor. That would be Cocoa (uses ObjC for now, although Apple is investing in Swift more and more, which doesn't provide some sort of stable FFI yet, I think, and might not ever, given how Apple loves to lock in its users) for Mac and WinRT for Windows (for which bindings exist, but they're not yet in a state where you can create GUI). Aside from that native UI is more than just buttons, menus and combo boxes - it's also a reflection of each vendor's vision of how the user should interact with the app. All in all, if you want to build a truly native App, your best bet is to separate the app into the frontend, which you would write in whatever language the OS vendor prioritizes and the backend, which you could write in rust, compile as a dynamic library and call into with FFI.
IIRC, binaryen has a C API and Rust bindings are available, so it should be accessible from Rust tooling
That's super awesome to hear! One tip I give to people reading programming language books is this: Type out every single example by hand (no copypasta) and run it. That way you not only read about the concepts but also get a feel for the syntax/grammar of the language.
Why is cargo-generate *two-hundred* packages to compile?! 
Sorry, I thought I was in the easy questions thread, haha.
In the max_by_key closure, n is a reference, which is why you get lifetime problems. For Copy-types (such as u32) you can simply dereference it: foo.into_iter().enumerate().max_by_key(|(_idx, n)| *n).unwrap().0 as u8
This should be easy: I'm parsing a toml file and try to get a table value from it but want a default value if not found. Let's say I have an `Option&lt;BTreeMap&lt;String, Value&gt;&gt;` in variable `opt_x`, how do I get the `BTreeMap` out of that Option, or an empty `BTreeMap` if the Option is None? This works, but I don't like that I create an empty instance that I'm not always going to use: ``` let empty = BTreeMap::new(); // default value, often unused! let x = opt_x.unwrap_or(&amp;empty); ``` Surely there must be a cleaner solution? I tried the following and other similar constructs first, but it wouldn't compile because I create a temporary reference: ``` let x = match opt_x { Some(v) =&gt; v, None =&gt; &amp;BTreeMap::new() // "creates a temporary which is freed while still in use" } ``` 
I definitely agree with that. That's why I got the actual book. Being to explore the construct Rust offers has been probably the best part. I'll get lost exploring what I can and can't do with structures and the book will then inform me why what I'm doing is wrong when I get errors from the compiler.
On my machine the corrected version is 2x faster than js version, so it is not exactly "comparable"
Also, bitwise operations are a huge overhead compared to just reading a single byte and comparing it against zero.
&gt; QT has a huge build and interface complexity due to having a C++ API. What exists is rather difficult to use if you even get it to compile. Since a few months the Rust Qt Binding Generator was rewritten in Rust and now available as a cargo crate. This makes development in the common case significantly simpler. https://www.vandenoever.info/blog/2018/10/30/building_qt_apps_with_cargo.html
What is allowed by crateio is completely irrelevant to my point.
TIL. I'm finally sold on the new Reddit interface. I have been resisting it, but markdown tips the balance.
A very serious pickup. Like the entire Rust compiler + Servo level of pickup, possibly more. GUI frameworks are huge beasts.
No- that would prevent grabbing a reference like `let x: &amp;u8 = &amp;v[0];`.
I was not familiar with the term, but your explanation actually made thinghs much more clear :)
Complementary genuine question: with Rust encouraging a data driven approach, **is dependency injection (and inversion of control) a relevant pattern in Rust** ? Is there a crate for this ? I am not perfectly confortable with dependency injection right now, but having transitioned from Python to C# at work, I start to really appreciate the convenience that it brings from a architectural and testing point of view :)
Thanks, there is this history rewrite by C fans, that it was the genesis of system programming, something that anyone can discover that it is utterly false when doing a bit of archaeology work with help from bitsavers, researchgate, ACM, softwarepreservation, dusted books on local libraries and many other sources of old papers and mainframe programming manuals. It just happened that by not being able to charge for UNIX, thus offering it for a symbolic price alongside the respective source code, was indeed what made C kind of the language of choice for systems programming. Had Bell Labs been allowed to charge something like e.g. a VMS comparable price, and the outcome would have been totally different.
Thats nice and all, but, so? The roadmap hasn't quite matched whats been done lately. For example, the only "Tooling improvements" from the 2018 roadmap that made it in was `rustfmt`, none of the "Library improvements", and we all know how the "Web site "improvements"" went. The roadmap has had little to do with reality, unfortunately, because i'd really have liked xargo integration to finally exist ^^^and ^^^i'm ^^^still ^^^not ^^^quite ^^^sure ^^^why ^^^it ^^^doesn't ^^^when ^^^compiling ^^^the ^^^core ^^^libs ^^^is ^^^so ^^^simple.
I can't really think of any situation ever where Rust and JS should have comparable performance.
Thanks for asking the question, I got the same error at work and didn't dare to ask ^^` (Windows10, Cmder, Rust 1.31 installed with rustup)
Would the `or_else` method help? It takes a function and calls it in case the value is `None`. ``` let x = opt_x.or_else(|| BTreeMap::new()); // This might work too let x = opt_x.or_else(BTreeMap::new); ```
Are you compiling both with optimisations? `--release` for cargo or `-O` for swiftc (or rustc).
That is a problem. When I set up and ran similar project under Framework IV (so quite a while before H2020), I tried to ensure that for each bit of critical work I had two partners able and funded to do it. In opposition to that, you also need to have as few members as possible: the largest consortium I can remember was five partners, but two of those were demonstration sites. It's also best to get partners who have done one or perhaps two projects before so that they know how things work, but absolutely avoid "frequent travellers". These days I do some work monitoring UK national projects. Those are more tightly monitored, and have a much higher success rate as a result. I can and will initiate the process for shutting down the project if they seem to be swinging the lead.
I saw that, but I had wanted to keep the signature of just the request object (for arbitrary reasons). I think I would use the method you point out going forward, but now I'm just seeing how far I can go using the working group's current Tide implementation.
In the end they both compile to assembly (js after a warmup period). If you manage to make code where optimizations are useless enough and avoiding all the runtime crap I don't see why they should differ substantially. The code isn't identical either, e.g. js is using floats instead of ints. Which pseudo-randomly perturbs the results. Even though js is almost certainly usually slower even in the best cases of little optimization potential it's not unbelievable that it could get lucky on some particular benchmark.
Yep, using a release build for both!
Why would you need to do that? 
Holy moly thanks, I'll give it a try. I was trying to find a solution and was not turning up any results before.
Thank you, can't believe I didn't try that (tried changing to `|(_idx, &amp;n)|`). In the future, I should have been able to determine this by the fact that its definition includes the closure `F: FnMut(&amp;Self::Item) -&gt; B`; both `&amp;Self` and `FnMut` should have clued me in that these are references (as opposed to `FnOnce`, which would take a value). Right? Is it quietly changing `n` into a reference based on the definition of FnMut? Shouldn't I get some kind of type error since I'm passing in a value with `into_iter` (as opposed to `iter`, which would pass in a reference)? Thanks again.
I've learned many languages due to my study. Java, Javascript, C, C#, DLV, SQL and so on. Trust me when I say that rust is not a real challenge it has different syntax yes but if you're somewhat familiar of any of object oriented languages than it's a cake walk and that's the best point of rust in my opinion. It takes the simpleness and safety of java and combines it with lower level C performance and usage (dlls and so on). I think rust is a good replacement for C in the 21. Century. It's about time.
Usually they are 1 byte per bool, because the processor can more quickly do operations on a byte than it can on a single bit. And memory is cheaper than time, after all.
Does [this playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=b0ab3353de94431e4f2eec7bdd6b7b63) work better
I made your first change, which seemed like the consensus recommendation. It helped a lot—thanks! I also tried out a bitvec, but that actually (very slightly) slowed things down, so I reverted back to the `Vec&lt;Vec&lt;bool&gt;&gt;`. Great suggestion, though, and thanks for teaching me about a couple of interesting crates. 
&gt; the processor can more quickly do operations on a byte than it can on a single bit Why is that? Is it because bit vectors require some arithmetic to modify specific bits?
`Vec` supports it is a basic operation, so `Vec&lt;bool&gt;` would need to allow it.
Didn't try. It is no longer an issue for me right now, as I have transfering projects instead.
Thanks for this, but most of your links are broken.
It's not particularly useful by itself for `Vec&lt;bool&gt;`, but there are many functions generic over `Vec&lt;T&gt;` which need this. For example, iterating over a vector without consuming it takes a reference to each element. let v = vec![false]; for x in v.iter() { // x is &amp;bool here, a reference to an element in the vec } If this were impossible for `Vec&lt;bool&gt;`, then the majority of code generic over `Vec&lt;T&gt;` would not work for `T = bool`. Even if std somehow had a different copy of each function operating on Vecs for `T = bool`, libraries generic over `Vec&lt;T&gt;` or `[T]` would still break, since it's expected that `iter()` returns `&amp;T`, and that all other such things do too, like `get(idx)`, etc. Since so much code dealing with `Vec&lt;bool&gt;` would have to be special cased anyways, the rust team decided to keep `Vec`'s functionality the same for all types, and simply allow users to use a more specialized type (like `BitVec`) if compatibility with generic functions taking `&amp;[T]` and `Vec&lt;T&gt;` is not required.
I’m not sure, but I heard that Option is pretty much zero overhead due to compile time optimisations. It’d be interesting to see if that’s true though!
it gives incorrect result
I think this depends on what level you're at. If you're already familiar with a few languages as you say you were, then I agree that Rust shouldn't be too challenging. But if you're new to programming, or perhaps only know one high-level language at an intermediate level, then I think Rust could be a challenge.
Yeah, the CPU usually has registers that are 64 bits wide, and memory loading operations that are a byte wide, and operations work on whole registers, so if you want to operate on single bits, you have to do masking and shifting operations that are unneeded for a single byte.
Opps I missed that, I forget how peek_mut worked.
I think this gives the right result: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=f2ad3ec8bf735379a121a2aed9d7cee2 I don't understand what's the purpose of the `for` loop.
try to build once in a windows console. if it works, your issue is probably cygwin's path
was it public? i really want to take a look at it.
Working on tests, and making the VDOM modular for a frontend framework I've been working on 
I wonder if the content was removed because they are making a new iteration of the course.
Have you considered Regex? ;)
It's part of an unmerged PR, so it's to be expected. The rust docs use old mdbook links which are not relative and not compatible with github rendering. You can remove the duplicate "rust-2018" from the URL and change `.html` to `.md`. Or, it shouldn't be too hard to find the pages in https://rust-lang-nursery.github.io/edition-guide/
Try adding an "f18" into the URL after "courses". I noticed this with a different course.
Agree; it's an easy jump from other procedural languages, thanks largely to the official book, and helpful compiler messages. Haskell... was, for me, very challenging in comparison.
If you remove the "impl" in the get_method&lt;S : impl Foo&gt;, this code compiles. It looks like you're trying to do basic dynamic dispatch. Why not use trait objects? That is, `&amp;Foo`? 
A year or two? ago when I first tried rust I really struggled with the borrow checker and lifetimes, mostly because I just kept trying to do the same old patterns I did using other programming languages (having many (possibly mutable) references between objects). I now know to restructure my code (if necessary), and also in some cases the borrow checker is better since when I started (I suspect). I also found (and still find) dealing with Result types kind of confusing. I never much generics/templated code in the past so that didn't help me much either :S. 
Dawson Engler is making a new offering but it's in C and focused more on the raspberry pi and devices
That does indeed perform a lot better. I suppose `PeekMut` has the slight overhead that it still checks whether a sift-down needs to happen, even if the element isn't mutated.
Option is only zero overhead if the type it's wrapping is NonZero, and in practice this is basically just pointers. So if you Option a pointer type, the compiler will treat zero / NULL as None and anything else as Some. Otherwise, Option just acts as any other enum, and you'll have a tag. But I'm not sure that's a huge deal.
I'm not sure exactly what you measured, but the druid calculator example has an executable size of 333k, and 7.3 MB memory as reported by Task Manager.
You can still make it slightly faster by storing all fields in a one-dimensional vector with the length `n * n`. This requires some modifications: ```rust #[derive(Clone)] struct Board { squares: Vec&lt;bool&gt;, n: usize, } impl Board { fn new(n: usize) -&gt; Board { Board { n, squares: vec![false; n * n], } } fn toggle_piece(&amp;mut self, i: usize, j: usize) { let index = i * self.n + j; self.squares[index] = !self.squares[index]; } fn has_been_visited(&amp;mut self, i: usize, j: usize) -&gt; bool { let index = i * self.n + j; self.squares[index] } } ```
I was measuring in Linux with htop.
I don't see why you would need to master C#, Java, \*and\* Python. Pick one, they're all virtually the same once you remove the parts they have in common with C++. If you know C++ and (Java OR Python OR C#) learning Rust seems like a fine next step, and probably a better idea to prioritize than yet another language with the same exact features as ever.
Haskell is great to learn, and I think it makes learning Rust even easier after you learn it. The understanding of functional programming helps a lot with using iterators properly and writing idiomatic code.
Hey u/asonix I'm looking at your crate. Unfortunately I'm still trying to wrap my head around tokio. As much as I'm a big fan of rust, I'm looking at doing this project in Go because tokio is that painful.
The swift version also is a nonempty heap so it doesn't have to check for empty version.
Nah, the runtime nature that create a practical difference between C#/Java and Python/Ruby. JS and Rust/Go get into two other categories. Basically different runtimes (bytecode/interpreter/browser/plain, possibly static binary) have huge impact on deployment that, in my experience, often really matters (and at other times is completely inconsequential, of course).
I wasn’t complaining I was stating my experience with the Rust community. I said it was good except for stack overflow. If shepmaster never logged on again stack Overflow would be a better place. 90% of the time he isn’t answering questions. He’s just formatting code and marking “incorrectly “ questions as duplicates to get more stack Overflow reputation. He wasn’t even taking the time to understand the question other wise I wouldn’t mention it. I understand fully how stack Overflow is supposed to work. He just makes it unbearable to use. I stand by my statement. You are welcome to your opinion. I disagree 
`Option&lt;T&gt;` has no _memory_ overhead when `T` is something that can't be zero, like a pointer, reference, `Box` or `Vec`. In this case, `Option::None` is represented as zero, which is equivalent to a null pointer. However, rust still has to check if an `Option` is None when you call `Option::unwrap()` or a similar method. So there is always a _performance_ overhead.
Try moving the peek_mut into the if body, using peek to check if the replacement is necessary
I guess I'm talking about the languages themselves - like, from a \*language construct\* perspective the ones mentioned have more in common than not (especially when you look at the features actually used). I also have written Python and Java professionally and, while the runtime has come up, it's rarely something worth differentiating them in terms of learning process. Like, if you know Java you can probably pick up Python fairly easily, regardless of the fact that you may be confused why your code is absurdly slow. They aren't carbon copies but I think it's fair to say that the languages share a \*lot\*.
I've been using gtk-rs for a while and I really like it.
there's native vs interpreted code and native vs framework gui bindings. from context I think they were referring to native vs interpreted code nothing wrong with a framework, any of the industrial strength ones like gtk or qt can be styled and customized on each platform to better fit platform expectations. thousands of companies have gone this route and it's a good one in terms of time savings and having a common code base
Well, `return elements.first!` will still check if it's empty or not, as `first!` crashes if you call it on an empty array.
&gt; I guess I'm talking about the languages themselves - like, from a *language construct* perspective the ones mentioned have more in common than not (especially when you look at the features actually used). Fair enough (though I really thing that the runtime aspect is neglected far too much), but I think that even then Python belongs in a rather distinct bucket from C#. OTOH, list from the heather without any Lisp in it is rather lacking.
Ehh, same order of magnitude.
I personally didn't find rust that hard to learn, I mean *yeah* the borrow checker was new. But it's just static analysis for how code should probably be written anyway. The lack of objects was interesting since I'm from C# mostly (and as it turned out, it's actually a good thing that OO is not a thing in Rust) PS: As I personally never really had issues with the borrow checker past "how do I do lifetimes" (answer: think for a minute, and realize what the compiler is telling you is sufficient most of the time) I can't really understand people's issues with it. &gt;.&gt;
I think it's more "once you've gotten the recommended and most ubiquitously used languages under your belt, try Rust to expand your understanding of programming methodologies." 
I believe you can cut ~0.5ms (and thus basically eliminate the difference) by preallocating the heap with the necessary capacity. You can do this by replacing the line ``` let mut heap: BinaryHeap&lt;_&gt; = iter.by_ref().take(k).collect(); ``` with ``` let mut heap = BinaryHeap::with_capacity(k); heap = iter.by_ref().take(k).collect(); ``` 
Won't that create a new binary heap? Or did you mean to write `heap.extend(iter.by_ref().take(k));`? I assumed that `iter.by_ref().take(k).collect();` would reserve enough capacity for `k` elements, though I hadn't verified it.
What are you using instead of error chain?
[This code](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=070c34ff857022ddc0566e22501fa6ae) does indeed give me better performance, very similar to [dbaupp's improved code](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=57270009fce109619dd5a6099128db9a).
I found they're still on the wayback machine: [https://web.archive.org/web/20190101082628/https://web.stanford.edu/class/cs140e/](https://web.archive.org/web/20190101082628/https://web.stanford.edu/class/cs140e/) Schedule with all the files: [https://web.archive.org/web/20181005073814/https://web.stanford.edu/class/cs140e/syllabus/#schedule](https://web.archive.org/web/20181005073814/https://web.stanford.edu/class/cs140e/syllabus/#schedule) Note: you can download it all with the [wayback_machine_downloader](https://github.com/hartator/wayback-machine-downloader): wayback_machine_downloader https://web.stanford.edu/class/cs140e/ --to 20190102235959
Hmm, I'm not quite sure. In tests, it *looks* like the `heap = iter.by_ref().take(k).collect();` version is consistently performing better than the `heap.extend(iter.by_ref().take(k));` in addition to better than the one-line version. But I'm not quite sure why that would be 
That indeed made it about as fast as the Swift version! I'd really like to understand why this worked. My guess would be that `PeekMut` still does some work in its `drop` method even when it's never mutated because its `sift` property starts out at true, and I was hoping that would be optimized away, but I can see why that doesn't happen. Maybe it would have been optimized away if `sift` started out as false and was set to true whenever `deref_mut` is called on it.
I'd take a `--json` commandline argument instead. It'd be pretty surprising to get a totally different, less human-readable format if you pipe it into `less`.
It turns out that my backup was incomplete, but luckily it's on the wayback machine at https://web.archive.org/web/20180327062700/https://web.stanford.edu/class/cs140e/ as /u/pheki noted. I do have the git repos if you need them. PM me and I'll give you a link to download the goods. Also, you might want to check out https://gitter.im/cs140e-rust/Lobby Not super active these days, but I'm sure people who worked on the course would be happy to help you if you get stuck. 
What makes this faster? Isn't that the exact math that would be done internally when using a 2d vec? Is it just the benefit of better locality here?
JS virtual machines have the downside of needing to implement deoptimization checks to handle cases where functions are called with different datatypes than they were jitted with.
[It's worth billions!](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare)
How to effectively optimize languages like JS was figured out in the 90's. The direct ancestor of JS - self - was the primary target of early academic work of optimizing dynamic language runtimes. In theory, languages with dynamic types, garbage collection, and tracing JIT can actually be *faster* than any static, AOT-compiled language like Rust. It just takes truly heroic effort by the implementers to do it. JavaScript has gotten pretty serious optimization effort put into it.
Everyone is saying that cloning is the reason you are slow, and that is true. However, you should know that not _every_ clone is expensive, just yours, in this case. You are copying what seems to be a _very_ large object, so of course, asking the computer for that much memory over and over will slow it down. If Board was a smaller object, cloning would be fine, becuase the computer can easily dole out a few dozen bytes. However, when you are cloning kilobytes over and over, you will see a slowdown. In this case, you can use references easily, which is good, and you should do that. However, in weird ownership situations, you may need to reach for shared ownership, like `Rc&lt;T&gt;`. I hope that clears things up! It is perfectly fine to use `.clone()` sometimes if you dont care about small allocations, and your application can take it.
Joining the crates.io team would certainly put me in a better position to get my concerns heard and perhaps even addressed, but it isn't a substitute for complaining in public. What about my issues with the new website? Should I join the website team too? What if more policy issues crop up? Join more teams? &gt; You could join the crates.io team or the community team, complaining on reddit is fine but understand that no real change is going to come from it as it is not an official avenue of communication. Many people read reddit and some of them are even members of rust's development teams. I think this is sufficient justification to use the website as a platform to air one's grievances. At best, you'll reach those directly involved, and at worse, you'll draw attention to the problem so that others may also try to help.
I don't really agree. Nothing about AOT compiled languages precludes GC or JIT. That's why I mentioned arenas - if you want to change your allocation strategy, just do it. JIT's harder and not something you'd likely get in Rust (closest thing would be PGO), and it was one area I was considering JS has an advantage but it's hard to find cases where JIT is really going to give a huge advantage over strong AOT like what Rust has.
The Speedy Web Compiler (Babel replacement) seems like a good candidate for this list. https://github.com/swc-project/swc
A dynamically typed language with a tracing JIT compiler lets you do some neat optimizations that aren't really feasible without those properties. Imagine for a moment that we have a program that uses Set&lt;String&gt; for two different things. In the first case, we have short strings only use the insert and member? methods. In the second case we use medium length strings and do more complex set operations. A sufficiently clever tracing JIT could figure out the usage pattern and determine that we want a HashSet with inline data (no pointers) for the first case and a BTreeSet for the second case. Further, it could discover that the second case actually works better as a BinaryTreeSet on Atom processors but not on Xeons. If the code literally says BTreeSet, as it would in Rust, you can't do the first class of automatic optimization - even with a profile-guided AOT compiler. And there's no way to do the second optimization AOT at all unless you're doing profile-guided AOT compilation separately for each target machine. 
The position will involve writing a lot of software in Rust.
I think the other reason why BinaryHeap from the standard library is slower is because your Swift code assumes the elements are copyable and performs some optimizations based on that. For example in the `insert` function you are able to move elements[index] = element line out of the while loop. But BinaryHeap can not make such assumption so it has to do some [unsafe trickery like this](https://github.com/rust-lang/rust/blob/2a663555ddf36f6b041445894a8c175cd1bc718c/src/liballoc/collections/binary_heap.rs#L626) which I presume is not very friendly to llvm, and probably misses some optimization opportunities.
Ha, my Swift version actually used to perform sift-ups and sift-downs using swaps until I looked at how it was implemented in Rust. It's indeed an important difference, but I would hope that `Hole` doesn't incur a performance penalty.
Hi i want to have a vector of traits, but the instances can be from different types of objects i already did it but there are a few things that i don't fully understand. &amp;#x200B; use std::rc::Rc; use std::cell::RefCell; use std::borrow::Borrow; trait Printable{ fn print(&amp;self); } struct Dog{ id:i32 } struct Cat{ id:i32 } impl Printable for Dog { fn print(&amp;self) { println!("is a dog {}",self.id); } } impl Printable for Cat { fn print(&amp;self) { println!("is a cat {}",self.id); } } fn main() { let mut printables: std::vec::Vec&lt;Rc&lt;RefCell&lt;Printable&gt;&gt;&gt; = std::vec::Vec::new(); let dog: Rc&lt;RefCell&lt;Dog&gt;&gt; = Rc::new(RefCell::new(Dog {id:0})); let cat: Rc&lt;RefCell&lt;Cat&gt;&gt; = Rc::new(RefCell::new(Cat {id:0})); printables.push(dog.clone());//Rc::clone(&amp;dog)does not work printables.push(cat.clone());//Rc::clone(&amp;cat) does not work (*dog).borrow().print(); dog.borrow_mut().id=10; for printable_item in printables.iter() { (*(*printable_item)).borrow().print(); } dog.borrow_mut().id=11; (*dog).borrow().print(); println!("dogs count {}",Rc::strong_count(&amp;dog)); } why Rc::clone(&amp;dog) does not work but dog.clone() does ? Why i need to dereference twice inside the loop when using iter()? does the iterator return another "Wrap Type" is there a way to avoid the dereferencing when using borrow() just like you can when using borrow\_mut() ? 
Saved for reference. Thanks again for your great contributions to Rust and the Rust community. And the very best of luck! :-)
Are they working on Redox? I thought that was just a side project of one of their lead engineers.
I have little need for a BASIC interpreter, and I feel like python is a reasonable great language for teaching kids to program. But that doesn't temper my reaction at all - all I can think is "neat!".
wrong subreddit, maybe you are looking for r/playrust/
Wrong subreddit friend 
Remote work possible ?
So I'm trying to do some FFI and was wondering if this was in general okay? &amp;#x200B; Let's say I have two shared libraries A and B with a C interface. Library B depends on library A. I think the easiest way to generate library B is to statically link library A. However, if I do this, is it safe to pass opaque pointers between functions in library A and B? This is assuming that both libraries are compiled with the same compiler version. I would prefer to have library B dynamically link against library A, but this is not a big deal. Having the two libraries be separate is, though. The libraries will be loaded into Python using CFFI.
It should also help with understanding traits (which are equivalent to type classes in Haskell)
I implemented `peek_mut` a few years ago, and yes, that's exactly how it works.
Awesome! Any idea what the reason was to have `sift` start out as true instead of only setting it to true inside `deref_mut`?
I was reading this blog post (http://aturon.github.io/2017/07/08/lifetime-dispatch/) and it says - &gt; What does this program print? Since the string literal "test" has type &amp;'static str, you might expect the second, specialized impl to be used (and hence to get specialized as the output). But, as explained above, from the perspective of trans this type will look like &amp;'erased str, making it impossible to know whether the more specialized impl can safely be used. I don't understand what "trans" means in this context (or as written in the code example).
Delete Windows, install Linux. That should fix your problems.
You put stuff into a long living collection and forget to remove them. You can't create traditional memory leaks because you are not directly managing memory.
I would think it rather involves rust development tied to the linux kernel, like modules or userspace tools, written in rust, and interacting with the usual (C-based) kernel.
Interestingly, that never came up in discussion around that feature. It does make sense, though!
Please read subreddit descriptions before posting (applies to whole reddit).
how the hell does someone master c++
It is not the same, because `Vec&lt;Vec&lt;_&gt;&gt;` involves an additional redirect. Think array of pointers. 
FYI, rustc's `-O` is `opt-level=2`, where `--release` is `opt-level=3` by default.
Oh, right. Thanks.
&gt; Option is only zero overhead if the type it's wrapping is NonZero, and in practice this is basically just pointers. Not quite: any types with "holes" in their range of values are considered, most importantly enums, whose discriminant is an integer that in almost all cases has some values free.
Very likely bitvec is slower because accessing its members requires a bit more arithmetic for the CPU. But keep in mind that the in-memory size of a bitvec is 8 times less. Your bitvecs are only of size 5, so the whole thing can fit in cache easily. But for larger boards, at some point the smaller size will become much more important, and the additional instructions won't matter: accessing uncached memory is insanely slow in comparison.
(On the run, so I'll be short.) I'd say that some knowledge of algorithms and data structures would help any software developer. You should at least look into some of the common data structures and learn about their trade-offs. Learn about [O notation](https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions). Maybe solve some programming problems. You may never need to implement your own data structures, but algorithms tend to crop up in job interviews. Not knowing CS won't hamper your ability to learn Rust, but it's worth having at least some idea since it will help you avoid some [pitfalls](https://accidentallyquadratic.tumblr.com/).
It's not so much the size of the object (with size 6, the boards are not that large anyway) than that it is cloned a lot of times in a recursive function. Cloning a huge object once is not a big deal. Cloning a mid size object 10000 times is.
`. by_ref().take(n)`
Consider using docker for your build process, brings you closer to reproduceable builds and allows you to target whatever distro+version you want 
I would like to throw in `cargo fix` as another tooling improvement :) the working groups, too! Being close to reality is a goal but not a requirement. The roadmap is a tool that you can use to get an idea what the community would like to have, and maybe prioritize your work based on that. The roadmap is not however a strict plan with fixed milestones, deadlines, and such. This would not work for a project where a lot of people are volunteers!
Very true. &gt; Had Bell Labs been allowed to charge something like e.g. a VMS comparable price, and the outcome would have been totally different. I for one welcome our commercial overlords who give us Objective BLISS.
Oh, I was wrong of the type of `x` in the question. It's supposed to be a reference, i.e. the type of `opt x` is `Option&lt;&amp;BTreeMap&lt;String, Value&gt;&gt;` so the or_else function has to return a reference. And then I get an error with or_else: ``` let x = opt_x.or_else(|| &amp;BTreeMap::new()); // creates a temporary which is freed while still in use ``` I'll edit the question. 
Do the Rust bindings now support binaryen's pass registration interface? Last I checked, that part wasn't accessible from Rust :/
Playing with capn proto rpc in rust
Good question ...
IIRC trans is a part of the compiler that converts mir to llvm ir. The idea is that when all compiler checks succeed then you know that the program is well formed - so you erase all lifetimes from it and give it to trans to build llvm ir. However, trans also has to do impl selection to properly generate monomorphised code (and it has to exactly replicate how it was done at typechecking time). So because trans does impl selection without knowing about lifetimes, it can't do specialization on lifetimes, therefore typechecker must also be carefully built to avoid allowing specialization on lifetimes. 
Welldone! You know what would be _very_ cool to see. A `MIX` `MIXAL` interpreter/compiler inspired by Donald Knuth's, "Art of Computer Programming".
Have a look at what [rcgen](https://github.com/est31/rcgen/) does internally to destructure `ring`-generated keypairs, perhaps?
You are not complaining? &gt;There are a few bad apples on stack overflow specifically making it hard to ask questions about rust without it getting flagged incorrectly and deleted. &gt; &gt;Shepmaster will find something wrong with your question and try to delete it &gt; &gt; He doesn't make any effort to actually answer the question, or even understand it &gt; &gt;... These are all complaints. I fully acknowledge what /u/Stargateuer said. He is the person who makes the rust tag really a good place to find things. All I see is that you feel mistreated, that is not okay. But without giving actual examples (e.g. a link to a SO question) these are all allegations. &amp;#x200B; &gt; I don't want to say anything personal. Because we are all real people behind these keyboards. &gt; &gt; If shepmaster never logged on again stack Overflow would be a better place. &amp;#x200B; Wtf. You are contradict yourself. &gt; 90% of the time he isn’t answering questions [https://stackoverflow.com/users/155423/shepmaster?tab=answers&amp;sort=newest](https://stackoverflow.com/users/155423/shepmaster?tab=answers&amp;sort=newest) That's bullshit and this is really getting ridiculous. &amp;#x200B; &gt; He’s just formatting code and marking “incorrectly “ questions as duplicates to get more stack Overflow reputation. You don't get reputation from closing or marking questions. &amp;#x200B; &gt;I understand fully how stack Overflow is supposed to work I don't think so...
Yeah, thank you guys for reminding me!
First, you become ScotT Meyers
Is there a binary or some other tool that doesn't require installing ruby? Or even just the files already downloaded?
Although, I can't seem to find the references again, this can apply to *emulation*, as well. Around the time when Transmeta was very nearly building competitive CPUs there was a research project by… HP (I think?) that wrote an emulator for one of their CPUs that would run code at about 105% of native performance. That is: code running in the emulator was about 5% *faster* than code running natively. It essentially did whole-program PGO on-the-fly.
Oh, for a second i thought you meant [http://cs242.stanford.edu/f18/](http://cs242.stanford.edu/f18/) which is still there.
Any visa sponsorships?
Thanks, but it doesn't seem to help - I have externally generated certificates and as far as I can tell `ring` cannot deal with them at all.
Ah, thanks for the info.
Not OP but System76 has their own linux distro called Pop! OS /r/pop_os. I expect this role will involve adding to that project.
netidee is funded by the profit of the .at top level domain; AFAICT they can't make profit so they have to get rid of the money again, and have found a very nice way to do so.
Just an idea, but project that might be worth creating a consortium around would be "Rust for HPC". Scientific computing has a reproducibility problem. With Rust's excellent build tooling, it should be possible to create a stronger science system.
Hot take: Knowledge about data structures are used as a proxy for knowledge about computer science in general, so their importance are somewhat overblown. Its just one topic of many. Of course its good to have a solid theoretical foundation, but you can do a lot without implementing your own fundamental data structures. So, i don't think this will be a problem for learning rust.
Very nicely done! I have a deep interest in compilers and language design (albeit an abject beginner in this domain), and it will be interesting to read through the source code. Thanks for sharing!
Oh, so much this! I'm administering a HPC cluster, and our in-house scientific software are mostly written in Fortran, C, and recently R. Only a small subset of it is because it needed to be in Fortran. The rest is because that one guy who did it was more comfortable in Fortran. Now, nobody wants to touch those codebases because they don't know enough Fortran. With the new GPUs and AVX units, I would guess it would be a great benefit if some of the tools could be written in Rust with some kind of transparent vectorisation that leverages the GPUs or AVX units. On the other hand, some scientists are using Julia for new projects precisely for the reason I mentioned. So, Rust would have to compete with Julia in that space. 
Hair style mandatory.
Cool, I'm on chapter 11 at the moment! &amp;#x200B; Although I'm sure at least the chapters on ownership and lifetimes will take some re-reading and practice to fully sink in...
Thanks a lot !
I will try to make an archive and post it as a torrent !
The kind of example you give with containers is perhaps most closely realized in SQL optimization engines, but even they do not in practice reach the performance of manual container choice (even if runtime-dispatched at some level) and build-time optimization. A more realistic example is combining devirtualization, deoptimization and inlining, where a piece of code with a virtual call might have quasi-persistent modes in the virtual call target. A static compiler could not make a single build-time choice that is always optimal, but a JIT compiler could do the inlining (and apply e.g. some peephole optimizations on top of that) and when the mode changes deoptimize and reoptimize. Here's a good article that goes into detail for Java though the techniques are widely applicable (see the section on Dynamic Deoptimization): [https://www.ibm.com/developerworks/library/j-jtp12214/](https://www.ibm.com/developerworks/library/j-jtp12214/) Ultimately the trade-offs for aggressive build-time optimization still tend to win out in real-world software especially when combined with profile-guided optimization. I am not convinced that a "sufficiently smart JIT" to truly beat state-of-the-art AOT is ever going to be realized.
Thanks. I knew something like this would have to exist, but it was just a silly example to test the for loop.
I'd probably write the vector init as let v: Vec&lt;_&gt; = (0..9).collect(); but meh.
Could be an issue with your Webpack config. Would you mind posting it here?
Library for text similarity using word2vec embeding. This will allow to compare equality of sentences with different words of the same context.
&gt; I'd heard that clone() can slow down code, but I didn't realize how big the effect would be! Yeah it's really going to depend on the data being cloned. Here you're cloning a `Vec&lt;Vec&lt;bool&gt;&gt;` so each clone call is going to make 1+board.squares.len() heap allocations, then copy the data over (and there's no guarantee the inner vectors are stored contiguously so it's blowing the cache at the same time). And while jemalloc can do some amortisation, allocations are never going to be as cheap as they are in a language with an advanced GC (and even then they're not actually free, IIRC Java can get down to about a dozen instructions per allocations, which is still significantly more than the 0 you need to not do an allocation).
Not sure if this will help, but generally when having difficulty with lifetimes, I find the best approach is to manually annotate all lifetimes instead of relying on compiler lifetime elision. Annotating something with the lifetime of static doesn't automatically make things live forever. [From my understanding](https://doc.rust-lang.org/rust-by-example/scope/lifetime/static_lifetime.html), if you use static outside of a str or a constant, it is just a normal lifetime with the name 'static and is no different than 'a or 'b. Maybe if you posted some actual code, more help could be provided?
I would expect that the total LOC would go down switching to rust which is more expressive than C. This does not seems to happen. Is there a reason for that? 
More features? Or code style?
Well yes of course, but that's no surprise for a beginner is everything hard and complex. What i mean by that is for a person like me who has experience in programming and has the knowledge and thinking ways of a developer, it is really easy to switch. And that is a really good "Feature" and this is actually not always the case with languages. &amp;#x200B; In our Age you can never possibly learn and master every Programming Language so you will just have the general understanding and a prefered Language. And if needed you can switch to another Language and for an experienced Developer that is not a very painful Process however that really depends on the Language so yeah.
I'm challenging the rust community to think about getting EU grants to fund the development of rust, its infrastructure or commercial programs. So far, I've written a [short post on Reddit](https://redd.it/adue67), which seems to have stirred up quite som interest!
&gt; You don't get reputation from closing or marking questions. The citizen Patrol Badge, Deputy Badge, Marshal badge, Cleanup badge, and many many more all give reputation for moderation. &gt; These are all complaints. These are my experiences on stack overflow. I even asked Shepmaster to stop posting on my questions because he never actually answers them and he still edits all of them. If no one believes me , go ask a question about Rust on stackoverflow with a new user name. If will be moderated to Oblivion. Thats all i'm saying. It's almost impossible to ask a question there and thats not ok. No other language has this problem that I'm aware of. Y'all can disagree on why that is all you want. but that is a fact. 
At the moment, it is a hybrid codebase, so there's some FFI involved. FFI can be somewhat boilerplate-heavy. Perhaps it will go down again once the oxidization is complete?
Returning `impl Trait` is syntax for having a single, concrete type that you don't want to (or aren't able to) name. Anyone using the function (or, with your idea, struct) has to accept that type. `&lt;Param: Trait&gt;` is syntax for allowing whoever is using the function/struct to choose which type they want to use there, as long as it satisfies the given constraint.
I would also be curious as to how much C code has been translated to idiomatic Rust. Besides FFI, there may just be sections where they have yet to rewrite using all of Rust's abilities.
\[This\]([https://abstrusegoose.com/strips/ars\_longa\_vita\_brevis.png](https://abstrusegoose.com/strips/ars_longa_vita_brevis.png)) is the only way
I don't expect it to decrease. Rust is verbose, for the good.
I don't think anyone doubts that you've had a bad experience. On one hand, some people are saying that questions are usually closed fairly on SO, for good reasons. On the other hand, you are saying that you've had questions closed unfairly. To make any progress, I think you need to show some links to questions that you think are unfairly closed as duplicates. That way, we can all see together if there is a problem.
Perhaps mundane/boringssl might be helpful https://github.com/google/mundane
It would be cool if they are going to be writing drivers in kernel modules in Rust and making those modules accessible in other distro's repositories. However, as a consumer I would prefer my drivers to be fully in the kernel, and fully upstreamed, which won't happen with Rust.
Perhaps mundane/boringssl might be helpful https://github.com/google/mundane
&gt; But without giving actual examples (e.g. a link to a SO question) these are all allegations. Have have one, https://stackoverflow.com/revisions/53032711/3: &gt; Also Shepmaster leave my questions alone and get a life. Note that Shep is nice to not have report it and just remove it away. Also note that Shep have reopen the question but I still think it's a duplicate.
medium is out jerking r/programmingcirclejerk. Bravo!
The code you posted does not compile - compiler gets confused on that double dereference line because it does not know if you are calling `RefCell::borrow` or `Borrow::borrow`. And once you remove `std::borrow::Borrow` import everything works - even once you remove all the manual dereferences. I'm not completely sure about the `dog.clone()` vs `Rc::clone(&amp;dog)`, but I think this is a funny type inference quirk - it seems to go in different directions, and thus the coercion needs to happen at different points: 1. When you do `Rc::clone(&amp;dog)` it infers that result must be `Rc&lt;RefCell&lt;dyn Printable&gt;&gt;`, so argument must be `&amp;Rc&lt;RefCell&lt;dyn Printable&gt;&gt;`, but it is `&amp;Rc&lt;RefCell&lt;Dog&gt;&gt;` and it cannot coerce that to the correct type because it is behind a reference. 2. When you do `dog.clone()` inference seems to go the other way - it knows that `dog` is `Rc&lt;RefCell&lt;Dog&gt;&gt;`, so when you clone that you get another `Rc&lt;RefCell&lt;Dog&gt;&gt;`, and to push it you need `Rc&lt;RefCell&lt;dyn Printable&gt;&gt;` - so when you need to coerce it now there's no reference, so it works out.
This is a subreddit for the rust *programminglanguage*
There is a catch to impl trait: When used as a function argument type, it means any type satisfying the traits. Otherwise it means a single, specific type, which just won't or can't be named, e.g. a closure. The technical term is universal vs existential type. So a field of `x: impl T` is not the same as `x: X where X: T`. In your example, the former would be closer to `x: A`, except you could only access the functions of `T`. Also, allowing impl trait as field types is in the works, here is an [example](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=21a99879b7ec76338346eeda51d738ee).
You seem pretty certain of your claims and your link points to a description of techniques for JVM without _scientific_ comparison with standard AOT performance comparison Note that this dates to 2004 when Java was all the fame. I think such a strong statement should either be proved (machine code comparison during execution) or verified (proper benchmark) In my personal CS experience, i never saw any of those 2 confirmation that JIT is _in general_ superior to AOT. Please increase my culture by arguing against my claims; I‘m open to accept my errors if you could convince me.
After complaining to stack Overflow help the question was finally changed from duplicate and just re worded. I would need to show screenshots of every question I asked being overly moderated by the same person, show were I asked him to leave my questions alone, and then show screenshots of all the edits made to a later question after he ignored my request to leave my questions alone. I don’t think I need to go through all that to just express my opinion that asking Rust questions is unfriendly to beginners on stack Overflow. Any new user would quickly discover that themselves. Reddit community is great, Rust forums are great, irc great. I am just expressing my opinion that stackover flow Rust question are not. 
If a JIT has designed magic optimizations; why couldn’t an AOT compiler (e.g rustic+LLVM) implement similar optimizations?
I'd be super interested to see some actual empirical defect rates for projects in c vs rust to see if you can actually quantify the language improvements, I suspect actual hard improvement data would go a long way to convincing people
I'm working on a kind of framework built on top of StructOpt for building Slack bots that run commands. The idea is to use StructOpt for describing a command, another trait for executing it, and a bunch of code that ties all that together. Those commands can then be run by either Slack or command line. So you can run the commands via either. It also helps to encourage keeping the commands totally independent of each other.
Have you seen this wonderful Stack Overflow explanation on why parsing HTML with regex is evil ? :D https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454
The Internet Foundation Austria (IPA) is indeed nonprofit, but the domain management is handled by company nic.at GmbH, so I'm not sure how "mandatory" it is for them to spend that money again. The fact that they do run the netidee programme is great, in any case.
Or they did, and it uncovered edge cases which were not handled at all by the old code and the new code does handle them.
IIRC some of the old blog posts / slide decks noted that the conversion to rust uncovered a number of bugs in the C code (e.g. edge conditions it didn't handle).
I would love to hear more about what kind of data you'd want to see. I've thought about this a lot, but it seems like if data suggests Rust has fewer bugs than C, then this only suggests a correlation. For example, other causes of fewer bugs might be the programmer themselves, the fact that it was rewritten from an earlier project and thus benefited from the design lessons of that project, or perhaps that the project isn't as widely used as its C version, and thus, has fewer bugs discovered. How do you control for those variables in a convincing way?
Kind of a hard/broad question to answer. How do you ever really know that you know anything? :-) Without getting too philosophical, I'll give you the frustrating first approximation answer that I use: you know something when you understand what it is you don't know, and when confronted with the thing you don't know, you _generally_ know where to look. For example, if you look at a lot of beginner questions, many of them are "trivially" answered by reading the book, or someone else's code, or some other type of doc (Cookbook, Rust By Example, etc.). The problem is that the beginner doesn't yet know how to explore the vast mine of information at their fingertips. Anyway, that's a bit of a strained explanation, but that's kind of how I try to gauge my confidence in whether I really know something or not. But it's hard, and subtle. In terms of something more concrete: take a non-trivial program you've written in another language. Can you conceptualize writing that in Rust such that you're pretty sure you either know how to do every piece, or if you don't know, you know how to figure it out?
Link to the repo?
I'm actually pretty tempted to write an MMIX interpreter or even JIT...
I would definitely follow that
Must be willing to move to Denver, Colorado.
Visa sponsorship is a possibility.
Dependency injection is simply the act of providing dependencies to some scope or object or so. Passing variables to a struct constructor or function can be thought as a form of dependency injection. So yes, dependency injection is very much relevant in Rust. Inversion of control maybe not so much, at least I haven't encountered any crates that use it.
I don't think number of github repositories is that common of a metric that people use to judge a language's popularity. When people talk about Rust as a "most loved language," people generally point to the stackoverflow developer survey, which actually directly asks this question. Rust also tends to rank high when looking at speed of growth, measured by e.g. increase in number of pull requests, or number of contributors. None of the above statistics are much affected by a large number of repositories from a single user. Note also that these measures do not indicate that Rust is widely used at all. It has a small but quickly growing dedicated userbase. This would also explain why not many jobs are available for it. Depending on a comparatively new, small technology as a business is a risky move, even if it's quickly growing. Rust's target area, system programming, is especially risk-averse and prefers proven technology. &gt; This leads me to me believe that there was (is?) a concerted effort to artificially boost github's "rust adoption" numbers. This hypothesis was further backed up by the fact that the committer was a Mozilla employee. It's a stretch to call the effort "concerted" when there is only a single user. It's also not that strange to find a Mozilla employee with a lot of rust code on github, simply because rust originated there. Lastly, if there was a plan to artificially pump up statistics like this, why wouldn't they do it anonymously? Why not post the user you're talking about?
If this was an intentional effort to rig the numbers, why would they use their Mozilla account. It seems very short sighted if they wanted to be covert. Could you please link an example of this. Seperate to that, the 'most loved language' statistic is not from the number of repos or amount of code at all. It is from a stack overflow survey. https://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted 
When you can write a nontrivial library or application and understand it well enough that you can help someone else do the same.
I tend to use a combination of \`super::{super::,}mod\` and \`crate::mod\` depending on the number of \`super::\` and whether it's clearer to think about it as a neighbour of 'here' or as 'this other part of the crate I'm part of'
They will not be working on Redox, except when there is crossover. This is a job pertaining to hardware enablement for Pop!_OS and Ubuntu with firmware, drivers, and userspace.
One reason I remember Federico mentioning is that the Rust code also has far more tests than the previous C code.
Thank you for your feedback :)
I'll second that. Most of Rust came pretty easily for me, and when I struggled with things, that was just a natural consequence of learning. I don't see it as particularly hard to learn, just something that requires a significant amount of of learning, so you'll feel ignorant for a while as you try new things to see if they work. But maybe that's just my background and intelligence serving me well.
The web just got a tiny bit better: you can now bookmark the example
Clippy just informed me that the syntax is: ``` error: useless lint attribute --&gt; src/lib.rs:1:1 | 1 | #[deny(missing_docs)] | ^^^^^^^^^^^^^^^^^^^^^ help: if you just forgot a `!`, use: `#![deny(missing_docs)]` | = note: #[deny(clippy::useless_attribute)] on by default = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#useless_attribute ``` Multiple-meta linting for the win.
This sounds like a dream job -- I've always wanted to move into kernel work because I know I'd find it engaging. It seems this position requests somebody more experienced, though?
Deoptimization can be made zero-overhead these days. Not sure if v8 does that, but see truffleruby.
I did a bit of digging and here are stats for the top rust github repos by kilobytes per commit. | index | repo_name | language | KB_per_commit | |-------|-----------------------------------------------------------------------------------------------------------|----------|--------------------| | 0 | [jeltz/rust-debian-package](https://www.github.com/jeltz/rust-debian-package) | Rust | 3980.05517578125 | | 1 | [dkarwowski/stm32f429x](https://www.github.com/dkarwowski/stm32f429x) | Rust | 1246.1142578125 | | 2 | [GregoryComer/rust-x86asm](https://www.github.com/GregoryComer/rust-x86asm) | Rust | 939.701017680921 | | 3 | [Yamakaky/rust-bindgen](https://www.github.com/Yamakaky/rust-bindgen) | Rust | 552.560546875 | | 4 | [kushti/mpt](https://www.github.com/kushti/mpt) | Rust | 420.130615234375 | | 5 | [deverton/condensor](https://www.github.com/deverton/condensor) | Rust | 411.63818359375 | | 6 | [yuri91/stm32f40x-rs](https://www.github.com/yuri91/stm32f40x-rs) | Rust | 344.0823653371711 | | 7 | [bednarskia/GraphicsInRustViaHeadBashing](https://www.github.com/bednarskia/GraphicsInRustViaHeadBashing) | Rust | 326.3265625 | | 8 | [lucasbrendel/xmc4200](https://www.github.com/lucasbrendel/xmc4200) | Rust | 321.48004557291665 | | 9 | [brayniac/nix](https://www.github.com/brayniac/nix) | Rust | 311.650390625 | | 10 | [kjetilkjeka/s32k144.rs](https://www.github.com/kjetilkjeka/s32k144.rs) | Rust | 307.68713618259807 | | 11 | [NextStepGuru/BotFly](https://www.github.com/NextStepGuru/BotFly) | Rust | 305.682689525463 | | 12 | [elastic-rs/elastic-requests](https://www.github.com/elastic-rs/elastic-requests) | Rust | 304.4521484375 | | 13 | [nikomatsakis/yaccrpop](https://www.github.com/nikomatsakis/yaccrpop) | Rust | 295.93505859375 | | 14 | [urschrei/ostn02_phf](https://www.github.com/urschrei/ostn02_phf) | Rust | 294.3227751358696 | | 15 | [serde-rs/aster](https://www.github.com/serde-rs/aster) | Rust | 291.3408203125 | | 16 | [elastic-rs/elastic-types](https://www.github.com/elastic-rs/elastic-types) | Rust | 286.599609375 | | 17 | [athenainn/rust-trace](https://www.github.com/athenainn/rust-trace) | Rust | 282.61489470108694 | | 18 | [shaneutt/riak-rust-client](https://www.github.com/shaneutt/riak-rust-client) | Rust | 271.6837890625 | | 19 | [rust-playground/strutil](https://www.github.com/rust-playground/strutil) | Rust | 264.8975830078125 | | 20 | [ProfFan/RMBoardTest](https://www.github.com/ProfFan/RMBoardTest) | Rust | 251.64271763392856 | | 21 | [Blei/rust-dumb-gtk](https://www.github.com/Blei/rust-dumb-gtk) | Rust | 250.80753580729169 | | 22 | [hyunsik/libhdfs-rs](https://www.github.com/hyunsik/libhdfs-rs) | Rust | 247.8026592548077 | | 23 | [brayniac/mio](https://www.github.com/brayniac/mio) | Rust | 238.0927734375 | | 24 | [fbernier/graphicksmagic-rs](https://www.github.com/fbernier/graphicksmagic-rs) | Rust | 228.15234375 | | 25 | [bluss/vsop87-rs](https://www.github.com/bluss/vsop87-rs) | Rust | 217.43190104166663 | | 26 | [Mark-Simulacrum/rustc-perf-collector](https://www.github.com/Mark-Simulacrum/rustc-perf-collector) | Rust | 208.7427900598404 | | 27 | [saurvs/astro-rust](https://www.github.com/saurvs/astro-rust) | Rust | 160.71568080357142 | | 28 | [wateryan/fixp](https://www.github.com/wateryan/fixp) | Rust | 153.71728515625 | | 29 | [holtchesley/jumprope](https://www.github.com/holtchesley/jumprope) | Rust | 130.8775390625 | | 30 | [chris-zen/hero-synth](https://www.github.com/chris-zen/hero-synth) | Rust | 129.07550048828122 | | 31 | [bjz/sdl2-rs](https://www.github.com/bjz/sdl2-rs) | Rust | 128.017578125 | | 32 | [id-Software/DOOM-3](https://www.github.com/id-Software/DOOM-3) | Rust | 124.30517578125 | | 33 | [autch/aquaplus_gpl](https://www.github.com/autch/aquaplus_gpl) | Rust | 123.5048828125 | | 34 | [ProtectedMode/llvm_sys](https://www.github.com/ProtectedMode/llvm_sys) | Rust | 121.8115234375 | | 35 | [matklad/bunny](https://www.github.com/matklad/bunny) | Rust | 120.23567708333331 | | 36 | [moorwu/iOSMSC5PluginSample](https://www.github.com/moorwu/iOSMSC5PluginSample) | Rust | 116.629638671875 | | 37 | [id-Software/Quake-III-Arena](https://www.github.com/id-Software/Quake-III-Arena) | Rust | 114.0224609375 | | 38 | [immartian/musicoin](https://www.github.com/immartian/musicoin) | Rust | 113.12511837121212 | | 39 | [billpmurphy/rustfix](https://www.github.com/billpmurphy/rustfix) | Rust | 107.5517578125 | 
You probably want /r/playrust
In the early days of Rust, the Firefox team did some stats on the security vulnerabilities in the codebase. About half of them were due to memory safety issues that Rust would have prevented.
Traits are an expression of IoC, aren't they?
Oh, Thanks you, everything it is working as expected after removing the std::Borrow import, no more dereferences in the code , i added the import because previously the compiler was complaining about not finding it in one of our early fights. Also it make more sense now why Rc::clone is not working, i tough on ask if there is a way to specify the type but i finally figure out the syntax for that. printables.push(Rc::&lt;RefCell&lt;Dog&gt;&gt;::clone(&amp;dog)); dog.clone() looks better but i remember reading in the book that Rc::clone is recommended. &amp;#x200B; PD: originally the code for the loop was using a Iterator (printables.iter()) but maybe i deleted it by mistake before posting, it was like this: for printable_item in printables.iter() { (*(*printable_item)).borrow().print(); } &amp;#x200B;
As far as I know, the [`assume(b)` intrinsic](https://doc.rust-lang.org/std/intrinsics/fn.assume.html) has a problem that it can impede LLVM optimisations because the expression used in the intrinsic is kept alive. Do you know if modelling `assume(b)` as ```rust if b { } else { unsafe { unreachable_unchecked(); } } ``` would have the same issue? For example, is it guaranteed that LLVM will always delete the else branch? I am interested in this because performing even exactly the same static analysis on the Rust level (more specifically MIR) should be more precise than on the LLVM level because of more precise aliasing information that is available in the borrow checker.
There's a slide deck from last year's GUADEC, which has these. Not exactly old :). https://people.gnome.org/~federico/blog/guadec-2018-presentation.html
Didn't know about that. Every time I've used it the branch got removed, I checked the assembly. It would be pretty weird if it didn't since it's unreachable and the compiler is pretty good at removing unrechable parts of the code. I use it mainly to unwrap filled options and removing branches that panic (and are impossible)
I'm looking at the questions from today (09.01.19) and look at the questions from users &lt;1k. * PK Chem: 0 votes, 2 answers (1 accepted) * user3034758: 0, 0 answers * subhojit777: 0, 0 answers * jmwright: +3, 0 answers * Nick Vincent: -1, 0 answers * georch: +2 votes, 2 answers (0 accepted) * Oliver Funk: +3 votes, 0 answers (comments say, that the error cannot be reproduced, nothing happened since 13 hours from OP, 2 close votes ongoing) I don't see anything bad here. If you ask a good question you will receive good answers. If you ask a \*not so good question\*, you will receive negative votes, because people want you to improve your questions (many people will retract their downvote when the question has been editied!). &amp;#x200B; I think your allegations are unfounded unless you can prove the opposite.
he also posted a question on so: https://stackoverflow.com/questions/54103154/rust-wasm-react-webview-unhandled-promise-rejection-typeerror-url-is-no
&gt; I used to wonder why Rust is frequently sited as the "most loved language" yet the number of available jobs coding in Rust is slim to none. It would seem to me that a language with such a dedicated following would quickly find its way into the center of software development projects. It's highly rated by the people who have used it. That doesn't mean that lot's of people are using it or have even tried it. Also, I absolutely love working with Rust, but I wouldn't necessarily choose it for a project at work just yet, even if I was the one making that choice. That language itself is wonderful (although there are still a few things missing here too), but languages like javascript or python or java or C# have a library for everything under the sun, which is pretty hard to ignore in a commercial situation. Also, there are comparatively few Rust developers, so if I was looking to hire people then I might be wary of choosing Rust (although it could definitely be a draw too). 
I've copy pasted your swift code to Rust and it is fast (1.1ms on my machine), need to investigate more. https://gist.github.com/pftbest/7ad3069461a173d951860a80a3015a50
You can find a problem with questions. There are enough vague rules to justify anything. Every single one of my Rust questions were overly moderated by the same stack overflow user. That is absolutely provable. Anyone new would have the same experience. 
You probably want (lalrpop[https://crates.io/crates/lalrpop]. Here's (how to use a custom lexer with it)[http://lalrpop.github.io/lalrpop/lexer_tutorial/index.html]
When every time you write code in another language, you think to yourself "this would be so much easier and more reliable in Rust", and then you run "cargo new my_new_idea", and then four hours later your boss asks why you haven't finished the thing in C / VB / Java / whatever. 
You could also use the docker image, but if you PM me I'll send you a link to download it all.
lol is that like [the esolang](http://www.dangermouse.net/esoteric/piet.html)
That means there are a lot of bugs Rust would prevent, if we could convincingly show that using Rust doesn't introduce a significant amount of bugs in other areas we would have our proof.
Thanks! I personally never use super, except for test modules to import what they’re testing. It’s likely something two levels up the hierarchy is closer to the root than not, unless you’ve got a *really* nested module tree.
&gt; I'm not familiar with the crate, and while I'm familiar with futures I admittedly haven't worked with them much, but it sounds like what you want to do is move the client and not work with a reference. This. If you are working with futures that require `'static` lifetimes, make sure all values captured by the future are fully owned. If you have any borrowed data, you should either copy it, clone it, or convert it to an owned type (e.g. for a `&amp;Path`, use `.to_owned()` to produce a `PathBuf`). Some structs which have lifetime annotations, for example `Foo&lt;'a, T&gt;`, should be converted to have a static lifetime, like `Foo&lt;'static, T&gt;`. If the struct implements `ToOwned`, use the `.to_owned()` method to do so. Closures used with combinators such as `Future::map()` and `Future::and_then()` that reference outer owned values should be annotated with `move |...|` to ensure the values are moved in rather than borrowed. Futures which require `'static` essentially disallow external borrows to data. Eliminate those borrows by cloning and taking ownership, and you should be fine. Data structures that are prohibitively expensive to clone can be wrapped in an `Arc` before cloning.
What platform are you trying to build for? Is it windows? web-view wraps system webview api, which is in the case of Windows, IE11. IE11 does not support wasm, so that might be a problem. Minimal reproduction project would help immensely, if you can post that. But in this case this seems like something to do with webpack.
No, we're just obviously inspired by the same source. The idea is that piet is to rectangles as serde is to json.
&gt; Knowledge is of two kinds. We know a subject ourselves, or we know where we can find information upon it. — Samuel Johnson
I'm currently half way through writing a futures wrapper around indexeddb. Will let you know when it's finished
Thanks for this, I'll certainly use it. &amp;#x200B; Ideally this tool shouldn't be necessary though, and it would be better if cargo cleaned up its own mess, kept the cache to a reasonable size, and let you choose where the \`.cargo\` directory should go (I'm on Windows, and my C:\\ drive is a tiny SSD drive which is supposed to only contain the OS...)
That's correct; it's short for "Translation". It's been changed to "codegen" since that post was written. https://github.com/rust-lang/rust/pull/50615
It uses cargo as a library, which has its own set of dependencies that is fairly large.
I've always enjoyed https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/ as a model for this kind of thing.
I know a language when I can go into flow while writing it. I can read/write, hack stuff out, and debug before that point and people might pick one of those as their threshold. On the other side, there may be architecture, philosophy, or library design topics I haven't grasped and I've heard people equate knowing something to mastery of the topic.
You can use winapi crate to call unsafe win32 functions with both gnu and msvc abi. 
I look forward to it! 
Some while ago I tried to express it: [https://github.com/snuk182/indep](https://github.com/snuk182/indep) . Nothing really special there, dynamic dispatching + reference counting.
Sorry but how does it work? Isn't the actual bins code of win32 using msvc abi?
Yes, all of the Pop!\_OS projects that we write for userspace are written in Rust, with a few exceptions. Other System76 hardware projects are also written in Rust (ie: imaging system). All projects should be written in Rust where possible. You do have to know C if you're going to integrate a feature with some existing open source software (ie: GNOME Control Center), or of course if you are writing a kernel driver.
Hmm... it might be helpful to count tests separately!
It works via Rust FFI and import libraries which are ABI-specific. MinGW (GNU) ABI is compatible with win32, that's what it was made for. 
Because the JIT has access to information that rustc + LLVM doesn't have. For example imagine I make a program that counts the number of '1's in a binary representation of a string, and then I feed it input that conist of 2^32 'a' characters. rustc + LLVM have no reason to expect a ton of a characters so can't optimize for it, the jit could in theory notice the trend and create a fast path that counts 1's in a's really efficiently. (This is assuming that we consider rustc + LLVM 'compiling' rust by embedding a JIT to be disallowed, which it is in practice)
A JIT compiler can do two things that an AOT compiler can not: * Profile the running program, with full visibility on all the details of how the running code executes. * Do speculative optimization, possibly running in parallel to the existing best version of the code. Let's consider a standard compiler optimization: Loop unrolling. In order to unroll a loop, you need to pick an unrolling factor (how many copies of the old loop body go in each new loop body). Unrolling a loop reduces the overhead of the loop itself, but it also increases code size which leads to a big performance drop when you start getting L1 code misses. What the correct value is will be different for every machine, for every different loop, and possibly for every different input value to the function with the loop in it. It's not practical to statically analyze source code and figure out the best unrolling factor for each loop. Compilers like LLVM have some decent heuristics, but they certainly don't get close to the optimal answer. And they don't have access to the program's runtime input data, so they can't even consider that factor. The best you can do with AOT compilation is profile-guided optimization. You pick a couple sets of input data, run the program on them with different optimization parameters, and then AOT compile with the best settings you found. There's been some research work on using genetic algorithms for this because the search space is so large, and they've shown that you can get decent performance improvements if you want compilation to take a couple days on a research cluster. Clear Linux could probably get another 10% performance boost if they did this. JIT compilers can do the same sort of thing, as your program runs, knowing the specific input data that your program is running on for this particular execution. An exhaustive search isn't possible - any work the JIT does competes with the main execution of the program - but there's a bunch of strategies that seem to work pretty well in practice. One neat trick here is that a JIT can use multiple cores to speed up the execution of sequential code by trying multiple compiled versions in parallel. None of this is terribly useful for Rust. The Rust developers picked a conservative design, preferring performance predictability over the hope that some sort of language runtime could try to outsmart the programmer and likely fail a lot of the time. But in 2077 when Objective Elixir programs are spending half their execution time in the JIT on 65,535-core workstations and still beating Rust on benchmarks it won't be hugely surprising. And with all that, FORTRAN will still be doing faster matrix multiplications.
That's great to hear! You guys will be a very strong consideration for my next laptop purchase! 
Maybe you could try to get a feeling with kernel work by writing a small module yourself?
I contributed this markov chain text generator to rosetta code: [https://rosettacode.org/wiki/Markov\_chain\_text\_generator#Rust](https://rosettacode.org/wiki/Markov_chain_text_generator#Rust) But it's quite ugly in places! I would appreciate hints on how to simplify it or improve it.
Thanks! I tried fixing the issue with https://github.com/matthiaskrgr/cargo-cache/commit/eb379bf0a4392fa6c9bb526c4f650d726cda9b73 Could you please check the git version and tell if the bug still occurs?
AFAIK both use the same C ABI on Windows, and when calling from Rust, you call C functions. C++ ABI is a different beast and here GNU toolchain and MSVC are incompatible. But you never link directly to C++ functions from Rust, you always go through C-like FFI.
At a minimum you have to understand this: https://github.com/rust-lang/rust/blob/master/src/test/run-pass/weird-exprs.rs
I'll have to take a look at this later, one of my to-do rust projects is a compiler (though right now i'm following terrajobst's c# one for making a .NET language compiler to get comfortable on the compiler side as I'm still bad at rust, and I always try to focus on learning one large thing at a time). Which reminds me, does anyone know of a good tutorial for using the rust LLVM bindings? My end of all goal would be compiling to machine code and LLVM seems the best way to do that.
Rust/C++/C, as Rust is a lower-level language that doesn't use runtime garbage collection, as Go does. As in, you can't remove the garbage collecting behavior of Go, so you wouldn't program an OS with it.
It's worth noting for this topic that the test coverage might be the reason that these specific rewrites in Rust reduced defect count, not Rust itself.
On the other hand, the relative ease of writing tests in Rust may be a reason that the test coverage was increased.
What the heck is that?
Gecko was about half, Firefox as a whole was more IIRC
thanks, added.
THANK YOU! This is exactly what I need!
I mean, sure, but at some point we're getting more categories than C++ has accepted language proposals.
I usually go by a few factors and see it a bit more granular than just "yeah i know this language": With python for example I consider myself an expert and would say i really know the language because I know pretty much all of the standardlibrary as well as lots of third party packages, have the lingo and formatting/naming conventions down and developed loads of stuff in it. In contrast to that there's C for example, where I say I have a basic understanding of the language and know how it works (and could probably develop most stuff in it that I wanted to) but by no means do I know all conventions, pitfalls or libraries, because it's a language I rarely write in. Related to that are languages like assembler or SCL that I have used extensively but where I never really integrated into the community or read into them, so I don't really know how much more there is to them (with asm I don't think there's that much to it, but again I haven't read into it so maybe I'm wrong) And finally there are languages like javascript (well Google App Script in my case) that I have used to build stuff before but have legitimately no clue how they work outside of that scope, I probably don't even know all of it's base-syntax. &amp;#x200B; So all in all I think it's really not enough to just say you know a language, because there's so many facets to it. A buddy of mine that knows a shit ton of languages (did a masters in IT) once said to me (because I had the very same question as you but relating programming in general, not rust specifically) that he'd say that you can say you know a language once you have the syntax down. Every library or really specific language details are a bonus. I'd extend on that and add that you should 'get' a language and have a basic understanding of what's considered idiomatic in it and, maybe more importantly, what's not.
Assign the same project to two different groups, one using C and the other using Rust. And then compare the results at the end. Of course, it's not an experiment a real company could do, but it would work.
It’s one of the oldest test files in rust that still lives to this day. It’s for testing parsing bugs. It has a fun history; some of the things that it was testing have been lost in the sands of time. evil_lincoln is a good example of this.
Thanks for the very detailed explanation. Is it true if I say that we are comparing hypothetical future JIT compilers to current AOT compilers?
I think that's probably the trivial answer, right? At least, to some extent. Aside from the practical problems associated with actually running that experiment (you'd likely need to secure funding in order to pay the groups, for example), comparing the results will be difficult if both projects don't achieve high adoption in environments with similar threat models. I think part of my point here is that convincing data to support these conclusions is pretty hard to come by. So when people ask for it, I'd like to know what would personally convince _them_.
Sure, https://hastebin.com/axahifaker.js
I'm building for OSX. Note that everything works correctly when I use webpack's server or Caddy; it's only when I attempt to load it in webview that I get this URL issue.
I've looked around on this a little and haven't found anything great that's Rust specific. LLVM has a good tutorial for learning the library by implementing a JIT compiler for a toy language written in C++. Personally I was going to follow that tutorial and just re-implement the C++ parts in Rust instead. &amp;#x200B; [https://llvm.org/docs/tutorial/](https://llvm.org/docs/tutorial/)
Don’t use mod anymore with Rust 2018 if they are in the same level and each has a separate Cargo.toml you can just reference there. For example mod1 has dependency on mod2 In mod1 Cargo.toml: [dependencies] mod2 = { path = “../mod2” } In mod1 lib.rs extern crate mod2; use mod2::WhateverStruct;
You need to parse them to pull out the data you care about.
"the Discord server" - could you provide some background I'm interested but I have never used Discord?
Discord is a chat platform and it is being used to host a server for people interested in Rust. It's quite active and it's listed as one of the Rust community hubs on the official website - https://www.rust-lang.org/community
Thanks I found it. I came back here to say as much but you beat me to it :)
My goal was to compare hypothetical future AOT compilers to hypothetical future JIT compilers. For current production compilers there are cases where Java beats C++ on long running programs due to JIT, but in most cases a good AOT compiler will give the best performance.
Totally plausible if they inline documentation with the code, as standard for rust
It is easy to add Ed25519 support to webpki. There's even an open issue for it: https://github.com/briansmith/webpki/issues/49. Nobody has expressed interest in it until now. I suggest leaving a comment in that issue.
Anything that uses Tokio does inversion of control, so that means Hyper and Actix. Rocket does it by extension from Hyper, too.
Can we see the code? That would be very helpful as it doesn't seem to be a problem with Tokio to me.
https://github.com/rust-fuzz/trophy-case versus http://lcamtuf.coredump.cx/afl/ In the latter, all the items in the table are exploitable bugs. The non-exploitable crashes are not even listed. Compare that to https://github.com/rust-fuzz/trophy-case which lists exactly 3 security bugs discovered to date; the entire rest of the table is not exploitable.
Proud to be Swedish &amp; reading this
Rolling a Rust version of the first few chapters in Cryptoeconomics.Study. Ideally this will follow along with Cryptoeconomics.Study as the course develops, but time will tell. It's a WIP so if anyone has any feedback, suggestions, or would like to work on it with me hmu! :) - https://burrrata.github.io/rusty_cryptoeconomics/intro.html also started compiling resources related to developing crypto or blockchain development in Rust, so if anyone knows of anything not on the list please let me know - https://burrrata.github.io/rusty_cryptoeconomics/resources/building.html
solved using [https://github.com/terry90/diesel\_as\_jsonb](https://github.com/terry90/diesel_as_jsonb)
&gt;r/rust &gt; &gt;49.4kRustaceans581Online &gt; &gt;For everything related to the Rust programming language—an open-source systems language that emphasizes safety, performance, and concurrency. Will this be improved in the next version of Rust?
Yeah that I know about, and i plan to do a first basic pass in C++ to minimize confusion points first, but I dunno how much different you have to do for... llvm-sys or whatever the wrapper layer is that is also used by the rust compiler itself.
First of all, it is not a binary understand/don't understand distinction. I feel like I'm still learning Rust, and I have more experience in it than most. (I sometimes joke that I have 25 years experience because I did my Masters thesis on static memory management for ML Kit, one of the sources of inspiration for Rust). So in general I would say it comes down to experience, having written several diverse programs in Rust. Lifetimes are obviously a major part of the learning curve (and I still run into them, especially when trying to do advanced stuff like carry a reference through a builder), so having basic use of lifetimes be second nature is important. To that I'd also add being able to use traits effectively. I'm working on a presentation of the traits in my 2D graphics abstraction which I'm hopeful will be a good learning resource. Best of luck on your journey, and may it be a rewarding one!
Prob if others would look at your code and say its at least close to idiomatic. Like you can have an extra clone or 2 over what is possible or on occasion re-implement something there are libs for but there shouldn't be much of that.
Would be really nice if you can suggest any source about writing a small module. I’m planning to buy two books to understand linux kernel. I am not sure if those books are suitable for someone who barely understands operating systems and cpu. these are the books: Understanding the Linux Kernel https://www.amazon.co.uk/dp/0596005652/ref=cm_sw_r_cp_api_i_G0KnCb1YRYP8S Linux Kernel Development (Developer's Library) https://www.amazon.co.uk/dp/0672329468/ref=cm_sw_r_cp_api_i_a1KnCbQ67J0ZN
Thanks for doing this, it's indeed very fast! I'm benchmarking it with Criterion and it runs in about 1.15ms here. I'll see if I can make it even faster.
https://kernelnewbies.org/ https://kernelnewbies.org/FirstKernelPatch
I don't know anything about kernel development, I'm just a big fan of learning by doing, and getting your hands dirty with things you're interested in. Others will provide much better suggestions. There's even some info/blogposts/guides for writing kernel modules in Rust.
I didn’t know you could mix crate and mod. Thanks for the heads up!
I thought recommended way is `cargo new my-new-idea` but in the code you can use underscores when referencing module names. I've trouble finding the link to the post that explains it. 
If you want it to, get a discussion going about it in #rust or #rust-libs on IRC, then make a pull request. 
From your EDIT 2 version, this is modified and seems a little more efficient: https://gist.github.com/rust-play/095b4bacec9179ea5949bddeb9d52510 If you care about the performance a lot, a hardcoded version is a little faster still (if you compile it well, native CPU and O3): https://gist.github.com/rust-play/612fcbc67a380862dc9e820ecb1bcf04
Cool ! However the cheat sheet URL is wrong (I also notified on twitter)
I am making a wrapper around a slice for purposes like toggling crate wide bounds checking through feature flags. the wrapper type is `pub(crate) struct Digits&lt;'a&gt;(&amp;'a [Digit]);` and I have a function \`iter\` on it that returns a `slice::Iter&lt;Digit&gt;`, which I am trying to feed into another function that requires its input implement `IntoIterator&lt;Item=Digit&gt;` (which is implemented for `slice::Iter&lt;T&gt;` so it should work). Basically, fn from_iter&lt;I&gt;(input: I) where I: IntoIterator&lt;Item=u64&gt; {} fn main() { let x: &amp;[u64] = &amp;vec![1u64,2,3,4][..]; from_iter(x) } `&amp;[T]` implements `IntoIterator`, but why is it giving me this error error[E0271]: type mismatch resolving `&lt;&amp;[u64] as std::iter::IntoIterator&gt;::Item == u64` --&gt; src\main.rs:5:5 | 5 | from_iter(x) | ^^^^^^^^^ expected reference, found u64 | = note: expected type `&amp;u64` found type `u64` note: required by `from_iter` --&gt; src\main.rs:1:1 | 1 | fn from_iter&lt;I&gt;(input: I) where I: IntoIterator&lt;Item=u64&gt; {} I get a similar error when trying to implement `IntoIterator` for my type
I got the green light from $EMPLOYER's legal for releasing our first crate! It's a small one, but hopefully not the last. It's a small struct that implements the \`Iterator&lt;Item = String&gt;\` trait for a directory containing files. The string returned are the lines of all the files in the directory. When a file is completely read, the next one is opened and read. Files are sorted "human readable" (\`file\_10\` appears between \`file\_9\` and \`file\_11\`). [https://crates.io/crates/dir\_lines\_streamer](https://crates.io/crates/dir_lines_streamer)
In addition other answers, LOC (within a reasonable multiplier) is a poor indicator of semantic or cognitive complexity, especially when different languages are compared. E.g. using monads or enums can be more LOC than integer-based status responses, but they increase rather than decrease clarity and coupling.
It's not a fair comparison when porting old C code to Rust code. The old C code had a lot of bugs and issued ironed out the hard way in the past, and it's current stability can be a sunk cost rather than due to the merits of the language. I'd expect porting an old popular C library to any other language (Rust included) to increase short-term bugs, purely because *any* port/rewrite carries a risk of new bugs being introduced.
You could just use closures for the action instead of a trait. What do you need to serialize that prevents you from excluding actions, or implementing Serialize/Deserialize by hand? 
I think dynamic dispatch is the right approach here. Can you show an example of what doesn’t work (I don’t know serde so much that I understand the part with the generic types)?
Oh, or do you mean that you can’t serialize the menu (that is the menu item text + which action to call) itself? You could implement your own serialization mechanism that asks each action for its ”unique name“ and have a factory that produces those actions again based on that name when deserializing.
The point about docs and LGPL was interesting.
Thank you very much for the pointer and the detailed example! I tried the code you shared and it works, but with a bit more benchmarking as you suggested I see something that I cannot explain... this is my code to benchmark the performance: [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4b8c2b55debb5f8b2a970cc1c7fecbdc) and below is the benchmark result: running 6 tests test tests::STDhasher_collect ... bench: 510,587,079 ns/iter (+/- 5,686,925) test tests::STDhasher_insert ... bench: 178,666,357 ns/iter (+/- 5,178,524) test tests::STDhasher_insert_and_get ... bench: 265,348,763 ns/iter (+/- 6,139,969) test tests::myhasher_collect ... bench: 532,956,371 ns/iter (+/- 3,947,768) test tests::myhasher_insert ... bench: 164,572,862 ns/iter (+/- 4,442,183) test tests::myhasher_insert_and_get ... bench: 201,608,705 ns/iter (+/- 4,292,103) it appears that: 1. first defining a hashmap and then insert key-values in a loop is much faster than using collect() in a Functional Programming manner. 2. for adding new key-value into the hashmap, the std and very-simple hashers have very close performance. 3. for getting value with a key, the very-simple hasher out-performs the std hasher, but not significantly. Are my conclusions correct as above? And why the insert method shows much better performance than the collect method? Many thanks again!
`IntoIterator` is indeed implemented for `&amp;'a [T]` but `type Item = &amp;'a T` not `T`. 
Can you use it to make something useful without having to dig into the documentation for something basic? At that point, you are beginning to know it.
Thanks for the reply! I will try to give more details. I am trying to build a rofi menu creator in Rust. So I would like to be able to declare the menu in a yaml file, and then be able to create the hierarchy in rust using the above structs. Thus serializing an already existing menu is not very important, what I really need to use serde for is to parse the yaml file and recreate the object. The problem in serde is that I need to implement the Serialize and Deserialize traits in order for it to work. But, these traits have generic types in the functions they declare, which means that I will not be able to make an object trait. I managed to get serialization to work using a crate called "erased-serde", but getting the deserialize part to work was more complicated and I gave up thinking that maybe I am overcomplicating things. If dynamic dispatch is indeed the way to go, I should probably spent more time into trying to make it work.
To be clear, I'm not against the idea that "in theory" a JIT'd language can be faster than a *strictly* AOT language. But it basically never actually ends up being the case, especially when we're talking about Rust and JS. I'm also not sure that the optimization described would be worth it. Data doesn't usually change drastically - if you have short keys, you'll probably keep having short keys, and you can just encode that in your AOT program. This is probably why it hasn't been pursued - especially since there's a tradeoff with keeping your JIT light. The corollary to "a tracing JIT can do anything you can do at AOT" is that anything your tracing JIT can do I can also do AOT. I can write data structures that dynamically change behavior. I can even use a JIT. I can have a DynamicSet that is instrumented to determine lengths of keys and optimize based on attributes of keys and operations. And it's a false dichotomy anyways - there are AOT compiled programs that JIT (Julia, Java). My initial point*, that JS is basically never going to be faster than Rust (or even comparable), imo still holds in virtually every case in real programs. JIT and allocation strategies may change this one day - but I personally doubt it. Some other JIT language that *is not javascript* could maybe do it though, and likely will for many use cases. * "I can't really think of any situation ever where Rust and JS should have comparable performance." 
Fixed. Thanks!
Didn't know about the examples repository. May contribute a few examples in my free time.
Not the author, but I appreciated the positive perspective.
I wouldn't expect that. C has substantial amounts of undefined behavior or implementation defined behavior that would be simply relied upon without realizing it. In Rust it's going to be more explicit so you're going to have more lines of code.
Teaching kids to program with BASIC is damaging to their developing minds. (I remember as a kid I looked into learning BASIC and my dad banned me from doing so for this reason and I learned Berkeley Logo instead.)
&gt; You Can’t Sort Floats There are some crates that make it possible to sort floats, like [`decorum`](https://crates.io/crates/decorum). The catch is that you have to choose among several different options for how NaN is handled. This isn't an area I know much about, but I've heard people say that allowing float sorting by default ends up causing confusing errors down the road, because the NaN conditions are so tricky.
BoringSSL is basically OpenSSL. Most of the code is the same.
It's a spectrum. I think when you stop fighting the borrow checker and lifetimes as much, you're doing pretty well.
I'm not sure about listing volunteer positions under jobs, shouldn't that be calling for participants?
Well this gives me second thoughts on applying to Mozilla...
I think you'd have to look at the generated code to see what happens. I suggested what I did since it makes the optimizer's job very easy, versus what it has to do when just using peek_mut.
His question is still valid though :) I guess you meant broadcast ...
That's just Dijkstra being grumpy as usual, I wouldn't take it too seriously.
I ve been writing cv-rs for a while. It contains some basic features and you can add more if you want. Of course, it's not that powerful as python is, but it's because they didn't share their codegen code. I created an issue but they didn't really address it 
Okay, so far I understand this: You implemented `Deserialize` and `Serialize` on the actions and now you want to call (via serde) the `serialize()` and `deserialize()` methods through the trait objects, which does not work, because they have a type parameter. But even if you could call those methods, this can not possibly work, because when deserializing the yaml file, wherefrom shall serde know which exact object to instantiate for the trait objects? There needs to be some factory that translates from *something in the yaml file* to *some real object*. So I think you need to implement `Deserialize` on `Menu` itself and do that translation manually. Is it really necessary that your `run()` method returns another `Action`? Everything could be much simpler if you separate the actions from the sub-menus like this: ```rust enum MenuItem { Action(Box&lt;dyn Action&gt;), SubMenu(Menu) } struct Menu { items: HashMap&lt;String, MenuItem&gt; } ``` You still need to implement your own deserializer for `MenuItem` for the reasons described above.
That'd be awesome!
I'm pretty sure that part of Steve's pride in Rust is that he's left it better than he found it -- meaning it'll be even easier for it to survive with its current trajectory. So...no, I don't agree with this. ;)
Ah i meant pick one, so that one receiver can consume it
Both of those are great books. Unfortunately they are targeting old kernels (2.x), but my feeling is that you'll get a basic understanding of major kernel subsystems despite contemporary kernels have evolved quite lot. https://0xax.gitbooks.io/linux-insides/ might be of your interest too.
Not really, you aren't really giving control to some library or framework just by using traits and/or dynamic trait objects. You still write the code yourself and you decide what is instantiated and when. When you give that control away we can talk about inversion of control.
The beautiful thing about Rust is that you don't have to "understand" it (to any pre-determined level) to use it. Because the things you don't know won't hurt you. (Well, that's not entirely true, but it's close. Compare with C and C++, where the things you don't know can easily hurt you.)
I like the idea of this granted I pretty much never use Discord. I've also had thoughts over the past month or so that it might be nice to have a working group formed around scientific computing/numerics/hpc type applications. So, we can focus our work on areas that are lacking and needed to make Rust a great language to do scientific computing/numerical work in.
I'll try it next time I'm on the windows PC, but I just installed it using cargo install, I won't have the latest version. But I have my doubts about that commit regardless. Isn't [path::join](https://doc.rust-lang.org/std/path/struct.PathBuf.html#method.join) already supposed to add separators? From the example on its docs, it seems like it does. Either way it would be very strange that the standard library's `PathBuf` wouldn't expose a method to construct a path without you having to detect the correct separator (using `if cfg!(windows)` stuff) yourself. What would even be the advantage of `PathBuf` over `String` then?
&gt; [disposition: merge] Summary issue for const-stabilizing const_int_overflowing. &gt; [disposition: merge] Const-stabilize const_int_ops + const_ip. &gt; [disposition: merge] Stabilize let bindings and destructuring in constants and const fn. &gt; [disposition: merge] Stablilize const_int_{rotate,wrapping,sign}. &gt; [disposition: merge] Stabilize uniform_paths. &gt; [disposition: merge] Stabilize the integer_atomics feature: Atomic{I,U}{8,16,32,64}. &gt; [disposition: merge] Stabilization proposal for #![feature(if_while_or_patterns)]. Yaaay! These haven't been merged yet, but even more interesting stabilizations are hopefully coming for 1.33! It's looking like a cool release already. :)
FWIW there are a fair number of papers that do this (papers that try to compare dynamic/ static langs). It's just not generally compelling in the end. Programmer experience is really hard to account for. How do you deal with a your two groups having totally different experiences? You can *try* to find people with similar experience sets - but that's really, really hard. I've read a number of papers that try (or don't try) to control for these things and I've yet to walk away from a paper feeling like it really demonstrated much at all.
I was working on [seekcrate](https://github.com/mglax/seekcrate), a toy program (rather, a PoC) to see if we could use the results of search engines to search for crates. In the end, search engines will always beat us at contextual search. It's my first Rust program so the code is horrible and I am sorry for that. The results are great, I think, as you can see in the examples given in the README file. &amp;#x200B; It currently uses scraping and only search on Google. I think scraping is against Google's ToU so I'm really documenting myself on using Google's API, though the first results I have are rather disappointing, searching on Google through an API is really not the same, quality-wise... I'll keep digging. &amp;#x200B; I also struggle a lot matching GitHub repos with actual crates on [crates.io](https://crates.io), I'll have to find a better method than what I'm doing right now. 
good please make linux usable! and hopefully also good hardware will follow, I want to one day buy a system76 and be happy with my purchase
Nu är du rejält ute och cyklar, hörru.
Removed most of the unsafe blocks from tantivy. Improving memory usage of tantivy at indexing. It was already pretty good. Now it is great . :)
It is probably not related to context. Crates.io search quality suck is not even as good as vanilla BM25.
thank you!
I think you might have meant to post in /r/playrust. This is the sub dedicated to the Programming Language called "Rust".
This post is from March, and https://news.ycombinator.com/item?id=18869474
I'm using Rust since years (started in 2014) and am still discovering new things. I guess I don't know Rust as much as I'd like to?
The feature was also designed to be very privacy conscious.
Is there a guide on how to use gtk-rs in a way that doesn't work against the borrow checker? Because in traditional gui development, it's not unusual to have multiple references to something, for example both a window and a button press function will have references to a button. (i briefly looked in the examples, but couldn't find an example that just tied an action to a button)
In my opinion, an enum is absolutely the right approach for differentiating between menu items with submenus, and menu items with actions: enum MenuItem { Action(...), SubMenu(Menu), } And then if you actually want to be serializing and deserializing actions, you probably want to assign something like a string identifier to each action.
Wrong sub. You’re looking for r/playrust
I'm sure it's not. https://github.com/hlb8122/geodesic/blob/master/src/daemon.rs
&gt; TLDR: If you’re looking for a crate, search for it on https://crates.io. Many great crates don’t show up Google! Interesting to see someone have this experience. This is the opposite advice I generally give folks. e.g. if you search for "async io" you won't see tokio, and if you search for "http client" you won't see reqwest. Prefix either with "rust" and type it into Google though, and you'll get the right thing above the fold if not the first result. Unfortunately, crates.io doesn't have a great metric to use as a proxy for "the crate people use for this thing"
I cannot say how much I *love* Rust. I'm not a programmer by trait (I'm a mathematician) and when I tried Rust, I fell in love immediately. It almost feels like someone has designed a language specifically for me... It truly feels empowering to write Rust.
Gtk has reference counting on its object and Gtk-rs relies on it so when cloning a widget, you're, in fact, not really cloning it.
I second this! Please include an updated graph if available.
I posted something similar [last month](https://www.reddit.com/r/rust/comments/a5g3ca/this_looks_like_why_firefox_is_a_pig/), and based on my Google Alerts surveillance, the meme of "Rust (and Servo) ruined Firefox" is getting more popular. Firefox userbase is unimaginably large. It is so large that not only Firefox users outnumber Rust users, any subset such as "Firefox users who once loved Firefox but hates it now and think it is ruined", or even extremely niche "Firefox users who once loved Firefox but hates it now and think it is ruined and heard of Rust and now strongly believes Rust is the cause", can match the number of Rust users, so we will hear more of these.
So i should just go about cloning everything?
I'm always amazed this happens so often
This works: let empty; let opt_x: Option&lt;&amp;BTreeMap&lt;String, Value&gt;&gt; = None; let x = match opt_x { Some(b) =&gt; b, None =&gt; { empty = BTreeMap::new(); &amp;empty } }; 
As someone new to Rust, can you explain more specifically what feels empowering about it? Thanks.
What I really like about Rust is that it offers me the upside of a low-level language but also protects me from many common mistakes in memory management. Mistakes I probably wouldn't even know about (given that I'm not a trained programmer), when I attempted to write the same thing in C/C++. Other than that, the documentation and package management is just incredible. Cargo... man... cargo is amazing. It lowers the bar of entry so much... And Rustfmt, thank whoever is responsible for Rusfmt. Absolutely amazing!
Plugging: https://afnan.io/2018-04-12/my-neovim-development-setup/
&gt; Different software has different needs, and I don't think a one-size-fits-all attitude towards unsafe code makes sense. There is strong network effect in software, so one-size-fits-all can be better than alternatives due to increasing return to scale, *even if one size does not fit all*. Usual expression of this is "ecosystem split". For example, some software will never be ported to non-Windows platform, one size does not fit all, and theoretically, it is perfectly reasonable to write non-portable C or C++ library. But writing non-portable C library severely restricts scale of your ecosystem and such open source project of yours is unlikely to succeed. As a real world example, Windows kernel provides API to dirty bit in page table, which is very useful for GC. Naturally, [CoreCLR used this API](https://blogs.msdn.microsoft.com/maoni/2016/07/02/working-through-things-on-other-oss/). Somewhat annoyingly, no other kernel provides this extremely useful feature. Microsoft was forced to implement inferior but portable solution.
Sorry for being off-topic, but MEM_WRITE_WATCH is my pet issue. The article is from 2016. In 2017, Linux gained userfaultfd, which almost enables this. Now if someone could write a library to bridge the difference... Alas GC world is too small and we will wait forever until this kind of obvious hardware assisted write barrier technology.
[This pull request is very exciting!](https://github.com/rust-lang/rust/pull/55986) It means Rust is one step closer to (principled) overloaded lambdas, which is a very useful feature.
Seeing the PRs of translating chunks of c -&gt; rust might provide a valuable learning experience for rust newcomers.
When you realize that it's impossible to specify the lifetime in a `FromStr` impl and complain about it. 
How did you find that?
FYI, there is an occasionally active #rust-sci IRC channel on irc.mozilla.org. For example I've seen bluss, the author of ndarray, in there quite a bit lately. There's also #rust-machine-learning, but it's quiet, so probably better off congregating in the one.
We discussed this [9 months ago](https://www.reddit.com/r/rust/comments/88f69x/things_i_learned_writing_my_first_few_thousand/).
Yeah, it works similar to the `Rc` type in Rust, which is also reference-counted (and doesn't actually clone the entire object when you `clone` it).
I think you can say you know Rust as soon as you can solve useful problems using Rust. Some people think that should be reserved for when you can solve "usual", "normal" problems, or even when you can solve most problems, but I disagree. Solving *any* problem is enough, IMO.
Dependency injection means (mostly) passing an argument (dependency!) to a function. You probably don't need any crate for that.
&gt; by trait I see what you did there. 
A simplest solution would be to wrap your `HashSet` in a `Mutex`. That would get be slow if insertions are not rare though. I think a nicer solution would be to `filter` instead of inserting in `for_each` and then call [`.collect()`](https://docs.rs/rayon/1.0.3/rayon/iter/trait.ParallelIterator.html#method.collect), as on a regular iterator.
Without writing a wall of text... :) Rust is telling you it is not thread-safe because it is really not thread-safe. And to make it thread-safe, you will actually cost yourself quite a bit of performance. All of Rust's base data structures are blazingly fast to write from a single thread, and that would be the idiomatic approach.
It's not just you. I think it was mentioned in this post that was linked the other day as well https://internals.rust-lang.org/t/the-state-of-rust-tarballs/9141
If you start asking whether `Self: Programmer`, the answer is yes.
If you're just looking to collect all the results, you might be able to use something like https://docs.rs/rayon/1.0.3/rayon/iter/trait.ParallelIterator.html#method.collect
If you are a mathematician why are you not looking at something like Haskell (or Idris or Agda etc...)
You could rewrite it like this: ``` let res: HashSet&lt;[u32; 3]&gt; = (1u32..(sum / 3)).into_par_iter() .map(|side_a| (side_a, sum - side_a)) .filter(|(side_a, b_plus_c)| (b_plus_c.pow(2) - side_a.pow(2)) % (b_plus_c * 2) == 0) .map(|(side_a, b_plus_c)| { let side_b: u32 = (b_plus_c.pow(2) - side_a.pow(2)) / b_plus_c / 2; let side_c: u32 = b_plus_c - side_b; (side_a, side_b, side_c) }) .filter(|(side_a, side_b, _)| side_a &lt; side_b) .map(|(side_a, side_b, side_c)| [side_a, side_b, side_c]) .collect(); ``` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e265d4371987f46668eefdd3e53a1e5c However the mixing of `map` and `filter` and then `map` again etc. is not really pretty. You should try to refactor it into fewer steps if possible.
What does that even mean: pub fn u8&lt;'u8: 'u8 + 'u8&gt;(u8: &amp;'u8 u8) -&gt; &amp;'u8 u8 { "u8"; u8 } The lifetime part
Take a look at the new macro support in 2018. 
As a security person, it would be a dream to see Rust take over all systems level development. No offense C/C++ I love you, but it's time for a new king.
Sorry posted from my other account on my phone by accident. That's me.
&gt;However, for my own projects I'm mostly uninterested in the web. I suspect this puts me in a minority, both within the Rust community and within the software development community as a whole. The vast majority of software developed today seems to be web-facing in some way or another. Is it really the case the most Rust software developers are web-facing? Given Rust's branding as a systems language, and what I see on the "What's everyone working on this week" posts, I'd be surprised if that were the case. For me, I use Rust professionally to simulate queueing systems and non-professionally to make art, so it's certainly not the case for me.
I have to go to bed, so I'll be brief. (Gah, I was not brief. --- Future Me) There's definitely some things I agree with you here! Folks can indeed come across as pretty harsh when using `unsafe` code, but in my experience, it tends to happen when `unsafe` is used unnecessarily. This is why it's a decent idea to try to justify your use of `unsafe` in the code with a comment, in addition to explaining why it is indeed safe. &gt; I've gotten the impression that, on-the-whole, the Rust community's attitude towards unsafe code is something along the lines of, "Don't ever use it unless you're a wizard... and you're not a wizard." Unsafe code, it seems to me, is seen as this incredibly dangerous thing, and if it's in your crate or application then there's something wrong. I mean, it's not a bad first approximation. Using `unsafe` is full of nuance, and you fundamentally cannot given pithy advice that is simultaneously nuanced. If I had to choose between "yes, you should use unsafe if it does what you want" and "no, do not use unsafe, it's only for wizards," I'd probably pick the latter. Both are, to some degree, correct pieces of advice. But both, undoubtedly, do not impart the necessary judgment that one must employ to determine when to use `unsafe`. The reason why I would choose the more conservative route here is because `unsafe` is, absolutely, fundamentally, one of Rust's core value propositions. To the extent that if a large fraction of code started using `unsafe`, then it would definitely diminish Rust's utility. It would perhaps be even worse if that happened and it didn't need to because folks didn't know any better. As we all get experience programming, I think most of us get pretty familiar with the notion that pithy dictums really shouldn't be followed 100% of the time. There's almost always a, "unless" followed by plenty of nuance. That just doesn't get transmitted, perhaps because it's not the common case. &gt; Ropey's readme notice—or something like it—is something I would like to see adopted as a norm in the Rust community. Different software has different needs, and I don't think a one-size-fits-all attitude towards unsafe code makes sense. But I do think we all need to be forthright about the priorities of our crates. In fact, that forthrightness probably shouldn't be limited to just the use of unsafe code. This is something I've been meaning to do, but I have so many crates that I just never quite get around to it. With that said, I'm not sure I would personally plaster it in a prominent place in the project's README, but probably create a separate document called `SAFETY.md` and describe pertinent details there. I could imagine writing things from "This crate will likely never used `unsafe`" to "This crate uses `unsafe` to elide bounds checks" to "This crate uses `unsafe` to implement a generic data structure and hasn't been thoroughly audited." I don't think this necessarily deserves a prominent place in the README because, to me, `unsafe` is fundamentally an implementation detail. But I recognize that reasonable people may disagree. &gt; At the most recent Seattle Rust Meetup I had a great conversation about unsafety with Ivan (don't know his last name, alas, but thanks Ivan!) and he had an excellent idea for Ropey that I think may be more widely applicable: provide a feature flag that switches to an all-safe version of Ropey. In Ropey's case this is pretty straightforward: the unsafe code is well compartmentalized, and could be easily swapped out with safe (but slower / more memory hungry) equivalents based on a feature flag. Yeah, this isn't the first time I heard this idea. I personally wouldn't recommend doing this. At least, I wouldn't want to, but others might. The reason is that I'd prefer to put all focus into getting one code path correct instead of maintaining two of them. It just seems like more maintenance burden to me.
&gt; Mistakes I probably wouldn't even know about (given that I'm not a trained programmer) Don't sell yourself short because many "trained" programmers don't seem to know about the mistakes one can make in C/C++ either.
self: Impl Programmer
Have you tried Haskell? Is there a reason you wanted a lower level language? Performance?
Thanks! I've actually dabbled with lalrpop before but wasn't sure if there was anything else out there I should be looking at. But one thing in the `yecc` grammar that I don't think (?) LALRPOP supports is a handy way of specifying precedence and associativity, like we have for the elixir parser [here](https://github.com/elixir-lang/elixir/blob/master/lib/elixir/src/elixir_parser.yrl#L55).
Yeah, I was looking for the same thing to try cobble together a quick native BASIC compiler. Unfortunately, I am blocked here since I don't know C++ :(
But you tend to use a lot of libs when in C that's a pain in the ass.
It's shorthand for manually writing out operator precedence with production rules. You should be able to do it in lalrpop without much issue. Alternatively (caveat: I haven't looked at Elixir's grammar to see if this was possible), you can try writing the majority of the parser as a recursive descent, use PEGs, parser combinators, etc. and fall back to a [operator-precedence parser](https://en.wikipedia.org/wiki/Operator-precedence_parser) for expressions. That's what I did for my WiP language (SMPL)[https://github.com/InnPatron/smpl/tree/master/smpl/src/parser].
In computer science, an operator precedence parser is a bottom-up parser that interprets an operator-precedence grammar. For example, most calculators use operator precedence parsers to convert from the human-readable infix notation relying on order of operations to a format that is optimized for evaluation such as Reverse Polish notation (RPN).
u8
So you basically want it to be JavaScript + Python.
Interesting, thanks. Well, I guess I better get started then...!
&gt; Being close to reality is a goal but not a requirement. ---- &gt; maybe prioritize your work based on that Which is my point. Whats the point of it if it doesn't have to match reality? Some goals for the year they are if what actually happens doesn't need to match. Whats the point of the RFC and pretend government? If everybody is going to work on their own things anyway, why bother pretending like what the community wants matters? &gt; The roadmap is not however a strict plan with fixed milestones, deadlines, and such. They don't necessarily need to be a strict plan and deadlines, but they should at least be what gets primarily worked on for the year, even if it can't get finished. Why bother if it doesn't have substantially more weight than random blog posts? And if they can't a postmortem on why not might be nice, more important stuff can come up i guess. For example, xargo integration is something that should be really simple. The core libraries are trivially compiled using cargo and the poorly documented [target specifications](https://github.com/rust-lang/rfcs/blob/master/text/0131-target-specification.md), and third party tools already exist that do this. So how come next to no work got done on it in 2018? According to [this](https://github.com/rust-lang/rustup.rs/issues/1538#issuecomment-445429764) comment, apparently because the embedded wg only needed a few and the team didnt feel like supporting anything outside their bubble. This feature in particular i really want because having to manually run a third party duplicate of a select few cargo commands is.. not ideal in the slightest, especially when it's so trivial.(inb4 "implement it yourself if it's so easy". Figuring out the cargo codebase is.. less trivial. They already know it, its their code, i don't know any of it.)
Here's a guide for building some basic loadable kernel modules. Talks about embedded and beaglebone, but should work fine with a Debian VM: http://derekmolloy.ie/writing-a-linux-kernel-module-part-1-introduction
This is wrong. I mean, teaching is often damaging to developing minds, because we put to much pressure on them and often tell them to stop asking too many questions. Aside from that, no.
A lot of people conflate Dependency Injection with DI Frameworks - like Spring or Juice. &amp;#x200B; There are DI frameworks in Rust, [https://crates.io/search?q=dependency+injection](https://crates.io/search?q=dependency+injection) &amp;#x200B; I can't speak to the experience with any of them, I'd be surprised if any were close to as mature with Spring - though I'd love to hear I'm wrong. &amp;#x200B; DI through construction is totally a recommended pattern though, especially with generic parameters - just like in other languages like Java where this is a really common pattern. &amp;#x200B; As an example, https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8e43a9cde8cd862357417f3b7a950081 &amp;#x200B; This is an example of Dependency Injection - we pass the cache dependency in as a construction parameter. And we do it using an interface - that way, when testing, it's as easy as possible to provide whatever custom dependencies we want. This is flexible - we can swap out the implementation of CacheClient for anything - a hashmap, a redis connection, whatever.
So, I'm not really familiar with Discord, but I'm not really seeing a poll on any of the Rust sub-channels? sub-spaces? and the link appears to be taking me to a non-existent page. However, it could be that I'm just on the wrong Rust language server if it's different from the one linked in the rust-lang.org/community page.
Thank you for linking that thread. I've read that thread but somehow missed the part about the index bug.
Part of me has debated just digging into the rust compiler and seeing how they use the llvm bindings, but that's going to be a... large undertaking. Maybe once someone's used LLVM in another language it won't be that bad but... well I dunno since I have no context.
Thank you for all your hard work! I've started playing with gtk and had difficulty using original gtk docs referenced on the website (I never used GTK in C, so I don't have a good intuition that I can fall back to. At the same time I came across this tutorial [https://mmstick.github.io/gtkrs-tutorials/](https://mmstick.github.io/gtkrs-tutorials/) and it turned out to be a very good intro into Rust + GTK development. Unfortunately it hasn't been completed and wasn't updated for a while. It would be a very good addition / collaboration if the original author is still interested. Sad to see such good work fading away -- it is #3 search result on DDG for "rust gtk tutorial"!
Wait, what's the `'e` lifetime for on the `BlobExtract` trait? It seems like it's not used at all. If you just want need it for the impl on `&amp;[i32]`, can't you make just that impl generic over `'e` instead?
Sorry, I got hired by System76 and it fell to the wayside.
FWIW, your code can be made a bit faster by using the unsafe `get_unchecked` function inside the `root` function – after that change, it runs in about 1ms on my machine. You can change all the other indexing operations to their unchecked counterparts too, but the one in the `root` function understandably has the most impact. I took your code and made it more like the stdlib's `BinaryHeap` type (most notably by using `Hole` in order to not require `Copy`): ([playground](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=da048f9082c1b676a5ee18cee8cfdbb3)). For me it runs about as fast as your code (without the unchecked improvement), although it's hard to tell because the benchmarks fluctuate a lot. Though code runs a lot slower than yours in the playground, interestingly enough. The two main reasons I can think of why this outperforms `BinaryHeap` are * `peek_mut` doesn't need to check whether the heap is empty, and * the `sift` property of `PeekMut` starts out as false. It makes a big difference here. I think the stdlib's `PeekMut` would really benefit by not sifting by default, and it looks like it could also use `unchecked` in its `deref` and `deref_mut` implementations ([which it currently doesn't do](https://github.com/sfackler/rust/blob/ec7ee87ef82edcc783b55192a6426edf5c30521f/src/libcollections/binary_heap.rs#L254-L267)).
Another thought: there is a community norm against memory leaks in a C library. On the other hand, technically, it is perfectly valid not to fix memory leaks in your C library. For example, maybe all intended uses are short running. Maybe it is expected to be used with Boehm conservative GC. In practice, if your policy is not to fix memory leaks in your C library, C programmers will avoid your library, even if it doesn't matter for their own uses.
I agree. I'll move them to CfP.
&gt;I've also learned a few tricks since then, so there are some things that I would do in a different way today. Yep, this is exactly the knowledge that is hard to acquire, especially if you are new to both -- Rust and GTK (and the bindings). Congratulations - I have a lot of respect for what (and how!) System76 does! I am eying a new Thelio -- hope one can get the drivers for Arch in the AUR! ;-) &amp;#x200B;
Wow!
This seems an anti-pattern to me.
Just for entertainment: I know what I don’t know about the language, and it is most of it. Do I know it then? Now being serious, I’ve been using Rust on and off since 1.0. Haven’t built anything big with it, only a few toy projects, a logger at work, and maybe something else insignificant I forgot. And man I feel like I’ll never get to know/use all features of the language. All while more features are being added. That being said, I enjoy Rust quite a lot because of what it offers.
Because anyone doing any serious math wants to have the full performance of their computer. From a performance perspective, Haskell is a mess
The most important part of my comment was the last sentence: This is a community project driven mostly by volunteers. The roadmap brings some clarity to what are important issues, but since only very very few people are being paid to work on Rust itself, we need everyone in the community to help out – in one way or the other. If you want xargo integration, there are three ways to get it: do it yourself, pay someone to do it, or ask very nicely. The roadmap is mostly the latter, except that it combines what *a lot* of people have been asking nicely for and which is thus more motivating.
I'd say it *is* an anti-pattern, but probably not as bad as this makes it look. It's about on the same level as implementing a trait for all tuples up to N elements just to be able to pass them into a function as a single generic argument. A procedural macro could probably be made to make this look like more traditional function overloads.
This feature of the compiler isn't intended as a general-purpose overloading mechanism, and I don't expect it will be used as such in practice. The purpose of that PR appears to just be to remove some inconsistencies regarding the semantics of closures versus regular functions. That said, some day variadic generics may normalize the idea of function overloading, but given that I'm not aware of any RFC for variadic generics, I don't think that's something that will be happening any time soon.
Man, everyone always forgets that at Microsoft we use Rust, too :(
To be honest it's a hard problem to deal with that even Pypi and npm face: basically, it's either you know the (a subset of the) name of the package you want to download or you're screwed because the lack of contextual search. Keyword-based search is too limited, I think..This addresses the issue, feature-wise, but I wish I could do it through the Google API...
Both, actually! Personally, my primary interest is in embedded, and I see lots of opportunities for rust being the major language for use in resource-constrained bare-metal end-nodes. Those kind of devices are most likely to be used in consumer products. But, I would be really happy if more projects also manages to obtain funding in order to boost rust adaption, and as such, discussions like this may be good input for others.
It's in the #meta channel.
What do you guys do with it?
This has been possible for years, those nightly features appear to be permanently unstable so...
(Informative:) In Sweden, EU grants are managed by https://www.vinnova.se , with the assistance of https://www.tillvaxtverket,se and https://www.energimyndigheten.se. What about other countries? Germany? Netherlands? France?
This *hasn't* been possible for years; you could write this code, but it wouldn't compile. Check what the nightly from two weeks ago has to say about this code: I guarantee it won't give you the same result as the current one.
Yes, one of the projects I'm been involved in, was hosted by Lund University and Lunds Tekniska Högskola, and I'm off to talk to them on Friday. Some of the grants available actually requires the cooperation of uni's.
It reminds me of when I sent my resume to Mozilla. They replied that they rejected my application for the job but encouraged me to volunteer my time with them...
I see quite a lot of rust posts related to web in some way. I kind of felt the same as OP until I read your comment. I think there just happens to be a lot of noteworthy growth in the web department lately, what with wasm and other things making strong progress. It does make it seem like rust is leaning heavily toward web facing, even if most of us are off doing something unrelated. But yeah, I see a post about web stuff and usually scroll past it. It's great stuff, but I'm a systems dev with little interest in anything more than a high level progress report on misc rust web stuff.
Can you go into more detail on why you call it a mess?
I can't wait to have any free time to star learning Rust
As far as I know, they wrote [Actix](https://actix.rs/) and use it for some projects, but exactly which hasn't been shared.
RemindMe! 10 hours
I will be messaging you on [**2019-01-10 17:05:13 UTC**](http://www.wolframalpha.com/input/?i=2019-01-10 17:05:13 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/aecbyb/rust_programming_language_seven_reasons_why_you/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/aecbyb/rust_programming_language_seven_reasons_why_you/]%0A%0ARemindMe! 10 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
The tuple way is nice and concise, but if you want (or have) to lazily evaluate the latter parts, you can use [`Ordering::then_with`](https://doc.rust-lang.org/std/cmp/enum.Ordering.html#method.then_with): a.something.cmp(b.something) .then_with(|| a.something_expensive().cmp(b.something_expensive())) .then_with(|| a.final_fallback().cmp(b.final_fallback()))
It would be nice if there was some blog post describing how. The VScode integration, IoT Core and Axtiv are known to whom spends to much time around here, but not at all everywhere else.
If I understand correctly, this is a callable struct that implements Fn, FnMut, and FnOnce? (Good job getting this working, but holy smokes I never want to encounter this code in the wild. I'm having traumatic flashbacks of C++ operator overloading.)
&gt; at something like Haskell I've played with many programming languages over the years. But out of all of them, I'm pretty sure Rust is my favorite. It just... appeals to me. In fact, it feels like the kind of programming language that I would design in a different life.
&gt; Have you tried Haskell? Yes, I've played with Haskell a few years ago and I *do* like it. But, for whatever reason, it didn't stick with me. I can't say why exactly. &gt; Is there a reason you wanted a lower level language? Performance? I like lower level languages for multiple reasons. One is that I'm a sucker for optimization, another is that I am a very detail-oriented person, a third is that low-level languages give me the impression to be able to implement anything I'd ever want to do. As a teenager, I spent countless hours tinkering with Assemblers (in embedded systems). When I studied mathematics, I got fascinated with Turing machines. Right now, I'm really excited about WASM. So, yeah, I think it's fair to say that I feel myself drawn to low-level languages. What makes Rust so appealing to me is that it is a low level languages that offer a lot of the benefits/conveneances of higher level languages.
Why does `run` return a reference to a box?
There's an excellent high-level [overview of the most common data structures](https://doc.rust-lang.org/std/collections/index.html) in the documentation for `std::collections`. In general, I agree with the other commenters that modules/crates will generally abstract over the details. The best thing to do is just to write some programs without worrying too much about optimization. Since Rust is good for performance-sensitive tasks, it can eventually be helpful to understand data structures in more detail, but it's not necessary to get started. For instance, let's say you need to associate keys and values. 1. You can get by just fine knowing that `BTreeMap` sorts keys, and `HashMap` does not. You don't need to know how balanced trees are implemented or how hashing works. 2. But if you're dealing with large amounts of data, it might also be helpful to understand the basics of time and space complexity to know that `HashMap` provides amortized constant-time lookups, whereas `BTreeMap` lookups perform tree traversals and are thus logarithmic. 3. Finally, for very performance-sensitive use cases, you might learn about the cache coherency and spatial locality of different map structures, which affects iteration performance among other things.
Yeah, if I ever end up using the technique for real, all the code in and after `mod my_func_impl` will be generated by a macro.
;-)
find someone who is also working on p2p protocol library
[IoT edge](https://github.com/Azure/iotedge) for one!
In rust, no types can be generated at runtime. User input, for example, is all either String, Vec&lt;u8&gt;, or something similar. If you want to parse that input as a number, you can call i32::from_str or similar in your code, but then once again the compiler can figure out what types to use. There is no “turn this user input into whatever type it is” function that would generate a type that the compiler can’t statically know. Similarly with integrating with external services - you’ll receive bytes from those services and then it’s up to you to write (statically typed) code that will try to interpret those bytes. 
I habe to do a web search to confirm it, but Actix is written by /u/fafhdr91 on its free time so he has the copyright, not Microsoft.
There is math and there is math. The programming tools' requirements for number crunching are far different from those for formal verification methods. That said, I'd like to know what beef does the thread starter have with Rust's type system.
I don't think you can find a suitable bound - the caller selects type for `P0`, and caller can't pick a suitable one in the first place, because it contains a lifetime that he cannot name.
I did not know that. I found the comment from fafhdr91 where he mentions that they use it at Microsoft over on HN: https://news.ycombinator.com/item?id=17191454 I must've jumped to conclusions, seeing a Microsoft engineer maintains it and Microsoft using it for some project(s). Thanks for letting me know! :)
Yes it was !
What are you trying to do? I don't mean "get this code to compile". I mean, what problem are you running to solve?
Will add a note in the intro of my book! Which public project do you think would be best to highlight?
Awesome! That's the type of thing I was after. Thanks so much :)
Can't we use an open source service instead? 
I "almost" got it to work by changing the trait - instead of the value implementing `Extract` (which then has the problem that the caller cannot name that value), instead there's `Extractor` which allows for `map` to select what it actually extracts (so that it can select what will be the lifetime of the value). [This passes `cargo check`, but then results with an ICE.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a5c232e58e79884c49810c43f16afa4b)
All types is known at compile time. After compilation there are no concept of types left, only machine instructions which operates on registers, ports and raw memory. User input and 3rd party services provides data unknown during runtime, but the type is known beforehand - bytes. Yet it is common that those bytes has specific layout that correspond to some type's layout. In this case you parse it into that type. If program don't know the layout of bytes how it would parse it? It can't. So your program should be aware of what data types can be given by user/service. Some data types are more flexible than the others, like json which can contain number, string, list or dict. But in any case you parse input which you expect to be json and later inspect resulting `JsonValue` (which usually is enum) to see what variant it contains.
Riot is an foss decentralized alternative. À major redesign will soon be launched and it will look more like Discord.
Interesting. I guess it should be possible to hide the boilerplate behind a proc-macro. Like: #[overload] fn foo(x: u64) {} #[overload] fn foo(s: String) -&gt; bool { true } Not sure if we *should*, but I guess we *could* :D 
We could! Unless I'm mistaken, though, the macro would have to be on some block of code surrounding both functions. Macro instances can't really share state / combine multiple functions into one item, and you'd still need exactly one `mod foo_impl { pub struct foo_struct; ... }` declaration. It's something I've tried to get around in the past but I haven't found any real way to do it.
In `main.rs` declare `pub mod token;` and then `use crate::token::get_token;` to use `get_token`
omg that’s exactly what I was looking for. I have an in-progress blog post where that’s almost exactly what I proposed. Little did I know it already existed!
omg that’s exactly what I was looking for. I have an in-progress blog post where that’s almost exactly what I proposed. Little did I know it already existed!
I really want to use rust for a bigger project, but the IDE support is still a bit below where I'd like it to be. Great progress was made last year, but we need at least basic macro expansion and better debugger integration before it'll dethrone C++ in my workflow.
Oh cool! I will try to give it a shot over the weekend :)
this one is a great article, thank you!
&gt; To me, unsafe is fundamentally an implementation detail. But I recognize that reasonable people may disagree. I think, in some sense, the entire debate is about whether unsafe fundamentally should be an implementation detail. There are, not majority, not mainstream, but non-zero Rust users who think it's okay to have incorrect safety declaration in the interface because the software is not security sensitive. My impression is you disagree with this. To me, unsafe is not an implementation detail, because unsafe functions can be marked safe, and some Rust users actively want to do this.
If you see my reply to another comment here the Azure IoT Edgelet project, which is on GitHub. That's the most I can say publicly :) I don't work in that area I just know a bunch of us here are big fans of it.
It would be helpful to have some detail. What sorts of uses of `unsafe` in `ropey` are critical to performance and yet difficult to avoid? I could read the code and try to understand this, but I'm lazy and would love to just be told. I think part of the community norm around `unsafe`
The toolchain needs to get a lot more portable first. Only a few architectures are supported and adding new ones seems to be painful. It is pretty far along, though, which is great, so there's some hope for the future.
As an example, [8cc](https://github.com/rui314/8cc), an open source C project, has an official policy of leaking all memory, that is, never calling free(), because it is hard. This is an exception that proves the rule: I think the decision is entirely sound, but it is so unusual that I have never seen any other open source C project does this.
There is also IRC but a consistent piece of the Rust community seems to be gravitating around Discord. I remember there was a debate in r/rust around promoting the usage of Discord given that it's not open source, but I guess this is a discussion that the Rust community as a whole needs to have.
*sigh*. This feature would be really useful for the pattern: fn foo(mandatory: String) { foo(mandatory, None); } fn foo(mandatory: String, options: FooOptions) { // implementation }
Sounds great. Will add a plug in the next revision
I think I talked a lot but didn't really state my position, so here it is. I think Rust community should uphold one-size-fits-all community norm for unsafe code to avoid ecosystem split. One important question is what this norm is. I think it absolutely should not be "Don't ever use it unless you're a wizard and you're not a wizard" or such. I don't think that matches, eh, design intent. My proposal is "Rust library should strive to have correct safety declaration in the interface". Let me explain word by word. "Rust library". I think it is okay to hold applications, aka code not intended to be reused, to less standard. "should strive". Making mistakes is okay and does not count against you, that is, not more than any other bugs. On the other hand, community norm is that these are bugs, and are expected to be fixed. Note that IT CAN ALWAYS BE FIXED, even if actually doing so is a bad idea because it is API breakage: you can change any such "fn" to "unsafe fn". "to have correct safety declaration". This is to be fixed in stone by unsafe code guideline, but general outline, I think, is easy. Using your code, safe code should not be able to perform use-after-free, to produce aliased &amp;mut, etc etc. "in the interface". As long as the interface is safe, any use of unsafe in the implementation is fair game and does not count against you and lots and lots of uses of unsafe is not a reason to avoid the library. I mean, "std" is full of them. Go look at it.
Soooooo... it means that we cannot be sure anymore what does this mean: ```foo.bar()``` because it may be ```struct Foo { pub Bar bar; }``` with `Bar` implementing `Fn`. I think it drastically increases the complexity :(
Sorry, trait bounds not satisfied
Is there a list of cool rust CLI tool replacements? From the top of my head: * ripgrep (grep, silver searcher) * exa (ls and tree) * fd (find) * cw (wc) * bat (cat, less) * xsv (column, cut, …) Are there more in this vein?
And quite often it’s not the trained C++ programmers who have to dig through segfaults and kilometres of g++ error logs to find the mistakes those trained programmers made, it’s the poor sods who use those libraries in hope that’s it’s going to be all good.
I decided this should be a separate blog post, so I made [one](https://www.reddit.com/r/rust/comments/aehow1/proposed_rust_community_norm_for_unsafe_code/).
Default parameters are more useful than this
I think you'll still have to use (foo.bar)() to call a member as opposed to a method.
Re-reading my proposal, I think it is principle-y and lacking in practical suggestion. Practically, I think unsafe {} in your library should have, ideally in comment, but at least in your head, ideally watertight, but at least handwavy (I am willing to accept extreme handwaviness), justification for why it is safe. If you can't produce handwavy justification in your head, declare the function unsafe.
You could make a macro that does it for you
Cool that this is possible, but I'm not a fan of function overloading. Is overloading an explicit goal or is this a side effect of the design?
I did a partial replacement for \`sha1sum\`, [https://crates.io/crates/treesum](https://crates.io/crates/treesum). It's recursive by default, but lacks the command line flags of the original. I should probably add those.
method macros would be nice, eg. `object.foo!(args)` where the foo macro gets the self object and its arguments. Could even scope the macro to a type? There's been some talk about this but there's a lot of edge case interactions that need to be explored.
This is Rust 2018 change. If you are not familiar, the easiest fix is to delete `edition = "2018"` in your Cargo.toml. See [Path clarity](https://doc.rust-lang.org/edition-guide/rust-2018/module-system/path-clarity.html). To quote, "In Rust 2018, paths in use declarations must begin with a crate name, crate, self, or super". Previously it didn't, and "use token::get_token" was okay.
\`hexyl\` 0.2 is available in Debian Buster. I just uploaded the 0.3.1 package, it should become available as soon as the builds are finished. I really like the tool.
Looks nice! Do you have plans to introduce diff support? Something similar to the result of `diff -y &lt;(xxd a.bin) &lt;(xxd b.bin) | colordiff` perhaps?
I think the lack of high grade and stable IDE support is really under stated. It makes it very hard to sell Rust internally at a company.
It's probably a mix of both, and Federico also mentioned that Rust itself also has helped to uncover some bugs in the C code (by providing actual tools for abstraction, exhaustive matching and of course the borrow checker). &amp;#x200B; But as /u/po8 mentioned that the increased test coverage uncovered more bugs is arguably also an advantage of Rust. It's so much easier to write tests than in C, so you're simply going to write more tests.
This 100%. This is one thing that bothers me in rust. There's neither function overloading or a good story for optional/default/named parameters. You just end up with a mess 
is it easy finding c programmers? Is it easy finding c programmers willing to do Rust full time? any c programmers resist doing Rust?
How many of items in the "Required skills and experience" list should a good candidate have?
Not sure OP is the author. I'd open an issue on the issue tracker about it, if I were you.
&gt; Haven’t built anything big with it you don't write code in your spare time?
I didn't mean that FYI. I meant a macro that generates a struct with multiple Fn implementations.
I would love to learn rust some day. But finding jobs is hard. C++ basically guarantees you a job in the industry.
Astrophysics... Looking for a project at the moment though 
True, but that doesn't exist in Rust either!
There are a lot of untapped signals, downloads, number of stars, clicks, code length, amount of doc, number of dependent crates, etc...
Search for the word "search". The very first result is an empty crate that is name squatting.
Oh this will be quite useful! Thanks 😎
Really? I was under the impression it was extremely portable. What architectures does it need?
Trained programmers are incredibly rare. Trained computer science graduates who can't write a hello world are a dime a dozen.
Definitely also need to know why you say Rust is a mess
What's Microsoft
I would add that we should have linter that expects comment for unsafe blocks and safety doc section for unsafe function
Indeed. I think that as Rust gets more popular, this will be the topic of endless impossible-to-settle debates on the Internet. At some point, hopefully, when more Rust code is being deployed, we'll be able to count roughly how many CVEs it's responsible for, and then find some way to make a relative comparison to it for C code (CVEs per LOC?). I predict Rust's relative numbers will be amazing. But then when you drill down into any one specific example, all of the aforementioned variables will come into play and none of them will be convincing on their own.
&gt; There is strong network effect in software, so one-size-fits-all can be better than alternatives due to increasing return to scale, even if one size does not fit all. Usual expression of this is "ecosystem split". I think this is a bit of a simplification. If you try to exercise a one-size-fits-all principle in situations where it's inapproritate, things just get worse for some segment of the community. If you try to find a way that unifies the situations of a music player application and a kernel module, someone will have a bad time. Sometimes ecosystems must be "split". A good example is `no_std`.
&gt; There are, not majority, not mainstream, but non-zero Rust users who think it's okay to have incorrect safety declaration in the interface because the software is not security sensitive. My impression is you disagree with this. Absolutely. *Very strongly disagree* with it, yes. You raise a good point. There's more nuance to uncover here. :-)
No relaxed ordering likely won't generate unique ids, however you can lower it to `Ordering::AcqRel`. That being said if you need unique ids maybe UUID version 4 (see https://crates.io/crates/uuid) is a better solution.
No relaxed ordering likely won't generate unique ids, however you can lower it to `Ordering::AcqRel`. That being said if you need unique ids maybe UUID version 4 (see https://crates.io/crates/uuid) is a better solution.
I only need locally unique ids, so an integer is fine. Why won't relaxed ordering likely generate unique ids?
&gt; No relaxed ordering likely won't generate unique ids Could you explain why you think that?
Could you assign each thread a prefix, and then have a thread_local counter?
&gt; No relaxed ordering likely won't generate unique ids, however you can lower it to `Ordering::AcqRel`. Why do you say so? I’m failing to find any reason why repeated calls to `AtomicUsize::fetch_add(..., Relaxed)` would ever give a same number save for wrap-around. I don’t see how raising the ordering to `AcqRel` would help with that either.
Relaxed ordering is fine to generate unique IDs. Just be aware of the overflow behaviour, as you might get a duplicate ID on wrap-around.
I think better phrasing which is closer to how things happen is rather than "do not intentionally misuse unsafe", more like "when unsafety (most likely unintentional) is demonstrated, i.e. by doing unsafe things using safe code, do not argue". You can't excuse it by saying the library is not security critical. You can't excuse it by saying it is a different use case, it is not a web browser, it will run locally, it is a path-tracing 3D renderer, it has different priorities, etc. You certainly can't say such excuses should be more acknowledged. No, when unsafety of the interface is demonstrated, either delete it or mark it unsafe. The end.
Maybe my own [broot](https://github.com/Canop/broot) for `tree` (and more) ?
Actually, these are \`Sync\` Futures, so I'm not sure I can get away with thread-local tricks. But: Currently, there is one global, static AtomicUsize for the whole network library, i.e. for all connections. As it's a client library that usually should be ok. For my use case, as I'm spawning many connections, it starts to be a bottleneck. I tried to move the atomic counter into the connection's Client struct, which increased performance even a bit more for the highly-concurrent use case (combined with Relaxed), but \_decreased\_ performance for the single-connection use case (I guess due to more indirections? not sure). I have some ideas to fix this but they are orthogonal to "use the most efficient, correct memory ordering for the atomic counter".
2\^64 unique ids ought to be enough for everybody ;)
Partly this is education too. In safe Rust a lot of the time you can get away with randomly changing stuff (ampersands, stars, lifetimes) until the compiler stops complaining. But if you do that for unsafe Rust, then things go badly wrong, e.g. you have just claimed that your interface is safe when it is nowhere near safe. There was an instance here on reddit only just recently. This is the well-established Rust programmer contract for unsafe, but if the coder comes from an background where "changing stuff until it works" is how things get done, then there is a culture mismatch to deal with.
If you are using tokio-threadpool, then it has the following methods that might allow you make this work per-thread-startup maybe? I'm not exactly an expert though. https://docs.rs/tokio-threadpool/0.1.10/tokio_threadpool/struct.Builder.html#method.around_worker 
That's a shame. Your tutorial is very complete and it would be very nice to have it directly on `gtk-rs.org`. If you ever feel like updating it, that'd be awesome!
This requires `(foo.bar)()`, but it's not new, since structs can contain closures.
The library is using tokio-runtime, but I think it is written to be no\_tokio (if you excuse the pun) and only adds it for convenience methods (like estabilishing tcp/tls/unix socket connections etc.). So I can't rely on tokio-specific behaviour. The Client struct I'm dealing with is Send/Sync for a reason and I don't want to change that, either. What I \_might\_ be an option, though, is creating a special-case "unshared" client that is really fast dealing with \_one\_ source of requests. But that's a lot more work that replacing two "SeqCst" with "Relaxed" or similar :)
I'd love if rust ran on Tensilica Xtensa microprocessors (used in ESP8266, ESP32).
[Dalek](https://dalek.rs/)? https://youtu.be/tE57KBK_GW4
Maybe OP is thinking about attributes / proc\_macros?
&gt; Folks can indeed come across as pretty harsh when using unsafe code, but in my experience, it tends to happen when unsafe is used unnecessarily. I've seen people get pretty vigilant about `unsafe` on reddit where they treat all `unsafe` code as bad, regardless of the benefit or the quality of the code. Similarly, I've seen some crates throw around `#![forbid(unsafe)]`.
There's also [skim](https://github.com/lotabout/skim)
Yes, I think this is harmful. I am against unsafe functions marked safe. I really have nothing against unsafe blocks.
Never thought someone would use my crate haha
I mean, Rust developers themselves messed up and had to release [1.15.1](https://blog.rust-lang.org/2017/02/09/Rust-1.15.1.html). Rust 1.15 std included unsafe interface. We all err. It's okay. But do fix these as soon as possible.
Unfortunately, because Rust tests tend to be inline with the code, I do not know of any way to exclude them short of running a full parser on the codebase. I made this chart as a quick hack with `tokei`, the (unbelievably ugly) `python3` script is in [this gist](https://gist.github.com/jesskfullwood/17928e33ce9312e5281495214d7c73d3) if anyone wants to play. I should add I have no affiliation with `librsvg`, I just thought it was interesting.
On a related note, should `unsafe` be used in APIs for violating invariants in addition to memory safety (see [API guidelines issue](https://github.com/rust-lang-nursery/api-guidelines/issues/179)). I worry there is such a strong bias against `unsafe` that this would be frowned upon despite the value. For example, I remember a `rustls` talk where it was mentioned that calls to a special function need to be watched for in code reviews to make sure they don't introduce security holes. When I heard this, my automatic reaction was that `unsafe` would help contributors and maintainers in their effort on this Similarly, I maintain `escargot` which wraps the `cargo` command line. I know I'll never be able to cover every case, so I [leak the abstraction](https://docs.rs/escargot/0.4.0/escargot/struct.CargoBuild.html#method.arg). Some calls to that method will break invariants of that abstraction. 
The https://tillvaxtverket,se has a comma instead of the a dot. Here is the correct link: [https://tillvaxtverket.se/](https://tillvaxtverket.se/)
When creating wrappers into other languages, I'm not sure the comment is as beneficial in all cases as one may think. For example, `nix::sync`: /// Commit filesystem caches to disk /// /// See also [sync(2)](http://pubs.opengroup.org/onlinepubs/9699919799/functions/sync.html) #[cfg(any( target_os = "dragonfly", target_os = "freebsd", target_os = "linux", target_os = "netbsd", target_os = "openbsd" ))] pub fn sync() -&gt; () { unsafe { libc::sync() }; } To me: the context and the function comment seem sufficient. There isn't even much room for error, here. No arguments, no return type: just a function call.
Yes, this seems 100% okay. You certainly can construct safety justification in your head, easily.
An interesting issue, but ultimately I am neutral (don't care either way) and I don't think any norm is necessary here. Marking unsafe things safe is BAD. Marking (Rust-narrowly) safe things unsafe is... I guess it depends on your taste.
The video is now online by the way: https://youtu.be/Sss2Tl7WRDQ
Never heard of those, but I'm a noob to microprocessors.
Oh the idea is that once you go the macro route, you can do anything including simply dispatching to 2 different functions. There is no need to go this route if you're already using macros. Eg. you have a foo macro, which depending on the number of arguments dispatches to 2 distinctly named functions.
Even without the special syntax - I don't think it really matters. I'll just execute some code that may use `foo`'s state - same thing a method does. Does it really matter if the `impl` is on `Foo` or on `Bar`? You'll have to look at the code or at the docs either way to find what it actually does.
Does anyone know the difference between [`ring`](https://github.com/briansmith/ring) and [`mundane`](https://github.com/google/mundane)? The two projects seem to be very similar in goals.
This is ALSO off topic there. They want /r/playrustservers
The ecosystem is pretty split. I personally always use \`\_\` in the crate name because I find the difference between in-code and out-of-code name annoying. In my rough estimation about half of the ecosystem agrees, the other half doesn't. (Notably pro-underscore: diesel\_\*, serde\_\*, ...; notably against: tokio-\*, slog-\*, ...
I need to preface this by saying I like systemd and I don't want to bash it. https://www.cbronline.com/news/systemd-vulnerabilities-qualys &gt;"The systemd vulnerabilities comprise CVE-2018-16864 and CVE-2018-16865, two memory corruptions (attacker-controlled alloca()s) and CVE-2018-16866, an information leak (an out-of-bounds read), Qualys said." Could this have been prevented if systemd was written in Rust or is even Rust not that "safe"? 
I think a community norm of avoiding unnecessary unsafe is a good one (and already exists). Any amount of unsafe is ok if it's there for a reason, for example wrapping a c library will have a lot of unsafe, but unsafe just to avoid having to deal with lifetime issues is a problem for production code.
I don't mean honest mistakes by people who know the rules and understand why the rules exist. I mean people for whom all of this is way above their heads right now (either because they are beginners, or just because that's their level). Perhaps they can't see any fundamental problem with cut/pasting some unsafe code to work around an immediate problem. Perhaps emphasizing that you are expected to demonstrate that you've done your "due diligence" if you use unsafe is a more polite way to discuss it, and makes using safe Rust the easier choice (which is what we want people at that level to use). This also applies to managing in-house software development with a team of varied abilities.
https://github.com/sharkdp/hexyl/issues/27 
I wonder if electron + rust-&gt;webassembly could be make a better cross platform app.
I hope that function overloading (mutliple functions with same name in the same impl block) will never come to rust. Rust already has a good alternative by specifying generic parameters with Into&lt;T&gt; or AsRef&lt;T&gt;, etc. For me code with function overloading is harder to understand when you read the code (it is easier to find one function that multiple functions).
&gt;lots and lots of uses of unsafe is not a reason to avoid the library. I mean, "std" is full of them. Go look at it. I'm not sure I agree with this. If a library has "lots and lots of uses of unsafe," I'm going to avoid using it, and the fact that `std` has a lot of unsafe doesn't change that. If there was a stdlib that didn't have as much `unsafe`, I'd use that instead of the current `std`. But 1) there isn't, and 2) `std` most likely has *way* more eyes on it than a crate I download off crates.io so I don't feel quite as much hesitancy at using it.
Lsd. It's like exa but faster, pretty colors, and awesome icons https://github.com/Peltoche/lsd
&gt; On a related note, should unsafe be used in APIs for violating invariants in addition to memory safety This has come up before, and I think the answer to this is a pretty solid "no." I seem to recall this being debated somewhat in the effort to stabilize [`catch_panic`](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html), where I _think_ (could be misremembering) that an argument was put forward to use `unsafe` to indicate the possibility of violating exception safety, even if it was still guaranteed that memory safety wouldn't be violated. I think the conclusion there was that `unsafe` was really specifically about UB, but that UB needn't be the only thing we care about preventing. Thus, [`UnwindSafe`](https://doc.rust-lang.org/std/panic/trait.UnwindSafe.html) and [`AssertUnwindSafe`](https://doc.rust-lang.org/std/panic/struct.AssertUnwindSafe.html) were born.
Eh... yes, unsafe code should be justified, so it's kinda problem, but "avoid having to deal with lifetime issues" is one of main uses of Rust unsafe. If your proof of safety doesn't fit the Rust way(tm), put it in raw pointer and use unsafe to dereference. Yes, avoid if possible, but I am completely unwilling to enforce this as a norm.
Sounds terrible, may be it is possible to remove this patch?
&gt;I’ve also been enamored with another technology recently: WebAssembly. 2019 is going to be a huge year for WebAssembly, even if many people don’t know it yet, and may not see the effects until 2020. This is fantastic news. WASM needs you and I also have great hopes for it. I'm very glad you have chosen this path. I wish you the best. 
As long as all uses of unsafe blocks are correct, why should one avoid it? I mean, I think I understand why anyone would have such preference. But I don't think it should be a norm to enforce. Other people have different priorities, and if they found making all Rust references to raw pointers in a hot function lets LLVM to generate 2 less instructions, I mean, I wouldn't do that myself, but I am unwilling to enforce norm against that. As long as it's not incorrect.
A good example of this is `merge` implementation in std. The entire thing is in unsafe block, because it is slightly faster that way. It is declared `unsafe fn merge`. See https://github.com/rust-lang/rust/blob/1.31.0/src/liballoc/slice.rs#L729. Not what I would write, but I don't condemn it.
20% does sound suspiciously high to me. In this benchmark, are the requests actually doing anything? Or are connections opened and then immediately closed? My guess is that the difference would mostly disappear when the threads start doing real work.
Whoops, somehow this escaped the reddit search I did before posting. Perhaps the archival of the old one caused it to be filtered out. Either way, my bad.
With cargo I feel like IDE support is just a luxury. I think many people can be extremely productive in Rust today even with sub optimal IDE support.
&gt; As long as all uses of unsafe blocks are correct, why should one avoid it? Because determining if unsafe code is correct has a cost. You don't just have to come up with a correct version once. Every reviewer has to be able to understand and verify that it's correct. Every contributor must uphold all involved invariants, even in distant, safe code locations. And even for a single person it's harder to ensure correctness. With unsafe, you can invisibly trigger undefined behavior unless you know the full scope of what you're doing. Absolute certainty would require you to know what you don't know, or knowing that there's nothing you don't know. It's a bit like eating mushrooms. If a mushroom isn't poisonous, why not eat it? But the actual issue is the determination if a given mushroom is safe to eat.
I mean, yes, you should not needlessly pay cost. But what if it's 5% faster? I think reasonable people can disagree whether 5% speed benefit outweigh everybody's re-verifying cost. Anyway, I think that's what cessen is saying. I am unwilling to condemn such choice.
I think /u/cessen2 (taking that example) may well be wizard-enough to use unsafe safely, but most users of his crate will not be wizard-enough to review his code and judge whether his unsafe usage is actually safe. Since it is the users of the library who have the choice and who are taking the risk, and who are probably using Rust because they like all the safety guarantees, then it is cessen's job to persuade those users that he knows what he is doing. Just implying "this may have safety issues and isn't for critical uses" isn't really that persuasive. What's going to persuade people is some kind of evidence of "due diligence" about the unsafe use. I can accept unsafe for performance reasons if I'm persuaded that someone's thought hard about it and tried hard to get it right.
I would say yes, assuming no bugs in `rustc` or the standard library: memory corruption and out-of-bounds reads are not allowed in safe Rust. Memory corruption was (partially) caused by the use of `alloca()`, which is not used nor supported by Rust, as far as I know. The out-of-bounds read was caused by the lack of bounds checking. Though as a disclaimer I don't know anything about systemd's internals so I don't know if the parts of systemd with the bugs were doing things that would require `unsafe` if it was written in Rust.
Faster? Is there a benchmark and does it matter? AFAIK it doesn’t have a grid view, and IDK about a tree view.
Thank you! Good suggestion!
Of course! I’ve seen it, but didn’t think of it right now. Thank you! I’ll definitely try it out
Try /r/playrust
&gt; I mean, yes, you should not needlessly pay cost. But what if it's 5% faster? I think reasonable people can disagree whether 5% speed benefit outweigh everybody's re-verifying cost. But the cost is necessary to ensure correctness. 5% more performance but less certainty about safety is not a choice I'd make lightly. Quite the opposite. You might have lots of experience with low-level and unsafe code, but I do not. I have to rely on keeping things safe-by-compiler, or have unsafe things be extremely simple and verified, and excessively documented, or trusting others to judge whether something is safe and correct. This isn't about condemning anything. In fact I feel that we should be generally less dogmatic about things. If someone deems it safe to use lots of unsafe all over the place, that is their choice. It is my choice whether I agree in the situation or not. Many projects will require lots of unsafe code, and I'll assume their contributors will be fine with it. I'm just expressing that even unsafe usage as an implementation detail only doesn't get rid of most of the tougher issues that can come up (in my opinion).
I do what I can. But I don’t think it is enough to say I know the language in a professional/productive level. However, I’m not in a hurry. I’ll eventually get a good sized project built with it and enough crates...
Eh no. No no no. Let's discuss the specific case of ropey. It is beyond my doubt all of ropey's interface safety is correct, *because they were at first implemented without unsafe*. Without changing the interface, optimizations were introduced using unsafe block. I think from library user's perspective, the main interest is interface safety, which ropey has. Problems in implementation safety is, in my opinion, not very distinct from normal variety bugs.
I hope Rust would not be the next huge monster which is hard to understand
Surprise: I thought this proposal would sound too strong. Apparently, at least for people who are replying, it is too weak! Lesson: we really have no idea what the consensus is. Hm. Maybe it's just me and everybody else is clued?! If so, I'd appreciate writeup of what it is, something similar to what I did.
Never heard of `mundane` before. Looks like it's a) Google-backed, b) quite young, and c) a Rust wrapper around the BoringSSL C library.
A side effect; see [this comment](https://www.reddit.com/r/rust/comments/aefzwk/overloaded_functions_are_now_possible_in_nightly/edoznv9/).
The one thing it doesn't currently support is optional parameters, or functions that take a variable number of arguments...
Yeah, if you're building a new safe data structure or container, but people do sometimes use unsafe even though there is a safe but annoying or boilerplate-y way to do it. If a library does that, I think it's fair for people to be concerned.
Yeah, if you're building a new safe data structure or container, but people do sometimes use unsafe even though there is a safe but annoying or boilerplate-y way to do it. If a library does that, I think it's fair for people to be concerned, even if the usage is actually safe (because any changes to that module can introduce UB by accident)
Federico has written some really nice detailed blog posts about the porting process. [https://people.gnome.org/\~federico/blog/librsvg-posts.html](https://people.gnome.org/~federico/blog/librsvg-posts.html) [https://people.gnome.org/\~federico/blog/tag/librsvg.html](https://people.gnome.org/~federico/blog/tag/librsvg.html)
He could easily have broken the interface safety through introducing unsafe blocks, couldn't he? Isn't it trivial to make any interface unsafe by putting an actually-unsafe unsafe block inside? But anyway, as a user really I don't want any actual unsafety at all (i.e. unsafe blocks which aren't in fact safe).
&gt; We do not tolerate hackers. Congratulations, you have just posted this at a place lots of them will see your message... &gt;WITHOUT having to worry about hackers. I hope I have scared you enough now, sleep well tonight... &amp;#x200B; PS: I don't think anybody here will seriously try hacking your server but (aside from being illegal) it would be kind of funny.
From what I've done so far, I don't think there is really a much of a difference in speed from refactoring Rust code vs Ruby assuming the ruby code has decent test coverage. If there isn't decent test coverage in the Ruby code, the rust refactoring might be faster due to run time errors the strongly typed language would catch. Of course, Ruby has faster initial development because of duck typing, not being strongly typed and Ruby black magic (being able to manipulate any type however you want at any time from anywhere). I've played around with Go, but I haven't done anything significant with it yet. I'd compare Rust with Java/C# similarly in time to refactor. I'd say it may be slower than C or C++, but that't only because of the memory safety provided by rust. Really at the end of the day, I'm not sure I'd ever consider refactoring speed a metric on choosing one language over another though.
Who would ever fill a _whole_ gigabyte of space!?
I'd recommend creating a MarkovChain&lt;'a&gt; struct that implements Iterator&lt;Item=&amp;'a str&gt;. That way, you can use itertools and generate a random string of n words just with `chain.take(n).join(" ")`, which should shorten the make_string function down considerably. I'd also implement a function like: ``` fn get_random_element&lt;T&gt;(slice: &amp;[T]) -&gt; Option&lt;T&gt; { let rng = thread_rng(); let index = rng.gen_range(0, slice.len()); slice.get(index) } ``` ...that's a slightly easier to read &amp; use version of get_random_index for anything that can be treated as a slice (i.e., the Vecs in the rules.) You might also be better off having rules be `HashMap&lt;Vec&lt;String&gt;, Vec&lt;String&gt;&gt;` so you can keep the prefix as separate words.
You don't need synchronization unless you're actually using it and adjacent memory operations for some form of communicating. For example, let's say you handle a task, then atomic add to a counter to indicate the task is finished. Without synchronization, the optimizer might move the add to the counter before some necessary memory operations for handling the task. Then, another thread might assume those memory operations are done, and cause a race condition. A memory order indicates that a memory operation can't be reordered as such. For just an ID, I can't imagine any contexts where it matters. 20% seems high for performance boost.
Yes No Yes
Only thing is if you are working with verification logic, Haskell is far too weak as a type system, mostly the work you do is in proofs, but if not it's in your own scientific language where by you can set logical constraints for all operations. Therefore almost all math related programming is about number crunching, and language performance.
I love refactoring in Rust. You make a change, and the compiler tells you everywhere you need to fix.
&gt; If you can't produce handwavy justification in your head, declare the function unsafe. I prefer to think things through from the other end: *should* this API be safe? If so, how do I make it safe? Or is that simply impossible?
is the difficulty of finding c programmers willing to do rust making you rethink your rust approach? or will it always be full speed ahead with rust? also is maintaining very large code bases and reading unfamiliar code easier in rust or more difficult than c?
You can order the search results with different criteria, number of downloads is one of them. But a 10-download crate might answer your needs more than a 100k-download one, and I would wish this little crate to be listed first, which is barely possible to do with a search based fully on keywords, except if your keywords are really specific. 
And here, respectfully, I (and I'm sure many others) disagree. On the one hand, `std` strives to provide a high-level, safe, efficient abstraction over low-level functionality, and this requires `unsafe`. Consider `Vec::with_capacity`: calling the C function `malloc` is unsafe, derefencing the returned pointer is unsafe, accessing uninitialised memory is unsafe, and converting that to a Rust type (like `&amp;[u8]`) is unsafe. You *cannot* avoid *most* of that unsafety (with the remainder being there for a significant performance gain, i.e. being able to extend your `Vec` without reallocating every time). On the other hand, requiring "few" uses of `unsafe` might simply mean pushing lots of code into one big unsafe block, which isn't necessarily the best design.
Honestly, at this point, I feel more productive in Rust than any other language. When I make a major change to code in Rust, I always have high confidence in some aspects of its correctness. Because of that, I can move faster. A huge part of it is knowing the core libraries well. When you know how to use iterators, map, fold, flatten, filter, range, collect, etc. really well, then you begin to think in terms of composition of those fundamental operations, rather than thinking in terms of for loops and your own data structures. And once you realize how easy it is to implement Iterator for your own purposes, then you can play this composition game on the next level. Also, I find that when I write an algorithm in Rust, I very often can change the signature of the main functions to be more generic -- they often take traits instead of specific types, or generic types, so that I can use these algorithms in more general ways. That tends to be a lot more difficult in other languages. That is, the other languages in familiar with -- I'm sure if I were a Haskell expert I would do the same. 
Oh, thanks, that's better! Still a bit ugly though.
It's almost like a super power and on 125k+ lines it's just amazing. I would not be confident that I didn't screw it up in a non strongly typed lang
I hope the parts for which that is true will actually increase in the future. I'm very looking forward to what const evaluation will open up in the future. I have some code where I'm actually itching for some more powerful compile-time verification of axioms unsafe code relies on.
&gt; find its eigenvalues/vectors Hi! I want to compute eigen vectors, did you find a library doing that? nalgebra seems to only compute eigen values and ndarray documentation doesn't give me anything when I search *eigen*.
Figured out the issue I was looking at the language channel instead of the community one. 
There is a benchmark and no it definitely doesn't matter but it is also very aesthetically pleasing. I believe you are right on the views 
I'm on mobile, apologize for terseness. You can just do `let tx1= tx.clone()`. I'm confused about what your code is doing. You generate 8 boards in parallel, then only receive and display one of them. Can you clarify what you're trying to accomplish?
Thanks. Yes, I get the cloning part. The way the solver (and the board generator) works is that it generates all possible permutations of each row, shuffles them, and goes through, row by row, until it finds a valid board. If it gets stuck (because there is no permutation for a later row that does not conflict with an earlier row) it begins again. On a single thread this takes, say, up to 20 seconds. I am running the same script on multiple (7) threads (and I'm hoping on multiple processors), and then taking the first valid result that comes back. This means I get a solution in about 1 second.
&gt;When you know how to use iterators, map, fold, flatten, filter, range, collect, etc. really well, then you begin to think in terms of composition of those fundamental operations, rather than thinking in terms of for loops and your own data structures Good list of things to look out for in my journey into Rust. How long do you think it took you to feel this way while using Rust?
1) Yes, in this case explicit threads are good solution. But take a look at [rayon](https://docs.rs/rayon) crate, for many problems it results in a much nicer code. 2) Yes, in this case you can simply terminate thread when error is received.
Now, who is trying to get this working in WebAssembly? (This isn't as absurd as it sounds, as there is no way to render HTML to a bitmap in any browser right now.)
Thanks for your hints! I followed your suggestions: [https://github.com/barafael/markov\_chain\_text\_generator/blob/master/src/main.rs](https://github.com/barafael/markov_chain_text_generator/blob/master/src/main.rs) That is, not the first one! I don't get it...
"Interface safety" has no value if the underlying implementation could still be broken. Would you trust a C library to be safe just because it says it could have been implemented in safe rust? More to the point: how could I know from looking at ropey's code that it could have been implemented entirely without unsafe? How do I know that the transformation to unsafe was done thoughtfully? Answering these questions in the codebase is the "due diligence" referred to above.
Ah, so the generating+solving process is non-deterministic and you're racing them to get the fastest result? In that case this looks like a good approach. As for cancellation there's no super clean way to do it, the long running function will just have to check periodically if it should keep executing or not. You could pass each thread a clone of an `Rc&lt;Mutex&lt;bool&gt;&gt;` which signals when it can stop. `thread::spawn` returns a `JoinHandle` which you can use to wait for the threads to complete. 
If sending fails because another thread already sent a solution, and if you want to do ignore that case, then by all means ignore the error. It will only fail if the receiver has been dropped. As for signaling to other threads that they should stop working, you could use an [AtomicBool][1] which you set to true when they should finish, and periodically check it from each thread. [1]: https://doc.rust-lang.org/std/sync/atomic/struct.AtomicBool.html
That was my exact thought. 11 years in, I'm pretty comfortable with the language, and yet today it took me 15 minutes with a colleague to find on Internet how: std::chrono::nanoseconds seconds = {}; Was initializing `seconds` to `0` when the constructor of duration is `constexpr duration() = default;` which doesn't. **TL;DR:** `constexpr duration() = default;` is not a *user-provided* constructor, and therefore ` = {};` does NOT invoke the constructor, but instead bypasses it, zero-initializing the members who do not have user-provided constructors (and padding). Obvious, right? *sigh*
I don't understand why...
Alright thanks
&gt; or perhaps that the project isn't as widely used as its C version, and thus, has fewer bugs discovered. Right now, that's certainly the most obvious issue. Popular C projects like OpenSSL just have a *massive* user-base than no Rust replacement can achieve in just a year or two.
&gt; About half of them were due to memory safety issues that Rust would have prevented. Not *quite*. That is, yes about half of them were due to the memory safety issues, however it's not necessary that Rust could have prevented all of them: unsafe Rust may have memory safety issues, and not all issues were manually inspected to be in a position to conclude that safe Rust code could have replaced the C or C++ code.
As noted by burntsushi, though, the most immediate rebuttal that comes to mind is that "not discovered" != "absent", and the number of users massively impacts discovery.
Yes, and even with CVE counting, you have to consider a ton of stuff that makes it mostly useless as well. As you said, it's the same variables as ever, but even at a macro scope you have all new ones - maybe one company has a huge Rust codebase, but they fuzz it a huge amount and just generally bug hunt way more, is that really showing that rust is worse than an unfuzzed C++ codebase? So, so many factors. &gt; This is a good example (among many others) as to why I'm not a strict empiricist. Same!
&gt; I think, in some sense, the entire debate is about whether unsafe fundamentally should be an implementation detail. So, for the record: I _am_ of the mind that use of unsafe is largely an implementation detail. Maybe I didn't communicate this clearly enough in my post. What I'm talking about in my post isn't introducing actual memory unsafety, it's the use of `unsafe` blocks. Actual memory unsafety is always a bug. `unsafe` blocks introduce the _risk_ of memory unsafety, and it's the level of acceptable risk that I think is different for different software. Sorry if I didn't make that clear in my post.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/oasislabs] [Oasis Labs on why Rust is such an important language for blockchain DApps](https://www.reddit.com/r/oasislabs/comments/aelrgo/oasis_labs_on_why_rust_is_such_an_important/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
True, Rust does not support variable number of arguments. But you case use Default::default() as an alternative to optional parameters, yes it is more verbose, but it is also more clear (for me) what the function receives when being called, if there were real optional parameters, it would not be entirely clear what the function receives when being called (you would need to inspect the function's signature, where the optional parameters would probably be specified).
traits is a good start of IoC but it is not sufficient. IoC is 'develop for interface, not implementation' There is many way to solve this problem, and the main/classic way is to create a registry singleton, and when you boot your application, you fullfill thr registry with the implementation you will use for every interface you have. And in method, function signature, parameters are interfaces (trait). And, in your code, when you want to instantiate an implementation, you ask the registry which one implement it. AFAIK, there is no easy way to do that in rust. 
The difference between theory and practice... ... the language has certainly been designed to account for portability, however in practice there are limitations. The first obvious limitation is using LLVM as a backend: if LLVM doesn't support a target, then rustc doesn't either. The second limitation is that even when LLVM does support the backend, then rustc itself must be taught to support it, and `core` ported to it, then `std` if sensible.
I'm the best of both: I'm a telecom graduate! Trained neither in programming nor (extensively) in computer science!
Does it render on macos?
I am really looking forward to what Matklad is cooking in rust-analyzer.
Just to be clear, I _also_ very strongly disagree with it. I take it as a given that interfaces and code should be correct with respect to memory safety (and if not it's a bug). As I said in my reply to /u/sanxiyn, my post is essentially talking about risk assessment with respect to `unsafe` blocks. I'm pretty sure you interpreted my post correctly, but just making sure since there seems to be some confusion.
Is there a reason that `&amp;Option&lt;T&gt;` isn't just coerced to `Option&lt;&amp;T&gt;`? To elaborate, this fails to compile (E0308; [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=791bb40d5875e98df0a72a8bf10fee64)): /// The in-progress program, if appropriate. pub fn program(&amp;self) -&gt; Option&lt;&amp;Program&gt; { &amp;self.program } However, this code works as expected: /// The in-progress program, if appropriate. pub fn program(&amp;self) -&gt; Option&lt;&amp;Program&gt; { (&amp;self.program).into() } So my question is why the conversion needs to be explicit. I thought perhaps it was a backwards-compatibility thing, but then I realized a coercion like this shouldn't be an issue there.
I don't think I'd mind function overloading by *arity*... but to be honest, after using Rust for a while, I've rarely needed it to start with.
I've been tinkering in Rust for a few years now, but in the last six months I've really ramped up the time that I spend in Rust. And I've focused a lot on mastering everything in the standard libraries (as well as essentials like the `log`, `cancellation`, `regex`, etc. crates). There's no substitute for just writing lots and lots of code. As you write more code, you'll find that itch that needs scratching -- you'll encounter situations where you think, "there's got to be some reasonable way to express this idea, but I haven't found it yet". Then you look for an existing library that does it, or a trait that expresses the right idea in `libstd`, or you think through how to split up the problem better. Just, over and over and over. There's nothing like repetition and practice, for mastering a new subject. For example, let's say you're working on an algorithm that reads from two arrays and writes to a third array. In the old days, I would have done something like this: let a: Vec&lt;foo&gt; = ...; let b: Vec&lt;bar&gt; = ...; let mut result: Vec&lt;zot&gt; = vec![default(); a.len()]; for i in 0..a.len() { result[i] = f(a[i], b[i]); } where `f` is some function that does some work. This is a fairly C-oriented view. You have two vectors, you step through them, and element by element you get the result and write it into the result vector. But this is not idiomatic Rust code, and not just for style reasons. Here's all the things wrong with this code: 1. The `result` vector is pre-allocated (which is good) *and cleared*. The values written to the `result` vector are never used. For simple `Copy` types (like integers), that just means that we're doing a `memset` that isn't necessary, and usually it won't be too bad. But for more complex types (types that have `Drop` impl, which are usually also non-trivial `Clone` types that do not implement `Copy`), you're going to have to do some expensive work that is wasted. 2. Bounds checking may or may not do what you want. I've worked in safe languages that did a great job of eliminating bounds checking. Unfortunately, Rust doesn't do a very good job on bounds-check elimination. In this code, there are three bounds checks (per iteration). The compiler may be able to eliminate the check on `a[i]`, since it can see that the iteration counter is bounded by `a.len()`. But there is nothing that ties `i` to `b[i]`, and I don't think Rust is smart enough to realize that `result.len()` == `a.len()`. A few well-placed `assert!(a.len() == b.len());` *might* allow the optimizer to eliminate these checks, but generally I haven't been impressed with Rust on this front. 3. If you screw something up in control-flow in this `for` loop (let's say you're doing some non-trivial work in here`, then maybe you forget to actually assign to `result[i]`. So now you have a bogus value in that index. 4. It just looks... like C code. After I started doing more idiomatic Rust, I would probably have written this same loop like this: let a: Vec&lt;foo&gt; = ...; let b: Vec&lt;bar&gt; = ...; let mut result: Vec&lt;zot&gt; = Vec::with_capacity(a.len()); for i in 0..a.len() { result.push(f(a[i], b[i])); } That's a little better. The bounds check in `result[i]` is gone, but is replaced by a different form of bounds checking ("is self.len &lt; self.capacity"), but at least the code is a bit better. Next would be: let a: Vec&lt;foo&gt; = ...; let b: Vec&lt;bar&gt; = ...; let result: Vec&lt;zot&gt; = a.iter().zip(b.iter()).map(|(a, b) f(a, b)).collect(); Now this is getting interesting. First of all, we used `zip` to *associate* every item in `a` with a corresponding item in `b`. Because the iterators for `Vec` (and slice) are highly optimized, the result is that the bounds checking is done *once*, before the loop. What is iterated is a sequence of `(&amp;foo, &amp;bar)` items. `map` transforms those items, by running a function `f` over them, but let that stand in for any input-transforming step. Then `collect` builds the final `Vec`, and it does it with pre-allocation of the entire output *and* (I think) skipping bounds checking on writing the results. Rust generates fairly amazing code in this situation. In fact, I've even seen Rust do loop-unrolling and transform this code into SIMD vector code. But even better, often I don't even bother to do the final `collect` step, if all I need is to enumerate the sequence of result items. If I can consume the results as a sequence, then I can remove the `.collect()` call at the end, and use lazy evaluation. That's a trivial, contrived example, of course. But the more you work with these tools, and the more you see how versatile and composable they are, the more often you'll use them. Don't be afraid of iterator composition, because you assume it's slow or expensive or whatever. Most of the time, the inliner will convert this code to highly efficient assembly code, which looks nearly identical to what would be produced if you'd written the best hand-optimized C code. Another example. I've been working on some code that compares two sequences of things. The core algorithm compares items between two slices. At first, I wrote the code with a signature like this: pub fn compare_slices&lt;T: PartialEq&gt;(a: &amp;[T], b: &amp;[T]) -&gt; ComparisonResults; That's great, that's fine. But I noticed that inside my code, the *only* thing I ever did with items in `a` and `b` was to compare them to each other for equality. Using slices means that I have constrained the representation of the caller; I have required that all of the items exist in memory, and that they be contiguous within each slice. But all I cared about was comparing them. I changed this to this signature: pub fn compare_sequences&lt;F: Fn(usize, usize) -&gt; bool&gt;(a_len: usize, b_len: usize, is_equal: F) -&gt; ComparisonResults; The caller now provides a function which compares items in two *abstract* sequences, and also tells me the length of the two sequences. The implementation no longer constraints *how* the caller represents the items (stores them in memory). Maybe the caller is using slices, or `Vec`, or some other data structure. Maybe the caller has an in-memory cache, and also fetches items from disk or from a network server. The implementation of `compare_sequences` doesn't care. You can write the old `compare_slices` function in terms of a call to the new one, like this: pub fn compare_slices&lt;T: PartialEq&gt;(a: &amp;[T], b: &amp;[T]) -&gt; ComparisonResults { compare_sequences(a.len(), b.len() |i, j| a[i] == b[i]) } That call is so succinct and so expressive that it seems almost like a definition, not just an implementation. 
Thank you, unfortunately, that’s not it. 
It indeed works on macos.
Just to reiterate, it isn't enough to count the number of lines of code inside of `unsafe` blocks. You also need to count the lines of code that might affect the assumptions of the unsafe code. As an example, any code in the `impl` for `RawVec` must be counted as possibly unsafe, even if it's just modifying fields, because modifying `self.capacity` without resizing the allocation could lead to memory corruption.
For this specific function, `sync` is fine. But just because a function takes no args and returns no data, doesn't mean that function is "safe" in any meaningful way. You have to understand the semantics of the function, not just mechanically look at its signature. 
I can't really think of any use off the top of my head; do you have an example in mind where it would shine compared to alternatives?
So, the entirety of your post is something that I already take as a given. I _absolutely_ think that memory unsafety should always be treated as a bug, and that incorrect interfaces need to be corrected. The topic of my post wasn't "is memory unsafety acceptable in some cases", it was "is _risk_ of memory safety acceptable in some cases". And then, how to we communicate different levels of risk so that people can make informed choices about which crates they use? So I guess what I mean is: I agree with your whole post. But I think there are further questions on top of it.
Ergonomics, mostly, although they also enable language-supported multi-closures, which are useful for efficiently encoding objects with arbitrary and possibly dynamic inheritance.
Rust generally avoids implicit type conversions, for a variety of (mostly-good) reasons. One of the good reasons is that it makes type inference tractable. Personally, I think type inference is more important than supporting a wide variety of implicit conversions. Personally, I like having convenient-but-explicit conversions for these situations. I don't think calling `.into()` is an excessive burden. 
&gt; However, if I do this, is it safe to pass opaque pointers between functions in library A and B? Maybe, but it's not guaranteed to be safe. One common situation where this is not safe, is when library A handles allocating / freeing objects. If you have statically linked the CRT (C runtime) into *both* A and B (which is a common scenario), then you have two different instances of all of the `malloc` state, stored in both A and B. If you call into A and allocate some object T, and then call into B and ask it to free that same object, then the statically-linked code in B will call *its private copy of A* to free it. And boom, you've corrupted heaps. There are other varieties of this same situation. In general, I would strongly recommend avoiding this situation. Either *everything* is statically linked into a *single* binary (A + B + your Rust crate), or A, B are both shared libs. 
There's still a clear difference between "this use of pointers is safe, but the Rust compiler cannot understand the proof" vs "I gave up fighting the borrow checker and used unsafe to make it shut up." The latter is against community norms but comes up every now and again among newcomers. I think the dividing line is "I understand the borrow checker well enough to know why it cannot understand this usage pattern." In other words, you should be able to justify not just why your code is actually safe in practice, but also why it cannot be expressed in Safe Rust.
Yeah, it's not enough, but it's definitely a nice indicator of whether something's worth reviewing or to just move on to another library. Something with 10 lines of unsafe _should_ be easier to review than something with 100 lines. Of course it's not a guarantee, but it's at _least_ a start.
"Rendering HTML" is lot more involved than running WebRender. There’s parsing, style resolution, layout, font management, … I think a more realistic use case might be porting to the web platform an existing Rust application that uses WebRender for GPU rendering. Perhaps one based on https://azul.rs/
`self.program.as_ref()` is perhaps a slightly nicer way to do that.
By the way, during a code review I would strongly object to the function signature of `argmax`. There's no good reason at all for it to consume its input. `argmax` does not depend on modifying the `Vec` (and dropping it is definitely a form of modifying it), there's a trivial way to do it without destroying it, and you're placing an excessive (and inefficient!) burden on all callers of the function. Also, you've baked in the assumption (and the possibility of panicking) that the vector is non-empty. Returning `Option&lt;usize&gt;` expresses this possibility, and places the responsibility of handling `None` on the caller. The caller can trivially call `.unwrap()` if they know a priori that the input is empty. Something like this: fn argmax(foo: &amp;[u32]) -&gt; Option&lt;usize&gt; { foo.iter().enumerate().max_by_key(|(_i, &amp;n)| n).map(|(i, _n)| i) } fn main() { let foo = vec![40, 50, 1, 7]; println!("{:?}", argmax(&amp;foo)); } I would take this even further. This function signature unnecessarily constraints the type to be `u32`, when really all it needs is `Ord`. It also constraints the input to be a slice, when all you need is an iterator. This is more useful, since it works with all integer types: fn argmax&lt;T: Copy + Ord, I: Iterator&lt;Item=T&gt;&gt;(i: I) -&gt; Option&lt;usize&gt; { i.enumerate().max_by_key(move |(_i, n)| *n).map(move |(i, _n)| i) } fn main() { let foo = vec![40, 50, 1, 7]; println!("{:?}", argmax(foo.iter())); } 
Wow, what great feedback, thanks! I thought consuming input was preferred if known beforehand that input was not needed after the function runs (which I did in this case), as it freed the memory. Is that wrong? I also note that you change `foo: Vec...` to `foo: &amp;[u32]`, which clippy also recommends. Why is that? Thanks again!
I find that if you're either a beginner, or you're trying to do something fundamentally wrong, you'll have a hard time, and feel like you're making progress very slowly. As others have said, refactoring is very pleasant, and I have high assurances that I've fixed almost everything when I make it compile again. But more than that, when I look back on a large project, I realize that I've spent *much* less time trying to debug heisenbugs and null pointers errors. In other languages, I may be running the program over and over, and finding small things I need to fix or seeing weird inconsistent behavior. I find myself doing that much less often with rust. Once you've figured out the basic structure of your program, things just move along nicely without any many hangups. As long as the proper high quality libraries exist to do what I need to do, I find myself much more productive with rust than any other language. But I think it's hard to notice at first.
I partly agree with you, but partly don't. Forgive me for picking things apart piece-meal. &gt; I think /u/cessen2 (taking that example) may well be wizard-enough to use unsafe safely I actually disagree with this. Not in the sense that I don't have faith in myself, but rather from: 1. My experiences coding in C++. 2. Seeing memory safety bugs pop up occasionally even in the Rust standard library. Memory safety (and, more generally, program correctness) is hard, and even very smart people who work very hard to get things right still sometimes get things wrong. I certainly have put a good deal of effort into the correctness of Ropey, including the unsafe parts. But that doesn't mean there aren't bugs. And when there are `unsafe` blocks in your code, that means some of those bugs can be memory safety bugs. That's the viewpoint I'm coming at this from, and that's the spirit of the unsafe notice in Ropey's readme. &gt; Since it is the users of the library who have the choice and who are taking the risk, and who are probably using Rust because they like all the safety guarantees, then it is cessen's job to persuade those users that he knows what he is doing. I definitely agree with this. And heuristics like "lots of tests + CI" are certainly helpful. However, to the extent that the users of a crate can't evaluate its quality on their own, this eventually comes down to earned reputation to some extent. &gt; Just implying "this may have safety issues and isn't for critical uses" isn't really that persuasive. &gt; &gt; [...] &gt; &gt; I can accept unsafe for performance reasons if I'm persuaded that someone's thought hard about it and tried hard to get it right. I think this is where the crux of my original post actually comes in. Different application spaces have different needs. I absolutely would never want Ropey to be used in medical devices or aircraft control software, for example. And I would still feel that way _even if I removed all the unsafe code_. The key point is that I _have_ done my due diligence, but _only with respect to Ropey's intended application_. And I think that's absolutely reasonable. Different applications have different cost/benefit analysis, different acceptable risks, etc. And that applies to risks of memory unsafety as well. For many application domains, memory safety bugs aren't especially more critical than any others--they're just another kind of bug. But they _are_ more of a pain to debug. And so there are still going to be people like me attracted to Rust (also just because it's nicer in other ways, too), writing libraries like Ropey and software like my renderer. I'm not trying to abdicate responsibility for due diligence, I'm trying to appropriately flag the _level_ of due diligence.
I am spewing Rust code out of my code editor like a machine gun. I get whole areas of functionality ready from crates.io and soon will be able to trust them better using `cargo-crev`, I do not care about formatting (rustfmt do it for me), I do huge refactors without thinking twice, and always get the correct code at the end thanks to the type system. I don't debug much, because usually I just have no bugs. I have plenty of simple unit-tests in places that need them. Rust is a 10x programming language for me.
Yeah it’d be cool to be able to do like a supersafe{}
[`Rc&lt;AtomicBool&gt;`](https://doc.rust-lang.org/std/sync/atomic/struct.AtomicBool.html) might be slightly nicer ergonomically and speed wise, but otherwise agreed.
Just about the only point I agree with is that `unsafe` isn't wizard-only. Clearly one of the *advantages* of lower level programming is having the authority to say "the computer should do exactly what I say." But I don't think you fully appreciate how *infectious* broken invariants can be. When something goes wrong in module A then unrelated module B is probably going to act strangely too - even if module B is entirely written in safe code. Don't expect corrupted program state to be contained until it hits operating-system isolation features such as the boundaries of a process or user. If a program saves and restores state even those limits aren't enough. (I see this several times a week with a rather terrible Android app that is supposed to track the city bus. It becomes *very* confused if the Android OS decides to kill processes to recover memory.) Unsafe implementation holds a program's modularity and correct documentation to a *much* higher standard than merely exposing an unsafe interface does. If you look in the standard library for `Vec` you'll see that `from_raw_parts` is easy to implement correctly (yet hard to use correctly) but `drain` is *really hard* to implement correctly and it has this rather scary note: &gt; Note 2: It is unspecified how many elements are removed from the vector if the Drain value is leaked. Said more plainly: "You must ensure that the returned iterator is dropped. If you don't then the library is allowed to do anything to your `Vec` as long as it doesn't violate type safety." In fact the effect of `.drain()` without dropping is similar to `.truncate()`. The missing elements are forgotten, not dropped, but it really *can* forget everything in the `Vec`. This sharp edge case is preferable to violating type safety and is allowed because normal lazy-coder use of `.drain()` - something like `for e in v.drain(..3)` - will drop the iterator when done. 
Holy mackerel! I was about to ask if/when WebRender would be available on [crates.io](https://crates.io)! To quote Truman (\*): "You never had a camera in my head" &amp;#x200B; Next interesting step for me is to find out how far along Vulkan rendering is and experimenting if one could combine WebRender with Vulkano to write a game GUI in html... one can dream, right? &amp;#x200B; ^((\*) Referencing the movie "The Truman Show" here
When you hand over control to the event loop, that's the inversion of control. You set it up beforehand but then it's responsible for calling all the futures you've given it. For things like Rocket that's all hidden very nicely but from your perspective when you run `launch`, that's the inversion of control.
This was actually my 2019 feeling as well - I tweeted about it here: https://twitter.com/InsanityBit/status/1072550602083848193 A big word for rust is "safe". What does that mean? There's memory safety and type safety. These need improvement - we need more work to make unsafe code safe, we need fewer soundness holes in the language, etc. There's also safety of being a rust developer. What's being done about typo-squatting? What about worms that leverage your cargo credentials? What about crates.io's infrastructure - have we modeled a crates.io compromise, and what that would look like?
Perhaps you might enjoy gfx-hal, an abstraction that can render to Vulkan, DirectX, Metal and WebGL https://github.com/gfx-rs/gfx
Perhaps you might enjoy gfx-hal, an abstraction that can render to Vulkan, DirectX, Metal and WebGL https://github.com/gfx-rs/gfx
Still waiting for the day we get keyword arguments. It's usually with constructors for me. You start with `new`, then `with_foo`, then `with_foo_and_bar`, but then we also need a `with_bar`, and maybe a `with_baz`, oh no how does this combine with the others?! Do we add a `with_foo_and_bar_and_baz`.
These are bugs found by the exact same automated tool, so the number of users does not matter in this case, only whether the tool has been correctly applied or not.
While you're here quick question on this &gt;In other news we are initiating a notable workflow change: WebRender patches will land directly in Firefox’s mozilla-central repository and a bot will automatically mirror them on github. Will issues still be created on GitHub, like easy / moderate difficulty ones? because I'm going to try and start getting more involved if I can find the time and Bugzilla just seems much harder to work with compared to GitHub where I can just click on the issues tab and filter by easy, like on Bugzilla it's just a wall of issue numbers and when you hover over to find the name there's no indication whatsoever about it's difficulty. 
Oh damned, that's embarrassing. I thought it was just a generic CVE list :(
About two weeks after you think you can say you know C++. Only halfway kidding, of course. C++'s complexity knows no bounds IMO. I've worked with C++ and developers experienced with C++ for many years but only so very, very, few know the full breadth and depth of C++. Most of the ones who I think do work on the various C++ standards stuff or have worked on it in the past.
Can you give some examples? I'm quite curious to see what kind of extra compile time checking one could do in Rust. Are you talking about const generics, and asserting that lists are nonempty for example? If so, how would that work?
2^64 / 3 GHz = 195 years
You double posted. Maybe delete this one?
Y tho. Can't you do everything with rust alone?
I ended up using the lapack/openblas rust bindings. It's fortran with hand optimised assembly so you will be hard pressed to find or write anything in rust that's better. 
...which will make it even more confusing.
That's what the builder pattern is for! https://github.com/rust-unofficial/patterns/blob/master/patterns/builder.md https://doc.rust-lang.org/1.0.0/style/ownership/builders.html
Yes, that was basically the joke. Good.
The benchmark is basically shoving a few million requests (which each take 2 different unique IDs) down through either 1, 6 or 12 connections and measuring throughput. Not the most scientific method, I must admit. There is bound to be a lot of noise, I guess I need to microbenchmark this a bit more... What numbers would be realistic?
This was made with projects already using Meson in mind. I wouldn't recommend Meson for a new Rust project.
&gt; "avoid having to deal with lifetime issues" is one of main uses of Rust unsafe If you're doing this on 2018 edition, most likely the borrow checker highlights an actual bug. If you overrule the borrow checker with `unsafe`, the bug is *still there.* Moreover, it's probably a use-after-free, which is [an exploitable vulnerability](https://www.purehacking.com/blog/lloyd-simon/an-introduction-to-use-after-free-vulnerabilities). So "use `unsafe` to avoid dealing with runtime issues" is one of those things that should almost never be done.
Thanks, I/we (not in this alone) settled for Vulkano some time ago. Doesn't mean I won't look at gfx-rs in the future though. I heard that Mozilla itself is interested/invested in gfx-rs nowadays, so let me ask: Is it feasible to create a GUI with it in combination with webrender?
&gt; fn foo(mandatory: String) { &gt; foo_with_options(mandatory, None); &gt; } &gt; &gt; fn foo_with_options(mandatory: String, options: FooOptions) { &gt; // implementation &gt; } This is a mess? Surely you're exaggerating... 
&gt; I thought consuming input was preferred if known beforehand that input was not needed after the function runs (which I did in this case), as it freed the memory. Is that wrong? It's... complicated. I don't think there's a single, universally-applicable rule. But here's how I would approach things: Can I compute my data without altering its input in any way? In other words, is my algorithm a "function" in the mathematical sense? If so, this is the easiest and usually best way to approach things. Especially if (as in this case) computing the result does not even require allocating space. Is the purpose of my algorithm to move or rearrange data in some way? If so, then it may be best for the caller of my algorithm to transfer ownership into my algorithm, for me to do my work, and then at the end for me to transfer ownership back. Especially if the representation of the data had to significantly change. Basically, when you compute new data from old data, and the new data has some relationship to the old data, you have a couple of options: 1) copy it, 2) move it, 3) point to it. Pointing to data, instead of copying data, tends to give you a lot more freedom (but it's not always possible). For example, let's say you had a `HashMap&lt;String, usize&gt;` which counted the frequency of different words found in some input text. You want to provide an algorithm which returns a list of the top N strings that are the most frequently-found in that hash map. How should we return the information? Let's say our function is called `top_n`. We could write the signature in several different ways: Output copies input: fn top_n(n: usize, map: &amp;HashMap&lt;String, usize&gt;) -&gt; List&lt;String&gt;; In this version, we would copy the keys from the hash table to the output. Output refers to input: fn top_n&lt;'a&gt;(n: usize, map: &amp;'a HashMap&lt;String, usize&gt;) -&gt; List&lt;&amp;'a str&gt;; In this version, we would build a new list that contains references to the keys in the input. Function consumes input, drops all of the strings that are not returned, and moves all of the strings that are returned into a new list: fn top_n(n: usize, map: HashMap&lt;String, usize&gt;) -&gt; List&lt;String&gt;; Each of these signatures is probably ideal in some situation, so we have to use our judgment. I would *probably* go with the reference-based one, since it gives me the most flexibility and puts the fewest constraints on the caller. I would be very suspicious of the move-based signature, because it means that I can't use the function without *giving up* my `HashMap`. What if i want to call several different functions that read my `HashMap` and produce different values? I don't want to clone my data every time I call something, just because one particular function consumed its input. &gt; I also note that you change ... That's because `&amp;Vec&lt;T&gt;` can't do anything that `&amp;[T]` can't do, and `&amp;Vec&lt;T&gt;` constrains you to *one specific way* to store data. Slices are awesome because they can refer to data stored in *many* different kinds of containers. You can get a slice from a stack-allocated fixed-size array (so, no heap allocations). You can get a slice from a `&amp;T`; it has a slice length of 1. You can get a slice from a buffer stored in a `std::io::BufRead` implementation. You can get a slice from static / const data. `Vec&lt;T&gt;` is just one *kind* of thing that you can get a slice from. So if the only thing you're doing is reading elements from an array view, you should strongly prefer `&amp;[T]` instead of `&amp;Vec&lt;T&gt;`. As always, there are exceptions, judgment calls, trade-offs, etc. But it helps to think in terms of providing maximum functionality, while minimizing the unnecessary constraints that you place on the caller. And if you notice, in my last implementation of `argmax`, I *did* use "move" semantics. But the only thing I moved was the iterator, not the thing the iterator points to. In this case, all I care about is being able to iterate through a sequence of items. And since i was going to iterate through *all* of the items in the sequence, consuming (moving) the iterator into my function was the best fit. Anyway, I'm rambling. Thanks for listening. 
My thought is that it "would significantly improve readability" is a matter of opinion, and one that I disagree with.
Regardless of what you write, you're going to refactor many times. As you learn new concepts and add to existing knowledge, you will refactor. I applied concepts that were new to me and when I revisited them some time later realized there were much better ways to solve a problem. Learning how to use tools well comes with experience. I am using techniques now that I couldn't before. It feels great. This isn't a feeling that is unique to Rust. However, what seems unique to Rust are the levels of design that can be taken to solve a problem. Rust has a depth to it that other languages don't. My goal has been to refactor to what feels "good enough", which is between "you ain't gonna need it" and "just release anything that works". 
On a more realistic job that's rarely how code gets designed. It's a simple function that needs more and more parameters over time. I don't want to preemptively create a builder for every function; your example is hiding the boilerplate too. I'm not saying rust is bad here, but I am saying they get it the least right. After writing my first few thousand lines, this is high on my pain points list compared to Java or Python.
The reason is that stout is buffered and that buffer needs to be protected against possible multithreaded writes to it.
Nice! Is there any particular reason why you want to move tests for external API into Rust? Testing code is usually pretty simple and is not exposed to untrusted data, so you're not gaining much from Rust in this case. And testing C APIs from C code makes sense. Also, have you considered bypassing the C entirely and exposing a Rust API directly from the Rust code in rsvg? That would avoid jumping through the GIR hoops and also avoid the unsafe bindings. Fun fact: the first CVE I ever discovered was in language bindings for a GObject library.
If you're full time with Rust, 6 months to a year. If you're coding in a variety of languages, longer.
I'd agree that it's not a "burden" *per se*, but it does seem like a safe and convenient thing for the compiler to do automatically. I'm not complaining that it doesn't work, just wondering if there was a deeper technical reason. I guess, based on the generality of your answer, maybe it's just architectural?
I guess my question is, what is the Actual Work associated with each request? Is a request doing something like "actually read and write to disk" or something like "for now this is just a stub that returns a constant string"? If it's the former, I'd be _very_ surprised to see a single atomic operation making a meaningful difference in your throughput. If it's the latter, then it makes more sense that your coordination overhead is going to dominate everything.
I'm a game dev so it's a particular pain point. It's been fine using vscode and the llvm debugging support it has for doing toy apps and little projects, but I don't think it'd be a pleasant experience using the same tools for the multi-million line projects I work on for a day job. I know big projects have been done in rust, but C++ just has a very real productivity edge right now. It's not because of the language itself, just the tool support.
Thanks! Interesting for `Option` to use that name but not implement `AsRef`!
Well, it does change the guarantees the library provides. A single unsafe block gets your library from "rust compiler has verified that all of this is safe" to "trust me, it's safe". And when it actually not being safe means stuff ranging from intermittent unreproducible crashes in production that cost you two weeks to debug to someone hacking into your system and stealing and/or corrupting all your data. With that much at stake you don't necessarily trust "trust me, it's safe" from random people on the internet. Getting unsafe code on board is a risk and/or a much more costly audit.
Note that `AsRef::as_ref` returns `&amp;T` (that is, it never fails to return a reference) while `Option::as_ref` returns `Option&lt;&amp;T&gt;` (because it can't return a reference to nothing). But that's a good point about the name, I honestly never thought about that :)
https://elementary.io/ is working on that and they seem to be pretty far along
I think doing something like this would require treating the `Option` type specially in the compiler, whereas right now `Option` is "just another enum."
I've played with haskell years ago. I love this language, I love its type system and syntax and `::`. I don't use Haskell because of 2 reasons (maybe they are outdated already?) 1. Idiomatic Haskell is beautiful but efficient Haskell tends to be obscure. E.g. I love idiomatic one-liner qsort implementation. It is more expressive than any description of qsort in any book. But it is very slow (or at least it was 6-7 years ago). 2. Immutability and laziness are great in theory but in practice, our computers are still imperative and some algorithms are in fact easier to do using mutable structures. Ofc there are some patterns like accumulators or tail-recursion or this dark magic called monads and friends. But they add lots of complexity and distraction from the core code meaning. These 'issues' make Haskell, in my opinion at least, perfect academic or toy language but not a viable choice for every-day programming. On the other hand, rust brings a lot of nice ideas from Haskell but most of the times they are optional defaults. I can use monad-magic and the language prompts me to use immutable structs but I can extremely easily opt-out preserving being idiomatic and clear. And idiomatic rust is in many scenarios the fastest.
Personally, I'm sympathetic. I'd love to have implicit conversions for conversions that cannot fail or lose information. Like u8 to u32, or especially u32 to usize for slice indexing. But from what I understand, it would greatly complicate other parts of the language, so I'm willing to put up with it. It also avoids horrible problems that I've seen in C++, where poorly-understood interaction between implicit conversions and math operators is a never-ending source of hilarity. 
The `stdout` itself is a global shared mutable resource. The options then are to * have it behind a lock and working well in any scenario; * not have it behind a lock and somehow restrict its use to a single owner (idea similar to what `rtfm` crate does, but `println!` could not exist in its current form); * not have it behind a lock and see it not working correctly in subtle corner cases (what you might observe from time to time in C-land).
InteliJ Idea has really nice support for rust.
hmmm brb i gotta reboot my server
Ah, I totally get why a programmer would choose Rust over Haskell, was wondering more about why a mathematician would.
The actual work is actually sending a row to a database and storing it to disk. Upon discussion with the crate author, it was pointed out that both Relaxed and SeqCst compile to the same assembly code, so I guess my 20% (actually 17%) were probably just noise...
If you want to be generic over iterators that return `u64` and iterators that return `&amp;u64`, you can use the `Borrow` trait: fn from_iter&lt;I, B&gt;(input: I) where B: Borrow&lt;u64&gt;, I: IntoIterator&lt;Item = B&gt;, { } That should let you pass both `vec![...]` and `&amp;vec![...]` to `from_iter`. Another thought on the side, you mentioned you want to use feature flags to toggle bounds checks. That might run into trouble, because feature flags are assumed to be additive. For example, say I have crates A and B that both depend on C. Now crate A doesn't set any feature flags, but crate B sets feature `foo`. In this case, assuming their version constraints are compatible, both A and B are going to depend on the same version of C with `foo` turned on. The assumption here is that, by not turning `foo` on, A is saying that it doesn't care whether `foo` is on or off. There's basically no way for A to say that it specifically needs `foo` to be off. When a feature does something like add new functions or implement new traits, that's generally fine. Callers like A aren't going to care about extra items that they're not using. But if the feature is something like "turn on bounds checks," that starts to get dicey. Maybe A didn't turn on bounds checks because it's calling C in a tight loop, and when B comes along and activates the bounds checks feature it ruins A's performance. (Of course it would be even worse if the feature was "turn off bounds checks", since A could've been relying on those checks for safety.) In these cases, usually you want to resort to something other than a feature flag, possibly by offering multiple different public interfaces, one of which does bounds checks and one of which doesn't. Or possibly offering different crates. Unfortunately I don't know of any approach that's as simple as feature flags.
There have been couple of great presentations on [Sequoia-PGP](https://sequoia-pgp.org/).
C+Rust+kernel+BIOS+Debian packaging seem like a pretty unlikely combination. Are you sure you're not looking for a unicorn? For example, Debian packaging is its own world with a lot of complexity, and is not any more exciting than the build systems it wraps. So having kernel and Debian packaging competence together is already quite unlikely. And you want Rust and BIOS and UEFI on top of that, all at the same time? I'd suggest dropping Debian packaging from the list and make Rust into a "good to have", because C gurus with all the other stuff are already rare, and the ones with Rust and Debian packaging on top might as well be nonexistent. Surely, a person with all those qualifications would be able to grok Rust in a month?
Thanks! &amp;#x200B;
Of course not, why do you think bindings exist?
Until you get a million users and it suddenly turns into every month. So care should be taken with how exactly you apply those.
On a realistic job, changing the function without updating the caller can result in broken invariants that the caller relies upon. In any case, adding a `None` parameter to the caller is also pretty trivial.
I want to create/use a data structure that shows ordering dependencies among data. Like a DAG. Once I create it I want to see each path independently. Does `petgraph` have a way to iterate over the unique paths in the graph? Or do I have to write this? Is there a better crate for this use case?
Please also note that in order for this to work correctly, you should always set the \`doc(html\_root\_url)="https://..."\` attribute in your published crates. &amp;#x200B; Eg: \`!\[doc(html\_root\_url = "https://docs.rs/hyper/0.10")\]\`
Sure, but you're saying you will pay for a game service offering multiple titles, not for a single game.
Why add electron to the mix, when you can probably compile the rust program directly for all platforms that electron is available for? Also as electron is quite a resource hog, wouldn't that undo one of the advantages of using rust?
Other libraries are Rust Crypto and Orion, was it related to one of those? 
I thought that's what we were talking about, but I dont think one-off games would be unsellable either. People throw a buck or two at phone apps, I could see them doing so for streaming game content.
You can use the `|` operator to match on one of multiple values: ``` match item { Item::Rock =&gt; // throw away, Item::Apple | Item::Orange | Item::Kiwi =&gt; // eat, } ```
1) because of cross platform UI issues 2) I dunno I thought maybe it would be the other way around: rust would undo the main disadvantage of electron, the resource hogginess. :shruggy:
Just because you have a million users doesn't mean you can update an atomic at faster than the core/system bus clock rate...
Depends. Ironically, people tend to not fork over small fees and *credit card info* to an untrusted, independent entity. They're much more willing to do it for major purchases, or through a store they (or others) frequent regularly.
That's what PayPal is for. I'm not sure why that's ironic, unless you were just being sarcastic.
Strongly agree, an implementation of sync or send will force to audit a big chunk of code even though it's only one line in the stats
It's ironic because people will take more risk with greater amounts of money.
How do I exit broot? I got stuck. Using on Ubuntu WSL
&gt; What's so magical about enums? With an enum, the compiler knows all of the possible things the enum can be. Strings aren't like that. So the compiler can know the integer assigned to each variant of the enum, since it knows every possible value. Does that make sense?
It just maps each variant to a number, starting from zero and counting up. If you specify an integer yourself, it'll use that. This is what the C language does, too. Note that this only works for simple enums, though! It'd _won't_ work if you rewrite the `Number` enum to `enum Number { Zero, One, Many(i64) }`.
Thank you! I'm surprised this isn't in the \[docs\]([https://doc.rust-lang.org/book/ch06-02-match.html](https://doc.rust-lang.org/book/ch06-02-match.html)).
The compiler will beat you into shape like a marine drill Sargent. Every stupid mistake you'd make with pointers will be beaten out of you. What you get is if a program compiles it will run. 
There is also little-known gem called peep; a less that doesn't take the whole terminal window and has a dynamically adjustable size. It was recently introduced in Rust Tokyo lightning talk event. https://github.com/ryochack/peep
[Some previous discussion](https://www.reddit.com/r/rust/comments/9wml68/introducing_mundane_a_new_cryptography_library/)
I also hope we can teach rustfix a few more tricks so you have it do a lot more of the boring parts (along with more IDE features like moving structs into modules and automatically updating all imports)
&gt; Orion That's not it either. 
I don't have a concrete example right now but using const generics with session types is gonna be pretty powerful
&gt; Testing code is usually pretty simple and is not exposed to untrusted data, so you're not gaining much from Rust in this case. Does Rust not have an equivalent to QuickCheck yet? (I can categorically tell you that C does not.) If not, I sense an opportunity...
It's described [later in the book](https://doc.rust-lang.org/book/ch18-03-pattern-syntax.html) in the section on patterns, since you can use it in other places besides `match`.
Yep: https://github.com/BurntSushi/quickcheck .
We have a policy that important work has to have items on Bugzilla and for a while we've been filing Bugzilla entries for the github issues we are working on. I can still see bikeshed type of discussions happening on github and I know that there is little chance of attracting contributions by filing easy bugs on Bugzilla so I imagine some issues will be filed on github when we care abouy their visibility. People are welcome to file issues on github too. Now if you are interested in finding a mentored bug on Mozilla stuff, have look at https://codetribute.mozilla.org/ which will help you find the right bugs to start helping out with. 
Yea, but I thought that was more about being able to use code with constants in a type? I don't really see how that leads to more safety.
/u/burntsushi, thanks so much for your thoughtful response! &gt; Folks can indeed come across as pretty harsh when using unsafe code, but in my experience, it tends to happen when unsafe is used unnecessarily. That's a fair point. I _feel_ like it sometimes goes beyond that, but that may be misinterpretation on my part, or it may be a minority of people / inexperienced people that are vocal but whom no one is really taking too seriously. &gt; This is why it's a decent idea to try to justify your use of unsafe in the code with a comment, in addition to explaining why it is indeed safe. This is an excellent point, and is something I should do better. I absolutely think this should be part of community norms. People reading your code should be able to quickly ascertain the purpose/justification of unsafe blocks. &gt; If I had to choose between "yes, you should use unsafe if it does what you want" and "no, do not use unsafe, it's only for wizards," I'd probably pick the latter. I _think_ I agree with you here. But I also think the situation you've presented isn't the situation we're in: we don't have to deliver such a ham-fisted message in either direction. _If_ we had to, then yes, "don't use unsafe code ever" is likely the better message. But I don't think we need to. And that's part of what I'm trying to figure out: how can we establish community norms/vocabulary/whatever that make a more appropriately nuanced message visible and digestible. I think focusing on intended application space might get us there. Even with zero unsafe blocks, I doubt I've ever written code that I'd be at all comfortable putting into medical devices, for example. But that doesn't mean my code isn't appropriate for less critical applications. Normalizing thinking/talking/discussing in these kinds of terms would, I think, be more useful to the Rust community than (IMO) over-simplifying to "unsafe is for wizards". And it would allow a healthier growth of a variety of Rust code targeted at a more diverse range of use-cases. &gt; that said, I'm not sure I would personally plaster it in a prominent place in the project's README, but probably create a separate document called SAFETY.md and describe pertinent details there. I definitely like this idea. I would like it even more if it were integrated into crates.io somehow. Part of the reason I put it directly in the readme is to make it visible to people browsing on crates.io. But I agree that my approach here is ham-fisted, and doesn't even really achieve the nuance I'm suggesting above. &gt; I personally wouldn't recommend doing this. At least, I wouldn't want to, but others might. The reason is that I'd prefer to put all focus into getting one code path correct instead of maintaining two of them. It just seems like more maintenance burden to me. Yeah, that's totally fair. In the case of Ropey, I don't think it would be much of a maintenance burden due to the nature of the unsafe code. In fact, in many cases I have slower safe versions already, against which the unsafe code is partially verified via property testing. But I certainly wouldn't _expect_ any crates to do this, and you're absolutely right that in many (possibly most) cases it would be too much of a maintenance burden. That whole section of my post was intended more as, "And this is something else some crates could do where it makes sense." Not as an edict that any crates _should_ do it.
Oh, good... and expected, honestly, given that Rust has type classes, ahem, traits. So we have the answer to PPs question, I guess: Rust really *is* better for testing a C API... assuming that *some* sort of property-based testing is valuable.
On the other side, say you don't have a simple enum, you *can* use: [std::mem::discriminant](https://doc.rust-lang.org/std/mem/fn.discriminant.html) for mapping integer values to enum variants, regardless of the enum contents. Useful for hashmaps, for example. 
I wonder if this could be improved to use atomics in the common case (i.e. when the buffer isn't full). Atomics are pretty cheap especially when there's no actual contention, so I think it should be possible to get unlocked writes pretty close to the performance of locked ones.
Rand uses "serde1", which is as good as any
I guess the thing that confuses me is that the program never specifies that the variant `Zero` is equal to `0`. Zero is just a name, so how does the compiler know what value to return when it is cast as an integer? Is the Number enum built into the language somehow?
I disagree that it is 100% OK; you might be able to "certainly construct... in your head", but others may not.
There was [webkit.js](https://trevorlinton.github.io/) :D
It's the first one in the list, thus it gets to be 0. Reverse the order and you'll break the association. Same thing happens in c++, the first enum gets to be zero, the next one is one bigger etc. It also works if you specify the value for the first one (+1 for the next one). Standard behaviour.
WebRender currently uses opengl but there is a long term project of moving to gfx-rs. In the mean time you can play with the work in progress gfx port by the zseged team: https://github.com/szeged/webrender
I just messed around with the code a bit to test something out, it seems that no matter what I change the names to, the result is still the same. For example: enum Florg { Bleep, Bloop, Blorp, } fn main() { println!("zero is {}", Florg::Bleep); println!("one is {}", Florg::Bloop); println!("two is {}", Florg::Blorp); } still outputs: zero is 0 one is 1 two is 2 I guess it's just printing out the positions of the enum variants? Which makes more sense than what I was thinking. 
That makes more sense than what I was thinking. I thought the language somehow knew that an Enum variant named `Zero` should display `0` when cast as an integer. Thank you for the explanation!
Gotcha. That makes sense. Thank you!
Outside of the book, it can also be found in The Rust Reference: &gt; Multiple match patterns may be joined with the | operator [match expressions](https://doc.rust-lang.org/stable/reference/expressions/match-expr.html) 
One concrete example I have is a struct, which must manually implement `Send` and `Sync` due to interference with phantom type parameters. I have some static assertions in place that ensure that the non-phantom fields are indeed `Send` and `Sync`, so it all stays safe. Here I'm specifically looking forward to a combination of procedural macros and assertions at compile time to ensure all fields that aren't phantom types are checked. Non-hacky and flexible size assertions would also be great. Both for size comparisons to ensure transmutes are safe, and to assert a certain size isn't exceeded, like when your type uses leftover space for a small buffer optimization.
For those like me who don't understand the significance of this: https://hacks.mozilla.org/2017/10/the-whole-web-at-maximum-fps-how-webrender-gets-rid-of-jank/ 
Thanks for the nice reply! Just one quick note: &gt; I think I agree with you here. But I also think the situation you've presented isn't the situation we're in: we don't have to deliver such a ham-fisted message in either direction. If we had to, then yes, "don't use unsafe code ever" is likely the better message. But I don't think we need to. Yeah, definitely! I more or less meant to point out here that it's a good thing we have conservative message rather than a reckless one. Aside from that, I don't know exactly how much control we have over the wording. Signal has habit of getting lost in the noise. You might hear, "don't use unsafe code ever," but someone else might decide to transmit that as, "only use unsafe if you're a wizard." It's not a phrasing I would choose personally of course!
A simple point, but one worth making: you will spend much more time getting past compile errors, but much less time debugging. So try to remember that the compiler is your friend, even when you get annoyed with it! Usually when it says "you can't do that" there's a good reason, even if you don't understand it at first.
I'm trying and failing to understand how atomics could help protect a buffer. Can you explain further?
The page mentions that they start from zero if you don’t assign. Maybe we can make it more clear now?
My thoughts on the use of `unsafe fn` are: 1. They should clearly and unambiguously state under which conditions it is safe (i.e. defined behavior) to call that functions. In other words, all the *proof obligations* 2. These conditions should be stated as formally as possible but in a way that is easy to read. 3. If you can state invariants in a "mathy" flavour (e.g. `length &lt; capacity`) then that is clearer. 4. If there are no proof obligations (e.g. some FFI function) then that should be stated *explicitly*. My thoughts on the use of `unsafe trait` are: 1. Everything I said about `unsafe fn` but instead for `unsafe impl`. My thoughts on `unsafe { ... }` are: 1. They should **_always_** (and I mean this *literally*) come with a comment that discharges all the relevant proof obligations. 2. I *really* mean always; even if you think the proof is trivial, it's better to explicitly write "trivially safe because...". 3. What you should explain is *how* the proof obligations are upheld, not just what they are. 4. Uses of `unsafe { .. }` should be kept to a minimum. The only reason why `unsafe { .. }` works is because unlike in C or C++, it is contained and limited. With every use of `unsafe { .. }` you are diminishing the value of this containment because more places now need to be checked. 5. Uses of `unsafe { .. }` for performance are legitimate, but then the performance increase should also be notable. 6. `unsafe { .. }` blocks should be *short* and *shallow*. The longer and deeper it gets the harder it is to reason about. This applies to functions in general, but there is more at stake when `unsafe { .. }` is used. If there is some safe algorithm that you are writing in the middle of `unsafe { .. }`, extract it out to a safe function. A good example of an `unsafe { .. }` block for `Vec::set_len` is: ```rust // SAFETY: When `deflateGetDictionary` returns `Z_OK`, it holds that: // 1. `dict_length` elements were initialized. // 2. `dict_length` &lt;= the capacity (32_768) // which makes `set_len` safe to call. unsafe { // Make the FFI call... let r = deflateGetDictionary(self.strm, dict.as_mut_ptr(), &amp;mut dict_length); if r == Z_OK { // ...and update the length to what was initialized. dict.set_len(dict_length); Some(dict) } else { None } } ```
I suppose those are good reasons. Perhaps it would be advantageous to make use the fact that [WebRender is now on crates.io](https://old.reddit.com/r/rust/comments/aekwyt/webrender_now_on_cratesio_mozilla_gfx_team_blog/)? Someone in the comments there also [suggests](https://old.reddit.com/r/rust/comments/aekwyt/webrender_now_on_cratesio_mozilla_gfx_team_blog/edqghkd/) a crate called [azul](https://azul.rs/) which also seems to make use of WebRender, but specifically packaged to make cross platform GUI's.
There are a number of lock free buffering strategies. A ring buffer is probably the simplest. 
&gt; I can categorically tell you that C does not. Except, you forgot about Theft: https://github.com/silentbicycle/theft
Hm, can't doc.rs automatically set `html_root_url` to itself with a correct version if it's not provided by crate author?
That's not a global variable, it's local to `main`. What you're seeing is that the compiler treats trivially copyable types (ones that implement the `Copy` trait) a little differently. If you did it [with something that doesn't implement `Copy`] you'll see that it doesn't compile. 
Oh, yeah that sounds quite interesting...
Thanks. Yes, it's certainly very helpful to be upfront about all this stuff. I agree about earned reputation being important. At work I have to review other people's code. (Although not Rust code quite yet!) So you need guidelines to keep the code quality up. "Unsafe needs justifying" seems like a pretty good rule of thumb to take full advantage of the features that Rust offers. Even for genius-level coders, I'd still like to see a justification of why unsafe is necessary, and to make sure it is as contained as possible. In our case, we'd prioritize maintainability by the rest of the team over a small speed advantage. So if I was considering an external crate for work, intentionally leaving it up in the air as you are -- saying that you're not specifically optimizing for memory safety -- isn't really satisfying. We'd like to know! (The license already says "no warranty".) But this problem can easily be solved. All we have to do is get a genius-level coder to review the crate, and then pin the version, and then update/review again from time to time. Rust does make it much much easier to control this particular risk. Obviously an external crate could cause us other problems, such as endless loops or infinite memory allocations or panics, so general code quality and care and testing are also very important to consider. But unsafe blocks are low hanging fruit ... they're too tempting not to consider early on ... and safety is a big selling feature of Rust. Maybe this explains people's fixation on them.
Yes: match item { Item::Rock =&gt; // throw away, Item::Apple | Item::Orange | Item::Kiwi =&gt; //eat, }
Move moves all variables used in the closue into the closure. But since a is a Copy type you get a copy.
The [Rust Reference](https://doc.rust-lang.org/stable/reference/items/enumerations.html#custom-discriminant-values-for-field-less-enumerations) can be a good place to look for these things: &gt; These enumerations can be cast to integer types with the as operator by a numeric cast. The enumeration can optionally specify which integer each discriminant gets by following the variant name with = followed by a constant expression. If the first variant in the declaration is unspecified, then it is set to zero. For every other unspecified discriminant, it is set to one higher than the previous variant in the declaration. I guess it's kind of odd if you haven't seen it before. But it's the same as C.
As a new reader of the book, I've had this question too, couldn't find a solution from googling. I later found this solution and then promptly forgot. I think the book would benefit from mentioning this in the section about match (6.2).
I have some good and bad news... ;) &gt; [disposition: merge] Stabilize uniform_paths. This will probably go into 1.32 instead of 1.33. &gt; [disposition: merge] Stabilize the integer_atomics feature: Atomic{I,U}{8,16,32,64}. This will unfortunately slip and go into 1.34 instead.
&gt; And man do I feel like I’ll never get to know/use all features of the language in the years to come. You don't really need to know *all* the features of Rust to develop complicated software with it. Depending on what you're using it for, you likely don't need to know anything about the Rust features needed for nostd development (for things like micro-controllers, OS kernels, etc.). You may not need to know the features for interfacing with C code (a lot of things don't need that, though it comes up somewhat often). And probably most people don't need to learn how to write procedural macros, though they are more likely to benefit from one or two libraries that do. And so on. Rust is a somewhat complicated language, which could be viewed as a disadvantage. But many of these features are critical for certain use cases or useful for creating good libraries, but are not things every programmer really needs to know (of course, knowing more is never a bad thing!).
and it's amazing. as are pretty much all burntsushi crates
In this case its copying the value. You can see that if you print out the variable address in each thread, like so: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=53e650bb91093a79fe691d21999cefc7](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=53e650bb91093a79fe691d21999cefc7) So why is that? You've specified move in your closure which, as per the book, "takes ownership". Its as if you had called a function say, fn my\_func(var: u64) like my\_func(a); my\_func doesn't see the same memory. To avoid the copy you could remove the move and the closures would attempt to borrow a instead, except you'll get a compile error because you can't borrow mutably twice for one thing, and another the lifetime of the threads might outlive the local variable. So you can make it static and allow the threads to see that variable as read only safely [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=ee05688de6fc048940f9df2f3fdaac4d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=ee05688de6fc048940f9df2f3fdaac4d) And mutably unsafely, which I haven't really experimented much with yet. To get shared mutability among threads requires Sync, so you can use AtomicUsize or Mutex in this case. [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=382237106ea3363e175fa40d552e6cad](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=382237106ea3363e175fa40d552e6cad) &amp;#x200B; &amp;#x200B;
They're working on a final list of blocker bugs? Does this mean that webrender is almost ready for prime time? I remember trying it many (10+) months ago and noticed that it was already surprisingly stable.
Can't you take the HTML and place it inside an SVG foreign element and render that to a canvas then turn that canvas into an image? It won't pick up third party content, but it works and it's been abstracted a few times as various libraries: https://html2canvas.hertzen.com/ Unless I'm missing the point of what you're saying...
So I haven't had time to write a test server to see, but I have a question: for UDP-based game servers, is it even worth it to use Tokio? If you have a game loop that just fetches all client packets at the start of a frame, runs a simulation step, and then sends the new world state to clients, how could a Tokio version improve things? Perhaps receiving and some light packet processing could happen in a thread pool so the main game thread doesn't have to spend as much time receiving, and the same for sending at the end of a frame, but otherwise I'm wondering if the complexity is worth it.
The same can be done with fuzzy testing, right? (well, modulo convenience stuff)
The goal isn't to find someone common. It is to find someone that knows what they are doing, and can actually do it. Knowing C means you know how to shoot yourself in the foot. Knowing Rust means you know how to keep your feet safe. It should go without saying, but knowing Rust is a huge plus on any programming resume, as it signals that the programmer is familiar with a number of best practices. We already have a lot of software written in Rust, so experience with Rust is a requirement if you're going to contribute and expand upon what we have. It's not a new development, so it's not going to change. Large code bases are a losing proposition in any language. C doesn't make it easy to reuse or share code, either. The C syntax is also incredibly outdated, so it's not capable of expressing logic as cleanly as you'll get with Rust. So yes, maintaining large or small codebases in Rust is easier than C.
That’s why I keep using it.
Re: how fast do you write Rust. I *feel* productive in Rust, and I think I write Rust as fast as any other languages, say C++, Java, Python, JavaScript, etc. On the other hand, completion curve? intermediate state? of Rust coding is somewhat different, and if I code my usual way Rust code-in-progress is probably not runnable unlike my usual Python code-in-progress. I believe (and to some extent I actually did) I can code Rust in a way Rust code-in-progress is as runnable, etc, as other languages, but I don't feel that's necessary. This is all subjective, it's not like I used stopwatch or even any low effort measurement of this. Probably I should. Re: Rust at refactoring. I am very confident that Rust rocks at refactoring. Subjectively, it is one of the largest win of Rust compared to other languages. No experiment backing, but the thing is, Rust is so good at refactoring that it provides *psychological safety* to you to attempt even larger refactoring you wouldn't attempt in other languages. Maybe I should be more confident when refactoring other languages and it will also work just fine and such successes will improve my psychological safety etc? I don't know, but confidence is a resource, and in my experience Rust is conductive to increasing this resource faster than other languages.
&gt; And once you realize how easy it is to implement Iterator for your own purposes, then you can play this composition game on the next level. I actually want this to be even more easy in Rust. I know it's a different problem, but ease of implementing iterator in Python with yield is spoiling. I know from reading code and my experience that trivial inconvenience surrounding Iterator implementation led me to write "inner loop pattern" where you receive callback and call that in loop instead of implementing Iterator.
He said the meme word!
I use `serde-traits`.
Good points. Integration with existing control flow integrity technologies seems immediately actionable and interesting, I am somewhat familiar with Clang's implementation, and since you work at Microsoft, can you suggest good documentation on MSVC CFI, especially not from user's point of view but integrator's point of view? Re: safe abstractions which needs to be implemented with unsafe. I think one good example is `take_mut`. As I understand, take_mut was verified by RustBelt. I feel there is (necessarily) a long tail here (as you pointed out, write-once initialization is one good example), and it doesn't scale to put everything in this category in std, but this category of unsafe uses is somewhat special and different from all other cases and in a sense this is a language/compiler extension(!) implemented in user library(!!), and probably deserves better curation.
&gt; "Unsafe needs justifying" seems like a pretty good rule of thumb to take full advantage of the features that Rust offers. Even for genius-level coders, I'd still like to see a justification of why unsafe is necessary, and to make sure it is as contained as possible. I 99% agree with this. I would just tweak it to "reasonably necessary" and "reasonably contained", where "reasonable" is a variable that changes depending on domain and intended application. But yes, I absolutely would like to see `unsafe` blocks' purpose and justification documented in comments as a community norm. Honestly, I should be better about this myself. &gt; So if I was considering an external crate for work, intentionally leaving it up in the air as you are -- saying that you're not specifically optimizing for memory safety -- isn't really satisfying. We'd like to know! Okay, but if that isn't satisfying for you, then _you probably shouldn't be using Ropey_. Right? That means your application domain is outside of Ropey's intended application domain. And what I'm trying to get at is that _this is a perfectly fine state of affairs_. Other people/projects to whom Ropey's priorities _are_ well suited can still use it. And you can use a different crate with priorities appropriate to your application domain. What is _not_ a fine state of affairs is if Ropey pretends to be appropriate for e.g. security sensitive applications, and then is used in domains that are inappropriate to the level of due diligence utilized in its development. Now, I can absolutely believe that maybe Ropey's unsafety disclaimer does a poor job of actually communicating what it's supposed to communicate. But I think the _idea_ of these sorts of indicators is useful, even if we as a community need to figure out what that should actually look like.
Yes, that used to work, but now there's a security feature that taints the canvas as soon as you render an SVG containing foreign objects into it. You can't export a tainted canvas to a bitmap. See [here](https://bugs.chromium.org/p/chromium/issues/detail?id=294129) for the Chrome bug about it.
Can you give an example of a pattern that is easy in Python but difficult or too verbose in Rust?
Yep. More precisely, a function that takes no arguments must mutate some form of global state to achieve anything useful. So the signature is deceptively simple. It some cases, a function like this might segfault because it relies on another function being called first to initialize some global structure. That said, commenting all unsafe code in a library wrapping a C library would be verbose and in many cases not useful. For instance in a Rust wrapper for `strlen` (not that that would be useful), I'm not sure what comment you could write that wouldn't just state what is obvious to anyone familiar with Rust's FFI and with what that function does. I guess something like this: ```rust // The library does not access the pointer after strlen has returned, so the lifetime here is valid. strlen takes a pointer to a C string which it does not attempt to free or reallocate and so our use of CStr is valid. The function does not access any global state, so the call is otherwise safe. ``` I can't imagine it would be very productive to have comments like this in every function of a library wrapping a C library. As usual with commenting, there's a subtle art to knowing exactly when a comment is needed.
Contrived example. In Python: ``` def filter(iter, predicate): for x in iter: if predicate(x): yield x ``` I think the key here is I don't explicitly define a struct Filter with two fields, iter and predicate. Once you have the struct it's pretty similar in Rust, but these "context" fields can grow larger than two. ``` impl ... Iterator for Filter ... { fn next(&amp;mut self) -&gt; Option&lt;...&gt; { for x in &amp;self.iter { if (self.predicate)(&amp;x) { return Some(x) ... ```
If you can't name the feature "serde" because you depend on the crate "serde", then how did cgmath pull that off?
Yes! Thank you. You said it better than I wanted to. Take (ha, pun...) an example of `take`. It is known why it is safe. It is also known why it can't be implemented without unsafe.
about the atomic data types, I think there's \`crossbeam\` (Docs [here](https://docs.rs/crossbeam/0.6.0/crossbeam/atomic/struct.ArcCell.html))
Sure, but it's basically deprecated, it internally uses a spinlock and clones the arc every time. I actually used it, but RwLock seems better and ArcSwap even more. You can read more about it here https://github.com/crossbeam-rs/crossbeam/issues/160
Thanks for the explanation
&gt; There is no such thing as a lifetime of a struct or a closure, there are only lifetimes of the references inside the struct or the closure. This is usually mostly true, but not strictly speaking always true. The most interesting exceptions that I can think of are the `Scope` and `ScopeJoinHandle` types in the `crossbeam` threading library. Those don't hold any references or even raw pointers. Instead, they're tied to a lifetime because they "represent" closures running on other threads, which might themselves have lifetimes bound to the current thread's stack. These sorts of cases are one of the reasons the `PhantomData` type exists.
I think I pretty much agree with everything here. Personal anecdote: it feels (I mean, it's me, not you) ironic that I am hearing this about drain and truncate (I mean, it's a good example! Nothing against that). One of my first contribution to Rust was (it was very different world then, there was no iterator yet, but conceptually) to let drain make use of truncate. I am not kidding. :) (You may ask what happened before. Before my patch, things were popped one by one, instead of using truncate to do so in batch, which is more efficient, but requires unsafe. Popping one by one can be done in safe.)
It does indeed mean that WebRender is close to prime time. :)
Proptest is pretty good too: https://github.com/AltSysrq/proptest
&gt; The topic of my post wasn't "is memory unsafety acceptable in some cases", it was "is risk of memory unsafety acceptable in some cases". And then, how do we communicate different levels of risk so that people can make informed choices about which crates they use? Thank you, thank you! This is, IMO, a much better formulation of the question. I guess I was the opposite of you, and considered my post in dispute but your question here as given! I pretty much support laissez-faire, anything goes policy to the question in terms of norm. I mean, I have my trade-off preference for my projects, but I feel I have no place to interfere for others. I think one way to explain my perspective is that as long as interface safety norm is firmly in place, any amount of "risk of unsafety" unsafe blocks is a strict improvement (at worst, equal) over what would be written in C, C++, etc. Safe interface is such a big improvement that if C++ users Rewrite It In Rust(tm) but with too many unsafe blocks for idiomatic Rust users' taste, I feel this is mission fucking accomplished, although he or she may need further assimilation, so to speak.
I don't see why you can't name it `serde`.
While a lot of unsafe in std is unavoidable (I am thinking of Vec (which includes Box), Rc, RefCell, etc.), also a lot of unsafe in std is done in the name of performance. I thought this were known, but now it seems to me, it is not. Some? seems to think most uses of unsafe in std is unavoidable. This can't be farther from the truth. While unavoidable unsafe is much more interesting and important, my feeling (I mean, I haven't done the count) is that majority of unsafe uses in std is avoidable. A good example is quicksort and mergesort implementation in std. I believe both can be done completely safe, but actual implementation is largely in unsafe blocks because that's faster. This is the right choice.
Okay, I think I understand. The lifetimes the caller can pass in are only one of its nameable lifetime parameters, or an anonymous one like "until the end of this scope"; it can't say "until half-way through your body".
&gt; I think one way to explain my perspective is that as long as interface safety norm is firmly in place, any amount of "risk of unsafety" unsafe blocks is a strict improvement (at worst, equal) over what would be written in C, C++, etc. Safe interface is such a big improvement that if C++ users Rewrite It In Rust(tm) but with too many unsafe blocks for idiomatic Rust users' taste, I feel this is mission fucking accomplished, although he or she may need further assimilation, so to speak. The problem comes with those of us who are migrating "down a level or two" from languages where, barring runtime bugs, the only source of unsafety is the FFI interfaces. For example, I'm working to migrate from Python to Rust primarily for the improved maintainability of having a more powerful type system.
My impression is people migrating from Python to Rust are not really people writing lots of unsafe blocks, but maybe I am mistaken? Yes, in that case, any unsafe block is significant step down in safety, but on the other hand, even that is probably significant step up in safety compared to, say, Python extension module written in C. Yes, I probably should think about this more.
&gt; At the most recent Seattle Rust Meetup I had a great conversation about unsafety with Ivan (don't know his last name, alas, but thanks Ivan!) and he had an excellent idea for Ropey that I think may be more widely applicable Oh hey that was me! Glad to be of some inspiration :)
&gt; Yeah, that's totally fair. In the case of Ropey, I don't think it would be much of a maintenance burden due to the nature of the unsafe code. In fact, in many cases I have slower safe versions already, against which the unsafe code is partially verified via property testing. But I certainly wouldn't expect any crates to do this, and you're absolutely right that in many (possibly most) cases it would be too much of a maintenance burden. Don't remember if we explicitly discussed this, /u/cessen2, but part of my idea for different backends is also the option of *allowing consumers* to potentially maintain/swap out their own backend (á la `HashMap` with its own specific hasher). Obviously this depends on the ergonomics of the specific APIs being exposed, but it does allow for the maintenance burden to fall elsewhere based on the consumer's priorities!
r/playrust
Blob is basically a `HashMap&lt;TypeId, Box&lt;Any&gt;&gt;`, and `map` pulls the arguments out the blob, passes them through the closure, and applies the returned changes.
I made a couple goes at starting with no lifetime annotations, and it seemed unavoidable. Anyways apparently it's [impossible](https://old.reddit.com/r/rust/comments/aebuh7/fiendishly_tricky_lifetime_problem/edp4dkt/)
You can use associated types to give a different concrete type for each implementation. Like: pub trait Op { type ScanIter : Iterator&lt;Item=i32&gt;; type FilterIter : Iterator&lt;Item=i32&gt;; fn scan(&amp;self) -&gt; Self::ScanIter; fn filter(&amp;self) -&gt; Self::FilterIter; }
&gt; Here the desugared version: Yeah, this actually does help a lot. Most of what I read about lifetimes so far seems to illustrate how to include the `lifetime-parameter` and while I eventually understood that it was distinct from the lifetime itself, I still couldn't understand how to express it. I now see that it's (usually? always?) implicit from the syntax and scope. The nested-lifetimes-blocks shown with `'x`/`'y`/`'z` clears things up. While I knew it was illegal to attempt to move data multiple times, I didn't picture the lifetimes that way. Aside: `move_x_twice()` moves in a coordinate plane but discussions of lifetimes in Rust often describe "moves" in terms of ownership. Was the ambiguity intentional levity? I found it a little confusing.
Heh, yes, goblin is somewhat panic prone, I should know, I am the one in [goblin fuzzing issue](https://github.com/m4b/goblin/issues/27). I feel being panic prone for goblin-like library is somewhat unavoidable, but it's just a matter of time(tm) with fuzzer to get it under control, and goblin's uses of unsafe for performance is pretty well thought out (especially scroll part, which got separated as library, but not all uses are abstractable like that).
Lifetimes aren't *actually* types but they are type-like. In type theory there's something called "kinds" (the type of types). A concrete lifetime, let's call it `'0` is a member in the lifetime kind whereas `true` is a member in the `bool` type which in turn is a member of the `Type` kind. Rust allows (parametric) *polymorphism* on both kinds in the language. When const generics land you will be able to promote existing types into kinds and constant expressions of those types into the type-level, e.g. `const A: bool` makes `bool` into a kind and `true` becomes type-like (but *not* a type!). Finally, we could make traits into a kind permitting polymorphism over them, for example with `fn foo&lt;trait T, U: T&gt;(...)` and `trait A { trait B; }` (an associated trait).
No need for typeclasses for QuickCheck. See Python's hypothesis for how to implement an excellent QuickCheck even without support from the (non-existent) typesystem. Hypothesis is arguably better than Haskell's QuickCheck. Especially about shrinking. Though that's despite being implemented in Python, not because. So the conceptual improvements can be back ported to Haskell and Rust.
Values are to types as types are to kinds.
Lifetimes are always implicit from the scope. However, with the introduction of non-lexical lifetimes it got a bit tricky. Also, renamed \`move\_x\_twice()\` to \`shift\_x\_twice()\`.
It's more a matter of "Python's ecosystem has a lot of pure-Python modules that I can depend on. Therefore, to retain that memory safety, I find or write `unsafe`-free Rust equivalents." As far as extension modules go, I never wrote them before I found `rust-cpython`.
For my use cases, I think it makes much more sense group any validation which could result in a panic into one or more "do the initial parse of..." methods which return `Result&lt;T, E&gt;`. That way, I don't find myself relying on my last-resort `catch_unwind` safety net as an essential part of the error-handling flow for untrusted executables. To me, that's a major code smell.
That's a great question and I think a good segue into the article. I'm guessing you didn't make it to about the midway point but I use tokio to break the execution into a receiving thread and a sending thread. That way you can broadcast at a consistent frequency (like 1/60s) without blocking the message handling logic. Of course, anything can be done without tokio but I believe it drastically reduced the complexity of the problem. As the title says, 150 lines of code.
&gt; C+Rust+kernel+BIOS+Debian packaging +willing to relocate to Denver I agree it's a tall ask. &gt; Surely, a person with all those qualifications would be able to grok Rust in a month? The danger with bringing someone in with no experience in a language is that they might not like it, or are just using the position as a platform to get paid to learn, and you'll wind up investing far more into them than what you get back. But Rust compounds this problem. The language is not simple, and it's not entirely clear that even after training them the developer will ever "figure it out." So it will be quite some time before the developer is productive, and in the meantime they will be a drain on existing resources because everything they write in Rust will likely have to be rewritten, or at the very least refactored.
[And have!](https://docs.rs/proptest/)
This is cool! I might end up using it myself. I [use a small Postmark Rust wrapper I wrote](https://github.com/ryanmcgrath/jelly/blob/master/src/emails/postmark/mod.rs), but it's not really full-featured. Nice to see alternatives. :)
Yes precisely :)
Because this feature also needs to depend on `cgmath/serde`, whereas cgmath's probably just is an optional dependency on `serde` itself.
&gt; I don’t really see how that leads to more safety. From what I’ve read it seems const generics allows you to take runtime checks and make them compile time checks (aka, part of a type constraint). For example, you could have an integer type that is guaranteed to be between [0,100) where, since that range is part of the type, it’s checked at compile. Thus you are using types to codify invariants, and therefore your code is more type safe. (I don’t know much about type theory so that’s my layman’s perspective. Please correct me if I’m wrong.)
or is there no such thing as reference collapsing in rust and im confused?
Arrayvec uses `serde-1`, which has the advantage of not conflicting with serde and also not conflicting with the `serde1` crate which will always point to serde v1.0 even if serde releases 2.0.
/r/playrust
Looks nice- glad to see more example projects for integrating rust into existing platform like mason. The only thing I would change here on the rust side is giving `libc` a specific version in `Cargo.toml` (`libc = "0.2"`). Even though it is stored in Cargo.lock, being able to safely run `cargo update`- to update patch versions- without breaking the project is nice. Even in an example like this, the code could break with the next major libc version, and the dependencies section is meant for indicating which major versions work. I'd say it's almost especially important in projects like this, since others will be copying the code and style? Sorry, got a bit out of hand. In any case, cool example!
If you are writing a binding to a header-only library like [nuklear](https://github.com/vurtun/nuklear), Sean Barret's [stb libraries](https://github.com/nothings/stb), you need a C build system, even if only to `#include` the header into a compiler object.
The repeated use of words i.e. helper helps helping helper to help itself help a helper.
It's so weird to read this and recognize the names of people who make cool graphics crates, like kvark and nucal, and realize "oh yeah, these are getting made for a *reason*..."
`no_std` protobuf is hard. Since `no_std` has many limitations, `alloc` is required for many features. Without `alloc`, you lose * Repeated fields (implemented through Vec) * Map fields (implemented through HashMap) * Recursive messages (redirected through Box) * string fields (without complex lifetimes though String) * bytes fields (without complex lifetimes through Vec&lt;u8&gt;) Even with `alloc` you lose standard map fields unless you want to use `BTreeMap`. So most libraries don't bother with it. It's just too difficult and has too many limitations to make it worthwhile.
An alternate option, in case the combined match expression doesn't work (like when you need to bind variables or use conditional guards): fn item_action(item: Item) -&gt; u32 { let eat = || { /* eat */ }; match item { Item::Rock =&gt; // throw away, Item::Apple =&gt; eat(), Item::Orange =&gt; eat(), Item::Kiwi =&gt; eat(), } } The closure gives you access to all of that function's local variables, and you can add parameters to pass any other info in.
How is that not covered by `foo.filter(|x| predicate(x)|)`?
You can use `:q`, ` q`, or just the esc key 
&gt; This is, IMO, a much better formulation of the question. Yeah, sorry, I could have been more clear. I've made a very small edit to my original post where I _think_ the confusion originated from. Hopefully that will clarify things for anyone reading later. &gt; I pretty much support laissez-faire, anything goes policy to the question in terms of norm. I mean, I have my trade-off preference for my projects, but I feel I have no place to interfere for others. I sort of agree, with two caveats: - I want people to be up-front about it for published crates. If I'm writing something security sensitive, for example, I _super want to know_ how much a crate cares about memory safety (among other things) relative to other priorities. I think this goes beyond unsafe code, of course. - I would like the community to err on the side of more safety. In other words, if something can reasonably be done safely then ideally it should be. And when I say "reasonably" here, I mean relative to the priorities of the given project. Of course, the reality is that laissez-faire is... well, the reality. Crates.io doesn't keep anyone from publishing an all-unsafe crate. But I think community norms can push things in a predominant direction. And that's what I'm hoping for the community to have a discussion about.
You can't
Thanks for the feedback, I declared the version now and I'll definitely keep this in mind for the future!
Ah, cheers! Yeah, in many ways out discussion prompted me to write this whole post. :-) Thanks again!
Oh, yeah! You did talk about that. It somehow slipped my mind--I suspect because it wasn't directly applicable to Ropey. But yeah, for certain kinds of crates that could make sense.
That's why it is a contrived example... Not all iterators can be defined by combining existing iterators.
Weird I’ve tried some examples and they all show a black square 
In any case in a no_std environment (presumably low power) maybe protobuf is an overkill? I would consider rolling a simple implementation that is closer to flatbuffers, than to protobuffers.
I use `quick-protobuf` in `no_std`. It requires unstable `alloc` and some tweaks (such as `BTreeMap` instead of `HashMap`).
Not sure what they meant specifically, but you could have a simple spinlock on atomics. If I'm not mistaken, the trade off would be increasing speed when not in contention, but wasting CPU cycles when in contention.
`no_std` is one of the most significant ecosystem split in Rust, and I don't know how to deal with it. Maybe we just need to suffer.
Someone mentioned QuickCheck, but there’s also PropTest (which is very nice to use).
I am trying to pipe something into my program and then ask the user for a line of text. Something like ``` $ cat animals.txt | cargo run $ Which animal do you like? $ panda $ Sorry, no panda for you ``` This is what I got (sort of) ``` let mut animals = String::new(); let stdin = io::stdin(); let mut handle = stdin.lock(); handle.read_to_string(&amp;mut animals)?; let mut raw_input = String::new(); println!("Which animal do you like?"); io::stdin().read_line(&amp;mut raw_input)?; let input = raw_input.trim(); ``` It works, except it hangs after reading the last line and I have to control-C out of the program. 
Async would make it easier to take the pressure off the main listener threads and to shuffle stuff around to a thread pool or two, meaning that you would get less dropped packets. Tokio and Codec Also you might normally have other async parts of your application, not just UDP, such as DB access, etc...
I wish you all the good luck, but that sounds... tough. The idea of doing validation before parsing is good, but usually you need to parse a little to do validation at all, and recursively so, because binaries are matryoshka dolls, so parsing and validation need to be interwoven. Maybe there is a good way...
Acquire and Release should be used to guard non-atomic operations after and before. AcqRel is just both. Here Relaxed is enough as threads don't perform non-atomic operations on shared memory.
This sub maybe should be named rustlang, or the other rustgame. :) 
How would you personally go about scaling this across multiple machines using Rust? I know it's a big and abstract question, but I'd love to hear the high level details.
Yeah I need to take a closer look. I think what I need to do is build a Future on top of UDP which emulates a virtual connection since UDP doesn't have that sort of concept. At the end though, I'm wondering if there are any performance gains from doing so, vs just have a single socket that fans out packets to a thread pool.
Ok, any frameworks do IoC, but the context inherits from the title of the thread is dependency injection. And, to me, in python, the Pyramid framework is a better example of IoC than Rocket.
Yep, after several years I know that getting my black belt will take a while. Fortunately much fun and profit can be had while still learning 
&gt; Looks like it's a) Google-backed, Nope, the usual: &gt; Disclaimer: Mundane is not an officially supported Google product. https://github.com/google/mundane
Please read subreddit description before posting (and do the same for any subreddit).
I'm confused, why is the `serde1` crate necessary. Isn't this the whole reason cargo has version specifiers?
Maybe this kind of problem could be helped by the addition of a couple of "badges" on crates.io? "Safety verified by compiler" and "Safety verified by {1,2,3..} prominent community members"? (According to some definition of "prominent") For minor crates, these badges would be hard to come by (without staying clear from unsafe) and users would pretty much have to verify by themselves, but for more common crates I guess it would be possible to find people willing to review?
Naturally. What I meant was that actions which currently result in a panic should either be done eagerly and returned as error variants on calls like `Object::parse` or deferred behind `get_thing()`-style substructure accessors which return `Result`. The end result being comparable to the `std::fs::File` API's use of `Result`. That said, I doubt what I write will be hugely featureful. I basically need to distinguish MZ, NE, and PE executables and extract embedded metadata, like the icon and application name.
Don't know about slack, but there is a discord community https://discord.gg/j5ShNT
The assumption is that when serde 2.0 is released, crates optionally supporting serde would want to be able to add support for v2.0 without dropping support for v1.0 (especially since dropping support would be a breaking change). But up until recent cargo and the `package` key, there was no way to depend on multiple versions of the some crate. So when serde 2.0 is released, crates like arrayvec can depend on `serde1` crate for serde 1.0, and `serde` for 2.0. I'm not 100% sure if this workaround is necessary with the new `package` key, but even if that also allows it serde1 could still be useful for any crate keeping compatibility with older compilers. Hope that makes sense?
Very much depends on the game I would say. For a lot of games, a single server can handle a single game instance very well (e.g. Hearthstone or DotA2), and you only need to make the game server communicate with other servers during start and end of the game. It's a bit different for open world MMOlike games. For those you usually have one/few server per spatial location in the game and then do a cellphone tower-like handoff between the servers. E.g. SpatialOS provides a engine focused on that functionality.
[There is](https://rust-slack.herokuapp.com/), though it's not nearly as active as the Discord server.
Cool, but wouldn't that require something like a proof checker like idris has? Because if you were building such types at runtime (based on user input for example), how would you check that they are always between 0 and 100 at compile time?
The current status is that intro-doc links only work on nightly, correct? Otherwise the tracking issue seems to be outdated.
Actually... I'm dumb. You *can* protect a buffer with atomics, but it might not help very much, or at all. With an optimal lock implementation, in the uncontended case, locking and unlocking should be one atomic compare-and-swap each. Using atomics directly to coordinate writes to a buffer also requires two atomic operations per write: one to get the offset in the buffer to write to (can be a `fetch_add`), one to confirm when the write is complete. Atomics would help more in the *contended* case, but that's not usually what we're worried about. In any case, the `Stdout` struct is currently defined as: pub struct Stdout { // FIXME: this should be LineWriter or BufWriter depending on the state of // stdout (tty or not). Note that if this is not line buffered it // should also flush-on-panic or some form of flush-on-abort. inner: Arc&lt;ReentrantMutex&lt;RefCell&lt;LineWriter&lt;Maybe&lt;StdoutRaw&gt;&gt;&gt;&gt;&gt;, } Since the FIXME's suggestion is not yet implemented, `Stdout` always uses LineWriter, which should mean that the buffer is flushed at every newline, even if stdout is piped to a file. Thus, `println!` needs to do a syscall, which I'd expect to be orders of magnitude slower than locking and unlocking. `print!` might not need to flush, but in most cases there won't be more than a few `print!`s per line. Therefore, I'm frankly confused how `stdout.lock()` could provide anything but a very small performance improvement in the first place. Admittedly, it does use OS native locking, which tends to have some overhead compared to an ideal implementation, but still – the syscall should dominate. It would make more sense for stdin, where you can read multiple lines with one syscall. For that case, it looks like libstd is on track to finally [switch to `parking_lot` for its synchronization primitives](https://github.com/rust-lang/rust/pull/56410); I wonder how much that will help. I'd like to see an actual benchmark... 
Makes perfect sense, thanks
Take my upvote. I wish every post on tech subredits had some article or post giving an overview of the significance of the submission. 
Thanks! This is the relevant comment by mundane's author I found: &gt; Ring is obviously a fantastic crate with a ton of users. We just have different tradeoffs than they do. For example, they're trying to move more towards pure-Rust implementations, while we're opting to be more conservative and stick with BoringSSL's existing implementations.
Yes, I think "essentially language extending" (defined as in something like [ Rust Distilled: An Expressive Tower of Languages](https://arxiv.org/abs/1806.02693), which gives Vec, Rc, RefCell in order; Things like `take` and `take_mut` crate belong here, and `rayon` is a big thing. As I understand RustBelt verified take_mut and rayon.) crates should be curated separately and formally reviewed. I expect we'd have something here in 2019.
Thanks!
Most people don't have English as their native language, but maybe you should consider using it for the crate docs, since it would make your crate accessible to more people.
Most crates make use of the builder pattern for such things. Anyway, I don't see the problem with just providing a `fn foo(mandatory: String, options: FooOptions)` and having FooOptions implement `Default`.
&gt; Even with alloc you lose standard map fields unless you want to use BTreeMap. How come `alloc` doesn't have `HashMap`, do you know?
`no_std` can also be an OS kernel, which would be expected to provide its own allocators. There is work on expanding `no_std` functionality, and it might one day be possible to allow `Vec` to be used in `no_std` with a custom allocator, but it has not been done yet.
Last time this problem was reported it turned out to be a bug with how the latest version of macos broke OpenGL loaders (glutin, SDL, etc.). WebRender itself doesn't create the GL context, it's provided by the embedding application. I haven't followed the resolution of this but we might need to update the outdated version of glutin used by the examples). You can enable webrender on macos in Firefox for example and I am pretty sure it will work (there's enough people in mozilla's gfx team using macos that we'd noticed if webrender in Firefox had this issue).
Don't be afraid to clone(). At least initialy. Code that does not compile can be bad for morale. clone() should get you out of trouble most of the time. 
There are other options, I think: * Use a lock-free structure for the stdout buf * Make the stdout buf thread-local, giving each thread its own independent one * Spin up a separate thread for the buffer and send to it through a channel. (This is a terrible idea, but it could be made to sort of work. Sort of.) I'm sure there are other possibilities.
Yes, because it requires a randomised hash function (security against DoS) which requires a random number from the OS. However `std` cheats on a couple of platforms and just uses a fixed seed, the choice to exclude `HashMap` from `core` is questionable. It could also be code size.
I don't like the current system. Library authors must go out of their way to support it, even if they don't need an allocator, and when they do, that's another crate with differences (e.g. `Vec` and `Box` are not in the prelude). IMO feature flags in `std` would be easier than the separate `core` lib.
&gt; In many cases compiler is able to derive the lifetimes on its own, but sometimes it is unable to and that’s where the developer needs to step in and annotate them manually. Additionally, it gives the developer a design tool, e.g. one can require that all structs that implement a certain trait have all their references live for the given duration, at least. I'm confused by the last sentence of this paragraph, could somebody clarify what is meant here? It sounds an awful lot like "lifetime annotations affects actual lifetimes", which I know to be false, so something else must be meant but I can't understand what.
Ah, I get you — working around Rust's restrictive memory management because it's sometimes easier to use pointers in algorithms, and you don't want run-time dereference checks. IMO you are half right and half wrong — there *should* be a better mechanism for checking `unsafe` code than just eyeballing it, however *memory* safety is only a small part of correctness, and for *that* we're still limited to eyeballing the code and running a few unit tests.
`alloc` doesn't have `HashMap` since `HashMap` uses `sys`for random key generation seen [here](https://github.com/rust-lang/rust/blob/729d3f07b4a6c558a7e86f1786a6905faddcfea8/src/libstd/collections/hash/map.rs#L3178).
I'm honestly a bit sad about the state of Rust stdio. In some ways it seems a step backward from C (!). * The C buffering options on a per-resource basis (unbuffered, line-buffered, block-buffered with a specified or default block size) are really handy. * The non-uniform treatment of Rust's stdin, stdout and stderr (each with their own datatype and interface) is annoying. * I don't know any way around the awkwardness with Rust stdio on file descriptors other than the standard ones. Here is [a crate](https://github.com/BartMassey/ptyknot) I wrote many years ago to deal with some of this. I don't know how much of this is still necessary; I don't know how much of it is right; it's full of `unsafe`. It definitely convinced me to not do anything clever with Rust stdio. Here is a partially-finished [RFC](https://github.com/BartMassey/rfcs/blob/master/text/0000-input-macro.md) I was working on about how to make some of the stdio stuff easier for new users. There's a proof-of-concept [crate](https://github.com/BartMassey/prompted) that goes with it. I should really finish this some day soon.
It's posts with titles like these that are annoying to stumble into in my rss feed.
The problem boils down to trust. Most Rust users trust the compiler to prove all code (outside unsafe) to be safe (according to the rust-interpretation of safe). The compiler is not free from flaws, but it's been thoroughly vetted, has a big heap of formal proofs and a significant amount of field-tests behind it's checks. No single human can be trusted to offer the same level of guarantees as the compiler does. Your code might BE safe, but how do I know? I don't even trust my own judgement here, so even reviewing the code myself won't build enough trust. The only way to trust unsafe code is for it to withstand review and field-tests. It would be nice if cargo had some support for this; only add/upgrade to dependency versions that has been significantly field-tested and reviewed. (Where having no unsafe code would reduce the requirement on tests and reviews) My own personal guideline for unsafe (outside of bindings which are pretty much throwing safety out the door anyways), is that writing unsafe code should include writing formal proofs for why my code is safe. If the benefit of the unsafe is not worth that time, I leave it be.
Thank you!
I think it just means having a bound on the struct. So the annotation does not affect concrete lifetimes of a type, but it affects typechecking such that only structs with certain lifetime bounds would compile. In other words, it affects the set of types usable with the trait, rather than individual types in that set.
You definitely need to tighten your atomics' orderings. `Relaxed` is not the `Ordering` you should pick when you're unsure, `SequentiallyConsistent` is. That is the only ordering that guarantees consistency across multiple atomics. In particular, without it, you could have a thread read inconsistent values of `len` and `last_node`. So, for instance, you might call `len()` on an iterator multiple times and see the same value, but get different `last_node()`s in that time, or vice versa.
Would you say... types are one of a kind ?
FWIW. The derive_builder crate is pretty good and know that you can do &gt; let opts = FooOptions { a : 2 , d : "ok" , ..FooOptions::default() }; And i think you're over generalizing your experience on 'realistic jobs' and misjudging complexity trade off when people are allowed to add optional arguments at will to any function. 
&gt; Until you get a million users and it suddenly turns into every month. The time above is for 3 billion ids every second…
After reviewing a lot of possible grants available in Sweden, I've found the following interesting, which is directed to **Swedish** and **German** companies who co-operate (Ping @FluffySupreme @Aspected1337 @ajpaverd @fgilcher ): &gt; Joint R&amp;D projects, focusing on developing innovative products and applications in all technological and application areas. Applicants are expected to develop products, technology-based services or methods which will in subsequent steps generate sustainable solutions with market potential and potential to address societal challenges. Basically, a catch-all grant. This application must be filed no later than 2018-03-13, giving ~8 weeks to write it. Anyone used to defining a SW-project, will do it in less time than that. Details is in https://www.vinnova.se/globalassets/utlysningar/2017-05562/omgangar/announcement_2nd_call.pdf893036.pdf with application form in https://www.vinnova.se/globalassets/utlysningar/2017-05562/omgangar/proposal_application_form_swe_ger_2nd_call_form.pdf893038.pdf - The form is 29 pages, although there is considerable amount of pre-written text, and "only" the first 9 pages must be filled out. It's basically nothing strange - all that information is needed to start any kind of project independent of funder - company or EU. 
You could propagate some restrictions with operations like `Bounded&lt;a, b&gt;(val1) + Bounded&lt;c, d&gt;(val2) == Bounded&lt;a+c, b+d&gt;(val1 + val2)`.
I recognize your first example. But i can not figure out the use of your second example. 
&gt;The Swapchain::new function is expecting references to the trait that Instance and Device implements. That's not quite correct, judging by the docs. The `new()` function is expecting a reference to a type that implements the `InstanceV1_0` trait. Rust doesn't collapse references (it does collapse dereferences though, so `*foo` is the same as `**foo`) so you should pass `instance` into `new()` and not `&amp;instance`.
There is no reference collapsing as in C++: a `&amp;T` is a always different type than a `&amp;&amp;T` or `&amp;&amp;&amp;T`. BUT, there is deref coercions, which are automatic "reference-level" changes in case where the compiler knows the target type exactly. So for example, if you have a `&amp;&amp;T` and pass it to a function expecting a `&amp;T`, it would automatically adjust the reference level. However, this does not work for generic situations where the compiler does not know the target type ahead of time. Eg, if you have something like this: fn foo&lt;X: SomeTrait&gt;(x: X) { ... } impl SomeTrait for T { ... } impl SomeTrait for U { ... } and you pass it a `&amp;T`, then the compiler will just see that there is no impl for a &amp;T and stop there. Hypothetically it could start searching for all impls that might apply if you change the "reference-level" in either direction, but this would be inefficient and potentially confusing/silently breaking for the user. For example, say you have these impls: impl SomeTrait for &amp;T { ... } impl SomeTrait for &amp;&amp;&amp;T { ... } and you try to pass a `&amp;&amp;T`. Given that every impl could behave totally different, it could get very confusing, or changes to your lib might break user code unexpectedly. --- That said, these issues already exist with normal method receivers to some degree. Eg, let x: T = ...; `x.clone()` will either call X's `Clone` impls that returns a new `T`... or call the generic `&amp;T` `Clone` impl that returns a cloned `&amp;T` if `X` does not implement it, which is often not what you intended. 
Rust does not collapse dereferences either, it just has deref coercions.
How exactly is this relevant to Rust?
What is the problem about inconsistency reads? It does not need to be in order it just needs to be atomic. A old value is as useful as a new one. Why is it a problem?
A type can belong to multiple kinds.
Nice find!
Because it isn't just about old and new. In fact, without sequentially consistent, old and new don't make sense. Consider this: ```rust fn foo&lt;T&gt;(i: vs::Iter&lt;T&gt;) { let size, last = i.len(), i.last_node(); let size2, last2 = i.len(), i.last_node(); if size == size2 { assert_equal!(last, last2); } } ``` That assertion may fail! Because the operations on `size` and on `last_node` have no defined ordering relative to each other. Looking at it in more detail, you have other subtle race conditions between methods, and they don't rely on atomics orderign. For instance, it's possible that, by racing another thread appending to the list, you can trigger this assert: ```rust fn foo&lt;T&gt;(i: vs::Iter&lt;T&gt;) { let last = i.last_node(); let first = i.next(); assert!(last.is_none() || first.is_empty()); } ```
`mod totally_offtopic {` couldn't help but remember a chapter from a ethics/politics book, "*in*voluntary servitude": [https://www.youtube.com/watch?v=oriwG5Xkim0](https://www.youtube.com/watch?v=oriwG5Xkim0) `}`
It's spam. The account has only three posts, to completely unrelated subreddits, all copies of this.
How come? There are lots of libraries or services for making screenshots of a webpage, e.g. https://stackoverflow.com/a/46243263 As for the Rust.. Sciter could do that, but it doesn't support JS websites (yet). I believe, Qt's browser should be able to do that, too.
This.
As a little aside, and to build upon what others have said, simple enums that are implicitly represented as i32s can be explicitly represented as other data types too, using the repr attribute: #[repr(u8)] enum Number { Zero = 0x0000, One = 0x0001 ... } This means that under the hood, each enum variant only occupies a single byte. Super useful!
Oxidized*
It's a homage to Discourse on Voluntary Servitude, the most famous work of Étienne de La Boétie. Not rothbard tho, please not rothbard lol.
I don't get why that's a problem. I will document that behavior on last_node. Thanks tho!
Thanks for the advice, I will try to translate the documentation this weekend 😂
All of them? They are "required" hence "must have". 
It seems they are looking for 50 years old nerd then.
Was expecting a post on borrow checker.
You can bind variables and add conditional guards using the `|` operator without any trouble: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5af5905983b7f0366806597c622ae2e1.
Because you locked stdin, it cannot be used until the lock goes out of scope. If you were to put drop(handle) right after handle.read_to_string(..), it would work. If you want to lock stdin, it might be better to get your animals from another function. 
Nice post, thanks for sharing. After reviewing the repo, your implementation seems similar to [IndexList](https://github.com/steveklabnik/indexlist). As for part 2, do you have a link to a full repository for this? I am having trouble seeing how this works within the Rust ownership model. How can you be sure that the `ListNode` which is pointed to in the `first` field of the `List` struct doesn't get freed? 
The issue is if you want to do something like `Variant1 | Variant2(data) =&gt; use(data) // or use(default) if it was Variant1`.
All of those either feature their own (very) limited renderer, or just use the one provided by Chrome. It would be nice to have one in pure Rust.
Maybe pick a library/program that you like and port it to Rust ? I would recommend to port something you have built yourself in order to be already confident on the topic you will be working on, so you can be able to focus your attention on writing Rust code. Can't say it works for everyone, but I am learning Rust this way currently and I am not struggling at all :)
Thanks for the review! I will think about it, I don't really care about that case`last_node` should just be documented to explain that, but the compiler reordering the API usage may cause other problems.
Mostly inherited from other compilers, e.g. gcc (and similarly clang) have `-O` be equivalent to `-O2`, but provide `-O3` above that.
This is an excellent article!
For my own small project I've created a fork of rmp crate which doesn't use any dynamic allocation, and works ok with serde_derive. I believe that `MessagePack` is much more suitable in embedded context than protobuf.
Author here, feel free to ask me anything about the project. Dness is currently only an MVP (minimal viable project). Dness does one thing: detect WAN IP through OpenDNS and update the appropriate records on Cloudflare. But already at v0.1.0 it has scratched my itch; solved a problem I had with the current array of dynamic dns clients, so I decided to release it -- not in the thought that dness will be some de facto dynamic dns client, but that if dness solved a problem I had, maybe it will solve others' problems. And I like it, I've deployed it on my windows machine, debian server, and I'll soon deploy it on an ARM-based router. The fact that Rust can deliver binaries to all these platforms is a major win. I know I'm in an echo chamber when I say this, but even in what may seem like crowded spaces I believe Rust implementations can carve out a niche and deliver features faster, safer, and to more platforms (people). Cheers to everyone; keep working on your projects!
I don't see how the first two would work. 1. The purpose of the lock is to make sure that two or more threads, writing to stdout concurrently, can't accidentally interleave the data they write at a granularity below individual `println!` calls. 2. Sooner or later, you have to reconcile the thread-local stdout bufs into the single stdout that the OS APIs provide you... and then you're either back to where you started or implementing your "Spin up a separate thread for the buffer and send to it through a channel." idea.
Using unsafe for performance seems a completely valid choice, same as is done in std. This means your code is going to get more scrutiny by people interested in safety, but that also seems fine. Even if you don't want to try to claim memory safety as a feature of your crate, it seems that you're not opposed to others putting in effort to increase confidence in the crate, so both the performance-focussed and safety-focussed groups may well get what they want in the end anyway. Thinking about the process that a company might go through to review a crate for their own internal use, it occurred to me that it might be useful to the author to hear that that review has taken place and the result. Obviously if someone reports bugs or offers PRs, then that is one way you'd hear and the crate would benefit. But when a review finds no significant problems, that could also be valuable information to share with the author, even if it's only informally. Perhaps simply publicly saying "we're using your crate" would allow people to look at a list and imagine for themselves what kind of review must have gone on. So whilst this isn't a direct report on safety, it does imply it.
ring also uses BoringSSL .
"lock free" in the sense of using atomics instead of mutexes, right? Not lock free in this way: https://en.m.wikipedia.org/wiki/Non-blocking_algorithm
Desktop link: https://en.wikipedia.org/wiki/Non-blocking_algorithm *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^231065
Never thought that we are only 2 having this problem ;)
There's a solid gitter channel.. why not ask them? https://gitter.im/solid/chat 
I loathe discord in general but it is where those wielding influence in the Rust community have considered more inclusive than IRC, which provides a far superior experience. IRC server is irc.mozilla.org and channels include, but not limited to #rust-beginners and #rust 
An unbuffered stdout would cause mixing of half-written lines. While this wouldn't lead to a crash, it is quite messy. (Technically, as long as you write less than 4k in one write, then you won't get mixed up output, but Rust often performs complex writes as a series of smaller writes.
Yeah that gets tricky, you can always fall to move your code in a function (exactly like your snippet, referring to the 'use' function): Variant1 =&gt; use(default), Variant2(data) =&gt; use(data), Depending on the particular case, you may get away with a closure so you don't need to pass extra context arguments by parameters.
Hey! At my knowledge there is no solid server in Rust. If you are interested to work on it, I've started an RDF/SPARQL database in Rust https://github.com/Tpt/rudf Solid servers heavily relies on SPARQL so there is definitely a strong overlap between the two projects. 
Yes, or if you want a conditional guard on only Variant2(data), but no guard on Variant1(data).
[https://www.jamestease.co.uk/blether/projects-to-learn-programming-language](https://www.jamestease.co.uk/blether/projects-to-learn-programming-language)
I would name the feature by what it does, instead of what crates it enables. So in this case: `--features serialization` (which depends on `serde` and `cgmath/serde`.)
It would be unblocking in the non-full case if you kept a pointer to the end, copy it, increment it, then CAS the updated value back to the pointer, then write the data into the previously reserved space. In the case that the increment overflows, then you might need to block.
Thanks for linking IndexList, I probably missed it because I implemented my own version some time ago, and only recently decided to talk about it. The major difference I can see between this library and my implementation is the trait hierarchy, which allows for writing generic code that can accept `Vec`, `VecDeque` and my `ListedList`. I like the Occupied/Free enum idea though. I have not yet implemented the list from part 2 for two reasons: 1. I am not confident in my abilities with unsafe. I know enough C++ to know that I know nothing and I have read enough blog posts to fear unwinding panics. 1. I am not sure if there is actually a legitimate use case for this list. I would imagine most people would stop reading at "I have no answer to the memory leak problem". As for your question, I am probably missing something. Since this datatype is theoretical at this point, let's say we have a list with one element: ``` { first: first_element, last: first_element, reclaims: [] } ``` If we delete the first element, we should have this image: ``` { first: NULL, last: NULL, reclaims: [first_element (with changed e_tag)] } ``` Now, begin and end will always give an invalid index, since it will point to NULL. Also, if we had an index on the first element, the e_tag of the element will have been changed, so the index operation will panic after dereferencing the pointer to first_element (which is still allocated). If we choose to call `shrink_to_fit` (or better called `gc`), first_element will be deallocated but the uuid of the list will change, so the index operation will panic before dereferencing the pointer. If I did not understand the question, I will gladly further clarify. Also, if I have done a mistake and my idea is unsound, I will gladly accept the consequences :) 
Lsd is an alternative to ls with prettier output. There are currently multiple pretty small issues that are decently beginner friendly. The maintainer of lsd is friendly and helpful, and will probably set you off in the right direction. one such issue: https://github.com/Peltoche/lsd/issues/40 If you don't know any rust though, i'd suggest reading the book, or at least the more fundamental chapters of the book first.
Whoops; I looked for that and missed it. Thanks!
Tried them and had to kill the terminal. Issue might be specific to my setup. Which is zsh, tmux on WSL ubuntu. Will give a try again.
broot is very new and there might still be bugs (some might be related to termion limits). So I'll appreciate any detailed report.
Does this mean, we can build html based cross platform GUIs for small rust apps easily?
&gt;you might be better using trait objects Why is better?
Implementing a linked list is a terrible approach to learning Rust. While something like that is easy to write in many other languages, that's just not true for Rust. If you want to fight against the borrow checker ever step of the way, feel free to continue, but you're better off writing toy programs. 
Trait bounds tend to get very unwieldy if you've got more than one associated type.
Very quickly a method named `then()` gets a name like [`then_with_fulfill_callback_and_reject_callback()`](https://rustwasm.github.io/wasm-bindgen/api/web_sys/struct.DomRequest.html#method.then_with_fulfill_callback_and_reject_callback). That's for only 2 optional parameters.
Please check out [Learning Rust With Entirely Too Many Linked Lists](https://cglab.ca/~abeinges/blah/too-many-lists/book/). This is probably one of those cases where you should use `unsafe` and wrap it in a safe struct (your `List`). Please note that you will be responsible for safe memory management (like in C). The borrow checker is great and keeps everything nicely safe without limiting you too much. The limitations are there unfortunately and they are pretty fundamental, the borrow checker can't solve everything so sometimes (pretty rarely in my Rust experience) you need to avoid it.
Is that any worse than `then(fulfill_callback: (), reject_callback: ())`?
Is there any way this could be turned into a warning, or even optimized away by the compiler? Or is inlining the only story for this kind of optimization and it's not happening in this case? (New to rust)
Main bug for Firefox: [https://bugzilla.mozilla.org/show\_bug.cgi?id=webrender](https://bugzilla.mozilla.org/show_bug.cgi?id=webrender) Blocking initial release: [https://bugzilla.mozilla.org/buglist.cgi?f1=blocked&amp;f2=blocked&amp;f3=blocked&amp;f4=blocked&amp;j\_top=OR&amp;known\_name=gfx-webrender-v1-p1&amp;o1=substring&amp;o2=substring&amp;o3=substring&amp;o4=substring&amp;priority=P2&amp;resolution=---&amp;v1=1386669&amp;list\_id=14493286](https://bugzilla.mozilla.org/buglist.cgi?f1=blocked&amp;f2=blocked&amp;f3=blocked&amp;f4=blocked&amp;j_top=OR&amp;known_name=gfx-webrender-v1-p1&amp;o1=substring&amp;o2=substring&amp;o3=substring&amp;o4=substring&amp;priority=P2&amp;resolution=---&amp;v1=1386669&amp;list_id=14493286)
Yea but I think they just want the user to not have to lock stdout himself if he wants to do performant writes to stdout.
Okay, that is actually the hunch I had. But if I understand what you are saying, then this should work: ``` let mut animals = String::new(); io::stdin().read_to_string(&amp;mut animals)?; let mut animal = String::new(); println!("Which animal do you like?"); io::stdin().read_line(&amp;mut animal)?; ``` But it doesn't. `animal` becomes an empty string, and the user is never prompted with anything in the terminal.
nice that you provide windows executables! thanks!
If it’s a singly-linked list, then it’s easy: ``` enum LinkedList&lt;A&gt; { Nil, Cons(A, Box&lt;LinkedList&lt;A&gt;&gt;) } ``` This is how most purely functional languages do it.
Right. That's why I'm asking -- is there a pattern, in Python, for creating an Iterator that is not based on an existing Iterator, where the syntax is more convenient than the same thing in Rust? 
Amazing and very useful! But english, please :)
I'm getting back into Rust after a year+ hiatus and I'm trying to refresh my mental model on how Futures (0.1) work (which is muddied by the fact that I've now used Futures in JavaScript, Swift, and Scala, as well as Rust...). So I have a function that will `and_then` a bunch of futures together and return the resulting chain. Let's say that these are all fallible database operations. So, *naively* I'd want to write something like this: fn sequential_ops(db: &amp;Database) -&gt; impl Future&lt;Item=(), Error=DatabaseError&gt; { db.op1() .and_then(|_| db.op2()) .and_then(|_| db.op3()) } But we all know that wont work because of the lifetime on the `db` borrow. So I'll write this instead: fn sequential_ops(db: &amp;Database) -&gt; impl Future&lt;Item=(), Error=DatabaseError&gt; { let fut1 = db.op1(); let fut2 = db.op2(); let fut3 = db.op3(); fut1.and_then(fut2).and_then(fut3) } And that should be correct, right? Specifically, if `db.op1()` **fails**, I'm guaranteed that `db.op2()` and `db.op3()` never start to execute, correct? Now, if `db.op2()` depends on the result of `db.op1()` (So, now it's `db.op2(x)`) I'm basically forced to clone my database object, or have the reference have a static lifetime. Is that correct as well? So I basically **have** to write something messy, like: fn sequential_ops(db: &amp;Database) -&gt; impl Future&lt;Item=(), Error=DatabaseError&gt; { let db = db.clone(); db.op1() .and_then(move |x| db.op2(x).map(|_| db)) .and_then(|db| db.op3()) } 
You can also do ```rust let empty = BTreeMap::new(); let x = opt_x.unwrap_or(&amp;empty); ```
Hi @maxfrai, I working in that, in some moments of day I publish the translation 😂
I'm not sure that a game counts as a "real world project", but… Github user KappaDistributive launched a 2048 game as a WASM webapp a week or so ago. It is intended as a project for newer Rust users to contribute to, and issues have been deliberately left open for them. I have contributed some to helping set it up, and it's kind of fun to play with. &lt;https://github.com/KappaDistributive/rs2048&gt;
Mandatory link: [*Learning Rust With Entirely Too Many Linked Lists*](https://cglab.ca/~abeinges/blah/too-many-lists/book/).
&gt; a problem I had with the current array of dynamic dns clients I'm curious to know what it was. For reference, I used ddclient.
This is what I thought too, but I didn’t realise there’d be a need for a Box. Why is that required in this case?
Yes. Python allows you to define iterators as class which implements next method, but you can also define iterators without class, without next method, using yield. I showed how above.
I would be very much in favor of named parameters but they aren't legal in current-day Rust. But in your example you had `foo_with_options(mandatory: String, options: FooOptions)` so if you want to be consistent it has to be `then_with_fulfill_callback_and_reject_callback()(fulfill_callback: (), reject_callback: ())`, which, yes, is quite long.