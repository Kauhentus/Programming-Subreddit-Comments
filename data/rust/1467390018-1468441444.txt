It *is* a library. Moreover, I suggest you look at the goals of https://pijul.org ;-)
Could be, feel free to write a patch!
GHC use to use darcs but eventually decided git had superior perf Note that pijul is a darcs like VCS https://pijul.org so the OP is rather deep into that VCS philosophy
Darcs has been around for a very long time. If you're a Haskell programmer, then it certainly isn't obscure. It's certainly lost favor over the years though. Migrating to a new VCS can be quite a lot of work.
For instance, it means you cannot implement the Vec module yourself (except by calling C functions).
Are you aware of how C++11 can do it with vararg templates? See [here](http://en.cppreference.com/w/cpp/language/parameter_pack), search for `tprintf`.
I knew that troll would come back, I hesitated about including it on the webpage ;-) 1. I would never write security-related code using git, because its merge algorithm is not based on any solid principle, and even has huge real-world flaws that can lead it to silently do really wrong things (https://tahoe-lafs.org/~zooko/badmerge/simple.html). 2. My limited brain can understand what it does (even though I'm not claiming I understand the full details of conflict handling). Just like Rust/Haskell/Ocaml are easy to understand because they're based on a solid theory, we believe darcs/Pijul are "the only option there" for us. 3. This choice is temporary anyway, because Thrussh was actually written as part of Pijul, which is a replacement for darcs. See http://pijul.org/faq.html, and feel free to ask more here.
Can you explain more of the rationale behind this project? What do you mean by "mutation points"? Are you comparing the sequencing reads of two samples directly? 
Things Ada has which Rust lacks * Range types for runtime checking of integer values, e.g. `type TDayOfMonth is range 1..31` * Pre and post conditions for runtime assertion checking - rust just has in-code assert macros * Support for object-orientated programming Things Rust has which Ada lacks * Compile-time checking for memory leaks: Ada uses manual memory allocation and deallocation * Compile-time checking for data-races * Compile-time checking of semantic types using "newtype" wrappers, e.g. `struct StreetName { asString : String }` and phantom types * Support for "protocol-orientated programming", as Apple devs call it Things which both have * Runtime bounds checking on string and array access. Essentially, Ada2012 has a lot of syntactic sugar allowing the easy, self-documenting, specification of runtime checks, but it has very few compile-time checks. I'm not sure it can still be called the most "safety-critical" of languages any more, even Oxygene - which like Ada is a Pascal derivative - has better [contracts support](http://www.elementscompiler.com/elements/oxygene/language.aspx#classcontracts). **Edit:** Just to be fair, as /u/llogiq [noted](https://www.reddit.com/r/rust/comments/4qs5sl/rust_and_ada/d4vleqn), there is a commercial extension to Ada called [Spark](https://en.wikipedia.org/wiki/SPARK_(programming_language%29) which uses static-analysis to check pre and post conditions at compile-time.
Would this make a reasonable basis for a secure distributed system written in Rust? Is it librarified in a way that I can easily tunnel arbitrary traffic through it and do authentication correctly? I've heard people lament before "why don't we just use ssh for everything?" since it's proven and anything can be tunneled through it. I'd like to create tools to help people build complex heterogeneous distributed systems in Rust, and one of the most important considerations is which protocols to use and how to make them secure.
&gt; I'm not sure about this. You seem to like git, but it is really complicated, and many people keep complaining about how hard it is to use. Eh this sounds like personal opinion. Rust is hosted on Git, as well as many other large popular projects. Many people find Git easy to use, once you settle into an everyday workflow. Just because some people do not prefer Git, shouldn't be a reason to not consider it. Too each their own.
* For pre- and post-conditions, we have [hoare](https://crates.io/crates/hoare). * It also would be possible to use [typenum](https://crates.io/crates/typenum) to write a crate that supplies ranged integer types, it's just no one's come around to it yet. * Object-Oriented Programming is overrated. There are precious little use cases that OOP handles better than algebraic types + judiciously applied traits. You also forgot Spark, which is an Ada subset with a prover to ensure correctness (to some extent) at compile time. Edit: why the downvotes? The OOP comment wasn't meant to downplay the benefits of object oriented languages, but the only benefit of OOP as currently practiced is inheritance, and most practitioners agree that it's best used sparingly.
Yeah, that's a big problem with the Rust community. You folks are awesome, but we're so few that those that do stuff have very little time.
Yeah, I'm using rustc_serializable at the moment, so I'll take a look at serde to see if there's any difference.
I'm not a fan of OOP either: I just mentioned in Ada's case as some might consider it a benefit, just as I mentioned "protocol-orientated programming" (POP) as a benefit for Rust. "Protocols" are what traits are called in Swift: POP is structs with traits, just as you described. I also focussed on the core language, which is why I didn't mention libraries but thanks for mentioning `hoare` which I hadn't heard of before. Incidentally `typenum` doesn't address the problem range-types solve. Range-types constrain variable numeric data at runtime: the Rust equivalent is a newtype `struct DayOfMonth { asInt :: i32 }` with a smart-constructor disallowing values outside 1..31. I knew about Spark, but didn't mention it since the questioner asked about Ada. Also I hadn't realised there was a free version of it. [It appears](http://libre.adacore.com/comparisonchart/) that if you used the free version of Spark your code must be GPL. 
This is cool. I've been looking to implement an SSH honeypot in Rust; this will be a good launchpad for that.
Nice! From the rust_gamedev reddit not_fl3 post: &gt; Rust gives great benefits - first of all its safety. Most errors are found and eliminated on compile time, its really great, especially for games! &gt; We used our own and closed-source at this moment engine, based on: * glium for OpenGL * sligtly modified nphysics for physics (bindings for a C++ library like Bullet3D would be extremely hard to make) * tinyecs (https://github.com/not-fl3/tinyecs, i build my ecs, now i maybe choosed specs insteed) * awesomium (bindings self-made in less than a day) for ingame gui; and imgui (imgui.rs bindings) for tools gui * ears for sounds * blender as game editor (Meshes, empty blender object with toml-file describing entity. All Exported with simple blender export script.) &gt; Team of five: 2 programmers, 2 artists (gui-designer, 3d-artist), and 1 game designer 
I just mentioned that twice, because I somehow assumed them to be libraries, trying to add them as dependencies to get their code. Nice work with thrussh! :)
&gt; I would never write security-related code using git, because its merge algorithm is not based on any solid principle, and even has huge real-world flaws that can lead it to silently do really wrong things So was there any effort made (by you or by somebody else) to improve the algorithm used by git and submit a patch? If there wasn't - why? If there was - why wasn't it accepted?
&gt; It also lacks tests and documentation. Is there any reason that you decided not to write tests for the project? The "old school" BSD projects like OpenSSH have some major barriers to contribution like that they're written in languages like C that are mostly esoteric by today's standards, and often unsafe to write by beginners in that it's easy to inadvertently introduce security problems. One of the most exciting things about projects like Thrussh is that they fully address that. However, another thing that makes the old BSD projects difficult to contribute to is that their test suites often leave a lot to be desired, so anyone not already deeply familiar with their workings doesn't have an easy way to check that they didn't cause regressions. Not including a test suite with any modern project leaves it susceptible to the same very high bar for contribution as its predecessor.
Ah right I forgot the conversion to a `i32`. Sorry about that. The stack overflow you're experiencing is probably due to [those 3 lines](https://gist.github.com/lhecker/1472ed7491472ac68cb25e73a4037fba/a97ac5f65e8595cde22a52d6193eb268985d329d#file-main-rs-L15-L17). Here I'm basically constructing those 2D-arrays _first_ on the **stack** and _then_ **move** them into a Box, by passing them as the first parameter of `Box::new()`. If you compile this with `--release` this 2-step approach should "actually" be optimized away and the data should be constructed directly on the heap (i.e. inside the Box). Did you compile it in release mode? The reason I'm using a `Box` together with arrays instead of a `Vec` (which would never cause such an error), is because I wanted to write it as `array[x][y]` instead of `array[x * SIZE + y]`. I'm going to change that now though. **EDIT:** I've fixed the example. :)
&gt; Compile-time checking for memory leaks What? We have RAII, but I'd hardly call that a "memory-leak checker".
The only way to do it currently is as `tt`. An RFC was recently accepted to add a new `lifetime` matcher, but it hasn't been implemented yet.
Thanks for the quick response and the insights :) You are right, I didn't compile with --release, works fine now.
&gt; Pre and post conditions for runtime assertion checking There are also several other nice Ada features designed for correctness, like subtype, a nicer iteration on enumerations, enumerated types as array indexes, and Static_Predicate: http://www.embedded.com/electronics-blogs/industry-comment/4405929/Using-Ada-2012-to-say-what-you-mean I'd like ranged integer types and few other such things in some form in Rust. The unit of measure types of F# is another nice safety feature: https://en.wikibooks.org/wiki/F_Sharp_Programming/Units_of_Measure
In Crystal variable (splat) arguments are packed as a tuple in the method argument. For example: def foo(*args) args end result = foo 1, "hello" typeof(result) # =&gt; Tuple(Int32, String) Making varargs be tuples is very convenient and type safe, as one can forward them between methods. We do something similar with named arguments: one can captured them with `**args`, and their type is a named tuple: a tuple where every key and its type is known at compile time. But since Rust requires type arguments in every method, I don't know if that's doable, probably not...
[AUR link](https://aur.archlinux.org/packages/servo-latest/#news)
If you aren't afraid of assembly and nightly you can [use this crate](https://github.com/kmcallister/syscall.rs) Effectively you'll write a function wrapping a call to an unsafe function which *prepares* the stack frame for the OS to intercept. It's worth pointing out that *The Native C* `write` symbol isn't a direct system call but a call to GNU's libc (on Linux, on *BSD it is a call to their libc) which does some magic to ensure everything on the OS is speaking the same language to the kernel/each other.
Trying to learn more about the Rust Macro system. I implemented a basic scanf *like* macro. Calling it scand because it uses the `Debug` trait to convert values into strings. It doesn't offer *all the features* of scanf. It's a semi-limited (only 11 args, 10 inserts) `format!()` except the base string argument doesn't have to be known at compile which fulfills my needs. https://github.com/valarauca/scand/blob/master/src/lib.rs
Cool, great job! Does libsodium or anything down the chain end up depending on openssl/libressl?
To clarify my comment regarding Range types, I am quite sure one can write a type generic over the Range (using typenum to specify the bounds) whose operations ensure keeping values within the range at runtime, as Ada does.
In particular, it's been raised that GCC did some auto-vectorization that LLVM did not.
&gt; It also lacks tests and documentation. I second the astonishment; seems strange not to have tests...
If anyone starts implementing this, I do have the foundation of a binding to [gssapi](https://github.com/erickt/rust-gssapi) that I someday need to spend more time on. I'd love any help in finishing it!
If your intent is to use the write syscall, rather than the libc wrapper on the syscall, you should check out this example from the syscall crate https://github.com/kmcallister/syscall.rs/blob/master/examples/hello.rs
Not happy at all :/ I implemented the exact same logic in Java and on my machine both implementations (Java and Rust) take ~7.7 seconds.
There are a couple of open issues that you could work on right now (see [this](https://internals.rust-lang.org/t/roadmap-to-rls/3628/4)). I have been experimenting with the compiler on this front (I wrote a PoC refactoring tool) so maybe I can help you if you get lost.
Thanks for this! I am now going to try darcs :) BTW, I would love to see a blog post on the progress on pijul! I saw the following on the website, but I guess it needs to be updated: &gt; No precise release date is planned, although a working prototype should be ready at most in June 2016.
Servo has a less sophisticated version of units of measure using phantom types if you're interested: https://blog.mozilla.org/research/2014/06/23/static-checking-of-units-in-servo/
Servo should have used Flatpak :) edit: someone has volunteered! https://github.com/servo/servo/issues/12102
`mem::forget` 😉
I would argue that inheritance is not the heart of OOP, but that instance methods are. eg. `Dog.bark()` is more important than `Dog extends Animal`
&gt; allowing the pointer to be in the middle of the struct that's probably a poor way to phrase this then
This is the problem with applying labels such as OOP and FP to languages: there are as many definitions of these concepts as there are practitioners. 
This caught my attention as well. The numerous security vulnerabilities that are routinely found in projects written in safer higher-level languages is a very clear indication that memory safety is not the only route through which a system may be compromised. To say secret leaks would never occur would require a much stronger argument than the usage of a memory-safe language. I would love a provably secure ssh implementation, but I suspect that this is not it. Would love to be proven wrong though.
There's been a bunch of improvements lately, and a metric-ton of helpful comments, issues, and contributions. Bash tab completions is a big one that was just completed, hot off the press. As a demo, I compiled `rustup` with this feature, which generated [this tab completion script](https://gist.github.com/kbknapp/09a37f2fce306573040ea0500e3b1408). [Here's a short demo of it in action (GIF).](http://i.imgur.com/icbrIYe.gif) As always, if you're willing to give this feature a shot and report any/all bugs and improvements it's much appreciated! I plan on looking into ZSH completions next, as that's the shell I typically use. So if anyone has any ZSH completion experience, stop on by ;) If you're looking for a project to jump in on, I'm always willing to mentor people on issues. Edit: I forgot to mention, although not shown in the demo, these completion scripts also support things like when only specific values are acceptable in a given option. i.e. imagine an option `--editor` which accepts either the values `vi` or `emacs`. The following completion would happen: $ prog --editor &lt;tab&gt;&lt;tab&gt; vi emacs $ prog --editor em&lt;tab&gt; $ prog --editor emacs
I haven't looked in detail but ndarray is often cited. http://bluss.github.io/rust-ndarray/master/ndarray/index.html 
I look forward `clap-rs` can generate manpage, because `fish` use manpage generate autocompletions.
Right. There are tests in the form of thrussh_client and thrussh_server. Unit tests are not completely trivial to write, since there's not much to test without seeing full and encrypted messages.
My attempt is called Pijul! It trickier than just a patch, unfortunately. Correctness and performance at the same time require some investment :-)
Thank you for the reply. I have changed it to: '${workspaceRoot}/target/debug/project_name' But still no luck. No big deal for now!
There are three main places I go to keep up with what is happening in Rust: General ideas: https://internals.rust-lang.org Compiler changes: https://github.com/rust-lang/rust Language changes: https://github.com/rust-lang/rfcs
Awesome. This is the #1 thing I keep missing in the various tools I wrote using Python and argparse.
In the mean time, have you tried `help2man`? That's how I normally generate my manpages.
[Linus wrote](http://www.gelato.unsw.edu.au/archives/git/0504/2182.html): &gt; And it looks like 99% of SCM people seem to think that the solution to that is to be more clever about content merges. Which misses the point entirely. Darcs' killer feature was supposed to be its [patch algebra](http://darcs.net/Theory), allowing it to make more intelligent decisions about merges. If Pijul is supposed to be a spiritual successor to Darcs, I'd guess Git people would also disregard it as 'missing the point entirely'.
If any want's to know what happens if you try to use the "Alternative python": from __future__ import braces SyntaxError: not a chance 
This is an excellent article, because it enumerates many of the problems that a novice Rust coder might encounter. It also did a good job at putting me off trying Rust entirely! My jaw dropped when the final proposed solution to fizz buzz was something like 30 lines with an enumeration and a custom formatter. Even the initial stuff with having to treat static and normal strings separately seems a bit crazy - it's a lot of conceptual load for solving problems that seem like they should be trivial. Anyone more experienced with Rust than me care to step in and tell me why this is wrong?
You can only deallocate in unsafe code in Ada. RAII and pool management are also an option and aliased types need to be explicit. 
The final solution is excessive for fizzbuzz; the original solution is probably the best. The point of this blog post doesn't seem to be to explain how to write the best fizzbuzz, but to explore common pitfalls of Rust using fizzbuzz as the example. &gt; Even the initial stuff with having to treat static and normal strings separately seems a bit crazy - it's a lot of conceptual load for solving problems that seem like they should be trivial. Rust is dealing with a much more constrained memory model than most languages. If you want a growable string, it has to be allocated on the heap; if you want an immutable reference to a string which is allocated somewhere else, you need a different type from that heap-allocated growable string. This is complex, but its essential complexity, not incidental. Other languages solve this by making a lot of assumptions for you and doing a lot of tricks. This works for those languages but Rust is specifically designed for a different use case. C, which has essentially the same memory model, has the same problem, but instead of providing a coherent set of types in the standard library, it drops the mic and walks away, which is why you'll see large C codebases with half a dozen (or more!) different string types.
There's also [collenchyma](https://github.com/autumnai/collenchyma), the compute backend developped for the Leaf ML project by AutumnAI. Unfortunately AutumnAI stopped development on Leaf, leaving it to the community. It's still there, and may be another place to work on.
Using [clippy](https://github.com/Manishearth/rust-clippy) on your code gives you some automatic advices, often making you learn good practices on the way.
But only in libraries (currently)
It does indeed only work with modern ssh software, although many things are generic enough that other crypto algorithms can be added.
This is a almost certainly a completely wrong approach. You want to have a fixed number of threads (in a thread pool) communicating over channels, not creating threads to respond to an event. 
The article was trying to make a point with the overly done direction that it went in, but to be honest I feel like the examples started becoming too contrived and it went too far off track from the original premise of "there are 2 kinds of strings so watch out for that." I can't blame you for being confused by it. But either way, one definitely doesn't have to dive *that* far down the rabbit hole just to implement FizzBuzz. It's much easier to just do something like this: fn main() { for i in 1..101 { match (i % 3, i % 5) { (0, 0) =&gt; println!("Fizzbuzz"), (0, _) =&gt; println!("Fizz"), (_, 0) =&gt; println!("Buzz"), _ =&gt; println!("{}", i), } } }
Great article, didn't know about `Cow`.
There are [smart-pointer libraries for Ada](http://www.adacore.com/adaanswers/gems/gem-107-preventing-deallocation-for-reference-counted-types/) like there are for C++, but like in C++ they have the problem that the compiler doesn't check they're being use safely. Further, they're not part of the standard. Rust by comparison uses lifetime analysis to ensure RAII is used correctly - tho Rc can still leak - and Box, Rc and Arc are a part of the standard language. Additionally Rust takes a much harder line on null-safety - aliases in Ada are nullable by default, whereas null pointers/aliases simply don't exist in Rust. Therefore I think it's fair to say that the core Rust language does a better job of ensuring memory is managed appropriately than Ada 2012. To be clear, I spent 3 years working as a Delphi programmer, and liked Delphi very much, and toyed with Ada off and on; however I do think that Ada is a product of its time, and the fundamental way the language represents data limits what it can do. 
Thanks for your quick response. Okay, I'll try to explain you the context. I'm programming a turn by turn game. Currently when it comes the turn of the computer to play, the time during which the AI runs the interface is frozen. Therefore my naive idea was to execute the AI on a parallel thread and simply wait that it ends by checking his status in the main loop. I'm using glium to do opengl, and as you can see [here](http://tomaka.github.io/glium/book/tuto-01-getting-started.html) the way it works is with a main event loop.
Some would argue that there are more definitions than practitioners. But that's probably splitting hairs.
1°) I just want the effect of the write function. 2°) Do you mean the libc cargo ? I want to know if rust can do it himself without binding. (Sorry for my bad english)
whats the best way to archieve that with rust?
Tagged unions &lt;3 =)!
Sounds like you should use Futures for that instead: http://carllerche.github.io/eventual/eventual/
My Java is a bit... "rusty" (Ha! Pun intended!), but I came up with [this](https://gist.github.com/lhecker/0d39cbe3de7666e49480585378fc54bd). This takes about 10.1s, while my Rust version takes about 5.5s (and the C one 3.6s). Are you sure your Rust and your Java version are using the same bit-width (i.e. both 64 or both 32 Bit)? My version for instance assumes the 64-Bit version for Java. If I replace the `long`s with `int`s it's about as fast as the Rust version, but such a comparison would not be fair, since then Java only has to churn through half the memory. 😉 Furthermore I wouldn't downplay Java. That language and it's VM consistently gets a lot of hate and is really underestimated, while it's actually one of the fastest VMs there is. As such it doesn't really surprise me that Java is only about 3 times slower than the (baseline) C version.
Running servo in a VM without hardware acceleration was an order of magnitude slower than running firefox in the same VM - is non-webrender just not optimised at all yet? Resizing all did very strange things, showing uninitialised graphics memory, and scrolling around the page. Also ran servo natively on several macbooks, and scrolling was completely broken in all cases (this also happened in the VM). Scrolling would just do nothing, although very occasionally it would randomly jump to somewhere on the page.
Do you mean the `libc` crate? It doesn't just wrap raw syscalls, it also provides C FFI, which is pretty much required if you want to do anything even remotely complicated.
Why re-implement what already exists, is tested, and maintained by someone else?
Nice, the method *is_ready* is what I need. Unfortunately I don't know how to create a Future into an iteration of the loop and get it result in an other iteration. To put what I say into code: for i in 0..2 { if i == 0 { // create the Future } if i == 1 { // access to the Future } }
Maybe for less binary size? Let link with libc only those who use FFI.
Because those libraries are extremely good, stable and well tested, and there's no reason to reinvent the wheel?
libc is not just syscall wrappers, you know.
Fizzbuzz here was just a tool to explain some newbie pitfalls by deliberately deciding to drive through all of them. The actual FizzBuzz in Rust is simple, you just have a match with print statements, or use the `let result = ` solution with `.to_owned()`, or perhaps `Cow` if you like performance. The custom formatter was probably just fun overengineering :)
The formated binary looks like this: \0\0mp3 \0sound/campaign/op07\0 sound1\0\xff\xff sound2\0\xff\xff \0sound/campaign/op08\0 sound3\0\xff\xff \0\0flac \0sound/hq\0 sound4\0\xff\xff I think I would use something like (pseudo code): file = many0!(level1) level1 = chain!(tag!("\0\0") ~ t: tag ~ many0!(level2)) I let you make the others levels ;)
I think it's enough to read each release note (once each 6 weeks), and only use stable releases. They are posted [on the Rust blog](http://blog.rust-lang.org/).
Just in case anyone ever really wants to do it: There's a (non-portable) pthreads API to try joining on a thread handle. I wrapped it in a Rust library here: https://github.com/badboy/thread_tryjoin-rs
Libc is traditionally dynamically linked. It is not present in the binary.
If the changes are not breaking, you can just ignore them. 
I actually expect (and would like) to have Rust stick with the 6-week model for the next years. That's because of [Rust stability guarantees](http://blog.rust-lang.org/2014/10/30/Stability.html), which is an ongoing process to prevent code that works on 1.x to break on 1.x+1. That way, upgrading Rust isn't like upgrading from Python 2 to Python 3, but like upgrading from Python 3.4 to Python 3.5. To make this feasible, the Rust team tests new versions on the whole Rust open source ecosystem published on [Crates.io](https://crates.io/) with a tool named [crater](https://internals.rust-lang.org/t/crater-plans/2206). If your code is open source, you get the benefit of having your codebase tested for compiler regressions at each update, and I would expect the Rust developers to take action if your code breaks (either work with you to fix your code in the new version, or hopefully minimize breakage). Well, this is my expectation as a user of Rust (you may want feedback from some Rust developer in case I said some nonsense). But it's also possible that, after some years of churn, Rust also adopt some "LTS" releases that are supported for some years, to cater your needs and the needs of large companies. In this sense it would be similar to Linux, Firefox or Chromium releases: those projects also releases a stable version once 6 weeks, but also support a number of long term versions (actually I'm not sure about Chromium). I don't know of any plan to do this, however. It's also possible that, in some (hopefully distant) future, a Rust 2.0 is released that drops support for all "deprecated" APIs. For me this would be a disaster unless a tool can automatically fix programs to the use non-deprecated APIs, and crater indicated that it has minimal breakage on the Rust ecosystem. I've seen some languages deal with major breaking updates in a terrible way, so I'd prefer to not have it unless it's a sure thing. --- Here's a (totally random) guess: Rust will only slow its pace of development if an alternative compiler is developed (for example, a verified compiler written in Coq!). Then developers could find useful to be compatible with all Rust implementations, and breaking updates would be more dangerous (unless synchronized between all implementations).
no PR to rustup now,? go go go 
I don't think Reddit lets anyone change links once they're posted.
It's being discussed in issue #278. But you can use the gist linked above to get completions for the current version of rustup ;)
[Here](https://www.reddit.com/r/rust/comments/2j2gne/why_your_first_fizzbuzz_implementation_may_not/) is the original discussion when the article was published in 2014 (and [here](https://news.ycombinator.com/item?id=8446923) on HN). It's nice to see it's still applicable in 2016 - it was written even before Rust 1.0 was released. (reddit doesn't find the previous post because the OP links to https:// and the original thread links to http://)
clap-rs was already awesome, but it keeps getting better and better! Thanks to you and all the contributors!
I'm pretty sure the entire point of FizzBuzz articles is to push a writer's weird random over-engineering principles.
Rust changes very incrementally. Big changes are announced widely when they're stabilized, and less widely at earlier milestones as well.
About named arguments, a convention is to make a struct with the arguments and pass it as parameter. One can even have optional arguments by using the [`Default`](https://doc.rust-lang.org/std/default/) trait. Perhaps Rust could adopt a syntax sugar for named arguments that just convert them to a struct at compile time. For example: #[derive(Default)] struct Point { x: i32, y: i32 } fn draw_point(p: Point); // explicit call draw_point(Point { x: 10, y: 10 }); // syntax sugar for the above draw_point(x = 10, y = 10) // explicit optional parameter draw_point(Point { x: 10, ... Default::default() }) // syntax sugar for the above draw_point(x = 10) Actually. This could be a RFC.
On Windows Rust barely uses libc, also known as the CRT. It uses nothing more than the basic memory manipulation functions such as `memcpy` and friends (mostly because LLVM injects calls to those functions). As a result, you could very easily remove the libc dependency on Windows since most of libstd is already built on top of Windows API.
pijul seems really cool, though cargo install pijul only shows 0.1, whereas the documentation seems to imply that 0.2 is the latest 'stable' version. Care to update crates.io so that 0.2 gets installed on cago install pijul?
But rust runtime need know how to work with C runtime, which dynamically linked. Right?
&gt; Anyone more experienced with Rust than me care to step in and tell me why this is wrong? Part of Rust's reputation for being difficult to learn is that it's really poorly suited to the sort of exercises people like to do when they're learning a new language. The C programmers seem to want to implement data structures and run [directly into the borrow checker deep end](http://cglab.ca/~abeinges/blah/too-many-lists/book/) while the scripting developers tend to want to make web servers (ecosystem is immature, it's semi-tricky) or do basic coding challenges, which runs into Rust's safety first mentality. This falls into the latter category. A language's ergonomics are heavily determined by it's core community of library writers. As languages, Python and Javascript aren't that different in terms of expressiveness / features but the experience of writing programs in the two languages is very different because the philosophy of the library writers is different. As a language, Rust has elements of C and elements of OCaml / Haskell with the ownership system tossed in the pot. What makes writing code in Rust very different from its parent languages isn't the borrow checker but rather the Rust community's focus on safety and control. This philosophy hits the one-off / throwaway problem domain of basic scripting exercises exactly the wrong way. As an example, take the basic starting point of reading a file line by line. This is a one-liner in most scripting languages. The simplest way I know to do the same thing in Rust: use std::io::prelude::*; use std::io::BufReader; use std::fs::File; fn main() { let file = File::open("some_file.txt").unwrap(); let mut lines = BufReader::new(file).lines() .map(|x| x.unwrap()); while let Some(line) = lines.next() { println!("{}", line); } } Going through it: The three imports are about control. Rust is low level enough that some people really do want to implement their own file reading using the underlying syscalls or their own buffering system. The `File::open` is typical but has several things that can go wrong. We're completely ignoring these with `.unwrap()` because we're doing this scripting style but the errors that I know about are: file not existing and the file name having an encoding error when getting translated from utf8 to the underlying OS string format (think emoji). There may be more errors. In older versions of Rust, you had to turn the string literal into a `Path` and handle the potential encoding error as part of this process. Lots of control, lots of safety. With our file handle, we're now wanting to a `lines` iterator. The underlying operating system call doesn't care about the contents of the file and doesn't let us read by line, so we need to buffer it so we can consistently read lines. Some people might want to control how this happens by writing their own BufReader, so you have to set it up explicitly (control!) instead of having your scripting language's runtime buffer behind the scenes. When fetching the next line, the iterator can fail in two ways: there's some sort of a read problem from the disk, which we're ignoring with `.unwrap`, and the file not having a next line (e.g. empty file), which we're handling with the `while let` destructuring. That's a LOT of decision points for an operation you've never really thought about (at least I hadn't). They're very much in the way for building a throwaway script to count the number of unique words in a file and you have to deal with all of them before you can get anything to run. This is terrible, why would anybody write in this crazy language? If you flip your mindset and imagine you're now writing file opening code for the Dropbox client and this is going to run on millions of people's computers. The one-in-a-million chance of something going wrong... will go wrong. Would you rather have the library designers and compiler point out where things can go wrong while you're putting the system together or figure it out yourself through months of debugging intermittent failures sent in as tickets from annoyed customers?
The very existence of a link with dynamic libraries increases the size of the binary compared to nothing dependencies?
I find it unnatural because _it's not how people describe the problem._ When I describe fizzbuzz, I say "if the number is divisible by 3, print fizz. If it's divisible by 5, print buzz" etc. I don't say "if the tuple provided by the remainder of the number divided by three and the remainder of the number divided by five is equal to tuple that starts with 3, then print fizz, otherwise..."
/u/protestor makes good points, but I would suggest something in addition. Try to build some basic web services in Rust. There's two ways that this helps: * example code * finding ecosystem weaknesses In the first sense, having existing web apps that we can point people to to show how things are done is great! It doesn't need to be a full tutorial or anything, but "A Twitter clone in Rust" or "Facebook in Rust" or whatever would be instructive to a lot of people. And the second ties into this, and the sibling comment. By doing so, you'll probably find some rough edges; that will point you to how to contribute. Some library is missing? Make a crate! Something's not ideal about a library that exists? Send a PR!
It's gifv a different format that loads better and has other improvements.
I actually think that dynamic linking might be implemented by the OS. Even if not, it represents a very small portion of libcore, and it is far more important than whatever miniscule space saving removing it would grant 
A dynamic library by definition shrinks binaries, because it doesn't require the library to be a part of the binary. Static linking everything would create larger binaries, not dynamic. 
Rust newb here. Started going through the rust book and trying out the examples.
You're indeed right about that. Compiling the C code using clang-3.6 does indeed yield similar results to Rust. I honestly wouldn't have thought that this is the case. In hindsight it's obvious, but I always thought that LLVM is actually better than gcc in autovectorization etc., but it seems that this is not the case.
&gt; "Fizz", even though it is treated as a reference, still has to be allocated in memory somewhere. Therefore, there's no performance penalty in this case to tell the compiler to treat them as owned strings as well. This isn't correct. String literals compile down to pointers into your binary's rodata. An owned String requires a trip to the system allocator and a memcpy of said string literal (unless the optimizer rewrites your whole program).
5/10, code concretely specifies numbers and strings are involved.
This is fantastic!
The easiest way to use it is by far with the cargo command: cargo install clippy cargo clippy
I actually wrote something to do bash completion for generic python scripts using argparse. Probably not nearly as clean as this, but I'll look for the link.
Thanks. :)
Every six weeks or so there is a new release of Rust, which you can read to see if any new additions were added that you might find useful. Breaking changes effectively never happen, especially given that the compiler will present warnings a few Rust versions in advance. I find that even though I develop exclusively with the nightly releases, all the code that I write still works with stable 99 times out of 100.
My only regret is that I have but one upvote to give.
What I do when I'm in a situation like yours is insert a statement like "let () = phi.renderer;" right before the error, which will tell you the type of phi.renderer when you try to compile it. You can then look up the methods for that type in the docs.
Here you go: https://bitbucket.org/johannestaas/pybashcomplete/src/bfdd8a010e55?at=master It only works for single python scripts, which it parses at runtime. It's a fun PoC but not much more at this point. It parses a python script at runtime.
I'm always looking for help and feedback with [Tera](https://github.com/Keats/tera/) (template engine similar to Jinja2/Django). Otherwise, looking at what i'm using and missing in Rust would be: - https://marshmallow.readthedocs.io/en/latest/ -&gt; the validation bit, but it would probably require being a compiler plugin to be nice to use - good third party libraries: for example there are 2 stripe libraries on crates.io but they don't seem ready for use I also think that when Hyper release its async-enabled version, we will see lots of activity/new web frameworks popping up (I know I will do one). That also depends on the kind of web dev you are doing: SPAs, traditional websites etc
You can always require `From&lt;u8&gt;` or something similar. I haven't tested I would expect it should get optimized away. Edit: It does indeed get optimized away in release: https://is.gd/w7J4b8
No one asked, but I'll explain it at a high level anyway :) In linux dynamic linking is implemented as part of glibc. ELF files define an interpreter. During `exec` the kernel finds the elf interpreter and loads that giving it the name of the program that was provided in the `exec` call. The elf interpreter (often known as `ld-linux.so`) then loads the program and its dependencies. The elf interpreter basically calls `dlopen` and `dlsym` for you before calling `main`. While glibc isn't part of the kernel, I would still consider it part of the OS as it's a basic system service that nearly every userland program is going to depend on. 
Would it be feasible (or desirable) to incorporate collenchyma on rusty-machine? It can run on CUDA and OpenCL as well as the CPU, sounds like a win.
Iron seems stalled, which is a pity. Maybe see if you can help push that forward?
I'm working with new developers of the rust-metrics library. Attending a tech conference for jsoncdc which is probably going to change format very slightly. I'm thinking about anomaly detection tools, and possibly going to start a prototype anomaly detection tool which sniffs logs, telemetry, chat and alert systems for correlations https://github.com/posix4e/rust-metrics https://github.com/posix4e/jsoncdc
The size of a binary is slightly bigger when calling a function from a dynamic library than when calling a syscall directly. However the size of a binary is typically _much_ smaller when calling a function from a dynamic library versus calling a function that is statically linked in. On non-windows platforms libc often does a lot of work on top of what the syscalls do, so by using libc we're actually reducing binary size by not having all that work statically linked into your Rust binary. On Windows we can't use syscalls since they are unstable, so we use the best thing we can which is Windows API. We don't use libc on Windows because it is objectively worse than working with Windows API directly. Really though, the size of the import tables in your binary to be able to use dynamic libraries is _trivial_ compared to the space taken up by your actual code. So avoiding dynamic libraries in the name of saving space only works in obscure code golf to get the smallest possible binary. In nearly all real world cases however there is no savings to be had by avoiding dynamic libraries. 
For stdout and stderr, flushing does... [nothing](https://github.com/rust-lang/rust/blob/master/src/libstd/io/stdio.rs#L85). It's all down to the buffering behavior of the console.
You could do something like `bool isDivisibleByThree = `... Then it starts to look closer to the rust solution, but without the cleverness :P
It seems to me that Rust will be useful in the long term, just not the short term.
&gt; Your example is really not that bad at all. Outside of the unwrap()s (which I assume are similar to try/catch) and the fact that you can't just iterate a file object directly, it doesn't seem too far from a scripting language. The Python version would be this: with open("some_file.txt") as f: for line in f: print(line, endl="") that's the entirety of the script, so Rust does have a fair amount of overhead, though I don't understand why /u/grayrest manually iterates the file, or imports `prelude::*` instead of just `BufRead`, or maps Result::unwrap instead of just unwrapping lines in the loop, this works fine: use std::io::{BufRead, BufReader}; use std::fs::File; fn main() { let file = File::open("some_file.txt").unwrap(); let lines = BufReader::new(file).lines(); for line in lines { println!("{}", line.unwrap()); } } 
If you are intending to use `malloc_buf` as an example which highlights the same issues npm, your point is not clear. The only thing which is clear about your point is that servo has a deep dependency chain. Whether or not this deep dependency hierarchy is a problem, and why it could be a problem, is not clear from your statement. Note: I'm not asserting your statement is incorrect or trying to cast doubt but to my eyes, whatever point you're trying to make isn't clear because you haven't provided enough details.
Note that `malloc_buf`, `objc`, and `objc_foundation` are all maintained by SSheldon, while `clipboard`, `constellation`, and `servo` are all maintained by the Servo team. (The latter two are both part of the main Servo repo.) The fact that we've split our code is divided into self-contained modules doesn't necessarily mean our efforts are fragmented. Or, to turn this around: What benefit would there be to combining, say, malloc_buf + objc + objc_foundation into a single monolithic crate?
That's a big chart.
Hey um, how exactly are you measuring this? I was curious, so I ran the bench on my machine, and I haven't gotten results like that. gcc C version has not been 2x faster, and clang is pretty much equal. Actually, they're all performing pretty much equally. My CPU: "Intel(R) Core(TM) i7-4720HQ CPU @ 2.60 GHz" [Rust benchmark code](https://gist.github.com/peterdelevoryas/15a8f2a20b8311e31be75ee9f43627f0) [C benchmark code](https://gist.github.com/peterdelevoryas/999e5d0ed537c5496c4648649fb5bf3f) I used the same code as you, I just added some time measurements around the matrix multiplication and averaged ten measurements. [terminal output (times in seconds)](http://imgur.com/SoS5xSN) Edit: I realized I should also add the compiler versions I used: gcc 5.3.1 clang 3.8.0 rustc 1.11.0-nightly Edit 2: Also, just in general, why was a naive matrix multiplication function used as a benchmark to compare 2 systems languages? The code generated by Rust and C is going to be practically identical, except for the case of gcc. If you want to compare languages, shouldn't the program be a little bit more complex?
[removed]
I personally think `Default::default()` is ridiculously long even for it's normal purpose. There needs to be a really short way to write that for all uses. Something that's still grep able, but is short and easy to type. It seems odd to use `=` instead of `:`, since you use `:` for the struct literal syntax. But I'm just nitpicking, I like the general idea. There really ought to be sugar for defining such a function too, not just calling it.
That is interesting, thanks.
Sorry for that. It's kinda hard to put my thoughts about this into words... But I tried to give a more detailed explaination to /u/mbrubeck's question above.
I've seen cases where Clang is faster than GCC and cases where it is slower.
Considering I just finished an encoding table for x64 instructions it's a bit too late for that. (I'm restricting myself to instructions which are valid in long mode, aren't part of any SIMD extentions, do not require privileges, no floating point or xmm/ymm registers for now). This keeps it manageable. 
It would be nice if you tested out your iron applications on https://github.com/SethDusek/uwsgi-rust/tree/iron and maybe implement chunked bodies edit: It would also be nice if somebody could update the readme.md. The entry point function needs to be updated to the new pub extern fn application() -&gt; Box&lt;iron::Handler&gt; and also the usage one
One major difference between the Rust and JS ecosystems is that Rust has a fairly good standard library (not quite "batteries included" like Python, but much more complete than something like C), while JS is one of the only widely-used languages today with basically no standard library (beyond a handful of built-in types and functions). So in Rust, as long as the standard library is well-managed, then we should expect it to act as the common ground where most truly widely-applicable functionality ends up, eventually. In Rust we don't need `left-pad` (joke crates aside) because `std::fmt` already implements that functionality. In fact, a lot of the most common smallish crates today (`time`, `num`, `crossbeam`, `rand`, `tempdir`…) contain former standard library code (or replacements for such) that was removed only because it wasn't ready to be stabilized at the time of the 1.0 release. Eventually many of these should become unnecessary as new std APIs are stabilized.
Yeah and including those features into the stdlib is actually the opposite of modularity and exactly my point: not every dependency graph has to be as large as servo's just for the sake of it. Why not bundle functionality together which belongs together (for whatever reason)? The problem now is though that I believe your impression about npm might be wrong: Most modules aren't things that are simply missing in Javascript's "stdlib", but rather very small seemingly atomic parts. The problem here though is that those parts are actually subatomic, because "atomic" parts traditionally imply that you stop splitting as soon as you don't have a reason for further splits anymore. Some very vocal devs though push for modules which are as small as possible, albeit in my personal opinion this a very very bad idea for the already stated reasons. As such I believe that the "vocal devs" of the Rust community might have a much greater influence on this than the quality of the stdlib.
You should report them to the mods; that's completely unacceptable.
You can also deref in the for pattern for &amp;n in u32_slice { ... }
I wish there is a graphql library in rust ;) It's somewhat on my todo list for quite a while. 
There are quite a few bindings lying around so you can use those high performance tools within rust. But I agree that more native support would be awesome. I worked pretty hard on the linalg components of rusty-machine. Sadly getting native HPC is a pretty huge and daunting task - definitely needs a big community effort. I'm hoping if I pull the linear algebra out of rusty-machine it might be able to rally a few people to improving it! And as for SVD specifically - I also really want it! It opens up the door to lots of improvements and new algorithms I currently can't use. Sadly I need to figure out some eigendecomp bugs before we can get it into rusty-machine.
Yep, I made my site all SSLy with Let’s Encrypt a couple of months ago. I did update the article a few times for Rust compatibility; the language definitely wasn’t stable when I first wrote it. But the last content update was in May 2015 for Rust 1.0.
`.chars()` yields unicode codepoints and is currently only implemented for UTF-8 strings. `OsString`s and `CString`s can contain non-UTF8 values.
You're looking for /r/playrust
I should add that you'll need a nightly Rust to use clippy.
Not UTF-8, but UTF with non-zero.
You can convert it to vector and call `.iter()`. For Unix the required trait is [here](https://doc.rust-lang.org/std/os/unix/ffi/trait.OsStringExt.html). For Windows I guess there is a similar trait which allows conversion to `Vec&lt;u16&gt;`.
Fun fact: `vec![T; N]` [doesn't construct an array on the stack at all](https://github.com/rust-lang/rust/blob/master/src/libcollections/macros.rs#L45-L53). The `vec!` macro will call [`std::vec::Vec::from_elem()`](https://github.com/rust-lang/rust/blob/master/src/libcollections/vec.rs#L1110-L1116) (which is an internal `Vec` function).
I have yet to see subatomic crates on crates.io. The closest to this I can find in Servo's deptree is stuff like https://crates.io/crates/ref_slice, but there's very little of that, and I think that's okay. Especially since it encapsulates an unsafe operation. The vast majority of Servo's deptree are crates belonging to larger units all maintained by the same group (Servo, or someone else) as Matt mentioned. So while the dep graph has a bunch of crates, it really is just one unit that you are pulling in; just broken into reusable crates. 
Not UTF at all actually (in the sense of valid UTF): Windows OS Strings can contain unpaired surrogates which is illegal in UTF-16, or in decoded codepoints (they're properly defined as "UTF-16 code units without NUL" or "UCS2 without NUL and with surrogates) and Unix/POSIX OS Strings are just non-NUL bytes, no encoding is defined or asserted (and while the system locale can contain an encoding, as far as I know it's not contractual to any API) 
Can I make a comment about tutorials like this? I love them, I do. But there's one thing I want to see more of: *explicit type declarations*. Now I *know* Rust is *smart* and can *infer* types. That's great. But ever since I started programming C I've always been *as explicit as possible* and it is even more important when I'm reading a tutorial so I know *exactly* what to expect at every stage. E.g. the following code for i in 1..101 { let x; let result = if i % 15 == 0 { "FizzBuzz" } else if i % 5 == 0 { "Buzz" } else if i % 3 == 0 { "Fizz" } else { x = i.to_string(); &amp;*x }; println!("{}", result); } ... could be written as: for i in 1..101 { let x : String; let result : &amp;str = if i % 15 == 0 { "FizzBuzz" } else if i % 5 == 0 { "Buzz" } else if i % 3 == 0 { "Fizz" } else { x = i.to_string(); &amp;*x }; println!("{}", result); } The advantage is that, as a reader, you know, without doing any mental gymnastics, that `result` is a `&amp;str`. Further, when you compile this, you will be immediately told by the compiler if your type assumption was wrong.
I think there is a misunderstanding here... My "main theme" in this discussion is: &gt; I really truly hope the Rust community will find a good balance between code duplication and modularity as to not have the same issues as for instance npm has. As you can see I don't even say that it's the case right now! How should I do that anyways? Doesn't cargo only have 5343 crates at the moment? With so few crates it's kinda hard to make some actual examples of something I'd consider misuse of the system, like with npm. Albeit you could say that packages like [`ref_slice`](https://github.com/steveklabnik/ref_slice/blob/master/src/lib.rs#L2-L31) or [`malloc_buf`](https://github.com/SSheldon/malloc_buf/blob/master/src/lib.rs#L8-L61) are already things I believe should probably not be part of a publically accessible module system. For only a few very trivial line of codes they are again at the mercy of the author doing the right thing and I believe this a bad trade off. I personally hope that cargo won't have too many crates like this in the future, because npm has those and it's annoying. In the end this is basically a discussion about development style, which is quite subjective and personal. I hope you can understand that.
[removed]
&gt; Furthermore this code is so extremely trivial it is not. It is unsafe code, which ideally application writers should never have to use directly. One of Rust's principles behind unsafe is that you wrap a safe api around it once, and then forget about the unsafety as you use this safe wrapper everywhere. ref_slice is the system working as intended. You want to minimize unsafe code being scattered around libraries and applications, you want it to be tightly wrapped in tiny crates or modules that can be verified at a glance and reused. In general for non unsafe crates I don't see tiny things croping up. Like I said, I looked at our deptree and that was the only tiny crate I could find, and it has a reason for being tiny. The other example is the void crate, but that is because the hyper authors have split up `unreachable` into bits, but they are all one unit, and used by hyper. Though I'm on my phone right now and can't check.
Neither does `OsStr` on POSIX. But it's useless on both when passed to filesystem API.
The problem is that the Rust `libstd` is intentionally very conservative with stability and does not have many utility functions. There was supposed to be an "stdx" effort that curates all sorts of useful utility crates, but I am not sure what happened to it (ask @brson). 
Yeah, I can imagine making that sort of thing toggleable. It makes sense that newcomers won’t yet be familiar with these sorts of things, and I probably hadn’t thought about that enough. When it comes to Rust conventions, though, the convention is to omit types locally if possible unless there’s a very good reason not to.
I'd be happy if browsers just had sane viewing controls for images. Zooming out an image should not cause every page on the same domain to *also* be zoomed. *That's just silly.*
&gt; How's your anwser any better than my opinion? Right, my opinion is that it is not trivial. Note that I did back it up with the raison d'être of that crate; explaining that Rust explicitly prefers unsafe code to be abstracted away in tiny crates or modules. There is a very good reason why that crate is tiny. I agree that in general tiny crates are bad, but in my opinion tiny crates for unsafe code in Rust are okay and are explicitly encouraged by the language. Note that `unsafe` in Rust is a much more complicated deal than "hard to implement" in JS. There is a lot of nuance involved with unsafe code, and there is even [a whole separate book](http://doc.rust-lang.org/nomicon) for writing unsafe code. &gt; Even a beginner in Rust could easily come up with that code. No. It is unsafe code. I would not recommend a Rust beginner write unsafe code, even if it looks obvious. There are non-obvious pitfalls that come with unsafe code in Rust (e.g. noalias). Writing unsafe Rust code is different from writing C code. _This_ unsafe Rust code is correct but it is very very easy to come up with incorrect unsafe code as a newbie. Just the yesterday I pointed out to someone giving a talk that their obviously safe wrapper around unsafe code was in fact not safe. `unsafe` is complicated. &gt; I can only recommend to read this article or the comments on HN I am well aware of that article and the left_pad incident :) I do not feel that Rust's ecosystem will be that prone to such incidents due to the lack of tiny crates (and a tendency to avoid them). This may change in the future, but so far so good. Node's tiny package issue was in there from the start, basically, because Javascript was missing lots of things. &gt; And yes I know that there are many of your opinion, but there are also many of mine. But who has the right to decide who's right? I am also of the opinion that tons of tiny crates are bad; you seem to be laboring under the assumption that I disagree with you there. I don't :) However: - I think that tiny crates for `unsafe` code is a good thing - I don't feel that Rust is going down that path. Time will tell :) I do agree that slice_utils would be a better thing to have. But I don't agree that `ref_slice` itself is a problem (because of unsafe). It can be improved, but it is ok as it is too.
I have a feeling that the whole rust web ecosystem is paused and waiting for something. I guess it's hyper's mio branch. And I still believe the rust web guys need to sit together for something like WSGI, Rack or Ring. We need a common Request / Response API to standardize interface between Web server and web framework. After that, the community could focus on different part and improve in parallel. 
Thanks for the help! I completely forgot that `u32` implemented the `Copy` trait. Is any one of these more idiomatic than the others?
Ah, I thought it was through Reddit mail, not email.
You want to post this on /r/playrust
You want to post this on /r/playrust
I meant the Ada2012 standard C++ like Ada, still allows a use after free, even if you use RAII. In Rust the borrow checker prevents this. Steven Klabnik demonstrated this in [an article on issues with unique pointers](http://www.steveklabnik.com/uniq_ptr_problem/) which was in turn discussed in [greater detail by Franklin Chen](http://conscientiousprogrammer.com/blog/2014/12/21/how-to-think-about-rust-ownership-versus-c-plus-plus-unique-ptr/) The following C++ code will compile, but segfault when run, despite the use of unique pointers and RAII #include &lt;iostream&gt; #include &lt;memory&gt; using namespace std; int main () { unique_ptr&lt;int&gt; orig(new int(5)); cout &lt;&lt; *orig &lt;&lt; endl; auto stolen = move(orig); cout &lt;&lt; *orig &lt;&lt; endl; } However the analoguous Rust program refuses to compile. fn main() { let orig = box 5i; println!("{}", *orig); let stolen = orig; println!("{}", *orig); } RAII and unique pointers are not sufficient to prevent leaks. Lifetime analysis and borrow-checking, which Rust has, prevent _all_ possible leaks that can happen using unique pointers, and all leaks that can happen from use of RC other than reference-cycles. This is a significant advancement on compile-time leak-detection compared to the facilities offered by C++ and Ada.
&gt; is a bit conflicting. I mean that it is ok the way it is. If there were more such things I am for putting it into a ball of a larger crate (with the unsafe stuff all segregated in modules), but that does not mean that the status quo is _bad_. So `unsafe` rust code is worse than C code, which is the issue here. It often is fine, but very easy to mess up if you don't know the exact rules the compiler interprets your code with. Trying to write unsafe Rust code as if it were C is a very bad idea, for example, and that is what I would expect most newbies to do. It often works; but is a dangerous way of going about it -- there's a separate set of rules and you need to be careful about them. A newbie knowing this is fine, but a newbie who is not aware of this can end up producing dangerous code. I'm aware that people can write code in C without things going boom, and that it's not too _hard_ to do it in Rust either, just _different_, and you need to be aware of the differences. The fact that these differences exist is not necessarily well-advertised, so I wouldn't expect newbies to know about them.
Well, not as written, above. The behavior depends on the remainders mod 3 and 5. You have to read the whole match to know that it depends only on divisibility.
Rust's borrow checking is designed to prevent stuff like use after free. It does nothing to protect against memory leaks. C++ has the exact same capabilities in that regard. Can you demonstrate an example of C++ code exclusively using RAII and smart pointers which leaks memory where the equivalent Rust code wouldn't? I don't think you can.
You might find such traits in https://crates.io/crates/num. I'm not sure why they aren't in std though, but it might be because of stability guarantees they didn't want to make, or they don't 100% like the current design.
The destructuring based solution `for &amp;n in u32_slice` is the most idiomatic for `Copy` types. `.cloned()` for types that are just `Clone`.
Unfortunately num doesn't seem to have a trait that exposes the wrapping operations. I really wish they would. It would make my RNG library a little bit easier.
OK it's a *little* more information at the top of the match than just divisibility (considered as just a boolean), but I think the point stands...
&gt; the convention is to omit types locally if possible unless there’s a very good reason not to I've never understood this mentality. Surely it increases the probably of *programming by coincidence*. Explicit programming gives you the advantage of double checking yourself, first by showing yourself you think you know what you're doing, and secondly by having the compiler either agree with you or conclude you haven't quite got it right. Finally it saves the reader of your code from having to search some distance from your declaration to find out what type your variable is going to be. I think that's just being nice.
I know some people that are waiting for impl Trait as well. Something like Rack would be good, but we shouldn't copy Rack directly; it's got some design flaws. Common interfaces are hard.
Ah, I have another function print_vector but I didn't include it because it comes after v.push() so I didn't think having that in the code would change how v.push() works. Here is the function: fn print_vector(v: Vec&lt;i64&gt;){ print!("["); for i in 0..v.len(){ if i != v.len() - 1{ print!("{}, ", v[i]); } else { println!("{}]", v[i]); } } } 
FYI, you can get the exact same output as your `print_vector` function with `println!("{:?}", v)`. Also, if you want a function to borrow a `Vec` but you don't need to push to it, you can often take a slice instead, which is more flexible for the caller (they can pass just part of the `Vec`, or even other things that aren't `Vec`s), and leads to fewer pointer indirections: `fn print_vector(v: &amp;[i64])`.
Thanks! 
From the [nomicon](http://doc.rust-lang.org/stable/nomicon/working-with-unsafe.html): &gt; unsafe does more than pollute a whole function: it pollutes a whole module. Generally, the only bullet-proof way to limit the scope of unsafe code is at the module boundary with privacy. So if `unsafe` is risky/tricky to get correct and it pollutes everything, encapsulating it to minimize the damage seems reasonable. Then everyone can use it and go on their way *safely*. Regardless, you may still disagree. From the design standpoint: * tricky things are often misused * subtle things which implicitly change rules aren't always obvious to everyone You may be a completely competent and knowledgeable programmer but not everyone is. Some are very competent technically but when it comes to programming, they haven't had the time/guidance/patience/expertise to do things properly. To give an example using `VB.NET`, I ran into someone using [`SyncLock`](https://msdn.microsoft.com/en-us/library/3a86s51t.aspx) statement (lock something so you have exclusive access) so incorrectly that it didn't do anything properly. Every time they'd call synclock, they'd call it on a different object so their exclusive locking would never work when things from different threads were trying to get exclusive access. They were doing this because `synclock` is the statement you use to get exclusive access and their call passed the type checker and compiled. The designer of synclock could never have predicted that it might be abused in this fashion. The Rust designers are well served to assume Rust will be used improperly for various reasons and so they should do all they can to mitigate such issues. BTW, the fact that there is disagreement over whether something is trivial is irrelevant. Triviality is in the eye of the beholder. When you call something trivial, everyone else in the room who *does not* think it is trivial might just think you're arrogant. Not everything is obvious to [everyone](https://imgur.com/xIJksNO). Even if it looks trivial, it might have hidden complexity many would not recognize.
Question for whoever knows the answer: is moving the methods to a trait a breaking change?
There are many people who are not fluent in English but are still capable of making technical discussion. With /u/hiceki it's difficult to tell what's lost in translation &amp; what's being misunderstood My opening comment, which was an aside, was made in reflection of their responses throughout this thread. If they aren't fluent in English they need to slow down to digest what's being written to them Ignoring that there's difficulty in communication in a plead to politeness will only leave the confusion implicit
The culprit here is that you are in a loop. Which turns the function call after `v.push()` into a function call before the next `v.push()`. ;)
The reason this matters even though it comes after is because you're inside a loop. The first push goes through, but for every one after that print_vector (before you fixed it) has taken ownership of `v` and you can't push to it.
What is a valid replacement for the `char_range_at` function that was deprecated in 1.9? I've been trying to do it myself to no luck.
Replying to this convo but more towards the beginning than the end for visibility reasons. The primary reason I made ref_slice was that it was originally in the standard library, but was then deprecated. So it was made as a way for people to have a drop-in replacement for an easy upgrade. Secondly, there's actually a soundness question with it, depending on the memory model we end up with. So even though it appears trivial, it actually isn't. Furthermore, that cuts to the core of what I saw with a lot of objections to JS's small modules philosophy. I saw a ton of conversations that went like this: &gt; A: this is dumb, that's a one-liner. And they wrote the wrong one! &gt; B: oh? How should it be implemented? &gt; A: like this: &lt;code&gt; &gt; B: that misses these three edge cases, actually. I forget exactly which package it was, but something similar in scale to isNumber actually went through three major version bumps, because they had missed out on an edge-case behavior that was important. People assume small chunks of code is easy, but they're often not.
It's a bit worse than that. On master, there are 3 pretty minor changes since the 0.3.0 release mid-March.
&gt; One operation that all integer scalar types support is `as` conversions from/to each other. I'm afraid this isn't true; only those integer scalar types in the standard library support this. Given that a trait defines an open set of types, it does not seem possible to define a method that performs a type conversion from one implementer to _any_ other implementer.
Of course, thanks.
Just to be clear: is your argument that Rust has _no advantage whatsoever_ over Ada and C++ with regard to memory-safety? Because if it isn't, then why are you arguing in the first place? Frankly it's peculiar how little you're concerned that Ada and C++ will compile code that segfaults when Rust won't. Anyway, with regard to your question, C++ is too complex for `unique_ptr` to save it from leaks. Firstly the interaction of inheritance and virtual vs non-virtual destructors will cause memory-leaks even if you use smart pointers [as shown in this example](https://social.msdn.microsoft.com/Forums/vstudio/en-US/2a0d1823-282c-4c31-9fda-5c135bb17a20/uniqueptr-memory-leak-when-using-base-class?forum=vcgeneral) and [this example](http://stackoverflow.com/questions/34912626/memory-leak-when-adding-an-object-to-vectorunique-ptrtype) Secondly the fact that a developer can create a `unique_ptr` directly instead of through `make_unique` leads to the possibility of a memory-leak if the pointed-to object's constructor throws an Exception. Neither of these leaks are possible in Rust.
Num was the.... Fourth? attempt at making a numeric trait hierarchy we liked. It still wasn't quite good enough to stabilize forever, so yes, it got moved out.
I'm saying that Rust has no advantage whatsoever over exclusively-RAII C++ with regard to memory leaks **(not memory safety)**. I agree that Rust makes it easier to write safe code because I'm not an idiot. As for the example you linked, the comments say it is undefined behavior. As for ctor exceptions, that's exactly why we have make_unique. My point is that compared to C++, Rust doesn't introduce any new tools for preventing memory leaks. At best, it makes it harder to do the wrong thing (though you still can if you really want to) 
&gt; The advantage is that, as a reader, you know, without doing any mental gymnastics, that result is a &amp;str Why do you care? I've been writing Rust code without explicit types and I really appreciate it when I actually want the types to change - I have to change less code.
Thanks. I've been busier than I expected, but I'll take a look at it as soon as I can make a little time.
You're right. For a trivially short program I *don't* need to know. But for teaching others explicitly mentioning types on declaration *is* helpful. And when working on a non-trivial program helping maintainers quickly, and I mean quickly, know what type a variable is (especially in a non-dynamically typed language) can only help. Do you like maintaining code? Not me. It sucks. But the longer you spend in a development career the more likely you'll be the one doing maintenance as the greenfield work is farmed off to n00bs (creating something is far easier than maintaining it). I do everything I can in my professional programming career to make code a) easy to understand and b) explicit so any misunderstanding between me and the compiler sticks out like dog's balls.
Im new to Rust and was running into a problem with floating point numbers. Why does an f32 like 4.0 added to a tiny f32 still equal 4.0? [playground link](https://is.gd/v947lk) I might be forgetting something about floating point numbers but its pretty frustrating right now. Thanks for any and all help! EDIT So brushing up on floating point number a little, the problem is probably when I use f32::MIN_POSITIVE, rust gives me the smallest positive float representable by f32, and if i was just using that number with other tiny numbers, it would be fine. But adding to to a larger number like 4.0, the number of bits needed to represent 4.0 + some tiny number exceeds what f32 can represent, so the number gets truncated. So i guess I have to rethink how I'm representing my data a little bit.
If you're testing things, use println!("{:?}", vec)
Hey how did you test your library? I want to run a client against an IMAP server but I don't really know which project to use for it.
Are you saying that if statements would be more scalable?
If you want to avoid truncation, you can add `x / 2^bits` where `bits` is your mantissa width - 1, IIRC, that'd be 23 for 32-bit IEEE754 numbers.
Awesome! Thank you so much. Ill give this a try
If statements had nothing to do with my comment either
What about changing the method resolution so that `type::method` is resolved to `trait::method` whenever `type : trait` and `type::method` doesn't exist? This would mean that moving inherent methods to trait methods is never a breaking change.
s/BigInt/BigIntTrait/ or Box&lt;[u8]&gt;
So Tessel has a C API? Or this end up calling Javascript underneath?
Yeah, `ident` is basically the superset of all possible names for things, so it can be used in type positions as well as regular identifier positions.
The module ports are accessed via a unix domain socket that communicates with the coprocessor through a daemon written in C. USB devices are accessed with the standard Linux interfaces (filesystem, ALSA, V4L2, libusb, depending on the device).
Thanks for the elaboration! &gt; Or is there something other than the aliasing problem in a possible future memory model? It's about if the element is at the end of the address space; something about a pointer to the end of that. ubsan would be able to elaborate; I forget the exact detail right this second, and it was an IRC conversation, not an issue... Shoulda filed one.
Rust has units of measure! https://crates.io/crates/dimensioned It's pretty usable, but needs some work. The main thing lacking right now is the inability to cleanly express derived units for use in function signatures. I'm getting started on a project that will depend on dimensioned, so that should push me to give it the loving touches it needs soon^(TM).
It was exactly that, thanks for your help. But, when variables became result ? read_line create a result parse create a result Why it is not directly a usable variable ? (hum, this sentence seems written very badly... sorry)
AFAIK the same is the case under macOS
The reason is - what if the string you try to parse is *not* an int? What if it's "hello" ? Then the parsing will not work. So a result represents a situation that could either succeed or fail. This way you can handle your errors up front.
I don't think mdinger alleged you insulted him, or insulted you?
Wrong sub. Try /r/playrust for better results.
First of all: Lots of unit tests. Then I use Some other IMAP client library in Rust and have an integration test which spawns a server in one thread and uses that client library to connect to the server. Rust IMAP libraries are are very incomplete, though. So I started to connect to my server code using mutt and see what's isn't working yet. So basically I think I will continue to working on it by implementing the commands that mutt tries to use. I'd recommend doing lots of unit tests. It's super easy and nicely done in Rust. Other than that, you 'll probably not find an IMAP server in Rust yet,to test against. 
Neat! It looks like the Tessel 2 has a MIPS CPU running Linux, which means it can natively run Rust code built with a standard toolchain, including libstd and Cargo crates and everything. (For comparison, the Tessel 1 CPU was a Cortex-M3 and I don't know what OS, if any, it used.)
This is fantastic! But the source code not being available on Github is a little bit disturbing these days (how do I submit a pull request?) Some documentation would be neat, if only to mention that installing the examples is as simple as `cargo install thrussh_server` and `cargo install thrussh_client`.
I've started building out a hierarchy of more intricate spaces in cgmath: http://bjz.github.io/cgmath - would be cool to start thinking of how we can do numbers better. I had started https://github.com/bjz/algebra/, but it's kind of languished - haven't had much time (brain energy) to work on it though. Also needs a great deal of thought. Took a long time to get the core cgmath traits straight in my head, and I still need to fix the transformation API. :/
Don't forget the methods on Result like `map`, `map_err`, `and_then`, and `or_else` to give plenty of options for writing further operations simply and cleanly.
I'll be on vacation for the next two weeks. I'm not sure if I can get online, so don't fret if the "what's everyone doing" and "ask questions here" threads don't get updated. In other news, I found that overflower could do with yet another mode (`no_panic`), and am looking into how to implement that. Also using quickcheck on overflower_support.
Porting [Zone of Control](https://github.com/ozkriff/zoc) from [zgl](https://github.com/ozkriff/zoc/tree/99853c3/src/zgl/src) to [gfx](https://github.com/gfx-rs/gfx) and experimenting with gfx+[rusttype](https://github.com/dylanede/rusttype)/[gpu_cache](http://docs.piston.rs/piston_window/rusttype/gpu_cache/index.html).
So Matrix is Diaspora?
Matrix is to Telegram what Diaspora is to Facebook. 
`for _ in 0..1000 { }`
Unused variables are often prefixed with an underscore. The following works without warnings for _ in 0..1000 {} 
More focused on messaging than social networking. Matrix is positioned in the same category as chat clients and IRC.
I find the match way clearer. Upfront you are told "this is about remainders of division by 5 and 3". Then "if both are zero", "if %3 is zero", "if %5 is zero", "else". You are not interested in "x%5" or "x%3" alone, it's about the different combination of the two. The match makes it clear: There are only 4 interesting combinations.
Thanks, will do :-)
&gt; The amount of people using the downvote-button as a "I disagree"-button is kinda depressing... I feel like the sidebar should be updated to say "any subjective and especially controversial opinion must be nipped in the bud". Have you noticed the score on your original post? Positive ten points.
I'm trying out Rust (again!) an currently seeing how it stacks up against C in terms of raw performance, and what is needed to get Rust as fast as possible. I just finished up a rather simple ["generate N prime numbers by trial division"](https://github.com/RDeckers/rust_c_comp) function in both C and Rust. After some tweaking they are now equally fast but I had to abandon all bounds-checking and divide-by-zero checking to do so... Going to try and vectorize it now (and get rid of the integer sqrt), and then maybe try something more complicated with multithreading.
Adding an ampersand (&amp;) before `a.as_slice()[0]` just causes a mismatched types error. It doesn't fix the problem. I'm not 100% sure this is correct, but I believe that trying to *own* a reference the first element in the Vec and rename it to `test` is not allowable, because then the Vec is in a bit of a weird state. Does it take the CPU time to shift the whole Vec down by one element so that the 0th element is now `"b"`? That would be rather unexpected behavior. But no one else can possible access `a[0]` if `a[0]` has been moved. So, Rust does not allow you to move an element out of a Vec or an array or similar things. I'm really not sure what converting to [a slice](https://doc.rust-lang.org/std/slice/) is supposed to gain you here. It's just another way of "viewing" the contents of memory of the Vec. It isn't going to change the physics of the situation at all, for better or worse. But, this code is pretty much functionally equivalent to yours: https://is.gd/TP7sdV The end result is a string in `test`. As for why it seems to be returning a `String` instead of `&amp;String`... I'm not actually sure. I wonder what the right answer to that is. Regardless, if it *were* returning `&amp;String`, I think it would cause some problems with your code in the form of a type mismatch.
No, just give them random names :) Note that the functions can be declared within the body of the function they are being used in itself, which keeps them invisible to the rest of the module. 
&gt; Does Rust have any syntax for anonymous non-closure functions? No. That was easy, who wants a bee-- &gt; If not, then the only way to do what I want to do is to make a bunch of single-use named functions for this purpose, which will require a hell of a lot of boilerplate, especially if I want to structure things nicely by using modules. Well, if you're using modules, you're going to have to have named free functions *anyway*, so I don't see what the issue is. If you're trying to do this all inline, you can just cheat: type SubcommandSpec = (&amp;'static str, fn(bool) -&gt; String); fn make_subcommand() -&gt; SubcommandSpec { ( "frog", { fn thingy(_: bool) -&gt; String { String::from("kero!") } thingy } ) } You can factor out the "define a locally-scoped named function and then immediately return it" bit into a macro if you *really* want to, but it's probably not worth the effort. There's not *that* much boilerplate involved.
Formatted input as you call it is *very* hard to get right in the general case. There has not yet emerged any implementation that is fast, secure and easy to use. On the other hand, a good number of *parsing* libraries have emerged that each offer different tradeoffs in the fast/secure/easy continuum. Perhaps we may see another crate in the future that offers a superior tradeoff and become part of std.
The thing is, I want to write unit tests for the parser but I have very little to go off of because I don't have real IMAP responses - the RFC only gets me so far with its examples. For example, right now I want to test a fetch parser but I don't have examples of a fetch response. So I want to hit an IMAP server and see what happens. I've tried hitting a yahoo email I set up but it's timing out on me after I connect initially. So I was hoping to set up a local server but I don't know of a simple way to do that.
Nooooo! I can only assume that the downvotes you received are due to the recommendation of `collect`: `collect` is about creating a collection with the result, if you do not care about the result creating this collection is quite wasteful. Instead, you could use a [`fold`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.fold): (0..10).fold((), |_, _| println!("Hello, World!")); however, it seems contrived to resort to `fold` where a plain `for` loop works in less characters: for _ in (0..10) { println!("Hello, World!") }
Maybe this thread motivated them. I see that your PR got merged as well as a big PR for Iron itself. :)
I see now that there is javascript trickery involved. It is a gif until imgur javascript is allowed. (It's still a gif, when I actually follow the link)
I see, makes sense. It's just that my mind is very used to the scanf/printf dual (cin/cout in C++, scanln/println in Go), and I was surprised in Rust being different.
I see, makes sense. It's just that my mind is very used to the scanf/printf dual (cin/cout in C++, scanln/println in Go), and I was surprised in Rust being different. 
I suppose the performance hit of just doing the integer arithmetic ‘by hand’ is negligible.
regarding synapse, it's actually probably because you tried to join a big room like #matrix:matrix.org. The initial sync of the 4 years of history is quite a stress-test for synapse.
I started working on a [language server](https://github.com/Marwes/gluon_language-server) for [gluon](https://github.com/Marwes/gluon) after reading the post on [language server support for VSCode](http://code.visualstudio.com/blogs/2016/06/27/common-language-protocol). After wrangling a bit with JSON-RPC it was quite easy to add rudimentary diagnostics and completion as I already had a function taking an AST and a location to return a list of completions (`fn (AST, Location) -&gt; Vec&lt;String&gt;`). There are still problems to work out but I hope to have diagnostics and completion in a solid (albeit limited) capacity by the end of this week. EDIT: [GIF](http://imgur.com/v36fcQq) showcasing both bugs and the server working :).
Why not XMPP/OTR?
Probably so they could change those internals without breaking anyone's code. What would they gain by exposing their internals that would make that worth it? 
Forgive me for being too lazy to search, but does Matrix allow any minimization of this problem? (Like lightweight Bitcoin wallets or RetroShare's somewhat organic scaling with number of friends, I believe this is a crucial feature for any decentralized protocol/implementations and maybe the point where we'll see the most improvement in the years to come)
This looks *extremely* helpful if/when I get around to working on one of these myself. Thanks!
`v[i]` is sugar for `*v.index(i)`. This is useful when you want to use it as an lvalue, for example: `v[i] = 5;` Side note: You don't need to call `.as_slice()`. Index notation (like method notation) will automatically deref the Vec to a slice. So you can just write: `let test = &amp;a[0];`
fns are not traits though, they're concrete "function pointer" types. Fn, FnMut and FnOnce are the traits.
Afaik it is planned to implement shallow syncs on the matrix federation protocol, meaning the homeserver would try to fetch the history only when one of its users actually requests to see it, and would only fetch the requested parts. This would make the whole sync-work much more light. But I don't know when this is planned to be implemented, I'm not part of matrix core team, and I have no idea of their priority schedule.
Perhaps better written as a Rust front-end for LLVM written in Rust. It doesn't mention explicitly that the compiler targets the Rust language (except for the examples), only that it is written in Rust.
I did not know that `v[i]` was sugar for `*v.index(i)`, that explains everything ! Thank you ! But ... how do you know this ? It is not shown anywhere on [this page](https://doc.rust-lang.org/std/ops/trait.Index.html), is it mentioned elsewhere ? If it is not, might do a PR for this, I think it's quite useful information to have.
A front-end parses a language. You are parsing Rust itself, correct? You could write as you have it, with "Toy Rust front-end for LLVM, written in Rust".
I'll take the bee if you don't mind.
You're looking for /r/playrust .
Thanks for the explanation. Makes now more sense to me. :)
Yes, you can do that [with a macro](https://gist.github.com/tilpner/28c962eb9f1eb8cbeb35). ^^Just ^^don't ^^tell ^^anyone ^^I ^^said ^^this, ^^okay?
this is the best way to phrase it.
Well, CString should work for any ones that use C strings, but if they use some other different representation, creating a SomeGuiString makes sense. It's a bit hard to answer in more detail because the question is quite abstract.
The old assembler is really not that interesting, if you would be doing something like that I'd either advise writing a similar thing just for the ops you are planning on using, or using the new infrastructure that I made for the dynasm-like tool at runtime. If you're really caring about performance it's probably even better to just use LLVM for jit purposes at that point. That said, the only thing that's hardcoded in the dynasm-like tool is the register allocation and operand form/size encoding. Immediates and displacements are fully variable. With a bit of work it could generate code for variable register allocations, which could also still be fast as the largest amount of time is spent on figuring out the proper encoding due to x64 being highly irregular. If the exact registers chosen were to be variable that'd only add a few bitwise ops at runtime. That said, I've finished the initial work on dynasm-rs, you can see it [here](https://github.com/CensoredUsername/dynasm-rs). 
I'm writing a custom integer type, and to mimic the functionality of the built-in integer types I'm `mem::transmuting` some `u8`'s into `ParseIntError`...
So using Rust fully addresses all the ways a beginner could easily introduce security problems? That's just just a dangerously stupid idea. Memory safety is only a small part of what you could do wrong in a crypto project.
I' am working on a simple Sudoku game using the Piston game engine. I' am very new to Rust.
I think you were trying to make this ¯\\\_(ツ)\_/¯! Type it like this ¯\\\\\\\_(ツ)\\_/¯ ^^I ^^am ^^a ^^bot, ^^visit ^^/r/ArmFixerBot ^^for ^^more ^^info!
Regardless of the reasoning, we're very likely to get special syntax for inclusive-inclusive ranges as well, maybe the other 2 kinds of ranges as well. They are currently on nightly. The proposed syntax was '...', but it may differ if the other 2 kinds of ranges get special syntax as well.
That's why I said: &gt; I get the feeling it was trying to prefetch gigabytes of chat logs which might make sense for a large server with many users but is impractical for a tiny single-user server. But thanks for confirming. Unfortunately, this kills federation. You can't advertise "it's federated" and then "joining a channel on another server could take hours". I hope ruma doesn't make the same mistake. *Note: I understand that synapse/matrix is young. However, getting it to the point where people can spin up their own servers should have been their first priority.
Ah, thank you. I was unsure about posting this here but I couldn't find it in the rules
&gt; Dependency management Swift doesn't have a package manager (yet), but you can vaguely lean on xcode for managing deps. Rust has a standard modern package manager which works great for statically linking 3rd party deps, but doesn't really do anything particularly interesting for dynamically linking system deps. &gt; Tooling Swift's tooling is way better than Rust on Apple platforms. Full xcode integration, custom lldb that "knows" Swift, REPL-style playgrounds, etc. Although it doesn't have e.g. all the sanitizers and stuff clang has set up yet. Rust **binaries** can use standard C-ish tooling on most platforms thanks to DWARF, but there's little serious tooling for analyzing/manipulating source. C-reduce magically works for whatever reason, though. &gt; Platforms it supports Rust is on basically everything that llvm supports, but no platform provides first-class support for Rust. Swift is on Apple platforms as a first class platform. There's some minimal linux support. IBM is pushing it for its cloud or something. &gt; Maturity of the ecosystem Swift has first-class integration with Apple's stuff, but Swift is otherwise somewhere around where Rust was circa ~0.10. Syntax isn't even stable yet. Rust is still pretty immature, but at least has basic stability guarantees. &gt; Possible future breaking changes Rust tries pretty hard to avoid breaking changes, but has basically zero tooling for handling them other than stability attributes. Certain nightly features are perpetually breaking (syntex). All of your Swift code is liable to break as 3.0 rolls out, but Swift has tooling for fixits to mitigate this sort of thing. Longterm Swift has a really aggressive story for ensuring ABI/API stability of libraries. Longterm Rust has no real story for ABI stability, and inherits many of the same problems of C++ here. &gt; Interoperability with "legacy" code Swift lives to interoperate. You can import C/Obj-C modules directly, and invoke them easily. You can have xcode generate bridging headers for you as well. Many Swift types magically bridge into Obj-C types for butter-smooth interop. Swift has been built to hypothetically support direct C++ interop. Rust sucks here, beyond the fact that there's no runtime mangling to do when talking to C. But it's very easy to have C and Rust disagree on ABI and cause infinite sadness due to a complete absence of support for C headers. &gt; Examples of domains were one would be highly unpractical to use Rust kinda sucks at GUIs and other really high-level things. Especially if you're inclined to think inheritance-y (see e.g. the DOM). Swift sucks at low-resource/no-runtime stuff. &gt; Place in the industry Swift is the future of programming on Apple platforms. Be there or be square. Some server-y stuff, but otherwise unclear. Rust is best suited for reimplementing our core infrastructure on a more solid foundation safety-wise. Some people seem to like it for misc tasks. The language is well-designed for applications that are structured as "batch" operations -- e.g. scripts. Otherwise unclear. &gt; [choose another important characteristic] * Rust takes fewer characters to type. * Swift is younger which as we all know is strictly better in tech. * Rust can hold its breath for 10 minutes. * Swift once caught a fish **thiiiiis** big. 
Yeah that sucks, I feel you. I can understand why they decided not to expose it and allow that extension. 
Thank you soo much for the honest comparison! :) This is what I wanted to read when clicking the link to hacker news. &gt;Swift's tooling is way better than Rust on Apple platforms Xcode is awesome and the integration with Swift is beyond anything I have seen in the past. But there is an emphasis to be made, it is only available on Apple platforms and when you don't have that, you're pretty much fucked (correct me if I am wrong). &gt; Rust tries pretty hard to avoid breaking changes, but has basically zero tooling for handling them other than stability attributes. What do you have in mind that would make it better? &gt; Rust kinda sucks at GUIs In your opinion, is that caused by constraints imposed by Rust or just caused by the immaturity of the ecosystem? Most of the big GUI frameworks work with inheritance, but maybe another paradigm would work well with Rust? &gt; Swift once caught a fish thiiiiis big. That's it, you managed to convince me to learn Swift! ;)
Your post seemed excited that now even beginners can write security critical code like a ssh library, no problems, because Rust does "fully address" inadvertently introduced security problems. I don't see how it could be interpreted differently. That completely oversells Rust's capabilities.
`w_h` is here: http://docs.piston.rs/conrod/conrod/trait.Sizeable.html#method.w_h So yes, it's part of a trait. You'll notice at the bottom: impl&lt;W&gt; Sizeable for W where W: Widget and, at the bottom of `Button`'s docs: impl&lt;'a, F&gt; Widget for Button&lt;'a, F&gt; where F: FnOnce() So, a `Button` implements `Widget`. And all `Widget`s implement `Sizeable`. So you can call `Sizeable`'s methods on a `Button`.
Perl 6 has the "\^..", "..", "..\^" and "\^..\^" [infix operators](https://docs.perl6.org/language/operators#infix_..) for constructing ranges. Rust has the ".." which is the same as "..\^" and "..." which is the same as "..", although using "..." for ranges gives an "error: inclusive range syntax is experimental" as of version 1.9, but "..." works in a match context just fine: fn main() { let my_number: i32 = 9; match my_number { 0 ... 9 =&gt; { println!("single digit number: {}", my_number); }, other_number =&gt; { println!("many digits number: {}", my_number); } } } // =&gt; single digit number: 9 For a bounded loops I use a silly 1+ prefix when the upper bound is constant: for i in 0 .. 1+uppder_bound { ... }, because I'm used to .. being inclusive on both sides. That said I don't know why languages don't use the [x, y], [x, y), (x, y], (x, y) construct for ranges, probably for ambiguity reasons I guess. 
One thing I see as an issue with the current state of Matrix is that a relatively small portion of the users actually install their own homeserver , most just create an account on matrix.org. This leads to development priorities to be much more targeted at end-users than homeserver owners. Hopefully Ruma will help with that. :) 
I don't put Rust on any particular pedestal, but rather place it in a class of programming languages that I'll call "not C/C++". The C languages allow a certain class of vulnerabilities like buffer overrun and printf attacks that rely entirely on the fact that they're not enforcing strict rules around memory safety. Every modern or semi-modern language (including Rust) has solved this problem (in various ways), but that doesn't imply that the problem is solved because so many of our day-to-day tools are still written in C-based languages. Even well-reviewed codebases with secure practices like OpenSSH have fallen victim to them many times in the past [1]. A Rust-based alternative like Thrussh is never going to be guaranteed to be exploit-free, but it _is_ guaranteed to avoid large classes of dangerous exploit types like these ones, which makes it fundamentally safer to write. [1] http://www.securityfocus.com/bid/5093/discuss
I suppose, my following question is not exactly easy without an example, but I'll give it a try. What's the difference between fn a&lt;T: SomeTrait&gt;(var: &amp;T) {} and fn a(a: &amp;SomeTrait) {} I mean, not the general difference, it's just that I had troubles with the first variant, when passing `var` into FFI and then derefencing it in a callback from FFI: although passed and received pointers were exactly the same, but when I tried to call any method on the received `var`, a program failed with segfault. Maybe all looks fine here, I'll fire an example to show an exact problem then.
The first function will be *monomorphized*, that is you get one version of `a` for each type implementing `SomeTrait` that `a` is actually called with. The second function will use a *trait object*, basically a fat pointer with size and vtable. The function will use this to dispatch method calls on the type it was given at runtime. Btw. your example has too little information to determine the cause of your FFI problem.
I assume you're asking why Rust checks the value of `b` in `a &lt;&lt; b` and `a &gt;&gt; b`, as opposed to ensuring no set bits get shifted out of range. I believe the answer is: because having `b` exceed the number of bits in `a` can have *wildly* different results depending on platform. Some platforms will result in `0`, others will take `b` mod the number of bits. Besides which, shifting off the end of a bit vector isn't as clearly nonsensical as overflowing an arithmetic operation on "integers".
The link is *right there* in my comment.
Is it possible to let Rust/Cargo link a project against an older version of the x86_64-linux-gnu system libraries *libc*, *libm*, *libdl*, *libpthread*, ... via build flags? I have all the right versions sitting in a directory, but of course setting *PATH* and *LD_LIBRARY_PATH* won't work because this breaks my system's tool chain. 
Can you tell me why this more DRY (https://it.wikipedia.org/wiki/Don%27t_Repeat_Yourself , less repetition of the struct name) isn't allowed, and if allowing it is a good Rust enhancement idea? struct Foo { x: u32 } impl Foo { fn new(x: u32) -&gt; Self { Self { x: x } } } fn main() {}
Is there a transcript for this?
If you want to be horribly obscure, you could also do (0..10).map(|value| println!("{}", value)).count();
Thanks for the talk. Very enjoyable while ironing. :-) An episode on the `AsRef` and `Borrow` traits you mentioned towards the end would be very nice, I think, and help newbies out tremendously.
Can anyone explain why this code: use std::collections::BTreeMap; use std::collections::btree_map; pub struct SortedU8Map { map: BTreeMap&lt;u8, u8&gt;, } impl &lt;'a&gt; IntoIterator for &amp;'a SortedU8Map { type Item = (&amp;'a u8, &amp;'a u8); type IntoIter = btree_map::Iter&lt;'a, u8, u8&gt;; fn into_iter(self) -&gt; Self::IntoIter { self.map.iter() } } pub trait U8Map where for &lt;'a&gt; &amp;'a Self : IntoIterator { fn new() -&gt; Self; fn iter&lt;'a&gt;(&amp;'a self) -&gt; &lt;&amp;Self as IntoIterator&gt;::IntoIter { self.into_iter() } } impl U8Map for SortedU8Map { fn new() -&gt; SortedU8Map { SortedU8Map { map: BTreeMap::new() } } } pub struct MapPair&lt;S:U8Map&gt; { left: S, right: S } gives the following compile error: src/lib.rs:29:1: 32:2 error: the trait bound `for&lt;'a&gt; &amp;'a S: std::iter::Iterator` is not satisfied [E0277] src/lib.rs:29 pub struct MapPair&lt;S:U8Map&gt; { ^ src/lib.rs:29:1: 32:2 help: run `rustc --explain E0277` to see a detailed explanation src/lib.rs:29:1: 32:2 note: `&amp;'a S` is not an iterator; maybe try calling `.iter()` or a similar method src/lib.rs:29:1: 32:2 note: required because of the requirements on the impl of `for&lt;'a&gt; std::iter::IntoIterator` for `&amp;'a S` src/lib.rs:29:1: 32:2 note: required by `U8Map` error: aborting due to previous error error: Could not compile `iterexample`. Play link: https://is.gd/zL2Cjm I don't get why it wants S to be an iterator ... I never specified Iterator on a trait bound anywhere. The error goes away and everything compiles fine if I just delete the MapPair struct, which is weird.
I think, there would have to be one unique official tool that is used every time a (breaking) change can be automatically fixed, so that people get used to running it when upgrading. It would have to be actively promoted as part of the language for widespread adoption. The better it is, the more freedom we get in evolving the language.
It's on my radar for upcoming episodes!
Not yet; I'd like to find a way to get transcripts of the interviews done, but transcribing is *very* pricey, unfortunately.
Yep. Left shifting uses the 5 (6 for 64-bit) least significant digits on x86, whereas [left shifting more than 32 bits on ARM yields zero](http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0497a/CIHDDCIF.html).
/r/playrust
I don't really understand what you are trying to do but I think there is a problem in your code. The IntoIter trait should consume the value, not borrow it, and .iter() only borrows a value but doesn't consume it. However in your code `into_iter()` impl returns .iter() (instead of into_iter() i guess ?) and your `iter&lt;'a&gt;(&amp;'a self)` returns a self.into_iter(), which should consume `self` ... I don't really get why it compiles but the way. Now if you could explain what you are trying to do we might have some hindsight, but without knowing what you are trying to do it might be difficult.
Obviously the apple is better, you don't have to peel it to eat it, so you can delay the garbage collection until you `Drop` the apple from your ownership 
You could also parallelise this more – e.g., running benchmarks and tests in separate builds (with Travis' build matrix and environment vars). For open source projects this is limited though, as Travis will only run so many builds for one project at the same time.
Code looks good!
How is that an improvement? You're still binding the loop variable, just as an explicit function argument. 
[removed]
May want to wash it, though, never know where it went...
Not necessarily a bad thing, but the last commit is from 2015-03-27, which was before Rust 1.0.
This was a mistake. Libpijul is 0.2 in truth and on crates.io, but pijul is 0.1 on crates.io
It's not (only) about testing the graph of possible executions though. It's also necessary to test that each transition only occurs if the proper checks were made (ie, if the proper calls to the encryption layer were made, and the results it returned were correctly taken into account). I'm not quite what it would take to encode the latter into the types, and therefore I can only think of using tests for those.
Orange too should be washed ;)
Nice. Have a look on [imag](https://github.com/matthiasbeyer/imag)s libimagstore - maybe you can get some inspiration from it. --- Libimagstore is the storage backend for imag, a personal information management suite for the commandline. It uses YAML headers for the store files and has a complex locking/borrowing mechanism. it has not yet been tested on correctness or performance, though.
Function values (i.e. `foo` given `fn foo()`) aren't function pointers but they can coerce to them, and closures without captures could theoretically do the same coercion too.
For the latter, I would actually ideally define a macro `o_try` that works like try but for `Option`s, so you don't have to use `match` at all. There's probably a crate that defines it already, but I don't know for sure.
The main use case is dynamic dispatch. For example, you can store objects of different concrete types in a data structure as trait objects, and still get to call the trait methods on them.
I'm working on a request driven black box testing framework for HTTP APIs: https://github.com/BonsaiDen/noir It has a very DSL alike style for writing tests and allows you to easily provide mocked external responses to you application (here we mock a call to icanhazip which would normally return your public IP address): #[test] fn test_ip_mocked() { Api::get("/api/ip") .with_headers(headers![ Connection::close() ]) .with_body("Some post data") .provide(responses![ IcanHazIp.get("/") .with_body("Mocked") .expected_headers(headers![ Connection::close() ]) ]) .expected_status(StatusCode::Ok) .expected_body("Your current IP address is: Mocked"); } **noir** makes use of a lot of learnings gathered from writing a very similar testing framework for Node.js at work (written for testing a very large Node.js API that sits between native apps and a lot of (legacy) customer backends). That framework was born out of the need to mock up do a dozen external resources with all different and complex response flows. And after writing about 1200 of these DSL like tests I wanted to condense the best parts into a new, but familiar tool for rust :) Now, there's still quite a bit of work left until **noir** hits its first official release. Big things on this list being: * A nice API for providing custom mocks * macros for quickly constructing multipart form data for use in tests * Lots and lots of examples / additional docs * Additional builtin mocks for mocking dates via chrono and/or resources other than HTTP (the JS version supports a few different JS ORMs as well as Redis and memcached) 
It sounds like it has an ownership/lifetime/borrowing system, but everything is inferred? Sounds too good to be true!
Definitely doesn't compile on latest stable. It would be nice if someone updated this, 300 commits makes it look like someone put in a decent amount of work.
I remember being rather sad when I was fixing a bug in rustc, and I was trying to follow the types, as it were, and some weren't even in scope. I had to import the type before I could annotate with it, which was kinda odd. The type inferencer didn't have to respect what was imported as far as I was aware.
But a lot of the time, you'll have methods called on something, and you'll want to know what code executes next. In order to do that, you need to do the static dispatch yourself, and that means knowing the type. So if you are hunting down a bug, to trace where the flow control goes, knowing the type is important.
It doesn't make sense to run benchmarks on Travis CI, AFAICT. You have no control over what's running concurrently on the system.
&gt; Have I just been living under a rock or is this a very strange way of doing things? Without knowing exactly where you have come from, I can tell you this is not a new concept. C#'s concept of Extension Methods work the same way and are common in many codebases.
So are those hypothetical transitive dependencies redundant or are you going to pull them all into your own crate just to save a bit of from-scratch downloading time?
Rust is not making things *hard*, as much as it is just making things *right.* Once you become familiar with Rust, it's not hard to get stuff done, but the Rust compiler needs to be able to prove that you're doing things safely or it won't let you do them at all. This is a great thing, but it does make learning Rust a little more challenging. Don't give up; the rewards are excellent. Many people have said they write better code in other programming languages as a result of learning to write effective Rust. What should the program do if the string *isn't* just hexadecimal digits? The result allows you to decide that.
It seems to me that striking this balance is more of a social problem than a technology problem - and I feel like it can be achieved by people who work on major Rust projects "blessing" certain crates and discussing when merging tiny crates together is a good idea. In the `npm` community, it seems like a large portion of their problems with tiny modules have occurred because of the combination of JS having almost no standard library, the challenge that web developers face in keeping JS payloads small, and the lack of the strong community-building efforts that Rust has. I'm not sure many of these are real problems with Rust - most of my Rust projects use between 1-5 first-level dependencies - unlike JS, which only recently got a form of tree-shaking, Rust does tree-shaking as part of a normal compilation process, and the early Rust community converged more quickly on a preferred coding style than the JS community.
I think rust could infer more, but it's a design decision not to do whole program type inference. It would be cool if that were an option, such as through an IDE.
I think most of the individual concerns have been more than covered here in terms of the language but I wanted to say that you do not need to spend multiple hours struggling. Feel free to drop in on the IRC or ask questions on this subreddit - there are plenty of people willing to help you figure things out.
When you say "web server" what do you mean? Do you mean an alternative to nginx or Apache, written in Rust? Or do you mean a web application written in Rust? For that, the best answer is probably the [Rust friends page](https://www.rust-lang.org/friends.html), which lists a number of companies using Rust in production. I am not sure if any of them are using it for a user-facing web application though.
Ok, I found the problem: Rust type inference just needed a little help. let r: Rc&lt;RefCell&lt;Box&lt;Trait + 'a&gt;&gt;&gt; = Rc::new(RefCell::new(Box::new(ImplTrait { i: 0 }))); 
It's actually more subtle than that: For 32-bit ARM, shift counts are taken as an 8-bit integer. So yes, shifting by any value from 32 to 255 will produce zero - and then 256 will leave the value unmodified again! This behavior is widely considered 'weird'. The AArch64 scalar shift instructions take the shift quantity modulo the number of bits in the thing being shifted. And both AArch32 and AArch64 NEON shifts take the shift amount as a _signed 8-bit number_ (yes, a shift left by -4 is a shift right by 4) SSE has similarly weird (by which I mean, different from the x86 scalar instruction set) shifts. IIRC, PowerPC takes shift quantities modulo 2n where 2n is the width of the thing being shifted. Nobody can agree on this! Even with themselves!
In my view you can currently refer to `Foo` by saying `Foo` or `Self`, unless you are creating a `Foo`, which is already "two ways of which one fails in some circumstances", but I also see where you are coming from.
Can you operate on the `ImplTrait` before you put it in a `Box`, or on the `Box&lt;ImplTrait&gt;` before you put it into the `Rc&lt;RefCell&lt;&gt;&gt;`? The `Box` can be unsized, but it's too late once it's inside those other containers.
If we could actually make a custom site to aggregate all the data and do everything this blog post proposes I think it would help centralize the discussion and allow anyone to see the dashboard of rfcs at various steps. It would be a fun community project I think to build out the tool we'd use to discuss and evolve the language we love together.
It looks like someone heard my prayers.
Not in my current design. As a hack I could force the Trait to have all of the Fns that ImplTrait needs. This would force all of my other implementations of Trait to have unnecessary Fns that just return Error. :-( Rats, my mental model of other languages got in the way here. Doing this sort of thing in Java/C++/C#/etc. is trivially simple and a best practice. What usually happens at this point is I refactor things to take advantage of the borrow checker and build an even better interface. :-) Trying hard not to be tired and grumpy... Thanks for your suggestions! 
You can only access trait objects through pointers, since anywhere that you have the actual value, you need to know how big it is. `Box&lt;Trait&gt;` and `&amp;Trait` both work, depending on lifetimes.
My understanding is that Box&lt;TYPE&gt;'s stored pointers of type TYPE. This type can be specified as a trait object which, in the example of /u/RaptorDotCpp would be HasName. You cant use static dispatch because they have different data structure types (and static dispatch requires specifying the data structure type) which is why Box&lt;&gt; is used.
The short answer is "no" The long answer is that there's a lot of the pieces you need, but everything is still pretty immature, so you'd be taking on significant risk at this point.
Rust is making things hard so you can't write bad code. Python lets you write bad code very easily, that's why so many people love it. Rust will make you slow down and write good code. &gt; Why I couldn't just get the vector out is beyond me. That's the exact statment that I would expect from programmers comming from languages that help write bad code fast. You need to handle errors. There's no way around it. What if the data you're trying to parse as hex, is not actually well formated? Rust won't let you skip handling errors. ~~Welcome in the world of real programmers.~~ Edit: Sorry for being snarky, but you're original message seemed quite arogant so I couldn't help myself.
&gt; Welcome in the world of real programmers. In the future, please refrain from making comments like this. This is unconstructive, unwelcoming and, frankly, just wrong.
Quite. It's so subtle that we should remove it :) Note that this works: struct Foo { bar: Baz } type Quux = Foo; let q = Quux { bar: Baz::new() }; 
RFC staging makes a ton of sense.
or: (0..10).map(|value| println!("{}", value)).last();
Nice, although Apple obviously refers to... well... Apple. And Orange has a color similar to rust. But never mind :)
Didn't read the post too carefully, but I have an idea relating to this. One thing that I think makes RFCs hard to follow is that you can't really sort comments on, for example, the issue page on github. What if there was something like a forum for every RFC, where discussion on concerns about the proposal could be individually discussed in their own threads? 
Do you have any more information on the ARM support? I've come across quite a few blogs and a few projects like zinc.rs, while they work not many seem to do much beyond a blinking LED example and can be tied to specific ARM microcontrollers. I'm wanting to migrate from using C on embedded projects to using Rust, though it's not clear how well that transition would go in regards to what I can do(without having to implement too much myself like drivers). - Is there a way to use the Arduino or mbed libraries/API? - Will I have any issues with expanded functionality from the likes of Shields? - Is there an easy way to know what crates I can use with Cargo for embedded projects due to limitations like `#![no_std]`?
How is what he said wrong or unconstructive?
Q1. See [`mem::uninitialized`](https://doc.rust-lang.org/std/mem/fn.uninitialized.html) (also unsafe -- of a higher degree). Q2. Not sure! ([bincode](https://github.com/TyOverby/bincode)?) Q3. Yes (afaik).
The `mime`'s `serde` dependency is optional so you can have the cake and eat it too already.
What I am trying to do: I would like to have a trait U8Map, which among other things guarantees that for every type T implementing U8Map, &amp;T implements IntoIterator. So that I can do this: fn u8mapiter&lt;T:U8Map&gt;(map: &amp;T) { t.into_iter() // whatever I want to do with this iterator } 
&gt; I ended up with this ugly thing `return hex.from_hex().unwrap();` does exactly the same thing. Why you think Rust makes things so hard is just perspective, in a scripting language it's just as hard but you are used to it. I wouldn't know how to write this in any scripting language (all I know is a little bit of JS) so I'd need to google how to do this.
I am far away from the Internals team, but 12 week cycles sound too short for large aspirational goals to be reevaluated. I would do this once/twice a year then have 12 weekly progress checks.
Consider that HasName is an abstract interface and has no memory size because it's just a collection of unimplemented function signatures. It's not something that actually exists other than for the compiler and the meatsacks operating it. Asking the size of HasName makes no sense, because it doesn't exist. So the vector can't know how much space to allocate for it. Dog could be 32bytes and Cat could be 128bytes. So you have to use a pointer/reference instead, as the size of a pointer is a known constant size. And the memory that is pointed to will be managed by something that does know which specific implementation is in use and the size of it's memory. In C++ you run into the problem of [object slicing](https://en.wikipedia.org/wiki/Object_slicing), where you have a collection containing instance of some base class and store a larger derived class, the extra data can get lost and when you read values you normally get gibberish converted from data in the next vector slot. To solve the memory issue, the alternatives would be to have some kind of union of all the trait implementations resulting in a vector with each slot taking the size of the largest implementation of the trait (which is not even be knowable if you are talking about 3rd party implementations). Of course it wastes memory unless all the objects you actually use at runtime are the maximum size. Or some way to enforce the size of the traits are the same size (or at least limit them). But there still has to be some way to know which function is called at runtime. In a vector of generic HasName's, when you call HasName for slot 0, do you call Dog.HasName or Cat.HasName? Something must know. So you need to store that somewhere. It's stored as another pointer to a vtable. A trait object is a pointer to the memory of the object and a pointer to the methods of the object's concrete type. In fact here is [the actual implementation](https://doc.rust-lang.org/std/raw/struct.TraitObject.html): pub struct TraitObject { pub data: *mut (), pub vtable: *mut (), } Read more about it [here](https://doc.rust-lang.org/book/trait-objects.html).
Traits have to be imported into the current scope before you can call the methods they define. That's why you often see `use std::io::prelude::*` at the top of a lot of files that do IO; it imports a bunch of related traits. So usually, only one of the traits defining `to_hex` or whatever will be imported, and the method call will be unambiguous. In the cases where both are imported and you have to resolve the ambiguity, the compiler will force you to use the more explicit `Trait::method(self, ...)` notation.
Rust is made for three things: speed, concurrency and safety. Safety is the important thing here. Using a result to wrap values before returning them, forces you to handle exceptions. If you did something like `from_hex(string)` and the string contained a non-hexadecimal character, you would get unexpected behavior. It might return a `None` value while you forgot to handle strings that aren't hexadecimal. In the long run, result will save you time and headaches. By the way, you could've used `let bytes = hex.from_hex().expect("Invalid hexadecimal string");`, the `expect` parameter returns the unwrapped value or causes an exception with a custom error message, in this case `"Invalid hexadecimal string"`.
Rust has uniform function call syntax, that is, `foo.bar(...) == Bar::bar(foo, ...)` (or maybe just `bar(foo, ...)`). The second (and third) options always works, but the first option is often nicer. For the first option to work the compiler needs to figure out which `bar` do you mean, and there must only be one single `bar` that you can actually mean (otherwise it won't choose for you, and you'll need to be explicit).
&gt; Why I couldn't just get the vector out is beyond me. Most comments don't seem to answer this in a straightforward and obvious manner, so here goes: Because the conversion can fail (if your string isn't hex), and Rust needs to notify you about this possibility (and the actual failure at runtime). Some other languages would raise exceptions but Rust avoids exceptions as they require relatively heavy runtime machinery (and thus constraint the ability to use the language) and are runtime faults (Rust tries to push safety to compilation time). Rust's solution is that operations which can fail return a `Result&lt;Value, Error&gt;` and *the caller* (aka you) decides how they want to handle the error whether they want to: * forward the whole thing up the stack with "monadic" error handling (`try!`, `#and`, `#and_then`) * get/provide/generate a default value/operation (`#or` and variants)) * explicitly `match` and perform more complex handling/operations on either or both cases * panic and kill the whole process with `#unwrap` or `#expect` (common for short/demonstration code, should be avoided in production code) Notifying the caller is also why Rust will warn you (by default) if a method returns a `Result` and you don't "use" it somehow (quotes because you can explicitly ignore a value by assigning it to `_`).
Just on the "Call for Participation" is there any chance we could get a section on rust-lang.com like https://starters.servo.org/ where the issues are update every day or something instead of having to check the TWiR email once a week?
Just libraries, no web server in the realms of nginx/apache/lighthttpd as of yet (from what I'm aware). Perhaps you could start writing one?
Lovely!
Nice little plugin. Mostly I just use the `(wrapping|saturating|checked)_(add|sub|mul|div|rem|shl|shr)` when I need it to be a certain way.
I'm actually thinking that masking and shifting is the ‘better style’ — explicitly telling the compiler that it may use operations that bork if set bits are shifted off the end.
... *that's horrifying.*
First of, you probably have to wait at least a tiny bit longer, the [PR for the implementation](https://github.com/rust-lang/cargo/pull/2759) was only merged 13 hours ago. You should also take a look at [RFC 1525](https://github.com/rust-lang/rfcs/blob/master/text/1525-cargo-workspace.md) for how it should work in detail.
&gt; I think they mean to do good, but forget the practical cost of such a rewrite. That's what it all comes down to. I remember being a student and learning C++ after C, and thinking what an amazing language it is. I knew a rewrite of the Linux Kernel was impractical at that point, but I still thought it was too easily dismissed just because I was naive about the cost involved. "C++ is better" was really all I knew (and by "knew" I mean "believed"), so it seemed silly *not* to use it. &gt; On the other hand, I don't see anything wrong with raising the question without pushing it. People outside of the Rust community are often not aware of what Rust would bring to the table and how they could integrate it in their code base without needing a complete rewrite I agree, but a project's issue tracker isn't the place. People can continue writing about rust and the benefits of using rust elsewhere and hope that the news makes it around. And yeah, there should rarely be an issue like "Please do this for me" without either a really really good reason that includes some actual plan for accomplishing the goal.
JS, Ruby, and lately Python have been my usual working languages. This behavior was just completely foreign to me.
[Crates.io is a production server running on Rust](https://github.com/rust-lang/crates.io)! It uses [conduit](https://crates.io/crates/conduit).
&gt; Why I couldn't just get the vector out is beyond me. Because if the string you tried to convert from hex isn't hex, then no vector exists.
The [pod](https://crates.io/crates/pod) crate may come handy. It exposes a `mut_slice` method, which is basically what you've done manually. It also comes with `Le` and `Be` types, so it's harder to mess up with endianess.
The votes here are not objective, yeah. It's a side effect of using Reddit.
I'm still feeling a little unsettled about Rust. Some things like: * collections * limited set of standard collections (BTree but no red-black tree) * no subclassing allowing substitution of one implementation of a collection for another (i.e. can't defined a pointer to a generic tree which could be implemented as either a `HashMap` or `BTreeMap`) * inability to specify a custom sort for a sorted collection * poor documentation (I know it is being worked on, but the docs are weak, have few pragmatic examples, and don't describe the plethora of traits a standard type often relies upon) * no c-style for built-in support (though someone did create a `cfor!` [macro](http://doc.rust-lang.org/book/macros.html)) * no function overloading - this would be *so* useful, so useful... I don't know. I just feel like there a bit more maturity to come to the language and supporting libraries.
https://github.com/rust-lang/rust/labels/E-help-wanted 
I assume you didn't read the article, because it is about people asking project maintainers to rewrite these projects in Rust. I am your typical hardcore unix/minimalist/c fanatic, who loves suckless, openBSD and Plan 9, and I am also learning rust at the moment. It _is_ cool. But it does not beat C (C89/C99) in two aspects: * portability (write, run on every possible system/architecture you could possibly imagine, and also a bunch more), only lua matches this, and only because it is written in C89 * stability/being well defined by a standard Performance is a minor problem, but in the long term, I think rust will maybe beat C in quite a lot of benchmarks. Edit: I just re-read my comment and realised it is quite random, but I don't know how to make it more coherent. Anyway, have a nice day!
Why not both? Have goals for several durations, i.e. until the next release, until the next 12 week cycle, for the next 6 months, for the next year, for the next 3 years, 5 years, 10 years. Pick what's appropriate, or whatever just works out.
Properties in Swift are cool .. i like the "willSet" and "didSet" observers ... i wonder if there is an easy way to have this with a macro 
Many companies (including Mozilla) do quarterly goals. I also hear what you're saying, but we haven't even had a full year of Rust stable yet, so pretty much every project has been a year at maximum. MIR did, but that's the only thing I can actively think of.
&gt; I guess that's why I'm a tester and not a developer. No need to idolize developers; we do the same thing very often. As you get more experience with Rust, it becomes easier to just knock something out. But it can take some time.
To briefly respond: * https://crates.io/crates/intrusive-collections - not everything needs to be on std to be usable, thanks to cargo * it would be nice to accept any map container. At the same time, knowing the exact performance characteristics of a container in my function is very nice. * you can implement Ord/PartialOrd yourself for a custom sort on any type you own, and if you want to do a custom sort on a type you don't own, you can make a tuple struct. * I would strongly disagree with "poor documentation" - there are definitely areas for improvement, but my experience doesn't match the strength of your claim here. Traits are definitely a weakness in the rust doc output, but the book + rust by example + API docs have covered most everything I've dealt with. * what about C style for loops are you missing? Much of it can be approximated with range iterators, but I personally don't miss the bugs they bring. * function overloading would be convenient in some situations, but at the same time it seems at odds with rusts general preference for explicitness. 
&gt;https://chrismorgan.info/blog/rust-fizzbuzz.html Why this week? This article is from 2014.
I don't idolize developers. I work with a team of 'em on daily bases. I just tend to bang out stuff fast and loose and then come back and iterate through them to add error catching, which works fine when scripting, but now I must take my time.
Sorry, that's a mistake. I picked it from Reddit but forgot to check the date.
&gt; applications written in Rust don't give you as much memory/thread safety if the libraries they depend on aren't safe! They give you more safety than the equivalent C/C++ program that uses the same libraries though.
&gt; You could achieve more stability by writing a standard and also writing down the BNF I am not sure, but is [this](https://doc.rust-lang.org/grammar.html) what you are talking about? Seems incomplete though. 
I agree that C is the uncontested king of platform availability. But, there is a lot of implementations, an a lot of them are partially or poorly standard compliant, especially on uncommon architectures. And the numerous undefined behaviors of the standard make this language very poor for stability.
This is true; I'm still all for writing apps in rust even when they use lots of C/C++ libraries. But some people don't see "incremental improvement" they see "fix all the things" (which Rust doesn't even do; it just helps a lot.)
&gt; What's wrong with a polite no and a brief explanation of why? Nothing, on the other hand there is nothing wrong with project maintainers being annoyed/bothered at getting that kind of questions dumped on them generically and out of the blue. &gt; It doesn't seem like the people that opened the issues were being impolite. They weren't being polite either, politely inquiring about a *complete rewrite of a third-party's project* would be offering to do the rewrite, hopefully having already started working on a POC and something to show for it (performance improvements or discovered/snuffed bugs) and possibly doing so in private to the maintainer directly so as not to pollute the bug tracker.
&gt; portability (write, run on every possible system/architecture you could possibly imagine, and also a bunch more), There is no way you can simply recompile your non-trivial C code (including libraries) on random architectures and make it run correctly, without working on fixing the problems caused by the architecture changes. You need a lot of effort to make it architecture independent. If you meant that it is possible to write code for all architecture that supports C, then we agree. However in this sense I think C is not much more portable than rust. 
I think your example is a completely solved problem - the overload accepting the struct will be called because it is the most specific. Both generics and overloading solve similar issues but within different scopes. An overload allows for a single interface to hide many implementations. Obviously, good code should follow the Liskov Substitution Principle and make semantic sense (i.e. `add(int, int)` and `add(double, double)` should have the same result to the caller regardless of implementation) Generics do this at a class scope, where you don't know at compile time what your class needs to specialize for. You could imagine the pain of having to write out a new subclass of `vectorX` every time you want to have a `vector&lt;x&gt;` for a new type. Generic parameters are an extension of this, whereby (as an example) you don't know what type of collection your method will be called with, but you know that they all will implement a certain interface that declares methods to act upon the parameter. Again, imagine having to write a new method for ever different collection type that you want to handle. And then, what happens if a user wants to call your method with his custom type? Without function overloading, generic parameters and compositional inheritance it would be very difficult. I think having to create a new method or class for each new type you want to use with code that you've already written introduces redundant code and wastes developers valuable time by doing a task that their tools (i.e. the language) should take care of for them. You have to actually change interfaces that might be in use throughout your system, which is a bad thing to do once it reaches a certain maturity and maybe even have other systems that call into it.
[removed]
It could link to relevant discussions at Reddit and the official Rust forums as well.'
Why is `panic!` behavior selected at Cargo.toml rather than an attribute on main.rs or lib.rs?
I would use the second if I'm actually binding the error. If not, the first one looks better.
I think we'll set a rust version of servo starters up at some point (or possibly add our projects directly to servo starters?). Lately we've been trying just to get into a better habit of making such issues available and approachable. Here are some repos with such tags: - https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy - https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-help-wanted - https://github.com/rust-lang-nursery/rustup.rs/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22 - https://github.com/rust-lang/rust-by-example/issues?q=is%3Aopen+is%3Aissue+label%3AD-easy - https://github.com/hyperium/hyper/issues?q=is%3Aissue+is%3Aopen+label%3Aeasy - https://github.com/rust-lang-nursery/rustfmt/issues?q=is%3Aopen+is%3Aissue+label%3Aeasy - https://github.com/rust-lang/cargo/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy Setting up a [servo starters](https://github.com/servo/servo-starters) instance for Rust is probably something any enterprising contributor could do. It would be a good Rust starter to set up servo starters for Rust. cc /u/Manishearth
It doesn't seem to compile on latest nightly
thanks for the explanation!
In this case, I really encourage you to check `expect`: it takes a `Result&lt;T, Error&gt;` and gives you the `T`, panicking if the result stored an error and printing the string you passed to it: result.expect("Oh my, why didn't it work????") When you want to add more robust error checking, just search for `expect` in your program :)
Normally I'd agree about keeping enthusiasm in-check, but this feels like hand-wringing over isolated incidents. As bad of an idea as rewrites are, sometimes it *is* appropriate to propose a rewrite in Rust, especially if a rewrite is already on the table and people are in the stage of working out the details (such as in the Nix thread in the OP, which is originally about a rewrite to *C++*, which we seemingly have no problem with :P ). Furthermore, none of the rewrite-proposers pictured in the OP are recognizable members of the Rust community, so there's little chance this PSA will reach them anyway.
And don't hesitate to come on Stackoverflow either; unless the most active tags which had to implement some "draconic" measures to remain useful, the rust tag has so far managed to remain friendly and approachable (probably helped by its lower activity so that we have more time for each individual user).
Indeed! Rust is just much more *in your face* than other languages: it exposes all the ugliness of the problem domain and ask you to choose how you want to resolve them, rather than picking some default that might or might not suit you and leave you wondering how you can actually tweak the behavior. *Explicitness* is a core value of the language.
Maybe, maybe not. If your dependency is a C++ library and you first have to write a C-compatible layer to be able to interact with Rust (because FFI), and then write a Rust-layer over the C-compatible layer to re-enforce invariants again (but in Rust, instead of C++), then the amount of C++ -&gt; C -&gt; Rust code you have to write might very well open the door for more safety issue that you would have writing straight in C++ :/ (Of course, once the C++ -&gt; C -&gt; Rust bridge is built, others can benefit and improve it)
&gt; That said, the cited examples after the issue tracker pictures are a weak demonstration: And the Tor one isn't just a drive-by commenter: they've filed [literally thousands of other issues](https://trac.torproject.org/projects/tor/query?status=accepted&amp;status=assigned&amp;status=closed&amp;status=merge_ready&amp;status=needs_information&amp;status=needs_review&amp;status=needs_revision&amp;status=new&amp;status=reopened&amp;reporter=cypherpunks&amp;order=id). (Of course, I have no idea of the organisation of the Tor project and maybe I'm misinterpreting it.)
Maybe large aspirational goals are more of a "vision" that can be broken into steps? For example, aturon mentioned "MIR: trans all crates.io". This does not mean that "MIR" is ready to be activated, it just states a step in the process. That being said, I agree that some long term vision could be good too; at the very least it would give people evaluating the language and judging it wanting a way to know whether their particular issues are in scope or not at this point in time.
I ended up using the *match-thing* after all, so I could have prettier printing when failing.
That would be excellent! Let me know if you have any questions!
Yeah it is slightly more code, but it is fairly mechanical code, so even though there may be bugs they should be less frequent than your typical bugs. But you are right. Fortunately the safety gained by having the bulk of the "real" code in rust should easily offset the potential safely lost by a bug or two in that small shim layer.
[removed]
Nice. I do want to see more. You have a bearable voice ;) and i would love to see more. Actually a state machine would be a good example to show affine types. 
That's a very good idea for a video! &gt; You have a bearable voice Thanks :) I've been working on it.
Yeah it takes very little research into these situations to find context that totally removes these as examples "RIIR". I don't disagree with the point the author makes that some people out there are encouraging rust rewrites where it's not feasible but it took very little time of actually investigating those examples to find that they did not support his overall point that this is somehow a trend that is overwhelming.
&gt; Nice article, but have you considered writing it in Rust instead of html? That's a good point. I was once experimenting with old apache httpd to hardcode my "blog" in apache. It was using sqlite as database, content was directly served from apache and my mod, not from stupid and slow php or django, no interpreters, no configuration. Start apache - that's your blog. Want to make a change in html? Recompile that shit for better performance.
I'd like to remind everyone to remain constructive, on topic, and friendly. Everyone is welcome here, and should feel as such. Discussing strong, off topic, and personal opinions does not help towards that goal.
`rustc` is *not* a reference implementation. It is the first implementation of three which are coming down the line, which must come to agreement on what shall be standard rust (similar to the situation with `cc`). (source: am writing the Rust spec).
Surely if `long` wasn't longer than `int` they wouldn't have called it `long`. Surely if `long long` wasn't longer than `long` they wouldn't have called it `long long`? It's not so much the assumption that's terrible, but the names of those types. I'm very glad Rust has things like `i32` and `i64`, and no implicit widening.
In Ruby, you can do something like this: class String def to_hex() ... end end This 'reopens' `String` and gives it a `to_hex` method. Rust traits are similar. You define a trait with a set of methods in it, and then implement that trait for a type like `String`, giving `String` those methods. You can also just define functions in Rust, but there are advantages to traits. Because its a trait, I can write a function that takes any type `T` where `T: ToHex`, and you can pass it a `String` or whatever else that implements this trait. (In the languages you listed, this is less of a concern, because they are dynamically typed and you can just pass anything to that function and your program will crash unless it has a `to_hex` method. Rust won't let you do that.)
I would put a nginx on top of your Rust server and do TLS termination there, and write the backend with [Iron](http://ironframework.io/) (or Conduit or Nickel), using [Diesel](http://diesel.rs/) (or RustORM) to talk with Postgres. The stack is immature, but it feels more solid than some established backend stacks. One thing gives me confidence is that Rust has static types and explicit error handling, so you can be more confident that edge cases are handled correctly (and if they are not, this is explictly marked in the source code). About avoiding outdated info: [Are We Web Yet?](http://www.arewewebyet.org/) is mostly up-to-date regarding information about the ecosystem.
&gt; but to make sure you get things right I recomend you think the worst edge cases: I know I'm a bit late on this (just now watching the video that addresses this comment) but is this even an important thing to consider? I mean I'm guessing at least 90% of all (official) N64 games were created using a compiler which should make sure that this kind of stuff does not happen (by reordering code, inserting NOPs or just throwing an error). Obviously handwritten assembly is an exception to this but what are you even supposed to do when you are trying to execute something that literally results in undefined behavior (as specified by the MIPS architecture)?
I think the author here is complaining about the drive by comment, requesting large amount of rewriting without providing anything of actual value. It is somewhat reasonable to request small bugfixes or features of volunteers, but the only viable way to do anything larger is start yourself, and try to get buy-in once you have something to show for it. There is a long history of people requesting an open source project add a massive feature without providing the required effort and leadership, and people get understandably annoyed at anything that hints of this behavior.
&gt; I know I'm planning on rewriting most of my personal apps in Rust, and while I think they'll benefit, the main reason I plan to do it is that I think I'll benefit. This resonates with me quite a bit. Worded well my friend!
Well yes but is the behavior known for the N64, has it been investigated? Because I don't think we'll ever see debugging of real hardware in this series (would be cool though ;) ). So the best/only thing one could alternatively do is to check for it and panic in case it happens. And again, I would be surprised if there are any official N64 games that are (ab)using these cases so unless you're aiming for LLE it shouldn't really matter if you emulate them correctly (or at all).
Have a look at the [Call for Participation section of the latest *This Week in Rust*](https://this-week-in-rust.org/blog/2016/07/05/this-week-in-rust-137/#call-for-participation). It lists a number of easy issues for rust-lang and community projects, some of which might have mentors available. If web programming is up your alley, [I have an easy, mentored issue for making sample projects for `multipart`](https://github.com/cybergeek94/multipart/issues/29), if you're interested.
Does anyone know what time the do update drops?
In like 17 hours
This is assuming that you actually get to the topic in a meeting. They're only once a week at most, and only an hour, so sometimes when there's a full agenda, things can get bumped back a week or two, even if the end result only takes fifteen minutes. Fifteen minutes is a fourth of a meeting!
I believe it's a flag passed to 'rustc', so cargo looks for the option and passes it for you. 
Yep, but my question is more like why was it designed as a rustc flag.
Uhm, I would expect that if a library set that it aborts on panic, any panic that happens on that library would abort, while panics happening elsewhere wouldn't. But yeah, the compiler needs to add additional code for unwinding support, the flag makes sense.
I'm going to be making a Snake clone using glium as the graphics renderer.
Would they compile to the same thing with the same performance?
~~He meant you could shadow state: `let (output, state) = machine_cycle(&amp;state, character);`, then state does not need to be mutable and you could remove line 66 in your final program.~~ Edit: doesn't work as pointed out. Thanks for the tutorial, I like it.
Of course, this also exposes the opportunity to make the inputs and outputs match. match (state, character) { (MachineState::Normal, '#') =&gt; (MachineState::Comment, None), (MachineState::Normal, '^') =&gt; (MachineState::Upper, None), (MachineState::Normal, '_') =&gt; (MachineState::Lower, None), (MachineState::Normal, c) =&gt; (MachineState::Normal, Some(c)), (MachineState::Comment, '#') =&gt; (MachineState::Normal, None), (MachineState::Comment, _) =&gt; (MachineState::Comment, None), (MachineState::Upper, '^') =&gt; (MachineState::Normal, None), (MachineState::Upper, c) =&gt; (MachineState::Upper, Some(c.to_ascii_uppercase())), (MachineState::Lower, '_') =&gt; (MachineState::Normal, None), (MachineState::Lower, c) =&gt; (MachineState::Lower. Some(c.to_ascii_lowercase())), } When people gush about pattern matching, this is what they're gushing about. The program looks like a lookup table.
ok didn't realize that, should have checked if it worked before posting.
And as far as I can tell, let mut output; let mut state = ...; loop { // set, not shadow (output, state) = machine_cycle(state, character); ... } Isn't legal syntax, although it seems like it could be useful occasionally if it were.
It seems to me that FSMs make parsing harder to understand?: [non FSM](https://is.gd/OsmFL3) version still using enums and matching of course. 
Yes it was, but I've since changed it to just echo things and exit main since panicing printed all kind of nonsense I didn't care about
I guess you can, but usually libraries I used just gave me some kind of object or just exposed some functions
I believe the single match statement is safer since it would insist on exhaustive matching.
It would be awesome if you could share your journey. I think it would be useful in learning how to be rustic.
The reason that's currently unsafe is because if any function panics while uninitialized memory has not been overwritten then a destructor could access the uninitialized memory. The only time you need to worry about this is if you use `mem::uninitialized` on a structure that has a destructor (either itself or transitively by containing another structure with a destructor). Check the documentation to see if the type implements `Drop`. Unsafe code is hard, if you can afford to zero the array that would be preferable. Premature optimisation is the root of all evil, etc etc.
Let's make a better meme then. How about 'Write Everything In Rust, Dontcha?'
I don't really see how that is a problem, as long as the reporter is not rude or ignoring already closed issues.
The Rust-derived language [dyon](https://github.com/PistonDevelopers/dyon) uses the mathematical syntax for inclusive/exclusive ranges. I honestly don't know why it isn't more common, though, it doesn't seem to introduce parsing ambiguities (assuming you use `(a..b)` for open ranges), and might not even require backtracking. Rust in particular would have the problem as `a..b` is an expression on its own, so `(a..b)` is the same as `a..b` today, and would require a major breaking change to fix (that might not be caught by the type system).
&gt; Are you saying you can only propose things if you partly implemented them No. 
[Image](http://imgs.xkcd.com/comics/is_it_worth_the_time.png) [Mobile](https://m.xkcd.com/1205/) **Title:** Is It Worth the Time? **Title-text:** Don't forget the time you spend finding the chart to look up what you save\. And the time spent reading this reminder about the time spent\. And the time trying to figure out if either of those actually make sense\. Remember, every second counts toward your life total, including these right now\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1205#Explanation) **Stats:** This comic has been referenced 453 times, representing 0.3863% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d52inwv)
Perhaps Rust should coerce anonymous function types that don't capture their environment to fns.
The body of `main` is very easy to understand. The body of `parse` (which might more accurately be named `tokenize`) is fairly difficult to understand, for two reasons: the first reason is that the loop invariants are non-obvious. For example, where you've written: let mut start: usize = 0; let mut i: usize = 0; loop { if i &gt;= len { if start &lt; i { result.push(Token::Normal(Range{ start: start, end: i })); } break; } I don't know at this point what it means for `i` to be greater than or equal to `len`, or `start` to be less than `i`. In fact, I don't know what `start` is, and I can only guess that `i` is the index of the character currently under examination. I can of course figure this information given enough time to digest the loop body as a whole, but this takes a while because I have to digest the loop body *as a whole* before I can really understand any one part of it. By the way, if `i &gt;= len`, you probably want `Token::Normal(Range{ start: start, end: len })`, not `Token::Normal(Range{ start: start, end: i })`. The second reason the body of `parse` is difficult to understand -- and in some sense, the first reason I gave is a special case of this reason -- is that the code does not express its intent. For example, in this snippet: else if buf[i] == '^' as u8 { if start &lt; i { result.push(Token::Normal(Range{ start: start, end: i })); } i += 1; start = i; while i &lt; len &amp;&amp; buf[i] != '^' as u8 { i += 1; } result.push(Token::Upper(Range{ start: start, end: i })); start = i + 1; } I can't immediately tell what parts of the code do what. If I try to break it down, the first thing I notice is that the middle block looks suspiciously like linear search. I would expect to see code like this in C, accompanied with a comment like "Find the next occurrence of '\^' after index i," but in Rust I would expect something more like a call to `str::find`. Once I see that pattern, the overall structure of the code starts to fall into place in my head, but the fact that I have to reconstruct the intent from the mechanism instead of having it laid out from the outset is a severe hindrance to understanding the code. It's still not precisely clear to me what the intent of the code is, so I can neither verify that the implementation accurately reflects the intent, nor that the intended algorithm correctly implements tokenization. Now, I won't claim that the finite state machine is *easy* to understand, but I will point out that the approach taken in the video very closely matches the formal mathematical definition of a deterministic FSM: a state space, an input space, a transition function, and a start state (it ignores the issue of final states, which would matter e.g. if you wanted to verify that every non-normal block was properly terminated). Personally, as someone with background in both formal math/CS and imperative loop-and-state style code (I am a firmware programmer after all :) ), I found the FSM approach easier to understand.
Rust is becoming a good language to do crypto in. While a lot of libraries are still in flux, and the issue of constant time code is still annoying, moving buffers around and making nice APIs is definitely easier :)
I don't know. Sounds a bit weird to me.
I've been looking for someone to help with guides for [Diesel](https://github.com/diesel-rs/diesel) (we have other issues that should be easy as well if you're interested). Ping me in our gitter room if you're interested.
&gt; The body of parse (which might more accurately be named tokenize) Agree. &gt; The first reason is that the loop invariants are non-obvious. Well, Rust doesn't help either, it lacks a general purpose loop (like in other languages: ```for (&lt;init&gt;; &lt;cond&gt;; &lt;step&gt;) { &lt;body&gt; }```), and unfortunately you can't "fake" it with: &lt;init&gt; loop { if !&lt;cond&gt; { break; } &lt;step&gt; } because the semantics of the continue statement would be different. I also don't want to use a silly cfor! macro and hope it's overhead get's optimized (it's kind of ugly as well). &gt; By the way, if i &gt;= len, you probably want Token::Normal(Range{ start: start, end: len }), not Token::Normal(Range{ start: start, end: i }). Yes. &gt; but in Rust I would expect something more like a call to str::find It seems cumbersome to use in this context: while i &lt; len &amp;&amp; buf[i] != '_' as u8 { i += 1; } vs match unsafe { std::str::from_utf8_unchecked(&amp;buf[start .. len]).find('_') } { Some(new_i) =&gt; { i = start + new_i; }, None =&gt; { i = len; } } About the understandability... people write lexers/tokenizers in thousands of lines of code and this is only ~60, I don't see the problem in this regard. 
See [RFC #940](https://github.com/rust-lang/rfcs/blob/master/text/0940-hyphens-considered-harmful.md) ^(which I wrote 🙃) for the rationale behind this underscore/hyphen behavior.
Instructions unclear. Rewrote Awesome in Forth.
Are those global settings or they can be set per operation?
&gt; Use as few third party libraries as possible I'm not sure using as few third party libraries as possible is very helpful. While Rusts standard library has more stuff than, say, the C standard library, it isn't exactly batteries-included either. &gt;It's a proprietary software - in cases there is good reason to use external library, the license has to permit closing the code. Many/most libraries on Cargo are licensed MIT or something similar, and there isn't much GPL on there, so you probably won't have much trouble with licenses. &gt; All third party code has to be updated from our private git repository (no github, no crates.io...). How do I setup cargo? Preferably not to download the code but use that already in our code tree. You can tell Cargo to fetch a dependency from a specific git repository, e.g. like so [dependencies] some_dependency = { git = "https://my-company/private-git/repo", branch = "some_branch" } Read more about that [here](http://doc.crates.io/specifying-dependencies.html) &gt; The daemon will work with (Unix as well as TCP) sockets - receive, process and send data in multiple threads Do you want to use one thread per socket, or do async IO using something like [mio](https://crates.io/crates/mio)? &gt; In order to communicate with other parts of the product, I will have to use Protobuf and Json. You will need a third party library for using Protobuf, and probably want a third party library for json (de-)serialization (or use rustc-serialize, if you don't consider that as 'third party', but it wouldn't be my first choice). &gt; Much of other code we have is C++ and some C. I would rather avoid writing wrappers for our C++ code, but I might consider using some automated tool. Rust can call C but not C++, so you will need C wrappers for your C++ code. I believe there are tools that help with generating the bindings in Rust, but I have no personal experience with those. Good luck :)
Thank you for your reply! &gt; I'm not sure using as few third party libraries as possible is very helpful. While Rusts standard library has more stuff than, say, the C standard library, it isn't exactly batteries-included either. Thats sort-of company policy. :( It has good reasons and I'm not in position to decide whether benefits outweigh the costs. &gt; Many/most libraries on Cargo are licensed MIT or something similar, and there isn't much GPL on there, so you probably won't have much trouble with licenses. I already noticed. However, I'm not exactly sure what's meant by this statement in the license: &gt; Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. How/when should the binary reproduce this. This statement is in prtobuf crate. Does this even apply to software built with that crate or does it apply only to code generator? I'm confused. That kind of fetching seems nice. But it might be more useful to use path within our source tree. We have directories like `/Foo/Bar/Project1` `/ThirdParty/Protobuf`etc. It would be better for me to fetch the code into `/ThirdParty/...` and point Cargo.toml to it. I'm not sure which way is the best. &gt; Do you want to use one thread per socket, or do async IO using something like mio? I'm not sure. I will probably use same technique which is used in our other products (which I don't know fully yet). BTW I find mio over-complicated (from users point of view) and I doubt its efficiency (as far as I understand, it has to look up the token based on file descriptor and then again, the callback has to look up data structure based on token). &gt; You will need a third party library for using Protobuf, and probably want a third party library for json (de-)serialization I already take this into account. We have our own parsing library written in C++ and I'm not sure if I will have to use that one. (I find it little bit annoying to have to deal with everything ours with no documentation.) &gt; Rust can call C but not C++, so you will need C wrappers for your C++ code. I believe there are tools that help with generating the bindings in Rust, but I have no personal experience with those. I know. I just hope I won't have to write too much bindings by hand. Also, writing it in pure rust sounds better to me (due to Rusts guarantees) &gt; Good luck :) Thank you!
Thank you for your time! &gt; emphasize the tooling. The Rust community is big on helping development with useful tools. For a recent project, rusty-cheddar (generating C headers for a Rust lib) was a big help Good point! I'll keep it in mind. &gt; Rust projects usually look shorter than their C/C++ equivalent (personal feeling, not precisely measured, would love some real stats on this) I can imagine why. It might also depend on situation. Do you take into account also length of dependencies? &gt; making a lot of little libraries is cheap. For a deamon, make an easily testable, deterministic library that will be built in the final executable. It's a useful pattern. Yeah, I plan to do something like that!
Thanks for the nice overview over the current state of using Rust on embedded platforms! I'm quite interested in using Rust on an mbed like platform. So far I played around a bit with zinc.rs and got some blinking LEDs on a LPC1768 :) &gt; mbed C API I think it would be great to have a `mbed-sys` like crate which wraps the [mbed C-API (HAL)](https://developer.mbed.org/handbook/mbed-library-internals#mbed-hal-api) and contains some examples to get started. I would happily contribute to such en effort.
I have no advice for you but just wanted to tell you that this makes me really hopeful - I might be able to write Rust as my day to day job after I did my masters degree if we make progress like this ... *awesome*!
&gt; And we only allow ASCII names for now: https://github.com/rust-lang/cargo/blob/master/src/cargo/ops/cargo_new.rs#L112-L117 (this logic is duplicated in Cargo and crates.io) As far as I can see, that code allows for much more than just ASCII. For example, `'ö'.is_alphanumeric()` returns `true`, and Cargo allows me to create project called "Röntgen" (`cargo new Röntgen`). About that, are there other naming conventions to adhere to, such as using or not using capital letters? Edit: Oh, another thing: Are you supposed to refrain from uploading your package to crates.io until it is ready to be used or can it be made available there during development too?
``` fn bubble_sort(v: &amp;mut Vec&lt;i64&gt;) -&gt; &amp;Vec&lt;i64&gt; ``` This type sig is not right. It says that the function takes a mutable reference to a Vector, which isn't consistent with your desire to not touch the original vector. Instead you want a non-mutable reference, so the compiler can prove that you don't ever change the original vector. Also, you will want to return a `Vec&lt;i64&gt;`, not a `&amp;Vec&lt;i64&gt;`. Since you are not touching the original vector, you'll need to create a new vector "from scratch" and return that new vector.
Use `rustfmt` and enable the `use_try_shorthand` config option
&gt; I already noticed. However, I'm not exactly sure what's meant by this statement in the license: &gt; Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. &gt; How/when should the binary reproduce this. This statement is in prtobuf crate. Does this even apply to software built with that crate or does it apply only to code generator? I'm confused. This basically says: If you compile a binary that includes code from that crate (which is the default when depending on the crate), and you then give this binary to someone else, you'll also have to give them a copy of the license. The exact location is not specified, it could be behind a command line option in the binary, it could be at the end of the Readme.txt or in a seperate licenses.txt. If you just want to deploy the binary on your own servers, you don't have to concern yourself too much with this. As an example of a very proprietary product using a surprising amount of open source code you can look at the Sony Playstation 4: http://doc.dl.playstation.net/doc/ps4-oss, I believe this list of licenses can also be found somewhere in the option menu on the console itself. So basically: Using MIT or BSD licensed code in a proprietary project isn't too problematic, you just have to be careful to keep track of what you are using and collect the relevant licenses.
If you're handling URLs specifically, might I suggest using the battle-hardened [`url`](https://crates.io/crates/url) crate? It makes things so much easier: let url = Url::parse("https://host.tld/thing?ding=dong").unwrap(); println!("Parameters:"); for (key, val) in url.query_pairs() { println!("{} = {}", key, val); } As a rule of thumb, I always assume my problem has already been solved by some crate and I only code my own solution if there are no existing ones, or the ones out there are too clunky, or don't fit my exact use-case. Edit: missing quotes in URL string, it's not *that* magical.
That sounds reasonable. Thank you for your advice! I'll communicate this with my boss.
This is cool but I feel like try! Looks better in some cases. Like its ok to use ? when there's a chain but if you're just using a try why drop a ? at the end? It'll just look weird and be harder to see if it's at the end of a line.
Perhaps you could help with [Redox OS] (https://github.com/redox-os/redox)? We have a huge amount of rust code ranging from the kernel, to drivers, services, command line utilities, and GUI applications Send an email to info@redox-os.org to be invited to the developer chat
Those are per item, but you can also use the traits from overflower_support directly.
The thing is: in rust typing `let v2 = v` doesn't coy the vector, it just moves the reference. (So v2 is actually a reference here). To actually copy the vector and its contents, use the `.clone()` method.
Oh, I gotchya. Yeah, that doesn't work, unfortunately. I'm glad you enjoyed it!
It's a totally contrived example, and you're right that there are many other, more efficient and intuitive ways to solve this particular problem. I'm not trying to demonstrate finite state machines, but rather how the match expression can be applied to model them.
You could try [untry](https://github.com/japaric/untry) discussions about it here if you want https://www.reddit.com/r/rust/comments/4bgv4g/untry_convert_try_calls_to_use_the_new_syntax/
To me it sounds like challenging author's choice of technology. Now if author has chosen one particular language/technology, by default (s)he has not chosen infinite number of others. By asking about any of non-chosen technology why it is not considered can lead to potentially thousands of questions: each commenter asking why their favorite is not considered.
&gt; Are you supposed to refrain from uploading your package to crates.io until it is ready to be used or can it be made available there during development too? You can do whatever you wish; it's an open registry. Unnecessarily taking names isn't great, but if you plan on using it, there's no harm in uploading early versions and not telling anyone about it until it's ready.
What the parent (TheFeshy) is committing is an [all or nothing fallacy](https://en.wikipedia.org/wiki/False_dilemma), security is a continuum. Something isn't secure or insecure, it is more or less secure. A system can definitely have more security by having a portion of it written in a safer more provably correct language, esp those portions that have had historically low quality. *edit, clarity.
Glad to contribute to better world!
Yeah that is true. One question might be OK but many would be bad. Also I see Rust being edge case because it's very new technology - I once started C++ project because I didn't even know Rust existed (it was also unstable then). If I did the same choice today, I would definitely choose Rust.
Rather than advocating for a *rewrite*, advocating for doing an new subsection in Rust (parsing, network facing components, threading). Getting Rust into the build process, this is 90% of the difficulty. 1. Get Rust into Build 2. Implement network facing or parsing component in Rust 3. Start defining project wide structs in Rust 4. Slowly Rust will take over project One doesn't need to RIIR, just get it into the build.
Ah, that sounds good. Thank you for your replies! I'll keep in mind your tool if I'll need it some day. :)
Thanks. In addition to the strict requirements, are there naming conventions other than avoiding dashes? Should upper case be avoided? Should non-ASCII be avoided?
The only official convention is `-sys` for crates that link to system libraries. But given that they end up as Rust identifiers, usually they're lower case. Also, WRT unicode, I've updated my original post. Whoops!
I should have replied to comment above yours. I totally agree.
&gt; First you forgot to make `foo` `mut` `foo` doesn't necessarily have to be `mut`. A builder passes itself along by value. Only the first might have to, if the builder produces an `&amp;mut`, and even then the more explicit version is clearer about dataflow, and Rust will make sure you get it right anyway. &gt; Secondly, in my examples I did not have `build()` return a result. Honestly this seems like a plus for explicitness. In the `try!`-on-each-line case, I know which lines can error. With `try!`s all on one line, or even with `?`, it's a lot easier to skip past. One example is from the PR, where try!(f.write_str(" + ")); gets converted to f.write_str(" + ")?; IMO this makes it a lot easier to skip over. Macro methods, so that you could do f.write_str(" + ").try!(); and let foo = FooBuilder::new() .set_a(1).try!() .set_b(2).try!() .set_c(3).try!() .build() would be the best of both worlds IMO. That boat has sailed, though.
The GCC implementation, which is planned, but hasn't been started yet, and mrustc, which is in the middle of implementing typechecking right now.
IIRC they're working towards it right now.
&gt; That kind of fetching seems nice. But it might be more useful to use path within our source tree. We have directories like /Foo/Bar/Project1 /ThirdParty/Protobufetc. It would be better for me to fetch the code into /ThirdParty/... and point Cargo.toml to it. I'm not sure which way is the best. You can do that as well- substitute `git = "url"` with `path = "relative/path"`.
Well, I did not intend to twist or dismiss anything. I can see that "things" is too generalizing, sorry about that. I do however believe that you can politely propose "total rewrites" without partly doing them.
They released it like 1 hour ago.
Here is the draft for next issue - https://github.com/cmr/this-week-in-rust/blob/master/drafts/2016-07-12-this-week-in-rust.md PRs welcome.
PR filed. Thanks!
You can do that in Rust, and some libraries do, but there are reasons that Rust libraries will often define traits. 1. In Rust, the arguments to a function will be statically typed, unlike the languages you listed. `fn hex_encode()` in Rust has to take a `String` or something similar, whereas in JS/Ruby/Python, it can take any object and maybe it will work. 2. With a trait, if I define a new type of object, I can define that trait for a new type I make. I can depend on the library to define the interface for "hex encoding something," but define for myself _how_ to hex encode my type that the library didn't know about. The most similar thing to traits in the languages you listed are probably Ruby modules, but they're still pretty different. The biggest difference between Rust and those languages is that Rust is statically typed, and this makes a difference in how it is designed.
Fantastic screencast. I'd certainly like to see more ;) I do have one question though: what atom integration displays the errors like that?
As I know rust compiler is written in rust itself, how can you do that?!
The crate and Cargo package can have different names too, not sure if they have looser rules because of that
I have made [my first PR to Cargo](https://github.com/rust-lang/cargo/pull/2834)! It's an attempt at implementing `cargo check` directly into cargo supporting crates with multiple targets (lib + bins), because I was tired of not being able to use the faster cargo-check option on my crate in the Atom rust linter. :)
TIL about the ABI. That was a cool read and it's great to see that a company like Coursera is using Rust. Every new company that uses it gives it more legitimacy!
I'd be interested in some Rust benchmarks if someone got this working.
Interesting. I might be totally wrong but I thought memcpy was actually an intrinsic in LLVM that would be optimized in certain cases (using SSE instructions to copy 128bit structs for example).
Is there a way to enforce that any class that implements one trait (e.g. Material) also implements another trait (Clone), as a kind of abstract subclass?
Yes, example taken from the book: trait FooBar : Foo { fn foobar(&amp;self); } If you implement `FooBar` you also have to implement `Foo` [Here is the chapter explaining this](https://doc.rust-lang.org/book/traits.html) under the section "inheritance"
Sorry, I should have been more specific about my situation! I'm going to be using the trait as a member in a struct so I need to be able to Box it - inheriting from Clone keeps me from being able to Box it because it's no longer object-safe, if I understand correctly. I want to be able to clone the boxed value to use it in other objects.
Why does it use *mut ()?
when does specialization land on stable?
Ah so https://github.com/rust-lang/rust/pull/32990 the title said it, but in the discussion, it had gotten removed. Thanks!
I agree this would be nice. Care to file a bug?
Ok, I didn't know if there was a rust doc specific bug tracker.
Many larger Japanese companies have explicit policies like this. It is, I think, both about trade secret issues, and about trying to have expertise in-house at all costs. To not be beholden to a third party you have little or no control over. I have acquaintances swearing every week over having to use crappy, buggy in-house libraries when much better MIT or BSD libraries are available. Those old, big corporations often had such policies in place long before the first computer ever graced their premises. That is, they may originally have been about keeping control over specific production methods, chemical-industrial processes and things like that. Then, when IT became a thing, the same blanket policy automatically got applied to those business sectors as well. 
Agreed, and they sent in a logo for the Friends page :)
From [Rust by Example](http://rustbyexample.com/cast/alias.html): &gt; Note that type aliases *don't* provide any extra type safety, because aliases are *not* new types Why not? Would there be any difficulty, or any downside at all, in considering type aliases to be distinct types? I always lamented that typedef in C worked this way, and was hoping (counting on, even) that rust would be different.
You don't need `Option::` there, since it's in the prelude.
I would legitimately be surprised if it was stabilized within the year.
Woo! For my birthday a new rust version! Its great to see the progress of the language, although I am really excited for when MIR hits stable. Kudos to the core team and all the contributors! A question to the bare metal guys, does the new abort functionality help at all since an OS really does not "unwind", or does the standard panic work well?
There was a rather in depth discussion about [this on HN](https://news.ycombinator.com/item?id=12048651) at least pertaining to x64 CPU's Hand rolled ASM will beat `REP MOVS` for &lt;2k allocations (if this defaults to glibc `memcp` then it does some weird ASM and SIMD stuff). `REP MOVS` will beat hand rolled ASM &gt;2k (Your processor decides to use SSE/AVX/AVX512, also disables some caching to better saturate DRAM BUS). The difference is caused by micro-code spin up. Linux kernel uses `REP MOVS` exclusively as Torvalds is trying to force Intel to speed up its microcode for smaller allocations. 
Just compiled a project last compiled on 1.7 and no issues. Good work team. 
It's a very significant feature. This means it's really important to get right, and so we wouldn't rush on stabilizing it. It's been a long process to even get the RFC accepted.
The first `&lt;T&gt;` in `impl&lt;T&gt; for DerefExample&lt;T&gt;` is declaring `T` as a *type parameter* for that impl. Otherwise, the compiler will be looking for a type *named* `T`, like the following: // No parameters, this is a self-contained type. struct T; // U is a *type parameter*, it can be anything struct DerefExample&lt;U&gt; { value: U, } impl Deref for DerefExample&lt;T&gt; { // This will *only ever* return a reference to an instance of *T* fn deref(&amp;self) -&gt; &amp;T { &amp;self.value } } So if you had code that put, say, a `String` in `DerefExample`, you couldn't dereference it, because it only implements `Deref` if it contains an instance of `struct T`: let deref_str: DerefExample&lt;String&gt; = DerefExample { value: "Hello, world!".to_string() }; // Notice that we can use T as a *value*, as it's a struct with no fields. let deref_t: DerefExample&lt;T&gt; = DerefExample { value: T }; // Works, because impl Deref for DerefExample&lt;T&gt; let ref_t: &amp;T = &amp;*deref_t; // Does NOT work, because no impl Deref for DerefExample&lt;String&gt; let ref_str: &amp;String = &amp;*deref_str; This is why you declare `T` as a *type parameter*, so `DerefExample` can dereference to whatever type its `self.value` is. The `&lt;T&gt;` goes next to the function if it's a type parameter for that specific function. In this case, you can have something like this contrived example: struct MyWrapper&lt;T&gt; { wrapped: T, } impl&lt;T&gt; MyWrapper&lt;T&gt; { fn add&lt;U&gt;(self, new_val: U) -&gt; MyWrapper&lt;(T, U)&gt; { MyWrapper { wrapped: (self.wrapped, new_val), } } } However, in `Deref`'s case, that doesn't make sense because you want the return type of `deref` tied to the type that `DerefExample` contains, so the type parameter is declared at the `impl` level (you also can't add type parameters to functions defined in traits like this, you would have to change the definition of the `deref` function on the `Deref` trait itself). Edit: fix `DerefExample` construction
When will box syntax, box patterns, and slices patterns be on stable? They seem to be very elegant, without any downsides.
The first two are tied together, and the second is separate. Last I heard, slice patterns had a lot of bugs, and that was the main blocker. Box syntax and patterns are caught up in some discussions around the finer points of type inference, last I checked.
That's `linter-rust`. I also have `rustfmt`, which automatically formats my source every time I save. I'm glad you enjoyed the screencast!
If I write in `Cargo.toml` `panic = "abort"` in my application, how will be considered selected panic in the dependencies?
Small note, it needs to be under a `[profile.*]` section. It will compile the whole thing with aborts, unless one of the dependencies has explicitly said "I require `unwind`", in which case, it will give you a compile error.
I am attempting to write a Rust wrapper to QML (Qt Quick), inspired by `qmlrs`. Instead of wrapping Qt directly, I've used bindgen to generate bindings for `libqmlbind`, "A C library for creating QML bindings for other languages easily through exporting objects to QML ". One crate named `libqmlbind-sys` contains the unsage bindings as generated by bindgen. Hopefully a safe wrapper can be written on top of it. https://github.com/nbigaouette/qmlrsng A simple hello world QML file works fine. I've just finished being able to port the QML `gallery` example (https://doc-snapshots.qt.io/qt5-5.7/qtquickcontrols2-gallery-example.html) and it works! I'm having issues with rpath on OSX, there's a lot of specific code to build on my machine, no documentation and no test, but I can interact with a QML window! It seems libqmlbind supports signals, I'm curius how it will look like... Any help welcome!
Even the feature itself is controversial: it is explicitly breaking [parametricity](https://en.wikipedia.org/wiki/Parametricity), which can be useful for reasoning about the behaviour of code (e.g. especially in the functional programming community).
I just glanced through that GitHub issue, maybe I missed it, but where is this flag? just curious.
Same. Always do the safe thing by default, and make people opt in if they want the dumb, insecure behavior. Or better yet, don't let them do something dumb.
Is this comment related to the one it is a reply to? Maybe implying that "optimising" memcpy is a pointless endevour? If the latter, it's somewhat missing the point: LLVM uses its memcpy-intrinsic as the one true way of moving things in memory, for large arrays and small types. E.g. reading a tuple like `(i32, i32)` into a local variable from an array or from a pointer is a memcpy-intrinsic call. The compiler has detailed knowledge of this intrinsic so it understands that, - there's no need for the overhead full function call and all the decisions necessary inside, instead a few load instructions can be emitted directly inline - it is OK to load that as an `i64` from memory (one read, rather than two) - it is OK to not load the full value if only one part is used (doing nothing is better than doing something!). The compiler can and does sometimes decide that there's no benefit to avoiding libc's `memcpy` (e.g. dynamic length, or large length), which is where the considerations you mention apply. LLVM will convert in-source calls to `memcpy` (and even some loops that behave like `memcpy`) into calls to the intrinsic so they benefit from these optimisations, and those that can't benefit end up being actual calls to the libc `memcpy` function.
Maybe I'm wrong, but I thought that's what 'GRND_NONBLOCK' was about. Sorry, my mistake. 
Anything we could help with? I think there's a lot of interest here.
True, that'll teach me to try to answer questions in the middle of the night. 
To expand further on what you're saying, this is the situation with sources of entropy in Linux. * `/dev/random` is paranoid, while `/dev/urandom` isn't. * When the device starts up, the entropy pool would be empty. * When the entropy pool is empty `/dev/urandom` blocks, `/dev/urandom` doesn't, it gives predictable output. * Once the entropy pool has enough entropy say 1000 bits, `/dev/urandom` gives proper random output for ever till the system shuts down (it uses those 1000 bits as a seed to generate more random data) * `/dev/random` will block once more after you read 1000 bits (it would exhaust the entropy pool and not create any more). Blocking after the initial entropy is gathered is not necessary and `/dev/urandom` takes the correct approach - using the initial entropy as a seed. Blocking can be harmful when a user of a package might try to overcome the blocking on their own, so using `/dev/random` isn't a good idea. On the other hand, giving predictable output without warning the user is harmful too so `/dev/urandom` isn't great either. The syscall [`getrandom(2)`](http://man7.org/linux/man-pages/man2/getrandom.2.html) improves this situation. Its available on very recent kernels - 3.17+. By default, it reads from `/dev/urandom`. It blocks if the entropy pool has not yet been initialized and doesn't block after that. This is the ideal behaviour that we need. There is a trade-off between making syscall and reading from a file - when using syscalls you won't run out of file descriptors and its accessible from jails. On the other hand, you can't access syscalls easily from scripts. The change that we're discussing does this: &gt; this change causes Rust to read bytes from /dev/urandom while getrandom() would block and once getrandom() is available to use that. This is not a good idea because the people using the API might not understand that if the entropy pool is empty, they will get predictable output. If they are on say, a VM which has no sources of hardware entropy, they will always get predictable output.
You can just edit directly on github and it will make a pull request for you. The problem with making it a wiki is that this decouples the history. Additionally, we test all the code in our docs so it is part of the CI process.
So if I understand correctly, getrandom doesn't do anything besides offer a way to block until randomness is available. But there's a flag that let's you ask if randomness is available, in case you want to write your own no-random fallback. So that patch queries if getrandom would block, &amp; if it would then it skips calling it, &amp; if it wouldn't it calls it which then doesn't block. Effectively the code would be equivalent by never using getrandom to begin with?
**AVOIDING PROGRAMMING BY COINCIDENCE USING EXPLICIT TYPES** If people would use explicit typing more often the answer might be more easily understood: fn bubble_sort(v: &amp;mut Vec&lt;i64&gt;) -&gt; &amp;Vec&lt;i64&gt;{ let mut v2 : &amp;mut Vec&lt;i64&gt; = v; Right - now you and the compiler agree that `v2` is a `&amp;mut` (mutable reference). Which means `v2` and `v` now point to the same thing - a `Vec&lt;i64&gt;`. I know it's a pain because type inference is "really cool" - but if you explicitly declare your types when you use the `let` statement you'll make less coding errors. This kind of mistake is also called "[programming by coincidence](https://en.wikipedia.org/wiki/Programming_by_permutation)" when you leave the compiler to make decisions you haven't reasoned for yourself - and hoping, by some luck, your program "just works". --- **AN IMPLEMENTATION OF THE FUNCTION** Here is another implementation that takes an immutable borrow (share) of a `Vec`, copies the `Vec` in the function and returns the sorted new `Vec`. fn bubble_sort2( vector: &amp;Vec&lt;i64&gt; ) -&gt; Vec&lt;i64&gt; { let mut vector2 : Vec&lt;i64&gt; = (*vector).clone(); let elements : usize = vector2.len(); for i in 0 .. elements { for j in 1 .. (elements - i) { if vector2[ j - 1 ] &gt; vector2[ j ] { let temp : i64 = vector2[ j - 1 ]; vector2[ j - 1 ] = vector2[ j ]; vector2[ j ] = temp; } } } vector2 } fn main() { let myvec : Vec&lt;i64&gt; = vec![ 4, 6, 2, 8 ]; let answer : Vec&lt;i64&gt; = bubble_sort2( &amp;myvec ); for elem in answer { println!(" {}", elem); } } --- **A GENERIC IMPLEMENTATION OF THE FUNCTION** And finally, because I'm having fun playing around, a generic version that takes any type that implements the `Clone` and `Ord` traits: fn bubble_sort3&lt;T: Clone + Ord&gt;( vector: &amp;Vec&lt;T&gt; ) -&gt; Vec&lt;T&gt; { let mut vector2 : Vec&lt;T&gt; = (*vector).clone(); let elements : usize = vector2.len(); for i in 0 .. elements { for j in 1 .. (elements - i) { if vector2[ j - 1 ] &gt; vector2[ j ] { let temp : T = vector2[ j - 1 ].clone(); vector2[ j - 1 ] = vector2[ j ].clone(); vector2[ j ] = temp.clone(); } } } vector2 } 
The proper approach would be Brian Smith's proposal -- have a way for early boot applications to opt into the risky behaviour instead of degrading security for everybody just to help a niche application. https://github.com/rust-lang/rust/pull/33086#issuecomment-218050254
I haven't tried but you could probably keep a stack of positions where the braces are encountered and just discard the old iterator and make a new one and `std::iter::Skip` until the spot where you need to go? When creating my brainfuck interpreter I also just read the validated input into a Vec&lt;u8&gt;. It's probably vastly over-engineered but you can check it out [here](https://github.com/cjschneider2/quirl) if you want.
As far as I know, no one has successfully gotten cargo working on Freebsd32. If you try and build it from the ports collection, it will bail out saying 64bit only.
FWIW the `make` you need is GNU make (`gmake`) not the BSD one.
Pure speculation on my part: i32 just looks more natural than s32 (string 32? short 32?). Apart from that, the term "signed integer" is a tautology. From a mathematical standpoint, integers are always signed, whereas unsigned integers are a special case of integers.
Ah, yeah, that is unfortunate. Whenever I write C, I always use `stdint.h`, or define my own if I don't have access. I was talking more about the full statement `sizeof(int) &lt; sizeof(lont) &amp;&amp; sizeof(long) &lt; sizeof(long long`.
Shows us some juicy examples!
As a naive user I would find it surprising if `HashMap::new` blocked on anything. If I needed a cryptographically secure hashmap I would look for a special way to create it (edit: sounds like the special way is `with_hasher`). So it just seems like a documentation issue. If the docs previously said that `HashMap` defends against this kind of DoS attack, then I agree it shouldn't have been changed.
RIIR made easy or something like: ``` cargo convert lib-code ```
Sounds like my longstanding cargo command line feature request `cargo new --video-game-with-a-dark-and-mysterious-main-character-who-must-fight-zombies-in-order-to-find-a-cure-for-his-daughter`
Did you reply to the wrong comment? The parent comment does not talk about any of this, especailly not `/dev/random` vs `/dev/urandom` which is totally irrelevant to the issue at hand.
This is about ownership rules. A slice only borrows the data, so it can only iterate over borrowed elements. However, if you *move* the collection into the iterator (which is what `IntoIterator` on collections does), you cannot yield borrowed elements, because the collection was already moved, so the borrow wouldn't live long enough. Someone has to take ownership, which is the iterator in this case.
I'd totally play that. Also, you should make use of cargo subcommands. Can't put all the complexity into the core, right?
Actually, I've started writing something that might end up being *rustfix*, but psssst!
I thought this was /r/programmingcirclejerk for a momemnt
It is far too young for juicy examples, the project is still very young. When I sat down with the author a few weeks ago, he basically had pointers -&gt;raw pointers and integer casts working. It will come! Just give it time.
1. SipHash-2-4 is designed to be a PRF, which implies being a MAC. I think Rust recently reduced the number of rounds, so it might not be fully secure, but given the limitations on the attacker learning about the hash, it's probably still okay for most use cases. 2. The implication of a weak hash is not that the hashmap resizes more often. It's that many entries will end up in the same bucket, an attacker will be able produce values which all share an identical hash and thus all end up in the same bucket. This reduces lookup operations to O(n) from O(1) and increases the cost of constructing the table from O(n) to O(n^2). 3. `/dev/urandom` will not block even if it hasn't received sufficient seeding yet, at that point the output may be predictable, which in turn allows above HashDoS attack. Compare this with the syscall Rust normally uses, which only blocks until sufficient initial seeding has been achieved and then never blocks again. It's different from both `/dev/random` and `/dev/urandom` and generally the best choice. So if the syscall blocks, `dev/urandom` is insufficiently seeded and thus potentially predictable. Nobody claimed that you have direct access to entropy, only that the output might be predictable. 4. If Rust uses Quicksort (or any other n^2 worst case algo) by default and doesn't choose unpredictable pivots, that's indeed worth improving.
Yep, worked without a hitch for me too on Raspbian, Raspberry Pi 3.
&gt; You are bad at your job. That's basically an [ad hominem](https://en.wikipedia.org/wiki/Ad_hominem) attack, which isn't very nice. Also after the PHP [hash table attack](https://nikic.github.io/2011/12/28/Supercolliding-a-PHP-array.html), how you initialize your hash tables seems like an important security concern.
&gt; The hashes are all keyed by the thread-local random number generator on creation by default. This means that the ordering of the keys is randomized, but makes the tables more resistant to denial-of-service attacks (Hash DoS). No guarantees are made to the quality of the random data. The implementation uses the best available random data from your platform at the time of creation. This behavior can be overridden with one of the constructors.
Rust does use mergesort by default. Servo also uses an introspective sort called quickersort for selector matching, because the naive recursive quicksort it used to use hit a stack overflow on Dromaeo. I'm not terribly worried about this, since internet-facing services frankly shouldn't allow arbitrary amounts of data in memory-backed datastructures anyway! If I knew someone was using a HashMap to store my stuff on their server, my first thought would be to OOM it. That attack will work no matter how early or late the service starts during boot.
Don't forget the ones against [Ruby](https://www.ruby-lang.org/en/news/2011/12/28/denial-of-service-attack-was-found-for-rubys-hash-algorithm-cve-2011-4815/), [Java](https://bugzilla.redhat.com/show_bug.cgi?id=750533), and [Python](http://bugs.python.org/issue13703). But hey, I'm bad at my job so what do I know?
The author asked me to drop in this link about contributing: http://jamey.thesharps.us/2016/07/translating-c-to-rust-and-how-you-can.html
The author told me that one of the reasons he chose Haskell was that there was already great tooling around working with C source code: https://hackage.haskell.org/package/language-c 
&gt; (though it looks to be mostly a renamed fork of multirust-rs). This is the history, yes.
&gt; I just want to add that you can access a tuple's members using the .0, .1, .2, ... nomenclature. Why would that go in the structs section?
Yes, absolutely! I've added an edit to my original post, both to give well-deserved praise for the release but also to clarify that this is, in the grand scheme of things, a relatively obscure scenario. That said, untold numbers of serious security vulnerabilities could have been prevented had language and library authors made the secure decision out of the box. While this specific situation is rare, the developers who write code for such environments should still receive the benefit of strong default security guarantees whenever possible. Seeing Rust's developers make (what I feel to be) a step in the wrong direction in this regard made me sad only because it is so otherwise out-of-character for what I've come to expect from this community! As a final point, defense in depth argues that it's important to get security right even in marginal cases, as it protects you from failures or unexpected behavior in other systems. This type of bug could in theory become more widely problematic if, say, a bug in the Linux kernel reduced the rate of entropy collection on macroscopic timescales (causing even normal userspace Rust code to be vulnerable). Alternatively, in a positive light, it could affect more people should Rust use become widespread in embedded devices, for kernel drivers, and for early-boot systems like `init`. By then, a decision like this is easily forgotten.
Hm. How did I end up with a reference to a reference? That was totally unexpected.
Because the "4. Syntax and Semantics" index has no separate sub-heading for "Tuples". On the page containing the sub-heading for "4.12 Structs" there is the sub heading of "Tuple structs". This section does not mention the `.0`, `.1` etc access members as I might expect in this "Tuple structs" section. See https://doc.rust-lang.org/book/structs.html
`a.iter()` gets you an iterator over references. Then, the closure passed to `filter` receives a reference to whatever the iterator contains, which in this case is references to `u8`. So there's your double reference.
They're under primitive types, since tuples are a primitive type: https://doc.rust-lang.org/book/primitive-types.html#tuples and the syntax is described there already. https://doc.rust-lang.org/book/primitive-types.html#tuple-indexing (This of course, doesn't mean that the book is perfectly clear here: I don't think rustbook supports second level headings, which is why we can't expose "tuples" in the TOC. The new book will be able to fix this, since mdbook is much better than rustbook)
It is seriously trivial to create an account. And you only have to do it once, then think of how many docs (or other!) improvements that you can make for everyone.
Oh you're right. Thanks. Perhaps you could link to the primitive type from the Structs page?
I think that's a great idea.
So not only wasn't `regex_macros` needed, but I was able to remove all the feature gates, and it compiles under stable now, too
Thanks. Somehow, I managed to miss it completely. 
Thanks, that makes some sense. 
that's correct. Now I get error message platform not supported :(
Worked on my PocketChip. http://imgur.com/oNtELzt
I have a PR in that allows it to compile with the current stable, beta, and nightly
I have a PR in that allows it to compile with the current stable, beta, and nightly. 
update to this: should now compile on the latest stable, beta, and nightly
fixed. thanks
It's all good! It's exactly why I added them there :)
`Language.C` works on preprocessed files so everything `corrode` generates will be specific to architecture (and more). There's actually a [K&amp;R preprocessor that's written in Haskell](https://hackage.haskell.org/package/cpphs) that could serve as the basis for being a bit smarter about things. Some things will just have to get expanded as generating Rust macros doesn't seem like a particular viable way (at least in a cost/benefit sense) but `#ifdefs` should not pose much trouble at all.
I'm going to try adding it to cargo port this weekend, but here is what you can try: This repo was updated awhile ago and cargo's process might have changes. So try compiling cargo from 7 months ago. You might need equivalent of night build of rustc from that time. Also, I don't see you specifying `--cargo-root` and based on messages above your cargo root is not /tmp/cargo...
May I suggest `cargo whololo`?
&gt; it's famously easy to write parsers in Haskell. And in this case because there's already [a very complete C package](https://hackage.haskell.org/package/language-c), so the parsing doesn't need to be implemented at all, only the conversion and codegen.
My emphasis was on the first part, to be honest. That there are guarantees of hash-DOS resistance.
Your suggestion looks fine to me.
This belongs in /r/playrust.
Going to assume this was intended for /r/playrust without actually watching the video at work.
Sorry, I was away for days. No harm meant although rereading it, I can see why you might read it that way. I've worked with people as students before and a common sentiment when instructing is for them to state that they understood every word that came out of my mouth. When they put them together though, they don't make any sense. That isn't to say they're unintelligent or that I'm much smarter than they are but that I'm definitely communicating on a different wavelength than they are. Part of it might be that I have superior experience in what I am instructing them in but a major constituent is that I don't appreciate or *even remember* how vast my knowledge of the topic is compared to theirs. A common problem for teaching is you are so familiar with a topic that you can't remember or even fathom what it was like when you didn't remember. If I can't remember not understanding a topic, how can I possibly appreciate how difficult it is for a student to struggle to grasp the topic? I can't. Generally, stating something is trivial is both overused and underappreciated by those who make the statement. If I teach a class on introductory statistics to freshman and start the class out telling them to not worry, this is a trivial course, I've made a big mistake by ignorantly doing the following: 0. I did not reassure them that it is an easy class 1. I divided the class into those who know what trivial means and those who don't 2. I divided the class into those who agree that the class is trivial and those who don't 3. and worst, pointed out that this topic is so easy to me which they might easily (and perhaps correctly) view as arrogance Generally, usage of trivial just highlights the speakers self superiority which can really grate on someone who can't understand with great effort. "I studied this topic for weeks and don't understand and he stands over there grinning like it's easier than breathing!" --- If after reading this, you think I'm picking on you or being really critical, please don't. I'm not trying to be harsh or critical. When you or I are in the position of knowing something someone else doesn't, it is in our best interest to try to present our knowledge in non-divisive manner. I didn't really want to get into an argument or discussion about such things. I was originally probably just trying to make a useful/helpful comment to perhaps point out a slightly different perspective.
Wrong subreddit. /r/playrust 
It's a great success over there as well.
If you're using random pivots there are no pathological inputs, only pathological executions and these are exponentially unlikely, so they can be safely ignored. (Though this is rather theoretical, it's probably better to use an algorithm with O(n log n) worst case runtime, instead of securely random pivot selection. Possibly switching from quicksort to another algorithm if quicksort doesn't terminate quickly enough. Introsort style)
&gt; And the final comment about people being offended is exactly the rude attitude we do not need any more of. I was absolutely loving this article until that last section, it was exactly like those reddit commenters who spout an incredibly popular opinion then say "downvote away, I don't care".
I feel like this is a very vague question. I think that Rust is "product ready" depending on the environment. You could build an API with it or a personal web page that would be relatively safe. If you're looking for a CMS or a social network of any kind, you will be building almost everything from the ground up. Without knowing what you are trying to do build, there is no way to answer that question. The question you should be asking is, should I be building this in Rust?
I think that proposal has a couple weaknesses that should be discussed. **First:** It allows the application to choose weak RNG seeds irrespective of what its libraries may prefer. This certainly sounds better than vice-versa, but I'm still unconvinced. The idea seems to be: 1. Libraries should *not* be allowed to *degrade* the RNG without the application's consent; 2. The application *should* however be allowed to degrade the RNG without the library's consent. While #1 sounds reasonable, when I articulate #2 alongside with it I just ask: why? Shouldn't libraries be able to *demand* a properly seeded RNG if they really insist on it? I can see the value of giving *some* priority to the application's choice, but even then maybe we ought to have an opt-in mechanism for libraries to refuse consent. **Second:** If I read the proposal right, the RNG seeding behavior is determined at compilation time for the whole application and its linked libraries. But as [this comment by eternaleye](https://github.com/rust-lang/rust/pull/33086#issuecomment-218022149) points out, there are applications that start up in a low-entropy environment but then continue running indefinitely, and may then later require strong entropy. Which suggests that such applications would still need a mechanism that allows them to delimit the scope that's affected by the weakly-seeded RNG's output. So the more I think of it, the more I agree with the comment that I linked; things should be left as they were. I'd also suggest that code that wants to use insecure `HashMap`s really should just opt out of [`RandomState`](https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html) and use a non-default, insecure [`BuildHasher`](https://doc.rust-lang.org/std/hash/trait.BuildHasher.html). There's no obligation to interact with an RNG at all in this case. And since the `BuildHasher` is a type parameter to the [`HashMap`](https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html), this means also that this choice would then "infect" the type of the affected maps, which provides the mechanism to delimit the scope that's affected by the insecure choice.
&gt; (I think C++ is getting a Trait-like system soon as well, but I'm not 100% sure about that) It's called "concepts", and it just missed getting into the next version of the standard.
Do you mean, show a warning if the crate would fail to be pushed to crates.io? Seems reasonable!
The `split()` method on a `&amp;str` will return an iterator over string slices, so this should work for you: `url.split('?').nth(1)` [(playground)](https://is.gd/WqaZIa).
Can anyone explain how I can use `try!()` inside rayon (or crossbeam). I can't make sense of the compiler error. This works: // f returns Result&lt;f64, f64&gt; fn foo(v: &amp;mut Vec&lt;f64&gt;) -&gt; Result&lt;&amp;mut Vec&lt;f64&gt;, String&gt; { v.par_iter_mut().for_each(|elem| { *elem = f(elem).unwrap(); }); Ok(v) } But if I replace the relevant line with: *elem = try!(f(elem).map_err(|_| "ugh".to_string())); I get an error: note: expected type `()` note: found type `std::result::Result&lt;_, _&gt;`
Well, then we can make a tool to diff them all and merge them up!
Who said it was an entropy driver? I'm thinking of a service manager, like systemd, that uses key-value maps and is ultimately responsible for seeding the RNG. There's actually quite a bit of code that your entropy driver relies upon.
I'm trying to spawn a thread from a member function (with `&amp;self`), doing some work with self (calling methods, for example). [Playground example](https://play.rust-lang.org/?gist=90114879df5b3fa376ddfa64c8258880&amp;version=stable&amp;backtrace=0). Of course, Rust doesn't allow me to, and I understand why. But I can guarantee that the thread does not outlive the object, it's just I cannot prove it to Rust :) Currently, I'm walkarounding this by converting a ref to a pointer and wrapping it in `AtomicPtr`, then moving it to the thread and unreferencing the pointer to a ref. It certainly works, but looks a bit.. unfriendly. I know, I can also surpass that by going with `Arc&lt;Simple&gt;` instead of self, but the function is meant to be defined by the user, so a ref would be definetily more welcome.
I need an ncurses library -- ncurses-rs or cursive? Alternately, what's a good alternative to ncurses to use? (I'm writing a chip-8 emulator)
Look at one of the crates providing "scoped threads", for example crossbeam or scoped-pool.
If someone has to write that, and they *need* a HashMap, and they *can't* block while waiting for entropy — an incredibly niche use case — that person can in the *absolute worst case* just copy the HashMap code and replace RNG calls with ones that don't block. Or they can contribute a patch that allows developers who need to to opt out of blocking RNG behavior.
I'm sorry for the confusion, I've amended that comment.
I'm sorry about that, I've amended the comment with stouset's correction.
Some people like to write ray tracers, some write new cargo subcommands, but tell you what: The best projects for learning Rust have already been started for you. Whether it's [servo](https://github.com/servo/servo), [rust itself](https://github.com/rust-lang/rust) or other projects like [rustfmt](https://crates.io/crates/rustfmt) or [clippy](https://github.com/Manishearth/rust-clippy), all of those projects have easy mentored issues – so whenever you choose to tackle one of them, you'll not only get a small, achievable task, but also an awesome mentor who will help you, and your work will help the Rust ecosystem. Everyone wins!
Yes (actually, I should have said `openssl-sys` above), but: A. it's just a naming convention; there's no magic involved, and B. someone still has to *write* that crate. So you can't just depend on `somerandomlib-sys` and have Cargo magically figure the rest out.
I thought the article was going to issue a challenge to RIIR... Sounds like a good way to get down and dirty with rust tbh, especially with smaller programs (gnu coreutils for eg).
It's not a keyword. It's just an enum variant, one that gets imported by default. The documentation is [here](https://doc.rust-lang.org/std/option/enum.Option.html) You can find a bit more about how enums work here: https://doc.rust-lang.org/book/enums.html Option is basically a nullable. Rust doesn't have `null`, but if you want to talk about a value that may not exist, you use `Option&lt;WhateverTypeThatValueIs&gt;`. When it does exist, it will be a `Some(value)`, else `None`.
Thanks, let me know how far you got :)
Again, are you replying to the wrong person? I never said it was trivial; quite the opposite.
On [`events.rs` line 30](https://github.com/Carl-Foster/snek/blob/master/src/events.rs#L30), you forgot a comma.
The goal of the author is straight syntax-directed translation, so the clean ups would be the purview of a linter/fixer pass afterwards. 
If you're still looking for an integer sqrt, I've found one that only uses bit twiddling (and it's based on http://steve.hollasch.net/cgindex/math/introot.html ): pub fn isqrt(mut num: u32) -&gt; u32 { let mut bit = 1 &lt;&lt; (32 - 2); let mut res = 0; while bit != 0 { let sum = res | bit; res &gt;&gt;= 1; if num &gt;= sum { num -= sum; res |= bit; } bit &gt;&gt;= 2; } res } Disclaimer: Haven't tested the code myself. Expect bugs.
In the definition of `sudoku_problem` the documentation says that a non-square box size will result in a `None` return value, but this isn't actually implemented. Also, as a style nit, I'd use a `Result` here and return a custom `Error::NonSquareBoxSize(n)` or something like that. It will make debugging for your users much much easier. **Edit:** Ah, I'm sorry, you do do this check, but in `sudoku_solver`. I recommend making `sudoku_problem` non-public since it is only called from that function, then perhaps adding a `debug_assert` in `sudoku_problem`.
Can someone explain what the purpose of the Send trait is? I know it's for types that can't be safely send across threads. But when and why is this ever the case? If only one thread can access the data, which is the case for Send, then why is this a problem? Neither the documentation, nor the nomicon explain this. This recently caused problems for me. I have a thread pool and I need to assure the work I put onto the thread pool is done in an appropriate order. For example mutable tasks on my data should never happen before immutable tasks that were scheduled before, or vice versa. So I used a RwLock, to lock my data appropriately. Turns out that you can't Send the locks to the thread pool ([impl&lt;'a, T: ?Sized&gt; !Send for RwLockReadGuard&lt;'a, T&gt;](https://doc.rust-lang.org/std/sync/struct.RwLockReadGuard.html)). So the thread pool needs to lock the data itself. That's bad, as the threads aren't scheduled in order. So my solution was to use a channel to sync up all the threads again. Pretty dumb, as the whole purpose of the RwLock is now mostly defeated. I actually might open source this library as I think it's really cool. It's basically a wrapper around data which only allows you to access the data by submitting tasks to it. The Tasks then get access to the data and can work with it. All of the immutable Tasks run concurrently, as the data is not modified. Mutable Tasks however run in the sequence they got submitted to make sure no race conditions happen. You can provide an optional post-processing Task that processes the data when it got modified. If multiple mutable Tasks are submitted, it schedules the post process after they are done, instead of running it between every single one of the mutable Tasks. This is super useful for UI applications that need to work with a large amount of data. It's impossible for the application to block on the data now as all the tasks run asynchronously to the main thread. The post-processing task then sends the processed data back to the UI thread where the results can then be picked up and displayed.
Historically my go-to first project for learning a new language is writing an IRC bot. Rust is no exception here. This gives a good cross section of functionality - networking and string manipulation being the obvious starting points. Adding the ability to connect to multiple networks at the same time and do/schedule asynchronous work (e.g. print updates to rss feeds without blocking normal interaction with the bot while it fetches them) adds multithreading/concurrency functionality to the mix as well. The project's scope is relatively easy and small - usually not too intimidating - and leaves you with something potentially useful if you use IRC. 
I'm writing parsers and data-munching stuff to generate statistics from old log files. Quite interesting and also quite performant
Personally, I'd try to calculate `(x + n)^2`, assuming I've already calculated the value of `x^2`. For `n = 2` and `n = 4`, this gives `(x + 2)^2 = x^2 + 4x + 4` and `(x + 4)^2 = x^2 + 8x + 16`. And since you already know the value of `x^2`, it will only take 1 `lea` instruction to calculate either of the two (at least on x86).
Short answer: You can't. Long answer: You theoretically can, but it's so hard and annoying that it isn't worth it. Consider finding a different way to do things.
I've also just realised that _Native_ probably isn't the right word... "Pure Rust" maybe?
You could use [Rc](https://doc.rust-lang.org/nightly/std/rc/struct.Rc.html) and you might also need [RefCell](https://doc.rust-lang.org/nightly/std/cell/struct.RefCell.html).
It can be done. A possible solution involves using a reference-counted wrapper such as `Rc` around A, [like so](https://is.gd/TX7hly). When you wrap a field in `Rc` you stop being able to mutate it, because `Rc` only implements the `Deref` trait (i.e., you only get immutable references to the wrapped value). You can get mutability back if you also use `RefCell`, like epic_pork suggested. If you'll pardon the plug, I wrote about this topic in [this article](https://ricardomartins.cc/2016/06/08/interior-mutability). However, I second deadstone's advice: find an alternative way to do things. It'll probably be a better solution down the line than peppering `Rc` everywhere.
As op said, the types `SA` and `SB` actually come from a third-party library. In other words the only "solution" is to modify the library. That's IMO a huge problem in Rust that everyone seems to underestimate :-/ 
Is there any reason to use the integer types from libc rather than Rust's native integer types when interoperating with C code?
You can do it: https://is.gd/OYY8Q8
That's pretty clever there, wrapping it in another struct and an option. Edit: I get the concern now.
We discovered that there is a seemingly important security tradeoff with the transfer between S3 and CloudFront - you can either have encrypted transfers *or* you can have S3 behave like a website and automatically turn `/` into `index.html`. We decided static.rlo was making the wrong tradeoff - the transfer from S3 to CloudFront was using HTTP, now it is using the S3 protocol. To get the website working again, we switched the configuration in the *other* direction - www.rlo is now doing HTTP transfers from S3 to CloudFront to get the `/` behavior (this still seems bad for security).
And now you can't write a function that returns a well-built `Structure`.
Rustfix looks interesting, but I think I made sure that there are no warnings from the compiler or from clippy already.
I'm not sure.
Right, and that destroys a really important property of rust: move is just a memcpy. 
Implementing data structures is harder in Rust than C, you have to throw `unsafe` around if you want a doubly-linked list with good performance, for example. But in my own project I just use other people's data structures, so it's not what I spend time writing.
Sorry, I don't know many of these terms, but what does unsafe mean exactly? Is that a bad thing or like a time overhead issue?
But won't that require a lot of explicit conversions if you want to use it from Rust anyway?
In my experience, not really. They're just aliases for Rust integer types anyway so it's not really any more verbose than mixing different Rust integer types (which I personally try to limit as much as I can). Literals work without any casting.
Is rustfix a real thing?
Whenever I hear "you can't do that in Rust" (and not because of safety reasons, just that Rust wasn't designed to support that) I think maybe Rust isn't the language for me. Languages should enable programmers, while protecting them from bugs and safety issues.
I read this as a thread which I'm replying to the most recent post. The fact that reddit allows you to split a discussion up at certain points to discuss different matters I'm ignoring because this is mainly a discussion.
I'm still kind of new to the Rust ecosystem so forgive my ignorance, but why the `ru` prefix and not `rust-` or `-rs`?
Well I did it in C++ first (I wrote my emulator, got everything done, then found rust, ported the emulator as a first project). On Windows I only tried win32 for the buzzer and the Beep() function actually blocks threads and can't be used in another thread so either you block your main thread for 255/60 seconds max or you have no sound. I decided to not bother and go for no sound :D I thought you might have a library that can easy create a buzzing noise without blocking everything. That's why I asked. I was quite busy right before I finished so I didn't get to debug my draw instruction. It's bugging around a little but I have no idea why. Chip8 is so simple that this will be the only thing you need to debug anyway. I mean you can implement all opcodes in a couple of hours and the draw instruction is the only challenge.
`unsafe` is an annotation that you assure the compiler you guarantee memory safety manually
&gt; You can't just change the underlying representation of a reference stored in a struct in a language at this level I'm sure others said the same thing about many of Rust's RFCs.
Was more thinking about Go, Swift &amp; Co, but yeah.
What are you even trying to say at this point? References in structs have a fixed representation so they work across translation units. Changing that representation when the target of that reference happens to be inside the same struct just isn't something that makes sense to do.
Given both the people who were involved in making rustc and rustcs history of trying all the things, I don't think "lack of foresight" is the issue here. This is intentional.
I started building [something](https://github.com/killercup/rustfix) a few days ago. Basic stuff works, but it's more of a proof of concept right now.
This might be helpful to find good resources to learn Rust https://www.reddit.com/r/rust/comments/4amwtk/i_want_to_learn_rust_where_do_i_start/
That's not exactly what unsafe means. Unsafe doesn't disable any checks, it allows extra things which are not checked. This is a big difference!
I'm trying to store a lazily evaluated value into a struct. I'm trying to use [this](https://crates.io/crates/lazy-scoped) crate to achieve it. However, I can't figure out what kind of type the field should be. The compiler wants me to satisfy `std::ops::FnOnce() -&gt; std::collections::HashMap&lt;grid::Move, grid::Grid&gt; + 'static: std::marker::Sized`, and I can't seem to understand what it wants... Here's what I've got so far: pub struct PlayerNode&lt;'a&gt; { grid: &amp;'a Grid, children: Lazy&lt;HashMap&lt;Move, Grid&gt;, FnOnce() -&gt; HashMap&lt;Move, Grid&gt;&gt; } impl&lt;'a&gt; PlayerNode&lt;'a&gt; { pub fn new(grid: &amp;Grid) -&gt; PlayerNode { PlayerNode { grid: &amp;grid, children: Lazy::new(|| { create_children_by_move(&amp;grid) }) } } } fn create_children_by_move(grid: &amp;Grid) -&gt; HashMap&lt;Move, ComputerNode&gt; { let mut children: HashMap&lt;Move, ComputerNode&gt; = HashMap::new(); for m in grid::MOVES { let new_grid = grid.make_move(&amp;m); if new_grid != *grid { let computer_node = ComputerNode::new(new_grid); children.insert(*m, computer_node); } } children }
I don't want to speculate too much about the thought process of Rust's designers. Still, we shouldn't assume rustc's rules are ideal or perfect. Despite Rust reaching 1.0.0, there's still room for improvements for certain use-cases that Rust programmers (such as OP) are beginning to hit. I'm skeptical that Rust's designers anticipated _every_ unusual use-case and intentionally decided not to support them.
`input` contains the newline that you typed. Try doing `println!("{:?}", input)` to see it.
aah got it :D looks like we have to use input.trim() instead passing input :D
Thanks. I tried 80 earlier but I didn't realize that ports under 1024 are only available to root.
How about `rulina`? :)
Yep. So generally you develop web apps that listen on higher numbered ports and deploy with something like nginx in front of it that proxies port 80 to your app (or 443 for https if that something is also doing SSL termination)
Im really happy to see advancing stages of TLS/SSL in rust without OpenSSL. I really, *really* want to include network security in my projects, however, I also personally don't like to write software with a particularly complex setup process for other users; as someone who primarily uses Windows, an OpenSSL requirement is usually a deal breaker for me. I really love seeing the progress of Rust toward the hopeful state of dependency-free TLS. 
With [*ring*](https://github.com/briansmith/ring), the building of the crypto bits is handled automatically for you, even on Windows. In fact, I develop *ring* on Windows as my primary platform so Windows support has always been a #1 priority. The main limitation of the Windows support is that the assembly language stuff is preprocessed by Perl. Thus, you have to have Perl installed to build it. However, when I get around to putting *ring* on crates.io, then when you build *ring* from crates.io, the preprocessing will be done ahead of time. Thus, there will be no extra dependencies to install other than the Rust compiler, C compiler + linker. In the not-too-far future, you won't even need the C compiler for *ring*.
That'll be amazing. I can't wait until an external compiler isn't necessary for things like this. Thank you for your work on projects like this! 
I suppose it's a matter of perspective. It disables the checks that prevent you from calling unsafe functions. If you write safe code, than obviously adding an unsafe block won't make it unsafe.
[removed]
The closed form solution isn't useful if you care about accuracy, because if you do it with enough accuracy to get exact results, it's just equivalent to doing the calculations the normal way. There's no such thing as a free lunch here.
Does it support jimmies?
But you can't move the struct. The reference is the memory address of another member of the struct. If you return the struct from a function, or moved it into one, that's memcpying the struct to a new location on the stack, invalidating that reference.
Rust does not natively support this in a good way, but I'm trying to build a safe abstraction to make it possible. I'm currently looking for feedback to see if this is useful to people in its current form, or if it needs further changes. [Please try it out!](https://github.com/diwic/refstruct-rs) 
I also think a hyper adapter would be very useful. I spent some time the other day to get rustls and hyper to work together without success. Same goes for using a standard TcpSocket. While the API chosen for rustls probably makes it very versatile, it makes it quite complicated to use even for simple use cases.
Why not just `linear_algebra`? The crate name is up for grabs: https://crates.io/crates/linear_algebra
You can implement a doubly linked list in safe Rust using Rc or a Vec. Also see https://github.com/pcwalton/multilist.
You could also use indexes into the string.
Good to know. I'm not that far yet because of work and exams coming up. But I'll let you know if I find a solution or if I do it your way and just skip the sound part. ;)
You can't implement a trait outside your crate for a type outside your crate.
I mean it's not like you actually use a chip 8 emulator. Might as well ignore the sound and move on to a game boy emulator or something. 
You could use a newtype: https://is.gd/2iQk1B
Well, "some folks are right" except that the log(n) solution is not log(n) and that the closed form also takes more than O(n) to compute.
&gt; I don't really understand what advantages I get from returning the struct itself. Because of this: $ ack Box src/|wc 0 0 0 I went through all my rust libraries and I use a total of one box. If your library starts producing boxes then there is a good chance I need to remove the box because I don't need it. So better not make the box in the first place :)
Hey, this looks like a promising start. I have no interest in machine learning, but I'm very interested in contributing to a pure linear algebra library (my field is numerical solutions of PDEs). Very busy these days though, so no promises! I'll keep an eye on your library in any case :)
Hi, I made an implementation of the Fifteen Puzzle Game for [rosettacode.org](http://rosettacode.org/wiki/15_Puzzle_Game#Rust) as a training, as suggested [here!](https://www.reddit.com/r/rust/comments/4ryk48/project_ideas_to_get_familiar_with_the_language/d55eaky) Can I have some comments ? Thanks !
That's what I meant by safe abstractions over unsafe code.
I wouldn't! The book is great, and everything I've learned from blog posts and the community is vital information for me.
Why does this not work: fn main() { println!("Hello, {:?}!", &amp;[b"\x01\x02", b"\x03\x04\x05\x06"]); } &gt; expected an array with a fixed size of 2 elements, found one with 4 elements I understand I can simply do this to make all this coerce correctly: fn main() { let a: &amp;'static [&amp;'static [u8]] = &amp;[b"\x01\x02", b"\x03\x04\x05\x06"]; println!("Hello, {:?}!", a); } But I'd like to do this without introducing a new variable binding or requiring explicit type decoration. I tried the following but it did not work and results in the same error as the first example: fn main() { println!("Hello, {:?}!", &amp;[b"\x01\x02", b"\x03\x04\x05\x06"] as &amp;'static [&amp;'static [u8]]); } So what I'm asking is, how do I write slice literals? I'm not interested in the (very limited) array types, just give me the array coerced as a slice...
Probably would have gotten on IRC earlier.
I can see an argument for having inference attempt unifying the types of array elements when initial inference fails by applying deref coercions to the first element and re-attempting inference. Or maybe comparing the set of all deref implementations for the first element to those of every other element. It would certainly make some easy cases like yours behave in a "do what I mean" fashion. But I can also see complex cases yield surprising behavior. If there are many applicable `Deref` implementations available, which in turn have their own `Deref` implementations, etc. . .how would you know which was chosen unless you explicitly annotate something, which is what you're trying to avoid in the first place?
Another one for clippy?
Why re-learn? I'm still learning it! I wish I had more time for that, but I'm otherwise very happy with my path to Rust. To make this comment at least minimally useful, I'll repeat my advice to join existing projects and take up easy mentored issues. There's no better way to learn, IMHO.
If you're into that kind of thing, see also [Rosalind](http://rosalind.info/problems/locations/).
Hey, thank you -- I appreciate that, and was able to learn several things from your code. In particular I like your approach to pattern matching on the (next,prev) tuple -- much nicer than the nested matches I was doing.
Yeah, this part was written when `box` was "stable" (before stable/unstable stuff existed) and then had the syntax updated, because we still thought `box` was coming soon...
&gt; So I'm wondering why it's not considered such an issue in other languages, like C. Well, C doesn't have move semantics, so it can't really come up. You're already handling everything like that manually, so you have to code it yourself. You could do the same thing in Rust if you were allowed to make anything `Copy`, and use raw pointers. But it would be terribly, terribly unsafe.
wow :0 "4\n4.2\n"
The magicalness of `Copy` also means there's a nice but odd-looking workaround: #[derive(Copy)] struct Block([u8; 512]); impl Clone for Block { fn clone(&amp;self) -&gt; Self { *self } } The case I needed this for was more complicated than a newtype, so not having to hand-write the `clone` (and then change it whenever I changed the struct fields) was useful.
It's really nice that those docs were expanded to explain `&amp;&amp;` better. That is really excellent! BTW, been working with .NET and in comparison, one thing which is so very nice about the rust docs are their compact examples. The [example at the bottom](https://msdn.microsoft.com/en-us/library/system.threading.cancellationtokensource.aspx) is very typical. They have walls of text and then one or two mega examples. The piecemeal nature of how the rust docs document every little function with very brief examples is really pleasant and very approachable.
I use that trick for every struct in winapi. https://github.com/retep998/winapi-rs/blob/master/src/macros.rs#L268
If you had continued reading the page, you would have seen &gt; Linux's /dev/urandom happily gives you not-so-random numbers before the kernel even had the chance to gather entropy. When is that? At system start, booting the computer. &gt; &gt; … &gt; &gt; In the meantime, Linux has implemented a new syscall, originally introduced by OpenBSD as getentropy(2): getrandom(2). This syscall does the right thing: blocking until it has gathered enough initial entropy, and never blocking after that point. Of course, it is a syscall, not a character device, so it isn't as easily accessible from shell or script languages.
Yep, same here. After 10k loc in my project I'm still learning new things every day.
I would love to use pure Rust libraries only, honestly. Unfortunately there are no pure Rust libraries that are quite as capable as SFML, yet.
IMO. A good approach is to port a small and popular library from other language that you know to Rust.
Ah! That makes sense. I guess you would need a 'relative reference' or something like that... Ugh. All of this headwind implies that, as a community, we need to be better with structs on the public interface that have references. There are times when it's needed, and times where it will be a problem. Identifying those patterns will help out a lot, I think.
I'm sorry, but that doesn't answer my question in the slightest. *Why* do you avoid Box so much? 
Ah, I get it. Thanks. Still very new to rust. 
This is great, too! Thanks. :)
Was there a major update recently?
&gt; I guess you would need a 'relative reference' or something like that... Ugh. This is what people are talking about in other branches of this thread about C++ move/copy constructors (these constructors rewrite the reference to the correct address when its moved about). However, this introduces a lot of issues, which are also discussed in other branches. Rust gains a lot by having only memcpy move/copies, but loses this ability.
Oh ok. Just to make it more visible, /u/gankro explains [here](https://news.ycombinator.com/item?id=12066259) (edit: fixed bad link) why the writing of the Rustonomicon stalled: &gt; Hey there, I wrote pretty much all of this. Sadly I wasn't ever able to finish it, and won't ever be able to due to contractual obligations. It has since languished due to lack of maintainership, even though it's part of the official rust docs. &gt; If anyone wants to take up the mantle and clean it up, it would be greatly appreciated!
Well it's definitely not `pkg-config` since that outright refuses to even attempt to work on `windows-msvc` and just returns a cryptic error about cross compiling. Granted that's because there isn't really a standard way to install random libraries and then find them. An optimal solution would need to be able to both find an existing version on the system and fallback to compiling the library itself across _all_ major platforms.
&gt; Why do you avoid Box so much? A Box is a heap allocation, heap allocations are expensive, and you're removing choice from your caller and/or making them pay for stuff they don't need. 
The latter did what I needed -- thanks!
I find it too easy to miss among other symbols. Making a single character impact control flow like this doesn't match usual Rust's verbosity and reminds me of the K language.
The implementing Vector part makes more sense if you are doing so with #![no_std], and with minor modifications it works for #![no_std] to gain vectors support, albeit vectors support increases binary size around 250-500KB.
This one has a fairly complex answer. **The short of it is:** I probably wont do it any time soon, but I'm not totally against it. **The long answer:** This library was essentially developed as when I started [rusty-machine](https://github.com/AtheMathmo/rusty-machine) there was no clear (stable) community library for doing linear algebra. The ones that did exist seemed bad choices (ndarray had just depreciated the linear algebra, and nalgebra was supposedly for low-dim work). And now that I have my own data structures etc. they are used throughout the entirety of rusty-machine and of course rulinalg. Changing over to ndarray would almost be a total rewrite of both. Right now I'm not convinced this is worth doing. However, if it is clear that the community wants to rally behind ndarray I would definitely look to support it by switching over myself. As one final comment I think ndarray is really awesome. I based quite a few parts of rulinalg on the work done in ndarray - and I got a lot of help from /u/neutralinostar too. I hope that answers your question :)
So?
If they have Python bindings upstream, I thought it would make sense to also have Rust bindings upstream.
Why?
Could you have a small script that sends the code to an external build server?
If you use uncompressed archives, you can just mmap out the files directly.
That’s (a) cheating, and (b) missing much of the point. But you can [integrate it with ECS](https://github.com/lambci/lambci#extending-with-ecs) if necessary, which would allow you to accomplish this, more or less.
Great, but you posted it on wrong subreddit. Rust game subreddit is at /r/playrust 
`ndarray` seems like an awesome library, but one possible downside could be that if this is exposed to users, one would likely be expected to let algorithms work on these N-dimensional arrays, which would complicate the implementation. In my field, ndarrays usually seem to be mostly used as "workarounds" for high performance in dynamic languages like Python, i.e. NumPy. For example, if you need to solve `m` `n x n` linear systems, one would "solve" with an `m x n x n` multi-dimensional array. However, in Rust, you could simply iterate `m` times and solve the `n x n` linear system for each iteration, which is conceptually a lot simpler. I would think that in a compiled high-performance language like Rust, it makes more sense to simply deal with matrices and vectors in the vast majority of cases. Would love to hear some opinions on this though, as I'm curious to learn how other people use ndarrays and linear algebra together!
That's what I'm looking for. Thank you!
I'm not sure, but I would expect to have the same API regardless of whether the matrix is sparse or not, without needing to change the code. I asked because OP said the library was meant for high-dimensional data, which is often sparse.
&gt; With try!() you'd likely see a couple more temporaries I don't see how this assertion is founded. Using temporaries is entirely orthogonal to the error-handling syntax.
I'm curious, is this an official client, or just something you whipped up in your spare time? If it's the former, we'd love to have Sentry listed on the page at https://www.rust-lang.org/friends.html :)
Yep, I know that. :)
* I'd have to setup the "mirror" on some our server, which most probably has greater costs than benefits. * Since it's proprietary code, I won't be able to share it, but I might provide some high-level explanation of what it does and how. * I will probably check this somehow (asking colleagues)
Wait, you want to use AWS Lambda to _compile_ your Rust code (not just run the resulting binary which is probably only a few MB)? That's fine I guess.
You're making a very good point, so let me try to explain why I'm dubious that it is a good idea. In terms of solvers, sparse and dense linear algebra is **very** different. With dense matrices, there is usually not so much configuration you can (or need to) do. Depending on the structure of your matrix, you can choose an appropriate algorithm, but beyond that it's more or less just raw number crunching. For sparse matrices, you would typically use iterative solvers, which do not directly solve your system, but rather iteratively approximate the solution until it is "good enough", which you specify through a tolerance parameter. As with dense linear algebra, you need to choose the appropriate algorithm for your problem. But in addition, you need to make a number of additional choices. These can often be very specific to the algorithm of the iterative solver, so a unified API is very difficult to get right, and often brings more problems than it solves. For example, for most iterative solvers you can specify the initial starting guess x_0, the desired accuracy, a suitable *preconditioner* for your problem (which in practice is often entirely necessary to get any kind of decent speed), and also perhaps a maximum number of iterations or other parameters. These examples are typically parameters that you need to specify for your actual problem. Indeed, sensible defaults are not sufficient. As you can see, supporting sparse matrices brings a lot of extra complexity to the project, and beyond the core notion of matrices and vectors, is almost entirely separate from the topic of dense matrices, since both the storage and implementations of core algorithms are different.
Well I just didn't know this, thanks.
That is the official cli client. Feel free to add Sentry there :)
I've been doing Rust for over three years, and I wish something like the book was around when I was learning it! I mostly learned it by writing a bunch of code for "toy" problems, reading extant code (which at the time was mostly servo, rustc, and the standard libraries), and lots of questions on IRC. I think it worked pretty well.
&gt; the combination of the final ? and the Ok() constructor is redundant. Without `Ok(x?)` the type conversion does not happen.
Rust's string (array?) funkiness strikes again! If `read_line()` overwrote instead of appending, it could lead to invalid UTF-8. At least it is consistent; every read function that takes a growable vector (`Vec&lt;u8&gt;` or `String`) appends instead of overwrites.
&gt; Part of the code which works with Foo structure is in the relatively hot part If you end up using `Vec` and know in advance the length that you want, you can use `Vec::with_capacity` to avoid re-allocating multiple times.
Okay, so I just got back to it and [committed](https://github.com/RDeckers/rust_c_comp/commit/a00a754bb70cbb5163352aefe9605d78b5d6b73c) an incremental sqrt for the rust code. What I ended up doing was to start with `(n+1)^2 = n^2+2n+1`, so if we know that `isqrt(m) = n`, then `m+2*n+1` is the first number for which the integer root is larger (by one). So, I added a few variables that keep track of how far we are from the last `m`, and of `n` which is our upper limit anyway, and when we overstep this boundary: compute the new boundary, reset the tracker, and increase the limit (sqrt). On my current machine this reduces the run-time by almost 30%, and I haven't really tried to micro-optimize it yet. edit: hrm, wait. I get what you meant now. I guess that might work better... edit 2: there doesn't seem to be a significant difference between counting steps till the next isqrt() or by keeping track of `(x+1)^2`. If anything, step-counting seems to be slightly faster right now. (~50ms vs 52ms to compute 50k primes, +- ~1s)
to me, this looks relatively cool and fairly promising but what would I know, any opinions?
That's just `map`? Rust's `?` has a more non-local effect and `?` doesn't feel prominent enough for that.
/u/Andlon answered this way better than I could have, and taught me a bit too! I'd love to see some work on sparse representations. As you're probably aware it comes up fairly often in machine learning. But it wont be something I work on for a while (nor do I have adequate knowledge yet).
`specs` is not an Amethyst library. It's not under the organization, developed independently, and just happens to be the ECS of choice for Amethyst, which still struggles to become usable. As for the game engines, let me point you here - https://github.com/amethyst/amethyst/wiki/Other-Game-Engines-in-Rust
well, you started to work on specs while partecipating to the Amethyst ECS discussion, as I was reading it. If you look at the phrasing in the article: "It spawned, amongst other useful libraries, a parallel ECS, specs" that's exactly what I wrote. I'm aware of that engine list, I just haven't included *every* engine anyone has ever built in Rust, just the ones that are actively worked on, and that are likely to be useful.
&gt; rust-curl also (despite being not a pure rust library) compiles really well out of the box on Windows, macOS and Linux. I had the opposite experience on Windows
With rust curl? When did you try it? The version on crates.io definitely compiles out of the box. 
Can you maybe post a bit more of your code? It seems you assign the response to a variable that is declared as a `StatusCode` somewhere.
It seems that you've imported `StatusCode::Ok` into your namespace, shadowing `Result::Ok`. That's a bad idea and that's why your match doesn't work. And to answer your question on how to get to the actual response - `Response` [implements](http://hyper.rs/hyper/v0.9.9/hyper/client/response/struct.Response.html) `Read` trait, so you can for example call `read_to_end` or even just `io::copy()` it to `io::stdout()`. I think that this behaviour is quite well documented on [this page](http://hyper.rs/hyper/v0.9.9/hyper/client/index.html#get), which contains examples and note about read behaviour. The docs are missing from the actual `Client` struct though. It's worth filing a bug, imho. But in general, it's always a good idea to always look at documetation of parent modules, as they usually contain a more general overview. So I'd read the docs for `hyper`, `client` and `Client` - in that order.
This suggests `serde_codegen` is unsuitable for you but it's not clear why.
It's a CI, so I think it's reasonable.
Hmm. That's odd. I don't have to do anything other than having to have VS2015 installed on the machine. Definitely compiles out of the box. I run this stuff on appveyor and it compiles it there just fine and my windows machine also built it just like this. (It also compiles for the gnu target on windows but the gnu target is meh :P)
Thank you for advice, I know about it. Because I get this struct from parsing data in which size of array is known I'll definitely use it.
One concern I have with this is that it strongly implies you can copy+paste the definition of `UnsafeCell` as given into your own code and get the same effect. So far as I remember, *you absolutely cannot do that.* Specifically, the article completely omits the most important part of `UnsafeCell`'s definition: `#[lang = "unsafe_cell"]`. `UnsafeCell` is kinda like the Highlander: *there can be only one.*
Quick question, what would you recommend in a situation like that, where one namespace shadows another? Just alias it?
Afair, the claim from the article &gt; [Raw pointers] don’t have aliasing or mutability guarantees, unlike references. is actually wrong, `*mut T` do usually come with aliasing guarantees, *unless it comes from UnsafeCell*, which is why it's a lang item. I'd love somebody who remembers this better than me to confirm/infirm it, though.
So I'm trying to do that clever thing where you `collect()` a vector of results into a `Result&lt;Vec&lt;_&gt;, sometype&gt;` to see whether anything in your `map()` failed, but I'm having trouble expressing the type which satisfies the trait bound when I'm returning `[Result&lt;f64, f64&gt;; 2]`: fn main(){ fn f(inp: &amp;f64) -&gt; Result&lt;f64, f64&gt; { if *inp &gt; 3. { return Err(*inp); } Ok(*inp + 1.) } let v = vec![[1., 2.], [3., 4.]]; // but I just want errors! let res: Vec&lt;[_; 2]&gt; = v.iter() .map(|elem| { [f(&amp;elem[0]), f(&amp;elem[1])] }) .collect(); } I have naïvely tried `Result&lt;Vec&lt;[f64; 2]&gt;, [f64; 2]&gt;`, of course. (and on the playground: https://is.gd/f1gtf1)
That's curious, I did just that (copy the definition), tested it in the Rust playground and it worked fine. I omitted the non-stable, non-public constructs, though. Maybe that's why it works? https://play.rust-lang.org/?gist=fe5b395b2e07e2b85758e337cf47ed10&amp;version=stable&amp;backtrace=0 Thank you for the comment. You're entirely correct that I should have mentioned the `lang` directive.
I think, if you deref a `*mut` pointer, rustc/llvm will still make optimizations assuming it is not aliased. Notably, the [rustonomicon quotes](https://doc.rust-lang.org/nomicon/transmutes.html): &gt; Transmuting an &amp; to &amp;mut is *always* UB meaning that, if `a` is an &amp;-reference, let b = unsafe { &amp;mut *(a as *const _ as *mut _) }; is UB. But this is basically what UnsafeCell does, and it can do it without it being UB because it is a lang item. At least, that's my understanding of this stuff, but again, I'd like confirmation by someone who is sure about it.
In this case it does stand out thanks to an uncommon combination of bright color and large heavy font. And sure, one could adjust coloring settings to make some syntax easier to notice but that's somewhat beside the point.
There is no inherent overhead from calling into C from Rust or Rust from C.
If you hover over the logos, it explains in what capacity, as well as providing a link if we have one.
This is what I've heard as well. Still, can anybody produce specific code which behaves incorrectly with the naive `UnsafeCell` implementation?
Oh! Hidden feature! (I never thought of hovering over the logos, I recognize the companies anyway so do not need the tooltip :x)
That doesn't seem correct, std::ptr::Unique&lt;T&gt; transmutes a *const T into a *mut T, so that's not UB: https://github.com/rust-lang/rust/blob/master/src/libcore/ptr.rs#L731
I think if you involve some functions with &amp;FakeUnsafeCell arguments you can get it to break. Its a bit hard to reverse engineer the optimizer for stuff like this.
The trampoline would get optimized away but in any case, it was removed in [PR 32080](https://github.com/rust-lang/rust/pull/32080), specifically [this commit](https://github.com/rust-lang/rust/commit/aec63821d04872f9190c3d8606d0a58428005222) which GitHub informs us is in 1.9.0.
Why does it not rely on Racer for code completion?
*Here's the Urban Dictionary definition of* [***Fenangle***](http://www.urbandictionary.com/define.php?term=fenangle)) : --- &gt;To arrange something after a lengthy or comlpicated period of negotiation. --- _I swapped three shifts to "fenangle" a week off work._ --- [^(about)](http://www.reddit.com/r/autourbanbot/wiki/index) ^| [^(flag for glitch)](http://www.reddit.com/message/compose?to=/r/autourbanbot&amp;subject=bot%20glitch&amp;message=%0Acontext:https://www.reddit.com/r/rust/comments/4sa08x/learn_you_a_rust_iv_lifetime_fenangling/d584jfh) ^| ^(**Summon**: urbanbot, what is something?)
Rust strings are allowed to have NUL stuck in the middle, which means borrowing a C string from it won't work right.
Can't IntelliJ integrate with external code analysis tools? Or the issue is that Rustc helps with completion but not with the other things? edit: for example, [intellij-haskell](https://github.com/rikvdkleij/intellij-haskell) makes use of ghc-mod (but ghc-mod is much more feature-complete than Racer)
While cool I fail to see how this is relevant to Rust itself. This is a topic better suited for /r/programming
While there is no overhead of calling C functions from rust as far as I know, the situation is a little more interesting if your rust functions will be called from C: Unwinding (during a panic) across ffi boundaries is undefined behaviour, as such you'll probably want to catch panics right before returning from a rust function to a C function, which can have an impact on performance, as servo has recently discovered, see [rust-lang/rust#34727](https://github.com/rust-lang/rust/issues/34727).
So this means that converting a Rust string to a C string is not a sure thing, and you need to decide what to do with a NUL in the middle? Why not just disallow NULs then. ... C strings are a mess.
Using vs code + racer, can't for the life of me get it to complete member fields/methods (foo.bar() doesn't auto comeplete, Foo::bar(foo) does, but who writes code like that).
I can try to phrase that differently, but I can't change the fact that it is one of main pieces used in Amethyst at the moment.
[Detraction of libuv](https://www.reddit.com/r/rust/comments/2l0a4b/do_rust_web_servers_use_libuv_through_libgreen_or/clq8r8s)
I'm not an IDE fan (I definitely see is uses), however, this was a huge blocker for people using Rust at work. Once this becomes more feature complete I'm sure rust will really pick up steam. This is awesome!
I'm curious, is the main reason to implementing a scripting language so that it would be easy to script for games built in piston, much like how lua is used for the source engine in games like garys mod?
&gt; our example seems to be using some kind of global state for the image repository, where initialize_the_repository() initializes the global state, and get_image_from_repository() queries the global state. Yes, exactly. I recognize that this can be problematic, but I'd like to do it in order to save on memory - load the images from disk once, perhaps even only when requested, and then pass around immutable references to them, rather than copying large amounts of pixel data everywhere. As a matter of fact, though, I think reference counting can solve this problem. Thanks!
Oh wow, I finally understand the `reference must be valid for the static lifetime` error. Why isn't the lifetime inferred along with the type? Also, is this a problem for every type constructor (Meaning `Foo&lt;T&gt;` is actually `Foo&lt;T + 'static&gt;`) or a special case for Box?
Autocomplete works for me only with file-local functions, before I see list of functions CPU usage reaches 100% for a few seconds... I don't have any suggestions for creates or core rust.
You are actually right about this case, yes. The general pattern is common in the codebase however.
I remember taking a look at the blog section of the piston.rs website a while ago and I got the impression that nothing is happening in the piston project, and the website maintainer is working exclusively on their pet scripting language project. Looking at the blog seems to confirm this: page [one](http://blog.piston.rs/) and [two](http://blog.piston.rs/page2/) contain only Dyon-related posts. Page [three](http://blog.piston.rs/page3/) contains a single non-Dyon-related blog post, from the 4th of March. The second most recent non-Dyon blog post is on page [four](http://blog.piston.rs/page4/) and dates from 2015. Perhaps my impression of Piston is completely wrong. If so, I think the website could benefit from one or two blog post that do not focus on Dyon. Even a summary of what has changed since 2015 would do much to counter this impression (unless Dyon truly is the only thing that has seen development in the last half year).
Oh okay. I was thinking he was asking which CI would be best, not about trying to get rust on it. When it comes to Rust right now I'd just stick with Travis CI and Appveyor
/r/playrust is the subreddit you're looking for. This one is for the programming language Rust, not the game. 
On top of what /u/K900_ has already stated you'll be better served typing that text out for people to diagnose because that is close to unreadable. Giving them some context as to what you did as well as a title that says "I'm having an issue with Rust, could someone please help me out?" will come across better than your title and will make them more inclined and better able to help. Best of luck! :D
https://github.com/rust-lang/rust/pull/34521#event-715195553
https://github.com/GuillaumeGomez/this-week-in-rust-docs/pull/29
I'd just not import it (and use the full path like `hyper::Ok` or `StatusCode::Ok`). If you still have a conflict (or just want to save typing), you can `use x as y;`.
Interesting, thanks for sharing. Also, seems like parking lot was able to sustain some pounding, definitely worth a look.
I have to appreciate the fact that their post is more nuanced than "REWRITE EVERYTHING IN RUST!!!111"
You didn't link it :C http://lists.llvm.org/pipermail/llvm-dev/2016-July/102133.html
Python is the only language with somewhat functioning Qt bindings, but even that is far from complete. The truth of the matter is that Qt has effectively zero support for every programming language except C++. GTK3, on the other hand, has excellent support for Rust.
&gt; In the case of C calling Rust, yes, definitely, because you need to catch panics on the Rust side (well, at least for production quality code). FWIW, you could compile with panics as aborts, then I don't think you need to catch panics. Whether this is a good idea or not, I don't know (because your code would have undefined behavior depending on the method of compilation, which seems a little hokey).
Also, the UI of your blog is not friendly to mobile screen in landscape mode : there is a side-bar that covers part of the text :/
Great! I would suggest putting something in the key takeaways too.
Ok... Last question I guess. Even without `println!` I still got an error about borrow for this code: fn call2() -&gt; Box&lt;Fn()&gt; { let varx = 3i32; Box::new(|| { drop(varx); }) } If closure is just an implementation of Fn for anonymous struct, I guess it should contain copied value of varx not a reference to it. &gt; Not good in what sense? It's an appropriate way to consume a value. I put drop() function to suggest compiler that varx will be taken by self and not &amp;self or &amp;mut self, but it looks like it doesn't care.
Yes, just call `map.range(Unbounded, Included(value)).next_back()` to get the last element &lt;= `value`.
They've even based themselves on the Jetbrains website. Great touch!
Alternative: C libraries should always accept an additional length parameter. It makes code more versatile, by allowing NUL in the middle and additionally more efficient, because you can get the size without having to look at them byte by byte and additionally slice constant strings in constant time.
&gt; closure is just an implementation of Fn for anonymous struct That much is true. &gt; I guess it should contain copied value of varx not a reference to it. So, this is maybe a little unintuitive. And perhaps I've been unintentionally misleading by virtue of being imprecise/incomplete (though I did start with a disclaimer! :D). In any case, let's take a step back. Creating a closure by default borrows the variable bindings from its environment. If you use `move`, it will take ownership from its environment and invoke move semantics for the bindings. If you use a binding in such a way that it is consumed in the closure, it will invoke the binding's move semantics. Move semantics are different for `Copy` types than for non-`Copy` types. Moving a `Copy` type makes a copy. Therefore it does not prevent continued use of the original binding the same way it does for a non-`Copy` type. So in your case, calling `drop(varx)` invokes the move semantics for `varx` and would a copy. But that doesn't prevent further uses of `varx`, so the closure still has its default behavior and borrows `varx`, storing that reference. It looks something like this. struct Anon&lt;'a&gt;(&amp;'a i32); // struct created by compiler impl&lt;'a&gt; Fn() for Anon&lt;'a&gt; { .. } // impl created by compiler fn call2() -&gt; Box&lt;Fn()&gt; { let varx = 3i32; let anon = Anon(&amp;varx); // drop makes a copy but doesn't prevent other use so closure still borrows varx Box::new(anon) // error: would leak borrow of stack variable }
`Foo&lt;Trait&gt;` is `Foo&lt;Trait + 'static&gt;` but `&amp;'a Trait` is `&amp;'a (Trait+'a)` and `&amp;'a Foo&lt;Trait&gt;` is `&amp;'a Foo&lt;Trait + 'a&gt;`. That `+ 'static` or `+ 'a` is part of the trait object itself and indicates the shortest lifetime that may be present in it.
Currently the autocomplete doesn't automatically trigger in places where it should. You can always bring it up with Ctrl+Space. However, let bindings do not typify unless you've explicitly written their type right now.
First off huge thanks to everybody who has contributed to racer and the surrounding tools that integrate it with the various editors out there. One question: What's the story for being able to navigate to structs/traits generated via macros? Its probably the feature I would like to see the most.
Tried to use the plugin. It does not see my `src` folder. What am I doing wrong? http://screencast.com/t/uhRA5xLAG39
I'm pretty sure you can compile with panic=abort and panics do not have o be catched. Correct?
Is there no consequence related to the different compiler tool chains?
Have you tried Atom as an editor for rust? That's what I've been using and I'm curious how intellij stacks up.
Only when the panic in your application is a fatal error. You cannot let panic=abort when it's not the case, e.g. you want to display a graceful error on panic.
It's possible IntelliJ-Rust will appeal to Atom users as I think there'd be less performance disparity than with most other text editors.
TL,DR: "We cannot assume a JVM or Python interpreter is available and vulnerability free ... Rust has immunity to certain classes of security vulnerabilities thanks to its powerful type system, making it an excellent choice for security critical functions. In addition it has trivial interop with C libraries and APIs. Rustup.rs makes it trivial to cross-compile to the ... target triple which statically links the resulting programs. Rust ecosystem is one of the fastest, and most maintainable ways to build the utilities we needed... Scala remains our exclusive language for our online serving, but Rust is here to stay powering small but critical components of our programming assignments infrastructure."
I'm trying to create a function which return a custom error type, similar to how the [book does it](https://doc.rust-lang.org/book/error-handling.html#defining-your-own-error-type). I got stuck trying to map the old error types to my new error type. The final try macro in the function fails, because the match inside the try macro expects a Result. I produced a minimal example [here](https://is.gd/Auksrk), and would appreciate a second set of eyes, as I can't make heads or tails of it.
It can be done, but racer's interface is incomplete and is difficult to work with in-memory buffers. Most editor plugins write the buffer to a temporary dotfile first, then delete it. IntelliJ's PSI engine is running all the time while you write, and is able to process code from many different kinds of sources. For example, std analysis currently comes from parsing out of a zip of the rustc sources.
Try importing the directory as a new project (File -&gt; New -&gt; Project from Existing Sources). It should prompt you for the Rust toolchain to use.
I know about Ctrl+Space, it doesn't work, it takes 3-5seconds to find suggestions for file-local functions and variables, never autocompletes crates.
It's a massive read and a bit complicated: https://github.com/rust-lang/rfcs/issues/1081 This is the last piece of the rust puzzle for me. I'm already bending over backwards for async coding in a multitude of other languages.
While the GTK+3 bindings are nice in Rust, the GTK is basically Linux only. Support for other platforms is generally from unofficial ports and are sometimes pretty janky.
It needs SDL2. If you're on a Debian-based distribution, `sudo apt-get install libsdl2-dev` should install it.
I'm actually just using rustc-serializer, but it's mainly because I was using it for another thing and found out it could also do JSON. I'll take a look at the one you suggested to see if it's simpler.
Thank You so much. That fixed it. I know this is really a noobish question but where is the .exe? It's no where in the files.
Is there something wrong by having coroutines as a library?
Cool~~~~Good luck. Make big money~
I'm not sure exactly why it can't determine the type in this case; but you can help Rust along without an explicit type using a partial type declaration. See: [playground](https://is.gd/v3Xh87). Edit: This is more likely due to `collect()` having trouble with the type inference. The docs note this as well: &gt; Because collect() is so general, it can cause problems with type inference. As such, collect() is one of the few times you'll see the syntax affectionately known as the 'turbofish': ::&lt;&gt;. This helps the inference algorithm understand specifically which collection you're trying to collect into.
Really important that `Cell` has a `Copy` bound on the type parameter `T`, see https://github.com/rust-lang/rust/blob/cfcb716cf0961a7e3a4eceac828d94805cf8140b/src/libcore/cell.rs#L163 Without the Copy bound it wouldn't be safe.
It's nice to see some use of parking_lot in the wild! Just a small correction, the original parking lot implementation in C++ was made by the Webkit people (Apple), not the Chrome people. I wrote the Rust version partly based on the C++ one, but with many parts rewritten entirely &amp; improved.
OK!
GTK3 is here since a while already. Not so sure GTK4 will be out any time soon.
Piston is a set of libraries for building game engines. To boost productivity, depending on the size and complexity of the project, you might need a scripting language. Some engines use Lua or another scripting language. My main reason for working on Dyon was it was so fun to work on it and use it, that I could not stop, I enjoyed it too much. I did it because I had some extra time waiting for Gfx releases, but once I started, it was like all the pieces came together and I built a scripting language that I use on daily basis.
I think this is due Rusts type inference being greedy. And indeed if you remove the assignment it works fine: https://play.rust-lang.org/?gist=8070e6794854f085e135fd7c6c3d66a2 Basically Rust infers the type of a variable on it's first use (which in this case is ambiguous).
You'll have to compile it for windows. The default is to compile with the native toolchain, which is linux in this case. You have two options: 1) compile with Rust on a windows machine. (Easy, if you have a windows box) 2) Try to cross-compile from linux-&gt;windows (Harder, maybe rustup can do this?) The cause of this, among other things, that Windows and Linux use different formats for their executable files. Edit: [The Arch Wiki](https://wiki.archlinux.org/index.php/Rust#Windows) has something on cross-compiling to windows using rustup if you're curious. If you are using Ubuntu or some other distro then you'll have to change the packages you install though. 
you can't run a linux binary on windows
I think I see why: since `&amp;mut T` is not `Copy`, `Cell&lt;&amp;mut T&gt;` would break the no-aliasing rule. Thanks for pointing it out, I'll add it to the article.
Ohhhhhhh. 
No I haven't tried Atom. Comfortable with Sublime etc. 🙂
Yep, that was the idea \^_\^. We don't want to alienate any of our friends here, but y'all are also possibly some of the best people to know about us. If someone here sees about the new business, they can go to their manager and say "hey, here's a company we can pay money to get us started in the Rust world"
What size projects would you do professional code reviews on? I've got a small (couple hundred lines of code) hobby project that I've been working on and have been thinking about presenting it to my company when it's finished. Most of the people I work with haven't heard of Rust, and I'd like to give them a good first impression and be able to demonstrate why it's a suitable replacement for some C and C++ projects. Basically, what would be the cutoff for "not worth our time" with regards to project reviews?
I agree on this point, and was also very apprehensive when reading that passage on the website. Later on they say that Rust has taught them more about pointers than any language before, but that doesn't make up for the "I don't know pointers"-statement given earlier. Should probably adjust the wording there, somehow.
I do like the name, good luck!
Will it be open / is it on github?
is /u/shepmaster this guy on [stackoverlow](https://stackoverflow.com/users/155423/shepmaster) ? No doubt he is one of the few best rust users !
The very same :)
Thank you for the advice! &lt;3 I hope to be known as more than a twitter celeb someday ;)
Thanks, this is really great feedback!! &lt;3
Thanks! I hope that I'm able to transfer the experience I have helping people on SO to helping companies adopt and learn Rust.
&gt; I have zero confidence in you as a programmer if you find understanding pointers difficult. That is a pretty harsh and negative statement, and very uncharitable reading of what is written. And you seem to understand that, since you followed it up with "downvote me if you must," but you said it anyhow. If you feel like you have to include such a statement in your post, you might want to reconsider your sentiment or your phrasing. "Understanding" pointers can mean a lot more than just "I understand the concept of a value that refers to another location in memory, and that such a value may not point to what you think it points to at some later time in the program." Pointers in languages like C and C++ are fantastically complicated concepts. Very few people actually understand them very well. In fact, a memory model was not defined for C or C++ until C11/C++11. Until the work that defined the memory model was completed in about 2007, no one could claim to comprehensively "understand" pointers in either language, without reference to a particular compiler and particular architecture. And even if you restrict yourself to just single-threaded programs, and ignore compiler optimizations that may do odd things in the presence of undefined behavior, there's still a huge gulf between an understanding of what pointers are and how they behave, and an understanding of how to use them effectively and safely when programming in the large. Without any compiler support, or even any standardized conventions on documentation, it can be hard to figure out how to effectively design an API, and communicate how it should be used. With just single ownership of values, and no standard way to convey whether a value is owned or borrowed, it can be quite hard to figure out how to effectively use or design particular APIs or data structures, without running into a mess of memory leaks, use-after-frees, double frees, or the like. The hubris implied by saying that "understanding pointers is core to understanding computers," and that the problems with them are mere "slips of the mind and leaving a keystroke out here and there" is part of why we have such a mess in pretty much any large piece of software written in C or C++. A reasonable person, upon encountering repeated issues encountered no only by themselves while learning, but also by people at the top of the field with years of experience, says "maybe I don't understand pointers well enough to use them, why don't I use some technology that prevents me from having to manage ownership of pointers myself as long as I can get the job done." An unreasonable person says "of course I understand it, any mistakes are mere slips of the mind, and anyone who doesn't understand it doesn't really understand computers." This kind of reasoning is dismissive, rude, and clearly ineffective at producing high-quality, stable, secure software. Understanding the limitations of human beings, including yourself, is core to understanding how to write good software.
I don't need to talk to C programmers to know that they fail at it, I have this website: https://cve.mitre.org/cve/ (This is also why I said "empirically", which is a stronger statement than anecdotes. Oh, and not that this matters, but I read K&amp;R at a younger age than you did...) EDIT: the parent deleted their post, but said something along the lines of "maybe it's because I read K&amp;R at 14 instead of picking up programming as a lucrative career in university"
Wow, let's not put down people who get into programming at a university, or who do it because it is a good career. There are many reasons that a person may not choose to or may not be able to (whether through exposure or available resources) be introduced to programming at a young age. The way in which a person became a programmer, whether they're self-taught, university taught, or taught elsewhere, whether they started early in their life or as an adult, doesn't say anything about their abilities or about the quality of their skills as a programmer. This sort of exclusionary elitism is unhelpful, and serves only to make our entire profession worse by erecting arbitrary barriers to participation from competent, hard-working people who have just as much of a claim to being a programmer as you or I do. Furthermore, what does it mean to prove themselves as a developer? To you? Are you a potential client? If not, then it doesn't seem like they'd need to prove themselves to you. If they can make a successful business, and improve the quality of Rust code, then good for them! Let's judge people by the work their business does, not vague shibboleths and arbitrary standards. Finally, why do you think it impossible that Steve knows of seasoned C programmers who would make comments like this? This comment is, for example, perfectly in line with the spirit of John Regehr's work. I don't imagine anyone would argue that John is not a C expert, and much of his blogging is about the difficulty, even for experts, in consistently recognizing instances of undefined behavior in real-world C programs. There _is_ a difference between understanding the mechanics of pointers and feeling comfortable and confident with them, and if anything, the evidence is that any real confidence is little more than hubris in the long term.
&gt; I think something like C forces you to think about the core of how a computer works Even the C specification is defined in terms of an "abstract machine". If anything, C forces you to think about how a PDP-11 works. Granted, hardware operates much more closely to a PDP-11 than you might imagine, thanks to this relationship, but still.
Good points all around! &gt; John Regehr's work. I did professional C development for 6 years and I would claim to understand pointers. Reading through posts by people like John make me **know for sure** that it's highly unlikely that I'll ever know "enough". Things that you take for granted you understand because the code compiled, ran, and produced the right output, so it *must* be right.
You gotta start somewhere. I was a rock star before I became a developer.
&gt; without needing to understand pointers, assembly, logic gates, and all the other things As someone with an Electrical Engineering degree, I wish I could say something like "you must understand transistors to program a computer" with a straight face. \^_\^
That's a good point, *I* certainly don't understand how eg superscalar pipelines actually work. The assumption that people, even people who write compilers, would "understand computers" is the main failing of the Itanium platform
I liked the 128 integer RFC, hopes it enters rust soon! (it discards the need of big ints in a lot of cases!)
&gt; As far as GTK+ 3.x goes, the devs are either insane, incompetent, or both and I refuse to use it. They may be (for other reasons) but the linked article doesn't convince me. They're going to use some non-semver scheme to specify stability guarantees? Bikeshed much?
We've got experience in web applications and data processing, definitely, as well as some arduino/IoT experience, natural language processing, working with databases, integrating with others' APIs, testing, improving legacy code iteratively, and much more! I would say areas where we have less experience are things like ios/android, game dev, Windows, and much more ;) We're quick learners, though. If we have subject matter experts to collaborate with, we can likely help integrate Rust in their specific case.
&gt; subject matter experts to collaborate with I feel that this is really key. If we are able to work with you to understand the problem you need to be solved, then the sky's the limit!
So [WASM](https://webassembly.github.io/) almost
It would be possible to implement yield with a type that implements compiler magic, but it would be massively more readable and usable as a "yield" keyword or something in that family (like await)
I would actually flip the GP's statement on its head, and say I have ~~zero~~ less confidence in folks who think pointers are easy :P It's _dangerous_ to think pointers are easy. It's dangerous to think of them as trivial pointy things that totally cannot ruin your day. It's dangerous to think of them as just a magic arrow to a floaty box as many college courses teach. What a pointer is? Sure, that's a relatively straightforward concept. I've spent hours explaining it to people coming from other language backgrounds who are otherwise amazing programmers (I've also had people grasp it in a second). But it's not necessarily _hard_, it might be new, but not hard. I've seen a lot more confusion on the C++ syntax for pointers and references (using `&amp;` to denote pass by reference, for example, that's counterintuitive), than I've seen on the concept of what a pointer is. But how to use a pointer? That's a completely different concept which requires years of experience to get right. And often universities do not emphasize this at all. I've sorta-mentored a lot of people from all kinds of backgrounds. And most teaching materials that they have touched are like "hey here this is a pointy thing go ahead and use it look how easy it is", as if they were giving a child a crayon, not a loaded ~~gun~~ bazooka^1. You write a couple of linked lists, a couple of simple programs, and think you've mastered pointers. As you start writing larger programs, you get an inkling of their destructive power, but still think you've got it -- the occasional segfault isn't a big deal. And then you touch a large codebase and go down the inevitable spiral of despair, depression, and drinking known colloquially as "systems programming". I've rarely seen the perils of pointers emphasized enough. I've rarely seen any kind of pointer ethic^2 being taught. Sure, it's out there -- there are tons of things out there teaching you how to use C++11 smart pointers properly -- but it's not directly in the discovery path of new programmers. Many program for quite a while before realizing this exists. Rust is an exception to this because it tries to teach an ethic from the start, partially through the documentation, and partially through the periodic meting of punishments of the form of making your terminal bleed^3. But Rust is not the language most folks learn pointers through first. Almost everyone I know who has grasped pointers well enough (well enough for it to not be too dangerous) have gotten this through many years of experience. There are a couple of people who grasped it early, but that's an effect of being exposed to the right code and right people, a privilege which very few have. This isn't really an indictment of the C/++ communities for not making the pointer ethic more visible -- "pointer ethic" is a nebulous concept, can be different for different codebases, and is not something I could write down even given time (If I had to I'd probably just sketch out Rust's model). But I am very much against pointers being labeled as an easy thing to use. Using pointers is hard, and it's dangerous to teach otherwise, or malign people who have issues with them. Incidentally, this is also why I love that the Rustonomicon is written the way it is -- it (over?)emphasizes how easy it is to shoot yourself in the foot, so that you'll never flippantly transmute again. You will instead write a `transmute`, remove it, ponder for a few days, discover the meaning of life, and maybe _then_ feel confident enough to put the transmute back in. ^1 Modified for predominantly American audience ^2 By "pointer ethic" I mean how you use and reason about your pointers. In large codebases, you can't keep track of all the pointers, so you should use them in a way so that _you don't have to_. ^3 Warning: excess exposure to bleeding terminals may lead to systems programming
There are, but in my understanding, the issue is that it's a full crate with dependencies and such, and some of the build system stuff is still being worked out here. like https://github.com/rust-lang/cargo/pull/2857
What lazy operator works similar to `MapCat`. The goal is to cross multiple 2 iterators. I.E.: let a = [0,1,2]; let b = [5,6,7]; let mapcat = [(0,5),(0,6),(0,7),(1,5),(1,6),(1,7),(2,5),(2,6),(2,7)]; I'm currently nesting for loops, and it works but lazy lists are preferable. 
Haha, I know. I was copying an algorithm from a textbook that I didn't want to take the time to completely understand; Knuth used an uppercase T, so I did too. 
Reddit doesn't do a good job of explaining that you either get a link or text, not both. And btw, no need to explicitly put "cross post" if you post a link; it'll be up at the top there automatically.
The part I take offense at is mostly the "We'll break API every 6 months and mitigate it by letting you have potentially dozens of versions of GTK+ installed in parallel... but we'll only guarantee that you'll be able to compile new code against the newest of the set of versions installed on a given PC." That's why the blog post is called "Why do we keep building rotten foundations?"
I believe that only applies to the unstable version ranges (e.g. 4.0...4.4) and both app developers and distros are free to just ignore these and wait for the stable 4.6+, which are guaranteed to not break anything. It puzzles me though why they'd keep skipping odd versions (4.1, 4.3, 4.5) with the new scheme.
Congratulations to everyone at Mozilla! This is a pretty cool step in proving that Rust is a great language.
&gt;Mobile post fall. Part deux.
How would crates work with building Firefox from source tarballs? I hope the plan is to bundle the required external crates inside the tarball. Downloading them as part of the build is a no-no for us (Arch Linux) and hacking around such by maintaining a duplicate list of additional files to download isn't ideal, either. I would be a sad panda if more rust integration makes building Firefox more difficult than it already is. As an aside, neither do we currently build Firefox langpacks because the barrier to do so is far too high (as best I understood it requires juggling ninety hg repos). Neither do we enable Telemetry because the necessary info is missing (#1285201). That said I'm already building with the rust MP4 parser and it went really smooth. Kudos!
Yeah, sorry, I've been really busy in general. I'd like to get more libui work in when I get a chance.
No worries, I can hardly talk since I've done nothing at all myself :) I just thought I'd spread the word in case anyone else wanted to volunteer their help. 
This is really cool, and something that e could actually really use at work! 
Saying pointers are simple is like saying digging holes is simple.
As much as I love Rust I honestly wish this never happens. With all the effort put into evolving web standards nobody seems to care we still abuse a platform that was (beautifully!) designed for a specific purpose for a completely different one. html is a document format and using an efficent native language such as Rust for manipulating HTML nodes to implement a web app is IMHO akin to ordering a double cheeseburger at mcdonalds with fries and a diet coke because "I'm on a diet". 
&gt; Firefox however currently uses gecko as its rendering engine, is it not? It does. &gt; Are there any plans for integrating servo as a rendering engine for Firefox, in addition to/instead of gecko? Servo does not implement enough of the web platform right now to begin considering doing so wholescale, in my understanding.
"Rewriting a browser from scratch" is one of the biggest reasons Netscape lost. See this post by Joel Spolsky: [Things You Should Never Do, Part I](http://www.joelonsoftware.com/articles/fog0000000069.html)
I missunderstood. I just the saw the example which looked like `macro!( yada, yada, yada)` and went back to work. 
DOM manipulation in rust compiled to WASM would be sweet.
[LorenVS](https://github.com/LorenVS/servo-vdom) made some progress towards that goal.
WASM is on a good course, too 
Sorry but this is gone. Document-focused “real” web*pages* will continue to coexist with web applications. The latter are in need of everything any other kind of application needs: performance, debugging, encapsulation, …
Could you clarify what about JS is beautiful for its purpose? Certainly *some* of its design decisions were questionable in ways that can be hotswapped without losing globally desired properties. (Triple-equals, anyone? Lack of static typing?)
By the way, is the integration of the parking_lot mutexes in `std` still hindered by lock poisoning?
Please don't use wildcard dependencies in code people could accidentally copy. Because they will copy and paste that code without reading your nice paragraph about how that versioning works. And then your post will contain broken code whenever there is a breaking change and major version bump to any of those dependencies. I would suggest you either tell them to just write in the current version, or tell them to use the version you used, or tell them to `cargo install cargo-add &amp;&amp; cargo add nickel`, or tell them to remove that star key from their keyboard if they can't resist the temptation. ;) PS: Great article otherwise 😄
What do you need nginx for? Iron already speaks HTTP.
^ That's QotW material!
It's like saying C is simple. Just because something is simple does not make it simple *to use* :x
Don't make me regret my silicon courses!
Not sure if this is relevant to you, but you might want to try the [zero-latency mode](https://blog.jetbrains.com/idea/2015/08/experimental-zero-latency-typing-in-intellij-idea-15-eap/). That was one of my biggest complaints with IDEs.
As far as I understood, browser.html is just a hack to be able to use Servo and is not destined to anything else.
Thanks for the feedback, did not know about cargo-add, I'll update the post now. :)
This is the best tl;dr I could make, [original](https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/) reduced by 85%. (I'm a bot) ***** &gt; The Rust core team&amp;#039;s original vision-a safe alternative to C++ to make systems programmers more productive, mission-critical software less prone to memory exploits, and parallel algorithms more tractable-has been central to Mozilla&amp;#039;s interest in backing the Rust project and, ultimately, using Rust in production. &gt; I&amp;#039;m happy to report that their code will be the first Rust component shipping in Firefox. &gt; For the Rust community as well, this is a real achievement: Rust code shipping to hundreds of millions of Firefox users. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/4sitzo/shipping_rust_in_firefox/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ "Version 1.6, ~78278 tl;drs so far.") | [Theory](http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/) | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr "PMs and comment replies are read by the bot admin, constructive feedback is welcome.") | *Top* *keywords*: **Rust**^#1 **Mozilla**^#2 **first**^#3 **code**^#4 **ship**^#5
As long as the async branch of Iron is still unreleased, it makes sense to put Iron behind nginx, because you can make synchronous Iron busy and DOS it by making long-lasting connections.
I would be very interested!
The more unreadable their code? You clearly have never read any of Knuth's code, an expert in literate programming.
They sadly deprecated the `Zero` trait in `std` and I feel a bit ridiculous for using [`num`](https://crates.io/crates/num) just for its `Zero` trait.
Shouldn't `iron = *` be `iron = "0.4"` in `Cargo.toml` to avoid your code breaking?
did you weave it? Producing: https://goo.gl/I4ubbz
Super-excited you are doing this! Good luck, but I'm sure you'll be great. Personally I'd love to see/hear more of what people are doing with Rust in the real world on r/rust, so the more you post, the better!
There is a lack of info in my post, I apologize. Rust runs on a localport and Nginx is serving on 80 port to the web. I use Nginx+supervisor because I really trust them, my rust service can crash, nevermind, it will restart and the server is still there (and I can update the rust service without interuption of service, Nginx can still serve something). You could do the same with NodeJS: it has a server, but you would prefer use it with an nginx frontend server: http://stackoverflow.com/questions/5009324/node-js-nginx-what-now. Not sure it's clear enough, feel free to answer :) Anyway, thnaks for your reply!
Are there any good Dyon resources? It looks interesting but the README is a bit dense.
It's because in the first part of the code you are using a string literal, which has a 'static lifetime, while std::env::current_dir() does not. You should probably turn them into PathBuf which are the owned versions of the Path slices. Or you could use a Cow if you have a mixture of Paths and PathBufs.
I encourage you to avoid reference-containing objects if at all possible. In general they are awkward to work with and don't cross scopes cleanly without a clear understanding of all the lifetimes involved (and this understanding is also required of everyone reading your code)&gt; Then you'll find that you can make `path_list` a `Vec&lt;Path&gt;` rather than `Vec&lt;&amp;Path&gt;` and your first example will still work. The reason is that `list.push(path)` *moves* the object `path` from the function scope into that of the `Vec::push` function, which then does some magic to make it owned by the vector itself. Your second example can't be directly adapted to this since `current_dir.as_path()` returns a reference, though you can maybe use `.to_owned()` or `.clone()` on the returned object to get the right kind of object, albeit a bit wastefully.
I gave VS Code a try around the same time I switched to Atom but I just couldn't get past the fact you couldn't have multiple projects open at the same time (similar to Sublime Text and Atom, or solutions with VS).
That's strange, are you sure the cargo project was imported correctly?
That seems very advanced. Are there any video tutorials? I can't seem to find one that would help :|
I've been working on this for a couple weeks and it's been usable for a while, so I thought I'd share its existence. The architecture it uses is inspired by the one from xscreensaver, so it should have the same security from that point of view (if not better) and there's a deeper description in the README. There's a [simple](https://github.com/meh/screenruster-saver) API in another crate that makes it easy to write savers, it uses glium as OpenGL API and does a lot of things automagically, so you can just focus on showing pretty things. (Note that I'm still writing the README for that). And there's an [example](https://github.com/meh/screenruster-saver-laughing_man) saver inspired by Ghost in the Shell (which is actually the saver I'm using). It needs a nightly compiler to build, same goes for the API, but hopefully it won't be an issue. If you feel like auditing the code (which would be nice) or writing savers for it and have questions feel free to ask. Also there's a bunch of unsafe code because x11-rs is just a raw wrapper and I couldn't find a safe one, and I'm also using pam-sys for authentication because there's no good enough safe wrapper for it either.
That'd still involve HTML layouts and CSS, though.
Does the IntelliJ engine do any Rust-specific processing? It's written in Java right? Is the Rust-specific part on Github?
Do you have a screen shot of it working? Some people might want to see it in action without having to install the whole thing.
A screenshot wouldn't do much since the whole thing is animated, but sadly recording your desktop in X11 and OpenGL don't go well together. But keep in mind the project is conceptually like xscreensaver, that is the fancy graphics are swappable and implemented separately. Even without the fancy graphics it still functions as a screen locker, it will just make the screen black and wait for you to input the password. In the next few days I'm going to add support for xscreensaver hacks, so you get access to the huge plethora of screen savers that have been done for it in the past 25 years. 
Thanks!
Great, I'll have to try it. I have trully been waiting for this. I wanted to create something really simple like slock but I prefer to procrastinate instead :D. Now waiting to see who creates a login manager, an implementation of dbus and maybe a getty program :)
To my understanding, Servo started as an experiment for using asynchronous algorithms for rendering algorithms. Unfortunately this is a hard thing to do correctly, safe, and efficiently. Then came Rust. Don't know which came first but this was my understanding for how these two projects began
Thanks all! Especially Chris for the great tips. Managed to get it to around 140MB – along with the space needed for gcc and cargo, there's just enough left over to [build mio](https://lambci-public-buildresults-e3xwlufrwb3i.s3.amazonaws.com/gh/mhart/test-ci-project/builds/120/9b033a751bbd9543ddae89122993bc6c.html), for example. Interested to see how many other Rust projects can build on it!
This wouldn't be hard to put together since Servo is just a bunch of cargo packages. For example you can use the Servo's html parser in your project without needing anything else. 
Please be constructive. "You must keep that link bookmarked" is not a very constructive way to start a conversation. I've found many bugs in Rust/Cargo, some of them yet unfixed. When they crop up I will search for them (usually it's just a matter of typing something in the URL bar and getting a result from the history), and mention the bug in the thread. This is a positive thing to do -- it centralizes the discussion and provides context. Railing on someone for doing this is unacceptable. Please be nice.
I totally smell what your steppin' in, but just the other day I wanted to stick a simple, lightweight GUI on a rust application, and would have been quite happy to write something small and run it in a browser without having to learn a whole new GUI framework.
Yeah, it could be different. Usually though a given platform/target defines a C ABI in enough detail that gcc and llvm will interoperate. (If it didn't, you'd have the problem of one compiler or the other not working with libc, for example.)
Rewriting it slowly is good though, in parts and with thorough testing. I think.
IntelliJ IDEA is written in Java, but the plugin is written in Kotlin (something a little more analogous to Rust on the JVM). There is no Rust code in the plugin (yet?). Everything is implemented as subclasses of the existing PSI classes which are normally used for Java but parts are generic enough for all languages, and IDEA offers hooks in the plugin descriptor for different functionality, such as inspections and context-sensitive actions.
lol that ship has sailed. I done mourned that a decade ago. An inefficient, text-oriented TCP-connection per request, client-only-initiated protocol serving content-and-render-jumbled together with a client side language literally invented over a ten day bender hacked into a GUI protocol over 20 years of incompatible implementations that can finally almost match the functionality of a remote display protocol first implemented in 1984, sign me up!
Hmmm. So why is `T` not `&amp;Example` rather than `bool` for the case where `bool` is converted to a trait object when casting the reference?
Yes, for example the spaceapi and spaceapi-server crates: https://github.com/coredump-ch/spaceapi-server-rs Or tealdeer, a tldr (simple form of manpages) client: https://github.com/dbrgn/tealdeer Or rpsrtsrs, a simple strategy game (still in very early development): https://github.com/coredump-ch/rpsrtsrs/
&gt; A screenshot wouldn't do much since the whole thing is animated, but sadly recording your desktop in X11 and OpenGL don't go well together. Consider using a virtual machine to take screenshots.
I keep getting errors when i do try on windows. It doesn't like me at all. This is the latest on windows: https://gyazo.com/8701934262942fa6c8df564249ac3e3b
Speaking of iron, does anyone know what's going on with that project? It seems to be incredibly stagnant as of late.
Weaving it is the only way to read it. Honestly: did you try to read, understand and modify the code and not just look at pretty set TeX? Because it's impossible to search in it due to the lack of syntax elements, it's structured like a book and not like code which makes it incredibly hard to understand what's happening. I also doubt that many people actually try to change TeX as a result of many of the decisions made in that code. //EDIT: also i want to point out that when you edit the code you need to do it via the source so going to the PDF and back is not exactly the solution.
looks like your missing openssl, try getting the correct version [here](https://slproweb.com/products/Win32OpenSSL.html) 
I think graydon started working on Rust years before Go went public, and originally the language did resemble go more closely in some ways, but I don't think it can be said that rust has taken much inspiration from that particular language. 
I think it is nice. This syntax was chosen because it requires fewer changes to move from closure to a function: f(x) = x + 1 f := \(x) = x + 1 When nesting closures, it looks like this: \(x) = \(y) = \(z) = x + y + z Calling a closure has different syntax than calling a function, because type checking is done in parallel and the semantics does not depend on it: \f(1) Besides, in Dyon the `|a|` syntax is used to take the norm of a 4D vector. Wanted to use this syntax for this to keep it closer to mathematical notation.
Did you mean at my workplace? I wrote one tiny tool in Rust where I normally would have used python: https://github.com/rnestler/ip-power-bar-rs But maybe I can use more Rust there in the future :)
:D totally agree with Manishearth's answer, Rust was designed before Go went public. BTW Rust's design elements coming from a wide range of sources, you can see them on https://doc.rust-lang.org/reference.html#appendix-influences. But no Golang in there :D
Well, I'll wait and see. I've got enough old code that I'll need to migrate from PyGTK to PyQt for native Wayland support without also risking having to migrate newer stuff away from GTK+ 3.x+.
The only thing that has broken between releases is just GTK themes due to improvements in the theming engine. The API doesn't actually break, and this is just baseless FUD from the Qt camp. GTK3 software written for GTK 3.10 will still compile and run on 3.22, even though there's a three year gap between these releases.
It looks great on the website, so I installed intellij and the plugin, then made a rust project. That is fine. Then I made a hello.rs with a normal hello world code. I got a message about needing to configure the toolchain, so I select the bin dir of rust. Then it had a textbox for standard library source code. Do I really need the source code of rust to develop stuff in an IDE? I added a run configuration, the cargo command was just run, I am a bit confused by the need to add that manually, but I know nothing about how to make plugins so maybe it can't be added by the plugin. Then, the run configuration said "Error: No Cargo.toml at the root of the module. So I tried to create a Cargo.toml but it didn't care about that, perhaps I put it in the wrong dir, but I put it in the project dir and the source dir... Bloody frustrating. All I want is to just try Rust a bit but with a real IDE. Better stop typing before I start swearing... Anyone who has an ide wha is wrong? 
I'm not sure I understand what's going on here; are you automatically generating the .h file so the extension can be built? Also, how does this fit in with the standard `manylinux1` approach for building Linux-compatible wheels for PyPI? What about Windows? I ask because I've just spent a lot of time setting up the build system for https://github.com/urschrei/convertbng in order for its wheels to work across platforms and Python versions without external dependencies; in the end, I just split the setup into two parts: 1. Grab the latest tagged release of the Rust binary from GitHub 2. Adapt the `setup.py` file to do the right thing w/r/t `@rpath` etc., depending on what platform it's being run. If I want to cut a new release, I push a new tag to GH for my Rust binary, and when the build finishes, I push a new tag for my Python package. I end up with zipped binaries for each platform, and zipped wheels (inc. a manylinux1 wheel) for each platform, respectively. It was eye-wateringly tedious to set up, but it works very well now, and it's fairly easy to port it to a new package. //edit: the part where I realised that I'd have to build my Rust `.so` inside the manylinux1 Docker container on Travis was a notable low point in my life. 
Graphene is Servo. Servo contains APIs which make browser.html possible, these APIs used to be called "graphene" and were intended for an eventual electron-like purpose. Not sure if this is still planned.
What would you use GC for? Just curious as it seems - at least, to me - that if you take away the need for lifetimes (which is what GC gives you), you've removed a lot of the point of using it. 
Go's abstractions aren't lightweight so much as nonexistent. The thing that really makes Go unique is its radical insistence on simplicity, even at the expense of usability.
I guess it depends on whether you talk about abstractions built into the language or user created abstractions. The later is nearly impossible in Go, due to the lack of generics. As for pragmatism, it depends on how you define it. One distinctive thing about Go is that it has a lot of special-cased syntax to handle things that are general purpose language features in other languages. I suppose it's pragmatic in the "get things out the door with minimal language features" sense, but it's not really elegant. As for the standard library, it's crippled by the lack of generics/overloading. For example, it doesn't even have a function to sort lists of unsigned ints. And of course, there's the whole no-reusable-data-structures issue.
All that said, back in the day we definitely tracked what Go was doing and drew a lot of inspiration from it. /u/acrichto' libgreen was trying to implement a similar concurrency model to Go. Likewise there were a few implementations of rustfmt and rustfix that never quite made it. Even our packaging story originally was go-ish where you'd just write something like `crate serde ="github.com/serde-rs/serde"` and rustc would checkout and build the code. Im sure there are others that we tried out and either got in, or cut out. 
Rust wasn't designed to compete with Go. Rust had many similarities in design, but it happened by accident.
What about if there may be aliases but they aren't deferenced during the time the reference is active? The problem is when writing a Rust library to be used from C code with the C code in control of memory management, "no aliases" is pretty much impossible to fulfill.
I realise that - but why still use Rust, then? Seems like a use mismatch. For example, I use C# (which runs on the CLR VM, which uses GC) for all my primary needs, and call out to Rust for things that require higher performance. Others use similar approaches, eg. the integrations others have built for Ruby (which usually runs on a VM, which uses GC) to Rust. You can get a good amount of the ease of use of GC with reference counting, too, which Rust makes available though the Rc and Arc types - these could be a reasonable alternative, though more syntactic sugar to enable this use case is probably needed for using them in this way to be ergonomic as compared to GC. 
Like I said, Go was using a different definition of systems language. They were never competing, just _appeared_ to compete.
OTOH, user-created abstractions give us the same basic end result as language-level abstractions (that being that programming is easier or less tedious). I disagree with the assertion that the lack of generics is a crippling language feature: some languages (notably Java pre 1.5) suffer horribly from a lack of generics, but in Go it's pretty clear that the recommended mechanism is through specialization of an interface rather than a type tag. While this is a little inelegant, I admit, it's very, VERY easy to prototype (since type safety can be added later). I define pragmatism exactly as you did "get out the door with as little cruft as possible". Languages like C++ and Java are hobbled by the amount of tacked-on crap that exists in both languages; Go solves that problem by simply stripping down the language to the smallest possible set of features that don't inhibit a programmer's productivity (for example, C++'s dumpster fire of a memory model, or Java's ridiculous runtime complexity and heavy abstraction to the point of self-parody [can you say WidgetFactoryDescriptionBuilderImpl?]). Now, Rust takes a different approach to this by stripping out *unsafe* features rather than *un-ergonomic* (is that a word?) features. The end result in either case is a much cleaner and more easily understandable language, but it's a matter of preference. To be totally honest, Rust is an occasional experiment language for me, not something I would, for example, use at work, while Go is my frequent go to for both personal and work stuff, and that's because at least in my mind, Go is "easy" while Rust is "safe and strict". I don't really know what you're referring to when you talk about "special syntax", it seems to me that Go is a very regular language and generally very self-consistent. As for the whole sorting unsigned ints thing, I admit that things like that are a bit of a rough edge in Go, and it comes down to the incredibly pedantic nature of the community sometimes ("Oh, we only implemented the intSlice and float64Slice because that's the most commonly used types, so who needs anything else? Just do it yourself!"). Obviously, the "correct" answer is to implement the sort.Interface interface, which exposes the Len(), Less(), and Swap() functions for that type. But yeah, that's a little tedious and should probably be implemented at the language library level by now. But at least Go gives you the tools to do it, you literally just add []uint as the binding type in the function signature for those three functions and it gets bound to the []uint type at runtime, which allows you to call sort.Sort() on it. While this would certainly be a hell of a lot cleaner with generics, it is pretty cool that you can define this behavior at a very granular type-by-type level, and that we as regular programmers have the same power as the standard library maintainers to "build the universe", as it were. At the end of the day, I like Go because it fits my use cases (ridiculously scalable AWS apps) very well, while Rust is (not yet) easy or useful enough for me on a daily basis to warrant serious use. But that's just a matter of preference, and I definitely appreciate the amazing accomplishment that is Rust. Both languages are marvels of software engineering, in my opinion, it's just that one is more useful to me right now than the other.
You're looking for /r/playrust.
I'm afraid that a full wipe might very well occur. Sorry for your loss. Also, you're looking for r/playrust
To someone looking from the outside, who might not know either language yet, they sound _really_ similar: - both compile to native code - both focus on safety (to different degrees) - both focus on performance - both focus on concurrency - both return errors by value instead of raising exceptions - both use panics for unexpected errors
Apart from the complete lack of type safety, the big problem with interfaces is that they cannot effectively refer to themselves, due to the lack of variance and namespacing. If you want a self referential interface, you have to carefully plan it out in advance and manually implement it on every type you care about. And the name collision issue means that it can't coexist with other variations of the same interface. Go's interface system really breaks down as soon as you want an interface that takes or returns interfaces. I'm not sure how "allowing" the programmer to copy paste the same 30 lines of boilerplate a gajillion times can really be considered to be "giving them a tool". As far as special syntax, the big things are slices and maps (replaceable by generics), multiple return types (replaceable by tuples and/or option types), variable return arity statements (replaceable by option types or methods), range iteration (replaceable by generics) and so on. It seems like the thought process was "ok, we obviously need syntax for dynamic type casts. But we should also have a way to test the type. But we don't want them to use different syntax. I've got it! Let's make the operations do different things depending on the number of variables you assign them to! Who cares if it's ugly and prevents composability? Ship it!" Not only is the result inelegant, but it leads to most built in operations being statements rather than expressions, meaning that they can't be composed. In true Go fashion, they decided to add yet another special case to the syntax (if let) in order to handle the most common case of this problem, while completely ignoring the rest. As far as users having the same power as standard library builders, hahahahahahahaha. Oh wait, you were serious? Go is pretty much the least user-friendly major language in this respect. For example, Go is the only language where it is impossible for users to define something like slice or map. Unless by standard library, you mean the standard packages rather than the builtins, in which case this is just vacuously true because pure-Go is so limited that the standard library is just as impoverished as user code. The other thing is that Go's design institutionalizes NIH. Instead of providing standard functionality, everybody is encouraged to write their own, buggy, incompatible versions. For example, it is easy to find countless duplicated functions with names like "findIntInSlice" across various Go codebases, which wouldn't even be necessary in any other language. 
Ooh this looks great and surprisingly mature! Thanks for posting! Is there any specific use case for which the language was designed? Or just a general purpose embeddable language with painless Rust interop?
&gt; Apart from the complete lack of type safety, the big problem with interfaces [...] Interfaces are type safe and are checked by the compiler via structural subtyping. I think you and the parent have an irreconcilable difference in values (that's OK) and are now talking past one another, and I think this thread is teetering way too close to "senseless language war" territory.
There is some truth to it, but only a little. The actual assertion, 'Rust was *designed* to *compete* with Go' is false: Rust developers never saw competition with Go as a driver of its design. Rust's top-level goals of creating a memory safe, concurrent system have never changed since the project became public, but the way it has achieved that has changed drastically. Rust's early design looked much like Go, and that's where the sentiment comes from. Although Rust's early design looked much like Go with MLisms, it was not at all influenced by Go - they were developed concurrently, in isolation. But that's not to say Go didn't influence Rust later - it did quite a lot during the several years it was in open development - but when it came down to many decisions we consciously made different choices than Go. The drivers that led to Rust's ultimate design were primarily our own experience dogfooding Rust, and our experience trying to build Servo. In the early years, Rust's basic design was consistently driven by real experience trying to build the types of software Mozilla needed out of Servo. And although the question of how to compete with Go was never a design driver for the *language*, we've always had to consider how Rust fits into a market where Go is really successful (it wasn't always clear that Go would be the huge success it is). And the design of the language helps greatly when it comes to telling the story of Rust's unique value compared to Go. So you could say rather that instead of Rust being designed to compete with Go, that Rust's strategy for competing with Go is driven by Rust's design. 
Fundamentally the difference I see is that Rust integrates a degree of static analysis into the language itself. Everything else I see as evolution, sometimes converging or diverging with other languages.
Neat to see that stuff like this appears. I hope sooner or later someone builds a version of JavaScript in rust for rust.
why_Camel_Case_When_Using_Underscores?
Just a friendly mod reminder to keep all our jets cooled here.
Full ack, but such a setup is essentially impossible to really get safe.
From the recent announcements (on integrating Rust in Firefox) it seems Mozilla started sponsoring Rust in 2009, the year in which Go went public (after 2 years of submarine mode).
Seems like you have created new project from IntelliJ. Unfortunately, this is not yet properly implemented :( Currently you have to run `cargo new` and then import project in IntelliJ. As for rust source code: we use it for stdlib analysis. It's not obligatory, but thanks to it you will get navigation, completion (in places where it's implemented ofc), quick doc etc.
You can define map in Python, Ruby, JS, Clojure, Haskell, ...
Sweet! Do we know when this will go out in a stable release?
&gt; Does Go really focus on performance? IIRC responsivity (and I/O throughput) is a pretty important pieces of Go's reqs/wants, the GC changes have very much focused on program responsivity and limited pauses (at the cost of of GC throughput)
&gt; Y'know, besides.... Of all the languages you list, only Javascript and possibly Lua[0] preclude writing maps which behave as built-in objects and have similar capabilities. And there very much are reasons to write your own maps in Java (and others), which is also the reason why the standard JDK includes a Map interface and (as of the JDK8) *16 public concrete implementers* (as well as 8 sub-interfaces and an AbstractMap to make implementing new maps easier): the default HashMap[1] is neat and generic but it's still a tradeoff and you may need more specific kinds of maps (there are lots of tree-based maps with useful properties), or want objects which are not inherently maps to be usable as maps. &gt; I don't like being mean, but that is a stupid argument. That you don't understand the argument doesn't make it stupid. &gt; In what language would it be better for users to be able to define their own map or slice type? All of them? You might need a concurrent map, a sorted map, a Judy array, a HAMT or a vEB tree. Same with sequence types, you may need a traversable heap, a rope, a gap buffer or an ordered set. &gt; It's always better to use the language defined one than some cobbled together home-grown implementation. No, it is not. It's always better to *start* with whatever the standard distribution provides, but if what the language provides does not fit the needs there's nothing wrong with switching to something else, and the shorter and less painful the transition the better. [0] I'd think the metatables system is flexible enough but not knowing any Lua I won't make that assertion [1] which is, incidentally, implemented in Java http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/java/util/HashMap.java/
November 2009 indeed according to Wikipedia.
All Windows APIs belong in `winapi`. If it isn't there feel free to open a PR or an issue and I'll get to it sometime during your lifetime hopefully.
I would like to know what all the hype is about. As a programmer coming from high-level languages, what does this mean?
You can do `perf &lt;name of rust program&gt;` to run and profile your rust program and get results that don't just show things like &gt; 1.50% rustc [.] _$LT$reader..DocsIterator$LT$$u27$a$GT$$u20$as$u20$std..iter..Iterator$GT$::next::hd9af9e60d79a35c8 But instead: &gt; 1.50% rustc [.] &lt;reader::DocsIterator&lt;'a&gt; as std::iter::Iterator&gt;::next The second style of output is much easier to read for rust developers.
AFAIK [everything is semantically a reference in Go](https://golang.org/doc/faq#stack_or_heap), it does do stack allocation *optimisation* but so does Java, and while Java possibly does less of it I expect the issue mostly comes down to the overhead of individual objects: AFAIK Go has none if you use concrete structs, while all Java objects have a base overhead of at least 3 words (class pointer, flags, object lock) aka 24 bytes on a 64b JVM. There's also the additional caveat of limited/absent "value types" support: Java objects embedding (including collections which are not the built-in Array) *must* go through references and heap allocation. CPython has slightly less overhead than Java (a type pointer and a refcount) but it doesn't do any SAO (or optimisations in general beyond very basic peepcode) and has no concept of values, or tagged pointers, or anything of that kind, so pretty much everything is literally a reference there.
A common pattern used in the Rust standard library is to write a macro that does the boring bits for you. Like so: macro_rules! entity ( ($($t:ty)*) =&gt; ($( impl Entity for $t { fn name(&amp;self) -&gt; &amp;str { &amp;self.name } fn hp(&amp;self) -&gt; i32 { self.hp } } )*) ); entity!(Character Player);
I usually solve these situations by using macros. IMO it's their most important use case next to reusable early-return code.
Probably the [binary search](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.binary_search) family of methods will be your best option. You get a `Result` with indexes, so whether you get an `Ok` or an `Err` the value should be what you want, or maybe off by one.
I tend to think matching C++ mangling at all should be avoided. It has two problems: first, you're not in control of your own destiny (e.g., the C++ ABI punts on non-ASCII identifiers); and second, you can wind up in unavoidable symbol clash situations if you are unlucky. Curious what you think of this. I hadn't realized Rust needed extra demangling in these areas or I would have put it in gdb. I'll file a bug about it.
&gt; My hope is that I don't have to write identical name() methods on every implementation of Entity. &gt; Is there a better way to handle this? Just use the field (name) itself! There is not point in methods that just return/set a field. 
You want /r/playrust 
potentially julia with CXX https://github.com/Keno/Cxx.jl/blob/master/test/qttest.jl (Is a similar thing possible with Rust? ... Although clearly it's unsafe.)
You are correct that they cannot.
Go is what Java wanted to be, with a less-enterprisey ecosystem and a good concurrent runtime. Rust is what C++ wanted to be, with no C source-compatibility and a safety-first design.
So sorry.
Thanks. Rust seems weird, but the more I think about why things are weird the more sense it makes. Been using python for too long ;)
Although there is [an RFC](https://github.com/rust-lang/rfcs/pull/1546) that would allow fields in traits.