Is there a way to return out from an inner block? &amp;#x200B; For example, in the following code: &amp;#x200B; fn do\_something() -&gt; Result&lt;Something,String&gt; { let config: Option&lt;Config&gt; = match config\_file { None =&gt; None, Some(ref file) =&gt; Some( toml::from\_str( &amp;fs::read\_to\_string(file) .map\_err(|e| format!("Cannot read file {}: {}", &amp;file, e))?, ) .map\_err(format!("Cannot parse file: {}", &amp;file))?, ), }; &amp;#x200B; Is there a way to return out of do\_something if \`read\_to\_file\` doesn't work?
&gt;AWS Firecracker Thanks.
The cheap ones, made to be accessible, yeah. There are more powerful devices from Samsung for example, just Google a bit. Now, should I mention the Pixelbook too? :-)
Awesome! Quick work. Just tried it out and it works great.
Yes, I know about the Pixelbook. But it's not available for purchase in stores here, and it costs $1650 for that model. We have about 200 chromebooks here, 190 of them are running low power Celeron or Pentium CPUs, and all of them have eMMC storage as far as I can see.
Lol we (clippy) didn't ask for it either :) I think I'd mentioned that I wished we'd backported some things to beta when those bugs started rolling in within earshot of a release team member I think. So Pietro mentioned that they were doing a point release and wanted to know if I wanted to include the clippy fix; I said why not. Initially a bunch of other stuff was there, but various folks ultimately decided not to, so clippy was all that was left. I did mention that clippy doesn't need to get a point release for that one fix, but they wanted to test the release process so they went ahead with it. So yeah, usually the bar is somewhat high (lower for beta backports), but this case was special.
I think early or mid June, I'll release it on GitHub. I'll post here on Reddit when the first version is released.
I think early or mid June, I'll release it on GitHub and any help is welcome. :)
You seem to have a fundamental misunderstanding about how rust and/or cargo works. Cargo does download the source of all transitive dependencies; that's the only way it can arrange to compile them. The whole vendoring thing only makes it easier to audit: a matter of degree, not of possibility. Moreover the third party tool is not required in order to do the vendoring; it just automates it. But if you're working in such an environment you probably should just stick to COBOL or whatever where I'm sure the tooling is much better (at least for auditing). I'm not sure why rust has to be everything for everyone.
Thanks for your feedback, I will think about it. Maybe I have an idea how to simplify this. :)
You’ll just have to write the serialize/deserialize functions yourself instead of deriving them.
&gt;Cargo does download the source of all transitive dependencies; that's the only way it can arrange to compile them. I was under the impression it was downloading an object file. But I bow to your superior knowledge. &gt;But if you're working in such an environment you probably should just stick to COBOL ... I will do that. Thanks for your time.
`spawn` is a method that returns as soon as the process is started. This is useful if you need to interact with the process while it is alive, for instance send and receive data back and forth. For non-interactive commands like `dir`, it is simpler to just start the process AND wait for it to finish. This is what the [`output`](https://doc.rust-lang.org/std/process/struct.Command.html#method.output) method does. The `expect` method in the example in the doc is what deals with the process failing to start (for instance if there is no `dir` command). Otherwise, the process did run, and you can check the output.status code, which tells you what it returned (e.g. it can return a non-zero code if you pass it invalid arguments). The doc of `output` also shows how to use stdout and stderr.
Have you seen https://doc.rust-lang.org/std/process/struct.Command.html#method.output ?
The 256 of SHA256 refers to the number of *bits*, not bytes. it's a total of 32 bytes. (though the 64 in u64 is bits as well, so your are tight that you need `u64; 4`)
hmm. I'm not 100% sure i'm agreeing with this. Could work directly while still using Bincode. i'll draft you something tonight because I'm at work now. But if you want the "express" way I'd just calculate the length of each field and insert b"47" at this specific offset. For the 2), you can loop through all the char
Even a straightforward editor like Geany puts the error messages in a buffer, and one can skip to the next error. (But, we learn. For instance, if there's a syntax error like missing ')' up front then the compiler will be naturally confused. Then I fix and repeat)
Thanks a lot. I am still fighting my way to clarity on the topic :)
Do you want me to open an issue ?
Many more eyes on this API. RFCs are sometimes announced / discussed in internals, when they are submitted and enter FCP, they are announced in TWiR, and continue to be announced there until they are merged. All of this gets more eyes than a stabilization PR that's not announced anywhere.
Just out of curiosity, why is parsing DDL the approach you are looking at? Personally I would usually prefer using a database's information schema or other introspection capabilities if at all possible. The upside is that it's easier to get working, but I guess the downside is that you need an active DB connection. Also it's harder for your code to spot when DB-specific extensions are in use, but full fidelity is pretty tough anyway.
This is about the [https://crates.io/crates/geos](https://crates.io/crates/geos) crate which provides bindings to [https://trac.osgeo.org/geos/](https://trac.osgeo.org/geos/)
Related: my [symlink crate](https://crates.io/crates/symlink) that I wrote a couple of years back.
So I have come up with this, which kinda of works, but I can't recurse into the sub-objects to extract their keys and values. fn make_fields(&amp;self, data: String, measurement_name: &amp;str) -&gt; Result&lt;Point, &amp;'static str&gt; { let mut point = Point::new(measurement_name); info!("string: {:?}", data); let t: HashMap&lt;String, Value&gt; = serde_json::from_str(&amp;data).unwrap(); for (k,v) in t.into_iter() { info!("key: {:?} value: {:?}", k, v); match v.as_object() { Some(o) =&gt; { let x = format!("{:?}", serde_json::to_string(&amp;v).unwrap()); info!("object: {:?} {:?}", k, x); self.make_fields(x, measurement_name); } None =&gt; { match v.as_i64() { Some(v1) =&gt; { info!("{:?} {:?}", k, v1); point.add_field(k, InfluxValue::Integer(v1)); }, None =&gt; { error!("skipping: {:?}, {:?}", k, v); } } } } } Ok(point) } The output is funky when it starts to extract a nested object, which I can't seem to get into a format for wrangling. [2019-05-15T07:03:50Z INFO solace_monitor::metrics] key: "bridgingTlsServerCertValidateDateEnabled" value: Bool(true) [2019-05-15T07:03:50Z ERROR solace_monitor::metrics] skipping: "bridgingTlsServerCertValidateDateEnabled", Bool(true) [2019-05-15T07:03:50Z INFO solace_monitor::metrics] key: "eventServiceMqttConnectionCountThreshold" value: Object({"clearPercent": Number(60), "setPercent": Number(80)}) [2019-05-15T07:03:50Z INFO solace_monitor::metrics] object: "eventServiceMqttConnectionCountThreshold" "\"{\\\"clearPercent\\\":60,\\\"setPercent\\\":80}\"" [2019-05-15T07:03:50Z INFO solace_monitor::metrics] string: "\"{\\\"clearPercent\\\":60,\\\"setPercent\\\":80}\"" thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Error("invalid type: string \"{\\\"clearPercent\\\":60,\\\"setPercent\\\":80}\", expected a map", line: 1, column: 41)', src/libcore/result.rs:997:5 stack backtrace:
Internet connection, using multiple languages... not the most important feature, but it’s a tool to help you save time so it should be fast.
Sure thing! That would be great.
Why do you want to do that?
What problem are you actually trying to solve by doing this?
That’s correct. I wanted to stick with the “ignorance is bliss” theming. Open to suggestions!
Points for the effort, but maybe taking the https://serde.rs/impl-serializer.html or https://serde.rs/impl-serialize.html route would be easier?
That’s nice to know. Thanks for sharing. Since https://gitignore.io supports gitignores for individual tools, not just languages, you could use Bliss to manage that file as well, in case your environment ever changes.
Cargo doesnt download any precompiled code. It only downloads the published source code from [crates.io](https://crates.io) and compiles it locally.
&gt;It isn't false at all... safety must be implemented at all levels for maximum effect That is true, but at what costs? I only lock the door to my house, the doors to the rooms are not locked.
Sorry but it's not. ;)
Really? Do you know where in the ${project}/target/debug/ tree it is? The only files I can find are deps/*.rlibs , deps/*.d and incremental/${project}/*.o. None of which seem to be source files / human readable.
&gt; Here's my feeling: every second I spend in MS-related tech is another second I'm not learning the future. That sounds a bit extreme.
https://lib.rs/crates/app_dirs (or the preferences crate) is a better way to portably write some data your application needs. Adding it to the executable is a really bad idea (and harder than you think.) As another person said, you'd need to modify the copy and swap it in, but that really isn't trivial to do right. I'd just use a file (either in the same dir or using app_dirs/preferences.)
Ah, I didn't realise there's more to the process. Thanks!
Thanks, that was helpful! I now have this, though it can only descend one level for now, I have to rework it to get full recursion, by having something return a Vec of points to add, rather than direct point manipulation. fn make_fields(&amp;self, data: String, measurement_name: &amp;str) -&gt; Result&lt;Point, &amp;'static str&gt; { let mut point = Point::new(measurement_name); info!("string: {:?}", data); let t: HashMap&lt;String, Value&gt; = serde_json::from_str(&amp;data).unwrap(); for (k,v) in t.into_iter() { info!("key: {:?} value: {:?}", k, v); match v { Value::Object(obj) =&gt; { for (ok, ov) in obj { info!("{:?} {:?}", ok, ov); let key = format!("{}_{}", k, ok); point.add_field(key, InfluxValue::Integer(ov.as_i64().unwrap())); } }, Value::Number(num) =&gt; { info!("{:?} {:?}", k, num); point.add_field(k, InfluxValue::Integer(num.as_i64().unwrap())); }, _ =&gt; { error!("skipping: {:?}, {:?}", k, v); } } } Ok(point) }
If you're curios the the beta backporting process is explained in [the forge](https://forge.rust-lang.org/beta-backporting.html). Stable backporting is mostly the same, just with the release team also needing to approve the release as a whole.
The source trees are locally cached under ~/.cargo/ by default (just like Maven .m2 etc), and you can configure cargo on a per-project basis to keep the dependencies sorted. I don't find much documentation on how exactly the directory structure under .cargo works, though.
Rebuilding std has other useful benefits though. You can pick different rustflags etc. for std to enable some debug information, pick a different target microarch, use PGO etc. All this will get much easier once we have std-aware cargo.
Yeah, Dyon might work. It has a ton of python-esque ergonomic features, some of them quite powerful.
Thanks, your crate looks intertesting. I'll give a look at it.
Oh excellent, thank you for that link!
I'm confronted to the same problem as you and has already thought of u/kitschysynq's solutions although I thought of one issue with it: You'd be registering a lot of components and systems to the world that you wouldn't need in every states of the game. It could cause issues if you have a similar component designed for two states but that you had to re-implement because one of the state requires specific behavior for exemple, maybe it could lead to collisions. Anyway, I think it's always better to separate different logics when possible, so it makes sense for me to have different worlds for different states.
Just because there was not an RFC doesn’t mean half of this happened. Anything that’s stabilized, RFC or not, goes through the FCP process, and TWIR covers them in the “tracking issues and PRs” section. The only thing an RFC would have done was to have had a second round of this, but this API was in unstable for four years.
Panics are for unrecoverable errors. Results are for recoverable ones. Can your caller do anything if you tell them you’ve errored? If yes, then use a Result. If no, then panic.
This sounds horrible and i hope to never encounter the system that requires this. --- I believe the best solution would be to define a tuple/struct along the lines of (Field1,u8,Field2,u8,Field3,u8....) and serialize/de-serialize that and create two functions to transform between the two.
I gave it some thought The world simply holds all the components. Having multiple dispatchers makes a lot of sense, and using an enum as a resource to tell which dispatcher to use next is actually quite easy too.
Neither the blog post nor the crate description give a summary of what the purpose of the crate is. Both would be helpful (in different situations)!
I'd be really interested to know how the solution you'll use turns out in the end!
Didn't you have some licensing problems with org-rs? So is it done now?
Mainly for that point about not having to worry about application DB connections. Using information scheme is actually a great idea I forgot about though and I can write it quicker and stepwise - general table def, then worry about translating indexes, views, synonyms, etc. Though a solid DDL export contains pretty much all you’ll need. Thanks for your reply!
[Here's a solution](https://gist.github.com/ElectricCoffee/aad0ed88a0162e35bf28d7c4303b8ea1) that I've found works quite well so far. The `States` enum is just used like any other resource in the system, and `States::Main` is set to be the default value for the resource. The game loop then just reads the current state of the resource and dispatches accordingly.
Is this Alternative to firecracker?
It's explained in README. crosvm is for client, Firecracker is for serverless, this is for cloud. They all share rust-vmm.
Awesome :) And another thing I came across recently: https://ogdl.org/, "structured textual format that represents information in the form of graphs". Looks very similar to termpose.
That is a good point! I'll add a small description at the beginning. Thanks for the suggestion!
https://docs.serde.rs/serde_json/fn.from_slice.html
Some websites, books and videos teach as if the "cargo run" is the only way to develop and use rust programs. This is totally misleading. Some readers even get an initial impression that rust is an interpreted scripting language like Python but a lot slower than Python. In my opinion they should talk about the debug and release options upfront and then tell the user they are using 'cargo run' for its convenience during development and it's strictly not for the final build they would distribute / test for performance.
I agree, but the question is if this is worth the effort. Changing this syntax would make it somewhat easier to understand. However, all the Rust developers have to learn the new syntax. People still using older editions have to know and use both syntaxes. Developers learning Rust will be confused by thousands of outdated code snippets on stackoverflow and other websites. Implementing these changes in the compiler, in rustfix, the documentation and learning materials is a lot of effort, too. The metric system is a poor comparison, because its advantages are far greater.
I'm old. My first thought reading the title was "oh wow, we now have support for 16bit x86 targets?"
What about conveying error states through the type system, and bubbing the error up? At least then you can log out some extra info before you shit the bed and crash the app.
That is something you can do with the error, so you should use Result.
Ah right. What is an example of something I couldn't?
I'm still waiting for reply from FSF. In the meanwhile I decided to roll forward with GPLv3
So, it's interesting, because in some ways, libraries vs applications have different responsibilities here. With an application, you are choosing what you want to recover from and not recover from. With a library, you are making a choice for others as to what you can recover from or not recover from. This means that libraries should lean towards using panics less, but in applications, you're more flexible. The general advice is that you can use panics if it was going to be a bug. It's like assertions; you're saying "this should never happen, but if it does, please blow up for me." Sometimes, you know better than the compiler if something should be true. This is reasonably rare, but does happen sometimes. Maybe you're using an API that could fail, but you know that every input you'll ever give it will not fail. In this case, an unwrap/expect is appropriate, because you don't expect the error case to ever happen. Does that make sense?
Sort of yeah. But how can you know it will never fail if there's an expect/unwrap used. Just because you know the impl details for instance?
Yep. So for example, consider replace: [https://doc.rust-lang.org/stable/std/option/enum.Option.html#method.replace](https://doc.rust-lang.org/stable/std/option/enum.Option.html#method.replace) Imagine you have an option, and you use this to put a value in an option: // x is some option here x.replace(5); Later in the function body, you want to get the value of x out. You *know* that you put something there, but since it's still an Option, Rust doesn't know that. It would still make you check for `None`, even though you know that's not possible. So here, returning an error would be boilerplate; it's never supposed to happen. An unwrap would be fine. This is, of course, a contrived example, but the point is that because interfaces are general, but you do specific things with them, sometimes you know that you're doing something specific that will not fail.
Imagine you have a stack (as in: the data structure). First pushing a value and then popping it will never fail, but the stack will have to return an Option&lt;T&gt; anyway to account for other cases where it might actually be empty. Unwrapping here is fine - the operation is guaranteed to never fail and if it does, you're in deep shit.
\*chuckle* I'm too used to the standard pattern of TWIR post names so it took me a while to even notice what you were talking about. That said, even support for a DPMI target would be great. As-is, the strongest compile-time guarantees I can get on my retro-computing hobby machine come from Free Pascal.
I'm in the process of writing my own deep learning library, and I have found arrayfire to be pretty good for my use case(although I will admit it's Ali could be better). That said, I'd say the "worst" part of ml in rust is the lack of good plotting libraries. So far, the best way of plotting data seems to be exporting it as a json and using python's matplotlib.
Got it, thanks
Also I'll remove the \`--use-tor\` functionality in the next release, because users can proxify their traffic using various configurable utilities such as anonsurf and so on.
&gt; and TWIR covers them in the “tracking issues and PRs” section. The FCP process for this tracking issue was not covered there. In fact, the only mention of this in TWIR is in this issue (https://this-week-in-rust.org/blog/2019/02/05/this-week-in-rust-272/), which only mentions the stabilization PR being merged.
That's a failure of TWIR then, but the point still stands that there is a full FCP for everything, even without an RFC.
Well... it is the same command, but with a simple flag. The ease of tooling with Python and Rust shouldn't be an excuse to not know various flags to pass, or about how compilers and other CLI tools generally work. Cargo is a great abstraction over rustc which is analogous to GCC including many features to ease project management. In many compiled languages you wouldn't ever want to deploy a debug build as you risk your debug symbols being leaked which would aid in reverse engineering your source code.
Well, that's not an excuse to mislead people.
Ahhh, that makes sense, cheers.
Related: https://www.reddit.com/r/rust/comments/ask2v5/dos_the_final_frontier/
Thanks. That's really helpful. Hopefully you got the Platinum reward I sent you. #Will show all the cached source cd ${home}/.cargo find . -name "*.rs" 2&gt;/dev/null #or for a specific package like ncurses find . -name "*.rs" 2&gt;/dev/null | grep ncurses # results example ${home}/.cargo/registry/src/github.com-1ecc6299db9ec823/ncurses-5.99.0/src I am somewhat confused as to why this is not stored in the project tree created by "cargo new project". But I am putting this down as a win.
What are you talking about? The root cause of this issue, and most severe bugs in the Rust language and implementation, is "insufficient review". An FCP that's not advertised anywhere and where only 5 people check a box and stabilize something is not sufficient review.
Ah fantastic, I'll have a play with this, thanks! The Rust community is really helpful. :)
Cool, I'll probably use this for the actual game, thanks
maybe you live in a different sphere- but the only windows items in my area are legacy. I can't walk into any client and propose windows-anything development and not get laughed it. Sure, some of their COTS stuff, but development-wise... Also, it's clear MS doesn't care about Windows, as such, they care about Azure because they're making impossible amounts of money off of it. Azure is larger than Windows to them in the sense that you can run whatever you like there and they still get a cut.
Cargo offline mode ! Thanks to whoever worked on this.
You can but only if you already use valid Rust syntax. If it's invalid then it errors before it's inputted to the macro transformation.
100% this. OP, I am hiring for a backend scala role, and would not want to interview you based on the behaviors displayed in your post.
What does the stdin look like? XXXXXX YYYY YYZZZZZZ ?
There are multiple "correct" ways for this and my go-to method is to simply have a error enum. If you want to put more information in it you can simply add a value to the respective discriminant. That way you can always use the try operator and still have the same error type. And just in case it happens that you have multiple error structs/enums, you can use \`.map\_err()\` and add a discriminant to a enum that can hold other errors and group them that way. Though that's probably overkill. But, there's other methods like the failure crate, which I have yet to use.
The simplest solutions are to use an `enum` and implement `From&lt;E&gt;` for other errors of type `E`, and using a helper crate like https://docs.rs/snafu/0.3.1/snafu/.
Interesting, the enum makes sense, thanks. How do you (do you?) implement \`Display\` on that? I can see that I could implement a giant \`match\` statement covering each of my error types but that feels like it would be kind of ugly. But maybe that's the only way?
It looks like $ "1234567890/n" if it gets read in correctly. But if it doesn't I get $ "123456789/n0"
In the Servo slides: &gt;We are **not** “rewriting the browser”. That's impossible. Put down the gun . Impossible things were done...
Well that sounds like you need something a bit more "powerful". You can of course implement Display and whatnot but have to write everything yourself. Or just use a perfectly good crate for that. If however you really want to do that yourself, maybe make use of the error struct in the standard library? It already carries lots of information.
Rust is being used everywhere these days. Cheers to all the rust compiler developers.
Does this relate to the earlier submission this week? https://www.reddit.com/r/rust/comments/bn1b47/simple_kvm_firmware_written_in_rust_from_intel/
I've always wanted to build a dependency injection container that can autowire stuff together. I figured out how to build one that isn't unreasonable this week.
Was Rust always "a safe language with destructors"? I've been leaning on that recently as the shortest way I know of to describe it.
Yes. To quote README: &gt; cloud-hypervisor also supports booting disk images containing all needed components to run cloud workloads, a.k.a. cloud images. To do that we rely on the Rust Hypervisor Firmware project to provide an ELF formatted KVM firmware for cloud-hypervisor to directly boot into. In other words, rust-hypervisor-firmware is a firmware intended for hypervisors. One such hypervisor is cloud-hypervisor. (rust-hypervisor-firmware mentions Firecracker as a hypervisor, but I think that's because cloud-hypervisor was not yet open.)
Hi guys, How do you match on several variants of an enum, with a common field ? Something like: match myenum { variant A(a) =&gt; {...} variant B(a, _) =&gt; {...} }
It certainly has been since 1.0.
I didn't know about snafu. Looks really helpful, thanks
What you write there should already work (as long as the different `a` have the same type)...
`failure` is actually really good. It has a macro to automatically generate Display implementations, which is really easy to use.
I am currently experimenting with error kind per service. Note that this may not be the correct way of of doing error handling. But hopefully something that might help you. See https://github.com/mmrath/ara/blob/master/ara-service/src/core/user/activation.rs Also see other files in the same directory. The idea is to create one enum per service or a group of services. Anything error that the end user does not need to know are converted to Internal variant - more like unrecoverable errors.
&gt; For fun, you can check Niko’s blog post on how Rust's object system works, **Marijn Haverbeke**’s talk on features that never made it close to 1.0 or even the introductory slides about Servo, which present a language looking very different from today. TIL that Marijn Haverbeke, author of Eloquent Javascript, is [on the Rust team.](http://marijnhaverbeke.nl/hob/saga/rust.html)
He has not been for many years, to be clear. But he was! :D
I'm a big fan of https://gitlab.com/torkleyy/err-derive. Fits well into the std::error patterns. But I've used failure and error-chain in the past. Err-derive is the simplest for me to reason about.
Yeah I mean like back when there was mark-and-sweep garbage collection or whatever it was. Were there also, from the beginning, deterministic destructors for types that wanted them? Is Rust the only safe language that has ever had that? Now that I look at [Graydon's old slides](http://venge.net/graydon/talks/rust-2012.pdf), it seems like the answer is yes (but destructors took second fiddle to ownership, borrowing, and value types).
Other languages with GCs have "finalizers", which is the same idea.
You were ninja'd by steveklabnik: &lt;https://www.reddit.com/r/rust/comments/boygqk/four_years_of_rust/&gt;
Except that you don't know when they will run.
He also closed out the very first RustFest in 2016 with a [talk about what Rust could have been](https://www.youtube.com/watch?v=olbTX95hdbg&amp;list=PL85XCvVPmGQh8nWR_Z-fTmPGsUWuzb-dn&amp;index=13)
Sure, that would have been true of Rust at the time as well.
Maybe these will help: [https://stackoverflow.com/questions/29401626/how-do-i-return-a-reference-to-something-inside-a-refcell-without-breaking-encap](https://stackoverflow.com/questions/29401626/how-do-i-return-a-reference-to-something-inside-a-refcell-without-breaking-encap) [https://stackoverflow.com/questions/30281664/how-do-i-borrow-a-refcellhashmap-find-a-key-and-return-a-reference-to-the-re](https://stackoverflow.com/questions/30281664/how-do-i-borrow-a-refcellhashmap-find-a-key-and-return-a-reference-to-the-re)
Without having done any resarch, I think they would be valid toml or ini for which there are plenty crates.
My understanding is that back in the day the managed `@` pointers would have non-deterministic destruction, but that other types had "real" destructors / RAII. But I'm not positive.
I’m not 100% sure as well, to be honest. That was before my time.
&gt;This is really important to think about in Rust code. If you are given say - an &amp;mut self, and you want to borrow against that and return, you need to explain in your function signature the lifetime of the returned borrow That's a good point. I've already encountered issues with the struct memebers where I can only borrow once and one of the difficult areas to interpret is while working with struct memebers. Say I have the example above, I add an additional function: &amp;#x200B; &gt;impl Test { &gt; &gt;.... &gt; &gt;fn write(&amp;mut self) { &gt; &gt;if let Some(ref mut file) = self.this\_file { &gt; &gt;self.process\_file\_another\_way(file, "Some test data"); &gt; &gt;} else { &gt; &gt;panic!("File not processed yet"); &gt; &gt;} &gt; &gt;} &gt; &gt; &gt; &gt;fn process\_file\_another\_way(&amp;mut self, this\_file: &amp;mut File, Data: &amp;str) { &gt; &gt;this\_file.write\_all(Data.as\_bytes()).expect("Unable to write data"); &gt; &gt;} [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0553ed34ab0f3596dc42a6c9d403580d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0553ed34ab0f3596dc42a6c9d403580d) I'll get an error: "cannot borrow \`\*self\` as mutable more than once at a time" This is a good point. Granted, I'm still trying to wrap my head around this. It would be convenient if I could just pass the reference again, but as you described above, i can't. At first, I interpreted this as: "how can I get the compiler to accept this". I started trying various ways to second borrow and even considered RefCell. In the end, I had to change my design, dealing with struct members directly through various other techniques, instead of accessing directly. It still alludes me why this is necessary in such cases, but If I eventually go multithread, it may save me headache in the long run. Erlang has a similar policy, only it copies all references to get around issues in such cases, and you rarely have to think about it. Rust forces you to think about your design. I'm still reading the official doc online, there's a ton there, but I learn quicker diving in and looking at use cases. Thanks for the info :)
The `Context` pattern it uses is the best part, IMO. Making it easy to chain underlying errors into your own "why did we try the operation that caused this error" context is way better than `foo.connect()` returning `no such file: frobnitz.txt` which is some internal DNS implementation detail leaking out and basically useless information in the "what can/should I do about it" error handling case.
Well, it's a cache, doesn't make much sense to have several copies of the same crate scattered around (**cough** npm **cough**)
Having watched your talk I think you did just fine. I found your criticisms of C, C++ and Rust spot on.
What means the `$crate` macro syntax in this PR? https://github.com/rust-lang/rust/pull/60675/files#diff-f7ad4a5ae3364771b775302f47d00063L369
Instead of implementing `From&lt;E&gt;` for every error, I've been using `map_err`, which is a lot less boilerplate in my opinion. Is this an acceptable alternative?
https://www.meetup.com/Rust-London-User-Group/
Good point. Others have suggested the `failure` create, so I'll take a look at that and see if it's overkill for my requirements or not. Thanks!
It's a special variable that always expands to `::name_of_crate`: https://www.cs.brandeis.edu/~cs146a/rust/doc-02-21-2015/book/advanced-macros.html#the-variable-$crate
I really like "Programming in Rust" by Jim Blandy. Good writing style and the concepts are well explained.
I thought the whole joke about Rust is that for everything not on the stack only ownership is transefered, and copies on the heap have to be commanded explicitely with \`clone\`
Perhaps there's a better solution, but combining the `failure` crate with `derive_more` is pretty convenient. `derive_more` let's you automatically derive `From` for your enum variants, making conversion from smaller error types to larger ones a breeze (works with the `?` operator). `failure` makes providing display implementations easy.
It probably is, but with `From&lt;E&gt;` you have to implement it once, and it will work automatically, even with `?`. While with `map_err`, you need to call it everywhere. On course, there are other aspects. `From` will only give you a single conversion from a specific error type. Consider: enum Error { ReadConfig(io::Error), WriteData(io::Error), } Implementing `From&lt;io::Error&gt;` won't help here. But lately I've liked the `snafu` crate, which allows you to do this.
Actually, the last time I looked at it, the GitHub link hadn't been added yet, so thanks. :)
I've never been to a programming language conference. I'd say I'm a "senior" engineer for certain types of systems but I'm pretty new to Rust. So... how good do I have to be to get enough out of a Rust Conference... or any conference to make it worth my while?
I find `snafu` to be nicer and easier to use.
Not very often though :(
Yep, \`@T\` was GC'd, but \`T\`, and Box'd T (\`\~T\`) would be destroyed deterministically
I really like their README's description of their philosophy and commitment to contributing back to and using open source rust crates. The rust-vmm crate can become an amazing resource when all these companies contribute back to it and try to use it whenever possible as opposed to the common coprorate policy of rewriting everything yourself to avoid licensing issues
if you want something being integrated into gnome-Desktop, check for gconf wrappers, this seems to be interesting, too [https://gtk-rs.org/docs/gio/struct.Settings.html](https://gtk-rs.org/docs/gio/struct.Settings.html)
Very, very nice! Do you know how it compares to other renderes performance-wise?
Four more years!
&gt; You still need things like tests and things like fuzzers The only two things named are tests and fuzzers. This makes me fell all warm and fuzzy.
Like re writing an os or sending an Elon Musk to space X. One small step for Musk one giant step for Elon.
I think this is the same reason that calling `.clone()` on an `Arc&lt;T&gt;` will give you a new `Arc&lt;T&gt;`, rather than reaching inside and cloning the `T`. The dot operator applies the minimum number of dereferences it needs to find a matching method name. In this case, `&amp;T` is always `Clone + Copy` regardless of `T`, so calling `.clone()` on a `&amp;&amp;T` just copies the `&amp;T`. Another approach you can use above is combining `zip` with `all`, which lets you do the dereferencing and equality checking explicitly. So something like this: let a = vec![true, true, true]; let b = vec![&amp;true, &amp;true, &amp;true]; assert!(a.iter().zip(b.iter()).all(|(i, &amp;j)| i == j)); But as /u/JayDepp pointed out, that doesn't check that the two collections are the same length, so you would need to assert that separately if it's not guaranteed already. Reading between the lines above, it kind of sounds like you want to check some assertion over the windows of a `VecDeque`, but you'd rather not pay the cost of allocating a vec for each of those windows. You could piece together a custom iterator something like this, to pair with whatever `.eq` or `.all` idiom you prefer: fn vec_deque_windows&lt;T&gt;( deque: &amp;VecDeque&lt;T&gt;, window_len: usize, ) -&gt; impl Iterator&lt;Item = impl Iterator&lt;Item = &amp;T&gt;&gt; { let mut base_iter = deque.iter(); std::iter::from_fn(move || { if base_iter.len() &gt;= window_len { // Clone the base iterator at its current position to make a window. let window = base_iter.clone().take(window_len); // Move the base iterator forward. base_iter.next(); Some(window) } else { None } }) } fn main() { let v: VecDeque&lt;_&gt; = vec![0, 1, 2, 3].into_iter().collect(); for window in vec_deque_windows(&amp;v, 2) { dbg!(window.collect::&lt;Vec&lt;_&gt;&gt;()); } }
You want /r/playrust, but if you ever feel like learning a programming language, you're welcome here.
It has been 4 year research project, no big changes for a long time, so I think it's time to stabilize it. Dyon uses Piston-Meta for parsing code, Here is the syntax: https://github.com/PistonDevelopers/dyon/blob/master/assets/syntax.txt
I'm not great at rust or at programming, but this is my attempt at cleaning up what you had: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=533963144e746f4554d09fe0b900bef5 The two big changes I made were to convert the keypad hashmap into a lookup function that returns an iterator over the key's characters, and to pass a `&amp;str` instead of a `Vec[u8]` or a `&amp;[u8]` for remaining digits. There's more you could probably do to make it more idiomatic, like getting rid of the `panic` by returning a `Result` type for the whole combiner. ([This](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=1bdc3616ffd620bf745f5f5d09182396) is what I came up with before I looked at what you had done. I guess I remember flip-phone keypads working differently than the code test site lol)
I am sorry what do you mean?
This is the subreddit for the Rust programming language, for writing computer programs.
Oh oke sorry i am new to Reddit 😅
The real benefit of the Rust conferences are the friends we make along the way?... Joking aside, I've met people at RustFests who were completely new to Rust and all of them had a mighty good time and learned a ton.
Nothing on the heap is being duplicated here. It's the *reference* to those heap values that's being copied.
When they said in college that undefined behavior could do anything including creating skynet they where joking.
The problem with GTK is it blatantly ignores a lot of things and reimplements objects on top of C as a hack... passing a ton of stuff around as void etc... it's nightmarish. It's isn't just insecure it's terrible code.
Very true. I haven't really written any projects that are big enough to benefit from implementing `From&lt;E&gt;` (only one or two `map_err` calls here and there do the trick). `snafu` looks very interesting though, thanks for sharing!
&gt;Note that these macros don't have superpowers and can't tell if two generic parameters are equal in type. A (limited) way to test that two generic parameters are the same is using my [TypeIdentity](https://docs.rs/core_extensions/0.1.6/core_extensions/trait.TypeIdentity.html) trait: use core_extensions::TypeIdentity; use std::cmp::PartialEq; fn is_equal&lt;L,R&gt;(left:&amp;Vec&lt;L&gt;,right:&amp;R)-&gt;bool where Vec&lt;L&gt;:TypeIdentity&lt;Type= R &gt;, R:PartialEq, { let left=left.into_type_ref(); left==right } Obviously,this only works if you can add a constraint in the where clause. I used `TypeIdentity` [to get around](https://github.com/rodrimati1992/abi_stable_crates/blob/660246e27e9220f741fa8fa57f2e5f972d8cfc9d/abi_stable/src/erased_types/vtable.rs#L180-L194) an ICE in associated constants,where if the type of the associated constant contains associated types they sometimes stop working.
Could I ask you to edit this post so as not to use the work “retarded” in a derogatory context? Thanks!
Who rewrote which OS?
No, the word is pretty fitting
Ah hello, bell labs when they rewrote Unix in C.
Ah,I though you were talking about rewriting a modern OS,with millions of lines of code.
Happy birthday Rust!
What's impossible about that?
Well,it seems like it would be a lot harder to rewrite an OS with millions of lines of code than it would be to rewrite UNIX back when C was created.
J bet a tool could be written to translate c, c++ to rust.
I for one would be very interested - I have a long background in C# and WPF. My Rust currently is still at the learner stage, but once more familiar may be interested in assisting.
As an experienced WPF developer, I have to agree to extent. WPF allows a lot of customisation and templating of standard controls, but being XML-based it does tend towards horrible levels of verbosity. I would definitely vote for something with similar intent, but simpler practice.
Where is joking?
A moment's reflection would have led you to why I and others might care about this -- I personally have a son with special needs. Perhaps you haven't done that reflection, or you have and don't care about how your words and actions might harm others. Either way, I wish you compassion, wisdom and maturity.
I have nothing to reflect on, because I do no refer to you, or your son in particular. So I'm not sure what here is to reflect, because world is not nice place by definition and I see no reason not to use strong word when appropriate.
I have one (hopefully simple) question about the issue people have with self-referential data structures. I constantly hear complaints about this issue and when I read the first 7 chapters of "Programming Rust" by Jim Blandy, there is an implementation for a tree data structure. A tree data type is self-referential, right? And I have no problem understanding the implementation. From what I understand from those complaints, a lot of them have to do with the efficiency of such self-referential structures: allocation on the stack vs. the heap of the self-references. Sure, you could make the self-referential structures without using Box or Rc (or any type of pointer-like reference) but it would be extremely hard considering Rust won't allow you to create/allocate a structure without knowing its size in memory beforehand. Hence, my understanding is that to circumvent the constraint, the use of Box/Rc is the solution. Is my understanding correct w.r.t to the difficulty of implementing a self-referential structure? Thanks
but to *safe, idiomatic* rust?
Baby steps?
God, I miss all those weird sigils.
A tree is a recursive data type, rather than (necessarily) a self-referential one. You can have a simple tree structure like enum Tree&lt;T&gt; { Branch { left: Option&lt;Box&lt;Tree&gt;&gt;, right: Option&lt;Box&lt;Tree&gt;&gt; }, Leaf { value: T } } without many problems. But what if we wanted to add a reference from each node to its parent? enum Tree&lt;T&gt; { Branch { parent: Option&lt;&amp;Tree&gt;, left: Option&lt;Box&lt;Tree&gt;&gt;, right: Option&lt;Box&lt;Tree&gt;&gt; }, Leaf { parent: Option&lt;&amp;Tree&gt;, value: T, } } There is now a chain from the root node to its children, and back to the root: a self-reference. And now we run into a problem. As soon as we add a left branch to our tree, we can no longer add a right: there now exists an shared reference to our root, so we can no longer mutate it. We also can't mutate the new branch, since it's owned by the root, which is now immutable. Oops! And this is a problem you'll run into any time you try building a self-referential data structure the way you would in e.g. C, but with non-owned pointers replaced with references. There are ways around this. One approach might be to just store all of the nodes in a Vec, and instead of storing pointers, just store indices. I believe this is the approach taken by [indexlist](https://github.com/steveklabnik/indexlist), a safe doubly-linked list implementation. You can also wrangle with `Rc&lt;Refcell&lt;Box&lt;T&gt;&gt;&gt;`s, which is illustrated by the [fourth chapter](https://rust-unofficial.github.io/too-many-lists/fourth.html) of Learning Rust with Entirely Too Many Linked Lists. Or you can go the `unsafe` route of using raw pointers, and taking responsibility for never dereferencing `parent` if it no longer exists. This approach is described by the [fifth chapter](https://rust-unofficial.github.io/too-many-lists/fifth.html) of Too Many Linked Lists.
That's true. However, most of my time is spent on `no_std` development, which failure supports very well, but snafu does not.
Is there anything in particular that prevents `snafu` from working on `no_std`? Pinging /u/shepmaster.
Ahhhh. Got it. Thank you. I should probably read those chapters again several times
Best fun fact: he hasn't been involved for 7 years, is still in the top 10 and... all his code is gone, except a couple of closing brackets: https://twitter.com/MarijnJH/status/1103683067057713152
You can also generate C++ classes that call C API, like https://github.com/dushistov/rust_swig do. By the way similar thing do in C++ world, C++ ABI is not clear, so sometimes you for C++ generate C API and then header only C++ library to wrap these C API with C++.
If you want that, it's very easily achievable through [resource dictionaries](https://docs.microsoft.com/en-us/windows/uwp/design/controls-and-patterns/resourcedictionary-and-xaml-resource-references). You normally have an App.xaml that is a global applied styling and then each page/control can have it's own local (like you would in Vue/Angular, etc), as well as importing from other files like sass.
Yes, that's basically correct. Though the deterministic destruction of `~` was more of an accident than an explicit design decision—up until the decision was made to remove GC.
Maybe WPF with CSS support?
&gt; “solved problem” ™️ protected by trademark?
SNAFU actually started as `no_std` but quickly ran into a problem: there’s no `core::error::Error`, it only exists in `std`! Without that, it wasn’t clear what exactly the correct behavior should be. I’m all ears to hear ideas about the right thing to do, however! /cc /u/thelights0123
failure just implements Display only.
But DOS had the cool games in the 386 - early pentium era.
`Ref&lt;&amp;CC&gt;` is a runtime checked reference (Ref) to a compile time checked reference (&amp;) to an instance of CC. You probably want a `Ref&lt;CC&gt;` instead, like in this modified version of your code, which compiles and runs: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9c88834e43b2fdadffd04a1dcfdf7783 I would also consider whether a `RefCell` is necessary in the first place here, but that's harder to determine without more context.
It feels familiar to me, but from Ruby rather than C. Uncertain whether that's actually the source though.
Are you asking about "adding dependencies to a project" or the physical act of "downloading" a dependency from the internet? In the latter case, cargo will cache downloaded dependencies for you, so you're only paying the download cost when the cache is cleared or you need a new version. I believe this is global to your system, but keep in mind that different packages may end up with different resolved dependencies (that is, project 1 might require dependency@1.2.1 but project 2 wants 1.2.2) In the former case, though: one of the chief learnings of the last, oh, 5 years or so of package and dependency management is "list your dependencies explicitly." python and Ruby adopted this in an ad-hoc way with virtual environments, but node was (to my knowledge) the first *major* case where they require it from square 1. The reason for this is that it avoid the endless headaches of "it works on my machine" because everyone is working with a different set of globally installed package versions, or that something doesn't work at all because it wasn't listed as an explicit dependency because it was already globally installed on the developer's machine and so it "just works".
Sweet thanks. So basicly ref needs the actual type its pointing to. This is just a small test for something bigger which needs RefCell to mut without having the parent object as a mut. Plus I'll need multiple refs for processing in an ecs design.
I knew that `RefCell.borrow()` method will return a struct `Ref&lt;T&gt;`, which will free in the end of scope, so I don't think there is a way to return its reference. But I have some solutions. You can make a static method that use `&amp;Ref&lt;Vec&lt;CC&gt;&gt;` as argument and return `&amp;CC`. I tested, that works well. But it's pointless to do this, since you can get its data like this: `&amp;aa.get_vec()[i]`. [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e27cb672bb4ba6c10c49f1549d63521d) pub fn get_cc&lt;'a&gt;(v: &amp;'a Ref&lt;Vec&lt;CC&gt;&gt;, i: usize) -&gt; &amp;'a CC { &amp;v[i] } Or make it dirtier by using `unsafe`. Not recommend this way, because we cheated. Data still live in `RefCell` but the `Ref` we borrowed to take out a ref to `CC` is gone, rustc didn't know that. &lt;..sniff&gt; fn get_cc(&amp;self, i: usize) -&gt; &amp;CC { unsafe { let p = &amp;self.bb.data.borrow()[i] as *const CC; &amp;*p } } &lt;..sniff&gt; Or just use [a simpler version](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0c66416f686921296943e3419562df18). I don't know if you must use `RefCell` for your project or not, I just try to help and correct me if I'm wrong btw. And I have a tip for you, if you want to turn off compiler warnings, just add `#![allow(warnings)]` (not recommend tho :) )
&gt; From what I've learned so far, with cargo I put the dependencies in my .toml file and it downloads them for that specific project and keeps it there. But how do I import it permanently, and then use it across multiple projects without having to waste time downloading it the every time. Cargo caches the source globally; you'll only download each one once. It will re-compile them per project, but the download is only once.
Oh okay thanks alot! Just one more question. What location exactly does it cache them at, if I'm using python it's usually usr/python/bin. Does cargo have a default path location set as well. Also, now that you've cleared it up that those installs are global, what do u do if I just want the package to be temporary?If I write a project, and after I'm done with I delete it, how do I decide which packages stay and which get cleared with the project folder.
`~/.cargo`
It's a terrible practice for Python. And like cargo, pip caches what it downloads.
The installs are not global; they are downloaded globally, but they are only visible to projects that add them to their `Cargo.toml`. You don't need to think about the global state, just what is in that manifest file, and cargo will handle the rest.
No I understand that it's not visible unless I specify it explicitly, I was talking in terms of disk space that it takes up. When Rust dues eventually become as big as JS or python, it's likely that some of the libraries will balloon in size to huge numbers ( a standard node_modules folder can easily hit a few GBs). Now I know this is way in the future, but I'm just curious. What I'm asking is, can I suggest that a particular package is temporary, so that after I delete the relevant project, the package also gets cleared from my disk space? Kind of like deleting a venv in python.
I've used `failure`, and `error_chain`, but for larger projects I usually end up defining my own error types manually, including defining all sorts of `From` traits. If you have a lot of code anyway, it's not too much work to maintain an `errors.rs` for it. I didn't know about `snafu`, looks interesting, thanks for mentioning it. There's another crate that I still want to take a closer look at, [custom_error](https://github.com/lovasoa/custom_error).
Fair. I can't seem to find one other than the Pixelbook that isn't emmc (which leaves a rather wide gap of medium range specs non-existent), though maybe there is. &amp;#x200B; Since Google makes the Pixelbook and is working on this Linux environment, it seems they have a vision of ChromeOS that goes beyond the ultra-low end (but also cheap and portable). I'm not sure exactly what their plan is or whether it will work, but it should be interesting to see. Their strategy of initially targeting ulta-cheap/ultra-portable laptops seems like it was a clever idea; it seems to have worked to make ChromeOS more popular than one would expect a novel laptop OS to be (i.e. a total commercial failure). &amp;#x200B; And for certain kinds of development, maybe the lower end Chromebooks would still be useful, if not as a primary machine. It could augment a desktop or bulky laptop for when you want better portability. And really, depending on what kind of software you're developing (and it's size), development can be less resource intensive than browsing the web (or much, much more).
(Not) glad to see &amp;'a syntax still exists though. Lifetimes are probably the ugliest thing in the language, and that forms a psychological barrier to understanding them.
In this example you can actually move `process_file_another_way` out of `impl Test` and get rid of the `&amp;mut self` parameter, since you never use it. This should make it compile. The reason why it complains is that when you make a mutable reference to `self.this_file`, that mutable reference of course requires a mutable reference to `self` itself. Hence storing that mutable reference to `self.this_file` in the `file` variable prevents the creation of any more mutable references both to `self` and `self.this_file`. So when you call `self.process_file_another_way(...)`, you attempt to create a second mutable reference to `self`, which could lead to problems. I hope this helps, although maybe double-check what I just wrote because I'm half-asleep and I might have missed something.
Fun fact: You can thank Marijn for pushing us to include the typeclass/trait system. His work was very important in getting early Rust off the ground :)
Totally agree. I don't think Rust in its current form competes with Python / R / Matlab in their respective use cases. Nevertheless, ML algorithms are still often implemented in C++ for performance reasons (XGBoost, LIBSVM, LIBLINEAR, etc.), and it's more reasonable to see Rust compete with C++ in those cases. I've tried implementing some ML models (e.g. [this](https://github.com/tomtung/parabel-rs)) in Rust (which I would have done in C++ if Rust didn't exist), and the experience was very pleasant. On one hand, since manual resource management is necessary given the performance requirements, Rust's zero-cost security features definitely come in handy; on the other hand, libraries like Serde and Rayon make tasks like serialization and parallelization a breeze.
This is pretty what I do for any project with an error type. For really small things or demos or playing around I just use `Result&lt;T, String&gt;` and `.map_err(|e| format!(“{}” e))?`.
r/lostredditors
I just explain that the scope is encoded into the type system, and the ' just means "generalized on scope".
I'm having trouble figuring out why the borrow checker is complaining about this seemingly simple generalization of an impl on `&amp;T`: Works: unsafe impl&lt;T: TrustedContainer + ?Sized&gt; TrustedContainer for &amp;T { type Item = T::Item; unsafe fn get_unchecked(&amp;self, i: usize) -&gt; &amp;Self::Item { T::get_unchecked(self, i) } } Errors: unsafe impl&lt;'a, T: ?Sized, D&gt; TrustedContainer for D where T: TrustedContainer, D: ops::Deref&lt;Target = T&gt;, { type Item = T::Item; unsafe fn get_unchecked(&amp;self, i: usize) -&gt; &amp;Self::Item { T::get_unchecked(self, i) } } The error in question is error[E0311]: the parameter type `T` may not live long enough the parameter type `T` must be valid for the anonymous lifetime defined on the method body ...so that the reference type `&amp;T` does not outlive the data it points at [playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d9e1cce15e6fc4f76db1434d0036deca) In the `&amp;T` implementation, the `T` may be bounded by any potentially short lived lifetime. Why does the `Deref` option seem to require a lifetime bound that the specific version doesn't? (Do I actually want `AsRef` or `Borrow` rather than `Deref` here?)
Is there a way to send command line arguments to clap programmatically? I want to test my program using rusts testing framework and I want to ensure that I configured clap properly.
https://github.com/cdr/code-server
Happy Birthday Rust!!! 🎂🎉 Keep up the good work guys!!!
Somewhere in ~/.cargo
[assert_cmd](https://crates.io/crates/assert_cmd) works well for actually using the built interface. [`App::get_matches_from`](https://docs.rs/clap/2.33.0/clap/struct.App.html#method.get_matches_from)(`_safe`) allows you to invoke clap's argument parsing on an iterator of strings directly, rather than from the command line arguments.
[Solved on Users](https://users.rust-lang.org/t/why-doesnt-t-live-long-enough-here/28275/2?u=cad97): don't name `&lt;D::Target as TrustedContainer&gt;::Item`. unsafe impl&lt;D&gt; TrustedContainer for D where D::Target: TrustedContainer, D: ops::Deref, { type Item = &lt;D::Target as TrustedContainer&gt;::Item; unsafe fn get_unchecked&lt;'a&gt;(&amp;'a self, i: usize) -&gt; &amp;'a Self::Item { let a : &amp;'a _ = self.deref(); &lt;D::Target&gt;::get_unchecked(a, i) } }
I suppose at the end of the day I am server centric and the idea of having each user download their own copy individual copy and store it in their individual home directory gives me the hives. I would much rather see the source dependencies stored in the project area by default, along with the main.rs. That way in the future when rust is a legacy technology like COBOL and git hub has been decommissioned, all the source will be there in the one place. Anyway I doubt I will convince you to my way of thinking but thank you for your help in this matter. I have updated the first post with the solution you have found.
In libraries I just use [err-derive](https://crates.io/crates/err-derive) these days; keeps things simple and stable. I wrote [err-ctx](https://crates.io/crates/err-ctx) for application code where reporting logical causation chains to the user is the main goal.
Please ban this guy and report them to Reddit. He has been repeatedly posting things that would be bannable in the Rust game, and also on the wrong subreddit without listening.
This seems ideal, can you point me at a codebase that uses this pattern?
[This project](https://github.com/tmccombs/dopen) contains a desktop file parser, maybe that’s useful to you.
Literally seconds after the Medium notification showed up on my phone, I scroll onto this post. I'm just a lurker so will likley not be writing anything, but I wish you luck. Rust is an exciting topic and your collaborative approach offers novel potential. Keep up the good work!
Thank you
How is the error handling? What does an error look like on invalid input?
What is the target audience and the goal of this? Do you want tutorials? Stories of people's rust journey? Articles trying to convince people to use Rust?
No, it was very intentional from the get-go that there be an RAII / deterministic-destructed type. I was careful to ensure this every step of the ridiculous path through the kind system :P It was just possible to put a linear subgraph dangling on the _edge_ of the GC graph. So you could have a GC graph that took a while to be collected (if you made one); but once it passed over to the linear bits (or if it started with the linear bits in the stack) it was always top-down, deterministic order.
Happy Birthday Rust ❤❤❤
Note that won't work if you have multiple error variants that can be constructed from the same inner error.
There's no point in doing that. It's better to return `Box&lt;Error&gt;`.
I'm not sure that evangelism is a good meme to lean in to. Have you considered a different name?
Something like Fuschia?
Rust isn't python. Let cargo do its thing. If it \*really\* becomes an issue for you (it isn't), then install cargo-sweep and sweep build files older then a certain number of days. I've been using cargo for the last 4 years and I'm still not worrying about this non-problem.
For code you control I think it's a good idea to use enums, nested if need be. This gives the most control and allows you to react to specific errors. For code you don't control using a trait should be fine. But note that boxing may incur dynamic allocation overhead, as well as calling a trait function being a virtual call.
Why not just do `&amp;aa.bb.cc[n]` instead? This will partially borrow both aa and bb, and if you need to edit cc you could release the borrow.
If you want to know how to do error handling without external dependencies, /u/burntsushi (Andrew Gallant) wrote a great [blog post](https://blog.burntsushi.net/rust-error-handling/) detailing the many ways to do it, and thejr tradeoffs.
&gt; maybe you live in a different sphere- but the only windows items in my area are legacy. It's true that there's not much demand for Windows-related development anymore, but I think you are wrong to equate "MS-related tech" with "Windows". My company uses .Net Core to develop cross-platform server applications. This is clearly MS-related, but I don't see it as outdated, irrelevant, or a waste of time. C# is a powerful language, and .Net a powerful environment, and I'm quite sure the experience will serve me well in the future.
r/play_rust
Even if they're ugly, they're an integral part of things that make Rust great. And I feel once you get used to them and how memory works, they make a lot of sense.
err-ctx looks perfect for me, thanks! I find myself using failure purely for adding contect which feels overkill
 fn crap() -&gt; *const [i32] { let arr: [i32; 5] = [1, 9, 8, 5, 10]; let ret = Box::into_raw(Box::new(arr)); ret } Calling this function several times without taking and processing the rawpointer would cause a memory leak as in any other language, correct?
My problem was with the deconstructing syntax for variants with structs: match myenum { A(a) | B(a, _) | C(MyStruct {x:a, y:_,}) =&gt; println!("{}", a), _ =&gt; (), } I was using `MyStruct {a, _,}` instead of `MyStruct {x:a, y:_,}`.
Surely you are aware that Rust the programming language has an official Discord server linked in the sidebar?
Done: https://github.com/ajmwagar/bliss/issues/9
Don't use these helper crates. They introduce unnecessary complexity to project for little of no benefit, stick to `std::error::Error`
feel like a world class scrub for having to ask this but with this code: fn intersect&lt;T : Hash + Eq&gt;(a : HashSet&lt;T&gt;, b : HashSet&lt;T&gt;) -&gt; HashSet&lt;T&gt; { let (mut smaller, bigger) = if a.len() &lt;= b.len() { (a, b) } else { (b, a) }; for x in smaller.iter().collect::&lt;Vec&lt;_&gt;&gt;() { if !bigger.contains(x) { smaller.remove(x); } } smaller } this fails like so: error[E0502]: cannot borrow `smaller` as mutable because it is also borrowed as immutable --&gt; src\lib.rs:39:13 | 37 | for x in smaller.iter().collect::&lt;Vec&lt;_&gt;&gt;() { | ---------------------------------- | | | immutable borrow occurs here | immutable borrow later used here 38 | if !bigger.contains(x) { 39 | smaller.remove(x); | ^^^^^^^^^^^^^^^^^ mutable borrow occurs here Can someone explain the sequence of borrowing that is happening that forbids this? My thought is that the `smaller.iter().collect::&lt;Vec&lt;_&gt;&gt;()` expression will perform some borrows but as it should evaluate to return a vector of references it is basically 'returned' and smaller should be borrow-able again? The fact I can do something like: let foo = smaller.iter().collect::&lt;Vec&lt;_&gt;&gt;(); smaller.clear(); But not let foo = smaller.iter().collect::&lt;Vec&lt;_&gt;&gt;(); smaller.remove(foo[0]); Then suggests to me it's lifetime related. But I'm not sure, and also what a sensible way to resolve this?
I agree with your comments about C++ and Scala. I would never trust C++ code written by someone who is not considered an experienced or expert C++ developer, and even then I would probably still manually inspect their code. The same applies to Scala to a lesser degree, unless you force developers to write code in purely functional way (which is kinda hard to enforce in Scala). I love Scala but I also know how easy it is for inexperienced developers to write bad Scala code. It's not a good language to chose for an inexperienced team unless you have strict code reviews and mentoring by experienced developers. Rust is definitely better in this regard, there are less ways of doing the same thing and the simplest way is often the recommended way. If you restrict the usage of unsafe, I would basically trust Rust code written by anyone. I would personally love to use Rust in a bigger professional project. I'm pretty sure it would be a revelation compared to C++, Java and Scala.
&gt; Normally in python whenever I want to import a dependency that I know I'm gonna be using all the time across multiple projects(numpy or pandas), I'd use some like pip install &lt;dependency&gt; and it would directly go into the interpreters path and stay there. I've done that for years in Python, but it's actually a bad practice because you don't manage the dependencies upgrades per-project. This could lead to recurrent breaking of code. In addition, you can't control the dependencies' versions used by others, so your code may work for your but not for other. Instead, you should use virtualenv, and use a *requirements.txt* with pip. This is the way to go to ensure that your Python code won't break and will work everywhere else. Interestingly, this is close to how things work with Cargo if you see your root folder as your virtualenv and the *.toml* file of Cargo as the *requirements.txt* of pip.
I wonder why the dev decided to make a textual format with first class support for reference cycles. Extremely skeptical. I do wonder if wood formats should have a comments syntax. It's possible to add your own... maybe I'll just provide a standard api for stripping out any wood that starts with a specified string.
Unfortunately none of the advantages of XML are available as rust crates yet. Creating Rust code from XML Schema or Relax NG is the most important thing missing. Thanks to `enum` and `match`, Rust can do very good mapping between XML structures and runtime structures, whereas mapping XML to language structures in Java, C++, Python, Go is always ugly and error-prone.
There exists at least two such projects for C to Rust translation. One has been abandoned though. I believe [https://c2rust.com/](https://c2rust.com/) is the most complete one. The result will be unsafe rust, but it is a good start when reimplementing code
If you might like something easier to type and read than xml, I've just gotten done porting wood to Rust. https://github.com/makoConstruct/termpose/blob/master/rust/README.md There's a whitespace based format, there's also a very simple s-expression format.
This is a good quality, thorough cheat sheet. Do you know of any cyst sheets for other languages that are nearly this good?
There's a fork of VS Code which hosts a server you can connect to with your browser, instead of the electron app.
😂😂😂👍
Yes, but that kinda defeats their whole talk about how you can do your development locally on your computer. Then you might just as well use the normal ChromeOS.
This is a question to everyone else commenting here, rather than the OP, because i was gonna ask the same thing today anyways: Is there even a single recommended create for this? Anything that is going to "become std in the future"? Also, how interoperable/compatible are all these crates? I used error_chain + error_chain_derive in the past, where it's most useful when everyone in the ecosystem is using the same crate. Does using one crate looking interoperability with others?
In general, you cannot remove an item from hashset by passing a reference that you got from that hashset itself. If you try to do that, you would need to construct aliased mutable and immutable references - one to the whole hashset (to be passed as `&amp;mut self`), and one to the value that is owned by the hashset. When you write let foo = smaller.iter().collect::&lt;Vec&lt;_&gt;&gt;(); smaller.clear(); you never use `foo` after clearing `smaller` out, so there's no error.
At block0 (block0.io), we are setting up a Rust dev team to work on various Blockchain-related projects. Tech stack includes Rust, Web Assembly, Parity / Substrate, Web3, Docker / K8s. Ping me if interested.
They used to be monthly and help is always appreciated :).
Very happy to help. Is there a website/forum that people ping in ideas? What kind of help do you need?
Who is using dyon?
Yeah, I'm not sure I follow. The most typical use case is that a dev has one or more projects on their personal computer (usually checked out from a central VCS repo). If cargo cached downloaded deps in every project tree separately, there would likely be a lot of duplication if the user works on several projects. But if you want persistent (not just cached) local (or company-internal) copies of all dependencies, cargo [allows you to do that](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#specifying-dependencies-from-other-registries), either pointing it to a custom registry, a git repo, or a local path.
http://catb.org/jargon/html/0/TM.html
For all intends and purposes I highly recommend to use a reverse proxy.
Sorry for the trouble :( Please ping `@mods` if you have trouble getting the role.
Would you consider using [https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.difference](https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.difference) cheating?
Is this for learning? I am asking since there is [https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.difference](https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.difference)
To make \`failure\` a little less verbose, I wrote \[\`failchain\`\]([https://github.com/cristicbz/failchain](https://github.com/cristicbz/failchain)) some time ago which borrows some tricks from \`error\_chain\`'s toolbox, you may wanna give that a look.
&gt;After calling this function, the caller is responsible for the memory previously managed by the Box. In particular, the caller should properly destroy T and release the memory. The proper way to do so is to convert the raw pointer back into a Box with the Box::from\_raw function. [https://doc.rust-lang.org/std/boxed/struct.Box.html#method.into\_raw](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.into_raw)
Seconded. If the target audience is people who already use Rust, they don't need evangelists. If it's potential new users, they're probably suspicious of evangelism. Potential contributors too, even if they sincerely just want to evangelize, probably don't want to be labelled evangelists.
I don't have any experience with `failure` (damn does this sounds much worse without the back ticks). How is it better than `error_chain`? Why would i migrate to it?
Why do you think it's ugly? If you want to give a human readable error message for your errors, then those messages need to live _somewhere_. A `match` expression is enforced to be exhaustive, so when you add a new error variant, the compiler will helpfully tell you to update your `Display` impl.
Have a look at this: https://github.com/google/tarpc/issues/224#issuecomment-490560298 In the above tarpc example patch, the bytevec crate allows to embed stuff within a serde serialized Struct passed as an argument for a tarpc exposed sendfile service.
Oh damn! Never thought other people were thinking that. Every time I tried to tell it to others, they just said I was wrong. Maybe things are finally changing? :)
Well, I think the problem is that majority of people prefer to just use someone's else opinion rather than thinking for themself. But I'm certain there are people who strongly believe that unnecessary dependencies should be avoided in general
I don't mean to be rude, but I said _I don't want to use a Reverse Proxy_.
Thank you :)) See you there
I feel like I'm taking crazy pills, but I am experiencing a very strange bug. I am making a simple HTTP request on an interval and `println`ing the response. For some reason, it wasn't outputting anything, but there were no errrors. I put a `dbg!("test");` in front of the request and it started showing "test" AND the HTTP response. I removed `dbg!("test")` and it stops showing anything. I did this about 50 times because I can't comprehend why a `dbg` would affect the output of anything else. How is that possible?
I get it. Would you clarify for us why? Most of the time people don't want to use a reverse proxy when that's the best option they can take.
It’s not clear at this time. Interoperability is usually good, since they share a common trait, Error.
Let's say you are writing a network service that uses two external network services as dependencies. (Maybe some sort of session cache and a DB.) You might need to get data from both at the same time. You need to wait on both futures, that's why there are combinators. (Maybe you were thinking of a different kind of composability?)
thanks. The reason is because CC won't actually live the way it does in this simple example. It'll be inside a HashMap&lt;TypeID, Any&gt; So have a function to get the correct Vec Type and downcast it to the correct type before I can use it. Its for an ECS framework, so doing this for dynamic typing.
Do you actually care or do you just not have an answer to his question? Here’s a simple reason: his deployment scenario prevents it.
There are [crates for handling the ACME protocol](https://crates.io/search?q=ACME), particularly [acme-client](https://crates.io/crates/acme-client) (which can be used as both a CLI and library) or [acme-lib](https://crates.io/crates/acme-lib) seem promising. But you're not likely to find something as all-in-one as Go is providing.
Sure, async code is precisely useful because it allows you to say that you don't care about the order in which certain operations complete, and explicitly require an order when you do. I'm not worried about that at all. What I _am_ worried about is the debuggability and reviewability of such code. Concurrency is Very Hard(tm) to reason about, so it is important (to me at least) that concurrent code is as easy to follow as possible, without hiding any side-effects or synchronization points. `.await` is a synchronization point. I care much less about being able to fit it into nice one-liners than I care about being able to easily follow what's going on in code that uses it.
I think it does pretty well for global illumination scenes. For difficult lighting you can switch to bi-directional path tracing (in contrast to e.g. Arnold, which is currently a uni-directional path tracer) or Metropolis Light Transport (MLT), which most of the commercial renderers do not support. I only used perf twice during development because the C++ code was faster and identified the bottlenecks in Rust, but I haven‘t really started tweaking the performance of the Rust implementation. First goal was to match the resulting images (C++ vs. Rust). Next goal will be to work on the performance and memory footprint ... You also can‘t compare the CPU only implementation against renderers which do support GPU rendering (like a lot nowadays do). No intention to support GPUs anytime soon.
Agreed, I just think that Rust has an amazing potential to be high level when the programmer needs and wants it to. And for libraries and other crates (submodules of your whatever program), you can get down to sort out the bits. &amp;#x200B; The type-safe macro system is such a great tool that allows it. Of course, at the same time you're very much right, because probably everyone in this subreddit knows what too much magic can hide, and how that leads to bad time. &amp;#x200B; However, at the same time, I know and I hope it's also clear, that debugging, profiling, tracing, and so on is rarely an exercise of pure code reading and mental parsing. I want Rust to be easily debuggable and trace-able, but not because the code is ASM-like, but because we have tools for that. (That's why I like that RFCs have a compulsory "how do we teach that" question, they probably should also have a how do we instrument/debug/error-report that part. And with async/await one of the main motivations of giving a compiler-provided implementation of it was to have better error messages. I hope this also helps with traceability too.)
I'm doing the rustlings exercises, and there is the following code: fn fill\_vec(vec: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { let mut vec = vec; vec.push(32); vec } I understand the concept of shadowing, but what is exactly happening to \`vec\`? Its values are being copied to the \`let mut vec\` or it is just a rename of the variable to allow mutability, without copy?
Seems like you are supposed to use the [Builder](https://docs.rs/mio-extras/2.0.5/mio_extras/timer/struct.Builder.html) type to build your timer. From the API it would seems like the timers are handled using a timer wheel. &amp;#x200B; `let timer = Builder::default().capacity(123).build();` Then you can register a "timeout": `let timeout_future = timer.set_timeout(Duration::new(5, 0), false);` &amp;#x200B; A single Timer instance supports many timeouts. poll() on the timer instance returns the value that was passed as second argument to set\_timeout().
Just looking at the docs, it seems \`Default\` is the expected constructor pattern. I suspect the use case is a timer that gets reset during processing pipelines/loops, hence the modify-the-registered-timer pattern. This avoids bouncing the poll descriptor in and out of the event set every time it expires or is cancelled.
It seems like this will unfortunately run into the issue of deref coercions: assert_eq_type!(str, String); seems to pass. I'm unsure Rust currently provides a way to statically enforce a specific type without coercion. At least not one that might not become coerced in the future. I've been wanting to work on some defensive clippy lints for months. This might get me motivated enough to work on one to lint against those coercions.
https://medium.com/learning-rust/rust-error-handling-72a8e036dd3 might be helpful
I get where you come from and you are right. My point is it will probably be easier to have a reverse proxy and save a lot of headeaches that will come after this one that rewrite all of these things in Rust because most likely most of them don't exists. Rust doesn't have Caddy, Rust doesn't have Traefik, Rust doesn't have K8s yet.
I always create a macro for that kind of stuff: ```impl_error!(MyErrorType {reason: String, code: u32};``` or something like that
*Rust Strike Force* could be a better name /s
Well, ok... I suppose they enforce the usage of default so that no Timer is registered with invalid parameter? That's awkward. A small example belongs into every documentation IMO Do you understand what capacity and num\_slots are for?
`let` bindings do not create any new variables, they assign a name to the variable created by the right hand side expression. So if the right hand side is another variable, then the let is just a rename. FYI in your example you can avoid that line by adding the mut to the function signature: fn fill_vec(mut vec: Vec) -&gt; Vec {
I think num\_slots is the number of spokes in the [timer wheel](http://www.embeddedlinux.org.cn/RTConforEmbSys/5107final/LiB0071.html) and capacity is probably the maximum number of timeouts allowed. I am not certain about what I am saying, as it is not documented in detail.
Do you believe the timer gets reseted without programmer's interference? [https://github.com/dimbleby/mio-extras/blob/master/test/test\_timer.rs](https://github.com/dimbleby/mio-extras/blob/master/test/test_timer.rs) Their test code does not appear to indicate this. Though I don't really understand their concept anyways
Sorry, verbiage mismatch. Here, "gets reset" would involve the programmer calling `set_timeout` or `cancel_timeout`. Nothing automatic.
This does look close to the solution I want, which I'd summarize as "std with less boilerplate".
I've generally avoided them, but I find that doing error handling correctly with only the stdlib is finicky and encourages short cuts. Rust's error handling is good, but there is definitely still room for improvement (imo, but also clearly in the opinion of all the folks writing and using error-helper crates.)
Oh I didn't know about this one! Looks interesting but also a bit more "magical" than \`cpp\`, but it also seems to do more than the cpp crate. I'll have to check it out a bit closer, thanks!
The std's lib `Error` trait is as simple as possible. I'm not sure what else you'd need, errors are not supposed to be complex
Thanks for all your work among the community, it was great to get the chance to meet you and so many other Rustaceans last night! Looking forward to seeing you around now that we're in Berlin :)
node_modules often ballooned in size because it contained many different copies of the same package. The download cache people are talking about only contains 1 copy of each dependency, version pair and only the source code, no compiled artifacts. As such, this directory stays small and isn't something you need to mess with.
Code node by liverpool street hosts rust london user group on a regular basis. Not sure when the next one is but there was one mid april. [https://skillsmatter.com/skillscasts/13813-internet-of-streams-a-wireless-sensor-network-in-rust](https://skillsmatter.com/skillscasts/13813-internet-of-streams-a-wireless-sensor-network-in-rust) &amp;#x200B; Also would really like to see London host a rust conference soon. I'm sure there's a few companies in the finance sector using rust that would be happy to be sponsors...
Oh hey, steveklabnik it's you :) thanks for answering my question! Is there an open discussion about this that i can read up on? I'm kinda wondering where this part of the language stands right now, and what we can expect / which is a crate better bet to build on
Yeah also I forgot to mention not sh*** expensive. I always feel that everything in London is about money and there's not so much enthusiasm as conferences, backspaces etc in Europe (see Berlin). I've seen that in many communities (from dance to everything). Competition, money and people leaving the country after a while. Little sad.
That was actually the Linux Users Group. (I'm the speaker) On the subject of a conference, we literally only need people running it.
You can just send a message on meetup. Many groups just separate running the meetups. So, one runs it in Januar, one in February... If you get ~a 3 month cycle, it doesn't become exhaustive, but more of a "it's my turn again!" thing
\o/. I'd be super interested in seeing your stuff a bit more. I'm don't make music (anymore), but enjoy listening and everything around it.
Thanks for dropping by and thanks for going on stage. Looking forward to see more of your Rust stuff for sure.
Maybe they don't want to follow the standard advice due to a misunderstanding, or their objections to the standard solution are more easily fixed than alternative solutions...
It is actually quit disappointing that a crate about such an important thing as pollable timers is documented so badly. The whole lib is working in an awkward way. The following code for example should cancel a timeout, what it does, but the timer throws an event anyways. It is hard to tell if that's a bug or intended extern crate mio; extern crate mio_extras; use mio::*; use mio_extras::timer::{Timer, Builder}; use std::time::Duration; fn main() { const TIMER: Token = Token(2); let poll = Poll::new().unwrap(); let mut gman: Timer&lt;u64&gt; = Default::default(); poll.register(&amp;gman, TIMER, Ready::readable(), PollOpt::edge()).unwrap(); let mut gman_tout1; let mut events = Events::with_capacity(1024); gman_tout1 = gman.set_timeout(Duration::from_millis(2000), 9001); gman.cancel_timeout(&amp;gman_tout1); loop { poll.poll(&amp;mut events, None).unwrap(); for event in &amp;events { match event.token() { TIMER =&gt; { println!("Timer-Event!"); if gman.poll() == Some(9001) { println!("my timeout occured"); } }, _ =&gt; println!("awkward"), } } } }
&gt; I suppose they enforce the usage of default so that no Timer is registered with invalid parameter From the perspective of a Vulcan, this might be correct, but from the perspective of a human I think there's more to it than that. Namely, you probably don't want to fill in all the struct fields yourself. [Check out all these fields](https://docs.rs/mio-extras/2.0.5/src/mio_extras/timer.rs.html#23-41). Do you know what they all do? Do you know how they should all start out? And maybe more importantly, why would you want to set them manually anyways? The builder pattern is not just a safety precaution -- it's a convenience to the user. That said, I've long wished for named/default parameters so we could just do `Timer::new(tick_duration = my_duration)` rather than `Builder::default().tick_duration(my_duration).build()`, but such is life.
&gt; Would you suggest I write an application with Rocket + Yew + Actix, or should I just try writing the entire thing with Actix? Its up to you how you handle frontend. Neither of the frameworks will decide the choice here. Actix works on stable Rust, Rocket doesn't. &gt; Last, what would be the most comparable language to Rust in terms of tutorials for eCommerce/Backend? I've found Python fairly easy to translate to Rust.
See the [AWWY](https://www.arewewebyet.org/) page. Rust is already pretty good for web development and is being used in production in many places already, but beware that some things could still be a bit lacking at times. It isn’t as mature as Django or RoR yet. If you’ve been able to find all the key-pieces of technology you need in Rust, go right ahead I’d say.
Thanks!
It's an open source project - submit an improvement!
I'm currently building a website that will take payments with rust. I'm using rocket for the backend, and JavaScript for the front end. Going well so far :)
I am partial to `The Ministry of Rust`
The Secular Rustaceans. Kidding aside, I thought the original name was pretty fitting. The target writers are "Rust Evangelists". I personally wouldn't give the name too much thought. Most similar projects end up failing because of lack of follow-through.
Sorry for the late response. As far as I can tell, the only way to do this would be to use a hash map and a binary heap at the same time, and duplicate data. There's no collection in the standard library or in any crate that I could find that does what you want. You could implement your own data structure if you wanted, but it raises the question of *how* you would implement a collection like that, and the only thing I can think of is to use a hash map and binary heap under the hood. Here's some example code, using petgraph for the graph: use std::collections::{HashMap, BTreeSet}; use std::cmp::{PartialOrd, Ord, Ordering}; use petgraph::Undirected; use petgraph::graph::{Graph, NodeIndex}; #[derive(Debug, Copy, Clone, PartialEq, Eq)] pub enum Cell { Space, Wall, } #[derive(Debug)] struct Node { parent_node: Option&lt;NodeIndex&gt;, visited: bool, } #[derive(Debug, Clone, PartialEq)] struct Distance { node: NodeIndex, distance: f64, } impl Eq for Distance {} impl Ord for Distance { fn cmp(&amp;self, other: &amp;Distance) -&gt; Ordering { match self.distance.partial_cmp(&amp;other.distance) { None | Some(Ordering::Equal) =&gt; self.node.cmp(&amp;other.node), Some(o) =&gt; o, } } } impl PartialOrd for Distance { fn partial_cmp(&amp;self, other: &amp;Distance) -&gt; Option&lt;Ordering&gt; { Some(self.cmp(other)) } } pub fn find_path(graph: &amp;Graph&lt;Cell, f64, Undirected&gt;, start: NodeIndex, goal: NodeIndex) -&gt; f64 { let mut nodes: HashMap&lt;NodeIndex, Node&gt; = HashMap::new(); let mut distances_map: HashMap&lt;NodeIndex, f64&gt; = HashMap::new(); let mut distances_set: BTreeSet&lt;Distance&gt; = BTreeSet::new(); nodes.insert(start, Node { parent_node: None, visited: false }); distances_map.insert(start, 0.0); distances_set.insert(Distance { node: start, distance: 0.0 }); let mut current_node: NodeIndex; loop { let Distance { node, distance } = distances_set.iter().next().unwrap().clone(); if node == goal { return distance; } for neighbor in graph.neighbors(node) { if nodes.get(&amp;neighbor).map(|n| n.visited) == Some(true) { continue; } let edge = graph.find_edge(node, neighbor).unwrap(); let new_distance = distance + graph[edge]; if nodes.get(&amp;neighbor).is_none() { nodes.insert(neighbor, Node { parent_node: Some(node), visited: false, }); } match distances_map.get_mut(&amp;neighbor) { Some(old_distance) =&gt; { if new_distance &lt; *old_distance { distances_set.remove(&amp;Distance { node: neighbor, distance: *old_distance, }); distances_set.insert(Distance { node: neighbor, distance: new_distance, }); *old_distance = new_distance; } }, None =&gt; { distances_map.insert(neighbor, new_distance); distances_set.insert(Distance { node: neighbor, distance: new_distance }); }, } } distances_set.remove(&amp;Distance { node, distance }); distances_map.remove(&amp;node); nodes.get_mut(&amp;node).unwrap().visited = true; } } This isn't really Dijkstra's algorithm because it doesn't return the full path but you could modify it to do that using `parent_node` if you wanted.
Yeah, I’ve thought about using a more professional branding. I didn’t put a lot of thought into the initial title and information, but it can all be changed. Suggestions welcome
I already had this thought a few hours ago. However, I have a minor problem: I have to understand the stuff before I can write a documentation about it .\_.
Yeah true, but once you do, if you have time, submit a PR so that it will be easier for those that follow you :)
I like the play on words!
In their test-setup in the git repo I've linked in the other comment they always user Timer::default instead of Builder
I'm curious what library are you using for the payment system? I'm toying with [https://crates.io/crates/stripe-rust](https://crates.io/crates/stripe-rust) and it seems to be what I need to process payment through stripe.com
Tbh I haven't got that far yet. I'm exploring just storing credit card info, but there are regulatory considerations if I go down that path.
Your IDE can exploit the configuration by sending e.g., -W clippy::pedantic at the time it fires up the linting service. For instance, in my nvim/ALE setup I have the following in my rc file: ``` let g:ale_rust_cargo_clippy_options = \'-- -W clippy::nursery -W clippy::pedantic' ```
Great to hear! Just curious, why did you choose rocket over Actix? Hope your project turns out. Love to see WASM projects work :,)
I would like to see just about any stories that talk about Rust. This includes tutorials, research, tips, or other non-official topics. I would not prefer to have version information / patch notes for rust, or other types of “official” topics like those found on Rust’s blog. Thank you for asking. Does all of that seem clear?
Tbh i never tried actix. Rocket just made it easy for me to do my routing, plus it should become async &amp; stable once the ecosystem matures.
I can't really recommend it. Not because the language is bad per se (it's great), but web dev definitely isn't its strongest domain, and there's a serious lack of libraries for a lot of work, and no properly curated lists of packages with extensive eyeballs to debug. If this is something you want to do your own time, that's fine. But if you're getting paid for this, use a well-known, established tool that already solves every problem you have; for 80% of the domain of eCommerce, Python and Ruby frameworks have libraries that solve your problems. Furthermore, from a software engineering standpoint, who's going to maintain the site after you? There's literally a handful of Rust developers worldwide and likely web dev is not their strongest domain.
This is just for me, if it was paid I would just whip up something with joomla probably. I’m farming industrial hemp and living in a camper by myself all summer so I will look to put a lot of time into this and try to get pretty elite with this stuff!
The bare minimum requirement for useful error reporting is the ability to add contextual information easily.
Trait objects are sometimes faster than monomorphisation, they certainly can reduce code size! I'd love to see some more work in this space.
Hi, You might want to look at my ambitious project [diwata](https://github.com/ivanceras/diwata). It's not quite there yet. Most of the libraries it is using is one that I also build, as there are shortcomings to the popular libraries I've been trying to use. Diesel is a rock solid orm for rust projects, but I can not use it, since it relies on static database schema of your app at build time. What I need is something that can handle a dynamic database schema in all sort of forms and irregularities, I ended up rolling my own orm for rust [rustorm](https://github.com/ivanceras/rustorm). I have been rewriting a lot of stuff such as the client side, from elm to all rust. I tried to recreate the elm architecture project in rust which is [sauron](https://github.com/ivanceras/sauron). This rewrite save up a lot of code in diwata project since I don't have to write a json deserializer code in elm to receive the data in client side, and just use serde for both server and client-side. Arguably I'm still writing a lot more code in the form of the library, but it's something other people can use it as well, and is not directly maintained in the main project. If somebody will try to analyze this project, they may say I'm suffering from NIH syndrome, but it's not. There are just a lot of missing infrastructure in rust that is isn't there yet.
I agree, the stripe api allows you to charge customer with the supplied credit card number, but you will get a notification that this is not safe to do. Their docs recommend you to use some form of token, which is generated at the time goes on to the checkout step. Your app will need to use this token and charge the customer with it, without having your app knows about the customer card number.
By contextual information you mean...? For me Error should identify what happened, why and where. I'm not sure what else you need
I think steam works like this. When I buy a game, normally it is a 1-click action, but sometimes it asks for my 3-digit number. I think at least in the UK you aren't allowed to store that number (you can store the main number) but I'm not a legal expert. I think steam gets a token from the bank that it can use for a period of time, and then it has to ask for your code again.
Trait objects have direct impact on performance due to dynamic dispatch. While code size impact is doubtful at best.
&gt;(I think to some extent Rust has tried to cheat this by making non-zero cost abstractions actively unpleasant to write, making it feel like the zero cost abstraction is better. I think this is a mistake that hurts the overall UX of the language and probably just keeps some people from using it at all, hurting our overall goals.) I wonder what would be examples of this. One thing that immediately comes to mind is the requirement to write `clone()` explicitly instead of having it invoked implicitly like the C++ copy constructors. While this is a great way to make the user decide whether they want to move or copy an object, with the default being (close to) zero-cost move, one consequence is that programmers are sometimes going to great lengths to avoid cloning, even in situations where it wouldn't hurt program execution, such as in rarely executed code paths, or objects with cheap clone implementations. Are there other examples where non-zero cost is being made unpleasant by Rust?
Interesting take, but I disagree. I think explicitly opting in to more expensive operations should be the default mode of operation. The programmer should understand whether the `clone()` is cheap or not. Making it `clone()` implicitly makes it so you're much more likely to opt into expensive behaviour unknowingly.
Yea, clone is a classic example, and I've long wanted a mechanism for types to opt into having implicit clone semantics without guaranteeing a memcpy implementation. (I'd also point out that memcpy's can be very far from zero cost as objects grow in size; Rust does nothing to help you realize when you actually *should* put this large object in the heap instead of copy it around.) That can be generalized to an overall philosophy Rust has adopted that heap allocations are expensive and should be discouraged and stack allocations are cheap to the point of being essentially free, neither of which is universally true. I think Rust has adopted this attitude toward virtual calls (as seen elsewhere in this discussion in fact), even though monomorphization is not actually always a performance win. But I also want to clarify that my point is not just sometimes the "expensive" thing is better (this is true of every performance trade off, which wouldn't be trade offs if there weren't cases that were inverted from the usual). I think its genuinely a bad philosophy to make expensive things unpleasant to encourage you to do something that would be more performant but rather unpleasant; I think this just makes the overall experience worse and keeps people from using the tool (in other words, just let them write the slow program when it doesn't matter). I know that most people who spend their time chatting about Rust online disagree with me.
Can't one implement copy in cases where it doesn't matter?
only if the implementation is a memcpy. But Rc's clone, for example, is cheaper than a memcpy of types over a certain size.
As someone who in a 3D game project once got C++ code from a team member that accidentally copied the whole scene every frame and had to spend a few hours hunting the bug why everything slowed down to a crawl, I consider the need for an explicit clone a great improvement.
one thing to keep in mind, mio_extras is stuff that was pruned from the main mio library and kept alive in another crate. so this is like stuff forgotten in the attic of the rust async house, if you will. You might have better luck with [crossbeam-channel](https://docs.rs/crossbeam-channel/0.3.8/crossbeam_channel/), which has some timer-related functionality via channels (`after` and `tick`).
Tbh, I like having to clone things manually. I always know when I need to clone something, and why I'm doing it.
Just a convenience I'd assume. Maybe `Timer` could do with a static `build()` method that returns a `Builder`.
&gt; The problem is that the concept of object safety, as well as sized and unsized types, and probably just some bad ergonomics around the coercions, has made trait objects really unwieldly to work with; I’m usually pretty annoyed when I have to use them. This section on trait objects has me wondering what kind of improvements could be possible here. All of the current concepts seem rather necessary to me at the moment.
It also affects compilation times in a very significant way.
&gt; While code size impact is doubtful at best. Not "doubtful" – the instruction cache is a limited resource and crucial to performance. Whether dynamic dispatch or monomorphization is faster, depends on many factors. When performance is an objective, you'll typically have to benchmark and profile both solutions for your specific case.
I'm curious about this. Do you have an example in mind?
No and tbh it's just what I've heard. I'd appreciate any evidence for (or against) my claims.
Thanks for the help! Sadly "libsodium-sys v0.0.12" didn't want to compile which I think might be related to the crate last update being 2 years ago
I think clippy should handle that tho.
Except that tons of potentially very expensive things are completely implicit - moves and copies are chief examples, but also dereferences for example. The idea that Rust makes you opt into expensive operations is really untrue except as a very vague rule of thumb, and it could definitely be refined - the current status is just the feature set we have bothered to implement so far, not something handed down from on high.
I've never seen anyone suggest that autoclone should be the default.
As /u/DuomanAsh said, just stick to the `std::error::Error` trait. I found the biggest problem is not the implementation of the `Error` trait but all the `From` implementations so that you can use `?` nicely, as well as implementing `Display`. There is [`derive_more`](https://crates.io/crates/derive_more) which helps you with `From` and `Display` and for me personally that's all that's needed.
By doubtful I mean it is more likely to be neglect-able as its impact depends on your code composition and amount of jumps. While objectively speaking, profiling is the best method to determine performance impact of both. Virtual dispatch is clear performance impact while code size _might_ be impact. That's why I'd prefer static dispatch to virtual dispatch in 95% cases
runtime &gt; compile times
Certainly a win with dynamic dispatch in Rust is forgoing inheritance hierarchies. Where you might chase through multiple layers of pointers to get at the inherited code to be called. Traits being ad hoc and further each object having it's own fat vtable that corresponds to the dedicated impl block means you aren't incurring costs from the already spurious inheritance abstraction.
&gt; Rust does nothing to help you realize when you actually should put this large object in the heap instead of copy it around. Clippy has a check for this. I kind of feel like a linter is closer to where it belongs rather than the compiler itself. That is, with a linter I'm asking for suggestion-level warnings. The compiler should just warn about things that are either trivial to fix (e.g., unused variables) or impact correctness. Maybe that's just me though.
Really stupid question, but does rust auto update now? I swear in the past I had to update myself, but today I went to update and stable was already on 1.34.2 on my Mac, nightly did update though. I have no memory of running "rustup update" since the 1.34.2 announcement.
You'll need to do something about all those `panic!()`s in `std` and possibly crates. A network service processing hundreds or thousands of requests per second does not want to crash just because somewhere an utf-8 string was not parsed successfully or somesuch.
&gt;Interesting take, but I disagree. I think explicitly opting in to more expensive operations should be the default mode of operation. I am not arguing for or against that (and I happen to agree with you in case of `clone()`.) I am just asking for *examples* of such choices having been made. `clone()` is one - can you think of others?
Things I've seen are: - even *having* a static method means a trait object can't be made - associated types not being useful even based as if they were `impl X` on their constraints in the trait declaration (some poking around shows that there are probably deeper issues than this otherwise off-the-cuff comment might suggest) - I really want `feature(unsize)` to be stable for some code I've been working on to case between `Arc&lt;SubTrait&gt;` to `Arc&lt;Trait&gt;` (where `trait SubTrait: Trait`)
I think another big example is allocation. For many, many workloads, avoiding allocation isn't important. And heck, it could result in \_better\_ performance sometimes.
You can use .as\_ref() for this: [https://doc.rust-lang.org/std/option/enum.Option.html#method.as\_ref](https://doc.rust-lang.org/std/option/enum.Option.html#method.as_ref)
I have similarly heard this many times and I haven't seen benchmarks. I'm sure it's true, because I trust the people saying it, but it doesn't help me at all because I have no pattern to look for to think "Ah, it's probably faster if I use dynamic dispatch here". The reality is, from my understanding (limited), that even if it's a "sometimes" thing it's really more like an "almost never" thing.
I think survivorship bias as generally lead to a near-guarantee that no one still using Rust values compile times more than runtime performance (plus other features), even if we all wish that compile times were faster.
I think you have to benchmark your specific use case
Isn't the Borrow trait just for that ?
No idea - reading into it now, thanks for the lead!
I'm currently working on an almost-secret project to reduce this cost. Stay tuned!
Then why does that not apply to everything else we make "explicit" because it is "expensive"?
Yes, that's a problem and not an argument that we *shouldn't* value compile times more.
I love Rust, but I work on two large codebases (rustc and a private project) and both have incredibly long compile times. On the latter, a great deal of work has been done to cater to rustc's performance characteristics. Big domain logic nested enums and monomorphised impls can easily multiply your compilation times to an unbearable degree.
That can be argued when you include debug build compile times. I work on a project where just *linking* the final binary takes \~1 minute. No one is complaining too much about *release* build compile times.
That sounds much simpler than perfect universal forwarding rvalue references &amp;&amp; in c++!
Not really! We tend to bring stuff into std when it’s well-proven and very popular; that just hasn’t happened in the ecosystem with error handling yet. Once that does, then the discussion will start.
Sure but that doesn't really tell me how to recognize it. Is it icache misses that I should be looking for? Is it anything I could notice from sourcecode?
I guess that's fair. All the options seem good to me, so I'm not too picky. I was just wondering if there's one that is already widely considered as better. I guess this way is good too, especially if they can interoperate well, because people can choose the style that works best for them. The very fact that errors are just regular types is already awesome and handy just on its own
You are pretty on-spot on the issue of zero-cost abstraction. They are not true zero-cost but instead are zero-certain-type-of-cost, and when it makes sense you need to opt-in. But that also means you need to realize why. Rust is designed with the idea of systems languages, it's the thing that becomes tight-loops in the end. So Rust has chosen to be zero cost on runtime CPU/Memory. Another thing is that Rust is something where you have to opt-in to side-effects (unlike C++) which means that you have to explicitly opt-in to mutability, this is because Rust is meant to be a language that tries to let you reason of parts without knowing the full implementation details (which is hard in C/C++). Note that clone is explicitly stating: you can make a copy of this, but it's not cheap/easy. If it were cheap/easy then you'd actually want to implement `Copy` which does implicitly copy things (when it's a cheap to copy as it is to move).Now if you can make the cloning cheap *but* need to share resources, this becomes a problems. You could make all the copies share a borrowed reference which means that they are all guaranteed to not live longer than the shared resource (which gets deleted later on), then you can implement copy, implicitly copy things around, and all you have to do is, after all things using the shared resource are gone, delete the shared resource. This is kind of how Arenas work. You could also have the copies use a system that smartly knows when to free resources. Something like `Rc`, but now cloning has a side effect. You have to explicitly increase atomic variables which can slow down code in unexpected ways, even when out of a tight-loop. Debugging this issue is hard. And remember, Rust is what you use when you need really really fast, for less constrained code you can use another language to define those parts that are better. And this is the thing, when dealing with rarely executed path those side-effects are a bitch. Imagine a bug that only happens when you go through a rarely executed path. Now imagine that this executed path is triggered when a reference counter goes over a certain size. Implicit copying means you don't understand all that is done, until you've looked into the details of how the class is implemented. Then you'd see that cloning can trigger certain cases, and then deduce that cloning must be called. By making the clone explicit it's easier to debug: we see the clone, look into what its doing, and realize the bug.
I really disagree. You shouldn't be copying large structures silently.
Rust moves are not a zero-cost abstraction, e.g., moving an empty `ArrayVec` memcpy's the whole vector storage, moving an `enum` memcpys the size of the largest enum variant, moving a heap allocated `SmallVec` memcpys the whole embedded vector storage, etc. etc. etc. How can Rust's ownership system be zero cost when such a fundamental part of the language, like moves, is not ?
A dereference is MUCH cheaper than a copy though, and moves are basically free.
Clippy can also (and does) lint about unnecessary clones. I don't see why this couldn't apply to \`AutoClone\` as well.
If you don't have explicit clone() then implicit autoclone is really the only other option isn't it?
I haven't used `warp`, but your code seems reasonable! If you remove the `&amp;` in `if let Some(&amp;err)`, your code will compile. Because the left hand side here is a bind pattern, it is trying to deref `MyError`. If you just do `if let Some(err)`, `err` will have the type `&amp;MyError`. This is fine, because you don't actually need an owned copy of `MyError` in this block.
Few more: * Downcasting ergonomics, perhaps allow \`dyn\` patterns via the \`Any\` trait in \`match\` * Downcasting of \`dyn Foo + Bar\` to \`dyn Foo\` * More flexibility for dynamically sized objects and arrays by value on the stack via alloca &amp;#x200B; I also think there's a lot of untapped potential for \`dyn\` improvements in FFI. * More control over vtable layouts. It would be nice if we could make objects with vtables that are compatible with various ffi vtable layouts such as C++ thin pointers, COM, or GObject and use standard \`dyn\` semantics outside of the (hopefully generated) ffi glueS * Safer FFI for C flexible array members.
A zero-cost abstraction is just meant to have zero _additional_ cost over doing the thing manually, not magically remove unavoidable costs.
You can also use ```...``` which will is the same and quicker.i.e ```MyStruct {x:a,...} =&gt; println!("{}",a)```
You could have types opting into auto-cloning. `Rc` and `Arc` are good examples here.
Sure, but those costs are not unavoidable.
Question is how much of a cost is this 'in practice'? It may not be perfectly zero-cost, but it may be close enough in practice for almost all use-cases. Tbh, I'm just guessing here as I have never benchmarked move operations.
&gt; Where you might chase through multiple layers of pointers to get at the inherited code to be called. Is that true though? C++ and Java should just put the parent vtable at the start of the child vtable. A pointer cast should be enough.
Because of the Deref trait dereferences can be arbitrarily expensive. I don't know how moves can be basically free when copies aren't, since they are both memcpys.
So this works, but requires type annotations at the use site: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d1a59387bf6c99a81cd76b794feb31a2
React Native is also IMO a good place to draw inspiration. In particular they have a styling system that is like CSS but with only the good parts (flexbox).
Because this is much more architecture dependent than other things (do you have examples?). Should the compiler start warning about things like "this isn't aligned and vectorization may be pessimized" or "this (estimated to be hot) loop *almost* fits within the icache for $processor; maybe shave off an instruction somewhere?". Performance things like this are guesses without measurement. If the structure is large and on the stack but never actually moved (e.g., it is made in `main()` and used via reference everywhere), should the warning still occur?
Test it yourself: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=67f7be14748a5ebf8bfe102dcb6f3973 You can comment/uncomment the vector types at the top and check how long does the code take to run on the playground. The difference is so noticeable that I did not bothered to add timers, but if its not slow enough for you, you can always make the `ArrayVec` larger.
Moves are memcpys of 8 bytes, done in a single instruction (and sometimes, with optimization, no copies at all because of expiring references). Copies can often be significantly more with unbounded size.
Wow, thank you! I don't mind type annotations. Boy though, I'm surprised this scenario, which seems fairly innocent, is proving so difficult. PhantomData is interesting. Do you know if there are any downsides to using it in this implementation? Or is it purely a compiler helper, _always_ compiling out to nothing?
Thanks, that's correct. Adding `x.as_ref().and_then(f)` should be the same as the function I posted. This is way more useful than what I had before. Thanks!
Is a move always a memcpy? I could see it being optimized out quite often by LLVM.
Do these GNOME+Rust hack fests occur frequently? I moved to Berlin recently and would love to attend if so!
The rules are applied inconsistently, but I don't think that means the rules should be thrown out entirely (I don't think you're saying that either). I think the original decisions involved personal preference and the fact that arbitrary lines had to be drawn. Things can always be made implicit later, but they can't be made explicit later, so keeping things like `Clone` explicit was the conservative choice. Personally, copying large types is something I wish the compiler actively helped prevent, maybe something like `#[derive(SmallCopy)]` which would fail to compile for types above a certain size. `AutoClone` seems like a broadly useful feature that would make a good companion to `Clone` and `Copy`.
Why would move be a memcopy when all it needs to do is change the name of a location in the source text, in consequent representations it can even be treated as the same reference. That's the whole point of move semantics.
I would feel the same as storing plain text passwords.
&gt;Yea, clone is a classic example, and I've long wanted a mechanism for types to opt into having implicit clone semantics without guaranteeing a memcpy implementation. I think this is one of the great simplifications of rust over C++ and I would be sad to see it go. Assignment never fires missiles!
Most well-designed Rust data structures are just fat pointers to heap-allocated memory. The actual memory need not be copied, since Rust's move semantics guarantee the original reference to this pointer is never used again; the fat pointer can simply be passed up and down the stack. Because of Rust's memory safety guarantees, cloning a data structure requires a recursive copy. This might be doable in a single memcpy, but not always.
&gt;Things I've seen are: &gt; &gt; - even *having* a static method means a trait object can't be made Are you proposing this or saying that this is how things work now? I don't understand why having estatic method should affect whether or not you can have a trait object at all.
That is untrue. Moves are memcpys of *the size of the moved object*, which is just as unbounded as a copy.
That's the way it is today.
What if you were allowed to implement move, but it had to be marked unsafe? Can the compiler be any more intelligent about implementing swap(a,b)? It seems like in that case it should only ever need to make shallow copies, and we know from pre-C++11 swapping is sufficient for many use cases.
This is inaccurate. Moving from a local to another local will usually be *optimized* away so it's just a change in the name, but there are many more kinds of moves. For example: moving into or out of a `Vec` or `Box`, moving out of a `Result` into an object, moving out of an argument into an object, or moving out of an object into an argument or return.
Moves are often cheaper, yes, but desiringmachines is well aware of this and is not making that comparison.
But... Why? That seems like a completely unnecessary arbitrary restriction.
I admit that I was never a fan of advice to use a reverse proxy (especially solely for tls support). But your pointer to traefik and others has convinced me that I need to reevaluate. Thanks!
&gt;Or is it purely a compiler helper, always compiling out to nothing? Correct. https://doc.rust-lang.org/std/marker/struct.PhantomData.html
Erm, that's a real problem with moves, but the named zero-cost abstractions don't rely on moves to be zero-cost (except maybe iterators in some circumstances).
I don't know the details, but having done work on projects with strong backwards compatibility guarantees (CMake), deny is a better default than allow for such things because rescinding support is much harder than saying "oh, yes, that makes sense" and lifting the restriction later.
&gt; Edit: also in principle since the compiler has a direct understanding of enums we should just make it smart enough to only copy the variant actually in use. As far as I can tell the compiler has all the information it needs to do that. True, I think there is an issue already open for that. This won't making moving `ArrayVec`/`SmallVec` fast, nor other more general data-structures (like an `ArrayHashMap`, `SmallSet`, etc.). &gt; What if you were allowed to implement move, but it had to be marked unsafe? I don't know if this is possible. AFAICT a lot of Rust code, and particularly a lot of unsafe Rust code, assumes this does not happen. Any change to the language would need to guarantee that all this code does not break. This is quite a hard constraint.
A programming language is a tower of abstractions, which build on top of each other. Almost all Rust abstractions build on top of move. Without moves, ownership &amp; borrowing wouldn't work at all (you could only borrow, or clone). Same for closures, for which even a `move` keyword was introduced. Async/await relies on generators (essentially large unions/enums), which are moved until you start polling them.
Is this something a future version of Rust could allow a type to override? For example: unsafe trait Move { fn move(src: *const Self, dest: *mut Self); } One issue is that the compiler is allowed to elide moves. So if you put some wacky side effects in the implementation, there's no guarantee that they'll actually happen. But perhaps that could be part of the documentation of the trait: "If you implement this, the compiler _may_ call it when moving a type, but the compiler may also call it zero times or more than once." Another issue is that a lot of unsafe code wants to be able to reason about whether something it's doing can panic. Usually that boils down to not calling caller-defined functions inside of critical sections. This would add the possibility that simply moving a type could panic. But perhaps this too could be part of the documentation: "Panicking inside of `move` is always undefined behavior." A thornier issue might be things like signal handlers, which can only call an extremely limited set of system functions, not even including `malloc`. If moving a caller-defined type can call arbitrary code, it might be much harder to implement generic code that deals with signals, interrupts, or forking. I'm not sure how to address that.
&gt;Because of the Deref trait dereferences can be arbitrarily expensive. Technically true, but most people who know enough Rust to want to write their own smart pointer know that the deref() method should be cheap on the order of a few instructions.
I'm not sure that moving from argument is a copy in cases where local to local would be. In my naive idea a call with a moved argument is: - push the heap location of arguments to the stack - jump to the called subroutine - pop heap location from stack - treat it like a local object I have little Rust experience but this is basic pass by reference. I'd expect move from Result to be optimized to this as well. As for others, I suppose I never considered such actions to be "moves" as it's pretty obvious that such invasive change in memory/object geometry requires copying of data. In such cases it could be argued that implicit move / explicit copy is not a performance but consistency issue. It's still the "sanest" option given all alternatives.
`Move::move` would need to be a `const fn`, otherwise you can't move in const context, and that's something that's allowed today. There is no way to make sure code inside `Move::move` does not panic, and a lot of code assumes that `Move::move` is just a memcpy of the bytes, and therefore it can be replaced by a `memcpy` of the bytes, so anything that does not respect that isn't probably an option. Also, would this be an `auto` trait? Or not? With negative reasoning, would this allow `T: !Move`? etc. Anyways internals.rust-lang.org might be a better place to explore this. There are probably many other problems / constraints in trying to solve this that we are probably missing.
I can second your point about dynamic dispatch vs monomorphization. Quite a few times I would have preferred to use \`&amp;dyn T\` over generics, but Rust very un-subtly pushes you down the generics route, due to the single trait/vtable limitation. This introduces a lot of boilerplate, awkwardness and maintenance burden because I often would have had to wrap multiple traits in a super-trait with manual downcast methods. &amp;#x200B; I'd love to see support for multi-trait box objects. &amp;#x200B; Rusts type system is amazing, but I sometimes feel like I have to bend over backwards and carry generic constraints all over the codebase to enable something that would be easy and painless in C++.
Unlike with static dispatch where functions that use a trait are essentially copy-pasted once for each concrete type they get used with (meaning they know the concrete method to call at compile time) when you're doing dynamic dispatch, you need access to the vtable to know which method to call at runtime, so you need a reference to self, which static methods don't have. You can get around it by just adding an unused &amp;self argument to the method
\&gt; Last September I commented to a friend that I was worried I would never do any work as good as the work I had just done (in reference to the Pin API), and I really did feel that. What makes the Pin API so innovative/ground breaking? (I'm not poking here, I just don't know/understand enough about it.)
I don't know if this is quite what you're looking for, but quite a common pattern in Rust which makes functions nice to use (and feels like function overloading) is making functions accept an impl of Into, like `fn foo(value: impl Into&lt;Foo&gt;)` as an argument, because you can just write `foo(foo_like_thing)` instead of `foo(foo_like_thing.into())`. This convenience however leads to your `foo` function being instantiated lots of times when effectively just the first line is different, All these instantiations are much less likely to already be in the icache, and if the function instead accepted a trait object, you avoid all that code duplication. Tbh it would be more ideal if the compiler could learn to deduplicate the common function bodies caused by this idiom.
Seconding this. C++s who knows where implicit moves/copies were the bane of my existence. If developers are ritualistically avoiding `clone` even when it doesnt make sense, thats their problem, the rest of us shouldnt suffer for it.
You're my new hero! :)
They happen every 6 months but the location changes every time. It might take a long time before it happens in Berlin again.
I'm not sure why you're bringing up the heap here, it not used at all in Rust's ABI. Here's what it looks like, on x86-64 Linux, to call a function with a large argument: * Get the large object somewhere, likely on the stack. (This is where it ends up when you write `let x = SomeLargeObject { .. }` or `f(SomeLargeObject { .. })`) * Put the address of the object in a register. (x86-64 uses RDI, RSI, RDX, RCX, R8, R9 for the first six arguments. 32-bit x86 would push the address on the stack instead.) This address refers to stack memory, as per the previous point. * Jump to the called function. * Use above register to access the object. Now if the callee just does something like `let foo = my_large_argument`, that will likely be optimized out such that `foo` will just continue using that same register. But I said "moving out of an argument into an object." Continuing the above, that looks like this: * Find some space for the new object. It doesn't matter whether this is stack or heap, the problem is it will *never* overlap with the location the caller used for `SomeLargeObject`. * Memcpy the argument (not its address, but *the actual object*) from the place the caller put it into the new object. For example: https://gcc.godbolt.org/z/sx24l_. Note that, while this example has the target object living somewhere else, it still applies if you simply construct the target object locally in the callee. It has to, for that object to have a consistent layout in memory. That is, Rust doesn't use pointers or pass by reference unless you ask for them. Values are stored *in line* on the stack, or in their containing object, or wherever they happen to be. This usually works great, when objects are small-ish, but it starts hiding costs when objects are large. You can work around it by manually putting large objects on the heap with `Box`/etc. but that's exactly what desiringmachines is talking about- large objects are a case where the expensive thing is the "implicit" default and the cheaper thing is "explicit."
I think Rust should be *more permissive* about code with performance costs that I think are trivially unimportant, like copying an Rc pointer.
One small pet peeve of mine is `String` doesn't `impl` `Add` so that programmers have to put `a + &amp;b` instead. Locally, this isn't too bad. But in a generic context I had to write a separate trait just to handle `String` and other types that have `Add` implemented. In fact, `a + b` could use either of the allocations, and it might be faster to use the allocation from `b` since you may not need to resize it.
I have investigated this and am confident that move constructors are the real issue (and have no chance of being added to Rust). Allowing specific types to opt into copy without being memcpy is completely reasonable.
I've written a few APIs using both Rocket and Warp. While I think Rocket and Actix are tied in terms of being the "pragmatic" choice for a web framework, [Warp](https://github.com/seanmonstar/warp) may be worth checking out if you favor a method-chain heavy dialect of Rust over a more imperative style. I wouldn't recommend using a WASM based framework for your frontend. What you get in regards of being able to use a more modern language and being able to use the same types on the backend and frontend, you also get bloated compile times and a lack of supporting libraries (think like Bootstrap or MaterialUI integration). Compile times longer than a couple of seconds are a killer when iterating on any aesthetic aspect of your site. You are much better off using TypeScript + React/Angular/Vue. I don't think there is a comparable language to Rust for use in web backends. You are likely best off looking at the framework-specific guides. [Rocket's guide](https://rocket.rs/v0.4/guide/), should you choose to use Rocket, is some of the best documentation I've seen for a web framework. Since you didn't mention anything related to databases, [Diesel](http://diesel.rs/) is a very nice ORM/query builder once you learn to avoid triggering its page-long compiler error messages :). Its not async yet, and so it can't handle an insane number of requests, but it should be more than suited towards your needs.
So can many copies, especially after inlining.
Rust does not have "pass by reference." Everything is passed by value and moves are memcpys unless optimized away.
What fortunate timing, I've been looking at this myself a lot recently. In short, as far as I know there's nothing Rust-native, but it can use any JavaScript engine that you can use through C. I've experimented with [JavaScriptCore](https://developer.apple.com/documentation/javascriptcore) (the engine provided with macOS and iOS) and [Duktape](https://duktape.org/), a much smaller footprint library. I'm in the midst of creating a most Rust-y wrapper that'll allow you to use the same code with both, but I'm a ways off it being done yet. But the C-based libraries are ready to go, if you can tolerate the syntax!
Even this imagines too much agency in the decision: there's no autoclone because designing an autoclone has never been a high enough priority and it takes work to do that. But the elevation of the inertia of where we are today to some sort of gospel makes this work much harder, because you are guaranteed a barrage of reductive arguments about making "expensive" operations "explicit."
Doesn't Rust do this already?
Isn't that exactly what the Copy trait is for?
Pin solved a very hard problem we had been struggling with for years (self referential generators) with 200 lines of library code.
I disagree with your assessment. Using autocert in Go is literally one line of code. I used it recently on a server and it was a *lot* easier than setting up a reverse proxy. Plus it is cleaner architecturally (assuming you have a single server) and easier to deploy. If there were a Rust equivalent I would use it.
It is (mainly) so that generic functions with a *signature* like `fn foo&lt;T: Foo + ?Sized&gt;(x: &amp;dyn T)` can always be called with the trait object (that is, `T = dyn Foo`), no matter what the implementation is. http://huonw.github.io/blog/2015/01/object-safety/
Interestingly, I actually still prefer clone on the `rc` types, since it makes the ownership story more clear.
err-ctx looks great, thanks! Doing the same with failure is much more verbose.
Maybe a build script would be better?
I once did something pretty similar by aligning key/value pairs with the same key. I solved the issue you are describing for `(&amp;mut, &amp;)` , `(&amp;, &amp;mut)` , ... with an `unpair` trait: [https://github.com/Bendrien/ommap/blob/master/src/iter.rs#L150-L183](https://github.com/Bendrien/ommap/blob/master/src/iter.rs#L150-L183)
See the err-ctx create mentioned elsewhere.
I'm extremely interested in hearing more about how you got to this conclusion if you have a few minutes
That same logic could apply to a hypothetical `ImplicitClone` trait
It's working really well! Took me about 20 minutes to write up some code that I was struggling to write before. Nested Promises in Rust are... not ergonomic without this. Kudos!
You should use [`catch_unwind`](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html) somewhere high-up to make sure that a panic while handling one request doesn't affect the other requests.
`Clone` has nothing to do with size. Rust already copies large structures silently.
Tons of unsafe code assumes that moves are memcpy's, and we've pretty much guaranteed it. But no one can assume types can be copied by memcpy *unless* they implement `Copy`. This is sort of connected to the problem with `?Move` - it's a part of the language semantics that every sized type can be moved and that it can be moved using a memcpy. Obviously if a clone impl can panic or do IO or whatever you shouldn't implement `AutoClone` for that type as a matter of good sense, but the same is true for `Deref`, which can of course also apply implicitly on assignmen.
`future.await` is a good example of how the language team doesn't need to listen to the barrage of reductive arguments to get things done. I think it sets a useful precedent in that regard.
https://crates.io/search?q=mock
That wasn't my experience. ;)
There's also [neon](https://neon-bindings.com/) for interfacing with node / v8, and ongoing work to stabilize an embedding interface for node: https://github.com/nodejs/node/issues/23265 It's not fully stable yet, and it's significantly heavier than those options cause it comes with libuv and the node std library, but it could be helpful. There's also various [scripting engines](http://arewegameyet.com/categories/scripting/) for other languages. Lua support is most mature rn.
When I've looked at mocking libraries, a lot of them needed you to have set up the trait being mocked specially, and seemed to mostly need nightly rust. So I could mock my DAO traits, but not the database connection that the Dao uses. Or am I missing something?
While that may be technically true for some places where moves occur, it is not a useful mental model to consider moves as anything but essentially free. Rust's move semantics guarantee that a move can be converted to an alias, as long as the memory of the source has the same or longer life time as the destination, which is almost always the case within a stack frame. A large object converted to a reference in a function argument gains the same advantage, because no copy needs to remain in the caller. (I haven't checked if this is actually taken advantage of on any current target.) Even if all this was not true, memcpy of known-size objects on stack memory is orders of magnitude faster than anything useful any program will ever do. In short, don't sorry about it.
Yeah. The Java ecosystem has always been a bit of a "goes above and beyond" anomaly as far as having native JavaScript runtimes. Rhino came about because, with all the hype about Java in the 90s, Netscape was planning to write a browser 100% in Java but only got as far as a JavaScript engine. Nashorn, on the other hand, was written by Oracle, who have a decent incentive to throw some of their budget at increasing the attractiveness of the language they own the IP to.
Makes sense, thanks for explaining. I agree that if we can trust devs to be smart about implementing `Deref` we can do trust them to do the same with AutoClone
I disagree, since I'd prefer the language to have as few edge cases as practical. Saying that `X` defaults to moving but `Y` defaults to copying sounds like a pain.
we already have `Copy` types
The `Copy` trait requires a bitwise copy and can’t run type specific code. `Rc` and `Arc` need to update reference counts on clone.
Hm, well diesel has mechanisms for testing although they're not super well documented: https://github.com/diesel-rs/diesel/issues/1549 You can also write a trait for your database interactions and implement it for your real backend + use a mocking library for tests
Fair point. (it's been a while)
&gt; Rust's move semantics guarantee that a move can be converted to an alias Except for: - `Box::new(thing_to_move)` - `*thing_on_heap` - `AnyOtherStructure { x: i32, y: thing_to_move }` And a ton of other cases where move is a `memcpy`. &gt; memcpy of known-size objects on stack memory The cost of a copy has nothing to do with where the destination lives in address space. The stack isn't some magical part of RAM that is magically faster for all operations.
I'm building an interpreter and try to move to traits (because make easier to add types after the fact for FFI) but is very HARD! &amp;#x200B; Rust certainly hate the idea of use traits alike enums. Among other things, implement stuff like clone, PartialEq, etc look like demand to know the full list of implementations? &amp;#x200B; I wish that one of this 2 things happened: &amp;#x200B; \- I way to "register" implementations to a trait system, or probably much better: \- A way to extend a enum from another: enum ValueFull from Value Also I wish exist a way to "pin" what exactly is the branch I will return: fn int(&amp;self) -&gt; Value::Int So I can take my cake and eat it too. &amp;#x200B; This will be awesome to declare stuff like arrays: let ints:Vec&lt;Value::Int&gt; = [1,2,3].into()
It is definitely not true that moves in Rust are somehow more expensive than moves in C++. For one thing, C++ must invoke a move constructor, as well as an additional destructor call, and since the "moved-from" state is required to be defined, the compiler cannot just alias the memory except under very special circumstances (prvalue or xvalue, I forget which one). What you are saying is that stack memory is not a zero-cost abstraction. Technically true, but I wouldn't say that's a useful way to approach modern software development. :-)
It sounds like you should maybe just implement the iterator trait for your `Spaces` struct so you have complete control over what value is returned by `next()`
If for item in myarena.iter() works then I think this should work ``` impl&lt;T&gt; Spaces&lt;T&gt; { fn iter(&amp;self) -&gt; impl Iterator&lt;Item = &amp;T&gt; { self.arena.iter().filter_map(Option::as_ref) } } ```
might have to use duktape for now then, I was aware of duktape but was secretly hoping for something in pure Rust :)
Custom trait is the route I've been going so far, but it just feels like a problem that should have already been solved. Especially in a language that puts first class emphasis on testing. It also proved hard to do with r2d2-postgres. The `Row` class returned from a query doesn't seem to be constructable from outside the crate, and depends on some core innards of the postgres protocol. :-( Wrapping Diesel would probably be easier, but it seems wrong to write an abstraction layer onto what is already an abstraction layer for the database...
Curious, is there a downside to implementing it like this? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b3ae21320f5c3a8ca8c843f07ecea486 The difference primarily being in this code: impl&lt;A, B&gt; AlignIterator&lt;B&gt; for A where A: Iterator, B: Iterator, { fn align&lt;T&gt;(self, rhs: B) -&gt; Align&lt;A, B, T&gt; where Self::Item: Borrow&lt;T&gt;, B::Item: Borrow&lt;T&gt;, T: Ord, { Align { lhs: self, rhs: rhs, phantom: PhantomData, } } } Where B is defined on the interface, rather than the method. I'm toying with the idea of using this because it allows the caller more clean *(imo)* syntax of `a.iter().align::&lt;i32&gt;(b.iter())` - is there a downside to this I might not be considering?
I should clarify - JavaScriptCore is actually available on all platforms, it just happens to be bundled with iOS and macOS. I far prefer the API it provides over Duktape's, but the runtime is also about 50x the size, so depends what you're looking for.
If the definition of the trait is that the compiler _may_ use the implementation instead of a memcpy, maybe that's enough to make it work in const contexts without forcing the trait to be const. (The compiler effectively always exercises its right to memcpy.) But yeah I'm thinking about this for the first time, and I have no idea what I'm talking about.
That's very elegant. An alternative implementation is self.arena.iter().flatten() which works because `&amp;Option&lt;T&gt;` implement `Iterator` (with `Item = &amp;T`). Not necessarily better, just putting it out there :) Yours is for sure less surprising.
But traits are allowed to have associated types, which you can only use in the monomorphized mode. How is that not the same?
There doesn’t *seem* to be a downside; go for it!
I have a type Numeric on my PosgreSQL entity, and using Diesel, this is the generated schema table! { spendings (id) { id -&gt; Int4, user_id -&gt; Int4, amount -&gt; Numeric, description -&gt; Varchar, } } and I update my struct accordingly #[derive(Queryable, Serialize, Deserialize)] pub struct Spending { pub id: i32, pub user_id: i32, pub amount: Numeric, pub description: String, } However I got these compiler errors error[E0277]: the trait bound `diesel::sql_types::Numeric: diesel::Expression` is not satisfied --&gt; src/models/spending.rs:47:10 | 47 | #[derive(Insertable, Deserialize, AsChangeset)] | ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `diesel::sql_types::Numeric` | = note: required because of the requirements on the impl of `diesel::expression::AsExpression&lt;diesel::sql_types::Numeric&gt;` for `diesel::sql_types::Numeric` error[E0277]: the trait bound `diesel::sql_types::Numeric: diesel::Expression` is not satisfied --&gt; src/models/spending.rs:47:10 | 47 | #[derive(Insertable, Deserialize, AsChangeset)] | ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `diesel::sql_types::Numeric` | = note: required because of the requirements on the impl of `diesel::Expression` for `&amp;diesel::sql_types::Numeric` = note: required because of the requirements on the impl of `diesel::expression::AsExpression&lt;diesel::sql_types::Numeric&gt;` for `&amp;diesel::sql_types::Numeric` error[E0277]: the trait bound `diesel::sql_types::Numeric: diesel::Expression` is not satisfied --&gt; src/models/spending.rs:47:10 | 47 | #[derive(Insertable, Deserialize, AsChangeset)] | ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `diesel::sql_types::Numeric` | = note: required because of the requirements on the impl of `diesel::Expression` for `&amp;'insert diesel::sql_types::Numeric` = note: required because of the requirements on the impl of `diesel::expression::AsExpression&lt;diesel::sql_types::Numeric&gt;` for `&amp;'insert diesel::sql_types::Numeric` &amp;#x200B; Any idea?
Hmm. I can see an argument for `Rc`, but I think, on the whole, it would hurt (especially in this case). I've already had to upgrade from `Rc` to `Arc` a couple of times. Having to tease out where a copy was done versus an implicit clone to avoid core synchronization would not have been fun. Granted my use case's performance were not tied up in that and I didn't care, but I could see where it could have been. For a language with a "fearless concurrency" motto, this kind of landmine for changing an `Rc` to an `Arc` doesn't sound "fearless" to me. I don't know; I like the `.clone()` adds a reference and a move transfers it being explicit in the code. *shrug* Aside: `Rc&lt;Arc&lt;T&gt;&gt;` is useful if a thread is bouncing an `Arc` refcount up and down. Have the thread own one `Arc` refcount that is managed with an in-thread non-atomic refcount. This pattern is also useful when exporting shared pointers to a refcounted language like Python. It avoids many inter-language calls.
That should just mean I can't call the static method via the trait. I'm assuming parent was saying this is a restriction of having a static method on the struct. If he meant on the trait then I'm not sure how he could expect that to behave.
I see these as "there's nothing to do *but* copy the bits" types. An `Rc` has additional meaning on top of its literal bitwise representation which an integer just doesn't have.
It is just a rename plus mutability. I suspect the purpose of that code is to teach that if you own a variable, you can do anything you want with it. Immutability applies to the binding (variable name), it does not prevent the data from ever being modified.
I'm new to programming. What is the point of something like this?
&gt; Rc and Arc are good examples here. I hope not, i love Rust because it makes ownership clear, i don't want ownership behind those types to become magic.
Without seeing your code, I'd guess you're making the http request inside a combinator (for an Iterator or Future, for example) without ever driving the combinator. For example, in the following code: fn main() { let urls = vec!["https://doc.rust-lang.org/", "https://play.rust-lang.org"]; urls.into_iter().map(|url| get(url)); } Nothing happens, except that you have created an object of a type similar to `std::iter::Map&lt;std::vec::IntoIter&lt;&amp;str&gt;, [closure@src/main.rs:3:35: 3:58]&gt;`. (You can see the type by prepending the map line with `let () = `, and trying to compile the code). In fact, if you compile the above code, you get an error message telling you that map must be used. You can use it by `.collect()`ing the results to a vec, calling `.sum()`, or iterating over it in a for loop. I'm not sure why the `dbg!()` macro drives the iterator. Macros are weird.
Oh, I dunno, I don't find the `.flatten()` surprising at all, but I'm a fairly experienced Haskell guy, so it's not as if I feel lost seeing something like that. It *is* frustrating that it's `for i in myarena.iter()` and not just `for i in myarena`; I feel like if I hammer on this for a few more days I could get an implementation I like, but I'd also like to get on with my life.
I want to have multiple implementations for trait that I can easily swap [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3b4044a9ff7dbbc5a3c07c16ef69cc1c) Despite trait impls are in different modules and only one is imported Rust still complains about competing implementations!
Maybe implement IntoIterator for &amp;Spaces&lt;T&gt;
And mine as well. :)
This is true. But I think it's important to note that even if OP *does* misunderstand something, it *is* a bit rude to assume this and respond as if it's the case. The fact is that no one else knows what it is OP misunderstands, if anything. If I asked a question and received a response that wrongly assumed that I've misunderstood the problem, I'd be a bit turned off asking more questions in the future.
If you just add move constructors we're back into territory where `=` can fire the missiles. If an `=` in Rust could panic, we'd have a much harder time writing panic-safe unsafe code. In unsafe code it's important to know you get from one line to the next; if you're in the middle of manipulating the internals of an object, you need to make sure its invariants are maintained when its Drop impl gets called or you may end up with UB at crash time.
I'd suggest making the return type concrete/ named if you're implementing this for a public API, as you cant use `impl Trait` in other places at the moment; it restricts what you can do with that value. For example, if someone wanted to name the type as part of a field in their own iterator structure, they wouldn't be able to without generics or dynamic dispatch.
&gt; Downcasting ergonomics, perhaps allow `dyn` patterns via the `Any` trait in `match` I don't think it's a good idea to make non-parametric reasoning, often an anti-pattern, any easier than it is already. Making it easier devalues types and documentation even more by breaking a caller's intuitive notion that a generic function acts uniformly with respect to instantiated type parameters. &gt; Downcasting of `dyn Foo + Bar` to `dyn Foo` This is upcasting; downcasting would be the inverse (`dyn Foo -&gt; dyn Foo + Bar`). I think we will do the upcasting this eventually, just a matter of time. t-compiler/wg-traits is actually already working on an implementation ahead of an RFC. However, this assumes that `Foo` is an object safe trait and `Bar` is a series of auto traits. Multi trait objects will probably come after at some point. &gt; More flexibility for dynamically sized objects and arrays by value on the stack via alloca Seems mostly like https://github.com/rust-lang/rust/issues/48055 for the latter at least. &gt; More control over vtable layouts. As long as it is opt-in with an explicit marker I'm usually fine with such control. I'm not a big fan of specifying things about `repr(Rust)` or anything that comes close to stable ABIs.
[rust-lang/rust](https://github.com/rust-lang/rust) repository has been mentioned **13 times** on Reddit over the last 7 days. The last 3 mentions: |Mention|Source| |---|---| |[..] else we&amp;#39;ll just need to be mindful of how we teach it. Certainly! Good progress is already being made on that front; our diagnostics guru Esteban Kuber has already made up some plans [ https://github.com/rust-lang/rust/issues/60613 ]. [...], I&amp;#39;ve had a little smile in the back of my mind. Same! =P|[/r/rust](https://reddit.com/r/rust/comments/bmhmtw/what_postfix_macro_could_bring_to_rust_asyncawait/emzfohl/ "/u/etareduce at 2019-05-10 03:03") | |You can get a repo&amp;#39;s lines per language count at https://api.github.com/repos/**REPO OWNER**/**REPO NAME**/languages and then feed it into a d3 pie chart https://www.d3-graph-gallery.com/pie as a static web page. You don&amp;#39;t even need an api key. Here&amp;#39;s an example Original repo URL: https://github.com/rust-lang/rust Language data URL: https://api.github.com/repos/rust-lang/rust/languages|[/r/AskProgramming](https://reddit.com/r/AskProgramming/comments/bmzx6a/github_piechart/en2iuh8/ "/u/firelemons at 2019-05-11 00:14") | |[..] experimental and unfinished- someone just needs to do the implementation work to generate better code here.Or as another example, that comment you linked pointed out rust-lang/rust#52924 [ https://github.com/rust-lang/rust/issues/52924 ]. Async-based futures are currently much bigger than combinators-based futures, because little to no optimization happens on their layout, unlike synchronous stack frames or user-defined struct types. tmandry is doing that implementation work now: rust-lang/rust#60187 [..]|[/r/rust](https://reddit.com/r/rust/comments/bnn9kh/are_we_await_yet/en8fbk4/ "/u/Rusky at 2019-05-12 17:10") | ^([Report an issue](https://np.reddit.com/message/compose/?to=gajus0&amp;subject=GitSpo%20Reddit%20mentions%20bot&amp;message=Hello%20Gajus,)|View all [mentions of rust-lang/rust](https://gitspo.com/mentions/rust-lang/rust))
You might want to look at the [enum_derive](https://docs.rs/enum_derive/0.1.7/enum_derive/) crate. I'm using it to solve some problems that sound similar to yours.
Hey, really appreciate the help. You led me down the path to work through a working solution, which led me to even removing the PhantomData. Huge thank you! My _(current)_ solution, for anyone interested: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1ddd94279099ed2f4d90364ce641c838
Awesome project! I might pick a different name that Terraform, however - https://www.terraform.io/ Seems like that project might make yours less discoverable.
Why don’t you call `align_by` in the definition of `align`? It seems cleaner than manually constructing the struct twice.
I'm developing an app with Actix Web and Yew. They work nicely.
Good call!
There's no way to do exactly what you're asking, but you could change it to `Stuff&lt;T&gt;(PhantomData&lt;T&gt;)` and have different implementations for e.g. `Stuff&lt;Impl1&gt;` and `Stuff&lt;Impl2&gt;`. I have to ask what you're actually doing this for though, because there may be a better way.
You can do it even simpler: trait Same&lt;Rhs = Self&gt; { type Output; } impl&lt;T&gt; Same&lt;T&gt; for T { type Output = Self; } fn main() { let _: &lt;u32 as Same&lt;u64&gt;&gt;::Output; } This is how I test type equality in typenum.
I made a pretty thorough, safe Duktape wrapper a while back but never published it or made proper examples. https://github.com/SkylerLipthay/ducc Here's a quick, untested example: ```rust let mut ducc = Ducc::new(); let class = ducc.create_object(); class.set("add", ducc.create_function(add))?; ducc.globals().set("Arithmetic", class)?; assert_eq!(9.5f64, ducc.exec("Arithmetic.add(4.5, 5)", None, ExecSettings::default()).unwrap()); fn add(inv: Invocation) -&gt; ducc::Result&lt;f64&gt; { let (a, b): (f64, f64) = inv.args.into(inv.ducc)?; return Ok(a + b); } ``` You can see more examples in the `ducc/src/tests` folder. It actually has all kinds of cool features like storing user data for access in JavaScript land and support for execution canceling (timeouts). I haven't had a need for this library since I made it, but that may change soon. Anyway if anyone is interested in using or contributing to this code, let me know!
Best I managed is to get bb first, which is what you didn't want. In case it helps... https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b0d564a9e7026d7c4604c05f432f069d Only option I can visualize as working would be to store Rc&lt;CC&gt; in the map or make CC Copy or something like that. No idea if this can be solved with lifetimes, maybe annotate CC and BB a bit? Dunno
Hey if you're interested, you might want to check out my work with Duktape posted [in this thread](https://reddit.com/r/rust/comments/bpicyx/javascript_engines/enuupge/). Let me know if you want to talk, or alternatively feel free to reference/steal it for your own work! Best of luck
To be honest, my `target` directory often is at least 400MB, and often reaches 2GB per project when using multiple frameworks.
I like enum inheritance too. Niko has posted about it here: http://smallcultfollowing.com/babysteps/blog/2015/10/08/virtual-structs-part-4-extended-enums-and-thin-traits/
&gt; err-ctx Ah I see, well, such information can be stored in user's created Error, if he'd wanted. So I'm not sure why there is a need for particular crate. From your needs, I believe you need exceptions rather than user crated errors, as such context can be quite heavy
I was so confused for a sec
They need to are specified as part of the trait object type itself, e.g. if `Foo` had an associated type `X` above, it would be called like `T = dyn Foo&lt;X=i32&gt;` (or whatever the type `X` is). This means `T::X` is known inside `foo` even when `T` is a trait object.
I am working on an app whose backend is written in Rust - using Actix framework. I have experience in builing eCommerce websites - but that's in PHP. I believe, if you choose Rust, then you would have to write everything required in an eCommerce website from scratch. You will get a web framework in Rust, which would reduce your work, but yes, you will have to write the eCommerce concepts from scratch. If you are concerned about performance, then choose Rust. If you want the site to be made quickly, without much effort, and with well-tested services, then go for some other language.
So as I was removing `xi-rope` dependency from my [org-rs](https://github.com/org-rs/org-rs) project I faced a necessity to have the a Cursor implementation for regular `String`. On one level I want to have a `trait SimpleCursor` trait that can be implemented both by my StringCursor and by `xi-rope`'s Cursor. On another level I want to have something like `AdvancedCursor: Simplecursor` that will provide more advanced capabilities, but also with possible different implementations for each Cursor. A good example of such "advanced capability" is searching. It can be done by using Regex or by Nom parser combinators. Regex search and Nom search implementations are specific to the Curosr (StringCursor will have different algorithms than `xi-rope`'s Cursor) In other words: 1 abstraction level over: My StringCursor and Cusror from xi-rope. 1 abstraction level over Cursor-specific searching algorithm. Possible combinations: 1) xi-rope cursor with regex searching, 2) xi-rope cursor with nom searching 3) my cursor with regex searching 4) my cursor with with nom searching In the end it all should be transparent to the user of `AdvancedCursor` trait. Thanks!
Thank you for the detailed reply! Will read rockets documentation.
Thanks for the input!
Or you can plan for microservices. Write the performance oriented features of the website in Rust, for example, the product listing, product search.
Great article, really appreciate the insight into language construction
I still think Rust should adopt my preferred syntax /s
`core` is the freestanding portion of `std` (all the parts that don't rely on anything provided by the operating system - e.g. memory allocation and file IO)
Embedded situations, without an OS, can use `core` but not `std`. Normally you don't need to know the difference, because `std` re-exports all the `core` stuff as well as what it provides (clock, network, mutex, etc)
I don't think that the decimal type is supposed to be deserialized to given that [it doesn't have any members](http://docs.diesel.rs/src/diesel/sql_types/mod.rs.html#179) so it can't be used for anything other than converting to BigDecimal. Try `pub amount: BigDecimal` (after adding the big decimal crate and the decimal diesel feature).
in rust?!?
But if we want `dyn MyTrait` to still implement `MyTrait`, then it needs to have all static methods available. Consider the following situation: trait MyTrait { fn do_thing(&amp;self, x: &amp;str); fn static_method() -&gt; String; } fn operates_using_trait&lt;T: MyTrait + ?Sized&gt;() -&gt; String { T::static_method() } fn takes_trait&lt;T: MyTrait + ?Sized&gt;(argument: &amp;T) { let s = operates_using_trait::&lt;T&gt;(); argument.do_thing(&amp;s); } fn main() { let x = ...; takes_trait(&amp;x as &amp;dyn MyTrait); } Where should this code fail, if not at `&amp;x as &amp;dyn MyTrait`? There's a solid guarantee in Rust that if a method compiles, any generic parameters that satisfies its trait bounds will succeed. `takes_trait` requires an argument, and uses that argument with a self-method, but also passes the trait to `operates_using_trait`. `operates_using_trait` requires that a static method be available. We could allow `&amp;x as &amp;dyn MyTrait`, but if we did, we'd have to break something else. I think the only other reasonable choice would be having the call to `takes_trait` fail - but doing that, we would end up in the odd situation where `dyn MyTrait: MyTrait` is a false bound.
I think FFI introduces snags here, and doesn't work well when deserializing complex types. For example, when deserializing types like String or Vec you sometimes need to allocate memory, and then you have a value that has been allocated in Rust but will be used in C++. And how exactly will you insert data into a C++ vector or map? What you want is probably a parser for C that can emit the serialization code. Adding Rust to the story only complicates things.
This is bad ass!!!!! Thanks for sharing.
The abstration is the code on top. An abstraction is zero cost if doing the thing manually achieves little in terms of performance. One abstraction doesn't inherit the performance characteristics of the abstructions it's wrapping. Everything costs something, the purpose of a zore cost abstraction is to cost nothing more (in theory) not cost nothing, so you need to exclude the middle. It's the difference that matters.
Hmm... The phantom data solution seems okay for this. I think a better option is to use features, assuming you expect any given user to only use one implementation.
Why wouldn't the call to the static methods at the site of the trait `impl` be "monomorphized" so there's no ambiguity? I totally understand from the standpoint of calling the static method when you have a trait object, but why doesn't the trait object know which static method to call inside it's own methods?
Additional question: I've wondered if there's situations where you might prefer `core` over `std` for the same type/function? For example, `std::mem::size_of::&lt;T&gt;()` and `core::mem::size_of::&lt;T&gt;()` as far as I can tell are equivalent. What's the point of having both?
`std` just reexports things from `core` for uniformity.
I'm trying to download multiple files asynchronously using reqwest, and write them to disk. The problem is that the files need filenames according to some data that I cannot work out how to pass along with the request object. Here's the code I have: use std::path::PathBuf; use futures::stream; use futures::stream::Stream; use futures::future::Future; use reqwest::r#async::Client; use std::fs::File; pub const NUM_PARALLEL_DOWNLOADS: usize = 8; pub struct Downloader&lt;'a&gt; { root_url: &amp;'a str, data_dir: PathBuf, } impl&lt;'a&gt; Downloader&lt;'a&gt; { pub fn new(root_url: &amp;'a str, data_dir: PathBuf) -&gt; Downloader { Downloader { root_url, data_dir } } pub fn get_archives(&amp;self, package_name: &amp;str, sub_package_names: &amp;[&amp;str]) { let urls = sub_package_names.iter() .map(|&amp;sp| { format!("{}/archives/{}-{}.tar.gz", self.root_url, package_name, sp) }) .collect::&lt;Vec&lt;_&gt;&gt;(); let client = Client::new(); let work = stream::iter_ok(urls) .map(move |url| { client .get(&amp;url) .send() .and_then(|res| res.into_body().concat2().from_err()) }) .buffer_unordered(NUM_PARALLEL_DOWNLOADS) .for_each(|b| { println!("Got {:#?}", b); Ok(()) }) .map_err(|e| panic!("Error while processing: {}", e)); tokio::run(work); } } The problem is that I cannot work out how to pass along the data in the package_name and sp variables for each request in order to write them to disk, as children of data_dir. Once they're downloaded and written to disk, I will untar the archives for use in my program. Any help would be greatly appreciated.
Lets ignore complex C++ STL types for a moment. What if I just wanted simple C structs? If Rust allocates memory with the system allocator then can C++ free and/or delete that memory safely? Maybe this is all a terrible idea. But Serde in Rust is such a delight to use. I would be so happy if I could add #\[derive(Serialize,Deserialize)\] to a C struct. God that would be wonderful.
But it's not doing it in its own methods in the example.
&gt; The cost of a copy has nothing to do with where the destination lives in address space. The stack isn't some magical part of RAM that is magically faster for all operations. Ok, but because it's used more often and is of somewhat limited size, isn't it much safer to assume stack objects to be in CPU cache (L3 at the very least, L2 pretty likely) than "heap" objects?
Because `takes_trait` doesn't have any input, it needs to know exactly what method to call at complied time. But there is no one correct static method, because the `dyn MyTrait` value's methods all depend on its value at runtime. I added in `takes_trait` as a separate function to demonstrate this. If we wanted to have this example "work", the compiler would need to silently transform takes_trait, a 0-argument function, into a 1-argument function taking in some `&amp;dyn MyTrait`, and pass in the `&amp;dyn MyTrait` value so that it could know what to call at runtime. Actually, you're right. I think my example above could work, if we made the compiler do that. Trying to reply to your post made me think of an actual contradiction though, which I've included below: fn main() { // prints X takes_two_of_the_same(&amp;X, &amp;X); // prints y takes_two_of_the_same(&amp;Y, &amp;Y); // what should this print? // takes_two_of_the_same(&amp;X as &amp;dyn MyTrait, &amp;Y as &amp;dyn MyTrait); } trait MyTrait { fn static_method() -&gt; &amp;'static str; } struct X; struct Y; impl MyTrait for X { fn static_method() -&gt; &amp;'static str { "X" } } impl MyTrait for Y { fn static_method() -&gt; &amp;'static str { "Y" } } fn takes_trait&lt;T: MyTrait + ?Sized&gt;() -&gt; &amp;'static str { T::static_method() } fn takes_two_of_the_same&lt;T: MyTrait + ?Sized&gt;(arg1: &amp;T, arg2: &amp;T) { let val = takes_trait::&lt;T&gt;(); println!("{}", val); } What should the last line of `main` print in this case? It's a similar problem as the last one, but this time I don't think there's even a possibility of interpreting this code in some correct, expected way. The two values of `&amp;dyn MyTrait` are definitely the same type, so calling `takes_two_of_the_same` with them should be valid. But `takes_two_of_the_same` only uses the type information to call `takes_trait`, so it shouldn't and can't really depend on either of the values. An attempt to monomorphize to the "correct" function will necessarily fail, because the two arguments of the same type have different functions underlying them. Hopefully that's a better contradiction to this feature. Let me know if that seems convincing?
&gt; Lets ignore complex C++ STL types for a moment. What if I just wanted simple C structs? Possibly, but the C-&gt; Rust and back marshalling code would be just as complex as the deserialization, since they're more or less the same operation. And right now you have no way of generating that code, and if you had, you could simply use it for serialization. &gt; If Rust allocates memory with the system allocator then can C++ free and/or delete that memory safely? Maybe, but the C++ code won't be able to call Rust destructors (`drop`).
Not an example, but a rationale. Dynamic dispatch can have better cache affinity because there is less code to store in the CPU caches.
&gt; is to cost nothing more (in theory) not cost nothing, The purpose of a zero cost abstraction is to cost nothing more that if you were to write the code by hand without using the abstraction. You can write the code by hand, without using the abstraction, using better moves as a foundation, and that code is often much faster.
No, what I am saying is that C++ moves are in many cases more efficient than Rust moves. For data-structures like ArrayVec or SmallVec, C++ moves have even better complexity guarantees.
&gt; But I said "moving out of an argument into an object." I didn't really understand what you were trying to say (and you weren't terribly precise, either): fn move_into_object(my_large_argument: LargeTypeOfArgument) { let foo = my_large_argument is "moving out of an argument into an object". Henceforth, `foo` is an object, isn't it? &gt; For example: https://gcc.godbolt.org/z/sx24l_. Note that, while this example has the target object living somewhere else, it still applies if you simply construct the target object locally in the callee. It has to, for that object to have a consistent layout in memory. Ok I understand now what you meant, but this is not (semantically) different from the Boxing or Vec examples I concurred with. I personally wouldn't expect an "alias move" here (I already mentioned data geometry and this is obviously invasive). But in cases where we're simply passing large-ish objects around for some sort of processing (either for reading from or sending a &amp;mut reference for edit in place) I wouldn't expect any compiler, Rust included, to actually do a memcopy. &gt; I'm not sure why you're bringing up the heap here, it not used at all in Rust's ABI Because my understanding of how Rust specifically does this is limited, at best. &gt; You can work around it by manually putting large objects on the heap with Box/etc. but that's exactly what desiringmachines is talking about- large objects are a case where the expensive thing is the "implicit" default and the cheaper thing is "explicit." I see. This is actually interesting insight, I didn't know that large-ish objects are inlined as well by default for example, unless Boxed. I should have expectet that, I guess, for objects whose many copies would comfortably fit into CPU cache (say, L2 on Intel) tho. I always (perhaps naively) assumed compiler does these types of decision based on sizes, numbers and downstream usage paths for objects, when generating (and optimizing generated) code from the IR in the backend.
&gt; If Rust allocates memory with the system allocator then can C++ free and/or delete that memory safely? It's generally considered a bad idea to free memory in a compilation unit that didn't allocate it. On Windows, you're specifically **warned** not even to deallocate something that was allocated in a different *compilation unit* within the same language because there's no guarantee that two different libraries or versions of MSVC++ will use the same allocation machinery or memory pools. If you allocate in Rust, write a freeing function in Rust that your C++ code can call. (Similar to how SDL2 has the `SDL_Free...` functions to free memory allocated by various other functions.)
Not calling Rust destructors is exactly what I would want. &amp;#x200B; I don't want Rust code per se. What I want is a C function that can take a structure and turn it into a stream of bytes. And a C function that can take a stream of bytes and turn them into a struct. With some amount of nesting. These C functions are black boxes. Just a few simple functions in a header. I don't particularly care how those black boxes work. I want them to be performant, of course. But mostly I want them to be easy to generate and even easier to use. &amp;#x200B; My (maybe bad) idea is that those black boxes might be relatively easy to make with Rust. Largely due to the delightful crate ecosystem that I so badly wish existed in C/C++ land. But the fact that the static (.a / .lib) or dynamic (.so / .dll) libraries were compiled with Rust is invisible and irrelevant.
I wouldn't write custom tests on a \`Row\` basis. In the end, the database interaction can't really be mocked properly and can be covered with integration tests. What I would do is have something like a \`Db\` trait that abstracts over the database interaction. `trait Db {` `fn user_by_id(&amp;self, id: u64) -&gt; Result&lt;User, Error&gt;;` `fn users(&amp;self, query: UserQuery) -&gt; Result&lt;Vec&lt;User&gt;, Error&gt;;` `...` `}` That way you can cleanly abstract away the database layer and mock it out.
This pattern only really works in a microservices setup. As the number of entities grows, that `trait Db` becomes unmanageable. Take the stereotypical Blog example. The trait would be: ``` trait Db { fn user_by_id(...) -&gt; ... fn users(...) -&gt; ... fn save_user(...) -&gt; ... fn delete_user(...) -&gt; ... fn post_by_id(...) -&gt; ... fn posts(...) -&gt; ... fn save_post(...) -&gt; ... fn delete_post(...) -&gt; ... fn comment_by_id(...) -&gt; ... fn comments(...) -&gt; ... fn save_comment(...) -&gt; ... fn delete_comment(...) -&gt; ... fn category_by_id(...) -&gt; ... fn categories(...) -&gt; ... fn save_category(...) -&gt; ... fn delete_category(...) -&gt; ... // And so on } ``` The alternative then becomes to have a Db trait *per entity* - which is exactly what I'm doing. And it's the implementation of those traits that I'm wanting to unit test.
&gt; What I want is a C function that can take a structure and turn it into a stream of bytes. And a C function that can take a stream of bytes and turn them into a struct. With some amount of nesting. `memcpy` will do that to a certain extent. I suggest you look into https://capnproto.org/cxx.html. It's a little verbose, but the library is popular, maintained, and probably faster than `serde` with `bincode`.
This canes, nice one!
Thanks! I'll have a look at this
I've been trying to learn rust better, so making a simple .gitignore generator that has an offline cache so I can use it anywhere and anytime. Sadly I kinda discovered there are better ways to structure my CLI tool AFTER I finished my implementation, so planning to re-write it this week. [Feel free to checkout it and give feedback.](https://github.com/Ryhazerus/gg)
I've used Cap'n Proto. And protobuf. Also flatbuffers. Plus god knows how many proprietary protocols. Let's say for a second that my idea is really really stupid and bad and no one should do it for any reason ever. Not even for educational purposes. For reasons listed by yourself and u/ssokolow. Be that as it may, are there any crates would be useful for achieving steps 3 or 4 of my stupid proposal?
When I push a vector on another vector (or a Que) the system does not allocate memory again, does it, if I push the owned vector, not a slice?
Probably dumb question: When I watched a talk about how async/await is implemented, it described how it's based on a polling mechanism. Polling does not strike me as something that would be zero cost. What intuition am I missing here? I've not done much work with concurrency, although I understand the basic concepts
I don't think you can generalize from this (fairly contrived) example to say that there is a general problem with move semantics. This particular code can be made faster in C++, but it will not be universally faster (branches are needed during the move in C++, along with extra destructors, move constructors, and so on). Add to this that a vector of length 8192 is hardly "small" by any measurement, and allocating 65,536 bytes on the stack is a serious problem in any piece of code, whether it's C++ or Rust. (The default secondary thread stack size on Apple iOS is 512 KiB.) For the _actually_ small vectors for which `SmallVec&lt;T&gt;` is intended, the C++ version is likely to be slower in many cases. Blind `memcpy()` of something like (exactly) 512 bytes is likely to be much faster than copy-to-capacity of 0-512 bytes where the size to copy is only known at runtime, because a loop will be required. I think that you're using the term "zero-cost abstraction" in an unusual way here. Traditionally, it just means that you couldn't model the same thing using lower-level primitives and do it better. It does _not_ mean that there aren't specific corner cases where you can do something more efficient for specific code. C++ has many similar corners: The requirement that every object has a unique address means that some C++ structs/classes are bigger than they really needed to be (leading to ugly hacks such as the fact that `std::vector` has `std::allocator` as a private base class in most stdlibs). Virtual method calls in C++ can often not be devirtualized, even when you expect that the concrete type is fully known to the compiler, due to the existence of placement-new. And the list goes on.
Do you (or anyone else in this thread) have an opinion on [the SpiderMonkey bindings](https://crates.io/crates/mozjs)? It seems a bit strange that Mozilla's engine — which has Rust bindings good enough to be used in Servo — is completely ignored here.
Here is an example: --- ERROR --- In `source/test.dyon:` Error #46014, Expected: `:` 21: println(c 22,5: println(\c((0.5, 0.25))) 22,5: ^ Piston-Meta shows only error, by comparing them and picking the one with deepest match.
&gt; Can you show an example, e.g., on godbolt, showing that Rust moves have less overhead than C++ moves? Otherwise, I don't believe that claim, and the example above proofs that Rust moves have an arbitrarily higher overhead than C++ moves, which contradicts your claim. I just wanted to address this specifically: C++ and Rust moves will be practically identical in performance for almost all well-written code. C++ is only as fast as Rust in the general case here because C++ compilers are generally very good at optimizing code, and C++ developers are used to writing code that optimizes well. That means writing only trivial move-constructors / move-assignment operators, and only trivial destructors, and making sure that they can all be inlined. On the other hand, it is very easy to accidentally defeat these optimizations. If your destructor is virtual, and you have made a non-inlined virtual method call on the object prior to destroying it, the compiler cannot devirtualize and inline the destructor call (due to the existence of placement-new). LTO does not help here, unless you have a particularly clever linker that knows about C++ semantics (which some linkers do to some extent; not sure if this particular case is handled). C++ generally gives you a _lot_ of freedom, and that freedom sometimes stands in the way of the optimizer.
One thing that bit me when trying to use pest for parsing a language was I only knew what was expected, but I did not know why it expected it. I did not know how it got to the rule it did and the more complex the grammar the easier you get to that point. It is impossible to debug the grammar.
&gt; Except for: Yes, though I believe the `Box::new(x)` case is actually handled specially by the compiler (using the reserved `box` keyword internally). Note that all of these examples require separate memory addresses in C++ move semantics as well. &gt; The cost of a copy has nothing to do with where the destination lives in address space. The stack isn't some magical part of RAM that is magically faster for all operations. It is not special in terms of the abstract machine, but the stack memory is almost always in cache, very rarely shared among threads (no cache synchronization among CPU cores, etc.). It is, for all intents and purposes, free. You can construct examples where it isn't, but it's not a useful thing to be thinking about until you have specific profiler results pointing to use of stack memory as problematic. :-)
Can you make a better example? It's not really clear to me what you mean by the `some_vec = some_struct.collect();` line. `.cloned()` sometimes helps avoid double references, but it's hard to tell from your code.
Does anyone have a good example where dynamic dispatch is basically required? [I've got this project] (https://crates.io/crates/gitpub) that isn't exactly performance critical but could possibly just have a better design I'm not thinking of. If anyone has a better idea I'm open to suggestions.
I find the prospect of more ergonomic smart pointers appealing, however I have feeling that designing this type of feature (AutoClone) would actually be tricky to get right. So I'm curious what the rule would be like for the compiler to chose between a clone and a move. In the case of `Rc` and `Arc` accessing the reference count does have a cost which can be negligible for some use cases but isn't for others. I would want the compiler to insert these explicit `clone`s only when strictly necessary but I don't know how complicated to specify/teach/implement and costly in build times the right solution might be?
Short answer: use [`VecDeque`](https://doc.rust-lang.org/stable/std/collections/struct.VecDeque.html) and instead of iterating the vector use `pop_front` method. Long answer: if you check out [`iter`](https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.iter) method of `Vec`, you will see that it takes `self` by reference. It means that instead of actually pulling items out of `Vec` iterator just returns references to it's elements. Since you don't modify contents of vector in this way, there is no sense in `collect` ing vector back from iterator. Actually consuming vector is possible trough calling `into_iter` but: 1. it is not possible since you pass `SomeStruct` by reference rather than by value; 2. Even if you could, collecting vector from iterator would be quite inefficient since it would require a fresh heap allocation on every iteration when mouse was clicked. Since you actually need to take an ownership over a value in vector, you could do it with `some_vec.remove(0)`, but: 1. It panics in case vector is empty; 2. Pretty inefficient since it shifts _every_ item of vector in memory. As I wrote in the beginning, `VecDeque` better serves the purposes you need. It has proper methods for getting items from the beginning of sequence which doesn't require massive memory manipulations.
It is probably quite safe to assume that stack memory is available in L1 cache, at least for small functions. The return address of the function is stored on the stack (on all architectures - otherwise you could not have arbitrarily deep call graphs), and this is a pretty "busy" thing. On Intel Haswell CPUs, accessing memory in L1 cache memory has a latency of 4-5 clock cycles. It is definitely possible to write code that benefits from avoiding that latency (by putting all required data in registers), but I would not even consider thinking about that until I had specific profiler data showing me it was necessary. :-) Compiler writers have already spent several human lifespans implementing very good register allocation procedures to prevent us having to think about it.
[G](https://github.com)itHub: [https://github.com/Gymmasssorla/finshir](https://github.com/Gymmasssorla/finshir) Crates.io: [https://crates.io/crates/finshir](https://crates.io/crates/finshir)
In order to simplify explanation: suppose we have this code: foo_vec.push(bar_vec); Pushing to `foo_vec` can cause memory reallocation since there can be no free space in it, but if capacity of `foo_vec` is sufficient, no memory allocations will be made. `Vec` is morally a triple of pointer to allocated memory and values of current length and capacity. When you move `Vec`, only this three items are moved, the actual data remains in it's place in heap.
v0.2.1 has been just released. Lots of functionality was added since v0.1.0: TLS support, the \`--connect-periodicity\` option, also unstable std features were eliminated.
&gt; Coincidentally, I just started writing some rust... I find this sentiment strange; people don’t look to other languages because you can’t do something in c++, but more often because you can. © John Carmack https://twitter.com/ID_AA_Carmack/status/1089286703817412608
Do you think that this kind of code is more cache friendly? ``` fn some_string_operation(s: impl AsRef&lt;str&gt;) { fn the_real_operation(s: &amp;str) { // the operation } the_real_operation(s.as_ref()) } ``` Maybe that the monomorphized code would be small enough to no impact the caching.
It may be possible to change the `Copy` trait to always invoke `Clone::clone()` in the future, and just be a marker for when you want it to be possible to do that implicitly. I'm not sure it would be a good change, though. :-)
In that case, even if you don't have to resize `b`, you still have to move its characters over by `a.bytes().len()` bytes, which can be fairly slow. :-)
This syntax actually has one less dot, like `..`.
Consider \`std::vector&lt;std::unique\_ptr&lt;T&gt;&gt;\`. In case of reallocation (e.g. because push\_back() was called and size == capacity), due to C++ move semantics, old memory has to be zeroed (because that's what move constructor of std::unique\_ptr does). So what happens is semantically equivalent to following: 1. memcpy(new_buffer, old_buffer, old_size) 2. memset(old_buffer, 0, old_size) 3. free(old_buffer) In case of `Vec&lt;Box&lt;T&gt;&gt;` step #2 is skipped.
This is pretty incredible, great work! fwiw I think this primarily shows just how much user land programs are slower than kernel land ones..
That is really cool. I'd been thinking about doing it but it looked like *way* too much work. Thanks so much for sharing it! I really want minimum-latency audio processing. Taking round trips through the userland device really hurts the latency, especially on a non-realtime OS like Linux. This roundabout way of achieving a [goal](https://www.cs.vu.nl/~herbertb/papers/openk_ieee.pdf) of [Cyclone](http://www.cs.umd.edu/projects/cyclone/old_cyclone.html), one of Rust's key inspirations, is fantastic.
&gt; Why is it impossible to implement IntoIterator for arrays? AS sellibitze pointed out below, the reason is the lack of const generics in Rust at the moment. Another reason is that introducing a proper `IntoIterator` impl would be a breaking change. Nowadays, since there is no direct implementation for arrays, `.into_iter()` due to deref coercions forwards to `.into_iter()` method of slice which yields references to elements in slice. Implementing `IntoIterator` for arrays would break existing the code since it would make iterator return owned elements rather than references.
I haven't seen that particular talk, but the author may be using "polling" in a looser sense than literal eager polling. OS mechanisms to support async I/O (Linux `epoll()`, macOS `kqueue()`, Windows IOCP) may expose a "polling" API, but under the hood they are completely reactive - i.e., they put the current thread to sleep and only wake it up once some I/O happens on one of the file descriptors that the thread was "polling". Note that certain patterns can still incur some overhead here, depending on whether the exposed API offers a "reactor" or "proactor" pattern, and how well that matches the underlying abstractions. I believe Tokio/MIO uses a "reactor" pattern, which matches `epoll()`/`kqueue()`, but Windows IOCP implements a "proactor" pattern, so there can be a (small) overhead on Windows. Disclaimer: This may have changed since last I looked into this, so feel free to disregard completely. Hope that clears it up. :-)
I think your comment is fair, and I agree with most of it. The only part I disagree with is: &gt; I think that you're using the term "zero-cost abstraction" in an unusual way here. Traditionally, it just means that you couldn't model the same thing using lower-level primitives and do it better. It does not mean that there aren't specific corner cases where you can do something more efficient for specific code. I think that zero-cost abstractions means you can't do better, manually, ever. If you can, then it must be a bug with the implementation of the zero-cost abstraction, not something that cannot be done by design. This shows, for example, when talking about Rust: "no compromises: memory safety without garbage collection" and when talking about C++ "there should be no room for a language lower-level than C++". Each language formulates its goals differently, but both goals are incompatible with "zero-cost abstractions (except for corner cases)". --- Also note that in C++ move constructors are often automatically generated, where in Rust they are always automatically-generated. While often the automatically-generated code is what you want, in C++, if it isn't, you can do better - in Rust you cannot.
Ahhhhh thank you! I've heard of those things but think I confused them in my mind. I'll rewatch the talk with that in mind.
&gt; As long as it is opt-in with an explicit marker I'm usually fine with such control. I'm not a big fan of specifying things about `repr(Rust)` or anything that comes close to stable ABIs. Yes, please. One of the things I love about Rust is how it gives you the choice for whether you want things like struct layout or function call ABI to be specifed (letting you choose the exact thing for your needs) or unspecified (letting the compiler do whatever it thinks is best), with unspecified being the default. The default being unspecified means that if you have no specific requirement (which is the case for most software), the compiler is free to do whatever it wants, which results in awesome optimizations benefiting almost all software written in Rust and also leaves Rust free to evolve. But you still have the choice of specifying specific requirements with little effort when you need to rely on them. This is awesome. I'd love to see this theme be expanded in other areas of the language, such as with vtables.
Everyone is talking about `clone()`, but allocation is another important one. In many cases (but not always) Rust makes using heap-allocated data significantly more frustrating and cumbersome, which pushes programmers to avoid it. I know there have been a few times when I wanted to heap allocate something because it would have been better in that scenario, but I didn't, because doing so would require adding a whole bunch of stuff all over the place in my type definitions, constructors, etc., which was too cumbersome and made the code look uglier and harder to read, and I didn't care enough to make that sacrifice.
A c++ vector of unique_ptr will not end up using memcpy, for example, though the rust equivalent will. Rust moves are also destructive so there is no nulling out of the source object, like in C++. So there are many cases when Rust moves can have less overhead, I would actually say the majority of cases. This set of cases where the actual contents of the object don't occupy its full space is an interesting counterexample which is valid some of the time, but in some cases the extra cost of branching to see e.g. which alternative enum is stored will actually cost more than doing the full memcpy, which further narrows this set of examples. Whereas the extra costs of non destructive move and no guarantee of memcpy are relatively pervasive.
Even with a single server it takes a single systemd unit file to make sure Caddy runs all the time. Also, for anything larger than 1 app instance you should manage and terminate your tls on the lb. After you have ran a Caddy instance once in your life it's as fast as go getting a lib. Also, managing tls only makes sense in languages such as Go, Rust, C++ etc. Nodejs and Python for example are not good candidates due to their blocking and slow nature. Which makes Caddy a reusable skill across ecosystems while with your approach you need to relearn it every time. I take Caddy for example because imo it's ridiculously easy to use.
&gt; Note that clone is explicitly stating: you can make a copy of this, but it's not cheap/easy. If it were cheap/easy then you'd actually want to implement Copy which does implicitly copy things (when it's a cheap to copy as it is to move).Now if you can make the cloning cheap but need to share resources, this becomes a problems. No, this is wrong. Clone (Copy vs. non-Copy) is not about performance implications (how cheap copying something is). It is about whether the type represents data that can be duplicated via a trivial `memcpy`, or needs to do something more special (like making a new allocation or modifying a refcount). Types which result in a valid instance after being `memcpy`ed should be `Copy`. Types which do not should not. `clone()` exists *not* to alert the programmer about performance cost. It exists to alert the programmer about something unusual happening. Much like the `!` in macro invocation syntax alerts the programmer that something unusual (compared to a regular function call) is happening.
Thanks for the reminder. I all ways forget which one it is
&gt; I don't know if this is possible. AFAICT a lot of Rust code, and particularly a lot of unsafe Rust code, assumes this does not happen. Any change to the language would need to guarantee that all this code does not break. This is quite a hard constraint. Well, by requiring that custom move implementations are marked `unsafe`, the responsibility would be on the programmer (much like with other `unsafe` things, or UB in C) to carefully verify that the code is correct and does not violate any invariants (in this case it would be "does my custom move implementation produce an instance of the type which behaves identically in all aspects to one that would have been produced by `memcpy`?"). You would only write a custom move implementation if you are willing to take the risks and you can feel absolutely sure that you have verified the correctness of it, just like with other `unsafe` code.
Correct, that's exactly what i was trying to say.
As I said in another comment (reply to another comment of yours), any custom move implementation would have to be written in a way that guarantees that the resulting instance of the type would behave identically to one that would be produced by `memcpy` with regards to all invariants. This means that `memcpy` and the custom implementation would have to guarantee identical semantics for the type, effectively restricting custom implementations to only being useful for performance optimizations (say, when not all bytes of the type's in-memory representation need to be copied for it to be valid), which is still a big win. This requirement means that in theory, it could be left unspecified whether the compiler actually uses your custom implementation or `memcpy`, since they are semantically equivalent anyway. Using the custom implementation could be a preference rather than a requirement, allowing the compiler to just use `memcpy` instead if it prefers. The compiler should still prefer the custom implementation when possible (as it is assumed that it should have better performance than `memcpy` (otherwise why even write it?)). Now that I think about it, this requirement also implies that custom implementations would be just as inline-able as `memcpy` and required to not do any non-trivial things (or really anything other than assignment of copy types or `memcpy`). Perhaps doing anything other than assignment of copy types and trivial type casts (and maybe some other trivial operations?) in move implementations could be made illegal and cause a compiler error? This would assist the programmer in writing correct move implementations.
Actually, polling is exactly what allows `Future`s to be zero-cost. This is because there is a mechanism for the `Future` to notify the executor that it should be polled, meaning that it will never polled unnecessarily (only when requested).
Or, it may be fast. I don't like that devs are making this decision, not the compiler.
Suppose you write `Vec&lt;T&gt;::with_capacity(N)`, push `N` elements, do a `Vec::set_len(0)`, move it, and then do a `Vec::set_len(N)`. With the compiler implementation, this unsafe code would be correct. With a user-defined implementation that only copies till `Vec::len()`, that would be UB. AFAICT, the only way to write an implementation for Vec that is semantically equivalent to the memcpy the compiler writes, is to do exactly what it does, which defeats the point.
&gt; A c++ vector of unique_ptr will not end up using memcpy, A C++ `static_vector` of `unique_ptr` ends up using memcpy just like Rust.
Just fyi, `O(0)` doesn't mean anything, you want `O(1)`. The complexity of the smallvecs is a bit weird; since big-oh notation is usually defined for "big n" we really *should* ignore the case where `n` is smaller than the embedded capacity, in this case moving in C++ and Rust is both `O(1)`... Anyway, you are of course correct that the C++ version is (significantly) better when the number of elements is less than the embedded capacity. I wonder what would happen if `SmallVec` would leave its unused capacity as uninitialized memory, perhaps LLVM wouldn't bother copying it in that situation.
Yep. The &gt;2GB directory was with Diesel and Actix (or maybe with Rocket) on x86_64 Linux GNU. The 400MB was with a custom embedded ARM project on the same computer.
&gt; So what happens is semantically equivalent to following: 1. memcpy(new_buffer, old_buffer, old_size) That's not what happens, what happens on growth is a call to `realloc`, which is different. It extends the allocation potentially in place, and if it needs to reallocate, it will do a memmove of the uniqueptr storage (just a pointer - if no custom deleter is used), and then it will free their allocation, without zeroing it.
&gt; I know that most people who spend their time chatting about Rust online disagree with me. I think auto-clone and making trait objects easier to use are definitely interesting ideas! For auto-clone, it's less that I don't think we should have it, and more that it makes me afraid. I know I've definitely been mildly annoyed by having to call `.clone()` on Arc/Rc, and it would indeed be nice for it to "just" work. I can imagine auto-clone being useful in other contexts too, e.g., for things that are thin wrappers around Arc/Rc or the conceptual equivalent. (Perhaps a database connection pool?) My fear resides in the very argument that keeps getting thrown at you: that it makes something which _might_ be expensive implicit. We surely have a lot of that today already (large memcpys being the obvious culprit), but to me, there's something different between "yeah I know that could be expensive because it might be a large memcpy" and "oh yeah that might be expensive because it can actually be invoking arbitrary code, let me go hunt down the possible pieces of code that could be invoked here." Today, I think that's _mostly_ limited to `Deref`, and the type signature of `Deref` is a fairly strong forcing function against doing arbitrary or expensive work (because it has to return a borrow). Auto-clone, I imagine, might not have that benefit. I'm not sure whether there's a philosophical difference at play here, but I do _generally_ like the idea of making expensive things explicit, even if it's not _all_ the things. I don't know if "explicit" and "unpleasant" are necessarily the same though. For example, I'd say most uses of `clone()` for me are (obviously) explicit, but not unpleasant. They only tend to cross over into "unpleasant" when dealing with Arc/Rc. And I suppose that might be why I think auto-clone could be a good thing. But I don't know whether it's good enough to balance out its negatives. Other than what I've already said, the other obvious potential negative is the abuse of auto-clone. Perhaps especially be beginning Rust programmers who just want things to clone automatically to get passed borrow checker woes. `Deref` could also of course be abused, and I don't think I've seen any instance of that yet (perhaps beyond providing an impl of `Deref` where perhaps convention says it shouldn't be), and that might defeat my point. But as I said above, the type signature of `Deref` makes it hard to thoughtlessly abuse it. I don't think an auto-clone trait would have the same benefit. With respect to trait objects, I definitely agree they could be better. But I worry that most of the trouble I run into with them is a result of inherent limitations in the idea rather than something the language could fix. But I am by no means an expert on this, so I leave that to you. :-) Basically, the biggest roadblock I run into is object safety. There have been at least a few occasions where I explicitly wanted to use a trait object (because I could afford dynamic dispatch, but very much wanted to reduce compilation times), but it turned out to be quite difficult because it was too hard to make my traits object safe. Or at least, I wasn't smart enough to do it in a way that didn't involve a lot more API complexity. The other aspect of traits that still trips me up from time to time is the omission of marker traits. For example, I recently introduced an accidental breaking change in a library because I internally refactored something into a trait object, but forgot to add `RefUnwindSafe` and `UnwindSafe` to the trait object (and someone was relying on these properties, which implicitly cascade through my types). It's easy to fix once noticed, but it leaves me with a bit of unease: what else am I forgetting? That's all I've got for now! Apologies for the ramble, but figured I'd just throw some of my own experiences and opinions out there. :-)
That helps a bit, but it still doesn't quite say what the *purpose* of `geos` is. It tells us what it is (bindings to C library that a lot of us won't know either), but not what we might want to use it for. Maybe something like "`geos` is a library for working with 2D and 3D geometry, focused on geospatial uses". To find this out I first had to follow links to the C library and then to JTS, because the C library's description is also unclear.
&gt; While there are some cases where internal iteration might be optimized better, I find it remarkable that despite switching to external iteration (you call `next` on the iterator) from internal iteration (the iterable things have `each` that calls you back) many years ago with the introduction of the `Iterator` trait, now Rust iterators can also do internal iteration with the `try_fold` family of methods! * https://mail.mozilla.org/pipermail/rust-dev/2013-June/004364.html * https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-07-2013-07-03 * https://medium.com/@veedrac/rust-is-slow-and-i-am-the-cure-32facc0fdcb
How can I get a single key as input? Basically a "Press any key to continue..." Is there any reason why there isn't a "readkey!()" macro?
As of right now, crates.io [has no squatting policy](https://crates.io/policies). It's been discussed a few times, but no universal solution was developed.
This reminds me of https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript Except ahead of schedule and with wasm instead of asm.js
\&gt; "The thing which might be getting in the way is your attitude." &amp;#x200B; I have a big ege and also ADHD. See: [https://www.youtube.com/playlist?list=PLXcr3tdUCbQaZGyjf0Bp9E6gj2pWxLrVw](https://www.youtube.com/playlist?list=PLXcr3tdUCbQaZGyjf0Bp9E6gj2pWxLrVw) &amp;#x200B; If you hire me, you also get my ego and my ADHD (mental health related) because those things are part of me. &amp;#x200B; \&gt; "but if it does, when you leave out an impression of very annoying type of beginner/junior who probably gonna be resistant to learning anything." &amp;#x200B; I am annoying (I got it from my mother). I like attention. That being said, I can learn a lot really fast. &amp;#x200B; See: [https://twitter.com/JohnReedForPres/status/1107447298043375616](https://twitter.com/JohnReedForPres/status/1107447298043375616) &amp;#x200B; Because of my attention span, I can hyper-focus on things that I am interested in and cram really fast. I don't really consider myself junior at say Bank of America because I wrote and provided the setup instructions, tutorials, educational resources, and even the plan for a new microservice, and people maybe 15 years my senior followed what I layed out. Because of my obsessive cramming of technical information, I can become a subject matter expert. I can also write a lot of code very very fast. For example, in college, I wrote maybe 15,000 lines of Java code in a 7 day (168 hour period) in coordination with a friend who added (I dunno 7k lines of code). I did the backend and he did the frontend. &amp;#x200B; \&gt; "who probably gonna be resistant to learning anything." &amp;#x200B; Because of my ADHD, I don't listen to verbal commands well, but I do accept reasoning in written and textual formats. For example, I communicate better over text than spoken word, and I can text super fast on my phone. My texting is as fast as my computer typing, and I also take email, Tweets, and other form of text-based communication. &amp;#x200B; \&gt; "I think this highlights it in particular. Provided it showed up in somewhat generally condescending context. It appears that instead of thinking that there is a reason for it, you write it off as something stupid." &amp;#x200B; I don't mean that the fact that people want braindead simple stuff is stupid. I think that is great. I think that most people are unintelligent relative to me, and also technologically inept, and so the design has to be made with that in account. "[Don't make me think!](https://www.amazon.com/Dont-Make-Me-Think-Usability/dp/0321344758)".
In case you haven't already found it: https://crates.io/crates/juniper.
Continuing off from my last message... &amp;#x200B; \&gt; "It's to late to go deep into this one, even if I could. But .. there are a lot of competing theories and practices. " &amp;#x200B; I am aware, and I know that some theories are impractical. For example, I do not believe that category theory based programming (ex. Haskell, PureFP, etc) is practical because it's basically built on PhD level mathematics that nobody fucking knows except people with advanced mathematics degrees. I just can't write code without auto-completion, and I dislike mutable state and leaky abstractions (is class "bat" a bird, a mammal, or both?). That's what pulled me towards a more functional programming style, but it's not category theory based. &amp;#x200B; I think employee happiness is important. See: [https://twitter.com/JohnReedForPres/status/1129348226224721921](https://twitter.com/JohnReedForPres/status/1129348226224721921) &amp;#x200B; \&gt; "Business is MMA to software engineering." &amp;#x200B; Good business is great, but if I hate my job and I hate and can't work with the technology, I'm not going to be productive, and no amount of money can change that. At Amazon Web Services, I thought to myself "the only thing that more pay at my current job can't get me is less dislike of my current job." If you hate your job and the pay doubles from $150k to $300k, you don't suddenly start not hating your job. You just have more money outside of your job, but you still spend most of your time at your job, which you hate. I'm a people person. I don't really care about money as long as I have enough. And given that Bank of America paid $86 an hour on W2 and my rent was $1350 a month, it's not that hard to have enough to cover rent, food, healthcare, etc. As long as my needs are covered and I have at least several thousand dollars in my checking account, I am good financially. I live in a 501 square foot apartment and it is damn near the perfect size. It's doesn't feel overly spacious like my previous, 650 square foot unit felt. If I had a hundred billion dollars and I wasn't married, I would still go with 500 - 550 square feet. The money doesn't matter as long as it's enough. What matters to me is status. Ultimately, somebody has to provide for the rest of the team, know the tech in-and-out, and be able to plan out and create new stuff themselves (or by pulling other people to join them). I do that better than anything with money because I frankly am not a money person. &amp;#x200B; If I wanted to maximize my money, I could have done things differently than I have. Also, you can whine about how not being dogmatically logically correct isn't a good quality, but ultimately the lack of that produces a buggy, shitty software system. Not clean code. &amp;#x200B; \&gt; "And even if you end up in R n D department of some sort, realizing that your mission is to provide value to others first will get you there faster. Currently, from the way you put it, I can't feel even a trace of this." &amp;#x200B; So I don't have much empathy and I don't like money (even though I'll take it). This means that I'm not as into the business side as you are. I can do other things. I am VERY people oriented. I can design, plan, execute, and even recruit people who are very hard to recruit, like for example PhD's. &amp;#x200B; See: [http://johnreedforpresident.home.blog/2019/05/13/the-problem-of-scala-at-bank-of-america/](http://johnreedforpresident.home.blog/2019/05/13/the-problem-of-scala-at-bank-of-america/) &amp;#x200B; Ultimately, if the technology is too "powerful" relative to it's user, it's not a good fit.
My opinion is: "use the search function/web search". This topic has come up countless of times.
Security was lightly touched on here, is this very vulnerable to meltdown?
Shouldn't you consider a *high* level language then?
\&gt; "OP, I am hiring for a backend scala role, and would not want to interview you based on the behaviors displayed in your post." &amp;#x200B; These behaviors are not intentional. I do not decide to have ADHD or a mental condition. I do not decide how my parents raised me, who they are, and the effect that these things have on my personality. Ultimately when you hire another person, you get that person. If you dislike them, then you dislike the person who you hired. &amp;#x200B; I personally read your sentence "OP, I am hiring for a backend scala role, and would not want to interview you based on the behaviors displayed in your post." and I disliked your curt \[terse and intense\] tone. It's not your fault that you are curt. That being said, I do not expect you to talk differently, regardless of what I think.
\&gt; "which is kinda hard to enforce in Scala" &amp;#x200B; I use a Scala static analysis tool (ex. [https://www.wartremover.org/](https://www.wartremover.org/) , [http://www.scalastyle.org/](http://www.scalastyle.org/) ), I have the IDE to provide its own supplemental analysis, plus I set compiler flags and warnings (ex. [https://tpolecat.github.io/2017/04/25/scalac-flags.html](https://tpolecat.github.io/2017/04/25/scalac-flags.html) ) in the build. If the codebase is shit, I might have to gradually turn on more compiler warnings and fix the errors as they are thrown until the codebase is not shit. Big languages can be wieldy. The Scala codebase that was handed to me a Bank of America was a nightmare. Imagine a C++ codebase written by a distributed team of people who don't know C++, don't do code review, who don't use or heed compiler warnings, and who don't fix broken tests. &amp;#x200B; \&gt; " I love Scala but I also know how easy it is for inexperienced developers to write bad Scala code... It's not a good language to chose for an inexperienced team unless you have strict code reviews and mentoring by experienced developers." &amp;#x200B; Yeah, I have to force it by setting up the style checker, static analysis tool, compiler warnings, etc. Basically, you need someone to set things up and provide "guardrails", as I believe you do with a system written in C++. You don't need the coding style to be purely functional, yeah, there needs to be enforcement (I like having the build do the enforcement by throwing an error at compile time because people can't ignore it when it won't build). Also, I wrote a build script that does the whole shebang - static analysis, style check, testings, etc. Script must pass before you can push your code into the production system. &amp;#x200B; \&gt; "Rust is definitely better in this regard, there are less ways of doing the same thing and the simplest way is often the recommended way." &amp;#x200B; That's great. C++ and Scala produce nightmare legacy codebases, especially when you don't have that enforcement that I described. That being said, I have never seen a big legacy Rust codebase. You might start to bump into problems when you actually have one in the real world.
:-)
This is library behaviour. `ArrayVec` is not part of the language or the standard library. It could do a major release to indicate compatibility breakage and specifically document such behaviour as being UB. People who write `unsafe` code using the `ArrayVec` library (or any other library) need to be careful about its semantics anyway. I think it would be a net win to allow for this possibility.
It takes multiple people to build a useful piece of real world software. Ultimately, I would like to be friends with my coworkers. I personally would look for a personality match as part of my overall hiring. People should work well together, and if you and I wouldn't work well together, then maybe I should find someone else to work with (or for). That being said, I actually personally like the brutal honesty that you are displaying more than politeness that sort of is a layer over bad things or problems.
This is a weird statement. There’s plenty of agency behind the decision to not prioritize autoclone over other things.
\&gt; "OP, I am hiring for a backend scala role, and would not want to interview you based on the behaviors displayed in your post." &amp;#x200B; It takes multiple people to build a useful piece of real world software. Ultimately, I would like to be friends with my coworkers and work well with people. I personally would look for a personality match as part of my overall hiring. People should work well together, and if you and I wouldn't work well together, then maybe I should find someone else to work with (or for). Thank you for your honesty.
I read that as no more squatting, :( There should be an option for the community to vote to take down packages. Other day I installed this graphql package, and realized there is nothing in it.
Well I hope that I can find someone who would be interested in interviewing me. Thank you for giving me your opinion, sir.
You got the wrong type: `Rc&lt;Box&lt;Vec&lt;Hitable&gt;&gt;&gt;`, which was supposed to be `Rc&lt;Vec&lt;Box&lt;Hitable&gt;&gt;&gt;`. You can't write `Vec&lt;Trait&gt;`. Even more, there's no need for the `Rc`, not should `list` be mutable in `color`. Also, `Hitable` shouldn't take `&amp;mut self` because it doesn't change the value. diff --git i/ch5-ray-tracer/lib/raytracing/src/lib.rs w/ch5-ray-tracer/lib/raytracing/src/lib.rs index 3e238f5..790eacc 100644 --- i/ch5-ray-tracer/lib/raytracing/src/lib.rs +++ w/ch5-ray-tracer/lib/raytracing/src/lib.rs @@ -3,7 +3,7 @@ extern crate cgmath; use cgmath::Vector3; pub trait Hitable { - fn hit(&amp;mut self, r: Ray, t_min: f32, t_max: f32, rec: HitableRecord) -&gt; bool; + fn hit(&amp;self, r: Ray, t_min: f32, t_max: f32, rec: HitableRecord) -&gt; bool; } #[derive(Copy, Clone)] @@ -51,7 +51,7 @@ impl Sphere { } impl Hitable for Sphere { - fn hit(&amp;mut self, mut r: Ray, t_min: f32, t_max: f32, mut rec: HitableRecord) -&gt; bool { + fn hit(&amp;self, mut r: Ray, t_min: f32, t_max: f32, mut rec: HitableRecord) -&gt; bool { let oc: Vector3&lt;f32&gt; = r.origin() - &amp;self.center; let a: f32 = cgmath::dot(r.direction(), r.direction()); let b: f32 = cgmath::dot(oc, r.direction()); diff --git i/ch5-ray-tracer/src/main.rs w/ch5-ray-tracer/src/main.rs index fec78d5..36fd7fd 100644 --- i/ch5-ray-tracer/src/main.rs +++ w/ch5-ray-tracer/src/main.rs @@ -29,7 +29,7 @@ fn hit_sphere(center: Vector3&lt;f32&gt;, radius: f32, mut r: Ray) -&gt; f32 { } } -fn color(mut r: Ray, mut list: Rc&lt;Vec&lt;Box&lt;Hitable&gt;&gt;&gt;) -&gt; Vector3&lt;f32&gt; { +fn color(mut r: Ray, list: &amp;[Box&lt;Hitable&gt;]) -&gt; Vector3&lt;f32&gt; { let mut rec = HitableRecord { t: 0f32, p: Vector3::new(0f32,0f32,0f32), @@ -42,7 +42,7 @@ fn color(mut r: Ray, mut list: Rc&lt;Vec&lt;Box&lt;Hitable&gt;&gt;&gt;) -&gt; Vector3&lt;f32&gt; { }; let mut hit_anything: bool = false; let mut closest_so_far: f32 = std::f32::MAX; - list.iter_mut().for_each(|h| { + list.iter().for_each(|h| { let temp_temp_rec: HitableRecord = temp_rec; if h.hit(r, 0f32, closest_so_far, temp_temp_rec) { hit_anything = true; @@ -70,9 +70,9 @@ fn main() -&gt; std::io::Result&lt;()&gt; { let vertical = Vector3::new(0.0f32, 2.0f32, 0.0f32); let origin = Vector3::new(0.0f32, 0.0f32, 0.0f32); - let mut list: Rc&lt;Box&lt;Vec&lt;Hitable&gt;&gt;&gt; = Rc::new(Box::new(Vec::new())); - list.push(Sphere::new(Vector3::new(0f32,0f32,-1f32), 0.5f32)); - list.push(Sphere::new(Vector3::new(0f32,-100.5f32,-1f32), 0.5f32)); + let mut list = Vec::new(); + list.push(Box::new(Sphere::new(Vector3::new(0f32,0f32,-1f32), 0.5f32)) as Box&lt;Hitable&gt;); + list.push(Box::new(Sphere::new(Vector3::new(0f32,-100.5f32,-1f32), 0.5f32)) as Box&lt;Hitable&gt;); while j &gt;= 0.0 { let mut i: f32 = 0.0; while i &lt; nx { @@ -83,7 +83,7 @@ fn main() -&gt; std::io::Result&lt;()&gt; { let mut r = Ray::new(origin, lower_left_corner + uh + vv); let p = r.point_at_parameter(2.0); - let col = color(r, Rc::clone(&amp;list)); + let col = color(r, &amp;list); let ir: f32 = 255.99 * col.x; let ig: f32 = 255.99 * col.y; let ib: f32 = 255.99 * col.z;
I'm too lazy to mess around with static_vector but based on this codegen from std::array I'm skeptical: https://gcc.godbolt.org/z/fpju6Z. I'm also skeptical because I don't see any reason why the addresses being on the stack or heap makes any difference. It's hard for compilers (IME) to go from move/copy constructors for *non-trivial* C++ objects, to memcpy. You misunderstand the vector example. Yes, if you move a vector you don't have to move the pointed to objects. If you call something like `push_back` or `push` though, when capacity is filled it will cause allocation of new memory followed by a conceptual "move" of all the existing objects into the new memory (and finally adding the pushed element). In Rust, this will obviously be a memcpy, for any object. In C++, this won't be a memcpy for anything other than trivial types. Even a type like unique_ptr where it would in fact work. There's been tons of work done on this topic and the concept of trivial relocatability by Arthur O'Dwyer exactly because it's very clearly seen that compilers don't do this optimization reliably (even for trivial types it's actually handled by the vector implementation not the compiler). &gt; Can you show an example, e.g., on godbolt, showing that Rust moves have less overhead than C++ moves? Otherwise, I don't believe that claim, and the example above proofs that Rust moves have an arbitrarily higher overhead than C++ moves, which contradicts your claim. At this point I've already given you a couple of examples/reasons and gone into quite a bit of depth. Neither move is strictly better than the other but as I've explained on average Rust's moves will be slightly faster in more situations. This makes sense; the trade-off is that Rust's moves are way less flexible than C++. I mean in C++ the move constructor can do anything, in Rust it's very limited to something very simple and efficient so nothing about this situation is surprising.
Your list type is wrong in main at least. Your color function expects a `Rc&lt;Vec&lt;Box&lt;Hitable&gt;&gt;&gt; ` but you're trying to give it a `Rc&lt;Box&lt;Vec&lt;Hitable&gt;&gt;&gt;`.
Rus people seem to have a very weird definition of "zero".
This is a problem, which people will realize once someone posts a malicious crate with a popular name, until that no actions done
You either end up with things like this, or you make things like Javascript's `left_pad` debacle possible. Pick your poison!
Also, can I get your opinion on something? &amp;#x200B; Is it just me, or are some of these people ( see comments: [https://www.reddit.com/r/rust/comments/boj48v/why\_im\_considering\_switching\_from\_scala\_to\_rust/enizt76?utm\_source=share&amp;utm\_medium=web2x](https://www.reddit.com/r/rust/comments/boj48v/why_im_considering_switching_from_scala_to_rust/enizt76?utm_source=share&amp;utm_medium=web2x) and [https://www.reddit.com/r/rust/comments/boj48v/why\_im\_considering\_switching\_from\_scala\_to\_rust/enm95cg?utm\_source=share&amp;utm\_medium=web2x](https://www.reddit.com/r/rust/comments/boj48v/why_im_considering_switching_from_scala_to_rust/enm95cg?utm_source=share&amp;utm_medium=web2x) ) kind of a dick? What do you think?
Wow, thanks. That's more than I was expecting. After making these changes, I'm getting the result I was expecting. Quick follow-up: What do the square brackets denote in `fn color(mut r: Ray, list: &amp;[Box&lt;Hitable&gt;]) -&gt; Vector3&lt;f32&gt;`?
&gt; What do the square brackets denote A [slice](https://doc.rust-lang.org/book/ch04-03-slices.html), which is like a part of a `Vec` or an array.
You could wrap the types in some generic type - that would prevent coercion. https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=8a7382d41a7d7e80df39eb928b1a923a
\&gt; "The thing which might be getting in the way is your attitude. And to some people who been working in the industry for past few years at least, lack of experience really shows with projected imaginations of how things should be you put forth." &amp;#x200B; It's not really imagination that I physically can't type out code without auto-completion. Like the way my brain works, I remember the first letter of the method name and rely on auto-completion for everything. Without the IDE being able to auto-complete (which was the case working on Amazon's Ruby codebase), I physically cannot type out the code. Like there are some things like that which I mentally cannot do, and if you are my employer, you ought to know about these things and adjust accordingly. &amp;#x200B; Because of this, I added this to my LinkedIn: &amp;#x200B; \&gt; "I like statically typed functional programming languages (15% rate discount)." &amp;#x200B; Basically, if the code is written in a modern language where I don't have to do extra typing to make things "final" or "const", my hourly rate for you drops 15%, but if you want me to program in say Amazon's Ruby environment where the auto-complete and go-to-declaration doesn't work, I won't work for any amount of money. If I did accept a job, I would basically just be sapping your money because I wouldn't actually be typing out any code, I would just be copy-pasting lines and hitting "\*backspace\*".
Also: - let col = color(r, Rc::clone(&amp;list)); - let ir: f32 = 255.99 * col.x; - let ig: f32 = 255.99 * col.y; - let ib: f32 = 255.99 * col.z; + let col = color(r, &amp;list); + let ir = (255f32 * col.x) as u8; + let ig = (255f32 * col.y) as u8; + let ib = (255f32 * col.z) as u8;
I can't give you a benchmark but I've seen this sort of thing twice (in C++), in real life code. In one case the person in question went rather crazy with complex templates. They ended up needing to factor back out some of the code that didn't depend on template parameters so that it didn't keep getting re-instantiated. In another case, someone did explicit code generation to monorphize completely a system that depended on complex runtime config. It ended up being a net loss in many cases. I do agree it's fairly rare in practice. However, it is rare as long as you don't abuse generics, and at least make some effort to factor out common, type independent parts of code. If you do these things then it will happen pretty quick. And yes, icache misses would be a tell tale sign; if you modify the code to increase monomorphization and performance decreases, compare icache misses in both runs and if they have increased dramatically then that's precisely the issue.
As a beginner, it's a bit difficult to find the good library to do some stuff (e.g in order to find a good way to parse some json content, I had to do some archaeological search before finding serde)
I was talking about the issue, not crates. But for crates, use crates.io's own search function.
The main use cases would be to embedd a scripting langage in a software in order to give users the possibility to extend and customize the functionalities without having to understand and fork the software.
@kod As a courtesy notice, I mentioned you in this Tweet: [https://twitter.com/JohnReedForPres/status/1129372578722799616](https://twitter.com/JohnReedForPres/status/1129372578722799616)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/learnrust] [How can I achieve custom derives with generic parameters?](https://www.reddit.com/r/learnrust/comments/bpr1pl/how_can_i_achieve_custom_derives_with_generic/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
The following Tweet is in response to what you (@wherediditrun and @kod) have to say: \- [https://twitter.com/JohnReedForPres/status/1129372578722799616](https://twitter.com/JohnReedForPres/status/1129372578722799616)
Javascript's debacle need not happen. Namespaced crates allow crate names to be reused, and versioned crates that cannot be deleted prevent \`left\_pad\` situations. Sounds like a good plan to me.
Hi, the author of the library here. I've tried to explain the differences with native integration, benefits/tradeoffs of this approach, and why it was published as a separate adaptor library that isn't just used by the upstream under the hood (yet!), but I'm around and happy to answer any questions!
Yes, but now you're replacing an abstraction under ones that are being talked about. You can make zero-cost abstractions in Python is my point. The base performance of the abstration is irrelevant for it to be zero cost.
Keys? Like you mean key press events from the OS? That's very OS specific behavior. That's the job of a package or third party bindings. On Linux this would require talking with Xorg or Wayland or taking the events from the kernel directly. All of which is very platform specific.
&gt; There should be an option for the community to vote to take down packages. Other day I installed this graphql package, and realized there is nothing in it. The whole point of a package manager is to make packages available. Allowing users to vote to remove packages will eventually lead to somebody's code breaking because they relied on a package the community decided should be removed. If we want to stop name squatting "for real", then we need to change the process. Taking down packages after the fact doesn't fundamentally resolve the problem. We have to change the publish process so you must apply for the package names you want. Those applications need to be looked at by a real person and you need to demonstrate you actually have something useful to point that name at. In the short-medium term, it seems extremely unlikely the crates.io team (which is quite small to begin with) would take on that kind of workload and responsibility. I think a better solution in the short term is for the community to build a site like crates.io but which whitelist packages for inclusion in that site. The site wouldn't even have to be a package repository, it's simply an alternate frontend for crates.io that hides packages that haven't been whitelisted.
So when do we get to start complaining about namesquating for namespaces? Namespaces don't fix squatting by themselves. I think they're useful to have for other reasons, but they don't prevent people from reserving names they "shouldn't".
When you want a heterogeneously typed collection, for example.
Not to be that guy, but should it not be going in `~/.cache/cargo/`?
Is there a way in the std lib to do a `split_at_mut` in-place? That is, instead of fn split_at_mut&lt;T, 'a&gt;(slice: &amp;'a mut [T], idx: usize) -&gt; (&amp;'a mut [T], &amp;'a mut [T]); I need fn split_at_mut_inplace&lt;T, 'a&gt;(slice: &amp;mut &amp;'a mut [T], idx: usize) -&gt; &amp;'a mut [T]; Implementing the latter via the former does not work because I can not create a `'a` borrow from the outer `&amp;mut`.
Could we also make a way to let the package repository rename the packages?
This is amazing!
A landing page has been published!!! https://dytp.org/
Question. Would this sort of thing suite a microkernel well? I imagine putting this in as a service to an MK would have interesting implications...
wat
So basically Linux meets [Nebulet](https://github.com/nebulet/nebulet)?
&gt; Tbh it would be more ideal if the compiler could learn to deduplicate the common function bodies caused by this idiom. This optimization is known as ["outlining"](https://en.wikibooks.org/wiki/ROSE_Compiler_Framework/outliner), ie the inverse of inlining.
I mostly agree, but I there is still room for a rule that accounts for exceptional situations like this. Consider the case of a package that is malware. It must be removed as quickly as it is discovered. There cannot be a 100% no removals rule. Packages that are blatant squatting and provide no useful functionality could potentially also be subject to removal without breaking existing code.
I don't think I have ever used crates.io's search function. My personal experience has been that Google searching "rust &lt;my need&gt;" has gotten me the result I wanted 100% of the time.
That's not possible, because removing crates might break code. However, crates could be **excluded from the search results**, both on the website, and in the `cargo search` command. Once a crate is excluded, nobody will accidentally use it. Excluded crates could then be transferred to somebody else who wants to use the crate name. The new owner could then publish his own code in a new (major) version.
No, it would just put it right back in userspace and negate any advantages you got by putting it into ring0 in the first place.
I take it you need `package_name` and `sp` in the `for_each` at the end? In that case you can try to thread them through the stream: return them as a tuple together with `url`, then from the `concat2` callback.
How do you distinguish between autoclone and move?
damn, wish I knew this before we started replacing some of our C++ components with rust; this would have nipped that in the bud pretty fast. what a joke
You can parse out the arguments of a custom proc macro attribute if that is a reasonable alternative for you instead of a custom derive. I've done this in the past to pull out arguments of the form #[xml_element("custom_name_here")] struct MyStruct { . . . } And then parsed into the attribute arguments using the following code: extern crate proc_macro; extern crate quote; extern crate syn; use proc_macro::TokenStream; use quote::quote; use quote::TokenStreamExt; // . . . #[proc_macro_attribute] pub fn xml_element(attr: TokenStream, input: TokenStream) -&gt; TokenStream { let item: syn::Item = syn::parse(input).expect("failed to parse input"); //clone our item so we can check and alter its attributes let mut original_clone = item.clone(); // assert that we need to have a name argument for the new XMLElement let args = attr.to_string(); assert!(args.starts_with("\""), "`#[xml_element]` requires an argument of the form `#[xml_element(\"xml_element_name_here\")]`"); // trim down to just the value let element_name = args.trim_matches(&amp;['=', ' ', '"'][..]); // match item and only continue if it is a struct type match item { syn::Item::Struct(ref struct_item) =&gt; { return gen_impl_code(&amp;element_name, &amp;mut original_clone, struct_item); }, _ =&gt; { assert!(false, "#[xml_element] may only be applied to structs"); }, } unreachable!(); }
In my last project I used Rust for core logic and C++/Qt for GUI. The serialization part was on only Rust side (thanks serde), sometimes when I need save some objects in C++, for example write them to QSettings, I (with help of rust_swig crate) just generated new method in C++ wrapper class, like `method to_string(&amp;self) -&gt; String` and that's all. But I don't see reason to use Rust, if your whole project on C++. Several years ago I need serialization in C++ only project, then I just took python+libclang and generate serialization/deserialization code directly from C++ header, just like serde from Rust do. I mark my C++ structs with macroses like DESERIALIAZE, and my python parser find marked by these classes/structures and do magic.
A "Ring 0 Microkernel" can be constructed on top of this project and benefit from performance improvement. Doing it in the reverse way, by putting this project in a Ring 3 service, doesn't make sense most of the time. Depends on your actual microkernel design though.
None of the series of CPU bugs should affect security here for now, since the WASM virtual address range is restricted to 6GB, and it is impossible to construct an accurate timer (at least before WASM gets threading support).
Thinking about my Version 2 [crates.io](https://crates.io) proposal : If every user's crate begin with their (unique) [crates.io](https://crates.io) user name, there are no namespace squatting in any of the categories, because any combination of a crate name and a unique username are also unique. In the popular category, the popular crates will be those who are a useable crates, and an unusable "Hello GraphQL" crate won't become popular
My point is that you've resolved the squating of `graphql` by prefixing it with the crates.io username. Great! Now, what happens when somebody other than the Facebook GraphQL team signs up on crates.io with the `GraphQL` username? At that point, this discussion cycles back to step 1 and we have people complaining about squating of crates.io usernames. Introducing another layer of naming just moves the squatting problem to that layer.
If removing a crate like this one "breaks code", that code was already broken.
&gt; It is frustrating that it's for i in myarena.iter() and not just for i in myarena So you *could* make your `Spaces` struct `Iterator`, but then you'll need to include internal state in `Spaces` to keep track of the iteration. It also means you have to decide how to end iteration. If someone iterates through all of the items in a given `Spaces` struct, what happens next? Do they start over at the beginning, or do they end (and if they end, then that means you need a method to reset the iteration, or else the user can only iterate over your `Spaces` struct a single time). For that reason, to me it makes the most sense to include an `iter()` method, and just have it return `self.arena.iter().flatten()` (or whatever variation you want). This would make it most similar to `Vec`, which (as far as I know) you must also call `iter()` on.
Not necessarily. If someone adds a dependency to `Cargo.toml`, but never uses it and forgets to remove it, the crate breaks when the dependency is removed.
&gt; but no universal solution was developed. Plenty have been developed, crates.io just doesnt want to have any of them, often because "it isnt literally magic and some amount of work may be involved".
Again, if you added a dependency on this crate to `Cargo.toml` and forgot to remove it, your crate is already broken. (You certainly never used it.)
Also, "hittable" should have two "t"s. I spent longer than I should have trying to figure out what a "hi table" was. :-)
 resource "geographic_terrain" "mountain" { height = "10000m" snowy = true trees = true }
Rustc emits no error and no warning when a dependency isn't used. When some code compiled and worked correctly at one point in time, but doesn't anymore, that's what we call "broken".
I think the simplest solution is to support package scoping (like npm's `@author/package`). Sharing a global package namespace is messy.
Yeah, I was thinking about that myself, but I think I've seen it written the same way in another implementation based on the same book. I thought it was an Americanism of sorts.
Your right, otherwise Arrays of Copy types wouldn't be Copy themselves (and IMHO shouldn't, as passing it around in a recursive call has unexpected expenses that are not there with, say, a vec or a slice).
It's a shockingly influential talk. I think it was the inspiration for [nebulet](https://github.com/nebulet/nebulet) which was originally called Metal.
Ha ha perfect
I love WPF because it is so easy to make great user interfaces. Keep doing this!
Yes, with the ability to apply for a top-level name similar to what Docker does
I'm not sure I understand what "in-place" is supposed to mean in this context. What would this function get you that the normal `split_at_mut` doesn't?
How does that solve the problem of squatting? Now instead of package name squatting we have author name squatting.
If you're trying to match a specific binary format, it's better to not depend on any existing Serde serializer, just write your own. If it is identical to Bincode in every other way, fork it.
Since we require a GitHub account to upload to crates.io, we could use your GitHub usernames and organization, which are already unique.
Yeah, given how rare it seems to me, having the default assumption that dynamic dispatch is slower seems reasonable. I've never optimized for icache before, only data caches, so this is something I should learn more about.
&gt;I don't think there is a comparable language to Rust for use in web backends There are multiple JVM frameworks that are comparable to Rust frameworks in terms of performance, and Scala is certainly comparable in terms of ML family language features.
Imagine a case where we have a voting system. I create a bot that generates crates.io accounts, and I storm vote serde into being taken off of crates.io. No thanks. Squatting is a bummer but the solution can never be to take crates down. Squatting like this is actually totally harmless. No one is hurt by that crate existing. It's malicious squatting we should prioritize - and a simple solution would be to just ensure that crate names are always a minimum distance from each other.
In general for most user names you wouldn't pay much attention to what the name is (except that you might learn to trust certain users after a while), nobody complains about username squatting on reddit or github (as far as I'm aware, feel free to show that I'm wrong). There is still the possibility to have focussed workgroup names (like rust-osdev on github) that can be used to group functionally related crates.
Could we at least have a squatting label? And filter squatted names out from normal results?
GitHub names can change though, as someone who has changed their GitHub name (and would have been very upset if it couldn't be changed)
The problem with all of those proposals wasn't how to __handle__ squatting - it was how to __determine__ squatting consistently.
I knew I was doing something wrong! I can now see that the standard Vec isn't the right data structure for what I want to do. I'll use VecDeque instead. Thanks!
So, should I download @foobar/graphGL or @foobaz/graphGL? This would make things even worse with forks.
Consistently or automatically?
Consistently. OP's example is an obvious case, but what about situations where someone started writing a library and hasn't finished it? Where exactly do you draw the line? __Can__ you even draw the line?
When you change your name, does GitHub keep a link from your old name to your new one? If so, forever, or can your old name be reused? Whatever the answers, we could figure out a solution, even if it requires manual intervention for edge cases. We don't have to use GitHub (I am always hesitant to tightly couple with another service). Account registration is easier to limit than package creation, e.g. we can require a unique email and use kaptcha, so username squatting will be less of a problem than package squatting.
Having a `&amp;'b mut &amp;'a mut T` doesn't give you an `&amp;'a mut T` if `'a` outlives `'b`. This means that if you have a `&amp;'a mut [T]` field in your struct you can't split it and save part of the split back in the struct, from a `&amp;'b mut self` method, even though such a thing would not introduce any memory unsafety in theory. The `split_at_mut` function ends up taking and returning `&amp;'b mut [T]` which can't be saved back to the field. I find it difficult to believe the matter hasn't been raised to the appropriate WG before; no clue how to find the discussion though.
&gt; If we want to stop name squatting "for real", then we need to change the process. Taking down packages after the fact doesn't fundamentally resolve the problem. We have to change the publish process so you must apply for the package names you want. Those applications need to be looked at by a real person and you need to demonstrate you actually have something useful to point that name at. I have to chime in here. That would disincentivize me sharing my code and breaking it up into smaller crates because, every time I want to do so, I'd run into "Do I really want to 'cross the rubicon' on my estimation of whether this is 'good enough'? F\*\*\* it. I'll just use GitHub URLs in my `Cargo.toml`s until I'm forced to stop avoiding crates.io." ...or, actually, to be honest, it'd just exacerbate that effect. I already procrastinate putting my packages up on package repositories. (To the point where I've yet to do it with Rust... ironically, I'm too paranoid about my dependency stability to trust any crate or crate version which *isn't* on crates.io.) Your proposal actually reminds me of the early days of SourceForge. I think I only ever put up one project while it was "submissions must first be approved by moderators" while I've put a couple dozen up on GitHub and the only reason I haven't put up more is that I haven't yet written a tool I have planned for easily rewriting Git histories before publishing to retro-actively separate a project into several dependent projects.
That signature is pretty horrifying and very far from the norm. I wouldn't use it as your metric for Rust knowledge. `unsafe` isn't well-documented in The Book, read [The Nomicon](https://doc.rust-lang.org/nomicon/) if you want to learn more about it but keep in mind it's the whole point of Rust that most programmers don't need to interact with unsafe code. The `Pin` API is _very_ new. Usually it takes a bit for documentation to catch up to features; keep in mind that `Pin`'s raison d'être (async/await) was merged into nightly only a few days ago.
I've head the C++ &lt;&gt; C &lt;&gt; C++ layering called the hour-glass pattern. It's useful when distributing dynamic libraries in C++: 1. The C layer is your stable ABI. 2. The external C++ layer is just header-only conversion to idiomatic C++ code, re-introducing RAII, type-safety, etc... And it's also useful to generate bindings in other languages :)
It doesn't do much, but I just published my first pair of crates. No lifetimes, `unsafe`, `Pin`, unstable features. So it depends on what you are doing.
You've hit a tricky but important limitation of `&amp;mut` references. It's not possible to pull a long-lived `&amp;mut` out from inside a shorter-lived one. (Even though that's totally allowed with regular shared references.) To see what that means for us here, let's look at the function I think you're trying to write: fn split_at_mut_in_place&lt;'a, T&gt;(source: &amp;mut &amp;'a mut [T], idx: usize) -&gt; &amp;'a mut [T] { let (left, right) = source.split_at_mut(idx); *source = left; right } That is, we split the `&amp;mut [T]` we're given, reassign the left side of the split to the source, and return the right side. The compiler's not going to like this, because of the limitation I mentioned at the top. But it feels like it should be legal right? What gives? The important thing to notice here is that line `*source = left;`. What would happen if we deleted that line? The function would still return the right side of the split, but it wouldn't modify the source. Which means that calling the function a second time would give...the _same_ right side. Oops! The right side is a `&amp;mut [T]`, and if we ever get our hands on two `&amp;mut` references to the same data we've invoked (drumroll please) _**Undefined Behavior**_. The reason we feel like this function should be safe, is that we know we're modifying the source in such a way that it can never give out the same mutable references again. But the compiler doesn't know that. It's not going to look line by line and try figure out all the logic of what we did. All it knows is that the sort of thing we're doing with reference lifetimes _could_ break the rules, and stops us right there.
You are trying to bite off too much of the apple at once. What you are looking at is a highly complex bit of machinery to do a very specific thing with very specific constraints. It's code that calls code that has to match a specific 'hole' in the calling code, which then returns a specific chunk of code which will be called. That's going to be complex. In c++ this would be abstract classes with templates and function pointers (shudder). &amp;#x200B; Most library code is not like this. Most library code has a few constraints, it might use PathBuf instead of a string for a path, a few other ease of life issues, etc. But it's not like that thing above. Sure, you will find it, but not constantly. Just keep chugging away at the language and it will come, I promise. Dip your toe into the rustonomicon. Read API design outline documents for rust, etc. You will be fine.
To be clear, I'm not really advocating for that. I'm just pointing out what would be required to "solve" namesquatting. My prefered solution would be what I mentioned at the end of my comment: essentially an index of crates on top of crates.io.
When two people upload a graphGL package, you need to search to determine which one you want. There is no way around that. But in many cases, you already know the author or group of your library. We tend to use many packages from same organization. I'd argue you shouldn't add a package without knowing who it comes from, and explicit is better. Forks wouldn't be published under the same name, because the author becomes part of the name. With npm, the scoped package's name is "@awesomedev/awesomeproject", you can't refer to it as "awesomeproject". Using "@" and "/" looks weird in crate names, so that's open to bikeshedding.
Are you worried about people who make a mistake misunderstanding clear rules or are you worried about bad faith actors intentionally trying to subvert clear rules? Because you can make sensible decisions for the former, but for the latter, you have to be mean. And it's not like the crates team has an issue yanking a crate if someone can show that it's *intentionally* trying to break things, so I don't understand why someone intentionally trying to break sensible crate squatting rules is such a hard problem.
I think the problem here is that the "save part of the split back in the struct" thing is only safe if you save it into the original `&amp;'a mut [T]` field. If you save it into a _different_ field that happens to have the same type, you've broken the rules.
Make the actual package id &lt;human-friendly-name&gt;-&lt;UUID&gt;. Create a separate curated area where things have just &lt;human-friendly-name&gt;s. No more squatting. No pre-approval process. No ties to usernames.
[FYI](https://docs.rs/futures-preview/0.3.0-alpha.16/futures/future/trait.TryFutureExt.html#method.and_then) If you don't know or understand something, it doesn't mean it is wrong.
I'm worried about different people having different opinions on what constitutes squatting.
On the topic of downcasting... ... I still remember, with horror, breaking code by introducing a decorator around a trait. For me, this points toward the root of the issue clearly: downcasting in many languages, such as C++ or Java, is incompletely implemented. I only see 3 potential solutions: 1. No downcasting. 2. Proper parametric downcasting: `AnyOf&lt;BaseTrait, OtherTrait, String&gt;` at least warns the caller that types implementing `OtherTrait` and `String` are treated in a special way compared to the rest of types "only" implementing `BaseTrait`. 3. Full wizard downcasting: type-querying and downcasting queries can be intercepted by the object itself, which allows a decorator to masquerade as whatever it wraps, ... I am afraid that (3) is particularly challenging to implement efficiently in a compiled language, especially "on the way back": starting from `Decorator: Trait`, cast to `OtherTrait` (not implemented by `Decorator`), cast back to `Trait` =&gt; are you using `Decorator`'s v-table?
I personally have no idea who's the creator of the libs I use. Never really cared about that to be honest.
In some organizations we need to investigate and justify every dependency.
&gt; But if we want `dyn MyTrait` to still implement `MyTrait` And what if we did NOT want that? Or more specifically, what if `dyn MyTrait` only implemented `MyTrait` if `MyTrait` was object-safe? It would move object-safety down one step, to where it really becomes necessary. --- Another alternative... ... What if the monorphized `operates_using_trait` was passed a v-table without an object's instance in the case where such a v-table is necessary? Then it would have the v-table to dispatch `static_method`.
Inability to do something for hard cases is a bad reason not to do it for easy cases, though. Example of easy criteria: - Crate has "well known name" if there's a wikipedia page about the name. (Or some dashing/capitalization variation of the name.) - Crate has no useful code relating to the subject of the wikipedia page. - Situation persists for 6 months after contacting the crate owner.
This works: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=dc67c7079c7c6effe468ea8272cd1655.
But if you lock this down as the only rule, that means other cases automatically become invalid.
&gt; More flexibility for dynamically sized objects and arrays by value on the stack via alloca I'd really like to be able to return dynamically sized objects without heap allocation, however I'm not convinced about the use of `alloca` as it's an easy way to blow up the stack or accidentally introduce performance issues. Instead, I think it would be beneficial to employ something akin to the Safe Stack approach. Safe Stack is a compilation mode of LLVM which splits the stack in two: - a call stack, only compiler-controlled values: address to return to, spilled registered, etc... - a user stack, containing the actual variables, etc... Not only does Safe Stack prevents ROP attacks, it does so at negligible performance cost (&lt;1%). Now, imagine applying a similar principle to Rust's run-time stacks: - A traditional stack, for statically sized objects. - A dynamic stack, for dynamically sized objects. It just works well: 1. Zero-cost abstraction: don't use DST, don't pay for the second stack. 2. No risk of blowing the stack: the dynamic stack can simply grow on demand (unlike the traditional one). 3. No accidental performance issue as long as the dynamic stack never shrinks; the cost is predictable, and the part of the dynamic stack that is often used is in the cache. I think it's a viable solution for allowing returning DST in Rust.
I understand your point but I fundamentally disagree. If package names are important enough that we need to address squatting, then surely namespace/username/workgroup names are equally (or arguably more) important. If somebody has taken the `graph_ql` crate name and not done anything with it, then why isn't it also a problem that somebody could take the `graph_ql` namespace and not publish anything there? To be clear, I think squatting is bad. I think namespaces are useful. But IMO, namespaces don't do anything to help with squatting.
I think your misunderstood withoutboats and that he was arguing: - Move constructors are the problem; not being able to move without arbitrary code being executed has too many issues. - Copy constructors, however, are not the problem.
Thanks alot. I was so focus on Any, since the Println! prints the world any, that I didn't think to use Box&lt;Any&gt;. Created a new function fn dc&lt;'a&gt;( &amp;self, a: &amp;'a Box&lt;dyn Any&gt; ) -&gt; Option&lt;&amp;'a T&gt; { a.downcast\_ref::&lt; T &gt;() } Needed to add lifetimes but works. I get back my data when I unwrap the results. Thanks to PhantomData this wouldn't work :)
&gt; That can be generalized to an overall philosophy Rust has adopted that heap allocations are expensive and should be discouraged and stack allocations are cheap to the point of being essentially free, neither of which is universally true. As someone who works in near real-time system in C++, I have been bitten by accidental heap allocations in the critical path often enough to have a deep respect for their cost. This is not so much an issue of expensive vs cheap, it's an issue of consistency: - Stack allocations have a consistent cost; if the performance is good enough, it will continue being good enough. - Heap allocations (and deallocations!) have a completely inconsistent cost. Allocation performance is often very good (~20 *cycles* with jemalloc) but once in a while are just plain terrible (measured in micro-seconds or milli-seconds). In essence, the issue is not latency, it's tail latency. In the absence of an allocator with consistent performance in both allocation and de-allocation in multi-threaded applications; heap allocations need be avoided in a number of situations, even before we factor in the issue of pointer-chasing and cache footprint. The fact that Rust has no copy constructor is a huge plus for me.
Copy constructors or copy-assignment constructors?
While I do think a good case could be made for `Rc`, as the cache-line is cached on first access, I would not find it fun to see an `Arc` being accidentally cloned in a hot loop executed concurrently from multiple threads. That's the kind of contention issue that is REALLY hard to pin down :/
Especially since one's cheap is someone else expensive's. I've heard arguments that `Rc` and `Arc` should be `AutoClone` for example, and shudder at the prospect of pinning down a hot loop performance issue caused by an `Arc` being accidentally cloned there leading to high-contention between cores as they play ping-pong with the cache line. I've had such contention issues before. Not fun. Not fun at all.
Rust generics are a huge pile of terrible to look at nonsense. Just write a non-generic or maybe slightly generic library about whatever you want and you'll be fine.
`Arc` is a terrible example; cache contention performance issues are really tedious to diagnose. And that is actually my chief worry about `AutoClone`: everyone has their own idea of what is cheap and what is expensive :(
That's a great suggestion I should have included. I ignored it in the work I'm doing because I'm targeting mobile platforms and the SpiderMonkey runtime is larger than I want. Obviously that doesn't apply to everyone though!
Note that you don't need a `DCast` struct, you can just make that function generic. In other words, you're not using `self` there.
And yet, whenever (near) real-time is necessary, or at least a strong control over tail latencies, memory allocations are a nightmare. The average memory allocation is fast, so for throughput oriented usecases it's not an issue, however the occasional spike in allocation (and deallocation, often worse) is a performance foot-gun and leads to horrible tail latencies. Having benchmarked a few memory allocators, I've routinely seen `free` calls costing upwards of 10s/100s of microseconds and sometimes spiking in the millisecond range. In average it's fast, but when it decides to be slow...
*Mouth watering* I'm looking forward to progress on this!
I would avoid a nesting function, and simply use a free function or other method instead. Specifically, I'm worried that `the_real_operations` are instantiated once per instance of `some_string_operations` and the optimizer may accidentally inline them at the call site (single site) or otherwise fail to merge the implementations. I would think a non-nested function could be more reliable in that area... but maybe my fears are unjustified.
Go ahead and implement it then.
how would I go about making a generic function that I can store for later use?
Ah, I don't know. How are you storing `DCast` (since it's generic)?
Regarding bloat, I seem to remember issues with a command-line parsing library (Clap maybe?) which generated a ton of code because each "parser" was duplicated for each argument, or something like that. Regarding performance without bloat; virtual calls only affect performance when they prevent inlining, and that's generally a small subset of the application which is hot enough to matter.
This is a great explanation for why you can't implement `split_at_mut_in_place` in terms of `split_at_mut` (without unsafe code). Implementing `split_at_mut` in terms of the in-place version is trivial, though. I guess there's a decent argument to be made that the in-place version is therefore more fundamental. OTOH, you may also want an in-place version that returns the left side instead of the right side. And there's no primitive (that I can think of) that allows you to implement both in-place versions with only safe code. So it's probably easiest to just implement the in-place versions in terms of `split_at_mut` and a couple `transmute`s.
It's a known issue that large types are expensive to move; nothing novel here. I am very disappointed in LLVM for not optimizing the whole thing out. In theory, *precisely* because moves are just `memcpy` and `memcpy` are lowered down to an intrinsic, the compiler should be able to completely optimize the loop you just wrote by realizing that `x = move_and_back(x);` is a NO-OP.
Both; whenever I wrote "constructor" you can substitute "assignment operator" with the same result.
Oh man, that looks awesome! Wish I'd seen it when I was figuring all this stuff out :) My approach is mildly different because of my aim to mush multiple JS engines through one API but this is full of hints for me in implementing. So thank you very much!
No. Rules can expand and evolve over time. We are not required to never do anything else once we have decided a rule now.
Thats why i have it as a generic struct. I declare it by using PhantamData so i'll compile even though I'm not storing any data of that type. Since the function is tied to that Struct, It can use T from the struct for downcasting. So I just store the struct that holds that T and the Function that uses it. Now if there is a way to create and store a generic function that holds a Type Reference to T, that would be better.
`Box::new` does use `box` internally but that doesn't work consistently. :( At least part of the problem is that the compiler doesn't like reordering the allocation and constructing the value.
Java/Maven repositories have solved this since forever: &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; Gradle syntax: compile group: 'org.springframework', name: 'spring-webmvc', version: '5.1.7.RELEASE'
I believe Ada also uses an additional stack for the same purpose! It lets them eliminate a lot of allocations that would otherwise have to be freed, which in Ada is unsafe.
If you look at the [source of `std`] (https://github.com/rust-lang/rust/blob/b982867a7349f84c17317599b59aeb5a7d8a83be/src/libstd/lib.rs#L354), it just re-exports the code from `core`, so they are, in fact, exactly the same. The reason for both is that `std` is everything the language provides, but `core` is the subset of that which doesn't require features from the operating system.
&gt; C++ and Rust moves will be practically identical in performance for almost all well-written code. Actually, there are such performance problems in library code that some patches are needed for the move semantics of C++. The issue is illustrated by `std::vector&lt;T&gt;::erase(iterator)`. Remove one element, you need to shift back all remaining N elements. One by one. With each move involving arbitrary code. What happens if a move throws an exception? You have a *hole* in the middle of your vector! And there the tragedy starts. There are two strategies to avoid leaving a hole: 1. Bubble up target element with its immediate neighbour until it's last, reduce length by 1, destroy target. There was never a hole, we're good, if SLOW. 2. Pre-poop your pants: set the length to `iterator - begin`, destroy target, move each element in turn, set the length back if everything went well. The hole is never visible, we're good, but don't uphold the Basic Exception Safety: in case of exception, we leak. That's not exactly great, so things were patched. First, the move constructor that is generated is `noexcept` by default, if possible. Libraries can now have a noexcept(true) and noexcept(false) paths, with the latter being more optimized. Oh, and getting `noexcept` wrong leads to program termination, be careful in life-or-death software. This was not quite sufficient performance-wise. It helped with avoiding the exception issue, but not the bulk-move issue. So, the second path is to introduce a `is_trivially_relocatable` trait, which says: you can just `memcpy` and forget about the source. And now libraries are empowered to implement every function THRICE: - Once for trivially relocatable types. - Once for non-trivially relocatable types with `noexcept(true)` move constructors. - Once for non-trivially relocatable types with `noexcept(false)` move constructors. Progress, in a nutshell. *Disclaimer: yes, I am bitter about the situation. Implementing containers is a huge pain in C++.*
"Often" is a ridiculous claim here. There are very few cases where this issue actually applies.
&gt; A c++ vector of unique_ptr will not end up using memcpy, for example, though the rust equivalent will. There's hope with trivially relocatable: https://quuxplusone.github.io/blog/2018/07/18/announcing-trivially-relocatable/
Don't worry, C++ has enough performance foot-guns that you'll still be thankful. Oh, and there's a Clippy lint to warn about moving large objects; if you don't use Clippy already, consider it.
I would say generics aren't so bad until you try doing really complex trait bounds, like the above method. I've only a few times had to write really challenging to read generics.
It's polling... but not busy-waiting. Essentially, a `Future` works in two-parts, and the second part is a `Waker` API. When a future cannot advance its work, it registers the condition to wait for in a `Waker` API; for example "waiting for more bytes on the TCP socket". Then, *only* when the condition occurs will the callback registered be notified, and that's normally when the callback calls `poll` again to move forward.
They're useful, and I use them from time to time, but they're not really a beginners feature to implement things with them. Write some programs using them first, and you'll build the skills to implement some generics of your own.
I'm pretty sure all that does is implement Middleware for closures, so you can stick a closure in an argument position that expects a Middleware. When you're writing something like that, you want to create as few constraints on how people might use it as you can get away with. So, if two lifetimes don't _have_ to be the same, you make them different. But, there are some constraints you need, all the type params here just express the constraint space. Probably the person who wrote this did a bunch of "compiler driven development", which is common in Rust. You write code, compile it, and address the compile errors as loosely as possible. Rinse and repeat. So, it's not like you have to be able to start at the 'i' in `impl` and type this all out and get it right the first time to be a Rust developer. It's an iterative process, and understanding that process is as much a part of coding as understanding the syntax.
I would just read about proper error types, semantic versioning and API stability, when to pass which type of argument (e.g. &amp;str vs String vs AsRef) and that's all.
I'm working hard on it. :) But it'll take a few more weeks.
Figured it out. First need a Function Signature type F&lt;T&gt; = fn( a: &amp;Box&lt;Any&gt; ) -&gt; Option&lt;&amp;T&gt;; Next I need my Generic Casting Function fn d_cast&lt;T:'static&gt;( a: &amp;Box&lt;Any&gt; ) -&gt; Option&lt;&amp;T&gt;{ a.downcast_ref::&lt;T&gt;() } Now I can store it for later use let pos_cast : F&lt;Pos&gt; = d_cast; let results = pos_cast( &amp;t.data );
You'd pretty much always use `std` for most situations. If you're making a library, you might use the `core` version if you're planning on making your library `no_std`-compatible.
It is also possible to use a slice of unboxed trait objects here. I went through the same tutorial and remember struggling with the syntax to create one so I'll post what I used: fn color(r: Ray, world: &amp;[&amp;Hitable]) -&gt; Rgb&lt;u8&gt; { ... let s1 = sphere(vec3(0.0, 0.0, -1.0), 0.5); let s2 = sphere(vec3(0.0, -100.5, -1.0), 100.0); let world: Vec&lt;&amp;Hitable&gt; = vec![&amp;s1, &amp;s2]; ... color(r, &amp;*world) I do not know how the performance compares to the boxed version, and eventually ended up using boxes for the bounding volume hierarchy that replaces this in the next book.
You're totally right, I edited my comment above.
That could work, but it's unlikely to get approved for two reasons: 1. It's not fundamentally different from `&lt;username&gt;/&lt;human-friendly-name&gt;`. 2. It still requires them to hire a pile of people to moderate.
Nested functions can't access the generic parameters of their enclosing functions,so I would be surprised if `the_real_operation` was copied multiple times.
If we don't, then we break symmetry between `dyn Trait` and `impl Trait`, when both can exist. I'd classify that as a bad thing, but I mean it could work as a decision? As far as I can tell, it would be a reasonable decision to switch to this. It's just not a decision that has been made. If we pass in a vtable, then we run into some other issues - specifically when we're given two inputs of type `T = dyn Trait`, and they have different underlying types. See the example I posted [here](https://www.reddit.com/r/rust/comments/bpep6h/_/envetad).
&gt; I don't think it's a good idea to make non-parametric reasoning, often an anti-pattern, any easier than it is already. Isn't parametricity pretty much DOA with specialization?
Yes, but I think that's not a good reason to make non-parametric reasoning even more ergonomic.
I'm working through the Rust book a 2nd time, and after messing with the guessing\_game example I thought I'd try to make a simple russian\_roulette game. Basically I'm having trouble with getting the input from the user. Trying to figure out a way the user can press anything to play, or press 'q' to quit, without having to press \[Enter\]. I was hoping to find something like C's getchar();
Only reply so far is: &gt; How long have you been using the .await syntax? One day, I replaced it with own await macro immediately to improve read-ability of my code &gt; ... &gt;What environment are you editing the code in? vim, when I used .await there was no support for syntax highlighting, but since I replaced it with my own macro, not a problem &gt;How the new syntax feels over time. It is unpleasant to use and will be replaced by my own macro in future until a better syntax will appear. &gt;Any other background information you think is relevant. I found it impossible to treat .await as ? because even if I know that it is magical field, I still find it alien as it uses . operator So someone who hasn't used it at all, refuses to get used to it, and explicitly said they'll refuse to use it until they get their way. Cool. Hopefully most of the community can be better than this.
I find Rust Generics easy enough to understand but it is ugly syntax, coupled with lifetimes annotations. But I have yet to see a language implement Generics in a clean way that reads well. Generics are possibly the hardest ergonomic challenge for languages.
There's a lot going on there because the author has ambitious plans for the API. I've done way wayyyy worse when trying to create an interesting API in other languages. If the API is stable, then it's not really meant to be read too frequently, as long as the code that actually does the labor is kept out of it and put somewhere else.
Umm..
I'm sorry for not accepting ugly new syntax for await operator. Clearly I'm wrong for preferring better read-ability over non-existing profit of postfix await
Ah, I totally failed to realize that `mem::replace` could also be used to implement `split_at_mut_in_place` in terms of the existing version... Oops. It feels a bit like cheating, but it's totally the best way to do it. &gt;I ran into it in the implementation of `ChunksExactMut`. Coincidentally, I did some work on the chunks code recently and even mentioned these in-place versions [in the PR](https://github.com/rust-lang/rust/pull/60555). There's a lot of duplication going on those types at the moment.
Haskell does it pretty well for the basic and intermediate levels, but no lifetimes to think about.
1. There is no `realloc` function in `std::allocator` and `std::vector` is based on `std::allocator` interface, so in-place growth is not possible. Even if there was `realloc` in `std::allocator`, it would be only usable for POD types (and `std::unique_ptr` is not POD) 2. `std::unique_ptr` is not "just a pointer", it is smart pointer. Smart pointer has to maintain some invariants, e.g. transition to empty state after move constructor was called on it. Empty state is `nullptr` (zeroed bytes). Let's look at libc++ for example. [Here](https://github.com/llvm-mirror/libcxx/blob/master/include/memory#L2493) is move constructor, it calls `release()` on its argument, which [sets](https://github.com/llvm-mirror/libcxx/blob/master/include/memory#L2642) it to `nullptr`.
Another dimension to library design is making sure you follow conventions established in the ecosystem. The Rust API guidelines are a good start for that: https://rust-lang-nursery.github.io/api-guidelines/ With respect to your specific example, I dare say that HTTP frameworks will likely have some of the most complicated type signatures you'll see.
Old names can be re-used.
What about a simple upvote, downvote, with no intention of removing the package? And search results would always prioritize the one with the highest upvoted package, when a related tag is search.
This is the job of a windowing library, typically used in conjunction with the graphics library for purposes of game development. The windowing library handles all the events into and out of a window, which is managed by the OS's window manager. If you're using a terminal and want to capture keys within the terminal specifically, you're looking for terminal specific functions. You'll probably be looking for something in the order of "stdin" if you're dealing with Linux terminals specifically. A quick search turns up something like ncurses: https://stackoverflow.com/questions/26321592/how-can-i-read-one-character-from-stdin-without-having-to-hit-enter
&gt;I don't think it's a good idea to make non-parametric reasoning, often an anti-pattern, any easier than it is already. Making it easier devalues types and documentation even more by breaking a caller's intuitive notion that a generic function acts uniformly with respect to instantiated type parameters. Parametricy is a good goal for assuming user expectations when designing APIs. However, parametricy has never an explicit promise of Rust APIs, and can't be because of type sizes. That has only degraded over time with the introduction of \`Any\` and specialization. Its a useful tool in the toolbox that deserves better ergonomics. As /u/gclinchtenberg notes specialization already breaks parametricy. Downcasting and specialization seem intrinsically related providing similar roles on different sides of the compile barrier. I think requiring an \`Any\` bound is sufficient to let users know there might funny business going on, similar to how we trust \`default\` to signal whether a function was specialized or not. Being able to downcast ergonomically would also be quiet nice for errors. Replacing the \`ErrorKind\` pattern with \`Error + Any\` would be much more ergonomic and would allow implementors of say \`io::Read\` and \`io::Write\` to include error information specific to their resource.
Every Discord blog post I've seen is a pleasure to read and this is no exception. It's fantastic seeing 2 of my favourite languages to program in used together to such success.
&gt; However, parametricy has never an explicit promise of Rust APIs, and can't be because of type sizes. Having some non-parametric functions such as `size_of` does not mean that you cannot have parametricity. You just have to adjust your meta-theoretical claim to include `size_of` as an exception. Note that Haskell does the same here. Notably, you can use `undefined :: forall a. a` which is a universal function. The equivalent in Rust would be `unimplemented!()` which is also non-parametric. This does however not negate parametricity as an abstraction principle and it does not negate the laws you can derive from it. &gt; I think requiring an `Any` bound is sufficient to let users know there might funny business going on, [...] If you require an `Any` bound then you are not breaking parametricity; But Rust only requires `T: 'static` because `impl&lt;T: 'static&gt; Any for T {}` holds. Moreover, Haskell also has the equivalent of `Any`: [`Dynamic`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Dynamic.html) which is probably where the inspiration of `Any` came from in the first place. &gt; Being able to downcast ergonomically would also be quiet nice for errors. Replacing the `ErrorKind` pattern with `Error + Any` would be much more ergonomic and would allow implementors of say `io::Read` and `io::Write` to include error information specific to their resource. It might be ergonomic, but I think you shouldn't make just anything ergonomic. Non-parametric reasoning is typically indicative of architectural design mistakes elsewhere.
It looks really promising so far, kudos to the compiler team!
It's not so much that you don't like it, it's that you replied to the survey asking about you experience using it with "I'm not," which isn't very helpful feedback.
The feedback is that my experience is so bad, I don't want to use it. If I have alternative to it, I'll prefer to use it. I'm not sure what is difficult to understand about it, as I already said `.await` is alien, not only because I have experience working with multiple languages, but also because it butchers existing syntax of language
OK, but *why*? Aside from "it's weird," you didn't give any reason as to why you disliked it. Did you find that it made code harder to reason about? Did it hurt readability? Did you discover some unexpected pitfalls? *That's* what would make for useful feedback, not just a statement of your refusal to use it.
Even something like C's `getchar()` wouldn't fix the biggest problem you're facing here: by default the terminal driver will buffer your input until you press &lt;Enter&gt;. (If you read the [documentation for `getchar`](http://www.cplusplus.com/reference/cstdio/getchar/) it implicitly mentions that getchar won't echo the input until you type a newline.) To get around that, you need to put your terminal into raw mode, which is very platform specific, so I don't believe a function to do it exists in the standard library. Here's an rough example using the Termion library to set the terminal to raw mode, and reading a single key press: use std::io::prelude::*; use std::io::{stdin, stdout}; use termion::raw::IntoRawMode; fn main() { // Yes, although we set raw mode on stdout, it will affect stdin. We assign // it to a variable since it will revert to 'cooked' mode when it drops. let _stdout = stdout().into_raw_mode().unwrap(); let s = stdin(); let mut s2 = s.lock(); let mut single_char: [u8; 1] = [0]; s2.read_exact(&amp;mut single_char).unwrap(); println!("You pressed the {} key", single_char[0] as char); } There are other terminal crates that will also let you do this, such as Crossterm, which also supports Windows.
Do people still write/use Erlang directly? Or is BEAM mostly just the VM/runtime for Elixir development?
/r/playrust
Take your time, don't rush it!
Crowd sourcing could help to a certain extent. If lots of people are using the usename crate, then that moves to the top of the queue to be considered a top-level crate.
Can someone give me a list of things I need to start writting async code using latest `Future` and `await`? Which libraries, which versions, nightly compiler and some feature flag. I would like to write some simple tcp echo server or something, but I got lost in what is the current state of art/in-progress status.
Have they evaluated a `BTreeSet`? The requirements sound very much like a `BTreeSet` would fit well.
Oof, GitHub names might not be the best choice then.
Look at my repo https://github.com/rofrol/rustommerce
When I saw the new await syntax I thought "ewwwwww, what?" But after reading the discussion that brought us here, I do understand it, and I can't suggest something better.
I agree, there are a few JVM frameworks that outperform Rust based ones in speed/throughput, although Rust-based frameworks tend to have lower memory utilization and more consistent latencies than their JVM counterparts. My overall point was that other languages/frameworks aren't so similar to Rust equivalents that someone might cross-referencing their documentation/tutorials to figure out how to write a web service in a Rust equivalent framework. I'll maintain that beginner/intermediate web developers intent on using a Rust web framework are better served by just reading documentation for that framework or directly reading about fundamentals instead of referencing documentation for non-rust web frameworks and trying to apply that to their work.
&gt; This does however not negate parametricity as an abstraction principle and it does not negate the laws you can derive from it. I think that's underselling it by quiet a bit. `size_of` rears its head all over the Rust especially in `unsafe` code, and with a bunch of special type system "workarounds" to deal with it such as; object safe traits, `impl` vs `dyn`, placement new, etc. `size_of` seems much more analogous to `seq` in that it changes a fundamental property of code execution invisibly, and breaks parametricity and can lead to unsound optimizations, but because of performance and other requirements is virtually required for the language. This logic applies doubly so to a language like Rust where zero-cost abstractions are part of the core DNA. &gt; If you require an Any bound then you are not breaking parametricity; I'm not following this distinction. Sure the `Any` trait itself doesn't break parametricity, but any use of its one method `downcast_ref` breaks the parametricity of the function its called in. Most of the time when I see a trait bound on the function I'm going to assume that that traits methods are used, and ergo a function with an `Any` bound is non-parametric. My proposal for the downcasting in `match` is just syntax sugar over `Any::downcast_ref` and therefore would still require the full `Any` bound and would therefore retain the current parametric properties of Rust functions. &gt; It might be ergonomic, but I think you shouldn't make just anything ergonomic. Non-parametric reasoning is typically indicative of architectural design mistakes elsewhere. Agree to disagree. There are very clear situations where being able to return a type that is open for extension but can downcasted is invaluable, the `Any` trait wouldn't be in the language otherwise. And there's precedent in other languages the open-for-extension with cheap downcasts is very ergonomic for errors in most OOP languages (dare I say, if this were the only use of inheritance we'd all probably have a better opinion of it), and in OCaml with extensible variants that leverage the existing match syntax. Rust's inability to describe `io` errors without listing out every possible error from every io syscall on every platform is pretty indicative that there's an abstraction gap between the language and the problem domain we map it to. I'm all ears for better suggestions, but the ecosystem of error handling libraries has not shown any reasonable alternatives and keeps moving towards leaning more an more on `dyn`. There are other good use cases with plenty of external precedent such as in syntax extensions "extending" AST node types, or event types in event handlers.
actix-web is currently at version 1 beta 5 Remaining is user guide https://github.com/actix/actix-web/issues/722 Examples are in version 1 https://github.com/actix/examples There are examples and tests in main repo https://github.com/actix/actix-web/tree/master/actix-http/tests - https://github.com/actix/actix-web/blob/master/MIGRATION.md - https://docs.rs/crate/actix-web - https://docs.rs/actix-web/1.0.0-beta.5 - https://docs.rs/actix-web/0.7.19 - [migration_from_actix-web-0.7.19_to_1.0.0-beta.5.md](https://gist.github.com/rofrol/351f97c40ebc83c20882c2859db8c626)
Sorry, slightly confused here. Are you suggesting that we keep this postfix, but name the operator `!await` rather than `await`? Like, get_connection().!await.call().!await Or is this something else?
&gt; Allowing users to vote to remove packages will eventually lead to somebody's code breaking because they relied on a package the community decided should be removed. This is a case where *basic common sense* comes a long way. As long as it's not fully automatic, it should be really easy to have a community group that removes namesquatted crates after some period of time (say, 3 months).
That's not a good solution, since you'd have to remember the author. That's way harder than remembering a singular crate name.
That sounds like a better idea. Few questions and musings: Would that be compatible with `extern "C"` functions? I know for instance, go needs special stacks for C calls that are fairly costly to setup. If so, could rust make FFI safer by creating an FFI stack that's just used for `extern` calls and objects passed to them? How 'bout flexible array members? Does this work for all targets or would it have to fall back to `alloca` on some platforms?
[romio](https://github.com/withoutboats/romio) and [futures-preview](https://github.com/rust-lang-nursery/futures-rs), both at their latest crates.io alpha versions should be enough to get you started. There's a metric ton of other async/Futures stuff out there, but the majority of it uses the tokio ecosystem and Futures 0.1. You *can* use it with async/await via `futures-preview`'s `compat` feature, but I would steer clear of that if you're just looking to get your feet wet. Once std futures stabilize, tokio should finally migrate to it and the compat wrappers will be a thing of the past.
After revisiting it, I have this to say. In general, I don't really care about money and I don't really feel like I have to work unless I need money, so I don't really feel a pressure to get a job unless I am running out of money. Like if I had infinite money I might go without a pay-for-salary job for maybe a lifetime. I kind of have to find a job that I want, and most of them I have no interest in. I know I seem like a selfish dick, but I have a very short attention span and very little empathy, but I am kind, true, and socially responsive in person. I'm more of a face-to-face people person than a business person, and I can read things like micro-expressions, subtle undertones, whether people are lying or telling the truth, etc. &amp;#x200B; The problem with getting a job programming in Java EE is that I frankly have no interest in learning Java EE and it's hard to get me to do something that I have no interest in. I have ADHD and I tend to either "zone out" or "hyper focus". If I "hyper focus" I can learn super fast and be super productive, which is good for a prospective employer, but if I "zone out" I'm not as helpful. I also have a mental disability.
I'm sorry to hear that. &amp;#x200B; After revisiting it, I have this to say. In general, I don't really care about money and I don't really feel like I have to work unless I need money, so I don't really feel a pressure to get a job unless I am running out of money. Like if I had infinite money I might go without a pay-for-salary job for maybe a lifetime. I kind of have to find a job that I want, and most of them I have no interest in. I know I seem like a selfish dick, but I have a very short attention span and very little empathy, but I am kind, true, and socially responsive in person. I'm more of a face-to-face people person than a business person, and I can read things like micro-expressions, subtle undertones, whether people are lying or telling the truth, etc. &amp;#x200B; The problem with getting a job programming in Java EE is that I frankly have no interest in learning Java EE and it's hard to get me to do something that I have no interest in. I have ADHD and I tend to either "zone out" or "hyper focus". If I "hyper focus" I can learn super fast and be super productive, which is good for a prospective employer, but if I "zone out" I'm not as helpful. I also have a mental disability.
I was wondering this the whole time I was reading. I don't have much experience with erlang but I can imagine it's somewhat hard to make a persistent/purely-functional BTree.
Oh wait. I think I get it. I come off as really self-centered and disinterested in other people. My brain is just that way - I don't do it on purpose.
I noticed this now! This is what happens when you are reading code on your phone at 1am lol
Oh wait. I think I get it. I come off as really self-centered and disinterested in other people. My brain is just that way - I don't do it on purpose. I'm am generally more attentive to things like facial micro-expressions, vocal undertones, whether people are lying or telling the truth, their preferences, etc. I'm basically a sociopath, but a nice sociopath who tries to do the right thing and tell the truth.
Oh wait. I think I get it. I come off as really self-centered and disinterested in other people. My brain is just that way - I don't do it on purpose. I'm am generally more attentive to things like facial micro-expressions, vocal undertones, whether people are lying or telling the truth, their preferences, etc. I'm basically a sociopath, but a good sociopath who tries to do the right thing and tell the truth.
After thinking about it, I want you to know that I never tried to do or be mean to you in any way, but you are being mean to me. When I did it, it was not intentional, but when you do it, it is intentional. &amp;#x200B; I have a brain that is different than yours, I don't think there is anything wrong with having a brain that is different than other people's. What is wrong is being mean to people who aren't trying to be mean to you just because they are different than you are. I can't legislate understanding, and you have not demonstrated understanding.
I was overzealous in my conclusion. Sorry about that.
\&gt; "The thing which might be getting in the way is your attitude." &amp;#x200B; My attitude is 100% not intentional. I have had zero intention or desire to be mean or a dick to you or to anyone else on the Rust forum. I am the way I am - it's not deliberate. &amp;#x200B; \&gt; "I'm not sure if this comes out in the interviews or communications, but if it does, when you leave out an impression of very annoying type..." &amp;#x200B; Again, annoying, but that is 100% not deliberate. I'm not the one who is trying to be mean to other people. In rare cases I am mean, but it's when I have determined that the other person deserves it and that they can learn a lesson from it, and that is not the case here. &amp;#x200B; \&gt; "Provided it showed up in somewhat generally condescending context." &amp;#x200B; Again, I wasn't intentionally trying to be condescending when I wrote this. Also, I updated the paragraph to make it more understanding. Some people really like Java. I don't. If you are a person who really likes Java and Java EE, good for you - keep programming in that. I am not that person (although I can make the decision to use more mature technology if a particular project warrants it). &amp;#x200B; \&gt; "It appears that instead of thinking that there is a reason for it, you write it off as something stupid." &amp;#x200B; I don't think of it as something stupid. Java and Java EE has its place, and there are many businesses that it is very good for. I think that many of the people are stupid, and they did stupid things and produced a nightmare codebase that had to be migrated over. I used the Swagger API to generate a swagger.json file which could be used to generate stubs in the new microservice which could then be filled in. I basically layed out and planned out the stuff needed for the other people. Like I was in charge of the new microservice because the old one was so bad it was basically non-functional and needed to be heavily re-written. I also like research and pick out libraries and frameworks. I'm like the "architect" because I make myself the subject matter expert and research, plan, and designed out the big picture for the new microservice at say Bank of America, and then other people kind of followed. &amp;#x200B; \&gt; "It's to late to go deep into this one, even if I could. But .. there are a lot of competing theories and practices. Which all promise to solve something or be better than x." &amp;#x200B; The theories and practices don't matter in and of themselves. What matters to me is how they work with the people who are say on my codebase. If everyone on my codebase hates functional programming, I'm either not going to do it (at the very least I won't design for it), or I'm going to work somewhere else. If everyone wants to code in Perl Script, PHP, and Ruby, I'm going to find another team and another place to work because I frankly can't even do that regardless of how "easy" some people think it is. &amp;#x200B; \&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game." &amp;#x200B; Or I could just get a gun and put a bullet through the MMA fighter's forehead. I don't have much empathy, and I don't really care for rules. I generally try to follow things though, for example truth, and I try to focus on people and how they would feel, react, etc. Like I'm good face-to-face because I notice tiny details of individual people. I hyper-focus well, but then I zoom out at other times. That being said, if people are engaged to me (and I tend to notice and focus on them), I can pay attention to them and be nice. I'm mentally different than say you. &amp;#x200B; \&gt; "Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; Ultimately they have to personally engage me with the business side in order for me to care about it. Like I personally don't care about say hospitals and health insurance companies unless I am on the phone and I deliberately ask them questions and listen to them and sort of pick up on their feelings through the way they speak, undertones, hesitation, etc. I'm basically a sociopath with ADHD and various mental "differences", but I am in general a good person. &amp;#x200B; \&gt; "Now that doesn't mean it's useless in all possible use-cases" &amp;#x200B; Actually, there are plenty of use cases where something else is more useful or better suited. Java and Spring is just one tool in a toolbox. It's just not the one that I like most. if I'm going to work nine to five, I want to like what I'm doing. No amount of pay can make me stop hating the technology that I am forced to work with, and no amount of pay can make me able to do something that I am mentally unable to do. I am different. &amp;#x200B; \&gt; "But being fixated on being dogmatically correct over being effective is generally not a good quality of a software developer." &amp;#x200B; I am in general focused on being effective, but my personal style is very mathematical. Also, when I code, I tend to do small teams of really good people rather than big teams of incompetent people. If I had to have like a hundred people in one central location who are just there to collect a paycheck and go home, that makes a big difference. There's no way in hell I could do something that isn't braindead if I had that group of people. &amp;#x200B; \&gt; "You will realize this sooner or later. But the sooner you do so, the better off your chances will be on the long run. And even if you end up in R n D department of some sort, realizing that your mission is to provide value to others first will get you there faster. Currently, from the way you put it, I can't feel even a trace of this." &amp;#x200B; I do provide value to others, but because I am different, I do it a little differently.
this is hilarious. i don't know how accurate git blame actually is, but for the sake of the joke i like to think it's very accurate.
In pure wasm, *maybe*. But it definitely depends on what you expose to the wasm environment at runtime. See defcon ctf challenge for a toy example. [wasm spectre bug](https://github.com/o-o-overflow/dc2019q-gloryhost)
The sad thing is that I really wasn't trying to be a dick when I wrote this article. Like I just came off that way without trying to come off that way.
Do you have any metrics for how much this improves compliation times across a few examples?
&gt; I think that's underselling it by quiet a bit. It just means you have to substantially alter your parametricity claim. Specialization will naturally obliterate parametricity for type parameters entirely (not for lifetimes! that's critical for soundness). &gt; This logic applies doubly so to a language like Rust where zero-cost abstractions are part of the core DNA. I personally don't think it was a good deal to weaken parametricity in favor of performance but that's just me; too late to do anything about it now. It's not without cost in terms of the value of abstractions and what abstractions you can have to begin with (e.g. you give up higher ranked types). &gt; I'm not following this distinction. Sure the `Any` trait itself doesn't break parametricity, but any use of its one method downcast_ref breaks the parametricity of the function its called in. This is like saying that functions `toDyn :: Typeable a =&gt; a -&gt; Dynamic ` and `fromDynamic :: Typeable a =&gt; Dynamic -&gt; Maybe a` violate parametricity because it allows you to encode a function that pattern matches on `a`. It does not because when you say `Typeable a =&gt;` you are in fact saying `TypeableDict a -&gt; ...` where `TypeableDict` carries the reflection functions. When we desugar like so into System F, we don't require anything extra from the core language and as is proven, System F preserves parametricity. The argument for `Any` is the same -- we are in effect passing a dictionary (or vtable). &gt; And there's precedent in other languages the open-for-extension with cheap downcasts is very ergonomic for errors in most OOP languages (dare I say, if this were the only use of inheritance we'd all probably have a better opinion of it), and in OCaml with extensible variants that leverage the existing match syntax. Yes, precedent like `instanceof` in Java, which I want no part of.
I just recently went through everything and tried to set up a project with the new `await`, and I had success using `tokio` and `futures-preview` with the "compat" feature. Since it seemed useful, this is a demo crate with everything for that set up: https://github.com/daboross/futures-example-2019 (more links to stuff in the README too).
Interesting library; Ultimately, I think this has to be automatic to have any ecosystem wide effect on binary sizes and compilation time. I would like to see experiments where `rustc` outlines and polymorpherizes generic functions automatically where it thinks it would be beneficial. I believe Niko already has plans here.
This is really awesome and should be part of the compiler. Even if it does not improve compilation times, having smaller binaries is already benefical anyway.
Couldn't they use [Vec::split_off](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.split_off) instead of making their [own split method using unsafe](https://github.com/discordapp/sorted_set_nif/blob/master/native/sorted_set_nif/src/bucket.rs#L27) Couldn't they just do it like this?: ``` pub fn split(&amp;mut self) -&gt; Bucket { let at = self.data.len(); Bucket { data: self.data.split_off(at) } ```
You are overly confident about what you're going to achieve with only a few months time. The recommendations to use dynamic languages is even more relevant as you share about your timeframe and goals. My recommendation is to not even touch dynamic languages and instead build your web site entirely with Squarespace. Get it online. Start promoting and tracking. Then, as reality presents itself and you find you have more time, use it to learn Rust fundamentals. Learning Rust, web development, etc etc is far too lofty.
Thank you
We could use a monthly mod-created crate-squatting-discussion thread until this gets fixed.
&gt; (e.g. you give up higher ranked types). Can higher ranked types be implemented, in general, without boxing? If not that’s exactly the non-paramecity of `size_of` rearing it’s ugly head once again. And I feel that I would be hard pressed to find a rustacean who wouldn’t give it up in that case. &gt; The argument for _Any_ is the same -- we are in effect passing a dictionary (or vtable). Then `match` sugar over trait `Any` should be equally parametric as the `Any` trait itself. And because of core parts of the language like `size_of` and specialization already breaking parametricity in much more fundamental ways this discussion is purely about ergonomics: we neither gain nor lose any type level proofs, any type-level abstractive power, or even any additional visual signal to the reader with this syntax sugar. &gt; Yes, precedent like _instanceof_ in Java, which I want no part of. Better precedent would be the matching features: `catch` matching which make OOP look awesome. I think that the presence of enums in the language, forcing a default case on `dyn` `match`, requiring the `Any` bound would deter most the common errors associated with `instanceof` usage and relegate it to mostly runtime specialization. `match` forcing a default branch is actually an advantage to the sugar becauses it forces more compelete thinking over just the `downcast_ref` method.
Ah yes. Let's run JIT code in the kernel. What a fanstastic idea. It's not like there have ever been any JIT bugs...... Like, wasm is cool and all, but this is fucking ridiculous. &gt; Since WASM is a virtual ISA protected by a Virtual Machine, we do not need to rely on external hardware and software checks to ensure safety. No offense, this is the dumbest thing I've ever read. VM protection doesn't mean shit. It just means you have an extra step of having to break out of a VM. But since we're in a JIT environment, that means absolute fuck all since exploiting the JIT engine means you get you generate basically whatever code you want, and since that's executing in kernel space, you lose instantly. Please, do not ever run this for anything in production ever.
I think yes since if your fn captures something like an rc and its executed from another thread it could lead to data races
I don't think the current implementation is persistent, they're just using a vec of buckets, neither of which are persistent.
FingerTree, a wildly used data structure in FP language, might also meet the need.
Yes to requiring `Send`, or yes to `Sync`?
For what it's worth, I wrote a wrapper with "less than 6 months of experience" (discord_game_sdk)
&gt; Did it hurt readability He said it hurts readability (since a macro improves readability over it). He also said it feels alien and it's unpleasant. And the most important thing: _he actually tried the new syntax_, but immediately reverted to a macro. It wasn't the best feedback ever, but it contained useful information (buried in not-so-useful opinion).
So, you are basically saying that it interacts unpredictable with something that broke the consistency of the language. Why do we have to get used to the thing that is not standard (set randomly by C# or whatever language, but it is a standard). Then people will want to use the .match and whatever that makes them easier to chain one hundred things and now we have more than one way to write the same thing. The precedence has been set. Rust has some things that I think is a pain to read (like .expect) and I personally don't use them, but I can't escape the await syntax. I don't even know why I'm discussing it. At least for me it looks like it has already been decided. I think I am as tired as you. &amp;#x200B; And you are correct about the term bikeshedding. Sorry.
I tried what you suggested and wasn't able to make it work. I can't pass a tuple through buffer_unordered as it required that the tuple implements IntoFuture: pub fn get_archives(&amp;self, package_name: &amp;str, sub_package_names: &amp;[&amp;str]) -&gt; Result&lt;(), ()&gt; { let urls = sub_package_names.iter() .map(|&amp;sp| { let mut path = self.data_dir.clone(); path.push("downloads"); path.push(format!("{}-{}.tar.gz", package_name, sp)); ( format!("{}/archives/{}-{}.tar.gz", self.root_url, package_name, sp), path ) }) .collect::&lt;Vec&lt;_&gt;&gt;(); let client = Client::new(); let work = stream::iter_ok(urls) .map(move |(url, path)| { client .get(&amp;url) .send() .and_then(|res| res.into_body().concat2().from_err()) .map_err(|err| panic!("There was an error getting the data!")) .and_then(|chunk| { let file = tokio::fs::File::create(path); (file, chunk) }) .map_err(|err| panic!("fuck")) }) .buffer_unordered(NUM_PARALLEL_DOWNLOADS); Ok(()) } Results in: error[E0277]: the trait bound `(tokio_fs::file::create::CreateFuture&lt;std::path::PathBuf&gt;, reqwest::async_impl::body::Chunk): futures::future::IntoFuture` is not satisfied --&gt; src/download_alt.rs:43:22 | 43 | .and_then(|chunk| { | ^^^^^^^^ the trait `futures::future::IntoFuture` is not implemented for `(tokio_fs::file::create::CreateFuture&lt;std::path::PathBuf&gt;, reqwest::async_impl::body::Chunk)` | = help: the following implementations were found: &lt;(A, B) as futures::future::IntoFuture&gt; Nor does returning a copy future into buffer unordered work as it references data in the closure. Chunk doesn't implement clone so I don't know how to fix it. pub fn get_archives(&amp;self, package_name: &amp;str, sub_package_names: &amp;[&amp;str]) -&gt; Result&lt;(), ()&gt; { let urls = sub_package_names.iter() .map(|&amp;sp| { let mut path = self.data_dir.clone(); path.push("downloads"); path.push(format!("{}-{}.tar.gz", package_name, sp)); ( format!("{}/archives/{}-{}.tar.gz", self.root_url, package_name, sp), path ) }) .collect::&lt;Vec&lt;_&gt;&gt;(); let client = Client::new(); let work = stream::iter_ok(urls) .map(move |(url, path)| { client .get(&amp;url) .send() .and_then(|res| res.into_body().concat2().from_err()) .map_err(|err| panic!("There was an error getting the data!")) .and_then(|chunk| { let data = chunk.as_ref(); let file = tokio::fs::File::create(path) .wait() .expect("There was an error opening the file on disk."); tokio::io::copy(data, file) }) .map_err(|err| panic!("fuck")) }) .buffer_unordered(NUM_PARALLEL_DOWNLOADS); Ok(()) } Results in: error[E0515]: cannot return value referencing function parameter `chunk` --&gt; src/download_alt.rs:48:25 | 44 | let data = chunk.as_ref(); | ----- `chunk` is borrowed here ... 48 | tokio::io::copy(data, file) | ^^^^^^^^^^^^^^^^^^^^^^^^^^^ returns a value referencing data owned by the current function
We need to know the index at which an item was added/removed, hence why we can not use a BTreeSet. This data-structure is one side of a coin - the other being a system which propagates updates to given windows of the set to the client.
Couldn't you make a modified btreeset where every node keeps track of how much children are in each of its child branches?
When trying to benchmark, with the command in the readme, i get:`** (Mix) No such file: bench/{benchmark}.exs`
Very cool! I wonder if it would be worthwhile to publish a generic rust version of SortedSet as a stand-alone crate?
Very cool! I wonder if it would be worthwhile to publish a generic rust version of SortedSet as a stand-alone crate?
The article has no original content, it just regurgitates points from the slides...
The article has no original content, it just regurgitates points from the slides...
The article has no original content, it just regurgitates points from the slides...
The article has no original content, it just regurgitates points from the slides...
The article has no original content, it just regurgitates points from the slides...
hi, I'm just doing this right now. you can add attributes to your derivation and feed them whatever you like. you can see my crate for some example : https://github.com/wagnerf42/derive-divisible/blob/new_api/src/lib.rs
hi, I'm just doing this right now. you can add attributes to your derivation and feed them whatever you like. you can see [my crate](https://github.com/wagnerf42/derive-divisible/blob/new_api/src/lib.rs) for some example.
Is there a way to tell `cargo watch` to watch multiple folders? Say `templates` and `src`
Is there a way to tell `cargo watch` to watch multiple folders? Say `templates` and `src`
Is there a way to tell `cargo watch` to watch multiple folders? Say `src` and `templates`
Is there a way to tell `cargo watch` to watch multiple folders? Say `src` and `templates`
Actually, their implementation is almost identical to the actual \[code used in \`split\_off\`\]([https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249)), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
Actually, their implementation is almost identical to the actual \[code used in \`split\_off\`\]([https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249)), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
Actually, their implementation is almost identical to the actual [code used in `split_off`](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
Here's a very simple example I wrote when trying to get the new syntax working, if you're interested: https://github.com/daboross/futures-example-2019/blob/master/src/main.rs.
Here's a very simple example I wrote when trying to get the new syntax working, if you're interested: https://github.com/daboross/futures-example-2019/blob/master/src/main.rs.
Actually, their implementation is almost identical to the actual \[code used in \`split\_off\`\]([https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249)), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
Actually, their implementation is almost identical to the actual [code used in `split_off`](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
Actually, their implementation is almost identical to the actual [code used in `split_off`](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
Is there a way to tell `cargo watch` to watch multiple folders? Say `src` and `templates`
Is there a way to tell `cargo watch` to watch multiple folders? Say `src` and `templates`
Our implementation is literally copy paste from stdlib’s implementation with a different capacity allocation initially. Yes of course we can just split and reserve, however, we are trying to avoid allocation/re allocations. I don’t think the add benchmark captures this adequately, as this operation only occurs when a bucket splits.
Our implementation is literally copy paste from stdlib’s implementation with a different capacity allocation initially. Yes of course we can just split and reserve, however, we are trying to avoid allocation/re allocations. I don’t think the add benchmark captures this adequately, as this operation only occurs when a bucket splits.
Sure - but that means not using the btreeset in stdlib anymore.
At that point do you go back to having a regular binary tree, to minimize the amount of rewriting you do on insertion?
At that point do you go back to having a regular binary tree, to minimize the amount of rewriting you do on insertion?
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
Usually a gigantic method signature like that doesn't come about all at once. You start with something simple. Maybe your requests only have one lifetime parameter, and nothing specifies `Send` or `Sync`. Then you add threading features or whatever, so you need to start sprinking `Send` and `Sync` in various places. And you run into use cases where you need to do more complicated borrowing, so another lifetime parameter sneaks in. All of this could take a year from the first version, and at that point you're an expert on what the library is doing, and it's easier to reason about each extra little bit of complexity. The important thing is that you understand the problem domain you're trying to write a library for. Everything else you'll pick up as you go.
Usually a gigantic method signature like that doesn't come about all at once. You start with something simple. Maybe your requests only have one lifetime parameter, and nothing specifies `Send` or `Sync`. Then you add threading features or whatever, so you need to start sprinking `Send` and `Sync` in various places. And you run into use cases where you need to do more complicated borrowing, so another lifetime parameter sneaks in. All of this could take a year from the first version, and at that point you're an expert on what the library is doing, and it's easier to reason about each extra little bit of complexity. The important thing is that you understand the problem domain you're trying to write a library for. Everything else you'll pick up as you go.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
\&gt; "This is evident in martial arts, which was a snake oil salesmen paradise until MMA came out and put all of them to a test in a brutal survival game. \&gt; Business is MMA to software engineering. If theory is not applied in wide spread manner, when it probably doesn't work or if it does work, when it doesn't scale or fails at cost - benefit analysis or other of n reasons." &amp;#x200B; This is literally stupid. Allow me to explain. Amazon was originally written in Perl. Amazon employees who were the long enough remember when they had to write and modify Perl code. Amazon as a corporation is now worth over $1,000,000,000,000 . Facebook was originally written in PHP. Facebook just created its own custom programming language, Hack, which is fast, but interoperable with PHP, and looks like PHP. I don't know anybody who codes in the Hack programming language who didn't work for Facebook. You can have the world's wealthiest company built on top of a shitty, shitty programming language. If I remember correctly, a big contributor of Java's popularity was advertising by Oracle. To be honest, I don't think the programming language matters, just as long as people get shit done, and I often can't get shit done in dynamically typed programming languages.
Usually a gigantic method signature like that doesn't come about all at once. You start with something simple. Maybe your requests only have one lifetime parameter, and nothing specifies `Send` or `Sync`. Then you add threading features or whatever, so you need to start sprinking `Send` and `Sync` in various places. And you run into use cases where you need to do more complicated borrowing, so another lifetime parameter sneaks in. All of this could take a year from the first version, and at that point you're an expert on what the library is doing, and it's easier to reason about each extra little bit of complexity. The important thing is that you understand the problem domain you're trying to write a library for. Everything else you'll pick up as you go.
Usually a gigantic method signature like that doesn't come about all at once. You start with something simple. Maybe your requests only have one lifetime parameter, and nothing specifies `Send` or `Sync`. Then you add threading features or whatever, so you need to start sprinking `Send` and `Sync` in various places. And you run into use cases where you need to do more complicated borrowing, so another lifetime parameter sneaks in. All of this could take a year from the first version, and at that point you're an expert on what the library is doing, and it's easier to reason about each extra little bit of complexity. The important thing is that you understand the problem domain you're trying to write a library for. Everything else you'll pick up as you go.
Usually a gigantic method signature like that doesn't come about all at once. You start with something simple. Maybe your requests only have one lifetime parameter, and nothing specifies `Send` or `Sync`. Then you add threading features or whatever, so you need to start sprinking `Send` and `Sync` in various places. And you run into use cases where you need to do more complicated borrowing, so another lifetime parameter sneaks in. All of this could take a year from the first version, and at that point you're an expert on what the library is doing, and it's easier to reason about each extra little bit of complexity. The important thing is that you understand the problem domain you're trying to write a library for. Everything else you'll pick up as you go.
hi, you can do it with attributes in the derivation itself. I just did it this morning : https://github.com/wagnerf42/derive-divisible/blob/new_api/src/lib.rs
hi, you can do it with attributes in the derivation itself. I [just did it](https://github.com/wagnerf42/derive-divisible/blob/new_api/src/lib.rs) this morning
Usually a gigantic method signature like that doesn't come about all at once. You start with something simple. Maybe your requests only have one lifetime parameter, and nothing specifies `Send` or `Sync`. Then you add threading features or whatever, so you need to start sprinking `Send` and `Sync` in various places. And you run into use cases where you need to do more complicated borrowing, so another lifetime parameter sneaks in. All of this could take a year from the first version, and at that point you're an expert on what the library is doing, and it's easier to reason about each extra little bit of complexity. The important thing is that you understand the problem domain you're trying to write a library for. Everything else you'll pick up as you go.
Many people still write Erlang. I see Elixir introducing BEAM (and OTP) to a new audience, rather than eroding the "pure" Erlang developers.
Many people still write Erlang. I see Elixir introducing BEAM (and OTP) to a new audience, rather than eroding the "pure" Erlang developers.
Many people still write Erlang. I see Elixir introducing BEAM (and OTP) to a new audience, rather than eroding the "pure" Erlang developers.
Unless you’re constantly moving very large, empty smallvecs around in an inner loop, this is going to cause you precisely zero problems.
Unless you’re constantly moving very large, empty smallvecs around in an inner loop, this is going to cause you precisely zero problems.
Unless you’re constantly moving very large, empty smallvecs around in an inner loop, this is going to cause you precisely zero problems.
Rust the programming language =/= Rust the game You’re looking for /r/playrust
`Send` only; you're effectively moving the callback to another thread and using it there. `Sync` would be for if you were calling the callback from multiple threads.
`Send` only; you're effectively moving the callback to another thread and using it there. `Sync` would be for if you were calling the callback from multiple threads.
`Send` only; you're effectively moving the callback to another thread and using it there. `Sync` would be for if you were calling the callback from multiple threads.
I wonder if the compiler could optimize this pattern by himself
I respect opting for a simple and safe implementation over hacking on BTreeMap's big unsafe mass.
I respect opting for a simple and safe implementation over hacking on BTreeMap's big unsafe mass.
I respect opting for a simple and safe implementation over hacking on BTreeMap's big unsafe mass.
I respect opting for a simple and safe implementation over hacking on BTreeMap's big unsafe mass.
For the love of god why? If that extra ten percent is important for your application, don't use a GCed language.
For the love of god why? If that extra ten percent is important for your application, don't use a GCed language.
You have the right to not like the proposed syntax (I don't like it very much too), but the topic was about experience of the `.await` syntax. If you genuinely tryed to use it, felt it was unpleasant and explained this experience, this would have been ok. The problem is you can't really talk about experience since you used a workaround to not experience the `.await` syntax.
[removed]
[removed]
You have the right to not like the proposed syntax (I don't like it very much too), but the topic was about experience of the `.await` syntax. If you genuinely tryed to use it, felt it was unpleasant and explained this experience, this would have been ok. The problem is you can't really talk about experience since you used a workaround to not experience the `.await` syntax.
`Send` only; you're effectively moving the callback to another thread and using it there. `Sync` would be for if you were calling the callback from multiple threads.
The [Jan Redmonk rankings](https://redmonk.com/sogrady/2019/03/20/language-rankings-1-19/) suggest that use of both is about even.
The problem is you can't talk about experience of the \`.await\` syntax since you used a workaround to not experience it. &amp;#x200B; You have the right to not like the proposed syntax (I don't like it very much too), but the topic was about experience of the \`.await\` syntax. If you genuinely tryed to use it, felt it was unpleasant and explained this experience, this would have been ok.
Someone created an issue [https://github.com/discordapp/sorted\_set\_nif/issues/1](https://github.com/discordapp/sorted_set_nif/issues/1)
quote: &gt;I found it impossible to treat .await as ? because even if I know that it is magical field, I still find it alien as it uses . operator &gt;vim, when I used .await there was no support for syntax highlighting,
The fact that I started to look for alternative tells more than just forcing myself to hurt my eyes reading code with `.await`
`await &lt;expression&gt;` is pretty much better
Actually, their implementation is almost identical to the actual [code used in `split_off`](https://doc.rust-lang.org/src/alloc/vec.rs.html#1233-1249), they just increased reserved capacity of the new vector and return a wrapped object. Given that their unsafe block is exactly the same, I don't think there's much benefit in using the STL here.
The problem is you searched an alternative before experiencing the \`.await\` syntax, so it's not an **experience** feedback.
Their experience is really similar to what everyone I talk to has said. I mean, not that it's productive, but literally a few hours ago someone was saying just about this.
The survey asks how long you've been using it for and they state how long. The survey does not specify a minimum amount of time you must have used it for.
"All cases" are invalid right now, so that seems a bit of a moot point. Also, rules can evolve.
Yes, that is a great talk too
Hi friend If you have Discord you should join the Rust Community Discord: https://discord.gg/aVESxV8 There's many people working on many projects. I'm sure one of them will be interesting to you.
Very interesting read thanks for sharing!
Not yet, but I plan to set up a compile-time benchmark, once I'm done with testing &amp; documenting the crate.
Thanks, I'll make sure I do.
I think this survey will: * Bias heavily to experienced rust users who will have an easy time picking up or teaching arbitrary language changes * Bias heavily to users who jumped onto nightly because they \*wanted\* .await * Primarily measure postfix (what .await provides) vs prefix Anyone who dislikes .await likely hasn't spent much time using it. Just like anyone who dislikes rust is less likely to be using it for very long, but obviously is a core group to focus on attracting. It's cool to see that people like .await though, I'm honestly just resigned to its stability and I guess I'll just have to hold myself accountable to getting involved in RFCs earlier, especially if we ever end up discussing a \`.match\` or \`.if\`.
That would depend on how good the heuristics are, and I'd like to keep the last say with the programmer. Also I think the annotation really isn't too costly in terms of readability.
Yes! Thanks, I forgot about the massive mess that is throwing move-constructors, and this is a great explanation of the situation. It was a mistake in my opinion on part of the C++ Standard Committee to not let explicitly declared move constructors be implicitly `noexcept` (in the same way as destructors), and let people opt in to it with `noexcept(false)`, because it is such a troublesome thing. Personally, I tend to simply require that move constructors are `noexcept`, and guard against the opposite with `static_assert`. It's not great, but it's usually a code smell when move constructors allocate heap memory, which is the primary source of exceptions in most C++ code. It can get real tricky, though...
I'm working on coreutils writen in Rust, contributions are always welcome, it's not intended to be 100% compatible with GNU' coreutils like uutils' coreutils. It's intended to implement most common features plus what is very helpful to have. Even if it's not on any version of it. I compare what is common between BSDs and GNU commands and implement that first, then I look at what features of all these versions, see what would be very helpfull, and implement that as well :3 Here the repo: https://github.com/GrayJack/coreutils
Note that this would have been a bigger problem if Rust actually had had move constructors. ;-) I have to say that placement-new is one of the features from C++ that I miss the least in Rust. It is a huge source of complexity, and is rarely the right solution.
Sure; it's not too costly, I agree. It's not that -- I just think you won't get nearly as wide-spread effects as one would get with automatic compiler support out of sheer laziness and because it won't be that widely know. It's the same reason why some things have much more impact when implemented in the standard library or as a language feature as compared to being in user space. E.g. compare the adoption of `dbg!` as a user-space crate and as when shipped in the standard library. Now, `#[momo]` will probably get used more because it does more for you and because it's less throw away, but the same dynamics still apply.
Thank you, and yes, I believe the compiler could become much smarter about monomophization, but creating the necessary heuristic is a subtle art.
I see this as a stop gap solution until the compiler becomes sufficiently smart 😎.
Yes, good on you! :)
It would be convenient if it could, but I don't think it can. Think about it. The compiler knows nothing about the length of heap-allocated strings. In fact, it doesn't know about the heap at all. You could be using an allocator that is particularly fast on your particular platform for those particular lengths of string - or then again, you could not.
I agree, and wouldn't be opposed to adding this to std proper. That said, an easier way of driving discoverability would be suggesting it as crate of the week, right?
Yes, it is a fantastic language once you understand it.
You are not allowed to do `&amp;a + b` either, even if you know it's better perf
&gt; I agree, and wouldn't be opposed to adding this to std proper. I'm not sure this should be added to the compiler as something that requires user intervention; optimization passes figuring it out based on optimization flags the user provides (or using `#[optimize(size)]`, which already exists on nightly) seems more appropriate here. I would want to avoid giving users decision fatigue. &gt; That said, an easier way of driving discoverability would be suggesting it as crate of the week, right? Sure, why not. On the subject of CotW, I'd like to make a shameless plug for https://github.com/altsysrq/proptest, which I think deserves far more attention than it has garnered thus far. :) And possibly https://github.com/AltSysrq/proptest/tree/master/proptest-derive as well but it has some bugs I need to fix first.
&gt; I think that zero-cost abstractions means you can't do better, manually, ever. If you can, then it must be a bug with the implementation of the zero-cost abstraction, not something that cannot be done by design. Arguably, using _any_ abstraction _at all_ has the potential to incur some overhead. You can implement an object-oriented paradigm using sufficiently magical macro invocations in assembly language, if you are of a particularly masochistic disposition, but such an abstraction will still incur some overhead for particular cases, where you could do better with hand-tuned assembly. Abstraction is not free. The point about _zero-cost_ is not that the abstraction is optimal for every use of the abstraction, but that you could not implement the same _general_ abstraction yourself and do it better. The best example is in C++, where you could not implement something like OOP using basic C primitives and get a better general abstraction than what C++ already provides, or you could not implement a templating system based on macros that is more efficient than the template system that already exists. It certainly does _not_ mean that you can't do specific things in specific cases that are more efficient than C++'s native classes and templates, but in that case you are choosing a different level of abstraction. &gt; Also note that in C++ move constructors are often automatically generated, where in Rust they are always automatically-generated That's not quite right. A move constructor is a function, with an entry in the symbol table and everything. Rust generates no such thing, and it eliminates the need to call such a thing all the time when the compiler happens to not be able to elide it. Move constructors in C++ incur a very significant amount of complexity in library code, which the optimizer then has to go and remove again for the code to be efficient. The vast majority of move constructors really are just `memcpy()` in C++, but the compiler cannot assume that it's the case for all of them.
This is your bias speaking. My _experience_ ended with me dropping `.await` out of code in favor more readable `await!`
&gt; especially if we ever end up discussing a `.match` or `.if`. Please don't, let's not embarrass Rust even more
What's all the fuzz with the async syntax stuff? TL;DR?
I use JavaScript every week. The await keyword in JS has some different semantics compared to rust. It's not so simple.
Still reducing unsafe if there is no performance penalty looks like a win to me. Let's have as little libraries using unsafe as possible if there is no penalty.
It might not, if you don't already have `syn` in your dependencies.
The link in the code is [here] (https://stackoverflow.com/a/48732525/1063961)
Here's a very simple example I wrote when trying to get the new syntax working, if you're interested: https://github.com/daboross/futures-example-2019/blob/master/src/main.rs.
Wait, it's "await?" now? I thought I read that postfix field was the chosen method. Not taking a stance just want to know for sure.
I was saying that I would try to be better about engaging about features that I disagree with earlier in the process. I don't want to talk in terms of embarrassment. This isn't a fight against an enemy, it's a discussion with a group who has done an insanely good job of building such a great tool, and we all benefit from it. A colleague expressed that this is sort of why they felt strongly about .await - because rust is \*so good\* to them, the first language they've really deeply enjoyed ,and this feels like such a wart, even if it isn't truly such a terrible thing. Personally, I find the RFC process extremely hard to follow. I'm on an impl Trait github conversation and it's impossible - tons of conversations and, frankly, tons of it is over my head, people are discussing a bunch of type theory shit I just don't have the vocabulary for. So, if someone throws a crazy idea out there, how am I going to see it and know to say "I think that idea is bad"? I honestly never would have guessed .await would be a serious thing, so I never would have bothered arguing against it - same with some of the other crazy ideas people had like \`await await await fut fut fut\`. But if I want my opinion known at a meaningful time it should be earlier. I don't like being a person who complains this late in the game, or complains at all. I hate being this negative about a feature in general, I just find conversations in RFCs hard to follow so I think I've been scrambling to be heard once there was an update, and others have been too. It frustrates me, and I imagine others. And the solutions like "Get more involved in RFCs" don't feel great either - even more noise in RFCs sounds like it would be equally painful but for more people. I think that's mostly what bothers me, even more than the syntax. I think in the future it would be helpful to have feature 'touch points' like "Hey, here's a view of the conversation from the lang-team's perspective" like what boats posted, but like, way more often. I can only imagine how exhausting this is for the language team, I'm exhausted just reading about it.
This is not what I understand from your post in the internals forum since you use the word immediately : \&gt; I replaced it with own await macro immediately &amp;#x200B; Maybe you should detail more your really experience the thing before you choose to replace it with a macro
Such a nuanced and well composed response! Thank you for your contribution.
I don't necessarily buy that argument. Properly implemented unsafe code is perfectly sound. In this case, the precondition is that the capacity of the target vector must be greater than the number of items that are going to be copied into it. Since you cannot prove this statically to the compiler, an unsafe block is required. Given the unsafe block is very easy to reason about, and the preconditions are fulfilled, the implementation is perfectly sound. Also, it's literally a copy-paste from libstd with one small tweak. Furthermore, there is a penalty to allocating and then re-allocating a vector. It may not be properly measured in the benchmarking suite we have, but, one can also reason that performing a memory allocation, copying to the newly allocated memory, allocating a new block of memory of the correct size, re-copying data to that newly allocated block of memory from the just allocated block of memory has a non-zero cost. Unsafe is not something to be afraid of - but it is something to be used with caution and thought in the effort of providing both safe and sound abstractions. Matter of fact, some of the most interesting rust crates (and even a large part of libstd) have unsafe inners.
Endtest spam
Oh I understand this point... It is just for me to imagine to even see `.match` and friends RFC would be a nightmare. But you're right about current RFC process, github is not suited for discussions and rather than having discussions, RFC should be only reviewed and majority of dialogue should be in comments to RFC test, rather than to overall PRs. The another thing with RFC process is that it is not always consistent overall. Community may throw ideas, but lang team is the one to decide whether to adopt it or not, and it is good. But then lang team members themself decide lots of stuff between themself, which might be fine, but in the end it means that rather than involving yourself into RFC, it seems in the end being in lang team is one who proposed and decides features. &gt;But if I want my opinion known at a meaningful time it should be earlier. I don't like being a person who complains this late in the game In case of `.await` it was sudden decision of lang team which ignored big chunk of community in favor of this _new_ and shiny `?` like syntax, and from their reasoning on decision it seems they only wanted to do it asap, so instead of considering other solutions they just choose easiest one, even if it breaks language a bit. True, it might be late complain, but talk about `await` stabilization was sudden, and `.await` is not way was initially proposed in RFC. There was _no_ RFC to adopt `.await`, it was one sided decision of lang team. So there is no way for community to be even involved in first place. Which I believe shows that lang team priority was to force their preference, rather than having any meaningful process. Even if they're going to write RFC after now, it will be just quickly adopted since lang team are also the one who decide it. So in short, community has no means to object lang team decisions even if they are bad. P.s. original async/await RFC didn't even consider this variant, so adopting it without RFC in first place is wrong
&gt;How long have you been using the .await syntax? **One day**, I replaced it with own await macro immediately to improve read-ability of my code
P.s. According to decision blog post, the final decision will at May 23th Although I'm pretty sure they already decided it among themself, it means that we can complain still :)
I have a really hard time getting lifetimes through my head properly. I'm struggling with this compilation error: ***E0495 -*** *cannot infer an appropriate lifetime for borrow expression due to conflicting requirements* &amp;#x200B; Here's the code on [Rust Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fcb01f29d2ba9cc7b70ea1705857585e), it's just a couple of lines. Thanks for any help!
`x.await?` is two distinct operators: `.await` awaits the future, returning a `Result&lt;Item, Err&gt;` if the future is fallible (which most IO-related futures are). Then we use `?` to propagate that failure up! Looking back at it that... isn't obvious. I'm not sure how we might be able to clarify this more besides just documentation, which will only come with time. Hopefully that clarifies it?
The issue in your first snippet is that `(file, chunk)` is not a `Future`. `file` is, though, so you can do this: pub fn get_archives(&amp;self, package_name: &amp;str, sub_package_names: &amp;[&amp;str]) -&gt; Result&lt;(), ()&gt; { let urls = sub_package_names .iter() .map(|&amp;sp| { let mut path = self.data_dir.clone(); path.push("downloads"); path.push(format!("{}-{}.tar.gz", package_name, sp)); ( format!("{}/archives/{}-{}.tar.gz", self.root_url, package_name, sp), path, ) }) .collect::&lt;Vec&lt;_&gt;&gt;(); let client = Client::new(); let work = stream::iter_ok(urls) .map(move |(url, path)| { client .get(&amp;url) .send() .and_then(|res| res.into_body().concat2().from_err()) .map_err(|err| panic!("There was an error getting the data!")) .and_then(|chunk| { let file = tokio::fs::File::create(path); file.and_then(|file| { drop(chunk); Ok(()) }) }) .map_err(|err| panic!("fuck")) }) .buffer_unordered(NUM_PARALLEL_DOWNLOADS); Ok(()) } Your second snippet doesn't work because there's some confusion between an async `Stream` (which `copy` expects) and your `chunk`, which is a `Vec&lt;u8&gt;`. You could turn the buffer into a stream, however, there's not much point in buffering the response in memory, just to dump it to disk in a single go. And you're also calling `wait` on the `file` future, probably because of the issue I mentioned above. That's bad, since it blocks the thread. There are two annoying complications here: one is that it's not obvious how to copy the response to a file. I'm using `fold`, which is like iterating over the `Stream`, but see also [this issue](https://github.com/hyperium/hyper/issues/1364). The other one is needing to massage to error types to make them fit well, although to be honest error handling wasn't particularly great in your original code. pub fn get_archives(&amp;self, package_name: &amp;str, sub_package_names: &amp;[&amp;str]) -&gt; Result&lt;(), ()&gt; { let urls = sub_package_names .iter() .map(|&amp;sp| { let mut path = self.data_dir.clone(); path.push("downloads"); path.push(format!("{}-{}.tar.gz", package_name, sp)); ( format!("{}/archives/{}-{}.tar.gz", self.root_url, package_name, sp), path, ) }) .collect::&lt;Vec&lt;_&gt;&gt;(); let client = Client::new(); let work = stream::iter_ok(urls) .map(move |(url, path)| { client .get(&amp;url) .send() .map_err(|err| panic!("There was an error getting the data!")) .and_then(|res| { tokio::fs::File::create(path) .map_err(|err| Box::new(err) as Box&lt;std::error::Error&gt;) .and_then(|file| { res.into_body() .map_err(|err| Box::new(err) as Box&lt;std::error::Error&gt;) .fold(file, |file, chunk| { tokio::io::write_all(file, chunk) .map(|(f, _)| f) .map_err(|err| Box::new(err) as Box&lt;std::error::Error&gt;) }) }) }) .map_err(|err| panic!("fuck")) }) .buffer_unordered(NUM_PARALLEL_DOWNLOADS); Ok(()) } Finally, the snippets above won't work directly because at some point you removed the `tokio::run` call. Even so, they might not work because I didn't test them. And of course, this doesn't look great, but should be much better with the upcoming `await` support.
&gt; Note: Only works on nightly Oh :(
I believe for C FFI your callback can only be function pointer, rather than using `Fn()` shouldn't you use `fn() -&gt; ()` as type?
What's the difference between `...` and `..=`? The first one only works in a match statement, but so does the second one. So any reason to use the first one if it would be more consistent to use the second one? And if there's a functional difference between the two, does it also apply to `..` inside and outside of a match statement?
The heuristics might be quite similar to the ones for inlining.
Can you evaluate JS code from Rust with that?
&gt; Would that be compatible with `extern "C"` functions? With some limitations: - Rust calling C: the C function receives a pointer to the element, it need not care where it's allocated, and since the Rust function stack frame is alive until the end of the function call to C, no worries. - C calling Rust: the C function may use `alloca` (C99) internally and pass a function to Rust. The Rust run-time would need to use TLS to store the data associated with the dynamic stack. &gt; I know for instance, go needs special stacks for C calls that are fairly costly to setup. That's a different problem. Go uses a small stack (2KB) by default and relies on special code to extend the stack and updating pointers to stack objects when necessary. Since C: - Cannot extend the stack. - May have taken pointers to stack objects that cannot be relocated. Any call to a C function must first ensure that the stack is large enough prior to the call, which is typically achieved by allocating a few new large stack, copying the existing stack, and updating all pointers to stack objects to point to their new locations. And yes, that's expensive. Here, I am proposing to maintain two stacks per thread, where the primary stack is your old regular stack which C is used to use. &gt; If so, could rust make FFI safer by creating an FFI stack that's just used for `extern` calls and objects passed to them? It could be possible, yes. That's what Safe Stack is about, though, so once again it's a different problem. &gt; How 'bout flexible array members? Rust already has Dynamically Sized Types; for example, a type can have as its last member a `[T]`, which is the morale equivalent to flexible array member, except it stores its size. Those DST could be stored on the secondary (dynamic) stack. They still would not be first class citizens since you could still not have a `Vec&lt;DST&gt;` as `Vec` expects all its elements to have a statically known size. &gt; Does this work for all targets or would it have to fall back to `alloca` on some platforms? It can be made to work for all targets.
Typically C callbacks has \`void\*\` context parameter that is passed along with callback pointer. So I guess FFI implementation op uses converts given \`impl Fn()\` to \`fn(\*mut c\_void)\` + \`\*mut c\_void\` and registers callback with these.
&gt; If we pass in a vtable, then we run into some other issues - specifically when we're given two inputs of type `T = dyn Trait`, and they have different underlying types. See the example I posted here. &gt; `takes_two_of_the_same(&amp;X as &amp;dyn MyTrait, &amp;Y as &amp;dyn MyTrait);` I don't see an issue, I only see a limitation. Since it is impossible to prove that two `dyn MyTrait` are effectively the same type `T` the compiler should reject such a call. A special provision could be made for when the compiler can prove they have the same dynamic type, but that's icing on the cake.
Is there much literature on a similar type of project, baking/transferring textures from two models? A common case would be normal maps where you have a high polygon count model, and a low polygon count model with UVs unwrapped. The details from the high use rays to the low which map the 3D space to 2D in the UV map, creating a normal map texture. I guess it's more niche and less popular than ray tracing?
There are many crates that stringify the type of expression and sadly require nightly. I wish that feature was stabilized.
While this is an impressive achievement, it is probably one of the worst ideas in the history of software development. Putting a JIT compiler inside the kernel is outrageously irresponsible. Especially if you're running WASM, which is usually compiled from some other language (like Rust, or C++, or C). Why not just build an actual kernel module? The authors seem to assert that the constraints imposed by the WASM environment sufficiently embody the safety measures required in kernel code. But isn't that completely unconvincing? If your WASM code is suffering from the overhead of a VM, the solution shouldn't be to put your code into kernelspace! It should be to get rid of the VM by building a native binary.
The first one was the older syntax for inclusive ranges, the latter is the currently agreed on. The old one might be phased out in some future Rust version.
That might be a good first step, but there is more: the function should be so big that splitting off the monomorphized parts leads to space savings. In this case the number of actual types could play a role, too.
How about [actix-web](https://crates.io/crates/actix-web)?
There are other alternatives to Rocket and `actix-web`, but the latest release of Rocket should have pretty much solved the issues with breaking changes in the compiler.
Oh, thanks. Saw the first one used in an article and couldn't really find much info on it (it's hard to google punctuation).
I think [this](https://stackoverflow.com/questions/30422177/how-do-i-write-an-iterator-that-returns-references-to-itself) might give some extra information.
This ist The Rust Channel 😁. So why should I convince you to use node.js? OK. You can use Rust on the backend side. We are using it for over a year now in a microservices environment. We use actix-web and hyper directly for the REST interface. We had much less problems than we expected and it turned out that Rust is very well suited for REST backends. So if you already feel confident with Rust, go ahead!
A `BTreeSet` does not let you access by index (rank) or get the index (rank) of a given element. A B-Tree can be augmented for this by maintaining extra information (number of elements per child node); the result is an [Order Statistic Tree](https://en.wikipedia.org/wiki/Order_statistic_tree). A quick search did not reveal a Rust implementation, but it would certainly be nice to have a high quality one.
Manually wrapping library errors into application errors and propagating them gets old really fast, so the first thing one would do is write some helpers. And end up NIH’ing code someone else has already written. Avoiding 3rd party crates is not a virtue. Not sure what you mean by exceptions given that Rust doesn’t have them. And the context here is usually just a string, nothing too heavy.
 &gt;P.s. original async/await RFC didn't even consider this variant, so adopting it without RFC in first place is wrong The original rfc proposed no concrete syntax. The only statements on syntax they made were that `await` interacts poorly with `?` (note: one of the important reasons for people to prefer postfix) and that the compiler built-in is the current way to use the feature They specifically left syntax as something to be resolved later.
I'm not too sure how I missed this, thanks a lot.
Neat! I think a useful extension would be allowing the user to specify which arguments to polymorpherize; this would allow: - Partial Polymorpherization: maybe `x` and `y` can be polymorpherized, but `z` cannot; with #[momo(x, y)]` it's still a win to only generate function per type of `z` rather than for every combination of types the triplet can have. - Arbitrary Trait Polymorpherization: sometimes you want to enforce that two arguments share the concrete type, but afterwards you don't need monomorphization. In this case a `#[momo(&amp;t0, &amp;t1)]` could just pass `&amp;t0` and `&amp;t1` to polymorpherized function.
RFC decided to leave it due to `await &lt;expression&gt;?` which is clearly stated as example. So while author did consider await as keyword operator, he didn't choose to purse it further due to `?` Regardless final decision on await should be through RFC rather than internal decision of lang team, which is very divisive. Lang team should conservative here and choose more consistent existing language syntax.
&gt;Avoiding 3rd party crates is not a virtue If 3rd party crate is not needed, then it is virute. &gt;Not sure what you mean by exceptions given that Rust doesn’t have them. Rust has panics, which behave like C++ exceptions. &gt;And the context here is usually just a string, nothing too heavy. Unless it is owned strings in which case it is quite heavy allocation
I would pick Rust (or any Static language) over node.js pretty much every time, the idea of writing a large single threaded web server in a dynamic language should scare you!
This would be great for WebAssembly code size.
I don't quite understand your second proposal. Where do the `t0` and `t1` come from? Letting users choose identifiers to outline is a no-brainer and will be done once someone (that may be me) gets around to do it.
Rocket on nightly is great. It’s an awesome library. It’s SSL/TLS is not ready yet on its own so you’ll need to use begins to reverse proxy.
I agree with not being afraid of unsafe and I believe this particular use case it perfectly safe. My point was more that if there is no valid reason (to me) to use it you better not to. For large projects we will search for unsafe first when things go wrong. If there is no unsafe then it is simpler to maintain.
What's the difference between that and the official Discord: https://discordapp.com/invite/rust-lang ?
I generally just stick the whole thing behind an nginx forward to the server to get around this, has the advantage of you get certbot working for free!