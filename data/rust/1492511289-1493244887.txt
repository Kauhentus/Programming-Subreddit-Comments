It means that the user won't have an installed RLS then (until they switch to a different toolchain or update the nightly again) It's a better situation than clippy, because clippy needs to be explicitly updated. This will implicitly update RLS as long as a new one exists. If one doesn't, you will temporarily not have it. I'm not 100% sure if this "nightly without RLS" thing can happen in the current situation; entirely depends on whether or not RLS is built on CI.
How do you set up vscode-rust to work with it? I could never get it to work without setting `rust.rls.executable` to a wrapper that now looks like: #! /bin/sh export DYLD_LIBRARY_PATH=/Users/j/.rustup/toolchains/nightly-x86_64-apple-darwin/lib exec rustup run nightly rls $* 
For such a short file, the time taken by the Python version is almost certainly dominated by interpreter startup time. Using a bigger input data would help to gauge the performance of actual code.
That one. Guess it doesn't like my system :-D.
I want to write a multi-threaded software rasterizer in Rust with a Qt front-end, and I have some C-lib dependencies. But I'm concerned there will be performance penalties if I have different allocators between the various libraries involved. I understand that I cant allocate in one lib and free that same memory from another. What I don't understand is if * 1) having multiple allocators in my application is an issue, and * 2) if so how do I ensure that all libraries are using the same allocator If CBar is using jemalloc 4.5.0, and RFoo is using jemalloc 4.4.0, is this going to cause issues? Do I have to worry about having code for multiple allocators in the CPU cache taking up space when other code could/should be loaded instead? Or is this just a non-issue? 
I'm probably being really stupid here, but how did you set it up? Where is the ```rust.rls``` configuration file supposed to be located? vscode-rust starts in legacy mode and I'm not sure how to change that, despite RLS being installed.
For me, the event giving me an opportunity to travel internationally is a big benefit, but I might end up going to one of those domestic events!
&gt; The Iterator trait has a number of other useful methods defined on it that come with default implementations that call the next method. Since next is the only method of the Iterator trait that does not have a default implementation, once you've done that, you get all of the other Iterator adaptors for free. There are a lot of them! Is it good practice to override any of them? Or are the default implementations as good as they're likely to get? This is often a bit of a headache in Java, where, yes, you *can* implement a Set by extending AbstractSet and just implementing size() and iterator(), but you're going to get a lot of O(n) operations. Or you *can* implement a stream by extending InputStream and just implementing the single-byte read() method, but you're going to spend a lot of time on index arithmetic when reading an array.
`rust.rls` is an entry in VSCode's user settings, not a file. :-]
Hrm... Did you adjust your `rust.rls` entry in VSCode settings to launch rls properly? Mine is now simply: "rust.rls": { "executable": "rls", "revealOutputChannelOn": "never" } I'm not sure what else the problem would be; I don't think I did anything else special other than adding the rust toolchain bin dir (EDIT: and `%USERPROFILE%\.cargo\bin`) to my `PATH`...
&gt; VSCode rustup run nightly rls
Open an issue and we will figure it out.
It is described in the documentation: https://github.com/editor-rs/vscode-rust
Relatedly, you may find this bug amusing: https://github.com/BurntSushi/ripgrep/issues/311
Have you tried to set`rust.rls.env`? { "rust.rls": { "env": { DYLD_LIBRARY_PATH=... } } }
For writing something either gets a value from a Result or exits with some status code on Err, is there a better pattern than doing this? fn main() { let data: String; match read_data() { // some function that returns Result&lt;String&gt; Ok(d) =&gt; data = d, Err(err) =&gt; process::exit(1), } // ...use `data` here } None of the unwrap/or_else functions seemed suitable, unless I'm misunderstanding some of them. 
Thank you. It works.
First thing I tried, but it doesn't work.
It looks like you have not shared your full code which makes this hard to help with. Did you accidentally put the errors in the middle of the code when posting?
In js, I (and probably the GP) use (more or less) equivalents for all of these tools, rustc -&gt; node/webpack cargo -&gt; npm/yarn clippy -&gt; eslint rustfmt -&gt; prettier rls -&gt; tern rustup -&gt; nvm I'm not saying that it can't be improved, but it seems like a sensible and nearly standard partitioning.
As the error says; they're not dropped at the same time, they're dropped in the inverse order that they're created. This means that x will be a dangling pointer for a moment. In your code, this doesn't matter, but in other code, it could...
For the doctest examples, they are all treated as comments and therefore not autocompleted, formatted, etc. But I can always uncomment them, write/edit then re-comment them so that's a moot point. 
I'm not aware of any ones that get overriden regularly.
Ah, fantastic, thanks. I'd just gotten stuck in thinking that `unwrap_or_else` was for returning default values on errors.
I am currently in the process of breaking it all apart in smaller modules. I have to mark most fields and functions in session.rs public because timesheet (but no other) needs to use them. I also use `use session::*` a lot... Is there another way? This part of Rust confuses me quite a bit(it seems more complex than #includes, but at the same time more flexible) but I can't quite grasp it. Here is where I got some info: http://www.suspectsemantics.com/blog/2016/05/26/rust-modules-and-file-hierarchy/ The Book does explain it nicely for libraries, but not for binaries. It also doesn't explain that the top level module is the one with main().
Wait. This is the first time I see workshops in the schedule o_O They weren't there when I planned the travel and bought tickets. (I'll probably skip them anyway if they require laptop.)
Yh sorry, my bad. I fixed the code. 
Ah, I forgot about `size_hint`, yeah, that seems legitimate. Why would you override `fold`?
FWIW, knowing that the tools team is considering unification of tools is great. I've brought this point up more delicately in the past and it always came across to me like it would never be considered. I think you are correct that RLS will go a long way to unifying these tools. Especially if it implements all of the LSP. I don't think anyone has the answers to these currently, but I think the future will be interesting for commands like [formatting](https://github.com/Microsoft/language-server-protocol/blob/master/protocol.md#textDocument_formatting) and how they are going to influence rustfmt, for example. To elaborate, can all of rustfmt's formatting rules be executed by the IDE? If not, do we try to extend the LSP so that this command is compatible with rustfmt? If the IDE can perform all of rustfmts formatting rules, then should the formatting rules move into RLS and rustfmt becomes a "dumb" CLI for editing files based on RLS' formatting rules? At that point is it still rustfmt, or is it more generically lspfmt? Frankly, from the sentiment I've seen over the years, rather than embrace the LSP and as a result make RLS more complex, I fully expect the Rust community to push back on this particular part of the LSP because "rustfmt already handles it". What are your thoughts? I'm an outsider, and as such may have incorrectly assessed the sentiment. 
Nope, the `lib.rs` with the empty module is the only `.rs` file in the project.
I somewhat agree with you. When I was first learning rust, I didn't find out about rustfmt and clippy for quite a while. I don't think that there needs to be one unified tool, but I do think that these tools need to be more discoverable. I don't think that 0 time/knowledge investment is a realistic goal. In addition, I don't think it is a good idea in the first place. Learning a programming language fundamentally involves some time/knowledge investment. Often, software that has a higher barrier to entry ends up being much more comfortable to use after getting familiar with it. It's really easy to learn Scratch, but it's really hard to use it. It's really hard to learn Rust, but it's relatively easy to use it.
When I said the compiler I meant cargo build. Same thing: cargo build is the interface people use to compile, so for discussions of UX; it is the compiler. The problem is that this is a _radical_ change from how people expect their tools to work. A build is a build, it should not change the actual code. We have years of software practice doing this. Cargo recommends placing generated files in an outdir for similar reasons. I don't want a build to potentially dirty my git tree. I don't want a build to potentially make my editor buffers stale (not all editors autoreload when their files change!). If I've checked out a project to test it I don't want random changes to happen. I don't want my patch to get littered with other fmt changes just because the last person to check in to master didn't run fmt. Yes, that last one only happens if fmt isn't enforced, but then we loop back to whether or not fmt should be enforced, and different projects have different opinions on this. Clippy has a fmt config checked in but we don't enforce it, for reasons. Hell, even _go_ doesn't autoformat, and Go is more opinionated and rigid than rust will ever be. I guess an explicit `autofmt=true` key in the cargo.toml (not just detecting that a fmt config exists) would be an interesting experiment. Still has the problems I mention above, but is way more opt in. But then it doesn't really solve your original problem of discoverability and there being varied tools that you have to learn. But really, what would? Your original problem was rather vaguely stated, and it's not really clear what aspect of the issue you're trying to solve. Many of these aspects are fundamental -- like the autofmt thing interacting horribly with editors. We already have a central location for tools to run from -- cargo. There's not much to learn for any tool (you vaguely described a problem of learning new tools), except perhaps RLS (which is still WIP) because of a weird setup process. One feasible thing is to autoinstall these -- which I think may be the final goal, but the component model is fine IMO (knowing the tool exists and being able to install it are not far apart). The big missing piece is discoverability. I think there's a general reluctance to put beta or alpha stage tools in the docs, but that can change as tools mature. Rustdoc is part of the docs, for example, but the style team is still doing things, so fmt isn't. RLS is still WIP. Clippy was never a Rust Team initiative, though we still hope to make it a part of the distribution and hopefully a part of the docs once it smoothly works on stable.
My expectation, if history is any guide, is that rustfmt will become a library that's used by both the rustfmt CLI tool and the RLS tool. It's how cargo works.
&gt; cargo +nightly build foo. Only works if you have installed it via rustup. The user is still manually picking the version of the compiler there, just slightly more slickly than `rustup run ...`.
Clippy tends to be: - opinionated - annoying - wrong This is by design. Now, while there basically is a policy of no new lints in rustc, even without that policy we'd be in the same situation where most clippy lints would be outside. Clippy is intended to be used differently from rustc. You are supposed to be more aggressive in turning off clippy lints (One rarely turns off rustc lints, if ever). You are supposed to be skeptical of its suggestions -- clippy tries to analyze far more complex situations, and will often be wrong, just because it doesn't know the intent. Clippy will suggest style things that people disagree with. We do try to minimize false positives, but we go in with the expectation that false positives will exist, and we won't deal with more niche FPs, especially if detecting them means creating many more false negatives. Yes, there are probably a couple of lints we could upstream to rustc. I have mixed opinions on this -- I have no objection as a clippy maintainer but the goal of keeping rustc's lints small is pretty nice. Anyway, it's not something I care to push for, feel free to do so if you want. I don't think any of clippy's other maintainers would mind (though I don't speak for them, so I could be wrong). But this would just mean some lints go into rustc, and would not impact clippy's status as an additional linting tool. &gt; Do you not feel like if clippy/rustfmt were integrated, then we could automatically transform these? Seems kinda nice. Doesn't need to be part of rustc. Rustfix exists already (but is still kinda buggy, so not advertised much. I hope it improves. I'm sure rustfix would love contributions though).
I guess that a user may be using a pattern to destructure the struct. Rust requires the pattern to contain a subpattern for each field in the struct, so the code will fail if a new field is added.
Sometimes it can be implemented more efficiently by pass-through. *C.f.*, *e.g.*, the [`either`](https://github.com/bluss/either/commit/9c53f97f72fa09f637c2820f8eb63329c9f407cc) crate
Unfortunately this did not fix my issue. Thanks anyway.
So in Linux dynamic library allocations are consider part of the application which loaded it. All allocations are part of its userland mappings. Sane. Windows does this by default, but there can be some privileged issues depending on what your application is doing. Mostly sane, but for higher priv windows drivers things get crazy. OSX for buffers too large you have to make a chain of `mmap` calls with OS specific flags to map memory allocated with a dynlib into the caller's userspace. As each dynlib is technically loaded into its own userspace mappings which is shared with all calling applications. Darwin's memory subsystem is hell. 
I'd argue that more importantly than reducing the line count is that it shifts your attention when you read the code. Take for instance: `self.events[n-1]` vs. `self.events.last()` The former requires me to understand the relationship between the length of `events` and `n`. The latter just straight up tells me that we're working on the last element.
I'm working on a Riak clone for a while now, https://github.com/arthurprs/sucredb Almost everything in life resembles a sinusoidal wave and this is no different, right now I'm trying to remember why I spend sooooo much time on it. Besides that I'm helping out crossbeam and looking where I can squeeze some more perf out of stdlib hashmap.
This will only work if vscode is launched from a shell.
FWIW, they aren't as widely advertised because they're still not ready yet. The intention is to do so when they're ready.
I write an application for a router now (https://gitlab.labs.nic.cz/turris/pakon-aggregator). Though I'm not sure if that router still counts as embedded (we have to cross-compile for it, it uses musl as the libc, on the other hand it has a dual-core processor and 1 or 2 GB of RAM, depending on the version). My experience is, cross-compiling is probably less pain than with C, though that C part is already done and I have to pioneer the rust part. There are some cludges and doing it properly will require further work, but the code compiles and runs. The „further work“ will be mostly to silence protests of colleagues who don't (yet) like rust. But the development itself is definitely easier in rust than in C, C++ or lua.
Very interested in hearing about your experience building (and releasing!) a game in Rust. Especially any bits about building for Android and iOS using SDL2. Curious to hear about how you're packaging the game up as well.
Forget what I said in my other (now deleted) comment - VSCode reads `~/.bash_profile`. So you need to insert the export into that, or let it source .profile. This takes effect even when VSCode not launched from a shell. It's documented here: https://code.visualstudio.com/docs/editor/integrated-terminal#_linux-os-x - the quoted settings are the defaults since 1.11.
&gt; I did get the add operation to work well enough with the zip() function, however I found out that it didn't work without the trubofish `::&lt;Vec&lt;f64&gt;&gt;`. Interesting, I just tried it with rustc 1.17 and it compiled fine (just removed the explicit type and compiled). &gt; If my understanding is correct, &gt; 74 v.iter().zip(y.iter()).map(|(a,b)| a*b ).collect::&lt;Vec&lt;f64&gt;&gt;() &gt; should loop over all the items in v and y and should be able to return an iterator on the result set which I can then collect/transform into a Vec&lt;f64&gt;. &gt; Shouldn't &gt; 75 }).collect::&lt;Vec&lt;f64&gt;&gt;(); &gt; do the same for the outer iterator? In your current code, you're actually trying to build a `Vec&lt;Vec&lt;f64&gt;&gt;`. A dot product of a matrix by a line vector would be the dot product of each row of the matrix by the line vector, right? Your inner outer `map` should be responsible to calculate the dot product, but right now it is only calculating an element-by-element product. This line v.iter().zip(y.iter()).map(|(a,b)| a*b ).collect::&lt;Vec&lt;f64&gt;&gt;() When used with, for example, `v = [1,2,3]` and `y = [4,5,6]` should output an element `32`, but what it does is `[4, 10, 18]`. The output vector from `vec_dot` would be same operation for all the rows of the matrix `x`, yielding a `Vec&lt;f64&gt;` result, but with your current code each "dot product" is not yielding an element, it's returning another vector. So, what do you really want to do? Instead of collecting the element-wise products into a Vec, you want to sum them. You can then solve your issue by replacing your `collect` call in the inner map by a `sum` call. The complete code is this: fn vec_dot2(x: &amp;Vec&lt;Vec&lt;f64&gt;&gt;, y: &amp;Vec&lt;f64&gt;) -&gt; Vec&lt;f64&gt;{ x.iter().map(|v| { v.iter().zip(y.iter()).map(|(a,b)| a*b ).sum() }).collect() } Sum also accepts an explicit type annotation like `collect`, but it shouldn't be necessary. If you still have issues with type inference (especially in these collect calls) post them here as well. I successfully compiled all the code with: &gt; rustc -V rustc 1.17.0-nightly (4be034e62 2017-02-27) A bit outdated, but I haven't really used Rust in a while. Some final words for you, who's starting to use iterators: as the [new TRPL says](https://rust-lang.github.io/book/second-edition/ch13-02-iterators.html) (you should check out the draft if you haven't already), iterators can look harder to read at first, but after you get used to them, they help you write more expressive code that is at least as fast as the raw loop. Anyway, that's it for now =) 
We've got other RustFests upcoming :).
Different year, same suck. Because we're rather cash-strapped, we cannot book the hotel for two days. People like the workshops, though, so we have to announce them once we can find a venue or someone sponsoring an additional day. For that reason, we're trying to get into universities instead of hotels, but damn, are they picky and expensive in Europe. I just don't want to drop them for the format in general, because people love the possibility to meet (or break out and go to town, even). We're working on a lot of changes behind the scene, like getting a regular sponsor on board and we hope to get that ready for the next edition.
What is the output of `cargo test --no-run`?
I was playing with this last night - [tinkering with hosting an API that wrapped it](https://algorithmia.com/algorithms/anowell/hiddenmessage/edit) - feel free to steal that. Pretty fun, even though the data has a visible impact on the image. Of course, that made sense once I read the source. Worth noting I didn't ever get it fully working. It seems [this condition](https://github.com/teovoinea/steganography/blob/6cc515ac9396aac073198c73ca903887b598c09e/src/lib.rs#L51-L53) results in embedding partial copies of the message several times - namely that (2,0), (1,1), and (0,2) will all contain the third byte of the data. So decoding winds up with some garbage data. Plus the decoding didn't stop at the end of the message, but still returns the rest of the alpha channel as zeroes. Still, I had a bunch of ideas floating around my head while playing with it. It could be interesting to see this evolve into a library with implementations of steg algorithms like JSteg, F5, and LSB, and maybe options to [encrypt the hidden data](https://arxiv.org/pdf/1112.2809.pdf). Wherever you go with it, it seems like a fun project!
&gt; Is it good practice to override any of them? `size_hint` is very common to override. The others are somewhat rarer, but [it](https://github.com/rust-lang/rust/blob/master/src/libcore/char.rs#L514) [certainly](https://github.com/rust-lang/rust/blob/master/src/libcore/str/mod.rs#L510) [does](https://github.com/rust-lang/rust/blob/master/src/libcollections/vec_deque.rs#L1934) [happen](https://github.com/rust-lang/rust/blob/master/src/libcore/iter/mod.rs#L563)
the output of `cargo test --no-run` is Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs 
The `derive` will compare each field using `==`. So it won't check whether two `f64` values are in close range, it checks that that they exactly equal (if they're finite).
The fact is simply that it's WIP, and you can't expect everything to be polished already. If all the tools were only available through a monolithic IDE, I don't think many of us would be using Rust at all.
Nightly either has the same number of targets, or more. Your code that compiles on stable should always compile on nightly. You could also just wait a while; this will eventually come to stable as well.
A project can specify that it, say, needs nightly-20170410, and `cargo build` will automatically use that compiler, instead of needing ad-hoc "infrastructure" like `rustup override set $(cat pinned-compiler.txt)`. This seems fairly related to the whole discussion of not having so many tools/things to learn: instead of needing `rustup`ing and overriding (and doing it in the right directory and debugging the inevitable works-on-my-machine problems), the project manages it in a single place, so that the programmer doesn't have to think about it.
There is no universal way to test approximate equality of floats "properly." You need to consider the error bounds for your particular computations and use case.
Ah, well, that's annoying! Since it seems like something weird is happening, could you post your full `Cargo.toml`, and information about what platform you're on (output of `rustup show` is probably enough)?
**TL;DR;** You need to handle epsilon yourself. Use `f64::EPSILON` So this was a fun rabbit hole for me :) No doubt more advanced practitioners already knew the answer, but here's my journey: Let's take a problematic example (5/3): https://is.gd/rG3ktz (if you uncomment the `assert!` and run, you'll see a failure) Examining the MIR (hit the MIR button at the top of the playground) shows that evaluating `a == b` will defer to the Eq trait: _0 = Eq(_3, _4); // scope 2 at &lt;anon&gt;:4:5: 4:11 Well... where's that defined? `Eq` for `f64` (and other primitives) comes from [cmp.rs](https://doc.rust-lang.org/1.16.0/src/core/cmp.rs.html#681) which defines implementations of `PartialEq` and `Eq` to be... #[inline] fn eq(&amp;self, other: &amp;$t) -&gt; bool { (*self) == (*other) } Wait, what? We're going in a circle! Turns out primitive comparison is what's called a [lang item](http://manishearth.github.io/blog/2017/01/11/rust-tidbits-what-is-a-lang-item/) which means it's baked into the core of the language. Okay, so we have to go deeper. If you examine the (surprisingly readable) LLVM IR (again, via the playground) you can see that rustc emits [fcmp](http://llvm.org/docs/LangRef.html#fcmp-instruction) LLVM instructions for our comparison: %2 = fcmp oeq double %0, %1, !dbg !21 So, again, this is something that's baked into our compiler backend. Will LLVM save us? Let's see... Going down one last dream level, we examine the ASM output (I moved over to godbolt at this point: https://godbolt.org/g/8o01D0 and changed the function because it was optimizing my code away), and see the following: movsd xmm0, qword ptr [rbp - 8] movsd xmm1, qword ptr [rbp - 16] ucomisd xmm0, xmm1 sete al setnp cl and al, cl and al, 1 movzx eax, al The comparison is done via the [ucomisd](http://x86.renejeschke.de/html/file_module_x86_id_316.html) which does an exact comparison, and is not aware of floating point rounding errors. So, you have to handle epsilon checks in your code, the automatically derived function will not do it for you.
`rustup show`: Default host: x86_64-pc-windows-gnu stable-x86_64-pc-windows-gnu (default) rustc 1.16.0 (30cf806ef 2017-03-10) `lib.rs`: #[cfg(test)] mod tests { } `Cargo.toml`: [package] name = "test-derive" version = "0.1.0" authors = ["redacted even though I have already linked to my github profile in another comment"] [dependencies] [lib] proc-macro = true I made some edits to the original post, and I believe that I have found an issue on Cargo's github that has something to do with the problems I'm having. No solution yet though :(.
The string `test` is baked into the `.rodata` section of the executable. At link time, the value `(0xabad1dea 0x00000004)` is placed in the `.text` section wherever your `let s;` binding took place. `&amp;str` is `{ ptr: *const u8, len: usize, }`, so all `let string = "Hello World";` bindings place two words (pointer, length) in your code, and the actual string contents go in data. If you later change where an `&amp;str` binding points, those two words are mutated in code, but the string data baked into the object file does not, and *cannot* (unless your OS gets funky), change.
Thank you for the clarification!
This took me a while to grok as well. Always happy to expound where I can.
Ah, fair, that makes sense. IIRC we don't have that by design because we don't want projects pinning nightlies. It's been discussed often enough. Not sure what the current stance is.
Couldn't this be solved with some kind of library/tool that would make it behave like on Linux?
&gt; Use `f64::EPSILON` Don't just do this! This is barely better than using `==`. All this value is is the distance from `1.0f64` to the next largest `f64`. If you're dealing with numbers near 0 it will be way too big, and for numbers far away from 0 it is far to small. There is no one "best" way to compare floating-point numbers. You really do have to understand what you're doing and tailor your tests to your algorithms and inputs. [This blog post by Bruce Dawson](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/) (warning: C++) points out many issues you can run into... though still nowhere near everything that can happen. It looks like the crate that /u/protestor posted below uses some of Bruce's ideas. Summary: floating-point math is _hard_. That said, I liked seeing your rabbit hole, and I learned about lang items. Thanks for sharing!
I believe the issue here is that you are using a reference to the textures variable above the creation of the MaterialCollection class, which will no longer be valid once the new function exits scope, correct? One solution could be to have a separate initialize function which handles the textures / materials collection allocation separately. Alternatively, you could also try to use a container class along the likes of a Cell / RefCell to hold the textures variable so that you can clone multiple instances of the same reference... I'm not entirely sure, I'm still bangin' heads with the rust language myself. I'd be interested to see more answers. 
Or better, avoid needing to compare floats for direct equality altogether :p
A bit like this? https://is.gd/bCcKvW Of course, this assumes that textures is immutable and is never moved. 
A Material looks something like this: struct Material&lt;'a&gt; { texture: &amp;'a Texture, } Texture's are stored in a HashMap&lt;String, Texture&gt; inside the TextureCollection. So once constructed the MaterialCollection will contain a load of references to Textures stored in the map. Once the HashMap is moved those references are all still valid right? Only I can't seem to work out how to define that through the lifetimes.
You could have materials own textures, then. If anything outside of materials needs the textures, you could provide an access function. 
 let textures = TextureCollection::new(...); let materials = MaterialCollection::new(..., &amp;textures); RenderEngine { textures: textures, materials: materials } That wouldn’t work in C++ either. The `textures` object lives on the stack, and `&amp;textures` stores the address of that stack object. As soon as you move it into `RenderEngine`, that address will be no longer valid. Even in C++, you will need to explicitly allocate `TextureCollection` on the heap to do this (through either `new` or more idiomatically `unique_ptr`), the latter of which would be equivalent to creating a `Box` in Rust. That being said, that still won’t make it work on Rust, because Rust currently does not support self-referential objects in safe code. There are some libraries that allow this to some limited extent, but IMO it’s easier to use either `Rc`, which ensures that the objects will always survive so long as you have a handle to it, or store an indirect reference (e.g. an index to an array) instead, which may or may not be valid.
it seems that [lettre](https://github.com/lettre/lettre) is the most complete smtp library out there. It does not seems to support attachment yet (judging from https://github.com/lettre/lettre/blob/master/src/lib.rs#L13), but it does have multipart support already, so it may not be too hard to add. Maybe you should open an issue and see what the maintainer say?
Sorry I think I was unclear with passing in the &amp;textures reference as it's only used to take references to things inside it's internal HashMap (which stay valid after the HashMap is moved). The C++ equiv. I'm trying to do is something like this: struct texture {}; struct material { const texture &amp;t; }; struct render_engine { const std::map&lt;std::string, texture&gt; textures; const std::map&lt;std::string, material&gt; materials; render_engine(std::map&lt;std::string, texture&gt; t, std::map&lt;std::string, material&gt; m) : textures{std::move(t)}, materials{std::move(m)} {} }; std::map&lt;std::string, texture&gt; textures{ {"one", texture{}}, {"two", texture{}} }; std::map&lt;std::string, material&gt; materials{ {"mat_one", material{textures.at("one")}}, {"mat_two", material{textures.at("two")}} }; render_engine e{std::move(textures), std::move(materials)}; 
Unless you are planning on never inserting anything into the textures map again, this would surely move the textures around inside the map once you are inserting new textures into it. Especially once it needs to reallocate. That's one of the reasons why Rust wouldn't allow this. But yeah, even if you plan on never modifying the textures map again, then Rust can't really deal with this very well atm. There's crates like rental, that somewhat try to solve this, but I think Rust should solve this on a language level (Immovable marker trait or something similar).
This is a weakness in the borrow checker- it doesn't understand the concept of an object with a stable address. Even though you can move a `Box`, `Vec`, `HashMap`, etc. without actually invalidating pointers to its contents, Rust doesn't understand that. The typical workaround is to use indices instead of references. This is unfortunate in some situations, but it does also prevent some real problems- for example, inserting and removing elements of a collection *can* invalidate pointers to its elements (including the `HashMap&lt;String, Texture&gt;` you are using, unlike a C++ `unordered_map`). I hope we can find a solution in the future, though, as we start to bump into it more frequently. For example, when working with `Future`s it would be nice to be able to store sibling references, especially as part of a future async/await feature. /u/tomaka17 has fought with it a lot while building a safe Vulkan wrapper.
I RIIR (rewrote it in rust) a tool originally in Ruby. Pass an argument to lex, and it will recommend a bible verse based on the topical bible https://www.openbible.info/ source: (https://github.com/AndyGauge/rust-prayer-lexer)
You're right, it's not very idiomatic to use plain raw pointers. However, this is a weak spot in the borrow checker. It might be possible to come up with a safe abstraction on top of raw pointers, but most of the time this is worked around by replacing references with indices.
That's fair. Do you have any knowledge on how big rust projects like servo or rust itself will organise their data without sibling references? I get that what I'm trying to do isn't rust-friendly at all and am interested in other people's design decisions
I mentioned using indices instead of references- you already have everything in tables, so that wouldn't be a major change for you. As far as I'm aware, rustc does that a lot; I know [cretonne](https://github.com/stoklund/cretonne/) does as well. There are also libraries on crates.io that provide graph data structures implemented this way. I haven't looked at Servo as much but a lot of it actually just integrates with SpiderMonkey's GC. A bit of a special case, but it is an example of writing a new pointer-based abstraction to sort of extend the borrow checker's capabilities. (`Rc` from the standard library is like this as well.)
that sounds like a good idea as far as I can see, save that it'd break compatibility so we can't do it.
And as to some of your specific questions, if you do go the rust direction: AFAIK, the Rust ABI isn't published/fixed, so not really what you want to target. As a general rule, if you're compiling to native code, you will typically end up falling back to the standard C ABI on your platform for linking between languages. In your language you would define some way to call a function using the C calling style for the platform in question, and then in a rust library export a function with that calling convention (https://doc.rust-lang.org/book/ffi.html)
If you want one example, check out [dyon](https://github.com/PistonDevelopers/dyon). Its basically what you are describing you want to try. It was written without an explicitly express purpose beyond exploring new ideas in programming language design, and its written in Rust. Also the rust compiler is written in Rust if that helps.
I just booked my flight from the US and I should be getting in sometime Friday afternoon. I'd be down to hang out with anyone that weekend as well!
IIRC Rust's HashMap is array-based instead of node-based, so its values move when the table reallocates.
&gt; Is possible to have some kind of "eval" in rust? No. &gt; If I have a rust function (like sum(a,b)), or a library (like a log library), and wanna use it from inside my lang (ie FFI), how do the glue? Some of the posters have mentioned using `dlopen()` and `extern` functions to create your FFI (in the style of the JNI). As an alternative, if you don't need *dynamically loaded* FFI modules, you could probably build something more ergonomic using macros and boxed closures. 
Yeah this is a subtle detail of the [`wait` method](https://docs.rs/futures/0.1.13/futures/future/trait.Future.html#method.wait), notably: &gt; This method should only be called when it's guaranteed that the blocking work associated with this future will be completed by another thread. In this case the work that you're blocking on is completed by the thread that's being blocked, so it ends up not working out :( This is something though that we'd very much like to make more ergonomic! You can follow along at https://github.com/alexcrichton/futures-rs/issues/360 for progress.
I'll just note this here in case anyone else finds this. I ran into the same problem and your solution worked. However, I tried making a shortcut to the batch file on my desktop and calling the batch file shortcut (`Desktop\vcvars64.lnk` from `cmd`) and it doesn't work. Something about be executed directly is what does the trick. To save future adventurers the time, it's located at the following path when installed to the default location. "C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Auxiliary\Build\vcvars64.bat"
Couldn't it only store Copy types, if that was the case?
Statically link the rust libraries could work. I loved langs that provide simple and direct packages. &gt; using macros and boxed closures How could this be?
Do you have any more context to this question? There are plenty of reasons to compare any number of languages to each other. The most obvious similarity between Rust and Haskell is their advanced type systems.
Note that implementations of PartialEq [must be transitive](https://doc.rust-lang.org/std/cmp/trait.PartialEq.html). That probably prevents you from implementing it in terms of an approximate match.
Here's a gist of what I am speaking about: http://play.integer32.com/?gist=9dfc1d0e3146942bc6e8b83522f6fa97&amp;version=undefined Unfortunately there's indeed some problems with writing code like this at the moment: 1) 'lifetimes everywhere 2) Additional indirection. Some of the code is able to avoid the problem 2) using slices instead of `&amp;Vec&lt;_&gt;`, using `&amp;str` instead of `&amp;String`, using `&amp;Path` instead of `&amp;PathBuf` etc. However, no such "custom reference types" exist for all types. This is where I thought that `FrozenCollectionHandle&lt;'t&gt;` (maybe with a more concise name, though :P) would be nice to have.
[Image](https://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 4445 times, representing 2.8605% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dggbecv)
Rust "traits" and Haskell "type classes" are very similar; the differences between them have to do with design trade offs and not fundamental differences. This is the big thing the two languages have in common.
There are many ways in which Rust is like a version of C/C++ that mutated when Haskell was injected into its veins. Of course, Rust is still missing many great features of Haskell, but they might still come in time. The lack of functional purity and lazyness will probably always be a major point of divergence though.
(And file bugs for those hiccups!)
Is there a good explanation what happens inside the `target` directory? Besides the resulting binary (`mycrate`), there is a file called `mycrate.d`. What's this? Also, there is dirs like `build`, `deps`, `examples`, `incremental` and `native`. Judging from the contents, `build` contains the artefacts of crates that contain separate build scripts, `deps` contain the artefacts of dependencies, `native` contains non-rust libraries. But is there an in-depth documentation for these? Also, what's the role of the `target` dir vs the cargo dir in caching the artefacts? (IIRC the source files are cached in the cargo dir?)
&gt; Isn't Rc the equivalent of a std::shared_ptr? I'm new at rust myself. However I don't think this is the case. I believe Arc&lt;&gt; is the equivalent of std:shared_ptr whereas Rc&lt;&gt; would be equivalent to your typical game engine / home grown simple reference counted pointer with no thread safety guarantee.
&gt; How could this be? Something like this: fn some_function(arg: i32) { ... } fn main() { let interpreter = Interpreter::new(); interpreter.export_function(function!(some_function(i32) -&gt; ())); // expands to: interpreter.export_function(FunctionSignature::new("some_function", vec![Type::i32], Type::Unit, |args| Type::Unit::from(some_function(args.get_arg(0))))); } Basically, the macro just makes writing the type info livable.
If textures are shared between materials and the RenderEngine, you should definitely be using Rc or Arc. If that doesn't work for you, you should associate an id with each texture and pass that to each material. This second approach is probably more costly because you need to then do a lookup every time you need the texture. The problem with your code is that Rust needs to ensure that every reference is valid no matter what. In C++, you could potentially delete textures and still try to use references to them. Rust knows that that's bad and doesn't let you do that. Smart pointers are a mechanism for sharing data the way you want and achieving memory safety. I know you said in another comment that you didn't want that, but since you really are sharing data here, it makes sense to use a shared pointer (Rc or Arc). 
On the other hand, often the reason something was written the way it was is because people had less experience with the problem domain back then, or technological constraints were different, or it was working around a bug that no longer exists, or so on.
How are debug symbols stored on Mac and on Linux? Inside the binary or in an external file? What are the formats called? Are there multiple formats?
That first paragraph is quote of the week material.
I agree with you that falling back to ref-counting to express this kind of scenario is unfortunate, and it's a trend that can be seen a lot, particularly in the gamedev space. Pushing back against that trend was the motivation behind [rental](https://crates.io/crates/rental). If you have any questions about rental or how it might be applied to your use case, let me know. I'm particularly motivated to help with this type of issue, since I think it's a particular weakness of rust right now.
I'm open to all feedback about how to improve it or make it more clear to users. Feel free to message me here or open an issue on the github repo for specific suggestions. I want it to be as useful as possible. EDIT: Part of the problem is it's really scraping against some language limitations and compiler bugs which need to be addressed before I can lift some limitations. I'll do what I can in the meantime, though.
In my experience, indices are by far the cleanest solution in cases like these. Not every reference needs to be represented by a pointer, and tree-like ownership graphs tend to be easier to reason about than the arbitrary, tangled pointer graphs that abound in languages like C++ and Java. With indices, memory management and mutability restriction become almost trivial, without incurring any of the runtime cost of something like an `Rc&lt;RefCell&lt;...&gt;&gt;`.
I don't have experience with haskell but seen some code. I do however extensively used elm which is based in haskell and the compiler is written in haskell. I can say that elm and rust has some 1:1 equivalents. `Result` in elm ```elm type Result error value = Ok value | Err error ``` is equivalent to `Result` in rust ```rust pub enum Result&lt;T, E&gt; { Ok(T), Err(E), } ``` `Maybe` in elm ```elm type Maybe a = Just a | Nothing ``` is equivalent to `Option` in rust ```rust pub enum Option&lt;T&gt; { None, Some(T), } ``` pattern matching in elm ```elm case maybe of Just xs -&gt; xs Nothing -&gt; [] ``` pattern matching in rust ```rust match option { Some(v) =&gt; v, None =&gt; [] } ``` Destructing tuples in both rust and elm is the same ```elm ( three, four ) = ( 3, 4 ) ``` ```rust ( three, four ) = ( 3, 4 ) ```
Because they both are programming languages.
"naked" references (i.e. `&amp;` and `&amp;mut`) in rust are only meant to be used temporarily and not stored in a struct like you're trying to do. That is why the compiler will always yell at you. The way I think about is: an object can be only owned by one other object. If you want to use that object somewhere else you can give it as a reference but *only* temporarily, e.g. during the scope of a block, never permanently. Also if you lend it away you cannot mutate it (and if you lend a mutable reference you can't lend it to anyone else). The only case you'd want to store a reference inside a struct is if you're doing something equivalent to { let x = ShortLivedClass{ reference: &amp;my_owned_object }; // do stuff with x } // x goes out of scope and the reference is returned anything else besides that, the borrow checker will yell at you. If you really want to store a reference you need to wrap it somewhere, be it a `Box` (if you don't know the size, like a trait), a `Rc` (if ownership is shared), `Arc` (if ownership is shared across threads), `Mutex` (if you can have concurrent access to the object), `Cell`, `RefCell` (if you don't want to expose mutability, like a cache) etc. In general, if you're starting with rust, I would treat every explicit use of lifetimes as an error as it probably means you're doing something wrong. Lifetimes are an advanced feature of the language, like reflection in Java. It has some uses, but most of the time you shouldn't mess with it. Going back to your question, in your case you probably want to wrap textures inside `Rc` or `Arc` (reference counted) so that you're guaranteed that the texture object is not destroyed before every reference to it is released. Something like HashMap&lt;Material, Rc&lt;Texture&gt;&gt; and think about it: how would you guarantee otherwise that the Texture object does not get destroyed before the hash map does?
They're both advanced and difficult programming languages with sophisticated static checkers that take a long time to compile.
Nice Idea. As far as I can see materials doesn't have to be a reference, so the following should work. struct RenderEngine&lt;'a&gt; { textures: &amp; 'a HashMap&lt;String, Texture&gt;, materials: HashMap&lt;String, Material&lt;'a&gt;&gt; } https://gist.github.com/82ec05271bf167540dea4c50aadda8b6 
Hi there, I'm the crazy guy who wrote this post, along with Frunk. I'm very much interested in collaboration, since that makes software more resilient as bugs are found and fixed and suggestions are made. Off the top of my head, I think Frunk might be a good fit if there's transformation of intermediary ASTs involved (e.g. Json AST, such as JsonInt(i64), to XML AST, XMLInt(i64)) anywhere along the transcoding pipeline, but it may not be such a good fit if there is just raw data and type manipulation happening at run time :) I'll need to take some time to delve into Rust's serde libraries to understand more.
Reference counting is overkill for this situation. You're not dynamically adding and removing references to textures, you just load up a bunch of textures once at load time, and share them between the materials that use them.
Here is a page with a nice list of similarities http://science.raphael.poss.name/rust-for-functional-programmers.html
Mostly just writing up my experience with rewriting the code from the ground up for github-rs. Probably knock out an end point or two as well. I'm going to also need to finish up my documentation PRs for rustc at some point.
I actually have library for doing this: https://github.com/WaDelma/bob I haven't published it yet to crates.io and I should propably get on it. Would love some help with it though. It doesn't use `Option` like you have for indicating presence of value, but custom types `O` and `I`. I actually didn't even think to use `Option`. Would that make it have better error messages I wonder.
It's primarily their approach to polymorphism. Rust traits are directly inspired by Haskell typeclasses. Both Rust and Haskell provide that "if it compiles it works" feeling. 
Using rls in vscode means you can not navigate using symbols in a .rs file. So unfortunately its unusable.
Thanks, I'll do exactly that.
Yes! I'm using it already and it's great.
As far as I understand this problem, I think that `materials` and `textures` should be separated from `RenderEngine`. Assumptions: * you load the resources at the start of application * you don't modify resources after the start The name "Render engine" suggests that it only does rendering, not loading, etc. So it makes sense to me that it should take immutable references to textures and materials. What if you want to change (some) resources anyway? I'd suggest using `Cow` so you can clone-on write your resource and drop it when not needed anymore.
/u/nasa42 ?
That's a tricky problem. Yes, struct should be equal when all their fields are equal. But when we talking about floats such comparison became useless. If I've implement custom PartialEq with `float-cmp` crate in my own app - it's not a big deal. But what about libraries? To be more specific: I need this in SVG processing library. In SVG all the numbers are f64. And I'm constantly comparing them. It's just simpler to write `==` and get a valid result that use custom methods like `fuzzy_eq`.
I'm Chinese who is hunting for rusty jobs, finallyI found two ([0](https://www.lagou.com/jobs/2904467.html), [1](https://www.lagou.com/jobs/2823070.html)), but they didn't welcome me. I hope it will help you somehow. 
If you are just storing stuff into a `Vec`, and only appending (never deleting) like probably the OP is doing, I doubt the performance impact of `*(ptr + index)` vs `*ptr` is even measurable (most x86 CPUs have special logic for this). Also in this particular case, indices are oblivious to reallocations of the vector, which is an advantage vs pointers. On the other hand, if the OP wants to resort the vectors or delete elements updating all those indices is going to be FUN. In this case the OP might be better having some kind of arena, and using RCs into the arena all over the place.
They are both innovative languages and that tends to attract the same kinds of people looking for something to challenge the way they think. They will both teach you very different things and they each have their strengths and weaknesses. 
&gt; struct field reordering, including optimization fuel (yay!) This is a really cool feature, but I fear we might see some performance degradation in combination with custom derive for larger structures. The problem is that custom derive uses the order of the fields in the source while the field order in memory no longer matches this. This can cause memory access to cache lines to be non-linear and thus more expensive as the cpu won't be prefetching it correctly. You will also have to opt-out of the new layout when it matters when you want to increase the chance that different sized fields share a cacheline, where they originally would because they were put next to eachother in the definition. Only practice will tell how much of an issue this turns out to be. It might be that the memory savings and thus cache pressure reduction might be a net win in almost all cases.
Okay, found my answer, and managed to make a nice flamegraph! I hope this helps other people that are trying to make flamegraphs on MacOS: http://stackoverflow.com/a/43491361/1106456 /u/carols10cents, maybe you could make an update to your blog post[1] about making flamegraphs that dtrace is a viable way of doing this on MacOS now! [1] http://carol-nichols.com/2015/12/09/rust-profiling-on-osx-cpu-time/
If you modify the shortcut so that the target is `%ComSpec% /K "X:\foo\vcvars64.bat"` rather than `"X:\foo\vcvars64.bat"` then it should behave as you wanted it to.
Inside the binary. It's called a symbol table, you can read it using `readelf --syms ./mybinary`. https://sourceware.org/gdb/wiki/How%20gdb%20loads%20symbol%20files
Or at the very least, a GitHub issue or other central place to link people to when this comes up. Something to note that the Rust team is aware of this limitation of the borrow checker, and to discuss ideas and progress on how to deal with it better.
It's a system-global counter that decreases on every optimization step. When it goes down to 0 no further optimization is done. This technique is [very old](http://blog.ezyang.com/2011/06/debugging-compilers-with-optimization-fuel/) but surprisingly effective at catching optimization bugs, since optimization order tends to be very deterministic.
I think the reasons to avoid Rc can be the following: 1. performance (increments/decrements of the counter; the impact depends on the usage pattern, of course) 2. semantics (the ownership here is not shared. It can lead to wrong expectations of a reader about the code) 3. readability (cluttered code, besides the wrong semantics) 4. ease of writing the program (this applies only if there is a better way of expressing what the author wants, of course)
Indices are not entirely safe either; if you delete elements from a collection then an index could become out of bounds.
They are *memory safe* though. That's the key point of contrast. Out of bounds is a runtime error that probably indicates a bug. This is "safe" according to Rust's definition of safety.
All rust compilers are already cross compilers. What you usually need is a cross-compiled libcore/libstd. Explaining more about why Xargo doesn't help would be useful here; if you're using it to build the OS already, I'm not sure why it wouldn't work for userland.
[removed]
Very cool idea!
&gt; I need to create a cross compiler `rustc` is already a cross compiler. To target a new system / architecture you only have to create a new target definition. Or do you mean cross compiling `rustc` itself to a custom target? &gt; Xargo doesn't seem help. :/ Could you elaborate on what isn't working? I can only guess with the few details given but here it goes: Are you trying to compile `std` for your custom target but `std` doesn't compile because of cfg variables / missing libc stuff / missing unwinding implementation (other targets implement this in C)? If that's the case then you can fork `std`, do your changes and then have Xargo compile that custom `std` as ... `std`. [steed](https://github.com/japaric/steed) may give you an idea of how to do that as it's a custom std re-implementation. This [Xargo.toml](https://github.com/japaric/steed/blob/a8d611a48b2cb491a7a79bebea14810dc7201088/Xargo.std.toml) is what you would use to build an application again a custom `std`. &gt; The request is, there are some useful resources to add support to a new target on Rust? Not many. This [old comment](https://www.reddit.com/r/rust/comments/5ag60z/how_do_i_bootstrap_rust_to_crosscompile_for_a_new/d9gdjwf/) of mine may be the most complete resource at the moment.
Can you elaborate on your is.gd link? There's no assert to uncomment, and when I wrap foo() in one it passes fine.
The problem is, Xargo doesn't work fine when we use rustc directly (I don't know why), and the other reason is that some syscall present on the libstd aren't implemented yet and some other will work in a different way. We admit that we are noobs in this world. So any clarification or help would be welcome.
I agree with you. After some thinking it looks like that for my case it's better to just remove PartialEq completely and implement FuzzyEq trait for a specific structs. It will make code a bit verbose, but more logically correct.
The definition of memory safety is relative to a language, so you could define the problem out of existence by inventing a language in which memory is specified to be an array of bytes, and so any program would be memory safe. That is a bit like what we're doing when we use indices. It better, of course, because it is local and there's still run time checking, but it does feel like giving up.
Though not on topic, I just would like to note that I've read all of you articles on Rust in your blog, and they are profoundly epic.
Elm's type system was very much inspired by Haskell. The original implementation of Elm was in Haskell. Rust's traits, enums, and pattern matching are directly inspired by Haskell as well. 
What's the difference? I can create an infinite iterator in Rust and it won't eat up all of my memory, that seems pretty lazy.
Thanks I had some connections problem, I'll go with it, it'll be fine I think. Really thanks a lot !!!
All I really wanted to see was `global_asm!()` :-D Now I can use it in rusl!
Huh. Probably a mistake, you shouldn't need `--git` (feel free to use it though, it shouldn't be any worse than not using it)
Sorry about that! Here's a much better example: https://is.gd/Lq5qp5 notice how the equality fails, even though the epsilon check succeeds and mathematically the two are the same.
What default value does the counter starts at? Is it customizable using Command line flag?
Yes, it is customizable. The users can also make sure that the problem lies in the optimization step by setting the fuel to 0 (in principle any value should work for safe codes).
&gt; I doubt the performance impact of `*(ptr + index)` vs `*ptr` is even measurable The main reason for this is that compilers know that `*ptr` is faster than `*(ptr + index)` and try to optimize accordingly.
Ok, thanks for the response. Maybe Xargo has more potential than I thought. I had started yesterday adapting libc and libstd to support my target system (the target triple would be `x86_64-unknown-pulsar`). Correct me if I'm wrong. The Xargo.toml that you had mentioned looks interesting, seems like I can replace any lib on the Rust core, is that it? So, Am I able to compile programs to execute on my OS using only Xargo with a custom libstd? To finish this set of questions. Can I use things like this without any problem? ``` @xargo rustc --manifest-path $&lt; -- --target x86_64-unknown-pulsar -o $@ ``` I'm starting to think that the problem is mine. For not having been able to compile programs in other directories using Xargo. It said my target did not exist :( Sorry for my ignorance :(
What is needed in order to compile a crate with a custom libc? For instance, I want to apply a patch to musl. Is it achieveable with xargo?
See ya there! Thanks /u/kibwen for picking up the mantle to organize this. :-)
*(ptr + index) can be lowered into a complex addressing mode instruction (e.g. lea on x86) - I really wouldn't worry about this aspect. The bigger issue is range checks.
WOOOOOOOOOO i will take a look at this later!!! awesome!!!
There are a *lot* of differences. For one, lazy IO means you can't do main = do file &lt;- readFile "text.txt" let fileEdited = file ++ "edited by me" writeFile "text.txt" Admittedly lazy IO is probably a bad thing, but this sort of stuff appears frequently. 
Thank you for so generously characterizing the cruel, gruesome takeover that so accurately portends my coming reign of blood. :) (Okay fine so maybe Niko begged me to do it)
I actually think they attract the same sets of people partly because of their differences. Rust for things where manual memory management is important, Haskell for things where it is not. 
There isn't no documentation for it yet; I will end up writing some, but to be clear, none of that, in my understanding, is considered stable or to be relied upon. Yes, source is cached gobally, compiled output is cached locally.
I'm still a noob at rust, but wouldn't something like this work? impl RenderEngine { fn new() -&gt; RenderEngine { let textures = TextureCollection::new(...); let mut ret = RenderEngine { textures: textures, materials: MaterialCollection::default() }; ret.materials = MaterialCollection::new(..., &amp;ret.textures); ret } } ...and then the compiler will optimize away the ::default call after compilation, assuming you implement it without side-effects. Something that should be remembered is that Rust's optimizer can be several orders of magnitude smarter than C++'s optimizer (at least for memory and function calls), because of explicit lifetimes and explicit side-effects.
A oneshot receiver is a future. You're adding indirection to no effect.
But the laziness stems from something very different, which is why I wouldn't compare these parts of the languages at all.
And Rust's error handling with `Option` and `Result`, which remind the user of Monads. There are other high-level similarities like memory safety and the typing system as well, but they're far from identical.
Same question. Considering that both Haskell and Rust require a lot of time to get into, I am not sure which I should start playing with.
Too bad it only supports Rust `1.10.0`, which was released on 2016-07-07. The latest version is `1.16.0`, which was released 2017-03-16.
You can skip kata. You can also contribute your own.
Oh hi, I have written some words on the topic in general that might be helpful. http://csclub.uwaterloo.ca/~tbelaire/blog/posts/rust-gba-redux.html 
&gt; You're going to have to help me understand why you think this is important. Rust has a notion of safety that is non-trivial, so statements like "indexing a slice isn't entirely safe" are meaningfully wrong/misleading. If by safe you mean "memory safe in the sense of Rust", which I did not and I explained what I meant by it. The reason the distinction is important is that using indices entirely sidesteps Rusts borrow checking features, and instead relies on run time checking. It also opens up the possibility of other bugs, for instance using an index for collection A that was supposed to point into collection B, which does not happen with references. I do agree that it is often the best workaround.
It's hard to rate a programming language's difficulty level because usually it's the case that the tricky things in the language are there to make programming in some sense easier... I think part of why Haskell, Rust, and C++ are perceived as "difficult" is that (1) they have many features to learn about and they're slowly expanding; and (2) they hit you in the face with compile-time errors that you have to really think to fix, because there's no compile-time debugger.
Very cool! Is this the work of people at Mozilla who are entirely separate from the Servo team? I'm always amused at how promptly Servo implements the shiny new web things while still plugging along at the old ones. :)
I'm biased. I know more Haskell. My work is mostly in the JVM, where I have to pay for a GC anyway. I literally went though the Rust tutorial and book a couple of weekends ago. But, both [John Carmack](http://functionaltalks.org/2013/08/26/john-carmack-thoughts-on-haskell/) and [Eric S. Raymond](http://esr.ibiblio.org/?p=1796) recommend learning Haskell in order to [make you a better programmer](http://dubhrosa.blogspot.co.uk/2012/12/lessons-learning-haskell.html), even if you never write it. I know quite a few languages, and learning Haskell made the biggest change in how I approach coding. Ultimately, it depends on your goals, though. TIOBE to a good trailing indicator for what you need to learn to get hired, and C/Java have been strong there (and in other similar lists) for quite a while even with all their troubles. But, if you are just exploring the whole idea space of programming languages, Haskell is a remarkably practical language for how close to the edge it is, and I can recommend it for that purpose.
The macro documentation is lacking :-( Most of the shorthand is listed on the macro documentation itself, but regrettably not on each item/method's individual documentation. Perhaps the one thing I should make prominent is that you can "fall back" to the builder methods inside the macro, which would probably help the discoverability some. Of course this someone in the stack of a thousand other things as well :-)
Indices have range checks, but when the alternative is `Rc` I'm sure the range checks are cheaper than the cache misses, allocation, refcount bookkeeping, etc.
Right, Rc is likely worse. The ideal would be to not use Rc or indices (i.e. make refs work for this type of case) :).
Now if only Kattis would get support for it.
&gt; I have to implement n choose k in Rust? Really disappointing This is tricky if you want to avoid overflows.
If you come from another imperative language, Rust will take less time than Haskell.
You don't have to disable the optimisation; you can also break the fields out into a separate struct, which may makes sense anyway if they're being accessed together a lot.
Can anyone enlighten me on how the performance of Servo is for this stuff?
I got the same one. Started implementing it, then realised the testcase required you to use a bignum implementation internally for n choose k. And I can't figure out how to use a bignum crate. so.. too bad, I guess?
I think there is a case for a common specialisation of Rc where there are 0 or 1 strong references to the object and any number of weak references. This means that there would be only one owner, and the strong references form a tree, meaning no ref loops causing memory to leak. It seems straightforward to copy+adapt the Rc implementation to do this, but I wonder whether a standard implementation would be better. Possible names: `Wox&lt;T&gt;` (weak-refable Box) or `Rb&lt;T&gt;` (Refable Box).
&gt; "fall back" to the builder methods inside the macro That would really be very handy! In this case, do the thousand other things first :)
Maybe Rust doesn't run on thunks the same way Haskell does, but a Haskell-like construction like `iter::repeat(10).take(5).fold(...)` is still lazy in the way that counts.
Thanks for the feedback, we'll look at getting the upgrade in there!
How does one handle `Ctrl-C` in Rust in a cross-platform manner?
&gt; but after signing up, I have to implement n choose k in Rust? Really disappointing Total bait &amp; switch. I want to learn rust. Not implement algorithms or learn how to program.
Out of memory, I think that it's "cargo run --example ropetoy", but I'm not 100% sure. As for debugging, make sure you have lldb installed
I got this to work, but then my "format code" and "format selection" context menu items disappeared. Is that a known issue, or should I file something for it?
Check out these issues on the GitHub repo: https://github.com/colin-kiegel/rust-derive-builder/issues/56 https://github.com/colin-kiegel/rust-derive-builder/issues/33 There's interest in pursuing that, but it'd be opt-in so that people who needed the decide-at-runtime behavior could still get that.
Hackerrank approach seems much smarter to me... Drawbacks of your approach is obvious, I am genuinely wondering what kind of benefits you get from that?
Just curious how different are the versions of rust from each other. I understand you don't normally put out a new release until ~.9or so but not much more. 
Well, all programs are about input / output... A program that doesn't produce anything is just a memory/CPU hog... It makes sense to me that hackerrank only requirement is that those input and outputs can be serialize / deserialize to text... 
Every six weeks, a new 'y' (as in x.y.z) release comes out. They're still x=1, so backwards compatible, but they often have a number of new features. My favorite ones since then: 1. cdylib (not applicable for this site though) 2. MIR (an internal change but still super huge) 3. New error messages 4. Cargo workspaces (not a big deal here) 5. `?` operator: this one is huge 6. custom derive in stable! Super super big 7. cargo check (not a big deal here) and tons of new APIs in the standard library. Those and `?` would be the largest changes for a site like this.
&gt;Final Comment Period &gt;[disposition: merge] [extend ? to operate over other types.](https://github.com/rust-lang/rfcs/pull/1859) Just so I understand this right - does this mean the implementation will be worked on according to the current state of the linked document in the top comment of the issue, or could there be additions somewhere in the comments (I've only skimped them, there's a lot of discussion) that are also taken into account in the initial implementation?
The trouble is that you're creating a local variable `secondGen` (which is stack allocated) inside `New` and returning a struct that borrows from it. When the function returns, the local variable will be deallocated and the returned value would have a dangling pointer. The borrow checker prevents that. You would need to allocate `secondGen` outside `New` and pass it as a (borrowed) parameter to `New`. Alternatively, change `child: Option&lt;&amp;ChildStruct&gt;` to `child: Option&lt;Box&lt;ChildStruct&gt;&gt;`, so that the child is heap allocated. Then you would do let secondGen = Box::new(ChildStruct{ child: None, title: "hi1".to_string() });`
It's not that; it's that they are older than the RFC process, so never hadn't a strict design, they still have lots of bugs, and because we don't have box syntax, box patterns don't make a ton of sense. We'll get there.
sudo apt-get install build-essential (You're missing some important stuff, I am 99% sure this will fix it)
It's been a long time since my last update - the tl;dr is I got stuck on thinking about Rust lifetime semantics interacting with runtime memory management, then the entire project got swapped out of my brain by a family vacation. Trying to regain momentum! Also, I can't claim to be anything more than a Rust and programming languages novice. Any input is truly gratefully received!
For me the problem with Haskell was that making things run fast is extremely hard and not well documented by beginner books...just taking a sum of squares of numbers from 1 to 1 billion needs a lot of understanding of Haskell internals to get to the optimal version. With C and Rust it's easy to do.. and of course with Rayon, in Rust it can be done parallely easily. Implementig quick sort in Haskell performantly..I wouldn't even try.
On that note, any chance of upgrading Clang, too (for C++)? :-D 3.6.0 is getting a bit long in the tooth...
"Lesser weevil"?
You might also want to consider using cargo to build your application as you add dependent crates and complexity increases. 
&gt; seems like I can replace any lib on the Rust core, is that it? Effectively you can replace / add any crate in / to the std facade, yes. &gt; Am I able to compile programs to execute on my OS using only Xargo with a custom libstd? Probably, if you get enough libstd working for your target. &gt; Can I use things like this without any problem? Not really. The dependencies of a crate are specified in the Cargo.toml file. Xargo.toml lets you specify which crates to compile and put in the sysroot, which is where std is expected to live, but the dependency graph of each of those crates is respected and compiled in turn. &gt; For not having been able to compile programs in other directories using Xargo. It said my target did not exist :( This is how `rustc` works. By default, it only looks for the target specification file in the current directory. You can expand this search path by setting the `RUST_TARGET_PATH` variable to point to the directory where the target file is.
Which can be circumvented rather easily.
Cool! I thought that it was because of performance issues, I think Rust should have box syntax too =p (even though is rarely used).
Thanks, this worked. My background is in java and it's the only language I know so far, so I've decided to branch out and give Rust a shot. From what I've researched just now, build-essential is also neccessary to compile in other languages. Why is that? Why isn't rustc enough to compile Rust? I also discovered [this thread](https://www.reddit.com/r/rust/comments/429eqr/upgrading_from_15_to_16_or_18_breaks_linking/) that had the same error as mine and the user solved this by installing gcc-multilib and lib32z1-dev. Do I need these as well or are these just different packages that do the same thing as build-essential?
If I want to pipe data from child process to another in streaming fashion, (I'm using processes launched with `std::process::Command`) I expect that I can use `std::io::copy(ps_1_stdout, ps_2_stdin)`. In the docs says that it keeps copying until the reader sends an EOF, and I expected that EOF will be send after the process 1 ends. However, the `copy()` hangs indefinitely. What I'm doing wrong?
Not all games need OpenGL.
That just means that 50% of any given puzzle is a bunch of cruft unrelated to the problem at hand.
[answer] No, I will not (be able to), but I would accept a PR and publish a patch release. Please comment with the name of your crate(s) so people can volunteer to help.
[answer] No If you're willing to comment with the reason and name of your crate, it'd be great to know why.
The `Command` has `Stdio::piped()` stdin and stdiout. But. This occured to me just a moment ago: from docs: The stdin handle to the child process, if any, will be closed before waiting. This helps avoid deadlock: it ensures that the child does not block waiting for input from the parent, while the parent waits for the child to exit. Maybe the process is still waiting for more input, so it is hanging itself? But how can I close the stdin pipe to it? Edit: If the output isn't piped, the stdout of the first command is directly printed to terminal. If it is piped, any attempts to read the stdout (even a few bytes) hangs.
I didn't have any bignum problems, just u64 worked fine.
I think we're talking about different katas (the types in this one don't match). I meant one where you're choosing the correct number of color combinations 
Laziness has been the defining feature of Haskell. Have a look at [A History of Haskell: Being Lazy with Class](http://haskell.cs.yale.edu/wp-content/uploads/2011/02/history.pdf), which even says it in its name.
If you want you can count how many Symbol references you've given out and if the arena is destroyed while there are still Symbol references you panic. Essentially move the lifetime check to runtime. If this is not acceptable, the Rust way is to mark the offending functions as `unsafe`. Yes it's awkward but Safe Rust comes with very serious guarantees you really shouldn't violate. (Such as the guarantee that no matter what inputs you throw at it, the result will not violate Rusts' safety guarantees such as memory safety, which isn't the case here if I understand correctly) A small note: The only reason to accept a `&amp;String` as an argument type is if you MUST know its capacity which is pretty rare. It's better to accept `&amp;str` in the majority of cases.
The article is well written, and in Rust I miss some Ada features (ranged integers, typed array indexes, contracts, static and dynamic predicates on types, annotations to read/write global/outer variables, and perhaps more), and I like the idea of formally proving critical parts of a program (despite perhaps SPARK is not the best way to do it). &gt; AdaCore has a history of scarce interactions with the communities [...] That facade is also breaking down, with lots of development now done on GitHub and several other community-friendly initiatives being started. Let's replace that "lots of development" with some numbers. &gt; There’s little doubt SPARK has a bright future ahead of it, too. Can you even compare the "magnitude" of the two futures? &gt; The compiler element of the tool is mostly maintained by a software vendor called AdaCore (of which I happen to be part of) This article rubs me in the wrong way because it sounds a bit like a way to advertise Ada/SPARK piggybacking on Rust growth, while I like the ideas behind Ada/SPARK and I'd like them to stand on their own merits. If you want high integrity software you also need integrity in the engineers and programmers.
I have been hard at work rewriting the renderer for [Amethyst](https://github.com/amethyst/amethyst), cleaning up the API, creating lots of builder wrappers, and silently thanking the gods of Rayon for parallel iterators. This week, I hope to bring the new renderer up to feature parity with the current system as well as landing the new physically based material system I'm working on. This will be a widely breaking change, but certainly for the better. I hope I'll have a PR ready sometime before the weekend!
The standard library (I think) links to some C libraries (the bunch of `lxxx` stuff you see where `-lpthread` means it's trying to link to the `pthread` library. See https://stackoverflow.com/questions/3322911/what-do-linkers-do for a description about what linkers do.
This sounds not like a bad idea. I will check out http://haskellbook.com/ and dabble a bit. Let's see. Maybe I end up with F# ;)
Thanks for the comments :)
How many apps use that spec? All the common ones I know of normally just use their own `~/.&lt;whatever&gt;/` directory, or a single file.
Though a bit verbose, I like the explicitness of your suggestion.
If you do this, you should *never* run `rustup self uninstall` - it will delete other programs in your `.local/bin` folder, and uninstallation will not remove everything that should be removed correctly.
A lot of applications follow this spec. The amount of hidden files and directories at the root of my homedir is now about a third of what it was a few years ago. The biggest benefit for me is that I don't have to walk through a lot of separate application specific directories to exclude stuff that I don't want in my backup. So if rust would start using ~/.cache it would already be a big boon for me.
Another important case are comparisons to zero.
Performance and stability are more vital to VR than they are to most, especially when dealing with mobile devices. As far as I'm aware, Mozilla originally backed Rust because they needed something to fill the performance gap, so understandably they're using it for VR as well as web rendering.
Also worth mentioning: besides the possible performance improvement, having more consistent performance is also important (perhaps even more so). When using loop + match I tend to get inconsistent branch miss statistics. Sometimes 0.5% of the branches are missed, sometimes this is 0.7% (resulting in performance that is measurable worse). 
cc /u/stedolan, the author.
I don't think so. Looking at my `~`... I see Ansible, AWS, CUPS, DBus, Gem, Gimp, gkrellm2, gnome, gnupg, gstreamer-0.10, ipython, Java, jython, kde4, NPM, pip, svn, terraform, tox, travis, unison, vagrant, vim, w3m, yarn, zoom, asoundrc, boto, docker, gmrun, less, bash, MySQL, PostgreSQL, pypi, Python, s3, Vault, X, rclone, colordiff, gist, SQLite, ... Some of those are old, but not all of them. One wonders what the marginal cost of adding one more program to that list is.
I'm not a company, but just started this as part of my upstream GStreamer time: https://github.com/ford-prefect/gst-plugin-s3
https://github.com/rust-lang/rfcs/pull/1888 would help
As I don't want to add reference counting, I'll have to be liberal with unsafe. Thanks for the tip on using `&amp;str`, that makes sense.
&gt; I can say that Rust is an excellent choice for writing a programming language ... if you actually need the control Rust offers. This. As /u/__desrever__ said, ML-y languages are nice to build compilers in. In this regard, Rust is a pretty ML-y language. Rust's advantages over F# are the ability to micromange runtime memory behavior, and easier access to native/C FFI. F#'s advantages over Rust are not needing to micromanage runtime memory behavior, and easier access to .NET FFI, and possibly the REPL.
Actually, the idea of a baby LLVM sort of project is kind of compelling. A nice portable IR and a library to perform some optimizations and translate it to assembly, while being small enough that unlike LLVM a user can actually understand the whole thing.
It's uncharitable of you to suggest that the author lacks integrity. I don't see any sign of that here. There have been many past discussions (even on this subreddit) comparing and contrasting Rust and SPARK. Many of us have an interest in building high-integrity software, and both of these languages have unique features that help developers achieve that goal. The author was very careful to make balanced, objective claims about both languages. If anything, this is a promotional piece for Rust, targeted at the high-integrity embedded developer community, and he's done the Rust community a service by writing it.
Assuming OP is following [the book](https://doc.rust-lang.org/nightly/book/second-edition/ch01-02-hello-world.html), we start with rustc to compile hello world and then immediately switch to cargo for the rest of the book. Also using cargo would not have solved their issue here.
Yeah, I understand that. Just pointing it out. I didn't realise the hello world example was introduced via `rustc` first.
&gt; When you say "I", do you mean you as a distro packager or you as an end user? That distinction is irrelevant in this case given neither Apple nor myself opted to follow it. Though I meant it as packager fist and user second: if the packager of my distro/system decided not to use BDS I can still use it as an end-user (for non-distro software), but if the packager did decide to follow BDS the BDS is essentially part of the distro's directory layout. &gt; In what way are assertions being foisted upon your systems? Because you can't opt in or out of XDG-BDS as a user or a distribution creator (aside from patching that support out of software you install beforehand). As noted by /u/auchjemand if the spec'd environment keys are not present the spec asserts a bunch of default directories instead.
Yep, currently the entire `~/.cargo` directory is considered "owned" by the rustup installation, so this behaviour is by design.
&gt; Then again it's hardly surprising considering Lennard was one of the authors. I dislike pulseaudio and systemd as much as any hater, however, you're getting your very understandable dislike of Lennart get the better of you here. Did you know that Hitler loved dogs, mind-blowing, isn't it? Could it then be that occasionally also Lennart might be doing something right? &gt; They're not tidying up jack shit, they're just foisting their assumptions onto my system Can you point me to the place in POSIX where it says that applications SHALL or MUST put their stuff into `~/.foo`? It's actually just tradition, a tradition [based on a bug](https://plus.google.com/+RobPikeTheHuman/posts/R58WgWwN9jp). Read it. As far as arguments by authority are concerned having Rob Pike slam the practice is as good as it gets. &gt; And now I have both a gazilion dotfiles in $HOME where I know to find them Have you ever tried to clean those out? The trouble is that many programs have more than one file there and it's not at all readily apparent which belong together. `~/.config/foo` is much better in this regard: Just delete the whole directory. &gt; an other set in ~/Library/Application Support where the system actually wants them to be. That's a disgustingly perverse name but rejoice! XDG has covered you: Just set the bloody environment variables. Where else but from such variables would applications know from where to put their stuff? You can easily move those things you have in `~/.config` for the simple reason that (properly) XDG-compliant apps will not just drop things there, they will readily accommodate to your verbosity kink. All those stray dot files in `$HOME` will not do that as easily, you will, as you so astutely observed, have to patch them. To what? XDG compliance, of course, because you've already set the env variable... Something something "Lennart forces everyone to use his stuff". Blame the man where he crowbared himself in, not where even suckless will readily fall in line because things are eminently sensible.
Rust doesn't really have much in the way of GUI frameworks yet, especially on mobile. For desktops, there is [Conrod](https://github.com/PistonDevelopers/conrod) (heavily work in progress, but stabilizing) and [Relm](https://github.com/antoyo/relm) (even more heavily work in progress). There's also bindings for [GTK3](https://github.com/gtk-rs/gtk) and [dear imgui](https://github.com/Gekkio/imgui-rs).
And I think this is actually one of the instances where it's sane to not use XDG: Where you've got a top-level directory that isn't readily split into config/cache. Pretty much any language-specific package manager falls into the same category as they're all managing a `bin` directory which isn't really "cache", and have little if any actual configuration (that's in the packages, not the manager). FWIW, cabal does the exact same (though that might be circular reasoning: I think cargo owes a lot of its design to cabal... a bit cleaned up, Haskell installations also have `~/.ghc`). But even if there's no such rationale I will forgive apps if they create a dot-thing in `$HOME`... iff it is a directory. For the simple reason that having one app add two files there leads to an uncleanable home directory, and if you only need one file right now you should already anticipate the second and put your single file in a directory of its own.
Slightly off-topic, but is there a glossary of symbols anywhere such that I could decipher the following? f : ∀α β. α → β → {foo : α, bar : β} I've always been interested in these types of papers, but such dense and foreign notation makes it difficult.
As far as I know the Pijul guys didn't have any effect on the direction of the language. I was talking about how prerelease, Rust transformed from it's anachronistic Go-like state to something closer to it's current form when a bunch of Haskell devs joined the Rust core team. I can't find the video, but there's a talk on the history of Rust by another former team member and he mentions that. 
Exercism.io has Rust also and I quite liked the challenges there.
But `cargo install` can install all manner of things that aren't managed by rustup, and shouldn't be removed just because rustup is uninstalled; ripgrep is a good example. rustup doesn't really own the rest of `~/.cargo` either: it's quite reasonable to uninstall rustup and keep Cargo's config and cache if you have Cargo installed from another source, like a distro package.
&gt; Because you can't opt in or out of XDG-BDS as a user or a distribution creator (aside from patching that support out of software you install beforehand) This is, essentially, the job of a distribution creator, is it not? For instance, software tends to install to /usr/local, have manpages that refer to /usr/local/bin, have routines that read config from /usr/local/etc, and so forth. A distribution creator needs to patch all of those. Sometimes if they're using a common set of code (e.g., GNU autotools) for these defaults, it's easy to patch; sometimes it's hard to patch, and the program author is entirely within their rights to hard-code /usr/local in the source. Is there a reason the basedir spec is different?
I appreciate the answer! Having done my fair share of FP, the structure of the snippet made sense, but the random symbols thrown in make it completely non-sensical. What's more is that there's no way to google the meaning of a single character in the context it's used here. Are these things one typically learns as part of a CS degree or a specialization thereof? I know I'm coming off as a bit ranty here, but without any sort of glossary or nice way of searching for meaning, this seems like academic tribal knowledge.
Ah ok, so we need to Box things.
I just came across [this](https://github.com/sciter-sdk/rust-sciter) framework (free to use, not open source), has anyone here tried it?
You can go [here](https://en.wikipedia.org/wiki/List_of_mathematical_symbols) and Ctrl+F for most of them.
A function call table would have close to similar performance: make an array of handlers, and use the op to index into the correct handler. Ultimately, using any table will have issues with prediction, since the processor can't learn a single branch point, even with the branch history predictor. To be more friendly to this, you could instead carefully write a dispatcher that generates a sequence of direct CALL machine ops, wrap that up according to the calling convention, and execute that. It's harder, but it would ensure all jump targets are known in the instruction stream, eliminating the kind of branch prediction woes you're seeing. This can't be done with safety, though. 
Or use any data structure that boxes things under the hood, like a Vec, HashMap, or Rc.
I was actually using this setup before. Every instruction had a function to handle it, and pointers to these functions were stored in a static array which was accessed based on the current instruction. This however was performing quite badly compared to the current loop + match approach (we're talking about potentially millions of function calls). Another problem with this approach is that it's hard for these handlers to influence the interpreter loop. For example, to force it to restart a function would have to return some value which you'd then have to check. I used to do this (https://github.com/YorickPeterse/inko/blob/c2ff526d2d31d7585bd920dca2185a3b5bf7142d/vm/src/vm/machine.rs#L151-L170), but it added quite a lot of overhead (on top of the function call overhead).
Correct, Haswell is supposed to have a pretty decent branch predictor. While I am using a Haswell chip the performance is not quite as good as I'd like, and I'd prefer something that's more consistent across different hardware setups.
You need to give `bar` a stable address. The easiest way to do that is to box it: https://is.gd/a4jEYm --- Without this, your `baz` pointer is a pointer to `bar` on the stack inside of `new`, which evaporates as soon as `new` returns. :-)
"You" meaning the upstream author? I think it's entirely reasonable for an upstream author to hard-code the path to a config file. Where is it going to figure out the right path from, some other config file? It should probably be configurable via a compile-time flag, but, again, the distributor needs to set that flag appropriately. And in every packaging system I've worked with, it's equally easy to write a patch that changes some constants and to write a build script that defines some constants. (Often the way to do the latter is to write a patch to the Makefile to set `CFLAGS=-DFOO=bar` anyway.) If the argument is "Software that implements the basedir spec should use compile-time flags or `std::env!` or equivalent to allow overriding the paths hard-coded in the basedir spec without patching the code," then, yes, that seems reasonable but not obligatory. (If "you" means the distributor, then, again, writing _and_ applying their patch is their job. The package is not correctly packaged if it installs to /usr/local.)
Cool, thank you! I knew that was what was wrong, but I didn't realize boxing it would provide a stable address. Which... Ok, in retrospect, I guess that makes sense, but, then again, like I said, none of this makes sense to me. For reference, here is my mental model of a [raw pointer](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/English_pointer.jpg/1200px-English_pointer.jpg). :) Edit: After some more tinkering, I find the box is not necessary with strings and vectors. This is because the "String" or "Vec" that moves is in fact just a pointer to data already on the heap, which has a stable address. I imagine. That's neat.
I think just stop at the IR, and let users translate it to assembly, or .NET bytecode or js or else. 
[answer] yes Although I currently have no published crates. Updating unpublished ones before publishing will be prioritized. 
You can also do so generically: enum Foo&lt;T&gt; { Bar(T) } transform `T` into terminating type later on like so: let foo: Foo&lt;Foo&lt;Foo&lt;()&gt;&gt;&gt; = Foo::Bar(Foo::Bar(Foo::Bar( () ))); this how function composition works with iterators: use std::iter::Take; use std::ops::Range; let iter: Take&lt;Take&lt;Take&lt;Range&lt;u32&gt;&gt;&gt;&gt; = (1..10).take(3).take(3).take(3); It's not a recursive enum, because you don't need an enum if you're programming generically. If you wanted to make methods to build that other type you could easily do so like this: fn foo() -&gt; Foo&lt;()&gt; { Foo::Bar(()) } impl&lt;T&gt; Foo&lt;T&gt; { fn bar(self) -&gt; Foo&lt;Self&gt; { Foo::Bar(self) } } Which would result in this type: let foo: Foo&lt;Foo&lt;Foo&lt;()&gt;&gt;&gt; = foo().bar().bar(); 
So I started trying old nightlies to see, when this was caused, and the first nightly that broke is nightly-2017-04-07 (day before still works). Looking at the different linking command, I think I found the issue: I have to link the shared libraries /after/ I link any static libraries. So, again linking command looks like this: cc -Wl,--as-needed -Wl,-z,noexecstack -m64 ...:(a couple -L) -Wl,--gc-sections -pie -nodefaultlibs ...:(a couple more -L) -Wl,-Bdynamic -Wl,--no-whole-archive -l stdc++ -l luajit-5.1 -l octave -l octinterp -Wl,-Bstatic -Wl,--whole-archive -l octave2lua -Wl,-Bstatic -Wl,--whole-archive -l c2rust -Wl,dynamic --no-whole-archive ...:(multiple rlibs: liblazy_static, libbyteorder, libstd, librand, ...) -Wl,-Bdynamic -l dl -l rt ... -l util Actually, -l stdc++ is linked in a slightly different place in newer versions, but in older versions it was coupled with other [link(name=...)] libraries. It is not important here (maybe it is, if you are searching which piece of code is responsible for this). octave2lua and c2rust on the other hand are C++ libraries, that I use in Rust/Luajit with their FFI capabilities. They are built in build.rs via gcc package. This command fails, claiming it cannot find any references to stdc++, lua or octave. If I change the order of linking, so that those system libraries are linked after the two static (.a) libraries, then the command works. The new command: cc -Wl,--as-needed -Wl,-z,noexecstack -m64 ...:(a couple -L) -Wl,--gc-sections -pie -nodefaultlibs ...:(a couple more -L) -Wl,-Bstatic -Wl,--whole-archive -l octave2lua -Wl,-Bstatic -Wl,--whole-archive -l c2rust -Wl,-Bdynamic -Wl,--no-whole-archive -l stdc++ -l luajit-5.1 -l octave -l octinterp -Wl,dynamic --no-whole-archive ...:(multiple rlibs: liblazy_static, libbyteorder, libstd, librand, ...) -Wl,-Bdynamic -l dl -l rt ... -l util So that is it. Where should this be reported? Also, I am traversing through Rust commits that day and really cannot find one, that could be responsible for this change.
I'm deeply in debt to /u/dtolnay for taking serde the next level. He did an amazing job here, and I have to say, a much better job than what I was doing back in the day. Thank you so much for getting serde across the 1.0 line!
I have been toying around with ASM based on https://github.com/pliniker/dispatchers/blob/master/src/threadedasm.rs, leading to https://godbolt.org/g/0rsrO8. This is about as unsafe as it can get, but it's at least something.
[answer] No. I haven't always even read my crate's documentation in rustdoc the first time. Migrating from hoedown to pulldown-cmark is as likely to *fix* their docs as it is to break them.
I'm just describing what the current model is - if you think that should change, please open an issue. One thing to keep in mind: if rustup doesn't remove the cargo cache, nothing will. Furthermore, if you don't have a separate cargo installed, there will be no way to uninstall programs installed via `cargo install` after you've uninstalled rustup! If you don't want to uninstall cargo-installed programs, or remove the cargo cache, then maybe it's not worth uninstalling rustup at all? Just removing all of your toolchains would give the same result, while still allowing you to uninstall everything later should you so wish.
This is a great library.
&gt; One wonders what the marginal cost of adding one more program to that list is. We want this to improve. "It's already messy, so it doesn't matter if we make it a bit messier" is an attitude that's incompatible with that goal.
In addition to the other answers: in the ML world (and in most type theory papers), we like to use greek letters for type variables. It's simply a writing convention so that, when you read α, β, γ; you know they are type variables (just like x, y, z are regular variables; i, j, k are integers; f, g, h are functions; and so on).
I don't mean to come of as condescending, but this is roughly standard notation for type theory, and most of the notation is common across mathematics.
Also, this ergonomics feature *should* be covered by [this year's roadmap](https://github.com/aturon/rfcs/blob/roadmap-2017/text/0000-roadmap-2017.md). :(
Well. By "assembly" I rather meant "whatever target language you want", with pluggable backends for various targets. Again, like LLVM. Then a user can use one of the existing backends or write their own to add to the mix.
I don't think so. It's less of an attitude stopping improvement and more of a reflection at our current state. The question is interesting to ask, and confronting the reality that dot-files in `$HOME` will never disappear is a useful exercise when balancing the trade offs here. Particularly when one might invariably ask themselves, "How much do I *really* care about this?"
The logo lools like a pixel penis
I have a question regarding serializing and deserializing a struct containing some collection of `Rc&lt;RefCell&lt;T&gt;&gt;` types: #[derive(Serialize, Deserialize)] pub struct StructA { ods_ref: Rc&lt;RefCell&lt;Type&gt;&gt; } #[derive(Serialize, Deserialize)] pub struct StructB { ods_ref: Rc&lt;RefCell&lt;Type&gt;&gt; map: BTreeMap&lt;Key, StructA&gt; } I need to serialize and deserialize `StructB`. Is there an easy way that doesn't require custom impls?
[removed]
Congratulations! It is truly one of the most important libraries.
Just do it. People will submit PRs and in a couple of weeks, it will be all done. Tiny pain for long term gain.
What is Amethyst? Is it a business asset management software?
Yeah I saw, I used your work to begin but I try to optimise it to get full performance of this wonderful console :)
It's a game engine. Assets in this case are textures, sounds, models, meshes, etc.
Pioneering work is never easy, I cheered when I saw Rust in the twitch stream. Well done! 
Yes, exactly. You can find it [here](https://www.amethyst.rs).
Spent some time with this, then gave up. It's too much of a minefield, results in really weird borrowing errors (probably due to register pinning), and greatly limits the number of supported platforms :&lt;
You want /r/playrust. Check before you post :)
&gt;I learned this by learning haskell, not from taking a type theory class. Care to point me to whatever Haskell documentation you learned this from? I am no stranger to ML family languages and never encountered these particular symbols. &gt;By standard notation across mathematics I was referring to the forall symbol, and that not something you need to attend college to learn. You do not need to attend college to learn it, but you seem to imply that it's easily accessible information. I've had trouble discovering these things personally, and I've made a career out of using the internet as a learning resource. I'm not really sure what your motivation is in your replies, other than to tell me I should just know these things.
That's the conclusion I came to personally - it might be worth it for somebody under some very specific use case, but not most of us. I'd prefer to have more control, especially in a systems language, but it's just not there and may never be. I really like Inko, I've looked at parts of the source code and it's clear and understandable. It has a lot in common with a language I'm dreaming up myself :-)
I'm somewhat hoping rustc or LLVM will include some sort of optimisation pass for this at some point, but something tells me that's unlikely to happen any time soon because it will affect few users. &gt; I really like Inko, I've looked at parts of the source code and it's clear and understandable. It has a lot in common with a language I'm dreaming up myself Thanks! It's worth mentioning that the GitHub page is a bit out of date in terms of explaining what the language will end up doing. The idea is to make a language with: 1. Message passing for basically everything (including `if`, etc) 2. An OO model that only provides objects and traits, without inheritance 3. Concurrency inspired by Erlang by using lightweight processes with their own heap 4. Exception handling inspired by the system described in joeduffyblog.com/2016/02/07/the-error-model, this basically makes exception handling not a total pain I was going to try and aim for a summer 2017 release of 0.1, but with all the work going into the interpreter loop I think I'll have to move that to later this year (e.g. there's no proper compiler just yet).
if you're only missing 0.7% of branches, then completely eliminating branch misprediction would only speed your code up by about 0.7% right? On something that takes 20 seconds to execute, you would gain less than a tenth of a second? I just think I'm misunderstanding something here.
Presumably a subset of instructions are much more commonly executed than the rest, might it be possible to unroll the dispatch loop for a subset of instructions? Have you considered super-instructions? Looking at the most common instruction pairs and create a single out of them, eliminating the indirect branch between them? I'm going to have to study The Error Model again. I remember seeing it but not having time to read it in depth. I'm very interested in better error handling in a dynamic language where you essentially have to have a nil type/value.
&gt; I'm somewhat hoping rustc or LLVM will include some sort of optimisation pass for this at some point LLVM already includes the necessary passes- tail duplication, mainly. The problem is convincing it to run them and not the inverse passes (which would be an issue even if rustc emitted the correct code directly).
yes (although I also welcome contributions).
Write up what you get working! I want to see it too 
I want to open a local html file in the default web browser. For this I use the url_open crate. But the file:// link is very clumsy to construct: https://github.com/medium-endian/trk/blob/master/src/timesheet/timesheet.rs#L353 Is there an easier way?
What? Why? Can you elaborate why you could not deserialize from the given Json string?
It's 0.7% of the total program, including anything that runs before/after the actual VM. Thus far I noticed that a difference between 0.5% and 0.7% can make a difference between 20 and 50 ms, but it's not very consistent. The total number of misses is 86 308 131 out of 12 348 983 360.
I'll do it when I'll find the solution to this problem :) Atm I just made it work in Thumb mode, I'm still looking for a way to define ARM functions for IWRAM section and Interrupt_Process. Then it'll be perfect, but now I'm kinda stuck. I only want to use Rust to do this, just Rust ^^' 
Nah, it's just a *sword*, which is obviously how "serde" is supposed to be pronounced. :)
Custom derives only see the type definition they're applied to, so your custom derive is only seeing `struct Foo {}`. They're not well documented right now, but I would use an attribute procedural macro that's meant to be applied to the `impl Foo` item. Attribute proc macros are declared similar to derive proc macros, but they require the `proc_macro` feature and a slightly different function signature. #![feature(proc_macro)] extern crate proc_macro; use proc_macro::TokenStream; // Will be invoked as `#[actor_impl]` #[proc_macro_attribute] pub fn actor_impl(args: TokenStream, input: TokenStream) -&gt; TokenStream {} The first argument is the arguments to the attribute, e.g. if you had `#[actor_impl(foo = "bar")]` you would see `(foo = "bar")` or something like that (I forget what exactly you get so if you use this argument, test it with different stuff including `#[actor_impl = "foo"]`). Edit: see my comment later in this chain for the semantics here. The second argument is the item the attribute was applied to, so if you had #[actor_impl] impl Foo { fn do_thing(a: u64) {} } You would get `impl Foo { fn do_thing(a: u64) {} }` Then I would use [syn](https://github.com/dtolnay/syn) with the `full` feature so that it provides [`parse_item()`](https://dtolnay.github.io/syn/syn/fn.parse_item.html). You can just `.unwrap()` the result as panics in proc macros will get turned into errors that are reported at the invocation site. If you have it parse this input you'll get a [`syn::Item`](https://dtolnay.github.io/syn/syn/struct.Item.html) with `node: `[`ItemKind::ImplItem`](https://dtolnay.github.io/syn/syn/struct.ImplItem.html). I recommend deeply exploring the `syn` docs to see how it handles the Rust AST (it's a relatively faithful reproduction of Rust's internal AST representation). After you've gathered the information you need to construct the types and impls you want, you can use the [quote](https://crates.io/crates/quote) crate to produce your output `TokenStream` with the new items (you can emit anything from your procedural macro). The original `impl Foo {}` block will get replaced with the output.
I addition to what others have said, there are also [QtQuick bindings](https://github.com/White-Oak/qml-rust) which look really neat
`#[link(name="foo")]` now means `#[link(name="foo" kind="dylib")]` per RFC 1717
If you're interested in writing safe abstractions using unsafe code, and just really solid Rust code in general, look at the standard library! Start with `Vec`, `VecDeque`, and `HashMap`, they are commented in great detail. Also, checkout [The Rustonomicon](https://doc.rust-lang.org/nomicon/), it contains a tutorial on implementing `Vec`, and goes over all of the fine points of writing unsafe Rust code.
There's multiple possible views on this: 1. Rustup is supposed to be the "top-level" (non-distro/global) rust installer, `cargo` is merely one of the tools installed with it. Sub-options: 1. Thus, de-installing rustup should deinstall everything -- `~/.cargo/bin` is strictly "rust development stuff". If you don't want things to be uninstalled, install them properly (i.e. through your package manager and don't tell me "can't do that as a user", `nix-env` works perfectly fine for users &lt;/end nixos shilling&gt;) 2. `~/.cargo/bin` *is* a proper way to do user installs of things. Then rustup should stand back and not touch that. But, well, it can indeed uninstall things without removing everything, so that option is in place. 2. Cargo is the top-level non-distro installer, not rustup, which is just a dirty hack devised by ill-advised people, therefore it should not touch anything. That's actually the camp I fall in but mostly because getting rustup to run on nixos would be a royal pain, and there's nix expressions available on github which do the right thing. Those nightlies etc. then work well with xargo. But then what do I care what rustup does I'm not using it in the first place...
Just as a general comment, the first paragraph of your blog post should probably say this explicitly and have this link. Kind of like what [This Week in Rust](https://this-week-in-rust.org/blog/2017/04/18/this-week-in-rust-178/) does: &gt; Hello and welcome to another issue of This Week in Rust! Rust is a systems language pursuing the trifecta: safety, concurrency, and speed. 
&gt; Where is it going to figure out the right path from, some other config file? Yep. Though to make things clear I wouldn't count a `config.h` as "source" in the above meaning. Stray constants scattered all over the place are a serious code smell. You probably would not want to / could not have it in `config.h` in the first place though, but `config.mk`: Also `make install` (if it exists) needs to know that path, and obviously there should only be one central place where it is specified/defaulted. More abstractly spoken: That path has nothing whatsoever to do with the actual program source, and the program source should be blissfully unaware of it. It is a detail of the surrounding system. Therefore, don't put it in the program source! &gt; Where is it going to figure out the right path from, some other config file? (Yes, same question again) Nowhere! Ideally, it should be passed in, especially when we're talking about compilers, because compiler builds should be bit-for-bit replicable and that means not hardcoding any paths. With GHC for example the `ghc` that's in `$PATH` is *not* a binary... it's a wrapper script which calls the actual binary with all the right options so that it can find its own nose. Whether you use env variables or argv for that doesn't really matter. 
I also recommend Clippy. It's insanely useful for avoiding common mistakes in rust.
I just learned a lot by reading the code for https://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html - it's really well documented, and shows just how clear Rust code can be, even with complex tasks.
Zero-copy means my struct is not packed in memory but potentially the fields are in areas of memory which are all very far apart from each other. Won't this be a hidden and hard to debug performance problem? I can imagine in many cases, we deserialize once but we access the deserialized data many times so makes sense spending more on the first part to save time on the second.
It's not really a university that provides this knowledge, but books. For instance, if you do an Amazon search for books on the mathematics of type theory, most of them with start by introducing the notation they use. That's standard practice for mathematical books. For instance, if you skim the first few chapters of [this](https://hottheory.files.wordpress.com/2013/03/hott-online-611-ga1a258c.pdf), you'll see this kind of notation being gradually introduced.
Unless you're parsing out only small parts of large blobs, the references should have much better locality than owned values. Since owned values are already spread all over the heap according to the allocators whim. The nonreference/not allocating fields (so not String, Box, Vec etc), should be copied in the struct and have good locality. In theory Serde could create a singular buffer for owned values, and the fields are references to parts of that buffer. But self referencing values aren't very ergonomic with the borrow checker. It's also probably uncommon for that to be measurably better than the new zero copy mechanics.
&gt; Are these things one typically learns as part of a CS degree or a specialization thereof? Yeah, at least in my experience.
I can do a crate (or help do a crate) for anyone without enough time. 
Been ramping into doing some complicated serde/bincode hackery for webrender and the folks working on this stuff have been absolutely wonderful!
Via [this GitHub issue](https://github.com/rust-lang/rust/issues/28307#issuecomment-295283017).
Ok, so as soon as I run a process in some context where environment variables are cleared (e.g., sudo), it's permissible to scribble in the XDG default directories? Or is the idea that the variables are in /etc/environment so that anything that goes through PAM picks them up, and any helper utility that clears all environment variables is defined as wrong?
… and for added fun, `\uXXXX` is a UTF-16 code unit. Or maybe a UCS-2 code unit. Who knows?
The fst crate as well. Anything from @burntsushi is usually a great read. There are a lot of comments, and he puts great thoughts in the design / code quality.
Sure! Here's what I'd do: https://play.rust-lang.org/?gist=785de217ee989a079a9c2b2d14038703&amp;version=stable&amp;backtrace=0 You'll also note that I've replaced the `unwrap` calls with an `unwrap_or_else`, you generally shouldn't use `unwrap` as liberally as you're doing, it will cause your whole application to crash when the `Result` is not `Ok`. 
It can't borrow from the original. If the API were structured such that deserialization took a mutable arena, you could deserialize anything: escaped strings are copied in unescaped form to the arena while others can be referenced directly. Edit: or you could just have Cow types in the struct. That'd be simple and backward compatible.
I've thought about this a lot recently, but my conclusion is that there is very little that is applicable to Rust, or even a hypothetical Rust-like language. Even if you ignore the practical concerns and backwards compatibility, there are the following issues: * MLsub does not support ad-hoc polymorphism at all, while Rust uses it heavily. Ad-hoc polymorphism is bad from a theoretical point of view and makes type inference hard, but it's pretty much necessary for any real world language. * MLsub does not support higher ranked types, which are required to usefully support lifetimes. Note that type inference for rank 3 or higher is undecideable. Type inference for rank 2 is decidable, but it is not clear whether it is possible to integrate into an MLsub style system. * MLsub does not support affine types, which are required for Rust style borrow checking. * MLsub does not support invariant types. This can be worked around by using a pair of type parameters, which is IMO a nicer approach theoretically. But it remains to be seen whether real world programmers would put up with this, and there's certainly no hope of being backwards compatible with Rust.
If you still need a diesel_cli with all three databases you can use https://github.com/mcgoo/vcpkg_diesel_build.git This uses [vcpkg](https://github.com/Microsoft/vcpkg) to get all the libraries you need.
I have some code that's structured like this: struct Str{ may: Option&lt;String&gt; } enum Enm{ Empty, Val(Str) } let myvar: Enm = Enm::Val(Str{may:Some("hey".into())}); How would I best go about printing the value of `may` inside `myvar`? I've arrived at the following, but I haven't been able to get rid of the `clone`: let temp = if let Enm::Str(ref n) = myvar {n.may.clone()} else {None}; println!("more text here {} etc etc", temp.unwrap_or_else(String::new)); 
Do you need the temp variable? Just do the printing inside the `if let`.
I think think I got it, nested destructuring is neat! let temp = if let Enm::Val(Str{may: Some(ref n), ..}) = myvar { &amp;n } else {""} println!("more text here {} etc etc", temp);
If the deserialization routine were allowed to modify the input string, I think it would be possible to perform the decoding in-place. The result of the deserialization would be a modified string and a structure with references into that string. I haven't used Serde so my opinion here is uninformed, but I imagine it would be a lot of work to implement this change (the input string would need to be an `&amp;mut str`, not just a `&amp;str`).
Good suggestion, I'll do that!
That's not a dot product, is it? If you do &gt; for each vec in vecs do the dot product and return a collection of vecs each dot product gets you a scalar, so the end result is a vector of scalars, not a collection of vectors. I may be missing something here, but this was what your original `vec_dot` function did, and it is what my `vec_dot2` does. What your function tried to do was different. If you really want to that, you have to change the return type of the function to `Vec&lt;Vec&lt;f64&gt;&gt;`. As I said before, you don't need the type annotations in the `collect` calls.
As someone who love History, I really appreciate the summary of the evolution of the serialization support in Rust. I can't explain why, but reading ancient Rust (like [this](https://github.com/rust-lang/rust/commit/6623597c187c025095842598f7d9db816cb1858b)) is exciting and intriguing.
Move to Finland, we have practically free university here ;) Okay, it costs about 100 euros a year.
A designer needs a special kind of talent to make complex things simple, or at least make simple straightforward and complex accessible. Part of the trouble is that classic GUI toolkits are kitchen-sink (Qt is famous for this, but the GTK+ universe is also full of Gnome-specific functionality). You want to pick the cherries without having to take the whole cherry tree. **PS** I sometimes feel the trouble is that they are GUI _frameworks_ and want to run your life. Most programs need a very restricted set of widgets and some auto-layout strategy (good match for a struct macro). Not every application is Photoshop.
&gt; Ok, so as soon as I run a process in some context where environment variables are cleared (e.g., sudo), it's permissible to scribble in the XDG default directories? Yes, if the user wants to pass environment variables through to the command that is run with elevated permissions, there are several ways to do that. I would assume that, if the administrator(s) lock down the methods for passing environment variables through, they understand the implications, including possibly having files created/written to some XDG BDS default for the target user.
&lt;edited, figured out the problem is in the bindings&gt;
I have not a lot of experience in C# but the YT Channel of [J M Archer](https://www.youtube.com/channel/UCOeX05Mko7ffxOl3Gg85NeA) have quite a lot of Rust and C# videos and i remember one he used both. .... i'll try to find it for you. A way is always [FFI](https://doc.rust-lang.org/book/ffi.html) if you language of choice supports that. EDIT: found it [C# to Rust FFI ](https://www.youtube.com/watch?v=ugre7cWp-mg) 
Yeah I agree. It's clear in hindsight, but when writing code that deserializes to a &amp;str, I wouldn't have thought of this. ...maybe this warrants a clippy lint? :)
Thanks, I'll take a look at it :)
Yeh it's easier to call Rust from C# because otherwise you have to bootstrap the CLR yourself. That might not actually be that difficult though, I haven't tried. You could kick things off in C#, which calls into your Rust code, wiring up some C# function pointers for your scripts. I've been working on calling Rust from C# lately, and wrote [a little tool](https://github.com/KodrAus/cargo-nuget) for packaging Rust libs as Nuget packages.
Spread the word! As always, I enjoyed your demo! I remember the time you released Overdrive at Evoke. I was like *“Holy shit that’s massive. Megadrive?! NO FUCKING WAY!”* ;)
The resources must manually and explicitly declare their dependencies. The idea is that when you implement the `Load` trait, you’re given a `ResCache` – the resource cache – that you can use to grab dependencies. For instance – not implemented yet but very simple with the current design – .obj *might* have .mtl links. I just need to read the name of the .mtl while loading the .obj, then `.get()` the .mtl via the resource cache. It’ll automatically grab the resource for me – and caching will help, of course. I implemented the resource cache with my [any-cache](https://crates.io/crates/any-cache) crate. Feel free to investigate, it’s very simple and stupid, yet very cool to use! :)
You could work around E0001 by adding an unused dummy variant to the enum. 
Wouldn't a language such as Lua be more suitable, given that functioning as an embedded scripting language is pretty much what it's made for? It may not be as well known in the community you're targeting, but does c# really make sense as a scripting language? Perhaps you should write your entire project in c#, so that people from your community can contribute. Edit: in addition, which operations should the 'scripting' part of your application support?
Java actually had a similar issue: its substring operation would just point to a subslice of the owned, garbage collected, string. In Java 7 the decision was made to get rid of this "optimization" and always copy on substring: https://www.google.com/search?q=java+substring+optimization (just some keywords to find more information). Rust lets you decide on the trade-off.
Is it absolutely necessary that the renderer is borrowed mutably during creation of the texture? If both wrap raw pointers, I assume SDL does some synchronization at a lower level, so using a non-mut-pointer should be fine. If not, you need to clarify the situation for Rust in some way, using either Sync primitives or RefCells.
Here are the MSDN docs for hosting managed code in a native application: https://msdn.microsoft.com/en-us/library/ms404385(v=vs.110).aspx
The RFC as written is supposed to include all the relevant content from the discussion by the time it gets merged, if the discussion results in changes or important clarifications to what was there originally.
I don't think that's the syntax for diverging function like you described, because it's used as a type parameter. 
Cool, I didn't know Java had had that issue. I guess serde let's you choose by letting you decide to not deserialize to a slice, but it would be pretty cool if we could excise the parts of the input buffer not used after deserialization!
 If I remember correctly it's like a "void" type, that cannot be instantiated, and thus the code path returning it will never be chosen. Like an empty enum
Are you saying Clippy is a good way to get into the rustc internals? I've been trying to navigate my way through one of the E-Mentor issues of the rust compiler, but I _might_ be slightly in over my head. 
Yes! /u/Manishearth is a great mentor and since Clippy is a plugin you can learn about how rustc ticks. Later you could transfer what you know to an issue for rustc!
Dyon looks great, but the project that I'm working on depends heavily on the community/third party developers. C# is the most used language in this area of work, therefore I would like to support it instead of lua or something else. I know that it's easy to host managed code within a native application, but that does not mean, that it's easy to integrate all functions into the managed world and such. Rust is sadly not really attractive to most developers coming from the .net world, I've already had a chat with most of the community developers.
Thanks, I'll look into it :) 
Thanks for the link! I remember thinking of this problem earlier, but could not come up with some good ideas. Nice to have some code to look at!
Do all the fields in the renderer need to be mutable? One approach is to split the mutable fields into a separate struct. https://gist.github.com/anonymous/5e1a9ad04e6564b821a7a48ba91ca619 Alternatively you could split the texturemap into a separate struct or you could use a RefCell as proposed by others.
It looks like nightly has been failing since build 100. Maybe that can shed more light.
I'd agree, mono is most likely the best way to go here, although there's also the coreclr: http://mattwarren.org/2017/03/23/Hitchhikers-Guide-to-the-CoreCLR-Source-Code/#vm-virtual-machine But I suspect it would be a lot more work.
Yeah, I've been looking at both for a C++ project, and even there it seems as though mono is generally the better way to go, as coreclr doesn't seem to be very tested for embedding yet. Or, at least, doesn't have the same platform support. 
Then the author or user should package it, and install via the system manager. I will freely confess I'm spoiled by using Arch, and having the AUR readily available for such cases. I will also confess ignorance of how to build a source or artifact collection into a `.deb`, `.rpm` or other package archive. But language-specific package managers should really only install development tools, not systemwide tools.
I'm not entirely sure what to look for, but since /u/yodal_ pointed out when nightly started failing, I pulled up the list of commits between those two, for [rust](https://github.com/rust-lang/rust/compare/c49d10207...956e2bcba) and [cargo](https://github.com/rust-lang/cargo/compare/de2919f...6f1b860). Maybe someone out there can take a look at these and figure out the next little bit! Crowdsourced debugging!
Interestingly I'm in a similar situation as OP. I'm currently porting a larger C# codebase to Rust and it used C# as a scripting language too. Now I need to decide how I will handle this with the Rust code base. I evaluated multiple Rust scripting languages and Dyon seems to be the best choice (Ketos and gluon are too functional, Rhai is unusable in its current state). However Dyon seems to be heavily made for game development, so it's not that great as a general purpose scripting language. And Lua seems to cause tons of linking issues with my mingw toolchain, so I'm not going to bother with that. So yeah, C# is probably still the best option, but hooking it up is probably going to be a pain.
NOICE
I would love to help with this tbh but I don't have time. ugh.
I find it helpful to have a few good articles / discussions about how Rust solves some common problems in other languages - so I can share them with co-workers and friends. There seems to be a good aggregation of UB examples, discussion and valid complaints about UB in general. 
that is so much shorter! Thanks. I have trouble getting this to work - I tried to get the imports right, but now there is the trait bound `url::ParseError: std::convert::From&lt;std::io::Error&gt;` is not satisfied the trait bound `url::ParseError: std::convert::From&lt;std::io::ErrorKind&gt;` is not satisfied Maybe you know what's wrong?
Hi, your conference site has 2 locations. If the conference is ~600 ppl or less, there might be a ~200 ppl space available on another floor. I don't think they have it on the website yet, it only opened recently. Anyway, your location website is http://cosmopolite-kiev.com/conference; you might want to check with them directly. Right across the street from your location there's a 190 ppl conference hall. You might want to consider a reasonable participation fee for renting either of these locations, as the price might be around $500 or less for 3-4 hours. Your other option is booking a next door venue "Tayger pizza bar" (not a typo, that's how they spell "Tiger") - they have quite a large seating area, I'd say 70-90 ppl in one floor at least, and lots of screens. They're kinda cheap, so if you guys promise to order pizza (and tolerate horrible service) they'd be ok to close the floor for you and let you use their TVs. I live three blocks away from your conference location and part of my job is conference business, so ama. For quicker responce pls message me in Facebook, my username is /dubicheva. 
i thing something like this could do the trick fn create_texture&lt;'a, 'b: 'a&gt;(&amp;'a mut self) -&gt; Texture&lt;'b&gt; 
I don't know about these things. What is the work needed? Is it something ongoing or mostly a one-time effort?
I'm not a super big expert here, but from reading this, it looks like at least some of this should be a one-time effort, that is, the migration to rustbuild. Nothing is ever static, so there's always little things to do in an ongoing way, but that'd be a big change that's more of a one-shot thing.
Nice! Can you share your code to come up with these lists?
The first example contradicts the description. The description says that a Rust `&amp;T` can be reseated, so you model it with a `const T*`. However, the example says it can't be, and also a `const T* const` is used in the C++ part. To take this further, since &amp;T can't be reseated and can't be null, it's better to think of is as a C++ reference rather than a pointer. 
Explaining `&amp;mut T` in terms of C++'s `T*` is problematic because `T*` is already present in Rust as the [`*mut T` raw pointer](https://doc.rust-lang.org/book/raw-pointers.html). `&amp;mut T` is also guaranteed to be non-null, and to not be dangling. It's probably best to refer to it in terms of C++ references with additional guarantees. To think about it, C++'s `const T*` is probably more similar to Rust's `*const T` as well, since AFAIK it's only advisory (someone can cast one type of the pointer to another, dropping the const "guarantee"). The Rc description makes it look like it's thread unsafe. Actually, Rust guarantees that only one thread access it at the same time. You should probably include Arc for completeness.
It's not that the &amp;T can't be reseated, it's that the variable it's stored in is immutable ("... if the variable storing it is mutable"). If you have a suggestion for how to make it more clear, I'm happy to change it. It's really not the same as a c++ reference where assigning to it modifies the referrant.
Maybe this https://briansmith.org/rustdoc/ring/aead/index.html
The problem I'm seeing with AEAD (as it relates to my needs for public key cryptography) is that it relies on symmetric key cryptography so it doesn't apply.
Where did you get that rustc? Are you sure it's not some multirust/rustup dispatch binary? My rustc has linux-vdso.so.1 (0x00007fff67353000) libz.so.1 =&gt; /usr/lib/libz.so.1 (0x00007fc8a07e3000) libdl.so.2 =&gt; /usr/lib/libdl.so.2 (0x00007fc8a05df000) libpthread.so.0 =&gt; /usr/lib/libpthread.so.0 (0x00007fc8a03c1000) libgcc_s.so.1 =&gt; /usr/lib/libgcc_s.so.1 (0x00007fc8a01aa000) libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007fc89fe06000) /lib64/ld-linux-x86-64.so.2 (0x00007fc8a09fa000) libm.so.6 =&gt; /usr/lib/libm.so.6 (0x00007fc89faf3000) librt.so.1 =&gt; /usr/lib/librt.so.1 (0x00007fc89f8eb000) Which should be very robust against changes in any of those libraries.
It's terrible code but here it is: https://github.com/jrmuizel/crates-io-list/
How does cargo-esr score things?
That's a good point, and to add to it, I would also be concerned that the complexity of some of it might turn off a new user. ("Why do I need to understand variance to use a pointer? I'm going back to C++!", cause that's something that really confused me and turned me off to the language, but I eventually came back out of curiosity)
 //RUST, types annotated for clarity let mut a : i32 = 3; let mut b : i32 = 5; let c : i32 = 7; let d : &amp;mut i32 = &amp;mut a; //d points to a now *d = 10; //OK, change a //d = &amp;mut b; //ILLEGAL, d is not mutable, so it can't be reseated let mut e : &amp;mut i32; //e = &amp;mut a; //illegal ince d already has a mutable reference to a e = &amp;mut b; //fine, no one has a reference to b; //e = &amp;mut c; //Illegal, c is not mutable The last three lines are wrong your Gist. 
Maybe I'm misreading it but that seems to just generate a signature for the encrypted data (or something along those lines) rather than actually encrypting it itself.
Does the value for each crate include the number of times the crate was included as a "secondary" dependency? (e.g does the inclusion of `iron` also count for `hyper`?)
Ah cool. I kind of suspected it would either be fairly simple or unreasonably difficult :)
around 33:00 in the talk, he references https://www.youtube.com/watch?v=UvrEfOg3Nyk which is a much more technical overview of how to bind C-ABI code to the native Android widgets.
Will do! I have a small grant to develop a VR game over the summer, and I'm considering a game involving a great deal of physics simulation, which would really benefit from a Rust-induced speedup :)
Honestly I just wanted something with this flow. * Get the other person's public key * Encrypt some data with it * Send it to them * They decrypt it I'm currently reading and going off of one comment here: https://www.reddit.com/r/rust/comments/3qvmma/encrypting_file_with_asymmetric_encryption/?st=j1sc3bgg&amp;sh=d2e5986d
I guess I don't know what that means, I thought VR was just a different way of displaying the same OpenGL code. Or does WebVR not allow JavaScript to touch GL directly, because JS might hang and drop frames?
True! I Think that an IUP Wrapper could be a cool approach for Cross-Platform Native GUI.
`-c &lt;crate_name&gt;` will list all score details. For example: cargo esr -c serde Short descriptions for all scoring factors are available in the `README`.
I'm not sure, but I would expect that adding these to MLsub would be just as hard as adding subtyping was to classic ML, i.e. it would require another research breakthrough. If I had to guess, I'd say that it would be possible to add affine types, and it likely is possible to add some restricted subset of rank 2 types or some restricted form of ad-hoc polymorphism, while it is impossible to add invariant types. But there's no way to know until someone actually does it or proves it impossible.
Interesting again. Why would invariant types be impossible? Naively I'd expect dealing with those to be simpler than dealing with variant types.
(Unless explicitly requested with a `repr`, enums choose the smallest tag that fits the range they need to hold.)
I added the raw pointer types, which may help. I think it's important to note that they really are more like c++ pointers than references since that was a confusing thing for me. I didn't mention, but I assume the C++ users aren't trying to const-cast they way around the type system. I updated the Rc bit to fix your note. I'll look into Arc... I haven't come across that yet.
Fair enough! I'm a fairly casual type theorist myself. At the moment I'm more interested in the discussion than definitive answers. Thanks for your thoughts!
I'm curious: How active is the Rust user mailing list at Google? And is Google using Rust for any "primary" projects, or is it just people's 20% stuff?
There is a great deal of talk about Serde all the time. I don't mind or anything, but it makes me wonder for what purpose everyone is using serialisation. Is it needed for something fundamental that I'm not aware of?
&gt; These are the same as a `T*` and `const T*` from C++. They work about the same except for automatic deferencing (see below). Maybe I'm misunderstanding, but I think this is wrong. Raw pointers in Rust don't auto-deref, because it's an `unsafe` action which the language wants to make explicit.
Active enough to provide great comments on my chart. And unfortunately I can't say much in response to your second question. One good place to see public Rust activity is in the Fuchsia tree. Recent activity has been in [magenta-rs](https://fuchsia.googlesource.com/magenta-rs) and [xi](https://fuchsia.googlesource.com/xi), with infrastructural support in [build/rust](https://fuchsia.googlesource.com/build/+/master/rust/) and [fidl/rust](https://fuchsia.googlesource.com/fidl/+/master/rust/fidl).
Deserialization of configuration files is my main use. 
I think the installed curl is too old for the instructions on https://rustup.rs/, so you would have to manually invoke sh on the downloaded script.
Coming from a Functional background this still helped me a lot. Thanks! Just beginning Rust I was overwhelmed with the duplicity and didn't understand the underlying differences or design choices. Seeing it all mapped out in memory makes it so much clearer.
If this turns out to be the root cause (or for that matter, even if it does not) an issue should be filed for rustc indicating what is wrong and pointing to this pull request (if it was indeed the problem).
Oh, you're absolutely right. I switched from distro packages to rustup the other day and that had totally escaped my mind. The distro packages (Arch) look even "better" in this regard: vincent@urdhva /tmp/usr/bin % ldd rustc linux-vdso.so.1 (0x00007ffe305cb000) librustc_driver-7cba27127ab7ec04.so =&gt; not found libstd-0caa395042f407db.so =&gt; not found libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007f0839e65000) /lib64/ld-linux-x86-64.so.2 (0x00007f083a209000) Thanks for pointing this out!
set your `Formatting.conjunctions` to `false`, and you have your wish.
Rust nightly (Linux only, but osx is almost done) has sanitizer support, and asan is one of them. It has some trouble with zero sized fields but that just causes false positives; it will still work. You can also tell cargo fuzz to use the sanitizer so that it can look for asan-triggering issues
Nice - I'll take a look soon if no one else has!
Good tips - I'll add to the post.
More than once have I seen crate future-availability concerns be quelled by citing that said crate is owned by the library team, and thus would unlikely be abandoned. This action certainly puts an end to "semi-official external crates are adequate for stdlib functionality" myth on crate.io. It shows that these crates have just as much of a chance to become abandoned as any other crate. It shows that I (and I expect many others) were wrong to assume that these crates would receive the same treatment as the standard library; namely, continued maintenance post depreciation. In light of this situation, when will the standard library team start incorporating common functionality that is currently delegated to external crates back into the standard library? The ecosystem for this type of functionality has had enough time to stabilize and mature. We already have a number of well-known and well-used crates (i.e. serde) that have reached maturity. The problem space these crates solve is now relatively well understood and there aren't many "gotchas" to be wary of, unlike the time of rusts 1.0.0 release. I urge the standard library team to start considering adding stable common functionality that is needed by modern software to the standard library. Also, no-js version: https://webcache.googleusercontent.com/search?q=cache:3VtE5oxzG6wJ:https://users.rust-lang.org/t/deprecation-of-rustc-serialize/10485+&amp;cd=1&amp;hl=en&amp;ct=clnk
[When I ran your version, I got an error about trying to convert a `&amp;i32` into an `&amp;mut i32`](https://play.rust-lang.org/?gist=8241749f0634d5fdabb0cfa8b824937c&amp;version=stable&amp;backtrace=0)
Is that optimisation useful in practice? I'd worry that most of the time it would be a `u8` tag followed by seven bytes of padding, especially now that rustc knows to put the largest-alignment fields at the front of a struct.
I don't think I've worked on a single "big" project (i.e. the kind of stuff I work on at my job) that didn't involve some sort of data structure serialization in the past fifteen years. But different industries have different requirements. I work in server/client network apps and web apps. JSON is used all the time to talk to web clients. I use YAML a lot for config files. Lower-level network comms often uses a format like Thrift or Protobuf or whatnot (whether on top of TCP sockets or a message broker abstraction). I'm sure if you're working in microcontrollers or other non-networked applications serialization is much less common of a requirement, but it's very common in the wide world of software.
The combo of a static and ephemeral X25519 key is a pretty common AKE handshake. I didn't really look at the code yet.
My mistake, I didn't realize your first comment already contained the corrections. Apologies for the noise!
No problem. I probably should have been more specific about what I meant. 😅
[answer] Yes.
Such a reaction as this is overly pessimistic. We have always, since long before 1.0, intended to deprecate rustc-serialize; it's the whole reason we took it out of the standard library, and then out of the tree, and then renamed it from libserialize so as to give no impression that this was not just an implementation detail of the compiler. You can read about the initial deprecation here, from December 2014: https://github.com/rust-lang/rust/pull/19755 . (Similar deprecations are also the whole reason why we have the rust-lang-deprecated organization in the first place, dating back to around 1.0.) Now that Serde is both perfectly usable on stable and has reached 1.0, there's no longer any excuse not to finish the task. &gt; This action certainly puts an end to "semi-official external crates are adequate for stdlib functionality" myth on crate.io. Certainly not. I'd love to put more things in the stdlib, but this is an overreaction. &gt; It shows that these crates have just as much of a chance to become abandoned as any other crate. This has always been the case. From the RFC that established rust-lang-nursery and rust-lang-deprecated ( https://github.com/rust-lang/rfcs/blob/master/text/1242-rust-lang-crates.md#the-lifecycle-of-a-rust-lang-crate ): "Eventually, a nursery crate will either fail (and move to rust-lang-deprecated) or reach a point where a 1.0 release would be appropriate. The failure case can be decided at any point by the library subteam." &gt; It shows that I (and I expect many others) were wrong to assume that these crates would receive the same treatment as the standard library; namely, continued maintenance post depreciation. From the OP: "We will continue for the time being to merge bug fixes while crates continue to migrate to serde". &gt; The ecosystem for this type of functionality has had enough time to stabilize and mature. Again, I'm closer a stdlib maximalist (I'd rather have mediocre standardized interfaces than good but unreliable ones (though obviousy good standardized interfaces are best)), but this is premature. Serde has been at 1.0 for a single day. There are no other crates important enough to put in the stdlib that have yet reached 1.0, though regex seems close, with rayon a bit further behind. Futures/mio/tokio seems poised to be in the stdlib someday, but it's far off. No idea how long until hyper makes it to 1.0, nor crossbeam. We have no datetime lib that seems to be anywhere near a feature-complete 1.0 release. The rand crate in rust-lang-nursery probably needs a complete rethink. Bitflags is useful, but part of me feels like it's calling for a language feature rather than a library solution. There's no clear winner among the plethora of options for parsing command-line arguments. Overall, I think it's worth waiting longer for things to bake. I hope that in a year's time (third anniversary of 1.0) we'll have well-vetted 1.0 releases for all of these (except maybe datetime), which would be a good time to start a push for stdlib expansion. Of course, if people want to put Serde in the stdlib soon then I won't complain (but let's get some experience with 1.0 first, just to make sure).
There's the subtlety to how field reordering optimisation handles enums mentioned in a sibling, and it also means, say, `Option&lt;u8&gt;` is two bytes instead of 16, and it applies to data-less enums (`enum Foo { A, B, C }` is a single byte).
rustc-serialize was never a semi-official external crate of the form talked of in stdlib-or-external discussions. It was a crate moved out of rustc, and was supposed to be deprecated in favor of serde, except for the fact that it could work on stable (due to rustc magic) and serde couldn't (not cleanly, anyway). This was going to happen, and we knew it was going to happen since 1.0. rustc-serialize kinda already was in maintenance mode post 1.0, without much activity wrt features. Nursery crates do have a chance of getting abandoned (though, not really, especially not if folks are using them). Graduated crates (eg regex) do not. rustc-serialize predates the whole nursery concept and only exists because of the whole stable issue, it was never a part of this contract.
It's called "never" and yes, that's true. Using it for something other than diverging functions are behind a feature gate.
Why does fuschia use gn build instead of bazel?
Only that. But hex has as far as I know no equivalent.
I use https://github.com/ia0/data-encoding
Hey folks! By the way, if you want to come and you are in Ukraine, or the ticket price is somehow preventing you from being able to afford coming, please let me know. We will work something out, promise. :) 
The hex crate is that right?
Yes, that should be possible by combining `ring:: agreement` and `ring::aead`. You want to use asymmetric crypto for the key exchange and symmetric crypto for encrypting the files (for performance reasons).
I'm already in Kyiv at https://frameworksdays.com/ if anyone is around, dunno what that audience overlap is :) The weather is so nice today!
Saving in a game
It is an overreaction to believe that deprecating a crate that has been destined for deprecation for over two years proves that the nursery is a bad idea. rustc-serialize predates the nursery &amp; the intention has long been to deprecate it in favor of serde. This particular user made a poor judgment based on their limited knowledge. In general it is a bad look to express an opinion as stridently as this user did when you aren't extremely certain you know the full picture,
Just have to say that __I am not able to distinguish between the colors__, they are too bright. Other than that I very much appreciate it :D 
A thing I always used to sell Haskell as a practical language (and now use for Rust) is that in many languages (such as Ruby, Python and - to some extent Java), parsing JSON yields a data structure consisting of hashes and arrays that _might or might not fit_ what you want to accept. You have to post-validate. See Rails parameter accept machinery for that. Getting that wrong is frequently used for exploits, if a field that _shouldn't be on that request_ is not properly ignored and passed through to the data layer. In Rust and Haskell from_str::&lt;MyApiDefinition&gt;(my_str); Is the first line of defense against that, allowing it to define a data structure and reusing its structural info for the API. And damn convenient at that! It doesn't solve everything and certainly does not against illegal values, but against illegal structures.
Pretty much. Casting &amp;Type into &amp;Trait simply involves `&amp;ptr` into pair of `&amp;ptr` and `&amp;vtable` conversion. For instance following code: pub struct Type; pub trait Trait { fn method(&amp;self); } impl Trait for Type { fn method(&amp;self) {} } pub fn to_trait(value: &amp;Type) -&gt; &amp;Trait { value } Generates this x86-64 assembly code. core::ptr::drop_in_place: ret &lt;Type as Trait&gt;::method: ret to_trait: lea rdx, [rip + vtable.0] mov rax, rdi ret vtable.0: .quad core::ptr::drop_in_place .quad 0 .quad 1 .quad &lt;Type as Trait&gt;::method It can be seen that vtable contains four elements - destructor (in this case one that does nothing), length (0), alignment (1), and a pointer to a method in a trait. The vtable is returned in `rdx` register in `to_trait` function (position-independent code basing on instruction pointer register is used to dynamically determine position of vtable). The object pointer was stored in `rdi` register, and is moved to `rax` register to match calling conventions, without any change. Essentially, this means there is no runtime storage cost to have traits without virtual dispatch involved, virtual dispatch only costs when you specifically ask for it (as opposed to C++, where every `virtual` class stores vtables, even when it shouldn't be needed, for instance when object with virtual methods is directly stored in `std::vector`), and conversion of non-virtual reference into virtual reference only involves adding vtable pointer outside of object, object pointer is never changed during such a conversion.
Just published [lua-patterns](https://github.com/stevedonovan/lua-patterns) which is a Rust binding to the original pattern matching code from Lua 5.2. If you appreciate a lightweight and fast string matcher and don't need more advanced regexp functionality, then have a look. It really is a 0.1.0 version, and in particular will panic if the pattern is bad; I'm looking into static verification. There's a _lifetime problem_ which [I can't resolve](https://github.com/stevedonovan/lua-patterns/blob/master/src/lib.rs#L429). Not sure how to solve this and still stay zero-alloc. 
As far as I understand, this is only counting crates on crates.io as reverse dependencies, right? If so, it will be skewed towards foundational crates that are lower level &amp; more composable within larger libraries, as opposed to "complete"/framework-ish crates that are more likely to be used directly in final binaries. A better measure of trending crates, though definitely harder to implement, would be to look at recent changes to Cargo.toml files on GitHub et al. and count how many times a particular crate has been added.
You could mention that unsafe pointers often used for FFI/bindings.
What uses the length an alignment?
``std::mem::size_of_val`` and ``std::mem::align_of_val`` (and I think unwind?)
Ah, sorry about that! You have two different `Result`s there - one that contains an error of type `std::io::Error` is returned by the questionmarks in case of error in this line: let file_str = format!("file://{}", std::env::current_dir()?.join("timesheet.html").to_str().ok_or(std::io::ErrorKind::Other)?); and one that contains `url::ParseError` that's returned by the questionmark in case of error here (and that you defined your method as returning): Url::parse(&amp;file_str)?.open(); So you'll have to give up on the questionmark operators in one of the statements. You have a few options to handle that, of course you could just `unwrap` instead, but I'd probably convert the `Result` like this: use std::error::Error; use url::Url; use url_open::UrlOpen; fn open_link() -&gt; Result&lt;(), std::io::Error&gt; { let file_str = format!("file://{}", std::env::current_dir()?.join("timesheet.html").to_str().ok_or(std::io::ErrorKind::Other)?); Url::parse(&amp;file_str).map(|url|url.open()).map_err(|err| std::io::Error::new(std::io::ErrorKind::InvalidData, err.description()) ) } fn main() { open_link().unwrap_or_else(|e|{ println!("error opening link: {}", e); }) } 
I gotta learn the new ``?`` syntax! Must be nice in cases where there is only one error type. Thanks for your edit and clarification!
What happens to memory layout when Rc/Arc get copied?
&gt; though then stuff won't update You could deep link to https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/export/svg as in https://codepen.io/anon/pen/YVWQvL Keeping a hard copy in the repo is still a great idea. 
No. Only `std::mem::size_of_val` and `std::mem::align_of_val`, which are called from places like `box_free`.
To answer my own question: No. To get Powershell integration, you need the CLR spun up in your process anyway. Once there, maybe it's a nice use case for your community, and maybe it's not, but it's not an alternative path.
So, if there are only weak ptrs alive, the whole memory can not be freed?
https://crates.io/crates/ctrlc looks like it handles the major platforms.
I thought about showing this as other blue `ptr` blocks (maybe faded in color) with arrows into the shared part, but didn't want to make the chart too busy visually. But I think it might fit.
One of the rules is about forbidding recursion, even indirect recursion. Is that something that might be verifiable by a compiler plugin in rustc?
&gt; But this only works on Linux, since that LD on MacOS uses different flags, like --gc-sections. Hmm, shouldn't you be using `cc` (clang) as a linker on macOS? Instead of LD. &gt; there are some incompatible flags: "-l" "c" "-l" "m", do you know why this is added and how can I remove it? AFAIK these come from the `libc` crate. If you are not using that, you are going to have to grep your dependencies for `link(name = "c")` or look into their build scripts for lines like `println!("cargo:..");` &gt; What do you think about this idea? Sounds good to me. I haven't used docker on macOS before but if it works, it works.
I don't see why not. Just check if function call graph is acyclic (a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)). If it isn't, you have recursion somewhere.
TL;DR: use [IUP](http://webserver2.tecgraf.puc-rio.br/iup/)
Rust is pretty nice w.r.t UB as long as you don't use `unsafe`, but in `unsafe` blocks it's quite a bit harder to avoid UB than in languages such as C.
indeed, while i can respect anyone's decision to use any language they want, i kind of thought there would be more detail in the decision making, which is fine it there's not but then i don't have much reason to read it if the points boil down to "i just like the way it works better"
It's happening! Thanks for all the encouragement. https://make-a-demo-tool-in-rust.github.io/
It would seems to me that Rust would help with 6-9 and maybe even 10. A good chunk of those are about curtailing the usual pointer related issues. Even without dynamic memory allocation many of them still apply. Then you have things like the forced checking of Result types and exhaustive pattern matching. Does cargo have facilities to add linters? That would help with 10. The part I find interesting about this list that recursion and dynamic memory allocation improve quality in other domains. I understand and agree with restricting them in ultra high reliability domain. It all comes down to a different allocation of costs and resources between the developer and program environment.
&gt; * Very welcoming and helpful community that actually focuses on the technical side of things rather than getting sidetracked by social causes Does anybody know what this is referring to, specifically?
It's going to be quite a while before there's a Rust compiler that is sufficiently trustworthy to use for safety critical code. Also, the aerospace community has a *ton* of experience using C and C++ for safety critical code, and the industry would need more experience using Rust in high importance applications before it would be a reasonable choice for a new safety critical project. That said, I'm optimistic that in another decade or so the aerospace industry may start considering using Rust for safety critical applications. However, that's very dependent on a sufficiently trustworthy toolchain being developed. I'm not sure what compilers NASA and aerospace companies use, but I doubt they're built on something as large and fast-moving as LLVM.
Dunno. There was an unfortunate kerfuffle around the composition of the Community Team (might have been called something else then, I forget) when Rust hit 1.0, but that was a fair while ago now and I'm not aware of anything more recent in that vein.
&gt; [...] not everybody will love to program in Rust and think about ownership in every line of code. We use C++ [...] Oh dear. People aren't thinking of ownership while writing C++?
&gt; I'd prefer if people remained civil of their own accord for the most part I so wish it'll happen one day ;) &gt; (aside from the "Please avoid using overtly sexual nicknames or other nicknames that might detract from a friendly, safe and welcoming environment for all.", a rule I disagree with as being overly sensitive, and open to wide interpretation) It's a problem with many rules in general, after laws are subject to interpretation (the whole concept of jurisprudence and seeking out previous similar cases). --- I hope that the Rust community will remain friendly and inclusive, and even become even *more*. 
Very cool! Do you have a link so I can read about the work that was required to get ASan support working?
You could do `f.into_iter().map(|x| x.into()).collect()`.
This showed up before, the Rust and Fortran version were optimizing away the benchmark, since the results weren't used. There's corrected numbers on the github for the benchmark. https://github.com/marblestation/benchmark-leapfrog
Well, I was being glib =p but I find I think about ownership an awful lot in c++, and often still don't feel at ease - partly because we aren't always very strict about it I'm afraid.. But of course, rust is much more strict than you really need to be in c++, you're right about that
The issue with doing the conversion in place is that it would require that the the in-memory representation of ETPitch(u32) matches u32, which probably is true, but it is not guaranteed by the compiler. Now this would be a requirement for in-place conversion from Vec&lt;u32&gt; to Vec&lt;ETPitch&gt;. If you're willing to trust that this is the case you could just the unsafe variant. (note this is obviously unsafe AND A HORRIBLE IDEA so don't do this) The closest safe thing is: fn from(f: Vec&lt;u32&gt;) -&gt; Vec&lt;ETPitch&gt; { f.into_iter().map(Into::into).collect() } But that's not in-place unfortunately.
shorter: `f.into_iter().map(Into::into).collect()` There's a surprising amount of things implementing the closure traits.
I don't know when I'll need this, but I've starred it for that one time I do need it. Great work!
Author of Clear Coat here. There are also a couple other IUP wrappers, but I believe Clear Coat is already more complete (and they aren't currently being worked on either). I was going to do a 0.1 release last fall after a little more work, but I've been spending time on other projects. I still plan to work on Clear Coat more, and hopefully I can get back to it before too long.
https://github.com/rust-lang/rust/pull/38699
I mean, it's a function, and they're the function traits :) The reason this works is UFCS -- `Into::into(&amp;x)` is the function form of `x.into()`, which of course makes `Into::into` just a regular function.
I'm pretty sure there's an actual Rust allocation: [link to source](https://doc.rust-lang.org/src/std/sync/mutex.rs.html#120). As far as I know, most system mutexes don't allocate. This, I believe, is because the safety guarantee provided by system mutexes don't generally allow them to be moved (and the guarantee needed by Rust is that anything can be moved if you're the single owner of it). Hence the extra indirection. The (excellent) parking_lot mutex doesn't have this problem. The mutex can be moved when there is no possibility of anyone else contending on it (which happens to match Rust's ownership semantics perfectly). From my perspective, any performance-critical application should be using parking_lot instead of system mutexes. I learned all this in irc discussions where I showed an earlier draft.
Previously: https://www.reddit.com/r/rust/comments/5trref/what_can_rust_do_for_astrophysics/?st=j1to1r3f&amp;sh=237b062e
Oh no, I didn't take it as an insult or anything. Just interesting. Probably an artifact of people learning from reading *The Book* as opposed to random pages of the api docs.
That's really cool. I wouldn't have expected it to beat FORTRAN. 
Half of the time I run in &amp;T vs T problems, so I play safe ;)
You have to be careful with creating aliasing `&amp;mut` references, creating references that outlive the thing they point to, creating uninitialized data where panics might happen, etc. These all sound like silly things to do, but often those are exactly the kind of things you need `unsafe` for. Edit: also mutating non-`UnsafeCell` data without a `&amp;mut` reference to it.
I would like to note that you could use my derive_more crate to derive the first From (as well as some other traits): https://jeltef.github.io/derive_more/derive_more/ 
Why not `struct.update_state()`?
True, but then isn't the numbering system wrong? I thought UK-style English used a different scale with million, billion, etc. and "milliard," "billiard," etc.?
You might have more luck installing [Arch](https://wiki.archlinux.org/index.php/Mac), if you're up to the challenge 
I'm from the US, so I definitely prefer it that way. I suppose a feature for down-the-line would be to add support for the long scale.
Ah, nice. Make sure to spread the word far and wide when it's ready for prime time!
Duplicity usually means deceitful. Duplication fits well here. To be fair, the OED does have an arachic definition for doubleness. Or, maybe you've uncovered a vast conspiracy in the rust standard library.
You can't implement `From` for `Vec` because, as you said, you can't implement traits from another crate for types from another crate. But you're write that these two types have the same representation, so doing `vec.into_iter().map(Into::into).collect()` feels silly and can be very expensive, depending on your use case. Because ETPitch is a _newtype_ (a tuple struct with only 1 member), it will have the same representation as `u32`. Therefore it is safe to call the unsafe function `transmute::&lt;Vec&lt;u32&gt;, Vec&lt;ETPitch&gt;&gt;`, which will not require iteration or creating a new vector. I'd like to see this knowledge about the representation of newtypes built into the language someday.
Cool! By the way, on a totally unrelated note, you should fix the email address you have set in your gitconfig. Your commits on github aren't all associated with your github account.
You was right. I remove these two lines from the libc and everything runs smoother :) ```rust link(name = "c") link(name = "m") ```
So based on the chart, what's the difference between `Cell&lt;T&gt;` and just `T`?
If you do a video please make sure to actually use the medium by providing animated visualisations. far too often video courses are just text read aloud, with a few pictures in between, which has the disadvantage of not being searchable and not being scrollable while offering no advantages. (adding a voice recording to an article on the other hand might be a good thing, because some people like hearing things more then reading them.) if during the production of your course you notice that you would not make real use of the video medium then just write a text with pictures instead, maybe with embedded videos in important places.
Seems some people have taken this crate as opportunity to create their own with their own languages. If you are too lazy to dispatch on the language yourself, I am pleased to announce the [numbers](https://crates.io/crates/numbers) crate, which can convert your i64 to english, french, and chinese.
things that i think might profit from a visual medium would be - graphs in rust (explaining the ownership/lifetime problems, reaching possible solutions) - zero copy parsing (seems to be all the hype in rust parsers) - not too rust specific, but i think data flow through iterators and map/reduce can be intuitively visualised, and (in my opinion at least) rust iterators are just a blast, especially compared to any non-functional language.
I should warn you that `Formatting::default()` is the same as `Formatting::none()`, and will generate hard to read formatting like this: 132 -&gt; "onehundredthirytwo. I would recommend `Formatting::all()`, which generates a much nicer style like this: 132 -&gt; "One Hundred and Thirty-Two".
You want /r/playrust/, this is a programming language subreddit.
You've averaged &gt; 2 hours of gameplay, *every single day* since the game was released, but you couldn't take 5 seconds to check you were on the right subreddit before posting??
Thank you! I will keep all of that in mind!
Thank you! :D
I think a little explaining about borrowing, ownership and lifetimes will be essential for a rust video course. This will be especially benefitial if you have some examples that won't work (and why + how to "fix" these problems)
You should *never* use `transmute`. You should use `from_raw_parts`, because `transmute` is not guaranteed to not break. (but like, don't do this shit without at least a `repr(transparent)`)
&gt; C: 2m53.504s &gt;Fortran: 3m16.314s &gt;Rust: 2m33.082s &gt;Go: 4m10.233s &gt;Julia: 3m59.223s Still pretty good.
Procedural Macros (for custom derive) please! :)
Thanks very much. This will likely be helpful to me personally, but in the future it will be a boon to have multiple resources.
Ion script looks pretty clean. Might have to give this a try.
And Nix contains a component called nix-shell.
Pronounce it "Linux" and brace for the "WELL, ACTUALLY...".
Not surprised. Bash has a lot of cruft to it.
Can you give details about where documentation for the "impl trait" to remove heap allocation feature is? I'm not seeing it in the main documentation, but maybe I'm missing something. This is actually something I wanted out of rust and I was a bit frustrated that I couldn't get it. So if you can provide more info that would be much appreciated.
Documentation is at https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md right now I think. Overview though: `impl Trait` doesn't remove heap allocation, it removes the need for it in this case. The problem is that each closure creates a new hidden struct, but doesn't assign a name to it. The value can be passed around on the stack, but since it has no real "type" besides `&lt;closure defined at XXX&gt;`, it cannot be returned directly from functions. The current go-to solution for this is to return `Box&lt;FnMut()&gt;`. The purpose of this box isn't to allocate on the stack, but just to hide the underlying (unnamable) type - it works well, but has an unnecessary heap allocation. The new syntax, `impl FnMut()`, declares a function that returns a single concrete type, but does not name that type. It is not as malleable as returning `Box&lt;FnMut()&gt;`, as you can only return a single type of closure, but it allows for returning it on the stack. `Box&lt;FnMut()&gt;` is still useful for cases where you may return two different closures, so the indirection via heap and a vtable actually serves a purpose - but if you are only ever going to return a single defined closure, `impl FnMut()` lets you "name" the unnamable!
Out of curiosity, why do you hate bash? I use it because it's the default on my distro, but substitute it for dash in the cases where shell performance is somehow relevant (esp. initialization).
I had trouble finding correct documentation at least.
As an example Cargo uses serde for API querys with JSON and for reading TOML files. The rust [toml](https://github.com/alexcrichton/toml-rs) library offers a serde api. (by alexcrichton in the linked post)
[JPL Guidlines](http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf) lists which GCC flags to use. So I would guess GCC is what they use. NICTA (now Data61) use GCC for seL4. But their method meant that they could verify the binary output (for ARMv6) which means they don't have to trust the compiler.
Does this mean you can't Ctrl-C a running program?
It will kill the shell, which subsequently kills all programs the shell is running.
Have you looked at [Fish](https://fishshell.com/)? No relation to Rust, just looks like a nice shell.
We use arrays (@) in Ion for storing arrays of elements. The $ sigil will always be a single value, not multiple arguments. Therefore, no need for defensive quoting. It should also be noted that @[command args...] is the array equivalent of $(command args...). For loops split strings by newlines in non-array expressions instead of spaces.
I've never seen a single instance of technical issues getting sidetracked by social causes in the Rust community. But, incivility is quickly shut down by application of the code of conduct (here on /r/rust and elsewhere), which is IMO a good thing. I also note that that uncivil behavior has little to do with technical issues.
I've not used Ion, so I have no way to compare, but I've long since changed my personal shell to fish and I am very happy with it. 
So, what about a Rusty AWK, then? And Sed?
The shell will implement features that will mitigate the need for these two commands. Array support already eliminates much of the point of Awk. At some point in the future though, I could look into getting Rust implementations integrated into the shell as built-ins. Maybe I could get ripgrep integrated as our grep solution.
Iterators, Traits and when explicit lifetimes are needed and how to use them.
Yeah zero copy is a big one. It's tempting to just copy everything because it's easier. But then I feel I'm getting too haskelly but without the saving grace of ghc 
You might be interested in trying out [TermKit](https://github.com/unconed/TermKit). The good things: I have not yet seen an other shell that is technologically more up to date and does not just assume a dumb stone age serial ASCII text transfer protocol°. The bad things: Powered by Node.js and still keeps the shitty syntax of UNIX shells. °Okay, there is PowerShell. PowerShell *is* nice and all, indeed. I just find it to be "bloated", requiring that massive .NET backend. And it lacks many features TermKit has. But I would call it the best shell of the three most commonly used ones. (UNIX shell, Batch/cmd.exe, PowerShell)
That's great to hear
How long will it take until TFS will be usable?
Alternatively, if manual implementations of `FnOnce` / `FnMut` / `Fn` were stabilized, you could just create a `struct LineClosure { n: u32 }` that implements `FnMut` (and `FnOnce`, by necessity...) and avoid unnameables entirely.
Does using a bash construct instead of `while test` affect the bash timings? I'm thinking something like `for ((i = 1; i &lt; 200; i++))` and similarly for the inner loop.
Working on that. I'll push to make it available ASAP. Keep your Saturday free ;)
Futures. What do they do, what is the relationship between all the crates involved, and how to use them concretely to speed up a program/task. That would be a great video topic. I'm... asking for a friend, of course.
Ripgrep can do replacements, so you might use it instead of sed.
I think /u/zefyear meant that the search term "nix shell" didn't point them to documentation for common Unix shell designs. "POSIX shell" would maybe give you something to get started with?
What you're referring to as GNU/Linux, could be in fact, called Xorg/glibc/systemd/Linux which in the end doesn't make much sense because in almost every casual use of name Linux op means this specific use of Linux to build operating system compatible with Ubuntus, Debians, Fedoras etc. And if one would be so willing to be precise then it would be musl/stuff/Linux. And what if you compile Linux using LLVM/Clang and don't use bash? /s
/u/ticki_ should be able to answer this question
The same could be done for /r/rustlang.
TermKit looks beautiful and dead. Do you know of any fork?
An update; I ended up asking about this on the [users forum](https://users.rust-lang.org/t/odd-benchmark-results-compiler-optimisation-wall/10503) and thanks to /u/comex, managed to fix the performance cliff by using `inline` :) Cut a new release for this.
Looking forward to your other posts that try to suggest the same thing for C, D, Go, Ruby, Python, Crystal, Pony, Elixir, …
Higher ranked lifetime bounds. I don't understand them.
At least some guys are working on it: http://llvm.linuxfoundation.org/
Yep thanks.
That's a great idea for IPC! Nudge ... 
There is an important difference though: sed also does in-place replacements, ripgrep doesn't because it wants to be a simple tool that never changes files
One actual reason to do this would be to make it explicit that you're never going to add or remove elements from the array - using the type closest to what you're actually going to do with it and all that.
I hope I can do it before summer. I've been busy lately, but I haven't stopped working on it.
There are some hints for handling this on the website: [Understanding deserializer lifetimes](https://serde.rs/lifetimes.html#trait-bounds).
Over-allocation is a common problem in big C programs. There's an interesting thread over at Hacker News about [reducing allocation in curl](https://daniel.haxx.se/blog/2017/04/22/fewer-mallocs-in-curl/), and these struck me as allocations that just wouldn't happen in Rust.
$string defines that the item is a string variable and not plain text, whereas @array defines that it's an array, not a string var or a literal string.
I haven't looked into it too closely yet (haven't got around to AJAX yet simply because I had no need for it yet), but that's what I was planning to try - take advantage of normal Rust `Future`s. I don't see why it wouldn't be possible (it might need a little elbow grease though).
Thank you - interesting read. :)
https://crates.io/crates/dpc-simplemap ?
You've declared the lifetime for the reference, not necessarily for `Node` itself. You might want `&amp;'n Node&lt;'n&gt;`, or `&amp;'n Node&lt;'m&gt;` where `'m: 'n`
Something like [this](https://is.gd/HakyyW)?
Arrays in Ion work like so: let array = [ "one two" "three four" "five six" ] echo @array let comma_string = $join(array, ', ') echo $comma_string let back_to_array = @split(comma_string, ', ') let words = @[echo one two three four five six] echo @words[..2] echo @words[2..3] echo @words[4..]
Is Ion aiming for POSIX completeness?
Also, `esac` just feels wrong.
Looks awesome! I'm excited to experiment with moving quasar off of my hack of a fork of rust-platform to give this a shot.
&gt; does rust support recursion? Yes. We do not have tail call optimization, though, so you run the risk of blowing the stack.
I wrote a blog post back in January laying it all out: http://words.steveklabnik.com/an-overview-of-macros-in-rust (Basically, a lot of this is not even quite implemented yet, and some of it is but isn't stable, and some of it is but isn't ever going to be made stable. So that's why there aren't a ton of docs.)
Agreed.
I changed from bash to fish some time ago. I noticed that there is some similarities in the syntax which I like. (Mainly reduced need for quoting because of the clearer separation between arrays and strings.) Also nice Rust-inspired keywords :D Is there other inspirations for the syntax? Or some frustrations in other shells you wanted to fix? Btw. I tried this on macOS and it run, but is it not officially supported?
Awesome. I'll have to check it out!
&gt; a type might be able to contain a reference to itself This is something that would be manageable with language support. You could avoid the need for a move constructor by making it a "relative reference". So if you have `struct Pair { a: u32, b: rel&amp; u32 }`, `b` would store that `a` is located 8 bytes before itself (assuming padding), not the absolute address of `a`. I haven't though through the aliasing implications of this, though.
I have a Core2Duo Mac mini and the only unusual thing about it is that the EFI is 32-bit. Not a problem for me! I compiled GRUB 2 for x86 EFI :D And it boots 64-bit FreeBSD just fine. (BTW I would really like to have Rust on 10.4 too… on PowerPC though :D)
OK. It just so happens to be a place in Sweden, and there have been a couple of Ethereum things being named after Swedish places too, so I wondered if there was a connection.
Searching rust lang instead of rust almost always does the trick for me. I'm happy with the name rust. I usually chuckle, though, when I search something like "rust corrode" and realize what I just put in the search engine. 
You can still mutate the array. You just can't change its size.
Thanks, that's the feature I was looking for.
Noob question here. Is this like having a function that takes a string reference vs an owned string? I'm not sure if a owned string makes a copy or not.
I feel like one could cover their bases with a unit test, like // psuedo-rust assert_eq!(sizeof&lt;ETPitch&gt;, sizeof&lt;u32&gt;); assert_eq!(vec![0x12345678].cast::&lt;Vec&lt;ETPitch&gt;&gt;()[0], ETPitch(0x12345678));
When will there be an official release?
Thanks; I'd meant to ask about that a while ago, but it slipped my mind.
unit tests really ain't good guardians against undefined behaviour though, which is the danger here.
The syntax is different (non-POSIX, closer to Fish's syntax with Rusty influences), and numbers overflow to `inf` instead of wrapping. There are probably other differences too, it doesn't intend to be a drop-in replacement.
Oh no, it is what it is. Please don't touch the name.
&gt; Rental is for more complex situations, such as when the borrower is not a reference but rather some other opaque type with a lifetime parameter Note that owning-ref's OwningHandle is also designed for this case. However, the API is unsafe.
And some possibly more consumable links (though clicking the pouet link helps our intro's popularity rating!): youtube: https://www.youtube.com/watch?v=GjuridCR2Fo vimeo: https://vimeo.com/214404716
&gt; In particular, HashMap insertions should be a lot cheaper with upfront parsing because you can pre-hash your tokens during parse. Any idea on how to do that? And yes, it is parseable. There is some upfront parsing happening already as I tokenize everything in advance. Hashing is killing much of my performance at the moment.
I'm confused by `$join`, is it running the command stored in the `join` string variable? 
Well done! 🎉
Is it planned to support VMWare Fusion? Right now, no network interface is detected :(
AMAZING!
Looks great! Just two small things I saw: With the derived Default impl, K is required to be Default - maybe do a manual one with just requiring V to be default? And then it'd be great if the default hash map implemented `Into&lt;HashMap&lt;K, V&gt;`. Thanks for making this!
Both great suggestions, should both be simple to do. 
&gt; There is some upfront parsing happening already as I tokenize everything in advance. If you want a fast interpreter, you should be compiling all the way to a flat set of instructions (eg. `Vec&lt;Instruction&gt;`). The translation is normally fairly simple as long as you have a high-level set of operations. &gt; Any idea on how to do that? That really depends where the problematic hashes are coming from. Let me show how to handle one possibility. Let's say you're using an AST evaluator (they're not fast, but they keep the explanation simple), and that `let temp = $output` compiles roughly to Store("temp", Load("output")) In this case `Load` and `Store` both require looking up their strings in a `HashMap`, which I'll call `globals: HashMap&lt;String, IonValue&gt;`. Note that `Store`'s second argument is not performing string interpolation. Evaluating `Load` should be returning a borrowed value, and *in a better world* `Store` should require a `Cow` string on the LHS (because in theory you don't always need to take ownership, but sometimes may want to). I say *in a better world* because you should note that `HashMap&lt;String, ...&gt;` is a horrendous data structure. Due to incomplete API design, replacing a value when you have a `&amp;str` requires an entirely pointless allocation. In fact, for names defined statically in the program, `String` isn't even the right data structure since it requires all of the values to be allocated separately. *Ideally* you should be using a data structure that handles your case efficiently, but to avoid this becoming too long I'll skip what such a thing might look like. We've established, then, that looking into `globals` with a `&amp;str` is expensive. A simple way to solve this is to find any statically looked-up strings, and add them to a simple `locals: &amp;mut [IonValueOrUnset]`. Change `globals` to a `HashMap&lt;String, IonValueOrIndex&gt;` where `Index(usize)` gives an index into the vector. When compiling code, generate the AST directly indexing into `locals` StoreLocal(n, LoadLocal(m)) When accessing through a dynamically generated name, looking up in `globals` will give an index, which will then resolve to the local value. 
"Mille et un" ? I'd say "Mille un"
Ah, that makes sense then. I already thought there would probably be a reason. 
&gt; they are pretty easily faked with indices. Without any compile time guarantees.
So sure of what? They they talk about social issues?
As this very program demonstrates, the unexpectedly large size of hello world is due to other/more-detailed factors than just some blanket/catchy "Rust is bloated" problem. https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html explores it.
Did you follow the instructions in the [follow up post](https://thekerneldiaries.com/2016/06/16/making-sure-the-correct-libraries-are-loaded-at-run-time/) to make sure that libssl and libcrypto are in your linker's library path?
We're already paying the Gtk cost, I don't think an integer increment is worth worrying about. Tutorials need to focus on pedagogy, not pedantry.
&gt; massive binary bloat problem This is greatly overstated. &gt; Don't hello world programs go to megabytes in file size? 373k for one I just built. And much of that size is in the standard library and jemalloc. If you disable both of those, it is not hard to go quite small. This is old (pre Rust 1.0), but someone has, with a little bit of linker hacking and disabling the standard library, gotten a Rust "hello, world" down to [151 bytes](http://mainisusuallyafunction.blogspot.com/2015/01/151-byte-static-linux-binary-in-rust.html). If you want a lot more detail, [there's a post about where exactly all of the size of a Rust executable comes from](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html), applying changes one at a time to see where it all is. Debugging symbols in jemalloc, and jemalloc itself, are a huge portion of it, followed by the standard library. For a C program, the standard library is already shipped with pretty much every system out there (though actually, on Windows, it gets complicated because many people link against various different versions of msvcrt and need to then ship the appropriate DLL with their program, in case the system it's being installed on doesn't have the right msvcrt), so they can avoid that size. With Rust programs, the standard library is statically linked with the executable, so every executable has a copy of all of the standard library (or all of the standard library that's used, thought that winds up being a pretty good amount for a "hello, world" because the formatting system uses a lot of it). Anyhow, it's possible to produce a very small Rust executable. It doesn't happen by default due to the use of jemalloc (which can be disabled, which is generally fine for smaller programs that don't do a lot of allocation) and the fact that the Rust standard library gets linked in (which can be disabled, but then you lose the functionality the standard library and have to just work with the system libraries). For a demoscene demo, you're already going to be bending over backwards to minimize size, so disabling the standard library is no big deal.
If you really don't want to use `format!`, here's a Rust Playground example of how to make that work. https://is.gd/63WcX1 The basic rules are: 1. The first item must be a `String`. Use `.to_owned()` if necessary. 2. The later items must be `&amp;str`. Use `&amp;` to trigger `Deref&lt;target=str&gt;` if necessary.
But you can see that this has already caused confusion. If the cost is nothing more than a copy, it seems that it should impl `Copy`. `Copy` vs `Clone` is a substantial difference in the interface of a type and what you can do with it. An explanation that says that all `clone()` does is copy a pointer will make most people reading it (at least, most people with a passing familiarity with Rust) wonder exactly the same thing.
I tried telegram around the time of the developer contest. I built a bot but nobody seemed to be using mine or others. Are there more people on the platform now, or what is a good example of a successful Telegram Bot?
Yes. (Macros incl. syntax extensions can generate things that need to be documented, so they need to be run to get full docs.)
https://github.com/rust-lang/rust/issues/15470 is a relevant Rust issue.
It's more the other way around: the compiler is part of rustdoc. Rustdoc loads various parts of the compiler as libraries to parse everything(/extract the doc comments and what they're connected to), expand macros and even syntax highlight.
[Here is it on the Wayback Machine](https://web.archive.org/web/20170316023847/http://jadpole.github.io/arcaders/arcaders-1-0). I seem to recall it failing to build with recent Rust versions -- not sure though.
I honor this work in the best possible way: "this must be fake!". You deserved it! 
We build some in house bots to send messages from our CI server, or monitoring servers, to telegram groups. I've been finding it hard to find a "good" telegram library. 
Perhaps tokio-tungstenite is what you're looking for: https://github.com/snapview/tokio-tungstenite
It is possible to explain things both simply and accurately. If your tutorial says that something costs "no more than a pointer copy" but actually there are other costs involved then your tutorial is lying.
No I haven't because the title of the post says runtime so I thought it is something I need to setup on the raspberry pi to run compiled code but isn't required during compile time. 
So I take it one would never *actually* want to copy tge underlying structs? 
Is there some nice crate for printing out error messages in a command line app? I want to print to stderr using different global verbosity levels (error, warning, hint (shown together with errors and warnings), info) that are set using command line flags. (I'm using clap as the argument parser.) I tried env_logger, but I felt that it's more fitting for daemonized processes, plus the loglevel was set using environment variable. I want something neat for a user interface, not for storing in log files.
There are a lot of people on the platform, but they don't necessarily use someone's bots. I myself only use my own bot and that of my friend. You can do a lot of things with it. I have my own bot plugged into the Wolfram API so it can quickly answer many questions. It also could show me XKCD and you could subscribe for the newest XKCD. It can also act as a interface to basically any script you make. 
I know what you mean, there are a lot of abstractions out there, but there were almost none which felt polished or complete. That's why I wanted to make one in my new found favorite programming language. If you have any feedback for my library, I'd like to hear it!
As the link that /u/dtolnay provided says, you can use `DeserializeOwned` when your data gets thrown away before the function returns, as in this case. I would also recommend having your function return a `Result` type, so that any error handling is propagated up. All told, this is how I would write that function: pub fn load&lt;T&gt;(json_file: &amp;str) -&gt; Result&lt;T, Box&lt;std::error::Error&gt;&gt; where T: serde::de::DeserializeOwned, { let mut f = std::fs::File::open(&amp;json_file)?; let mut props = String::new(); use std::io::Read; f.read_to_string(&amp;mut props)?; Ok(serde_json::from_str(&amp;props)?) } 
My Rustfest talk. And it will be finished before Sunday morning. I hope.
I am working on [a domain specific language for designing slides](https://github.com/ruuda/pris#readme). I’ve used it to do the slides for Rust Utrecht last week, so it is in a semi-usable state now. This weekend I added a custom lexer in order to support comments. I think this week I will improve the primitives for doing alignment.
And you'd be right.
i am working on a fully decentralized social network
How is Gtk-rs related to the effort to have Rust suitable for Gnome development? I know there is an effort in this direction by some Gnome developers but I miss the whole picture of the different projects. 
Thanks, this is precisely the thing I was looking for.
Now I read the follow up post again, I think that is might be something I missed. Thank you
It doesn't copy the string itself, it only copies the `String` struct, which is a pointer to the data, the length, and the capacity. What they're referring to is calling `.clone()` all over the place, which _would_ make the deep copy.
I really appreciate all the work in this direction. I think Rust could very well be one of the leading languages when it comes to the adoption of WebAssembly and things around that. Easy access to WebAPIs from the language itself are thus great to have. I will look into the code soon.
&gt; my types don't match the requirements for OwningRef Sure - my types `T` aren't `O: Deref&lt;T&gt;` with respect to the owned type - they're generally structures of Cows pointing into a single String, and there's a bunch of checking and error-handling to get to that point.
I have no idea what the state of it is, but there's also [tokio-inotify](https://crates.io/crates/tokio-inotify) so you could potentially avoid using another thread for your notifications.
I like the idea of it but unfortunately it doesn't seem to support Windows and although I don't work with Windows much, this is something that I hope to be able to run on any of the big platforms.
I guess it might be more performant than a.to_string() + b + c too. (Fewer allocations.)
That makes sense - hopefully something like it will some day.
`cargo run` will build your executable if it's not up-to-date.
That's not what I'm asking. I'm asking whether it *would* build, *without* actually building. That is, I'm looking for some kind of a dry-run switch. Edit: Ah, pardon me, after rereading my question, I agree that it wasn't very clear.
/u/MiniTip 1000 bits
Sent Bitcoin tip of 1000 bits (~$1.24) to *jadesnail*. [*^(What is MiniTip?)*](http://minitip.org)
The packer will be, yes :)
I am using `positioned_io` library and got the following code but won't compile. How can I fix it? Looks like a clash somewhere as it should satisfy the trait in subject. extern crate byteorder; extern crate positioned_io; use std::io::{self, Cursor}; use std::fs::File; use positioned_io::{SizeCursor, ReadAt, WriteAt, ReadBytesExt as PReadBytesExt, WriteBytesExt}; use byteorder::LittleEndian; struct Block { buf: Vec&lt;u8&gt;, } fn read_i64(&amp;self, i: usize) -&gt; io::Result&lt;i64&gt; { self.buf.read_i64_at::&lt;LittleEndian&gt;((i * 8) as u64) } The compiler error is: error[E0277]: the trait bound `byteorder::LittleEndian: byteorder::ByteOrder` is not satisfied --&gt; src/lib.rs:50:18 | 50 | self.buf.read_u64_at::&lt;LittleEndian&gt;((i * 8) as u64) | ^^^^^^^^^^^ the trait `byteorder::ByteOrder` is not implemented for `byteorder::LittleEndian`
I think converting from `&amp;[T]` is actually what I want, since most of time I'm creating this from user input (I'm actually planning on using it as a backbuffer for a `String` replacement).
Emacs can do that as well, with, IIRC, `flyspell-prog-mode`. More generally, it should be trivial to implement with any text editor which supports plug-ins or any kind of scripting. 
Guys, it's a copypasta, don't take it seriously.
What about a pattern when you assume internals' layout, but create a test that check that the layout is indeed what you've assumed? (The best would be a static assert, but I guess that's not possible here). If we'll really start randomizing field order, what would be the best approach to do something like that? I imagine `std` could provide something like `StructRepr`, which would have the same definition as `Struct`, but all fields public, with compiler ensuring that layouts are compatible. I wondered about that when seeing that abomonation doesn't work for `HashMap` and `BTreeMap`
This is almost certainly because your code and `positioned_io` are using different versions of `byteorder`. The fix is to not do that: use whatever version `positioned_io` is using.
Oh, shit, wrong channel. 
Just yesterday I saw https://github.com/evestera/json_typegen which does exactly that and even has a web version! http://vestera.as/json_typegen/
I continued my work on [relm](https://github.com/antoyo/relm), an asynchronous GUI library based on GTK+ and futures/tokio. * I fixed the stable `relm_widget!` macro. * I added the ability to use gtk+ widgets from other crates. * I added the ability to create a relm widget where the root widget is also a relm widget. * I also started to update the crate to use [`futures-glib`](https://github.com/antoyo/futures-glib-rs) : you can see the current work in [this branch](https://github.com/antoyo/relm/tree/feature/futures-glib). * I fixed a few issues and added minor features in this crate, while working on porting my `mg` crate to `relm`. This week, I'll continue to port `mg` to `relm` to discover and fix new issues in `relm`. Also, I wish to continue the update to `futures-glib` (it might be too early for that since the `Spawn` trait has not yet been merge in the `futures` crate).
I often use awk to do this: `something | awk '{ print $2 }'` (Note that `cut`often doesn't help since some fields are separated with different number of spaces.) Does Ion have some equivalent?
This is probably not what you want, since (even in Java, I don't know about C++ and Go) it generates intermediate strings for each addition. Basically, you have an allocation graph that looks like this allocation allocation \ allocation \ \ \ \ \ (("abc" + def) + "qwe") + zwc) which results in high load to the GC. In Java you're supposed to use `StringBuilder`, but Rust's equivalent of `StringBuilder` is `String` (I know /u/steveklabnik1 has joked before that the only change he wants for Rust 2.0 is to rename `String` to `StringBuffer`). You can't add a `String` to a `String` because you already have an `impl` for `&amp;str` and there's no point having a seperate `Add` implementation for adding a `String` to a `String` since it would do the same as the `&amp;str` impl but consume its argument. The preferred way is to use `format!` (one allocation) or to use `some_string.extend(def.chars().chain(zxc.chars()))` (one allocation and highly flexible, but slower than `format!` since it has to convert from `u8`s to `char`s and back again)
In javascript all numbers are `f64`, so you don't need to guess ;)
v0.13.0 of [`uom`](https://github.com/iliekturtles/uom) has been released to crates.io! This week will be working through open issues.
Thank you, this is exactly what I was looking for! Cloned the repository, went a few commits back and now I have a local copy of all the articles, including code and images.
&gt; Petition for something on the public API of HashMap definitely not, getting RANDOM value from hashmap is something that for all this years as software developer i never seen someone needed or used, so it would be change of standard hashmap just to fit 0.000001% use case best "standard" way would probably be ordered map that exposes its elements also like list, so you can do random sampling on it and if you really need top performance than custom hashmap implementation is an option
Great! As someone paying the Rundfunkbeitrag I'm looking forward to seeing what you do with this ;)
&gt; add_event_listener figures out the event name from the passed closure's argument instead of accepting a string with the event's name Is that unambiguous? According to the MDN docs, all mouse events such as `click`, `mouseup`, `mousedown` are handled by an event with the same interface: [MouseEvent](https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent). In any case it might be better to have the API be as close as possible to the usual Web APIs to avoid writing a separate documentation (and possibly automatic derivation from WebIDL)
One thought that might be useful: could you pop up a level and say more about the problem you're trying to solve? Perhaps there's a totally different way of going about this!
&gt; even in Java IIRC, modern Java compilers will do magic with `a + b + c + ...` String concatenation to avoid the ~~extra allocations~~ intermediate Strings, essentially using a StringBuilder behind the scenes. But, yes, that used to be a problem you had to watch out for in Java too.
It would be a great building block for other abstractions, since it's essentially like a systems language equivalent of first-class continuations.
I'm writing a messaging application that anonymizes messages by routing them between users before getting to their destination. Currently if a user wants to send a message to a different user, that user makes a request to the server for a route. The server has a hashmap of names to users. What I'm trying to do is to get that hashmap to return a subset of the users it currently holds.
Working on [osmpg](https://github.com/sharazam/osmpg), which is a tool for in-memory transcoding from .osm.pbf files to a postgres database. Not yet finished, a lot of areas need to be cleaned up, not much documentation yet. My main problem was that I underestimated decompression - a 100MB .pbf file can grow up to 1GB when decompressed. The planet.osm is 38 GB big, I can't put that all into memory. So the technique I came up with is to do concurrent download / decoding at the same time. Meaning that I download the world in parts (countries / states / continents) of ~3GB each which will (decompressed) fit into 64GB RAM. This way I have a concurrent stream of download &gt; decode &gt; insert. Current tools such as osm2pgsql can't build a custom database schema (every tool has its own hard-coded schema), plus they take ages and need several intermediate columns / disk space. Just for comparison - osm2pgsql took 20 minutes for importing a file, osmpg takes 30 seconds.
For the last week or so, I was hacking on a toy (but practical) project, intended to test the current viability of the async Rust ecosystem (futures/Tokio/hyper). Now, since the experiment was a success, I'm finishing the write-up that relays all my discoveries and conclusions. Both that and the project itself should be out somewhere inside of this week. 
Unstable-only might be good, you'd just have to open a PR that makes that detail public in an unstable way and see what the libs team says. FWIW, OP's usecase [is already fulfilled with unstable `#[doc(hidden)]` methods](https://github.com/rust-lang/rust/blob/846891aeff1a2a73524c404c6eeff5e8daf4caa2/src/liballoc/rc.rs#L402-L457) (because `rustc` needs this).
You can store the users elsewhere and use either indices or `Rc` to refer to them in the hashmap.
That's more or less what I was saying earlier. Just a shame it requires this kind of workaround.
:D
Well it looks pretty much the same on all platforms, but it's still very simple and under development and in no way ready for prime time or anything like that. But certainly good enough for my purposes. 
FWIW, my [reffers crate](http://docs.rs/reffers) has an Rc/RefCell that supports `Rc&lt;[T]&gt;` (constructed from an iterator). It can be used as a pure Rc (without the RefCell part) if you wish.
Fair enough. The project is still in the early stages so I can rework it.
In case you cannot make sense of the number there, this wisdom from the standard is great: &gt; JSON is agnostic about numbers. In any programming language, there can be a variety of number types of various capacities and complements, fixed or floating, binary or decimal. That can make interchange between different programming languages difficult. JSON instead offers only the representation of numbers that humans use: a sequence of digits. All programming languages know how to make sense of digit sequences even if they disagree on internal representations. That is enough to allow interchange. So, if you are not sure how to put that human-interpretable sequence of digits into finite memory with encoding inaccuracies, sucks to be you. Also, the whole thing rather presumptions, I write pi and tau using greek symbols, because if I tried anything else, I'd not be done in any lifetime, 'static included.
 echo @[something][2] let output = $(something) echo @split(output)[2] There's a lot of examples provided on the repository.
I wouldn't have imagined rustaceans having so little sense of humour. :(
`select` makes you select things by using a bunch of functions and types, so you'll have something like `Or(Class("foo"), Attr("id", "bar"))`. Less painful than `html5ever` but still not as easy as CSS selectors..
Any thoughts on being able to handle that with something like xattrs? Of course, then you might be doing separate requests when fetching xattrs than when fetching the actual data. Would be interesting to think about whether a pipe could carry the xattrs as well. Essentially, treating any file as one default data stream and one or more named data stream that can also be extracted from it. [Solaris does something similar](http://docs.oracle.com/cd/E19253-01/816-5175/6mbba7f02/), though I don't know if it supports having xattrs attached to pipes.
But POSIX shell would imply a shell that met the POSIX definition of a shell, which is a Bourne shell. This doesn't appear to be a POSIX shell, but instead a shell that runs on Unix-like platforms, such as Linux or Redox. Linux is not necessarily fully POSIXly correct, and Redox certainly isn't, but they're both Unixy enough that the same shell can run on them. I think people are reading too much into the phrase "a nix shell". It would have been maybe slightly more clear as "a *nix shell", and probably more clear still as "a shell for Unix-like platforms". The actual name of the shell is "Ion", that phrase was just supposed to describe what Ion was, which is a shell for Unix-like platforms.
This is excellent. I wonder if it's possible to work in an explanation here of how `Sized` fits into the mix? For instance, why `[T]` is not `Sized` but `&amp;[T]` is.
Ah, I didn't remember the docs correctly. I thought that `+` creates a new copy of string each time (just as for integers). Seems like the only way to optimise it further would be to call `reserve()`...
That would require that I can return an `&amp;Foo`. My types are the likes of: ``` struct Foo&lt;'a&gt; { bar: Cow&lt;'a, str&gt;, xyz: Cow&lt;'a, str&gt;, } ``` I then create a rental struct around a `String` and a `Foo`. They'd come under OwningHandle, not OwningRef, but I have no desire to write unsafe code.
Note that `[a, b, c].join()` will call `reserve` automatically.
That seems elegant. Thank you for suggestion!
Nice! I liked bash and never used other shell scripting language but I think I'll give Ion a try. :)
fully decentralized so no servers at all, fully p2p. a bit of DHT mixed in, but its not used for storage, too unreliable in my opinion. (there really is no lack of interconnected http server social networks :)) i will probably have something publishable in 2-3 months, i will probably post progress reports to this thread each week for motivation.
To some extend it looks a little like my four in a row exercise I used to explore rust. The game is different and my objective was to use recursion and multiple threats to select the best move. At times it makes very odd moves. The initial version was written in Ada and had user I/O. The rust version tries to use rust idioms as much as possible as I used it to explore the rust language and features. Surprisingly I didn't suffer much the issues others have with lifetimes and so but I admit this thing is very simple. I did really enjoy writing it and it was easy in the end thanks to the enormous amount of resources available. I share the gist https://gist.github.com/sergeken/f281e42da8e496b632165711f3e7e58f . So you can have a look and feedback too.
While we're on the topic of demos, does anybody know of a demo which is a good demonstration of hyperbolic geometry?
Okay, here's what I have so far: [https://github.com/bschwind/file-watcher/blob/master/src/main.rs](https://github.com/bschwind/file-watcher/blob/master/src/main.rs) It's *close* to working, but there are a few problems: * Only one client can connect * The CPU spins at 100% after the first client connects However, the first client to connect is able to receive file change messages so that's kinda cool. I'm pretty sure the CPU spinning happens [here](https://github.com/bschwind/file-watcher/blob/master/src/main.rs#L99-L105) but I'm not sure of the best way to go about diagnosing this issue. I'm using [multiqueue](https://crates.io/crates/multiqueue) for broadcasting file changes to each client because it implements the Futures API. Should I instead maintain a HashMap of connections and just iterate over each one to send data to clients?
Considering hash maps are implementation details, this O(N) implementation I feel is best you can do without implementing your hash map. Try using vectors instead, if possible. extern crate rand; use rand::distributions::{IndependentSample, Range}; use std::collections::HashMap; use std::hash::Hash; fn rand_hash&lt;K: Eq + Hash, V&gt;(hash: &amp;HashMap&lt;K, V&gt;) -&gt; Option&lt;&amp;V&gt; { if hash.is_empty() { return None; } let index = Range::new(0, hash.len()).ind_sample(&amp;mut rand::thread_rng()); hash.values().skip(index).next() }
Thanks, I was hoping to go further with it but ran out of time to do it within the 48 hour limit.
I have an enum `Bar`: ``` enum Bar { Baz(Baz), Boo(Boo) } ``` Each variant in `Bar` implements the trait `Foo`. In order to make it easier to use the `Foo` methods on the `Bar` variants, I'm trying to implement `Deref` for `Foo` on `Bar`. However, I get a lifetime error I can't reason about. Normally I would just use a `Box&lt;Foo&gt;` instead of doing this enum business in the first place, but the `Bar`s have to live in a `lazy_static`, which won't let me put a Trait Object because it's not thread safe. I could always impl `Foo` for `Bar` and just write the boiler plate to call the methods for `Foo` on the variants `Baz` and `Boo`, but I'd rather avoid having to do that and just use deref and get that "for free". [Here](https://is.gd/BEEYiH)'s a gist of my problem in its shortened form. EDIT: Never mind, found the solution! You need to do: fn deref(&amp;self) -&gt; &amp;(Foo + 'static) 
ho, the way I understood it ; this is what he meant by random. maybe I misunderstood.
You can definitely verify it in at least some cases - just make sure that no closure exists which takes a `Fn`. 
Very inspiring, I was there and saw it on the big screen :) Is the demotivation tool or sync tracker written in Rust too? Are you using this? https://github.com/rust-qt
Check your cargo.lock to ensure that you don't have two versions of serde being used.
Can you provide actual numbers? If 25% faster = a few milliseconds, then it's probably just variations in the operating system scheduler. You need to have the computation take a few seconds on the fastest one to get a reliable feel for how fast it actually is, in my opinion, for a simple benchmarking methodology. Really, the performance should be identical. Rust does not have any FFI overhead beyond obvious things like converting a C string into a type that makes sense in Rust. You should also mark the function as `extern "C" pub fn` just for good measure. Also, `if l.starts_with("f ") {` should really be `else if l.starts_with("f ") {`, since there is no situation where it could start with "v" and also start with "f ", and that will waste CPU cycles checking the "f " case even when it found "v". The "if n == 0" "if n == 1" is the same way. I recommend using "else if". I'm not sure what the advantage of doing the string conversion in two steps is over just using [c_str.to_str\(\).unwrap\(\)](https://doc.rust-lang.org/std/ffi/struct.CStr.html#method.to_str), as a sidenote.
Maybe just try to run `cargo update` right off the bat? (Mentioned just in case OP isn't aware of that command)
I just released a new version containing both of these changes. Appreciate any more feedback.
Oh shit nice one. I did. Bincode depends on serde 0.9.15. My library utilizing bincode is used in my other program that's *also* using serde (via `serde = "*"`). Except the most recent version of serde is 1.0.1. So there's the clash.
Ah ok, I'm used to JS modules where a file is a module and handles all imports/exports at that level.
I'm writing yet another [gzip decompressor in rust](https://github.com/ricbit/rgzip). I wanted to write a gzip decompressor from scratch, I wanted to learn rust, why not both at the same time?
Probably just not pushed to crates.io yet
In the works. I'm not saying it's going to be in good usable form _soon,_ but there are things about it that excite me. Notably, I'm using it as a testbed to explore extreme performance (startup time, input -&gt; screen latency, and scrolling smoothness). I would be eager to pair up with somebody who knows windows well (although re-learning Windows is one reason I've been spending time on it) and is interested in co-owning it.
The difference here is that the existing API is sufficient for arbitrary elements. The iterators you get from `keys()`, `values()`, and `iter()` should be enough for those cases.
When I added the workaround to get `String` working as a prefix field, I did it mostly for completeness and didn't expect it'd see much use, but It seems to be much more common than I thought it'd be. It's fascinating to see the various use cases play out that didn't even occur to me at the time. If anyone else out there is also using rental, I'm always interested to see what you're using it for and how it's going.
Do you know if there's any effort made toward mixed-language link-time optimization? Specifically between C and Rust, it seems that compiling both to LLVM IR and *then* let LLVM performs its magic would allow cross-language inlining.
I'm specifically looking for a random element, not just an arbitrary one. Maybe I didn't make that clear enough.
Look at my edit on the post.
Hmmm, I need to implement an esperanto-numbers crate. Esperanto has a ridiculously simple system, so a crate should be relatively easy to construct.
There appears to be a JSON Schema. Maybe you know more about JSON than I do, but would that be worth supporting generation from?
NZer here. Never knew they were English words until I learned German and an old dictionary had the same word in both languages
Yes, I've looked a bit at that possibility, and if I have the time I want to try creating a similar solution for JSON Schema. A couple of reasons why I ended up doing this first though: 1. It seems to me though that a lot of the people/websites actually using JSON Schema (often in Swagger/OpenAPI) don't actually use it according to spec. For example many completely omit the "required" field that specify which fields are not nullable, which defeats some of the point of a schema in my opinion. 2. JSON Schema also has some challenges for code generation in that it can easily represent types which are very hard to represent with serde, so it may require actually writing the deserialization code more or less specifically for a hypothetical json_schema_typegen. The references in JSON Schema also means that a naive tree walk is not quite enough (though not far from it). I guess I should make a proper thread to "announce" json_typegen (as there is also some other interesting "further work") so I don't entirely derail this one.
The ideal thing would be an proper implementation of an inplace transform, like [this](https://is.gd/hAUpBv). This implementation should hold up all safety rules (caveat: if the .into() call fails this would leak memory/not call destructors on other items but this is technically safe). I believe the [map_in_place](https://crates.io/crates/map_in_place) crate provides several of such implementations, including guards to actually handle panicing map functions appropriately.
Could it be that the Rust part uses system malloc when linked into the C program and jemalloc in the Rust-only binary?
Lojban numbers ought to be even easier.
I wrote my own lexer the other day in Rust. I'm not a lexer expert by any means, so I think I based it on the lalrpop lexer. Either way, you might be able to steal some ideas from it: https://github.com/dagit/rust-prolog/blob/master/src/lexer.rs At the start of the file is where I define the tokens. Each one gets a name in the rust code (like `VAR`) and a regular expression for recognizing it `[A-Z][_a-zA-Z0-9]*`, which says variables start with a capital letter and are followed by any number of letters (capitals and lower case), underscores, or digits. Additionally, I use an archor `^` at the start of each regular expression. Arguably I should hide that from the user, but let's move on to the next part. My `Lexer` type is like yours but stores less information and just has a reference to the string. `match_and_consume` checks if a regular expression matches and if it does it consumes part of the input string and returns the match, otherwise it has no effect. The `next` function starts out with a loop for stripping out things we don't care about like white space and comments. I just realized I have a bit of repeated code between newlines and comments that I could refactor to get rid of. After stripping off things and updating the line counter we're ready to look for matches. That's where I use the `actions` macro to tell my lexer what to do with each token type it encounters. The macro takes a list of pairs of the form `&lt;some regular expression&gt; =&gt; &lt;function that returns the token&gt;`. For instance, for `VAR` it looks like this, `VAR =&gt; |s:&amp;'input str| Token::VAR(s)`, in my `tokens.rs` I have the following definition: pub enum Token&lt;'input&gt; { VAR(&amp;'input str), ... } The `actions` macro then expands out to a big set of `if`-statements where the `VAR` regular expression is checked for a match and if it matches then the action (here: `|s:&amp;'input str| Token::VAR(s)`) is run over the matching text. Making the lexer this way ends up being quite flexible. Edit: Fixed a potentially confusing part.
I go over all of this in this video: https://www.youtube.com/watch?v=p9Obe-Xg35o In short, demotivation is written in Rust (that's where we get the most gain from actually using Rust), the sync tracker is [emoon's rocket editor](https://github.com/emoon/rocket) written in C++. We don't use rust-qt; we pack all of the Rust bits of the tool (which contains most of the logic) in a C API, and the top-level project is a Qt project that exposes the logic of that library via some Qt views.
Ah, for some reason I thought that we only intended those guidelines to govern official APIs, rather than suggesting that the whole community use them. :)
In order for the standard library to make that promise, the language has to make a promise to the standard library that the standard library will be able to uphold that promise. That's pretty meta, but it means that if you follow the same guidelines the language will never do anything that could make you break downstream code (according to the definition of breakage laid out in that RFC, which excludes type inference failures). The most pertinent issue is that we've defined adding non-fundamental impls as non-breaking. Without incorporating the orphan rules into negative reasoning, as Aaron is talking about, that definition is totally bankrupt.
Besides technology, it's aesthetically mesmerizing!
typegen is cool and I like this tool. I wonder if it can try unexpected chars well so I have a test: * From { "layouts": { "1900x200": "1", "1900*200": "2", "1900_200": "3" } } * To #[derive(Default, Debug, Clone, Serialize, Deserialize)] struct Layouts { #[serde(rename = "1900x200")] n1900_x200: String, #[serde(rename = "1900*200")] n1900200: String, #[serde(rename = "1900_200")] n19002002: String, } * mostly, it works as expected. but it will be better for me if they can be handled as follows :) 1900x200 --&gt; n1900x200 1900*200 --&gt; n1900_200 1900_200 --&gt; n1900_200_2
2017 goals before the half way point of the year? Excellent.
Can someone give me a hello world example of mixing Rust and C? Like a .c file and a .rs file, one returning "hello", and the other "world". Then how to compile it. Tried doing this last night and got errors about libc. Maybe I'm not using cargo right. So include that in the "how" too. Thanks!
Started working on an implementation of SSHFS in Rust, which is going much better than I anticipated thanks to /u/acrichto's [ssh2-rs](https://github.com/alexcrichton/ssh2-rs) crate, and /u/Zargony's [fuse](https://github.com/zargony/rust-fuse) crate :) ninja edit: also still using rust at work, which has proven to be the most portable and reliable part of the stack for about 7 months now :P
(`cargo tree`, via `cargo install cargo-tree`, is _very_ useful for debugging this sort of stuff)
Do the examples here help? http://doc.crates.io/build-script.html
unrelated to this project, but a question about rustfmt, it does not support comma first formating, does it? let a = vec! [ 1 , 2 , 3 ] i mean you would not format your function chains let a = foo. bar(). baz(); either. (same for struct definition/initialisation) edit: oh, and function call parameters, and ); or ]; on the same line as the other things. edit2: and normalizing to /*! instead of /// 
i think the trailing coma is [1, 2, 3] for never vs [1,2,3,] for always
&gt; The console is inspired from the awesome Pico-8, so there is a compatibility mode (not 100%) available with Pico-8 console and cartridges (P8/PNG).
Oops, just search for "HACK", I'm on mobile at the moment. I cloned the connections HashMap Arc twice so I could use it in two separate "move closures" As for the 100% CPU thing, I haven't figured it out yet unfortunately. I suspect something in multiqueue is the issue though.
happy to hear it :D
Maybe you're still using version 0.0.1? Did you try 0.0.2?
Depending on what you are lexing, you may not need `buffer` at all. You can just store the `Chars` iterator in the lexer directly, saving some space. You may need to store 1 token in the struct as a lookahead. You can also avoid allocations in `expect_number` and similar by storing indices into the source string and slicing it, but you need to be careful if you plan on dealing with utf-8. (I would get indices from the CharIndices iterator to be on the safe side)
BUT THERE'S NO UNSAFE CODE https://github.com/frewsxcv/rust-graph/blob/master/src/lib.rs in all seriousness, i'm the squatter of the crates.io name. if someone has a serious (subjective) graph crate, i'd love to hand it over
Those are some nice ideas actually, I think I can actually use that for my implementation
https://github.com/frewsxcv/rust-graph/blob/master/README.md &gt; I had a work-in-progress graph crate I was working on, but then found out about petgraph which I've been using.
This is really useful. Maybe it should be part of `rustfmt` itself for better maintainability. 
For the uninitiated, what benefits does this have?
I can speak a bit towards AVR. LLVM 4 moves us further along, but there's still a good bit of work to do. For example, we cannot currently compile stock libcore due to a [segfault inside of LLVM](https://github.com/avr-rust/rust/issues/26). The generated code is also not very optimized in many cases. It's my hope that having LLVM 4 as the base will make it easier for people to contribute patches to get progressive parts more and better supported. As always, folk are welcome to pop on over to [to the avr-rust repo](https://github.com/avr-rust/rust/) and help out! If you are really raring to go, there's [a branch](https://github.com/avr-rust/rust/tree/avr-support-4.0-tim) from a few days ago where I merged in the at-the-time-latest proposed LLVM 4.0 branch. I'll probably rebase and replace the main development branch shortly. As always, the majority of credit goes to /u/dylster3!
One step closer to `rustc` not needing a linker :3
Certain ARM targets we didn't have before, various performance improvements are some things you can expect from it.
Ooh, is there any more info about this somewhere?
Store the next random value external to the map. Update the value on every map insert using the insert/query rate as your exponential sampling factor. After usage, update the value to the next value in the map (assuming your keys generate a suitably random hash distribution). Obviously this is not cryptographically secure in any way. Engineered re-inserts will force particular values to be chosen too often, there are no repeats (excepting re-inserts), and the ordering will be consistent. Some of those trade-offs may actually be wins for your use case. As long as your load factor and distribution arent too wacky, these operations should be mostly constant time/space.
In Rust there is a difference between `let x: &amp;mut i32 = &amp;mut a` and `let mut y: &amp;i32 = &amp;a`. The first is like "const pointer variable", the second is like "pointer to const". "const pointer to const" would be `let z: &amp;i32 = &amp;a`.
Library discovery is a difficult problem in every language ecosystem, and I think we're doing relatively well but it's still not great (it's a hard problem!). Some heuristics to look at to gauge the quality of any given crate: * the existence of documentation * the number of other crates that depend on that crate (the "dependent crates" link on a crates.io page) * the number of downloads (will be heavily skewed by the prior metric) * whether the version number is at least 1.0.0, indicating that the author has some faith in the stability of the library * how many versions have been released, which tends to indicate a responsive and active author * how recently the most recent version was released, which can help determine whether a crate has been abandoned * whether the authors themselves are well-known for quality work (which requires some familiarity with the community) * whether the authors are present in community spaces, which indicates that you may be able to reach them if you have problems * by clicking through to Github, the usual tactics to determine the quality of a Github repo (pulse, number of contributors, state of the bug tracker) Ultimately the goal for Rust is for the library team to "bless" several high-quality crates and move them into the rust-lang organization directly (and perhaps the stdlib itself someday), so if you see a crate that lives in github.com/rust-lang, that should be a good sign. Unfortunately it's still such early days that there are relatively few crates that meet that criteria, though with lots of hopefuls baking in github.com/rust-lang-nursery (not all of which will make it). And ultimately if all this is too much work then I recommend just joining IRC and asking someone to recommend something. :)
It's hardly a joke, it would be fantastic to be able to use LLD, especially for cross-compiling. Having support for LLD wouldn't tie us to LLVM, it will always be the case that we support the system linker as well.
That code doesn't do what you think it does: you're shadowing the old `s_len` with a new, unrelated `s_len` during the match. Since binding a variable will never fail, the entire catch-all clause is dead code.
That's the error you get if you invoke `rls` with no data on stdin (specifically, if I run that on macOS, and then press \^D to close stdin, it spits out that error). You're not actually supposed to invoke `rls` yourself in the terminal. Your IDE is supposed to talk to it instead.
Just FYI, the singularization of the Inflector crate is pretty horrible, by coincidence I tried it a few days ago and it got a lot of names wrong.
I wonder if zero-copy deserialisation is supported for `Cow&lt;'str&gt;` too. It would be awesome to be able to deserialise with zero-copy and then mutate what's needed.
Fixed it, i was just misusing vscode. rls was looking for the wrong path and i thought i just didn't install it correctly but thanks anyway, now it's working correctly
So *this* kept me very busy for recent months! Kailua is an integrated type checker and IDE (VS Code) support for Lua, which makes use of special comments driving the type checking. The game studio I'm working for now internally is using or in progress of adopting Kailua for every single project requring Lua scripting. I'm pretty sure that this is one of the most complete solution for type checking with Lua, and after getting a clearance from the management I'm releasing Kailua as a free and open source software today. Enjoy!
If you want to deserialize escaped characters in strings, you have to use `Cow` anyway.
&gt; zero bugs. prove it.
What's the best way to deserialise packed structs from a byte slice? I looked into Serde but it doesn't seem to support packed structs as a data format. I also looked into Nom but the structs I am decoding are length(u8)-type(u8)-data triplets, and Nom doesn't seem to have an easy way to switch on a u8.
First of all, note that integration between gtk-rs and gstreamer-rs is not as great as it could be right now (https://github.com/arturoc/gstreamer1.0-rs/issues/25 and https://github.com/arturoc/gstreamer1.0-rs/issues/2#issuecomment-292595041) What you need to do here is to a) have GStreamer select a video sink that supports the GstVideoOverlay interface (which is unfortunately not wrapped yet in gstreamer-rs, so you have to go through ffi), b) catch the prepare-window message from the GstBus in a sync handler, and c) configure the native window ID (of the GdkWindow, which is also not exposed in gtk-rs so you need to use ffi) on the sink with the GstVideoOverlay interface. It's all not easy and simple yet unfortunately, some more work is needed on the bindings to wrap all the relevant parts. Generally you have to do the same as is done in this C example: https://cgit.freedesktop.org/gstreamer/gst-docs/tree/examples/tutorials/basic-tutorial-5.c Alternatively there is another option for rendering video by using the gtksink/gtkglsink elements of GStreamer. These provide a GtkWidget that you can directly integrate into your GTK UI. This will at this point probably also require some FFI usage unfortunately, but that hopefully changes soon. For that you can find an example in C here: https://cgit.freedesktop.org/gstreamer/gst-plugins-bad/tree/tests/examples/gtk/gtkglsink.c Note that there is also a GStreamer API nowadays called GstPlayer, which should make writing playback applications much easier. You can find the C docs here but it's also not yet wrapped in gstreamer-rs: https://gstreamer.freedesktop.org/data/doc/gstreamer/head/gst-plugins-bad-libs/html/gst-plugins-bad-libs-gstplayer.html#gst-player-new So tl;dr is, I guess, that more work is needed on the bindings for making all this convenient to use and without having to use FFI. Any help with that would definitely be welcome though :)
Both TWiS and the roadmap feel like they're missing a bit of perspective on where Servo is going as a project... Would it be fair to say that for now only the parts that can be used in Firefox will be polished to production quality, with the rest of Servo serving as a sort of testbed for experimental stuff and as a place for people to cut their teeth on implementing web standards from scratch?
Is it possible to expand the list of types? It could be really useful when working on a project where Lua is embedded in another program with [certain API's and classes](https://api.cuberite.org/index.html) exported to Lua. Also, is it possible to make it do checks over multiple files? A project I'm a part of allows plugins to be written using multiple files instead of just a single large file. I've seen Lua editors that only check the file you're working on. It looks really promising though, I'll definitely keep it in mind.
&gt; Best example is that you collect() a Vec&lt;Result&lt;T&gt;&gt; into a Result&lt;Vec&lt;T&gt;&gt; which still blows my mind! This example is in the documentation, so it's not *exactly* tribal knowledge :)
&gt; JSON is not JavaScript though Some background on this: http://timelessrepo.com/json-isnt-a-javascript-subset
But LLD *is* a linker. How it makes rustc closer to "not needing a linker"?
LLVM is the compiler backend used by rustc; the stuff that actually generates the binary machine code that runs on your processor and does all the performance optimisation magic. With every new version of LLVM, there are new optimisations that should result in better/faster/smaller binaries. In particular, IIRC, LLVM 4 has a new optimisation which eliminates some memory copying, which can really benefit Rust code. LLVM 4 also introduces new support for some processors that were not supported before, such as some ARM processors. Notably, it also introduces support for the AVR processor architecture used by Atmel microcontrollers (such as on the popular Arduino boards used for many electronics projects). These are all already usable with the Clang C/C++ compiler, but for Rust, someone needs to port/test/verify support in the core lib and rustc. There seems to be some effort being made on this [here](https://github.com/avr-rust/rust/).
The repo you linked to seems moribund :X &gt;AVR I'm super hyped for this. I'm teaching my dad to program using Arduino, hopefully Rust on Arduino becomes a thing soon.
It is too soon to talk about RISC-V. Only the user spec is done and the rest with the CSR and priv. spec is still in the works. The subset of the priv. spec about S-mode and M-mode should be frozen this year with the release of priv-1.10. Also the ELF spec is not done. There is so much to do before a typical Rust programmer can compile for RISC-V. 
This is really cool. It would be great if you could turn it into a 'survey form' type website, where it asks you "Do you prefer? [a], [b], [don't mind]" repeatedly and then generates your config at the end.
Fair point :)
We don't want to remove crates, since that has the possibility of breaking someone's build somewhere. We are working on enhancements to crates.io to help people find good crates as part of the [2017 roadmap](https://blog.rust-lang.org/2017/02/06/roadmap.html); for one, [RFC 1824 is in its final comment period](https://github.com/rust-lang/rfcs/pull/1824)!
Hard questions: what’s the mean and std dev of wage you pay your software engineers?
Rust support for this tool I wrote was somewhat horrible a week ago, but after some [contributions](https://github.com/fiatjaf/module-linker/issues?utf8=%E2%9C%93&amp;q=label%3Arust%20) and changes, I think it is near beta quality. I hope people here will bring me more feedback. Thank you.
Are you referring to `lld`? It's got decent `x86_64` support but I think it will be quite some time before it supports all of the LLVM targets that `rustc` supports.
You can see the in-progress work we've started at https://github.com/avr-rust/arduino
Username checks out. Though that grouping of three bits in the middle is bothering me.
&gt; Go then, there are other ~~worlds~~ branches than these. &gt; &gt; - Stephen King Yep, we've been working in other branches. For example, [avr-support-4.0-tim](https://github.com/avr-rust/rust/tree/avr-support-4.0-tim) was updated just yesterday ;-)
It already does, just not all cases. Not sure why it didn't here.
You're right, /u/kibwen is speaking in shorthand. Two things: 1. When using ld, if you want a _cross_ ld, you need to build it. Which takes a while and is annoying and all of that. LLD is already a cross linker, in my understanding. 2. We could [in theory literally put lld inside of rustc](https://github.com/rust-lang/rust/pull/36120) and then you wouldn't need a separate linker at all.
&gt; How does one find the good crates among the... not so good crates? I wrote [cargo-esr](https://github.com/rust-alt/cargo-esr) in an attempt to tackle that *problem*. It's not perfect. But it's good enough (IMHO) at narrowing down good choices. And unlike the ambitious RFC 1824 effort, it's already available and usable. Feedback welcome.
Hey, yeah, difficult :) It depends (mostly on experience and somewhat on the location where the person is based, since it is a remote-friendly listing), mostly discussed after the first interview. For reference, we have offices at Seattle and London, and our engineers seem to be living quite nicely at those places already.
Great point! I think it's a short oneliner title for one's application. But it's also optional, so no worries if skipping it, imho! https://www.quora.com/What-is-resume-headline Will check it with our team to make that one more self-explanatory, thanks for the feedback! And hope this won't put off anyone from submitting an application. ;) **[Edit]:** asked and it would be the person's current job title.
Can't you use the same `connections_inner` for removing it too? Like here: https://github.com/snapview/tokio-tungstenite/blob/master/examples/server.rs#L109
Neat! TIL.
Any chance that this works with firefox, given that it now supports web extensions?
I've released 0.1.32 because there was another bug apparently, but it's fixed now, cheers!
Both most likely since a lot of the compile time is spent doing llvm optimization, they probably also figured out other cases where the codegen itself to make new executables generated more efficient code
Good to know.
&gt; It's easier to get an overview of what features are available and what each of them is for and what it all looks like in practice this way than by reading and trying to digest a bunch of prose [...] You are right. I haven't taken much time to document all those things---there are tons of other things yet to be documented, not to mention that the already documented things may be not sufficient. I did attempt to document various internal interfaces (available at docs.rs) so that at least contributors to the internals can get some help though.
Is there a list of all (significant) contributors?
So what's the mean and std dev of wage you pay your software engineers?
I've run into this problem quite a few times (especially with game projects, since Piston and Amethyst have very, very many dependencies that are only occasionally re-exported), and I've never seen a helpful error message for it. In which circumstances is it detected?
That's always a tricky one — how do you decide what is "significant"? Is 100 lines of whitespace changes significant? A single character fix that causes the code to no longer erase your hard drive? 1 commit, 10 commits, 100 commits? To my mind Dylan has done the majority of work, so that's who **I** think of. Otherwise your best bet is to check the git author list ;-)
Maybe a clippy lint?
* `mut &amp;self` should be `&amp;mut self` * `my_function` in the lambda example should have `0` as the body not `0;` * destructuring requires struct name, e.g. `let Obj { x, y, z } = obj;` * `-&gt; ()` is unnecessary and unidiomatic
&gt; ECMAScript 2017 (JS) now features shared memory and atomics Not sure shared memory is something you want to bring up when arguing that Javascript is coming closer to the likes of Rust. ;) There are a few mistakes in there as well. Javascript isn't an untyped language, its type system is just really bad. You probably meant it's one of the fastest dynamically typed languages. Duck typing also doesn't mean what you think it does, I think you're confusing it with dynamic dispatch. 
Is there a way to find a transcript of this? I generally prefer to read than to listen, and this sounds like a great resource. 
Awesome! I just had a brief look at it. I have a somewhat-different vision for the design approach I want to take (but at this point it is still just an idea in my head). I want to make a higher-level, more generalised library (to control PWM/SPI/timers/etc) that abstracts away the capabilities and details of the different Arduino boards / microcontrollers behind a higher-level API. Yours seems to be designed around the Uno specifically. When I actually start working on it (might even be sooner than what I said before), I'll let you know so we can collaborate.
What would it lint on?
The compiler compiles itself, so any across-the-board optimizations will improve compilation speed.
[TimNN has stated that they are interested in AVR](https://github.com/rust-lang/rust/pull/40123#issuecomment-295278404), so that seems reasonable. Dylan picked up and (from my viewpoint) did all of the work to get LLVM to support AVR, which is a monumental undertaking. I've [done some work at getting support merged into Rust](https://github.com/rust-lang/rust/pulls?utf8=%E2%9C%93&amp;q=is%3Apr%20is%3Aclosed%20author%3Ashepmaster%20LLVM%20). Now I guarantee that I'm forgetting someone, and they are going to feel bad when/if they read this.
I've been using this for a couple of weeks now and it's been excellent. Thank you for working on it :)
In addition to what the others said, LLVM has been putting quite some effort into improving compilation speed, and they've done a pretty good job so far: http://lists.llvm.org/pipermail/llvm-dev/2017-April/112026.html
🤦 Wow what's wrong with me. Thanks, corrected!
Ah, they fixed the typing in the Windows previews! This makes it much better to play around with the nightlies on windows.
That's true, it has types (function, string, number, object, null, undefined), dynamically typed is a better way to put it. Corrected! Yeah I was really trying to focus on interfaces there, revised that section. Thanks!
can't put a trailing semicolon though, if you want to return data /s
I don't recall; I think when paths match in a type error, but it's not a perfect analysis.
Interesting, thanks! Do you know any good resources on Type theory? Would love to read more about it. 
&gt; Maybe play could add that as an option. Do you mean "a clippy button in a playground"? If so, [behold](https://play.integer32.com/)! (also has top ~100 crates)
I think Piece's book, [Types and Programming Languages](https://mitpress.mit.edu/books/types-and-programming-languages) is the book that most people would point you to. If you want more depth on a specific topic, then almost any paper by Simon Peyton Jones or Phil Wadler is worth reading.
Some minor nitpicks to an otherwise well-presented post. &gt; JavaScript's WebAssembly WebAssembly isn't really Javascript, any more than C is Python because Python can call C through FFI. &gt; Rust is fast, at times even better than C/C++ in performance, according to [The Computer Language Benchmarks Game K-Nucleotide benchmark](http://benchmarksgame.alioth.debian.org/u64q/knucleotide.html). Rust is fast, yes, but even when Rust is winning I'm still not comfortable with people talking about the Benchmarks Game in a manner that implies you can deduce things from looking at the table of numbers. The game isn't well controlled, so trying to deduce anything from a surface reading is likely to turn out badly.
~~Actually a couple things are broken as the APIs aren't completely compatible but I will try to make it work and get back to you.~~ I just missed running `npm install` and `npm run pack`, it actually runs just fine in Firefox. 👍 (But I had to add an "id" to the manifest file so I was able to use the Addon, I'm not sure yet if this is only needed during debugging or always.)
I think the reason that there are N initiatives is that everyone comes to Rust with a different background. For every piece of information that one person would find incredibly useful, another person would find it boring and obvious, and another would find it cryptic and baffling. We've tried really hard to demonstrate good Rust code in the book, but we don't have room to cover every possible construct. Our goal is to incrementally build up your Rust knowledge so that by the end, you can be productive in Rust and you're ready to read and write more Rust code. A book of patterns or recipes is actually [a book we're explicitly *not* writing](https://github.com/rust-lang/book/issues/253), if you end up writing such a thing it would be a welcome addition to the resources available!
Whenever someone asks "am I the only one" the answer is always "no". Except this time. I think you might be alone.
You may also want to have a look at this. https://github.com/jamesmunns/teensy3-rs-demo
Never mind. pub type NoteFunctionFactory = for&lt;'a&gt; Fn(&amp;'a Function, f64, f64) -&gt; Function&lt;'a&gt;; 
np! just wanted to make sure you got to the right place
This is something that [I've seen proposed before](https://internals.rust-lang.org/t/proposal-support-s-natively-via-llvm-mc/2879). While I had some objections initially, when coupled with the possibility of also shipping `lld` as a linker this could make it much easier to support a wide variety of platforms without dealing with incompatibilities of different assemblers, and support cross-compilation without the dependency hell of dealing with trying to get cross-compilation toolchains set up. Shipping out of the box (or via appropriate invocation of `rustup`) with support for cross compilation of Rust, a cross-linker, and a cross assembler would be a big win for Rust. Of course, at some point, you ask "are we developing a compiler, or a cross-platform development tools package manager"? It can be a bit hard to tell where exactly to draw the line.
Yeah, that's awesome! But that's another thing that new users have to find out eventually, whereas if it's in the playground maybe the docs can reference it directly without anyone complaining that the documentation points to some third party resource. I dunno, does that concern make sense?
Note: This subcommand is not part of cargo and needs to be installed. It is available [here](https://crates.io/crates/cargo-tree). 
Oh, I've got some slow background work to migrate our playground to the official one, so I agree with that point. However, there's always the issue of *which* third-party things to appear to officially condone. For example, I get frequent requests to add crate X to that playground. Since it's financially prohibitive to support *every* crate, some set has to be picked. It seems wrong for me to blacklist all the XML crates except my own, so I pick the top 100 downloaded crates. Likewise, does having a Playground button for Clippy disincentivize other people from producing competitors? It's never just an easy decision.
There's effort going into making all of Servo production-quality. For example, "stshine improved the inline size calculation for inline block layout. mrobinson fixed several problems with laying out absolute positioned blocks." are improvements to the layout system.
That's a good point. Actually, that question is central to the entire ecosystem, isn't it. :| All right. Sorry, /u/steveklabnick1, but I'm back to my usual solution to these things: I'll just lurk and whenever someone asks a question I know the answer to I'll try to pipe up. Doesn't solve your documentation issue, though. &gt;.&lt;
Thanks, I'll add some code samples for them then.
Thanks for the answer!
Thanks for offering to mentor me! It would be really cool :) right I'm not able to work on any side project due to university exams :( I'll be free from the 12th of may. 
&gt; segfault inside of LLVM clearly the only solution to that is rewriting LLVM in rust
:D
If you really want to be able to read papers like this read [Types and Programming Languages](https://www.cis.upenn.edu/~bcpierce/tapl/), which is probably the standard introduction to this kind of thing. It don't think it is available for free, but it is well worth the price. Another option would be [these](https://www.cl.cam.ac.uk/teaching/0910/Types/typ.pdf) lecture notes from the Cambridge types course. They're based on the first few chapters of Types and Programming Languages.
&gt; I'd certainly hope that's possible. Yes, now that I know about your repo, I will make sure to at the very least give your code a good read. Maybe I can directly make use of it in some way. Even if not, it will be a learning resource, together with Arduino and Atmel docs/datasheets and the Arduino C libs' source code. There are also several other comments in this thread with links to other Rust embedded efforts. Lots of great stuff to have a look at! :) I love the Rust community. &gt; My lurking fear is that there isn't a good abstraction across boards at some level. A lot of electronics-related functionality is very common (SPI, UART, PWM, etc.) and available on all boards (albeit with some variations). I already have some ideas for possible ways to abstract/generalise it, but I need to experiment a bit before I can really say how much of it will be useful. I have also thought about possible ways to elegantly separate board-specific code from the generic stuff so that Cargo features can be used to only build the module for the board that the user cares about. 
Syscall.rs looks like functionality that could be subsumed into [nix](https://crates.io/crates/nix), which I'm a maintainer of. We have a tracking issue for revamping our syscall support [here](https://github.com/nix-rust/nix/issues/341). I don't know if your plans were to only so *nix systems, but maybe we can combine forces here? We could even make you a maintainer if you wanted to after a few successful PRs as we need a bunch of work for the syscall subsystem. Edit: Fixed link to nix
Really your first 3 points are somewhat orthogonal to the work. There needs to be a bit of theory done to show how to add these features to MLsub, but there is no particular reason to think that they would not integrate with it. Higher-rank is likely to be the hardest to integrate into Stephen's presentation of the theory because he uses sets as part of his model for type schemes, but in terms of inference they could potentially integrate very well: MLF is the most complete form of inference for higher-rank types and it is based on subtyping. The fourth point does indeed make it very hard to add algebraic subtyping to Rust itself -- although it might be possible in some limited forms. Although that doesn't mean you couldn't create a rust-like language with algebraic subtyping included from the start.
Support for Firefox, as well as different version control system hosts (GitLab, Bitbucket, Gitweb, etc.) would be nice. Maybe if it's possible to add custom attributes, crate authors could add URL templates to point to a canonical web-accessible source for the code, e.g. https://github.com/hyperium/hyper/blob/v$VERSION/$PATH#L$LINE -&gt; https://github.com/hyperium/hyper/blob/v0.10.9/src/status.rs#L32
Thank you very much. Thanks to you and your unwavering will I've defeated laziness and computer slowness and managed to upload a working version to Firefox AMO. The `id` trick was providential. The URL is https://addons.mozilla.org/firefox/addon/module-linker/. It can't be installed yet, however, because it must be verified by some Mozilla personnel. 
I don't get your point about canonical web-accessible source. Any "blob" on GitHub already works, it can be a commit, tag or head of branch. Firefox support is coming. GitLab may come anytime soon, but it will require a lot of work. BitBucket is almost impossible, but if the extension gets thousands of users claiming for it I may be tempted to rewrite everything to support it.
Thanks for this, it's great! As a general comment about rustfmt, I find that personally, so far, I like "block" style everywhere as opposed to "visual" style, to fight rightward drift. Also, so far, any time I've ever seen rustfmt turn code into something completely unacceptable, it's been because the "visual" style shoved everything to the far end of the file where there wasn't much room. I would think that "block" mode would be more acceptable the vast majority of the time. Am I wrong? Are there examples of where block mode is completely terrible looking? It's unfortunate that a tool that has the power to end the endless fights over style would even have such a detailed configuration that would just continue fights over style. Ideally, it would just produce a style that's mildly acceptable in all cases, and we could all agree that the consistency is nice and all quit worrying about style once and for all. Where do we see the future of rustfmt? Will almost every project use the default? Will the default be considered an "official" rust style? Do we expect that every project will maintain their own detailed custom config files? Will there be popular configs that do all-block-mode indention like I seem to like, and I could just copy their configs?
&gt; It can't be installed yet At first I didn't believe you, but then I tried it and even though it tried to install, Firefox prevented me since it's not signed. I'm sure there's a setting somewhere that I can turn off to allow it, but I suppose I can wait a couple days or whatever.
I don't think you understood. I meant that if this extension and similar tools could read a special crate attribute that tells you where the code is hosted, you could generalize this feature over many different code hosting services. It would require crate authors to be aware of this custom attribute but if it was made an official attribute in cargo's docs it could be really useful for this. You wouldn't be able to add links to arbitrary version control websites, but you would be able to add links from known version control hosts to unknown ones. Edit: and also, not all crates are hosted in the root of the git repository listed in Cargo.toml. They could be in a subdirectory and there's currently no way to specify this in a crate's attributes.
&gt; unityped language Is that kind of like C\#'s `object', where even `int`s derive from it? Or is there a different nuance to how JavaScript works that makes it different.
Trait impls aren’t very discoverable IMO. There’s usually a lot of uninteresting implementations, and buried among them would be a few oddballs here and there like `impl&lt;A, E, V: FromIterator&lt;A&gt;&gt; FromIterator&lt;Result&lt;A, E&gt;&gt; for Result&lt;V, E&gt;`. If only there was a [Hoogle for Rust](https://www.haskell.org/hoogle/?hoogle=%5Bm+a%5D+-%3E+m+%5Ba%5D)…
&gt; implies you can deduce things from looking at the table of numbers For popular languages, it at least gets you in the ballpark though. Rust is in the same realm as C and C++, JavaScript is roughly an order of magnitude slower (not bad!) and Python is another order of magnitude slower. However, once you're within an order of magnitude, it ceases being useful as it comes down to hashing algorithms, cache locality vs allocations, etc that need to be tuned for each performance-critical solution.
I just wanted to say that glassful is a very cool library, and could fit in the Rust gamedev scene.
Does the [`switch!`](https://docs.rs/nom/2.2.1/nom/macro.switch.html) macro work for you? If that doesn't help work, describe the data layout in more detail and I could write out a little example parser.
japaric maintains a fork (?) of syscall.rs called sc. I've used it for the last few months. He might be interested in the crates.io name...
&gt; Which is fine, but... why couldn't all this just be inferred? You might be interested in this thread https://www.reddit.com/r/rust/comments/64zhjo/why_do_we_need_explicit_lifetimes/ Check that out, and then I'm happy to say more.
Well, at least with the current system `extern crate` declarations don't include all the info cargo needs though. `Cargo.toml` has versions and/or information on where crates can be found, as well as things like features to be enabled; none of these are relevant for rustc at the time of building your crate but are used by cargo to download and build your crates dependencies.
JSON supports borrowing strings that contain no escape sequences. It will fail to deserialize a string like `"a\nb"` into a `&amp;str` exactly the same way it would fail to deserialize it into a `u32` or any other non-String type. Borrowing is useful even in JSON for string fields that contain a hexadecimal SHA hash or similar value that you know will never need escapes.
Ok, I think I more-or-less understand it, although it seems to be somewhat out of the scope of this extension. Having the full path of the source code specified at Cargo.toml would be useful no matter what. Something like that is what the Golang package system does, isn't it?
Thanks for the link. I understand that my question is part of the popular genre of "begging for lifetime inference" :-) I do see this as somewhat different, though. I'm not really asking for general lifetime inference as I understand the complexity issues that would occur with such an approach. Rather I'm wondering if there's some reason the existing elision rules don't apply to function signatures produced using generics? The rules listed [here](https://doc.rust-lang.org/nomicon/lifetime-elision.html) would seem to apply equally well to situations like `impl Get&lt;&amp;u64&gt;` like I listed above.
Oh wow, I didn't even know that. I read online to use cargo tree, and I must have forgotten installing it. 
Common patterns (as discussed here) that could be replaced by usage of `collect`.
New versions of Firefox just don't allow it, nightly or unbranded versions support unsigned add-ons if you set that key https://wiki.mozilla.org/Add-ons/Extension_Signing
TIL https://www.mihneadb.net/type-search-for-rust-docs/
&gt; what we are doing is agglomerating all of the values of the language into a single, gigantic (perhaps even extensible) type Ok, so it's kind of like Go `interface` as it holds: - the interface definition - the pointer to the data (which includes a pointer to the type definition) So, if a language did something like Go does with `interfaces` (every variable binding holds the type of data it is), then that language would be uni-typed? And I'm guessing this is a language-level distinction because JavaScript (and any language implementation, for that matter) can have multiple types through a JIT, where the types can essentially be memoized and the type checks omitted from critical paths (e.g. check once at function call and assume they won't change throughout execution of the function). That was an interesting read, thanks!
Indeed, but that doesn't fix the "very old library" problem. :-°
That would make me happy :) It's basically just a proof of concept. It could probably use a full rewrite to target Vulkan.
The precise implementation doesn’t really play a role – what matters are the semantics at a surface level. The whole “unitype” idea is really just an abstract and somewhat facetious way of saying that these languages don’t have type checkers at compile time. I would not read too much into it :)
Big thanks for /u/llogiq for pointing me in the right direction to getting this working today!
This is really neat. Great idea!
omg I'd love it if rustc could handle assembly files. that'd remove *all* remaining uses of the C compiler in Robigalia!
Lua can't be Sync, but why can't it be Send?
Perhaps you should try [`#[proc_macro_attribute]`](https://github.com/rust-lang/rfcs/blob/master/text/1566-proc-macros.md#detailed-design), which is available in nightly now (the syntax would need to be changed to `#[rdoc("doc.md")]` though.)
From the docs I was sure only #[proc_macro_derive] was around but this is most likely what I'll want to do going forward! Thanks for the heads up!
Correct. Same thing for Bincode and any other format in which the Serde data model's "string" and "byte array" types are represented without escape sequences - they can always deserialize to `&amp;str` and `&amp;[u8]`.
I know it's something I've wanted occasionally especially just having the README be the crate doc. I might work on an RFC for it then if there's enough want for it.
The way `Rc` in the stdlib handles this is by providing [`try_unwrap`](https://doc.rust-lang.org/std/rc/struct.Rc.html#method.try_unwrap), which transforms an exclusive `Rc&lt;T&gt;` (which is not `Send`) into a plain `T` (which could be `Send`). Then on the other side you can re-wrap it as `Rc&lt;T&gt;`. Now this unwrapping and rewrapping may not be very efficient. You could in principle work around this by writing an wrapper type `struct ExclRc&lt;T&gt;(Rc&lt;T&gt;)` which unsafely implements `Send` and does some checking during construction to make sure the `Rc&lt;T&gt;` has only one owner.
If you're doing reference counting across threads you're going to need [Arc](https://doc.rust-lang.org/std/sync/struct.Arc.html) not Rc. I've modified your example to use Arc instead [here](https://play.rust-lang.org/?gist=b4907f048fb709cfbdce9370a9bde7df&amp;version=stable&amp;backtrace=0). But it looks like Lua will need to implement Send and Sync for it to work. I'm not sure what you can do to avoid unsafety or if it is safe but the compiler doesn't know. Maybe somebody else can help you out a bit better.
The reason why `Mutex&lt;T&gt;` requires `Send` on `T` is because one could lock the mutex, clone the `Rc`, and then unlock the mutex. Now you have an `Rc` that is still connected to the original `Rc`, but it’s alone and no longer protected by the mutex. To make this safe, it’s necessary to find some means to block the `Rc` from being cloned while inside this mutex. There are probably ways to do that, but the complexity will depend on how much flexibility you want to keep on the `Rc`.
I believe that's exactly what I've done here? SendWrapper does not allow types that are !Send to leak out, so you cannot get a cloned Rc out of the SendWrapper (but you can use Rc types while inside the visitor). Are you saying there's a way to get the Rc out that I'm not seeing?
Btw. is the Lua API wrapper publicly available somewhere? It would be interesting to see.
Hm, if you are doing message passing on every interaction anyway, isn't that basically no different from locking on every operation? I understand that the wrapper is intrinsically !Sync, but is it also intrinsically !Send, or is that just because of the Rcs? It seems to me that if you could somehow guarantee that there isn't anything that could access the Lua state left "lingering" in the earlier thread upon send, you could mark it Send. Couldn't you have something like having the Lua state guarded by some synchronisation mechanism, and then perform actions to the guard? That would mean that you don't have to lock and unlock on *every* operation, but only once for a bunch of operations.
Oh.. you can create an Rc and then put it in a RefCell in thread-local storage, then the system changes threads and boom :( There's absolutely no way around that whatsoever is there. That's.. incredibly disappointing!
Such parameterisation will definitely get easier with ATCs. It's unfortunately not appropriate to switch based on a feature flag, though.
Is that because of the "features should be strictly additive" rule?
This is super helpful! Thanks for putting this together.
For those, like me, who had no idea what a Popsocket is: https://www.popsockets.com/pages/learn
yes and no. In order to do that you need copiable keys. because you need to take next keys but then you borrow from the map. so in order to do a remove which borrows rw you need first to copy the key you got from the next in order to release the RO borrow. this will cost you as overhead the copy + one extra lookup and you need to implement copy for your key type. let's be clear : i'm not saying it is a big deal. you can weasel around to get it working. my point is that is not so easy to design an api and hit all use cases. on the opposite it's very easy to just say that the use you didn't plan is just a corner case.
The biggest issue I've had with Rust is the library ecosystem maturity. I did a ton of backend Python stuff for my last job and I would've switched to Rust had I stayed there, but there are a lot of libraries missing that existed in Python. So I wanted to ask, what libraries have you used in your Rust projects, how have you liked them, and how did their ergonomics compare to their equivalents in the Python ecosystem?
There's an open issue about it https://github.com/rust-lang/rust/issues/15470
Not sure how easy this one is. Let's say I have a type that wraps `[u64; 100]`, or something similar relatively large. The values are created at run-time. And I have a collection that may hold a lot of those values. However, I know that there will only be a few unique values of the type, so I'd rather keep then as pointers to a collection of the unique values instead, saving space. What's the best approach for it?
&gt; I am definitely not qualified to judge, but my first impression is that string handling is kind of a mess/difficult. My gut reaction (perhaps this was from Python background) was it seemed like it is principled at the expense of being practical. Python has immutable, reference-counted strings, so it hides a lot of magic, at the expense of unnecessary allocations. If you want strings that are simpler to use at the expense of performance, try [easy_strings](https://github.com/Storyyeller/easy_strings).
rust-zmq: considerably more low-level than pyzmq lib and very little documentation. took a while to run down 1) the hwm was automatically set pretty low and I was dropping messages, 2) no indication how to set hwm, had to look in the code for a long time. but the library is working great. serde for json parsing: performance seems to be great, mapping the incoming json objects to structs was a bit rough but probably since I was learning new language at the time. time: seems to be working ok. it's only day 2, so that's it haha. to be clear, I'm still going to need to send data back from rust to python to run code on gpu via theano. my plan is to use rust for the most performance critical parts (where python is slow) and zmq to get data back and forth. 
I'm genuinely surprised you find the syntax economical, the other Python programmers I know have switched to Rust complain about its verbosity. A few questions: - Did you find it difficult to use iterators? I'm used to abusing generators in Python and had quite a hard time giving them up in Rust. - On your second day with Rust, did you find yourself compelled to use boxes? For example by returning an iterator. - Did you use any external crates? If so, did you find crate usage straightforward or was the documentation unclear? No pressure to answer of course, I'm just curious. PS: there's a great crate out there called [ordermap](https://github.com/bluss/ordermap) that you'll probably like. It's a dictionary inspired by Python's recent re-implementation of dicts. It's backed by a Vec and is therefore crazy fast for iteration purposes, and is also 100% safe Rust. In recent news, Rust beat C for the [k-nucleotide benchmark game](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=knucleotide) thanks to this structure.
Wow, that's a great success story and very valuable feedback! Have you tried clippy yet? It's a great way to get automatic suggestions on how to tweak your code (as compiler warnings). Assuming you use rustup, it's just a `cargo +nightly install clippy` and then `cargo +nightly clippy` away.
No because you can only switch on byte slices, not integers. I think the `alt!` macro might work but I haven't had a chance to try and it also looks way too general to generate efficient code. I'm trying to parse USB descriptors which are a classic length-type-data thing like this: length: u8, type: u8, (more fields depending on the type) 
Can you explain why? I'd like to provide an rust idiomatic API and `struct Model(model)` is a just a newtype of model. If I keep the old signature for the callback I also have to expose the old `model` type. Also the user would then be forced to dereference the pointer.
&gt; It would be very helpful if there were more "tutorial" type articles that described a problem and how the author used rust to solve it. There is some in [rust-learning](https://github.com/ctjhoa/rust-learning) (disclaimer I'm the owner)
Rust references must never be NULL, a pointer can be NULL. By directly having the pointer converted to a reference you a) hide that a pointer is involved and b) have no way of actually checking that this requirement holds (and if it's just an assert!(!ptr.is_null()) )
 let sum = samples.iter().fold(0.0, |_, sample| (sample.to_raw() as f64).powi(2)); The into_rms function confuses me. I may be wrong but it doesn't seem like you're summing the floats, but only returning the last one. Unless there's fold magic I don't see.
I think you should use [`-c`](https://perf.wiki.kernel.org/index.php/Tutorial#Period_and_rate) instead. Your log clearly indicates that it has "woken up N times to write data", and N correlates to the number of samples actually taken. With `-F` the kernel will dynamically adjust the sampling rate to match the frequency [1], which can be inaccurate for short-running programs. `-c` will fix the frequency from the beginning and avoid such problems. [1] The linked wiki page explains why this is required. In short the sampling is done via counting the number of interrupts and triggering the write when it reaches some threshold---it is never related to timing.
Just use references (i.e. `&amp;[u64; 100]`)? The details depend on where you want to keep your pointers. You could for instance have a `Vec&lt;[u64; 100]&gt;` with the unique values and a `Vec&lt;&amp;[u64; 100]&gt;` for the non-unique references. To safe space you might even consider a `Vec&lt;u32&gt;` with indices into the vector with the unique values.
We could host it under the PistonDevelopers organization, if somebody are interested in working on it.
Inserting is also fairly fast.
Your experience with Rust feeling like a "superpower" is also how I felt when I arrived from C#. Not having to put everything in a class (which in theory is a benefit in Python too, but in all the industrial Python code I've worked on 90% of the code is OOP) is awesome, but the raw, obscene speed of the whole system is amazing. The best bit is that I always feel like I know where to put my optimisation efforts (I managed to knock 15% off the runtime of another dev's already-optimised tool within a few hours of looking at the code for the first time). As for lifetimes, you _almost never_ need explicit generic lifetimes. Occasionally you need `'static`, but the only times I've seen that explicit generic lifetimes are needed is when you have an output borrow that relies on one of a set of input borrow arguments, which is fairly rare. I actually dislike the syntax, but if I designed Rust I would have made it a Lisp and it would have never been adopted, so I'm at least happy that others are making the decisions for me and that they're not utter cretins. A low bar, I know, but the only syntax decision I really care about is homoiconicity vs non-homoiconicity, and most other syntax evolves naturally from the semantics of the language. Right, so `String` is difficult when you first come to it (hence the breathless "OMG Rust has 400 different string types!?!?" comments you see) but it's absolutely the right decision. A lot of other languages treat strings as magical wired-in black boxes, but apart from literals you can more-or-less define strings yourself in Rust. That's not true for any other language I can think of except C/C++ (but I might be wrong there). You get used to the concepts very quickly. Once you understand borrowing you will understand strings, simple as that.
Syntax seems to be to a large part a matter of what you are used to. When moving to Python, the Indentation Instead of Curly Braces thing bugged me. When I switched to Rust, the curly braces bugged me. Now I am fine with them again. Other than those braces, I don’t think the syntax is actually all that different.
I'm sure petgraph would be a good candidate, paging /u/neutralinostar
&gt; I decided to try Rust because despite fairly heroic efforts, the Python code I have been working on was just not cutting it. Aside: did you try `pypy`? And could you instead consider a sorted list of `namedtuple` or something similar?
Check out the [syntax index](https://doc.rust-lang.org/stable/book/syntax-index.html). It is a good resource when you have some idea of what you are looking for, otherwise you can just read the entire page and possibly stumble across something you need.
Yes, want!!!!
Right now it's one item per file. I can try to figure out a way to allow it will be split up through a delimiter of some kind. Feel free to open up an issue on the repo. If you don't have the time I'll open one up for you when I get the chance!
One of the first code samples looks pretty clearly wrong... // Replace, e.g., "1 + 2" with "3" expr.transform(&amp;mut |ref mut expr| { if let BinOp{ref kind, ref left, ref right} = expr.kind { if kind == Add { if let Literal(I32Literal(l)) = left.kind { if let Literal(I32Literal(r)) = right.kind { Ok(Expr{ ty: Scalar(I32), kind: I32Literal(l + r) }) } } } } None }); The `Ok` in the middle is created and then immediately discarded. The closure always returns `None`... Also, the `expr` parameter seems to be mutable for no reason.
It already is a good choice! :D https://github.com/frankmcsherry/timely-dataflow https://github.com/frankmcsherry/differential-dataflow 
I tried doing a `proc_macro_derive` but it puts the doc comment after the struct you want to document not before :( might have to do it in the convoluted way you mentioned in order to get it to work on stable. I'll experiment at some time.
I'm workign on a [Raytracer](https://github.com/k0nserv/rusttracer). Been figthing with triangle mesh rendering and [visual bugs](https://www.reddit.com/r/raytracing/comments/6792vc/holes_in_rendered_models/?utm_content=title&amp;utm_medium=user&amp;utm_source=reddit) the past few days. Think I solved it now though. Planning to work on acceleration structures now, likely bounding volume hierarchies. Also want to implement smooth shading via vertex normal interpolation.
Wasn't this discussed here recently? https://www.reddit.com/r/rust/comments/66eodg/algebraic_subtyping/
Damn. [Forget everything I said](https://play.rust-lang.org/?gist=a6ff229d4c4ab4a89b3bb1184f7700df).
I have more crates than .. my code has smells? Um. Let me work on that. Yeah, I went with abomonation back when I was super keen on that most of all. Maybe I should update it. ;)
&gt; That is, the same code in Rust sometimes takes a few more lines of code than Python, but requires far less documentation on how to use it: type safety usually ensures it only gets used correctly. Ah, but this is how we end up in a situation where tons of crates exist that have limited documentation ;) Just because it can't be used incorrectly doesn't mean it's obvious how it *should* be used.
&gt;I am confused about whether I should be using stable, beta or nightly. Basically, how much awesome new stuff do they have and how unstable are they? There are a lot of interesting features behind feature flags in nightly: https://doc.rust-lang.org/nightly/unstable-book/the-unstable-book.html (I think the "unstable" part mostly refers to that the syntax of the unstable features might change in a future update, in contrast to the features in stable which are guaranteed to be forward compatible.)
I mean economical as in efficient, even though it's relatively wordy compared to Python all of the additional syntax contains a huge amount of information in it. There's a lot of steps taken to reduce typing, like f64 not float64, fn is two characters, etc. - At the present moment I know that rust has something called iterators, I have looped through them but ran into a wall trying to return one from a function. So waiting for more info I guess. - Have yet to touch boxes in my code - Yes used rust-zmq, serde and time, cargo is great but docs are sometimes lacking Thanks for showing me ordermap - I will definitely give it a look. In my case I'm using the std BTreeMap as my core data structure as I need to keep the keys sorted. 
ah - good to know, thank you
I definitely benchmarked sortedcontainers but it was slower than banyan in my use case. sortedcontainers was runner up though. 
Just FYI, `pypy` has excellent support for emulating CPython's C API these days. And pretty good support for numpy IIRC. That said, there's not much to be gained if your cycles are primarily spent in C code.
Holy verbose and redundant code batman! Box::into_raw(Box::new(WeldConf::new())) There *must* be a better way.
An immutable heap allocated string is `Box&lt;str&gt;`. Stack space is cheap so it's rare you need that over `String` unless storing it in a struct that is itself heap allocated. I don't think it's fair to characterize it as "my most frequent use case is to bypass borrowck". In these cases usually an owned string is the only solution -- not from a compile time perspective, but from a runtime one.
I'm genuinely interested how that would compare to the 30-40x gained by switching from already heavily optimised Python code to (beginner?) Rust code?
As another python user, I came to the same conclusions! I think you can stay on stable now that macros 1.1 and `?` operator are in. I use nightly myself mainly because of habit. I do run tests on stable/beta/nightly for all my crates though. You should install clippy (`cargo install clippy`) to get a very very good linter. For a quick reference I sometimes use http://rustbyexample.com Macros are quite simple to write for basic stuff actually, it can be something as simple as https://github.com/Keats/gutenberg/blob/master/src/config.rs#L42
The point about having an awesome compiler was proven again to me a few days ago when I worked on the XPath exercises over at HackerRank, the reason being the surrounding code is only available in Ruby and the error messages you get when something goes wrong are basically non-existant. AKA just a backtrace of functions/methods and no real "error message" at all.
Ah there's no reason to rename petgraph though.
In my case I am implementing Genetic Programming. But for neural networks and deep learning stuff you should definitely check out the work of [AutumnAI](http://autumnai.com/)! It is in Rust. I'm taking a look at the guide now, thanks :)
Thanks, I was looking at https://github.com/georust/rust-geo as an example too. I think I'll go with traits in their own files. It seems easier now that I think about it.
TL/DR: Change `inner_get_a_foofy()` to `Foo::inner_get_a_foofy()` or `Self::inner_get_a_foofy()`. Rust never looks up names in the enclosing `impl` scope like that. It only looks for local variables, names that have been defined in the module scope, or names that have been explicitly `use`d. This makes the code more predictable and less fragile. If you see a function call, you can always know for certain where the function has been defined. You can move code in and out of `impl`s without it unexpectedly changing meaning. If you add a new function to an `impl`, you'll never accidentally change the meaning of old code. This sort of robustness has been a design principle for Rust, at the expense of some extra verbosity. Now, the reason `i.inner_bar()` works is because it knows to look for a method defined on `i`. It has nothing to do with the fact that you're typing it inside `impl Foo`; that call would work anywhere in the whole module. So in the same vein, you need to tell the compiler where to find `inner_get_a_foofy`. You can do this with `Foo::` or `Self::`, or by explicitly `use`ing it. (`Self` is a magic word that always names the type currently being `impl`d.) 
Depending on how your code is organized, you might have difficulty keeping the collection of unique values borrowed. (That might be because you need to push new values into it over time, or because you need references that last longer than the collection they came from.) One way to work around that would be to keep a `Vec&lt;Rc&lt;BigT&gt;&gt;` or something like that, so that the Rc's you pull out of it can have an independent lifetime.
So yeah turns out you're right. I was running into a lifetime/ownership issue at the time I wrote that and the `connections_remover` hack fixed it. I guess I later rearranged my code in such a way that the hack wasn't necessary but I swear I needed it before!
That nest is insane, could he not of done something like this? (i mean the structure): // Replace, e.g., "1 + 2" with "3" expr.transform(&amp;mut |ref expr| match expr.kind { BinOp { kind: Add, ref left, ref right } =&gt; { let Literal(I32Literal(l)) = left.kind; let Literal(I32Literal(r)) = right.kind; Ok(...) }, _ =&gt; None }); Those pattern destruction can clearly never fail, no? (`Ok()...None` definitely makes no sense, easy to miss with that nest)
Or right.... I missed the fact the `Literal(..)` is probably `ExprKind::Literal(...)`.
I have heard the phrase "Type Tetris" in the Haskell community, in reference to refer to the phenomenon of trying to figure out how to use a poorly documented library by how the types fit together.
Returning iterators is harder than it needs to be, but for good reason. Every step in an iterator chain returns a new struct that wraps the rest of the chain as a borrow. So the type of a bigish iterator quickly turns into generic code madness. What you need is a way to say to the compiler "I'm returning something that implements the iterator trait, and I don't care what it is." Fortunately you can. On stable there's "trait objects" like `-&gt; Box&lt;Iterator&lt;Item=i32&gt;&gt;`. These have a slight performance penalty for heap allocation and a virtual method call. Also they can't be inlined. On nightly you can use "impl trait" which looks like `-&gt; impl Iterator&lt;Item=i32&gt;&gt;`. This takes advantage of the fact that the compiler knows exactly what type you're returning so it just fills in the blank. I think you are limited to a single type though, so you can't​ return a different Iterator based on an if statement or something.
I'd myself make it multi level. First create lowest-level layer and then add convenience layers.
I want to use symbolic values in the switch, e.g. const FOO: u8 = 1; Can you make it work with that? Thanks for the function example.
&gt;Thanks to you and your unwavering will I've defeated laziness and computer slowness and managed to upload a working version to Firefox AMO. I guess I'm glad I was able to help you lol. Thanks so much for the addon, it's working really well and having it in Firefox means I will actually use it in my every day. 😀
&gt; they're characters from the Canadian Aboriginal Syllabics block Oh my god
Just say the word, and I'll be glad to update it for you :)
I'd actually recommend [The Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/) to learn. It's helped me immensely with that.
Here's the GitHub link from the tweet: https://github.com/mitsuhiko/indicatif
True. Sorry for the noise.
What IDE did you use?
&gt; I've been with Rust forever and I still don't know how to write a macro. I know how to write macros, but I still choose not to unless in extreme circumstances. Like in Lisp, macros are a feature of last resort.
I use VS code with the [rust](https://github.com/editor-rs/vscode-rust) extension for all my rust coding. It's served me very well so far, anything that I can't do with the key combinations provided by the extension can be done with the integrated console, so I really have no complaints.
Thanks for sharing this, just spotted a `pub` in the trait method declaration, which should be removed.
I currently use emacs with the [spacemacs](http://spacemacs.org/) configuration. This makes easy to enable features such as code completion, error checking, rust support , etc.
I think that's just a random demo, not integrated into cargo.
 Don't really understand the issues with anonymous parameters. Can s.o explain more please ! :&gt;
I am currently using atom with a bunch of plugins for rust. Namely: [atom-language-rust](https://atom.io/packages/atom-language-rust) [linter-rust](https://atom.io/packages/linter-rust) [autocomplete-racer](https://atom.io/packages/autocomplete-racer) [rustsym](https://atom.io/packages/rustsym) Also [dbg-gdb](https://atom.io/packages/dbg-gdb) gives you an interactive and graphical debugger that works with rust and [vim-mode-plus](https://atom.io/packages/vim-mode-plus) is a very good vim emulation, if you are used to that. I am switching between this and the already named VS Code rust extension from time to time. Currently it seems VSCode got the upper hand again with RLS support, but that changes quite frequently. Atom just requires a little more maintenance to find the most up to date plugins for rust support, while VSCode has this one nice and maintained package. I have also tried the mentioned vim and spacemacs plugins for some weeks, but I noticed, that I really prefer GUI applications. For anyone that feels similar, I hope this was a helpful read.
It's really neat, almost feels like a complete IDE experience.
How does this compare to the `progress` and `pbr` crates?
Author here. I can't talk about `progress` but i used `pbr` but the reason I replaced pbr with this for my own uses is: * this one is automatically synchronizing so you can use it with multiple thread etc. * this progress bar supports turning off easily * it uses a simple template system for styling which is easier to customize * it correctly calculates widths if ansi codes for coloring are involved * the finishing of progress bars supports hiding them again * progress bars can be crated on the fly if multi progress bars are used * it supports progress bars that are just spinners * progress bar messages format more appropriately (eg: can be set to fixed width)
What about providing a library to generate graphics separately from the execution code? That would be awesome :)
&gt; WebAssembly isn't really Javascript, any more than C is Python because Python can call C through FFI. I was under the impression that "JavaScript's WebAssembly" is closer to an after-the-fact version of "Java's JVM", in that WebAssembly bytecode was specifically designed to be quite close to a binary representation of a JavaScript parse tree, such that existing JS engines could be used to run it with minimal effort. The relationship between the two is, at any rate, much closer than "Python can call C through FFI".
The way I'd describe it is, roughly, if you were to define the following enum in Rust: enum JsValue { Null, Undefined, Boolean(bool), Number(float), String(String), Object(HashMap&lt;String,JsValue&gt;) } And then every value in JS is of type `JsValue`.
I disagree with this. You might as well just always develop on nightly, there's no significant downside and it makes it easier to use tools like clippy, rls. There is a tradeoff however in using nightly-only-features (i.e. anything behind a `#![feature(foo)]` flag), since those are actually unstable. You should program so that all your code runs on stable unless you have a good reason not to. 
The use of "forall" is very standard in type theory for polymorphism (generics), but not really used elsewhere, so it understandable that you wouldn't have seen it, particularly since most FP languages don't actually use it (though it shows up in odd places in Haskell).
Because "create on heap" isn't an operation that should have to go through a managed-ownership library type first, if managed ownership is not wanted. It's a completely unnecessary detour - even if it's zero-cost in the end. &gt;(Note that Into is just a library trait and does not give any new coercions or similar.) Right, for a moment I forgot that `Into`/`From` isn't implicit. (Which I find very unfortunate, but that's a different topic...) The best we could do then, I guess, would be ~~&amp;nbsp;`(box Foo::new()).into_raw()`&amp;nbsp;~~ `Box::into(box Foo::new())`. ~~Still, there's a missing specialization for *mut T that would allow .into() instead of into_raw().~~ &gt;I think it should be explicit. Where we come to the problem - there's no explicit way to construct on the heap. There's `box_syntax`, but it's hidden behind a feature gate and only partially solves the issue. There's the worked-on placement syntax, but it hasn't seen progress in two years(?). Stable Rust *apparently* constructs everything on the stack, and the only way to put something on the heap is to allocate and construct on stack, move into a managed type that allocates on the heap and copies it there. If you just want a pointer to a new heap-object, do all of the above and then move the pointer out of the managed type. That already sounds very wrong... In practice those operations get optimized away - but that's the opposite of *explicit*.
I see, thanks. 
The friends page is usually intended for companies actively using Rust (usually interpreted as "we have money on the line"), rather than just listing organizations who have produced some Rust code under their banner. E.g. there's plenty of Google-owned Rust code out there, but unless Google puts that code into a production capacity we wouldn't put Google's name on the friends page (and of course we also require companies to opt-in to the friends page, we never assume that we're free to list them just because we know that they're using Rust).
&gt; Unfortunately this is, imho, only due to other languages lying about their apparent simplicity. 100% agreed. The str vs String issue was painful to learn when I needed to get something done *now*, but by not hiding that ugliness from the user, it allows them to avoid making a bunch of critical errors in the future. 
I have been going through the reference all afternoon. 10/10. Thanks! 
Seems nice. Does it windows?
I've always wondered how you can re-draw inplace in a terminal, what do you use to do this?
Awesome. I only checked the examples. A couple of thoughts: * The `single` example handles small VTYs and dynamic resizing very well.. great. * Maybe if sizes can be % of `COLUMNS` instead of absolute. The other examples would handle smaller VTYs better. * Can multiple progress bars exist in the same line? If not, is there a way to have multi-progress in the same bar?
Aren't function calls in Python essentially dictionary lookups?
What I like to do is put traits that are implemented for multiple things in their own file, with all implementations in it; standard impls and traits that are only implemented for a single object, go underneath that object. 
For a single line, the `\r` character brings the cursor to the beginning of the current line, so you can draw over it. For multiple lines, you need terminal-specific control codes or a library like [ncurses](https://en.wikipedia.org/wiki/Ncurses).
I think this is comparable (identical? haven't read the code)to [linked hash map](https://crates.io/crates/linked-hash-map). Maybe looking at the source will be of interest to you!
wait vscode is open source? i never even realised...
I've had great luck with intellij.
not that im opposed to microsoft paying some reperations to the open source world, but im confused about wth their endgame is with this, also if i compile it myself, will it still contain the telemetry or do i need to patch it out by hand?
Nice job! It's great you've taken the plunge and built something you want to publish. A similar library exists called [LinkedHashMap](https://github.com/contain-rs/linked-hash-map), that allows one to retrieve entries in the hash map in the order they were inserted. However it doesn't support efficient random indexing, or any at all, so your library is great for solving that issue. One thing I would recommend is finding a way to get rid of the `Named` trait requirement. I see that your trying to use it to allow items to specify their name, but it will be more appealing to incorporate the name into the return type or input type of read/insert/update methods. The name sounds fine to me IMO. 
Work continues on my lossless TOML parser. This week I'm making multiline strings parse correctly.
Yep. I guess padding with spaces to the terminal width should work. But you will need to query the terminal width with each update. Using the escape code is easier for lazy people like me ;)
Have you read the document at https://github.com/matklad/rfcs/blob/anon-params/text/0000-deprecate-anonymous-parameters.md ? If so, could you point out which parts of it you don't understand?
And then you discover `CStr`, `CString`, `OsStr`, `OsString`, `Path` and `PathBuf`.
Yes, that's exactly the sort of thing I was wondering. Thank you
Maybe so! What's the project? Also, I should point out that I'm probably not done implementing methods from `Vec`. Pull requests encouraged ;)
TOML parser. I want to retain the order of the keyval pairs (vec) but but ofc I want it searchable (hashmap). Your comment about the name being intrinsic to the item being stored applies to key/value pairs pretty well. I'll have to play with it to make sure but it's nice to have options either way :)
This is very neat. I just integrated it with a cli that uses `hyper::Client` a lot. Required wrangling with buffers and the read / write traits a bit, but [managed to get this gist working](https://gist.github.com/clux/25feae0e300dc66f1d101a9fd56ada18) without too much pain. Getting a useable ContentLength was actually the most painful part.
My report on Windows 10 Insider Preview (should be no different to current stable, Creators Update) with conhost.exe and an unusual font selection ([Triplicate](http://practicaltypography.com/triplicate.html)): - multi works well, but flickers quite a bit. - download works well and looks great. - single is printing 60 characters and then *wrapping* even though my terminal is 120 characters wide; this naturally throws things off. Something incorrectly reckoning the character width as 2 rather than 1, I’m guessing? - morebars is slightly more screwy in probably the same way as single. Thanks for this, it looks good! Now I just need to come up with a decent excuse to have a CLI progress bar… (Update: with Lucida Console, but still with codepage 65001 [their moderately broken UTF-8 one], single writes to 79 characters only, not 120, and so doesn’t wrap at all. This is all *really* weird. And now I finally get to understand what morebars was supposed to do. As for under WSL, it behaves basically the same as Windows, except that the program is notified of width changes and adjusts its progress bar width to match, which didn’t happen in Windows.)
+1 for VSCode + Extension. Why? Some people just want to watch the world burn. But seriously. VSCode is a really, really good editor. * I use it for C, C++, C#, Javascript, Erlang, Prolog, Lisp, F#, and now Rust. * No emacs pinky. * Just works right out of the box. * Command pallete is also pretty baller. * They replaced their grep system with the rust version recently and got massive performance increase. I am literally here because of VSCode release notes from about a week or 2 ago. * Solid Git integration. * Cross platform. * Did I already mention that I like to watch the world burn? 