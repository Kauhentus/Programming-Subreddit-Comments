Did you read that post? Fuchsia isn't moving away from Unix, it's simply not a Unix based OS and lacks a lot of what makes an OS a Unix OS.
Yeah, the point is well made in the article that it's especially nefarious in when it's in RFC threads, especially ones 'exploring the solution space'. Rust is blessed that its gatekeepers are sane people that will try to avoid dogmatism and look at every alternative exhaustively. It's after all, how they reached the current iteration of Rust, that went through many radical transformations.
Yes, why not? Rust is not its core/std implementations. This is unsafe rust with a custom core lib.
I am right there with you. I also think it's going to be interesting when Fuschia lands, can run Chromium and Android apps, and runs every new Chromebook and Google-produced Android phone... all-the-while ushering in some new ideas, instead of yet-another-unix. It'd be cool to have a rock solid Unix in Redox OS and see how the new-fangeled Fuschia plays out. (And yes, I'm leaving out all of the licensing considerations. :(...)
Funny, I did that shortly after reading your message and it has 3x the upvotes &lt;3
lol i didn’t even think about rustup support for redox. good work, krabby patties!
Funny story, it's because production doesn't follow back errors like debug does. Or so I think... Thanks for the love &lt;3 :D
And if you want to make it generic over chunk size, there's always \`chunk.reverse()\`.
Are all of those features confirmed for fuschia?
Makes me wonder if it wouldn't be interesting to split RFCs into two documents: problem definition and solution proposal. You can give the former without a later and just start a discussion. Problem definitions also would have an easier time getting merged, it'd just be a recognition that "yes this is something we want to solve at the very least with a std lib". While the different solutions would be sub documents under the same thing. You could also have merging if problems into a larger one, while the sub solutions could remain, honest that they solve a specific aspect of the problem but not the whole thing. Then again, this might be too much trouble to be worth it.
Great question! My understanding is that the wasm module's memory will always be sandboxed from the parent scope.
They're already there, basically. Chromium already has a Fuschia port and ARC commits have been landing in Fuschia for months.
Exactly. Unlike Fuchsia, Redox has a lot of those Unixy things like signals, clone, and exec
The authors of the program have the option to release their versions to crates.io at their discretion. They don’t have to follow their source repository. Maybe they didn’t want to publicize that version. Maybe they haven’t gotten around to it yet.
True, but just because a company can do something doesn’t mean they will. I was under the impression that the flutter apps would run on fuchsia, not that android apps would run by default on fuchsia. Not that there’s not a precedent for that, but it doesn’t sound like they’ve confirmed they will do that.
re your second point, yes you can do that, and that's a common pattern. You're not passing an unsized value though, you're passing a sized value that you can later coerce to the unsized value. The more general way to do this is to take a type argument `S: Unsize&lt;T&gt;`, where `T` is the type you want to unsize to. That only works on nightly though, since it is unstable. I created a dst_vec data structure a couple years ago that you can take a look at, if you want: https://github.com/mikeyhew/dst_vec. It hasn't been touched for two years except for a bit of cleanup today, so no promises :)
Who knows - it's up to them and I am of course fine with them releasing when they see fit. I'm not mad or frustrated, just confused. :) I think the most confusing thing is that they are not tagging their releases on GitHub, so I can check out each file's history on GitHub but have no quick way of correlating it to the versions in crates.io. Looking at the version list in crates.io, they released 0.21.0 in January, they released 0.21.1 last week, and right now the one from January is yanked. So what I'm guessing is that there is a security thing or a critical bug or something in 0.21.0, and it got yanked last week. The commit I'm looking for is from February, and my theory is that that one will be in the next release, whenever that may be. In the mean time I have a copy checked out on my hard drive, it's just for a hobby project anyway.
Is it possible make this compile? ```rust struct Foo&lt;T, U, Func: Fn(U)&gt; { t: T, func: Func, _u: std::marker::PhantomData&lt;U&gt;, } impl&lt;T, U, Func: Fn(U)&gt; Foo&lt;T, U, Func&gt; { pub fn new(t: T, func: Func) -&gt; Self { Foo { t, func, _u: Default::default(), } } } impl&lt;T, Func: Fn(&amp;T)&gt; Foo&lt;T, &amp;T, Func&gt; { pub fn bar(&amp;self) { (self.func)(&amp;self.t); } } fn test() { Foo::new(3 as i32, |a: &amp;i32| println!("{}", a)).bar(); } ``` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4d7a0ac7602c2bdea81f3868e6145c60
Thanks! I wrote a follow up question here: https://www.reddit.com/r/rust/comments/bdbtpr/hey_rustaceans_got_an_easy_question_ask_here/eldtqm4/
The `&lt;T&gt;` in things like `Result&lt;T&gt;`, `Option&lt;T&gt;`, `Box&lt;T&gt;` and `Vec&lt;T&gt;` means that they are generics. It wouldn't really be "extern rust" if it inherently disallows things that are all but core language elements.
&gt; The main advantage of dynamic linking really is the ability to substitute one version for another; which only really matters for distributions, to patch users' machine with minimal bandwidth. Which, notably, doesn't even work because of versioned symbols fundamentally break the concept of dynamic linking, and dont even give you the "fixes", and everything is so runtime/environment inter-dependent that you can't dare upgrade without extensive testing. And god forbid you need more than one version of something. [👀^link](http://harmful.cat-v.org/software/dynamic-linking/) Dynamic linking\* was a mistake and for our sins we're condemned to DLL hell and ancient software versions because upgrading is too dangerous *cough* linux *cough* ---- \* well it has it's uses, but it shouldnt be a default. It should only be used when you need it. Stuff like plugins.
User **Globi** in beginners chat, teached me the solution: Using an 'a lifetime in the second impl for all references.
It seems that there was an off-by-one (in tree levels) error in the implementation that caused the results to be incorrect. Upon fixing it, the performance is definitely worse than Annoy. &amp;#x200B; I profiled the result (with \`cargo flamegraph\` from the \`flamegraph\` crate), and I placed the performance issue here: [https://github.com/vadixidav/hwt/issues/3](https://github.com/vadixidav/hwt/issues/3). You can track this issue until I resolve it. Once it is resolved, I may have to perform additional improvements before I reproduce the paper's performance again. Sorry!
If it's Safescreen, Windows collects and sends hashes of executables you run to Microsoft, and then warns you about uncommon executables.
There isn't, as far as I know. How would a generic caller know which function they're allowed to call? This sounds like an X Y problem. Maybe say more about what you're trying to accomplish, and someone could suggest a better way.
So, would a Linux-based distro built with relibc and oreutils (i.e. the only C code is the kernel, everything on top is Rust) be Rust/Linux? :thinking: (Also, _bot_, the usage of Linux here was correct. Take your copypasta elsewhere.)
0.21.1 has most likely been released off https://github.com/image-rs/image/commits/memory-safety-0.21.1 and the name of the branch quite strongly supports your guess.
It also matters for things like OpenCL libraries: different users have different graphics cards, so they'd use the latest supported by their graphics card unless you want to distribute a dozen different OpenCL.so files for every single card out there...
It would be useful to list the features in `std` that are not in `core + alloc`. It takes a bit of manual cross-referencing to figure it out from the official docs.
I performed some optimization and now it's blazing fast and also correct! You can check the master branch. The API is less ergonomic now though (takes in a slice to place in instead of giving back an iterator), but I will be fixing that before I make a release. &amp;#x200B; I still don't have specific performance metrics comparing it versus Annoy. I would really appreciate investigations into that. I am currently profiling and optimizing the code, so you can expect the performance to keep increasing. I am testing against completely randomly distributed features, so I might actually get faster performance with real data (in real data the nearest neighbors are closer since they may actually be there!). I will gather some real data from the \`akaze\` rust crate later to include in the repository for benchmarks you can compare with Annoy and FLANN. &amp;#x200B; Keep in mind, Annoy isn't designed for performance the same way FLANN is (Annoy is actually concerned with memory constraints), so a really good benchmark would be FLANN vs \`hwt\`.
Have some more upvote
Try using traits then? See: https://stackoverflow.com/questions/27957103/how-do-i-create-a-heterogeneous-collection-of-objects You'd still have to impl that Trait for the 60 different plugin types...
I'll try that, thanks! I didn't realize you could do that.
As luck would have it, next week is my orientation for the new job, so I’ll be in town and going! Extremely convenient.
I have an enum where all variants are tuple-like and have a `0` field: ``` enum Test { One(Something), Two(Something) } ``` I also have a vector of `Test`s and am looping through them. I need to access the Something value, but Rust keeps saying there is no `0` field in that enum. How can I do this?
Here is the all c code, if this helps: ## predictor.h ```c #ifndef RUST_TF_PREDICTOR_PREDICTOR_H #define RUST_TF_PREDICTOR_PREDICTOR_H #include &lt;stdint.h&gt; typedef struct Predictor_S Predictor_t; typedef struct RawTensor RawTensor; typedef struct CTensor { const float *data; uint32_t data_length; const uint32_t *shape; uint32_t shape_length; } CTensor; typedef struct CTensorArray { CTensor *data; uint32_t len; } CTensorArray; //typedef struct CTensorArray CTensorArray; CTensor *create_tensor(float *data, uint32_t data_length, uint32_t *shape, uint32_t shape_length); CTensorArray *create_tensor_array(CTensor *data, uint32_t len); Predictor_t *load(char exported_dir[]); CTensor *to_tensor(RawTensor *tensor); RawTensor *predict(Predictor_t *predictor, char *output_name[], char *input_names[], CTensorArray *input_values); #endif //RUST_TF_PREDICTOR_PREDICTOR_H ``` ## main.c: ```c #include &lt;stdint.h&gt; #include &lt;stdio.h&gt; #include &lt;predictor.h&gt; #include &lt;stdlib.h&gt; #include "../src/predictor.h" int main() { char path[] = "test_resources/regression-model"; //Predictor_t *pre = load(path); float x[] = {1.0f}; float y[] = {2.0f}; float *xP; xP = x; float *yP; yP = y; uint32_t shape_x[] = {1}; uint32_t shape_y[] = {1}; uint32_t *shape_x_p; shape_x_p = shape_x; uint32_t *shape_y_p; shape_y_p = shape_y; CTensor *xTensor = create_tensor(xP, 1, shape_x_p, 1); CTensor *yTensor = create_tensor(yP, 1, shape_y_p, 1); printf("-----%s------\n", "jack coo"); printf("CTensor in c data:%f len:%i \n", xTensor-&gt;data, xTensor-&gt;data_length); printf("CTensor in c shape:%f len:%i \n", xTensor-&gt;shape, xTensor-&gt;shape_length); CTensor *xy[] = {xTensor, yTensor}; CTensor *xy_p; xy_p = xy; // CTensorArray *tarray = create_tensor_array(xy_p, 2); // // // RawTensor *wow = predict(pre, "y_hat", "x,y", tarray); // CTensor *res = to_tensor(wow); // int loop; // // for (loop = 0; loop &lt; res-&gt;data_length; loop++) // printf("%f \n", res-&gt;data[loop]); return 0; } ```
Though keep in mind that on some architectures, it is possible to leak secrets across same-process sandbox boudaries (Spectre).
I just wanted to say that the Rust playground is much more useable on mobile than similar sites, like the one OP linked to, for other languages. I really appreciate that.
Just to clarify, if I used the same overall layout but instead of injecting bytes into wasm memory, I piped it to another process via stdin. Would the same risk be there?
Format your code by indenting it 4 spaces. Don't use ```.
In the C code, you're passing a pointer (\`xTensor-&gt;data\`) where \`printf\` expects a float. This ends up printing the float as zero, and the pointer in place of the length (because floats are passed in different registers than integers/pointers). You'll want to put a dereference on the \`xTensor-&gt;data\` in the C code to make it match the rust code.
To get the contents of an enum, you must always match it. Otherwise, you could add another variant without a .0 value and get a lot of errors elsewhere, which would violate locality. Just write a getter function and use it everywhere else.
[removed]
Is there any reason for this?
Is there a way around me having to hard code every single variant in a match? I wish I could say `if let Some(v.0) = MyEnum`.
u/mutabh i change uint32\_t to int32\_t and then print it like you said, it works ,thanks: -----%s------\n", "jack coo"); printf("CTensor in c data:%f len:%d \n", *xTensor-&gt;data, xTensor-&gt;data_length); printf("CTensor in c shape:%f len:%d \n", *xTensor-&gt;shape, yTensor-&gt;shape_length); printf("CTensor in c data:%f len:%d \n", *yTensor-&gt;data, yTensor-&gt;data_length); printf("CTensor in c shape:%f len:%d \n", *yTensor-&gt;shape, yTensor-&gt;shape_length); 然后就work了。
You can use `|` within the match, so it becomes `match self { One(v) | Other(v) =&gt; v }`. For a small enum like yours, I'd just write this once in a getter function an use it. For much larger enums, I might use derive_getter or some similar procedural macro.
Old Reddit and some mobile apps like mine don't support it.
Interesting start, are you going to continue the series? I'd like to see a host API wrapped and exposed as import functions to the plugin. Then things would be getting really interesting. (Like can you use bindgen for that?)
This might be a mix of issues with the theme and the highlighter. I can only reproduce 11 and 14 using "Atom One Dark Theme" (the version by "Mahmoud Ali").
Here's a nice trick that a lot of `no_std ` crates don't seem to use: you can use the `core` functions and types even when not in `no_std`. So if you have a simple crate you don't need to pick between `std` and `core` every time.
I know it is Rust, but I think in this example we disabled most of features (reasons why are w using rust). If you want write code like this is better to use C. But it's nice to know rust allow such things.
It would be very hard to debug such a library since no_std does not have STDIN/STDOUT/STDERR.
Use `Developer: Inspect TM Scopes` on texts and you will find out it's all syntax highlighting's problem. The colour of Atom One Dark hides the problem. The theme I'm using works perfectly fine for TypeScript, which is maintained by Microsoft itself.
Rust Core Team ⊆ Rust Team. This should be Dev Tools Team to do this.
Nor does the mobile site.
Tip - You can reply to comments directly, and make sure you mention the correct username. Since you're using `c_int` in the rust code, the correct type on the C side would just be `int`
Yes I do, and when I used `pic` with `thumbv7m-none-eabi`, it still generated a global offset table. I'm not sure why what you're seeing is different. Does passing `--emit-relocs` (I don't recall whether that should go to the compiler or the linker, I think it's an unstable compiler flag) change that? The benefit of a global offset table (I think) is the dynamic linker is easier to implement.
Did you make your picture by compressing the bitmap with audio compression and converting it back?
Add a readme
Why don’t you do it?
I tried and am trying to do it.
&gt; I fear that a systems programming language without stable ABI for dynamic linking will have lots of problems For what it's worth, C++ also doesn't have a stable ABI and appears to be doing just fine.
Oh crap, my apologies! I was 100% convinced I posted that to C prog channel... Due to severe lack of time recently, there’s my proof I’ve started losing it o.O Thanks for spotting it, and next time I’ll double check I’ve got the right subreddit selected!
They have these really neat programs now that let you inspect a process's state as it's running. Very useful with debugging, so useful that they have that in the name I think.
A library should never access stdin/out anyway. (A test program or tool based on the library can of course use stdio).
Thanks! Also, about the pic, nah, nothing that fancy. It’s basically my photo encrypted using ECB mode, and hence demonstrating why it’s such a bad idea. Anyhow, if you’re interested in the code snippet that generated it, you can find it here: http://www.jakubkonka.com/2017/09/12/ecb-art.html
I didn't say there's never a need for a `std` feature. Use one if you want to offer extra functionality. I was just pointing out there's no need to do [this](https://github.com/Alexhuszagh/assert_float_eq/blob/master/src/lib.rs#L40-L44).
Good point! Then I suppose the biggest problem is just that it's not the norm. My README says something similar: &gt; This is because the norm is to use std. Using core needs someone to break the norm, often only behind a feature flag.
For temporarily debugging... The `dbg` exists for a reason.
Oh yes, if you don't ever use the std then definitely there's no reason to have a feature flag to enable it
There's this: https://9to5google.com/2019/01/02/android-runtime-app-support-fuchsia/, but I guess it doesn't have to mean that Android apps will run by default on Fuchsia. The whole project might even get cancelled.
It was mostly likely yanked in response to suspicious activity on the project founder’s computer. See https://github.com/PistonDevelopers/piston/issues/1274 and https://github.com/PistonDevelopers/piston/issues/1257
I think these videos are so great. Sometimes I'll watch video lessons or tutorials on different subjects, but most of the time I just want something short and sweet that's going to tell me, "hey, learning/doing \_\_\_\_\_\_ is really fun and cool!" These videos do that for Rust more than any others I've seen 🦀❤️
I just this makes sense as long as there is a way to target Redox-only APIs still so it isn't chained to bad Unix APIs forever (e.g. `fork()` which was discussed recently). Presumably you can do `cfg(unix &amp;&amp; !redox)` or something like that? `if (UNIX AND NOT APPLE)` is a common pattern in CMake.
True, but it is also true that GTK language bindings have much better time compared to Qt language bindings.
Now I want to try that :-).
Nothing so spectacular, I've since found out what the deal is: https://github.com/image-rs/image/blob/memory-safety-0.21.1/docs/2019-04-23-memory-unsafety.md Actually I've looked through those issues and am now slightly puzzled. They are apparently suggesting that they are targeted by politically motivated persons but the Piston project seems to be just a bunch of gaming stuff.
&gt; a bunch of gaming stuff. You missed on how the far right is trying to get gamers to support their abhorrent ideology? Your 'mens rights activists', incels etc etc etc. They're a juicy target for radicalization because they are already sexist and racist assholes that stew without consequences on their ingame chats thinking of how to show swasticas in inventory photos.
Other way around; `Fn(T)` is contravariant over `T`, as per the [Nomicon](https://doc.rust-lang.org/nomicon/subtyping.html).
Here's an interesting read on the topic: http://harmful.cat-v.org/software/dynamic-linking/
Great, now this is happening. I don't even know how to respond to this. Your comment seems to be breaking multiple subreddit rules, including the Code of Conduct, so I'll just report it.
Shrugh. I'll delete it now, but if you think 'to be just a bunch of gaming stuff.' does not make you target, you're far far out of touch with 2019.
However, the perfectly working [TypeScript-TmLanguage](https://github.com/Microsoft/TypeScript-TmLanguage) is nearly 5600 lines. It's not impossible for a person to do, but I really need to take a research on how it distinguishes `&lt;` as operator, type parameter bracket and JSX bracket...
Why can't Unix abi be a layer on top of a more efficient and modern base?
That's sort of the case on Windows and MacOS. As I understand it, they have a more minimal CRT (C RunTime) library that libc depends on and *that* is the point of ABI stability for syscalls.
 #[cfg(and(unix, not(target_os = "redox")))] Is how you do `cfg(unix &amp;&amp; !redox)` in case that was a question
It's the a site for other languages that you'd recommend? When I googled "Java online" there were a ton of them, I just picked one which wasn't tied to Java and had a nice domain name.
Ok get it. 😁
Get it 😁
Already fit this.
Yeah, it's good now.
LOVE IT! &lt;3
Looks useful! I am missing the reasoning behind the `HashMap` → `BTreeMap` thing. Is it just to decrease memory usage, or is there more to it than that?
Great video! I've noticed one thing though: instead of doing `let (position, print_me) = data;` you can do the pattern matching right in the parameters: `fn run(&amp;mut self, (position, print_me): Self::SystemData)` (it's common pattern in Amethyst and it's IMO cleaner than the `let` construct).
HashMap does not exist in no_std (because the standard hash algorithm requires randomness to function IIRC). The compatibility flag is there for when you want to keep using the fast HashMap algorithm with the standard library, but fall back to binary trees when unavailable. It also makes less code change required to port stuff to no_std :)
`chunks_exact_mut` seems to be a better choice as you won't get a last chunk with fewer elements.
In Debug or Release mode? Once again, it really depends. If you use generics, or inlined code, then dynamic linking doesn't help anyway. Normally, dynamic vs static shouldn't affect compile times, only link times: - Linkers in Debug should be relatively fast (as in, seconds). - LTO is much slower, obviously, but then again LTO only works across library boundaries with static linking, so if you really need to squeeze every ounce of performance, dynamic linking is out of the window. The (C++) unit-tests suite of the main project I work on is comprised of about 100 distinct binaries, all statically linked, and on my 8 cores machine it takes about 30 seconds to relink them all (in Debug) if a change occurs in the "core" libraries. It happens rarely, so it's not much of a problem.
Subscribed！
`|` being strict evaluation in contrast to the short circuit `||` operator was a neat trick I didn't know. Interesting post!
I know, the video was not mine though 😁 .
Ah yes, that is true. I misunderstood. Though that time could be reduced with a GUI library on top. Like Avalonia for C#.
There's also the normal Rust meetup on Wednesday (at Mozilla) if you're interested!
Hey there, publisher of that version here :) As @simukis noted below, the source tree is here: https://github.com/image-rs/image/tree/memory-safety-0.21.1 The reason is explained [in the docs](https://github.com/image-rs/image/blob/memory-safety-0.21.1/docs/2019-04-23-memory-unsafety.md) but totally unrelated to the security issues that bvssvni had experienced. 'Just' a bug that made it into the version. This came at an inopportune time during the transition of the organization, which makes this slightly messy. We have planned to give a proper introduction into the organization in a blog/webpage soon, and also put up the safety notice on said blog.
Note: for `ctgrind` you don't need the linked C repo, the necessary functionality today is already present in Valgrind, so you can use Rust interfaces, e.g. see this [crate](https://github.com/RustCrypto/utils/tree/master/ctgrind).
That first issue linked is kind of weird. To jump from "I have malware" to "I'm being politically targeted by a massive coordinated attack" is a huge leap to take. Am I misreading this? It reads like very severe paranoia. I appreciate their dedication to security though. I suppose it's better to be too serious than not.
Hey, thanks! I am hoping early this coming week to get part 3 finished which is all about using a `proc_macro` to do a lot of the heavy lifting for plug-in developers. I’d be curious to hear if what I am doing there is what you are envisioning.
Should be able to come to at least the start of that too!
That transition explains part of my confusion. There are still a couple of places where Piston is mentioned, for instance in the "how to contribute" link, in case you were not aware of this already.
Thank you for the notice, the changes related to the organization were only applied to `master`. That makes `crates.io` inconvenient at the moment-it was a slightly rushed release. We'll see what else should be backported, [for example this fix](https://github.com/image-rs/image/commit/2173f03c5e8e4151b65dd12470b9d771a433e5d8) that I had missed.
Agreed. Still, there are still many cases where `Rc&lt;RefCell&lt;_&gt;&gt;` is the right tool for the job. For wayland-rs for example, I really could not have made a lib with a reasonably usable API without using it in quite a few places.
I may be biased by my history of working on wayland-rs, where basically a lot of object fundamentally need to keep references to each other. That would really be a nightmarish API if I didn't use `Rc&lt;RefCell&lt;_&gt;&gt;` under the hood to be honest.
Did you ever try the index based approach?
The index-based approach cannot really be applied without bringing `Rc&lt;RefCell&lt;_&gt;&gt;` into the story here tbh. To expand a little on that, I have some internal state that must be accessed whenever sending or receiving Wayland messages (to handle the protocol logic, which is stateful). I could make a "single point of interaction" object that must be used for everything, but this would be a really unpractical API given how the Wayland protocol is used in practice in graphical apps. So rather I have a lot of small objects that each keep some internal link to the shared state (or some part of it, to be exact). So yeah, my internals are full of `Rc&lt;RefCell&lt;_&gt;&gt;`, `Arc&lt;Mutex&lt;_&gt;&gt;` and trait objects (to handle user-provided callbacks mostly). This is the result of 5 years and 4 full rewrites of the crate to be honest. ^^"
But that should no longer be the case with 0.5.
Just relooked at it. Planning on giving it a shot this week!
&gt; No argument here, I agree that a panic is much nicer than undefined behavior. My point was that the difference is unlikely to matter to the end user. From the user's perspective both result in a crash, and the nice stack trace will not alleviate the fact that their Firefox (or whatever) has crashed. Even from an end user perspective I'd argue there is a difference between a crash and "your machine got taken over because of a vulnerability". In that sense, a crash is much better than UB. (Not all cases of UB are exploitable vulnerabilities, of course. But most vulnerabilities arise from some form of UB.)
I dunno, I prefer the let construct for some reason :)
I'm not a fan of destructuring in function arguments, but it's cool that it's possible. I think simple named arguments are easier to read.
Author of [SideFuzz](https://github.com/phayes/sidefuzz) here. You (probably) solved a mystery for me! I was noticing that SideFuzz was producing false-positives. It was finding non-constant time results even when I was pretty sure that what I was testing was constant time. I designed SideFuzz such that the fuzzing function should produce a Result::Err when DiffFuzz passes it invalid input. This use of Result could easily be the source of the false-positives. Thanks for the great writeup.
Had the same problem. I basically take each `Bytes` chunk and send it into a threadpool: https://github.com/getsentry/symbolicator/blob/bd5dfb2c8a9aa478e0f80ddecb059a468e129759/src/endpoints/minidump.rs#L46 I don't know how performant this is, but for our purposes it's ok. It's conceptually simple at least.
You have to move actual file operation to web::block
How about we let New Testament scholars give him the rundown?
I think it's because the `get_type` method exists but I forgot why.
https://github.com/tinaun/futures-native-timers my crate has a mac-os implementation that works, maybe you can look at that. I'm interested in learning about how your posix implementation works - I've run into issues with certain signals not being correctly handled in applications with lots of timers
Don’t say such a thing xD
You’ve run up against the [object safety rules](https://doc.rust-lang.org/book/ch17-02-trait-objects.html#object-safety-is-required-for-trait-objects).
It's because `get_type` is a static method. Static methods are called without a corresponding object, and if you don't have an object, you can't dispatch on it. Let's say there's `struct A` and `struct B` that both implement `Atom`. Then you make trait object, `dyn Atom`. Now, you try to call `(dyn Atom)::get_type()`. The compiler can't know which get\_type to call because you don't have a concrete instance of `struct A` or `struct B`. You can circumvent this by specifying that `get_type` is conditionally implemented only for those types that implement `Atom` AND `Sized`. `dyn Atom` doesn't implement `Sized` so `get_type` isn't implemented on it, so it doesn't run against any rules.
True, get_type needs a self variable (self, &amp;self, &amp;mut self, Box&lt;Self&gt;, etc.) since otherwise it cannot be called from &amp;dyn Atom
I don't know. I'm rooting for Linux, but it's easy to see why Google would want more control over the platform.
Are you not running into https://github.com/actix/actix-web/issues/769 ? The current release and alpha both give me chunk of the size of the file, which isn't super useful.
You can track the issue in https://github.com/actix/actix-web/issues/634 as well
By the way, the `self variable` and all it's variants (`Box&lt;Self&gt;` / `Pin&lt;Self&gt;`) is called `receiver`.
This is the subreddit for the Rust programming language. I believe you're looking for /r/playrust
Try posting this to /r/playrust and you might get some better help and tips. This is for the programming language Rust.
I'm so sorry lol thank you
I'm sorry didnt realize thank you
There's a crate, actix-form-data, that accomplishes this. You can either use that crate directly (I haven't used or audited it, fyi) or take inspiration from how it handles this problem. It uses futures-fs under the hood. &gt; performant file upload in actix web ? YSK that actix currently has a bug where file uploads are slow: https://github.com/actix/actix-web/issues/634 Side note: Unless you absolutely need multipart, I'd recommend against it in general. It requires more code and isn't as well supported (by really any Rust web framework). For uploading files it's easier to just support direct file uploads when possible. The exceptions being when you can't fit your other request parameters into URL/headers or when you have to support a standard HTML form.
Alright, almost there. I typed cargo run to run the file but then it said that I needed VS 2013, 2015, or 2017. Since I downloaded VS Code, do I really need Visual Studio? Or what can I do inside of VS Code to help make the program compile.
I updated multipart example [https://github.com/actix/examples/blob/master/multipart/src/main.rs#L22](https://github.com/actix/examples/blob/master/multipart/src/main.rs#L22)
The two ways to fix this are: fn get_type(&amp;self) -&gt; AtomType; Now the method will be available in the trait object, but it requires an instance of a struct implementing `Atom` to call it, or fn get_type(&amp;self) -&gt; AtomType where Self: Sized; Now the method will be left out in the trait object case. You can have both variants in the trait (with different names) if you need to call `get_type` both without a struct, and as a trait object.
I have an app where I incrementally build up a `BTreeMap` of tokens to buffers. Each buffer is basically a `Box&lt;BitWriter&lt;Vec&lt;u8&gt;&gt;&gt;` (where `BitWriter` is from the `bitstream-io` crate). During the build phase I write to all of the buffers, and once the map has reached a certain size, I write all the buffers to file by sorted token order and clear the map. I haven't figured out a way to do this that doesn't involve (1) making a copy of the keys, then (2) iterating over the keys while doing `remove` on each key in order to transfer ownership out of the map. Copying the keys is needed because `remove` needs a mutable map, and I'm not allowed to borrow the keys while removing. On the other hand, I don't *actually* want to remove keys individually from the map -- I'm only doing it that way in order to get ownership of the buffer that I need to take ownership of. In theory I could easily borrow the buffer read-only during this iteration, since I just want to read it and write its contents to a file. But `BitWriter&lt;W&gt;` insists on owning the underlying writer of type `W` -- it takes the writer by value, not reference. There's no way for me to read its underlying writer without also owning it (via `into_writer()`). Maybe I could wrap the writer in a smart pointer to get around this?
I wasn't aware of this issue, but it has not been a problem for us (yet). But I don't see how I would be able to fix this issue by changing my code anyway. Seems like I just have to wait for a fix?
&gt;In Debug or Release mode? Both,either way having a lot of dependencies in Rust slows down compile-times(as in the time it takes "cargo run" to build and to run the program locally),even if the functions you use from them are marked #\[inline(never)\]. This might get better as incremental compilation improves,but we'll see.
actix-form-data is licensed under the GPL. Keep this in mind while trying to use it at work.
I disagree. What advantage does C give here? We still have access to lifetimes, enums, generics, etc.
Bad bot. No leaking r/pcj here.
I've not researched the subject extensively, but it is possible that the Debug build is slowed down by the sheer amount of Debug Information to include in the binary, which can greatly increase link-time with static builds. I wonder if it is possible, and if it would be helpful, to compile in Debug without any Debug information. It would make actual debugging (and backtraces) more difficult, but would otherwise speed-up the edit-compile-run cycle.
Yes, you are misreading it. :) I did not imply a massive coordinates attack toward a single target, but a likely massive attack toward many targets. That's a huge difference.
In the last case, `get_type` does not need to be an instance method. This works fine: fn get_type() -&gt; AtomType where Self: Sized {}
Thanks, fixed.
The last time I've tried (a while ago) removing Debug info from Debug builds caused segfaults at runtime(while compiling in Release mode without them does not).Maybe I'll try again later to see whether the bug has been fixed.
I see, thanks! Could you use `hashbrown` hacked up as necessary — in particular with a cheap default hash function that isn't attack-resistant?
Hi, thank you for the response! What do you mean by direct file upload ? My use case for multipart upload is to be able to handle files larger than my server's RAM
Thanks, the last method worked.
I’m not sure, I didn’t run into that, but I also already had vs 2017 on my computer so maybe you do need it
The editing is insanely good...
One more question: Why does the bottom method work?
&gt; let a: f64 = (1..600000000) &gt; .map(f64::from) &gt; .fold(0.0, |acc, fr| acc + fr.powi(-2)); Thanks very much for this, but I don't understand how this works. Where did the `-2` come from? What is `acc, fr` doing?
Now can you please explain how it works?
I've expanded the code a bit. This should better show how it works. ``` fn main() { let (cols, rows) = (93, 31); for y in 0..rows { for x in 0..cols { let c = ( // map column from -1.0 to 1.0 (3 * x) as f64 / (cols - 1) as f64 - 2.0, // map row from -2.0 to 1.0 (2 * y) as f64 / (rows - 1) as f64 - 1.0 ); let mut z = (0.0, 0.0); let mut i = 0; while i &lt; 32 &amp;&amp; z.0 * z.0 + z.1 * z.1 &lt; 4.0 { let re = z.0 * z.0 - z.1 * z.1 + c.0; z.1 = 2.0 * z.0 * z.1 + c.1; z.0 = re; i += 1 } print!("{}", b" .:*H@"[i / 5] as char); } println!() } } ``` I have used a few tricks to make the code more compact. Instead of declaring each variable individually I used tuples and I combined the row and column loops.
Why do you suspect the Piston developers were targeted in this way? As I said in another comment, I don't see the political controversy of your projects, admittedly being unfamiliar with them. You do cool gaming projects but that hardly makes you guys a radical left wing think tank?
They're not much easier to read when the only reason you're aggregating arguments into a structure is to pass the to a function.
What's Fuschia meant to be? Google give me flowers, and the google source pages seem quite technical.
With Xargo and `panic_immediate_abort` libstd feature similar filesizes are reachable even without no_std. See [min-sized-rust](https://github.com/johnthagen/min-sized-rust#remove-corefmt-with-no_main-and-careful-usage-of-libstd). I've also created a Docker containter for building fully static (musl) and very minimized executables: https://github.com/vi/xargo-musl
Now you have to zoom in with that library for '3d' on the cli.
Piston in general is for gaming. But image-rs is widely used,
wrong subreddit, you want /r/playrust
`#![deny(bare_trait_objects)]` may be recommended to keep you explicitly writing `dyn Chooser` and avoiding confusion between a trait and it's dynamic representation.
thanks bro just saw lol
`&amp;Foo` is a reference with compile-time checked lifetime. It costs essentially nothing. `Rc&lt;Foo&gt;` is a reference-counted reference to a heap-allocated `Foo`. It is very cheap as cloning it just means incrementing the refcount, which is super fast. However, when you first make one, it costs you one heap allocation. If `Rc` makes your code cleaner, by all means use it. It will not be a performance issue in 99% of the cases.
Can you give me an example please? I think I am missing something, I couldn't get it to work.
Sure: ```rust syn::Error::new(ty.span(), "expected bool").to_compile_error() ``` The `ty` here is the token you want to highlight the error. see also: https://stackoverflow.com/questions/54392702/how-to-report-errors-in-a-procedural-macro-using-the-quote-macro
I think you’re in about the game, this thread is about the programming language Rust.
I'm using `timer_create` after all so I think I might stumble in the same problem. But I didn't have opportunity to test it properly Thanks for link, though I already found the problem with my MacOS impl
Doesn't `&amp;Foo` and `Rc&lt;Foo&gt;` have the same memory allocation size though? looking at `meh::size_of` seems to imply that - am I misunderstanding?
One crate to rule the DOM One crate to find things One crate to bring JSON And in the Rust code bind things This code, no other, is made by code elves Who'd pawn parent process to get it themselves Ruler of net troll and mortal and hacker This code is a lib crate for Patreon backers If trashed or buggy it cannot be remade If found send to Ivon: the bandwidth is prepaid *[Apologies to the late J.R.R. Tolkien and the National Lampoon.]*
Wrong sub buddy. You want /r/playrust
`size_of` is the same for each - the size of a pointer. However, that's the size of just the reference you're passing around, not whatever it may be pointing at. In other words, it's just the on-stack size of something. You can try this: make a Vec containing 1000 u64s and see what `size_of` says about it. `Rc&lt;Foo&gt;` is a pointer pointing at a heap location where you can find a refcount and a `Foo`. But `&amp;Foo` just points directly at a `Foo` which may be allocated wherever. If the `Foo` is a local variable, it lives on the stack, so there's no heap allocation involved.
Haha, perfect thumbnail.
It now takes a `Vec&lt;impl Display&gt;`. What are your thoughts?
It now takes a `Vec&lt;impl Display&gt;`. What are your thoughts?
I like your idea, but I don't know how to implement an efficient way to use it. I don't want users to do something like this: Foo::get(vec![1, 2, 3].iter()); with an implementation that just collects that args.collect(); format!("bar{}", args[0], args[1]); Do you have an idea?
 std::mem::replace(&amp;mut tree, BTreeMap::new()).into_iter().for_each(|(k, v)| ...)
Obviously in mobile it looks great lol.
exactly. And thank you for the response! I REALLY LOVE sentry btw! :)
Thank you for being that responsive and! I tried that way but had error with `file` and `bytes` lifetime that I was unable to solve. It compile nicely now. Thanks!
It's not a Mandelbrot or anything, but I've tried my hand at golfing Rust as well https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8d006c2b28d23f3c69d0596498dd1f88 Probably could be done in way less code but I really wanted to pull that UTF-8 trick off.
There is my problem, I have no token. I am directly converting into a `Vec&lt;NestedMeta&gt;`. Where do I get the token from? I would like to use `args[0]` but that is not working.
This is my new favorite crate, thank you so much!! Three questions: &amp;#x200B; 1. Can we remove the post panic frames? They're just noise anyway and have never given me any useful information. &amp;#x200B; 2. Can we perhaps do some trickery using the \[\`init\`\]([https://docs.rs/init](https://docs.rs/init)) crate to avoid having to manually insert \`color\_backtrace::install()\` somewhere into the code? &amp;#x200B; 3. What do you think about integrating this directly into rustc? Maybe we could add \`RUST\_BACKTRACE=pretty\` option for these beautiful stacktraces?
`NestedMeta` implemented `Spanned` trait : https://docs.rs/syn/0.15.22/syn/enum.NestedMeta.html#impl-Spanned :)
It looks very straightforward: repeat the formula max. 32 times, and then print a character corresponding to the number of iterations. This is done for 93x31 cells.
Because when `self` is a trait object it's *unsized*. Because of the trait bound, the method is thus "invisible" in that case.
1. This is already implemented, mind the "(n post panic frames hidden)" in the screenshot! :) 2. I'm not exactly sure.. it would certainly work as long as you don't have LTO enabled. However, I'm not sure what would happen if the code is not explicitly referenced with LTO enabled.. I guess it might be optimized out then. Either way, I'm not sure if everybody would like this rather implicit approach, but we could easily create a second crate that depends on the main crate, additionally containing such an \`init\` function. 3. I'd certainly be happy for it to be included in rustc directly!
This is the create I didn't know I needed!
Use IntoIter instead of iter and I don't get it, your format doesn't make much sense. What do you want to do with the Displayable elements of the Vec?
Well, if we include it into rustc directly, then \`color\_backtrace::install()\` becomes automatic :) &amp;#x200B; \&gt; This is already implemented, mind the "(n post panic frames hidden)" in the screenshot! :) &amp;#x200B; But they're still shown, it's just that the code is not expanded, right? For example, in this \[image\]([https://i.imgur.com/k2cAOF1.png](https://i.imgur.com/k2cAOF1.png)), can we not print the circled part? And maybe also skip the useless frame number 8?
Didn't know about having to bring traits into scope, thank you :)
Performance is one thing; correctness is another. If you use lifetimes, the compiler will guarantee that your code will not panic at runtime due to misusing the reference. If you use `Rc`, you will get runtime code panics if you screw up. Always avoid runtime checking if you can make it work.
Huh, what a weird pattern. But it works! Thanks!
Could you consider re-enabling Issues on your repo in github? This is an awesome crate and people may be interested in opening suggestions.
I agree with your general sentiment, compile time checks are better. However, I don't think there's much you can screw up with basic `Rc` usage - it's pretty much fool-proof.
That should be fine.
Oops, done, thanks for letting me know! This wasn't intentional. Apparently, creating a repo privately and making it public later results in GH defaulting to disabled issues.
This looks quite well done. The view construction is surprisingly concise considering it’s not using macros. Do you have any apps built with it online?
Thanks @andraantariksa for sharing this video. Appreciate it and the feedback below.
I agree it's cleaner. In some of my other examples the destructed tuple would start getting very large. Btw, Amethyst is awesome.
You can try to access an `Rc`without following the borrow rules at runtime. If you never try to mutate the contents of the `Rc`, you're probably good, but that's an invariant you have to maintain in your code without the help of the compiler. ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3cd9b91e083737a9067a6452e066f466))
This is absolutely fantastic!
Thanks for the tcod-rs bindings :)
Seems to me the worst stuff is the text. Text rendering is the blocker of many a project.
Political motivation does not mean you are being targeted for your side being political. For example, government X might want a strategic advantage in a cyberwar, by targeting the infrastructure of political opponents (other countries). The likely reason the Piston project might be/was a target, is because of widespread image libraries.
Oh, I see! The two of us had inverted ideas of what "post panic" means. In my mind, "post panic" is referring to frames of functions called *after* the panic happened. These include all kinds of uninteresting internal Rust functions that deal with unwinding and formatting. Adding another heuristic for "pre panic" ("post" in your mind) / Rust runtime initialization functions is a good idea as well, I'll put it on the TODO! Regarding frame #8, I'm sure we can skip this as well, however I don't see it locally. What caused it? Generally speaking, the skipping relies on a simple prefix matching heuristic -- I'm sure there are a lot of corner cases where it won't work perfectly yet and tweaks are required. When in doubt, it doesn't hide frames. I think this is preferable over an aggressive approach that might hide interesting frames.
There is always hope, it is just a really big job, and so few things are native applications anymore thanks to the web. People just turn to electron. So a big job with less incentive to do it. I wish it would be done though, I dislike everything being web pages or electron.
I started learning and sort of translating some material form Python into Rust here: [https://github.com/swfsql/deep-learning-coursera/blob/master/01%20Neural%20Networks%20and%20Deep%20Learning/C1W2%20Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb](https://github.com/swfsql/deep-learning-coursera/blob/master/01%20Neural%20Networks%20and%20Deep%20Learning/C1W2%20Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb) It's not a plain translation because sometimes I also try to experiment, even if it gets unnecessarily complicated. &amp;#x200B; For now, partly, only the first programming assignment was completed. But it worked!
Have you used cargo-strip from [cargo-binutils](https://github.com/rust-embedded/cargo-binutils) ? When compiling my binaries where 500k in size for `debug` mode and 25-26k in `release`. When using cargo-strip, it got reduced down to 5-6k.
Caveat: this will need to do fresh allocations for the tree every time, instead of reusing the previous allocated space.
&gt; Adding another heuristic for "pre panic" ("post" in your mind) / Rust runtime initialization functions is a good idea as well, I'll put it on the TODO! Awesome, thanks! &gt; Regarding frame #8, I'm sure we can skip this as well, however I don't see it locally. What caused it? I suppose frame #8 is analogous to frame #9 from [your screenshot](https://camo.githubusercontent.com/f05d40bcabb28e5123b3d65bd76a87ce1c098d64/68747470733a2f2f692e696d6775722e636f6d2f624d6e4e64416a2e706e67). It came from an explicit panic invoked by `panic!("foo")`. &gt; I think this is preferable over an aggressive approach that might hide interesting frames. Yeah, that makes sense. This could be another reason for moving the crate into rustc as the compiler probably has precise information about interesting and uninteresting stack frames.
Probably even worse is that native has to be defined for some platforms like Windows with wpf, universal etc. A native cross-plattform is always going to be optionated in some way or another. The only thing that could work if one could design for each platform the UI in one language separately but then you're back to having separate front-ends. At this point I just prefer a GUI that looks the same on all platforms and uses some OS specific features.
this post is 3 months old.
I'm working on it. I'll have more to say soon, as I will be asking for community help, though I'm also pretty confident of making good progress even without lots of extra hands.
Awesome
yeah for me i would want cross platform with key things like file open/save dialogs being native.
If you haven't yet, you should go look at https://areweguiyet.com/ which is a pretty good review of the current options and where they're all heading in the near future.
Performance problem should be fixed in master
You could also consider using a different bitwriter like the one from bitbit (just googled it, no comments on how good it is), which has a getref method that returns a reference to the writer, or you could maybe just use a bitvec crate instead. If you're set on bitstream-io, you could send a pull request adding a method to get a reference to the writer, since it's likely possible.
In the real world, electron is a really good choice: \- UI components re-usability between your web app and your desktop app \- good tooling \- Good enough performance for 99% of use cases &amp;#x200B; Even if I love rust, for a Desktop app I will always choose electron for the UI part which communicate to a rust core (using neon).
Could you elaborate on how `lazy_format` differs from [`format_args`](https://doc.rust-lang.org/std/macro.format_args.html)? As I understand it, the point of `format_args` is also to gather the information for formatting a string without needing to allocate anything. Does `lazy_format` cover additional/different use cases?
To rule out the obvious, make sure you're running your app with your json flag so it goes to the branch where it prints the json instead of using debug. You need to put flags after `--` when using `cargo run` or it'll be passed to cargo instead: `cargo run -- --json`
[splines](https://crates.io/crates/splines) is a spline interpolation library with support for serializing, `no_std` and some common crates such as [nalgebra](https://crates.io/crates/nalgebra) and [cgmath](https://crates.io/crates/cgmath). This post is the official announcement of the `1.0.0-rc.1` release candidate.
What does it mean when I see something start with `::` (e.g. `use ::something`).?
I originally tried using `format_args` for this sort of thing. However, `format_args` has elaborate lifelime requirements and therefore can't really be returned from the caller, even when all of the captured variables have `'static` or sufficiently permissible lifetimes. For example: let content = String::from("This is a sentence"); content .split_whitespace() .map(|part| format_args!("Token: {}", part)) .for_each(|part| { println!("{}", part) }) This code fails to compile because `format_args!` can't be returned from the mapping function, even though it's capturing an `&amp;'a str` with a lifetime that should be permissible. Replace `format_args!` with `lazy_format!` and it compiles correctly.
Yup! I’m doing this. I even added a `eprintln!` call to make sure the json serializer was being used.
[GTK](https://www.gtk.org/) is a cross-platform toolkit supported on every platform, and [works quite well today with Rust](https://gtk-rs.org/). In the Redox OS camp, the [Orbital](https://gitlab.redox-os.org/redox-os?utf8=%E2%9C%93&amp;filter=orb) team has been developing [OrbTk](https://gitlab.redox-os.org/redox-os/orbtk) as a cross-platform solution in Rust around an ECS designed for OrbTk's needs. It's almost ready for developing complex desktop and web applications with.
Personally I’m rooting for a diverse operating ecosystem
Your code contains: if matches.is_present("json") { let json = serde_json::to_string(&amp;resp.data)?; println!("{}", json); } else { println!("{:#?}", &amp;resp.data); } I guarantee that the Debug output you are seeing is coming from the bottom println, not from serde\_json. ;) You will need to minimize this down until you can identify why `matches.is_present("json")` is returning false when you believe it should be returning true.
To use a library crate, add it to the "dependencies" section of your Cargo.toml file. There's no "installation" step. The library is downloaded and compiled when you build a project that depends on it.
I’d love to hear informed opinions on the relationship between ‘opt-level’ and constant-time execution. This is something I’ve been running into, where the higher the opt-level the higher the t-statistic is for detecting variable time code. Does Rust / LLVM destroy constant-time code with optimization? Or is there something else going on?
Yeah, I might try to modify `bitstream-io`. I like that it writes to a `Writer`, though; the other crate you mention just maintains a buffer in RAM.
wrong sub, try r/playrust
That's cool !
omg. I figured it out. it's because I had a typo in both of my `Vec` arms: https://github.com/spikegrobstein/radarr-rs/blob/better-arch/src/main.rs#L105 I have `if let Some(matches)` rather than `if let Some(_matches)` which is causing the new `matches` to shadow the other one. ugh. so dumb. so yeah, now the `handle_resp()` function properly has the `--json` flag being picked up and I'm running into another error, but this all makes sense. got me on the right track. I really should have just done `Some(_)` and avoided this non-obvious typo. thanks for making me take a fifth look at this.
figured out the issue. it was a typo in the code itself, which prevented me from seeing that the `--json` flag was set that just happened to be in both `if let` arms that returned a `Vec`. this line was shadowing the `matches` variable: https://github.com/spikegrobstein/radarr-rs/blob/better-arch/src/main.rs#L105
To install a binary crate hosted on crates.io, from the command line: cargo install &lt;crate_name&gt; To install a local binary crate from the source, in the crate root directory: cargo install --path=. Both of these will install the binary to your cargo directory, usually `~/.cargo/bin` on Linux/MacOS. Not sure about Windows.
1. I think the API change is more related to async functions, which are de-sugared into futures. Not every function returns a `Result`, right? 2. Futures 0.3 has an executor. But the idea is that anyone could create his/her own executor with the given API interface. Currently many futures are running on `tokio`, so this compat layer is made to let you run futures on `tokio` now. There's also compat support to convert 0.1 futures to 0.3 futures in the package, if you check the project. 3. Async story is getting closer. `Future` made its way to std, along with `Task`, `Pin` API and many others. The async WG released [runtime](https://github.com/rustasync/runtime)
Mind if I use this as an excerpt for the project?
Yes, I will be using this for \[Diwata\]([https://github.com/ivanceras/diwata](https://github.com/ivanceras/diwata)) which had \[elm-webclient0([https://github.com/ivanceras/elm-webclient](https://github.com/ivanceras/elm-webclient)) before. I need to have the client side be written in rust as well to cut down more code especially in decoding the JSON data from API calls. I also need to squeeze more performance using the wasm code.
Tease ! Tease !
Awesome! In the `README.md`, it suggests including this package in `[dependencies]`. Is it possible to use 'dev-dependencies` and a [configuration flag](https://stackoverflow.com/questions/39204908/how-to-check-release-debug-builds-using-cfg-in-rust) to install it? Or will rust fail to compile the release version even if the symbols are only used within that configuration flag?
This is an absolute path, starting from the root namespace rather than the current module's namespace. (This is similar to filesystem paths, where "/foo/bar" is an absolute path while "foo/bar" is a relative path.) In the latest versions of Rust, thanks to the [path clarity](https://doc.rust-lang.org/nightly/edition-guide/rust-2018/module-system/path-clarity.html) features, this form of absolute path is no longer necessary, since you can use `crate::foo` to refer to an item named `foo` in the root of the current crate, and just `foo` to refer to an external crate named `foo`.
Fair enough, I know. But a lot of it I've written about already, including some nitty gritty of getting text right (spoiler alert, it's a hard problem), my approach to 2D graphics, and the general data-oriented approach I'm using. I also have a blog post in the queue about the "smooth resize test," or why GUI toolkits have such a hard time avoiding artifacts when a window is resized. So a bit of patience, and then I promise you'll see a lot more stuff.
Out of curiosity, does anyone you're aware of actually distribute application/library updates as DLL's, except for when they're part of the operating system anyway? From what I've seen if you can update a DLL the application depends on, you can just distribute a executable anyway.
Great ! Holding my breath...
Is it a good idea to do global installs from cargo? Won't this potentially lead to conflicts with installs from the package manager? (Or does cargo do user-level installs by default?)
Hey all, I'm trying to update my Pushrod library so that it draws to a 3D graphic texture rather than directly to the screen. This way, each `Widget` object has its own texture memory (preferrably in heap), and can directly have the GPU display that on screen rather than having to blit to screen. I saw some code posted a while back that covered this, but I cannot - for the life of me - find it on the 'net. I'm hoping someone knows how to accomplish this. This will help with making `Widgets` that can stretch, rotate, zoom in/out, fade, etc.
I'm looking for some help with the next round of drawing routines in Pushrod. Right now, Pushrod is fairly inefficient when it comes to drawing on screen. Each drawing cycle performs a re-draw of the screen, and this is highly inefficient. I'm looking for a way to modify the `Widget` library so that it draws to a 3D texture (OpenGL 3.2), and the drawing cycle then draws that to a master texture, and draws that texture (via an image) every drawing cycle. If the widgets aren't invalidated, the image doesn't change, so it doesn't matter how many times the image is redrawn. I'm hoping someone knows of an article to perform this, or has done this themselves in the past. It's a much more efficient design, and should work on any device that implements OpenGL. This means, smaller devices (Raspberry Pi, Orange Pi, etc.) should be able to handle the drawing cycle, and it should be blazing fast. Hope somebody has some insight!
Cargo installs to the user's home directory, usually ~/.cargo/bin
Binaries from `cargo install` go inside `~/.cargo/bin` IIRC, so it should only affect the current user (unless you're doing something silly like adding another user's `~/.cargo/bin` directory to your own `PATH` variable).
&gt; Yes, QT, GTK and some other toolkits allow to render a 3d scene into a window, but do nothing to help with detecting which part of the scene was clicked on, or at least I failed to find relevant APIs. Qt's `QGraphicsView` can do it. We KDE users made a big deal of it back in 2008 when it was [announced](https://blog.qt.io/blog/2008/12/02/widgets-enter-the-third-dimension-wolfenqt/) ([YouTube](https://www.youtube.com/watch?v=MXS3xKV-UM0)) because GTK+ couldn't. If those links die, the demo's name is WolfenQt. The TL;DR is that, if you use `QGraphicsView` to do your 3D and call `QGraphicsScene::addWidget`, input routing and focus should Just Work™.
Any crates that I could use for creating sound filters? Like equalizers, pitch adjust, bitcrush, etc.? Needed for a game I'm writing.
`dyn Trait` is, just like `[T]`, a type that is not `Sized`. Meaning that since the size of it is not known at compile time. One could argue that since `fn get_type() -&gt; AtomType` does not take anything unsized (like e g `self`) then it should be callable in the vtable, but Rust has not implemented that feature (unlike at least one other language I know, Delphi/object pascal).
TIL this feature exists. Nice.
*A relevant comment in this thread was deleted. You can read it below.* ---- . [[Continued...]](https://www.resavr.com/comment/what-issue-with-dynamic-12497654) ---- *^The ^username ^of ^the ^original ^author ^has ^been ^hidden ^for ^their ^own ^privacy. ^If ^you ^are ^the ^original ^author ^of ^this ^comment ^and ^want ^it ^removed, ^please [^[Send ^this ^PM]](http://np.reddit.com/message/compose?to=resavr_bot&amp;subject=remove&amp;message=12497654)*
I second getting this into rustc. Would be really nice to have as 90% of the time I'm looking at compiler errors anyway :')
You're thinking of `RefCell&lt;T&gt;` (which is often combined with Rc). Rc has no intrinsic interior mutability, and can't panic on access.
I can see this. What is a big show-stopper for me is interaction with heavy duty graphics. Canvas do exist, but passing data to them via JS seems to be a performance killer huge enough to actually matter.
love it. thanks!
OrbGL closely mimics html canvas API with focus on path. I see it as a questionable decision. Even Cairo contains subAPI for constructive area geometry and Skia provides pixel-based pre-defined shaders to combine layers. &amp;#x200B; Paths might be useful, but I think an API built around composable layers and pixel shaders would be a lot better for performance (it would be more friendly for modern hardware) and could be made mostly declarative and easier to use.
Seems I have to give QT a shot. Thanks.
The metered crate is exactly what I need for a project I'm working on. It even supports async functions! I was getting ready to write this myself. Great post that wound up saving me a lot of time.
When I try compiling for webasm, I get an error “rust-lld not found”. What should I do?
That would be great. At least for now, the guide still says they are required.
Unfortunately, despite GTK itself supporting and compiling on windows, [gtk-rs doesnt](https://github.com/gtk-rs/gtk/issues/702), so thats mostly out, unless you want to build and setup proper binaries some other way and hope it works.
Shrinkwraprs is basically obsolete now that we have type aliases [https://doc.rust-lang.org/book/ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases](https://doc.rust-lang.org/book/ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases)
No, type aliases can't enforce separation between the newtype and the underlying type, which Shrinkwrap maintains.
I think the point of using newtypes + shinkwraprs is that you still have the power of distinct types. Type aliases are not regarded as actual distinct types, so they can be unintentionally mixed-up. [for example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=efd03eb8287688053580bd85a71b05e5)
I want to access them cheaply. Have a look at the current version: https://github.com/greaka/rest-client/blob/9c425738e772e8c009e2ba63f0ec2aede3c3c9bc/codegen/src/lib.rs#L65
It might look that way but it's not the case [https://doc.rust-lang.org/book/ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases](https://doc.rust-lang.org/book/ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases) &gt;`type Kilometers = i32;` Because `Kilometers` and `i32` are the same type, we can add values of both types and we can pass `Kilometers` values to functions that take `i32` parameters. However, using this method, we don’t get the type checking benefits that we get from the newtype pattern discussed earlier. &gt; &gt;The main use case for type synonyms is to reduce repetition
You might want to look into the [KHR\_swap\_buffers\_with\_damage](https://www.khronos.org/registry/EGL/extensions/KHR/EGL_KHR_swap_buffers_with_damage.txt) EGL extension.
I won't lie to you. This seems rather complex and not immediately obvious to future readers what this macro is actually doing.
Qt. It's pronounced “cute” not “cutie”
Hmm, ok, I will try and improve the README. Thanks for letting me know.
First you need to define a set of things that are guaranteed to remain stable at the ABI level, in terms of source constructs and the ABI-level things they map to. This is _plausible_ in Rust, though I'm not aware of it having been done, and it would be a huge amount of work. Second, you need to define a set of things that are meaningfully allowed to _change_ while still "being compatible" at an ABI level, i.e. you "ought" to be able to add a method to the end of a trait object's vtable without breaking clients using the early entries, right? But you need to nail all that sort of stuff down, and there's a _lot_ of it. This takes even more work than the first part, and as far as I know nobody's done it here either. Finally, you need to put in place mechanisms to _insulate_ against coupling across library boundaries that you want to be able to dynamically relink. The main form of such coupling in Rust is the generic system's monomorphization. That is pretty much entirely incompatible with binary relinking, as it instantiates a replica of every callee in every generic caller, essentially inlining the implementation. So you'd need to do something like implement "extern linkage" generics in terms of trait objects, and properly defer all of their sizes and static information to dynamic calculations. Plus you need to defer enough information to re-resolve the whole trait system at runtime -- someone might link you against a library with a new impl, after all. This would be a _very_ large project, almost redesigning the entire compiler and runtime system. I don't mean to push Swift here, but Swift did this, and even there (where the language was _designed_ for this outcome) it was a massive undertaking. Rust has largely (at least after the first couple years) opted to sacrifice most things that help with dynamic linking in favour of design choices that prioritize runtime performance.
These are amazing! Thanks for sharing!
I meant it more from the point of view of readers of the code you integrate this macro in. The README does a sufficiently good job at explaining it I think.
[https://github.com/KDE/rust-qt-binding-generator](https://github.com/KDE/rust-qt-binding-generator)
&gt; I'm curious if that would support also mobile development (iOS, android) It's meant for incorporating Rust code into a C++ project and, last I checked, the C++ side is responsible for making the Qt calls and providing the top-level build automation, so it probably does.
This is very helpful. Snafu crate especially looks like something that would make boilerplate in my projects much smaller
I would be honored!
Hi, I wrote a short article about C++ vs Rust compile time memory safety, and I wanted to share here first before sharing with larger audiences. Any feedback will be greatly appreciated! Thanks!
I just skimmed very briefly - but I wonder if it comes across as biased. It may look like the examples were chosen for Rust strengths. Are there any cases where C++ is better at reporting errors than Rust? (Maybe a caveat regarding that Rust can sometimes reject valid code. Which maybe you have already?)
Keep going !! This project is very promising 👍
One option is to use [`std::process::Command`](https://doc.rust-lang.org/std/process/struct.Command.html) and [ffmpeg](https://trac.ffmpeg.org/wiki/Slideshow).
&gt;Even from an end user perspective I'd argue there is a difference between a crash and "your machine got taken over because of a vulnerability". Sure, there's an objective difference, and an educated user might even understand it. But the difference is unlikely to matter to typical users when they experience a panic-induced crash, especially if they suffer data loss because of it. There are good reasons why the borrow checker is primarily advertised for the compile-time safety it provides.
I mean you could just implement Deref for your type...
That regex macro crate is unbelievable! So great
shrinkwraps too. Holy f\*ck
Thanks for the explanation!
I'm glad you enjoyed it :)
Oh, I actually already knew about this crate, don't know how I forgot to include that as well. Though, last time I tried to run ctgrind from RustCrypto, I for some reason couldn't (that's all I remember).
Thanks!
It is bad practice though as it's using `Deref` on a newtype. You can read more about it [on stackoverflow](https://stackoverflow.com/a/45086999/3131852).
To be fair to C++, people should probably compile with GCC options \`-Wall -Wextra -Werror\` or similar. It's stricter and can diagonase more errors. It detects uninitialized variables, too. Just yesterday, it caught a copy/paste error on my part in which I forgot to change a variable name so that a local variable stayed unused and the compiler complained about it. Thank you, compiler! But yeah, I agree that C++ is lacking w.r.t. safety. It's easy to find blog articles by C++ programmers warning others about certain dangers. One of the biggest problems is "lifetime safety". The most recent blog articles I can recall are about dangers of dangling pointers/references in the context of \`string\_view\` and on a topic of "function object references" (C++ equivalent of \`&amp;Fn\`). Another big issue is thread-safety. Nowadays, you're forced to be careful when designing a custom data type: You better not build a type that *isn't* `Sync`. `const` access is assumed to be thread-safe by many. I really love that in Rust you get to explain these things to the compiler so it can prevent misuse of a non-Sync type. You don't have to conservatively use locks and atomics everywhere to stay `Sync` if you don't need `Sync`.
Can this reticulate splines?
It was, thanks!
Have you seen [https://crates.io/crates/failchain](https://crates.io/crates/failchain)? It seems to have even less boilerplate and I love its error chaining capabilities.
Keep up the good work! I'm watching this progress with a lot of interest. I have a direct need to build a GUI application that will run on a headless PI (no desktop environment) screen on boot i.e Kiosk style One of the options for that today is using JavaFX, which i'd rather not! I love the idea of having a native binary for low powered devices such as a pi!
I have to agree. &gt; Are there any cases where C++ is better at reporting errors than Rust? The only thing that comes to mind right now that has the potential for better static checking is the use of "const generics" (non-type template parameters in C++ terminology). I mean, you could use "dummy types" in Rust to emulate the concept of integers as compile-time parameters to some extend. But this is somewhat verbose and limited.
Woah, that does not require the standard library? Amazing, thanks!
I think I once heard about it but never tried
&gt;fn main() { for y in 0..31 { for x in 0..93 { let c = ( // map x from -1.0 to 1.0 (3 \* x) as f64 / (92) as f64 - 2.0, // map y from -2.0 to 1.0 (2 \* y) as f64 / (30) as f64 - 1.0 ); let mut z = (0.0, 0.0); let mut i = 0; while i &lt; 32 &amp;&amp; z.0 \* z.0 + z.1 \* z.1 &lt; 4.0 { let re = z.0 \* z.0 - z.1 \* z.1 + c.0; z.1 = 2.0 \* z.0 \* z.1 + c.1; z.0 = re; i += 1 } print!("{}", b" .:\*H@"\[i / 5\] as char); } println!() } } Remove the col/row variable and you can shorten it further.
The intrinsics are [available in `core::arch`](https://doc.rust-lang.org/core/arch/x86_64/index.html), but nightly-only for now.
What do you think about `Foo::get(format_args!("foo", 1, bar));` as a usage, compared to the current version? This way you can use different types.
If you happen to have an Ether Dream DAC, you can test this with some demos under the [nannou v0.9 branch examples](https://github.com/nannou-org/nannou/tree/v0.9/examples/laser). Two demonstrate how to use the raw and frame stream APIs while the GUI example is slightly more advanced and demonstrates how to change stream settings in real-time.
&gt; I dislike everything being web pages or electron. There is Proton Native, and some React Native support for desktop apps too. AFAIK, those are using native UI components to each supported platform, so no webpage/electron issues(supposedly, but since JS is used there might be some drawbacks still).
&gt; The only thing that could work if one could design for each platform the UI in one language separately but then you're back to having separate front-ends. Haxe is pretty neat. It provides a single language that sort of transpiles to other languages iirc. Recently the very popular UI toolkit from Actionscript, Feathers UI has announced they'll be migrating to Haxe which should be pretty interesting. There are some other UI toolkits written in Haxe already too(probably much more mature than when I last checked/followed the language 6 or so years ago). &gt; At this point I just prefer a GUI that looks the same on all platforms and uses some OS specific features. QML should be able to do that with QtQuick Controls 2(v1 was native, v2 they dropped native support and focused on performance with GPU and having a consistent design across platforms).
&gt; is the most mature Qt bridge for Rust. Last I heard that's true and it's under the KDE umbrella for some time now which is a pretty good indication of support :) &gt; I'm curious if that would support also mobile development (iOS, android) I think that's doable, but Qt licensing might make that less desirable, at least I recall using Qt on iOS/Android, and especially embedded as not being as open/free to develop for with Qt.
I'm rather new to Rust so maybe I don't have some insight yet, but some of these macros seem like they shouldn't be macros. E.g. the regex one looks very useful, but it seems very constrained in what it can do, because the mapping from regex group to struct member and how to convert them is implicitly done in the macro without any control over it. If I were to implement this in a method myself, I'd have the full power and could control all aspects of it.
Just do like every other software does on windows: provide DLL files alongside the binary and you're fine.
That's kinda like the annoying GNU/Linux thing. While accurate, not entirely important to most people who just care for a recognizable/associative word to reference what's being talked about. I'm not a big user, so I just say it as Que-Tee(as in the letters individually), still write it as Qt correctly but I imagine if I just spoke it as "cute" to someone who wasn't familiar they'd be a tad confused, they might recognize the individual letters though :P --- Oh you were specifically correcting QT to Qt. Above still kind of applies :)
Why all the downvotes on this guy? At least reply with some valid reasoning. Electron has it's fair share of negatives, no one is saying it's perfect. But often there are plenty of solid reasons to go with it, especially if you've got an existing webapp, or webdev skills, or want to make the most out of that large ecosystem. &gt; Good enough performance for 99% of use cases This right here is very true. Majority of UI needs are going to be fine and that's what electron is being suggested for here, UI/UX. Any business logic that's unrelated to that is going to be best suited in something like Rust or external API just like was pointed out. If you need native UI elements, then obviously electron isn't the right choice for you either. There are UI kits for web that will give the native look, but I don't advise them.
Hey, does this involve a 2D graphics lib over gfx-ll? I'd love to help on this, but I'm not clever enough to actually run the project (multiple failed attempts). :P
I get the point of this argument. In terms of the stackoverflow answer, I would say that an the following would a ba _is-a_ relationship: #[shrinkwrap] struct Email(String); The reason I think this is that an email is a string, with some special requirements during creation. If you only derive `Deref` and not `DerefMut`, this will upload the invariants that were made on creation.
That issue is about compiling gtk-rs with specifically with MSVC, not compiling on Windows in general, because that works with GCC.
There is also WebGL, but I guess you meant 2D specifically? Isn't the non-canvas support more attractive in that area? Markup + CSS can go a long way to handling performance well. What would you be using the canvas for that Markup and CSS wouldn't suit? If it's only for a specfic part of UI, you could probably bring up a window/view that isn't browser based and do your handling there, you could technically run that headless and stream an embedded version of it, perhaps with WebRTC or something, bit silly but I think would achieve the purpose, provided you had use for handling UI other than that view/window. &gt; interaction with heavy duty graphics. Any example of what you have in mind?
Looks cool! Is Windows supported? Couldn't find any mention (or missed it).
Useful read https://stackoverflow.com/questions/2401764/can-ffmpeg-be-used-as-a-library-instead-of-a-standalone-program
Okay, I was getting confused between type aliases and newtypes. So shrinkwrap just lets you omit the `.0`?
WebGL to my knowledge utilizes canvas element as well, am I wrong? \&gt;Any example of what you have in mind? What [vtk](https://vtk.org/) does. Essencially take volumetric and/or planar data arrays, run preprocessing and display the result as a colored map or 3d body, possibly with coordinate grid. Also, CAD apps.
Is there any 'deep' reason why rust doesn't allow assignments on struct declaration to do the same thing as the 'declare-new' macro here for a default constructor? I guess it would be bad if the type has no default type so you'd 'have' to assign something to get the new working.
&gt; WebGL to my knowledge utilizes canvas element as well, am I wrong? You're not wrong, but depending on your performance needs, you do get a lot more control/flexibility due to [the features it supports](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API). You can use the GPU more effectively due to that. &gt; Essencially take volumetric and/or planar data arrays, run preprocessing and display the result as a colored map or 3d body, possibly with coordinate grid. Ok, so 3D rendering looks like a given there? WebGL would be much better for that than rendering via just the Canvas API. You can get more out of the WebGL2 support too if that's useful to you(further down in the given link). gfx-rs is also working towards WebGL support, so using WASM could work perhaps, any of your intensive processing could happen there in Rust instead of JS, the overhead between WASM and JS isn't that expensive last I checked. There's some libs out there for doing 3D stuff in the browser though I personally haven't used any, three.js maybe?(I think there's a rust port of that too). &gt; Also, CAD and GIS apps. So, using web markup + css is good for UI stuff that those would have, any toolbar/panels could be handled via that rather well(React should be well suited for handling these as components and connecting to state). While the main content(3D or 2D) that's being worked on and any 3D/special UI widgets would be rendered via WebGL. Any need for a more traditional menu up top of the window can be done with electron, it'll provide a native menu, you get all the other native integrations you're probably wanting, and shortcuts etc. I have an interview later in the week for a company that's actually doing a CAD sort of web app product(they also use Rust), they also have a renderer that updates to the browser but renders the scene via GPUs "in the cloud". So definitely doable.
Yes, Windows is supported. Except for the explosion emoji, everything works fine on Windows.
Oh, I forgot to link to [PixiJS](http://www.pixijs.com/) which has a nice real-time example(I'm sure there are many others, but this is a popular lib for interactive canvas/webgl stuff iirc). They have plenty of examples further down that you can click to view of actual projects using it. Not quite the same as what you're asking about, but still meets the needs of interaction and performance for many others.
&gt;Ok, so 3D rendering looks like a given there? Not really, but it is common. &gt;While the main content(3D or 2D) that's being worked on and any 3D/special UI widgets would be rendered via WebGL. Passing to and from literal gygabytes of data? I think JS part might protest.
This crate seems cool but I found a blocked that wouldn't allow me to use it. Basically it's unusable(afaik) with if statements. Take this code: ``` fn replace_hyphens_from_version(cap: &amp;Captures) -&gt; impl Display { let mut from = match_at_index_str(cap, 1); let from_major = match_at_index_str(cap, 2); let from_minor = match_at_index_str(cap, 3); let from_patch = match_at_index_str(cap, 4); if is_any_version(&amp;from_major) { lazy_format!("") } else if is_any_version(&amp;from_minor) { lazy_format!("{}{}.0.0", Operator::Gte, from_major) } else if is_any_version(&amp;from_patch) { lazy_format!("{}{}.{}.0", Operator::Gte, from_major, from_minor) } else { lazy_format!("{}{}", Operator::Gte, from) } } ``` It gives the following compiler error: ``` if and else have incompatible types --&gt; src/range.rs:168:13 | 165 | } else if is_any_version(&amp;from_patch) { | ________________- 166 | | lazy_format!("{}{}.{}.0", Operator::Gte, from_major, from_minor) | | ---------------------------------------------------------------- expected because of this 167 | | } else { 168 | | lazy_format!("{}{}", Operator::Gte, from) | | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected struct `range::Range::replace_hyphens_from_version::LazyFormat`, found a different struct `range::Range::replace_hyphens_from_version::LazyFormat` 169 | | } | |_________- if and else have incompatible types | = note: expected type `range::Range::replace_hyphens_from_version::LazyFormat&lt;[closure@&lt;::lazy_format::lazy_format macros&gt;:15:14: 16:55 from_major:_, from_minor:_]&gt;` found type `range::Range::replace_hyphens_from_version::LazyFormat&lt;[closure@&lt;::lazy_format::lazy_format macros&gt;:15:14: 16:55 from:_]&gt;` = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info) ```
.. and it's been resolved
Seriously all these are amazing, goddamn.
Exactly, I did. And I don't think it's pedantic. It's just simply a word and not an abbreviation. It's like saying “IT” when you want to talk about Steven Kings “It”.
I would rather suggest something more practical. So, what about [docopt](http://docopt.org/)? It has a [Rust implementation](https://github.com/docopt/docopt.rs) too.
Very nice but I find that using \`specs-derive\` also makes life simpler.
I considered that but it points users towards clap/structopt. What would be the advantage?
`nalgebra` crate does exactly that with the help of `typenum` crate to emulate integer generics.
Whatecer unsafe code you write, if it is actually safe due to API and checks, will be rejected if you ommit unsafe block. Otherwise Rust typically does not reject valid code.
Yes, in the medium to long term. I'll have a GSoC student, Brian Merchant, working on it this summer. In the shorter term, the plan is to use platform graphics (Direct2D, CoreGraphics, Cairo).
Isnt a big application / use of thus database systems?
Why are all the examples showing function attributes instead of macros?
If you're willing to put a bit of effort into learning how to drive it, the [appsrc example for GStreamer-rs](https://github.com/sdroege/gstreamer-rs/blob/master/examples/src/bin/appsrc.rs) has most of what you want. The missing bit will be changing the GStreamer pipeline so that instead of putting your frames out on screen via `autovideosink`, you encode them into a suitable format and save to file.
Of course
Thank you for adding this much needed functionality to the rust ecosystem! It's all the little efforts like this that make the developer experience great!
Those count as macros.
They are a mix of Derive mode macros and Attribute macros. The attributes generate code from the defined structs and add behaviour to the data. https://doc.rust-lang.org/reference/procedural-macros.html
&gt;the plan is to use platform graphics What would you think about 2d graphics based on per-pixel shaders? Like, draw a cyrcle with shader checking if point coordinates correspond to x\^2+y\^2&lt;R\^2 and outputting fill color if yes and null color otherwise. Also, what about snapping key points of the scene to pixel grid?
It's a difficult question to answer I'm not 100% I know enough about all the tradeoff involved to answer it. You can go too far in using macro and there are some downsides like making it more difficult for IDEs to provide hints. Ideally, functions are prefered but there is a reason for macro and a lot more can be done with there metaprogramming features. If a macro can be replaced by a function like with the Regex one then you would have to be considerate when deciding to you it. Macros can reduce code boilerplate and increase readability. With the Regex one there doesn't seem to be too much lost as there is no native support for Regexs or type information. The macro is likely constrained compared to a function but then nothing is preventing a developer from using both.
Nice article. One issue with it though &gt; I couldn’t manage to run it successfully even though I told the author of the project the opposite. I thought it would be rude to make him waste his time on a project that he wrote 6 years ago I think it's not good to mislead someone that their project works. Now they believe it works and anyone following in your footsteps will either see you got it working or be told by the maintainer that it works. Better to say it didn't and that you'll continue searching for answers by yourself.
Well, I use it anyway, as it seems pretty stable. And it was updated two weeks ago, btw. I like **docopt** for it's ease of use. And it's not that opinionated on usage text and structure as **clap** is. You may want to use clap if you decided to implement very complicated CLI app like **git**.
My guess would be that the default pattern is considered more explicit
Same. I agree with your sentiment about not wanting to waste the author's time, but I think the way you went about it was a bit of a disservice. I think it would be better to be upfront that it didn't work but that you don't need them to work on a solution. After all, maybe they're interested in returning to the project and just needed to be given a reason to justify it? It's really up to the author on whether it's a waste of time or not.
eh, I can't say I'm happy to see this kind of public shaming on this sub. "This open source developer isn't doing the unpaid work fast enough for me" doesn't engender much sympathy from me. I understand the frustration of a dependency not being updated fast enough, but I don't think a public shaming is the right course of action to improve the situation.
It's not what I'm focusing on right now but I see the value strongly; clearly it's excellent for running on GPU. I'm focusing on traditional 2D because most UI elements can be expressed in terms of it, and I believe it can be implemented well on GPU as well. I'd like to add shaders also, but not in the very near term. In the meantime, people should take a close look at [makepad](https://github.com/makepad/makepad), which is shader-based (OpenGL and WebGL). Of the efforts other than druid, it's the one I find most impressive.
&gt; Otherwise Rust typically does not reject valid code. That's not really true though, Rust's fundamental tradeoff is to reject all programs the borrow checker can't prove to be free of memory safety issues. This must necessarily also reject programs that *would* actually behave correctly at runtime, because the compiler can't reason about the entire runtime behavior of the program (in other words, the borrow checker has false positives). C++ went a different route, at least wrt. memory safety, and will instead often *allow* programs that are clearly UB or have memory safety problems (C++ compilers have false negatives).
Clang is also getting the -Wlifetime and -Wlifetime-debug switches, which perform lifetime analysis on C++ code.
I'll be reading through these tonight, thank you! Is it a good assumption that this could be used to enable your users to write plugins in any language that targets wasm?
Thank you both for your comments! You are absolutely right and I should tell the author that it didn’t work for not to mislead them. I think I reacted a bit emotional by not wanting the author to waste his time on that. However, as you both said, it’s up to the maintainer whether to invest time to fix it or not. I’ll let him know as soon as possible
Thank you both for your comments! You are absolutely right and I should tell the author that it didn’t work for not to mislead them. I think I reacted a bit emotional by not wanting the author to waste his time on that. However, as you both said, it’s up to the maintainer whether to invest time to fix it or not. I’ll let him know as soon as possible
`SliceRandom` is only implemented for slices, and yes `&amp;str` is not a slice. The easiest way to fix it will be to [convert](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7033e2324baa3df9197115dd825f8c3d) your string to vector of chars. Alternatively you can write `letters.chars().nth(rng.gen_range(0, letters.len()))`, but mind the linear complexity.
You can use `letters.as_bytes().choose(&amp;mut rng).map(|&amp;c| c as char)` if your string is ASCII.
What do you use for syntax highlighting on your blog?
Ah, yes, lazy_formet uses an opaque type (similar to a closure) as its.return value, so every call site has a different return type. I do this to allow it to be `no_std` and ensure maximum opportunity for inlining; one of my design goals was that lazy_format (like other rust abstractions) should be 0-cost; it should be as efficient as hand-written structs and `write!` calls. You can solve this by Boxing the `lazy_format`, or using other Rust type-erasure features: if is_any_version(&amp;from_major) { Box::new(lazy_format!(...)) as Box&lt;dyn Display&gt; } ...
&gt; That's not really true though, Rust's fundamental tradeoff is to reject all programs the borrow checker can't prove to be free of memory safety issues. This must necessarily also reject programs that would actually behave correctly at runtime, because the compiler can't reason about the entire runtime behavior of the program (in other words, the borrow checker has false positives). Nah, it just makes those programs available in a safer interface from the std (no_std gets nuffing iirc). Namely the pointer types Rc&lt;RefCell&gt;, Rc&lt;Cell&gt;, Arc&lt;RWLock&gt; etc...
I was thinking of making a GUI app using PyQT and Rust for the logic. Would it be better to call my Rust code through FFI or use something like rust-cpython?
Is...is `structopt` not practical? D:
I agree -- Shaming isn't a good way to encourage people to spend their free time for you! OP already states that they are considering solving their problem by migrating away. Shouldn't the case be closed at that point? :(
I tend to agree, but also "your project might be broke for months" is something you'd want to be aware of when picking a web framework. The relevant patch is already merged, but not uploaded to crates.io. My options right now (also because of the way rust dependencies work): - Drop rocket and rewrite everything to a different web framework - Fork rocket - Discontinue my project until this bug is fixed - Point people at the issue and hope something happens
&gt; Passing to and from literal gygabytes of data? Dunno, I don't have experience with what you linked to, but I do have experience with 3D in different areas where it's totally possible to get get visuals like the pictures I saw on the link. Even native 3D apps can choke on gigabytes of data, ones that are used professionally in the film industry, all depends how that that data is being used/applied. I've worked on some photogrammetry to real-time assets for VR where the input 3D data at full size was over 100GB, billions of triangles, that gets reduced down to around 2-3 million, and further optimized by splitting the mesh into chunks for occlusion culling, and separate textures(100x8k for both normals and diffuse). Is that GB of data constantly changing in this case or is that the full size? You could partition it into something like an octree, there are point cloud viewers that do stuff like that with very high density data being loaded in/out, similar to how Google Maps and MapBox do with 2D tiles at various layers from zooming/panning. It's not practical to load in all data for them at full resolution, not even on a native app out of browser. --- I'm not claiming it will be the right choice for building an app for those needs, while I certainly imagine it being capable, electron won't always be appropriate. If your app doesn't suit running off electron, by all means choose something else, I was just stating for the majority of apps, it's really great at meeting most users and developers needs.
Yup, that's one of the main goals of the lib. I am targeting "lower class citizen" hardware, and I'm happy to hear that it's on the list! The hardest part is going to be the text input, but I have a lot of experience in that regard - for single lines of text. Multiple lines (like a text buffer) are much more difficult. But I'll tackle that as I get to it.
Yup, that's the concept. The idea would be to draw all of the items on a single image, and use that buffer against which to invalidate. Only once an image becomes invalidated will it be swapped out. I _had_ this working at one point - the problem became when I tried to do clipping and offsets. But I think I know what I did wrong. I can revisit that code.
I think we're going to see a lot of cool procedural macros in the near future as more and more articles are written about how to write them and what kind of things you can do with them. I don't know if there's any interest (aside from me), but I'm working on a macro to let you easily parse/construct URL paths and query strings into structs. The current code lets you write something like this: #[derive(Debug, Deserialize)] #[serde(rename_all = "lowercase")] pub enum SortDirection { Asc, Desc, } #[derive(Debug, Deserialize)] struct UserListQuery { column: Option&lt;String&gt;, direction: Option&lt;SortDirection&gt;, keyword: Option&lt;String&gt;, limit: Option&lt;u64&gt;, offset: Option&lt;u64&gt;, } #[derive(AppPath, Debug)] #[path("/api/companies/:company_id/teams/:team_id/users")] struct UserListPath { company_id: String, team_id: u64, #[query] query: Option&lt;UserListQuery&gt;, } This will enable you to write code like: let path_string = "/api/companies/company123/teams/32/users?offset=10&amp;column=name&amp;direction=asc"; let user_list_path = UserListPath::from_str(path_string); println!("user_list_path: {:#?}", user_list_path); This works but it's still a work in progress, with a goal of getting it as simple and performant as possible without sacrificing flexibility. Looking forward to seeing more quality-of-life macros in the future!
There is one other option: fix the bug and publish a PR. Am I missing something?
Have you looked into [Phil Oppermann's blog](https://os.phil-opp.com/) at all? The first two posts are the relevant ones since most of the blog is about x86_64 kernel development, but I'm curious if they would be a useful resource for you.
It's `atelier-dune-dark`. Actually, I want to use `woodland`, which is the one I use both for `alacritty` and `vim`, but I couldn't find a stylus file for it.
The patch has been merged, but I need the updated version on crates.io to fully resolve the issue. I currently need to rely on a [patch] section to build the project which means the whole cargo workspace can't be uploaded to crates.io anymore.
Thanks, the conversion to vector of chars seems to be the one that fits better. I'll read more about this kind of conversion too, since it seems to be really useful.
Do you use something like [Prism.js](https://prismjs.com/) to support the theme?
If I understood correctly, this converts the string to bytes, pick a random byte and convert that byte back to a char? I like this idea and might use it in the future, but for now I decided to go with the "convert to vector of chars" option, since it's easier to understand. Thanks for the help :)
May I ask how to find and access the Cargo.toml
the blog engine [`hexo`](https://github.com/hexojs/hexo) uses `highlight.js` under the hood.
I was reaching out to lazy_format to avoid the allocation in the first place. Thanks anyways
Ah ok. I was only aware of function-like macros.
When your `SytemData` tuple starts to get complex you can create a struct with named fields and use shred-derive to `#[derive(SystemData)]`.
full hardware support for (the entirety) AVX-512 hasn't release yet.
&lt;3
You can also just start with a byteslice using this syntax: let letters = b"ABCDEFGHIJKLMNOPQRSTUVXWYZ"; See this [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e1c9450b700ad6f71b00d32c50bee641)
From [Rust Cookbook](https://rust-lang-nursery.github.io/rust-cookbook/algorithms/randomness.html#create-random-passwords-from-a-set-of-user-defined-characters): extern crate rand; fn main() { use rand::Rng; const CHARSET: &amp;[u8] = b"ABCDEFGHIJKLMNOPQRSTUVWXYZ\ abcdefghijklmnopqrstuvwxyz\ 0123456789)(*&amp;^%$#@!~"; const PASSWORD_LEN: usize = 30; let mut rng = rand::thread_rng(); let password: String = (0..PASSWORD_LEN) .map(|_| { let idx = rng.gen_range(0, CHARSET.len()); // This is safe because `idx` is in range of `CHARSET` char::from(unsafe { *CHARSET.get_unchecked(idx) }) }) .collect(); println!("{:?}", password); }
Good bot.
&gt; this converts the string to bytes It doesn't convert anything. Rust strings are UTF-8 encoded, so one character can have one or multiple bytes. `as_bytes()` exposes the string as a slice of bytes, e.g. returns another "view" of it. There's no conversion or allocation involved. Wrt. the `.chars()` solution, that does no conversion, but returns an iterator over the individual characters. The issue with that is that there's no random access to a specific character. So if your RNG returns 10, it will start from the first one and count to ten instead of returning "J" directly. Also, if your string is not ASCII (so it has non-Latin characters), `as_bytes` will give you a byte that gets converted to a nonsensical character, while `chars` may seem to work, but `letters.len()` will be larger than `letters.chars().count()` (because the encoding has more bytes than characters). /u/raggy_rs has another good solution for ASCII strings. Finally, if you know you only have a contiguous range of characters, you can generate a number from e.g. 0 to 25, then add that to `b'A'` to get a random character.
Nb. `letters.chars().count()` is not necessarily equal to `letters.len()`.
There is a typo in "Extremly", it should read "Extremely". Apart from that, the README is devoid of any information, and your claim of "Fast" does not seem backed up by any benchmark, so what do you expect us to talk about?
Thanks so much for your note. :)
Yes, you are totally right, we should use `count` in my snippet.
Cool list! Didn't know about most of them. I'm a little jealous that my derive_more hasn't made it though: https://github.com/JelteF/derive_more
I wrote [this](https://github.com/njaard/oakland)
Use `&amp;T` over `Rc&lt;T&gt;` whenever possible because `Rc` implies heap allocation
It's an homemade theme ?
I've achieved decent results programmatically creating "seed" frames for gifs using ```imageproc```, but I imagine encoding for video might be quite different from that.
What does "access" them cheaply means? Do you want to use the elements of the vec to format a a string passed to the proc macro? You will probably need a lazy_format or something like that.
Snapping is absolutely required for font rendering (hinting). Yes, modern hi-resolution displays somewhat help, but not completely. FullHD is with us for quite some time and the difference between hinted and unhinted rendering is clearly visible. Similarly, snapping should help with small icon rendering.
Do you know who I am?
&gt; Nah, it just makes those programs available in a safer (if you call call panicking if invalid safer) interface from the std (no_std gets nuffing iirc). Namely the runtime pointer types Rc&lt;RefCell&gt;, Rc&lt;Cell&gt;, Arc&lt;RWLock&gt; etc... This incurs a performance cost and requires rewriting the safe-but-rejected program though. I was more talking about programs like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9c9a2c3687bfe74ca6261c3392934e34), which are clearly safe as-written, but are rejected by the borrow checker because it doesn't model or can't reason about parts of the program's behavior. C++ would just allow this without thinking. *This* is a fundamental tradeoff Rust makes. It is also something that isn't fixable without giving up the safety guarantees entirely, because it is a non-trivial semantic property and thus undecidable ("Is this program memory-safe for all inputs?"). Naturally, I think this is a very good tradeoff, or I wouldn't be using Rust in the first place. However the strategy of "giving up" at compile-time and employing runtime checks is also well-established already, for example in Java (escape analysis, much of generics) or Objective C (elision of refcount manipulation), languages like C++ and Rust just either can't afford or don't want to employ implicit behavior like this.
Are you perhaps suggesting that there would be a popular usecase for a version of rust (or similar) where a tracing runtime garbage heap collector could be active optionally as a global pointer type? Rust devs probably avoided the idea for the same reasons that they have no runtime (C bare bones usecases). Well i know about the projects to create a runtime GC in rust as a library, but i'm 95% sure those will not get popular because they're not super-egonomic builtins. I do think that if Rust had gone that way, it would look very different and cargo would probably have a new library tag 'usesGC' or similar.
Please, what do you mean by your comment exactly? My interpretations: Intel hasn't released it; LLVM doesn't support it, or Rust doesn't support the full spectrum of AVX-512 yet (even not in 'nightly').
I like the styling on your blog, very enjoyable read.
All posts on Reddit are automatically archived six months after being posted. For longer-term discussion, and for putting answers somewhere with better search engine discoverability, prefer the Rust tag on Stack Overflow.
(sorry for the meta-comment, just wanted to say that reddit archives threads after 6 months: https://www.reddit.com/r/help/comments/az320v/what_is_an_archived_post/)
Thanks I didn't know.
By using `structopt` you're CLI is already better than 99% of software hard there.
I mean that's a really ugly solution for something that can be extremely trivial.
Did you write said book? Because if you did, I would love to learn what could have changed to make it irrelevant. And no, hi-resolution screens are not widespread enough to make it irrelevant (and likely won't be for quite some time, maybe for decades)
&gt; I wonder if there will ever be an enum&lt;T&gt; {Some(T), Empty, None}? What does this even mean? If you want such an enum why not just write it?
You have reinvented modularization. And libraries. Think jpeg. You don’t need to know the Joey algorithms, you just need libjpeg.
When you run `cargo new` to create a Rust project, it will create a Cargo.toml file. Chapter 1 of [The Rust Programming Language](https://doc.rust-lang.org/book/title-page.html) will walk you through this in more detail.
I didn't write that book, but much of my career has been on font technology and 2D graphics. I wrote that line as something of a joke, I'm actually quite interested in engaging a more substantive discussion. I totally agree that on low-dpi screens you want something that looks *really* close to platform text, which is actually one of the main reasons my stuff is designed as an abstraction rather than trying to use 3D API's.
Thanks for the clarification, it helps a lot. Doing some tests to see which method so far works better for me.
I saw that on the Rust cookbook, but decided to look for another way since I didn't want to use unsafe, specially when there seemed to be a method that already did what I needed.
Can't say i agree with the blog that the 'bulge' (ie: separating most of a complex function into subfunctions) is bad. Good naming can make complicated or obscure code extraordinarily clear, It's not a real surprise that most of the good refactoring books suggest dividing big functions into smaller parts and naming them well. You can often spot opportunities for better reuse like that and it's a way to avoid getting blinded by familiarity with the domain to how complex the code actually is to a newcomer.
Before you can do this, you have to define what an 'element' of a string is. Is it a byte of the string encoding? Is it a code point? Is it a grapheme?
avx512 has many subvariants and not all of them have cpus that exist yet that support them.
Hm. Ok. I'm a career chemist. As one, I often have to draw chemical structures. My editor of choice is Biorad ChemWin, because nothing better was invented yet. However, when I scale chemwin figues, I often hit undesirable artifact, like step on vertical lines, for example. Also, some elements look quite awful when drawn at certain angles. Some of said artifacts can be blamed onto redactor failing to produce perfect positioning, but some cannot. I suspect, this type of graphics needs some equivalent of autohinting to look good without handcrafting for specific resolution. Maybe something more. Yes, it is a niche application, but the problem is real and probably spreads to other types of similar graphics as well. The problem is very apparent on fullHD displays, and I doubt it will disappear before 8k displays become a norm.
thanks sounds promising! are things like, tabs, drop downs, and resize-able panes, and grid layouts in the road map?
&gt; he most recent blog articles I can recall are about dangers of dangling pointers/references in the context of `string_view`... Thanks for the suggestion! I added `string_view` lifetime example to the article. &gt; To be fair to C++, people should probably compile with GCC options -Wall -Wextra -Werror or similar. Those options only catch one (uninitialized variable) out of five code examples in the article.
&gt; programs like this, which are clearly safe as-written I think this program could be undefined behavior as written, though I don't know if the LLVM optimizations that could trigger UB are currently enabled. The problem I'm worried about is that things[1] = 3; implicitly calls `IndexMut::index_mut`, which takes `&amp;mut self` over the whole array. That means there's a region where you have overlapping `&amp;` and `&amp;mut` references to part of the array, which violates the aliasing guarantees and I think gives the compiler license to eat your lunch. I'm sure there's a way to do this By The Book with unsafe pointers, but I think value of this example (other than just being pedantic, I swear), is highlighting that safe Rust is making much tighter guarantees to the compiler than comparable C/C++ code does, and a lot of "safe looking but invalid" examples actually do violate those guarantees.
Mac default software (QuickTime) creates .mov or .mp4 so idk
Good point! In my case, `T` is a complex data structure with Vecs / HashMaps in it, so I imagine `Rc` incurs less of a penalty since most of the data will already be heap allocated?
How much of that would be solved by doing the drawing operations in a properly gamma-corrected colorspace, but otherwise treating antialiasing as exact-area coverage without doing fitting to the pixel grid? I'd guess it would look very nice even at 1080p.
Bulgur, not bulge 😇. The point I was making wasn't against splitting complex functions per se. It was about going too far in the splitting. If you split a piece of functionality out, it should have some actual meaning. Not doing something like: ``` fn log_call() { debug!("The function was called"); } fn something() { log_call(); ... } ``` (Here I'm *not* exaggerating, I literally mean such one-line function)
&gt; but if you’re curious, the specific type is `HashMap&lt;&amp;str, usize&gt;` If you are hashing a `&amp;str`, does the hash function operate on a pointer address, or the string slice behind it?
Since you indicated in your article that you might be seeking feedback about the concept and your analysis, here's my $158. It is a valid concept, but it is also pretty well known to most as the general principle of isolating unrelated components or those that can live on one side of an abstraction or interface etc. I'd be careful about writing in the authoritative manner of official docs when also telling a story of discovery since it comes across as a bit r/im14andthisisdeep. What I would do with this kind of writing is try to compress it to a minimal list of core facts and arguments that are strictly true and see if it isn't in fact a more satisfying result. Then you start weaving a story of your discovery if you feel like it. Usually I try to not to introduce _new_ parables and illustrative analogies etc unless dealing with something that is counter-intuitive. A nuclear reactor is a new one. &gt; Lifetime subtyping doesn’t work like a temporal Venn diagram This is an example of empathizing with what I believe a common mental model of subtype relationships and pointing out that it's totally wrong for the task at hand.
Support for Git repos would be neat. Once projects get big, you often need many git repos, and it can take a lot of work to set up. In the past I've used a python setup script, but a parallel tool that speaks Git, HTTP, and AWS S3 would be awesome.
I have somehow never heard anybody say serde out loud and assumed it was pronounced as the french merde. I'm still undecided if i will accept this new 'sir-dee' :P
I think downloading vs 2019 will work (hopefully). Thanks for the patience in helping me out.
Keys must implement the `Hash` trait, so in general the implementer can decide the particular behavior. Link below is to the implementation for `str`, which passes the underlying bytes to the hash function. https://doc.rust-lang.org/src/core/hash/mod.rs.html#599-604
No prob!
"As teased in the last post, we recently switched towards stretch to avoid non-Rust dependencies and potential performance improvements." I'd also avoid potential performance improvements.
For the international community, a heads up: my talk "Friendly Ferris: Developing Kind Compiler Errors" is in Spanish (although you can faintly hear the live translators speaking). I will make an effort to contribute subtitles to it, but it will probably take me a while :)
Chemical structure is usually pure black-and-white, with only occasional coloring. Quite often lines with width of 1-2 pixels is used. Rogue greyscale should not appear &amp;#x200B; Here are examples with artifacts visible on fullHD monitor A a very forgiving case of [C60 fullerene structure](https://upload.wikimedia.org/wikipedia/commons/c/c8/Buckminsterfullerene-2D-skeletal_numbered.svg) depicted in svg. On my screen I see steps on 2-3 and 3-4 lines (but not on 4-5 and 1-5 lines) at 100%. [Here](https://upload.wikimedia.org/wikipedia/commons/c/c3/Cyclopropa212_C70fullerene-2D-skeletal_renumbered.svg) steps can be seen on 66-67 and 2-12 lines. Another example [a fairly small structure](https://upload.wikimedia.org/wikipedia/commons/0/0f/Berberin.svg) , when I open the svg in separate page and scale down with firefox to 50% (this is roughly the size it would be displayed on reading chemical paper pdf with comfortable font size) I see clear steps on the line going down from the upper O letter. The step becomes uglier if the structure is scaled to 30%.
As i understand it `&amp;` are not really pointers. `&amp;str` is not the type "Pointer to str" as it is in C. it is primarily there to indicate it is borrowed and not owned. Hash is implemented for the type `str`. The trait Hash requires `hash(&amp;self,...)` so it can use `&amp;str`. `&amp;&amp;str` and `&amp;&amp;&amp;str` will deference to the `hash(&amp;str..)` implementation but could be [overwritten](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=860c704cd89670cd4e193fcadb7f5701) (if you owned the hash trait ) Pointers in rust are in the `ptr` module.
I'm constantly amazed that i'm not cynical enough, but never saw something so lame.
That's really interesting and I didn't know that they are working on lifetime. Thanks for the info!
Is that really much shorter than ``` fn main(){println!(r#"████ █ █ ███ ███ █ █ █ █ █ █ ████ █ █ ███ █ █ █ █ █ █ █ █ █ ████ ███ █ "#);} ``` ? lol
Would it be worthwhile to make the verification results available to the compiler, making safe unchecked indexing and some optimization improvements possible? Is it something you're planning to pursue?
Well actually I still got some questions. I am planning to download visual studio 2019, but which extension do I need now.
If you want, you can implement the `FromStr` trait for your struct and inside use the `regex` crate to parse the string, having as much control over the process as you want. E.g. you can write impl std::str::FromString for LogEntry { type Error=AppropriateErrorType; fn from_str(s: &amp;str) -&gt; Result&lt;Self, Self::Error&gt; { lazy_static! { static ref LOG_ENTRY: Regex = Regex::new(r#"(?x) (?P&lt;foo&gt;\d+) \s+ (?P&lt;bar&gt;true|false) \s+ (?P&lt;baz&gt;\S+) "#).unwrap(); } let caps = LOG_ENTRY.captures(s).ok_or("Could not parse line")?; let foo: usize = caps.name("foo").as_str().parse()?; let bar: bool = caps.name("bar").as_str().parse()?; let baz: String = caps.name("baz").as_str().to_string(); Ok(LogEntry { foo, bar, baz }) } } and it should behave similarly to `recap`. It's a lot more boilerplate code, though, for something fairly common. (`recap` doesn't generate code quite like the above, though [it does use `lazy_static`](https://github.com/softprops/recap/blob/6424d76b93620b283823c302a5a3a5e57973bff3/recap-derive/src/lib.rs#L29). Instead, it requires that your struct implement `Deserialize` and then uses [envy](https://github.com/softprops/envy) to deserialize from the capture groups.)
So you shouldn’t need one, VS Code and Visual Studio are different applications, but they share the same binaries and such in the backend. So just use VS Code
Do I need Visual Studio Community if I have the required Visual Studio Build tools?
I don’t know, try it and find out
&amp; in general are pointers, but some are “double pointers”, like &amp;str and &amp;[T]. They contain both a regular pointer and a length.
Hashing &amp;T will always be the same as hashing T in rust because we prefer value semantics. It is actually impossible to implement hashing by address for a &amp;T in Rust because Hash is already blanket implemented for &amp;'_ T where T: Hash.
It defaults to just being warnings sadly, but it's still going to be interesting regardless!
If I'm not mistaken, functional programming, or at least Haskell, frequently encourages that kind of 1 to 2 line functions. Sure, Haskellers tend to be more elitest than necessary, but it may also have something to do with how terse it is to declare and use such functions. Naming is still a problem though, as is excessively generic code.
That's for the unsized `str`, and then `Hash for &amp;T` passes through to `T` to do the hashing, which completes the story for `&amp;str`. https://doc.rust-lang.org/src/core/hash/mod.rs.html#662-666
The `decimal` crate does seem like a good fit for that. I imagine it hasn't updated for a while simply because the API is stable and there's only so much that can break for a crate like this.
For working with money I'd recommend storing number of cents as an integer and avoid float issues. Or maybe used fixed point.
Today I've become a Rust mentor at [https://exercism.io](https://exercism.io/), which means that I can give feedback on Rust exercise solutions of people that have chosen to receive (free) feedback. I like reviewing other people's code (especially when they actually want to get feedback) because I get to teach them things I know, and often I learn from their code as well. I'd really encourage anyone that feels the same way as me to try it out! There's no commitment whatsoever, so you can come online as much or as little as you like to teach people how to write more idiomatic Rust.
If `T` is `Vec` then you just going to allocate pointer to underlying memory and length. Regardless, any heap allocation is worse than not having heap allocation regardless of how smol it is
I decided not to try it. But something new happened: I downloaded the build tools and guess what? I got the program in VS Code to compile and print Hello, world! But when I change the code into something else and I do cargo run, it still prints Hello, world! so I think i have to save my changes or something but how do I do that?
Uh ctrl+s...
Same, except I've always made it rhyme with "hair day".
Right, this can be improved at low-res by doing the rendering taking gamma into account. I did a [quick test](https://levien.com/tmp/Berberin.png) using Gimp but am not going to claim this is the best you can do. On the other hand, if you just quantize the endpoints to integer coordinates, you're not going to change rendering much at all. Issues of gamma in rendering are very deep water, and there's no one right answer. Rather, I would approach this as a design task where you seek out the best possible final rendering given the technology available. Or, these days, you could just buy a proper monitor.
How do I compile the examples? When I run the bash scripts it complains about something not being set correctly in Cargo.toml
Meanwhile, YouTube has (auto-generated) Spanish subtitles _and_ automatic translation into a few dozen languages. Skipping through a bit the English subtitles seem to cover most of it pretty well.
Unfortunately at this point `bincode` is limited to rust only however (in theory) you could use this same scheme with another serialization format. I haven't experimented with any other languages and how they interact with wasm
For years, having only ever seen it written down, I pronounced Sqlite as "skwullite", and so SQL as "skwull"... Learning programming and tools from text sources only is hard in unexpected ways... :P
Once my crate reaches 1.0, are there any projects or tools that assist in avoiding making inadvertent breaking changes in minor/patch releases?
I have the VS Code editor open, pressed on a random line in my code, pressed ctrl + s (without the +), typed in cargo run into the terminal, same thing happened. What step am I missing?
I'm doing a Google integration at work and this is how they handle money. There is an int for the whole number of dollars, and an int for the cents \*10\^9 &amp;#x200B; so basically fixed point I guess
Are you describing the reactive pattern which is essentially small components linked by queues, thus encapsulating functionality with hard interfaces? It sounds like it. It's used in banks a lot for handling dependencies between systems. A way to implement this is Rust is utilising an ECS but with the addition of a driving clock (like an FPGA) which schedules the Systems per cycle.
The `rust_decimal` crate also looks good. It is pure rust and updated recently. `decimal` wraps a C library, so I imagine there is nothing to update as long as the library is stable.
I too have always assumed it was pronounced like merde
What did you change? You may have to do cargo build first
On the extreme end of that side of the spectrum, concatenative languages like Factor (think Haskell except you're only allowed to use point-free style) encourage using one line functions just about everywhere. The way I see it, they are using functions to factor out not only common functionality, but common code structure and just boilerplate code in general. In everyday languages, it's a balancing act. Too much factoring, and you have to look everywhere for code and the benefits start to become insignificant. Too little, and you're introducing unnecessary verbosity and duplication.
I know right! I asume it's pronounced like this based on ser(ialize)-de(serialize)
heh, thanks! ..and fixed :D
I'm not seeing any of the AVX-512 intrinsic functions. Just the basic datatypes. The Autovectorize may work though, but that's not what you're looking for. There are a ton of AVX-512 instructions so I don't think anyone has had the time and drive to add all of them. If you only need a few it maybe possible to add the ones you need by hand. Help on how to do that and most up to date info for AVX-512 support should be at [https://github.com/rust-lang-nursery/stdsimd/issues/310](https://github.com/rust-lang-nursery/stdsimd/issues/310) It looks like more people are trying than the last time I checked.
You know I forget how I pronounced it in my talk, but it's one of those things I think will never be agreed upon but we all know what it means
Test suites? At least one test case per function will make sure that the API is not broken.
`&amp;` are references which are a type of pointer, as far as I'm aware.
I wrote the following program: fn main() { let x: bool = true; let y: bool = false; println!("{}", x||y) } I entered cargo build without errors, and cargo run without errors but it still printed "Hello, world!" without the quotations.
I have been pronouncing it with a silent e. Sir-D
&gt;I did a [quick test](https://levien.com/tmp/Berberin.png) using Gimp but am not going to claim this is the best you can do. That's actually quite good, IMHO &gt;On the other hand, if you just quantize the endpoints to integer coordinates, you're not going to change rendering much at all. It probably isn't pure grid snapping, some constraints should be probably take into account. Consider a pixel grid 21x21 with 1-pixel width lines \[(0;0) - (10;10)\], \[(10;10) - (0;11)\] and \[(10;10) - (20;20)\]. Then scale it up to the 40x40 grid with requirement that the picture appeared to be black and white only and shape and relative length of the lines didn't distort and line weight was kept the same (unscaled) Chemwin occasionally produces 1-pixel steps on vertical lines on upscaling. &gt; Or, these days, you could just buy a proper monitor. If you are the only person affected, sure. It isn't always the case, and frankly speaking, 1080p monitors still occupy majority of the market to my knowledge.
Your original post's [link](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=aeadf83622b18966308f8eae6e07d2b7) to it still works. Ping /u/YatoRust
I can’t find it now, but From the research I did last time I worked on this, there are only three small nations who do not use 100 cents to the dollar. Google aims to support everyone everywhere, so this makes sense. Or are they using space to store fractional cents? If you’re wanting to build a hobby application, it’s probably much easier to just use an i64/i128 cents and format on output.
I can’t find it now, but From the research I did last time I worked on this, there are only three small nations who do not use 100 cents to the dollar. Google aims to support everyone everywhere, so this makes sense. Or are they using space to store fractional cents? If you’re wanting to build a hobby application, it’s probably much easier to just use an i64/i128 cents and format on output.
fractional cents
&gt; About your last paragraph, are you perhaps suggesting that there would be a popular usecase for a version of rust (or similar) where a tracing runtime garbage heap collector could be active optionally as a global pointer type? I was really just mentioning that this is something *other* languages do, and since Rust often chooses to be explicit rather than implicit I don't think it would be a good fit. We already have plenty of often unpredictable performance pitfalls, so adding more isn't going to help a language meant to compete with C++ in performance and reliability. I'm also a bit skeptical about this since Rust has been doing mostly fine without first-class GC support so far, and the only compelling use case *right now* is integration with GC-based runtimes like Lua, JavaScript and Python. What could happen with an optional built-in GC is that this ends up causing an ecosystem split similar to what happened with D, where the GC is also optional AFAIK. &gt; i'm pretty sure Rust won't give up it's many pointer types for a generic one that requires a runtime and heap allocation, no matter how much it simplifies code and makes new people easily grok the program. Yes, this is true. I understand the desire for this, but this sounds more like a teaching problem rather than anything else. Adding a first-class GC to Rust would be a huge amount of work (just think about how the RFC discussion would look, and then there's still the entire implementation). Writing a competitive GC is extremely difficult by itself already, and there's just no resources to do this, and I doubt there will be any in the future. Add to this the risk of ecosystem fragmentation, and the weird spot it would put Rust in as a language (it's now somewhat closer to a more difficult version of Go, with no real gain over it??).
TBF, i expect the 'go successor' will be nearer rust, so something like this may happen in google land. To be specific i expect they'll reimplement cargo, whatever they need of borrowing to be competitive when the GC is not desired, Result/Option/match instead of go error codes, and Deref.
Yeah that's a good point (even though indexing an array is a built-in operation, not an actual `IndexMut` impl), a better example would perhaps be to put the mutation in an `if` that happens to never be executed (but the compiler can't prove that).
It’s the infamous zero vs null. Hard to represent in Rust. “I don’t have anything to put here” and “I’ve explicitly put nothing here” are different logical ideas.
No problem! The other way you can solve this problem is to resolve the conditional lazily, rather than before your return value: lazy_format!("{}", if is_any_version(&amp;from_major) { lazy_format!("") } else if is_any_version(&amp;from_minor) { lazy_format!("{}{}.0.0", Operator::Gte, from_major) } else if is_any_version(&amp;from_patch) { lazy_format!("{}{}.{}.0", Operator::Gte, from_major, from_minor) } else { lazy_format!("{}{}", Operator::Gte, from) } } `lazy_format` captures its arguments completely lazily, so it won't even evaluate the `if` until it's rendered. This seems like it might be a common use case, so I'll see about creating an additional macro in `1.4` that handles conditional formatting in `if` or `match` conditionals.
[AVX-512 has some 13 different implementations parts](https://en.wikichip.org/wiki/x86/avx-512#Implementation) &gt; Intel hasn't released it Not all of it is fully documented. **AND** Not all of it is in silicon. There is _more_ documented then sets released in chips. &gt; LLVM doesn't support it Supports what has been documented. &gt; Rustc doesn't support the full spectrum of AVX-512 Supports in nightly what the LLVM does.
I've always dreamed about writing one, but it's a massive task and there is lots of research to do. It doesn't have to be widget/container based, you could use simple base components and derive magic to make containers out of structs. Also events should be handled via async/await instead of callbacks.
&gt; Rust uses the Hindley-Milner type system It's more accurate to say that Rust uses a variant of the bidirectional type system with regions and region subtyping. Bidi is similar to HM, but requires one to write types for things like functions.
I mean, you picked an unstable pre-1.0 and nightly only framework to develop on buddy. Things will break occasionally. Although, yes, getting cargo to work with forked rocket (and diesel) is a pain because you also have to fork rocket_contrib. At least I had to with the uuid v0.7 break.
Unstable and unmaintained are two different things. I can deal with breaking changes, but right now the current version is defunct and upstream is unresponsive. If this is an issue of maintainer capacity it would be a good idea to look for additional maintainers.
This looks nice! One thing I noticed is that the color codes are still emitted when stderr is redirected to a file, whereas something like `env_logger` will detect this and skip colors.
Is the project public? I couldn't find the git repository.
Someone once asked something similar on the rust discord. I think they eventually went with a solution involving threads and channels. The basic flow for that would be: Spawn a child thread which spawns the external process -&gt; the child thread puts the process' output in the sender half of a channel -&gt; the main thread eventually does `try_recv` on the receiver half of the channel, either getting the process output if the child thread has sent it by that time, or a `TryRecvError` if not.
This is exactly the block of code I was looking for. Thanks!
I managed to compile a C library to wasm32-unknown-unknown with the cc crate by setting the compiler, archiver and some flags. However, I cannot conditionally compile for 'normal' builds and wasm in my build script. Putting `#[cfg(all(target_arch = "wasm32", not(target_os = "emscripten")))]` above my set_flags() function makes it invisible to the compiler when I compile to wasm32-unknown-unknown.
Why times 10^9? Is this to get some kind of nano-cent precision? If so, wouldn’t this introduce similar precision-based errors to what floating point numbers have to contend with?
Still Rusting at work, started to delve into code generation which enabled me to define the bulk of an in-house network protocol via CSV files and have the rest generated by build.rs ... I love it.
So did you figure out what happened? Any write-up anywhere on how things were fixed?
That sounds promising, I will give it a try tomorrow morning. Thanks!
Just starting out with the game! Not interested in mega-bases, just working on getting a little nondescript base going so we can go mess with people and take their shit without having too much to lose haha
No, but yours doesn't have a phallic hieroglyph - which is totally necessary btw, try changing the hieroglyph to something else and see the pattern change.
You need it on Crates.io in order to PUBLISH, but not to solve the issue? Am I understanding that right?
Sound code for my game and/or work on a `gba-hal` crate.
If the external process runs indefinitely, the child thread will never get cleaned up.
(Someone please correct me if I screw this up.) Crates are local to your Rust project. This means that you'll need to start a Rust project first. You can do this by running "cargo new project\_name" in the terminal. This will create your project's directory with a few files in it, one of which is Cargo.toml. Inside Cargo.toml, you specify external Crates you'd like your project to make use of. Once you've specified them, you'd have to run "cargo build" in the terminal after you have cd'd into your project's directory. This will download the crates and make them available to your project.
tokio_process would be my guess
Yea, as said, I will have to take more time to get my understanding for Tokio going.
I can guarantee that the process will exit, but I can't that it won't crash or get killed. Then the thread stays blocked as well, right?
Feel free to join the project and provide feedback.
I'm sold!
Still using Piston? How is it working out for you in practice?
Rust is such a huge language, and there are so many different levels of “I know Rust”. They range from a basic understanding of Cargo and how to write different control flow structures, to knowing how to use lifetimes and traits and smart pointers, to a thorough understanding of the nomicon to “I am on the compiler team”. At what level is someone qualified to be a mentor on Exercism?
The talk by Alex about procedural macros is really great. An excellent introduction to the topic. I really like the way Alex gives presentations: you can feel the motivation, but it's still very grounded. So thanks for the talk! &amp;#x200B; In any case, I agree that proc macros are friggin great. There is so much potential, that I'm sure the Rust community will leverage over time.
I've been working on a game that simulates cars, pedestrians, bikes, and buses in an OpenStreetMap-derived version of Seattle. The [link above](https://github.com/dabreegster/abstreet/blob/master/docs/articles/rust/article.md) talks about some pieces of the code that might be interesting to folks here -- particularly a more usable test runner and an immediate-mode GUI library. [This page](https://github.com/dabreegster/abstreet/blob/master/docs/articles/features/article.md) has more details and screenshots of the game itself. I'd be happy to discuss any part of the project, and if you try out the game, hear any feedback on it. Don't expect any playability yet, just a pretty map with some moving things. :) (Note: This project is unrelated to [Citybound](https://github.com/citybound/citybound), which I'm very excited to try out.)
Can't the "listener" thread be responsible for doing that killing / restarting? Then it would just shovel output from whatever child process it is currently waiting on into the channel.
I always found this advice weird. I need to manage money all the time (doing business apps) and use decimals everywhere. Why? Because I need to do calculations! One very simple: Add a tax. Then just computing the total and you get cents everywhere... P..D: With decimal you get some control on rounding, and the match check as far as I know. Exist a real superiority of using cents as integer (in the face of calculations) that I have missed?
floating point precision depends on how many digits are to the left of the decimal. hence floating. this has fixed precision.
You've gotten some reasonable advice in this thread, so I just want to offer some words of encouragement. When it comes to async/concurrent programming in Rust, things are in flux. The good stuff isn't yet part of stable Rust, and everything is moving fast. When you go to learn the mio/tokio/futures bit you'll end up trying to jam several complicated crates into your head at once, and it'll take a bit! Don't worry, you're right, this is all a bit tricky. tldr: Here be dragons. Don't feel bad if it takes some time.
You've gotten some reasonable advice in this thread, so I just want to offer some words of encouragement. When it comes to async/concurrent programming in Rust, things are in flux. The good stuff isn't yet part of stable Rust, and everything is moving fast. When you go to learn the mio/tokio/futures bit you'll end up trying to jam several complicated crates into your head at once, and it'll take a bit! Don't worry, you're right, this is all a bit tricky. tldr: Here be dragons. Don't feel bad if it takes some time.
floating point numbers are terrible for big amounts of money because above X bits of integer value (depending on if it's f32 or f64) they just round away the small parts of the number entirely. So a sufficiently large number of dollars + one dollar = the same number you started with. On the other hand, fixed point values allow fractional values at a pre-selected amount of precision, so you know clearly when the number will overflow, and adding a big and a small number won't ever cause loss of data.
I asked this question a while back, and got response from some of the authors of the decimal crates so it should be of interest: https://www.reddit.com/r/rust/comments/a7frqj/have_anyone_reviewed_any_of_the_decimal_crates/ Personally I have used https://github.com/akubera/bigdecimal-rs for both decimals and money since it's variable sized, but I think rust_decimal is a very good alternative as well if you want fixed size decimals.
Shrinkwrap looks like it would be useful for me, but I was under the impression that Deref polymorphism was an antipattern.
I think it is somewhat rare to see cents stored as integer. I have seen systems where the amount is stored as integer(generally 64 bit). But that is done to for performance. Note that in recent processors double and int would perform similar, while decimal would be orders of magnitude slower. When performance is not critical, decimal is the choice for dealing with money. It is very common to store more than 2 digits for cents and this is not fixed even per currency. Which makes storing it as an int troublesome.
For future reference, [here's an example (with explanations!)](https://gist.github.com/Technius/43977937a28e8846d917b53605e32cc3) of how you could do this with tokio and tokio-process.
Why Direct2D which is Windows only over something like Skia?
They are. All of those things you just mentioned are going to be part of the base library. Layouts are coming in 0.3.x, as are the drop downs and such. I am going to go with a universal approach and create an in-application menu bar that stays in the top of each window for access to the application menu. This way, there's no requirement to make it platform-specific. It all works the same way regardless of platform.
Right now, I'm finding that it does everything that I need. I am going to be splitting out the drawing routines into their own separate `Trait`, which should make it easier for me to drop in a replacement library as I get time. The only disappointing thing is that it's using a solid 50-55% CPU 100% of the time, and I need to find out ways to mitigate that usage. I know it's in the drawing routines, which is why I'm making the push for drawing to 3D objects, and blitting only on change. I'll be working on that for the next 0.2.x release, and the drawing routines separately after that point.
I would suggest the opposite, if you are building a hobby project then just use decimals. Unless of course if you only want to deal with google APIs then using ints would make it easier.
yes, Fractional cents are very common in finance.
I believe decimal is a wrapper around a popular c lib. C lib I believe is quite solid, so in my opinion it should be good to use. Not updated for long time might me also mean that the crate is very stable. Things too look for is, are there open issues/PRs without comments for long time. Like others mentioned there are other alternatives as well.
I don't know how merde is pronounced but I always said it like turd
Please just write a descriptive enum and stop relying on vague types
To clarify something I see in this blog post, this is not valid Rust syntax ([even though it's written like that in the documentation](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html)): pub trait IntoIterator where &lt;Self::IntoIter as Iterator&gt;::Item == Self::Item, { type Item; type IntoIter: Iterator; } This is the error that produces: error: equality constraints are not yet supported in where clauses (see #20041) --&gt; src/lib.rs:3:5 | 3 | &lt;Self::IntoIter as Iterator&gt;::Item == Self::Item, | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The way it's written in source is like this: pub trait IntoIterator { type Item; type IntoIter: Iterator&lt;Item=Self::Item&gt;; }
Can u post the error message? Try to install wasm-pack.
Never mind, upgrading my Rust and resintalling wasm-pack solved the problem
Mentors aren't assigned users of the site or even submissions, they can browse all exercises of that language track and read the submissions before deciding which one to give feedback on. The exercises range from very easy to very hard, so if someone only feels comfortable giving feedback on easy exercises, that's totally fine. The easy exercises have the most submissions anyway. Being able to explain things clearly is far more important than mastering the language. I hope that answers your question!
The reason that binary floats for currency are bad is *not* because precision-based errors exist, it's because accounting practices (and laws, probably) are designed to handle precision errors in base 10, not in base 2. If you store your currency in a decimal-friendly way, you can handle rounding errors in a way that accountants find familiar and comfortable, instead of weird and jarring.
So, couple things it could be: First, and I believe you’ve said this already, but you’ve saved the file, correct? Second, make sure your terminal is pointed at the correct directory. Check the portion of the terminal right before cursor. By default, cargo new creates a main.rs with the Hello, world! Printout. So make sure that the main.rs that you’re editing in your editor is in the directory you’re running cargo run in.
I really enjoyed the talk Without Boats gave on async. I know it must have been suboptimal to have a cold while trying to give it, but it was a great walkthrough.
I use libc::fork, libc::socketpair, libc::fcntl to set them nonblocking and wrap them in a UnixStream. Then you can use mio EventedFd for async polling.
I still have no idea what y'all are talking about. Why is it hard to represent in rust? Why can't you just make an enum that works that way?
Skia is a large non Rust codebase and the authors seem to be aiming for pure Rust. I say this as they mention they transitioned to a Rust flexbox implemention.
I've been watching this project since it's released under google's github. It's awesome and happy to see it evolved this much. Good work
You can. But then you and your dependencies have to use the same one. He gave a code example on how the current pattern is to nest options and that seems silly. Not arguing in favor of this being a thing, simply restating his point.
&gt; But then you and your dependencies have to use the same one. Why? I feel like I'm in crazy world. None of what y'all are saying matches up with my experience of reality.
Hi, I'm the maintainer of rust-openvr. At a glance, it looks to me like you've got basically the right idea, but you're confusing the notions of \*camera transform\* with the \*view transform\*. &amp;#x200B; The HMD-to-absolute pose transforms head-relative positions to tracking-space relative positions, and the eye-to-head pose transforms eye-relative positions to head-relative positions. Transforming a vector with a matrix looks like \`M \* v = v'\`, so we know \`hmd \* (eye \* position\_relative\_to\_eye) = position\_relative\_to\_tracking\_space\`. In other words, \`hmd \* eye\` is the matrix that transforms from eye-relative space to tracking space. This can be considered the camera transform for the eye in question. Note that \`eye \* hmd\`, the matrix you're using, doesn't make sense, because it confuses unrelated spaces. &amp;#x200B; To actually render graphics, however, you want the inverse: to compute the camera-relative coordinates of a tracking-space position. In other words, you want \`(eye \* hmd).inverse()\`. This is what's usually referred to as the view transform, contrary to your example.
The allocation could be avoided but still work on `char`s instead of `u8`s by using [reservoir sampling](https://en.wikipedia.org/wiki/Reservoir_sampling). If I were to write a "falsehoods programmers believe about randomness", "you have to know the length of a sequence beforehand to pick an (or `k`) elements from it uniformly" would have to be on the list. It looks like `rand` must provide reservoir sampling in the form of [seq::IteratorRandom](https://docs.rs/rand/0.6.5/rand/seq/trait.IteratorRandom.html), though, so you're in luck! Just use that operating on `str::chars()` iterator.
Wow this is really impressive! Nice work!
Is this also the case for `Box&lt;T&gt;`? I wonder if the `Pin` API has any possible implications for this..
Working on my implementation of the Minecraft Beta 1.7.3 terrain generator. For the purposes of debugging changes I make to the terrain generation, I decided to make some fast mapping tools based on the worldgen code. I got a tad bit carried away with the optimization though ... it's now a multithreaded mapping tool that uses the power of Rust to generate images like [this](https://imgur.com/a/thJscMN) in only 36 seconds (i7-4790 4C8T).
Then it should be seer-dee.
Wouldn't it just be easier to have a u64 for the number of cents \*10\^9?
Why is it a double deref?
When I try compiling for webasm, I get an error “rust-lld not found”. What should I do?
When I try compiling for webasm, I get an error “rust-lld not found”. What should I do?
Sorry, duper. Ignore please.
The more you know
It does, and that makes a lot of sense. I was holding off on being a Rust mentor until I felt more comfortable with the advanced parts of the language, but I think I’ll sign up and give advice on the easy questions, like you suggest.
Hell yeah dude. That makes perfect sense. I just had a hard time figuring out what each function actually returned.
Are the Rust Meetups from earlier (October 2018/ April 2019) in Denver being released (were these recorded?) I know someone was able to create a RUST toolchain / compiler etc, for the Nintendo 64 to create games with.
The best alternative, for this particular problem, would be to find somebody to help sponsor the development of the solution for https://github.com/briansmith/ring/issues/535. Then you could use the new version of *ring* and let Rocket use the old version of *ring* in the same program.
Realistically, adding more maintainers to one's project is one of the most time-consuming thing the original maintainer can do, unless they just don't care about the project at all anymore. It takes a lot of time to create a governance structure and to coordinate with other people.
https://projecteuler.net/ is open for every language.
You really can't get around the fact that you are going to lose data on certain operations with either representation. E.g. Fixed point will lose precision on operations on very small numbers that floating point would better preserve. For an illustrative example, a 0.1% annual interest rate is equivalent to a 3.17e-11 second-ly interest rate. A fixed point representation would need more than 38 bits in the fractional component to represent that value as anything besides 0, which would leave only ~25 bits left of a 64 bit representation left to the integer component, which can only represent ~33 million. Both of the floating point decimal math crates mentioned in this thread use 128-bit representations and wouldn't have an issue with this and would also handle basically every money-related math problem just fine. If you think about it, a floating point number is just a fixed point number where the ratio between integer and fractional precision is dynamic. So if all your calculations and intermediate values are around the same magnitude that you can know ahead of time, then you can pick a fixed point representation that will be more optimal than a floating point representation. However, if you don't know the magnitude, or your calculations are in multiple magnitudes, you were probably better off with the floating point.
SQL was originally SEQUEL (Structured English Query Language) and some people still pronounce it like that, so in a way you're not far off
Working on my Game project "Space Factory" - porting it to use the [Specs ECS](https://github.com/slide-rs/specs). Also beginning work on a simple UDP implementation based on [Reliable Ordered Messages](https://gafferongames.com/post/reliable_ordered_messages/). [Serde](https://github.com/serde-rs/serde) was a wonderful place to get started with serialization (using Bincode). Also finishing up [4k1w](https://fourkingsonewar.com) "AI" work. I LOVE rust Enums with (for instance) message data structs in the body. Thanks to all the compiler teams and library authors for such a beautiful language and environment!
Great!
The killing/restarting is independent of in/output of the process though. For reference I am writing a testing framework for chess engines and the engines have to obey Time Control. If they don't(they don't answer) , they get killed.
Similarly, Advent of Code is entirely language-agnostic.
C# -&gt; see pound
but how do you represent a third of a penny in base 10 :S
`Self` is `&amp;T`, and the method takes `&amp;self`, so the type of self is `&amp;&amp;T`. Therefore `**self` is the owned value. `*self` is the reference type `&amp;T`, so calling `(*self).hash(state)` would be infinite recursion.
Working on porting python browsercookie library into rust so that I can use it with my current rust tooling. https://github.com/tunnelshade/browsercookie-rs (Currently, supports Firefox on Linux/OSX). Windows should be easy to add, next up is Chrome support.
Wait... Should I not be saying "see-quil"? Is everything I know a lie?
Check out this series: https://blog.1aim.com/post/004-mail-3-example/.
Not at all. I never mentioned queues and they are not part of the pattern. I mean, in some cases, queues could be the best API for it, but it's not the point here.
The current code generates something like this: fn get(parameters: Vec&lt;impl std::fmt::Display&gt;) -&gt; Result&lt;Box&lt;Self&gt;, Box&lt;std::error::Error&gt;&gt; { let request_path = format!("https://foo.bar/{}/baz?id={}", parameters[0], parameters[1]);
You could separate front- and backend by using, as example TCP-Ports. Yes, that requires more logic in both parts. But you would be complete independent regardless of the language and you don't need to worry about bindings or any other fancy stuff. Just implement a tcp server on one, and a tcp client on the other side. Now both parts can communicate (relatively) easy. So you can write front- and backend in any languange you like. &amp;#x200B; I don't know if this would be a "better" way, or even if it is a good way. Maybe it's complete off the track. It's just an idea to get rid of the need of a special binding.
Yeah, it's not really a good idea. You need a dynamic formatter to accept unlimited arguments. But you can still use IntoIterator and do let iter = parameters.into_iter(); let path = format!("{} {}", iter.next().unwrap(), iter.next().unwrap());
This. This pattern is just follow good modularization and expanding to use eventually something like full on Command-Query Responsibility Segregation. Company I work with does modularization of common things into a core domain in our project, larger things are libraries. All things implemented with CQRS for ease of modification. A nuclear reactor is built like good software. You segregate components into proper domains of the application (DDD) and setup your message passing for integration. Actor model, queues or other methods work fine. The goal is to separate concerns and keep related things still workable.
Additional options: [https://leetcode.com/](https://leetcode.com/) [https://www.codewars.com/](https://www.codewars.com/) [https://www.codingame.com](https://www.codingame.com)
If it's specific to Seattle they might appreciate it at /r/Seattle or /r/seattlebike
sadly, this is not possible, as I cannot determine how many times i have to repeat it this way. let request_path = format!(#path, #(parameters[#counter_vec]),*); the counter_vec is a vector that will be iterated and the return values are the indices. I don't know if I can count without using a variable like that.
hmmm.... i could try something like this: let count = path.matches("{}").count(); let mut counter_vec = Vec::new(); for _ in 0..count { counter_vec.push(quote!{ iter.next().unwrap() }); } --- let request_path = format!(#path, #(#counter_vec),*);
I use Exercism for class exercises — mostly great. The interface is actually nice once you get used to it. I've solved about 50 problems. Project Euler is awesome, but as mathy as the name implies. The challenges get esoteric pretty fast. I've solved about 70 problems in Haskell, none in Rust. I haven't tried Codewars yet. Advent of Code is quite fun. I solved to day 20 of this year, and all the previous years, one in Rust. Codingame is detailed well-written challenges. I've solved about 20 puzzles in a mixture of Rust and Haskell, competed poorly in one of the larger challenges. Haven't tried LeetCode yet.
You probably can by dynamically outputing the rust code, you can iterate over the iterator and output it as format arguments.
I have been using the *lettre* crate, and it works quite well for me: [https://github.com/lettre/lettre](https://github.com/lettre/lettre)
thanks for your input :)
It works ~anywhere with OpenStreetMap data, though Seattle has some extra GIS shapefiles that help determine where on-street parking exists. The demo is very rough right now; I'll publicize more widely once things are a bit more playable.
This is a bit lengthy, but anyhow. Three things this week: * Updated [https://crates.io/crates/thin_main_loop](thin_main_loop) to last version of futures-preview. I was hoping that an event loop crate for native GUIs would spawn some interest and that people wanted to either help out or build things on top of it, but so far nothing. Maybe when futures 0.3 and async/await become stable it will take off. * Improved the [synth example](https://github.com/diwic/alsa-rs/tree/master/synth-example) of the [alsa crate](https://crates.io/crates/alsa), mostly because I wanted to try it out on a Raspberry Pi. And now it works there but it's quite CPU hungry - I have a good guess of what it is but I'd like to do some profiling to be sure. As perf does not seem to be easily installable on raspbian, any recommendations for how to profile code there? * I'm continuing my long term effort to rewrite the server-side method dispatcher of the [dbus crate](https://crates.io/crates/dbus/). Given the requests I've got over the years I feel the the current design does not cut it. I made a breakthrough last week as I realized that with some clever generics I was able to make type safe method handlers, like this: struct Score(u16); let mut call_times = 0u32; cr.register::&lt;Score,_&gt;("com.example.dbusrs.crossroads.score") .method_iface("UpdateScore", ("change",), ("new_score", "call_times"), move |score, _, (change,): (u16,)| { score.0 += change; call_times += 1; Ok((score.0, call_times)) }); Given this example code, we can deduce that since the third parameter to the closure is a single `(u16,)` and the return value is a `(u16, u32)`, this will expose a method `UpdateScore(in UINT16 change, out UINT16 new_score, out UINT32 call_times)` on DBus. When called over DBus, glue code will be inserted that reads the arguments, check the types of them (and return an error to the caller if they are incorrect), and then call the closure. After the closure finishes successfully, a return message will be created and the return values appended.
Try this: https://docs.rs/lazy_format/1.4.0/lazy_format/macro.lazy_format.html#if-conditional-example
Isn't the requirement of types for functions something the devteam decided regardless of the type system not mandating it?
sorry but I'm pure atheist
I'd wager it's because skia is not rust and hard to build. That'd be a poor dependency for anyone wanting to adopt paw.
That's what -Werror is there for. I doubt the compiler will not have any false negatives so it can't be anything but warnings.
Wait. Wait! Are you… are you saying there’s no such thing as Santa Claus?!?
Also, am I correct to fix up the 3x4 matrices in the do so that they are 4x4?
I Agree, was the first video I watched. It was nice to get be able to put a face to that boats guy that shows up whenever async await is discussed :-)
I like Exercism, but the mentoring mode just doesn't work. It took 7 days to get feedback on one of my submissions recently, on the Haskell track, and so I switched to free mode.
You can use https://github.com/rust-dev-tools/rust-semverver/blob/master/README.md to make sure you introduce no breaking changes
Writing a gpu accelerated 2d renderer in Rust is gonna be pretty hard.
Should I idę VS Code, Eclipse (Corrosion) or IntelliJ with Rust extension? Which is best and why?
Hacker rank used to support rust, IIRC, the last time I tried it, they were using 1.16 when 1.21 was already released. I had also sent them an email requesting them to update rust compiler but I guess they removed it altogether. :( On the other hand, I also sent couple of emails to leetcode asking them to add rust and they did! Which is awesome! :)
About your \`pair\` function, you could have used \`Result::and\_then\`: the function would have been less verbose.
Shouldn't `BtAddr` implement `Copy` like `IpAddr` does? Anyway, awesome crate!
Even one billion dollars won't fit this format.
Would be nice for `discover_devices` to return iterator rather than Vec so that user could decided whether he wants to store all addresses or just look up particular one
That's the most interesting discussion of Rust's design I've read so far!
Kattis has support for Rust also: [https://open.kattis.com/help/rust](https://open.kattis.com/help/rust)
If you need that to be absolutely correct you would want to create few levels of safety here. First use newtypes. `RealMoney` type that represents real money on account should be impossible to create out of thin air without unsafe code. `Add&lt;RealMoney&gt; for RealMoney` should always destroy original objects. Also you may want to split `RealMoney` into two. Beware of leaks though :) `Money` type that represents imaginary money for the purpose of calculation should use either fixed point 128 bit representation, or rational type so you could divide by any rational value without precision errors. Also you may add approximation flag to mark values that were rounded during computation.
Try getting in contact with the organizers directly. I don't know if they record their talks.
For little projects you will be fine with VS Code (and build from CLI), for more ambitious projects, you should check Intellij with Rust extension, it is getting better and better with each update. If you choose Clion you can even do profiling inside the IDE.
The talk on WebAssembly was great too. Thanks, u/autodidaddict !
perfect! @BitgateMobile, looking forward to 03.x :)
There already is [webrender](https://github.com/servo/webrender), which has been used for GUI toolkits like [azul](https://github.com/maps4print/azul) in the past
Not quite a "challenge" site, and the contents are all in Japanese, but an old service I worked on called [CodePrep](https://codeprep.jp/books/category/Rust) has a few Rust books. They may be outdated by now though.
Hey y'all, this is the 5th episode of Full Stack Fest's own podcast. In it I interviewed Lin Clark and Till Schneidereit about how WebAssembly and WASI can be a game changer at some many levels. Enjoy!
Working on adding more crate alternative suggestions to the command-line tool chit. [https://github.com/peterheesterman/chit/blob/master/alternatives.json](https://github.com/peterheesterman/chit/blob/master/alternatives.json)
Last time I solved challenges on hackerrank it supported rust 1.29. Also I asked them to add rand crate into their env. So if nothing changed they support rust. But I'm not sure whether you can use it in every challenge.
My only problem with this post is the fact that bulgur is decidedly not pasta smh
I've also been happy with exercism! I especially like looking at other people's solutions after making my own, to find more rusty ways of doing things
As is CodeAbbey.com
You don't have to. Just use `CHARSET[idx]`instead.
It's not ugly. Randomness is hard. Btw, if you only want Alphanumeric, checkout [rand::distributions::Alphanumeric](https://docs.rs/rand/0.6.5/rand/distributions/struct.Alphanumeric.html).
i believe in the [where clause](https://doc.rust-lang.org/rust-by-example/generics/where.html)
If you are looking for competitions you can do in Rust, both Google Code Jam and Google Kick Start allow it (but I don't remember if Google Hashcode allows it...)
Thanks, it works! However now I am at a loss on how to write something to the process' stdout. I made a FramedWrite the same way you constructed the FramedReader, but I can't seem to get the Future to do what I want.
No one mention about [codeforces.com](https://codeforces.com) ?
Your problem is a little vague but from experience here are some things that i remember being stuck on. Futures need to be handled by the runtime, either through directly spawning them , or combining them with another future into a tree and spawning the top future. There are multiple ways to use the FramedWrite, the simplest is to create a mpsc (from the future crate) and do a send_all. ( and make sure to spawn this future in the runtime )
Rust still works in the Algorithms section, with a currently installed version of 1.32. It's just not active in every track where it could be used, and there is no template for it, but other than that It should work fine on Hackerrank.
Not yet! I'm still trying around a lot and didn't want to publish it so far. ^((throwing it onto github usually ends up that the project moves to the bottom of my priority list which I try to avoid this time..))
At the time I evaluated it the last time there were no proper bindings for skia (c++). [https://github.com/rust-skia](https://github.com/rust-skia) seems to have gained some traction in the meantime, which is great and would be worth considering. Initially I went with piet but after I managed to couple it with winit, I experienced some crashes with the d2d backend, so I just moved towards bare d2d. I gained some experience with handling COM due to gfx-hal so that was quite straightforward. My requirements on the rendering backend: \- supports most of the features of a 2d library (paths, clipping shapes, gradients, text, ..) \- ideally hardware accelerated, lightweight (&lt;1-2ms GPU and CPU for basic applications, layout w/ stretch &lt;100us btw!) \- easy to use API My current opinion on the different options: \- d2d: easy to integrate, API okay-ish, windows-only but hardware accelerated (!) \- webrender: would be my favorite, still early stage afaik, lacks some features (paths, gradients, ..) \- skia: cross-platform, simple API (?) and hardware support (?), annoying to build/integrate, Rust bindings? \- piet: promising, simple API, early stage (?) &amp;#x200B; I will see how things evolve, do more benchmarking and try to keep track of the ecosystem.
Why another library when there is serde which seems to be the go to library for serialization/deserislization?
This is an experiment I started with an objective of un-compromised out-of-the-box performance. Currently, this gives 10x better performance as compared to bincode (goto crate for binary serialization using serde). You can see benchmarks for more details.
Hi, I start to understand less and less :D. Let me state what I think I understand. A future describes a task to be executed in the future. The task can be done `tokio:run()` or `runtime::block_on()`. How I obtain the futures I want seems like the problem to me. I want to be able to write something to the subprocess' stdin. I don't know how to get a future that writes any arbitrary String to the Chid's stdin. I want to be able to process the subprocess' stdout. The subprocess has a given timeframe, in which it has to write a line which starts with specific String. It can however, in this timeframe write other lines to it's stdout, which should get ignored. The future u/Technius provided me with doesn't do that, as far as I have tested. Let's say the keyword is `world.` My subprocess sends it's first line `hello`, which the future reads and checks with `line.starts_with("world")`. Since it doesn't the future returns `None`, but it should rather wait for the next line the subprocess sends.
The build script is compiled for and run on your machine, which is why making the function conditionally-compiled for only wasm causes errors; build.rs is compiled for target `your_arch-your_vendor-your_os`, which isn't wasm, so the function is skipped. You can get the target your crate is being compiled for from [the `TARGET` environment variable](https://doc.rust-lang.org/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-build-scripts). // build.rs let target = std::env::var("TARGET").unwrap(); if target.startswith("wasm32-") { // Implementing target_os != "emscripten" is left as an exercise to the reader set_flags(); }
[rustlings](https://github.com/rust-lang/rustlings) &gt; Greetings and welcome to rustlings. This project contains small exercises to get you used to reading and writing Rust code. This includes reading and responding to compiler messages!
&gt; Hi, I start to understand less and less :D. Future's and their runtime are one of those things that require a lot of background knowledge before you understand the problem and how they solve it. For the part dealing with your processes reading stdout it looks like you want to take your future and [filter](https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.filter) ( and maybe `fold`, but I can't tell ) and wrap that resulting future in a [timeout](https://tokio-rs.github.io/tokio-timer/tokio_timer/struct.Timer.html)
In case somebody else didn't know how to listen to the podcast, clicking wildly on the photo and various other elements on the website: &amp;#x200B; At the very bottom of the linked episode's page, there should be a bar on which you can click “play”. &amp;#x200B; I wonder if I am getting old...
Not any harder than writing a 3D renderer in Rust which is only as hard as using Vulkan or OpenGL typically. Of course there's a lot of 2D specific stuff like font rendering to reimplement which is why I suppose the authors are going for the Direct API's while the graphics API's for Rust mature.
there seems to be sporadic use of rust at hackerrank.
i couldn't make sense of their interface.
Yes. `Box&lt;T&gt;` and `Pin&lt;T&gt;` both forward `Hash` to `T`: * https://doc.rust-lang.org/1.34.0/src/alloc/boxed.rs.html#410-414 * https://doc.rust-lang.org/1.34.0/src/core/pin.rs.html#285 (These are `[src]` links from https://doc.rust-lang.org/1.34.0/std/hash/trait.Hash.html#implementors.)
That's pretty awesome, congrats! I like the readme too, it does a good job at explaining what this is and what it may be used for.
I ended up getting quite decent results out of the f3's onboard DAC: https://github.com/antoinevg/stm32f3-rust-examples/blob/master/src/stm32f3-02-dma.rs :-)
Sadly not the first time. I think just about every dependency-related pain I've had with Rust so far has been with Rocket and/or ring breaking or causing conflicts. I hope they're working to figure out a way to prevent this issue in the future, as Rocket otherwise seems to be one of the cleanest and most elegant Rust web frameworks.
Thanks for the `#![no_std]` support, this might be very interesting for embedded
Thank you very much!
What's the date and why is that information not on the page linked?
Because it's not yet fixed. We're working on that part and hope to have some final information soon.
Usually people spitball an idea in internal threads or issues in the RFC repo. Once an RFC is open, if the author does nothing, closing it requires a significant amount of work: picking an appropriate team, getting the RFC assigned to somebody in the team, that person needs to work through the RFC, understand it (which might be hard if the RFC does not make any sense), write a closing comment proposing to close it (which type of closing? postpone, never, ...), then the whole team needs to sign-off it, which ideally requires every team member reading and working through the RFC, ...
codesignal.com
Ring isn't nightly-only (although it is pre-1.0), and the vast majority of (possibly all) issues I've had in the past with Rocket have been caused by Ring or its dependencies rather than Rocket itself. I suspect the real issue isn't even really them, but rather the fact that they are depended on my a number of commonly used crates and break if different crates require different versions of them in the same build - likely due to non-Rust code being linked. I can only imagine that this is a maintenance nightmare for both Ring and any crates that depend on it whether directly or indirectly. (such as Rocket)
How much did tickets cost in past years? Will it be more than €100?
Did you compare the outputs of your program with the actual Fibonacci numbers? When I compare them, it becomes pretty obvious that the implementation is not correct. This part in particular is wrong: `for element in 2..n - 2 {` `fibonacci_sum += element;` `}` Here is the Wikipedia definition: `F0=0` `F1=1` `Fn = Fn-1 + Fn-2` Ignoring the difference in start index between your version (I'm going to stick to starting at F0) and wikipedia, you get F3=1 while the actual result is F3=2 `F3 = F2 + F1` `F2 = F1 + F0` `F3 = F1 + F0 + F1` `F3 = 1 + 0 + 1 = 2`
If that were the case, then lifetime analysis would need to be interprocedural, which is not the case.
&gt; double pointers Don't we usually call these "fat pointers"? Or have we changed the name?
How gnarly are the error messages when I screw up?
&gt;The algorithm itself slightly refines an obscure problem in circuit switching, so it is quite useless, but I wrote a paper on it anyway. The best kind of science
Pretty informative actually. The implementation turned out to be near-trivial, and i added a trick to make sure that if you pass in something that isn't iterable, it throws an informative type error.
If you use a tuple instead of an array, you avoid this issue.
You actual implementation of the problem and the binary with the user input are two different things. Write you lib with unit tests to verify its correctness, and then, you can create the user input.
Someone also wrote a cargo plugin to automatically download, run, and submit answers for AoC too: https://github.com/gobanos/cargo-aoc
Sounds like Niko is groping towards rediscovering something like [Six Thinking Hats](https://en.wikipedia.org/wiki/Six_Thinking_Hats), with a side of the early wiki theory around [thread mode vs document mode](http://wiki.c2.com/?ConvertThreadModeToDocumentMode). Which is cool.
Thanks. Will change that for the next version.
You are right, thanks. Added to the list of changes for the next version!
We're aiming for a similar ticket price.
I have been enjoying exercism as well. It has you write tests using crates setup to be a library instead of a binary, which is different from the Rust book. Other than that it's pretty simple to get started.
command to update: rustup update
Nice, actually I worked on one too but with dynamic sized types, will try to benchmark against yours and update I found serde to be too restricted for binary types so I made one
Really love the format of this article. The register definition expandos are super cool and definitely something i'm gonna steal
Awesome. I have “support for dynamically allocated types” in development roadmap for this crate. I can probably take inspiration from your code on how to go about it. Have you open-sourced your code?
I can still hear the old, electromechanical Strowger switches my dad maintained in the local telephone office. I think that was a generation prior to crossbar switches, though. Still, your crate brought back memories.
Indeed -- I created an issue for this: [https://github.com/athre0z/color-backtrace/issues/6](https://github.com/athre0z/color-backtrace/issues/6)
\`rust\_decimal\` seems better, looking at the documentation.
Man the title had me but the content not so much. Buddy I think you want to post this over at /r/playrust as this is the subreddit for a programming language called Rust.
This is neat! I’m definitely gonna play around with this. Nice work!
Well, you could write your own frontend that generates MIR, and then pass your MIR to the Rust compiler backend. Keep in mind that it's a moving target though, so you'll have to keep up with API changes. Also, &gt; which was dropped in order to attract the C++/C/Java oriented programmer segment Is not really true.
realised and posted on the other subreddit right after
Haha, you are ALMOST right, but it is about Rust programming language.
I made size a function and not a const variable and its part of the deserializer/serializer impl, and each type can define its size to be static or from a buffer, and I trust the optimizer to see when a type size is known at compile time. (I needed to add inline attr for it to work fast) I also made RefList which is a list that stores a reference to the buffer, thats creates the objects from buffer on demand so it wont need to allocate a Vec for it (but that restricts the type to the lifetime of the buffer) If a type without a lifetime is needed I made List to work with smallvec so if the list is small it does not allocate on the heap I'm planning to open source it but its still spaghetti and not clean
Thanks! :D Let me know if you run into any problems i didn't anticipate :)
More specific, it is `rustup self update`.
Posted here: https://www.reddit.com/r/rust/comments/bg5tdg/generic_returns_in_rust/
I agree with second part, but for first one you don't need to subject yourself to VSCode's Electron nightmare. Just check the list of other text editors that support LSP and use one of them: https://langserver.org/
Well, I hope you are aware of the digit length of the results... I mean what's the max possible unsigned value to be stored in **i32**?
Many thanks for your swift reply, and for correcting me regarding the motivation to change syntax. I guess the main reason was of technical nature, then? &amp;#x200B; \&gt; Well, you could write your own frontend that generates MIR, and then pass your MIR to the Rust compiler backend. Keep in mind that it's a moving target though, so you'll have to keep up with API changes. It might be a dumb question, but why is translating to MIR a better approach than translating the hypthetic "*MLy|* syntax to *Rust* *syntax*? Thanks you, again.
I prefer this project to the other similar ones. It looks very clean.
&gt; I guess the main reason was of technical nature, then? It wasn't exactly "technical nature", it was a slow and incremental process of design that led to choosing a syntax that works better for the language. What it was __not__ though is some sort of a marketing ploy to "attract C++ programmers" or whatever. &gt; It might be a dumb question, but why is translating to MIR a better approach than translating the hypthetic "MLy| syntax to Rust syntax? Because MIR is easier to generate than Rust code, mostly.
Agreed
Thanks! :)
But what was the ticket price in previous years? I didn't attend last year's rustfest
Love this. Are there any plans to add MacOS support? I appreciate the MacOS BT is really different to Linux BT and it may not be worth while.
There are currently hundreds of Rust solutions in the review queue, and mentors aren't able to keep up with them. Hopefully the situation improves as more people sign up to mentor Rust submissions.
I've tried many of them, and I prefer Exercism for the following reasons: * you implement the solution offline, so you can use the IDE of your choice * all test cases are openly available so you don't have to guess at which edge case you aren't handling correctly, which is a common frustration with some of the other websites * they don't check your solution online, so you are free to use the language version of your choice and you can even add dependencies without any problems * all exercises of a language track are made specifically for that language, so the Rust exercises actually encourage you to write idiomatic Rust – there aren't dozens of exercises about linked lists, slices are used correctly in function signatures, you're sometimes asked to implement standard library traits, you get to return `None` instead of `-1`, etc * you can choose to receive free feedback on your solutions (though there currently aren't enough Rust mentors to keep up with all the submissions, so unfortunately it can take a while for them to get back to you)
You could customize an editor to not show the curly braces, and to insert them automatically based on indentation. Then you could work with rust code as if it did not have them.
Why are you using `Option::take` here?
Doesn't it "unwrap" the value, leaving either the struct, or None? Am I misunderstanding it?
No, that's not what it does. It's there to allow you to take a value "out" of the original `Option` - `let mut a = Some(foo); a.take()` will set `a` to `None` and return a new `Option` containing `Some(foo)`; `let mut a: Option&lt;X&gt; = None; a.take()` will leave `a` as `None` and return a new `Option&lt;X&gt;` containing `None`. This allows you to modify an `Option` in place without invaliding it. If you just want "give me the data or crash", use `Option::unwrap` directly, or (preferably) `Option::expect`, so you can crash with a meaningful error message.
Ok, great, thanks for clearing it up!
Mostly I'm trying to write up a design doc for [skribo](https://github.com/linebender/skribo) and see if I can recruit more people to work on it. This is the last week of my contract and I'm looking toward focusing on other things, about which more soon. I've been experimenting with [makepad](https://github.com/makepad/makepad) and am impressed - the performance, smoothness, and cross-platformness are all way ahead of other attempts at GUI I've seen, though things like text need more work. I'm curious how difficult it would be to integrate PathFinder 3 and am offering a $100 bounty for that.
I'm packing for my trip to Berlin for Oxidize conf. And I'm playing with an stm32 board (blue pill), trying to write an embedded MIDI driver on top of the excellent embedded-hal. So far progress is slow because my rust experience is ... eh... rusty and so is my embeded-fu
The wizard idea is pretty great
Please feel free to file issues with the crashes. It is early stage, and it's always tricky to depend on things that are not done, but it's a good way to get things to improve.
Yes, though I'd strongly recommend using a maintained linear algebra library rather than writing error-prone implementations of everything yourself. For example, here's a conversion function for nalgebra: pub fn vr_to_isometry(m: &amp;[[f32; 4]; 3]) -&gt; na::Isometry3&lt;f32&gt; { let translation = na::Translation3::new(m[0][3], m[1][3], m[2][3]); let rotation = na::UnitQuaternion::from_rotation_matrix( &amp;na::Rotation3::from_matrix_unchecked( na::Matrix3::new(m[0][0], m[0][1], m[0][2], m[1][0], m[1][1], m[1][2], m[2][0], m[2][1], m[2][2]))); na::Isometry3::from_parts(translation, rotation) } (conversion from matrix to quaternion is optional, you could also just return an \`IsometryMatrix3&lt;f32&gt;\`) You might also be interested in [my OpenXR bindings](https://crates.io/crates/openxr). OpenXR is presently only well supported on WMR devices, but is expected to supplant OpenVR and the various vendor-specific APIs later this year. It's a much better API, and will be maintained in favor of OpenVR going forwards.
That's not at all an obscure problem; congrats! I'll be sure to go through your paper and see how you treat the problem theoretically. Aferin!
I'm so excited! I definitely want to go!
This looks super nice. I noticed an issue that'd come up with non-Copy IntoIterators. I chucked you a PR.
No, Rust's type system is very much based in a world of local type inference with functions being the boundaries -- there is no global inference, which is a major feature that makes bidi distinct from HM. I wrote the following yesterday as an explanation to someone in a discord server, hopefully this helps (edited for format): HM is basically all about removing as many type annotations as possible, even if it means removing some type system power; bidi adds back some type annotations - it's between HM and something like C++'s completely directional type system - in order to allow more type system power while still getting rid of a bunch of unnecessary type annotations. Bidi type systems are common in modern languages like Idris and Rust, whereas older FP languages use HM type systems -- ML, Haskell, that kind. However, Haskell and OCaml _have_ generally extended HM to make it more powerful, and to require more annotations.
I looked at lettre\_email. It appears it is not able to do inline content dispositions, which is required for inline images to be displayed.
I've seen the following done in order to get a random variant of an enum using the `rand` crate: enum Foo { Bar, Baz, } impl Distribution&lt;Foo&gt; for Standard { fn sample&lt;R: Rng + ?Sized&gt;(&amp;self, rng: &amp;mut R) -&gt; Foo { match rng.gen_range(0, 2) { 0 =&gt; Foo::Bar, _ =&gt; Foo::Baz, } } } But I thought that you weren't allowed to implement external traits on external types? Isn't that exactly what this is doing?
As of \`rustup\` version 1.17.0, \`rustup update\` will issue a \`self update\` automatically after toolchains are updated (in fact any install sequence will too).
&gt; Then you can use mio EventedFd for async polling. You can already do that with regular stdin/stdout.
It was likely a cross-site attack, accessing cookies from other sites. We are moving image libraries to a new organization `image-rs` to reduce the attack surface.
 x\^-2 is the same as writing 1/x\^2. \`acc\` is initialized to 0.0 and \`fr\` is a value from the iterator. Each value to the power of -2 is added to \`acc\` and then the value from \`acc\` is returned. This can be also rewritten as a for-loop. &amp;#x200B; let mut acc = 0.0; for i in 1..600000000 { let fr = f64::from(i); // acc = acc + 1.0 / (fr \* fr); is the same as below acc = acc + fr.powi(-2); } acc
I'd love to add it, but as I don't currently own a Mac it's not trivial to develop for it. If I do manage to get a dev environment up and running I'll try though.
You can also enable lazy mode on the event loop to reduce CPU usage: https://docs.rs/pistoncore-event_loop/0.42.0/event_loop/trait.EventLoop.html#method.lazy
You're correct, they're referred to as fat pointers.
Thank you! Due credit to Dr. Yavuz Oruç for both helping me with the proof, and proofreading everything I wrote. He refused to have his name on the paper though, saying that I came up with the algorithm.
So glad to hear that!
Still waiting to be discovered by Gavin Belson for some ingenious usage of my algorithm
It also checks if type parameters are from the same crate. [Here](https://doc.rust-lang.org/nightly/reference/items/implementations.html#trait-implementation-coherence) are the specific rules.
Yeah but you don't always want to update your toolchains (nightly for example).
That looks nice, I was looking forward to be able to build mobile apps with rust. I don't understand what is free and susceptible to be charged in the future though.
Another one here asking for past ticket cost. It would be great to have an idea of the cost. If it is similar to Zurich, we will be screwed, salaries in Spain are far the lowest in Europe...
I'm not sure. I know that Spectre can be used to leak secrets between processes, but I don't know what the attacker needs to be able to control in one or both of those processes to make it work.
actix-web (and examples) won't build on stable on mac os, it requires nightly cargo feature \`rename-dependency\`. Specifically it fails when installing the \`hashbrown\` crate. From what i gather actix-web should work on stable, right? what's wrong?
Can you explain a bit what you're trying to do? Your title mentions auto(?) deriving `PartialEq`, `Eq`, etc when using `Rc` and `Box` but your code has neither `Rc` nor `Box`. Your sample code also mentions a bunch of things not present (`RValue`, `DataType`, etc) and it's not clear what you're trying to derive `PartialEq` on.
To solve the ownership issue you could pass a reference to an array of stacks into the init function, and have a callback where you create the threads, for example fn main() { let mut stack1 = [0xDEADBEEFu32; 128]; let mut stack2 = [0xDEADBEEFu32; 128]; let mut stacks = [&amp;mut stack1, &amp;mut stack2]; init(&amp;mut stacks, |ctx| { ctx.create_thread(|| { loop { // Do stuff thread A } }); ctx.create_thread(|| { loop { // Do stuff thread B } }) }) } fn init&lt;F&gt;(stacks: &amp;mut[&amp;mut [u32]], init_fn: F) where F: FnOnce(&amp;mut Context) { // Call init_fn with Context to create threads. loop { // Run forever (or alternatively return when all threads have finished) } } trait Context { fn create_thread(handler_fn: : fn() -&gt; !) -&gt; Result&lt;(), u8&gt;; } Another idea would be to pass in an initial stack argument like this create_thread&lt;T: Send&gt;(data: T, handler_fn: fn(T) -&gt; !) -&gt; Result&lt;(), u8&gt;; It's possible that you might be able to use a `move || {}` closure instead, but I have no idea how you would initialize the stack and program counter with an `FnOnce`.
Many people do. I prefer “double”.
What version of Rust and Cargo are you using?
https://doc.rust-lang.org/book/index.html
Oops, sorry, I ran past the question, as the OP was asking for over 100 EUR, which is about roughly our price point /cc /u/micachito.
Looking at the trait for an `FnOnce`, it looks like it wouldn't be much more difficult than initializing the stack with a single argument. pub trait FnOnce&lt;Args&gt; { type Output; extern "rust-call" fn call_once(self, args: Args) -&gt; Self::Output; } `create_thread` would change to fn create_thread&lt;F&gt;(handler_fn: F) -&gt; Result&lt;(), u8&gt; where F: FnOnce() -&gt; !; You would then move the `handler_fn` struct itself onto the stack (using something like `std::mem::size_of` to figure out how much space it should take), then point the program counter to `F::call_once`
I highly recommend CodeWars. At first, I was put off by the title, because I don't necessarily want to compete with my code in a "war." But the actual site (other tracking how many exercises you've completed and ranking you) has very little to do with competition. My first thought was that it might be speed coding, or code golf, neither of which I am interested in. It is not that. &amp;#x200B; What code wars **is**, is a collection of community-submitted coding problems for which you can view others' solutions after you complete your own. With regard to voting on submitted answers they have two metrics: **clever**, and **best practice**. I really like this, because I think the two are often, and unfortunately, conflated. It is really fun to complete an exercise and then go look at the top voted clever and best-practice solutions to the problem. &amp;#x200B; Also, it runs tests on your solutions. Some of them take time into account and won't allow an inefficient solution to pass, even if it would eventually generate the correct answer. &amp;#x200B; That being said, the majority of my participation on the site has been in Haskell, and I have not checked out what Rust has to offer.
I just landed a Rust PR to allow multiple arguments in `dbg!` and shaved off a few millis from the benchmarksgame regex-redux benchmark. Also some compact_arena development and there'll be some mutagen news, too.
I think you have the same problem as [this post](https://users.rust-lang.org/t/enum-with-box-trait-and-comparsion/16723/5) if I'm understanding correctly. Basically you want structs to automatically implement ValueFull if they implement Value and already implement PartialEq, Eq, etc. and then be able to compare two boxed ValueFull objects. &amp;#x200B; The problem is that, as mentioned in the link, the trait itself has to implement PartialEq and Eq because the compiler doesn't know how to compare a Vec&lt;bool&gt; and a \[i32; 1\] for instance. Here's an example of what you could do: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=85581714b5e3102aa0dfbb5d65838a3f
Nothing happens for me (only prints "info: checking for self-updates" and then exits) even though im on 1.17.0. Do I have to wait a while before attempting the update?
I'll use OpenXR as soon as it supports my Vive, and does that mean you recommend nalgebra specifically for this or was that just a suggestion?
Yeah, sorry. The edits was destroyed by the reddit editor. Now is more clear.
Rust is an ideal candidate for audio processing/DSP. I help with the `vst` crate, and we've recently begun discussion with some LV2 devs (of `lv2-rs` and `lv2rs`, I know, a little confusing) to unify our efforts. Long term goal is to create an abstracted plugin API that can target multiple backends (lv2, vst, au, jack, etc.) We're making a site with the hopes of creating a database of useful audio resources as they relate to the Rust ecosystem (I'll share the link on this soon!), and later down the road we'd like to expand areweaudioyet.com. We were also kindly granted a forum instance via discourse, which can be found here and includes all mentioned discussions above - http://rust-audio.discourse.group So... a lot of web dev this week :) Maybe some more Rust soon...
Yeah is the same thing. Look like I need to implement this manually. But I wonder about Clone. It look to me it could auto-derive but still have the object restriction??
The documentation page has some of it summarized: https://doc.rust-lang.org/ Personally, I really like learning through "the book", but Rust By Example is also pretty popular, if you want to go through the pratical way. Also, if you're learning and want to test something, you can use the playground (https://play.rust-lang.org/), which even allows you to share if you have any question about how / why your code works.
Honestly, I think emitting Rust syntax is not such a bad idea. You don't have to chase the rapidly moving target that is MIR *and* you get to write it as a regular proc macro.
Yeah, `Clone` is not object safe.
I find that using Python by default and switching to Cython for performance-critical things is a pretty productive workflow, and good for applications where you have e.g. a UI that is easiest to write in Python, but a small performance-critical core. The upside is that you can use Python, then benchmark and only optimize what needs to be fast. The downside is that Cython is pretty terrible language.
Congratulations! I'm happy to hear you had a pleasant experience translating to Rust.
Great article, I really liked the detailed explanation of every peripheral configuration! Another nice DMA feature is that it can also be triggered by ADC conversions, making it also easy to transfer analog readings to a buffer, which is basically the other around of what you did.
re-read my question
I'd store the number of dollars as a u128 and cents as a u8. I'd wrap these in a struct.
I have been using exercism and have thoroughly enjoyed it so far. I like that I do everything on my computer. There is one mentor who has helped me a lot. His suggestions led me to one of those aha moments. Though others who’ve commented on here are right, mentors can take a long time to give feedback. I am grateful for their help, but wish they had more good mentors like the excellent one who has helped me in the past. I’ve completed 21 exercises, and I always check others’ solutions to see if I could have made mine better. Other sites mentioned here look great. I’ll have to look in to those when I’m done with all of my exercism exercises!
Glad to see better IDE support highlighted. The IDE experience definitely contributes to the friction of working with rust when compared to other languages. Once we have a solid IDE experience not only will productivity go up but learning and exploring the language will become easier for new rust programmers.
Very happy to see "long-standing requests" on the roadmap. Slightly concerned that none of the examples include macros, both macros-by-example and proc_macro_hygiene. Hopefully that work hasn't fallen off the radar.
Is part of the goal of this project to allow people to experiment with to augment autonomous vehicle navigation to test out different ideas?
See [this post](https://old.reddit.com/r/rust/comments/bfemx6/building_a_plugin_system_using_rust_and_wasmer/) for additional details
The rename-dependency Cargo feature was stabilized in the 1.31.0 release. You may need to update your Rust distribution.
Thanks for taking a look! Hosting an app is free, plans for charging tbd but likely only for tools around charging for an app. It’s also open-source so you could build and host it yourself.
Good to see that there will be some attempt to get a kind of feature parity wrt C++ templates, namely const generics, GATs, and specialization. Too bad there's no variadic template like feature in flight to be stabilized. I just hope the other features do make it into stable Rust this year.
For practise questions [link](https://sn99.github.io/rust-practise-questions/)
I'm going to say learn C first.
So I benchmarked my crate against yours but I used slightly bigger struct (20 fields) and the results are exactly the same (about 8-9ns), so I guess even when taking into account dynamically sized structs - its still possible to reach those speeds. your code did gave me some ideas so I will update when I will have something to show &amp;#x200B; u/devashishdxt
Working of SideFuzz (https://github.com/phases/SideFuzz), a fuzzer for finding timing vulnerabilities. My main focus right now is figuring out why it’s producing false-positives. Given enough time to run, it eventually determines that *all* code is variable-time, even code that is obviously constant time. I’m not sure if the problem is my statistics calculations, the test harness, or some weird f64 rounding issues.
I recommend nalgebra, as it is the most complete, actively maintained, and strongly typed of the libraries I am aware of. Some people don't like having that many different types; [nalgebra-glm](https://crates.io/crates/nalgebra-glm) may be preferable if you feel that way.
The "war" thing bothered me too. But I guess we're always at war...with the borrow checker. Thanks for the detailed review!
Yes, I also have a `Map` type that is generic over the `Parser` and mapping function. But the type quickly became just as long as the functions themselves, so the `impl Parser` made it significantly easier to read and write the parsers. In the `Parser` trait I did write out the types explicitly (so `fn map&lt;F&gt;(self, f: F) -&gt; Map&lt;Self, F&gt; where ... { Map(self, f) }`).
You may read the official book (if you installed via rustup, `rustup doc --open` should show a local version of the docs, including the book), look at [rust-learning](https://github.com/ctjhoa/rust-learning) and/or join a project (this week in Rust has a list of issues, many of which are mentored. We may also help you find a project if you tell us what you want to learn)!
\&gt; So far, the different structures for representing everything associated with a road/intersection/etc strongly resembles ECS. Would explicitly using an ECS library help? &amp;#x200B; This seems like a really cool use case for [specs](https://github.com/slide-rs/specs), which will soon be WASM-compatible as well. Come talk to us about it any time on [discord.gg/amethyst](https://discord.gg/amethyst)
A lot of people pronounce it "ess-cue-ell". [Both pronunciations are on the wikipedia page](https://en.wikipedia.org/wiki/SQL), I don't think either pronunciation is more correct than the other
I feel like procedural macros could cover the same surface area as template parameter packs in C++. But I've never tried. It would be great to be generic over functions of any signature though.
It's always possible to do better, and I like the energy around trying to find ways to do that. There's a good reason serde is not in the standard library. The key is to use evidence to justify the fact that it's better, not just NIH something because you feel like it. I think the author has done that.
I wanted to use nalgebra-glm, but it wouldn't build for me. I'll try again though.
Not specifically. In college, I worked on some ideas for navigation assuming a city mostly has autonomous vehicles (AVs). AVs could participate in small auctions to change to a green light faster, a sort of economic generalization to what emergency vehicles sometimes can do. Another idea is putting "micro" tolls on arterial roads to prevent them from exceeding their freeflow capacity by too much, and instead having "lower-priority" AVs take longer routes, make the trip at a different time, or use transit instead. These were fun ideas to explore, but ultimately I'm not motivated to enable people to use money to drive faster. If you're interested in these forms of navigation, check out chapter 6 and 7 of my [undergrad thesis](http://apps.cs.utexas.edu/tech_reports/reports/tr/TR-2157.pdf). I can also point you to people I was working with that've continued in this direction. I'm focusing on the trade-offs between different modes in A/B Street. Removing on-street parking and adding a bus lane probably helps people using transit, but maybe that neighborhood has so many cars trying to park that the reduced capacity would just mean lots of cars roaming around trying to find a spot, ultimately making traffic worse for everyone. The fact that AVs are coming "soon" in some form motivates the urgency for something like A/B Street -- if AVs don't idle in on-street parking, we'll reduce the amount of dedicated parking -- but what will replace it? I'd also love to start modeling ridesharing in A/B Street, since my hope for AVs is not that individuals will own most of them, but that instead individuals will sell their car (and stop needing space for it in the city) and use some kind of autonomous ride-share in conjunction with transit.
So where are you using `impl Trait`, exactly?
I actually wrote it way back then forgot about it then came back and then again forgot, it is not complete but might help newcomers, I always found learning a language easier if I had a set of practise problems(a lot of them)
The only thing I really need is better compile times :)
Using tuples wasn't the end of the world, but still, thanks I am super stoked to use this!
God, I love this language.
Trying to get the [practise questions book](https://github.com/sn99/rust-practise-questions) I wrote a while back into light
Cool, but I can't tell from just looking if it supports BTLE (low energy). Does it?
This is the subreddit for the Rust programming language. You're looking for /r/playrust
Weird! It worked perfectly on my side. Did you manage to update rustup?
I would love that. Power of rust with ml-esque syntax. Yummy
i'm happy for you
I shall try! thank you. I know he has [his slides up online](https://github.com/monocasa/n64-slides-apr) and the other tools to create said roms, but... a talk in regards to working with said software and how / when he first tinkered with it, would be great as well!
Thanks Steve :)
No, one billion dollars is 10¹⁸ Nanocents. It's strictly better than what jackmott2 suggested, because with two seperate ints the upper two bits of the lower int would be always zero and thus wasted. Also besides being more difficult to program: I bet it's quite a bit slower because you will have to do a lot of weird modulos after any arithmetic for splitting the number. If u64 is not enough, you could go for u128 which luckily has excellent compiler support in Rust.
Scrolling around that demo map (on Chrome on Galaxy s9) is really smooth as long as I don't drag my finger down and trigger the address bar or the refresh indicator to start rendering (both of which cause jankiness). Is there any way to forbid Chrome from doing those animations? (Either force the address bar to be always visible, or have a full screen button? I'm not sure about the 'drag to refresh' thing though). It's impressive that Chrome's UI elements are causing worse jank than your map element. If you can find a way to disable them then your demo will look even more impressive. In terms of js API design, one approach would be to copy one of the existing osm widgets, and see if you can make a drop-in replacement.
The rust-learning GitHub repo is "build failing", LOL
Thanks for your input, I think api-parity with some smaller OSM widget would be a quite nice first step. Regarding the jankiness with address-bar, I think web manifest (to hide the address bar) could do the trick. I suspect it's because the resize-listener hooks get some activity when the address bar appears and disappears. I've put some really experimental work in the component lately, mostly with implementing the dom interface with dodrio. Even though it's very experimental dom-lib, it seems promising. Loading time seems to have halved with it, and it seems a bit smoother on desktop browser, which would indicate an improvement on mobile.
For now, I really enjoy the Rust plugin for CLion by Jetbrains! It's really quite usefull. Also, CLion has a great built in debugger. It can be quite slow from time to time though...
Is there a difference between a projecting dispersed in many files and a project made up of only one source file?
This may help: https://github.com/servo/servo/issues/23015#issuecomment-475050175
Thanks, this is super useful since I've been working on almost this exact thing (DMA from memory to SPI in this case).
Don't know why this isn't first priority. Poor ide experience is the biggest issue when trying to introduce rust at my company.
That's a place I live! Hurrah!
I read through the Pijul docs a few weeks ago, and it sounds really interesting. I think the mental model of patches is easier to understand than a graph; so I'd love to see this take off. In the comments of previous releases, a user ran benchmarks which highlighted some performance issues. I'd love to see them ran against 0.12! Slightly Offtopic: This is licensed as GPLv2, so is git. From my understanding a user couldn't link against https://crates.io/crates/pijul to create a client GUI app, is that correct? I'm just curious how so many closed-source git clients exist - did they write the libs themselves?
I couldn't be happier with the roadmap.
Hey guys, new to Rust here. How easy/difficult do you find it to do threading in Rust? My experience with threading is mainly with Java and C++.
Not everybody has the same “biggest issue.” It’s still a very high priority, to be clear.
Cool stuff, keep us posted!
Performance should be much better in this release (our diff, one of the main bottlenecks, was of quadratic complexity, and is now linear), but disk usage will still be quite high. Hopefully this will be fixed in the next release. Indeed, as far as I understand, you can totally link against [https://crates.io/crates/libpijul](https://crates.io/crates/libpijul), but only if your license is compatible with GPL2 or a later version of the GPL. If you want to write a client under another license, you can still call the \`pijul\` binary and parse the output.
Yeah, since enabling `Cargo Check` as the external static analysis tool, I've been endlessly delighted with my rust IDE experience. Most errors are instantly pointed out and more subtle ones load in after a second or so.
Looks excellent! A consolidation and completion year will also give the community time to catch up with all the things that have changed, and the sense that Rust doesn't always need to be barreling forward but can be content with where it's gotten is a good one.
I was specifically answering the part of your question about storing money. I didn't answer the other part because I don't have an answer for you. In the future if you want help consider being nice to the people trying to help you.
&gt; Output shell completions for cargo by `rustup completions &lt;shell&gt; cargo` Yes!
I've never been so happy to see a fucking gray cube. Thank you so much for your help. I finally figured it all out.
If they make it fast enough it can compile before you write
Little vague description. If speaking about concrete features, I wait for https://github.com/rust-lang/cargo/pull/6864 , looks very promising. Hope this feature increase CPU usage on my machine.
Yes this was the problem, I reinstalled rustup forgetting I already had rust from last year
&gt; Performance should be much better in this release (our diff, one of the main bottlenecks, was of quadratic complexity, and is now linear), but disk usage will still be quite high. Hopefully this will be fixed in the next release. Awesome! &gt; And indeed, as far as I understand, you can totally link against https://crates.io/crates/libpijul, but only if your license is compatible with GPL2 or a later version of the GPL. If you want to write a client under another license, you can still call the `pijul` binary and parse the output. I searched a bit and found https://libgit2.org, which lists GitHub, GitLab, etc., as users. From the page: &gt; GPLv2 with Linking Exception. Link with open and proprietary software, no strings attached. Would you be open to adding something like that for libpijul? I'd just like to see more tools built from it (mainly a repository viewer like Nest, and a GUI client), but it seems like the license could be a blocker as Pijul matures. If not I understand, just wanted to mention it.
&gt;Also, CLion has a great built in debugger. It can be quite slow from time to time though... And MSVC debugging is on the roadmap for 2019.2!
Is adoption not one of the biggest goals lately? It seems to be a goal as they mention community a lot.
Adoption is absolutely a goal. That doesn’t mean that one person’s experience with IDE support being a large blocker means that it is the largest blocker, generally. For example, I hear more people complain about compile times than I do IDE stuff. That also doesn’t mean compile times are the single largest blocker either!
I am quite productive with the RLS extension for VSCode. One issue that makes it difficult to integrate at my job is that it requires a Cargo.toml file, while we have a custom build system that uses rustc directly instead of cargo. I'm not sure what the solution is.
They can't get past the guessing game example with the current ide support. How are they going to get to the point of worrying about compile times?
Many people don’t use IDEs at all. And some of them think the current support is fine.
Many developers work very successfully in languages with poor or no IDEs. For many people, it's just not the most important thing in comparison to (for example) compile times, custom/private package repositories, or having a good version of *that one package I really need*.
I'm guessing you come from a Java or C# background? Rust isn't that far behind the IDE support of a lot of languages... I come from a JavaScript background, and while I wish the IDE plugins were a bit dnappier/more reliable, the actual output is about on par with what I'm used to. Meanwhile my usual workflow of googling / looking up the docs in my browser and using a code search tool like ripgrep to find uses of variables works just fine with Rust.
I don’t use an IDE so this isn’t a priority for me.
Newbie here - I started learning Rust on Maundy Thursday. The on-line documentation on [rust-lang.org](https://rust-lang.org) is just fantastic. Those who had made it can be proud of themselves. Considering that English isn't my native language, I especially like the simple, easy to understand language, and the documentation is well structured. I have the Rust Essentials book too.
Right, I will try to generate a reproducable test case within the next days! Should have opened an issue immediately back then
Have this in my library [postcard](https://docs.rs/postcard), which also targets no std use cases, though it is based on Serde
Is the Rustdocs 2 effort suspended/dead?
For now, basically, yep.
It also generates typed client helpers visible to rustdoc. [https://www.jsonrpc.org/specification](https://www.jsonrpc.org/specification)
Not sure about rustdoc2, but there’s many long standing rustdoc issues with the current rustdoc that no one really cares enough to fix, unfortunately :/ To recall a random one, showing deep derefs in the docs, for some crates not having that is a nightmare.
Got excited to see Sequoia mentioned, got considerably less excited to see that means no Pijul with smart-card based private key (aka the RIGHT way to do things).
Smart-card based private keys are already working in Pijul for SSH keys, via agents. PGP keys don't work yet, but that doesn't mean we won't support them, just that they haven't been implemented yet. If it turns out PGP was the right choice, we will continue in that direction. If not, we won't have wasted time implementing useless features.
Every language seems to have IDE's that are constantly breaking, require cryptic configuration, or generally obfuscate what I'm trying to do. Poor IDE experience is why I don't use IDEs anymore. And consequently, why I wouldn't care if IDE experiences improve.
I would love to see something like this. I love Rust, but I honestly can't stand all the syntax choices that were made. * `&lt;&gt;` for types? It's difficult to read, especially when they're nested, and it's something I hate about Java and C++ too. Scala does this better with `[]`. Or Haskell, with capitalised being types and lowercase being generics. * `'` for timelines and everything else about the timelines syntax. * `|a, b, c| { a + b + c }` for closures instead of something like `(a, b, c) =&gt; { a + b + c }`. * `::` as in `use std::borrow::Cow`. Annoying to type and to read. Why can't we have `std.borrow.Cow` like a million other languages? * Why does Rust need macros for even the simplest things? I'm looking at you `println!()` and `format!()`. Maybe I just have really weird taste, but while I think Rust is super cool, it's an unergonomic and unreadable language.
It does \_not\_.
I'm not a huge fan of discussions about hypothetical projects that could justify a license change. The goal of the license is to encourage people to contribute stuff back. I'd be super happy to see people write GUIs that I can use, less happy to see them write software and ask me to pay for using my own project.
&gt;MSVC debugging As someone new to Rust, can you explain what this means and which benefits it provides?
It took me a moment to find it in the middle of the text, but to be fair the page linked does say: &gt; While we don’t have a final date yet, we’re aiming for late fall this year.
Macros just expand to regular rust code. Obviously you don't need macros; just replace them with the code they expand to.
You're never going to please everyone, if we made your choices I would be annoyed about them because I like all the syntax you dislike. Does it make you or I wrong? Nah, it's just preference. Something needs to be picked, and once it's been picked that really ought to be the end of it (for that particular language at least).
If I want to compile code in release and not in dev profiles (or vice-versa) is the "debug_assertions" attribute the correct one to use? Basically what I want to do is #[cfg(dev)] .. code only executes on cargo run .. #[cfg(release)] .. code only executes on cargo run --release ..
Sorry I must have missed that.
I think what should be on the roadmap is putting into Rust whatever is necessary to helping the Tor project completely switch over to Rust.
Do you know what that is?
How does one use experimental API (such as the "shrink\_to" method of Vec) ?
Use the `debug_assertions` configuration option: if cfg!(debug_assertions) { println!("Hello from debug!"); } else { println!("Hello from release!"); } [https://doc.rust-lang.org/reference/conditional-compilation.html](https://doc.rust-lang.org/reference/conditional-compilation.html)
Glad to finally have it on it's way..
So good to hear that the work with pijul is ongoing :) I did a bit of searching, but couldn't find anything regarding CI. Is there any documentation regarding something like integrating with Drone for continuous integration?
Roadmap should include a plan to outsell Java and Python books, else people will continue programming in lesser langues.
Could someone explain polling to me? I know I'm missing something because to me it looks like you're basically calling poll as fast as possible without waiting for any interval in an infinite loop. Is that not insanely inefficient? How's this not block the rest of your code from running if you need to do some other stuff after you've initially scheduled your future. Given that the polling model is better with regards to canceling + allocations than the callback model, are there any other languages using it?
Personally, while I wouldn't point to IDE support as the star feature or a model example, I find the IDE support on par with a lot of languages and certainly not in my top 3 hopes for Rust in the short term.
Fair enough. I wasn't sure if the potential restriction was deliberate due to the FAQ: &gt; What is the license of Pijul? &gt; The license is GPL2, or any later version. This means in particular that Pijul is free software, and can therefore be used freely to develop any kind of projects, including commercial ones.
There's no integration with any CI system that I know of, but it would be pretty cool. One thing we're missing to integrate Pijul in NixOS (which is very easy to use as a CI system) is the ability to clone a specific set of patches, but this would be quite easy to implement. Other than that, the Nest has hooks to indicate when a patch is pushed, see [https://docs.rs/pijul-hooks](https://docs.rs/pijul-hooks) to see how to use them.
/u/steveklabnik1 - just wanted to point out a typo: "plans to look over revamp their processes" in the second paragraph of the governance section - you probably want just "look over" or just "revamp" or combine them with an "and".
Most common is a single binary that acts differently depending on the arguments you give it, like git or cargo. You could also have multiple binaries, each with their own main function.
That's what I'm using right now, though, the name appeared a bit weird so I wanted to check that I'm using the correct attribute.
Alright. That sentence was added because there was a confusion at some point among some people, as to whether the license prevent the use of Pijul as the version control system of a commercial project (for instance a project unrelated to Pijul).
Perhaps Microsoft Visual Code?
Thanks, I know.
That definitely seemed like the most common theme in their plans.
I'm a sucker for language features, and the talk of finishing const generics and GATs this year is exciting. I do wish work on the `become` keyword would resume...
It's not actually polling in that sense. When a future needs to wait on IO, it returns `Pending`, but only after registering the Waker object passed to it (from the executor) somewhere (namely, the reactor) so it will get triggered (have `wake()` get called) when the IO completes. When that happens, the executor resumes polling. It's really more of an "implicit callback" that is tied to a task rather than polling.
&gt; less happy to see them write software and ask me to pay for using my own project. They will just make this GUI web-based SaaS, and charge a subscription. :D . Should have AGPLed it. ;)
Would putting a fake cargo.toml file work? Just fill it and don't use it. Have to spend some time keeping it synced perhaps, but just having it would not break anything, would it?
BTW, you can express all your examples in Perl. It's not the same abstracting power but your examples don't call for it. It is just not true, as you claim, that you cannot express it in any dynamic types language. In more details: 1. If you assign to hashtable a list of lists where the inner lists are 2 element lists, it's converted into hash table. BTW, arrays/lists and hash tables have different types in Perl, '@' vs '%' sigil. This let you write the same examples as 'my @arr = map @foo $bar' or 'my %hash = map @foo $bar'. 2. There is also the built-in 'wantarray' that tells you if the function is called in array context or not. So you can return scalar, e.g. lists evaluate to their size in scalar context. Agree that is more limited, also not available in other dynamic languages, but it is still there. Posted from phone, so excuse typos and formatting.
Well this isn't a Rust thing at all, it's a Windows dev tool problem. The integrated CLion debugger wraps the GDB CLI on Windows, which is fine for anything compiled with the GNU toolchain. However if you want/need to use the MSVC toolchain (default for a lot of proprietary C/C++ stuff) you need to use microsoft's MSVC debugger - whose license forbids non-MS dev tools from using it (so you _can_ use it in Visual Studio or Visual Studio Code). It's a major quality of life improvement that people have been asking about for awhile. In terms of Rust, it will make integration with C/C++ projects much easier on Windows.
Emacs support is 💯
It was a license problem. afaict the workaround involves reverse engineering microsoft's binary format/debugging symbols and doing a clean room reimplementation of the MSVC debugger. Not exactly trivial.
Thanks! Mind sending a PR maybe? It’s rust-lang/blog.rust-lang.org on github.
Intellij rust is amazing. I'd be bold and say it is on par with java nowadays.
Also also, I'm pretty sure it's inverse(hmd\*eye) instead of inverse(eye\*hmd) because (**AB**)−1=**B**−1**A**−1
So like I would use a web framework where I define different routes with appropriate handler functions, I should just go with clap defining multiple sub commands? Or is it multiple binaries more common?
This seems interesting, but it's not clear what this tool actually do. It looks like the goal is to go from an normal frontend app written in rust to a PWA with some magic. But what is this magic? Does it handle making the app works offline? Does it handle the service worker stuff that seems needed for PWA (if this is really needed, I don't really understand PWA yet)? Also, what part is the hosting vs strictly PWA related? Can I use Woz whithout the hosting part?
Typically polling a source of data will actually block until data is ready, so that you aren't hard looping and eating a ton of CPU. For a single source of data this would be like trying to make a blocking read on a socket; you block until the underlying kernel network call has data to return. If you have multiple sources of data though, trying to read from each of them synchronously causes problems since you may be stuck trying to read data from source 1 when source 2 has data ready to go. So instead you basically tell an underlying runtime that you want data from multiple sources, and what to do with that data once you have it. 'Polling' is basically asking that runtime to take care of checking each of these sources and once one of them has data it runs that code. Network IO is a common example for this type of thing, but really it applies to anything where you want your code to be 'notified' when some event happens. A great example of a language with first class support for this is Golang. Golang has 'green threads' (goroutines) as mentioned in the talk, and the golang runtime is responsible for scheduling how these threads run since they are not true OS threads. Golang also has 'channels' which the goroutines can use to send data from one thread to another. If you have multiple golang channels you want data from, you can call 'select' against them and you will get the data from whichever channel had data ready first.
Whoops, yes, that's what that was supposed to say. `eye * hmd` doesn't make sense in any context.
Congrats! I find developing for VR is especially rewarding due to the feeling of physicality even the simplest tech demo has.
So the magic parts are automating the checklist of things that are required to be a pwa. As you said that includes a service worker so it can be used offline, but also means setting up niceties like splash screens for iOS and Android, app icons, and serving over https. As for hosting, you can think of it as a static hosting service (like netlify), but it’s optional. The build command generates all the files locally so you could host it with whatever static hosting service you want. Thanks for the feedback! This could be clearer on the website/docs.
You'll need to install and use rust nightly. If you have rustup, should be something like so \`rustup install nightly\` and then when you're building/running \`cargo +nightly run\`
Rust Sacramento is hosting a hands-on workshop tomorrow night at the McClellan Innovation Center in the airport business park. Our group project is to reimplement commands from BusyBox in Rust with each person or team working on a different command. We'll have a few experienced community members (myself included) to help out and answer any questions. Food and soft drinks will be provided by LaunchBadge, LLC. Everyone is welcome!
Yeah I tried what you said at first without thinking about it and it just looked subtly off. It was hard to figure out
This brings to mind an excellent talk I recently saw: Category Theory in Life by Eugenia Cheng. The author demonstrates categorical graphs in understanding causal relationships of events to help understanding and divisive/opinionated discussion. https://youtu.be/ho7oagHeqNc (Skip to around 34:46 to see it in action, but be sure to watch the whole talk too, it's excellent!)
Blender 3D [https://www.blender.org/](https://www.blender.org/) is a open source program / project. One can write 3D interactive software, (For example games - look for Game Engine modules in the Python API) [https://docs.blender.org/](https://docs.blender.org/) A GUI toolkit based on Blender 3D **could** be better than a browser DOM, but on the other hand we do have Servo - the browser engine written in Rust for Mozilla Firefox [https://servo.org/](https://servo.org/)
The [rust book section on threads](https://doc.rust-lang.org/1.30.0/book/second-edition/ch16-01-threads.html) does a pretty good job of explaining concurrency and is always a great place to start with new topics in Rust. I would say spinning up a thread to just do some work on its own is incredibly easy. When you start getting into more advanced things (ie sharing/reusing a network connection between threads) it will seem pretty frustrating at first since even if YOU know what you are doing you still have to appease the compiler with things like `Arc` around your `Mutex` and traits like `Send` and `Sync`. But ultimately once your code compiles you can have a ton of confidence that it will actually be correct, which is many peoples reason to love Rust.
It really depends on the use case but if it’s a cli tool to manually invoke, many users prefer single binaries.
I'm amused how it's already a third of the way through the year, and it's only now they're realising the roadmap. 🤦
We are a bit late, it happens. That said, the RFC was accepted a while ago; and the decision about what went in was not too controversial, so the teams have had a decent idea since late January.
It works even as an empty file. I'm not sure what features of the RLS are broken in that state. I can at least tag and get tooltips for most things.
Not really specific to Rust, but readability is an incredibly important aspect of coding. Breaking up your project into multiple files assists with that. If you have a single file that is thousands of lines long it can really slow you down to jump back and forth between different parts of that file. However if I'm writing a small bit of code I will often keep it in one file.
How would you say this compares to something like Capn Proto?
Bobby tables approves of the first async await example
Done and done
The sublime text rust plugin is top notch
```` // A and B are mutually exclusive trait A {} trait B {} // C should have a default implementation // implemented differently for type A and type B trait C {} impl&lt;T: A&gt; C for T {} impl&lt;T: B&gt; C for T {} // &lt;-- error[E0119]: conflicting implementations of trait \`C\` ```` What is the right way to do this?
What does this mean? It wasn't clear from the linked issue.
[This currently isn't possible in Rust, although you can work around it using associated types](https://github.com/rust-lang/rust/issues/51774)
I'm sure this is impossible to say for sure, but is there any sort of idea of how much compile-time performance gain there is to be had? Are there any low hanging fruit that are likely to boost it a lot, or will it be incremental changes the entire way through? I'm personally looking forward to as fast a compiler as can be, as I'm already dealing with a slow enough C++ compiler.
Can’t make any promises. There are no big gains to be had by low-hanging fruit. There will be slow and steady gains as things progress, but no huge jumps, if I understand things correctly.
Good to know, thanks!
Previously you could only output completion for rustup itself, now you can do it for cargo as well.
Awesome! Thanks for the link and reply! I'll have a good look
Thanks!
It provides you with a shell script you can load when you open a new shell that will enable tab-completion for subcommands and options to `cargo`.
I'm curious to know what is the reason for not using cargo in your build tool? If it is because of private repositories then this should now be fixed?
Sadly the completions for bash don't actually work: -bash: /redacted/.rustup/toolchains/stable-x86_64-apple-darwin/etc/bash_completion.d/cargo: line 82: syntax error in conditional expression: unexpected token `(' -bash: /redacted/.rustup/toolchains/stable-x86_64-apple-darwin/etc/bash_completion.d/cargo: line 82: syntax error near `@(t' -bash: /redacted/.rustup/toolchains/stable-x86_64-apple-darwin/etc/bash_completion.d/cargo: line 82: ` if [[ "${cmd}" = @(test|bench) ]]; then'
I've converted a large multi-language repo to Bazel (made my builds so much faster and more reliable) and [rules_rust](https://github.com/bazelbuild/rules_rust) + [cargo-raze](https://github.com/google/cargo-raze) have been wonderful and easy to use. Unfortunately it seems RLS doesn't support Bazel projects at all yet, and I've actually stopped working on the Rust portions of the project because editor functionality has more or less disappeared now. I'd absolutely love for this to be prioritised somehow, running Rust in large build systems is going to become more common over time.
I'll give that a try!
Just released [abi\_stable](https://crates.io/crates/abi_stable) 0.2(For Rust-to-Rust ffi, with a focus on creating libraries loaded at program startup, type-checked at load-time.), I am thinking what to do next,since the building blocks for extending modules and vtables in minor versions (while keeping ABI compatibility) are already implemented (this was the most pressing feature to implement).
To say this is an Elastic Search alternative is.... well... a bit of a stretch. It seems it can only replace basic keyword search/suggest, it can't do 95% of what ES does. I do love the overall goals for the project to be lightweight and performant. Would like to switch away from ES as it's a bit overkill for us and Java is an absolute memory hog. Though to switch away we'd need at least a basic way to query multiple data based on various criteria, location lat/lng filtering, etc. Will defo keep my eye on the project 👍
FWIW, I gave it a quick try like for 0.10 and 0.11, trying to import the few first commits of mozilla-central, and not much has changed compared to 0.11 (https://www.reddit.com/r/rust/comments/9z2pkl/pijul_011/ea794nn/).
It’s not really “correct”, but it’s the closest thing that exists.
Not at present. Once I have finished improvements to the Bluetooth API, I will start working on the BLE central and peripheral roles, respectively. Depending on overlap between the bluetooth and BLE implementations, I might split it either into a separate module or crate.
I for one, have been very happy with Emacs and the Racer plugin
What do you mean by "inline"? Encoding the image as base64 in the src attribute? If so, I have never done it, sorry :(
Absolutely. I love that Cargo has such a well designed CLI, and that there was so much emphasis on the command line output of Rustc errors and warnings. From the ASCII arrows pointing to the line position of errors, to the way cargo right-aligns its output, the CLI experience was no small part of convincing me to learn the language, and stick with it. I’m really excited about JetBrains support, but it’s secondary to the basic tooling. Nothing frustrates me more than working with C++ compilers. Even with first-tier IDE support, one often needs to read the text output. P.S. please fellow Rustaceans, don’t ever abandon Emacs support entirely
It you are talking about a web server routing by uri route, look at https://crates.io/crates/usher or for a framework, rocket.
When I learned that PyCharm and IPython existed after having learned python in the standard REPL, that was a real turning point for me. Auto-completion makes a world of difference for learnability.
For some reason I like long compile times.
I initially tried using a macro, but ran into difficulty when the types to impl had generic parameters: ```` trait A {} trait C {} macro_rules! impl_c_for_a { ($T:ty) =&gt; { impl C for $T { } }; } //... struct X {} impl A for X {} impl_c_for_a!(X); // this can work... //... trait Foo {} struct Y&lt;T: Foo&gt; { v: T } impl&lt;T: Foo&gt; A for Y&lt;T&gt; {} impl_c_for_a!(Y&lt;T: Foo&gt;); // but how do I pass in and parse a more complex type? ````
Extract parameter too? That’s not in PyCharm yet, and that’s been running longer as tool than the rust plugin
I've spent the past two days going through the Rust book and found it to be an easy and very fun transition from Java. I instantly fell in love and want to continue using Rust but have a few questions. 1. I've been learning React for a few weeks now because I need to build a performant, reactive web application for a project I'm working on. What are the most popular frameworks/crates/general resources to get started with this in Rust? 2. I got into Rust because I was exploring learning paths for blockchain engineering, was going about it in C++ and couldn't help but to try out Rust. Does anyone have resources to help me get started or could tell me the common frameworks/tools used? 3. Do any common JS libraries/frameworks have better compatibility with Rust than React? To the point where it would have a significant impact on my performance?
Here are the basics: Whatever loads your program defines what the entry points are, because the entry point(s) is/are just a function that said other party has agreed to load. 1. If you create a compiled binary, you have one entry point and the operating system's loader will call it after loading your program into memory. `main` is actually not what the OS calls though. It's what the standard library's setup routines call once they're done. For example, in C and C++, the standard library's setup routines are responsible for preparing the `argc` and `argv` arguments that `main` receives. The [Contemporary section](https://en.wikipedia.org/wiki/Entry_point#Contemporary) of the Wikipedia "Entry point" article goes into more detail but the gist is that ELF and PE executable formats have a metadata field that says what offset in the machine code to start executing at. GCC uses `_start`as the name for the libc-provided function that does all that setup and then calls `main`. 2. If you create a library, then whatever program loads your application will determine which entry points there are and how many of them. For example, Python's extension API will expect to find an `init` function with a name based on the filename of your extension when you `import` it. When you're writing a program in a web framework (be it Django for Python, Rails for Ruby, Spring for Java, or what have you), you still have a single entry point from OS to your application server. It's just a question of how many functions your application logic exposes to the server and how you declare when to call them. Basically, it all comes down to something like this Python-style pseudocode: def routeA(...): ... def routeB(...): ... def managementA(...): ... def managementB(...): ... def initRouting(core): core.addRoute('/', routeA) core.addRoute('/foo', routeB) core.addManagement('cleanup', managementA) core.addManagement('cron', managementB) def main(): core = Core() initRouting(core) core.run() The only reason most frameworks appear to have multiple entry points is that they provide something like that `main` for you and you just write the functions and the `initRouting`. You can see that in [Actix](https://actix.rs/) where you're responsible for writing `main` but, no matter how much a framework hides the initialization flow or moves parts of it off into an application server (eg. J2EE), that's fundamentally what's happening. The OS calls one entry point, then some code in either an application server or your binary calls some "set up routes" code you write, then either parses the command-line to determine which management command to call or starts listening for requests, which it will parse to determine which route function to call.
&gt; The purpose of this library is to provide an OpenGL Context on as many platforms as possible.
This looks fantastic!
I mean, it's good, but not even remotely close to on par with Java. A substantial size rust project still loads errors quite slowly, autocompletion is generally nonexistent inside declarative macros, type inference fails sometimes, etc etc. It's getting better! Still not even close to done, though.
Hi, I don't really understand what you are trying to do, you didn't specify if you wanted to use the bools or operate on them. If you want to operate on them you can do something like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a3fbe8ee0ffbc1ce376440b05050fac7) but it's a lot of complication and it's probably not faster than without SIMD. To me SIMD is supposed to be used when you have values contiguous in memory and want to make some operation on them. In your case your bools are contiguous but you access them in arbitrary order so the bools in the &amp;mut \[bool; 8\] won't be contiguous. If you want to use them to sometimes make an operation on some other data, that's totally different, but again since they are not accessed in order I don't know if you're gonna get any performance increase. Also why are your offsets isize and not usize?
The naming confusion here comes from the name of the underlying system call: "epoll" on Linux. Which was named after another older interface also called "poll". And yes, these kind of do the opposite of what their name suggests, which is to register to receive a notification rather than checking in a loop.
 I'd just like to interject for a moment. What you're referring to as Linux, is in fact, GNU/Linux, or as I've recently taken to calling it, GNU plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities and vital system components comprising a full OS as defined by POSIX. Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called "Linux", and many of its users are not aware that it is basically the GNU system, developed by the GNU Project. There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine's resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called "Linux" distributions are really distributions of GNU/Linux.
Not only is this a spammy and petty all the time, it's also wrong. We're _talking about the kernel_.
it's closer to 70-80 for me
Long compile times = good excuse to take a coffee break?
Its also a bot. I'm hoping it gets banned soon. :-/
Does the bazel build approach still allow you to publish crates?
&gt;The goal of the license is to encourage people to contribute stuff back. Have you considered the [Mozilla Public License](https://choosealicense.com/licenses/mpl-2.0/)? It's basically "do what you want, but if you modify the original source code, you must publish that change."
There's only a couple people working on rustdoc. More man-power would help.
I know this is old news at this point, but its always annoyed me by its passive aggression. &gt; The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. GNU libs are an ~~essential~~ optional part of an operating system, but useless by themselves; they can only function in the context of an actual functioning system with a kernel that works.
Gotcha. Multiple views...
Thanks for writing such a detailed migration guide!!
Short answer: The key piece you are missing are the "Waker"s. When we poll futures, we poll once. If it returns `Pending`, we say, "OK, here's a waker. Use it to let me know when I should poll you again." And so we don't poll again until indicated. For I/O, there's probably an I/O event loop that is responsible for delivering such notifications. This is nice because wakers are totally abstract; you can write low-level futures based on any kind of async event you want, instead of having to write a single event loop that has to handle all kinds of events you might need (like libuv). Instead different kinds of events can be driven by totally separate components, but still work together.
No, for me it's the same feeling as running a dishwasher or a washer/dryer. It's a sense of the automated accomplishment of things. It's the feeling that the longer the compiler takes, the more quality that binary will be in the end.
I'm working with Tokio and Futures and need to pass some argument to a Future. I can't seem to figure out how to do this. The examples I've seen are all structs which `impl Future`, so the state they work with is already there. I won't know the state until runtime, and for code cleanliness I want to separate the struct from the state I need `poll()` to work with. How can I do this?
Late to the party - sorry! Someone below mentioned [Rust Decimal](https://github.com/paupino/rust-decimal) so I thought I'd mention that I'm the maintainer of that library and happy to answer any questions. I'm also very interested in what you're thinking about while evaluating libraries as well as reasons for ultimately choosing it versus reasons for not choosing it. All in all, I want to make it an "obvious" solution to choose so any feedback is very much welcome!
Awesome work, thanks for the background. Love reading this stuff. Anywhere I can learn about the new hashmap implementation?
I'd say it wouldn't, as publishing is a cargo command and when you use bazel you don't invoke cargo directly. I haven't tried though, as I don't push crates but build docker images instead. You'd think it'd be possible to add a cargo publish feature to rules_rust similar to how you can push docker images, but it just doesn't appear to be there yet.
Right - similiar situation I've been facing trying to convert various Maven/Java projects over - bazel is a \_build\_ tool, not a \*cough\* \_project comprehension tool\_.
Tail recursion would be nice. It isn't *too* big a deal due to having imperative loops, but would still be useful for making tail calls to other functions. I find it amusing that if Rust had eager drops, an explicit tail call operator wouldn't be necessary since it's only real purpose is to drop values before making the call rather than after.
I understood two of these words
Thanks for reading. I self-proclaim myself to be a Rust development news reporter. :) gankro wrote [Why Hashbrown Does A Double-Lookup](https://gankro.github.io/blah/hashbrown-insert/) (hashbrown is the name of the new HashMap) which explains an interesting aspect of the new implementation.
The problem is when programming, you often have to load a few pieces of clothes, try a particular setting, and then realize your clothes are now ruined so you need to try a different combination, and you're also thankful you didn't throw in your entire laundry or you'd be in big trouble. Long compile times spent optimizing is great when shipping for production, but when actively working on the code, iteration time, the time to add a small piece of code and then check if it works, becomes important. If the time to typecheck a piece of code is longer than it took to write it, then there are serious issues.
I'm confused about this. In the Tokio examples they use a `loop` to call `poll()`. Isn't that the same as infinite polling?
Okay I'm working on my canvas thingy still for Piet programming, but I'm a bit held up on the UI. I've already got all the drawing and parsing methods, which I will probably rewrite a third time some day, but for now I want to get text input operational so I can see changes in real time. I got a lot done this week and I'm proud. Here's the link, again, if anyone is curious: [https://github.com/anyusernameworks/spidey](https://github.com/anyusernameworks/spidey)
The point of native Rust GUI toolkit is to make all work in native rust code (not WebAssembly) and drop JS/HTML/CSS parsing overhead. &amp;#x200B; I guess if there was an easy way to access DOM from the code embedding Servo, that would be doable. I didn't find such a way. Care to educate me?
I wonder how much cost would is it to get back to the state you was before in this polling model? If I understand correctly, futures are sort of organized in a big state machine, assembled from smaller state machines. Every time it is "not ready", it bubbles up that "Pending" up the call stack until it gets back into executor. Once new data is ready for the future, it is polled and it will call poll of nested futures, until eventually it polls the future that was waiting for the data to arrive (for example, on the socket). So, let's take a contrived example of data arriving one byte at a time. Wouldn't this cause thrashing in the sense that this whole stack of futures is polled every byte, only to make very little progress (one byte)? Whereas in "push" model, this byte-at-a-time will be delivered directly to this innermost future?
They did it in C# at some point when ValueTuple support required System.ValueTuple nuget package.
Wrong sub. This is for the rust programming language. You're looking for r/playrust
Not only this, but futures stabilization is closer than ever with [#60224](https://github.com/rust-lang/rust/pull/60224). I don't think I've ever been this excited over a new compiler release.
parking_lot is also close to merging. This means 1.36 has: - Faster HashMaps - Faster Locks - stable Futures - NLL for Rust 2015 - stable alloc - probably some other things
Hey, You’re on the wrong subreddit. You’re looking for /r/PlayRust :)
Make sure to get the worst anti virus software out there and use a mechanical disk. Then you will get even more time to browse reddit.
Holy moly! You could open an issue here: https://github.com/rust-lang/cargo/issues
I did, but thanks!
&gt; I don't really understand what you are trying to do, you didn't specify if you wanted to use the bools or operate on them. I want to use the packed booleans in a next step. The remainder of the computation is a better fit for SIMD, but I first need to get the boolean values packed into a SIMD struct/register. In my example above, I only showed the part that doesn't work yet. &gt; In your case your bools are contiguous but you access them in arbitrary order so the bools in the &amp;mut [bool; 8] won't be contiguous. In this case the boolean values I need are indeed not (necessarily) contiguous in memory; `some_bools` is obviously contiguous, but I only need a small subset of them in the rest of the computation. I know their indices, and their indices are contiguous in memory (in `some_offsets`). Hence my attempt to use a gather operation. The behavior I'm after, is the have something with this behavior in the for loop: macro_rules! extract_bool { ($idx:expr) =&gt; { offsets_chunk[$idx] } } let chunk_must_match_read = m32x8::new( extract_bool!(0), extract_bool!(1), extract_bool!(2), extract_bool!(3), extract_bool!(4), extract_bool!(5), extract_bool!(6), extract_bool!(7), ); But I wanted to see to what extend I could use SIMD there too, since the operations necessary are seemingly offered through the [vector-of-8-pointers type](https://docs.rs/packed_simd/0.3.3/packed_simd/type.cptrx8.html). &gt; since they are not accessed in order I don't know if you're gonna get any performance increase. Sure, it's not going to be 8 times faster than doing all steps one-by-one. But the equivalent of `some_bools` and `some_offsets` would at this point in execution be in (L1, largely) cache, so it's not impossible that it helps. I mean, I assume Intel decided to add gather/scatter after figuring out how it could make it faster (in some situations) than dereferencing pointers one-by-one and then packing them into SIMD registers, right? &gt; Also why are your offsets isize and not usize? The offsets are `isize`s since that's [what the offset function requires](https://docs.rs/packed_simd/0.3.3/packed_simd/type.cptrx8.html#method.offset).
I used Visual Studio Code with rust-lang extension and it's realy good
Wouldn't https://github.com/Microsoft/microsoft-pdb have helped here?
Even C++ has pretty good IDE support nowadays.
Probably? I'm not super well versed in MSVC stuff, I'm just parroting stuff from the Jetbrains bug/feature request tracker where this has been requested for a few years
As someone who worked with them in the past to figure out needs, I'm pretty sure all the Rust features they needed have landed by now. And back then they pretty much had everything they needed too, it was just that there were a bunch of papercuts that have gotten fixed over time. (Global allocators was one of the last pieces they needed IIRC)
I would prioritize the RLS 2.0 effort and proper autocompletion support over non-standard build configurations. It's not like there's a dearth of build systems, and RLS can't realistically support all of them.
We have. Compatibility is unclear.
Thanks for the insight, we did understand the license we chose.
I remember reading somewhere that the newer Hashmap makes rustc 5% faster overall. Compilation time throughout the ecosystem reduces dramatically, in addition to the obvious improvement in runtime performance. Don’t quote me on this though, we’ll have actual benchmarks on this in a couple of weeks.
Awesome talk, keep up the good work! Have just one question, does anyone know if async/await is coming to embedded world as well?
Hopefully those three months can give Tokio and hyper time for a refactor to futures 0.3. that has been the main blocker for me for using async/await, rather than the nightly restriction
You can use them with async/await today by enabling the \`compat\` feature and using the associated helpers in futures 0.3.
Yeah that's the hope :)
I'm less familiar with Tokio. Could you include or point to the example you find confusing? Usually you use a macro or a `return` to return early if a `poll()` call indicates a future is pending. Indeed "short polling" a future in a hot loop would be wasteful, so futures are not designed that way. It could be the case that there's some magic in an example that is not obvious and tricky to grok.
I know but it's really awkward and messy to use (type juggling between 0.1 and 0.3 etc).
Ah, okey, thanks.
Oops sorry. thanks mate
I million % agree with first 3. they are Obviously right (your version). 4th is a matter of taste I think. 5th is because of ownership issues
You probably read it from me. In any case, it should show visible impact on https://perf.rust-lang.org/ shortly.
The blogpost is well written but slightly inaccurate. See [this](https://www.reddit.com/r/rust/comments/b38cwz/why_hashbrown_rusts_new_hashmap_implementation/eiyuckz?utm_source=share&amp;utm_medium=web2x) reddit comment for why.
If I recall correctly we used to have store the complete hash within the table, and we don't in Hashbrown. That means that we will check for key equality a lot more. &amp;#x200B; The bench I saw was using integer as keys. Has there been benches with a key type for which computing the key equality is not as cheap? (strings for instance)
Same here
Hashbrown claims to not allocate for empty maps. Is this still true for the std implementation?
Isn't it possible to keep the cargo based project alongside bazel so that you could actually have IDE support. (I personally don't understand the hubbub about monorepos and build tools like bazel and pants).
When you say &gt;their indices are contiguous in memory do you mean for each offset you want the next 8 bools from that offset or just that you will access the indices 8 by 8 and they point to 8 bools scattered throughout the some\_bool array.
 The Language team is taking a look at async/await, specialization, const generics, and generic associated types ☺️☺️☺️
The latter. `some_bools` and `some_offsets` are arrays, thus contiguous in memory, but consecutive values in `some_offsets` are not necessarily close to one another. They happen to be monotonically increasing, though I don't think I can exploit that fact here. To make it very concrete, `some_offsets` could, e.g., be `[0, 5, 9, 10, 11, 15, 36, 37, 40, 101, 200, 201, 204, 209, 217, 230]`.
The stability point for Windows is the WinAPI DLLs (most importantly kernel32.dll).
Then why not just: for offsets\_chunk in some\_offsets.chunks\_exact(8) { let bool\_simd = m32x8::new( some\_bools\[some\_offsets\[offsets\_chunk\[0\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[1\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[2\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[3\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[4\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[5\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[6\]\]\], some\_bools\[some\_offsets\[offsets\_chunk\[7\]\]\], ); }
Is any article about what difference between https://crates.io/crates/futures and futures from stdlib, and why these difference was introduced?
Interesting. Why was the hashmap implementation changed? And what’s the benefit of the new system? I assume it is faster to lookup k/v pairs now?