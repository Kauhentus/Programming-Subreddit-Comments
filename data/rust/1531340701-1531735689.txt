Any way to subscribe to this blog? 
No, that doesn't work, because it only returns from the closure, not from the function where this code lives.
I've rarely been able to get rls to work, and the few times I have it has massively underwhelmed in the auto complete department compared to the intellij plugin, even on simple things like enums. It's a shame cause I'd love to get rid of the overhead of intellij but I don't for see that happening anytime soon.
If I had infinite time, I would so do this. It looks like _so_ much fun.
&gt; True, async IO is not fundamental in the sense that nobody can work without it. It's also not fundamental in that it's only relevant for a fairly small chunk of use cases, my array processing application doesn't give a damn about async execution. If you need async IO Go is decent enough, if fairly limited tool for that use case, python, C#, whatever are all pretty competitive too, it's not an area that really _needs_ shaken up. imo there's a much bigger pay off in going after C and C++'s traditional domains. Async will be a nice thing when it happens, but it's only really relevant if your entire application is mostly network handing with some simple processing.
It wasn't a common pattern, until I noticed that I can unify some return cases by using `Option::map`. Made for [some nice code cleanups](https://github.com/KillTheMule/nvimpam/commit/fc954ec29fa88c300d6f982cef859bb8bbd77092). Thanks!
https://github.com/redox-os/relibc sounds kinda like what you're talking about. But yes, Google's work in bypassing libc is pretty impressive. But it also leads to some [pretty fun bugs](https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/) when mistaken assumptions are made.
You need to use `.flat_map()`, not `.map()`.
It's fine from here...
&gt; This is not acceptable, I will take a deeper look at this. The more I think about it, the more I think this is a rabbit hole you don't want to get into. You could of course make a new list and check it for duplicates, but then you'd have to solve the problem of "which is the right order of renaming files to achieve this" in general, and that sounds kind of hard. On linux, you could make a temp dir, put hardlinks with the new names in there, remove the old files, and then move the hardlinks to where the old files were. But you're looking for some fun bug reports from people recursing into different file systems. No idea how that would work on windows, anyways... The most important thing probably is to make sure you don't rename half the files and error out inbetween. That would wreak havok indeed. Feature idea: Something like `dry-run`, but it prints out a sh/cmd/ps1 script that does the renaming. Better yet, make it possible to print out the inverse renaming, so one can reverse it.
What is `#[repr(transparent)]`?
Thanks I‚Äôll try that!
Use the `?` operator.
Interesting! I have always wanted to try that tech stack.
`#[repr(transparent)] struct Foo(Bar);` lets you define a new type that is guaranteed to have the same ABI representation as `Bar`. It's specifically meant for FFI code. Details in [RFC 1758](http://rust-lang.github.io/rfcs/1758-repr-transparent.html).
`let response_body = Client::new().get_response()?.get_body()?;`
Modulo Windows compile problems, I‚Äôve found actix-web to be pretty good. But I‚Äôve only been using it for a day so... :)
Yea, there is no doubt that Rust is a better language. My comment was more towards the fact that for web related things, rust doesn't really have any frameworks that provide the same type of ecosystem Spring offers.
Go was built by Google, for Google. When Google built Go, they literally started with "we need a language we can build web backend stuff in". Go is _designed_ around async IO and web backend stuff. Rust is not designed around web backend stuff, and the community is still figuring out the best ways to do async IO and backend stuff in it. Uplifting anything that's currently available into the stdlib will just slow things down.
Well, it's better than nothing :)
There is an atom feed: https://rustwasm.github.io/feed.xml
Oh well seems like this is it! Thank you very much!
I had never considered frontend implementations in rust. That was probably the most interesting part.
As far as I'm concerned, async IO in Rust is solved, mio is it, done.
&gt; The more I think about it, the more I think this is a rabbit hole you don't want to get into. You could of course make a new list and check it for duplicates, but then you'd have to solve the problem of "which is the right order of renaming files to achieve this" in general, and that sounds kind of hard. On linux, you could make a temp dir, put hardlinks with the new names in there, remove the old files, and then move the hardlinks to where the old files were. But you're looking for some fun bug reports from people recursing into different file systems. No idea how that would work on windows, anyways... I need to think about it. I could also implement some kind of recursive algorithm similar to dependency solvers in package managers. However, that problem can escalate too quickly. &gt; (e) Have you thought about irregular files and what to do with them? I do not have a proper overview of what can happen and such, but you might want to investigate. I don't know what do you refer to. Currently, it only renames files and symlinks. I skip Directories and I think that Sockets, Devices, etc. cannot be renamed without needed permissions. In addition, I want to implement a flag to ignore/include `.git`, `.svn`, etc. in recursive mode.
Looking at the relevant implementations (https://github.com/rust-lang/rust/blob/master/src/libstd/sys/wasm/fs.rs , https://github.com/rust-lang/rust/blob/master/src/libstd/sys/wasm/net.rs), the answer seems to be that they don't.
According to the Page Info window in Firefox the RSS feed URL is https://rustwasm.github.io/feed.xml Looks like the twitter feed is [@rustwasm](https://twitter.com/rustwasm).
Go has exactly the same kinds of problems when things depend on c libs.
Sure, but afaik there‚Äôs far less dependency on C libs in Go. They‚Äôve reimplemented a lot of that stuff in Go directly. 
&gt; Why is Go able to provide a robust http solution If you use Go long enough, you learn that there are serious reasons to avoid the built-in HTTP library for building an HTTP server. The built-in one does a lot of memory copying, which hurts performance, and the built-in router isn't very fast either. go-fasthttp is _much_ faster than the built-in HTTP library, for instance. Take look at [these benchmarks.](https://www.techempower.com/benchmarks/#section=data-r16&amp;hw=ph&amp;test=plaintext) You'll also notice that `actix` performs well across the board. `actix` is pretty easy to use, and incredibly high performance. If you just want "super easy to use" and don't care about performance, `rouille` is good stuff. &gt; I quickly noticed that there were breaking changes between hyper 0.11 and 0.12. That's fine I guess, but already that means I'm signing myself up for a not so insignificant refactor not too far into the future from the very beginning. A good web framework will keep `hyper`'s implementation details from breaking your code, in my opinion. I haven't ever looked into Gotham too much.
&gt; Expect a blog post soon for what I mean by ‚Äúvalidity‚Äù-based vs. ‚Äúalias‚Äù-based, and for a first draft of such an ‚Äúalias‚Äù-based model. Yay, I will.
I see, thanks for the explanation!
Yeah that is true, it came up for me immediately because they haven't yet written sdl2/opengl/directx in go =) 
 let nextline = if let Some(q) = nextline { q } else { return Default::default() } Or with the [inner](https://crates.io/crates/inner) crate: let nextline = inner!(nextline, else { return Default::default() }); 
This release had pretty good performance improvements for me.
Tulip was first mentioned in the Python world in what, 2013? It then evolved to asyncio and still is only recently stable-ish. And Rust is a much newer, rapidly evolving language (both in terms of language idioms and, to a lesser extent, language features).
Huh it works for me now too. Not sure what that was about!
 loop { match self.0 {} unsupported!() } ü§î 
For me, breakage means both bug and "intended breaking change"... basically everything that causes headaches for me as user. I can recall a bunch of breakages: * introduction of a sidebar * the recent auto hiding of definitions * that markdown parser change * change in what is considered a code block and what isn't. Probably affected cargo test more than it affected cargo doc though * making the sidebar separately scrollable from main content * inter docs links breakage, connected with this recent lints breakage * various breakage in search. got fixed after some time fortunately, but it lived on on master. From a personal experience, cargo doc broke more often for me than cargo build. It feels to me that `cargo build` always has a crater run ahead of breaking changes while rustdoc just tries out stuff on master and looks for bug reports if there are any breakages.
Congrats to ralfj and good job aturon!
I would like this too. Improving discoverability would be very useful.
I'm on vacation, so /u/nasa42 did all of the work this time. Hopeful I'll return next week.
You're looking for /r/playrust
I think it is Rust plugin's fault. I have multiple large Java projects and they all work nice on the same machine. But some sometimes when the only project open is a very small Rust project is open, it just gets too slow and CPU at near üíØ
I fully agree there. Discoverability definitely needs to be improved. The main reason I feel somewhat comfortable on that front is because I've been lurking in /r/rust and taking notices since before 1.0.
Are you using MSVC or MinGW? IIRC, CLion only supports debugging Rust on the MinGW toolchain and not the MSVC one.
Btw. is the upcoming events section tracking only English language events? Because there are more Rust events in Tokyo, but they are in Japanese. I've seen only the English events end up here.
In the `wasm32-unknown-unkown` target, most of `std` returns an error (if the return type is `Result`) or panics. I sort of disagree with this design, especially since some other targets do not have `std` at all. (Crates must be `#![no_std]` and use `core` instead.) I‚Äôd prefer to have a unified design for all targets, to deal with some stuff that `std` currently assumes is provided by the operating system not necessarily being available. But admittedly it‚Äôs not obvious what that design should be, in the details.
By that logic, Python version 2.3 should have been version 1.0. After all, that was the first release to come after the initial release of the Twisted framework for event-driven I/O. I use Rust perfectly well for command-line applications, despite async I/O not being fully ready yet. I use Rust to write compiled extensions for Python, despite async I/O not being fully ready yet. Dropbox uses Rust to circumvent traditional performance/reliability trade-offs in their storage backend, despite async I/O not being fully ready yet. Mozilla is migrating Firefox internals to Rust, despite async I/O not being fully ready yet. If anything, Rust's biggest strength has nothing to do with async I/O, in that it's the first thing which has a good chance of replacing C dependencies/components with something with stronger compile-time checks. Heck, by your logic, one could also argue that Go, Node.js, and everything else with a good async I/O story also don't deserve a 1.0 moniker yet, because, unlike TypeScript and other transpile-to-JavaScript languages, they don't have first-class DOM API integration.
Well, that's a pretty clear picture of a nail. If you can reproduce this consistently, I'm sure the IntelliJ Rust team would love to see a bug report. This obviously shouldn't be happening. Just curious, what are your plugin settings? Settings &gt; Languages &amp; Frameworks &gt; Rust. The ones that are likely to be a big hit on performance are "Use cargo check to analyze code" and "Expand macros (may be slow)".
[Project Ice Puzzle](http://www.matthewmichelotti.com/games/project_ice_puzzle/) is the most polished Rust game I've seen so far. (and fun!) Nice work!
This is great news! It‚Äôs such important work that so many other languages just drop on the floor or relegate to academia, seeing Mozilla promoting and investing in it is highly encouraging.
I believe events need to be actively requested via a PR against the twir repo, I don't think that they even _could_ keep track of everything on their own.
You're probably aware of this, but in the future I think the idea is the [portability lint](https://github.com/rust-lang/rfcs/blob/master/text/1868-portability-lint.md).
This is essentially what [`interpolate_idents`](https://github.com/SkylerLipthay/interpolate_idents) was. There actually is a stable concat_idents, called [`mashup`](https://users.rust-lang.org/t/announcing-mashup-a-stable-implementation-of-concat-idents/17137) (written by the same author as `tt_call` mentioned elsewhere in this thread). 
Most of the std utilities are unimplemented when building for `wasm32-unknown-unknown`. However, the emscripten backend `wasm32-unknown-emscripten` uses emscripten-provided utilities to make a filesystem and provide networking. emscripten emulates functionalities of a normal operating system in the browser. Check out emscripten's website (https://kripken.github.io/emscripten-site/) for details, for example on how their custom filesystem works
Using the MinGW toolchain (stable-x86_64-pc-windows-gnu)
Yes you are right. most of the time I don't notice the runtime cost. Every small java service I have is allocated minimum 256mb. I have never thought of tuning because the server I use has half of its 64gb ram unused. 
Are your slides up some where?
No, I didn't keep the slides. I didn't consider them to have relevant content and didn't put any URLs or references in there.
Actix is also the fastest 
An easier way might just be to make a hashset of all the pre-renamed file names and check against that, though you might also need to pre-populate a hashset of all the resultant names, in case you have two files that rename to the same thing.
[Rustberry](https://crates.io/crates/rustberry) (my Raspberry Pi library featuring pin/subsystem ownership) had its initial release this week. I posted a discussion thread on Reddit that somehow got popular, and I was surprised to see it show up in TWiR! I'm going to keep adding features to it and maintaining it, but for now, I have a [much bigger project](https://blog.tokumei.ninja/tag/tsukurou.html) to work on.
Looks like you tried to write markdown in the new fancy pants editor - may want to fix that URL :)
A few months ago I started contributing to the `wasm-bindgen` crate and from that experience I became very interested in learning more about how compilers are built, this project is the result of that interest. The idea is that this crate will provide an entry point for building JavaScript development tools in Rust. The crate will provide a raw token stream from a String of JavaScript. I would love to have any feedback you are willing to share! 
No, my main concern was about that example that uses `quick_main` whereas now we can return `Result` from the `main`.
Originally TWiR issues used to come on Tuesdays, but sometimes it's Thursday. Anyway, have a good vacation, for sure.
The moderating is always the problem with this sort of suggestion. Everyone's too busy writing cool stuff to do that much moderation. ;-) The best list of such is probably https://github.com/rust-unofficial/awesome-rust
At the same time, many of the UaF scenarios that have been given would not necessarily be caught during code review, either.
I love you.
&lt;3
what is the `radfft` library-sounding thing they reference a few times? I don't see it on google. Some fast fourier transform thing, I guess, but it's being used on consoles, and now I'm just curious to know more.
Why did you use actix name in front? Drop actix please the name belongs to someone else 
&gt; If you can reproduce this consistently I am not sure I can reproduce it consistently. Once in a while suddenly it becomes so unusable that I can't even type. I was suspecting if was actually rust but what I saw was Intellij was using pretty much using 100% CPU. I closed other java projects just to make sure they were not causing the issue. nowadays I code in VS Code when travelling to save battery and still use IntelliJ when at home. I am away from computer but I think I have "cargo check" enabled and the other disabled.
Netty and Xnio are exceptions but the most popular and trivial apps use spring or similar stuff. Spring boot even has support for undertow but then it won't be same as the raw performance. Any performance gain by undertow would be lost quickly with spring in there. I know I am probably comparing apples to oranges. BTW I am very happy spring user. Much of my day work involves using spring. Again my intention was not to say java frameworks won't scale. What I was trying to say is that one might need to worry about scaling earlier in java than Rust. 
Small nitpick, the syntax for constants is `const JS: &amp;str = ...;`. `static` has far more niche uses and the syntax for both puts the name before the type.
Using the `cargo check` setting means that IntelliJ his running `cargo check` basically every time you save (including autosave-because-you-stopped-typing). This is done as a child process to IDEA, so CPU usage will show up as IDEA. I don't know how much that actually hangs the IDE, but it would explain the CPU utilization, especially if there was a bug that would start up multiple check instances.
Can someone please help me compile this simple program? https://play.rust-lang.org/?gist=4955c50e99b107445449d8b263efd0ff&amp;version=stable&amp;mode=de bug&amp;edition=2015 
I am an experienced systems programmer that learnt rust in January 2016 and understood all aspects of it. there a way I can get a quick 1-page list of the following since then? * new concepts * new features * new syntax I may ask again a few times to get better answers. 
How is the sidebar a breaking change?
IDK I just didn't like it.
Good question, I don't see it referenced from that user's Github account either. I just found this link dropped into a random HN thread with no other context as to its origin.
Not sure how official this is: [https://github.com/mongodb-labs/mongo-rust-driver-prototype](https://github.com/mongodb-labs/mongo-rust-driver-prototype)
https://play.rust-lang.org/?gist=4955c50e99b107445449d8b263efd0ff&amp;version=stable&amp;mode=debug&amp;edition=2015 `return` is only implicit when the expression is at the end of the function.
It's example, the online version isn't use it.
Yes right. The error message was so confusing. I should probably raise a bug?
C hasn't mapped directly to machine code level features for decades.
Here‚Äôs a direct link past all the redirects: https://rustwasm.github.io/2018/07/10/this-week-in-rust-wasm-004.html
Yeah, that‚Äôs one proposal and it‚Äôll still take a lot of design and implementation work.
Created an issue for this: https://github.com/rust-lang/rust/issues/52284 
I think your best bet is rust release change logs. Rust 2018 edition doc also has some interesting features - some of which are already in stable. https://rust-lang-nursery.github.io/edition-guide/2018/status.html 
AWS Lambda does not support Rust natively. You need a wrapper in Python, JavaScript, or Go. I think Fargate is a better option for running Rust in a serverless environment in AWS, unless you need something only available in Lambda.
I've heard of the concept of edition, what is it? 
Netty also has a lot of C++ code for its own epoll wrapper. 
But it uses more characters in code than Java, I was surprised. Nothing can be more verbose than Java, yet there it is. Nature's prank.
So do the "unsupported" macros cause a compilation failure or do they fail at runtime or what?
Whoops, thank you compiler! Shouldn't be a macro according to the source, my, mad. Must be a function somewhere with special logic, probably a panic or whatnot.
Currently "This Week in Rust 241" is still pinned which confused me a bit.
[removed]
oops, I should've done that ü§¶‚Äç‚ôÇÔ∏è Thanks üëç
Emscripten emulates a fake filesystem (and does similar things for many other system calls), but Rust's native wasm support does not. Basically using std::fs makes no sense since there's no filesystem, and std::net makes no sense since there's no native network access. Use the stdweb api's as they become available, or use your own bindings.
The author of the gist works for RAD Game Tools. It's probably part of one of their libraries
Sorry, I was saying what I said in my specific context (looking for an equivalent http module as the Go http module I was referring to, as a novice user who is not aware of discussions in the Rust community). I for one, think it is a good idea building libraries like that with a specific goal and leaving it up to other libraries to provide a whole service. But, as a novice user, I see h2 upon a google search for a http module for Rust, and it leads the crumbs to Hyper, which says "breaking changes are coming, and beware of using it". That's why I wrote what I wrote. 
I have already thought about that solution The problem I see is that it does not consider files in the filesystem that were not included to be renamed. You could have no conflicts in the hashsets but some files could conflict with other files. I don't want to overwrite files by accident! 
True, I'm guilty of being an arm chair critic who did not make meaningful contributions to effect change in this regard. But, my ask was about discoverability of stable crates/libraries that people much more versed in Rust than I am and with more vested interest than I do could contribute seamlessly. I'm not blindly complaining that networking or HTTP isn't ready yet. It might be ready across multiple projects and we don't even know it ;-) 
Sorry, but it appears that the awesome-rust list is merely a list of crates in the Rust ecosystem. It may help with finding interesting crates, but it doesnt help with the "recommendation" we're discussing here. Of course we cant come up with a single recommended library for every function that is not in stdlib, but we should think about doing so for the most common needs like http/ssh/json/csv/requests etc. 
&gt; However, that problem can escalate too quickly. It's unsolvable in general. I'm not sure how powerfull `regex`'s regexps are, but once you can use submatches, you can swap the first 2 letters of the file name, and then having both ab.txt and ba.txt will not permit any proper renaming order. You could of course think about temporary names or so.. &gt; I don't know what do you refer to. Me neither, but I had a vague feeling about pipes/sockets/devices/fifos that one might need to think about "what if". Seem you got that covered though, just wanted to point it out :)
Again, I think your opinion is completely biased: &gt; * the recent auto hiding of definitions You can change it in the settings. &gt; * that markdown parser change &gt; * change in what is considered a code block and what isn't. Probably affected cargo test more than it affected cargo doc though This is the same change, it took **3** releases to be made by default and you had a lot of warnings and stuff to help you make the migration. &gt; * introduction of a sidebar &gt; * making the sidebar separately scrollable from main content I don't see how it affects anything besides the docs navigation... It cannot be considered as a breaking change. &gt; * inter docs links breakage, connected with this recent lints breakage Only in nightly. &gt; * various breakage in search. got fixed after some time fortunately, but it lived on on master. Sorry about that, worked a lot on it and some issues passed without me notifying. But again, doc navigation, not breaking change.
Prof. D. Lemire ran his own benchmark and could not reproduce this result.
Wait, so the `-dev` package isn't actually needed to build a dependent application?
That, or (if you e.g. organize a meetup) you can ask the community team to give you access to the community calendar, from where we will copy dates, too. Or message me or /u/nasa42.
I wonder if this has something to do with Rust being a moving target? Many projects don't support very old compilers simply because there isn't much motivation and newer features can't be used.
Edited thanks. (switching back and forth to fancy pants and markdown editor is a terrible experience)
Could [dont panic](https://crates.io/crates/dont_panic) be used to make these compiler errors?
Does this overlap with https://github.com/ratel-rust/ratel-core ?
If you want to treat the errors in place instead of returning them, you could write something like: let client = Client::new(); let response = match client.get_response() { Ok(res) =&gt; res, Err(e) =&gt; { /* fix err or panic */ }, }; let response_body = match response.get_body() { // Same as above };
There's also the [if_let](https://crates.io/crates/if_chain) crate that allows writing things like ```rust if_chain! { if let Some(y) = x; if y.len() == 2; if let Some(z) = y; then { do_stuff_with(z); } } ```
Try with: pub fn get_track(id: i32, session_cookie: &amp;Cookie) -&gt; Result&lt;Track, Box&lt;Error&gt;&gt; { Alternatively, you could define an `enum` that has both error kind `a` and error kind `b` as options, and define the type conversions. But this is probably easier, and if you're doing IO anyway, that single allocation on an error path won't really hurt your performance.
`Error` is a trait and you cannot return `Trait`s directly in Rust. You can either `Box` it or return `impl Trait`. I don't think eitheir option would give you the chaining behavior you want, try using the `failure` crate. It is made to allow error chains to happen. 
Using `impl Trait` will not allow you to return different types.
Yeah, that is completely unfair. The entire premise of Rust is that humans cannot be perfect all the time. We cannot hold them up to a perfect standard. All we can do is try to focus on verifying the unsafe code (either through manual review or formal verification) making it less and less of any one project, and reuse it in more and more codebases (to decrease the percentage of total Rust code that is unsafe).
&gt;&gt; Growing complexity of the software is the real problem of our time, and Go addresses these issues the best. &gt; &gt; This is easy to see for a person looking to choose a language today. Rust comes with a lot of complexity at the beginning. I think you're confusing complexity of the language with complexity of the software developed in it here. The comment you quoted talks about complexity of software, and I would actually argue that Go is quite bad at addressing this issue, given its weak typesystem. (Yeah, I like to manage complexity via the typesystem.) Rust is more complex than Go, but that's partially *because* it gives you more tools to deal with complexity in the software you develop.
An issue with that is that it generates unnecessary costs: one of the great features of current Rust is you can *move* an Rc/Arc and incur no Rc cost when doing so. If clone were implicit, every (owned) Rc/Arc parameter would incur a clone cost even when that's completely unnecessary. I may be misremembering but I think it was /u/mistuhiko who noted (in a tweet maybe?) that through implicit moves &amp; references cloning an Rc/Arc turns out to actually be relatively rare, and as a result significantly more efficient than one could expect. An AutoClone would lose much of that, and requiring adding some sort of rc-elision optimisation pass for these smart pointers.
&gt; because [Jaguar cores] don't have any 256b wide SIMD execution, the 256b AVX ops just turn into two 128b ops each, so there's no frequency wonkiness or anything to worry about Same applies to Zen cores :) Intel's super wide SIMD really looks like a disaster with all the downclocking. [CloudFlare found out](https://blog.cloudflare.com/on-the-dangers-of-intels-frequency-scaling/) that if you use AVX-512 for TLS crypto that runs together with arbitrary web server code, the performance of that is going to suck.
The problem is that in Java, most exceptions incorrectly inherit from RuntimeException, so in practice you often need to deal with expected error cases using catch. In the process, it's *incredibly easy* to also handle other errors that you didn't want to handle there. Moreover, it's often not obvious which exceptions a function actually throws if you can't read its code (it's often undocumented). If people actually used checked exceptions "correctly" this would not be an issue but that usually isn't the case in my experience.
What do you mean by "many projects"? My comment is about bugs in rust compiler itself, not some other "projects".
Can someone explain the "punch card" code? Normally I can look and the weird code samples and more or less understand what is going on, but in this case I have no clue.
The Rust Cookbook appears to be exactly what you're looking for: https://rust-lang-nursery.github.io/rust-cookbook/. I think it hits everything you asked for except for SSH.
Without reading your code, out of curiosity, what is causing you to limit functionality to UTF-8 file paths?
&gt;potentially pernicious performance pitfalls What is this, "P for Programming"? Do we get as mask?
Looks like there is definitely some overlap, but overall different immediate goals. Thanks for pointing this crate out, I looked for something similar before I got started and I am not sure how i missed this. 
Thanks for the feedback, I did not realize this!
You could try to compile something like: let () = ..=..; That gives you an error like: | | let () = ..=..; | ^^ expected struct `std::ops::RangeToInclusive`, found () | = note: expected type `std::ops::RangeToInclusive&lt;std::ops::RangeFull&gt;` found type `()` That is because `..= x` is of type `RangeToInclusive&lt;type of x&gt;`, and `..` is of type `RangeFull`, so `..= ..` is of type `RangeToInclusive&lt;RangeFull&gt;`. Adding another `..` to the end, `..= .. ..` is the same as `..= (.. ..)` which has type `RangeToInclusive&lt;RangeTo&lt;RangeFull&gt;&gt;`. Then it is just repetitive.
Sounds like you want `map`.
This seems like it will be awesome for my `Text&lt;A&gt;` to `Text&lt;B&gt;` conversions from what it seems. It even enforces that there's only one other non-ZST field.
 enum MyError { A(ErrA), B(ErrB), } impl From&lt;ErrA&gt; for MyError { fn from(err: ErrA) -&gt; Self { MyError::A(err) } } impl From&lt;ErrB&gt; for MyError { fn from(err: ErrB) -&gt; Self { MyError::B(err) } }
&gt; This is the same change Didn't know that. Thanks. I think you are doing great work. Just shared my experiences.
That is impossible. It changes the type of all items, which is not what I need.
You can use the [`fold`](https://docs.rs/futures/0.1.22/futures/stream/trait.Stream.html#method.fold) method to do this. e.g. to sum all the items in a stream you can use fold like so: `iter_ok(0..n).fold(0, |total, n| total + n)` The result from the closure will be fed to the next invocation as \`total\`.
Then I guess you want `fold`.
Indeed, this is exactly what I needed. Thanks!
No, this is not correct. It is NEVER legal to write to something that another thread has an "active" mutable reference to. \`UnsafeCell\` allows you to \*write to a shared reference\*, but it has no effect at all when it comes to mutable references.
&gt; or return impl Trait. That bit is incorrect, semantically `impl Trait` is replaced by the concrete type during compilation (sort-of like `&lt;T&gt; fn(a: T)`), so you won't be able to return different types in the same way `&lt;T&gt; fn(a: T, b: T)` requires that a and b have the same *concrete* type.
&gt; , but today is limited in scope while we get it bootstrapped and work on the presentation. So I'm assuming we should hold of discussions of alternative crates atm?
You should ping on IRC/discord, or open an issue on github if you have any breaking change. Generally, they're absolutely not intended and are bugs. Lately, I focused on added tests a bit everywhere to reduce them as much as possible.
The full change log is [https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-160-2016-01-21]. I've tagged the release before Jan 2016 so everything above it is the full change log since you last learnt Rust. I guess looking at the `Language` section of the change log would be what you want. A quick list here: * `#[no_std]` * Empty Structs. So something like `struct Foo;` * `#[repr(...)]` * `?` * proc macros and custom `#[derive(...)]` * `loop` can return a value from `break` * C compatible `union`s * Associated constants * `impl Trait` * `main` can return `Result&lt;T, E&gt;` * Pattern matching will automatically apply dereferencing * `dyn Trait` This is a **very** short and skimmed list of features that is language only, the libraries (`std`, `core`, `alloc`) all got loads of changes as well.
If it involves networking I would honestly say maybe wait. I did a project at work in rust over the past 2 weeks that did a whole bunch of Async networking and while it was possible, a whole bunch of things were unpleasant. Even aside from the ecosystem changes you‚Äôd need to brace yourself for, there‚Äôs also just the fact that writing Async code with Async/await syntax is going to be significantly more ergonomic. If it doesn‚Äôt involve networking - or it doesn‚Äôt involve much networking - or you‚Äôre willing to do core logic in rust and do your networking in a different language via ffi - or ... - then yeah go for it and use rust now. It‚Äôs still an awesome language with a lot of nice features, this is just an area that‚Äôs still being worked on. 
Thanks, I was sort of ignoring AWS' container support because it was missing a bunch of stuff I thought was critical to make it worth looking at. Looks like Fargate might address most of those missing features and I hadn't seen anything about it yet. It gets harder to keep up with the new stuff they are adding every month at this point.
Glad the hint is valuable to you. I don't know where i've got this from. I had this in my knowledge graph for some time.
I did a small personal project 2 weeks ago with hyper and gotham. And I would recommend you not start any big projects right now. As you pointed out everything is kind of in flux right now. Which I did also get to experience first hand with my project. I started out with writing code for latest hyper crate, but then had to downgrade as gotham hadn't upgraded yet. I got my project working in the end, but I am very reluctant on adding new features to it currently as it would mean more code to migrate later.
I'm building a futures supervisor library, and wanted to add exponential backoff for the retries. I couldn't find a library that only provided the timeout durations, so I figured I'd write one. Hope it comes in useful!
Yeah most of the stuff I'm interested in involves a significant amount of networking. Ah well, I'll wait a while longer.
My guess would be its a lib for the [radix FFT algorithm](https://en.wikipedia.org/wiki/Split-radix_FFT_algorithm)
I think it would be a cool experience to work for Mozilla full time. I'm definitely going to have to apply for when I graduate in May
One should just use error chain instead.
Yeah, even better.
My plan is to continue working with futures 0.1 until async/await arrives on stable for projects that I want to finish now. You can work on and complete projects using futures 0.1. AFAIK futures 0.1 isn't going to stop working when async/await arrives. After it arrives, I'll switch to async/await for new projects. If I have to do some maintenance and time permits, I'll go back to the old projects and update them to async/await. I do have one project that won't be finished this year so I'm saving the async parts for last but if I get to that code before async/await arrives I'll probably use whatever's currently on nightly.
I assumed some other synchronization is happening, since two threads writing to the same memory is an obvious race. But yeah, I shouldn't assume things. My comment was mostly focused on necessity of UnsafeCell, since it's easy to miss that.
Do you absolutely need asynchronous networking? The synchronous/threaded networking story is pretty good already, and plenty fast/lightweight enough for most uses.
Did you remember to clone your Arc inside your thread? Also a Mutex is not necessary since your thing is immutable.
Have you looked into using the failure crate?
https://docs.rs/backoff/0.1.2/backoff/backoff/trait.Backoff.html
I typically use Rocket to make JSON APIs and if you are going for simplicity I recommend it. If we stabilized something from the crate ecosystem now, it might just be bad forever. We have standardized on things like serde and rand, which remain third-party, and I think are good and idiomatic third party crates. I think these things will get worked out over time faster and end up better in the third-party space. Futures was able to get figured out outside of stdlib and I think the conclusion is an incredibly powerful abstraction I think would be good to stabilize on at this point after some people use it for a while. Futures need to be in stdlib tho (due to async/await) while web things are better outside of the stdlib where they avoid bloating the stdlib and can move faster and prototype faster. Rust is a unique language and it isn't as if everyone has got everything totally figured out as to how things should be abstracted in it using its powerful type system. Now I will say, hyper is already our third-party "stdlib" for http. Once futures comes down into stdlib and it stabilizes, things will improve.
Example: https://play.rust-lang.org/?gist=6737acf6b5e09ce4d459083ed8e2f1d9&amp;version=stable&amp;mode=debug&amp;edition=2015
I think that most of what I want to work on will benefit from being asynchronous but you make a good point, it's easy to just assume that one should be using asynchronous networking without evaluating whether it's actually necessary, will re-examine that assumption and see if it holds for everything I want to do.
The first reason is just simplicity. I prefer just using validated String/&amp;str instead of OsString/OsStr or other storage methods. Also, I think that follow/promote/force the UNICODE standard is not a bad decision nowadays. PS: Thanks for your awesome crates, I am using `regex` and `walkdir`. Your code (ripgrep, etc.) is a great learning source too!
FWIW, even without async/await built-in language syntax, there are `#[async]` and `await!` macros that you can currently already use - they are just not as ergonomic as async/await. So I would also weight in on whether your project can wait, how long, and on whether you would be willing to invest time in a couple of months to move from the async/await library features to the language features (and updating your dependencies accordingly). I mean, people have gotten a lot async networking done just using futures without any kind of async/await library/language feature. Sure, async/await makes things (a lot) nicer, but it is always possible to find some feature that Rust does not have right now and say "I'll wait". Often (not always), it is better to just start using it, and adapt, than to wait. So I'll weight all of that in your decision.
Thanks for sharing! It's close, but doesn't quite do what I want it to do. The main difference [from the usage examples](https://github.com/ihrwein/backoff#permanent-errors) is in the way errors are handled. `exponential-backoff` doesn't have any opinions about error handling, where `backoff` uses closures and comes with more constraints on how errors can be handled. In the end I wanted `exponential-backoff` to be optimized for integrating in other libraries, and I think it should be pretty good at that!
Networking as in you need a http server, client or lower level tcp/ud
Why not actix web. That seems to be the popular way to go atm.
Thanks for the kind words! I think the key problem you'll face with the insistence on UTF-8 is that people will invariably have file paths that don't contain valid UTF-8. Indeed, they might even want to use your tool to fix the fact that some file paths don't contain valid UTF-8. :-) In any case, I actually started ripgrep with the UTF-8 assumption as well, but the bug reports quickly accrued and I capitulated! Either way, I was mostly just curious to see what your roadblocks were. The lack of ergonomics for OsStr is definitely a valid answer. I believe an RFC was recently accepted that will add more standard string searching methods to OsStr that should hopefully make cases like this easier to swallow.
Thank you! I appreciate your marking the release for me, I will take a look. And also thanks for the skimmed list, I get the sense that nothing major has changed that I have to spend time learning. I will go through the release logs. 
This could be a check while populating target names before they are executed, but indeed it's tricky and there could be some odd edge case where things might go awry. Good luck!
Gotham looked more like the right tool for my needs. 
Idea is very snappy for me, been using it for upward of 5 years now, I do give it an ssd and 6 gb of memory. I just find this plugin to be really slow, idea is very responsive for me for java, Scala, Python, go. Of course my anecdotes are not data and all that.
I work with yocto at work and actually managed to write a small script in rust as a test and it ran wonderfully. Unfortunately when my new manager tried to run it llvm failed to build on his computer (using meta-rust built rust and llvm). Since the script was so small and we wanted to change it's functionality anyways, it was easier in his mind to just replace the rust code than to fix the build on his machine. That being said, I was super impressed with how well the build process worked for me (props to meta-rust!). Hopefully I can solve that problem in the future because Rust feels like a perfect fit for yocto.
&gt; Should I wait for async/await syntax? You should **await** for it. (Sorry.)
Sounds like the start to an awesome project. I'm excited to see more updates!
I'm not involved in cookbook development right now, but maybe you should open an issue.
Really cool! Do you plan to use RTFM? 
You can also just use blocking IO for now -- if it's not highly performance critical, with a bottleneck in IO, it'll be fine and much nicer to work with until async/await arrive. 
If you want to write some network services, and you want the benefits of using Rust, I'd start now. The tools are already there to allow you to be successful. You get a much more performant service than if written in most other languages. You get the "fearless refactoring", such that you don't have to worry if you forgot to change something somewhere when you refactor an idea. For instance, [conduit.io](https://conduit.io) (soon-to-be Linkerd 2) uses Rust to have a safe yet fast proxy. Writing asynchronous Rust today is similar to writing JavaScript Promises a couple years ago, before it got async/await. Some people becry that to be the work of the devil, but tons others just got work done. You won't be learning wasteful concepts. Understanding how futures and executors work will help you even when async/await lands in Rust. If you rather wait, you'll be waiting a while. It *might* stabilize at the end of the year, but i think it's more reasonable to think a year from now.
Awesome! A while back, I managed to replace a couple of simple functions in Betaflight with Rust, but was too chicken to actually do a test flight with it :P I'd love to see a full flight controller firmware in pure Rust someday!
Wait, can't you just use thing directly in t2 or you actually have to keep the original?
To be clear I'm very enthusiastic about rust and I've written a few smaller bits and bobs in it so I'm quite familiar with the language. My worry is more that I'll write a whole bunch of code and then immediately have to change it when the async/await and Tokio stuff stabilizes. What you're saying about the \`\[async\]\` and \`await!\` macros is interesting though. I'll have a look into them and see if it makes sense to just start development. I think for work it's probably still a little risky but for personal projects maybe I'll just go ahead. It's not like I ever actually complete side projects anyway üòÇ
[failure](https://github.com/rust-lang-nursery/failure) is the new trend
You could, but then you don't have access to thing anymore in the main thread.
`await!(rfc2394());`
With some basic experience in mind, does the community have some good references to embedded Rust in stuff like RPis and Arduinos? Something oriented towards networking would be great!
Btw I always wondered why can't you just call thing.clone()? Since it's an instance of arc anyway so it calls Arc::clone.
You could use one of the coroutine libraries, they can help you to write async code that looks to be synchronous. If you separate the network related stuff from the business logic then you won't have to change too much if/when you switch to async/await.
I managed to get RLS to work intermittently, and with very basic features on a couple of small projects. I found these projects were small enough for the Intellij Rust plugin and there were so many features. For large projects (eg I was using actix-web) both are too slow to be usable - IntelliJ works as an editor but only the occasional autocomplete etc. RLS for some reason gets stuck trying to analyse the code and it makes VS Code unusable as it uses so much CPU. The current Rust IDE experience is still really poor.
You can "pretend" to write some C code if you want to show [working FFI examples in the playground](https://play.rust-lang.org/?gist=f9b24aad43b58e4d8b0cfdd79f7c7391&amp;version=stable&amp;mode=debug&amp;edition=2015).
Yes, but explicitly call Arc::clone is the best practice, since `.clone` can look expensive. 
Rust is not a great language for async programming right now. You'll be fighting with both the type and the ownership system. It's not comparable to what happened in JavaScript or what is currently going on in Java. Both of those languages could benefit from being GC:ed which deals with memory management across operations much more gracefully. They also have a much simpler type system with promises/futures. Then there is the looming ecosystem shift you hinted at. It's almost guaranteed that there will be one or two migrations within the next year, not all components you use will be in sync. This just doesn't work for my projects at least. When I'm working on something I don't want to spend too much effort on tangential things. But if you are willing to experiment and learn about the plumbing of async Rust I'd go for it. Keep the scope down, and your expectations reasonable.
Can you give us a link to this research?
https://docs.rs/tokio-retry/0.2.0/tokio_retry/strategy/struct.ExponentialBackoff.html no?
That's the biggest thing holding me back from starting with rust for now.
It doesn't seem like it has any (configurable) jitter implemented, which is pretty important to prevent accidental DDOSes from occuring.
https://docs.rs/tokio-retry/0.2.0/tokio_retry/strategy/fn.jitter.html Retry accepts Iterator&lt;Item = Duration&gt; so I guess you use it like ExponentialBackoff(..).map(jitter(...))
There is a typo in your first screenshot. https://github.com/ChuckDaniels87/rnr/blob/800c7ac92b91294c53ee3854464846cc11e26b82/src/renamer.rs#L45 `s/accesible/accessible` 
I need to think about file checking order and also how to avoid some performance pitfalls in the accessing file system/checking iterations. I believe that I will need to find a robust design even if it falls on the conservative side of the problem. I prefer having false positives than to overwrite wrong files. I'd do my best to solve it, thanks for the discussion!!
What do you mean by "non-blocking" exactly? Unless you have separate mutexes for your methods, or you're using atomics or some other fancy lock-free concurrency constructus, one thread will always block while the other is doing its thing. That's assuming that neither method requires `mut` and that your type is `Sync`. If both work on `&amp;self`, then you shouldn't need locks at all, or maybe just an `RwLock` if you have `&amp;mut self` methods elsewhere. Perhaps you meant non-deadlocking?
Right now feels like a particularly sore moment due to the absence of tokio support for the latest futures developments on nightly. Even for people like me who live on nightly, one must wait until the ecosystem catches up to begin experimentation in earnest.
In that case I should be using that.
I personally wouldn't try async/await in a product I hope to ship. It's very much in a "does this way work out" stage. I'd say try it out only for the sole purpose of offering feedback on it's design, if you have the time.
Our approaches diverge here. In `exponential-backoff` jitter is expressed as a factor between `0%-100%`. With a jitter factor of `0.3`, a duration of 1 second will move to the range `[0.7 - 1.3]`. It seems `tokio-retry`'s jitter is set to be random, and cannot be configured ([src](https://docs.rs/tokio-retry/0.2.0/src/tokio_retry/strategy/jitter.rs.html#12)). It also makes use of [rand::random()](https://docs.rs/rand/0.5.4/rand/fn.random.html) instead of caching the generator for subsequent uses. For me `tokio-retry` is different enough that it wouldn't work for what I'm trying to build.
&gt; Indeed, they might even want to use your tool to fix the fact that some file paths don't contain valid UTF-8. That is actually a strong reason to use non-valid UTF-8 strings. I should rethink this issue. I am not sure if it is better to create a "non-valid UTF-8 mode" switch to handle this situation or directly change all Strings to OsStrings. I suppose the current issue you refer to is [this one](https://github.com/rust-lang/rust/issues/49802). Thanks!!
One can also use the `enum_derive` crate to automatically derive that From https://docs.rs/enum_derive/0.1.7/enum_derive/
Fair point. The pros and cons have to be weighed though. If its a really large codebase and they got stuck on an older hyper and futures implementation, its possible there could be some extensive and costly refactoring that might just never get done (to support async await). Then again, maybe writing the equivalent code in an alternative will lead to just as much maintinence burden for other reasons and still underperform. I think it depends on the size and performance criticality of the project.
&gt; It also makes use of rand::random() instead of caching the generator for subsequent uses. It doesn‚Äôt matter, as the generator is already thread-local.
Thanks!!
It's nothing special at all, it just [returns an Err](https://github.com/rust-lang/rust/blob/5430c0c5c0fbdfb8e89358a187d2f9a8d4b796d4/src/libstd/sys/wasm/mod.rs#L61-L63)
Probably not since what that crate really does is turn a panic into a linker error, which is a bit mysterious to people who don't know what's going on.
Cool project! I'd like to follow along (reading, not building my own). I hope you'll post here the next articles in the series.
Definitely did not expect Rust full stack to come so quickly, with RustX no less!
I've created an issue for this, thank you for the call out. https://github.com/rust-lang-nursery/rust-cookbook/issues/433
I haven't but I'll definitely have a look at it ~~in the future~~ right now.
I would do my best to keep one mode, in order to keep things simple. On Unix, an `OsStr` can be converted to a `&amp;[u8]` at zero cost. At that point, you can use the regex crate's `bytes` module to match. Windows is where it gets thorny. You can't get a `&amp;[u8]` at zero cost. Instead, what I typically do is [lossily convert it to a `Cow&lt;str&gt;`](https://doc.rust-lang.org/std/ffi/struct.OsStr.html#method.to_string_lossy). In most cases, this only costs a UTF-8 check with no additional allocation, so it's not a total loss. Moreover, this sort of thing is already happening in Windows (between it needs to transcode to/from UTF-16 at the boundaries), so you're at most adding a constant additional cost to the execution of your program.
Mabe his/her machine was 32bit? Meta-rust readme says that it currently only works with x86\_64 host (don't know the details why). I haven't used Rust for any real work projects (just in my free time and some evaluation at work) but I think it would be a really good choice for embedded development especially with Yocto.
However, the generator itself is recreated on each call instead of being cached. It's not a huge performance problem, but it will show up when run in a tight loop. See [rand#289](https://github.com/rust-lang-nursery/rand/issues/289) for more on the topic.
Also, Zen has 4x128b units, so it can achieve quite some throughput. A downside of the Zen SIMD units is that they can't do FMA on their own, though. Two units have to be combined, which reduces the throughput for FMA heavy code.
https://github.com/r-darwish/topgrade
&gt; An AutoClone would lose much of that, and requiring adding some sort of rc-elision optimisation pass for these smart pointers. I don't believe this applies to rust in the same as C++. Because Rust has affine types (this doesn't change that -- its just sugar), the compiler can and does already know about a single use site and can choose to move. The thing that would be absent is that you would not get a warning/error if the compiler changes from move to clone semantics for second use in a function body. I can see the value of having a warning in some situations, but the majority of the time when I'm working with Arc or Rc I try to move or use refs first, then sprinkle clones where the compiler complains. This seems to just cut out the middleman.
You can. It's just convention to call `Arc::clone(&amp;thing)` instead since it clarifies that you're cloning the `Arc` and not whatever type is contained within it.
Thank you for the information. I have already used `to_string_lossy` in the file list retrieval, but `bytes` module will be definitely useful to manipulate non-valid strings. I will take a deeper look at your implementation and I will investigate more about Windows issues. Sadly, I don't have any Windows system to test my code, but I suppose that I can write some tests to be run in a CI/CD system.
Hey I was wondering if you have hit some problems with compilation time? 
With all due respect, I have seen a dichotomy between how the tokio/hyper maintainers view the latest futures/async/await work and how the rust team views it. I don't know if the people actually working on the development of async/await would say it's "very much in a 'does this way work out' stage".
&gt; This just doesn't work for my projects at least. I hope you're not giving up on `reproto`. I still think it's a cool project, and an impressive amount of work already. Rust's async programming story will definitely be in flux for the next several months. Rust 1.29 is supposed to land `async/await` on stable based on the schedules that I've seen, although it's an open question of whether the work will get done in time.
well there's really two parts two it - the concept as known to the compiler, and editions as a branding push. ## editions, as known to the compiler * editions are a flag set in a crates Cargo.toml. edition = "2018" * editions can only do three things: * turn existing warnings into hard errors * turn existing warn-by-default lints into deny-by-default lints * add new warn-by-default lints "core rust" (basically mir + the core trait system) stays the same no matter what edition the crate is compiled under, and a project can use multiple crates from many different editions at once without conflict. most new features will continue to work on every edition, only things that require breaking changes will be restricted to newer editions. for example, async fn unambigous in item form: async fn foo() -&gt; i32 { 3 } but async blocks let future = async { 3 }; are not, as you can define a `struct async { ... }` in rust 2015. Thus, the compiler thinks an async block is a struct constructor expression abd won't compile. in "rust 2018 mode" async is a reserved word, so asnyc blocks work as they are expected. rather than issue a breaking change for every version of rust, editions make this change opt in, so you could decide to use async blocks or asnyc as an identifier on a crate by crate basis depending on your needs. it's a useful feature! ## editions, as a branding push Rust is a constantly evolving language. having releases every 6 weeks can let features stabilise without much fanfare, and people who don't keep up with rust every week can often miss whats new. in this case, the edition serves as a "rallying point" for language features to showcase all the new things and changes over the past year or so, for people who might not have checked out rust since the original 1.0 announcement. The majority of new features do not require the edition 2018 flag, but the edition 2018 compiler flag does enable lints to encourage new styles of writing code (like dyn Trait and underscore lifetimes) that weren't possible before. 
This is supposed to be a good introduction to the more spiny parts of the language: http://cglab.ca/~abeinges/blah/too-many-lists/book/.
Ah, haven't given up. I am in the process of switching jobs and will be having a well-deserved vacation, so less time to work on projects right now. reproto doesn't depend on asynchronous programming. Thanks for the shout out though :).
With non-blocking I meant \`thing\` should be available to both threads in parallel. Also it should be mutable. Maybe I have a solution with Arc and Mutex, I have to test it tomorrow. Thank you for your help!
This looks good, thanks!
Rust 2018 is targeted for the end of October. If you start working with Rust daily, learning bit by bit, you *might* be well positioned to actually use async/await. If on the other hand you were to wait until end of October, you'll be that less prepared to benefit. 
Maybe I am on the right path now. My next Problem: Both threads loop, they both should have access to the same object. Now it's like this: ```rust let thing = Arc::new( Mutex::new( Something::new() ) ); let thing_clone_1 = Arc::clone(&amp;thing); let t1 = thread::spawn(move || loop { let shared = thing_clone_1.lock(); shared.do_something(); }); let thing_clone_2 = Arc::clone(&amp;thing); let t2 = thread::spawn(move || loop { let shared = thing_clone_2.lock(); shared.do_something_selse(); }); ); t1.join(); t2.join(); ``` Probably because of the `.lock()` in the first thread and loop the mutex is locked for the second thread - it never passes `thing_clone_2.lock();`. Is there a solution for this? Thank you for your help!
Yea, and I'm not trying to be argumentative. I definitely do have reservations about the new design. But it definitely is still an experiment. There is a ton of rough edges and unresolved questions. I'm confident it will smooth out eventually.
What you're saying is like this as far as I can tell. You want a type `T&lt;U&gt;`, which currently isn't possible in Rust without HKT, but say if it was: &gt; accessible length Unfortunately `len` is not a trait in `std` so you need to define your own. &gt; has to be indexable (and mutable) Indexing by `usize` here `T: IndexMut&lt;usize, Output=U&gt;` &gt; contents has to be comparable `U: PartialOrd` should do. Apart from using traits, a slightly hacky solution and not recommended, using `DerefMut` would look like this: fn sort&lt;U: PartialOrd&gt;(lst: impl DerefMut&lt;Target = Vec&lt;U&gt;&gt;) { let v: &amp;mut Vec&lt;U&gt; = *lst; // stuff } I think a slice is probably a better target for `Deref` but I'm on mobile and I'm not sure how the syntax would look for that.
Does anyone have experience putting the contents of a csv data file into a ndarray or any matrix library type. I have been having issues with specifically the csv::stringRecord type. My first attempt and Idea was to put all the items from the StringRecord into a vector. Creating the ndarray from\_vec and shaping it into the matrix i want. I have had no success so far. I am pretty new to rust lang. 
You might be interested in Swift, since Apple has released their async library. [https://github.com/apple/swift-nio](https://github.com/apple/swift-nio) It seems quite complete.
Yes, sure. You just have to define your own trait to get length. [Code on playground](https://play.rust-lang.org/?gist=74a88121446629881e26b236ff927a65&amp;version=stable&amp;mode=debug&amp;edition=2015) Also, you need some way to move items around. You can't take mutable references to two distinct items, because indexing mutably borrows the whole container. I can think of two non-`unsafe` ways around this: first one is to clone items (which I did in my example), and the second is to have another trait to allow swapping items around. 
If there's a mutex, things inside it aren't going to run in parallel. Concurrently, yes, but if your mutex is locked in one thread, it's going to block all of the others that need access to it. Everything that doesn't need the mutex to be locked can run in parallel, however, so it's generally advisable to do as much of your work outside of the "critical section" as possible.
I see, thanks for the explanation. I'll maybe use channels and split it into two structs then. 
With all other things being equal, non-blocking IO and performance end up going hand in hand at certain scale. Go baked in the non-blocking part, Rust didn't. Try any rust-implemented ToDo backend and see how it compares, I guarantee you'll be surprised at the results. Todo-Backend https://www.todobackend.com 
I'm just gonna leave this here, Todo-Backend https://www.todobackend.com 
Yes. Don't use Rust for async I/O now. Dealing with breaking changes is very time consuming.
You're looking for /r/playrust.
This always amuses me and I don't know why.
You shouldn‚Äôt return `std::error::Error` but a type dedicated to that function / group of functions allowed to fail with both `a` and `b`. You can then use something like: ``` do_a().map_err(YourError::FailWithA)?; do_b().map_err(YourError::FailWithB)?; ``` Free to you to use `error-chain` or `failures` for all the code to write around that but I tend to think those are pretty unneeded and will make you spend a lot of time loose-coupling your code to an _error framework_, which is a mistake to me (disclaimer: personal opinion here), especially if it implies using a lot of macros.
[Oh dear]()https://i.pinimg.com/originals/0d/79/ce/0d79cee7543b80dfaf8e559a1b9c3420.jpg.
Do people just not read any other post titles when they come here to post?
I'd personally probably go for Go right now. It has a primitive type system but it's pretty great for high concurrency network applications. The amount of projects in this space being written in Go for the last few years is a good indicator for that.
I think you can post to a subreddit from the main page without ever going to the subreddit. I've always assumed that's what's happening. 
SSD and relatively fast quad core + CPU are essential, then IDEA itself is plenty fast. Autocompletion does become very slow with big delays on larger projects for me though. But it generally does not block typing or the regular UI.
I also recently tried VS Code + RLS again after the "nearing 1.0" RLS announcement. I had really high hopes but was sorely disappointed. It still crashed regularily, was really slow and had very poor auto completion results compared to IDEA.
Oh man... thanks haha, I'll leave this here for the lols
&gt; two parts **to** it FTFY. :)
[removed]
[removed]
As /u/Cetra3 said, a `std::iter::Map` is actually an `Iterator` implementation that wraps other `Iterator`s. A `BTreeMap` is a tree-based implementation of the basic in-memory key-value store, AKA map AKA dictionary AKA associative arrays. :) The essential reason is that `std::iter::Map` makes a recursive type is that it does NOT use pointer indirection, while `BTreeMap` uses heap allocation and thus indirection. The Rust compiler isn't smart enough to know you meant something semantically different though!
I was about to jump in here and give similar information. Great explanation!
After seeing what the Python netlink library can do, I've been yearning for a Rust implementation. I'm super stoked you're building this! Thanks so much for all the work you're investing! :D
Because println is a macro it can match on the case where it doesn't need arguments (string literal) and handle that differently. I believe the macro source does this, but I don't know what it changes (the formatting stuff is an internal compiler extension). So, the macro can do both, and it can do so just as if it were a function in the case of a static string literal.
Very cool, TIL about netlink. Is this more efficient than using sockets that loop back to the host machine?
By that logic, you shouldn't bother learning Rust at all because any exercise you can do in Rust you can also do in Java. Pay less attention to whether or not you have implemented some algorithms before....and how to implement those algorithms in Rust. 
This is great! I have a use case for this and was considering an implementation calling the ip tool directly, this is much better. I'm hoping to use this in the near future.
Having netlink crates is really great, its not exactly nicest thing to do manually. But did you seriously name your crate iproute2? I understand that accidental name collisions happen, but intentionally grabbing existing projects name can be seen bit hostile. And yes sorry bikeshedding naming is really annoying
&gt; But did you seriously name your crate iproute2? Yeah. Lack of inspiration, and I did not want to spend too much time on naming. This crate was supposed to provide to the rust ecosystem something similar to what the `ip` command provides, that's why I named it after it. &gt; intentionally grabbing existing projects name can be seen bit hostile. I did not think of that, and I think you're right. I'll change the name. I anyone has idea, they are welcome :)
&gt; I'm super stoked you're building this! Thanks so much for all the work you're investing! :D Thank you :D By making this announce I also wanted to check if this is something the community would like to have so I'm glad you're enthusiastic about it. &gt; After seeing what the Python netlink library can do, I've been yearning for a Rust implementation. That's funny, I started working on that precisely after I had to use `pyroute2` at work. It has been my main resource/inspiration.
What is your use case? Feel free to open feature requests on github, I'll try to work in priority on what people would like to use.
I'm sorry, I don't really understand the question. What do you mean by sockets that loop back to the host machine?
Pretty sure it is. I worked with giant java projects in IDEA it was flying. 
Oh, I'm sorry. I'm not super familiar with network stuff other than one systems class, apologies if I get terminology wrong. The only time I've done inter-process communication would be between a server side language and an SQL server, where if I understand correctly, the SQL server opens a port, and the script on the server connects to that port, and they communicate from there. Something like [this](https://screenshotscdn.firefoxusercontent.com/images/4e9c5116-4b5d-4f9d-944e-4d99251860f7.png) (sorry for the bad drawing) Is the purpose of netlink to make communication like this better?
Just a note: It wasn't until the "References &amp; Borrowing" section in part 2 that I realized that the partial arcs were supposed to be arms, rather than just more variations on children's building blocks in a pile. (When I was little, I had rectangular, triangular, cylindrical, and arch-shaped wooden building blocks.)
In your example, the php or nodejs process communicates with an SQL process on a remote host via TCP (or UDP maybe). The SQL process opened a TCP socket and started waiting for incoming connections on port 6543. The php or nodejs process that wants to query the database opens a TCP socket and connects to the remote socket. Fundamentally, netlink is not _that_ different: processes communicate via sockets. But netlink does not allow remote communications: the two processes must be on the same host. This allows the protocol to be _much_ simpler than TCP, and more efficient. For example a TCP packet must be encapsulated into an IP packet, which itself is encapsulated into an Ethernet frame, and all these layers need to be encoded/decoded on both ends. In theory a process could communicate with the kernel over TCP or UDP, but why pay the price of the whole IP stack, when you don't need remote communications?
I haven't played with RTFM at all yet, but I'd be open to going in that direction if it turns out to be necessary. 
While I personally don‚Äôt have a use case for this, I think this is super cool, and you are super cool for making it. üòé
tcp to localhost.
A cool thing you can use netlink for is to emulate different network conditions like you would using `tc(1)` https://en.m.wikipedia.org/wiki/Tc_(Linux). This allows you to tweak all sorts of fun knobs such as packet loss, latency, and packet ordering! ‚ú®
**Tc (Linux)** tc (traffic control) is the user-space utility program used to configure the Linux kernel packet scheduler. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Coming from other languages I find the fact that traits can be implemented for references to a Struct somewhat surprising. However, after reading through lots of Rust tutorials and books, I don't really see this aspect of the language described anywhere. Have I missed it? Is there somewhere that explains the rationale for why there exists all four (am I missing any?): impl MyTrait for Box&lt;MyStruct&gt; impl &lt;'a&gt; MyTrait for &amp;'a mut MyStruct impl &lt;'a&gt; MyTrait for &amp;'a MyStruct impl MyTrait for MyStruct Why doesn't Rust just infer from the functions in the trait what kind of references can support the trait? I have an example of my confusion: struct Foo { a: u32, } trait T { fn inc(&amp;mut self); } impl&lt;'a&gt; T for &amp;'a mut Foo { fn inc(&amp;mut self) { self.a += 1; } } fn main() -&gt; () { let mut f = Foo { a: 5 }; let b = &amp;mut f; // error[E0596]: cannot borrow immutable local variable `b` as mutable b.inc(); } My intuition is that there are two axis of mutability. The reference can be mutable in that it can be reassigned, then the second axis being whether the struct referred to is mutable or not. Here the struct is mutable, so I don't understand why I can't call .inc() If I change the line to (\*b).inc(); I get a more helpful error. If I impl T for Foo {} instead of &amp;'a mut Foo, then suddenly the code starts working. Why wasn't it enough to have the trait implemented for the mutable reference since that is what I had. Thanks!
I had this done to me in real life. "Yeah I've been developing a new idea for a thing in rust." "Oh, in lua?" "No . . . rust." "Doesn't rust use lua as a scripting language?"
[removed]
Yeah that would be nice to support. The `tc` cli is not particularly user-friendly imo.
https://japaric.github.io/discovery/ is great, though you might not have the board it talks about (~$15).
I have a very dumb question, but I still can't figure it out and my Google Fu skills have failed me. How can I share an immutable, read-only variable between threads? clone() isn't an option because the library I'm using doesn't implement that on the struct I'm trying to share.
I'm going to need to read more in-depth on this when I have more time, but, my first thought it is highly inaccurate. I think the author has done his best to understand what is going on with Rust, but, has failed to do so accurately. It would've been good if he had sought feedback before publishing. For example, the size of the stack is not known at compile time. The size of a "stack frame" can be known at compile time, but, not the entire stack. I'll have more to say about this when I have some more time.
Very interested in netlink audit. Thank you for working on this.
&gt; actix-web if going with the actix actor system I'm not sure any web framework has really won yet, or any of them is truly mature. It has been less than a month since Actix started cleaning up its unsound `unsafe`s, some `unsafe`s are still not really reviewed (not even mentioning potentially panicking safe code), no API stability guarantees (it's still 0.x.x not 1.x.x), documentation could be improved... I could go on. Sure, actix-web is exciting and everything, but it is not a mature web framework yet.
This was very helpful, thank you. 
I think your getting started example could use some improvements. Since your API is based around providing an iterator, any code using it will also have to handle the case where the loop was never run. It seems like you can fix that and eliminate a lot of boilerplate by providing a more ergonomic API: impl Backoff { fn run&lt;F, T, E&gt;(mut self, f: F) -&gt; Result&lt;T, E&gt; where F: FnMut() -&gt; Result&lt;T, E&gt;, { let mut result = f(); while let (Err(_), Some(duration)) = (result, self.next()) { thread::sleep(duration); result = f(); } result } }
Curious to know team size and how much dev time this took? Amazing work!
I‚Äôm not sure what dichotomy you are talking about. We are ready to spend time looking into the Async / await developments and spend time integrating them, but we have not gotten that signal from the futures group. The initial release of Async / await is going to be an mvp. It will be lacking features needed to build only using Async / await. It will also take time to invent idioms and patterns to replace those used using futures directly. All this will take a bunch of time. Tokio is being used today to build real products. I must weigh that with jumping in the latest and greatest. It will have to be an incremental transition. I also can‚Äôt persobally devote the amount of time needed to track a moving target, so there will have to be some level of stability before I jump in. 
So when they validate and refactor you have to actually use another thing? Why not just impl From and be happy? Sure the stack trace is nice, but if Failure can generate it why can't you do it inside From? I wanted to do it but never went to look how Failure does it.
Interesting, thanks for the link!
Edition 2018: 2 Parts 2 It
Thank you. I was just wanting this functionality and `backoff` would not work for me because of the error handling. I plan to use your crate!
&gt; It seems like when using a string literal, Rust will copy the value of that string into another variable, but when we use a String type, it moves the value instead. To clarify this a bit, the only thing that gets copied with string literals is the pointer to the text- not the text itself. This is possible because the text itself is stored outside of the stack *or* heap, and lives "forever." So string literals aren't copyable because their size is known at compile time, but because nobody has to own the text, the way a `String` object must. However, things *could* work the way the post describes, copying the entire text of a string literal around. This is how array literals work (so that might be a better example for this series). The downside is that requires literals of different lengths to have different types.
Put it inside an `Arc`, and clone that.
We've been discussing some of the misconceptions here: https://users.rust-lang.org/t/the-copy-trait-what-does-it-actually-copy/18730
I wish that when an issue was finally merged, someone could provide a summary of what the end result of the discussion was, because I see people talking about changing feature gates and such, but to find out what the end result is, I have to read the code itself. I think it would encourage more people to test it out on nightly if it was just slightly easier to discover *how* to use them.
Looking forward to see community build support similar to OpenResty (Lua)
There's nothing quite as satisfying as seeing an SDK for Rust from the company behind a product I'm personally familiar with.
If it is immutable, can't you just give each thread an &amp;foo?
It looks like that one actually has an exposed software debugger interface, which would be very helpful. I'd like to see what you come up with!
How about using Go-style channels and [Coroutine](https://en.wikipedia.org/wiki/Coroutine) instead on rust? I think is far better than async/await because avoid to move between [Blue &amp; red functions](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)
I am trying to remove duplicates from a vector. The elements cannot be sorted. Similarly hashing wouldn't make sense here either equality isn't based on the bytes of the struct. Basically I want to do the following as idiomatically as possible: for element in list for other in list if element == other remove other I know this can be safe, because the inner for loop can iterate backwards through the list, and it only needs to check elements after the one from the outer loop, so there is no risk of iterator invalidation. I just don't know how or even if it can be done idiomatically using rust's vec methods.
The idea of a coroutine or green thread blocking is pretty much identical to that of an async function awaiting, except it‚Äôs explicit to the programmer where the block happens. The only differences beyond that are just runtime implementation details. 
&gt; kdb-esque scripting environment? I'm in the process to do something like that, but more general-purpose. My plan is build a relational language with columnar, row-nar (? ) and streaming of tables. I'm debating [if using rust for this](https://www.reddit.com/r/rust/comments/8ygbvy/state_of_rust_for_iosandroid_on_2018/) (my quick toy prototypes are on F# and swift) but I think this kind of tool have great potential, specially because I wish to marry it with a Jupyter-like interactive terminal (no unix compatible) for this.
You did compile with --release right?
But not similar to channels. With channels is also clear when the block happened. 
I've been running it with 'cargo test', which to my knowledge runs in release mode. But even it it didn't, I feel like the fact that all arithmetic in debug mode is wrapped would make the non-sse much slower rather than the other way around. I'll double check on cargo test running in release mode though.
 `cargo bench` implies release mode, but I don't believe the same is true of `cargo test`.
No test does not run in release by default.
Sorry, was commenting from the beach. [Here's the link](https://lemire.me/blog/2018/04/19/by-how-much-does-avx-512-slow-down-your-cpu-a-first-experiment/).
Yes you're right - running it in release mode seems to be the fix
I don't think it's *that* far off. The wording about the stack size is unclear but I don't think the author misunderstood that part- they talk about pushing and popping things at runtime which is a fairly accurate approximation of what really happens. It's also a fairly clear explanation of `Copy`, IMO. The detail about copying string literals is wrong, but if you substitute "array literals" instead it's spot-on.
Hey there! You‚Äôre probably looking for /r/playrust its an easy mistake, don‚Äôt beat yourself up over it. But while you‚Äôre here, have you ever thought about learning how to code? If it‚Äôs crossed your mind, Rust would be an interesting place to start!
I too am interested, as there were some very promising modules and extensions on there, but some of them had performance issues, weren't as maintained, and I couldn't have easily contributed as I don't know Lua.
r/lostredditors
This isn't published on crates? Would rust web-frameworks be able to use this, or is it not useful for that?
I‚Äôm the long time maintainer of meta-rust and the author of cargo-bitbake. Thanks for mentioning both!
I‚Äôd gladly take patches to make the SDK work if it doesn‚Äôt work for you. It‚Äôs just not in my workflow or the other maintainer‚Äôs workflows to use it. 
Somebody opened an issue on that 43 minutes ago.
The issue to make it work on other architectures as a build host is [https://github.com/meta-rust/meta-rust/issues/23](https://github.com/meta-rust/meta-rust/issues/23) 
I left the default arm out because it was irrelevant to my point. The `...` is also eliding irrelevant information.
Postgres didn't have upsert until like two years ago. Being 1.0 is not the same as being "done".
If I were on my computer I would probably steal the name. I still think we need a better policy on it and the response so far has basically been "it's not been a problem yet, so oh well". I mean, I own rustup on crates.io. I've never even written a real crate. I've been tempted to republish so we can get download metrics though.
You can use [Criterion](https://github.com/japaric/criterion.rs) to set up some nice benchmarks.
I haven't personally tried targeting Android or iOS, but here are some relevant resources I bookmarked when they showed up in /r/rust in the past: * https://github.com/kennytm/rust-ios-android (Example project for targeting iOS and Android from Rust) * https://mozilla.github.io/firefox-browser-architecture/experiments/2017-09-21-rust-on-android.html (A more low-level example of targeting Android which actually steps through integrating the Rust "Hello World" code into an Android UI.) * https://github.com/tomaka/android-rs-glue (An alternative project focused on building Rust modules for Android applications) * http://nitschinger.at/First-Steps-with-Rust-and-JNI/ (Article about manually writing JNI bindings in Rust) * https://github.com/Dushistov/rust_swig (Tool to automatically generate JNI wrappers for specified Rust APIs) I don't know of any tools to automatically generate Objective-C or Swift bindings to a Rust library, but [cbindgen](https://github.com/eqrion/cbindgen) will allow you to automate deriving the C bindings for Rust libraries. See [this article](http://dreamingofbits.com/post/generating-c-bindings-for-rust-crates-with-cbindgen/) for a quick introduction.
&gt; Just got to thinking about what if the Linux kernel was re-written in Rust. That will never happen, so it doesn't matter much. The effort involved would be astronomical. &gt; Ignoring the amount of money, time, and resources to start a project, if the Linux kernel were re-written in Rust, could it have avoided bugs like dirty cow (which, iirc, is some kind of race)? It depends. That doesn't look like that kind of race condition that Rust could prevent directly. Depending on how the code was structured, it might be possible to design an API to prevent it, but more likely the code would be marked `unsafe` and called like that. And if you redesign the whole thing to play well with the Rust compiler, it probably wouldn't be Linux any more, but something else. If you're interested, [there is](https://www.redox-os.org/) an operating system written in Rust from scratch. Will it replace Linux? No. Is it still a worthy exercise? Yes, probably. &gt; Or if OpenSSL was in Rust, would Heartbleed ever have happened? You can have Heartbleed in Rust. The code would be highly unidiomatic, but it's still possible. But then again, that code was unidiomatic for C too. The issue was reusing a buffer from one connection to another without clearing it first. You can certainly do that in Rust. &gt; Personally, I'd like to become skilled enough to start re-writting at least the common programs on Linux and BSD systems. There is a [coreutils](https://github.com/uutils/coreutils) reimplementation effort in Rust. It's badly in need of help. You'd be surprised by how much work there is in implementing a program compatible with something mundane like `cp`.
 [On Heartbleed](https://www.reddit.com/r/rust/comments/2zd797/would_rust_have_prevented_heartbleed_another_look/). [Also on HN](https://news.ycombinator.com/item?id=9219432). And a bit [on coreutils replacements](https://www.reddit.com/r/rust/comments/7d7195/replacements_for_coreutils/). 
If you‚Äôre in a reasonable cloud provider and not FaaS, you‚Äôre paying per second. The fractions of pennies you save in startup times doesn‚Äôt even begin to justify a five second delta in startup as compared to your ability to ship code and sustain product. If that time does matter, you shouldn‚Äôt be using containers. If any container you run takes 22 seconds to startup you‚Äôre over you‚Äôre head and should not be using a container architecture to begin with. AWS lambda pre-warms most runtime (especially those that are JIT-ed) so this isn‚Äôt really an argument for Rust vs Java. 
I use https://github.com/Dushistov/rust_swig for connect java with rust on android. There is even hello world android example inside this project. I never program for iOS using Rust. But in theory you can use rust_swig to connect rust to c++ via rust_swig and then use objective-c to call c++ directly.
The readme looks wrong: Inconsistent cargo.toml and extern crate declaration. (ngix-rust vs ngx-rus). Can we now use hyphens in extern crate declaration?
https://doc.rust-lang.org/unstable-book/library-features/alloc-system.html
Agree, potentially rls can be faster, but looks like not in the near future: https://internals.rust-lang.org/t/no-rls-and-rustc-integration/6982 . At now for big project with C/C++ dependencies it rebuilds them again.
@dragostis You debug release build?
And what exactly do you not understand one the one simple rule that helps whole humanity to live in harmony to each other? The ‚Äûdon‚Äòt be a d*ck‚Äú rule should be easy for everyone to keep. Instead of reserving names while returning nothing to the community you could have thought about and written down a concept of what you would suggest and sent that one to the Rust team responsible for cargo.
Rustup is great, but it is solving a slightly different and temporary problem. People who just want to consume applications that happen to be implemented in rust (eg Firefox) aren't going to start by installing rustup. Imo this is naturally going to bring rustup into conflict with distro "release" builds - we just haven't thought that through yet because right now we're focusing on the bleeding edge rust developer experience...
Someone at our local meetup has been working on their own netlink library, have you seen it? https://github.com/jbaublitz/neli Perhaps you two can end up collaborating. :)
I mean he does have a point. For a language focused around safety, this is a quite problematic flaw. Especially considering how weird crate handling is done sometimes (*cough* piston *cough*) 
I agree that he does have a point but the method he is treating it is wrong. 
The name choice is glorious.
Thanks for the hint. I wonder why there is no `JsonStr` type in serde-json for zero-copy usage. Doesn't sound like there's any drawback?
I found this related issue: https://github.com/serde-rs/json/issues/321 If I understand correctly, it looks like this would change the error messages in an unfavorable way.
[removed]
What's the point of Maybe when we already have Option?
 I am new in rust but **if let** seem to work for you.
It would be like just a wrapper to make Maybe acts like Monad :p And we can map/damp it directly(more monadic ways :P) Thanks for your comment:D
That made everything clear. Thank you.
Did you know https://github.com/polachok/pnetlink exists? 
&gt; quite surprising to me! How come?
I believe this is the third patch release that ties back to default match bindings. It was a great feature to add and my understanding is the patches also largely relate to the non-NLL borrowck, but that's about half of all the patch releases since 1.0 occurring in the last couple months and all pointing back to the same thing. Though some number of bugs are to be expected over time, I think having several in relatively quick succession make it to stable, that are each severe enough to warrant patch releases, indicates there's a lesson to learn somewhere. Unfortunately I'm not sure what that lesson would be. Maybe the feature was "too big" in some sense to move as quickly as it did? Maybe there could be more investment into finding/testing/fixing soundness issues? Maybe things related to inference need more formal verification testing? I don't know. None of this is intended as a slight against the developers either; the Rust team does an amazing job. I love that flaws are found, fixed, and patches released instead of downplaying the issues. But I get the sense there's room to grow even better here.
&gt; The stack can also be fast because the amount of space needed from the stack is known at compile time. This means that we can allocate a fix-size portion of memory before we store anything into it. I read that as referring to the stack frame of a function. You generally move the stack pointer by a fixed offset before starting to store data in it. (ignoring alloca/VLAs, which I think rust doesn't support anyways) --- As a sidenote: On windows the total size stack of the main thread is embedded in the executable at link time. &gt; The default stack reservation size used by the linker is 1 MB. To specify a different default stack reservation size for all threads and fibers, use the STACKSIZE statement in the module definition (.def) file. 
I'm so happy. I tried to figure out how to make an NGINX module in Rust in the past and gave up after how unfriendly the build process was, but now it looks like there is a real way to make it work, and I finally might be able to have a legitimate use case for Rust at work.
It's better to gather some feedback from experienced rust programmers before posting an article with significant inaccuracies
When you `impl Trait for Type`, you can imagine replacing `Type` for `self` in any of the methods. So with `impl&lt;'a&gt; T for &amp;'a mut Foo`, `inc` takes type `&amp;mut &amp;mut Foo`. Now, when calling a method like `b.inc()`, Rust follows a few steps to figure how which method to call, including what are called _autoref_ and _autoderef_. So with `b.inc()`, Rust first looks for a method that takes exactly the type of `b`, which is `&amp;mut Foo`. That doesn't exist, so it tries to add references (autoref) and find a method taking `&amp; &amp;mut Foo`, and that doesn't exist. Then it attempts the mutable variant and tries to find a method for `&amp;mut &amp;mut Foo`, but `b` is not `mut` and you cannot take a mutable reference through an immutable binding so that cannot be done. Rust would try to deref and find something taking `Foo`, but this would move out of a borrow so no further attempts to find a method are made. Following the same logic for when you `impl T for Foo`, `inc` takes type `&amp;mut Foo`, which is exactly the type of `b`, so Rust finds a match for `b.inc()` after the first step instead of failing at the third.
In my experience as a software developer, time pressure causes bugs. It's a simple psychological effect that is very hard to resist, even for experienced and excellent people. At the moment, I see a lot desire to ship the 2018 edition, which is a form of time pressure. Maybe let's copy C++'s approach and rename to Rust edition 20XX? ;)
So I made this to understand how tokio-core works internally. It's intentionally kept simple to understand and in no way a competitor to tokio. It has been quite popular in russian rust community on telegram and helped some people to understand tokio. I decided to post it here before it becomes obsolete with new futures :)
Hm, I see. Maybe dont-panic's approach is not suitable here. But I would still prefer a compile- (or link-) time error to a runtime panic...
this is what we use in production -- it's great -- just wish it had namespace support
Right... OR I'm just writing Rust like I would Java, and the katas are therefor no good at actually helping me. Like I said.
The dates seem interesting. Is this project 8 months old and has only just been discovered.. or has it been incubating as a private repo for a while and has now been released as public?
I'd like to see implicit enumification for `impl Trait` at some point.
The locks in this example will be held until `shared` is dropped, whenever that happens. By the way Reddit doesn't support fenced codebooks or syntax highlighting. You have to use 4 space indents instead.
I'm ignorant and not sure why I should be excited. Could someone tell me the top use-cases for writing your own nginx modules? Thanks
What can we learn from this for crates.io? I‚Äôve linked the HN thread since there‚Äôs a lot of useful discussion in it about what could have been done to prevent the issue and what kind of follow up is needed, still. What manner of similar risks are there for cargo and crates.io? Could something like this happen with build.rs exfiltrating confidential info? Can sandboxing build.rs prevent some issues, or is that simply not useful because the rest of the code will still end up in your build anyway? Would 2FA help mitigate the spread of malicious code throughout crates.io? Is the team and community equipped to handle a scenario like this, should it come up? What about package signing? Etc. 
I'd say it's a very nice and for some reason underrated (given the amount of stars on git) piece of learning material for rustaceans who want to understand all this black magic that happens under the hood of [tokio](http://docs.rs/tokio/) and *futures* in general. And I'm also wondering why is it not included in any major Rust Book? :)
Awesome, I'm happy to hear that! :D
Option already has monadic operations available on it: `&gt;&gt;=` is called [and_then](https://doc.rust-lang.org/std/option/enum.Option.html#method.and_then) and `return` is called `Option::Some`; it also has Functor operations (`fmap` is called [map](https://doc.rust-lang.org/std/option/enum.Option.html#method.map)). The one issue is that you simply can't *express* Monad itself in Rust because it lacks some of the higher-order type-manipulation bits. Your library doesn't change that. &gt; And we can map/fmap it directly(in more monadic ways :P) https://doc.rust-lang.org/std/option/enum.Option.html#method.map
I have a very good PC with a brand new SSD. It doesn't help. On the other hand, Qt Creator and VSCode are extremely fast. So it's purely an IDEA problem.
I newer worked with Jave, but Python plugin is also very slow. And I have like 100 LOC.
Autocompletion is slow and works mostly only for std. IDEA doesn't have a complete support too, but it's much better.
I guess see version in debug mode does actualy calls functions. While non-sse version in release mode optimized to use sse instructions
Good point about not being able to enter the loop. [I've created a patch](https://github.com/yoshuawuyts/exponential-backoff/pull/2) that makes the method panic if the retry count is 0, wihch ensures the loop is always entered. Ideally we could encode this at compile time as an invariant, but I guess the type system isn't quite there yet haha. Thanks for pointing out a bug!
I guess sse version in debug mode actualy calls functions. While non-sse version in release mode optimized to use sse instructions
Yes, clearly Rust needs more incomprehensible type errors :p I prefer a type system where ordinary humans can read source code and understand what's going on.
Rust compiler written in brainfuck would be more impressive.
Yeah, I feel like the 2018 edition has been a little unhelpful. It's causing features to be rushed. Both in terms of bugs getting in, and in terms of design decisions not being quite as well thought out as Rust's usual (very high) standard. I wouldn't be sad at all if either: 1. The release got pushed back to 2019 2. Features not ready are dropped
I got it It seems unnecessary I‚Äôll remove Maybe in next release Thanks for your advices:D
Oh I see. I can agree with that. I guess I didn't expect it to fully work so it doesn't bother me that much.
It seems nowhere near done either way, by and large it's just straight bindings for the C API, with a few debug macros, and a few work-in-progress rust-level helpers (methods and an untyped header iterator).
Easy, just port it to BASIC.
My issue isn't with using symbols for some operations (e.g arithmetic) but with avoiding key-words for operators in places where keywords make sense. In this case I'd prefer a `mod` keyword over the `%` symbol (and possibly a `rem(ainder)` keyword, though this seems already rare enough that a normal method would suffice). Personally I also prefer using `not`,`and`,`or` keywords for logical operations instead off their symbolic equivalents (overlooking a `!` is too easy), but I know this is controversial.
...except for the fact that you cannot write Rust like you would Java...if not only because one is OO and the other isn't....nevermind they both don't exaclty have the same syntax.
Yeah, I don't think you're able to help me. 
I have written an nginx module in Rust at my company and first looked at this repository. That crate is currently very limited and supports only few helper operations. To me it seems more like a "let's try this out quickly" and not like an attempt at creating an nginx rust SDK. Looking at the other rust projects from that organization, it seems more like providing a small interface from Rust to C, such that you still need to build the actual infrastructure in C but are able to call Rust functions from C. While writing my own nginx module, I wrote a pure-rust library, which should make it easy to create dynamic nginx modules. I got the go-ahead of my company's CTO to open-source it, so you can expect me to have a blog post ready in the next few months. While it's not at all feature-complete (and probably won't be), it provides easy access to write a custom request handler or to hook into nginx's request handling phases.
There are several use-cases for nginx modules. First of all, nginx itself is very light-weight and about every functionaly is a module. For example the whole nginx config is read, parsed and forwarded by a module. HTTP proxying is its own module. And so on. The use-case for new nginx modules would for example be to implement a new protocol, such that nginx can proxy it correctly. Another use-case is high-performance metric collection.
clickable link: https://twitter.com/nnethercote/status/1017585833178615809
So far I haven't really done any production work with rust + yocto combination so this isn't really an issue at the moment. Still, it would be an interesting thing to do (and also to see how meta-rust works in detail). I didn't try to build SDK with meta-rust yet, but I'd guess it needs some additional configuration. Maybe as simple as adding *BBCLASSEXTEND = " nativesdk"* and modifying the nativesdk packagegroup. 
&gt; Similarly hashing wouldn't make sense here either sinceequality isn't based on the bytes of the struct You could still \#derive[Hash]. Then simply do HashSet::from_iter(list).into_iter().collect() I don't know if this is the best way, but it could be faster than your function.
&gt; RPis A [new library](https://www.reddit.com/r/rust/comments/8x1ayd/calling_all_raspberry_pi_owners_rustberry_010_has/) was released recently. And since Linux runs on the Raspberry Pi, all linux networking libraries should work.
A common use case would be parsing and modifying http requests, which has to be done quickly and correctly on high traffic servers
Thank you. I will return in two weeks (but probably join TWiR next week already).
Even with other synchronization, it is not legal to write to something that another thread as a `&amp;mut` to. `&amp;mut` must not be aliased. That's why all the synchronized data structures (`RwLock`, but also `AtomicUsize`) use shared references. That *that's* where, as you said `UnsafeCell` becomes important -- it is the only legal way to write into a shared reference.
For some reason it really bugs me when people censor themselves and write Brainf**k instead of Brainfuck. This isn‚Äôt u.s. television.
Unless I'm misunderstanding you that won't work either. There is no way to distill the struct into a hash for that. The only way to check if two structs are equal is to feed them into a function that spits out a bool, a function that might potentially takes minutes to hours to run.
Do I understand correctly that '(*&amp;mut *unsafe_cell.get()) = 42' is UB even when e.g. locks are used?
[Link to the internals post on this concern.](https://internals.rust-lang.org/t/concerned-about-rust-2018-stability/) &gt; Second, I think there is good evidence that our standard for making a point release has changed a lot. Contrasting two bugs, one from 1.15.1 and one from 1.27.1, is instructive I think. ... &gt; What we‚Äôve seen is a huge shift in our capacity to make point releases, rather than a shift in the necessity of making point releases. This doesn‚Äôt seem to me like a cause for concern.
Just so you know, I haven't forgotten about this! I'm finally finishing up my rewrite of artifact and have figured out how to include an mdbook in the project. Once I get the docs ported I plan on seeing how to use your tool. It's been a loooong process :)
Hi all! I'm the original author of the post in question. As mentioned by u/CUViper, we're having a discussion about the accuracies of the post over here: https://users.rust-lang.org/t/the-copy-trait-what-does-it-actually-copy/18730 Thank you all for the feedback. Just to clarify a bit about the intentions of the blog post: I'm not a prolific developer/writer/blogger and I had no idea so many people would read it. I use my Medium blog as more of a public development journal, so it is very much a work in progress! This kind of discussion is the very reason I love posting publicly! Thank you all for helping me learn this beautiful language!
I'm really interested in that project, will keep an eye out for the announcement!
Rather than concern myself with the details of the implementation, I'd rather pull in the crate and let it work its magic. Crates are cheap and don't require much work to include as a dependency. Personally, I am of the opinion that even for one API interaction you should still pull in the idiomatic crate, but not everyone agrees, and there are arguments to the contrary.
afaik, no, that would be a syntax error
I'm a security guy. Trusting people not to be dicks isn't really my style. If I were a dick I'd weaponize the rustup crate, not talk about it on Reddit. Instead I try to talk about one of the biggest flaws in our ecosystem and usually get downvoted to the point where the only one who bothers to respond is the guy who just wants to insult me. 
The cross-platform code I see being written in Rust is a bit simpler than the counterparts I've seen written in C.
This is amazing! The output is way shorter than I expected.
All we need is a {Rust,MIR,LLIR}-to-BASIC compiler now.
The problem is that failure is not ready and we are learning with it. Just like error-chain was one day. Now it's legacy code.
While it is not only actix there is a blogpost and repo from this week that makes front+backend app in rust and uses actix-web. [https://medium.com/@saschagrunert/a-web-application-completely-in-rust-6f6bdb6c4471](https://medium.com/@saschagrunert/a-web-application-completely-in-rust-6f6bdb6c4471) and the repo [https://github.com/saschagrunert/webapp.rs](https://github.com/saschagrunert/webapp.rs)
If your vector can be a `Vec&lt;Option&lt;_&gt;&gt;`, then you could do something with `Vec::as_mut`, `split_mut_at`, replacing duplicates with `None`, and finally collapsing the vector.
It's not about what I do. It's about what happens when you hit the debug in the IDE.
&gt; The naive attempt shows it impractical, and the indexing seems not possible: FWIW, this (and the failing function calls) are probably because rustc doesn't yet emit traits to the debug info. See [this bug](https://github.com/rust-lang/rust/issues/33014). 
Thanks for the info, it seems there isn't much progress to handle this, unfortunately.
My experience on Android has been pleasant compared to alternative native languages (essentially C/C++). The main win comes from having a standardized build system in Cargo compared to the varying build and meta-build systems with C++ libraries: integrating Rust libraries is normally as simple as adding a line to the Cargo.toml. This is a productivity win when comparing competing libraries' performance. In my use case I'm using Rust for libraries used in Java and C# on Android.
Ok. What kind of data do you have?
That is pretty similar to what I'm doing now. I create a new array of true as long as the given vector. I run the loops and by the end everything that is a duplicate has its bool set to false. So I run through and pull out all the elements with a corresponding true into a new array and throw out the old one.
Well, why are such words not welcome on television? Because people don't want to hear them. The same could be the case elsewhere.
I also struggled to find example applications for actix. One listed on the actix-example is https://github.com/OUISRC/muro . Another way might be searching on github for actix-web https://github.com/search?p=1&amp;q=actix-web&amp;type=Repositories&amp;utf8=%E2%9C%93 . You can also check out my side-project https://github.com/flofriday/thumbcloud. I used static files, websockets to create a filesharing server. However, I just started learnig rust so the code might be rough at some parts. Just as a reminder there is a whole actix subreddit, for actix related questions and projects.
The structs represent graphs, and I consider them duplicates if they are isomorphic to each other. I have an algorithm to check if they are isomorphic which I have wrapped in the Eq trait. 
In my country you can swear as much as you want on television and no one is complaining about it.
Some time ago I tried to use thread sanitizer on my rust code, and I noticed several warnings coming from std. At that time I thought they where false positives, but after reading this post, I'm suspicious that they might be real issues. Did anyone try to check standard library using sanitizers? is it a good idea to do so?
There are complete set of examples for actix [https://github.com/actix/examples](https://github.com/actix/examples)
&gt;&gt; What we‚Äôve seen is a huge shift in our capacity to make point releases, rather than a shift in the necessity of making point releases. Oh that's a great point. To date, the attitude I had picked up on was basically "6 week releases are already pretty quick, so intermediate releases should be reserved for bigger bugs that make it through". If that has shifted due to the ease of making a point release such that the threshold for severity is lower, cool! I agree that by itself is no cause for concern. Maybe a webpage that captures the current point release policy as well as such shifts could be useful. I still think there's likely something to improve given that the point releases all came so soon after the last and come back to the same feature, even if the threshold has changed. Perhaps it was just the natural course of things. Bugs happen. They just happened to be related and quickly discovered this time. Perhaps there was a deeper cause. Either way, it's worth finding out to possibly prevent similar occurrences going forward.
&gt; 2. Features not ready are dropped This *is* happening; async/await is the best known one, but there are others as well.
Similarly where I live. That seems beside the point, though.
Super cool! Thank you. üòä
I've seen it but I thought it was more for the generic sub-protocol whereas I was initially mostly interested in the route protocol. I'll ping @jbaublitz
In my mind, this was sort of a perfect storm situation: We're working on NLL for many reasons, but one additional benefit is that the code is much easier to work with and understand. This was a feature built around borrowcheck, and most of the focus is on NLL, so it's a tricky codebase that's getting less attention than usual. Additionally, this is not the kind of feature where you write new code to use it; it's a "the compiler now does what I wanted instead of making me write `ref`." It's not like `impl Trait` where you specifically start using it, it just affects code generally. This means two things: one, not as many people were willing to switch to nightly to try it; I know I didn't turn it on even though it was a feature I really wanted. Second, after it lands on stable, *lots* of people start to try it, since it's not a specific feature, but something that affects virtually all code. Additionally, it is true that more and more people are on stable rather than nightly these days, which means less testing, but also, more people testing after release. All of these factors came together to make bugs. Bugs happen. But I'm waiting to see if it happens with other features first before having broad opinions about Rust development generally.
It used to be actually impossible to make a `z` release. We figured they should be pretty rare! But the 1.15.1 situation made us put in the work, and so now, doing one is (in my understanding) basically the same as any other release.
That would be nice indeed. I already looked at it quickly, but like most netlink protocols it lacks proper documentation. For netlink route I was able to just look at other projects in python and go but for netlink audit, the main implementation is in C, which I don't know as well. I'll look at audit in more detail this week end, and I'll pm you when I have something decent enough :)
&gt; And I'm also wondering why is it not included in any major Rust Book? : TRPL is focused on learning Rust; teaching Tokio doesn't accomplish that goal. As for other books, stuff has been changing too much for too long. That's gonna change, finally, soon though :)
its*
The only difference between our setups was that he was using a mbp and I am using an imac. The build was running in the same docker image so I imagine everything else is the same. Next time I try it I'll probably try to build rustc into the docker image so that this doesn't happen again.
I enjoy this as well. :)
Yes I did see it, I even mention it in the README! pnetlink supports more messages at the moment, but does not parse most of the netlink attributes (`IFLA_LINKINFO` for example). So pnetlink is great for dumping links, addresses, routes, etc., but to create or modify those, you'll have to manually parse or encode the attributes. The reasons I started my own implementation instead of contributing are: - I wanted to learn. I did not know much about Netlink, and implementing it from scratch was a really good exercice. - although I think libpnet is a great library (libpnet is the first rust project to which I contributed :D), I think the API it provides, where each packet comes in two types `MyPacket` and `MyPacketMutable` is a bit confusing. Also I like to understand what my code does, but with code generation I lose that ability to some extent. I wanted to write some benchmarks to see if the code generated by libpnet is faster than my hand-written one, for parsing and encoding. Btw are are you @polachok on github?
Mmmm, you can technically shove Rust into any iOS/macOS app as an embedded binary, which I've done to (mostly great) success.
&gt; Some time ago I tried to use thread sanitizer on my rust code Hm, any hints that it valid case for "hread sanitizer"? As I know to use tsan you need mark your mutex and atomic implementation with special hints for compiler. By defaults it supports only libc and c++ std:: primitives. But you can use special hints only for C/C++. So, how can you check rust code with tsan?
Hm, no one has yet create gdb's python pretty printers for Vec?
I didn't try to use it on mutexes, but it works perfectly fine with rust's atomics. I was checking a lock-free queue that I was writing using unsafe code.
Yes, `HasLength` is implemented for slices containing any type. There's no point to implement it for `&amp;'a [T]`, because `len` already takes `self` by reference. Turbofish on `sort` is there to force a coercion to slice - without it the compiler deduces that `T` is `[i32; 5]`, which does not implement `HasLength`.
Has anybody used the \[ntp\]([https://github.com/JeffBelgum/ntp](https://github.com/JeffBelgum/ntp)) crate? What's the difference between \`ref\_time\`, \`orig\_time\`, \`recv\_time\`, and \`transmit\_time\`? And which time should I use to synchronize the clocks of different computers?
/r/playrust
*quits
Some debuginfo improvements are blocked until the debuggers are ready. That's why I've been working on adding rust support to lldb and getting it into rustup. Once that is done, I don't know how high a priority this particular bug has, but it's on my list of things to look into.
```rust extern crate rand; fn main() { if rand::random::&lt;bool&gt;() { eprintln!("QUITE"); } } ```
FWIW, I don't mind the name. On the contrary, I think it makes it easier to find the crate. So I suggest you keep it.
Just two minor comments to the author unrelated to the post itself (which I'm excited to start reading now!): The opening sentence has the typo "Rust-unelated" (or at least I think it's a typo :-P) The Reddit link at the bottom goes to https://www.reddit.com/rhttps://www.reddit.com/r/rust/comments/8ykuhv/the_tale_of_a_bug_in_arc_synchronization_and_data/ (which is a 404)
The word is still there when you censor it. The * changes nothing, everybody knows which word is meant. Either use it without censoring, or don't use it at all.
Looking forward. It would be good to build a network module to enable outbound TCP/UDP calls using nginx event-loop.
I think it is certainly a good idea to check the libstd test suite with sanitizers! The more tools we can throw at this to gain confidence, the better. :) I would have been really impressed if tsan was able to find this issue. Would have been great. Alas, it's probably still extremely useful for other cases.
Thanks, I fixed those!
The Rust Cookbook is waiting for dust to settle. Here's the open issue: https://github.com/rust-lang-nursery/rust-cookbook/issues/267
You could. But then Clippy complains, and rightfully so. 
I've wanted something like this for ages!
Electron performance issues always on front-end side. Nothing stops you from making [nodejs modules in rust.](https://github.com/neon-bindings/neon) Write a back-end for it, then try PoC with electron, see if you satisfied with the result.
return self.next().map(logic-after-if).or(Default:: default())
Neat idea! I guess in the future it will also be complete, as in have async/await or const generics.
I can see why duck + dynamic typed languages wcan be slow. I can see how languages that use white space as part of the language can be slow. There is no excuse for Rust plugin to be slow. Even Scala plugin performs alright once index is built. 
https://www.reddit.com/r/rust/comments/85b5f4/building_a_fast_electron_app_with_rust/?utm_source=amp&amp;utm_medium=comment_list Given the current state of Rust GUI programming, Electron is fine. However, it is problematic if your goal is light weight and small foot print.
Can I ask you why you need that specific functionality? If you're continuously writing to a shared object from two separate threads, then you will definitely run into issues, including cache misses due to cache cohesion, contention, a saturated bus, etc. So it doesn't really matter what kind of model or techniques or threads you use - the updates to thing will always be executed sequentially. The fact that it is so difficult to write in Rust is a symptom of that underlying problem. Your solution really depends on what you're trying to achieve.
You have a point.
Depending on your licensing and performance requirements for the GUI, you may want to look at Qt. Fairly recently they added something called Qt Quick that allows you to avoid the overhead of electron and use a markup language called QML to design the GUI for apps, and javascript for the business logic. I personally haven't used it, but I think it might be worth a look since the tools to create Qt bindings to rust code seem to be coming along pretty well, and it seems aimed at people who don't want to learn C++ for just a single project.
Hey right, good idea! I'll definitely keep that in mind for the next round of simplifications I'm planning, though I'm happy with the macro for what I've encountered before. Thanks!
&gt; I'm interested in working products using the framework The examples are still quite useful imo.
The google sheets dashboard looks much easier to follow: https://docs.google.com/spreadsheets/d/188xuIgrzGLCu68UKpRjcmpRZ0ytxe-HG_ClViBqFvbI/edit#gid=674920922
&gt; there is [one `Relaxed` access in `make_mut`](https://github.com/rust-lang/rust/blob/c0955a34bcb17f0b31d7b86522a520ebe7fa93ac/src/liballoc/sync.rs#L793) that Hai and Jacques-Henri have not yet been able to prove correct. Where can I see proofs for things like this (for cases that have been proven, of course)?
https://os.phil-opp.com/ Best resource there is for OS development in Rust. There was also a set of slides made that talks about this but I can't find it right now.
You could use Electron but it's a resource hog.. I recommend using the [web-view](https://github.com/Boscop/web-view) crate, which has a much smaller footprint :) (It uses IE11's engine on Windows and libwebkit on Linux/MacOs.)
I think all the hard work you've been doing to improve the debugging experience in Rust is at least worth a flair, but I'm hard-pressed to come up with a good one seeing how many codebases you've been contributing to to make it happen. Would you happen to have a particular flair that you fancy? *Note: I've thought about `debug-info`, but it seems a bit dull...*
Unfortunately that docs spreadsheet hasn't been updated since the end of May. Of course there's the [GitHub 2018 project](https://github.com/rust-lang/rust/projects/3) but that hasn't been updated since April 20. And there's the [rust-roadmap](https://github.com/rust-lang/rust-roadmap) but there's only been a few issues even updated this year. As a non-fulltime contributor, it's really frustrating to see good resources like these constantly abandoned. I have no idea what the state of the project is outside of a few small parts I'm working on. I wish the team would pick something, *anything* and stick with it. 
I used C++ &amp; QML for my final project at a technical highschool. The task was to create a Display for a Go-Kart. QML is really easy to learn (especially if you are familiar with Web technologys). However, the Qt C++ framework is definitely different from how vanilla C++ and much to lern. And figuring out how QML and C++ communicate with each other took me a while. Once you figured out how Qt works it is really nice to work with but I don't know how rust &amp; QML is.
\&gt; I'm evaluating the viability of rust to power all our apps logics for Linux, OSX, Windows, iOS and Android, for a large-ish ERP project. Currently I have python, obj-c, swift, .net code all around our stack, and wanna have a bit of sanity :) Hi, If you are trying to do ERP-ish kind of project, please take a look at my project [https://github.com/ivanceras/diwata](https://github.com/ivanceras/diwata) The long term of the project will be an ERP with all the customization will be plugin based, right now it is a useful smart database interface.
Wrong subreddit. You are looking for /r/playrust/.
Opss thx
The compiler errors usually have valuable information if you learn to read them.
Thanks! I understand the compiler behavior now. Looks like you can impl MyTrait for Box&lt;Vec&lt;Foo&gt;&gt; So I guess there are more or less no restrictions for what type can have an impl against a trait. Interesting! Thanks again.
I completely understand not having time to work on integrating with futures when they're not yet fully implemented. The dichotomy I was referring to was in how the current work is portrayed by different stakeholders.
I believe there are pretty printers for Vec if you run it via `rust-gdb`, but I wish there were also for HashMap and a few more basic data structures.
I haven't done a lot of game programming but from what I hear, modern architecture tends to shy away from inheritance in favour of composition anyway. You'll probably want to use an [Entity-component-system](https://en.wikipedia.org/wiki/Entity%E2%80%93component%E2%80%93system) like [specs](https://github.com/slide-rs/specs). The boilerplate necessary to implement traits will hopefully someday be reduced through some sort of delegation syntax, but for now you can use macros.
**Entity‚Äìcomponent‚Äìsystem** Entity‚Äìcomponent‚Äìsystem (ECS) is an architectural pattern that is mostly used in game development. An ECS follows the Composition over inheritance principle that allows greater flexibility in defining entities where every object in a game's scene is an entity (e.g. enemies, bullets, vehicles, etc.). Every Entity consists of one or more components which add additional behavior or functionality. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Can we also have the date of the last update? From the global view, we have no way of telling if a feature is stuck since 2015 or if there has been real progress in the last 2 weeks. Sure, you could check on the github how is it going, but it would still be very useful to have it in the global view.
Thx. I took a quick look at the link. I guess there is so much learning setting up bare metal OS. My question is, with all due respect, "Can this help me to get a quality research topic?" I kind of searching what I will be doing for 1 year, I want to explore all options.
Yes, shure. I think that this is what Mullvad, the Swedish VPN vendor, is doing right now. 
No, incremental compilation did the job :)
If you want something very simple, you can try implementing [custom Deref](https://play.rust-lang.org/?gist=a68d1c32916eb5d72e94faaf6b7959d8&amp;version=stable&amp;mode=debug&amp;edition=2015) 
An idea for future version of cargo - when you are about to update crate it could offer you a chance to review diffs of sources between the current version and the newer one. I know I'd use it to skim changes and this would probably represent a nice barrier. Perhaps the system could be connected to vendoring system so that organisations could only use crates that have been audited locally (and perhaps they could choose to audit only crates that aren't popular or aren't authored by known organisations as not everyone has time to audit std). Perhaps information on completed audits could be propagated back to crates.io as well and then each crate version could have a list of completed audits - users would be more at ease with crates that have been audited by mozilla or one of the tech megacorps. 
An idea for future version of cargo - when you are about to update crate it could offer you a chance to review diffs of sources between the current version and the newer one. I know I'd use it to skim changes and this would probably represent a nice barrier. Perhaps the system could be connected to vendoring system so that organisations could only use crates that have been audited locally (and perhaps they could choose to audit only crates that aren't popular or aren't authored by known organisations as not everyone has time to audit std). Perhaps information on completed audits could be propagated back to crates.io as well and then each crate version could have a list of completed audits - users would be more at ease with crates that have been audited by mozilla or one of the tech megacorps. 
In [https://github.com/kennytm/rust-ios-android](https://github.com/kennytm/rust-ios-android) say &gt;Note that &gt; &gt;cargo-lipo &gt; &gt;does not generate bitcode yet But I read that maybe it can do it now?
My guess would going with the trait route. In (safe) Rust you can't hold values with different types in the same array. You can however use a boxed trait `Box&lt;dyn MyTrait&gt;`, this will use virtual dispatch rather then static dispatch however. You're correct in thinking this would be tedious, but macros can come to the rescue here. You could create a macro that defines a struct with a field `base: UnitBase` along with all custom fields, as well as automatically implementing the `Unit` trait. Something like this: ``` create_unit! { struct SpecificUnit { specific_param: int, } } // Result: struct SpecificUnit { base: UnitBase, specific_param: int, } impl Unit for SpecificUnit { fn get_base(&amp;mut self) -&gt; &amp;mut UnitBase { &amp;mut self.base } } ``` Then atleast you don't have to manually write every base field and trait implementation.
I haven't used the crate, but it seems to be a fairly direct translation from the [underlying packet format](https://www.cisco.com/c/en/us/about/press/internet-protocol-journal/back-issues/table-contents-58/154-ntp.html). 
I used a game as an example, but my concern is not really game-specific. It can be applied to any code that has a similar concept, such as a GUI, where widgets all have common data (such as position, parent widget, visibility flag, and so on), and common functions which act on that data (like move the widget, reparent it, show/hide it, etc..) Then, specific widgets would add on top of that their own data and behavior. I'll have a look into the entity-component system you mentionned, but from quickly skimming the sample code of specs, it gave me a feeling of over-complexity.. I'll look more into it though.
Look interesting. I'm working a bit lower, with a relational language as glue and for the business/data logic. My plan is like to have a in-memory kind of rdbms that as far more full featured than sqlite/postgres (featured as mean can do data processing, scripting, etc, not pretending to be better than postgres!). But as front-end look good.
Very interesting, I didn't think Rust would prioritize the struct's field to then use deref as some kind of fallback.
&gt; Would 2FA help mitigate the spread of malicious code throughout crates.io? I'd prefer if solutions could be based on methods that aren't susceptible to shortcomings of GSM network. Sim cards can be cloned, phones stolen, GSM doesn't use strong crypto. If 2FA is used then at least offer another kind of 2FA, perhaps some scheme with out of band GPG signatures - owners of crates would be encouraged to use a separate machine with minimal third party software installation dedicated only for reviewing/signing crates before they are uploaded. 
This does look kinda good. But I still get the feeling that I would be fighting against Rust in order to mimic the inheritance it doesn't support. I'm so used after all these years of thinking in terms of inheritance, I can't think of any other way to implement this.
I'm dabbling in Rust, trying to see if it's worthwhile to move a C# project over. It's a simple console app, but I'm finding some things about Rust to simply not make any sense. First. What purpose does it serve to have two separate ```string```s? It seems like all it does is create confusion, because the basic ```str``` is *sort of* a reference, but sort of not, while ```std::str```, which is always borrowed. And the documentation, at least The Book, does a poor job of separating ```str```, ```std::str```, and whatever it means by ```String```. I get that a string can be hardcoded (and thus only accessible by pointers), but that doesn't seem to be the distinction between the different types. Two. Modules simply do not work the way the Book says they should. I have ```lib.rs``` in my crate's ```/src``` directory, with one line: ```pub mod test_module;```. Then, also in that directory, I have ```test_module.rs```. There's a basic function in there. But when I put ```use test_module;``` in ```main.rs```, it won't compile, because "no test_module in the root." What am I missing?
I closely watch most parts of the forthcoming edition ‚Äì as time allows. But what i am really missing is some visible artifacts of the new website. It got mentioned every now and then and that its nearing its final stage but i never stumbled upon anything i can look at. Its not that i was specifically on a hunt to find it, but every other aspect of the 2018 Edition just jumped directly into my face with a bunch of links and discussion on reddit/internal/chat ... i am just wondering if the accessibility is somehow "bad", if the community is not very interested in it so it doesn't come up very often in discussion etc. just that it is turning out quite well. I really want to see what's cooking in the website department but i can't really find any access :(
Yeah, I wonder if there's some automation that could help keep this up to date? 
Which is an [anti-pattern](https://github.com/rust-unofficial/patterns/blob/master/anti_patterns/deref.md) in Rust
It's a complicated question. The industry has been using inheritance as the solution to this problem for a long time, so that's the solution best understood. That said, ECS are on the rise. Unity uses a kind of CS for their engine -- each GameObject that interacts with physics has-a RigidBody component, rather than is-a PhysicsObject. Using an ECS is a lot of work to understand fully, probably the same amount of work if not more as _properly_ understanding how to use inheritance in a proper manner. At the overly simple, though, ECS is not that bad, and works in the GUI space as well. It's just somewhat complicated, and specs is a bit more complicated due to working with safe data lifetimes. ----- That said, a lot of people are eagerly awaiting delegation. That way, a superclass can be modeled as a trait and a base `struct`, and the subclass can be a `struct` containing the base `struct` and delegating the trait implementation to it. For now, you can imitate this with a custom macro for each "superclass" pair. Otherwise, you can use the C solution but with `Rc&lt;RefCell&lt;` or whatever smart pointers you require. There's nothing intrinsically bad about structuring it that way!
(why not Edge? Let IE die!)
Well, at least `rust-gdb` now understands Vec data structure, it prints length, capacity and the elements in the human-friendly format (regards to /u/tromey). However, if the vector is large or is actually matrix, you might want to use indexes and it is can be done in not obvious way, that's the post about the workaround.
In the first thread thing is collecting some information, the second runs a webserver where this information is being presented. So only the first one has to write, the second only reads. 
tsan hooks in to the compiler via LLVM, which explicitly understands atomic operations, and so those are automatically supported. I don't know about mutexes, but I would assume it understands calls to `pthread_...` functions (although I don't know if Rust still uses those directly).
std::str is methods on &amp;str. You need String and &amp;str because one is owned, one is borrowed. Where is your main.rs located? In src?
Understood! This is partly because the web site is one of the last pieces to get *fully* developed, since the contents depend on the work being done all year by the other teams (where only the first draft is scheduled for Preview 2). For the design, we're working with a contractor and have kept initial rounds of feedback to a limited audience to avoid being completely overwhelmed. As we prepare an initial version for public consumption, we're also working to build up some people infrastructure to manage the content in the future. TLDR: I hear you, but you're not missing out on anything -- it's just not quite ready for wide distribution yet. More soon!
With the C solution though, having an instance of UnitBase as the 1st member of every other unit structs, I can typecast everything to a UnitBase\*, like: struct CustomUnitOne { UnitBase base; int blah; }; struct CustomUnitTwo { UnitBase base; char \*blah; }; UnitBase \*create\_unit\_one() { /\* Create a CustomUnitOne \*cuo on the heap \*/ return (UnitBase\*)cuo; } Then I can store every unit in an array of UnitBase\*, and have a set of functions which act on generic UnitBase\* data. UnitBase can contain function pointers for mimicing polymorphism. Specific functions can then typecast to their specific type. Although this solution works in C, I find it very dirty and a bit tedious, but still manageable. However, as far as I understand Rust, this wouldn't work as I don't think I can typecast that way, though I might be wrong.
Does the absence of async/await in this report mean it is fully decoupled from Rust 2018 at this point?
Comparing the results of fuzzing Rust programs to the results of fuzzing C++ programs (when neither have previously been fuzzed before) gives strong evidence that Rust's promises are valid. Compare [https://github.com/rust-fuzz/trophy-case](https://github.com/rust-fuzz/trophy-case) to, say, [https://llvm.org/docs/LibFuzzer.html#trophies](https://llvm.org/docs/LibFuzzer.html#trophies) (filter for "modern C++ projects" if you like).
The compiler will make you handle it no matter what panics you have unless you make it a compile time invariant
Ah, so you'd own the full struct by pointing to a member. And you can free it just with the `void*` due to how alloc works in C. So yeah, for a similar pattern in Rust you'd want to impl a trait and then hold on to `Box&lt;dyn Trait&gt;`. This is all assuming you don't do any downcasting. (If you have to downcast, my position until proven otherwise is that you're doing something wrong.) If you want a closed set of things, you want to use an `enum`.
Yes, it won't be shipping in Rust 2018. re: regular updates, I apologize for the relative silence; the futures team and net WGs intend to start posting much more regularly, starting with an announcement about 0.3-alpha on Monday.
You can totally do it this way in Rust! In fact, you can exactly replicate C‚Äôs wa exactly (although that uses a lot of `unsafe`). But yeah, I‚Äôd recommend doing it some other way. Maybe think about the problem domain from a different angle?
Yes downcasting would be an issue. Enums also have the downcasting issue. Like if I have: enum UnitSpecific { Fighter(FighterType), Wizard(WizardType) } struct Unit { x: i32, y: i32, specific: UnitSpecific, } This representation would be somehwat ideal (as long as we're talking about non-expandable types.. Wouldn't work so weel with GUI widgets for instance).. However, within methods of FighterType, it wouldn't have access to generic Unit behaviour, unless each type is linking back to its parent Unit through a weak Rc or something, which again adds a bit of tediousness.
Edge is Win10-only, so you have to write support code for IE anyway. On top of that, it looks like Edge could only be embedded in UWP apps until very recently. Googling around for information about embedding Edge eventually lead me to [this article](https://blogs.windows.com/msedgedev/2018/05/09/modern-webview-winforms-wpf-apps/) from only a few months ago, talking about a then-*upcoming* early version of WinForms- and WPF-embeddable Edge.
It sounds like you've fallen into a quite common trap: `lib.rs` and `main.rs` are the roots of **two separate crates**, despite being located in the same directory. Since `lib.rs` (the library crate) publicly exports `test_module`, to access that from `main.rs` (the binary crate), you need to write: extern crate name_of_your_crate; use name_of_your_crate::test_module; 
Yeah I want to avoid unsafe, especially if it would crawl all over the code.. I've been trying to find a different angle, but I can't come up with anything. All those years of C++ makes me think in inheritance only, hard to come up with something different!
The slides I was referring to were [https://phil-opp.github.io/talk-konstanz-may-2018/](https://phil-opp.github.io/talk-konstanz-may-2018/#1). For general OS Development, [https://www.osdev.org](https://www.osdev.org) is THE best resource on the topic, especially if you're focused on x86. As for *scholarly* resources, that I can't help you with. Most operating system development is done by hobbyists who want a challenge rather than by people who actually want to analyse a new approach. There simply isn't much demand for innovation in OS development.
If you want to use 1GB of RAM to blink the cursor, it's a great choice. 
I'm not even close to your level of experience, but is this [code](https://play.rust-lang.org/?gist=669459ec4983cdad9b861724bb9762f1&amp;version=stable&amp;mode=debug&amp;edition=2015) something that you think would work? When using rust, I try to think of ways to use _componentization_ instead of inheritance, and things (usually) turn out easier to understand. 
At least `fence` is not supported by tsan: "This will be a false positive because drop_slow uses a fence, and tsan doesn't work with fences." https://github.com/rust-lang/rust/issues/39608
Sounds like an optimal use case for a channel. There's one in the standard library module `std::sync::mpsc`. The gist of it is this: During setup, you do `let (tx, rx) = mpsc::channel()`. Then, in info-collecting channel, you do `tx.send(some_info);` and in the webserver you do `let info = rx.recv();`.
If the game Rust is giving you compiler errors something is going horribly wrong.
Yeah that's basically what I described in the original post as a solution. It would work, but feels a bit tedious I think.
My hope is that once we find the best abstraction we will stabilize our usage just like we stabilize an API. The same is true of futures and error handling. Maybe we will always be chasing the stars though.
Good to hear, thank you!
This looks like another typo: &gt; They key point is that when an Acquire **read reads** from a Release write
I suspect [U2F](https://en.wikipedia.org/wiki/Universal_2nd_Factor) would be a more likely choice, given that it's an open standard supported by Chrome, Firefox, and Opera and with inexpensive USB dongles readily available.
**Universal 2nd Factor** Universal 2nd Factor (U2F) is an open authentication standard that strengthens and simplifies two-factor authentication (2FA) using specialized USB or NFC devices based on similar security technology found in smart cards. While initially developed by Google and Yubico, with contribution from NXP Semiconductors, the standard is now hosted by the FIDO Alliance.U2F Security Keys are supported by Google Chrome since version 38 and Opera since version 40. U2F security keys can be used as an additional method of two-step verification on online services that support the U2F protocol, including Google, Dropbox, GitHub, GitLab, Bitbucket, Nextcloud, Facebook and others.Chrome, Firefox and Opera are currently the only browsers supporting U2F natively. Microsoft has enabled FIDO 2.0 support for Windows 10's Windows Hello login platform. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
With generics I can do stuff like this pub trait Foo&lt;FooType&gt; { } struct Fooer&lt;T, D: Foo&lt;T&gt;&gt; { fooer: D, xs: Vec&lt;T&gt; } how can I replicate the behavior of `Fooer` when `FooType` is an associated type? pub trait Foo { type FooType; } struct Fooer&lt;T, F&gt; where F : Foo, F::FooType : T // Obviously doesn't work { fooer: F, xs: Vec&lt;T&gt; }
\`p gs.field.cells.buf.ptr.pointer.0\[index\]\` should work too.
Ah, I'm very happy to hear this. I felt like it would be a real rush to get it done for the 2018 edition, and a bad thing to stablise without a good amount of feedback and proving in production. Very much looking forward to trying this out on nightly though! :)
Sweet. For reference, auditd / go-audit / osquery may be useful to look at
Vec&lt;F::FooType&gt; should work
Nice to see this progressing! A couple of comments from a quick scan: 1) Your integration code is incorrect, because you are doing cosine-weighted hemisphere sampling but you are not accounting for the corresponding weight of each sample. If you sample according to a non-uniform distribution, each sample must be weighted by the inverse pdf - in this case the reciprocal of the dot product between your sampled direction and the surface normal. You probably want to return this weight from your `create_scatter_direction` function along with `bounce_direction`. Then you need to multiply your reflected\_color value by this weight. You'll notice then that the two cosine terms here will cancel out, and it's a possible optimization to just remove both of them. However, once you get into general integrators and importance sampling according to arbitrary BSDFs, you'll probably want to just eat the redundant computation as it will make the code much simpler. 2) In your discussion of random number generation you want to be generating numbers in the half-open range \[0, 1), not the closed range \[0, 1\]. I think your code actually does this, just your notation is wrong. 3) Looking at your image, your renderer looks incorrect. I would expect the distribution of light on the back wall to be roughly symmetrical, but yours is biased to the right. That seems like a bug in your sample direction or random number generation code. 4) I noticed the "fudge factor" at line 52 in your `get_radiance` function. This seems to be essentially multiplying the albedo of each surface by 2, which is a very bad idea. Consider what happens if you have an object with an albedo greater than 0.5: you'll be adding light at each bounce so your renderer won't conserve energy. If you're finding the images are too dark, the obvious solution is to make the light brighter, but more importantly you need to account for the display function. That's a huge topic in itself, but to keep things simple you can just apply a 2.2 gamma to the final color values just before you write your image. Gamma is just `pow(x, 1/g)` where `g=2.2` for your purposes.
Hey all, I have one part of rust that keeps coming back to annoy me (probably because i've been using traditional OOP languages for most of my programming history). It has to do with extending structs. In one stack overflow thread, this was the answer to a user asking how to extend his struct (SO thread: https://stackoverflow.com/questions/32552593/is-it-possible-for-one-struct-to-extend-an-existing-struct-keeping-all-the-fiel) i understood the first part of the answer entirely, but what I don't understand is why someone would extend a struct like the second part. It seems kind of counter-intuitive, since greet is almost like a free-function now. In addition, if one wants to extend a more complicated struct, won't they have to replicate all fields which exist on `Parent` on `Child`? Then, you can't even call the methods implemented on `Parent` if `greet` receives the `Child` type that implements `SayHi`. You could use use structural composition to get around this I guess, but why even have the trait at all then? If someone could explain maybe even give a better example, you'd be releasing so much confusion in myself :O ``` trait SayHi { fn say_hi(&amp;self); } struct Person { age: u8, } struct Child { age: u8, has_toy: bool, } impl SayHi for Person { fn say_hi(&amp;self) { println!("Greetings. I am {}", self.age) } } impl SayHi for Child { fn say_hi(&amp;self) { if self.has_toy { println!("I'm only {}, but I have a toy!", self.age) } else { println!("I'm only {}, and I don't even have a toy!", self.age) } } } fn greet&lt;T&gt;(thing: T) where T: SayHi { thing.say_hi() } fn main() { let p = Person { age: 42 }; let c = Child { age: 7, has_toy: true }; greet(p); greet(c); } ```
There is a dedicated r/rust_gamedev too in case you want to talk about specifics.
Well, it's obvious now that you've typed it out :) thanks!
Not to provide an answer, but I know the glib-rs library does something like inheritance to manage porting over GObject. http://gtk-rs.org/docs/glib/
A colored version of \`implemented\` [https://screenshots.firefox.com/S22GSSvrN15EoGql/forge.rust-lang.org](https://screenshots.firefox.com/S22GSSvrN15EoGql/forge.rust-lang.org)
By that logic, everyone should leave their curtains and doors wide open. I mean, everyone knows you and your family have genitals and poop/pee. Why censor yourself! If someone likes closing the door when pooping despite all of us knowing what he or she is doing behind that door, just leave them be. Don't be a preachy a** :D
I won't be using that stuff when it comes out anyway. Mio and an event loop is plenty of async for me. 
You may want to watch this talk: https://youtu.be/4YTfxresvS8
+1 NIM /NimiqTipbot
Wait, you're telling me coding in rust isn't a game?
+1 NIM /NimiqTipbot
Processing tip to nasa42 for 1 NIM. [Balance &amp; Deposit](https://np.reddit.com/message/compose/?to=NimiqTipbot&amp;subject=Balance&amp;message=I%20want%20to%20check%20my%20balance%20%26%20see%20how%20to%20deposit!) | [Withdraw](https://np.reddit.com/message/compose/?to=NimiqTipbot&amp;subject=Withdraw&amp;message=I%20want%20to%20withdraw%20my%20NIM!%0Areplace_this_sentence_with_a_digit_value%0Areplace_this_sentence_with_your_NIM_address) | [Help](https://np.reddit.com/r/NimiqTipbot/comments/8mpksa/nimiqtipbot_howto_and_faq/) | [What is Nimiq?](https://www.nimiq.com) | [Get Free NIM](https://nimiq-faucet.surge.sh/)
Processing tip to maxfrai for 1 NIM. [Balance &amp; Deposit](https://np.reddit.com/message/compose/?to=NimiqTipbot&amp;subject=Balance&amp;message=I%20want%20to%20check%20my%20balance%20%26%20see%20how%20to%20deposit!) | [Withdraw](https://np.reddit.com/message/compose/?to=NimiqTipbot&amp;subject=Withdraw&amp;message=I%20want%20to%20withdraw%20my%20NIM!%0Areplace_this_sentence_with_a_digit_value%0Areplace_this_sentence_with_your_NIM_address) | [Help](https://np.reddit.com/r/NimiqTipbot/comments/8mpksa/nimiqtipbot_howto_and_faq/) | [What is Nimiq?](https://www.nimiq.com) | [Get Free NIM](https://nimiq-faucet.surge.sh/)
This looks like black magic. Nice work :). I'll definitely play with it later.
If it is it's a terrible one. 90% of the quests are "go to this line number and do this exact thing".
That was a very interesting talk, thank you for this. It kinds of give me a new perspective on how to structure things, which is what I was looking for.
Relation to Rust is unclear; please leave a comment explaining why this fits here as per our relevancy rule.
I want this all the time. 
I think it's important to recognize that everything you do is shaping your understanding of programming. Now that you've been exposed to C, that experience is always going to stay with you. My experience is that Rust's compiler can guide you to accomplishing more as beginner compared to C, I know it did for me. Both are great experiences to have had in their own right. As far as Object Orientation goes, I like to think of objects as little cells each with a single responsibility in a much larger ecosystem interacting with other cells. Cells are small, avoid writing classes with too much responsibility. A lot of people tend to write OO programs as "procedural programs with walls". I'd take a listen to Sandi Metz's talks on Object Oriented Programming - she has some really insightful/wonderful things to say about it.
Nice meme (although I'll have to point out rule 3). However while Electron definitely comes with a fixed cost of around 30 MiB of RAM, that's about it. After that it scales fairly well. If you are doing most calculations in Rust, it should be fairly lightweight.
I will try this, thank you! 
Objects are a great fit for solving certain architectural problems that you won't experience until your programs start to get larger. For example, dependency injection via the gateway pattern, object-relational mapping for SQL databases (Python's SQLAlchemy ORM is truly excellent), controller objects in MVC, etc. In many cases where strictly OO languages would require objects or inheritance to provide dynamic behavior, Python allows you to do nice things with functions instead. Objects can provide a nice way to keep the scope of mutable state in your program under control; this can lead to more maintainable and easier to understand code. I think Rust and Python are a great pair of languages to pick to learn. Rust provides the experience of being guided towards correct programs by a compiler and structuring your program using a set of interfaces (traits). Python is the dynamic wild west where you can get the machine to do just about anything you can imagine (so long as you're ready to wait a while) and there are very few rules. You can get a frighteningly large amount done in a very small number of lines of Python.
I hardly ever use Python classes too. But that‚Äôs more because most of the Python programs I make are very small. If they start to get big enough to require classes, chances are I‚Äôll use a different language like C++/Rust/Go 
Despite being in the wrong subreddit, to answer your question you need to build a tool cabinet and place it in your base. This stops it from decaying. Some modded servers ('no-decay') servers prevent this behavior altogether.
If you want to become better at programming, learn Lisp - not kidding. But if you are interested more in a great traditional language (in the sense of C like) to make useful things, choose Rust.
There is also CEF (Chrome embedded framework) which leaves out node.js.
It is one of those games where you are not allowed to walk out of bounds. Also, it is supposed to be fast, but you are not allowed to race, what is up with that?
I close the door on the toilet for my own calm and privacy, not to protect *your* sensibilities ;-) Besides, you can't choose not to use the toilet (not for long, in any case), while you can choose not to use certain words.
For IoT, increasing rapidly, We are concerned with security, i think innovation needs to curb the breaches as there is not any os which runs on very low specifications.
The proofs are being developed in https://gitlab.mpi-sws.org/FP/LambdaRust-coq/tree/ci/weak_mem. Keep in mind this is work-in-progress. `Arc`, specifically, is in https://gitlab.mpi-sws.org/FP/LambdaRust-coq/blob/ci/weak_mem/theories/typing/lib/arc.v. However, those proofs are not fully done yet -- they found a problem in the definition of data races recently, so they are working on updating that definition and then adapting the proofs to show that things are still data-race-free under the new definition.
No that's actually not a typo. "Acquire read" is the subject of the sentences, and that subject "reads" from a "Release write". Any suggestions for how to make this easier to parse?
*lol* I was not sure if this post would interest enough people so I didn't put it on Reddit... well, I guess I was wrong. ;) I'm already enjoying working on Rust full-time again. :D
Sorry if this may be obvious, but what is a hack-n-learn? My google-fu is failing me here. 
Instead of having a guest speaker or other organised activity, it's an open session. Everyone is invited to bring a laptop and work on a Rust programming problem, or bring a problem and ask others to help you solve it, or just wander around the room and chat. If anyone gets stuck they can just call out their problems and those nearby will chip in with suggestions. Sometimes we have someone connected to the projector so people can watch some live coding if they fancy that. I hope it's an interactive, social event and our hosts kindly provide free food and drink too. 
Thanks a lot for this post, always great to see Rust promoted, even more so when it features our research. :D I have a little correction to make though: &gt; In order to prove the correctness of the standard library, Ralf Jung with colleagues designed an approach to unsafety using separation logic and own calculus that they called Œªrust. Using that calculus they proved that all standard library primitives and containers work as intended and that they do not violate the fundamental invariants of Rust. We haven proven *far* from everything in libstd. That would need way more manpower than we can muster. Instead, we have focused on the libstd primitives that seemed most interesting, and that seemed to stress the type system the most. That's mostly around interior mutability. As such, we have verified Cell, RefCell, Rc, Mutex, RwLock, Arc and some more individual methods [listed in the blog post on the paper](https://www.ralfj.de/blog/2017/07/08/rustbelt.html). Also, I should add the usual caveat that this is a *model* of Rust and that we have been making simplifying assumptions. See [my recent post on a bug in Arc](https://www.ralfj.de/blog/2018/07/13/arc-synchronization.html) for an example of a bug that we missed.
Try [this](https://github.com/sfackler/streaming-iterator/blob/master/src/lib.rs) for inspiration.
I love it! I'm currently looking for something similar and this is perfect. Thanks.
Hi Ralf! Thank you very much for your feedback and your great work! I was really happy to know, that you would continue working on this topic. I will edit the post to reflect your feedback. As for your recent blog post, I've read it already :) I'm following your research since the start.
I suspected it might not be, which is why I said "looks like". However, I'm tired out of my mind right now, so a more useful reply will have to wait until tomorrow (from my perspective).
I think it is easier to do things in Rust when you try to keep things simple, therefore doing things the C way is usually easier (and "rustier" if I can borrow the pythonic way of speaking) than doing the way you would do in C++. If you want to keep the inheritance look you can do something like: ``` struct BaseStruct { x:i32, y:i32, } struct A { base: BaseStruct, z: i32, } trait Base { // Acessor methods } impl Base for A { // Implement acessors } ``` You could also write macros to avoid repeating the Base implementation everywhere.
That code is fine if other threads just have a `&amp;UnsafeCell&lt;T&gt;`. However, that code is UB if any other thread has (at the same time) an `&amp;mut T` to the contents of the `UnsafeCell`.
&gt; Rust is known for being slow to compile. All the sanity-checks that the borrow checker performs or the generic types it supports, for example, don‚Äôt come for free. I hear there are possibilities for improvement in this area but: one, I haven‚Äôt researched what these are, and two, they haven‚Äôt materialized yet. It is my understanding that the actual compilation bottleneck is not type-checking (`cargo check` is fast), baring algorithms complexity explosion which are generally fixed when discovered, but the code generation part. 
Python might not be the best to learn OO. Of course you could do it, but you would learn more easily with a language like java, as the language is built arround object. 
https://github.com/redox-os/redox Redox OS is an OS being written 100% in Rust, it may help you to study their code and docs.
Edited the post. Could you please review the changes and confirm that it's now OK?
Ah, makes sense. Thank you for explaining!
Interesting. That was an unresearched claim from my part... Do you have pointers with more information? Thanks!
Most terminals seems to blow up when you use emoji in them :( Could use one of those weird old ASCII characters though.
Oh, computer-verified proofs, even! When one tries to prove that some Rust code is correct, does one have to manually write Coq statements that describe its behaviour, or is there some software that can analyse the Rust code and do that automatically (so that also that step is computer verified)?
&gt;We did not discuss SeqCst above, and in fact there are not many cases where it is really needed. Release and Acquire are enough most of the time SeqCst is the default memory order for C++ atomic operations (for example: [https://en.cppreference.com/w/cpp/atomic/atomic/load](https://en.cppreference.com/w/cpp/atomic/atomic/load)). Why not in Rust?
At least we can use, red color `Wrong:` and green color `Right` prefix for those or different colors for those titles, right?
Your friendly professional gopher here. &gt;Generics &gt; &gt;Winner: Rust. ‚Äònuff said. There is no doubt that Rust wins when it comes to generic types. I just wanted to mention that in the code Go mostly used for (networking services and command-line utilities), the generics problem isn't that pronounced. I do hope we get something like parameterised packages for Go 2.0 though. &gt;Difficulty &gt; &gt;In the Rust case, there is no denying that it is a complex language. Maybe not as complex as C++, but it has a lot of things going on. Writing code in Rust, therefore, requires more effort. The payoff is that, once the code is written and compiles successfully, there are high chances that it will run just fine. The same cannot be said of Go, in which I‚Äôve experienced plenty of runtime crashes. `nil` pain is real. If there is one design decision in Go that I would *really* like to change, it's the inclusion of `nil`. `nil` is Hitler. &gt;Build system &gt; &gt;Winner: When considering the native build systems of each language, Rust wins with its Cargo tool. When considering Bazel, Go wins for the time being. This might change with Go 1.11, when (experimental) versioned modules support lands in stable Go.
I invite you to check the sidebar: &gt; Anything related to the Rust programming language: an open-source systems language from Mozilla, emphasizing safety, concurrency, and speed. And direct you to r/playrust for the video game.
As I mentioned, the simple "proof" is to call `cargo check` then `cargo build`: - `check` only does type-checking, - `build` type checks and then produces the library/executable. In general, `cargo check` is pretty fast (seconds), while `cargo build` is significantly longer, which points at a code generation bottleneck. It does not indicate whether the time is spent in `rustc` preparing the LLVM IR, or in `LLVM` converting that IR to assembly. Also, note that `cargo test` compiles your code *twice*, a first time to produce the library/executable and a second time to produce the test executable (which not only recompiles all code because of `cfg(test)`, but also additionally compiles the tests).
&gt; Mind you: Go is a bit better than Rust in this area because Go‚Äôs type aliases are treated as semantically different by the compiler‚Äîrequiring explicit casts between them‚Äîwhile Rust just treats them as syntactical aliases (like C‚Äôs typedefs). From my extremely limited Go knowledge (I just did some extra research) both languages have syntactical aliases and a(/at least one) newtype pattern. Am I missing something?
Well depending on what you need from `UnitBase` you could do away with it all together and add the required methods to the `Unit` trait, rather then on `UnitBase`. But depending on what you actually need this could also increase the amout of boilerplate code.
I think I saw somewhere that Rust -&gt; HIR -&gt; MIR -&gt; LLVM IR doesn't actually take that long, but the LLVM IR generated isn't great, so LLVM has to spend longer optimising.
Please don't.
step further: rustc --auto-correct-explain :)
I wish people would stop trying to claim that you can't compare certain programming languages just because they are a little different. There are a huge number of programs for which Go and Rust would be very good choices. Probably the top two choices. That's why people compare them. In fact I would go as far as to say that *most* programs which you might write in Rust or Go, could easily be written in the other language. I can't think of *many* types of program that could only be written nicely in Rust or Go.
Go did recently acquire type aliases in the same sense as Rust's type aliases, in that they are purely syntactical aliases and do not correspond to separate and distinct types. Type aliases in Go (`type Foo = Bar`) are not often used, and IIRC, the original motivation for adding them was as a tool for refactoring. As far as I can tell, the OP is using "type alias" incorrectly in Go land. Type aliases in Go (`type Foo = Bar`) have the same semantics as type aliases in Rust. The probable source of confusion is that since type aliases were added somewhat recently and rarely used, I believe folks have often referred to Go's newtype pattern (`type Foo Bar`) also as "type aliases." But they are not aliases and are indeed new types (in `type Foo Bar`, `Foo` is a distinct type from `Bar`). Go also has some additional rules [around assignability](https://golang.org/ref/spec#Assignability) that can blur this line a bit more, but usually Do The Right Thing. In my experience, neither language really "wins" on this particular and specific front, but there are definitely some interesting differences in expressibility when it comes to encapsulation, which is something you often want to with newtyping.
&gt; I wish people would stop trying to claim that you can't compare certain programming languages just because they are a little different. Note that the OP still did a comparison, which seems consistent with your view, no? If I were the OP, I would have made the same exact hedge in the introduction because there _are_ a ton of people who think certain languages shouldn't be compared. This is a case where everyone is probably a little right and a little wrong, simultaneously.
Yeah, the author also clearly mixed up the notation here. In Go, a type alias is this: type meters = int type feet = int and a new type is this type meters int type feet int The difference is that you can do `meters(1) + feet(1)` in the first case, but in the second the compiler will emit an error.
None of the mainstream OO languages I can think (e.g. C++, Java, C#) are entirely devoid of functional programming. I think in the present day, people are finding out that it can in fact be practical to use more than one paradigm in a language.
No. Do this in your editor, not on the output from `rustc`.
`env RUSTFLAGS='-Z time-passes' cargo build` will print this information. It will look like this https://gist.github.com/MaikKlein/9645b3145cca403448c9d9e4a3bae6a7
Yeah I agree it is clearly just added to stop people who erroneously think that Rust and Go can't be compared from complaining. I don't think the author believes it. But as a result he is spreading that silly idea, and we'll probably get even *more* misguided apples and oranges people. We shouldn't give in to their weird objections!
Interesting read. I like both Go and Rust for different reasons, and I seem to have very different freferences from you. One thing I particularly enjoy about Go (compared to many other languages, including Rust) is that it is so much less bureaucratic. I like that Docstrings are just plain text, without any "mini language" embedded into it, for example. I like that compiler errors are just single lines. Related to that, I kind of like that the type system is simple enough that you never need more than a one line message to see why something doesn't typecheck (though I also love Rust's type system, both have different aspects to love about them). It feels to me that while Rust is the result of top-of-the-line engineering, Go is optimized to make all the little things about programming much more pleasant: You don't have to figure out what an error is about, all the naming and name spacing is beautiful, etc. One thing I think that is unnecessarily bad in Rust and so much better in Go is method declaration syntax: impl MyType { // lots of other methods ... pub fn my_method(&amp;self, arg: usize) -&gt; usize { // code } } When I see the declaration of the method, I don't even know what type it belongs to and I have to scroll up to see that it's `MyType`. It also took me some time to really remember how `self` is used, because it doesn't work like other arguments. Why is it after the `&amp;` where the type is supposed to go? When it's used like a type here, why isn't it `Self`? Why does my method look like it has two arguments when I call it with one? Why do all my methods need to be indented by an extra level for the large `impl` block? In Go it's so much nicer: func (m *MyType) MyMethod(arg uint) uint { // code } The only thing that's a bit weird here is that there is no dot in there (so it's not `(m *MyType).MyMethod` even though it's called that way, but I think I like it better without. Both languages are really similar in that you can chose how you pass the calling object, as a reference/pointer or a value (though the semantics are different, but that's not so important here). That said, of course I don't want to bash Rust, I love it, but there are just so many design decisions and tradeoffs to be made that no language will ever be able to get everything right. After all, every language's design is shaped by its intended use case. For Rust that was building a highly optimized browser engine. For Go it was building Google's many web services, and building lots of them. I think both of them are extremely well fit for their intended purpose, and both are great languages well beyond that.
From what I remember, there exist ballot checkmark and X glyphs in the basic multilingual plane that get used by Node.js testing frameworks.
&gt; I'd take a listen to Sandi Metz's talks on Object Oriented Programming - she has some really insightful/wonderful things to say about it. Do you have some specific link to recommend?
Huh. Yeah, the Book definiely does not make that clear, so thank you! What would ```name_of_your_crate``` be?
In ```src```, yeah. And just to make sure I understand, "borrowed" bsaically means that you're using a pointer to a variable, while owned means you're using the variable directly?
Great, thanks for updating. :)
Have to agree, enough Xmas-tree text interfaces as there is. It would not be difficult, however, to write a filter that would most of this....
Hm, we've gotta be missing something, then. Could you maybe upload a git repo somewhere so i can poke at exactly what you have? &gt; "borrowed" bsaically means that you're using a pointer to a variable, basically, yes (there are also unsafe, raw pointers that do not borrow) &gt; while owned means you're using the variable directly? basically, yes. (Though in some sense it means, "who is responsible for destroying this resource", usually that's because you're using it directly)
I was not involved in the design of that API, so I cannot tell. Rust does not support default values for parameters, which may have played a role. ;) `SeqCst` is the strongest possible choice, so if an algorithm works at all then it works with `SeqCst`. The reason for my comment, however, is that `SeqCst` is frequently used when it is not necessary. That's not an issue other than for performance -- but it is, I feel, also indicative of thinking about concurrent code the wrong way. `SeqCst` lets you think in terms of all possible interleavings ("either A happened before B, or B happened before A"), whereas Release-Acquire makes you think in terms of transferring ownership/access from thread A to thread B. I think that's usually easier to think about, as your mind does not get bogged down thinking about way too many ways in which multiple operations could be interleaved. Release-Acquire is somewhat "local" where `SeqCst` is inherently global.
Currently we are translating Rust code to Coq statements manually. But it would indeed be very nice to have that automated. :) There's probably some fundamental work needed to make that feasible (bringing our calculus closer to MIR, in particular), and then a bunch of tooling. Right now we don't have the manpower for that, but it's certainly on my list of projects that I dig up whenever someone knocks on our door asking for an internship or so. :D
I just pipe everything to cowsay.
That's what I remember... but LLVM should spend no time at all optimizing Debug builds and yet they are slow too.
My understanding is that time-passes is less accurate these days, as it doesn‚Äôt properly capture the new query interface. I could be wrong though!
I don't seem to see it but where does this specify that the returned borrow cannot outlive a consequent call to `advance`?
Thanks, I edited those too. Sorry, English is not my native language and it is not spoken in my country. Unfortunately, I do not have enough language exposition to polish my skills.
Hey, thanks for the comments! &gt; 1. Your integration code is incorrect,.. I'm not surprised. I keep meaning to read Physically Based Rendering at some point, but for now I'm mostly just making it up as I go and drawing from random sources on the internet. I'll make a note and try to fix this in part 3. &gt; 2. In your discussion... Fixed, thanks! &gt; 4. I noticed... Yeah. there are a few cheats in my code. Another one is that the light's brightness is 2.0. As for the gamma correction, I'm already doing that. I accumulate the colors in the image buffer in a linear color space, and then when I convert the floating-point colors to RGBA32 to write the image they're clamped to (0.0, 1.0) and gamma-corrected.
If I recall correctly then a large part of the slowness is due to the amount of llvm it generated by rustc. This is largely due to how traits/generics and monomorphisation are currently implemented. This part also doesn't change in debug builds.
Very cool. Thanks for describing how it is done!
It's okay, we are plenty of foreign speakers here (myself included) with varying level of fluency. :)
I'm not sure I completely understand what it is you were trying to do initially, but usually to channels are used to pass data between threads, e.g [std](https://doc.rust-lang.org/stable/std/sync/mpsc/index.html), or [crossbeam-channel](https://crates.io/crates/crossbeam-channel))
&gt; I haven‚Äôt found a profiler for Rust as well-integrated as pprof is in Go. Yes, there is a library to generate pprof-like traces, but it hasn‚Äôt worked very well for me yet and it‚Äôs a bit cumbersome to install (needing gperftools to be present on the system). This old post contains some more information on this topic and other available tools. Which profilers have you used and how do they different from pprof? I haven't used pprof for Go, but I basically use the same profiling tools for C and C++ with Rust just fine: on Mac I use Apple's Instruments, valgrinds, ...) and on Linux I use perf, valgrind, Intel VTune... 
 fn next(&amp;mut self) -&gt; Option&lt;&amp;Self::Item&gt; Desugared, that's fn next&lt;'a&gt;(&amp;'a mut self) -&gt; Option&lt;&amp;'a Self::Item&gt; Meaning that the result is linked to self.
I totally agree with the "Profiling" section. Although being rather a tool than a language problem, it is currently way too difficult to set up profiling and get quick results. Same goes for benchmarks, which are currently only integrated in nightly Rust and even there you have a split between the standard profiling tool and [criterion](https://japaric.github.io/criterion.rs/book/index.html).
actually I tried a lot. I also want to have custom controllers derive from Controller and RestController and provide default functionality. But that't too difficult at the moment to do. I'll look at Channels. Thanks.
Just a tip: when you use the Rust Language Server, you can hover over `self` to get the type of it. That's my workflow when I'm deep inside a `impl` block and don't remember the struct I'm implementing methods for. Funnily enough though, it doesn't work when you hover over `Self`.
I am not aware of any tool that lets you track the names of heap allocations (for Rust) and generate a graph like [this](https://i.stack.imgur.com/o1uet.png) (pprof output). Rusts profiling tools can more or less just say "malloc was 10 times from 0x12345", but this isn't really helpful to see what variables (hash maps, vecs) store the most memory in your program. There is heaptrack ([picture](https://blog.netways.de/wp-content/uploads/2016/09/heaptrack-2-1024x735.png)), but it just tells you how many allocations there were, not from what exact variables they came. pprof is vastly more intuitive here and I'd love to have such a tool for Rust. I think this is because Go knows what names are attached to what allocations (since it has a GC), so it can acurrately tell you where exactly your memory is used (including the names of the variables).
I agree with you. Something similar happened to me during my sophomore year at CS. The subject was algorithms and in the laboratory classes we used C for programming. It was a real pain in the ass for such a naive programmer as i was (and i still being). I remember spending more time trying to figuring out why does the program was making memory leaks rather than understanding the algorithm itself. After that i keep some hard feelings about that language, although I'll not deny that great things have been made with C (e.g. Linux). But as you, when i started with Python it changed everything. Now after a while i'm facing that old algorithm problems and I really understand them. Also i'm interested in some OS area subjects, but the memories that C brings me it kept me away. Now i've discovered Rust and it's a new world! i feel i can hack without fear :)
For what purposes couchdb is really useful? 
programming is helping you understand programming.
You don't need ORM if you don't use objects in the first place. What's wrong with a relational data model? It's got a very nice algebra. (Dependency injection and MVC are also things that really don't need OOP, OTOH, it's not like OOP would cause their necessity).
CouchDB is a NoSQL database with extremely powerful (and simple to setup) replication capabilities. Its performance is also quite stellar compared to industry leaders such as MongoDB (uses way less memory for equivalent performance). It‚Äôs written in Erlang. We‚Äôve been using it in an IoT context for it‚Äôs replication features mainly. 
Thanks! The reason I was asking is that I was under the impression that anything other than SeqCst is dangerous/prone to errors (example: [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2177.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2177.html))
Go wins here. Go's transparent newtypes are way better than Rust's opaque newtypes: can avoid miles of boilerplate. Probably the feature I miss most from Go ‚Äî I really want to be able to make a new kind of integer *that automatically gets all the properties and capabilities of an integer* in one line.
Hey there! I was once there too. I tried to apply the way of thinking that came from years of inheritance-centered OO experience and it is often not the best way to approach a problem in Rust. Luckily, it turns out that in the real world, you very rarely will actually want to ‚Äúextend a struct‚Äù in terms of both behavior and data. There‚Äôs always a way to structure things a different way, and it will often be easier to read and reason about. These days, I now prefer Rust‚Äôs way of doing things, it just took a while to wrap my mind around it. Here‚Äôs a two-step way of viewing a problem that helped me get out of my traditional-OO mindset. 1) How would I write code to do what I need to do with just functions (purely procedurally)? 2) How would I clean up that functions-only code using all the nice things Rust provides (enums, traits, generics)? Note that this isn‚Äôt what I do to approach problems every time, but just a tool that can help one to see more Rust-y solutions by abandoning the pure-OO perspective. You will often find that problems that you thought need inheritance to solve actually don‚Äôt need it at all. You‚Äôll start to see that if you need polymorphism (variation in behavior) with a fixed number of variants, and enum is a great tool. If you need it for an unknowable or expanding number of variants, traits fit that problem pretty nicely. If you need to reuse data, composition of data structure is easy, and more importantly easy-to-read. Also, there‚Äôs nothing wrong with free functions - they might be a code smell when creating an OO architecture, but in a language like Rust there‚Äôs no reason to avoid them. It‚Äôs also worth reading up about the trade-offs between solving a problem with data structures (pure data with no behavior attached) vs objects (behavior abstracted behind an interface) - see https://www.cs.helsinki.fi/u/luontola/tdd-2009/kalvot/04.2-Objects-Errors-Boundaries.pdf for a little bit more explanation. This concept really opened up my mind about needing everything to be an object. Note that you can still use objects (‚Äútrait objects‚Äù) in Rust, but knowing which situations they are suited for will make everything easier. Hope that helps! :)
Well, that's... the name of your crate! It's usually the same as the name of the directory it's in, but if you're not sure you can find the name in `Cargo.toml`. 
Interesting piece: thanks for sharing it. You might include a **Performance** section. In my experience, this is one of Rust's biggest wins: out-of-the-box Rust code is just a lot faster than equivalent out-of-the-box Go code. Here's one [benchmark](https://github.com/BartMassey/ttt-bench) I use.
&gt; just syntax sugar Huh, TIL that you can write the "long forms", too. &gt; One advantage of making `self` special is that types can have associated methods. I mean, you could still have them with different syntax. One obvious way would be pub fn MyType::new() -&gt; MyType { which mimicks the way you would call it. Of course I'm not arguing for actually making that Rust syntax, at least not in its current form. It's just one thing I like a lot better in Go than in Rust. Another thing is trait imlementations. Of course you can't just get something like Go's automatic interface implementations in a language like Rust, but even when you compare it to something like Haskell, Rust's `impl`s feel pretty repetitive. 
I could be making stuff up here, but I think llvm code generation is more parallelizable. I compile rustc on a server with 64 cores these days, and frequently see CPU usage go above 1000% for a little while at the end of each crate compiling
If nothing else, even for debug builds it's still necessary to generate machine code. While LLVM has fast methods to do so for use in debug builds (FastISel), these cannot handle a number of peculiarities of the IR generated by rustc (including the pervasive use of invokes, switches and non-scalar returns), so this needs to fallback to the full-blown SelectionDAG mechanism (which is also used for optimized builds). And well, rustc just generates a *lot* of IR.
Sure, you can compare them, but you still can't say on the whole which is better. I think that's what the author is getting at.
Won't compile because x borrow the iterator, thus you can't create y.
Is this implying that `SeqCst
How does CouchDB compare to TiDB? (which seems to be also easily horizontally scalable but is compatible with MySQL's protocol)
Is this implying that `SeqCst` is a performance hazard, and yet also mandatory due to certain features of C++? If Rust ever gained default function parameters, would that cause the same performance hazard? This sounds like something that would be worth bringing up in any RFC to add default arguments, which appear rather frequently.
In the for loop starting on line 14, you're attempting to move `Vec` into multiple different closures, one for each iteration. Anything that has been moved from can't be moved from again.
It might, but it also might not. \`vgo\` is a bold experiment aiming to do versioning in a way that's never been done before, and it relies heavily on particular assumptions about what package maintainers will do. Maybe it'll usher in a new era of simplicity in dependency management. Or maybe it'll crash and burn horribly. I eagerly await the results.
There is no difference in terms of performance hazards or requiring `SeqCst` for correctness between C++ and Rust, at least none that I know if. It's just that the C++ committee decided to make the "strongest possible" (and hence also "most safe") choice the default, whereas Rust decided that programmers should be explicit and not forget about the fact that ordering modes exist. I do not know how big the practical performance difference is, you'd have to benchmark that for each application individually. On x86, `SeqCst` is translated *almost* the same as all the other instructions (the only exception are `SeqCst` stores, which need an extra synchronization instruction) -- however, these modes also affect what the compiler will do when optimizing, so there might be a measurable difference even on x86. ARM has much weaker ordering guaranteed by the hardware and hence is more likely to exhibit noticeable performance differences.
&gt; I close the door on the toilet for my own calm and privacy, not to protect your sensibilities ;-) Exactly. People who voluntarily choose to censor themselves tend to do so for their own sake. The point I was trying to make is your demand that they cater to your sensibilities (by not self-censoring brain***k) is not any more reasonable than them demanding that you cater to their's.
There's [a third-party crate](https://crates.io/crates/newtype_derive) that does a fair bit of this.
Yes that is a commonly held view. I happen to disagree. :) Concurrency in general is dangerous/prone to errors if you don't have a tool like Rust's type system to help you. I don't think the difference between SeqCst and Release-Acquire is making a significant dent, and I think the claimed "simplicity" of SeqCst is actually more complicated than what you have to do to convince yourself that Release-Acquire code works (like what I outlined in my post). When all you need is transferring ownership, Release-Acquire is exactly the tool designed for this job and SeqCst is using an unnecessarily powerful tool.
I keep seeing this claim and it doesn't line up with my experience, so I'm going to lay out what I'm seeing and maybe somebody can explain what's going on? Working on [this project](https://github.com/saethlin/slack-rs-api) can be a real bummer because it's slow to compile. Specifically, 16-18 seconds to run `cargo check` after a small change. It `cargo expand`s to 121,172 lines, so that's ~7,000 lines/second. The C++ project I work on for my research is ~75,000 lines after macro expansion, and compiles to a binary in 2 seconds. That's ~37,000 lines/second. Jonathan Blow's compiler which specifically aims for speed manages ~70,000 lines/second to produce an executable and while constantly interrupting the compiler with a metaprogram running in an interpreter. The TCC project boasts about 859,000 lines/second but admittedly it's working with a language where each lines is probably easier to compile. Yes these are not all on the same CPU (Jonathan Blow is running on a laptop), yes not the same language. But the point stands- `cargo check` seems like molasses to me compared to running `clang++ -fsyntax-only`, even when I'm presenting the compiler with what sure feels like a similar amount of code.
I'm really curious about this, what are they doing that is so radical/different from other package managers? Mind you, I've only worked with high level pm's (yarn, composer, pip) Where can I read more about this?
You can do that too, it's just a bit less well-defined. For example most would agree that Python is better than BASIC. Same way you can say some vehicles are better than others, even if they have very different uses. A Chinook is better than a Skoda Estelle.
We have a Godwin winner here! :D
Traits can be much more flexible than inheritance and without many of its drawbacks. Instead of a base object with several attributes, each can be its own trait, like Named, Positioned (x, y), Angled. Then your functions can require whatever combination is necessary in that context. All of the objects are free to be designed without regard for the base object, just implementing specific functionality as warranted. And then you don't have to dig through four files to get to the base class that's causing strange behavior way, way downstream. One of my favorite parts of rust is never having to try to grok other people's inheritance models. 
That's certainly something that Rust does that Go doesn't, and you can try to minimize monomorphization to reduce compile times, but it's far from the largest part of the problem. Even in projects without heavy (or any) use of generics, I see the LLVM stage of compilation take a long time. I suspect it's even more fundamental- the IR rustc produces for individual functions just isn't in a style LLVM is very fast at generating code for.
See also the discussion in https://github.com/tokio-rs/tokio/issues/424 and on https://twitter.com/Jonhoo/status/1017841357069709312.
Not from her videos, but I would recommend her POODR book.
Yep. Rust leans heavily on LLVM to do optimization of the generated IR, and LLVM isn't super fast at it. There is redundant work being done by LLVM because the cost of avoiding the redundant work means a lot of additional logic in the earlier steps. When comparing go and rust compilers, you can reasonably say that Go optimized for build times and has a lot of room to improve in terms of optimization for better runtime performance, Rust is very much the other way around, with lots of room to improve as far as build time but very good optimization. Benchmarks I did of several real-worldish webservices implemented across rust, go, C#/mono (nancy), and node.js bore this out. Rust knocked it out of the park for raw performance but Go's compilation times were really impressive and something nice to have as a developer who is iterating in small steps.
It's something like Seastar framework for C++? That would be great.
It seems like different projects (and the language features they use) have much different compilation performance profiles, which would explain the outreach recently from the compiler maintainers looking for "worst offender" packages to focus on in testing. 
I don't know if you've tried this yet, but building with `-Z time-passes` shows that around 10 of those seconds are attributed to "expand crate." (I also see roughly 18s on my machine for `cargo check` so the time should be comparable.) Un-expanded I see roughly 20k lines, so *something* is spending a long time generating the other 100k. Might start by looking at heavy use of custom derive (you've got serde as a dependency) or if you have any huge macros in your own code. I'm not sure the best way to tell whether it's `rustc`'s fault or the macro's fault, though.
Ah if you‚Äôre doing gamma correction already that‚Äôs good. The lights brightness can really be anything you want it to be, or you can put a fudge factor right at the end before your gamma correction and can it a camera response function. As long as it‚Äôs a constant at either end of the path and not at each vertex. I can‚Äôt recommend PBRT enough!
Yes, that is a somewhat accurate comparison. They're not directly comparable, but tokio-io-pool does essentially shard connections and their associated compute onto execution threads in the pool. One of the major missing features at this point is work-stealing, which will likely be necessary for particularly skewed workloads or non-uniform tasks.
Do you have a link to where async/await was confirmed to not be in 2018 edition? I‚Äôve read the tracking issues but didn‚Äôt see that. 
When I mentioned the same thoughts on the previous patch thread, Steve replied that a lot of the burden is due to the old borrowchecker being bug prone. I think that as a result there is a fatigue associated with continuing to fix the old borrowck, and focusing instead to release the new one `polonius`. At least, that‚Äôs how I would feel, working on buggy legacy code. 
Thanks, had forgotten about that. It's not really a complete solution, and not nearly as convenient as the Go thing, but it's a good start.
If your data is not modeled well relational you would use a nosql db, such as a document db or a graph db. Also note that these days lots nosql databases also support SQL as a query language and in fact is usually referred to as 'not only sql'. 
CouchDB has much more powerful index capabilities. Since you can have structured data within a single document, you can write MapReduce views on structured data, which lets you do some pretty cool things.
I‚Äôm not sure there‚Äôs a specific citation, it‚Äôs just pretty clear that the timelines don‚Äôt match up.
Include the superclass instance as a field in the struct, and implement `AsRef`/`AsMut` to access it. You can store `AsRef&lt;superclass&gt;` (or `AsMut` if you need mutability) as the analogue to C's `superclass*` although you won't be able to get back down to a specific subclass without using `Any` as another bound.
As Rusky mentioned, this may well be an issue with macros; I personally don't use any (not even serde) and cargo check is a few seconds at most, with cold disk. It would be interesting to take a peek at what's happening with `perf`, to see where the time is actually spent.
Russ Cox, who, with Google's blessing, is the de-facto BDFL of Go these days, has a whole [10-part series of blog posts](https://research.swtch.com/vgo) about the design. Of particular interest are [the article about Minimal Version Selection](https://research.swtch.com/vgo-mvs) and its predecessor [about NP-completeness of traditional version selection](https://research.swtch.com/version-sat).
Thanks! Good to know there's an issue opened for the matter.. probably it's not a bad solution to wait until async/await story is ready, but in my experience there is a demand like "how to async in rust" in the community, especially among the beginners, because tokio is already out there, and people need to use it somehow, and I personally find it better to use something when you have some comprehension in your mind :) but okay, i think it's not a right place to discuss contents of books or something, thanks for you link anyhow :)
While it‚Äôs not the right thing to do, it still should actually work.
Did you read the io project chapter? It should have...
Indeed, teaching Tokio doesn't accomplish the "learning Rust" goal, while teaching "toykio" actually might accomplish a goal like "learning asynchronous in Rust" or so :) but I've got your point and I don't really want to argue.. at least not in this thread :D
The problem with this is that Traits cannot have data. So if I have 20 unit types, all of them implementing the Positioned trait, then I have to declare (x,y) in 20 structs, and write the move function in 20 structs that does the same thing. Same thing with all the different traits.
whats wrong with nil?
I personally think that webassembly could possibly form the basis of a electron style application platform. Combine wasm with sdl2 for input and graphics handling and add some basic file and networking apis and you can have sandboxed applications that run cross platform.
Depending on what you're doing, Godot + Rust can be a very nice pairing for Rust + GUI. Excellent performance, seamless cross platform (desktop/mobile/web), intuitive node-based design pattern. 
WebAssembly outside of a web context reminds me of Quake 3's QVM. Quake 2 had mods distributed as platform-specific shared libraries, which was a security risk, so to help make mods more safe and distributable Quake 3 has a bytecode VM with a bunch of syscalls that is compiled to through a special llvm backend. This enabled developers to quickly iterate by compiling game code to a DLL during development, but then shipping finished versions as a .qvm module so they were both secure and portable on end-user systems.
[https://github.com/sos-os/kernel](https://github.com/sos-os/kernel) This might also be interesting.
Yo this is fuckin dope.
Ah ok. I also missed the username the first time, and coming from you means it's likely so. I am a bit saddened. But reading through it again, it seems like people are *still*, after all this time, bikeshedding over the syntax, which is just lovely, lol.
&gt; Some have compared WebAssembly to Java applets; in some ways, they‚Äôre very right, but in some ways, they‚Äôre very wrong. Eventually I‚Äôll write a post about the wrong, but for now, the right: in some sense, WebAssembly is a different way of accomplishing what the JVM set out to do: it‚Äôs a common virtual machine that can be used to build very cross-platform software I'd like to see the post about the wrong. It seems obvious that a wasm vm would be much slimmer and less burdened with overhead of things like the GC, but they seem to accomplish the same goal I'm the context of this article.
I did a few tests because for me an incremental release build usually is much faster than cargo check. A clean release build takes 55s, and `touch src/lib.rs` takes 5s with `cargo build --release` and 10s with `cargo check`.
&gt; through a special llvm backend Quake III predates LLVM by a few years :)
How well does Rust support functional programming? 
That's quite the broad question, but I'll try to answer anyway: Not very well. True, Rust *has* higher order functions, and since `impl trait`, we can even return functions from functions without needing to box them. Rust also has iterators with powerful combinator functions (map, filter, reduce, etc. like you'd expect from a functional language). Algebraic Data Types and destructuring pattern matching will warm your heart if you come from a ML-family language. *But* Rust is at its heart an imperative language, and you will sometimes need to fight the compiler and standards library if you try to go all-immutable, all-functional. If however, you bend a bit and go for a hybrid approach, you'll be very happy with Rust.
Sure! There‚Äôs already a book in progress for that, by Aaron :)
one nit, criterion works on stable.
Great answer, thank you :)
Oh, cheers. I didn't know that, since I've expected it to rely on the nightly-only benchmarking system.
The heap tracer built into jemalloc(default Rust allocator on Linux and OSX) can produce those, shouldn't be too hard to access it from Rust.
ahh, I meant LLC
It‚Äôs not cynical, it‚Äôs very common! I‚Äôm gonna try to make it happen, but part of why this is a short post is that I‚Äôm trying to get back into the swing of blogging. 
How about the time you save and the network bandwidth involved with dealing with container images? And the caching is not 100% automatic, you'd have to make sure that your packaging tool is correctly doing it, which you could ignore if your overall container size was 2MB instead of 173MB. Overall it seems that you are suggesting putting more work to "make the comparisons equal", but by that accounting, we should then add a metric for "time spent optimizing," because stripping symbols from a binary is literally a subsecond, singular command, which seems unfair to make a big deal over.
Could this be because the build scripts are compiled in debug mode for `cargo check`? I saw that manishearth mentioned [this sort of thing in an issue](https://github.com/rust-lang/rust/issues/48683#issuecomment-386174563), but I don't know enough about cargo internals to alter the settings
Does Seastar do work stealing? I don't think it does.
I'm a Rust newb - this looks really cool. Inviting more comparisons to Seastar: 1. Does `spawn` have to be `Send` here? tokio's `CurrentThread` executor doesn't require `spawn`. Maybe this is future proofing for work stealing it does? 2. Would it be possible to `spawn` onto a specific thread? For example, if I wanted certain requests to be processed only by a single a thread, if I processed a request that "belonged" to another thread I would have to "Send" it to that thread.
I hope servo will be easily embeddable soon..
Sure, but with macros it's one line of code. 
Do you think wasm games will be as popular as flash games were? (And why?)
Games in wasm, or wasm generally?
I really think this is one of the biggest failings in Rust right now, for both ‚Äúwrapper‚Äù style newtypes and composition over inheritance ‚Äî without some way to automatically delegate to the internal value, you‚Äôre stuck writing a ton of boilerplate. 
Well, I wasn't asking for a "proof". I was asking if a list of specific known issues exists with corresponding tracking bugs and potential ideas for improvement...
Everything can be Secretly Hit... nil. So you either have to keep checking it (which is tedious) or sometimes you get `nil` where you thought you can not and crashes happen.
The good thing about pprof is that it does sampling, not instrumentation, and it works purely in user-space without kernel support. So you can execute your code with a tiny performance penalty and still get good profiling out of it. I've successfully pprof-ed live servers and even a FUSE file system where performance is critical and haven't noticed a penalty on the actual performance. Valgrind, on the other hand, does instrumentation and the code becomes much slower. Apple's Instruments should be fast because it's based on dtrace, which is fast, but then you need kernel-level support. I don't have much experience with the other tools you mention.
The main thing I had in mind with the statement that "these shouldn't be compared" is my feeling that people tend to put these two languages together only because both were released at a similar time. Years ago, when I saw Rust's announcement, it felt like a reaction to the recently-announced Go and thus it made sense to put them in the same bucket‚Äîbut I realize now that they aren't that similar, and that there are many more languages to be considered in this same area. In fact, I'd like to see people comparing Rust to other languages more frequently. "Rust vs C++" on Google returns \~800k results, while "Rust vs Go" returns 35 million. However, the first comparison is also a very interesting one. Lastly, what mikeyhew said below: you can compare them (and I did), but it's not possible, for me at least, to say that one clearly wins over the other.
Haven't read much about vgo myself, but note that Cargo heavily depends on semver (right?) and this relies on package maintainers doing the right thing as well. It's actually pretty hard to get semver right when shipping binary libraries. Also, if vgo truly is a bold experiment... I'm more concerned than I was. The open-source community has its ways about dependency management, which are pretty standardized. Trying a vastly new approach in a language may make it harder to integrate projects into existing codebases, and also make it harder to create binary packages for Linux distributions. What do you think?
Try searching for "null biggest mistake" in Google or, if you are into Podcasts, check out [https://newrustacean.com/show\_notes/e003/index.html](https://newrustacean.com/show_notes/e003/index.html)
Good point; I forgot about a Performance section! However, I don't think I have enough data to write something meaningful. As I mention in the article, I implemented the same project (a FUSE file system) in Rust an Go to compare performance and I found the Rust variant to be much better without putting any effort in optimization. However, I later found some issues in the Go FUSE bindings that, when addressed, made performance almost the same... I still believe it'll be possible to make the Rust variant significantly faster though.
Cool meetup, i hope the talks will be recorded since i wont be able to attend it.
Non pointers and non interfaces cant be nil in go though
That holds for C as well, and the term "_The Billion Dollar Mistake_" was coined about C. Actually, in all statically typed languages that I can think of that did this mistake primitives can't be null. It's still considered a flaw.
In my very limited experience, the main reason for difficulty here is the memory management aspect. There are all of the features that you think you basically want: fluent iterators, first class functions, immutability by default. However, when you actually try to go and construct a higher order function combination, you quickly run into the problem of telling the compiler where to put all of those functions. For example, the environment that a closure captures--should it move with the closure or stay in the defining level of the call stack? And if it is merely borrowed by the closure, well, you'd better be sure that the closure is done with those references by the time they are getting cleaned up. All of this is to say, it will quickly become clear how much work a functional runtime like Clojure's is doing for you.
It took me a while reading through the threads to work out the significance of this, but having done that: this sounds awesome! Am I right in thinking this would work as a drop in replacement for the `rt::run(server)` call in this example? https://github.com/hyperium/hyper/blob/master/examples/hello.rs
I think this is a great idea, but you‚Äôd really want to expose a lot of the OS‚Äôs native text rendering and layout management. This is important so applications look native to the platform - different operating systems use slightly different font rendering techniques. You also want to use the native font rendering so the system‚Äôs accessibility system can read the text in your application. Embedding [skia](https://skia.org/) could do the trick though, if you combined it with a simple layout manager. 
Hmm why not? Depends on whether the module is logically part of the library or binary, I suppose. 
Here's an example where of the two only Rust can be used: embedded. 
&gt; I believe that I am somehow losing the string data or getting back a null reference. That *does* feel like a likely candidate. Raw pointers don't have lifetimes, so, when transforming them into slice types, it's very easy to accidentally let the backing for something fall off the stack without getting a compiler warning. I recommend opening it up in a debugger like [gdbgui](https://gdbgui.com/) and stepping through it to see what's happening.
Can someone show me how to get the median of several random integers using the median function from https://github.com/BurntSushi/rust-stats? I've been trying for like an hour but I keep getting errors about traits not being validated. Just started learning Rust and I would really appreciate it. So far I can get it work with with: extern crate stats; fn main() { stats::median(1..5).unwrap(); } but not with my own set of numbers.
I don't think the target of C/C++ or WASM would make the difference here. You still have all the in between things like FFI, string handling, etc that is not that much of an improvement at least in its current stage. In fact, you could argue that if you are a language targeting WASM, you can get more wins targeting LLVM instead. There're two sides to that argument (built-in optimizations vs not-really-cross-platform nature of LLVM).
I only looked in the source for a couple minutes, so could be wrong, but it seems like the example shown results in all of the accepted TCP streams to be associated with the Reactor of the first worker, even though they are then sent to different workers to execute. That'd mean they all still have to synchronize with the first Reactor, and all the other reactors wouldn't actually be doing any IO polling (unless the new futures then made new connections or something). In that case, it'd be a round robin version of the thread pool, without work stealing or support for blocking futures. Did I overlook a step that deregisters the socket from the first Reactor and forces it to register with the one in the worker it was sent to?
Running WASM on the EVM is quite the opposite of solving the issue. The whole problem with Solidity isn't that it's buggy, it's that programs written in Solidity are buggy. Solidity is too much like a general purpose programming language (specifically, too much like javascript). Using WASM to enable even more general purpose programming languages on the EVM just leads to even more bugs.
One big point I'd like to see emphasized is how married the JVM bytecode and the Java stdlib are compared to WASM which does a good job divorcing itself from the surrounding APIs needed to compile/run it.
Yea, You should be able to replace the `rt::run` call. That's just part of hyper as it's a good default if you don't have specific reasons to not use it. (Note, a work-stealing executor is usually always better outside of benchmarks, unless you have a surprisingly fair environment.) For per thread variables, couldn't thread-locals work for that?
Rust is helping me understand why we have things like PHP and JS. 
As an addendum, Servo uses Mozilla's Spidermonkey. This [recent benchmark](https://pspdfkit.com/blog/2018/a-real-world-webassembly-benchmark/) showed its wasm performance in a very great light compared to other browsers.
Looks right to me on the Rust side. Try checking what bytes are pointed to by `id` before and after the conversion from `*const c_char` to `&amp;str`, with either a debugger or print statements.
Why not wasm based PWAs? Is the performance that different to 'true' native? Can't imagine most GUI needs all that.
So I delved into the .Net Reference Source and found why I was getting the exception. Basically the _ParameterInfo interface exposed by mscorlib is useless. However, as I delve into the internals, I decided to spin off some of my work and published my first crate: https://crates.io/crates/mscorlib-sys This has bindings, but those are based on a tlb, which may be inaccurate or glossing over relevant details. So now I'm working through the ref source and doing it "properly" for the next couple of minor (likely breaking) versions. And working on the next layer, where I have to somehow incorporate the various interface mixins and dynamic dispatch functionality into rustic functionality. Whee! Just thought I'd post an update. 
Is there a way to embed wasm compiled modules in rust apps?
I think its more nuanced than that. Solidty isn't a bad language because its buggy. Its a bad language because its features (or lack thereof) lends itself to easily writing buggy code. Would opening the door to C be worse? Probably. But opening up to languages better suited to the task sounds like a net win to me.
Games in wasm
I‚Äôm really excited about using wasm as the basis for plugins. Most applications of sufficient complexity require plugins to allow for custom functionality, but it‚Äôs a bit of a crap shoot in terms of how they are implemented. Some take a .so file, some embed a JavaScript interpreter. Some (like ESRI) embed a python interpreter. Some roll their own format entirely. Wasm has the potential to revolutionize how we design, write, and secure plugins for large applications. 
[removed]
Hmm. The only ```Cargo.toml``` I have is for the original project. It sounds like I need to add it there?
Ok, thanks. It's been a long time since I even dabbled with C++, and even then, I never got too far into the difference. It's going to take a little more dabbling to get it down, I think.
Interested to check out the compose implementation!
You can convert between Options and Results using `Option::ok_or()` and `Option::ok_or_else()`, and `Result::ok()`. That should help you avoid cases where you have an Option wrapping a Result. In a function like [`parse_input`](https://github.com/grantcooksey/hangman/blob/master/src/hangman/mod.rs#L52), you can use a `match` statement to clean up the code, like so: ``` match trimmed.chars().next() { Some(c) if c.is_ascii() &amp;&amp; trimmed.len() == 1 =&gt; Ok(c.to_ascii_lowercase()), // handles every other case _ =&gt; Err(BAD_INPUT_MESSAGE), } ``` Using `unwrap` frequently may be a sign that you can simplify the logic of your input if you truly know that the code should work, but it can also mean you can stand to use more of Rust's pattern matching syntax to destructure your data, e.g. using `if let Some(x) = foo` or a `match foo` statement. Using a `match` can also help you notice places where you should handle another case (i.e. what if you get `None` or an `Err`). The other common suggestion people tend to give is to avoid using `String`s for error types, since they make it harder to extend your error system (someone else can do a better job of explaining this than me). All in all, it looks like quite the nice project! Welcome to Rust! 
Flash's success as a game platform was mostly based on the easy tooling and ecosystem available to make the games. If someone stepped up and made a similar type of ecosystem and tool that compiles to wasm then I don't see why not.
The tools are already there, you can already use webgl + nphysics, images, vector graphics etc. What more do you need?
&gt; If they could just drop the W, and make it a nice platform agnostic low level programming language we could use for things like Nebulet, I'd be much more jolly about it. I do agree with that part. I personally like WASM as a whole, but my least favourite part is the 'W' in front. Otherwise, I think it's a very nice open-specified low-level portable bytecode.
Yes but it‚Äôs not easy; you‚Äôd use the wasmi crate.
[webrender](https://github.com/servo/webrender) (Servo's rendering engine) already exists as a library in the rust ecosystem. A few people (including me) have been trying to build modern, cross-platform, react/redux-style native UI toolkits with it (for example, [limn](https://github.com/christolliday/limn)). But it is all kindog work-in-progress.
Yeah, but all of that requires a lot of technical knowledge to put together. Compared to the flash animation editor that had dozens of tutorials and an easy to use interface and language (Actionscript). There is no comparison for wasm (yet, thus my original point).
I have a function that calls another function which returns a Result. I need to check if the Result is Ok or Err and if it is an Err, I need to return early from my function. This is what I'm doing now: match callable(&amp;mut param) { Ok(_v) =&gt; (), Err(_e) =&gt; return, }; Is there a rustier way to do this? I asked on SO as well [here](https://stackoverflow.com/questions/51344951/how-do-you-unwrap-or-run-a-command-if-err). Thanks!
seems like *debug god* or *his holy debugness* would be appropriate?
I'm a bit concerned that web browsers run wasm much slower than asm.js right now. Is it really that inefficient?
Usually you would define a different iterator for each struct
As a learning experience, I‚Äôm writing a text editor. Text editing obviously has a lot of insertions and deletions. Though I‚Äôve never used one, this is what I‚Äôve heard the point of a linked list is. Though I‚Äôve also heard that linked lists are usually to be avoided. Is a human editing text is enough insertion/deletion to justify a linked list vs just being thoughtful with vectors? 
If I'm reading that graph correctly, Firefox runs webassembly about 4x faster than asm.js and the rest of the browsers it's close to 1 to 1 performance
I'm a newb, but I'm thinking you can just use the `?` operator at the end of your expression. Like: callable(&amp;mut param)? Check out this link for some info on it. https://m4rw3r.github.io/rust-questionmark-operator
`Relation` is a trait, not a type, so it doesn't make sense to try to pass around values of type `Relation`. What you want here is a [trait object](https://doc.rust-lang.org/book/second-edition/ch17-02-trait-objects.html). I highly recommend reading that to understand trait objects if you don't already know how they work. If you want the TL;DR though, you basically need to change the type of the argument from `Relation` to either `&amp;dyn Relation` (if you want to borrow the `Relation`) or `Box&lt;dyn Relation&gt;` (if you want to take ownership of the `Relation`).
I've not figured out immediately how to do 2-level indexing, but it works: (gdb) p gs.field.cells.buf.ptr.pointer.0[1].buf.ptr.pointer.0[2] $4 = Owned = {1} Wonderful, thanks!
I actually don't to propagate an error back up the call stack, the function I'm writing doesn't return. I got an answer on [StackOverflow here!](https://stackoverflow.com/a/51345372/5155574). Thanks though.
Linked Lists are a fine data structure in the right situation, but they can be difficult to write in Rust without using unsafe operations. But there is also a linked list implementation in the standard library you can use. https://doc.rust-lang.org/std/collections/struct.LinkedList.html
Coroutines are topical for rust, this is an implementation and an API that could be of interest to rustaceans.
I just want to hug everyone involved in this very important work. On a less cheesy note, how common is it for a language feature to be reviewed so rigorously, both in rust, and in other languages in general? 
Does ropey immediately load the entire 20GB log file I'm going to accidentally open into memory?
+1 NIM /u/NimiqTipbot
Processing tip to ErichDonGubler for 1 NIM. [Balance &amp; Deposit](https://np.reddit.com/message/compose/?to=NimiqTipbot&amp;subject=Balance&amp;message=I%20want%20to%20check%20my%20balance%20%26%20see%20how%20to%20deposit!) | [Withdraw](https://np.reddit.com/message/compose/?to=NimiqTipbot&amp;subject=Withdraw&amp;message=I%20want%20to%20withdraw%20my%20NIM!%0Areplace_this_sentence_with_a_digit_value%0Areplace_this_sentence_with_your_NIM_address) | [Help](https://np.reddit.com/r/NimiqTipbot/comments/8mpksa/nimiqtipbot_howto_and_faq/) | [What is Nimiq?](https://www.nimiq.com) | [Get Free NIM](https://nimiq-faucet.surge.sh/)
Instead of let file = try!(File::open(String::from("./resources/words.txt"))); You can use let file = File::open(String::from("./resources/words.txt")))?; Ending a statement with '?' is the new syntax that does the same as 'try!'. Generally, where you use 'expext' or 'unwrap' you can also use '?' to move the error handling up. If you can have multiple Error types from one function, it is possible to use faillure::Error. While it is possible, I think it is somewhat of an anti-pattern to use a string as the error type. You can create a struct and either use the faillure macros or define Debug and Display yourself. guesses_remaining is probably always positive, so you could use u8 instead of i8.
With macOS depreciating OpenGL, will mac be a target of azul? 
All fp functions are made by macros :P (because some `partial`/`currying` features couldn't be implemented in pure Rust...however macros could do that) from fp_rust 0.1.30 we could do this: ```rust (compose!(reduce!(|a, b| a * b), filter!(|x| *x &lt; 6), map!(|x| x * 2)))(vec![1, 2, 3, 4]) ``` it's the beginning :D
I‚Äôm writing a simple text editor to expand my comfort in dealing with files and maybe even a bit of a-sync. It‚Äôs a bit difficult to motivate for an uninteresting product, but I‚Äôm learning and that‚Äôs enough. 
Ropey itself is just a library, so it really depends on the application that it's used in. But it would be very easy with Ropey's APIs to pause loading beyond a certain size to warn the user, and ask them if they want to continue. (Specifically, see the [`RopeBuilder`](https://docs.rs/ropey/0.8.0/ropey/struct.RopeBuilder.html) type.) Another thing you might be getting at is: can Ropey work with files that are larger than available memory? And the answer is no. You might be able to build something on top of Ropey that would page in parts of files at a time, but it would be going against the grain, and at that point it would almost certainly be better to use something else. But assuming that you _want_ to load a 20GB file, and you have that much memory available, Ropey shouldn't have any problems with it.
Some other data structures commonly used for text editors are gap buffers or ropes.
Thank you very much. I‚Äôll look into those ASAP 
Where could async/await fit in this?
Generics are more common than trait objects in Rust: pub struct RelIter&lt;R: Relation&gt; { pos: usize, data: R } pub fn next&lt;R: Relation&gt;(rel: &amp;R, pos: usize) -&gt; Row { rel.row(pos) } In this case the compiler will generate one "Scalar_next" and one "Row_next" function. In the trait object case, there will be only one "next" function and the right function will be called because of function pointers sent in as a parameter to the function. This is a tiny bit slower, which is why Rust generally prefers generics (but there are good use cases for both).
Not OP, but introducing nil violates the entire type system.
+1. If you're creating a separate struct for the iterator data, then you should hold the wrapped data with generics. Each implementation of the trait would then implement `IntoIterator`. Sadly, you can't just do `impl&lt;T: Relation&gt; IntoIterator for R`, but you could use a macro to save on copy and pasting.
AFAIK Unity3D and Unreal allows you to export games to webassembly. It is just another compile target. But last time I looked some features such as multithreading and SIMD were still missing. 
Why does the name matter?
https://reddit.app.link/qQ4MloQczO
Because people think it's just about the Web and Javascript. This entire blog post was dedicated to dispelling that misconception. There are people who hear WebAssembly and actually think you're talking about compiling to Javascript.
I mean, I don't think that's going to change at all with wasm. It'll just provide an additional alternative that some tools will make use of, and others won't. Sure, it's possible to compile down to wasm, which makes it a bit more portable, but then you'll generally need to have header files (or equivalent) for all the different languages that are compiling to wasm, which will probably only ever be provided by the community. I can definitely see the benefits of a powerful, secure, and fast scripting interpreter that can be embedded into all sorts of applications, but we've had that in the form of Lua for years, and, while it's definitely had a lot of impact, it's certainly not been universally adopted.
As a point of clarification, the current Tokio runtime runs "I/O tasks" concurrently and does work stealing across them. The differentiation isn't "I/O vs. Compute". It's more a question of uniform vs. not. Also, the current runtime only uses a single Mio \`Poll\` handle vs. this one uses one per thread. \[#424\]([https://github.com/tokio-rs/tokio/issues/424](https://github.com/tokio-rs/tokio/issues/424)) tracks work to improve this.
For those wondering, this appears to be an analytics tracking link that (eventually) resolves to: https://www.reddit.com/r/rust/comments/8yz8xb/announcing_ropey_v08_an_editable_text_buffer_for/
Great article Steve, thank you for that :) There might be a small confusion about Solidity, EVM and webassembly though. The EVM defines opcodes, executed on a stack. Thats the EVM language. Solidity compiles into EVM opcodes, but the EVM knows nothing about Solidity. Solidity has its own repo, and is different from the EVM. The plan is for webassembly to be included in the EVM, but not in Solidity. Instead of using the current EVM opcodes, the EVM would run webassembly bytecode. I am not sure if that means that languages like Solidity would compile directly into webassembly or into something higher level.
I don't necessarily think you'd need os native text rendering perse, but it should blend in well with the rest of the programs. So you do want to expose enough information about the current environment so that something like Pathfinder can the itself to mimick the current platform and active settings. As for the accessibility aspect, that's a trickier problem. I'm not well versed in how current platforms approach this. I would guess that it strongly depends on the gui toolkit being used, but wether the os interface can be seriously abstracted over to provide an os neutral internal api, I can't really say. A lot would need to be incrementally worked out, for basic interaction with other applications, printer support, peripheral access, etc. But starting with making mostly self-sufficient programs like games work first, fully cross-platform and with neigh on native performance, would be a minimal viable product as far as any proofing ground for something like this would be.
&gt; can Ropey work with files that are larger than available memory? And the answer is no. What if you nevertheless open a file that is larger than the currently free memory, so that swapping happens? Does it become unusably slow? Or were you talking about opening files so large that you run out of swap space as well?
&gt;Give thanks, it seems the reddit app is just giving me an annoying link :)
Are you sure it's *Reddit* doing that? They have their own link shortener (`redd.it`), and the link includes tracking information that suggests it's coming from a third party.
&lt;3 &gt; how common is it for a language feature to be reviewed so rigorously, both in rust, and in other languages in general? Researchers have looked at plenty of things -- verification of intricate algorithms is still challenging enough that being the first to verify some property of such an algorithm is worth a paper. So just from my immediate vicinity (work that is done by people I work with), [RCU](https://people.mpi-sws.org/~dreyer/papers/rcu/paper.pdf) and [Haskell runST](http://iris-project.org/pdfs/2018-popl-runST-final.pdf) come to my mind. Other groups have looked at cryptographic [hash functions](https://www.cs.princeton.edu/~appel/papers/verif-sha-2.pdf) and [random number generators](https://www.cs.princeton.edu/~appel/papers/verified-hmac-drbg.pdf), just to name a few.
If i use the share button in the reddit app i get it, but it might be android wrapping its own tracking functionality around it
This looks cool but are there any kinky feature flags? :P
/r/playrust
Has anyone encountered a situation where they need to assert the equality of two large structs and get actually useful and readable output when they're not? I'm basically running two different implementations of the same algorithm in an integration test, and I want to see the differences between them. The structs in question are simple (less than 5 fields in total), but they contain at least one large byte buffer which is 64 kilobytes. One approach I'm thinking of is writing the assertion function manually, which would then compare slices of the buffer in 128 byte chunks. But is there any crate which does this already?
Not necessarily. I'm fairly sure there are embedded frameworks for Go. Don't know what level exactly. It probably needs some form of thread support. Here's one for BeagleBone and Raspberry, so it probably runs on top of linux: https://embd.kidoman.io/
So the other tools I mentioned are sampling profilers, but I think all of them require kernel support. You seem to mention kernel-support as a disadvantage, but I don't follow why. Maybe you could explain? There are sampling profilers for C and Rust without kernel support, but `perf` pretty much beats them all in features nowadays, and you can add kernel support by just loading and unloading a module live, without rebooting the kernel, so it is pretty much without any downsides AFAICT.
Is there any way to speed up the RLS in projects with local dependencies? Any time I have a project with a library dep that's not on crates.io it becomes almost unusable (but it's great the rest of the time, thanks RLS people).
Thanks for getting rid of the pathological performance when operating on huge grapheme clusters. (0.6 guaranteed that grapheme clusters would be stored in contiguous memory, sacrificing O(log n) worst case performance. While this doesn't matter for any sane text, it opens up algorithmic complexity attacks.)
Oh! I don't follow the specifics that closely. If you want pointers, I guess the most appropriate place to ask would the Discord channel of the [wg-compiler-performance](https://discordapp.com/channels/442252698964721669/446730868485128193) work group.
Seastar uses o_direct and kernel io_submit not thread pools for file io.
Use libpnet ! Very very usefully for your purpose. You can create tcp / ip / arp and whole ethernet packets. this lib is realy awesome and mighty.
As much as I liked using Lua when playing with Redis, there are two issues with it: 1. It's a separate language, unlike WASM which is a *target* language, 2. It's a separate language, with its own idiosyncrasies (1-indexed...). A common IR is a very different thing. As for the issue of exposing a header/declarations for interfacing with any other language, I would hope that this can be automated. A common format to declare the interface, one generator per target language, done.
&gt; What if you nevertheless open a file that is larger than the currently free memory, so that swapping happens? Wait, do you still enable swapping nowadays? I've had it disabled on all my computers for years now, it just doesn't make sense most of the time.
In the event that your memory dies fill up, your pc basically dies so it's a good backup
I have no experience designing an editor, but I've always assumed the starting point for buffering would be to memory-map the file to edit so that it could be any arbitrary size?
that works for reading, but now imagine what you need to do when you insert a new line somewhere in the text
Having *some* swap enabled allows your system to swap some things that aren't being used to swap. Like, if the kernel has data that it very infrequently uses, it's better to swap that to disk, so you can store more disk cache in your memory. Right now, I have 8GB of swap enabled (Excessive, I know), and 2.25MB of it is being used, even though my memory is around 2.40GB used.
First thing I would do with the code is combining all the error reporting methods: you have Result&lt;...,&amp;'static str&gt; in a couple of places, and `panic!()`'s, `.expect()`'s and `.unwrap()`'s peppered all over the code. Build a single `enum Error {...}` with all of your error kinds (you can also implement a std::convert::From&lt;std::io::Error&gt; for it to convert from an IOError into your own kind, when handling IO), make all the functions that are peppered with the above return a `Result&lt;..., Error&gt;` instead of what they return and bubble the errors up to the `main()` function where you can handle them in a clean way. Also, your `GameState::update(&amp;self, guess: char) -&gt; GameState` should probably be changed to either `GameState::update(self, guess: char) -&gt; GameState` or `GameState::update(&amp;mut self, guess: char)`. There's no point that I can see in passing an immutable reference to `update`
Have you tried [pretty_assertions](https://crates.io/crates/pretty_assertions)?
Yes, but why isn‚Äôt it 10x faster in all of them? That‚Äôs what I would expect, based on the concept. Keep in mind that asm.js is way slower than native performance. Firefox is the odd one out.
You might want to document how you handle the linebreak ambiguity of \r\n (when is it a single windows linebreak, when is it a mac followed by a unix linebreak), especially when somebody slices through the middle of it.
Try this: let data = vec![rand::random::&lt;u8&gt;(), rand::random::&lt;u8&gt;(), rand::random::&lt;u8&gt;()]; let median = stats::median(data.into_iter()); The median function requires an iterator, which can created from a Vec with the into_iter method.
You almost never want to _disable_ swap. What you probably want to is to _strongly discourage_ swap in favor of main memory, so that whatever's in memory is what you're using the most. Various operating systems make this tunable to various degrees (e.g. `vm.swappiness` for the Linux kernel).
This looks great! The API looks very nice. :-) One thing I wonder though, especially if this is intended to be used in text editors, is how arbitrary data (possibly invalid UTF-8) should be handled? Looking the API of ropey, it looks like this necessarily becomes the caller's responsibility. But I'm not sure how the caller is supposed to manage that? For example, I might open a random CSV file in vim that's encoded in latin-1 that I largely expect to just work. In order to use ropey, I think I'd have to transcode the latin-1 to UTF-8 and then reverse that mapping when writing back out to disk. I wonder how feasible that is. There are also other instances where you have a file that's predominantly UTF-8 but has an encoding error somewhere. If the editor wants to _preserve_ that encoding error, what is the guidance on how to deal with that in ropey?
When is the TCP stream registered to the reactor? When it's first created or when a read/write is performed with it?
I've been working on a little custom renderer and decided to go with [kivy](https://kivy.org/#home) over electron mainly due to resource hogging (caveat: I have a strong aversion to front end web hacking) and because I found GUI libraries in rust for multimedia apps to be still a bit rough around the edges. Very early days so can't comment on how well it's worked out yet. I'm using sockets, but there is also [pyo3](https://github.com/PyO3/pyo3). Just a thought.
Definitely this. ^ How does ropey work when it comes to arbitrary data is need to know.
Not too long ago, I used an old laptop with 2 GB of memory, and no hard drive, so no swap. I was livebooting, with no spare space on the USB stick, so if I saved or changed a file, it went into RAM as well. I had to keep an eye on the memory usage all the time, and it sometimes went to high and everything crashed. :-) I even contemplated [mounting a swap over the network](https://www.reddit.com/r/linuxadmin/comments/47zara/mounting_a_swap_file_over_sshfs_even_if_crazy/). Eventually I put a swapfile on an SD card that I put in the built-in memory card reader. Anyway, even with more memory available, I don't want to risk a crash when I use too much.
This thread contains all the stuff I would have said in response to Boscop :)
Originally, it was associated with a reactor right when accepted from the listener. It's possible that's changed in tokio, I haven't looked at that part in a while, such that it registers on the first read/write.
But isn't that exactly what ropes are good for? You don't need to change the original buffer, you just allocate a new leaf node with the newline and insert it in the tree.
what do you mean?
Hey! I'm trying to do the web server project in the [book](https://doc.rust-lang.org/book/second-edition/ch20-01-single-threaded.html). But I cannot even get past creating the `TcpListener`. Running the following code: use std::net::TcpListener; fn main() { let listener = TcpListener::bind("127.0.0.1::7878"); println!("{:?}", listener); } just gives me: Err(Os { code: 11001, kind: Other, message: "No such host is known." }) I'm on Windows 10 64bit. I tried running it as administrator and also tried different ports (including 0), still the same result. Does anyone know what the problem could be?
1. The `CurrentThread` executor doesn't require `Send`, but in order to send the future *to* a `CurrentThread` executor (i.e., a thread on the pool), it needs to be `Send` :) 2. You already get some of this for free. Specifically, any additional futures spawned (using `tokio::spawn`) from inside a future that has already been assigned to a thread will be assigned to that same thread. There could also be a `spawn_to` method though!
As seanmonstar observes below (above?), yes, in theory you should be able to just replace that with `tokio_io_pool::run`. I don't know whether the "root" future in `hyper` can simply be `.wait()`ed on, which is what the current `::run` does, but that's also something I hope to improve in the future. You can set up thread-local variables by setting an `after_start` closure using `tokio_io_pool::Builder` :)
Yeah, I was worried about this too initially, but carllerche [pointed out](https://gitter.im/tokio-rs/dev?at=5b4a249c95e03e3d7b4a8168) that the association with a reactor actually happens the first time the I/O resource is *polled*. And thus each stream will be associated with the reactor of one of the pool threads. As for `blocking`, I think this already won't work because `blocking` [crashes](https://github.com/tokio-rs/tokio/issues/432) when used with the `CurrentThread` executor. This is a little sad, and I think we'll need work-stealing to fully resolve that.
I haven't tested that, so I can't say for sure. But I would expect it to probably be fine. Generally speaking, Ropey only accesses the parts of the text in memory that are actually requested in the calls, so if the calls are only working within a small area of the text, only that part would need to be in memory. Of course, I would still expect _some_ slowdown, and especially if you're doing lots of incoherent edits or queries then it would be as slow as anything else with incoherent access patterns in swap. Also, my general experience with significantly spilling into swap with any software is that it tends to slow down the system as a whole, so I wouldn't necessarily expect that to be different with Ropey--but that's not anything to do with Ropey in particular. In any case, I don't know for sure. If someone wants to test that out, I'd be very curious about the results!
But unlike Go, Rust has generics - and they tend to be quite verbose, at least on the declaration side. So that function implementation is going to look more like: pub fn&lt;'a, R, S, T&gt; MyType&lt;R, S, T&gt;::new() -&gt; MyType&lt;R, S ,T&gt; where R: Trait1, S: Trait2&lt;'a&gt;, T: Trait3&lt;R, S&gt; { // ... } pub fn&lt;'a, R, S, T&gt; MyType&lt;R, S, T&gt;::from_string(String) -&gt; MyType&lt;R, S ,T&gt; where R: Trait1, S: Trait2&lt;'a&gt;, T: Trait3&lt;R, S&gt; { // ... } And so on - you'd have to repeat all that for each method!
Thanks! That works. I think my issue was that I was doing `vec.iter()` instead of `into_iter()`. Guess I'll have to read up on that.
Rewrite it in Rust, and then I'd be interested. :P
There are many different ways to design a text buffer for editing, each with its own trade-offs. Doing something like memory-mapping a file and using a piece table on top of it is one way to go, for sure! Ropey is designed with the assumption that you want to load the file into memory and want the various basic editing and query operations to be as fast as possible. If you're curious for an overview of Ropey's guts, I wrote up a [document explaining them](https://github.com/cessen/ropey/blob/master/design/design.md), which also briefly describes some of the reasoning behind Ropey's design choices. In any case, I'm certainly not claiming that Ropey's design is The One True Way. Far from it. But I do think I've made good choices with good trade-offs for many use-cases.
Line 31 forces the type to be inferred as a reference, as you yield a reference. Later, it mismatches when you return the struct, and the entire thing mismatches because of that first yield.
Please either post the full error message or a fully compiling piece of code (except the error),
Oh thank you, I'd forgotten about that other return. That seems to have cleared up that error, although I'm now having issues with finding a lifetime for the return value that checks out
You may be thinking of piece tables. Ropes let you share data between ropes, but not (at least normally) with a flat buffer. I suspect it would be possible to change Ropey to initially have its leaf nodes point at string slices in a flat buffer, but I don't currently have any plans to do that.
I don't think ARM devices can be called "embedded" in this context. They can run pretty much anything under Linux these days.
Yes, there's only one Cargo.toml. You don't need to add anything, it already has the name there. It should look [like this](https://doc.rust-lang.org/cargo/reference/manifest.html#the-package-section). 
You're welcome! Yeah, all grapheme-related code (except for making sure CRLF clusters don't get split across leaf nodes) has been removed. Of course, grapheme support is still critical for a good text editor, so I've included examples of how to efficiently implement that on top of Ropey: - [Grapheme iterator](https://github.com/cessen/ropey/blob/master/examples/graphemes_iter.rs) - [Prev/next grapheme stepping functions](https://github.com/cessen/ropey/blob/master/examples/graphemes_step.rs) But this gives the client code full control over how it wants to handle segmentation. 
You can compile wasm to a rust module: https://github.com/CryZe/wasm-to-rust
Why use SDL over HTML and CSS? One of the reasons Electron is so successful is because everyone already knows the tooling.
&gt; Relatedly it might be a good idea to guarantee that a \r\n doesn't get split into two tree leaves. Though I'm not sure if it's worth the downsides. This is already guaranteed! :-) I'll add that to the notes about line endings, along with CRLF behavior when slicing. But to answer your slicing question here as well: if you slice through a CRLF grapheme, splitting it, the resulting slice behaves as if only the part of the CRLF it got is present. Essentially, slices don't "know" that they're part of a larger text, and behave as if their text is the only text that exists. &gt; Document what byte_to_char does when the index points into the middle of a codepoint. Ah, good point! Will do. To answer here as well: it returns the index of the char that the byte is a part of. &gt; I'd expect a function called slice to take byte indices, not char indices, might want to rename it to something like slice_chars. Hmm. I'll have to think about that. A rename would indeed make that clearer, but would also make client code more verbose. And given that Ropey already has strong and documented stance that editing and slicing operations are done in terms char indices, I'm not sure if the verbosity trade-off is worth it.
Thanks! And thanks for the question, too. :-) Handling different text encodings is outside of Ropey's scope, but making it convenient and flexible for client code to tackle encodings is absolutely one of the considerations in Ropey's design. The expectation is that most "serious" editors will largely ignore the `Rope::from_reader()` and `Rope::write_to()` convenience functions, and instead work directly with [`RopeBuilder`](https://docs.rs/ropey/0.8.0/ropey/struct.RopeBuilder.html) for reading and the [`Chunks`](https://docs.rs/ropey/0.8.0/ropey/iter/struct.Chunks.html) iterator for writing, incrementally encoding/decoding a chunk at a time with something like the encoding\_rs crate. Maybe this is worth pointing people to in the `from_reader()` and `write_to()` method documentation. &gt;There are also other instances where you have a file that's predominantly UTF-8 but has an encoding error somewhere. If the editor wants to preserve that encoding error, what is the guidance on how to deal with that in ropey? By encoding error, do you mean just straight-up invalid utf8 data? If so, Ropey can't handle that. It expects valid utf8, and explicitly doesn't handle arbitrary binary data. Having said that, client code could easily substitute something valid (such as the unicode replacement character) in place of the invalid data while loading. But that won't preserve the encoding error, of course. Out of curiosity, what is the use-case you have in mind for a text editor handling arbitrary binary data?
&gt; slower than asm.js My understanding is that asm.js isn't that much slower than native performance. It starts up slower of course, because it has to be parsed (from a verbose JS subset) and compiled. But I've seen some benchmarks where it's within 2x of native.
I have it enabled. As far as I understand it, it is used for suspending the OS. Also, I had some 40GB compile jobs and that would have been impossible on an 8GB laptop without swapping.
Finally got a chance to spend some time on this. It IS good. The guy skips a bit in his explanations, and assumes a lot of knowledge in the reader, but I get by on having already gotten quite far in the two books... and google of course. But he's funny, he explains the stuff that actually matters, he shows us why the obvious answer is wrong and THEN fixes it, instead of just providing a Stack Overflow implementation. Yeah, this will do just fine :)
You should have it enabled for OOM scenarios so that processes don't randomly crash - once you're OOM without swap space, any call to malloc is liable to fail and most software doesn't have good error handling for that scenario. With SSDs and NVME in particular, swap can be very fast. It's still orders of magnitude slower than keeping everything in memory but on a dev machine with 16gb+ of RAM, swapping should only occur in rare circumstances where the kernel doesn't have much choice or when the data is used so rarely that it doesn't make much difference.
&gt; Out of curiosity, what is the use-case you have in mind for a text editor handling arbitrary binary data? Well, the CSV as latin-1 use case. The way I framed makes it _sound_ like it's just a simple matter of the editor performing a transcoding step, but this pre-supposes the fact that the editor even knows it's latin-1 to begin. In terms of use cases, I can open such files in `vim` just fine and even edit them without worrying about transparently changing a part of the file I didn't touch. But that isn't the only use case. Sometimes the world just doesn't cooperate and doesn't give you valid UTF-8. Web pages are an example of this, even when a web page advertises its encoding as UTF-8, it may not actually be true. Being able to open, inspect and manipulate files like this in my text editor is something I've done on more than one occasion. File paths are another example of this where on Unix they can be arbitrary bytes. My suspicion is that there exists a design for a rope data structure that operates on `&amp;[u8]` containing arbitrary data but still provides the same level of Unicode support that you provide today by assuming it's UTF-8 but not erroring when it sees invalid UTF-8 (or perhaps, permitting the behavior upon witnessing invalid UTF-8 to be configurable). The regex engine achieves this by using an internal implementation the works on `&amp;[u8]` and exposes two completely different API surfaces: one for `&amp;[u8]` and another for `&amp;str`. Both provide full Unicode support.
I think the person's point was to make it look to the native platform, and use its patterns. Vs having an app that fits both.
Well, that's all I needed out of this thread. Thanks so much for the heads up, this is going to be a huge time saver!
I don't run anything critical on my computer, so if a program crash I can just restart it :) As for the programs I write, I've found along the years that no matter how carefully you craft a program, there's always the unpredictable: - the user pressed CTRL+C to interrupt the program, - the disk is unreliable so you cannot save *right now* (maybe it was a network disk?), - a segmentation fault comes out of nowhere and bring the program down, - ... Rather than trying to handle every single source of failure, I've found it more reliable, by far, to embrace the fail-fast principle, and design the program so that the work it was performing can *always* be resumed. Since a program's results are generally centered around I/O (disk, database, other services), it's a much smaller surface than all possible programming/hardware errors to consider. Just design the few I/O interactions in a way that they can be resumed at any point, and you won't find yourself in a pickle if the program crashes^1 , even if such crash is due to an OOM situation. ^1 *Though if it crashes due to a programming error, a patch may have to be applied before you can resume successfully. That's still the least of the consequences, so I'll take it.*
Oh I fully agree with that general approach. For me, having some swap space around is just an extremely low cost preventative measure. Since the mental overhead is zero and disk space is plentiful and plenty fast, it's far better to reserve some swap space than deal with the occasional crash-restart-restore state cycle (which are rare in general, even when working with relatively unstable professional software like CAD, but also time consuming). I haven't experienced any slow down that I could trace to excessive swapping, however, so that cost benefit analysis may not apply to everyone.
Debatable. Decreasing swappiness is a commonly recommended performance tuning technique, but for most workloads, it doesn't make sense. Swapping is good. Applications aren't the only things that use RAM. The OS can use your memory to create buffers to, for example, optimize network transfers. It also can cache frequently-accessed files to reduce disk usage. So maybe it will feel slow when you switch back to that document editor you haven't touched in a while, but at least your web browser's profile was been cached in memory so you didn't have to read from disk every time you loaded auto-completion from your url bar, or whatever. One case swappiness doesn't make sense is database servers, where the database software is smart enough to manage memory itself and has a better idea of the underlying data structures than the OS. The OS might try to cache files for the DB, but perhaps at the expense of swapping some of the database's RAM out, leading to unnecessary slowness.
Oh, that's really interesting! I suspect it wouldn't actually take that much work to adapt Ropey to handle this. All of the functions for e.g. finding char boundaries, line endings, etc. are hand-coded, and wouldn't take much work to make happy with arbitrary bytes (if they're not already--I just never thought about this, so didn't verify). Then the rest is a matter of adding some API's for working with \`&amp;\[u8\]\`, and storing a flag in \`Rope\` for whether it's entirely valid utf8 or not (and panicking on methods returning \`&amp;str\` when not). I'm pretty sure this could all be done in a backwards-compatible way, so I don't think I'll address this for 1.0. But I'll consider it for later!
Awesome, great to hear it!
I've had that happen before when I had swap disabled, so I added a cron process to kill anything that looks like a runaway process (i.e. if my free memory dips below a configurable number like 10%, I kill the top process). However, with 32GB of RAM, the only time I had that happen was when I was testing a Python program, and the library had a gigantic bug/memory leak, so I'd say it's very rare. And obviously, I can easily comment out and disable the cron process whenever I want. I have since gotten rid of it though, as now I have 128GB of RAM, so I truly live a leisurely life.
To be explicit about 2, what I was thinking, which seastar has, is you can share requests to a certain thread. For example a key value store, where you hash the key to a specific thread. There‚Äôs a multi core redis implementation one seastar that works like this.
That's more than the size of the SSD in my laptop
Why did you decide to use capnproto instead of just using serde with bincode? Did you want to allow changing the protocol while client browsers are still using the old version of the frontend (from cache)? Wouldn't it be a valid solution to just reload the frontend from server when the protocol has changed (if the change is incompatible)?
Because you can render HTML with CSS on a (hardware accelerated) surface if you want to. So the the can be embedded in the native application as any other dependency it has. That doesn't change anything about the application container. But I agree that those parts are what make electron successful. So those parts should probably become sort of essential libraries for this stack.
During the development I had some alternative implementations which used serde and my own created message types, which is a valid approach too. The reason for using capnp was the performance aspect and the ability to versionize the API. 
Or you could define the graphics primitives based on canvas and webgl, in which case the HTML and CSS renderer would make perfect sense in this application container. But that is also what's lead to vendoring electron itself with each application. So deciding not embedding those parts might make for this version dependency to be loose enough for not going that route. That would make the application container more akin to docker, Java or flash. Ignoring the bad parts of those systems, they were able to update the trusted part more regularly with often little impart on the applications they support.
The why: &gt; Our team was made up of developers with experience of C/C++ systems engineering and developers for whom this was their first systems-level project and statically compiled language. &gt; Both appreciated the extra comfort, guidance and security provided by the Rust compiler. Rust allowed the experienced developers to move fast and develop features quickly with less errors, and allowed those exploring systems development for the first time to move forward with confidence, curiosity and protection from the "gotchas" of C/C++. This pairing seems like a perfect reason to choose Rust. 
You can convert u8 to char via the 'as' keyword. Just do this: c[0] as char
You want [`char::from_u32`](https://doc.rust-lang.org/stable/std/char/fn.from_u32.html), which turns a codepoint into the corresponding `char`. Beware of edge cases though. One character is up to four bytes, so you probably want a more intelligent routine to read one character instead of one byte. Additionally, locking individually for each byte or character read is going to be inefficient.
I would be interested in performance comparisons between this lib and one in Rust..
Hey, we initially wrote our vst plugin using the rust VST crate and it was pretty awesome. When we started looking at GUI editor options we ended up opting for turning our current rust VST into a static library and linking it into a C++ Juce frontend. We did look into doing a Conrod GUI but ended up running into issues when dealing with the VST window handling. While there were ways for us to work around the window handle, I wanted to keep my VST cross platform. I'm definitely interested in seeing how the rust VST stuff develops going forward though, and I'm interested in helping the VST community grow in Rust so I'll definitely take you up on your offer. 
&gt; can Ropey work with files that are larger than available memory? And the answer is no. Why not support mmap-backed memory segments?
The debugger did save me in the end, but I don't really understand why the solution I found worked. My new rust code is as follows: pub extern fn parameter_changed(obj: *mut Driver, id: *const c_char, val: f32) { let obj = unsafe{&amp;mut *obj}; let str_bytes = unsafe{CStr::from_ptr(id)}.to_bytes(); let str_bytes = str::from_utf8(str_bytes).unwrap(); obj.set_parameter(str_bytes, val); } Taking str::from\_utf8(str\_bytes).unwrap(); out of the set\_parameter function call and putting it into a variable seems to have fixed my issue, but I'm not sure why. Any ideas?
You could make a hash based on some basic isomorphic invariants. Add this with a [linked-hashmap](https://github.com/contain-rs/linked-hash-map). I think it could be more efficient because you will filter a lot of graphs and won't recalculate the number of edges/nodes/nodes with number of edges/(strongly) connected components/cycles of length 3/something of linear/quadratic complexity.
Thank you C[0] as char != 'q' It is working
Requiring kernel-level support is not a bad thing per se, but from experience, most of such tools (not only in the profiling area) tend to not be portable and/or have different features depending on the OS. Further, if you need kernel-level support, it's likely that the userspace tool will need extended privileges. perf may be very cool... but it's Linux-only. Of course, some features can only be implemented via kernel code... so it's a matter of tradeoffs, as usual. There is something nice about bundling performance tools in every server or tool you deploy, exposed for-free via e.g. an HTTP handler, and in a consistent manner across programs and platforms. I like having the same tooling on all the systems I develop on.
Makes sense, thanks!
Except it doesn't have the name there. It just has the first three lines (name, version, and authors). The docs make it sound like as long as ```lib.rs``` is in the ```src``` directory, it can pull module definitions from there. But that's what I tried, and it's not working.
I'm not 100&amp;#37; sure how to answer that, other than it isn't part of the trade-offs I made. Which I guess is about the same answer for any "why not feature X?" question. Ropey simply isn't intended for larger-than-RAM situations. But I suppose some more specific reasons are: * In general (IMO), text editors should support loading/saving files from/to different text encodings. Unless the editor has multiple code paths for individually working with each encoding, that means that for the general case you need to decode the whole text file into RAM with a canonical encoding anyway. So memory mapping doesn't help. You could, of course, decode to a temp file, and then memory map that... but, again, different trade-offs. * Ropey still needs to keep its own data structures in memory, regardless. Granted, those structures are small compared to the total text size (and I hope to get them even smaller over time), but it's still enough that the ceiling of what you can load is lower than people might expect when they hear "memory mapped". I'm certainly not claiming these are the only valid trade-offs to make. And it would be great to see other libraries that make other design choices! I would be especially interested to see something based on piece tables, which I think would work especially well for memory mapped, larger-than-ram kinds of situations.
That code won't behave the way you expect on keyboards not using the US QWERTY layout. Characters outside the ASCII set, such as the √© and √® on French AZERTY keyboards, take multiple bytes to represent. ssokolow@monolith rust_test [master] % cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs Running `target/debug/rust_test` e [10] e [101] [10] √© [195] [169] [10] Here's what you get out when using the `as char` approach: ssokolow@monolith rust_test [master] % cargo run Compiling rust_test v0.1.0 (file:///home/ssokolow/Documents/Critical/src/rust_test) Finished dev [unoptimized + debuginfo] target(s) in 0.94 secs Running `target/debug/rust_test` e '\n' e 'e' '\n' √© '√É' '¬©' '\n' Unfortunately, I'm not sure how to get the "pop off just the next character" behaviour you want without re-implementing the basic UTF-8 mechanism for synchronization. (There's a table in the [Description section](https://en.wikipedia.org/wiki/UTF-8#Description) of the Wikipedia UTF-8 article but, basically, the first byte tells you how many additional bytes you need to read to get the rest of the character.)
cc: /u/boscop 
I'm no expert, but that looks to me like you're still triggering undefined behaviour, but reorganized things so that the optimizer expresses it differently. The only safe semantics that change would have altered is the lifetime of `str_bytes`, which would have given you an error before if that was the problem. Also, is there a specific reason you're using `CStr::to_bytes` followed by `str::from_utf8` rather than just `CStr::to_str`?
Ok, so I do that and get a problem: `impl&lt;R: Iterator&gt; Iterator for RelIter&lt;R&gt;` `where R:Relation` `{` `type Item = Row;` `fn next (&amp;mut self) -&gt; Option&lt;Self::Item&gt; {` `Some(self.data.row(self.pos))` `}` `}` When try to use it: `fn main() {` `let r1 = Row {` `names: vec!["a".to_string()],` `data: Vec::new()` `};` `for row in r1.iter() { //&lt;--iter() not found in Row` `println!("{:?}", row);` `}` `}` The intention is to apply the [same kind of operations](https://en.wikipedia.org/wiki/Relational_algebra) across anything that is a relation. With a class-based language or swift protocols is easy, but now in Rust how turn r1 into Relation? This is what I have in swift: `protocol Relation {` `}` `struct RelScalar: Relation {` `init(data:Value)` `}` `func makeScalar(of:Value) -&gt; RelScalar {` `return RelScalar(data: of)` `}`
This would be a huge boon. 
I think you want https://doc.rust-lang.org/std/ops/trait.CoerceUnsized.html
Just a comment on the code quality itself; I think you have done an excellent job. It is set out clearly, well documented and it is a pleasure to follow and read the code. Well done. 
Could it be possible to convert the vector into a String and get then just compare the strings? c.iter().collect::&lt;String&gt;() != "q" Of course, it doesn't matter if only comparing an ascii character anyways, but for another character it might be useful.
Yeah. We need a better files API for the web, but I think PWAs will do the trick.
Yes, there is no good GUI solution for VSTs yet.. We have a [mac-only solution](https://github.com/robsaunders/webview-rs) and a [Windows-only solution](https://github.com/vanderlokken/rust-vst-gui) (both are embedding a browser web view), but they aren't unified into a cross-platform crate yet. Btw, some time ago I forked winit, piston and conrod to allow passing the parent window handle down to where the window is created when using conrod. It works, here is an example gain plugin: https://github.com/Boscop/easyvst/blob/master/examples/conrodgain.rs
Is there a `#` thingy for preventing macro arms from appearing in documentation?
Great write-up!
Those structs contain an associated labeling, which is I think what you referred to by invariant. But it isn't enough to hash that because it is many to 1, ie as far as I know there is way to label graphs so that if the labels are equal, and therefore that hashes too, then the graphs are isomorphic
Sorry for the delay. Yesterday was distracting and, by the time I remembered, I was once again too tired to be properly insightful. Typically, the solution I've seen to make the intent clear is one of the following: * Use a different "terminology" font for the "Acquire read". * Put "Acquire read" in quotes * Replace "Acquire read" with `load(Ordering::Acquire)` inside `&lt;code&gt;` tags.
Honestly, the thing I'm most looking forward to. Anyone knows if they maintain a communication suite not in Russian?
It seems that rustup only has access to nightly toolchains from the past week. Is it possible to install an older toolchain?
I'm working on a Vulkan(o) renderer for ggez. 
&gt; For example, I might open a random CSV file in vim that's encoded in latin-1 that I largely expect to just work. In order to use ropey, I think I'd have to transcode the latin-1 to UTF-8 and then reverse that mapping when writing back out to disk. I wonder how feasible that is. Vim's global `encoding` option tells Vim what encoding to use for text stored in RAM. The buffer-local `fileencoding` option tells Vim what encoding was used for the file stored on disk, and is usually set by trying all the alternatives listed in the `fileencodings` (plural) option until one of them works without an encoding error. Vim converts from `fileencoding` to `encoding` when reading, and back again when writing out. There's also the `termencoding` option that tells Vim how to encode text when drawing to the screen, but that doesn't affect round-trip encoding. 
MyCell variant only accepts Sized types. Line 1 works because i32 is Sized, as the compiler knows what is its size at compile time. Line 2 doesn't because Foo is a trait and traits are usually not Sized, because the compiler can't really tell the size of the trait before the end of the compilation. Please look into the docs for Sized types to get a precise description, as i'm pulling these out of my memory right now. As for the next question, Boxes are fancy pointers of sorts. They represent some heap allocated memory and because of that they implement all sorts of magic methods to allow them to be used as transparently as possible. The same is not true for the RefCell, which is supposed to be used to work around some of the borrow checker paranoia in a relatively safe manner. As such they don't implement many of the traits that boxes implement because they are intended to be used with care. Check the docs for Boxes and RefCells to get more acurate info, but I'm almost sure that Boxes are what you want to use. 
Thank you for your reply. I used ?Sized which I thought means it takes something optionally sized. Did I mess that up? Next, I‚Äôm interested to learn how the compiler is distinguishing Box and RefCell in these cases. Box should be covariant and RefCell invariant, but in other languages with this idea you generally need to declare it. I‚Äôm trying to understand if there is a set of rules (which I wrote an explanation but it may not be the real explanation). Does the compiler special case these types or is there a general principle I could read about with regard to variance?
I'm not sure that comment is applicable to the Rust Embedded WG. Most (all?) of their communications are public and in English. 
Nice blog, what stack/theme did you use?
Can't wait for AV1! I'm hoping to store my movies using AV1, Opus and Matroska in a near future. &gt; ~5 fps encoding @ 480p That's pretty slow though. What kind of gains could be made with hardware support?
Link to the code: http://play.rust-lang.org/?gist=5f290d7a50efb1d92249b1f4bc10453f&amp;version=stable&amp;mode=debug&amp;edition=2015
Swapping very inactive pages out leaves more room for disk caching.
AV1 is itself a great project, and it's cool to see that Xiph is using Rust!
No, you didn't mess up the usage of `?Sized`. It does mean the generic can be unsized, and since you put it in a box, things workout. A reason you can't just convert from `Box&lt;i32&gt;` to `Box&lt;Foo&gt;`, since they are different sizes. A `Box&lt;T: Sized&gt;` is going to 1 word, a single pointer. A boxed trait object is a "fat" pointer (it's two pointers internally, one to the data, and one to the vtable of methods that apply to that specific impl of the trait).
Trying to fix some panics in Vulkano. While also working on my first rust talk! I'll be speaking at the Sydney rust meetup in 1 week o.0
I really hope that AV1 will not repeat `libvpx` in it's terrible encoding performance. Compression ratio is good and all, but if it will take you several hours to encode 1 minute of FullHD video, then people will simply continue to use h264/h265.
&gt; But I need to check each time if is not out of bounds. Yes. That is also what a `for i in 0..len` loop will do: at each step, it has to check to see if `i` is still in range or not. A loop has to have *some* kind of condition check, or it would never terminate.
Something doesn't add up with your explanation though. For example, it's impossible for latin-1 to return an encoding error. I mean, this is okay so long as your internal data structures don't absolutely require valid UTF-8. But if they do, then I don't see how your can achieve the same functionality as vim (easily).
I'm just joking. But Rust w/ nightly breaking things is painful, and the lack of good IDE integration (vscode, at least) make figuring out expected types a painful endeavour. Untyped languages don't deal w/ this.
I don't know myself, but I think it still makes sense. If you start off trying utf8, that will return an encoding error on latin-1, right? So then you keep going from there, trying the other encodings that can error out. Eventually you exhaust those, and then there's ambiguity (e.g. any of the code pages for 8-bit encodings, which aren't distinguishable from each other), so then you just pick one and convert to utf8 from that. If you write it back out with the same conversion, it should be bit-for-bit identical, right?
Very cool. Just an FYI, The trust-dns Client library supports dynamic update with BIND9, using SIG0 for auth. That‚Äôs if you want to get rid of the nsupdate call. Nice post. Enjoyed it.
Oh wow, thanks! To me, there is still a lot that I'd like to clean up and refactor. And there's still a fair bit of code that I suspect can be simplified. But I'm glad it's readable!
Hmm. That might work! I guess you still have to pay the transcoding overhead every time, but I'm guessing that's probably acceptable.
&gt; if it will take you several hours to encode 1 minute of FullHD video, then people will simply continue to use h264/h265. One of the big design considerations for AV1 is real time encoding. Iirc the current goal is optimizing the reference encoder. 
Picking up Ash after creating a ray tracer. 
What's the topic? 
Nope, you can't collect a `String` from an iterator of bytes. `String` is a `Vec&lt;u8&gt;` that uses Rust's usual safety mechanisms to ensure that the bytes are always valid UTF-8. In this situation you probably want `std::str::from_utf8`, which returns a `Result` to handle the possibility that the bytes are not valid UTF-8.
I don't follow. I know the len of the data, I don't need to check at each step in a for: for i in 0..r1.data.len() { r1.data[i] } 
Says it in his about page :)
"Runs on top of Linux" is not really embedded, rust can run on bare metal and fulfill hard realtime requirements.
This is not really off the ground and I think the scope of the project is really large, but my plan is create a project management tool in Rust. I like to call it the project management tool for centralized and decentalized users. It would allow for cli management of your projects by being an interface to GitHub and GitLab, and maybe BitBucket issues. It would also provide backup and offline support. Eventually I'd also like it to have a nice front end created in React and TS. It'll take a while, but maybe one day it'll be a cool finished project.
A regular loop has two bounds checks: one in the `for i in 0..data.len()` to check if `i` is still less than `data.len()`, and another when you index using `i`. An iterator-based loop does that check all in one place.
You're looking for /r/playrust
The loop compares i against len at each iteration.
Why do some packages compile with a binary target, but not wasm32-unknown-unknown? For example, simdnoise.
Working on some web assembly related front end dev projects!.Having made a jsx compiler macro, now I'm hooking it up to wasm and figuring out the lifetimes so that I can update the HTML in response to events. (Hint: implementing IntoWasmAbi on your strict sis necessary. thread_local is a trap!)
Thanks!
If you _really_ want to avoid writing the bounds check, you can store a `Range` structure in your iterator and call `next` on that in your `next` implementation. But the check is still there either way. When you do `for i in 0..len`, the `Range` (what you get from typing `x..y`) is an iterator that has a `next` implementation that reads very roughly as `if low &lt; high { low += 1; Some(low - 1) } else { None }`.
I'm going to be talking about my game pfsandbox.net https://github.com/RustSydney/talks/issues/26
[removed]
Oh thanks
Ohh thanks
Ah thanks!
So, is this because the range? If I change into while not happend, right?
Yeah, I would guess so too. And in practice I suspect there are smarter ways to go about guessing and ruling out encodings, so that you typically wouldn't need to go down the whole list of potential encodings making attempts. Incidentally, Ropey's convenience `Rope::from_reader()` method loads utf8 files at a bit over 1.5 GB/s on my system, which is about twice as fast as vim (also on my system). And `from_reader` verifies that the text is valid utf8 while it loads. So I think there's room for decoding to take place while still being pretty performant.
Based on the issues on github this doesn't appear to be using multiple threads or SIMD yet. I would think that would at least get up to real time encoding for 480p videos.
Not every package is going to support every platform. That particular crate appears to only support x86 and x86_64.
It would be sweet if rayon could help this library.
As /u/cessen2 says, it's a prioritised list, so you need to put any 8-bit encoding last since it will always succeed. According to `:help fencs`, the default (if you're running in a Unicode locale, as all modern systems should be) is: * `ucs-bom`, which fails if the file does not begin with a UTF-16BE, UTF-16LE or UTF-8 BOM * `utf-8`, which fails if the file is not valid UTF-8 * `default`, which means "the locale's encoding", which is probably also UTF-8 * `latin1`, which always succeeds Regardless, it sounds like Ropey with transcoding shouldn't be any worse at handling latin-1 CSVs than Vim is, since Vim does transcoding too.
AV1 isn't just repeating `VP9`, it's [doubling down](https://code.fb.com/wp-content/uploads/2018/04/av1_pic7.jpg). Yes, it's 500-700 times slower than VP9. At least in this particular mode/with these particular settings.
IIRC plans are to use the SIMD accelerated functions provided by libaom.
As you say, your program takes arguments. You could rewrite it to use std::io::stdin instead (perhaps only if no arguments are given). https://doc.rust-lang.org/std/io/fn.stdin.html
I guess the best way to show this is just to go through a desugaring/inlining of a simple for loop: for i in 0..10 { use(i); } First, let's desugar the range construction: for (i in Range{start: 0, end: 10}) { use(i); } and the for loop: let mut __iterator = IntoIterator::into_iter(Range{start: 0, end: 10}); while let Some(i) = Iterator::next(&amp;mut __iterator) { use(i); } `IntoIterator::into_iter` is a noop here, so can be dropped. Next I inline `Iterator::next`: let mut start = 0; let mut end = 10; while let Some(i) = { if start &lt; end { let mut n = start + 1; mem::swap(&amp;mut n, &amp;mut start); Some(n) } else { None } } { use(i); } Or, cleaned up a bit: let mut start = 0; let end = 10; while start &lt; end { let i = start; start = i + 1; use(i); } As you can see, `Iterator::next` defines both the "check" and "increment" part of a C-style for loop.
 let r1 = Row { names: vec!["a".to_string()], data: Vec::new() }; for row in r1.iter() { //&lt;- iter not found You need to add a method like this: impl Row { pub fn iter(self) -&gt; RelIter&lt;Self&gt; { RelIter { pos: 0, data: self } } } ...although that is a *consuming* iterator so `into_iter` would have been a more fitting name. If you want a *borrowing* iterator, you need to adjust `RelIter` like this: pub struct RelIter&lt;'a, R: 'a + Relation&gt; { pos: usize, data: &amp;'a R } impl Row { pub fn iter&lt;'a&gt;(&amp;'a self) -&gt; RelIter&lt;'a, Self&gt; { RelIter { pos: 0, data: self } } } 
The question you want to search for is "how to read standard input in Rust". Standard input (stdin) and standard output (stdout) are available in almost any programming language.
&gt; Except it doesn't have the **name** there. It just has the first three lines (**name**, version, and authors). ...play that back again? :) Anyway, it sounds like something simple is wrong and it can get very frustrating. If you post your code and directory structure somewhere, we can probably figure it out quickly. 
You *can* coerce a thin pointer to a fat pointer, since the compiler knows the concrete type when doing so -- it will assign the `&lt;i32 as Foo&gt;` vtable on the spot. However, their custom `MyCell` won't do this without the `CoerceUnsized` trait.
Under linux you can use this: http://valgrind.org/docs/manual/ms-manual.html Not aware about any rust-specific tool.
This doesn‚Äôt directly answer your question, but I was recently wondering the same thing and ended up at [this SO post](https://users.rust-lang.org/t/how-much-memory-are-my-objects-using/3565), which led to code that got me the answers I was looking for.
[As big as I could get it without hitting the default macro recursion limit:](http://play.rust-lang.org/?gist=b407696fe69a064780d68ddda40e96cc&amp;version=stable&amp;mode=debug&amp;edition=2015) rule90!( (f f f f f f f f f f f f f f f f f f f f f f f f f f f f f f) | W, ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ., ); (I am not indenting the output by hand on my phone, go run it if you want to see the output, I'll maybe edit it in here tomorrow)
Based on chatting in person with a few people working on AV1, there are two aspects: * Some organizations like Netflix (but typically not Youtube) have a small enough catalog of videos that is viewed enough times that it makes sense to increase by 100√ó the compute time (parallelized of course) when encoding a video, in order to compress it further and save on bandwidth. However this is only one possible use AV1. The other extreme is WebRTC or other video chat, where a single consumer laptop or smartphone needs to encode in real time (and low latency). Of course there is a trade-off between how much computing power you spend and how much compression you get. It is expected that encoders will have many settings available, to support different use cases. * "~5 fps encoding @ 480p" is the fastest *today*. A few months ago the fastest was orders or magnitudes slower than that, simply because everyone was working on compression techniques and the bitstream format, and the reference encoder is meant to demonstrate techniques more than for practical use. There is still a ton of room for improvement. When comparing with x264 note that its earliest git commit is from 2004, and even that is a 32k lines import from CVS. This is quite a head start in terms of work that went into optimizing the encoder.
jemalloc (Rust's default allocator on most platforms) has built-in support for that sort of thing. * https://github.com/jemalloc/jemalloc/wiki/Use-Case%3A-Basic-Allocator-Statistics * https://github.com/jemalloc/jemalloc/wiki/Use-Case%3A-Heap-Profiling That or an external tool like Valgrind is the proper layer at which to track memory allocation, so you won't find anything more Rust-specific. (Memory-usage information in languages with heavier VMs operates on the same "ask the allocator to do it" principle... it's just that the allocator is more tightly coupled with the language.)
A [package manager for Idris](https://github.com/dcao/elba). It's still pretty early days, but dependency resolution is down!
That's a really cool topic! I like how you note that you're unsure if it's a full game or an engine; I have the same issue with my own programming-heavy sandbox game. I think games that can incorporate gamedev itself into their gameplay have a really interesting future - that's the direction that Minecraft went for some time with mapmaking and command blocks.
[Week 05 of the Summer Roguelike Jam In Rust](https://github.com/Lokathor/roguelike-tutorial-2018/blob/master/lessons/week05.md) This week we add some potions and bombs.
Is the Gamecube controller all from gilrs? I might have to actually send them the PR to make their xinput loading not be junk &gt;_&gt;
I‚Äôm writing a small lightweight file system for a vm. 
All nightlies should be available. I think there was just a gap in early July where there were no nightly builds available (they are not posted if certain things are failing). The only complete list I know of is at: https://static.rust-lang.org/dist/index.html
[removed]
[removed]
AV1 is definitely awesome. I just hope you are right and that encoding overhead will decrease over time to reasonable levels. It's still early on, AV1 just stabilized.
God rust macros look truly terrible.
It's an acquired taste
And Google can built a custom hardware to accelerate VP9, which is fine for them. But how often do you see VP9 outside of youtube in comparison with h264? Yes, granted hardware acceleration helps a lot, but even without it, the fact that VP9 encoding is unbearably slow greatly hinders its adoption across wide public.
Thanks! If you want to play with the recursion limit, you can use this kind of thing to short-circuit parts of the recursion: ( __inline ($($fuel:tt)*) | ($($lcells:tt,)*) (., ., ., ., ., ., ., ., ., ., ., ., ., ., $($rcells:tt,)*) | ($(($($history:tt,)*))* ) ) =&gt; { rule90!( __inline ($($fuel)*) | ($($lcells,)* ., ., ., ., ., ., ., ., ., ., ., .,) (., ., $($rcells,)*) | ($(($($history,)*))* ) ); }; 
I use libusb to talk directly to the GC -&gt; wii u adapter. It gives me better control over individual ports + slightly more accurate. Its the same thing as what dolphin is doing here: https://dolphin-emu.org/blog/2015/01/01/dolphin-progress-report-december-2014/#40-4594-native-support-for-the-official-nintendo-gc-controller-adapter-for-wii-u-by-skidau gilrs xinput seems fine? Doesnt support dinput though.
They static link to xinput, which is just dumb, no justification. You should dynamically load the xinput dll available on the system and then you can work on previous versions of windows, or even just quietly not have xinput if it's not on the system. https://github.com/Lokathor/rusty-xinput if you want to see what I mean. Feel free to grab out anything or everything there. It's already been integrated into an upcoming winit branch too ;3
This actually checks twice: 1. [the range iterator will necessarily check against the upper bound on every](https://doc.rust-lang.org/src/core/iter/range.rs.html#209-265) 2. the slice index will then re-check the bounds The advantage of iterators is eliding the second bounds check, the first one can't be avoided, the loop has to have a termination condition.
Has anyone ever done an actual study to try and determine whether people care at all if their apps look native, or if it improves usability? I ask because I always here this mentioned as if it's a given. Personally, I almost prefer apps that have their own style. I want my OS to be a simple vehicle for running my apps and then get out of the way. I realize there's a high likelihood I'm in the minority here.
&gt; I'm not sure how to get the "pop off just the next character" behaviour you want without re-implementing the basic UTF-8 mechanism for synchronization. str::from_utf8 can be used for that: [Utf8Error](https://doc.rust-lang.org/std/str/struct.Utf8Error.html) returns the valid prefix, you can use that to "consume" the relevant bits from the slice (possibly using `from_utf8_unchecked` to avoid checking for validity twice) then update the input buffer.
Ooh I see, a gilrs PR to fix that would be appreciated :)
One of those "more projects than time" things :P
&gt; then people will simply continue to use h264/h265 Last time I checked x265 also had bad performances. That's the problem with modern codecs: the high compression ratio is obtained through a lot of calculations.
Am I understanding this correctly that you can only test private functions from within the `src` folder? So I have to basically place all my unit tests under `src`? What's the recommended way to organize this?
Holy... Knowing Russian this was ridiculously hard to read. I still don't know how the package's name is supposed to be pronounced. Can somebody help?
totally understand.
The official Rust convention is to place unit tests in the same file as the code they are testing. You can also make your functions public and export the modules and then add separate (typically integration) tests to `/tests`. Cargo, by convention, compiles and runs each source file into a separate executable when you run `cargo test`.
Cyrconv (CYRillic CONVerter, I assume. Hint: it's in the Github project name)
Thanks, I think I like the `load(Acaquire)` variant.
this is great :D
Is there way way to only allow generics with a specific size?
One of the simplest solutions would probably be to leverage all the support (libraries, apps, etc) that exists for [TOTP](https://en.wikipedia.org/wiki/Time-based_One-time_Password_algorithm), as lots of people already has apps like Google Authenticator and Authy on their phones. It doesn't need to communicate at all after setting it up, meaning that it's possible to use even if the phone is in air plane mode. In addition it's a time-tested solution, used by, among others, Google, Facebook, Github, Lastpass, AWS, Cloudflare, etc.
**Time-based One-time Password algorithm** The Time-based One-Time Password algorithm (TOTP) is an algorithm that computes a one-time password from a shared secret key and the current time. It has been adopted as Internet Engineering Task Force standard RFC 6238, is the cornerstone of Initiative For Open Authentication (OATH), and is used in a number of two-factor authentication systems. TOTP is an example of a hash-based message authentication code (HMAC). It combines a secret key with the current timestamp using a cryptographic hash function to generate a one-time password. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I think those macros are beautiful &lt;3
Sorry for my ignorance...
Preparing to help with Redox the OS. I hope to try and make some user applications to run in it and showcase the OS.
I'm afraid it will not be as straight-forward as the built-in benchmarks. In addition to what has been said, there are a few other, language-agnostic ways using [flame graphs](http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html). 
&gt; The official Rust convention is to place unit tests in the same file as the code they are testing. This makes me gnash my teeth. I'm used to having all my tests in a `test` directory. I could maybe see myself putting tests for `src/my_module.rs` in `src/my_module_test.rs`, but the same file? Is this mandatory for some cases?
[removed]
 $ cat text.txt | ./cyrconv is an equivalent of $ ./cyrconv &lt; text.txt Pipe (`|`) connects the standard output of one command with a standard input of another command. Thus, `echo "..." | my-app` will receive the echoed data via stdin (standard input) instead of arguments (`argc` / `argv`).
You didn't say exactly where you'd want to allow them, but you could check for the size and throw a [compile time error](https://doc.rust-lang.org/std/macro.compile_error.html) if it's now what you wanted.
[removed]
[removed]
&gt; Is this mandatory for some cases? Tests are in no way special when it comes to visibility. If you want to test private items, you need to put your tests in a location where they can access those items, be it in the same module, or a sub-module.
I don't think it's mandatory, it's just convenient because of visibility rules. You can put tests anywhere you want, but if you need to test internal implementation details then using the same file is the easiest way. You can control struct and function visibility with [restricted `pub`](https://doc.rust-lang.org/reference/visibility-and-privacy.html#pubin-path-pubcrate-pubsuper-and-pubself) in order to emulate `internal` and `friend` visibility modifiers from other languages.
I'm a little confused about the semantics of `&amp;`. From what I understand let s = String::from("abc"); foo(s); creates the string `"abc"` on the heap and a slice of the form`(pointer, length, capacity)` on the stack. Then for the call `foo(s)` this entire slice is copied on the stack and the compiler ensures that `s` isn't used after the call because ownership has been transfered. On the other hand, if the call was `foo(&amp;s)` instead, then only a pointer to the slice would be passed, adding a layer of indirection. For general heap-allocated types though let t = my_type::new(); foo(t); just creates a pointer on the stack. And in this case `foo(t)` and `foo(&amp;t)` behave identically, only the ownership semantics are changed. So how can you ever tell what `&amp;` is going to do exactly? Consider let v = vec![1]; foo(v); Perhaps vectors store their length and capacity on the stack like strings. Or perhaps those values are stored on the heap and the stack only contains a pointer. Unless the documentation is generous enough, I wouldn't know how to determine which was the case. Also, how would you ever pass a pointer to a pointer?
How would I do that? And if I would do that would the compiler be smart enough to compile it then. Because atm I get the error this type's siye can vary.
As someone who can actually read Cyrillic: this is terrible D: 
Thanks for the heads up. I'll have a look and try using your crate. Seems to be the better solution to the problem.
In my defense, I was on my phone. :P Thank you.
&gt; several hours to encode 1 minute of FullHD video libvpx-vp9 is not *that* slow. With `tile-columns`, `frame-parallel`, `threads` and a reasonable `speed` (not `0`), it could do around‚Ä¶ 4fps (IIRC) at 4K resolution on my machine.