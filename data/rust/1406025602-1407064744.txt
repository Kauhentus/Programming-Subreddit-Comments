Coming from a functional language, the right-associativity can be quite confusing as I've learned to parse `A B C` as `(A B) C`.
The complaints about leading `::` confuse me; I don't know of any documentation someone can read where they *don't* also see the `use` syntax used repeatedly, and, in the docs I just glanced over, the global path syntax is either not mentioned at all, or first mentioned well after `use`. (I.e. it's not necessarily entirely the fault of the documentation.)
I feel like this would be a bit more aesthetically appealing if Rust didn't use "angle brackets" for the sake of appeasing the C++'ers and just went with either square brackets, parentheses, or functional notation. impl&lt;T: Add&lt;T, T&gt;&gt; Add&lt;Vec2&lt;T&gt;, Vec2&lt;T&gt;&gt; for Vec2&lt;T&gt; { fn add(&amp;self, rhs: &amp;Vec2&lt;T&gt;) -&gt; Vec2&lt;T&gt; { ... } } impl[T: Add[T, T]] Add[Vec2[T], Vec2[T]] for Vec2[T] { fn add(&amp;self, rhs: &amp;Vec2[T]) -&gt; Vec2[T] { ... } } impl(T: Add(T, T)) Add(Vec2(T), Vec2(T)) for Vec2(T) { fn add(&amp;self, rhs: &amp;Vec2(T)) -&gt; Vec2(T) { ... } } impl(T: Add T T) Add (Vec2 T) (Vec2 T) for Vec2 T { fn add(&amp;self, rhs: &amp;Vec2 T) -&gt; Vec2 T { ... } } // for comparison, this is the closest approximation in Haskell: // instance Add t t =&gt; Add (Vec2 t) (Vec2 t) where // add self rhs = ... Part of the problem is that due to C++ my eyes are sort of trained to see `&gt;&gt;` as a single operator rather than as two closing delimiters. It would also help if the type of the function could be inferred but that's a much tougher problem that I'm not even sure can be solved.
It's mentioned in the new guide, for what it's worth: http://doc.rust-lang.org/guide.html#installing-rust
The reason why concepts never made it into C++ is because they couldn't come up with an agreeable design for duck-type traits. And they are still working on it. So I'm quite iffy about how it would come out. I'm also not sure how it would interact with the rest of the type system (especially the type inference part). It could possibly work, but you might end up with some awful, unreadable type signatures inferred by the type engine. And lastly, it helps to have the explicit (albeit ugly) signatures so that the code is inherently self-documenting. It would be quite a surprise if I call a function that apparently claims to work on all types `T` yet fails because there's some hidden trait involved. Merely failing at compile time isn't necessarily helpful, the compiler needs to give sane error messages. C++ is notorious for generating pages of confusing error messages: try using `&lt;&lt;` on a type where you didn't define a suitable overload, or try using `std::sort` on a type without a comparison operator.
Interesting! I had only checked the 30 minute intro and the tutorial, since those seemed more aimed towards new users than the full guide. Thanks.
I know this is not something fundamental like lifetimes elision but it still is a suggestion to improve one of the most important parts of the standard library. Comments are very welcome.
&gt; Because failing early is almost better than later. It will fail at compilation time, what would be earlier? You'll get a warning about `x` being unused if you don't use it, and an error because it's of type `()` if you try to use it as an integral value.
Note that *bugs* (e.g. `None/Some` and broken TI) are not criticisms of Rust (and thus not disappointment, unless "rust disappointment" is "disappointment in the current implementation state")
It can fail earlier at compilation time, i.e. closer to the original behaviour that's likely to be a mistake (in this case, the `x = y = ...;` is semantically useless and could be outlawed, but IMO).
Re-wrote my FizzBuzz with dbaupp's help using slices
&gt; The complaints about leading :: confuse me; take that as a symptom of the relative vs absolute paths which usually trips up newcomers, its possible more error messages might help. personally I find the deep namespacing can get excessive aswell (::std::vec::Vec) -in conjunction with methods also being divided by traits - maybe this is library design (could vec::Vec be reexported by std?) or maybe error messages could navigate for you "Vec not found, try std::vec::Vec"
&gt; take that a a symptom of the relative vs absolute paths which usually trips up newcomers, its possible more error messages might help. To be clear: I'm confused how someone could know about global paths, but apparently not about `use`.
Implementors of the trait need to at least override one of the two methods. Could we add some kind of metadata (e.g. an annotation along the lines of `#[mustImplementOneOf(one, other, ...)]`) so that failing to override at least one function would be a lint-time error?
[#7771](https://github.com/rust-lang/rust/issues/7771).
Very good! Glad to see the stdlib getting more consistent. I've never worked directly with the socket APIs, but the RFC makes it seem like a clear win to me. On a side note, isn't the convention that only zero-cost conversions should start with `as_`?
Thanks. I should have looked into the issue list before commenting. ;-)
I haven't heard of it. Anyway, as I said in the RFC, exact names should be discussed anyway, so if there really is such a convention, I'll modify the RFC.
I have now, though If I had come to the thorn library from somewhere other than r/rust I would not known that thorn_sfml existed, so It would be helpful to put a link to the example in the README for the thorn project. That said there is a lot more going on in this example than is necessary to demonstrate what thorn can do for me. Reading through that example I see where *ResourceSharer* is used, but it's not clear why. For example, the font_sharer object is created, has a single method called in the main scope, and a single reference in the while loop within the main scope. Why does this resource need to be shared? Again I've never used something like this, so I may not be giving you any valuable input here. However, it's not obvious to me when I should choose to do use the library. If you can write your examples and documentation to help me decide whether using Thorn is the right choice then you're doing something great! 
Given that [the Runtime is a trait](http://doc.rust-lang.org/std/rt/trait.Runtime.html) this should be possible, at least in theory. I'm not sure of the mechanics though
For me: [T] - really really Bad, &lt;T&gt; - is better, (T) - is not that bad, especially if you know D :) Of course Haskell is the tersest one. By the way in C++11 &gt;&gt; is valid in templates too. 
His criticism is certainly imprecise and emotionally exaggerated. Speculating whats going on in his head - cut through the emotion to see what generated it:- He indicates he doesn't like `using namespace std` in C++ (when he confusingly says 'rust-disapointment: std by default..') I bet he prefers to write "std::vector" rather than 'using std::vector;' (.. a member of the 'explicit is best' crowd); he's gone ahead making type aliases like 'Tiles' .. maybe thats his preferred workflow for managing deep names ..I would prefer Vec&lt;Tile&gt;, but his way allows him to change the collection later. if his mindset is to manage with typedefs, the extra 'use' probably wouldn't have helped him ... it's just another jump in the source .. so either he didn't look for it, or he's writing this example to illustrate the problem he feels. He's got a single source file but has divided it into mods ... probably just to illustrate what he doesn't like about rusts path behaviour 
Maybe 'hate' is technically too strong a word. I'm thinking like 'haters.'
I don't say that it make Rust an bad language in the future, I just agree that this is something that can frighten newcomers.
Odd. I was not in Chrome and OSX Preview.
Very nice! [Here][1]'s an earlier article using Haskell that's similar in spirit, also "solving" FizzBuzz using monoids. (Sadly the original seems to have fallen off the Internet; thank god for the Wayback Machine.) We should have `Semigroup` and `Monoid` traits in `std`. They're very useful and, unlike most similarly useful type classes, don't even require HKTs. (Perhaps we might want to come up with more non-mathematician-human-friendly names for them, like `Combinable`.) [1]: https://web.archive.org/web/20121021233736/http://dave.fayr.am/posts/2012-10-4-finding-fizzbuzz.html
Yeah I really like parentheses. I would actually be in favor of changing it because I don't think they'd be *that* alien coming from mainstream languages (unlike `[]`, which can be pretty confusing at first). Seems very, very unlikely that it'll happen though.
&gt; impl[T: Add[T, T]] Add[Vec2[T], Vec2[T]] for Vec2[T] { impl(T: Add(T, T)) Add(Vec2(T), Vec2(T)) for Vec2(T) { I think parentheses are by far the most natural option.
I don't think components are supposed to be polymorphic in that way. In any case, vtables are a large amount of overhead, if you have lots of types of a trait object it means that nearly every virtual function call will be two cache misses. Components are supposed to be plain old data stored inside of "Systems", as a flat array such as Vec. The "Entity" is simply an ID for which components are tied to. This pattern is limited and you will probably have to break out of it when you need relational data and other things which do not cleanly map to the "every component has a single parent entity" of ECS.
Maybe paths should be with `/` so people understand they're paths? pub type TileVec = /math/Vec2&lt;i32&gt;;
I've crafted this is in a few minutes to clean up my tests cases that needed `before_each` block badly. Couldn't use move out of internally called function as I had a bunch of [T]s in there. Made it look a bit like rspec (ruby) / kiwi (ObjC) Worth wrapping in a crate?
Quick, spot the heavy C++ users in this thread! They are the ones who get where this person is coming from and understand the complaints. It's important to realize that C++ has a Way about it, and Rust violates some of that Way, causing discomfort. 
YES! This is fantastic!
Absolutely. Using indentation to delimit blocks is just so elegant. Unless it's wrongly indented, indentation of code is just redundant information. Removing this redundancy while getting rid of visual noise is just ideal. The same applies to naming conventions, although significant naming style would have the single downside of needing possibly altered names for bindings. (E.g. Qt bindings in a language requiring snake_case would need transformation of Qt's camelCase names)
&gt; rust-disappointment: type is a keyword &gt; Agree : type is a useful word a lot of people may want to use in a struct, even if not a huge concern for me. Yes this. Its getting lost in all the noise but it was a real annoyance for me. "type" is just too generic and common a term to be reserved as a keyword. 
I just realized: what happens if unwinding happens while a `File`, or other linear type, is in scope? :C There seems to be a fundamental conflict between unwinding and true linear types. Unless you just resolve it by having unwinding past a linear type be a program abort in all cases... Maybe that would even be a good idea, though? Maybe the two could serve different use cases. Embedded environments and the like would prefer to use linear types and abort on failure, while high-availability task-based architectures would prefer affine types and unwinding.
&gt; Worth wrapping in a crate? The answer to this is always "yes."
Go full PHP. pub type TileVec = \math\Vec2&lt;i32&gt;;
This is a running debate in the Haskell world too. Names from math have the advantage of being completely precise as to what the thing is intended to mean. I personally prefer using more approachable names and prominently mentioning the correspondence with the mathematical concept in the documentation, but there are good arguments on both sides.
If you use generics properly you can have a vector of components of the same type which are allocated in the vector without indirection and then also called with static dispatch: trait Component { fn update(&amp;self, current_time: f64); } struct SubSystem&lt;TComponent&gt; { components: Vec&lt;TComponent&gt; } impl&lt;TComponent: Component&gt; SubSystem&lt;TComponent&gt; { fn update(&amp;self, current_time: f64) { for component in self.components.iter() { component.update(current_time); } } } This is one example where Rust allows for "zero-cost abstraction". The code above is abstracted over the concrete component type but does not force components to be accessed through a costly indirection. 
What you're thinking of is not an ECS. It's just a different take on OOP.
Thanks! I did mention during the talk that I was ignoring that the string concatenation was quadratic and that we would really want to use a different data structure, but had neglected to learn about this important property of String append, because the original code was ported from Scala where I also deliberately ignored the issue of string concatenation, especially when moving to the parallel case. I will update my code accordingly, although I am curious what the story will be when I add actual parallelism for the Rust example.
Because the latter stores the vector returned by `os::args` in a local variable, while in the former it just lives in a temporary and lifetimes of temporaries aren't extend by references to them.
`as_slice()` is a view of the same memory as the String you call it on, so it has the same lifetime. In the first example, file_name refers to the slice, which won't outlive the underlying String, which won't outlive its containing Vec, which is just a temporary with the lifetime of the expression. `let args = os::args();` in the second case extends the lifetime of the Vec, which extends the lifetime of the String, which extends the lifetime of the slice. Alternately, you could change the first example to something like let file_name = os::args()[1].to_owned(); let path = Path::new(file_name.as_slice()); let mut file = BufferedReader::new(File::open(&amp;path)); 
If we can think of better names, we should use them. The vast majority of people are not enlightened by adhering to mathematical names, and adopting elitist jargon only serves to erect barriers to language learners. Sadly, programmers are generally just as awful at naming things as mathematicians are. :)
But this does only work at compile time right? For example let s = SubSystem&lt;Component&gt;{components: [Component1,Component2]}; And it doesn't work anymore if I try to add new components at runtime like s.components.add(component3); 
FYI, [an RFC](https://github.com/rust-lang/rfcs/pull/66) to improve this use case was accepted last month, and [there's a tracking issue](https://github.com/rust-lang/rust/issues/15023) for it :) I don't know if this should be expected to land before 1.0 though.
Hm... perhaps someone who knows exactly how this works can explain in more specific detail how this actually works, but I've always understood it as the code: x().y().z(); effectively expanding to: let t1; let t2; let t3; { t1 = x() }{ t2 = t1.y() }{ t3 = t2.z() } Ie. If x() returns a value it's fine, but if x() returns a &amp;'a pointer, the 'a is the temporary lifetime of the block; it expires before the next block where t1.y() would be invoked, so the lifetime isn't valid. By pulling it out into two statements you have: { let tmp = x(); let t2; { t2 = tmp.y(); } } Because the borrow from x() is valid for the entire scope the encloses the sub-scope where y() is invoked. That seems to match the behavior I've seen...but I've been wrong before. (If the above isn't how it works, I'm keen to know how it really does work...)
Cool, I learned some things about Rust libs and idioms from your version.
What makes you think that people read documentation first? In my experience documentation is read after copying code, reading blogs and failing that StackOverflow.
Ah! You are right, somehow I had read it as `TileVec` being parametric itself. `type` does not seem to be really not working right now, I remember being bitten because I could invoke `Vec2&lt;i32&gt;::new(...)` but not `TileVec::new(...)`; it's really frustrating because you need to completely break the abstraction to access the methods.
yes, classic OOP with V-tables is unfriendly to both I-cache and D-cache, because the access pattern is unpredictable.. indirection to both code &amp; data. Rust Trait objects would have the same problem. &gt;&gt; shouldn't this already be a layer of indirection? the fix is to split up and sort data by type,(instead of inheriting to lump everything together) ... then the same code is loaded once into the cache, then applied to a sequence of homogeneous data (in an array or vector) - and d-cache prefetching works as you iterate through it. the more data you can have in longer homogeneous sequences.. the better. Working with that suits Rusts' &amp; C++'s ability for zero-cost abstractions through generics/templates (exploit more compile-time knowledge) Rusts' trait objects might let you mix the styles a bit? ... e.g: you could have homogeneous arrays of different types, and have another vector of trait-objects that point into them for a polymorphic view.. but basically if you can avoid vtables (or any other type of dynamic decision per object - ADT's would have similar problems.) its usually an improvement
Why not let columns: Vec&lt;String&gt; = line.as_slice().split(' ') .map(|l| { l.trim().to_string() }) .filter(|l| { l != "" }) .collect(); // collect into a Vector PS.: Apologies if it doesn't work, I tried running the example through rust playpen, but couldn't get it to compile...
There are a lot of concepts in Rust that either don't exist or don't translate well from C++. This person definitely took some time and is not lazy.
Out of curiosity, is it possible to pass rustup an argument to grab latest release version rather than nighlty? or actually a list of paramaters the script takes (if any) would be cool.
I agree. I filed https://github.com/rust-lang/rust/issues/15898 for this.
That's not really an ECS. ECS is cache friendly when you store components in arrays of the same type, so the system that processes them can just iterate through the array: struct SomeComponent { // component data } fn processSomeComponents(components: &amp;[SomeComponent]) { for pos in components.iter() { // update the components } } Entities are typically nothing but IDs. There are several ways you can associate components with their entities, such as their position in the array or a database-like index. Zero-cost abstraction applied to this case means the structs are actually stored contiguously in memory (unlike e.g. Java which stores arrays of some class as arrays of pointers), any methods you add to SomeComponent (not that you should be using lots of methods in an ECS) can be statically dispatched (again unlike Java, which forces all methods to be virtual by default to go along with storing them all behind pointers), and the &amp;[SomeComponent] slice can be a pointer into anywhere- a Vec&lt;SomeComponent&gt;, an array on the stack or in some data structure, etc.
Thank you for this great help. I'd like to confirm some things: 1) Filter .filter(|&amp;l| { l != "" }) So I understand correctly, does adding "&amp;" make it so `filter` is borrowing the &amp;str being passed into it? Or is it just different syntax for dereferencing &amp;&amp;str? 2/3) String vs &amp;str Other than when I specifically need a growable String, should I normally default to using &amp;str? &gt; something owned to put in the HashMap, you will likely want to convert this into a vector Since I'm used to languages with GC where references can be passed around and the garbage collector will eventually handle it, what is the accepted/normal approach to use cases like this where many transformations are being done with some eventual data structure being the only place where it needs to be stored? It seems costly to be doing these copies, when it feels like I should be able to just be passing ownership of the reference down the chain of functions. Strings get copied all the time in GCd runtimes I've used, so is it just that here I'm seeing it explicitly done? In your first example, you mention you're keeping them as references as long as possible. Does that mean that you only need to do a copy at the final step when it is placed in the HashMap? Is there any way to make the return type HashMap&lt;(&amp;str, &amp;str), Vec&lt;&amp;str&gt;&gt; so no copies happen? (I can't figure out how to if it is possible). Or is it normal to return something like HashMap&lt;String, String&gt; that has new copies? 
&gt; Two points are valid. &gt; rest are silly/invalid. Interestingly, I am exactly opposite in which criticisms I sympathise with. 'get/get_mut' isn't much different to get() get() const. ":" isn't a big deal and fits pattern matching better. 
How does someone figure that out via the docs without trial and error with the compiler? For example, looking at http://doc.rust-lang.org/std/iter/trait.Iterator.html#tymethod.fold it is not clear to me what is being done with ownership. Should I assume functions are always borrowing?
You can add to components if it's mutable. Note that you don't want SubSystem&lt;Component&gt;, you want a particular implementation of Component- SubSystem will contain all the components of that type for all the entities, and update them all at once- that's what makes it cache friendly.
There are only two hard things in Compute Science...
There's a pull request someone has made to deal with this to make it compile, but it doesn't deal with PathListMod (look at the diff), so this might have problems. Pull at https://github.com/phildawes/racer/pull/29
I see way more emotion in this thread than I do in the original complaint. The poster's choice of the word 'meh' is the polar opposite of emotion. People are inventing all manner of information about the original poster: skill level in various programming languages, preferences in said languages, knowledge of various features in Rust, motivation for posting... It is nonsense. This thread is trying to invent any reason for this person to be an idiot and for the complaints to be invalid. I don't even really agree with the complaints and I can see that. It feels like a defensive echo chamber, and what's more some of these complaints aren't even that clear. For instance the complaint about snake_case reminds me of early discussions of gofmt on hacker news. Some people love the type of output gomft generates, but found the notion itself totalitarian bullshit. I happen to love gofmt, but it is very easy for me to understand that perspective. This person might love snake_case, but we really don't know. This huge burst of analysis and premature judgment of this poster's fairly cryptic complaints, looks very defensive--defensive of a language that is changing at such a rapid clip that many people are postponing writing software in it until the rate of change slows down. We don't even know what we want yet or what idiomatic style for the language is, so it seems ridiculous to me to judge this guy. Edit: extra word, grammar, clarity
Aaahh! You're right. I'm not sure when exactly I started letting cynicism get the better of me, but years of trying to deal civilly with people online has burnt me out. We need more people like you and fewer people like me. I've invited you to become a moderator of this subreddit, if you're so inclined. I think I need a vacation.
Yep, that's true, but I still prefer a fresh approach instead to carry old stuff. I do think the shape of the arrow `&gt;` is inappropriate, because is naturally hard to count i.e.: `&gt;&gt;&gt;&gt;` instead your brain is more prepared to count this `]]]]` or `))))` because they are similar to `||||` (the way we started to count). That's why many of us use conceal or different fonts. Then as stated below, I think considering `[]` as `array access` is weak, your brain can distinguish easily in a context the O from 0. 
Everyone has off days! And spending a long time on the internet can wear down the best of us :) &gt;I've invited you to become a moderator of this subreddit, if you're so inclined. That's very kind. I would very much like to accept but I do not have any moderating experience and am no rust expert either!
&gt; increment I completely agree with this. I've written quite a bit of C++ code that operates on an abstract set of values whose only operations are equality and increment. It wouldn't make *sense* to implement `+=` on them. But I would require both `fn increment_ip(&amp;mut self) -&gt; ()` and `fn increment(&amp;self) -&gt; Self` - the latter is very useful.
I'll make sure to take questions from IRC. It will be roughly 10 minutes of me blathering, followed by up to 15 minutes for questions.
&gt; I am also confused by the `using namespace std` criticism. Rust does not glob import everything inside std by default. Rather, only the prelude is glob imported. If lookup of trait methods was fixed, the prelude could go away and everybody would be happy.
&gt; much better readable FTFY. &lt; is intended as an operator, and therefore floating and of smaller height than lowercase characters =&gt; the worst imaginable type of character for enclosing sections of code. ([{ are higher than all other characters and therefore (unsurprisingly) perfect for what they are made for: enclosing.
&gt;The vast majority of people are not enlightened by adhering to mathematical names, and adopting elitist jargon only serves to erect barriers to language learners. Err, but if it's actually the *concept* that people are unfamiliar with, surely having a unique name is less misleading? There's nothing elitist about calling a new concept by a new name.
I prefer 'carrying old stuff' unless the fresh approach is **clearly** better.
I agree that trying to figure out who this person is or why they are saying what is ridiculous. (Also, there _will_ be a rustfmt, so prepare for totalitarian bullshit.)
This is why compilers are there, though: they double check your work for you. With a compiler, fixing it would take a few minutes. Humans are terrible, fallible creatures. Like, look at this: https://github.com/steveklabnik/mojikun/commit/4503c3cc2752bd8a5d354231a32ad3f869c61f95#diff-282ebe97a8a5429da70ddd7137b25f2cL9 A freaking bug because I forgot the deafult argument. In a one line function. I have commit to Rails, and a freaking Ruby tattoo on my body.
There are no 'better' names. They say exactly what they mean. Changing "Monad" to "FluffyBunny" only serves to further muddle the issue. The vast majority of people will not care about satisfying the borrow checker either, but we have it.
Upvoted. I personally prefer providing better resources for people to learn. Monads are only hard because people say "monads are so hard!!!" and you're primed to think they're hard. When I first grokked monads, I wasn't sure that I did, because surely, this incredibly tough concept _must_ be more complex than that. Basically, I believe in people.
I was also reading it faster. I think it is because I'm used to it and I like camelcase more than snakecase. Also, I think people are more familiar with camelcase than snakecase because Javascript and web dom uses it. Javascript is today's basic language, everybody knows it, and its not going to disappear anytime soon. So, I would design something similar to it (camelcase). It makes the barrier to learn Rust lower.
I agree 'better' is subjective, this entire argument is entirely subjective.
... much maligned and much loved. ;)
Awesome, thanks!
So it's at like 17:00 Eastern and 14:00 Pacific?
Doesn't matter, genuinely nice people are more valuable than Rust experts.
No, but there is something elitist about insisting on adopting far-flung academic terms *if* a more approachable alternative exists. That "if" is the open question. We have already set this precedent with "lifetimes", which in the literature are referred to as "regions".
Thanks for the encouragement. I have specifically been trying to cultivate the 'nice' and 'patient', becuase they don't come easy to me.
There doesn't seem to be any sound on the stream :(
Your audio's busted!
Same.
Double kudos, then.
Maybe I misunderstand: you can't import a package into scope in Java and then do package-relative imports. e.g. this wouldn't work: import java.io; // illegal import io.BufferedReader; import io.File; 
I feel they are hard because people tell you they are hard, but important. So you try to learn them - without actually knowing anything else except that they are important. I was recently writing some Rust and came up with the problem of nested matches as there were multiple things returning Options. Having dabbled in Haskell, I recognized that this is actually the (a?) problem that monads solve. Usually you should just try to create something and when you have a problem, use Google / IRC / whatever. At some point you will learn about monads. :)
I think it would make sense to issue a warning on a lint pass if the compiler is going to look for this at all.
This is amazing and beautiful, and Rust should do this sort of trait-based "coercion" more pervasively.
The simple answer is that generics in Rust is compiled as multiple versions of the same method or struct (please correct me if I'm wrong here). The result of this is that there isn't a general `Foo::new(T) - Foo&lt;T&gt;` implementation, but instead a `Foo::&lt;uint&gt;::new(uint) -&gt; Foo&lt;uint&gt;` if it's used with a `uint` and a `Foo::&lt;f64&gt;::new(f64) -&gt; Foo&lt;f64&gt;` if it's used with an `f64`, but the compiler lets you call them as `Foo::new(T)` because it knows what the type `T` is. This is fine until you want to call a general static method like `Foo::constructor_helper() -&gt; uint`. That's because there is no clue as to which type of `Foo` we are using here, so what you need to do is to tell the compiler what `T` is: struct Foo&lt;T&gt; { a: T, b: uint, } impl&lt;T&gt; Foo&lt;T&gt; { fn new(var: T) -&gt; Foo&lt;T&gt; { //This method call is reusing the type parameter Foo {a: var, b: Foo::&lt;T&gt;::constructor_helper()} } fn constructor_helper() -&gt; uint { 2 } } fn main() { let c = Foo::new(1u); //I just picked uint, but anything will do here let d = Foo::&lt;uint&gt;::constructor_helper(); } [Try it here](http://is.gd/TkrfAB) Edit: Writing `constructor_helper` as a freestanding function outside the `impl` would be more optimal, since it avoids duplication of the code. Otherwise there will be a copy of `constructor_helper` for each type `Foo` is used with and that will, in turn, make the final executable file larger.
I'm not a heavy C++ user for a long while now, so C++ pitfalls don't seem natural to me. For simple setters/getters being able to parametrize over the mutability of the self seems very, very natural. So does having the same name for mutable and non-mutable versions. Going through all the invocations of certain functions and changing them because some argument is now going to be mutable is simply a PITA. I don't like the pattern matching neither. Eg. when you match for `enum`s with something between `(` and `)` simple typo there completely changes it's meaning.
The compiler needs to know what type `T` you want for `Foo` so it can find the correct associated function. You can specify the type you want in the path for `constructor_helper`: Foo {a: var, b: Foo::&lt;T&gt;::constructor_helper()} This is because `Foo::&lt;T&gt;::constructor_helper()` and `Foo::&lt;U&gt;::constructor_helper()` could potentially do different things, and the compiler doesn't know how to pick the type you meant to use. [Here's a playpen with these changes](http://play.rust-lang.org/?code=struct%20Foo%3CT%3E%20{%0A%20%20%20a%3A%20T%2C%0A%20%20%20b%3A%20uint%2C%0A}%0A%0Aimpl%3CT%3E%20Foo%3CT%3E%20{%0A%20%20%20%20fn%20new%28var%3A%20T%29%20-%3E%20Foo%3CT%3E%20{%0A%20%20%20%20%20%20%20Foo%20{a%3A%20var%2C%20b%3A%20Foo%3A%3A%3CT%3E%3A%3Aconstructor_helper%28%29}%0A%20%20%20%20}%0A%0A%20%20%20%20fn%20constructor_helper%28%29%20-%3E%20uint%20{%0A%20%20%20%20%20%20%20%202%0A%20%20%20%20}%0A}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20c%20%3D%20Foo%3A%3Anew%281u%29%3B%0A%20%20%20%20let%20d%20%3D%20Foo%3A%3A%3Cint%3E%3A%3Aconstructor_helper%28%29%3B%0A}).
Is there a reason that `(y = 3i)` can't be made to evaluate to `3i` instead of `()`? edit: D'oh, just read riccieri's comment below that speaks to this.
It amazes me what Rustians are considering "simple".Rust really needs simpler macro system. macro_rules! is not friendly and can't do much (it cannot even concatenate two tokens AFAIK). The other system is literally writing a compiler plugin. What people usually want is saving couple of keystrokes here and there and creating their own shortcuts for things that can't be easily expressed in short form with the language itself. How else am I going to convince people to use Rust in production environment? One can not expect whole team to know Ocaml and have experience in writing compilers...
&gt; can't do much (it cannot even concatenate two tokens AFAIK). Just because there's one thing it can't do, doesn't mean that it's "weak". In any case, concatenating identifiers and using them is fundamentally non-hygienic.
Rust can't do all of that either: use std::io; // legal use io::{File, BufferedReader}; // illegal (But, Rust can bring submodules of a crate into scope.)
But sometimes (most of the time, I'd argue, especially in embedded) people want non-hygenic. Just as `unsafe` let us escape certain good rules, thus we should be able to escape hygenic macros. 
Yep. I suspect in most cases with academic names, they simply weren't trying very hard, because their only audience is other academics. Putting in more effort yields better names a fair amount of the time.
Why does embedded in particular need non-hygienic macros? You can always pass arguments to them to avoid hygiene issues. In any case, escaping hygiene would be some what like allowing fn foo() -&gt; int { x } fn bar() -&gt; int { let x = 1; foo() }
There *are* better names, even if "FluffyBunny" isn't one. So let me rephrase: there aren't *always* better names, but sometimes there are. You have to think critically to find them, not just pull things out of a hat. Monads are fundamentally defined by an operation `m (m a) -&gt; m a`. This can be read as "flattening", and in many cases that's very literally what it is. (For instance, `Option&lt;Option&lt;T&gt;&gt;` -&gt; `Option&lt;T&gt;` or `Vec&lt;Vec&lt;T&gt;&gt;` -&gt; `Vec&lt;T&gt;`.) This operation is usually called `join`, but I think `flatten` is just flat-out a better name. Then, because this is the defining operation, the trait itself can be named after it, `Flattenable` or just `Flatten`. It's not perfect, but it gives a hell of a lot more intuition than "monad".
Is it just me, or is there only one intern presenting on the video? I saw nothing about rust.
Yes, the recording of my talk is not up yet, unfortunately.
Thanks you two for your answers, they completely solve my issue and better understand how rust work. I had tried Foo&lt;uint&gt;::constructor_helper(); (without the first ::). type parameters and path both using :: is a little bit confusing some time.
I was a little surprised at how much rust norms / stdlib ends up having the user put data on the heap (well, worse, on the heap with some minor indirection on the stack; and creating more allocator churn). From the perspective of realtime/embedded development it seems like an unfortunate holdover of C++ poorly performing norms.
CPUs can and will prefetch not only forward but backward as well (Sandy Bridge and up I think). If memory access is linear you will see a definite benefit. This means no vtables. Have linear memory of one type of data and loop through it. CPUs are so good at instruction reordering that sometimes the impact isn't as great as you might think, but very real speedups are possible.
I'm surprised about the comment on slide 35. It should be easy to define `Config` as a static variable, with `'static` as the lifetime parameter. Something already seems of with the definition of `Config` on the previous slide. I would've expected `pub struct Config&lt;'a, 'b&gt;(pub Pair&lt;'a&gt;, pub Pair&lt;'b&gt;);`. Other than that, great talk. Having done work on collective operations in the past (not in Rust though), it's especially nice to see people point out the potential in parallelizing `.map()` and `.fold()`
MISRA puts a large number of limitations on C macros. So unhygenic macros in the embedded context might be limited to personal projects.
[This](http://is.gd/NAkvGg) works if you want to avoid specifying a type for constructor_help. ``` impl Foo&lt;()&gt; { fn constructor_helper() -&gt; uint { 2 } } ```
Are you missing some close `&gt;` and `]`s?
https://www.kernel.org/doc/Documentation/CodingStyle &gt; 2) macros that depend on having a local variable with a magic name: &gt; #define FOO(val) bar(index, val) &gt; might look like a good thing, but it's confusing as hell when one reads the &gt; code and it's prone to breakage from seemingly innocent changes.
I'm not talking about a macro creating that code and having it fail to compile, I'm saying that ignoring hygiene is similar to allowing that code to compile. In any case, I imagine the vast majority of macros are perfectly sane to write as hygienic macros, it just requires adding an argument or two them.
Embedded is fine. We have a bunch of "compiler plugin" macros in zinc, one specifically parses DSL for I/O registers into rust code. You really need that additional power provided by plugins to do extra validations and stuff.
And we aren't talking about cache, or race conditions invalidation.
I don't think so. Rust can't be all things to all people. While I think how to take advantage of non-volatile memory architectures is a worthy cause for programming language community to pursue, I don't think Rust should be that language.
I'm curious, what is missing from rust for this? I can't really imagine that a lot would change because of this, yes the OS might need new drivers and a compiler for that architecture, but other than that i don't really see this as a big change( at least not bigger than a new computer architecture) , and if it is really a bigger change than that , it won't take off in the next 20 years.
You can add components at runtime, there's no restriction there. You can't, however, mix components of different type within one sub-system: // Two different types of components: struct TransformComponent { ... } impl Component for TransformComponent { ... } struct EnemyStateMachineComponent { ... } impl Component for EnemyStateMachineComponent { ... } // and the corresponding subsystems for them let transform_component_sys: SubSystem&lt;TransformComponent&gt; = SubSystem { components: Vec::new() }; let enemy_stm_component_sys: SubSystem&lt;EnemyStateMachineComponent&gt; = SubSystem { components: Vec::new() }; // adding a component at runtime is no problem transform_component_sys.components.push(TransformComponent { ... }); // but the compiler won't allow adding different component types to the same subsystem, // which incidently would also defeat the purpose since calling update() would then again require dynamic dispatch enemy_stm_component_sys.components.push(TransformComponent { ... }); 
You're right, I added a link to Thorn_SFML in the Thorn README. About the example, I know it is very light. That's why I made a little more advanced one, though you may find it too light as well: https://gitlab.com/Bastacyclop/thorn_sfml/blob/master/examples/access_borrow.rs I may add other examples later. About the documentation, you can make it with 'rustdoc src/thorn.rs' and 'rustdoc src/thorn_sfml.rs -L target -L target/deps', I'll add this info to the READMEs.
I'm a noob programmer so I don't know. I'm putting it out there for people above my pay grade to think about. I think that the stack and the heap will go away. Or maybe memory closest to the processing area of the chip will be called stack/heap. There'll be one memory and it'll be used for everything. Think of a big HDD that's fast as SRAM/DRAM.
Yay!
/u/riccieri was right about the naming conventions for conversions - it's in the [style guide](http://aturon.github.io/style/naming.html), look under the section "Conversions".
The stack and the heap are just logical partitions of a single homogenous memory. They exist because they are useful, not because they are (necessarily) built into the hardware. Having everything replaced with memristors wouldn't change their utility.
I didn't know that. I'm a new C# programmer. Where are stack and the heap located in hardware? Cache? RAM?
I didn't think about that at the moment of writing, but I suppose it would have made a good example. I hope, by the way, that the compiler can optimize those cases to remove duplicate code.
Right, that's the kind of stuff that's going to be decades before anyone outside a lab should worry about it. For now it'll just be used to speed up our existing system possibly with slight modifications that are probably papered over at the kernel level (but make the kernel more efficient).
The application's stack and heap exist in the process's memory space, which exists in the OS's virtual memory, which exists in the hardware's registers, level 1..n cache, RAM and swap space.
I remember that I found it strange when I first bumped into the same kind of problem, but I use to think of it as a module under `Foo`.
I see. That's good to know. I, myself, would have made it freestanding, but I chose to not do it here to explain the phenomenon. I don't know why I didn't mention it anyway.
Yeah, I already took that into account. RFC now uses `to_` prefix for methods and `To` for the trait.
I probably would have tried impl&lt;T: AnotherTrait&gt; Trait for T { ... } But doing so might result in the compiler complaining about conflicting implementations in your case. It really doesn't like multiple generic implementations that much. From what I understand it's not desirable to have to specify "overload resolution" rules just so that rustc can pick one possible impl over another. So, the idea is to not have any overlapping impls at all. But the compiler currently enforces this pretty pessimistically. I hope this will get improved. There's probably already an RFC to that effect.
This is what I did in the first place, only T: AnotherTrait can't match AnotherTrait since it is not a type. So Trait won't be implemented for types like &amp;AnotherTrait if there is only this implementation.
Oh awesome! 
If its still a Turing machine, someone will port c to it, port *nix to it, and life will go on. Although the lack of cache misses would be sweet.
I just had some time to go through the tutorial. It works really well and the code is very instructive. One nitpick from me: I suppose you have reasons to prefer glfw over sdl2, but for the sake of tutorial you should stick with sdl2 as it's more readily available on platforms. I didn't feel like going through glfw setup on my Ubuntu and so simply typed `apt-get install libsdl2-dev`, replaced glfw with sdl2 in cargo and rust source and everything compiled and executed without hassle. The tutorial is really much simpler if done the sdl way, at least on Ubuntu.
Vec&lt;Component&gt; isn't legal Rust - Component is a trait, and therefore isn't a (statically sized) type. It can't reasonably be legal Rust - all elements in a vector must have the same size! There are 2 versions of doing something that is like Vec&lt;Component&gt;: 1) Vec&lt;SomethingImplementingComponent&gt; (or, equivalently, Vec&lt;T&gt; in a generic context where T:Component) would have one layer of indirection (because of the Vec), This indirection is inevitable (in any language) unless you place the array in a static variable and isn't particularly interesting. (Note that, if the vector is stored in a struct that is a static/passed as a parameter there is still only that single indirection). Note that here (of course) each vector can contain only one type of component (however, you can of course have an enum of various component types - which would have the same size as the largest included). 2) Vec&lt;Box&lt;Component&gt;&gt; (or, similarly, Vec&lt;SmartPtr&lt;Component&gt;&gt; for some SmartPtr). In this case each component is behind a pointer and its functions are referenced in a vtable behind another pointer - memory layout is [vtable | ptr | vtable | ptr | vtable | ptr | ... ] - accessing requires 2 indirections per element (but one indirection is to the vtable which may be in the cache).
In my opinion, putting shared code in a separate package (or in this simple case, simply using the [[lib]] section of the same package) is the proper solution. This way, if you change some code in one of your binaries, you won't have to recompile the shared code.
That works, thanks a lot! I had tried something similar (specifying the shared code using [[lib]]) but didn't think of doing it like you suggested.
`impl Drop for File {...} // where File is linear` Before cringing, just let it sink in for a couple seconds and try to find a reason why this is bad. Unwinding implies imminent task failure. Linear values are owned by the task. Most of them have meaningful cleanup (such as `File`). Others require none (an uninitialized, i.e. "`out`", reference - its existence requires that the memory it's pointing to doesn't yet contain a valid value). In all the other cases, an `impl` of `Drop` that calls `abort` is indeed a pretty good option.
You're right that my mod-based solution is not a good one, but I disagree that putting the shared code in a separate package is cleaner, at least not in the general case. I think if different people are working on different parts of the project, than separating it into different packages is cleaner. If the whole project is a unit than having multiple packages is just unnecessary complexity. Your suggested solution using [[lib]] doesn't work, as adding a [[lib]] or [[bin]] section seems to override the implicit paths (i.e., anything in src/bin is no longer recognized). /u/dpx-infinity has suggested a solution that works. Thanks for your answer!
Yes, these implicit paths are very finnicky (I personally don't use them). I would disagree that splitting a project into multiple crates is unneccesary complexity, as that is the sole method Rust currently gives you to get incremental/parallel builds which get very important, very quickly. I do agree that Cargo makes this unnecessarily verbose in practice (e.g. forcing you to have a separate directory per package).
If disk becomes just memory, then I think that means Windows' leaky approach to managing resources (not working? reboot, or if that fails reinstall) isn't going to cut it. The UNIXes are better placed to work in this environment. If people are going to expect instant-on that means *really* long-lived processes, so safety in the language is a huge advantage. I think Rust is well-placed for this.
Yes, but if you use [[lib]], you'll also have to specify all the binaries explicitly (as you did in your example). It seems like specifying anything explicitly will override the implicit paths that Cargo would otherwise look at, among those src/bin. As I said in my original question, this question was less about achieving a specific outcome and more about doing so by using src/bin.
We're talking about different things! You're completely right, splitting the project into multiple crates is good. I was talking about splitting it into multiple Cargo packages (which would require you to have multiple Cargo.toml). I'm sorry, if I've caused any confusion :)
The macro system is both a lot simpler and a lot more powerful than you seem to believe
Don't forget off-by-one errors.
It would be great to add this to the huge web framework benchmark and see how it does: http://www.techempower.com/benchmarks/ 
I plan on talking about unsafe at the very end of the new guide, so it can at least find a place there.
This is really good, but I still don't like the description "the programmer telling the compiler that the code is guaranteed to be safe". First, it's odd to me to frame this as the programmer guaranteeing something 'to the compiler'. The compiler doesn't care. It's going to compile the code regardless of whether that code actually maintains the required invariants, and it doesn't suffer the consequences when those invariants aren't maintained, because it's a compiler and has no agency. What's important is the guarantee to the people using the code. From this perspective, it's odd to me that the one construct in the language that can lead to undefined behavior would be described as 'guaranteed to be safe' - it explicitly isn't guaranteed, because the guarantees are explicitly turned off. You can only trust the code inside an unsafe block to the extent that you trust the author to do the right thing, trust the test coverage to cover all potential issues, or trust the real-world usage to have exorcised all demons. And the first thing you should do when code does break in an unsafe way is audit the unsafe blocks. I think a better way to phrase this is "the programmer asserting the code inside is correct despite compiler checks being turned off". 
&gt; Middleware is registered using `iron.chain.link` I'm sold.
If anybody knows somebody at HP working on this I'd love to talk to them.
That's why I much preferred the idea of `trustme` to replace `unsafe` as a keyword, it seemed to more closely represent the intent.
&gt; These invariants are assumed to never happen, you'd assume that invariants always happen, or even never stop
The idea of persistent memory was mentioned on lwn.net last year I think, and the discussion was that in the end it would still be necessary to have a "hard reboot". So, in a way, it would just mean that starting up after an hibernate would be instantaneous; and a full stop/start would be as today. *EDIT*: I just realized HP aimed at removing the hard-drive totally, and persisting stuff in memory, in which case any case of hard-erase would mean losing data... and therefore would require re-installing the OS etc, that's quite ambitious!
One of the areas of major churn in Rust's evolution was the decision to remove `~`. This discussion and decision took place because the designers of the language wanted to encourage/enforce a particular behavior. Their decision was bounded by a general knowledge from Systems programmers that results from hardware characteristics: Heap accesses are slower but unbounded in terms of size, while Stack accesses are faster but with greater constraints on size. However, Stacks are only faster because their size constraints enable Cache locality. With memristors, the cache and RAM and disk can effectively coexist without any distinction. What would have happened if a heap access and a stack access had a 0.01% speed gap, instead of orders of magnitude? 
However *unsafe* is a concept already used by other memory safe systems programming languages.
I feel like it shouldn't be trusted though, we need to scrutinize it, and trust regular rust code. `unchecked` is very clear on its meaning and it doesn't offer bias.
I worry about unsafe code in the libraries. It would be great if it was only in specific functions and the source would be embedded in the .so/.dll so it could be reviewed and perhaps recompiled (using LD_PRELOAD).
Yes, I guess the question is whether you segment some area of memory to emulate an old-fashioned hard drive, in which case you could do some kind of reboot. But I guess they are maybe thinking more radically. So how about you have a process which acts as a data store or key-value store, like memcached, which is expected to live forever (for the life of the machine). This is when you need a safe language!! Watch those cosmic rays, though! It will be interesting to see what they come up with.
Yes, persistent memory is definitely an interesting area. Cosmic rays, and faulty modules, are already a memory plague, which is why when it matters people prefer ECC modules; I would suppose for persistent memory you would always use ECC. Regarding the reboot issue, I would suppose partitioning could come into play. 1 partition for the OS code and setup, and the actual "running" data kept apart in a partition the OS can flush if necessary... it's an interesting avenue, but I am afraid it will take time to figure out how best to address corruptions (whether technical or functional).
`unsafe` code is actually supposed to be safe code, though, that the compiler unfortunately can't check. Really anyone who uses `unsafe` needs to sign in blood that they understood the contract that they've entered with the compiler.
I'm going to stop responding in this thread, because I seem overly negative, while I don't want to. &gt; The macro system is both a lot simpler and a lot more powerful than you seem to believe The plugin system is very well designed and powerful, but by any means it is not simple to use. If anyone thinks it is simple, it's because he's/she's a programming languages enthusiast or developer with experience in the area. The macro_rules! system is simpler (not simple, just simpler than plugin system), but it is still not that simple and not that powerful at all. I'm not sure how much of this is its current state and how much is design choice, but it seems overly limited and I hit it's limits every time I'm trying to implement some fancy macro idea. If someone wants to see simple &amp; powerful at the same time, here's an example: * http://qznc.github.io/d-tut/meta.html * http://nomad.so/2013/07/templates-in-d-explained/ Creating datastructures, properties, functions etc. in D feels as natural as just using D language itself, just in the compile time. Anyone that needs a quick macro, can write it in the flight, without studying compiler APIs or spending much time thinking about it. 
It's supposed to be *correct* code. The term *unsafe* doesn't mean incorrect, it means flirting with danger and that's exactly what the escape hatch from compiler enforced memory safety is.
Thanks for the correction. I have fixed the comment and also other places in the slides where I had remnants of my old code that used `String` rather than `&amp;'a str` (which allows for `'static`). The code and slides are now consistent. As for the definition of Config, I'm using lifetime elision (a debatable sugar). What I would have written without sugar would have been `pub struct Config&lt;'a&gt;(pub Pair&lt;'a&gt;, pub Pair&lt;'a&gt;)`, because of the intention to have all the pairs come from the same place anyway.
I did some toying with macros in zinc because I don't like how iomem macros are working. There's too much repetition there with specifing the member names, repeating the register and type names, linking meta etc. It's my personal taste, but it made me work with macros on that and hit some walls, and precisely this makes me think such a trivial thing is overly complicated. You can take a look here: http://pastebin.com/jdLL91rr 
Have you seen the refactoring work? https://github.com/hackndev/zinc/pull/90 The original macro code is surely quite ugly.
I am very interested in this as well. I remember reading in the reddit comments of another rust web-framework that Rust didn't expose enough low-level networking primitives to be competitive to e.g. Go, Netty.
No, I haven't, actually. It looks good, I'll read more into it when I have time, and drop my exercises on improving ioreg. Thanks! The whole platformtree etc. in zinc sure looks great, and is a powerful concept. I'm playing with Zinc and I'm looking forward to use zinc in the future for all my embedded work. Hopefully even at work one day. Still this example, shows macro_rules! is not powerful and flexible enough, and even for relatively simple tasks one needs to resort to full blown compiler plugin or accept ugliness. And while I agree that rust syntax plugins are great because they are very powerful and well integrated with the compiler, one could just write a preprocessor for DSL in any language generating code in any output language before actual compilation and achieve similar result, only with bigger complications and worse integration. People can resort to this syntax plugins when writing frameworks or bigger projects like Zinc, but when toying with their own project, they will just give up and do copypasta instead, no matter how ugly. And I can't imagine convincing coworkers to use it, if I will have to explain to them that simple stuff that C pre-processor could do previously are impossible now, unless you start dealing with AST, compiler plugins and DSLs.
&gt; Stacks are only faster because their size constraints enable Cache locality Stack allocation also doesn't involve syscalls (because the memory is already allocated)
I wonder if the loop that pops items off the queue can be replaced with an `Iterator`. I'm not familiar with `PriorityQueue` but from the docs there is an `iter()` method but that says it returns results in arbitrary order. Maybe there should be some kind of pop iterator.
This is the wrong subreddit. You are looking for /r/playrust.
When I try to use dist[start] = 0u; I get &lt;anon&gt;:46:5: 46:21 error: cannot assign to immutable dereference (dereference is implicit, due to indexing) &lt;anon&gt;:46 dist[start] = 0u; ^~~~~~~~~~~~~~~~ what's the rationale for that? Can't we just make the []= operator require a mutable self?
erickt put this together today to start keeping better track of upcoming events (there are a lot lately!).
I'd be interested in chasing this down. I've been looking for a way to contribute to Rust for a while, and I think that making it competitve with Go in the networking arena would be a worthwhile project. If you find that comment, or anything a little more specific, would you mind posting it here or PMing me?
The trouble with having prefix parameters is that it makes it harder to refer to the type constructor itself. Eg: if you have List&lt;String&gt;, the syntax makes it straightforward to have Something&lt;List&gt;, which is different than Something&lt;List&lt;SomethingElse&gt;&gt; (this would require HKT btw)
Sadly I don't even know where I'd start to look for the comment. I'm sure the Iron Framework team would love to have someone working on benchmarking and performance analysis though!
&gt; I'm using lifetime elision Lifetime elision is illegal in `struct`s: [example][eg]. [eg]: http://play.rust-lang.org/?run=1&amp;code=type%20Pair%3C%27a%3E%20%3D%20%28int%2C%20%26%27a%20str%29%3B%0A%0Astruct%20Config%28Pair%2C%20Pair%29%3B%0A%0Afn%20main%28%29%20{}
For #2, adding it would be a backwards compatible change, and Rust should avoid doing that until post-1.0. Furthermore, I don't see a point in making DBC a critical component of the Rust ecosystem, and the prelude should only have what is minimally important.
Any pop_iter method would have to consume the PriorityQueue similar to how move_iter() works. Not sure if this code could be reworked to use that.
It can't, because that would have to borrow the `PriorityQueue`, preventing modification inside the loop. (And this is true even after [#8372](https://github.com/rust-lang/rust/issues/8372) is fixed, unless `PriorityQueue` was made into the `Iterator` itself, or the `pop_iter` offered some way to call `.push`, either implementing such a method directly itself, or providing a proxy method like `iter.queue().push(x)`.)
&gt; 1) Can't the syntax be modified to use expressions directly (AST macros support that, right?), rather than embedding them in strings? So more like #[precond(x == 12)] ? For `foo!(...)`-style macros, yes, but the grammar of an attribute is something like: attribute := '#[' meta_item ']' meta_item := identifier | identifier '(' meta_item , * ')' | identifier '=' string i.e. attributes can only be things like `#[foo(bar, baz(qux = "x"), quz = "y")]`.
Link doesn’t work.
Looks like it was a one-time use link. Could you resubmit?
I can't figure out how to get Google Calender to give me a permalink.
It is intentional. Some people strongly dislike this practice. We haven't committed to it, though it did find its way into the guide. Since its what most seem to use perhaps we should not keep it a secret.
Ack, my mistake. Too many code changes and my not keeping my slides up to date with my actual working code. Will fix this, thanks!
I feel like it should be `precondition` and `postcondition` due to Rusts tendency not to shorten identifier names. Otherwise, this library is really cool! :)
As long as we have a reasonably talented dictator, please do bring on the totalitarian bullshit. The way gofmt muted accidental formatting discrepancies and divergence is incredible and one of the best things about go.
That's a good idea. A web view without the need to login with a Google account would be a nice addition.
It's working for me right now, perhaps someone fixed it? Can you try again? edit: This [link](https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com&amp;ctz=America/Los_Angeles ) should work if the OP link isn't working for others.
very pretty code, first thought is, why don't you use the prelude names? You don't need to qualify Iterator, Vec, Option, from_str etc.
You can get closer to straight-line code/avoid pyramids of doom using match-is-an-expression: loop { let line = match self.inner.read_line() { Err(_) =&gt; return None, Ok(l) =&gt; l }; if line.is_empty() || line.starts_with("#") { continue } // ... } Also, instead of collecting to a `Vec`, you can just write something like let mut splits = s.splitn(' ', 1).map(|s| s.trim()); let command = splits.next().unwrap(); let params = splits.next().unwrap(); which will be mildly more efficient, due to avoiding allocating the `Vec`.
&gt; You can get closer to straight line code using match-is-an-expression: Is the match type coherent here? Woudn't the `return None` give it a type ()? &gt; Also, instead of collecting to a Vec, you can just write something like IIRC I originally tried to use `.nth()`, then there was no `Option.zip` so I moved them to iters, then it did not work and I had other things to change so I went with a Vec and it worked so I rolled with that. I'll try to change that, thanks.
&gt; very pretty code, first thought is, why don't you use the prelude names? Mix of Python habit (unqualified names make me unconfortable) and having never read the prelude (thus not realising so much stuff lived in there). Turns out I needed none of the `use` in the main file, so that's cool.
&gt; Is the match type coherent here? Woudn't the return None give it a type ()? No, `return None` has "type" `!` aka ["bottom"](http://www.haskell.org/haskellwiki/Bottom), i.e. despite appearances, it is an expression that never returns, `a` can be any type in `let a = (return 1);` because the control flow of `return` will mean `a` will never be reached. This property is extremely useful for this early-returning-`match` construct.
Ah cool, thanks a lot (I knew about bottoms but had not realized `return` was one, that's good to know)
The example at the bottom also works without all the lines mentioning `TheTrait`.
I think the module import style is great in general (better than importing individual names).
I see ... thanks! That's the danger of toy examples, I guess.
&gt;After all it’s not always possible to know the type at runtime! I guess you mean at compile time.
You mean the last sentence? Actually, that's a teaser for another blog post to introduce runtime polymorphism.
Have you considered using [`lines()` from `Buffer`](http://doc.rust-lang.org/std/io/trait.Buffer.html#method.lines)? You could iterate over all the lines with [`filter_map`](http://doc.rust-lang.org/std/iter/trait.Iterator.html#tymethod.filter_map), like this: self.inner.lines().filter_map(|maybe_line| match maybe_line { Ok(line) =&gt; { let s = line.as_slice().trim(); if s.is_empty() || s.starts_with("#") { None } else { Some(line) } }, Err(_) =&gt; None }) to skip the ignored lines, instead of using `loop` and `continue`. I don't know if this will actually make things better, but it's an idea...
Oh, wait. Sorry, I missed that detail :P You are right, this would just mess it all up. Then I got nothing. I have to agree with the others, by the way; nice piece of code.
If you need runtime polymorphism, it is because you can't always guess the type at "compile time". Your sentence say the opposite
&gt; Oh, wait. Sorry, I missed that detail :P You are right, this would just mess it all up. No worries mate.
I think we're in complete agreement. What I was talking about was the multiple binaries plus shared code situation. I guess once your project reaches a size where you'd like to split the shared code into multiple crates, you have no choice but use multiple Cargo packages, at least for now.
Can you point me to it when you can? I wasn't able to find it
I think python's dynamic types make the subscripts possible? Rust has static types so that wouldn't work, as the subscript operator has to return a single type deduced from the lhs; there's a nice proposal to use .0 .1 .2 shortcuts like Swift.. I hope it gets support (it would be great with tuple-structs)
I don't have a strong opinion on the syntax. But what you have to keep in mind is that tuples are not necessarily homogenious. So, if i have a `mytuple` of type `(int,f64)`, the type of `mytuple[index]` would depend on the index. Since Rust is a statically-typed language, this can only work if the index is known at compile-time. The 4 in `val4` is known at compile-time since it's part of the function's name. :) 
Don't forget that you can do: let (_, _, _, fourth) = my_tuple;
Is there an RSVP for this?
That's essentially what the lineish iterator does (except it also splits the line in 2 so that the command part is within easy reach for callers)
I mean like a nested iterator, like this: pub type Item = (String, Vec&lt;u8&gt;); struct LineishIterator&lt;R&gt; { inner: R } impl &lt;R: Buffer&gt; Iterator&lt;Item&gt; for LineishIterator&lt;R&gt; { fn next(&amp;mut self) -&gt; Option&lt;Item&gt; { self.inner.lines() .filter_map(|line| line.ok()) .map(|s| s.as_slice().trim().to_string()) .find(|s| !(s.is_empty() || s.as_slice().starts_with("#"))) .and_then(|s| self.parse_command(s)) } } impl&lt;R: Buffer&gt; LineishIterator&lt;R&gt; { fn parse_command(&amp;mut self, s: String) -&gt; Option&lt;Item&gt; { let mut v = s.as_slice().splitn(' ', 1); v.next().and_then(|command| v.next().and_then(|param| match command { "data" =&gt; from_str(param.as_slice()) .and_then(|n| self.inner.read_exact(n).ok()), _ =&gt; Some(param.to_string().into_bytes()), }.map(|data| (command.to_string(), data)))) } } pub fn lines&lt;R: Buffer&gt;(buf: R) -&gt; LineishIterator&lt;R&gt; { LineishIterator { inner: buf } } The main benefit I see here is that you remove all the control flow elements (`return` and `continue`) so that the logic is easier to follow. You pay the small price of an extra allocation because the `map` has to return a `String` instead of a reference since it escapes the block. YMMV I edited this to use the iterator from `Buffer.lines()` instead of implementing my own. Edit: It may or may not be a concern that errors are handled completely silently. There's no way from the type signature to know if the iterator returned `None` because of an IO error, invalid input, or EOF. You may consider changing the signature to `Iterator&lt;IOResult&lt;Item&gt;&gt;` so that you know when errors are encountered and can handle them robustly.
Not really, though I'd appreciate it if you filled out [this form](https://docs.google.com/forms/d/1v0y6D__MC2jkFd6zJF54huyrCRe002rcQAntHgmfN1I/viewform?usp=send_form), if you haven't already.
Other useful expressions of this type are `break` and `continue`. For example: https://github.com/steveklabnik/guessing_game/blob/master/src/guessing_game.rs#L23 This doesn't return a number, and that's okay.
Thank you! 
This is why the better analogy is not to indexing but to struct fields, `.0`, `.1` etc., as in the proposal that was submitted.
Not very scalable. It's like asking people to index arrays by `let fourth_element = my_vec.next_one().next_one().next_one().next_one()`
Oh yes! I love stuff like this! 
You are 100% right, it is redundant. It's a refactor I have planned for the near future.
Great proposal, but it can wait until after 1.0 right?
Could this be solved by allowing `box self` in trait methods? That way there is a way to indicate "I need to take ownership of this" while still allowing that method to be called through trait objects.
[It is already allowed][allowed]. In any case, to be clear, you [can actually call by-value `self` methods through a trait object][by-value], the problem only arises when you're implementing a trait for an unsized type. [allowed]: http://play.rust-lang.org/?code=trait%20Foo%20{%0A%20%20%20%20fn%20foo%28self%3A%20Box%3CSelf%3E%29%3B%0A}%0A%0Afn%20main%28%29%20{} [by-value]: http://play.rust-lang.org/?run=1&amp;code=trait%20Foo%20{%0A%20%20%20%20fn%20foo%28self%29%3B%0A}%0A%0Aimpl%20Foo%20for%20uint%20{%0A%20%20%20%20fn%20foo%28self%29%20{%0A%20%20%20%20%20%20%20%20println!%28%22by-value%20self%20on%20a%20trait%20object%22%29%3B%0A%20%20%20%20}%0A}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20x%20%3D%20box%201u%20as%20Box%3CFoo%3E%3B%0A%20%20%20%20%0A%20%20%20%20x.foo%28%29%3B%0A}%0A
How is &gt;[Language] is the programming tool of choice for discriminating hackers. Supposed to be understood. Is the winning language the language hackers who discriminate use, or is the winning language used to discriminate against hackers?
That's subtly different. An API is *unsafe* when using it can lead to memory corruption. Rust's unsafe is meant to be used when the block inside it *cannot* lead to memory errors, but the compiler isn't smart enough to see that.
I thought it was pretty clearly the former. The latter interpretation doesn't really make grammatical sense...
Thank you. I'm not that strong in English grammar :)
s/cannot/should not/ , just like in Modula-3, Oberon, Sing# and many others.
&amp;str is guaranteed to be valid unicode (utf-8 in its &amp;[u8] representation), which is not the case of &amp;[u8]. The confusion about str and String will go away at some point. The reason for the current situation is, that String was just recently introduced such that the APIs still have to adapt for that change.
Oh! That's sneaky. In the grand line of C and C++ I had never considered that break, continue or return would be *expressions*. It will probably take some time for me to adjust, but this is really an interesting fact.
They are a mess in reality too. Is there a language that gets strings right? Ruby does within its paradigm (disregarding performance), but I don't know of any lower-level languages that have been able to do it "right"
I like the .NET way. A string is conceptually backed by an array of Char, supporting string-y operations and no knowledge whatsoever of bytes or encodings. An Encoding can reify any string into an appropriate byte array, and an Encoding can take a compatible byte array and give you a string. It seems like a reasonable division of responsibilities.
It's worth pointing out that in this case "discriminating hackers" means "hackers with sophisticated taste in programming languages," not "hackers who treat people poorly based on their ethnicity." 
Once you've constructed a string, there's no myString.GetEncoding or similar. The particular fact that UTF-16 was chosen internally has no impact on any code that uses strings as far as I'm aware (though if you have counterexamples, I'm interested).
discerning hackers perhaps
`&amp;str` just represents a view on an existing string, `String` represents a dynamical allocation of a string. If you want to create your own strings dynamically, or mutate a string, you need to use `String` (or roll your own) because `&amp;str` (like any other `&amp;T`) is a shared, immutable reference to string data. It's a pretty clear division. If `&amp;str` didn't exist, things like string literals or substrings of other strings or just strings whose lifetime is controlled by something other than `String` would have to be wrapped into a newly dynamically allocated `String` before you could do anything with it.
This was... unexpectedly interesting. Boring technical nitpick: &gt; For example, the person who made the idea of ‘null pointers’ called it “my billion dollar mistake”, and Rust eliminates the concept of null pointers altogether. You can only eliminate that concept by adding in a bunch of theory of linear and affine type systems, which is, whatever, theory. You don't need linear or affine types to eliminate null pointers, or, more precisely, to keep track of nullability in the types. You just need types-parameterized-over-types (templates, generics) and either native algebraic datatypes (`enum`s-with-values-in-them in Rust), or something more primitive they can be built up from. So C++ can have `optional&lt;T&gt;`, by virtue of unrestricted `union`s, which is the same thing as our `Option&lt;T&gt;` and Haskell's `Maybe a`. You *do* need linear or affine types to enforce (absence of) aliasing guarantees, in other words ownership, and thus to have memory safety without garbage collection.^1 (I'm assuming Steve knows all this and just got mixed up in the interview, but for the record.) ^1 Even this isn't *necessarily* true, I think, but I don't want to digress too far.
I think this is largely offtopic, but I do mention Rust a bit. ;)
I recently wrote a string guide: http://doc.rust-lang.org/guide-strings.html Specific criticisms/improvements very welcome.
Good start - clears some things up for me. ##Suggestions * add a section for indexing - i.e. how do I compare just the first 3 characters of two strings? Or fetch the character in position 3 in the string? Or iterate through the characters in the string? * comparing - i.e. how do I know if one string is greater than another - and on what basis is the ordering done (binary value of the strings, or based on character set)? * applying regular expressions to strings, is `&amp;str` preferred over `String` for this?
These are great suggestions. Would you mind opening a GitHub issue with them, actually? That way I can track it more easily than a reddit comment. If you don't want to or can't, I can for you. If you do, then you'll know when it's fixed. :)
Thanks! I thought *to discriminate* was followed by a direct object, leading me to the same doubt as ismtrn. And I guess the fact that it was posted to the rust subreddit alleviated the weird thought of *hacker discrimination*, in a way... :P
Ha! Yeah. It's a weird word, that can be positive or negative. I'd say that the positive usage has largely fallen out of favor, but that could just be my own experiences.
By 'conspiracy' I mean 'a lose group of people advancing their interests.' I'm referring to the events of http://www.thebaffler.com/salvos/the-meme-hustler , if you don't know that history. And ESR is specifically who I am referring to, and he is, indeed, mega-racist. (Finally, I would suggest that there is a -teeeeeeny- difference between a six month freelance contractor and the CEO/CTO. Just a bit.)
If you can use a view (`&amp;str`), then you should prefer that.
Honeslty you probably wouldn't be against capitalism like so if you were in Europe, like here for instance you don't have to endebt yourself to make studies. Things like that.
It has a lot of numeric index parameters in the API. Are those code points or UTF-16 code units? Code points would imply that the APIs do an O(n) search before doing any actual work.
Sorry Steve I don't have a github account (I know, I know, terrible of me). Uh - just throwing suggestions out there - if any of them are things you identify as worthwhile - it would be great if you could open an issue. Apologies for not setting this up for you.
I'm coming from python, ruby, and clojure (and I'm pre-literate in go). What I want to be able to do is to have functions accept a string, cut it up, and return a string that has been transformed according to my need. It took me a terribly long time of reading, trying and failing to do this simple thing, resulting in help from irc. I'm not proud of this, but I still feel like my journey has left me with no clarity. So idioms for doing useful operations on strings, and how that impacts the lifetime and ownership considerations would be very helpful. E.g. if I am given a string like "http://foo.bar.baz/some/path/here" and I want to manipulate /some/path/here and return some.path.here (for instance), how would I do that, and why - specifically how should it be thought of to manage the lifetimes and ownerships. Thanks!
There's not a single comment in this thread pointing out an issue with the design of the types, yet a comment claiming it's awful is upvoted to the top...
Well, if I had grown up somewhere else, I would be very different, but I'd like to think that I'd still be far left. Social Democracy may be capitalism with a human face, but it doesn't fix it's inherent internal contradictions.
Rust's string type design is solid. It has a wrapper around `&amp;[u8]` with a UTF-8 guarantee (`&amp;str`) and a wrapper around `Vec&lt;u8&gt;` with a UTF-8 guarantee (`String`). If you understand the rest of Rust's type system, then it's pretty clear why both exist. You can also make use of `&amp;[char]` or `Vec&lt;char&gt;` for native endian UTF-32 but it's not generally useful, and separate types can't bring anything to the table (unlike with UTF-8).
Being on-topic to the off-topic half of a partly-on-topic post, I have no idea to what extent this discussion belongs here, but what the hell: &gt; And ESR is specifically who I am referring to, and he is, indeed, mega-racist. Is this a relevant fact? Honest question. I mean, as far as I'm aware, Abraham Lincoln was mega-racist. (And Newton was an alchemist and a numerologist.) One part of a person's beliefs don't inevitably end up "infecting" the others (which is not to suggest that there's no interplay involved). [I know basically nothing about Eric Raymond beyond that he's famous and has a website.]
It's related to a core design item of Rust -- allocations are explicit and optional. Because of this you have to consciously manage Strings (strings with their own allocations) and &amp;str (slices of allocations elsewhere) all the time. This will always be true, but the "ergonomics" of it might improve.
Could you expand on how rust encourages one to use the heap and indirections? I've been following it (granted, from afar) for a while and failed to notice that much indirection going on. I thought it'd be relatively easy to manage the memory, somewhat resembling C++, even if forced to deal with the borrow-checker once in a while.
I asked the same thing about the String guide. I think this can probably made more clear. https://github.com/rust-lang/rust/commit/226b7d1b725300fe6fbcfc1a66dfc1298f0af893#commitcomment-7068087
It does matter quite a bit for free software. If community leaders are openly racist (or sexist or homophobic or otherwise bigoted), it restricts the kind of people who will feel welcome participating in that project, and, in the case of someone with ESR's stature, maybe even open source as a whole. Considering that many developers contribute to open source to build their resumes (and many companies heavily weigh open source contributions in employment decisions) that closes off opportunities for career advancement to whole groups of people.
The design is sound, but the naming is slightly confusing at first, because &amp;str appears to be a pointer to a non-existing type. I realize that this has been bikeshedded thoroughly, but perhaps it would help newcomers to rename &amp;'a str in to something like StrView&lt;'a&gt; or StrSlice&lt;'a&gt;. (Assuming lifetimes will be elisioned most of the time) 
I see no difference. Either they hold their business relationships to a high standard or they don't. But hey, enjoy your contract while you've got it. They have the right to hire you, and you have the right to sell your expertise. Sounds like a true free-market, capitalistic endeavor. --- *Edit:* And how does *"...are mega-racist libertarian people..."* suddenly become *"...ESR is specifically who I am referring to..."*?
If it's really that simple, then I guess I can go around telling people *"The Rust contributors are rabid anti-capitalists."* even though I'll be thinking of one person in particular.
ESR wrote the definitive lore and one of the earliest and most influential book on Open Source. He matters a whole lot more than I do.
I wrote [this](http://stackoverflow.com/a/24159933/1256624) a while ago; it's mostly obsoleted by the strings guide, but maybe reading a second phrasing of the ideas will help someone.
Yup, and it was a major inspiration.
You *did* made a sweeping generalization. It's bound to wind some people up. I think it must be a symptom of a way of thinking, kind of leaps of reasoning that don't translate naturally into fully-formed, fully-checked verbal statements. You'll be fantastic to mis-quote in years to come -- so many radical and contradictory statements. Don't run for president!
And you're writing the documentation for Rust. Who cares? I'm not going to slander a group of people based on one member. Fine, he matters more than you. Doesn't make what you said right. 
well i did understand the intent. just reacting to someone else's post, i should have replied this to them. discriminating has possible negative interpretation discerning less so all language ambiguity :)
&gt; Mozilla ousts Brendan Eich but is OK with you? I don't understand the implication. Is steveklabnik a crypto-homophobe somehow?
A bunch of commented examples of plugins would be absolutely amazing for those of us that want to learn how to make them ourselves. The biggest issue for me is the *giant* API scope, so seeing how pieces work together would be great!
Could you provide some concrete suggestions for improvement? My belief as of now is that the problems with strings in Rust stem from either (a) inexperience with manual memory management, strings being the topic of frustration because folks tend to encounter them first; or (b) familiarity with STL strings, which try to feel like strings in more dynamic languages from a memory management perspective, and frustration that Rust strings don't behave that way. (The approach of `std::string` works well for beginning use cases, but when you start wanting precise control over memory usage then the heavyweight nature of typical STL string implementations—namely, copy-on-write atomic reference counting with a small string optimization—tends to get in your way.) I am certainly open to hearing about ways we can improve, however!
I agree with you, but would't limit it to the few examples you gave. I dont think community leaders should be publicly dragging anyone down, irrespective of their personal beliefs. Yet that's exactly what Steve does in that article.
&gt; Steve's views are far more radical than Brendan's one small donation he made years ago. Steve's *views* are less relevant than Brendan Eich's *political action*, and the positions of a contractor doesn't reflect on the company as much as those of the CEO. &gt; And let's not forget that Mozilla is all about open source software, which to Steve is apparently a capitalistic conspirasy. And yet Steve is OK and Brendan is gone. The whole point of open source is to make free software palatable to capitalists, this is hardly a conspiracy. To the extent that Mozilla should care about things outside the web remaining a thing, I don't see why they as a non-profit should feel threatened by anti-capitalist talk. Compare that to material support by the CEO for discriminatory laws that *do* threaten the Mozilla employees and volunteers and *do* make Mozilla look bad in the community they work with. &gt; You call Brendan a "homophobe". Just because one believes in a traditional family doesn't make them afraid of homosexuals. Homophobia is not a phobia. I don't know Brendan Eich personally, but activism that pretty much only serves to negatively impact the live of non-heterosexual people goes beyond holding beliefs, either way. There's nothing dishonest about calling donations towards prop 8 an act of homophobia. &gt; By the way, I was and am against endeavors like Prop 8. I prefer to keep government out of social interactions, including marriage. Thanks for clarifying that your support for equal marriage is based on libertarian fundamentalism rather than empathy with queer people, I guess. 
&gt; Steve's views are less relevant than Brendan Eich's political action... Brendan's "political action" was a small one-time donation made in private. He wasn't out there tearing anyone down publicly. &gt; ...and the positions of a contractor doesn't reflect on the company as much as those of the CEO. I'd agree with that. It's a more reasonable statement than asking if Steve is a crypto-homophobe. Yet still inconsistent in my view. &gt; The whole point of open source is to make free software palatable to capitalists, this is hardly a conspiracy. I fully agree. &gt; To the extent that Mozilla should care about things outside the web remaining a thing, I don't see why they as a non-profit should feel threatened by anti-capitalist talk. Nor do I. That's not the point. He's accusing those who are paying him of engaging in conspiratorial activities, which has nefarious overtones. &gt; Compare that to material support by the CEO for discriminatory laws that do threaten the Mozilla employees and volunteers and do make Mozilla look bad in the community they work with. All laws are discriminatory on some level. If the US federal government for example adopted Marxist philosophies, it would discriminate against its opponents, and so would be no less threatening toward those Mozilla employees. &gt; Homophobia is not a phobia. If it's not a phobia, then don't call it a phobia. Say what you actually mean. &gt; Thanks for clarifying that your support for equal marriage is based on libertarian fundamentalism rather than empathy with queer people, I guess. Oh my goodness. So it's not enough to agree with a person's position, but it must be for the same reason as well? No, it's not out of empathy for a specific group. It's out of a desire for ***all people to be free***. How you make that into a bad thing is beyond me. Call it *"libertarian fundamentalism"* if you wish. Doesn't matter. Whatever you call it, I'm willing to stand up for people even if I disagree with them and even if it means standing up *against* those with whom I do otherwise agree.
If there was a UTF-8 type (utf8), I would find it clearer to use `&amp;[utf8]` and `Vec&lt;utf8&gt;`. At the very least have a better connection between the type names; either `String` and `StringVector` or `StringSlice` and `String`, whatever makes `String` the most common type in use for most programs.
I am also a total rust noob, but I would write it like this: fn transform_path(foo: &amp;str) -&gt; String { foo.split('/') .collect::&lt;Vec&lt;&amp;str&gt;&gt;() .tailn(3) .connect(".") } fn main() { std::io::println(transform_path("http://foo.bar.baz/some/path/here").as_slice()); } * You pass a string slice, because you're not trying to mutate the argument - just read it. * You return a String, because the lifetime of any string slice you create inside transform_path() ends as soon as transform_path() returns. One question I do have though: Why is the type notation required for collect()? For example, if I remove the "::&lt;Vec&lt;&amp;str&gt;&gt;", rustc says: string.rs:3:5: 5:18 error: the type of this value must be known in this context string.rs:3 foo.split('/') string.rs:4 .collect() string.rs:5 .tailn(3) error: aborting due to previous error Why can't the type be inferred by the type information encoded in the function signature? edit: And a small criticism: Why oh why is the method for concatenating strings in a vector "connect()" rather than "join()"? Connect has far greater networking connotations!
Not rust-related, but the concepts might be interesting to people who like rust. 
&gt; While I was speaking, I was trying to figure out how to explain how to explain this to an audenice who may not be programmers. So the way to explain this to non-programmers is to... mention type systems. It seems pretty conceptually simple: tag values that may be null with some extra meta--data that says whether it is null or not. How it is actually implemented is less interesting, conceptually speaking.
C++11 actually forbids copy-on-write by tightening up the iterator invalidation rules. AFAIK, it was intentional as a way to strong arm implementations into stopping.
Heh, and based on the votes, there are lots of people in this community who are OK with slandering a group because of one member's beliefs. Didn't think this community was so eager to malign and alienate. Funny how those who preach tolerance are so often the least tolerant.
Deleuze/Guattari is the bomb. Every since I read Nomads and the State, my world has been upside-down.
Keeping politics out of code is impossible. They are intractable
It's comparable to C++ (well, to some of the many different C++ styles), basically all the standard container objects put some fixed size management data on the stack and then one or more pointers to the heap that you're always indirecting through. It's probably magnified a bit by variable sized objects on the stack seemingly not working at all right now. It ends up looking very heap heavy from the perspective of C (esp C99) and small embedded systems, where the very low and deterministic overhead of the stack is helpful for performance. It doesn't look bad compared to 'proper' 'safe' C++ style, but that style also ends up with a lot of allocator related overhead (and thus some of the big interest for tcmalloc and jemalloc in C++ projects). It should be possible to allow more use of the stack, while preserving the rust safety properties.
Shouldn't the `1i` give it enough information that it should use the `int` version of random?
&gt; but it doesn't fix it's inherent internal contradictions Like everything else in the world it's not perfect like we have this problem that companies must always seek short-term income with ever-growing revenues but overall it works well. Looking at communist countries, I don't see a single one is history that's been successful. Look at Cuba, the people there are often in misery and suffer from dictatorial laws and so on.
&gt; let secret = (rand::random::&lt;int&gt;() % 100i) + 1i; Sorry about OT, but I just thought about the current discussion regarding &lt;&gt; vs [], and couldn't help but notice how much nicer this looks: let secret = (rand::random::[int]() % 100i) + 1i;
I suggest making one! I used to use bitbucket for everything, but I've began using github for my (regrettably small and new) Rust projects.
Wouldn't this just be &amp;[u32] and Vec&lt;u32&gt; with lots of wasted space?
Homophobia has almost never meant a literal fear of homosexuality; for the last 30-40 years it has been the analogue of the word racist. That's just how language *is*, and it's certainly not a lie to use it like that! :) You strike me as someone who is really just wanting to drive home a point -- I don't see you really listening to what people are saying to you. You're reaching for arguments because they support your position, not because you've actually thought them through... :(
&gt; Brendan's "political action" was a small one-time donation made in private. He wasn't out there tearing anyone down publicly. It wasn't "one-time". And it wasn't exactly small, by most people's standards, though perhaps it is by the standards of political donations. And surely you recognise the difference between expressing an opinion and giving material support to further a political cause? &gt; If it's not a phobia, then don't call it a phobia. Say what you actually mean. That *is* what the word actually means. That's how language works.
As an admittedly unmarried man, I'd argue that marriage comes with a slew of material privileges. I guess in the long term we could ~decouple~ them from the social contract of marriage and eventually deprecate marriage, but in the short term marriage equality seems like the path of least resistance to extend those privileges to ~everybody.
If people who preach tolerance *weren't* intolerant of intolerance, they wouldn't get anything done.
&gt;Homophobia has almost never meant a literal fear of homosexuality; for the last 30-40 years it has been the analogue of the word racist... And you say I'm the one who's not really listening to what people are saying? First, this isn't ultimately about Brendan. It's about Steve. Second, the point wasn't to quibble over the definition of "homophobia". Yet that's what you and ben0x539 chose to focus on. So let me rephrase. Just because one believes in a traditional family doesn't make them utterly antagonistic toward homosexuals. &gt;You strike me as someone who is really just wanting to drive home a point -- I don't see you really listening to what people are saying to you. You're reaching for arguments because they support your position, not because you've actually thought them through... :( Shall I use arguments that *don't* support my position? What have I not thought through? Please give me something concrete. And what makes you think I'm not really listening? Is it merely because we disagree on some points? Am I required to mindlessly agree with an opposing position?
&gt;I'm aware of only one. A quick google shows there have been a number of others to various anti-same-sex-marriage candidates and causes. &gt; I'm comfortable with calling it "small". As I said, by most people's standards. $1000 is a significant amount of money to most people. &gt; Point is that he wasn't on a platform tearing people down. No, he *privately* made significant material contributions to a cause that would make people's lives objectively worse. Whereas Steve exercised his right to freedom of speech to criticise public figures (as an individual, and not as part of the Rust team). &gt; *What* is what the word means? The word homophobia does not mean a literal fear, but refers to prejudice/discrimination. There is nothing unusual or incorrect about using it in that sense. You're being overly literal-minded if you argue that it is incorrect to describe people as homophobes simply because they are not *afraid* of LGBTQ people.
Here is the code of get : impl&lt;K: Clone + Ord, V: Clone&gt; BTree&lt;K, V&gt; { pub fn get(self, k: K) -&gt; Option&lt;V&gt; { return self.root.get(k); } } So yes ownership is taken from the `tree` variable and you can't use it anymore. It's a bug maybe. 
&gt;A quick google shows there have been a number... One, ten, whatever. You're focused on a tiny detail and ignoring the point. &gt;As I said, by most people's standards... And as I said, relative to his presumed net worth, it probably isn't. You're focused on the dollar amount, I'm focused on the percentage, and again none of this has much to do with the overall point. &gt;No, he privately made significant material contributions to a cause that would make people's lives objectively worse. Yes, they would likely feel that their quality of life has been lessened by the hand of government. As I've stated elsewhere, I disagree with that legislation. &gt; Whereas Steve exercised his right to freedom of speech... Well, how we use our money can be freedom of speech as well, but I get your point. Do you suppose Steve has ever made political donations that would be in line with his views? &gt;...to criticise public figures (as an individual, and not as part of the Rust team). He did more than just criticize public figures and then posted it on the Rust subreddit. Not a wise move considering much of the article would be considered controversial to many. Yes it was freedom of speech, and I fully support is right to say what he said. Doesn't mean I have to agree with it. &gt;The word homophobia does not mean a literal fear... Again, hung up on tiny details and not addressing the original point I was making. Just because one is in favor of traditional family, doesn't mean they are *[insert current definition of homophobic]*.
&gt; Just because one believes in a traditional family doesn't make them utterly antagonistic toward homosexuals. Yes, I can't imagine why anyone would think that a person who makes significant material contributions to causes that would make LGBTQ people's lives objectively worse is “utterly antagonistic” towards LGBTQ people.
 What I said was that it doesn't *make* him antagonistic toward them. Just because people may hold that particular belief doesn't automatically mean they're antagonistic, irrespective of what others may think.
&gt; You're focused on a tiny detail and ignoring the point. The point I was making here was that it wasn't a one-off event but a pattern of behaviour. &gt; You're focused on the dollar amount, I'm focused on the percentage Actually I was focused on the amount relative to an average person's net worth, the reason being that making thousands of dollars worth of donations is not an option for most people. But I assume you'll argue that this is irrelevant too. &gt; they would likely feel that their quality of life has been lessened by the hand of government I think it's curiously shortsighted to blame the government and yet overlook the organisations and individuals who invested thousands of dollars in influencing the outcome of the vote. &gt; He did more than just criticize public figures All I see is that he called certain people racist. &gt; and then posted it on the Rust subreddit Actually, someone else did. &gt; Just because one is in favor of traditional family, doesn't mean… [I addressed this elsewhere](http://www.reddit.com/r/rust/comments/2bpnia/long_interview_with_steve_klabnik_whos_producing/cj8aefs)
Why on earth would you behave in a manner that harms other people if you're not antagonistic towards them?
Is implying that Brendan is homophobic merely because of his support of his apparent position on marriage an example of tolerance?
Which material privileges are those? If you mean tax-related privileges and the like, some countries already have civil unions that are marriage in all but name, conveying all the same legal benefits. &gt;in the short term marriage equality seems like the path of least resistance to extend those privileges to ~everybody Note that banning heterosexual marriage would still technically count as achieving marriage equality.
yes. btw you might want to read http://rustbyexample.com/move.html, awesome tutorial :)
Any time a law is passed that restricts a behavior, a person could likewise be considered to be "harmed" by some personally held definition. But to answer your question, there are many who believe that the strength and integrity of society in general is bolstered by a traditional family unit. Whether or not they are correct, such a motivation isn't inherently antagonistic toward those who feel they are adversely affected. They may be wrong in their conclusions, but it doesn't mean they're out to get anyone. Nor does it mean they're *not*. One can't tell merely from this alone.
Always strikes me as odd that the conversation always seems to have government involved. Is it really such a strange idea that two people should be allowed to marry without the blessing of the state? How about if government's only involvement is insofar as there's a legal contract? Then the whole debate goes away with respect to government defining such privileges.
Thanks, I get that the whole thing is somewhat experimental, I suppose some parts are more experimental than others.
&gt;...But I assume you'll argue that this is irrelevant too. I'm saying that the overall point doesn't pivot on those details. &gt;I think it's curiously shortsighted to blame the government and yet overlook the organisations and individuals who invested thousands of dollars in influencing the outcome of the vote. How am I overlooking those who invest thousands in influencing the vote? I said it above, and I'll say it again. I oppose the legislation. I oppose supporting the legislation. I think it's unwise. Brendan disagrees and supported it. However I don't believe that his contributions to a cause in which he believes deems him worthy of dismissal. &gt;All I see is that he called certain people racist. Yes, and such should not be done casually. Overall I find the article to be generally disparaging of some peoples world view. &gt;Actually, someone else did. You're right. Someone else posted it here. My mistake.
Because if people were allowed to marry without the State's blessing then the majority would lose the ability to enforce their social values upon the minority, which is completely against the spirit of democracy :O
&gt;...as if the government action was not prompted by individual and corporate lobbying... Nope, people who support such legislation are part of the problem. But it doesn't mean they're hateful. They just have a different view of the role of government than I. My blame of the hand of government in the oppressive sense is inseparable from blame of those who empower government. I don't like Brendan's means of enforcing his social ideals, but I won't demonize him for his ideals either. He wasn't criticized specifically for contributing to the political process, but rather for contributing to *that specific* political endeavor. &gt;I don't think the claim that ESR is racist is unique to Steve... -I'll grant for this conversation that the individual is a racist. However that's not what Steve said in the article. He said *"..the founders of the open-source movement are mega-racist libertarian people"*. So he not only maligns a group rather than an individual, but he also at least loosely associates racism with libertarianism. &gt;People's worldviews are not above “disparagement”. You yourself have been quite disparaging of some people's worldview. Of course they're not, but there's a difference between broadly disparaging someone or something and expressing a difference of opinion on specific points. If he's out there claiming to be "anti" some group of people, he's going to hear disagreement.
If the 'utf8' type represented a single multi byte grapheme this would work I suppose. Something like: struct Grapheme { len: u8, bytes: *const u8 } ...but thats basically what a string is anyway; except we can get away with a u8 (or less) because graphemes are never 256 bytes long. Itd bloat the memory usage for strings up like crazy, but it would have some pretty useful properties; every interaction with a string would have to be through a meaningful grapheme (unlike array of u8, which is very easy to break, eg by running to uppercase on each character). maybe not a great idea, but you could do it.
&gt;If it was just about his 'ideals', this would be a different conversation, but the whole problem is that he's trying to enforce them. Yes, I know that. I'm not saying it's merely his ideals. And it's not that he is contributing to a political endeavor. The issue was that he was contributing to *that specific* endeavor. That's what I said above. It's starting to seem like you're trying to take this in circles, or maybe you're just not reading what I'm writing. &gt;By pointing out that some libertarians are racist? No, by making an unnecessary association that I described above as "loose". Not a rigid "all libertarians are racist" statement. &gt;Ignoring the conflation of a group and an individual... Oh sure, let's conveniently ignore that. Quite the mistake to make. &gt;You, on the other hand, started out by accusing him of having a chip on his shoulder. I said that it *"sounds like"* he has a chip on his shoulder, and in that article it does. I've *accused* him of nothing. The guy just sounds to me like he's bent out of shape regarding a bunch of stuff. It's my opinion. &gt;I'm sorry, can you remind me, who was “broadly disparaging”... He is. He claims to be anti-capitalist and says that he's drawn the conclusion that capitalism is "bad". That's pretty disparaging of a large group of people. &gt;...and who was “expressing a difference of opinion on specific points”? I was and have been, though it's difficult when you consistenly try to misrepresent what I've said.
Yes? Generally speaking, if intolerant activism is met with no social repercussions, that's not tolerance.
In a world where civil unions are universally treated by laws and regulation just like marriage, yeah, I wouldn't make that argument. As I understand it, currently civil unions don't tend to come with the same sort of recognition as marriage, especially across different jurisdictions.
What does this have to do with "the traditional family unit"? People aren't trying to ban straight people from marrying. The effect on straight marriages is exactly 0.
I agree that if we were living in a dystopian nightmare state where the government does nothing but enforce contracts and is funded by pure lack of empathy somehow, campaigning for marriage equality would probably not be anyone's first priority.
“Communism has historically led to misery and suffering, so we should stop trying. Capitalism has historically led to misery and suffering, so we should keep trying until we get it right.”
Well, he apparently feels the need to use government to enforce it. If you want to know why, ask him or someone else who feels that way. My point was that support of such legislation can be for motivations that are non-antagonistic, misguided though they may be.
That's correct.
So if one calls another homophobic though they haven't substantiated that claim, their behavior is tolerant because they're genuinely convinced of that claim? I would think that the tolerant person would attempt to understand the motivation of the other so as to discern whether or not they are indeed homophobic rather than jumping to that conclusion. In other words, if Brendan's contribution to that legislation is something with which someone may disagree, I would think that a tolerant person would tolerate his behavior until they can confirm that the contribution was indeed made out of a spirit of intolerance. And if indeed he wasn't intolerant but rather made the contribution for other reasons, then the tolerant one should be tolerate his activity though they disagree with it. No?
That was indeed your point, but you didn't give any valid arguments to back it up.
Did you read the thread? I described the non-antagonistic motivation that some people have. I didn't say they're correct. I didn't agree that it would have any real impact on society. I'm just reiterating their position. Just because you don't like their claim and just because they may be entirely wrong in their conclusions doesn't mean that it isn't what they genuinely believe and that they hold ill will toward homosexual people. I wasn't making their argument. I was *describing* their argument.
Okay, well, I'm gonna stand by calling it a homophobic act to finance PR efforts to deprive non-heterosexual people of equal rights. I'm sorry that we disagree on that.
If I have some suggestions should I add them to that case or just open up a new one? Thanks for this work btw.
There's no need to be sorry, and you can call it whatever you want. Ultimately you don't know what's in his heart and mind, and neither do I.
Well, this is incredibly off topic, but your comment suggests that you haven't tried to understand ESR's position, which is not about moral failure, rather biology, human biodiversity, and the existence and heritability of a trait called 'g' which is measured using a number of IQ tests. It seems you'd rather criticize some straw man ESR, not the actual one. I'd call that arguing in bad faith.
All good points. I linked to a ticket below, would you mind leaving a comment with this? If not, I can.
&gt; Looking at communist countries There is no 'communist countries.' There were socialist countries attempting to bring about communism. The Union of Soviet **Socialist** Republics. &gt; look at Cuba You can't just look at these countries without regard for history. The United States has been fucking with Cuba for so long, of course they have problems. When the biggest imperial power in the world says "Don't trade with these people," things aren't going to be roses. Also, Cuba has a lot going for it. Their universal heath-care system is world-class, and their doctors are awesome, from my understanding.
&lt;3. I feel the same.
Well, you wrote "...ESR's racism is the direct result of his expectations that failings are due to some sort of moral failure of the individual..." which has nothing to do with what ESR actually wrote (which I just reread to ensure that I don't mistake his position), so I can only infer that you have some bee in your bonnet about ESR so you write "Racist!" expecting your fellow travelers to nod their heads. 
Careful. `&amp;str` can be a view on a `String` as well. `String` implements `trait Str`, so you can obtain a `&amp;str` using `String::as_slice()`. I'm not sure I like the fact that `&amp;str`/`String` are comparable to `const char *`/`std::string`. A common criticism of C++ is the duplication of string types. [This guy](http://yosefk.com/c++fqa/) rails against the duplicate (and arguably inferior) facilities of std::string several times. Calls to `String::as_slice()` also remind me of C++ code mixing `const char *` and `std::string`, which is littered with casts via `std::string::c_str()` calls.
ATS is really intereseting. Dependent types &lt;3_&lt;3.
So, I'm interested: Immediately following that code, I say this: &gt; It didn't work! Rust says "the type of this value must be known in this context." What's up with that? Well, as it turns out, rand::random() can generate many kinds of random values, not just integers. And in this case, Rust isn't sure what kind of value random() should generate. So we have to help it. With number literals, we just add an i onto the end to tell Rust they're integers, but that does not work with functions. There's a different syntax, and it looks like this: And continue. Was this explanation not enough? Was it that you tried to compile, got the failure, and didn't read on? I'd like to fix the guide here, if there's a problem. EDIT: Reading the bug report, it looks like the code in the guide may not compile any more, or something? Unsure. I'd love to get to the bottom of this, though.
Nope, because it can be any time that implements `Rem&lt;int, T&gt;`. That `T` is unresolved.
I'm not cringing; I had the same idea. I just reached the conclusion that I don't think it makes sense. Basically my thought was that you would distinguish three classes of types: "normal" non-affine types (is there any actual word for these?); affine types; and linear types. The distinction rests on whether the thing can be freely duplicated and whether it can be freely destroyed. These are represented in the type system by the built-in `Copy` and `Drop` traits, respectively. "Normal" non-affine types implement both `Copy` and `Drop`; affine types implement `Drop` but not `Copy`; true linear types implement neither. (Here `Drop` represents not "does a thing when it is dropped", but "can be dropped at all", which POD types trivially satisfy. The compiler would emit an error if a type without `Drop` would fall off a scope without being explicitly consumed. There's a bit of abuse-of-notation going on where `Drop` refers to both the drop glue for a given type *and* to the `Drop` impl the programmer might write for it; I'm mostly using the former sense. I.e. a type declared linear would not have drop glue generated because it *couldn't ever* be dropped. Which is of course the guarantee that's violated by unwinding.) So basically, if you `impl Drop for File` then it's no longer linear, but affine. And `File` is a somewhat bad example for a linear type because it *can* have a sensible `Drop` impl (and if it can, then why not have one), whereas I think true linear types would tend to be the ones which can't, like `&amp;out`. &gt; Others require none [cleanup] (an uninitialized, i.e. "`out`", reference - its existence requires that the memory it's pointing to doesn't yet contain a valid value). This is only true as long as the `&amp;out` was created to point into the local stack (i.e. where the compiler knows about it). If it points into either some heap-allocated structure or to something that was passed in as an `&amp;mut` and then temporarily moved out of, then doing nothing when unwinding through the `&amp;out` would result in the destructor of the affected structure accessing invalid memory. The only safe thing to do in the general case is abort. As I said, as long as this only applies to `&amp;out` it doesn't really bother me, it's not nice but the tradeoff is worth it, but if there were many other linear types (asides from ones being linear due to containing `&amp;out`) then it might start bothering me. But that's fairly hypothetical, because I haven't encountered any examples yet of types which would want to be linear *other than* `&amp;out`.
&gt; There is no 'communist countries.' There were socialist countries attempting to bring about communism. The Union of Soviet Socialist Republics. No private property, state-owned production means is not communism? They had to cut quite some heads when they instaured the Soviets.
It wasn't immediately obvious to me that whitespace stripping, substring finding, and other string manipulation required converting a `String` to a `&amp;str`. I can't tell what functionality is unique to `&amp;str`, and what is unique to `String`. How about adding a diagram to the [Rust string guide](http://doc.rust-lang.org/guide-strings.html)? I could also use more formatting methods, like left and right justification, centering, joining and splitting, case swapping, and title casing (for code points that have lower/uppercase). 
Rust is a language that lets you do everything you could do in C++, except that code you write at 3AM doesn't let random people own your machine.
* Speed: Rust is a close-to-the-metal systems language with performance in the same league as C and C++. * Safety: At compile time, Rust guarantees the absence of nasty bugs like dangling pointers, heap corruption, buffer overruns, and race conditions. * Modern features: Rust incorporates goodies from functional languages such as closures, algebraic data types and pattern matching.
This is a pretty good two-sentence summary: &gt; Rust keeps the C abstract machine model but innovates on the language interface. Rust is expressive, its type system makes system code safer, and its powerful meta-programming facilities enable new ways to generate code automatically. -- [Rust for functional programmers](http://science.raphael.poss.name/rust-for-functional-programmers.html)
I've been thinking about this: The problem with the "mutability modifier polymorphism" approach is that it adds another moving part to a language which already has a few, and is rather narrowly targeted. I.e. the power-to-weight ratio is not very compelling. The problem with the "just use HKTs" idea is that it can't work, because `&amp;` and `&amp;mut` are built-in types with capabilities which no user-defined trait will ever let you abstract over. The `Deref`* traits are not appropriate because they return concrete `&amp;` or `&amp;mut`, whereas the whole idea was to avoid that; and they only deal with *de*referencing, not *forming* references or sub-references. But maybe a synthesis of the two ideas could have some potential: Introduce a built-in higher-kinded trait, say call it `Reference` (with `Self`-type of kind `Lifetime -&gt; * -&gt; *` in Haskell notation), which is implemented by the built-in reference types `&amp;` and `&amp;mut`. Being built-in, it doesn't have any actual user-callable methods, but instead `R: Reference` tells the compiler that `R` is a built-in reference type, and thus is subject to the borrow checker and has capabilities such as, given `R&lt;MyStruct&gt;`, dereferencing and then forming a reference to a field to get `R&lt;TypeOfField&gt;` (the fact that `R` stays the same across this operation is crucial). And to get the least common denominator of capabilities between `&amp;` and `&amp;mut`, you would simply neglect to specify `Copy` and `DerefMut` as additional bounds. (Potentially the same trait could also let you abstract over `&amp;move` and/or `&amp;out` should we gain them later on? And potentially there are problems with this approach. I haven't given it a tremendous amount of thought, it just seems like a promising idea.)
The main thing isn't that exceptions are unlikely, it's that you have to go out of your way to cause memory errors that aren't detected and silently cause problems or crashes that could lead to security issues if your program is exposed to untrusted input. This isn't a big deal for some high-level languages, so the selling point is really to achieve that without sacrificing too much performance to still be useful where right now only C++ and similar can be used.
I've only been using rust for a little bit, but I love the functional-ML inspiration the language has. I've had a lot of trouble trying to ease my way into languages like haskell but rust was much more approachable for an imperiative programmer like me.
My understanding is that Cuban doctors are valued all over South America, though my memory on this is admittedly quite fuzzy.
Yes, because communism is stateless, classless, and moneyless. 
So how is this different from the graphics libraries that are already present in the Piston library? Im confused.
`rust-graphics` only does 2D and isn't really GPU accelerated.
OOM, needs more memory. Building librustc currently takes about 2G.
The image in the left sidebar is broken http://gfx-rs.github.io/img/logo.svg 
If it is a memory issue, you could create a swapfile to be able to compile it anyway (albeit very slowly). Run these commands as root: # Create a 2GiB file on /swap fallocate -l 2G /swap # Format it as swap mkswap /swap # Register it as a swap on fstab echo '/swap none swap defaults 0 0' &gt;&gt; /etc/fstab # Enable it swapon -a Out of curiosity, is there any particular reason why you are compiling rust on the server instead of downloading a pre-compiled nightly?
The code in this article isn't colored, which violate the second article of the Geneva convention on code readility, please fix. :( 
Trust me, you wouldn't want to see what the version of pygments github pages is using does to Rust code...
+1 Thanks!
Actually, it's reasonable with this theme. On another theme I tried it made half the text unreadable..
Which theme are you using?
http://jekyllthemes.org/themes/simplygrey-theme/?
Is this just a wrapper around OpenGL, or do you have ambitions to abstract more than that? If so, I'm especially curious about how you plan to abstract shaders. EDIT: OK, "Graphics API agnostic (OpenGL/Direct3D/Metal)". Curious++ *re* the shader question.
See https://github.com/gfx-rs/gfx-rs/issues/71. I think our shader parameter/vertex format stuff is robust enough to work across the desired APIs, but you *will* need to provide a shader per API you want to support. No good way to get around that, best real solution seems to be just writing a new shading language that can transpile to the others.
Perhaps someday we'll have your_string[:] as the way of getting slice of your_string.
Thanks, it's better. :) And the article is interesting.
&gt; that code you write at 3AM doesn't let random people own your machine. More like own the internet. Looking at you heartbleed.
The story is in the interview, actually.
Thanks :) 
Unless all your 3AM code is inside an `unsafe{}` block...
`let secret_number = (rand::random() % 100i) + 1i;` The way i see it, the `% 100i` satisfies the RHS of the `Rem&lt;RHS, RET&gt;`, as you said. So now we must determine what the return value needs to be, by marking the `1i` as an int, shouldnt the rust compiler know what the `Ret` value is?
I can definitely get behind this effort. I'm drawn to the idea of an abstract graphics API wrapper that is well-written and popular in the Rust community.
`let box mut q = p;` attempts to destructure a Box, but I think trait objects simply can't be dereferenced. I'm not sure why the for loop doesn't like an iterator trait object. Probably, the for loop just doesn't support them. `p` does definitely implement `next()` so you could write your own loop: let v = vec![1i,2,3]; let mut p = box v.move_iter() as Box&lt;Iterator&lt;int&gt;&gt;; loop { match p.next() { None =&gt; break, Some(e) =&gt; println!("{}", e) } } In any case, heap allocating an iterator is pointless, as they're lightweight and lazy objects (at least as typically implemented). 
I've had a higher success rate of "code compiles =&gt; code works" than with C++, even though I have much more experience with C++. Overall, I love that there's now another language taking the RAII idea from C++. I think it's a great concept that isn't used anywhere near as much as it should be.
I read that remark to mean you are calling all of the kernel and GNU people racist, and I do not feel I was mentally taking liberties with your words.
Maybe we should just lint against `Box&lt;Iterator&lt;E&gt;&gt;`. Or we can wait until `trait Iterator&lt;E&gt; {...}` becomes `trait Iterator {type E; ...}` which would stop `.next()` from working at all through a trait object. To OP: there is no good reason for using iterators through trait objects, nor can they really work like that. Why do you think you'd ever need such a thing?
The second error "`for` loop expression does not implement the `Iterator` trait" is a recent thing I think: for loops have been fixed so that you have to give them an iterator (I think they used to work with anything that had .next() returning Some or None, which meant you could accidentally screw them up by defining e.g. None to be something else). I just hit this in racer and hacked an iterator wrapper to get it compiling again. E.g. pub struct BoxIter&lt;T&gt; { iter: Box&lt;Iterator&lt;T&gt;&gt; } impl&lt;T&gt; Iterator&lt;T&gt; for BoxIter&lt;T&gt; { #[inline] fn next(&amp;mut self) -&gt; Option&lt;T&gt; { return self.iter.next(); } } then in your example for i in BoxIter{ iter: q} { ... } 
One reason I've used them is that chaining and mapping iterators makes type signatures horrible. E.g. I had this error yesterday which I still haven't managed to decipher (how do I include the 'Send' bound in the type signature?). I ended up boxing the iterator and making it a trait object as a workaround. ../racer/nameres.rs:623:12: 623:14 error: mismatched types: expected `core::iter::Chain&lt;core::iter::Chain&lt;core::iter::Chain&lt;core::iter::Chain&lt;core::iter::FlatMap&lt;'static,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;,core::iter::FlatMap&lt;'static,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;,core::iter::FlatMap&lt;'static,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;,core::iter::FlatMap&lt;'static,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;,core::iter::FlatMap&lt;'static,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;` but found `core::iter::Chain&lt;core::iter::Chain&lt;core::iter::Chain&lt;core::iter::Chain&lt;core::iter::FlatMap&lt;'_,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;,core::iter::FlatMap&lt;'_,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;,core::iter::FlatMap&lt;'_,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;,core::iter::FlatMap&lt;'_,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;,core::iter::FlatMap&lt;'_,proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;:Send,core::option::Item&lt;proc() -&gt; collections::vec::MoveItems&lt;racer::Match&gt;:Send&gt;,collections::vec::MoveItems&lt;racer::Match&gt;&gt;&gt;` (expected no bounds but found `Send`)
You are making this much much harder by overloading `Drop` to mean `NonLinear` which I find absurd. Having a `Box&lt;T&gt;` on the stack with an `&amp;out T` pointing into its heap allocation is simply wrong, and it would deserve all the UB that calling the destructor on uninitialized memory implies. To be a bit more clear, in such a case the `Box&lt;T&gt;` would not exist as a value until after the heap allocation has been fully initialized.
That is the whole point with rust-graphics: To get an easy to use 2D api with low dependencies. You make it sound like a bad thing...
The reason the iteration doesn’t work is because you’re trying to iterate over a type error!
As I understand it (I could be wrong), `rust-graphics` is an immediate mode API, meaning you issue draw commands to the renderer in a procedural way, for example: 'clear frame, draw line, push transform, draw rectangle, pop transform...'. This is easy to understand, and is fine for most simpler 2D applications, but it becomes a significant bottleneck because the CPU and GPU are working in lockstep. For more demanding applications, a 'retained mode' is preferable. This means that you upload vertex data and shaders to the GPU before drawing, set up some alterable parameters to modify the output of those shaders over time, then finally begin issuing draw calls, and changing the parameters as needed. This allows you to take full advantage of the parallelism that the GPU provides, and this is the kind of 'best-practice' approach that the `gfx-rs` API should lead you towards. I see `gfx-rs` as a type and memory safe abstraction layer that encourages best practices, yet also allows one to take advantage of the power of the GPU, whilst being blind to the actual semantics of the information it is receiving. So it should be pretty flexible. One way to look at it is that `gfx-rs` could be the foundation on which things like `rust-graphics` or `snowmew` are implemented on top of.
&gt; To get an easy to use 2D api with low dependencies. That is a really great goal, and certainly needed! Your libraries have great ergonomics, and we still have much to learn from them. I think `gfx-rs` will always have a higher barrier for entry, but this is required for the kind of use cases we are targeting.
First of all, I'd like to state something simple: &gt; A simple programming language does not (necessarily) leads to simple programs. As evidence, I'll cite C: while everything is explicit, subtle bugs creep in (dangling pointers, double-free, out-of-bounds errors). The language is simple, wielding it correctly is hard. Now, on to your questions: - learning curve: depends where you start from. Rust mixes concepts from both the imperative and functional languages, so you need to understand Sum Types/Pattern Matching as well as Lifetime and the difference between by-value and by-reference. If you come from C++ and dabbled with Haskell like me, it's a cinch. - powerful: I will suppose you meant *expressive*, and yes it is. Rust is built on *expressions* (rather than statements) and combined with functional programming goodness you can express pipelines of operations easily without fussing over the details of iteration. - performant: the Rust language, despite its high level feel, actually maps very well to lower-level instructions; combined with the fact that the compiler is built on top of LLVM, performance is (for now) in the same ballpark than C and C++. In the future, because Rust type-system has more information about aliasing, it could actually beat them. - pleasant: I found it pleasant, the syntax is lightweight and type inference means there is very little noise. Furthermore, the type system is powerful enough that many bugs that would be caught at run-time in other languages are caught by the compiler instead; and the compiler points you directly at the faulty bits, so investigation time is close to 0. - free: it is a statically typed language, but the use of type inference reduces the noise a lot, so I would say somewhere between Python &amp; Java (little experience with JS). Hope it helps.
If it compiles, it works. For the most part at least, as indexing, slices, ranges, the rare unsafe block, and a few other things can still result failures, but it's overall a much more pleasant experience because it's obvious where the error is occurring.
I think there is a typo in the linked article. In the rendering thread, it says let mesh = renderer.crate_mesh(vertex_data); while I think it should be let mesh = renderer.create_mesh(vertex_data); instead, which is also what the example on Github uses. 
even when working on demanding applications, its great to keep an immediate mode api around for debugging &amp; trying ideas out quickly 
gfx-rs got impressive ergonomics considering its goals. I'm going to test it today. This is a project I am very excited about and glad to see some Rust veterans putting their effort together on this.
&gt;by marking the 1i as an int, shouldnt the rust compiler know what the Ret value is? All the compiler would know is that the return type should satisfy `Add&lt;int, T&gt;`. Even so, knowing that it should satisfy `Rem&lt;int, int&gt;` and `Add&lt;int, int&gt;` still doesn't give an exact type for `rand::random()`. I made an example case [here](https://github.com/rust-lang/rust/issues/15960#issuecomment-50250387) showing that the type of `rand::random()` is not necessarily `int`, even if the resulting type from the calculation is known to be `int`.
&gt; You are making this much much harder by overloading Drop to mean NonLinear which I find absurd. Whether or not that's true, I still think that the types you would want to be linear are the ones which *can't* be allowed to fall off scope and (relatedly) *can't* have meaningful destructors. If you can write a meaningful destructor for a type then I don't see any reason why that type couldn't or shouldn't be affine. Do you? &gt; Having a `Box&lt;T&gt;` on the stack with an `&amp;out T` pointing into its heap allocation is simply wrong, and it would deserve all the UB that calling the destructor on uninitialized memory implies. Perhaps we could be less strident and categorical in our statements? By removing the ability for `&amp;out` to point to arbitrary locations you would also, I think, remove most of its utility. N+1st time I'm writing this, but e.g. I think the trait for `box` should look something like: trait Alloc&lt;T&gt; { fn alloc(&amp;'s out self) -&gt; &amp;'s out T; } and would be used as e.g., being super-explicit about every step: let gc_ptr: Gc&lt;Foo&gt;; let foo_ptr: &amp;out Foo = (&amp;out gc_ptr).alloc(); *foo_ptr = Foo::new(bar); // `gc_ptr` can now be used so `alloc` takes as argument the obligation to initialize a `Gc&lt;T&gt;`, allocates the `Gc` box, and returns to the caller the obligation to initialize the contained `T`. Similarly, C++'s `emplace_back` on `Vec&lt;T&gt;` could be expressed as: fn emplace_back(vec: &amp;'s mut Vec&lt;T&gt;) -&gt; &amp;'s out T which allocates the additional element and returns the obligation to initialize it. You could [also][1] emplace multiple elements at a time: fn emplace_n_back(vec: &amp;'s mut Vec&lt;T&gt;, count: uint) -&gt; &amp;'s out [T] In fewer words: `&amp;out` is placement new reified as a type. [1]: https://github.com/rust-lang/rfcs/pull/98#issuecomment-46036846
The code-completion application "racer" does (edit: did) it and I was trying to get it to build against 'master'. It appears he changed it 4 hours ago -- removing the boxing. Im wondering if that code ever compiled now.
Thanks for the hint. The application I was trying to compile was updated while I slept, so it's a non-issue for me now. I will keep your suggestion in case I run into such code again, thanks :)
Racer is exactly what i was trying to fix, he updated racer last night and its not using the boxing anymore.
Which is one of the reasons why I always say that rust seems to be the first C++-replacement made by people who actually understood why C++ is as great as it is.
Isnt it? Id argue that SDL2's broken graphics API is a reasonably clear example of how abstracting shaders out of the developers hands and into the 'backend implementation' has turned out to be a bad idea. An easy to use graphics API is great, but SDL has pretty clearly shown its (the SDL api that is) not useful for anything except toy implementations; people doing real work almost invariably use opengl directly instead of the graphics api. want to draw nurbs curves with geometry shaders? nope. want to process in vertex shaders for ui animations? nope. want to specify how fonts are rendered in detail in fragment shaders? nope. want custom masking for windowed areas in fragment shaders? nope. Without a solution for cross platform shader support, Im pretty skeptical about the viability of a simple graphics api; gfx-rs certainly is much more interesting than rust-graphics to me for that reason. To be fair the SDL api is about pushing pixel blocks around, not doing useful things like drawing lines and curves (like rust-graphics) but I feel some of the same issues apply. 
Where can I read more about the #[ATTR] annotation? I am especially interested in this part https://github.com/gfx-rs/gfx-rs/blob/f0ef4a91c769b4cc9f03810c8af5b03caa1b0c98/src/gfx_macros/vertex_format.rs#L215 
Right. This interview was a conversation, transcribed by a non-native speaker. My intention was solely to refer to ESR, that's all I'm saying. That sentence could have used a better wording or some punctuation or something.
If you aren't trying to store the value in a non generic struct, then the abstract anonymous types are exactly what you want. If you are trying to store it in a nongeneric field, then your best bet is to copy the compiler's output into a `type`, or make that field generic over `Iterator`.
(Nb. the person you replied to, /u/phildawes, is the author of racer)
Wasn't paying attention to who was replying, thanks for tweaking that last night.
No, because even `for i in p` doesn't work.
Yeah, but the *branding* of that as open source was implemented to make it palatable to corporations. Before that it was called "free software".
I don't know what branding you're talking about and I don't know what it has to do with the act of sharing software. You said, the *point* of open source ("sharing software") is to make free software palatable to capitalists. This implies that I share software to achieve some political end. Since I know that I do not have that motivation, I am chiming in to assert that your claim is false.
The rust pretty printer can output a fully annotated version of a given program, I believe. Try `rustc --help`.
what you're doing used to be called free software. some guys noticed that corps don't like to engage w/ free software because it has 'free' in the name. so they came up with the term 'open source', registered open source dot org, copy+pasted the debian free software guidelines and called it the open source definition, and stamped a bunch of licenses that the fsf was previously calling free software licenses as open source licenses. doing the whole open source and/or free software thing is done for whatever reasons, but terming it open source and not free software is done to appease people who are afraid of free things.
&gt; what you're doing used to be called free software. some guys noticed that corps don't like to engage w/ free software because it has 'free' in the name. so they came up with the term 'open source', registered open source dot org, copy+pasted the debian free software guidelines and called it the open source definition, and stamped a bunch of licenses that the fsf was previously calling free software licenses as open source licenses. It sounds like you're referring to the Open Source Initiative and *not* open source. &gt; is done to appease people who are afraid of free things. For some definition of free.
No, not at all! I love rust-graphics. But it and gfx-rs do very different things.
Fixed, thanks.
Just to be clear, you're trying to emulate C code like: typedef enum { flag1 = 1, flag2 = 2, flag3 = 4, flag4 = 8, flag5 = 16, } whatever_flags; ?
Steve Klabnik: &gt; "My anti-capitalism is intrinsically tied to my interest in theory. [...] I thought, the fundamental problem of the world is definitely the accumulation of wealth [...] Eventually I realized that Marx was saying all these things I had been thinking independently. [...] I actually tend to identify more as a communist than an anarchist. [...] a bunch of rich people were sick of paying taxes. Like, that’s what it was. That’s why we’re a country. [...]" Oh dear! I expected something Rust related and instead I had to read through an endless list of gormless epiphanies of a teenager. Thanks for sharing!
The code in the guide does compile...after reading further. I actually didn't expect to find a problem and then a solution in the next few paragraphs down. Could you add something to the affect of "It won't compile yet, but try it out!"
Well, here's the closest I've been able to get: #![feature(macro_rules)] macro_rules! g( ($e:expr) =&gt; ({ let goal = concat!('g', stringify!($e)); goal.replace("()", "o").replace("(\"", "").replace("\")", "") }); ) fn main() { let goal = g![()("al")]; println!("{}", goal); let goooal = g![()()()("al")]; println!("{}", goooal); } Without dynamic typing or overloading/default arguments, the only other way I could see was macros. The macro has to be wrapped in parentheses/brackets and has to have an exclamation point, so we already don't have the exact target syntax. I tried to do something besides just string replacement, instead using a sequence of expressions, but something like ()() got parsed to one expression instead of two, so that seemed impossible.
I thought your main issue was getting the type… If what you want is to find the definition, then just use ctags with a decent editor. Or if you want, combine both: extract expanded typed code, run ctags on it and jump to the definition…
&gt; ...not useful for anything except toy implementations; people doing real work almost invariably use opengl directly instead of the graphics api. I would look more at [Processing](https://www.processing.org/) for an examples of the kinds of things that rust-graphics would be good for. Artists can create beautiful things despite the limitations. From there they can then venture into retained mode graphics if they find it too limiting (that's what I did).
If nothing else, you could grep the source for "enum Result", "struct Result", or "type Result".
use bitflags! macro. 
Seems good!
this some example how to use bitflags pub struct ScreenBuffer { pub handle : HANDLE } impl ScreenBuffer { .... pub fn set_mode(&amp;self, mode: OutputModeFlags){ unsafe { SetConsoleMode(self.handle, mode.bits()); } } .... } bitflags!( flags OutputModeFlags: u32 { static EnableProcessedOutput = 0x0001, static EnableWrapAtEolOutput = 0x0002 } ) then you can use it like this: stdout.set_mode(EnableWrapAtEolOutput | EnableProcessedOutput); 
I've put in a comment in the github issue. I hope I've explained what I'm thinking of.
Wouldn't this be possible with the [Fn traits](https://github.com/rust-lang/rust/pull/14590) from unboxed closures?
This actually seems like a very nice idea for testing. Have a bound-checked type that can be used to test the program but disable it at runtime if desired once bugs are fixed.
Thank you!!!
I would not know how to solve the lack-of-overloading problem between () and (&amp;str). It seems these Fn traits also don't allow emulating generic functions.
Here is one based on that which (AFAICT) actually conforms to the rules of the contest. #![feature(macro_rules)] macro_rules! goaler( ($e:expr) =&gt; ({ (stringify!($e)).replace("()", "o").replace("(\"al\")", "al") }); ) fn main() { println!("{}", goaler!{ g("al") }); println!("{}", goaler!{ g()("al") }); println!("{}", goaler!{ g()()("al") }); println!("{}", goaler!{ g()()()("al") }); println!("{}", goaler!{ g()()()()("al") }); }
So is the only way to implement this is via a global var?
I guess you meant to post that under reddit.com/r/playrust instead of reddit.com/r/rust
.6. g()('al') must be a valid rvalue if applicable in your language. So no, it's not quite there
This would be an acceptable incomplete solution though!
I haven't heard of HKT before, what does it stand for?
Higher kinded types.
I think everyone is missing your point, OP, but I understand. Right now there is no tool for something like that, but I hope that it exists one day. There has been a few threads about the state of tooling in rust. Right now, there is racer, which is an auto complete engine for rust, Google rust racer to find it.
*Warning: contains vague recollections.* When Andrei Alexandrescu was writing a book on D, one of the things he set up was an automatic process that would extract code samples from the text, compile them, and make sure they had the correct output. Maybe it would be a good idea to add something similar to... whatever you're using. Since you're also giving "this looks good, but doesn't work because..." examples, maybe give yourself the ability to distinguish code samples that aren't *supposed* to compile, and typeset them a little differently; you could add a "Note: does not compile" to the code box.
I approve of this "cheating". I do recall I mentioned something similar on IRC, though I would've stored an integer, for, you know, efficiency :). I really hope this will work one day, and I believe the trait reform will improve the situation here.
Something like ghci's `:t` would be insanely cool. A repl is a bit of a way off still though. :(
 //! test.rs #![feature(overloaded_calls)] use std::ops::Fn; use std::ops::FnOnce; use std::fmt::Show; use std::fmt::{Formatter, FormatError}; struct Goal { value: String } impl Show for Goal { fn fmt(&amp;self, fmtr: &amp;mut Formatter) -&gt; Result&lt;(), FormatError&gt; { return fmtr.pad(self.value.as_slice()); } } impl FnOnce&lt;(),Goal&gt; for Goal { extern "rust-call" fn call_once(self, (): ()) -&gt; Goal { Goal { value: self.value.clone().append("o") } } } impl&lt;'a&gt; Fn&lt;(&amp;'a str,),String&gt; for Goal { extern "rust-call" fn call(&amp;self, (s,): (&amp;'a str,)) -&gt; String { self.value.clone().append(s) } } fn main() { let g = Goal { value: "g".into_string() }; println!("{}", (&amp;g)("al")); println!("{}", (&amp;g()()()()())("al")); } == $ ./test gal goooooal So close...
That page was very helpful! Can you tell what is the best way to split a long string literal to multiple lines? In C++, I can do: const char *str = "long long long string " "continues without line breaks"; In Java: String str = "long long long string "+ "continues without line breaks"; I tried this in Rust, but it makes a line break: let str = "long long long string continues without line breaks"; This is the solution I'm using, but I think it contains unnecessary allocations: let str = "long long long string ".to_string()+ "continues without line breaks"; 
&gt; Read your result from the compiler error. I found this humorous. Is that a good thing?
This is the most promising suggestion. Thanks.
This is what we used to do is haskell too before we got type holes :) 
The C++-FQA is many things, but certainly not a good ressource for anything but unfounded rants by someone who doesn't have a clue about the language. Also, some of the things that you listed are actually totally awesome and rust will have to provide replacements for them at some point. Also rust adds some other stupid ideas like shadowing of local variables (basically this is a worse form of missing const). So, yes, rust has it's advantages, and it may well be better then C++, but the situation is certainly not as simple as you put it here.
Ada's optional dynamic checks (i.e. can be turned off) must be a really good way to develop. Instead, the state of the art for most languages seems to be unit tests, a sort of local optimum of checking a program for correctness, which might give people tunnel vision with regards to the fact that there are other ways to check for correctness out there (*i.e.: unit test or no tests at all* is a false dichotomy). 
Sure, the FQA is a humorous rant, but it manages to make several good points. Funnily enough, the author has [a page addressing ad-hominem responses](http://yosefk.com/c++fqa/faq.html). And definitely check me on this, but I think that every C++ feature I mentioned has been deliberately excluded from Rust. At the very least, there are well-reasoned rationales for keeping out [exceptions](https://mail.mozilla.org/pipermail/rust-dev/2013-April/003815.html), [constructors](http://doc.rust-lang.org/complement-design-faq.html), [assignment overloading](https://github.com/rust-lang/rust/issues/4047), [life before main](http://doc.rust-lang.org/complement-design-faq.html), implicit casts, ~~and struct inheritance~~. I doubt streams were ever considered, though I suppose "no initializer lists" doesn't say much, since rust, lacking constructors, initializes structs directly through struct expressions. I don't mind things like `let a = 4; let a = "four";`; given the explicit "`let`" syntax of identifier repurposing and the `#[warn(unused_variable)]` lint, it's difficult to do this accidentally. I suppose the falling out of scope may even allow for memory optimization. The reasons for inherited mutability are summarized [in this history question](http://www.reddit.com/r/rust/comments/264d2t/history_question_why_was_mut_from_structsclasses/chnkty5). Edit: hah!
&gt; .6. g()('al') must be a valid rvalue if applicable in your language. "If applicable in your language" seems to give us a pass.
That rebranding was about removing the FSF definition on *freedom* from the movement, not the word "free". Free here meant *libre*, not "free of charge", which is not necessarily true of FSF-defined free software. For example, I can release GPL'd binaries and sell them to you, then charge you (a reasonable amount of) money to receive the source code on a CD. The OSI movement was founded to promote licenses that allow corporations to use and modify open-source code without releasing the source code the their applications themselves.
`"AOP".expand_abbreviation() == ` ["Aspect-oriented programming"](http://en.wikipedia.org/wiki/Aspect-oriented_programming)
I think the applicability is with regards to the language having a concept of r-values.
Ok, sorry it took me so long, but I guess I finally understand what you want. If the types you're interested in are in the docs, you can use [that](https://gist.github.com/soli/300a8627a20ed9af8ade) It's very crude but basically scrapes the first &lt;pre&gt; of the corresponding page of the docs… Could probably be more general but works for full paths: &gt; rustdef std::result::Result pub enum Result&lt;T, E&gt; { Ok(T), Err(E), } &gt; rustdef std::comm::channel pub fn channel&lt;T: Send&gt;() -&gt; (Sender&lt;T&gt;, Receiver&lt;T&gt;) 
I think that an AOP implementation would require a preprocessor, because rust macros cannot change code that haven't "called" them. In any event, I have yet to see a good use case for AOP besides trace logging - which can easily be done with a debugger or even an instrumented LLVM.
It's definitely possible via macros / syntax extensions to some extent. For example, take a look at the [LibHoare](https://github.com/nick29581/libhoare) library. Blog post [here](http://featherweightmusings.blogspot.com/2014/07/libhoare-pre-and-postconditions-in-rust.html).
What would the advantage of a macro based system be over the pattern Lisp, Ruby, Python, Haskell etc use, which is just wrapping the concerns in another function that implements the cross-cutting functionality? Is there any literature, other than people trying to sell things, showing what the AoP ~~hacks~~ implementations in language like Java provide over using a HoF? I tried google but I'm probably not using the right search terms. Edit: found something. Seems like monads are required for the [complete solution](http://soft.vub.ac.be/Publications/1997/vub-prog-tr-97-10.pdf). Also, attribute grammars seem to be the related field of research for functional languages.
&gt; initializer lists What's wrong with initializer lists? Rust has just `vec!`, which is awful in comparison.
Please, no AOP. It is the cause of much "magic" in the Java ecosystem. Keep it simple.
To be fair it's only "magic" in the Java ecosystem because they hacked it on as a bytecode post processor. It's possible to express it within a language (My opinion has softened a bit since my first reply to this thread) but it stops being a paradigm and is just another part of your code structure. It's another pattern that's only really of note in languages that aren't expressive enough to do it natively.
I hope you are right. It is just very complex once you have objects that get hacked to do totally unexpected things using AOP. Things appear out of the blue and you have no clue where they came from. Sometimes too much power is not a good thing. 
Oh yeh, I agree, I think it does as much harm as good when it's hacked on to a language that isn't capable of supporting it.
Are you interested in struct decorator attributes in general, or the usage of `#[vertex_format]` in gfx-rs? Might be helpful to look at the original PR: https://github.com/gfx-rs/gfx-rs/pull/122
We debated naming for so long. [Here's the discussion.](https://github.com/rust-lang/rfcs/pull/60) I don't really want to revisit it.
Understandable confusion, but /r/rust is for the Rust programming language. /r/playrust is for the game Rust.
oops my bad, But thank you! 
The "obvious" solution is blocked on a compiler bug. Working on it :)
You never made ret mutable. I don't know if that's your issue but that did jump out right away. :x
To paraphrase something I read a while back because I can't remember it verbatim: In other languages, you spend most of your time reading stack traces and working a debugger. In Rust, you spend most of your time arguing with the compiler.
I just copy pasted this to the playpen (http://play.rust-lang.org/) and it worked fine after replacing `println` with `println!`, even after uncommenting `print!("");`.
You got the clobber wrong. It's supposed to be just `"rax"`, not `"%rax"`.
In `DrawLink::new` in line 109 you create a reference to `link.r` which is a short-lived function-local thing. Then, you transmute this reference into something else wich is probably stored somewhere else. Unfortunately, the lifetime information of `link.t` gets lost on this way. After the function `DrawLink::new` is finished, `link.t` (the memory location in the stack frame) does not exist anymore. If you later try to tramsmute it back to a mutable reference to a mutable reference, it will actually be a dangling/illegal one, possibly pointing into nirvana or into some other function's stackframe. The compiler could not help you avoid this lifetime error because you transmuted the lifetime information away. Unfortunately, I can't give you a tip on how to do this binding. I don't know enough about Box2D in terms of who owns what and what should be considered borrowed. But this is the first thing I would try to think about if I were you: Get the ownership/borrowing relations sorted out and then make it fit with some potentially ugly code. Watch out for lifetime errors while transmuting references. As far as I know references of type `&amp;Trait` where `Trait` is a trait instead of a concrete type are fat pointers (a pair of pointers, one pointing to your data structure and another one pointing to some vtable). I don't know if you should be trying to transmute them into some other raw pointer pair. It seems to me that it would work, but is horribly ugly because it assumes a lot about the current Rust implementation. Instead you might get away with static typing. So, instead of dealing with abstract/dynamically-sized types, just could write some generics and create different wrappers for different shapes. If you need this runtime polymorphism on the Rust side, I guess you're back to an extra level of indirection (what you tried to do already, but failed because of the lifetime error). Maybe you could solve the lifetime error with a box. So, instead of referring to a stack-allocated reference you could refer to a heap-allocated reference -- just to get around having to transmute a fat pointer.
The polymorphism is here to permit the user to specify how the drawing should be done, so I don't think that I can get rid of it, maybe with some trick. However I think that using a `Box` is a nice idea, I'll try that soon and hope it'll work. Thanks !
You mean using globals?
Nice hack!
pczarn posted this in an RFC thread and I find it interesting. Since last time I posted this libsync has been moved under std and libunicode has been factored out.
you truely solved my problem.Thanks :-)
What does the `extern "rust-call"` do? 
But how do the two times compare? Which one is longer?
Hopefully we can have something like that for Rust! It looks quite promising! Made to be callable by editors to get general info about the program, cool!
Hmm, but traits aren't inherited, so you still have to repeat all member function.
I think working out compilation errors is faster than debugging in most cases, but that's not the point I was trying to make. Catching as many mistakes as possible during compilation is a good thing, because it's much more explicit. The compiler can tell you right where the problem is, though it's very limited in helping you fix it. A debugger won't spot discrepancies for you. A stack trace only says so much. Bug reports from even well meaning users are hopelessly vague and often difficult to reproduce. Rust lets you nip problems in the bud.
&gt; Abstraction is a very useful tool, and when presented the way it is in ? C++ should never be a bad thing. Even in an operating system kernel, std::vector should be a win over manually managing arrays almost all the time. There is so much wrong with this that it makes me angry knowing that someone spent effort writing something they know absolutely nothing about.
Since the FQA is wrong in all the details and there basically isn't a single paragraph that presents a realistic and truthful argument, isn't it fair to conclude that the author doesn't understand C++? Is that ad-hominem? The alternative is that the author would know better, but intentionally attempts to mislead his readers. That's hardly better. But it doesn't really matter what the reasons are. The bottom line is that the FQA is worthless since it *always* says for every single point, that the "official" answer is bad and nonsense. No matter what topic, no matter the facts. If the facts are at odds with the rant, that FQA always chooses more rant. And if there is a n issue that might have some legitimacy, then it takes it and pushes it so far that it loses all connection to reality.
And that the rust docs [link](http://doc.rust-lang.org/complement-design-faq.html#there-is-no-life-before-or-after-main-%28no-static-ctors/dtors%29) to the FQA as some kind of reference will make C++ programmers wonder if the people who wrote the docs really know what they are talking about.
I disagree, it's magic from its initial concept in research papers from IBM (at least the first I read about it, well over a decade ago). Aspects were supposed to be cross-cutting code that handled orthogonal issues without appearing into each separate concerned code. The problem is, it's not obvious from the code where or when these concerns apply, they get spread out in different files and the same code will result in different behaviour seemingly for no reason (there is a reason, but multiple layers of indirection contribute to make it obscure). I would consider signing up for a fund to keep Aspects away from core Rust...
Well, as mentioned elsewhere, if you want something deep, you have **racer**, which is written in rust, and provides `find_definition` (or something like that). But for a quick reddit hack, bash seemed fin :P (I'd have used zsh if it were for me).
In theory it's just abstracting out shared behaviour into a separate unit, which in most use cases is just a higher order function, which are awesome. If you have a type system like rust's where you can trivially encode the extra information about the cross-cutting concern in the type itself (phantom types are awesome for this kind of thing) then you can statically guarantee that the concerns are applied everywhere they are required. Of course in a language with with a sufficiently powerful type system you don't notice this as "aspect oriented programming", it's just "programming". There are presumably some instances (trace logging potentially?) where you may need higher kinded types to get a fully generic implementation, but it's still "just code" unlike the hacks that are required to express the same thing in a weak language. AoP in something like Java where it has to be hacked is as unpleasant and obfuscatory as you say.
I actually working on a project that will include a VM written in rust. Its just a hobby project but i am hopeing to develop a jit as well. I developed my own bytecode and a compiler to get from clojure to that bytecode. See: https://github.com/clojit
Yes, A &amp;rarr; B is "A has an `extern crate B`".
Rust is a systems programming language. Scraping text out of web pages is not it's sweet spot. There are more appropriate languages for that.
(Not quite on topic, but...) FWIW, if you are actually wanting performance while generating random numbers, there's a variety of ways one can speed it up from the naive code; the first and biggest will be compiling with optimisations via `-O` or even `--opt-level=3` (via `cargo build --release` if you're using cargo: I believe this may output binaries to `target/release/` so be sure to check in there). Also, avoid calling [`random`](http://doc.rust-lang.org/std/rand/fn.random.html) repeatedly, since this does a relatively heavy-weight look up into [task local data](http://doc.rust-lang.org/std/local_data/index.html). It is better to cache this look-up by calling and saving [`task_rng`](http://doc.rust-lang.org/std/rand/fn.task_rng.html), which isn't really written down anywhere ([filed this doc failure as #16072](https://github.com/rust-lang/rust/issues/16072)). The following [benchmark](http://doc.rust-lang.org/master/guide-testing.html#microbenchmarking) shows some others (results first due to the size of the code): test a_random ... bench: 1150266 ns/iter (+/- 135201) test b_taskrng ... bench: 568055 ns/iter (+/- 209331) test c_isaac ... bench: 151234 ns/iter (+/- 18947) test d_xorshift ... bench: 59821 ns/iter (+/- 17401) i.e. using an ISAAC generator directly is ~8&amp;times; faster than using `random`, and xorshift is ~20&amp;times; faster (at the cost of some statistical properties/lower "randomness"). #![feature(macro_rules)] extern crate test; use std::rand::{mod, Rng, Isaac64Rng, XorShiftRng}; static COUNT: uint = 10_000; // a macro that creates the benchmark functions by inserting the // $initialiser statement before the loop (to allow creation of RNGs // etc), and using the $generate expression to create each one. The // `$(...)*` syntax is for repeats, to allow multiple benchmarks to be // defined at once. macro_rules! benchmarks { ($( fn $name: ident { $initialiser: stmt; $generate: expr } )* ) =&gt; { $( #[bench] fn $name(b: &amp;mut test::Bencher) { b.iter(|| { let mut m = 0u; $initialiser; for _ in range(0u, COUNT) { let x = $generate; let y = $generate; if (x*x + y*y) &lt; 1.0 { m += 1; } } 4.0 * m as f32 / COUNT as f32 }) } )* } } benchmarks! { fn a_random { // no initialisation required. let _ = (); rand::random::&lt;f32&gt;() } fn b_taskrng { // save the task_rng to avoid the look-up inside `random` each // time. let mut rng = rand::task_rng(); rng.gen::&lt;f32&gt;() } fn c_isaac { // create a randomly seeded RNG, without the additional // overhead the task_rng adds to try to ensure good // security/behaviour. let mut rng: Isaac64Rng = rand::random(); rng.gen::&lt;f32&gt;() } fn d_xorshift { // use a faster RNG, which has weaker randomness properties // (ISAAC is described as cryptographically secure, xorshift // is certainly not). let mut rng: XorShiftRng = rand::random(); rng.gen::&lt;f32&gt;() } } (Compiled with `-O --test`.)
Dragonfly is just a BSD flavor though correct? It should run on BSD variants as well?
well it already runs on OSX...
BSDs aren't different flavours of one OS. They are separate systems with some smilarities but different aims and development philosophies. DragonFly was a fork of FreeBSD, but slowly drifted apart. This port of rust might however make it easier to port it to the other BSDs.
There are a lot of issues here. The most important one is that you must not violate the "Rust rules" with respect to borrowing, aliasing, freezing, validity of pointers. For example, if you try to give some C code access to some Rust data structure, it should be considered borrowed during the whole time. And if the compiler is not able to track this (which it most certainly is not, since you probably pass raw pointers to some C function), you yourself as a Box2D binding provider have to make that users cannot invoke memory safety bugs. You do this by providing an interface that is safe. There are some ways to approach this depending on how one is supposed to use the Box2D library. For example, you could work with closures to ensure lifetimes and to maintain borrows: extern crate libc; use libc::c_void; /// represents a fat pointer to some object of unknown dynamic type /// so that it can be stored somewhere in C code and later be turned /// back struct FatRefForC { raw1: *const c_void, raw2: *const c_void, } /// example trait trait Abstract { fn foo(&amp;self); } /// this takes a borrowed pointer to some abstract object /// and invokes a closure with its representation so you /// can pass it to C code fn abstract_to_c&lt;U&gt;(r: &amp;Abstract, func: |FatRefForC|-&gt;U) -&gt; U { let fr: FatRefForC = unsafe { std::mem::transmute(r) }; func(fr) } struct Foo { value: int } impl Abstract for Foo { fn foo(&amp;self) { println!("Foo says {}.", self.value); } } /// Think of this as a function that gets called by C or C++ code unsafe fn part_of_your_c_callback(raw1: *const c_void, raw2: *const c_void) { let fr = FatRefForC { raw1: raw1, raw2: raw2 }; let br: &amp;Abstract = unsafe { std::mem::transmute(fr) }; br.foo(); } fn main() { let f = Foo { value: 23 }; abstract_to_c(&amp;f as &amp;Abstract, |fatref|{ println!("representation of the fat reference: ({},{})", fatref.raw1, fatref.raw2); // This can be passed to some C code along with a pointer to // part_of_your_c_callback. Let's simulate it here: unsafe { part_of_your_c_callback(fatref.raw1, fatref.raw2); } }); // At this time, the C/C++ is not allowed to have any handle to f anymore // becase it's not considered borrowed anymore by the Rust compiler. } This should be safe. But it may not work for you. If it does not work for you, meaning: you can't use the Box2D library like that and you have to resort to dynamic checking of borrows then you should look into `RefCell` I guess. But this only solves the borrowing/freezing problem, not the lifetime/dangling pointer problem. If Box2D stores pointers to some Rust datastructures (indirectly via your C++ glue classes) and you can't wrap it like above then you're close to fucked I guess. Getting this right is somewhere between difficult and impossible depending on the design of Box2D. Be warned. Unless you explain much more about how you think Box2D and other Rust code should interact with respect to ownership and borrows, I think I've said all I can say on this subject.
The different BSD's diverge a lot more than linux distros do in terms of core OS features.
BSD's aren't necessarily *flavors* of the same core kernel like Linux. On Linux 99% of the time your building with the GCC, using the glibc, using the Linux Kernel. This isn't always true on BSD. FreeBSD, OSX, DragonFlyBSD all have different kernels (FreeBSD has its own kernel, OSX has darwin). The packages built on top attempt to use standardized POSIX interfaces, which Linux also *offers*. But often times compilers and programs will attempt to use un-standardized interfaces that are only available locally to improve performance. 
It looks like line noise. Static typed line noise.
&gt;&gt;that approach would lead to to doubling the number of numeric types If the operator overloading is powerful enough, thats library not language; I think the namespacing could manage it? - if you have a preference against one being default, you could demand people specify a `use num::unchecked::*` vs `use num::checked::*` to select. &gt;&gt; My guess would be that this either needs to be ... a language feature. coming from C++ of course what I've seen is the language feature of powerful overloading, able to implement dimension-checked numeric types for example. Once you have that can implement whatever you need... For my use cases the correct approach is debug vs release build... throw all sorts of checks and asserts in the debug build, to ensure your code generates no errors *by design*. Then the release build runs as fast as possible, with no runtime cost for error checks.. anywhere. I've never personally overloaded float, but we had a use case where 'bool' was worth doing (some quirky behaviour on a console and ways of avoiding branches). But vecmaths was always custom types so you always had somewhere convenient to throw debug assertions in. 
The problem, IMO, is not the definition of shared behaviour as a separate unit/concern/aspect, it's the fact that the application of such behaviour is not visible using tooling (with existing tools), and hard to see even by people that know the code, once you hit a certain level of complexity. I would be ok with something like AOP if it was driven by annotations in the affected code. As a matter of fact, the attribute macros are pretty close to that goal already. 
`Latest commit by over 44 years ago` What's happening! lol
I like it. :)
This library is maintained by ccgn and nwin which has done most of the work themselves. At the moment it contains 8192 lines of code! We will release a 0.1 version soon. Feedback is appreciated! For usage, see README.md and the examples. Online docs is here http://www.piston.rs/docs/rust-image/image/index.html Feel free to open issues. 
&gt; The OSI movement was founded to promote licenses that allow corporations to use and modify open-source code without releasing the source code the their applications themselves. Not sure where you get this idea from. The OSI's definition of 'open source software' is based on the Debian Project's definition of 'free software', which itself is almost identical (in practical terms) to the Free Software Foundation's definition of 'free software'. I'm not aware of any licences that are considered 'open source' but not 'free' or vice versa; it's simply a matter of whether there's a focus on (purported) ethical superiority or (purported) technical superiority. There *are* licences that allow corporations (and individuals and any other groups) to use and modify the code without releasing their changes, i.e., non-copyleft licences like BSD. The FSF also considers these to be free. I'm not aware that the OSI promotes non-copyleft licences more strongly than copyleft licences.
I tried to talk mostly about the language, and then quickly about some projects in the end. They were really interested!
I saw Piston mentioned in there. Thanks!
Piston really interests me as a hobby game dev, and I wish I had free time to help write some code for it! Maybe I will, as this is my last week at my internship. (conflicting happiness and sadness!)
What about Rust looks like line noise to you?
Things like impl&lt;'a, T&gt; ImmutableVector&lt;'a, T&gt; for &amp;'a [T] { are visually pretty noisy.
There seem to be valid uses of iterators through trait objects to me. If you want to define a trait that should allow iteration over its elements: trait Iterable&lt;T&gt; { fn iter() -&gt; Box&lt;Iterator&lt;T&gt;&gt;; } ..and as Box&lt;Iterator&lt;T&gt;&gt; doesn't implement Iterator&lt;T&gt;, you end up having to wrap it: struct BoxedIterator&lt;T&gt; { iter : Box&lt;Iterator&lt;T&gt;&gt; } impl&lt;T&gt; Iterator&lt;T&gt; for BoxedIterator&lt;T&gt; { .. } I don't see how else you would be able to implement an Iterable&lt;T&gt; trait, without restricting the implementing types to share the same implementing type for the Iterator. 
44 years ago was 1970, or 0 in epoch time
Hence the RFC for removal of `'`. impl&lt;a, T&gt; ImmutableVector&lt;a, T&gt; for &amp;a T Or: impl&lt;a, T&gt; ImmutableVector&lt;a, T&gt; for a &amp;T Edit: I'm informed that further approved extensions to lifetime elision will make this `impl&lt;T&gt; ImmutableVector&lt;T&gt; for &amp;T`.
Which trades syntactic clarity for potential ambiguity.
It's completely unambiguous to the compiler.
So is machine code. Heck, so is the `'` that you're proposing to remove. It's the human reader that matters.
And the human reader can use case.
Do you have any ambitions to get this into Servo? Servo needs pure-Rust image processing and I believe are still using rust-stb-image.
&gt; I'm informed that further approved extensions to lifetime elision will make this impl&lt;T&gt; ImmutableVector&lt;T&gt; for &amp;T. Oh, that's actually great.
I'm surprised TaskRng is so much slower than ISAAC.
Wrong subreddit. You are probably looking for http://www.reddit.com/r/playrust
They *are* planning on getting rid of the `"string".to_string()` non-sense...right? I understand there's some logical reason for it, but it just looks absurd to an outsider.
This is great! I was planning on doing a talk about Rust at my company in the near future, so I will probably take some inspiration from this :)
"They" have no current plans for it (and, fwiw, it's nice to not use 'they' here, since they (the core team etc.) often read reddit). `to_string` is not nonsense, and definitely not just some random abstract hypothetical reason: e.g., there's a large semantic difference between the types `&amp;str` and `String`; and, every `.to_string` call is an allocation and byte copy, overuse of them can easily crush an application's performance, having them implicit would be worse. (The `.as_slice` calls for viewing a `String` via an `&amp;str` are less necessary.)
The task RNG is reseeding itself with 2 KB of randomness (from the OS, e.g. opening and `read`ing `/dev/urandom`) for every [30KB](https://github.com/rust-lang/rust/blob/5ebf4813a6503d5312f457b8a6ba7b6998a45f2b/src/libstd/rand/mod.rs#L173) it generates; maybe we can bump up that threshold, but... it's common advice to use the OS for randomness as much as possible and increasing the threshold is going in the wrong direction.
&gt; Forces the evaluation of the thunk so subsequent accesses are cheap. The value is heap allocated. Why heap allocated? (i.e. why can't the `Inner` type just be stored unboxed?) Also, given there's a lot of `unsafe`: - Does `let t = Thunk::&lt;Box&lt;int&gt;&gt;::new(proc() fail!()); t.force();` avoid crashing horribly? - I think this should possibly be using [`UnsafeCell`](http://doc.rust-lang.org/master/std/cell/struct.UnsafeCell.html) (formerly `Unsafe`) internally, due the internal mutability.
Have you ever tried to debug a program with a leak or memory access error? Preventing even one pathological bug is enough to make up for the cumulative compilation errors for the rest of the software's lifecycle.
I'm amazed there are so many earning FOTT, so many great contributors.
Inner has to be stored behind *mut, which I get by casting Box&lt;Inner&lt;T&gt;&gt; to *mut Inner&lt;T&gt;, which makes T heap allocated as Inner&lt;T&gt; is heap allocated. I didn't know about UnsafeCell, but it looks promising. I think I'd replace *mut Inner&lt;T&gt; with UnsafeCell&lt;Inner&lt;T&gt;&gt; and just get *mut Inner&lt;T&gt; from that, meaning I don't have to heap allocate the final value. I have no idea if `let t = lazy!(fail!()); t.force()` crashes horribly. I'd appreciate a more experienced eye. EDIT: Running under valgrind, `let t: Thunk&lt;Box&lt;int&gt;&gt; = lazy!(fail!()); t.force()` does not leak or crash horribly. EDIT2: In case it isn't clear, the unsafe is almost entirely there to accomplish two things: 1. Get a &amp;'a T while having interior mutability without using RefCell because RefCell does not give you &amp;'a T. 2. Call the stored proc() safely through a &amp;-reference, which is supposed to be very hard/impossible. EDIT3: Ported to UnsafeCell. Values are now stored unboxed and with minimal memory overhead. I believe a fully evaluated thunk has a single enum tag in memory overhead, i.e. u8 + T.
So, I didn't understand every bit of your example, but now I directly pass to the C code the fat pointer to the Trait instead of a pointer to the fat pointer and it works fine, maybe you could look at the new code, to see if it's really safe. The only thing that may be a problem is that the "callback trait" is borrowed while it is held by the ``World`` ([starting from here](https://gitlab.com/Bastacyclop/rust_box2d/blob/c81344beb5bf5a69df1c9283512e54c91f31dde2/src/dynamics/mod.rs#L75)) while it should only be borrowed when used by the ``World``, Using a ``RefCell`` might be the solution, but I believe the only moment where the "callback trait" should be borrowed is when ``World.draw_debug_data()`` ([here](https://gitlab.com/Bastacyclop/rust_box2d/blob/c81344beb5bf5a69df1c9283512e54c91f31dde2/src/dynamics/mod.rs#L134)) is called, though i'm not entirely sure. Should I require a borrow at this time and an unsafe pointer in ``World.set_debug_draw()`` ? I could also remove ``set_debug_draw()`` and merge it with ``draw_debug_data()``. Or is it beter to use a ``RefCell`` ? You can see an example of use [here](https://gitlab.com/Bastacyclop/rust_box2d_testbed/blob/182a1a5a5029faaf71362fe988093db3dfaaf141/src/testbed.rs), I'm currently using unsafe pointers to use the borrowed callback but I want to get rid of them. Thanks for your help so far. __EDIT__: I removed ``World.set_debug_draw()``, moving the borrows to ``World.draw_debug_data()``, I believe there are no problems anymore (if I miss nothing).
Walks through walls, cheats. Acts like a baby when caught in the act. 
I often wonder if the rust team has ever considered the strategy of using lazy evaluation by default. I wonder myself if lazy is that good in so many cases, that could be even convenient to force the programmer to specify when you want a non-lazy expression and not the other way around.
An `Iterable` trait that doesn't return a type known at compile time is almost entirely useless. The anonymous return types RFC solves this, for trait methods it acts like an associated type. Until then, one could make `Iterable` generic over the element and iterator types, though that doesn't work that well with inference.
When I see "lazy evaluation" it is usually in the context of sequences. e.g. in many languages I can define a function that returns an infinite sequence of Fibonacci numbers (in most of those languages it's only "infinite" until the integers overflow, but anyway...) but the function will only compute the *n*th number when I take *n* items from the sequence. e.g. `yield return` [in c#](http://msdn.microsoft.com/en-GB/library/9k7k7cf0.aspx). Is there anything like that in rust?
[Some functional languages are lazy by default](http://mitpress.mit.edu/books/lazy-functional-languages). Using lazy constructs is a performance loss if the underlying value is always accessed. It is a performance gain if the value is only sometimes accessed. 
[`Iterator`](http://doc.rust-lang.org/master/std/iter/trait.Iterator.html)s, although it currently requires "manual" implementations, [there's no `yield` construct](https://github.com/rust-lang/rust/issues/7746) (yet). That said, the fibonacci example (and others) can use build-in wrappers: std::iter:Unfold::new((0u64, 1u64), |&amp;(ref mut a, ref mut b)| { let old = std::mem::replace(a, *b); *b += old; Some(old) })
Rust's big feature is memory safety without garbage collection. This is valuable because it makes performance more predictable. In general Rust is designed for predictable performance, eg. explicit heap vs. stack allocation. Lazy evaluation by default makes it harder to reason about performance, so I think it's opposed to the goals of Rust. Opt-in lazy evaluation could be useful.
All true. Still, I wish for a less verbose way of expressing things. I know that implicit conversions are frowned upon by many Rusticeans but they have their value especially if they're almost for free. In this case I'm not talking about `to_string` because I know that it's expensive. But I do wonder whether it's worth giving a type like `std::str::MaybeOwned&lt;'static&gt;` a little more love. For example, this could be nice: /// maybe-owned string with static lifetime parameter type Mos = std::str::MaybeOwned&lt;'static&gt;; fn fizzbuzz(i: int) -&gt; Mos { match (i % 3, i % 5) { (0,0) =&gt; "FizzBuzz", // implicit conversion (0,_) =&gt; "Fizz", // " (_,0) =&gt; "Buzz", // " (_,_) =&gt; i.to_string() // implicit consuming conversion into Mos } } I guess it depends on how much of a hassle the use of a MaybeOwned type is. I don't have much experience with it. But I don't think it would hurt having the compiler call into_maybe_owned automatically especially since it's almost for free w.r.t. performance.
For reference, here's the source code to make your own: [dependency tree Gist](https://gist.github.com/pczarn/19ee08f2995f2b84231d). 
It is broken. (Although I was thinking the wrong thing originally, it's not going to crash/be unsafe because of the value that the `Thunk` contains, but because of the values that the constructor `proc` captures.) extern crate lazy; struct Dropper { x: String } impl Drop for Dropper { fn drop(&amp;mut self) { println!("dropping... {}", self.x); } } fn main() { let value = Dropper { x: "hello".to_string() }; let t = lazy::Thunk::&lt;()&gt;::new(proc() { // this has to be a reference (just to ensure that `x` is captured by // the `proc`, or else move-zeroing papers over the problem. let _y = &amp;value; fail!() }); t.force(); } prints task '&lt;main&gt;' failed at 'explicit failure', crash.rs:16 dropping... hello dropping... hello i.e. the destructor of `value` is running twice. `value` is captured by-value into the `proc` environment, and the `copy_nonoverlapping_memory` causes the `proc` to be duplicated in memory (once in the stack frame of `force` and once inside the `Inner` object); when it fails, destructors are run on these two "separate" `proc` instances, causing the contents to be dropped twice, as the above output shows. (I filed [a bug](https://github.com/reem/rust-lazy/issues/1). :) ) You need to be super, super careful about duplicating values. One fix would be changing to `Inner { EvaluationInProgress, Evaluated(T), Unevaluated(proc() -&gt; T) }`, and then do something like match *self.inner.get() { Evaluated(_) =&gt; { return } EvaluationInProgress =&gt; { /* handle this case... fail? */ } Unevaluated(_) =&gt; {} } match ptr::replace(*self.inner.get(), EvaluationInProgress) { Unevaluated(f) =&gt; *self.inner.get() = Evaluated(f()), Evaluated(_) | EvaluationInProgress =&gt; unreachable!() } The first `EvaluationInProgress` case needs to be handled properly, which can theoretically be triggered if the `Thunk` is stored in a shared location with access to itself (i.e. if `force` can be called recursively), like `Rc&lt;RefCell&lt;Option&lt;Thunk&lt;...&gt;&gt;&gt;&gt;`. I think this is currently a point where current code is also broken (with or without failure in the language), but I can't trigger it right now since I'm having trouble convincing the compiler to let a `proc` capture a `Thunk` due to the `'static` restriction (maybe in the morning). In any case, with unboxed closures, you will need to be explicitly careful about this situation (since closures will not have their `'static` restruction; although, [#16068](https://github.com/rust-lang/rust/pull/16068) makes steps in a similar direction). *update*: I used a bit of `unsafe` code to demonstrate what happens when a `Thunk` can refer to itself during construction: extern crate lazy; use lazy::Thunk; use std::rc::Rc; use std::cell::{Cell, RefCell}; static N: uint = 10; struct Dropper { x: String } impl Drop for Dropper { fn drop(&amp;mut self) { println!("dropping... {}", self.x); } } fn main() { let value = Dropper { x: "hello".to_string() }; let counter = Rc::new(Cell::new(0u)); // initialise this, and put the thunk in later let x = Rc::new(RefCell::new(None)); // unsafely simulate a thunk referring to itself (by converting a // handle to a type that can be captured). let y: uint = unsafe { std::mem::transmute(x.clone()) }; *x.borrow_mut() = Some(Thunk::new(proc() { // again, force it to be captured. let _ = &amp;value; // avoid infinite recursion if counter.get() &lt; N { counter.set(counter.get() + 1); // reverse the conversion, to be able to interact with the // Thunk (this Thunk, in fact) let z: Rc&lt;RefCell&lt;Option&lt;Thunk&lt;()&gt;&gt;&gt;&gt; = unsafe { std::mem::transmute(y) }; match *z.borrow() { Some(ref t) =&gt; t.force(), None =&gt; {} } } () })); match *x.borrow() { Some(ref t) =&gt; t.force(), None =&gt; {} } } Output: dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello dropping... hello Whoops! There's one instance of `Dropper`, so there should be exactly one run of the destructor. (Changing `N` changes the number of drops; each drop corresponds to a `proc` value, either the original one inside the `Thunk`, or the ones that have been unsafely/incorrectly duplicated on to the stack inside `force`.) &gt; Call the stored proc() safely through a &amp;-reference, which is supposed to be very hard/impossible. I think you may now agree that there's a very good reason for this. ;) --- BTW, I highly recommend you try to use functions like `ptr::{read, write, replace}` as much as possible, rather than manual `forget`, `uninitialized` and `copy_*_memory`s, e.g. your current code could be written as let func = match *self.inner.get() { // everything is done Evaluated(_) =&gt; return, Unevaluated(ref producer) =&gt; ptr::read(producer), }; ptr::write(self.inner.get(), Evaluated(func())); This sort of code has the advantage of doing smaller/fewer copies (i.e. if `T` is huge, the original code is possibly copying the whole `Inner` value, even though it only needs the two words from the `proc` when unevaluated, and needs literally none of the data when it has already been evaluated), and also of being simpler and so easier to verify. E.g. I feel it is more obvious from this code that `func` value is duplicated inside `self` and on the stack. At least, that's what the `ptr::read` function should strongly suggest to you.
Would love to read more about the Send/Share ideas as well as the by-variable capturing stuff.
Was that for professional reasons?
I appreciate this response. Sorry for not making my point especially clear. I didn't really cite anything last time; I'll try to substantiate my claims a bit more here. &gt; I'm not aware of any licences that are considered 'open source' but not 'free' [...]. [Here's a list of open-source licenses that are nonfree](https://www.gnu.org/licenses/license-list.html#NonFreeSoftwareLicenses). They're part of what I was thinking of when I said that - "well, this movement seems to advocate giving away the source code to programs, while not maintaining the central point of being free software". I can't link to individual subheadings, but [here's another point](https://www.gnu.org/philosophy/open-source-misses-the-point.html) I was trying to convey: &gt; Second, and more important, many products containing computers (including many Android devices) come with executable programs that correspond to free software source code, but the devices do not allow the user to install modified versions of those executables; only one special company has the power to modify them. We call these devices “tyrants”, and the practice is called “tivoization” after the product where we first saw it. These executables are not free software even though their source code is free software. The criteria for open source do not recognize this issue; they are concerned solely with the licensing of the source code. The language is a bit dumb (tivoized? tyrants? really?) but I think the change-of-values embodied in open-source software is specifically targeted at enabling this kind of behavior. This is a more political statement than the strictly technical question of "are open-source licenses free?" which is, as you said, fairly often true (but not always!). Yes, the "loophole" exists in some free software licenses where you can create modified executables using free software and give them away without releasing the source. Thus these executables are nonfree, while the original code or license is free. Since I believe that part of the point of free software (as a movement, not an individual license) is maintaining that free software will remain free, I see this as a weakening of the goals of free software. Open-source software doesn't have those goals. It's much more about giving the code away, but not even necessarily the freedom to use it. Quoting the FSF on [one of the licenses mentioned](https://www.gnu.org/licenses/license-list.html#SML): &gt; - You must get the licensor's permission before distributing the software. &gt; - You cannot sell copies of the software. &gt; - It's possible that your license can be terminated if you received the software from someone who did not obey the license's terms. Well, that certainly seems like "open-source" (they're giving the source code away) but there's definitely no interest in anyone's freedom besides that of the licensor. I *do* believe that OSI's point is to make the idea of using software where the source code is available more palatable to corporations, because corporations care about their own values more than those of the user. Thus they advocate a superset of licenses over the FSF, and stop making political claims at the expense of the user's freedom. This isn't necessarily *horrible* (I think a lot of good has come of it, along with some of the bad seen above) but I really do think it's an accurate depiction of the two sides.
Have you read [the RFC](https://github.com/rust-lang/rfcs/pull/127) covering Send/Share?
What's the point of doing that? And why the virtual keyword? What's virtual about it? Seems like a bad choice especially since things like `&amp;a as &amp;Foo` don't work and adding a method for `Foo` is not callable on `a` or `b`. I don't get it. Someone please rationalize this. What's the point of this?
Reading a related thread on a C++ forum.. someone also suggested there that foo[index] could be specialised when its a constexpr , and actually do tuple access.. though i doubt Rust would accept that kind of 'special casing'
Yes. Using valgrind it's actually doable. But it wasn't a very complex program.
It's not at all in a final, featureful, production-ready state (hence the feature gate).
I don't see anything wrong with raising these questions. As it is now, the benefit of this partially-implemented feature is not apparent and I wasn't able to find a corresponding RFC nor anything in the rust-dev mailing archives that explains what this is about. But I thank you for pointing out its incompleteness. I thought I was missing something (hence my comment). I'm still interested in what is to gain from such a feature. Any takers?
I did. But I guess I have to read it again. Last time I did not understand what "unsafe traits" and the 3rd goal (bullet point 3 of summary) was about.
I could imagine that a lazy expression by default could be a soft guarantee. If the compiler checks that the expression is gonna be always accessed, it could be optimized out. Also, if the lazy expression would endanger a lifetime guarantee, it could be evaluated to avoid that. I'm agree that we lose predictability that way, but wouldn't be an option to make the programmer explicitly care about predictability when it is really necessary?
I think one of the reasons numpy is so successful is that it provides a slightly generalized version of the abstraction you mentioned [1]. Annotating a bit of memory with shape, type and strides is very powerful. [1] http://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html
My understanding is that it already does match C/C++ performance wise.
In many cases, yes. I'd caution that it's hard to make a blanket statement like this, however, especially since it's early days for the Rust compiler. There are many known cases in which we have work to do to reach the same performance as C++ (for example, just the other day, fibonacci). However, for many real-world use cases Rust will run just as fast as C++. I don't believe there are any substantial language-level issues that we don't plan to fix that will prevent us from reaching C++ level performance. Often-cited things like unwinding, zeroing out, and stack checks for green threads are going to be fixed.
Predictable performance is one of the primary reasons Rust exists. If you want to default to laziness and do work to opt in to predictability, you want Haskell.
I have no idea how to implement lazy-by-default in a non-garbage-collected language.
Are there any benchmarks/... measuring this or is equal performance just the goal that rust aims to achieve? The [language shootout](http://benchmarksgame.alioth.debian.org/u32/rust.php) only contains a hand full of rust programs and who knows if they are well optimized. Also, probably there are different kinds of problems where one language or the other is at a disadvantage. There are tradeoffs being made (like bounds checks), so for which kind of code is this expected to have performance implications? Is there some analysis of this somewhere?
I've taken a look at your project and I have to say it's quite impressive how much work you put into it. One thing I noticed is that your code seems to lack at least one `#[repr(C)]` to make a struct's layout C/C++ compatible. I think you need it for the `FatAny` struct since you pass this to some C++ functions by value. It probably worked without it because this representation is currently kind of standard in Rust AFAIK. But it may change in the future. I find it odd that I see no `extern "C"` in your C++ code. You are aware of the fact that the C++ compiler will mangle the name otherwise, right? The macros for creating wrapper types in `rust_box2d.rs` are interesting. What I find odd are the `from_ptr` functions in the `Wrapped...Base&lt;T&gt;` traits. Even for unsafe functions they seem pretty unsafe because they allow you to do something that's equivalent to an invalid downcast in a class hierarchy via `reinterpret_cast` in C++. Another thing that is even more puzzling is that you defined your wrappers with a lifetime parameter. It does not seem to make sense at least in the case of the `World` struct. I would have expected it to have no lifetime parameter because this struct is the _owner_ of the C++ allocated `b2World` object. And this struct can be considered an _owner_ because it is apparently responsible of releasing it in the destructor. So, you _own_ a `b2World`, you don't need a lifetime parameter for it. You only need a lifetime parameter for things you have _borrowed_ so that the compiler can help you avoid creating dangling references. But this is a distinction that seems to be missing in your wrapper macros. It seems to me that you need to know much more about Rust and its type system with respect to memory safety to be able to handle this kind of complicated library binding. Ask yourself for every object you like to refer to somehow: *Who* is supposed to own it? Who is responsible for freeing it? Much of everything else follows from that. For example, if you treat rigid bodies as being owned by the world as far as your API is concerned, then getting hold of such a rigid body would be a borrow of (part) of the world in which case this borrow should have a lifetime parameter that refers to the world. Internally, you can do all sorts of tricks and use unsafe code to call C++ functions. But the API has to be safe and this requires you to think about things like ownership and such. In case the world owning everything else in it, you can think of it as a container like `Vec`. The `Vec` type does not have a lifetime parameter. There is no need. An object of this type _owns_ all of its elements. And if a user of your API asks the world to get hold of some of its object, this should _freeze_ the world. This is needed to avoid memory safety issues. If you havn't checked out Niko's great talk about memory safety, I encourage you to [watch it](https://air.mozilla.org/guaranteeing-memory-safety-in-rust/). But maybe I have it all wrong and you know very well what you are doing and this `'l` lifetime has a legitimate purpose. It just does not feel like it to me right now with the limited amount of time I spent checking the code. HTH
What changes are planned for unwinding? Just generally making it faster?
- I'll add the ``#[recpr(C)]``s, I thought it was only necessary for enums - The ``Wrapped...Base&lt;T&gt;::from_ptr``s are using a specified function to make the conversion, in fact a ``static_cast`` from C. - I putted a lifetime parameter on every wrapper but I thought about making the difference, I shall fix that. - I know that I may not know enough about memory safety, but it's a learning exercise for me, I actually never did a binding before. Thanks for giving you opinion :)
I might stay up this evening to watch it - but it is awfully late - no chance of holding it an hour or two earlier for the European audience? Also - does one have to sign up to the site to watch the introduction? Or is it sufficient just to visit this webpage at the appointed time?
Type errors can be time consuming and difficult for beginners. But the key is the difficulty is capped... any professional will know how to resolve any type error the compiler throws. It's just a matter of time. On the other hand, you hear about how known memory leaks can go unresolved for years without any progress made on finding them in large software projects like Windows or Firefox.
how does it fare with inlining closures at the minute: does all the elegant functional style chaining and using closures with iterators optimise out to equivalent imperative code (e.g.: can you count on a 'map' taking a small closure compiling like an equivalent for loop in c/c++) 
Clean writeup. One thing I am wondering though, don't you need to take the `sqrt` of `(x*x + y*y)` to calculate the distance(hypotenuse)?
I don't care about compilation time, I want to know about runtime performance.
I'm sure they will post a recording somewhere. If they want Rust to catch on, Mozilla would be wise to make content like this available.
Closures will be static function calls.
Well, Haskell is a very different language and has dynamic memory management. I believe that lazyness by default and GC don't need to go together. I could be wrong, thought. I'm not attacking Rust, I love the concept of the language and I hope it becomes a standard in the industry, but I'm also curious.
There are many issues with lazy-evaluation by default, SPJ himself said that should he define Haskell today lazy-evaluation would be opt-in (and eager evaluation the default). From the top of my head, the worst issue is *space leak*, for example in Haskell summing the elements of a list risks creating as many thunks as there are elements in the list (and may even retain the list in memory itself) whereas with eager evaluation this would be O(1) and the list could be eagerly disposed off as well. Due to this tendency, it's better to be explicit about it, so as to call the developer's attention.
That's more a question of the compiler than the language itself. Language wise Rust should be able to match the performance of C++ for equivalent code.
I'm far from being a professional in compiler technology nor in programming language theory, but I believe that as long as you don't make a strong guarantee about the default-laziness, it should be possible. This means, the compiler could handle an expression as unevaluated until something forces it to evaluate it. In a non-garbage-collected language like rust, this 'something' could be a lifetime going out of scope, or a referenced mutable reference being modified.
I want to submit an RFC soon, but the short of it is that it should be fully disablable just like C++, in both libraries and executables. Disabling unwinding will be treated as essentially an optimization flag.
Sure, if the servo team is interested, that would be great. It would also be nice to get some input on how a good API to enable progressive rendering of interlaced images (yet unsupported) should look like.
Generally, yes. I am working on unboxed closures to make it even more likely to happen.
that doesn't make any less a valid concern for others. compilation time was actually one of the factors that inluenced go's design/development goals.
That's really interesting.
I implemented a program in each language to find the sum of all primes under 2 million, using the same data structures and algorithm. The results were: C++: 1.8 seconds. Rust: 3.2 seconds. Python: 34 seconds. So it's in the same league, but all the automatic checks do slow it down a bit. EDIT: I'll give details (incl. code) when I get off work in a couple hours. EDIT^(2): I found out that I was running the C++ code using a vector&lt;bool&gt; and the rust code with a Vec&lt;bool&gt;, so the C++ one had better cache efficiency. I rewrote the C++ one to use vector&lt;char&gt; and it dropped down to the 3 second time that rust had. [Timing results](http://pastebin.com/km4XXC5h). Compiled with clang -O3 and rustc --opt_level=3. And [code](https://gist.github.com/minno726/4c429f0f0c583e112585). cpp_solution_old is my original 1.8 sec solution, cpp_solution is the one with vector&lt;char&gt;, rust_solution is my transliteration of cpp_solution, and rust_idiomatic is the original one I benchmarked with.
Go instead of python would have better for your benchmark. And are you using idiomatic code style for each language ?
Remind me in about 5 hours. I can't post it right now from work.
A couple things I noticed: you don't have to import `String` it gets automatically imported by prelude. For getting a note, you're converting the arg from a `String` to a slice just to pass it into the `get_note` function, then converting back into a `String` in the function body. I don't see any reason you couldn't just move the `String` into the function, since it isn't used afterwards
Laziness is implemented by building dependency graphs out of dynamically allocated objects. Tracing garbage collection is pretty much a hard requirement for the kind of laziness in Haskell.
That's not going to turn out well without purity... your functions could be evaluated in any order. There's *already* no guarantee about ordering when it wouldn't cause an observable side effect.
sub-second compilation of large programs yields a development experience similar to that of usually interpreted languages like python and ruby: change code, run, see results. in case of c++, only really small programs behave this way. any non-trivial code base takes a couple of minutes at least to build and link.
Why do the benchmarks show Rust being much much slower than C++ then?
All that reorder is determined at compile time, right? As long as you can calculate the moment of evaluation of a lazy expression at compile time too, I think you are fine. I still don't see why wouldn't be implementable in a language like rust, with the same kind of static memory safety. This doesn't mean, that couldn't be a very bad idea for many other reasons, of course.
args[1] == String::from_str("post") should probably be args[1].as_slice() == "post" 
although he can do that, I'd rather leave as is so it could be more generic.
Usually this is only the case in benchmarks where micro optimizations are the greatest determinant of benchmark outcome. Often times, winning solutions are unsafe, unidiomatic, or inconsistent with a language's "real world" performance. There's also the issue of Rust's libraries not being as optimized as the mature languages it is put up against. For example: http://benchmarksgame.alioth.debian.org/u32/benchmark.php?test=regexdna&amp;lang=all&amp;data=u32 According to this, Javascript is a much faster language than C. When you compare benchmarks for practical use cases, you get a better idea of performance. Unfortunately, it's rare to come across those, especially with an immature language such as Rust. http://dwrensha.github.io/capnproto-rust/2014/01/15/benchmark-update.html This benchmark compares the C++ Cap'n Proto implementation to a Rust implementation. But at the end of the day, benchmarks will say whatever you want them to say. Creating a benchmark for a toy task isn't very useful for getting an idea of practical performance. It's simply a game. That being said, *unsafe* C/C++ will be faster than safe Rust. Optimized C/C++ libraries will be faster than unoptimized Rust libraries. 
In addition, one of the only reasons Haskell's garbage collector is efficient enough to allow Haskell to compare to C and C++ in performance is because of immutability by default. Because new references can only refer to old values, you can almost (I think?) perform the garbage collection step in one pass. The Haskell GC uses a lot of tricks that just won't work in a general language that uses mutable values.
Also, sometimes the benchmarks will really be `gcc` vs `llvm` benchmarks. I have noticed on some benchmarks that `llvm` doesn't perform as well as `gcc` and when you compile the c++ code with `clang` all of the sudden the rust and c++ code run at the same speed. Benchmarks are really just a complicated game.
I posted about this above, but what did you compile the c++ code with icc, gcc, msvs, or clang? I typically see icc and gcc out performing clang, but when c++ code is compiled with clang it runs at the same speed as rust since the both will use llvm then. (Also another thing to check is to make sure you compiled all the programs with the highest optimization levels)
Rust and Haskell have very different goals. For example, Haskell is largely a research language that happens to have active developers using it in production. Haskell seeks to test the boundaries of new ideas in compilers and functional languages, and has crazy, wacky concepts at the fore. (Like monads, functors, categories, and whatever a `prism` is. I'm still not sure about those.) I'll respond to a few things you said because, I think you are mistaken and I want to consolidate my replies to one single top-level reply. ###Laziness &gt; If the compiler checks that the expression is gonna be always accessed, it could be optimized out. This is just, in general, not possible to do for expressions. The strictness checker in Haskell for example, is not perfect, and can even induce problems by reducing sharing. Efficient Haskell programs often resort to explicit annotations of strictness and laziness to get around this. &gt; Also, if the lazy expression would endanger a lifetime guarantee, it could be evaluated to avoid that. The result, I suspect, would be that almost all laziness would be removed where it might be wanted. The result would just be less deterministic performance and confusion as to when laziness is actually invoked (the same situation as it in Haskell, I suppose, except much more likely to occur.) ###Garbage collection &gt; Well, Haskell is a very different language and has dynamic memory management. I believe that lazyness by default and GC don't need to go together. I could be wrong, thought. I'm not attacking Rust, I love the concept of the language and I hope it becomes a standard in the industry, but I'm also curious. Then, &gt; I'm far from being a professional in compiler technology nor in programming language theory, but I believe that as long as you don't make a strong guarantee about the default-laziness, it should be possible. This means, the compiler could handle an expression as unevaluated until something forces it to evaluate it. In a non-garbage-collected language like rust, this 'something' could be a lifetime going out of scope, or a referenced mutable reference being modified. And, &gt; All that reorder is determined at compile time, right? As long as you can calculate the moment of evaluation of a lazy expression at compile time too, I think you are fine. One of the only reasons Haskell's garbage collector is efficient enough to allow Haskell to compare to C and C++ in performance is because of immutability by default. Because new references can only refer to old values, you can almost (I think?) perform the garbage collection step in one pass. The Haskell GC uses a lot of tricks that just won't work in a general language that uses mutable values. Haskell doesn't rely on rewriting at compile time to determine the orderings of expressions. Rather, it relies on immutability. Without that immutability, performance of garbage collection goes out the window. And laziness really needs garbage collection to work well.
I'll recommend using `match` to parse the arguments, because the "program usage" patterns become clearer: use std::os; fn main() { match os::args().as_slice().tail() { [ref command, ref title, ref text] =&gt; if command.as_slice() == "post" { // Write note unimplemented!(); } else { fail!("{} is an unknown command", command); }, [ref title] =&gt; { // Get note unimplemented!(); }, args =&gt; { fail!("Unexpected combination of arguments: {}", args); } } }
Would this run `foo` or `bar` first? How do you deal with the fact that Rust is impure? let a = foo(); let b = bar(); let c = b + 2; print(c); print(a); 
Visit the page at the appointed time. It will be recorded, don't feel obligated to watch it live :)
Thanks for the input everyone! I also just found this guide for strings and it clears up a lot of my questions. http://doc.rust-lang.org/guide-strings.html
Checking that match statements catch all enum variants wouldn't work too well with that sort of enum inheritance. In some situations, you might be able to do something like this instead: enum NetworkStreamResult { StreamResult(StreamResult) NetworkStreamFailure } With associated types (or their temporary workaround, extra type arguments) you could let a particular impl's doSomething return its own enum type: trait Stream&lt;StreamResult&gt; { // ideally, this instead of the type arg: // type StreamResult fn doSomething() -&gt; StreamResult } impl Stream&lt;NetworkStreamResult&gt; for NetworkStream { // ideally, this instead of the type arg: // type StreamResult = NetworkStreamResult fn doSomething() -&gt; NetworkStreamResult { ... } } 
Is a good question. It will always depend of the nature of foo and bar, but you should be able to know this at compile time. We have some possibilities. 1. If *foo* have side-effects (deal with I/O, modify and read some common global state, or something like that), *foo* would have to run before *bar*. 2. If *foo* doesn't have side-effects, *print* surely will have, and because *print* needs to access *bar* before *foo*, *bar* will have to run first. 3. Because the compiler traces *a* and *b* in compile-time, it knows that they both will be accessed by following the given trace which has no branches. Therefore, the lazy expressions would be optimized out, and no memory space would be required to store the unevaluated expressions. I'm not sure what is the purity you are talking about in this context. If you mean that the compiler has no way to check if a function has absolutely 0 side-effect, I get your point, but it is hard to believe that the rust compiler can't do that internally.
Rust doesn't enforce purity, so it can't know any of those things. It doesn't know the difference between a function with a side effect and one without one. Keep in mind that *rustc is already an optimizing compiler* and LLVM does a good job inferring what it can without the low-level building blocks being corrected annotated with purity (along with everything else).
That does look a lot better! Pattern matching is one of my favorite language features and I'm glad it's a feature in Rust!
it doesn't matter what the issue is. faster source change to execution means tighter feedback to the developer, which in turn means saved time. i can't think of any development scenario where having a nonzero build time is beneficial compared to instantaneous build/not having to build at all.
Looks good, I agree with japaric about using match to parse arguments. Your current code will fail with `index out of bounds`if called without any arguments. Also check out [cargo](http://github.com/rust-lang/cargo), the Rust package manager / build system!
For a related question, how does it compare as far as memory usage?
I know that but I care! :)
For what it’s worth, I’ve made a pure Rust physics engine that uses almost the same algorithms as the Bullet 3d physics engine. Obviously, I tried to reproduce Bullet's demos to compare the performances. When I started nphysics a year ago, it was more than 8 times slower than Bullet Physics because floating point operations were not inlined yet (missing #[inline] statements on the standard library). As of today, for a simple stack of 512 boxes benchmark, nphysics is around 1.5-to-2 times as slow as Bullet for a comparable stability (both engine used the same number of iterations to compute contact forces). I did not even took the time to optimize nphysics very much while Bullet has some smart memory management and a hand-optimized SIMD-based LCP solver (this the part that will compute contact forces). Also my collision detection algorithm is very generic while Bullet uses a more optimal (in term of complexity), box-specific algorithm. So I am really convinced that the Rust compiler produces really fast programs, and will get even better in the future. I know this is not a microbenchmark, and that reproducing the exact same simulation with two physics engine is not possible. Though I think this gives a more concrete idea of Rust's performance.
I get it. I'm aware of the deduction of the readonly/readnone function attributes in LLVM. Why Rustc doesn't use it? Reducing complexity? EDIT: Mmm, I found this: http://thread.gmane.org/gmane.comp.lang.rust.devel/3674/focus=3855
&gt; fibonacci What does C++ have that rust doesn't? Memoization? Tail-call optimization?
Stack bounds checking hurts performance of Fibonacci. But it's fixable.
It's also a language question since the language might contain features that cannot be implemented without a performance penalty. The main question there is how often those language constructs will be used in which kinds of applications, and how significant the necessary performance penalty will be.
I'm ashamed to admit I don't even know what that is
 I should have qualified it by adding "*can be*". There are some situations where unsafe code can be faster. For example, non-sequential access of a vector will be faster without bounds checking (unsafe). 
The pedantic rust syntax allows the parser to catch a lot of potential bugs within a few seconds. Once the program parses it has a greater chance of being bug-free, than a corresponding C++ program (in my experience). So you end up having to compile and test the entire code base fewer times. That can be a time-saver.
Which Python implementation did you use?
Would love to see a post about this!
Servo needs it to represent the DOM efficiently. (e.g. [this blog post](http://smallcultfollowing.com/babysteps/blog/2013/10/24/single-inheritance/).)
Here's my results with some decent documentation. It's weird that Rust is faster than C++. Even with clang++ rust is faster, so there's something in my code that's different. I haven't looked at the asm yet, but I'm sure someone could figure out what's tripping the compilers up. [Gist](https://gist.github.com/anonymous/2ccc33beca32146cce3f)
Also, this.
If one is often turning a `&amp;str` argument into a `String`, then it should be passed as `String` to allow the user to transfer ownership and avoid allocations if they already have a `String` (and don't need to use it again in the main function).
`x * x + y * y &lt; r * r` (where `r` is the radius) is a perfectly fine way to define a disk. In this case the radius is 1, so the inequality looks the same with or without the square root.
yes, if you see the error quickly. if the project builds for minutes only to present you a compiler error, something isn't quite right. again, fast compilers help greatly.
Rust already supports implicit SIMD intrinsics (types like f32x4, etc) which are automatically SIMD-ed by LLVM (atleast for basic arithmetic operations). A small example: http://rustbyexample.com/staging/simd.html
And the idea is that this check is provably redundant for a recursive call using tail call optimization?
&gt; I think the right thing to do on EvaluationInProgress is to block until it is Evaluated. Is there a good way to do that? For a single thread, it is impossible; the only way to see `EvaluationInProgress` is if `force` is being called recursively, that is, if the value of the `Thunk` depends entirely on itself. This means execution is essentially blocked at that point, and being blocked in a single thread is a bad idea (since the thread just deadlocks and can't continue at all). In a multithreaded scenario, it's theoretically possible to block and wait for another thread to finish executing (assuming that it is actually another thread that is forcing it), e.g. with a type like [`RWLock`](http://doc.rust-lang.org/master/std/sync/struct.RWLock.html). However, if you are implementing the `Thunk` in a way where that matters (that is, allowing it to be `Share`), you *need* to be using that sort of type, using `Unsafe` directly will be prone to data races e.g. if two tasks `force` at the same type. (On that note, you should probably be using a marker like [`NoShare`](http://doc.rust-lang.org/master/std/kinds/marker/struct.NoShare.html), and possibly `NoSend`; at least until you make sure it's safe.)
I think it already has them: http://blog.aventine.se/2013/07/16/my-vision-for-rust-simd.html https://github.com/rust-lang/rust/issues/3499 http://doc.rust-lang.org/std/simd/ I think /u/sebcrozet's point was just that he hasn't got around to using them yet.
I don't think anyone's questioning the value of the Rust compiler's pedantry, they're just wondering whether the same pedantry could be done faster. Happy Cake Day!
The reason is that when you do it this way, you don't introduce an allocation.
Thanks! We have an issue on improvements, if you have any ideas: https://github.com/rust-lang/rust/issues/15994
Rust uses four spaces, not two. And it's considered better to use `//` on each line than to use `/* */`. fn post_note(title:&amp;str, text:&amp;str) -&gt; () { should be fn post_note(title: &amp;str, text: &amp;str) { Note the spacing and the lack of a return type. You shouldn't need a new binding [here](https://github.com/bryanjos/rust-note-example/blob/master/note.rs#L41), right? you don't use it. Most people prefer `.to_string()` rather than `String::from_str`. You could also use Cargo for this project. That's it! Mostly nit-picky.
`restrict` is also outside the C++ Standard, so while widely implemented it's technically nonportable.
That RFC, [the first take](https://github.com/rust-lang/rfcs/blob/39b3617ba104548edd9011df7e4b4621f6671c1d/active/0003-opt-in-builtin-traits.md) and [the original blogpost](http://smallcultfollowing.com/babysteps/blog/2014/02/28/rust-rfc-opt-in-builtin-traits/) are the only information written down; however, the newest RFC is the only one that is now relevant (e.g. it's the only one with unsafe traits), and the first RFC and blogpost are quite similar.
And sometimes, like with iterators, you can write safe code that doesn't have the bounds checks, and _really_ get the best of both worlds.
/r/playrust
No (Fibonacci can't be easily TCO'd, since neither recursive call are in tail position), the idea is there's lower cost ways to avoid stack overflow, e.g. I believe you can just have a guard page at the end of the stack, marked in such a way that any access (read or write) will crash; this is then essentially zero cost for each function call. The cost with *small* recursive functions is the check (and the branch in it) is a significant portion of the code the function executes and the recursion means it is executed often, whereas the stack check is a much smaller proportion of the code in a big function. 
Gotcha, thanks.
Anyone know what it would take to a TLS certificate for `rust-lang.org`? If folks are going to encouraging piping `rustup.sh` to `sudo sh`, it'd be nice if it weren't a gaping a security hole.
its available where it matters, thankfully
This. A million times this.
What happens when a task crashes and has to unwind, I thought that it's required to unwind it to reclaim the space. Won't those optimization flags make all programs crash when one task crashes?
That seems right. I think the design I will pursue is to expose two datatypes: `Thunk&lt;T&gt;`/`Lazy&lt;T&gt;` which are the current, fixed, implementations and `AtomicThunk&lt;T&gt;`/`AtomicLazy&lt;T&gt;` which would be Sendable and Shareable and use an RWLock or Mutex to block on multiple groups trying to evaluate at once. EDIT: I've made your suggested refactors and added a test for the simple case of double-free. I will be adding a more heavy-duty test for your second case later.
What I think the other posters are getting at is that with a powerful type system you don't gain a tremendous amount from actually doing the code-gen and linking parts of the compile step. Its basically only useful if you're debugging or running unit tests, which at least for me is a tiny fraction of my dev time. If it parses and type checks then it works. Parsing and type checking rust is only a fraction of the complete compile time, so you gain most of the benefit, even if a full compile still takes 10s of seconds.
Well ideally with this library you'd be able to model those like Haskell lists: // An infinite, lazy stream struct Stream&lt;T&gt; { head: Lazy&lt;T&gt;, tail: Lazy&lt;Box&lt;Stream&lt;T&gt;&gt;&gt; } impl&lt;T&gt; Stream&lt;T&gt; { fn head(&amp;self) -&gt; T { *self.head }, fn tail(&amp;self) -&gt; Stream&lt;T&gt; { *self.tail }, fn infinite_map(&amp;self, iter: fn(&amp;T) -&gt; B) -&gt; Stream&lt;B&gt; { Stream { head: lazy!(iter(self.head()), tail: lazy!(self.tail.infinite_map(iter)) } } fn as_ref&lt;'a&gt;(&amp;'a self) -&gt; Stream&lt;&amp;'a T&gt; { Stream { head: lazy!(&amp;self.head()), tail: lazy!(self.tail.as_ref()) } } fn zip_with(&amp;self, other: &amp;Stream&lt;A&gt;, combiner: fn(&amp;T, &amp;A) -&gt; B) -&gt; Stream&lt;B&gt; { let (self_ref, other_ref) = (self.as_ref(), other.as_ref()); Stream { head: lazy!(combiner(self_ref.head(), other_ref.head())), tail: lazy!(self.tail.zip_with(other, combiner)) } } } fn fibs() -&gt; Stream&lt;u64&gt; { let fibs = Stream { head: lazy!(0), tail: Stream lazy!({ head: lazy!(1), tail: lazy!(fibs.zip_with(fibs.tail, add)) }) }; fibs } Disclaimer: this code has never been run and probably won't compile, but it's interesting to think about.
Will the process just crash on failure when unwinding is disabled? How will resource clean up happen? I should probably wait for the RFC
The language itself doesn't particularly impose any difference vs. C++ in terms of memory use (Rust gives the same low level control over memory layout and access patterns). Of course, the standard libraries may have differences, although it's worth remembering the Rust standard library hasn't been optimised to the same extent as a C++ one. (That said, Rust currently uses jemalloc as the default allocator, and requires that deallocation passes the size of the allocation, allowing an allocator to store little-to-no metadata about each allocation. Both of these are likely to reduce memory use and increase performance relative to a default C++ application.)
When done it should be similar, there'll probably be more of a skew towards stack allocations than C++ has as well, but I have no numbers for that.
Probably, but for lots of use-cases breaking the whole program with a unrecoverable failure and modelling all recoverable failures as `Result&lt;T, E&gt;` makes more sense.
&gt; C++ is, on average, 25% slower than C++. Huh?
Nobody on the Rust team knew this was being done.
Works for me: use std::io::fs::File; fn main() { for _ in range(0i, 10) { spawn(proc() { let path = Path::new("someText.txt"); let mut file_ptr = File::open(&amp;path); }); } } 
I think there's issuers that have free/cheap deals for nonprofits.
Pure awesome.
The AST of generic functions is stored in the metadata of a library, and when you compile against it you get a copy of that AST and monomorphize your own copies when you need it. So, in short: it doesn't work, it's not actually dynamic.
nice, (and now i'm glad i moved my vecmaths over to tuple structs) do you know if you can express a dot product or 'horizontal add' (if you destructure and write it out manually.. will it optimise to the appropriate instructions..)
https://www.startssl.com/ has free certs for anyone! Also, not for nothing, but I feel like Mozilla should be able to swing a cert ;-)
Sweet.
Yes. If you don't want that to happen, don't use the flag.
I assume they mean C is 25% slower. I can imagine justifying this by showing that C sometimes needs more allocations for the same code due to shoving "generics" behind a `void*` instead of being able to use a template.
So who did it?
Debatable, it's good for performance, but lets implementation details bleed into the interface. I personally like providing a function that's generic over `StrAllocating` and then calling `.into_string()` within the function, which is a no-op for `String`. For some reason people really disliked that approach, when it was suggested for Rust's standard libraries though.
I'm on my phone, but there's a different method that let's you specify. IIRC this call is read only. I don't think Rust can or will prevent you from making two calls to open the same file. I don't know how that'd work...
I'm trying to understand why a byte copy would be necessary here: struct Dog { name: String, age: uint, } impl Dog { fn new(name: String, age: uint) -&gt; Dog { Dog {name:name, age:age} } fn bark(&amp;self) -&gt; String { format!("I am dog {}. I am {}", self.name, self.age) } } fn main() -&gt; () { let hunter_dawg: Dog = Dog::new("Hunter".to_string(), 5); println!("{}", hunter_dawg.bark()) // See no ; } As I understand it, a struct must be laid out in contiguous memory, so `"Hunter"` must be beside the age `uint`. But in this scenario `"Hunter"` is a const, `5` is a const, and ~~everything is on the stack~~ (`String` is [apparently](rustbyexample.com/str.html) heap alllocated). Why do we need to make a copy? If `hunter_dawg` were in the heap then I guess there would be no way around it; `"Hunter"` would be somewhere in the processing instructions (I think?) but it would need to be copied because we don't know what address the heap memory will have. But wouldn't the same thing happen for "5"? We're making a copy aren't we? Why is one treated differently than the other? 
This benchmark is dubious because technically you have the upper end of the range inside your while loop. A good compiler can detect that its value will never chance and only compute it once (this optimization is a special case of "loop-invariant code motion"). If your intent is to test for this optimization, maybe it's ok, but otherwise it will throw off the rest of your results.
You left out ~~checked arithmetic~~ bounds checks. It's a perf hit for numerical code and Rust has it on by default. I've seen people ask for the ability to turn this off with a compiler switch/crate attribute, but dev team is against this (which saddens me). Relying on unsafe blocks to avoid the ~~overflow~~ bounds check is neither composable nor scalable in many cases.
What if we know that it works, but simply want to modify behavior and quickly see the results? In game dev, it is not crazy to have such an iterative workflow.
For sake of correctness, the traditionally written fibonacci is not TCO-able, but is possible to write such that it is. The naive implementation: fn fib(n:uint) -&gt; uint { match n { 0 | 1 =&gt; 1 n =&gt; fib(n-1) + fib(n-2) } } But it can also be written as: fn fib(n:uint) -&gt; uint { fibn(n, 0, 1) } fn fibn(n:uint, smaller:uint, bigger:uint) -&gt; uint { match n { 0 =&gt; smaller, n =&gt; fibn(n - 1, bigger, smaller + bigger) } }
&gt;&gt;Every function has a small (like 4 instruction) prelude that checks that the stack won't be overflowed by the current function call. could a "leaf function" optimisation work, e.g. imagine if the check ensures N bytes are free in the stack, leaf functions that are guaranteed to use &lt;N bytes of stack no longer need to perform any check. (This might be a tradeoff, since non-leaf functions would need to over-reserve that N bytes?.. or could they in turn know they get to use it all, if they make no leaf calls?)
Should be possible. Check out the sources for https://github.com/bjz/cgmath-rs Many of the vector computations in it are optimized for simd (although it requires a bit of macro magic in the case of matrices).
http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/ The syntax would look like: RemindMe! 5 hours "sum of primes program in Rust"
Someone not on the Rust team, I guess. Ninja edit: Unless there's memory wipes involved.
I'll message you on [**2014-07-31 08:25:53 UTC**](http://www.wolframalpha.com/input/?i=2014-07-31 08:25:53 UTC To Local Time) to remind you of this post. [**Click Here**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[http://www.reddit.com/r/rust/comments/2c5ax6/how_does_rust_compare_to_c_performancewise/cjcol9n]%0ANOTE: MAKE SURE THE TIME OPTIONS ARE CORRECT.%0AEXAMPLE: RemindMe 48 hours/days/weeks/months etc%0A%0ARemindMe! 5 hours ) to also be reminded and to reduce spam. _____ ^(I will PM you a message so you don't forget about the comment or thread later on. Just use the **RemindMe!** command and optional date formats. Subsequent confirmations in this unique thread will be sent through PM to avoid spam. Default wait is a day.) [^([PM Reminder])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK HERE else default to FAQs]%0A%0ANOTE: Don't forget to add time options after RemindMe command!%0A%0ARemindMe!) ^| [^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/) ^| [^([Time Options])](http://www.reddit.com/r/RemindMeBot/comments/2862bd/remindmebot_date_options/) ^| [^([Suggestions])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Suggestion) ^| [^([Code])](https://github.com/SIlver--/remindmebot-reddit)
That's something you need to put into an unsafe block right?
Hihihihi! Very niceeeeeee!
Nothing to do with nickel.rs but WTF's with TOML? &gt; TOML aims to be a minimal configuration file format that's easy to read due to obvious semantics. Yeah... because it's really obvious to me what the difference is between `[package]` and `[[bin]]` ?? Further down it's [explained](https://github.com/toml-lang/toml#array-of-tables) but uck. I understand JSON's not perfect but it's more than adequate. Their examples even *explain* it using JSON. &gt; No, JSON doesn't count. You know why. No, I really don't. Please explain yourself Tom. /rant
Ah I see it now, thanks.
You mean divide-by-zero checking? This is the first I've heard about "checked arithmetic"; Rust does *not* do overflow checks by default. This is also the first time I've heard about the dev team being in favor of overflow checking. Also unsafe blocks do not affect the semantics of arithmetic.
Are you quite sure? My C++ test had 680ms after, 790ms before, with C++ and rust exactly matching (not too surprising, given that it's basically the same backend). Looking at the asm it's clear what's going on. The original C++ code does an int-&gt;double conversion and does the compare as a double. In general, that's required for correctness, what if the double was greater than maxint? Your rust code casts the result back to u32, so it's not really the same.
i can see game dev and maybe ui work being a special case where you need to run the program to get a feel for it. That seems like it would be really annoying if you need to step too far into the game to see...
Fortunately, the semantics of restrict allow you to just `#define __restrict` and your code will still work on non-supported platforms, it will just not be as fast.
I knew I was missing something somewhere. I forced c++ to compare as a uint32_t and changed Rust's sqrt to a f64 for correctness (doesn't actually make an execution time difference in my case). Now they spit out identical times. Thanks for the sanity checks. 
&gt;C++ is, on average, 25% slower than C++. As well as 25% faster. Compilers vary. Machines vary. Many kinds of programs nowadays are memory- and thus cache-bound. &gt; If we can get 1x to C++ I'd be in heaven. It might be a genuine industry changer. I don't think this is necessary for most parts of the code. If it were, we'd all be writing code in ATS and FORTRAN.
It's on my radar to do this. I haven't found the time to look into it yet.
Woops, fixed. Thank you.
The actual FFI functions should not be public—given the convention of having the `ffi` module containing those things, your crate root should have `mod ffi;`, *not* `pub mod ffi;`. Beyond that, translation to Rust idioms is typically desirable.
&gt; As well as 25% faster. On *average*. &gt; I don't think this is necessary for most parts of the code. If it were, we'd all be writing code in ATS and FORTRAN. Well no, we do need it, otherwise we'd write everything in python.
My assumption about what OP meant to say is invalid, or my assumption about how OP might justify their statement is invalid? I think we're in violent agreement.
Hey there, great talk. At first I thought it was going to be a too-basic intro - but then some unsafe code was shown and discussed - and was quite helpful, actually.
The truth, as always, lies somewhere in between. * In statistical programming, many things *are* written in python (or R or matlab) - or incidentially fortran. Java is also on the rise, C++ is big with banks as far as I hear, C is very uncommon. * Of course there is a need for programs that *run fast* - in fact that's one big objective in my work - to make our processes run in hours instead of weeks. * Even with that said, there is also a requirement to be able to specify or infer *useful metadata* about the program. Languages like Rust (or ATS) allow us to define (or even prove) certain aspects of our program. This is helpful because it enables us to write better programs (read: with less bugs), faster (because we save time on debugging). I remember reading an interview with John Carmack, who said that static analysis is the biggest win for the game programming industry. Rust's lint tool is a big win in this regard. * Another property of programming languages factoring into their usefulness is their *abstractive power* - this is where python is (usually) better than C++, because the abstractions built into the language enable to use less abstractions to get stuff done. * The other side of the coin is *control* over runtime behavior. In this regard, python users are rather lost. They have to trust the VM to do the right thing for them. Sometimes this will fail, and they will have to extend their programs with C modules (or Rust modules?). Rust strikes a very delicate balance between control and abstractive power because you can use reasonable defaults inferred by the compiler (which will be fine in 90% of all cases), or you can go down to the metal.
&gt; I thought it was only necessary for enums I don't know. I thought it applies to more than enums. &gt; but it's a learning exercise for me, I actually never did a binding before. Then, you picked a pretty hard problem as your first one. I would try to start smaller. 
Thanks!
I wasn't defending bash, just pointing out that for a quick hack involving munging strings and gluing together existing Unix filters, Rust is not a sweet spot. Rust string handling has been going through some changes recently, and the std libraries are not yet very consistent in their use of String vs str slices. And Rust's I/O APIs need some loving attention. 
Did you publish the fix already? Beause it still says &gt; String is a wrapper class around a &amp;str which is as true as `int` being a wrapper around `&amp;int`: Not really.
Would it be more correct to say &amp;str is a public copy of a String? Rust is not my forte, this post is as much of a tutorial for me as it is for the reader.
Nice pipes!
I tried it with GCC/Clang/Go from Ubuntu 14.04, recent Rust, and more aggressive optimization (-Ofast -march=native). I got similar results, with Rust fastest. The C++ version was surprisingly slow with Clang. https://gist.github.com/mprobinson/79e08967bf15888cb066 edit:updated with raphlinus's suggestions, no major performance changes
It doesn't work for recursive functions like a naive Fibonacci benchmark; in other situations, the small functions can often be inlined and thus incur no stack cost anyway.
Why not just interpret the code instead? Then you can do a build for release. Compilation during development seems like a waste of time. You can still do type checking while you interpret it.
No. `&amp;str` is a **view**, commonly called a **slice**. `&amp;str` can be considered a wrapper around `&amp;[u8]`, where `String` is a wrapper around `Vec&lt;u8&gt;` i.e. a heap vector of bytes.
No. It's more like what I said about `int`s: `int` is type for a variable you can *store* an integer value into. `String` is a type for a variable you can *store* a string value into. `&amp;int` is a type for a variable with which you can *refer* to some integer value that is *stored elsewhere*. `&amp;str` is a type for a variable with which you can *refer* to some string value that is *stored elsewhere*. This is what the ampersand is for. You can read `&amp;T` as "reference to a T". In case this T is not a single thing but an array of something of some length, we call it a slice. You can make a slice pointing to some array or just a slice of it. And in the case of `&amp;str` we call this type a "string slice". Slices *refer* to 0 or more "things". `&amp;[int]` refers to 0 or more integer values that are stored consecutively *elsewhere*. `&amp;str` refers to 0 or more `u8` values that are stored consecutively *elsewhere* and make up a valid UTF-8 string encoding. The reason why we see `&amp;str` more often than `&amp;int` is because copying a string value is expensive, much more expensive than copying a single int. In some situations, however, you don't need a copy. If you don't need a copy of a string value, you can use `&amp;str` to *refer* to the original string value. This is much much cheaper. After all, a slice is nothing more than a pointer and a length. The string value of a string literal is stored in a static read-only memory region of your process (static = exists during the whole time the process runs). How do we refer to them? With `&amp;str` of course! That's why when you write a string literal expression, it has the type `&amp;'static str`. Like any other reference, they have this "lifetime" metadata attached to them (only at compile-time) so that the compiler can help you avoid creating dangling references. 
Eh, `StrAllocating` is showing implementation details too. (Although it does make for nice APIs, but isn't quite as good as taking a `String` as making costs clear, since `&amp;str` Just Works, but can be expensive.)
&gt; it's not actually dynamic Imagine a future where a given machine has many applications written in Rust. If someone found a security issue in, say, the stdlib, all those executables would have to be recompiled, even if they were dynamically linked? That would make the-world-is-ending bugs like heartbleed a lot more fun
for my purposes i think i would want to roll my own unsafe::Vec without bounds checks. for some use cases the correct approach is a debug build with all the extra checks,(which is used for testing) whilst the release version counts on program-wise assumptions for full performance. eg in some cases, indices and what they're indexing into are immutable- they can be checked manually on creation, once i guess you could play by the book and have these unsafe and mark code using it unsafe.. it would just be quite pervasive. 
The [strings guide](http://doc.rust-lang.org/master/guide-strings.html) may help, as might [my answer here](http://stackoverflow.com/a/24159933/1256624).
Ahh, from what you're saying I think the part that confused me was that I thought String and &amp;str were pointing to different things. int and &amp;int i get, but why is String called String and not just str ? Confusing.
I prefer a thin safe layer with RAII and no traits if possible. Nice abstractions can often be developed in a separate library.
Is that going to change? 
no `++` in Rust. :)
I fail Rust forever.
It's a tough call. I started off my [glfw-rs wrapper](https://github.com/bjz/glfw-rs) pretty thin, but it is now much more ideomatic, and enforces thread-safety. Callbacks are especially hard. The `ffi` module is public though, but nobody uses it...
I think the amount of time you spend debugging depends enormously on your development environment. When I work on my own stuff I spend relatively little time debugging because I know all the code, and it's generally not that big. When I'm in a more shared environment at work (where I guess I have ownership over ~250kloc, some of which I know very well, some not so much at all) being able to make quick modifications is invaluable - it helps me to learn more about the code, print values out and so on.
&gt; Here's a list of open-source licenses that are non free. Are these actually considered OSS by the OSI? Because I understood you to be saying that the OSI endorsed these licences, which as far as I know is not the case. All this says is that they're software licences that are not free; there's no claim that they're supposed to be open-source or that OSI claims them to be open-source. &gt; OSI's point is to make the idea of using software where the source code is available more palatable to corporations Agreed. &gt; Thus they advocate a superset of licenses over the FSF Again, not sure that this is the case. As I said, the OSI's definition is practically identical to the Debian definition, which as far as I know is functionally identical to the FSF definition. I know of only a few areas of disagreement, for example that the FSF considers the GFDL to be free in all cases and Debian considers it to be non-free in certain cases. The significant difference between them, as far as I understand, is that the "open source" movement is an attempt to depoliticise the "free software" movement to appeal to business (which, of course, is itself a political act).
Vim. On a more serious note, I don't think there is an IDE. A text editor with https://github.com/PistonDevelopers/rust-empty is quite comfortable to get started in the beginning.
Rust is still unstable, so it's hard to give proper tooling support for it. So, at most, you'll mostly see support for syntax highlight. So it mostly makes no difference whether you use a text editor or a IDE. If you want a IDE anyway, there's a plug-in for IntelliJ. Personally, I use Emacs. Calling cargo from the editor is easy, there's support for GNU Global tags, and compilation error highlight. There is even experimental support for auto completion, though I don't personally use it. 
I recently switched from Atom to IntelliJ with the Rust plugin. The plugin gives IntelliJ a bit more intelligence than simple syntax highlighting, although there is a lot of work to be done. But development is active, so I'm hopeful it improves in the future. 
I'm using Emacs with Racer. Integration is pretty easy, and it lets you navigate to definitions. It doesn't give you any of the language-aware editing actions that you expect from an IDE these days -- text editing only.
This might just be it.
Definitely expose the ffi but under a different name. It sucks if something is incorrectly wrapped and you need to do it again.
Well, with flycheck it does gives you error checking, and you can use projectile to call cargo test, and you'll have jump to error in the compilation buffer. What other feature from an IDE would you like to have?
I personally prefer YAML. I also find the use case for TOML confusing, I see no advantages over YAML (which is far more adopted).
Does this mean dynamic libraries are actually GPL-viral? That's a huge problem from a licensing standpoint. 
D doesn't force GC down everyone's throat. Use `@nogc` in the immanent release.
&gt; m.to_f32().unwrap() I don't know much about Rust so I was surprised by this: an u32 to f32 always work so why use an option type? I fully agree about using explicit conversion instead of implicit conversion, but this means that in order to have readable code, conversions should be as painless as possible! Wouldn't it be possible to use overloading to have 'generic' conversions (with option type) and also functions without the option type for the conversions which cannot fail? 
I guess it would be possible to make the dynamic linker monomorphize functions on demand (and cache the results), such that semantically-compatible changes can be made in libraries and propagated to executables. If that turns out to be a problem. 
myself, as a c/c++ user, I like having C bindings looking as close as possible to C code - it reassures me how suitable rust is as a C++ replacement, i'm still in the same place. of course you could build rust abstractions around those. I've found GL in rust irritating because it relies on wooly typing,(e.g: passing offsets as void pointers..) so you might want some generic wrappers for sanity. But its reassuring when you can see something 1:1 with C inside unsafe blocks. 
Yay! :D
language-aware editing
Isn't *any* form of a GPL'd program viral? What specifically about dynamic libraries do you see here? Note also that static libraries also store this same metadata.
[Searching for “rust sublime text”](https://duckduckgo.com/?q=rust+sublime+text) very quickly leads me to https://github.com/jhasse/sublime-rust. As for Vim and emacs, src/etc/{vim,emacs}.
What! Not Rustafarians? ;)
I thought it was Rustaceans. C'mon people, we gotta settle on just one.
I don't know, I don't understand that much about language design. I was just curious, given the usefulness of dynamic linking.
Unfortunately cargo runs rustc relative to the file and not the top of the project so the jump to error isn't working at the moment because all errors are simply the filename without a path.
Scoured the subreddit to find this comment again. First read, I said "huh', moved on. Two hours later I drop my muffin as it clicks. An error I was having earlier completely makes sense now. Why did I not get such a simple concept? Thank you!
I heartedly disagree. The more the merrier! My current favorites are Rustillians and Oxidizers, but I'm going to have to come up with some more for the next meetup announcement...
Rustafarians has weird cultural and racial appropriation / overtones to it, so many of us prefer something else.
There's another thread currently about a very similar topic http://www.reddit.com/r/rust/comments/2c8kt3/best_rust_ide/ 
I've thought about that same problem with functions like glVertexPointer. I looked into WebGL to see how it was done there, but js just uses the number type, so it wasn't an issure there, and doesn't help this problem. I was thinking of using a macro that takes the vertex struct and the identifier for a member within that struct. I haven't played around with Rust macros much yet, so I'm not 100% sure that it would work. Something along these lines: struct MyVertex { pub x: f32, pub y: f32, pub z: f32, } static TRIANGLE: [MyVertex, ..3] = [ MyVertex{x: 0.0, y: 0.0, z: 0.0}, MyVertex{x: 0.0, y: 1.0, z: 0.0}, MyVertex{x: 1.0, y: 0.0, z: 0.0}, ]; gl::ffi::glVertexPointer(3, gl::ffi::GL_FLOAT, 12, gl_attr_ptr!(TRIANGLE, MyVertex, x)); gl::ffi::glDrawArrays(gl::ffi::GL_TRIANGLES, 0, 3); Although something like this would only work in an unsafe binding, and not in a safe wrapper. I'd rather call a single function that takes care of glEnableClientState/glVertexPointer/glDrawArrays/etc. all at once. It could take a VertexFormat or something as one of the parameters.
&gt; As for Vim and emacs, src/etc/{vim,emacs}. I use this stuff for vim, and it works well. Someone published it as a package somewhere if you use Vundle, but I just `cp -r src/etc/vim* ~/.vim`'d, personally.
I like both: a library that provides a nice Rust-like interface, but that uses a thin wrapper underneath, so someone else can make their own nice interface if they prefer to do it a different way.
That's why you use projectile. C-c p c will run cargo from the top of the project.
For some projects you want both compilation speed and decent runtime performance. Some examples: game programming, image processing, audio processing, etc.
Yes, so you code in interpreter mode, and then when you make a release (for testers or whatever) you do a full build and go out for coffee. Interpreted languages don't have a compiler, but they can still catch typos while editing code and have code completion.
I think you are confusing GPL and LGPL. Isn't being a dynamic library only relevant for LGPL?
It would be much nicer to code with decent optimizations and if you need to make modifications often then waiting for the compiler can take you out of the flow. I've removed my edit before I saw your comment it didn't make sense in this context. 
I do use projectile. Same problem.
Meh, then I guess I'm wrong. That's a tooling problem, anyway. Maybe we should file an issue.
I personally use Vim and love it, but I guess the op wanted a full fledged IDE like VS or XCode.
I should've saved the screenshot with 4,999 rustaceans...
Interesting! From the example of the `double` function, it seems like it is doing whole-program type inference
The Rustice League
Something like VisualD would be great. http://www.dsource.org/projects/visuald
This is nice and cozy, but can't it be a part of Rust ecosystem somehow? Just an alternative compiler that would output JS or asmJS would have a much higher chance to survive.
Hi Mr Yeya, I've run into similar problems. I'm glad it isn't just me with the issue, sometimes it feels like I am stuck in a Blizzard of confusion which won't let me get on to find the answers
Atom is the most fully featured, but I'm loving kate for being so lightweight but still managing to have a built in terminal, projects, etc.
Precisely
This is possible sorta through emscripten.
This is why I love the Rust community. Friendly and welcoming to everyone. Big props to the people keeping it this way. Being trans you always feel like the laughing stock of the internet. First, when people notice you are a girl, they get all suspicious, claiming you aren't real and asking for evidence (refer to the thread posted about half a year ago about a very offensive "joke" aimed at a female rustler). And then when they manage to find out you are trans they are like "oh so you aren't a **real** girl?", which can quite honestly break me down for several days. This would NEVER be tolerated in this community which makes me so very happy. Again, thanks to all the awesome people involved for keeping it this way. I appreciate it a lot. 
Does rust-empty offer any real advantages over using cargo as a build tool?
Try downloading clang from [here](http://llvm.org/releases/download.html). Then when compiling, add -L path/to/those/libs/. I had the same problem last night. I got things compiling properly after that.
I'd expect a language targeting javascript to make a lot of different tradeoffs from, even while being inspired by, rust, so I'm not sure how much either side would benefit from that.
Executable size is a big concern for me - Making a "Hello World" was shockingly large (Around 3.5MB iirc) kinda put me off from using rust at first - hoping this gets better
Sure, if the end goal is to compile to JS, then automatic memory management (ala Swift) is gonna work better. We need more widespread adoption of Native Client, where Rust may shine one day.
As far as I understood from cmr's presentation, it is kinda blocked by the inability of our standard libraries to work within web environment. Is there any progress on that, and how do I track it?
&lt;3. We're not perfect, and it's going to be harder as we grow. For example, check the voting on the stickied thread: over time, it's gotten worse. For example [this subthread](http://www.reddit.com/r/rust/comments/1nvsdh/a_note_on_conduct_please_read/ccnuyz2). That doesn't mean it's not possible, it just takes active, sustained effort. As your comment shows, I think it's really, truly worthwhile.
No clue. I don't think that a lot of it _will_ be possible. For example, how do you do threading?
/r/playrust
Oh. Well, in that case I think `unsafe_get()` and `unsafe_set()` are perfectly composable (unsafe blocks compose well) and scalable. It's not a performance issue if you can get around it: the only issue is that it's not as convenient to get around it as you might like.
[This](http://weblog.luite.com/wordpress/?p=14#concurrency-and-exception-handling) is the only reference I've been able to find for the GHCJS runtime system's thread handling. But surely if we can get Haskell into Javascript, it could be done with Rust ;).
I'm definitely giving this a shot, I just wasn't sure if this was the most widely accepted, etc. Thanks!
"Rustbuckets". Edit: Oh, hell. Obviously it's Rustaceans.
Keep fighting the good fight, you make a lot of people's days brighter. &lt;3
It's going to be a Cargo cult anyway
One of the project managers for office construction took the initiative. I'm told it has a sister that will be installed in the Mountain View office as well.
Why are there 5 support holes on the rusted gear? I can't help but draw a mental [pentagram](http://en.wikipedia.org/wiki/Pentagram) between them.
It's only blocked on doing the work, which is going to be difficult (like any other Rust porting but worse), but the way forward is pretty clear. The only major obstacle to running Rust on the web is that JS does not have threads. An initial web-based Rust runtime would be forced to not support tasks. There are potential solutions, but they are all hard. There is not much progress, but the issue is https://github.com/rust-lang/rust/issues/2235.
It's possible, but with great cost. There are already systems that simulate (slow) coroutines in JS, and coroutines should be enough to implement a multitasking scheduler.
Yes. There's basically no documentation on it yet though. Watch Yehuda's portion of https://air.mozilla.org/sprocketnes-practical-systems-programming-in-rust/ for some details.
Nice work Simon! Look forward to using this more in Iron :)
Well... I program, and though I've read the rust tutorials, I have yet to write more than 10 lines in it ;-) Nevertheless happy to be here! 
There's no aliasing in the first example. The value `a1`, which is of type `int`, is trivially copyable (is a `Copy` type). My guess is that the value of `a1` before the comparison is stored on some temporary before executing the block. As to why the second example is disallowed (from my tests tuples also are `Copy`) I'm not sure. **EDIT**: My mistake, the first example does behave in a aliased-like way. I didn't check the value of the equality check before posting - it is `true`, contrary to what I thought. I don't know if it has some memory safety implication though (I'd guess no).
That makes more sense. Thank you for explaining!
That's a better reason. We're developers though. If we can't write JSON, we can't write Rust. JSON is easy to validate at least. Comments would be nice though... I've wanted those many times.
I agree with Rustacean.
A possible solution to the lack of threads in JavaScript is to support generators. The drawback of such a solution is the need to use a different [standard]library :( fn main() { let g = generator { let ... sender, receiver ... for number in range(0u, 10) { let s = sender.clone(); spawn(generator { yield sleep(random()); yield s.send(number);// yield is required here because i only have synchronous channels :p }); } println!("The winner is {}", yield receiver.recv()); }; g.run(); } I hope if yield syntax gains more support and love. The last time i read about it was [here](https://michaelwoerister.github.io/2013/08/10/iterator-blocks-features.html). i found some 2014 comments in [the corresponding issue](https://github.com/rust-lang/rust/issues/7746). I think that my first Rust project may be to try to implement `generator` as a macro and write that [standard]library.
This doesn't work because the parser is greedy, and you're telling it you want a set of expressions. A tuple is a valid expression, so that's what you get. Looking at it another way, your macro is ambiguous in the case where you want a subtree. It could be that you wanted a flat tree of tuples (and made a mistake with the first element) or you wanted a subtree there, but there's nothing in the grammar to say which it should be. The simplest solution I see would be to explicitly use `tree!` for subtrees, since that's ultimately what you're describing.
Probably because operators on primitive builtin types are builtin operations while operators on tuples go through the operator traits as method calls that eventually inline to builtin operations. Just a guess, I haven't seen that difference express itself as observable behavior before.
Yes, I suppose I should have specified LGPL, but the issue is that those libraries thus become intermixed with your own.
I'm aware of and understand both, but I should have said the latter to be unambiguous.
You misunderstood what I meant by "composable." I mean it on a crate level. Here's an example: team Foo builds crate A which is large, complex and does lots of math. Team Foo wants to use it to build crate B which is security-critical with perf a secondary concern. Team Bar now wants to use crate A as well, but to build crate C which runs a backend batch process that munges petabytes of data. Perf is critical, security isn't a concern at all. Team Foo doesn't want _any_ unsafe accesses in crate A. It would mean crate B is less secure. Do you see the problem? With a compiler-level switch, the teams can have their cake and eat it too. Team Bar can get bleeding fast code and Team Foo can get safe code. WRT "not scalable", crate C from team Bar is _huge_ with lots of dependencies on crates from other teams and even third-party, open-source code. Every percent of perf is millions of dollars. It isn't feasible to go into every single dep that's on the hot path and change accesses to be unsafe (and thus faster). It's just plain impossible to do it for third-party crates if upstream doesn't want it unless you want to maintain an internal fork.
How does e.g. C++ handle a composable choice between bounds-checks and no-bounds-checks?
actually,in one of my project,I not only call rust from c but also call rust from java :)
I find it very interesting that someone with no coding experience would be subscribed here. If you don't mind satisfying my curiosity: how did you end up interested in Rust? Even in programming circles it is not *that* well known (although that is changing - this post is proof of that ;)). 
That would be great, thanks!
&gt; Are these actually considered OSS by the OSI? Not all, but my preliminary research says at least two: - NASA open-source agreement is [OSI approved](http://opensource.org/licenses/NASA-1.3) but [nonfree](https://www.gnu.org/licenses/license-list.html#NASA). - Reciprocal public license is [OSI approved](http://opensource.org/licenses/RPL-1.5) but [nonfree](https://www.gnu.org/licenses/license-list.html#RPL). &gt; Again, not sure that [the OSI movement advocates a superset of licenses over the FSF]. If we list free software licenses that are GPL-incompatible (and thus not advocated by the FSF, for various reasons): - Academic Free License [FSF](http://opensource.org/licenses/AFL-3.0) [OSI](http://opensource.org/licenses/AFL-3.0) - Apple Public Source License (APSL) v2 [FSF](https://www.gnu.org/licenses/license-list.html#apsl2) [OSI](http://opensource.org/licenses/APSL-2.0) - Common Development and Distribution License 1.0 (CDDL-1.0) [FSF](https://www.gnu.org/licenses/license-list.html#CDDL) [OSI](http://opensource.org/licenses/CDDL-1.0) - Common Public Attribution License 1.0 (CPAL) [FSF](https://www.gnu.org/licenses/license-list.html#CPAL) [OSI](http://opensource.org/licenses/CPAL-1.0) - Eclipse Public License [FSF](https://www.gnu.org/licenses/license-list.html#EPL) [OSI](http://opensource.org/licenses/EPL-1.0) - European Union Public License (EUPL) version 1.1 [FSF](https://www.gnu.org/licenses/license-list.html#EUPL) [OSI](http://opensource.org/licenses/EUPL-1.1) - IBM Public License, Version 1.0 [FSF](https://www.gnu.org/licenses/license-list.html#IBMPL) [OSI](http://opensource.org/licenses/IPL-1.0) - Lucent Public License Version 1.02 (Plan 9 license) [FSF](https://www.gnu.org/licenses/license-list.html#lucent102) [OSI](http://opensource.org/licenses/LPL-1.02) - Microsoft Reciprocal License (Ms-RL) [FSF](https://www.gnu.org/licenses/license-list.html#ms-rl) [OSI](http://opensource.org/licenses/MS-PL) - Nokia Open Source License [FSF](https://www.gnu.org/licenses/license-list.html#Nokia) [OSI](http://opensource.org/licenses/Nokia) - Open Software License [FSF](https://www.gnu.org/licenses/license-list.html#OSL) [OSI](http://opensource.org/licenses/OSL-3.0) - Q Public License [FSF](https://www.gnu.org/licenses/license-list.html#QPL) [OSI](http://opensource.org/licenses/QPL-1.0) - RealNetworks Public Source License (RPSL), Version 1.0 [FSF](https://www.gnu.org/licenses/license-list.html#RPSL) [OSI](http://opensource.org/licenses/RPSL-1.0) - Sun Public License [FSF](https://www.gnu.org/licenses/license-list.html#SPL) [OSI](http://opensource.org/licenses/SPL-1.0) 
i'm very interested in programming, have done some online tutorials on codecademy, and I'm mainly interested in low-level languages and maybe scientific computing. so i've treated reddit as a rabbithole for languages and the two most i've found through searching are rust and lisp. i know absolutely nothing about either, but plan to dig deeper when i have/make time
cheerio! /is that how one uses "cheerio"?
Note that this has no value as a benchmark of function calling speed (which is the only point in writing a naive fibonacci).
More configurable, but that's about it. Cargo and rust-empty can also coexist if you want the power of rust-empty plus the conveniece that cargo provides.
Yes, it's true that using an LGPL library in Rust would be much trickier.
Only if there are generics or `#[inline]` functions (presumably C++ has similar problems). I opened [#16159](https://github.com/rust-lang/rust/issues/16159) with some ideas about how the compiler could assist.
Here are the rust-related packages I'm using: * **language rust** (which adds support for rust syntax highlighting) * **Autocomplete Plus** (which requires racer to work with rust) * **racer** (which is an atom package, but *also* requires you to build the [racer](https://github.com/phildawes/racer) program, as well as install the [rust source files](http://www.rust-lang.org/install.html) somewhere. This is the only one that required configuration; you have to tell it where to find those two things. * **Atom Lint** (which works with rust if you have the language-rust package) and here are a few others I like: * **ask-stack** (for accessing stackexchange in the editor) * **recent projects** (which makes it easier to open previous projects after opening atom) * **terminal status** (which allows you to enter terminal commands from a small pop-up window, which is great for quickly compiling and running your program) * **web view** which allows you to open web pages in editor tabs - this is great for rust tutorials or documentation. And of course you'll need the rust compiler and optionally cargo. Also to get some of these packages to install I had to install one of the community editions of Visual Studio to get some required libraries, and at some point add one of the atom directories to my path - but I think that was just quirks of working in Windows.
Yes. It's not very difficult. The two tricks are: 1) Use #[no_mangle] to preserve symbol names. 2) Get the linker flags from rustc when it runs. Note specifically that the default rustc create type (lib) *wont work*; you need to specify either staticlib or dylib. Here's an example: https://github.com/shadowmint/rust-extern
Nice! Do you think we have the momentum to replace all references to Reddit Gold on this sub with a more appropriate metal?
Yeah... I know. That bites me a lot. I always leave trailing commas. But it's easy to spot at least. 
Just photoshop it.
&gt; With Rust, it will be the other way around and that's a problem for perf-critical projects Servo is a perf-critical project, and it has bounds checks on. &gt; but Rust is aiming for the C++ market, and people in that market are using C++ for the perf, not the security. Err, Mozilla is a huge user of C++, and it wants the security. &gt; You need to give people a way to make the tradeoff on their own, and not just at the level of a specific line of code, but on a library level too. I'm not convinced until we see some actual numbers indicating it matters a lot. &gt; I'm afraid that Rust might end up like D and Go as a C++ competitor: it will make decisions that make it impossible to achieve C++ perf for large projects. I'm skeptical that bounds checks are going to make it "impossible for Rust to achieve C++ perf". I have yet to see bounds checks be a perf concern in idiomatic Rust code (and I've looked at a *lot* of instruction level profiling of Rust), and so I would like to see some numbers before we do anything like add a compiler switch. Bounds checks simply aren't as much of a problem in Rust as they are in, say, Java, because of iterators. And iterators are quite practical—Servo uses plenty of numeric code, and much of that uses iterators. Indeed, the reason that GPUs, with their simple texture caches, do so well at numerics in practice is that numeric code tends to lend itself well to straightforward iteration patterns. I see something like NaCl's software fault isolation, which adds bounds checks to *every* load and store on x86-64 and ARM, as a sort of upper bound on performance loss. Last I saw, the slowdown was something like 7%. Now consider that in Rust, the bounds checking is done probably an order of magnitude less often than that, and you're looking at overhead that just doesn't matter. Turning off bounds checks is a big deal for safety and I do not want to just randomly add compiler switches until we *know* it's a performance problem. Edit: I just did an experiment with arbitrary matrix multiplication without using iterators: basically a worst-possible case for bounds checks. Here's the source: https://gist.github.com/pcwalton/271f01693068104665a1 On my machine (Core i7) I got the following numbers: $ ./mm --bench running 2 tests test mmbench ... bench: 8785 ns/iter (+/- 833) test mmbench_nbc ... bench: 8650 ns/iter (+/- 398) test result: ok. 0 passed; 0 failed; 0 ignored; 2 measured So less than 2% of a difference. And that's the worst case, in non-idiomatic Rust. Changing floating point to integer makes no difference: still less than 2%.
The JSON decoder uses a value stack, not sure if you've noticed. You can use something similar to keep information you're going to need later, like `value_type` there.
Integers are primitives and they don't go through `Eq` (how would `Eq` be implemented for them other than using `==` ?). IMO, the second example should work the same way `vec.get_mut(vec.len() - 1)` should work, but doesn't right now. For most cases, borrowing the lvalues involved in a call as late as possible is the best option, not sure if there's other cases where it leads to bugs (though no direct memory safety implications, as borrows still have the same rules, they just start later, as close as possible to when they're really needed).
That's true...it was just using it in the decoder and I'm working on an encoder right now, so I hadn't thought about that. I was stuck thinking about how, in emit_map_elt_key it actually calculates the entire sub-tree twice to do something (similar) to what I was needing. However, I don't think that this is a real solution, as that means I won't actually emit the key inside the emit_map_elt_key() function, but this may be a reasonable workaround for the time being. Given that basically all I'd be doing is storing the result of each emit\_\* function in the stack and then writing them later, why don't the emit_* functions return Result&lt;&amp;[u8], ErrorType&gt; instead? Wouldn't it be better to have more control over when you want the data to be written?
jensnockert got some bindings that are "only" 5 months old https://github.com/jensnockert/cairo.rs
I personally have no problem handing off maintenance of `rust-cairo` to anyone who wants to maintain it. I'll bring it up with the rest of the Servo team tomorrow.
[redacted]
`-C prefer-dynamic -O` and suddenly you're at 8-12K. A statically linked glibc hello world is around the same size as a statically linked rust hello world.
I was also surprised by that code. But as I wanted to focus on the concurrency I didn't investigate further. Maybe a (m as f32), i.e. a type cast may be fine. But I'm not sure if that's cleaner.
Let me make this clear: the Rust community is not happy for people to cast aspersions on other groups. (Anyway, a model of an *idealised* community seems like a perfectly reasonable thing to try to follow.)
Unfortunately reddit does not allow you to do this
&gt; at least two Fair enough, but if we go back to your original claim, “to promote licenses that allow corporations to use and modify open-source code without releasing the source code”, I don't think that's what we've got here. We've got a small minority of licences which, while still requiring the source code to be released, cannot be consider completely free because of legal technicalities. &gt; If we list free software licenses that are GPL-incompatible OK, but GPL-incompatible is not the same thing. They're all considered free and thus acceptable, *but* the FSF advocates its own licence as the best choice. The OSI doesn't have its own licence to advocate as being the best choice, so it considers all of these to be equally acceptable. That's not the same as advocating non-free licences, which was the original claim you made.
s/photoshop/browser developer tools/
I'd look at "How to Design Programs" on the Lisp side. And also possibly "Realm of Racket".
"Linguistic appropriation": certainly. But I haven't seen any jokes or parodies on behalf of Rastafarianism. 
How does Rust compile time compare to c++?
Awesome! I'll try this out thanks! I figured that it had to do with the standard library... Still new to Rust so i wasn't sure if you could make it dynamic or not, *i've been spoiled by MSVC making it all dynamically linked (Where a Hello World in release = 7K)* So in telling it to be dynamic - what files would i need if i wanted to distribute to someone without rust (more of a Windows concern than a linux one) - by my guess just rustrt and std dlls (for this program, and adding other ones where i need until theres a rust runtime package?) Also curious, will std be made smaller\split up for people on size constraints (or for people who want to release the smallest, painless version of their app) or is it possible to modify the std crate to only have the bits i need (so if i only need certain features, i keep them, and nuke everything else?)
OK sure.
also you can probably use ASM and call SSE\MMX instructions - Intel's stuff is well documented on the Intel Intrinsics guide which not only shows intrinsics but asm instruction names - this is good for if theres a feature besides basic math that you want, should be easily able to connect them with the types from std::simd (f32x4,u8x16)
I'm pretty new to vim, what plugins would you recommend to make Rust coding a bit easier - (Using gVim on windows, and Vim on my rPi with Arch)
I think this is something everyone should think about. I recently realized how useless it is trying to cut down, disregard, and disrespect other people, no matter who they are. How many people are you making happier by calling a person, using a certain language, method, compiler, typing, or mindset, "bad"? You do it only to feed your ego; to feel superior to someone. If you instead learn to listen and respect people, you can spread knowledge and happiness, because you can both learn from each other. Feelings are weird, but still very real. Some people have a hard time respecting people's feelings because you can't see them or touch them. If I say calling me inexperienced and bad at programming hurts me or offends me, do you stop? If you punch me and I say it hurt, do you do it again? I said it in another thread yesterday, but I love this community for being so respectful and kind, always trying to help, learn, and teach.
Thank you for running the numbers; they'll come in handy. &gt; Servo is a perf-critical project, and it has bounds checks on. There's "we really care about perf" projects like Servo, and then there's "if we shave 1% of runtime we'll save tens of millions of dollars a year" projects. People I work with work on the latter. We're talking projects that have a half-dozen engineers rework a subsystem for a year in the hope of getting that 1%. Where I've rewritten a small piece that ties into such code that then shaved 0.2% of runtime and everyone's batshit ecstatic. For projects like that, flipping a compiler switch to get 2% back is worth building a large team to implement custom compiler changes that take _years_ to implement _and that's exactly what happens_. So don't discount what 2% means to some people. &gt; Turning off bounds checks is a big deal for safety No disagreement there. 99.999999999% of software should run with them turned on, including projects that "merely" care about perf and don't care much about security. &gt; and so I would like to see some numbers before we do anything like add a compiler switch Agreed 100%. I'm not asking for more than an open mind from the Rust dev team on this; if large projects come in saying "we've shaved 3% of perf by hacking the compiler to eliminate bounds-checks and would like a compiler switch; here's some benchmarks", then the dev team should be open to that. What I'm currently hearing on the mailing list/reddit/irc is that a compiler switch for turning off bounds checks would somehow "fork the language" (IMO nonsense) and in other ways make the sky fall down on our heads so isn't something that could ever be done. Those kinds of statements are concerning. But you've reassured me that the dev team will be more open-minded about this, given benchmarks. So thanks for that.
*fwiw* the benchmarks game `make logs` record some times - [meteor-contest C++ g++ #6](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=meteor&amp;lang=gpp&amp;id=6#log) [meteor-contest Rust #1](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=meteor&amp;lang=rust&amp;id=1#log) 
the irony
Agreed, but luckily, there is hope. It doesn't _have_ to degenerate. We just have to stay on top of it.
You _really_ should use `match` rather than `is_ok()`, because it's exhaustive. In this case, there are only two cases, but still.
* https://github.com/wting/rust.vim - Rust syntax highlighting * https://github.com/Valloric/YouCompleteMe - General code completion (doesn't have Rust support, but it's still useful). * https://github.com/scrooloose/nerdtree - Directory displaying and navigation in vim
https://mitpress.mit.edu/sicp/full-text/book/book.html is a book on Scheme, a dialect of Lisp. It was MIT's "introduction to programming" text until very recently.
&gt;You pray to your God I don't "meet" you at a Rust meetup. Because you're fucking marked, mate. Whatever you're threatening to do... try to dispassionately think about the costs and benefits. I can't imagine a scenario where it would actually help anything to start some shit.
This is a case where you can also benefit from the `select!` macro which is basically just waiting for one of a number of events to happen. You can replace the inner `loop` of `worker` like so: select! { _ = receive_from_main.recv() =&gt; break, montecarlopi_result = receive_from_montecarlo.recv() =&gt; { m = m + montecarlopi_result; i = i + 1; let sender_clone = sender.clone(); spawn(proc() { montecarlopi(n, sender_clone); }); } } This way you can avoid polling in the worker every 50ms to see if the montecarlopi or main task has sent you a message and you'll receive one right away. Another note to point out is that currently the runtime will not exit until all tasks have exited, so sadly the the last remaining montecarlopi task will prevent the program from exiting until the task itself has exited. One way to get around this would be polling, but it's not necessarily the most elegant solution.
that's awesome, you might have just provided the entry point i've been looking for. in other words youre my hero
i suspect these are books?
This feature will alos make it easier to compile applications to run in the browser with Emscripten or PNaCl, without having to modify the compiler.
It's looks like it's a great deal slower (0.30s vs 11.45s). At this stage that's understandable but a little disappointing.
I've never actually maintained a package people *actually use* before, but I'd certainly be willing to try. Edit: That does of course, assume people would actually use rust-cairo.
I'm not sure if it's in your nature, but you might want to get someone to actually follow-up against that threat of physical violence -- that's against the law in many jurisdictions, regardless of whether its online or not.
std as already been split up/made smaller. See http://doc.rust-lang.org/src/std/home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libstd/lib.rs.html#126 for all the pieces it is made of. To ship a dynamically linked executable you'll need libgcc_s, libstd, libcore, libcollections, etc. We still have some optimization work to do wrt size, still in progress.
Yeah, the first one is free online. Also, to avoid making two posts, w.r.t. the SICP discussion, there are also SICP lectures by the authors of the book that are really good, if a bit fast paced.
Are there any proposals for exiting early or forcefully shutting down tasks?
Awesome - Thanks for the information, it's greatly appreciated!
MaybeOwned&lt;'static&gt; would have to be a trait, and since you can't return unboxed traits, the return type would have to be something like Box&lt;Mos&gt;, which isn't any less verbose or more efficient than just returning String.
thats awesome! i have so much new info now, can't say thanks enough!
&gt;/is that how one uses "cheerio"? Cheerio means goodbye, so probably not :) 
Just to make sure I understand this correctly, is it that the compiler is borrowing a2 before looking at 'a2 = (2,)' ?
Yup.
I would love to have some actual docs on this. If you can write up some of the major points, I can take it the rest of the way. Interested?
aha! I found a workaround: struct Foo { x : Vec&lt;int&gt;, y : Vec&lt;int&gt; } fn main () { let foo = box Foo { x : vec![1,2,3], y : vec![4,5,6]}; let tmp = *foo; let Foo { x, y } = tmp; } Somewhat confusingly, though, this does not work: struct Foo { x : Vec&lt;int&gt;, y : Vec&lt;int&gt; } fn main () { let foo = box Foo { x : vec![1,2,3], y : vec![4,5,6]}; let Foo { x, y } = *foo; } 
I wrote the code implementing RFC 43. If you want to move fields out of a `Box&lt;T&gt;` separately, you now have to first move the `T` out of the `Box&lt;T&gt;` into a temporary and then move the fields of the `T` individually. In some of these cases of bindings or "functional update" style struct construction the restrictions could be loosened in the future, but it's not possible at the moment with the way that the Rust compiler is designed.
Clearly, these windows are using different styles. I wonder if you can find a program that would show all the WinAPI properties of a working window, so that you can compare them in flight.
A few weeks back I've read some hacker news discussion about Rust where people basically complained about having to write `pub` everywhere for toying around with it or experimenting with larger module designs. They wanted something that worked more like a simple namespacing system without visibility control. Regardless of whether thats a good idea in general, it was totally doable with a custom attribute, so I wrote one. Right now its kinda limited in that it always applies to a full AST subtree, with no way to exclude certain kinds of child elements. (If there is demand for finer grained control, please file a bug) 
It's error [#13259](https://github.com/rust-lang/rust/issues/13259). What you can do for now is to start every thread that calls winapi with unsafe { ::std::rt::stack::record_sp_limit(0); }
/u/whataloadofwhat - let us know if this works.
This is sweeeet, though the `-rs` seems a bit excessive.
Ah, that's a shame. The workaround worked though, which is nice. Thanks for the help. And thanks to everyone else too.
This is probably exactly it.
Heh, I'm having trouble with finding good names for this stuff ;)
Perhaps you could have a look at or contribute to rust-windows (https://github.com/klutzy/rust-windows)? 
I tried this but I couldn't get that to work. It claimed that it couldn't find a defintion for `InitCommonControlsEx`, even though I was linking `comctl32`. I tried just `InitCommonControls` too (which takes no arguments so no chance of fucking up my declaration) but I got the same error.
I gave it a try but I couldn't get it to work. Though I have no idea what needs to go into a manifest, really. Here's what I was using: &lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt; &lt;assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0"&gt; &lt;dependency&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity type="Win32" name="Microsoft.Windows.Common-Controls" version="6.0.0.0" processorArchitecture="*" publicKeyToken="6595b64144ccf1df" language="*"/&gt; &lt;/dependentAssembly&gt; &lt;/dependency&gt; &lt;asmv3:application&gt; &lt;asmv3:windowsSettings xmlns="http://schemas.microsoft.com/SMI/2011/WindowsSettings"&gt; &lt;disableTheming&gt;false&lt;/disableTheming&gt; &lt;/asmv3:windowsSettings&gt; &lt;/asmv3:application&gt; &lt;/assembly&gt; Which was kind of butchered from the one on [this page](http://www.transmissionzero.co.uk/computing/win32-apps-with-mingw/) The resource file I was using was just: #define APP_MANIFEST 1 #define RT_MANIFEST 24 APP_MANIFEST RT_MANIFEST "win.exe.manifest" which I found ... somewhere that I can't remember (sorry!)
Have you tried the `DynamicLibrary` route?
nice.. would it be possible to do something like 'inherit-use' this way aswell, or flattening a subtree: for each submodule of the current, use ::* all its siblings, and pub use all the submodules - I'd invisage using this within a 'mod.rs' ... my feeling is sometimes the deep namespacing is overkill, when you've also got functions inside impls/traits
The official answer is that YAML is *way* more complicated.
`implicit-pub`?
1. Get rid of the curse word in the public documentation. It's juvenile, and not even contextually cursing any specific behavior. 2. In Lex.rs, the `advance()` function, I'd use Option::mutate instead of match. 3. In Lex.rs, with `skip_comment()`, you don't need the `return`. You could also optionally use Option::map_or 4. In Lex.rs, at `impl&lt;'a&gt; Iterator&lt;String&gt; for Lexer&lt;'a&gt;` function `next`, you can make it easier to read with Option::map. Course, these are all small things. I'm not the person to ask about high level review.
The `c2u8` function doesn't need to exist, since you can just write `c as u8` or use a byte literal `b'\n'` (etc.). Similarly the `s2u8` function is just `s.as_bytes().to_vec()` (you can likely skip the `to_vec` in many situations). You don't need to `.fuse` the `.bytes()` iterator: it will continue to return `None` once finished. Theoretically the lexer could be written to return `&amp;'a [u8]`s pointing into the input `&amp;str` rather than allocating a `Vec&lt;u8&gt;` for each word. I don't think these manual [`.cmp`](https://github.com/cgaebel/wavefront-obj/blob/ceb1dac888179cd2c4708a342ca02c45eb46c16d/src/mtl.rs#L89) chains are doing what you expect, e.g. if `self.name == other.name` and the `self.specular_coefficient &gt; other.specular_coefficeint`, the first part of the chain becomes `Equal.cmp(&amp;Greater)`, which is `Less`.
I have to admit that compilation times is the one thing I do not like about rustc. Or, more specifically, the lack of separate compilation. About the compilation times, I don't think rustc is much worse than, say, clang++ or g++. Comparing the compilation times of the triple { nphysics, ncollide, nalgebra } with the compilation times of bullet would not be fair as I use a lot more genericity than bullet. There was a time when those three libraries were 100% generic (i-e every single type was parameterized by, at least, the scalar type). Then, the compilation times of the triple was very fast but any application using nphysics required several minutes to compile and more than 6Go of RAM. That’s why I removed most of the generic stuffs, and switched to conditional compilation (i-e, on must recompile ncollide if he wants to use the f64 version, or the f32 version or the 2d version, or the 3d version, etc.). Thus, today, compiling my physics engine and its dependencies is still a lot slower than compiling Bullet, but it does not matter that much because I think the real issue for a developer is the lack of separate compilation. About the (lack of) separate compilation, in C++, when a single file is modified, only it (and everything that use it for headers) has to be recompiled and every object file must be relinked. In Rust, modifying any file of your project will trigger a recompilation of the whole project. This is very annoying because I like to make small modifications and recompile immediately. Doing so, I have to wait several seconds instead of just a few milliseconds as when I modify some things in Bullet. This is very frustrating. I know that to have some form of separate compilation I could split, say, ncollide into several smaller crates, and create a "facade" that reexports everything for the user (i-e just like libstd). However, my brain associates "crate" with "library" so having to separate things into smaller libraries only to fasten the compilation does not feel right. But I might end up doing just that in the future for the sake of productivity.
Awesome, thank you! I'll keep that in mind for Part 3 (or 4?). This series is more about me learning Rust than anything else. The blog posts are just a nice side effect.
Thanks Steve. There's all kinds of things wrong with this code. The next few parts will be about cleaning it up and I'll keep that in mind.
Is there a way to manually specify private inside of a module like this?
Ah, I wouldn't really know where to start on that, but if you can point me in the right direction, sure. 
nice post! &gt; I believe things get a little more complicated if you try to use more advanced rust features, as you have to figure out a way to get the Rust runtime started manually. I'm not sure exactly when the runtime gets activated, but at the very least it is involved in using tasks, IO, logging, and message passing. Humm... is that true? I thought that was only the case if you chose not to use the standard library and rely on libcore (ie. #[no_std]).
Thanks anyway.
Thanks for the advice, although I'm not sure what I can do, especially since /u/enthusiastOfRustMayb has now deleted their account.
 use std::io::BufReader; enum Messages { ClNoop = 0, ClMove, ClAttack, } static PACKET: &amp;'static [u8] = &amp;[0, 1, 2, 3, 0]; fn main() { let mut reader = BufReader::new(PACKET); match reader.read_u8() { Ok(msg) if msg == ClNoop as u8 =&gt; { }, Ok(msg) if msg == ClMove as u8 =&gt; { }, Ok(msg) if msg == ClAttack as u8 =&gt; { }, _ =&gt; { }, } } [Playpen](http://play.rust-lang.org/?code=use%20std%3A%3Aio%3A%3ABufReader%3B%0A%0Aenum%20Messages%20{%0A%20%20cl_noop%20%3D%200%2C%0A%20%20cl_move%2C%0A%20%20cl_attack%2C%0A}%0A%0Astatic%20PACKET%3A%20%26%27static%20[u8]%20%3D%20%26[0%2C%201%2C%202%2C%203%2C%200]%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20reader%20%3D%20BufReader%3A%3Anew%28PACKET%29%3B%0A%0A%20%20%20%20match%20reader.read_u8%28%29.ok%28%29.unwrap%28%29%20{%0A%20%20%20%20%20%20%20%20cl_noop%20%3D%3E%20{%20}%2C%0A%20%20%20%20%20%20%20%20_%20%3D%3E%20{%20}%2C%0A%20%20%20%20}%0A})
Just linking against `std` doesn't require a runtime to be started (although one is started by default), e.g. the following doesn't touch any runtime at all but still has its implicit `extern crate std;`. // NB. no #[no_std] #[start] fn main(_: int, _: *const *const u8) -&gt; int { 0 } There are large parts of libstd which can be used without starting a runtime, since a lot of std is just reexports of functionality from low-lying crates like libcore, libcollections and librand. libcore is useful for guaranteeing you're free of the runtime, and for situations where you just can't satisfy the dependencies of `std` (e.g. writing an operating system from scratch, where there is no libc). If you're writing a library on a platform where `std` works, and wish to avoid the runtime to make embeddability work more nicely, it's perfectly OK to just use `std` and be careful to avoid the parts that use the runtime (unfortunately, atm, whether a `std` function requires a runtime or not is mostly only deducable by experimentation or reading the source, the docs don't cover this in much detail).
You can use the trait [FromPrimitive](http://doc.rust-lang.org/std/index.html), I modified you example: http://is.gd/EcRjbI. One remark: I would use singular for the enumeration type, the variable assignment just looks weird as it is now.
**Disclaimer**: rust newbie. http://is.gd/9ODVAY Added a method to convert a u8 to a `Messages`, since you can't statically guarantee any given u8 will be a valid enum value. I tried to use `cl_noop as u8` instead of the underlying values, but it wouldn't compile.
That `.bytes` behaves as you say isn't guaranteed by the documentation and could therefore change anytime.
So far nothing got removed…
They did, but I went through and pulled them out the spam filter. :)
Not right now, but if you need that feature file a issue on that repo. Its not really hard to add.
I did not change anything, but suddenly everything works fine! Thanks!
Basically, just a list of what's actually required. Thinking about it more, your comment and sample is enough to get me going, I think :)
Yes. This is how we used to do multi-view IDEs, for things like tank sims, or rear view mirrors back in the day. Its been years since I've done graphics devs, so I'm afraid I can't help much more than that :)
&gt; Just linking against std doesn't require a runtime to be started (although one is started by default) ... Mmm... we're talking a pretty specific case here though. ie. You've compiled a crate as staticlib/dylib with #[no_mangle] on some symbol, which you then invoke from C code. The program main() resides inside the C itself. For example (as in the OP) you're using python's ctypes library to load the shared library and invoke rust functions in it. Practically speaking, it works perfectly as far as I can tell. ...but what's starting the runtime in this case / is it actually started? The first call to a rust function? The first call to a rust function with #[start]? Just loading the dylib magically triggers something (this seems extremely unlikely to me, but perhaps there's some plausible mechanism for it). The more I think about it, the more surprised I am that running rust code from a C context seems to work so well. I've literally never had any trouble with it from python or straight from c; but I don't really understand how the runtime is bootstrapping itself (if it is? perhaps I just happens I've never used part of std library that relys on it; but that seems pretty unlikely...)
Do you know about the AutoModerator bot? It should be able to approve those posts automatically.
Any news on this?
Nice! Notice that you use `|` to join match arms and you can use it as an expression: game.next_mov = match args.key { piston::keyboard::Up | piston::keyboard::Down | piston::keyboard::Left | piston::keyboard::Right =&gt; Stop, _ =&gt; game.next_mov }; Also, use new lines and indention to make stuff clearer: c.rect( (game.x * BLOCK_SIZE) as f64, (game.y * BLOCK_SIZE) as f64, BLOCK_SIZE as f64, BLOCK_SIZE as f64 ) .rgb(1.0, 0.0, 0.0) .draw(gl); A little about game logic: A game often emerges from the combination of 3 different cases, 1) where object respond to their own internal state and 2) where objects are interacting 3) where objects respond to user input. An AI system belongs to 1, while a physics system belongs to 2 and how to respond to user input belongs to 3. While you can make each of these more advanced, it boils down to the same principles. If you decouple them, then you can improve one of them at a time! Write down how you would like to improve 1, 2 or 3. Btw, congrats on using Github! A pro tip: Split it up hard tasks into simpler tasks. In the Piston project we use labels in the issue tracker "Easy", "Medium" and "Hard". If we have a hard task, we try to split it into simpler tasks. The issue tracker is a good way to organize your thoughts. As soon as an idea hits you, create an issue for it. Don't worry about many tasks being left undone. Even if it takes longer time to write down stuff, it is very valuable for later when the project grows and you start forgetting stuff. "Thinking in the issue tracker" is just as valuable as writing code!
What's the recommended way of doing chained comparisons? I fixed everything else. Thanks!
I was a bit confused about `TVertex`, then I figured the `T` stands for `Texture`. Maybe `VertexUV` or `TextureVertex` would be a better name? If you want a short name, then perhaps `UV`? `fuzzy_cmp` takes `x` and `y` arguments, which is a bit confusing, since `x` and `y` often refers to different dimensions. Perhaps `a` and `b` would be better? Put global functions that are not directly related to the common use of of the library in a sub module. This cleans up the interface a bit. For example,`fuzzy_cmp`, `sliced` and `to_triangles` could be put in a `utils` module. Those are just a few things I got time to look at. Great work!
Do you have any sources for the 2x claim? Genuinely wondering. I haven't seen many, if any, performance comparisons.
http://www.reddit.com/r/rust/comments/2c5ax6/how_does_rust_compare_to_c_performancewise/
&gt; In Rust, modifying any file of your project will trigger a recompilation of the whole project. This is only true if your project is one crate. if you split it up into separate crates, as you mention later. A crate is a compilation unit, a package is a library.
I think there are many things here that can be represented a lot better in Rust. I took me quite some time to grasp what was actually going on, since you pretty much need to know how the `process_philosophers()` function works, before you can really understand the `eat()` method. Some suggestions in no particular order: * `left_hand` and `right_hand` are not terribly descriptive names. It sounds like it would signify what a philosopher actually holds in each hand, and not which chopstick he is trying to pick up. On top of that Foucault's left hand is really his right hand, and vice versa. I'd suggest calling it `first_chopstick` and `second_chopstick` instead. * Instead of sending integers around for picking up/putting down a chopstick, and finishing the meal have an `enum { Take(uint), Put(uint), Sated }`. Not only does it avoid the integer casts, but it also makes the intend much clearer. * The channel towards each philosopher does not have to take an `int`. A bool would already be much clearer. A `enum {Chopstick, ThinAir }` even more. * It's not clear to me why `process_philosopher()` has to send the something to the philosopher after he has finished the meal. Is there a need for synchronization I'm overlooking * `10000u64` is IMHO more idiomatic than `10000 as u64`, bonus points for `10_000u64` * It might be nicer to store eating phillosophers (`(rx, tx)` tuple) in a vector. You would then iterate over that vector, until it's empty, removing a philosopher once he has finished eating.
Here is an alternative, just for the fun of it. It don't claim that it is better, but I had fun coding it :-) http://pastebin.com/xGQwbyFu
All great suggestions, thank you! Basically agreed on all points. Now to actually do that...
I like it!
Thank you.
&gt; If there are no plans to replace Servo with Gecko then what's the point? It's simply research at this point. It is to further explore the possibilities of solving difficult problems with modern development tools, practices, and hardware in mind. There's no reason that Servo, or at least the lessons/tools cultivated during its lifespan, can't be used within a future project. 
It is a research project, thats the point. If Servo turns out to be a viable strategy for use in web browsers, Gecko might be succeeded by Servo, or a different, also in rust, rendering engine. Do you have a source on the Samsung topic? I have not heard of that, but if they are, it would be quite interesting.
TVertex stands for texture vertex, but that definitely needs a comment. I'll rename fuzzy_cmp. You're right in that they're confusing. The unrelated freestanding functions aren't pub, so it shouldn't really matter where I put them. 
I'd love to have an example in the tutorial you're working on showing how to use Cargo in a multi-crate scenario. The basic setup with a Cargo.toml and lib.rs works perfectly when building one crate, but it's not entirely obvious to me how to scale that to multiple crates. (Do you still just use cargo build, e.g., from the root of a directory of folders that each have their own lib.rs and Cargo.toml?)
Ah, that clarifies it quite a bit!
The guide actually already has this, check out the 'modules' section. It's very recent, so it's cool that you missed it :) The tl;dr is that you just `cargo build` once, yes.
Awesome, thanks for info! Gotta keep my eyes peeled...
All of this is done except the vector part. The channel towards to an enum was a huuuuge improvement. Thanks again for the great suggestions!
This recent blog post might also be useful: [Calling Rust from C (and Python!)](http://harkablog.com/calling-rust-from-c-and-python.html)
R is a new language?
In addition to what other's have said, there is a lot more to performance than just compiler optimizations. If Gecko is replaced with Servo, there will undoubtedly be huge differences in code abstractions, data structures used, etc. Those differences will contribute more to speed differences (either faster or slower) than compiler optimizations imo.
Maybe we can add a line of text to the shortened link on the playpen saying that posting a shortened link to reddit will get it caught in the spam filter? That would probably solve a lot of problems without needing automoderator
Any link shortener suffers from this.
Rust as a language is a huge thing. It's C++ done right with 1/3 of the verboseness. I've never thing the software community so excited about a new language like with Rust. Even the enthusiasm for golang subsided significantly when people realised they couldn't get rid of the garbage collector and couldn't get used to the type system. If Rust is just research it means it can be abandoned at any moment. And there's a lot of people who want to write production code with it, which means it would be a pitty.
Rust is not just going to be dropped by Mozilla one day out of the blue, that's not how languages work, especially languages as popular as rust. Servo is a research project built from the INDEV language Rust, not the research language Rust. Nothing is going to happen, there are enough people interested in Rust that even if Mozilla dropped it, I am almost sure some other company would pick it up. 
But would there be enough interest for the language to evolve? You could throw programmers at it but would they be good enough to allow the language to grow? I want to commit to a project with rust given how productive it makes me compared to C++. But hearing that the language is an experiment makes me nervous.
If you're nervous, wait for 1.0. I do not think I can do anything to convince you other than saying to wait until the language is stable.
Most things do not need a runtime, and runtimes are not started automagically in libraries (there is a bit of magic in binaries, where the `main` function is, by default, run inside a runtime, but you can disable this magic by using `#[start]` to define the "raw" entrypoint). To start one, you need to explicitly call one of the functions that the runtime crates provide. If you don't start one and try to use functionality that relies on it, the program will abort. (Just BTW, `#[no_mangle]` changes no semantics, it just allows one to call a function externally using the short symbol name rather than having to write out the long `_ZN...` mangled name which would work fine.)
I think it is better to have an enum for the forks (like in /u/Bob_goes_up's version), because it is more strongly typed than just using uints. (The compiler won't allow you passing invalid arguments etc., the code is more self-documenting etc.) Similarly, it would be clearer to use an enum instead of bools, like /u/Florob0x2a suggested.
I have made both of those changes!
Hm, maybe write a macro macro_rules! lexical_ordering { ($( $ord: expr ),*) =&gt; {{ $( match $ord { Equal =&gt; {} a =&gt; return a } )* }} } lexical_ordering! { self.name.cmp(&amp;other.name), fuzzy_cmp(...), ... } (untested.)
As other have pointed out, this question was answered fairly comprehensively on the other thread. E.g. &gt; I did not even took the time to optimize nphysics very much while Bullet has some smart memory management and a hand-optimized SIMD-based LCP solver (this the part that will compute contact forces). [^src](http://www.reddit.com/r/rust/comments/2c5ax6/how_does_rust_compare_to_c_performancewise/cjcalo1) &gt; especially since it's early days for the Rust compiler [^src](http://www.reddit.com/r/rust/comments/2c5ax6/how_does_rust_compare_to_c_performancewise/cjc2lv1) &gt; There's also the issue of Rust's libraries not being as optimized as the mature languages it is put up against. [^src](http://www.reddit.com/r/rust/comments/2c5ax6/how_does_rust_compare_to_c_performancewise/cjc8iva) &gt; I rewrote the C++ one to use vector&lt;char&gt; and it dropped down to the 3 second time that rust had. [^src](http://www.reddit.com/r/rust/comments/2c5ax6/how_does_rust_compare_to_c_performancewise/cjc6w57) I.e. it's not valid to say "Rust is 2&amp;times; slower than C++" as a blanket statement since there's ample evidence of Rust programs that match (or beat) the C++ ones (without having to go to great lengths to microoptimise them). *And*, there's perfectly good explanations for why some programs are currently slower, e.g. yet-to-be-implemented optimisation (that is, implementation details/deficiencies of the current Rust compiler, not something about the actual language), or yet-to-be-optimised libraries.
TypeScript is far from popular. Mostly Qt apps mistaken for TypeScript projects, [like this](https://github.com/qbittorrent/qBittorrent). [See for yourself](https://github.com/trending?l=typescript), most TypeScripts projects in trending are actually C++/Qt apps.
Your lldb link is broken. It should go [here](http://lldb.llvm.org/).
http://www.reddit.com/r/rust/comments/2bcof3/rust_type_inference_question_functions_vs_closures/
Ah, thanks, didn't see that. Makes sense.
Servo is just a (big) project to set the viable goal for the language, and technically speaking the lack of Servo wouldn't hurt the value of Rust whatsoever. (Though practically speaking having Servo was beneficial for many things, e.g. public relations.)
I see.. Didn't realize there was no support for variable-length arrays (yet?). Thanks! I thought DST would help with that-- but after some reading it seems like it would still require a pointer.
Thanks for the tips.
Caused, apparently, by the [massive localisation files](https://github.com/bitcoin/bitcoin/tree/master/src/qt/locale).
Nothing really new here, but I find jotting my thoughts down makes things 'stick' better. If there's a better way to do something than my final code, I'd love to hear it!
Even in Haskell only the most trivial functions are left to be inferred. Once you go into the typeclass territory you'd annotate everything for your own sake. The types themselves serve as documentation.
TBH, I think these stats means nothing: 1. the heuristic approach of github to determine the repo language is far to be perfect; think just dotfiles, or think about ruby / sinatra apps where the 80% of the code is a fat jquery+plugins+what+is+cool+now. Without consider `bugs` like [typescript](https://github.com/trending?l=typescript) 2. Quality of repos. 2013, probably on the twitter wave, was the Scala year. 2014, it's the golang year 2015, hopefully rust and swift. How I determined that? I'm on github night / day for work and fun, and I'm not basing that on stars/watcher etc... but quality of software and adoption rate. 2013 saw a big amount of great Scala projects (finagle, kestrel, scalatra, kafka etc...) and I would say a bit of Clojure as well. 2014 without doubt is go lang with: (docker, nsq, martini, etcd, consul, groupcache etc...) I know some of these project started before, however they gained big popularity/business adoption later. Of course, java, c(++,#,...), javascript are kind of "stable" and the "big bosses". On the other side of top languages python and ruby went from a huge spike (especially for ruby) to a more _normal_ position, but still in the top 10. 3. Community keep in mind that not all communities are github friendly, it mostly depend on the community or the philosophy. Take for example, c#, j# most of the code is on codeplex. Take haskell, a bunch of code is on Darcs Python? They love bitbucket. 
A better way, you say? I know not whether ’tis, But it has ample fizz: http://www.reddit.com/r/rust/comments/27ziqs/some_issue_regarding_obsolete_tilde_syntax/ci5xlrq (Hmm, I probably shouldn’t attempt to rhyme. I evidently can’t do it. I should try mime.)
I was thinking more of Ocaml, where it's more acceptable to leave functions unannotated.
Currently Servo is being embedded in Chrome (by zmike, I think), via CEF. I'm not sure of the details, but the code/instructions are [here](https://github.com/servo/servo/tree/master/src/components/embedding). Gecko is a bit strongly tied to Firefox, so it's harder to seperate the two. Embedding Servo in Firefox would be hard. Embedding Gecko in Chromium mught be easier, but I'm not sure.
Actually I am not so happy about the enum of forks. My ideal code would make it easy to experiment with dead-locks in a party of 10 three-handed philosophers dining on a graph shaped table with 45 forks on the planet of Zonk, so I don't like hardcoding the number of forks. If I had used a `struct Fork(uint)` or just an `uint` or a generic type to represent a fork, then I could have added a collection of available forks to the Table struct, and I could have added a vector of required forks to each Philosopher. That would make the code more generic. The table could be initialized like this: let mut table = Table::new(vec![1u,2,3,4,5]); table.seat( spawn_philosopher("A", vec![1,2]) ); table.seat( spawn_philosopher("B", vec![2,3]) ); table.seat( spawn_philosopher("C", vec![3,4]) ); table.seat( spawn_philosopher("D", vec![4,5]) ); table.seat( spawn_philosopher("E", vec![1,5]) ); table.exec();
As a Java veteran slogging along in a PHP job, I can confirm I do appreciate type annotations in function definitions. It's great to be able to see, at a glance, what a function takes and what it returns, instead of having to make assumptions from its name or sift through its documentation. That said, I love local type inference. Saves a lot of boilerplate without losing much information, since you know the types of the inputs and you know what you're doing to those inputs. Rust's type system is very satisfying to work with. It has everything I want and very little I don't. Even in Haskell, I add type annotations to most of my functions. It avoids inference ambiguities and helps ensure correctness.
&gt; Rust was developed by Mozilla as a safe language to develop it's products with, right? I assume this is Firefox and associated products. Using Rust for Firefox is a rather hard project since Gecko is deeply tied to Firefox. Using Rust for a new browser engine? Doable, and [it's being done](https://github.com/servo/servo/). There is also some collab with Samsung for making it work on Android, probably with the intention of using it in mobile browsers. I'm not entirely sure what the future plans for this are, but it sort of works in Android at the moment. &gt; Now, Rust at the moment is 2x slower than C++, the language currently used for Firefox. As mentioned elsewhere, this takes a comment about a very specific scenario (where the C++ was optimized and the Rust was not) out of context. When I first started I did some comparison of speeds, and I found that Rust is just as fast for most scenarios. IIRC there are currently some benchmark programs that are slower, but that is fixable (not all optimizations have been incorporated into Rust? I don't know).
I personally like to have type inference stop at function boundaries; when you have a type mismatch it's easier to track down. Especially since some type mismatches occur due to derefing and String variants.
It is allowed, but you do get `unused_variable` warnings, so…
I'm not sure but I think this feature exists to minimize mutability. Rather than mutating one variable, you can redeclare it with a new value. In any case, it's not nearly as bad as it may look. The type system prevents using an int in place of a float, or string. It's true that this feature can cause bugs, but it can also prevent them. Without shadowing you'll often have to give different names to variables (of the same type), and that makes it possible to use the wrong variable. 
Why not `fn foo(mut x: int) { ... }`?
I guess it's just a matter of preference. Having mut in the function argument exposes what the function does internally.
&gt; It has a massive mindshare in the academic space 
Yes, the community can pick up the language, but will there be enough brains in the community to keep it going? $deity knows how many open-source projects languish due to the lack of TLC.
A benefit is that using a single letter for a common variable, for example `c` for drawing context. The variable can change type, which the design of [Rust-Graphics](https://github.com/pistondevelopers/rust-graphics) heavily depends on. Each method returns a new type and you can only call `.draw(gl)` when the context provides enough information to do the drawing.
It would be great if there were some lint or warning for this - I can see many people falling into this trap when rust becomes more widely used. 
I'll answer to myself, in case someone else has the same question. There is the concat! macro: let str = concat!("long long long string ", "continues without line breaks"); http://doc.rust-lang.org/0.11.0/std/macros/builtin/macro.concat!.html
I think the best argument for variable shadowing is the ability to stop an object's mutability. let mut vec = Vec::new(); vec.push(1i); vec.push(2i); let vec = vec; However, I also like it in the case of intermediate variables. Sometimes it's simply prettier to split a long method chain into two lines with let bindings. Instead of using a "let temp", you just use the variable name twice; this way the temporary doesn't clutter the rest of the function's namespace.
It doesn't particularly expose it, e.g. `rustdoc` doesn't show a `mut` there.
I also noticed this yesterday. I'd rather not have it, because it introduces hard to find bugs. I've had bugs related to shadowing in my own C++ code (just last week). Also, there have been bugs in Gecko because of shadowed local variables [1], so clearly this is dangerous. I know Rust is a language which aims to prevents bugs (even if it reduces convenience), so I am wondering why this is allowed. Is it worth the risk of having bugs? There was also a comment about having an option in lint to warn about variable shadowing [2]. Will there be such an option? I hope so. Btw. That thread has also some use cases how people use shadowing, so people interested in it should read through it. [1] https://mail.mozilla.org/pipermail/rust-dev/2013-May/004306.html [2] https://mail.mozilla.org/pipermail/rust-dev/2013-May/004298.html 
&gt; There was also a comment about having an option in lint to warn about variable shadowing [2]. Will there be such an option? I hope so. Lints can be loaded into the compiler dynamically ([relatively simple example](https://github.com/huonw/copypasteck)) including being `cargo` dependencies, so 'anyone' can write such a lint.
Thanks, didn't know that.
I've always found one letter variables a little dangerous for anything other than loops. Is it really so hard to type cnxt or similar?