Why is limn-layout not noteworthy? Limn is interesting even if just for finding out why it did not work out.
I gave it a quick try but it seems like we're getting a macro issue. I couldn't get it to work as is. I don't have time to look further for the moment but don't hesitate to give it a try, a PR would be very welcome! :)
A state machine is basically another way of 'using boolean variables and checking them'. I wanted to avoid that extra checking because the algorithm in it's purest form doesn't require it. In addition, correct me if I'm wrong, but recursion, in this case, is extra bad, for two reasons: 1) Stack space isn't infinite and there exists an input that can cause the program to recurse deep enough to cause a crash; 2) Each recursion requires setting up the stack frame, which isn't needed and basically slows the algorithm down (marginally, yes, but still).
There's a _subtle_ difference between these two declarations: - `fn a(&amp;mut self, a: String) -&gt; &amp;mut Self` - `fn a(mut self, a: String) -&gt; Self` The first one (which is your version) returns a **borrowed** value, with the lifetime tied to the `St::new()` call (which gets dropped at the end of the statement and that's why you cannot assign it to the `s` variable - everything will be dropped before the assignment). The second one, on the other hand, returns an **owned** value (with which you can do anything you want, including moving the ownership).
A state machine is the proper way to solve a problem like this. The goto is just a poorsman state machine. Every recursive algo can become iterative I was just showing how to use enums to make a state machine. It's not hard do convert this algo to iterable. You should try if it's not obvious to you. This is extremely basic stuff... Try it out, otherwise you won't learn.
Yeah well, that's what I'd wanted to try to have, since I cannot really use `'a` in `MyFut&lt;'a`&gt;` within `Future::poll` The problem is that despite 0.3, it is still difficult to make non-`'static` futures generally. I want to avoid to rely on `Box` since allocations are sad if you can avoid it
The problem is that `MyFut&lt;'a&gt;` doesn't do what you want it to do. `'a` _outlives_ the `MyFut`. If you only have the lifetime in poll (which does exist right now, it's just unnamed), then there's no way to store it in the structure. In order to make a `!Unpin` future you need to lie to the type system, use `'static` references (or pointers), and translate them into something safe with accessors that take `Pin&lt;P&lt;Self&gt;&gt;`.
Maybe https://docs.rs/diesel_migrations/1.4.0/diesel_migrations/macro.embed_migrations.html?
I think I was able to solve it using a newtype with Visitor and Deserialize impls for it. Seems to work, and only 30 LOC. Now stuck on the next issue of a date failing to parse... :D
That‚Äôs perfect, maybe I‚Äôm blind here but it should get it‚Äôs own section on the main website ü§∑üèΩ‚Äç‚ôÇÔ∏è
It was part of `diesel`, but I think it got moved out at some point.
[actix-web](https://github.com/actix/actix-web) support websockets. Here is [example](https://github.com/actix/examples/tree/master/websocket-chat)
Hyper for http, writing simple wrappers to make it handle rest calls is quite quick to do. I you want more functionality out for the box, checkout warp framework. I really enjoy it. Tungstenite for ws, hyper conns can be upgraded to ws connections
Hey, I was wondering if a package like this exists! I'm currently learning Rust but have extensive Python/Data Science/Stats experience. Can I be of assistance?
You mean something different from running `cargo clippy`?
Ha, yes. It's true that even during his time, Jim Crow, KKK America, Lovecraft was viewed as an extreme racist. Look up his cat's name.
Great writer, though!
How does it fair copying files across the network? One of the reasons I like rsync is it lets me copy between my desktop and laptop over ssh just like copying on a single machine.
I actually have a good reason to not use it: your distro's Rustup package is broken and clippy doesn't work the way it should. Even in spite of that, I try to use it whenever I can.
If you're on nightly, you can implement the state machine as a generator. It would take some restructuring since generators let you write state machines with mostly linear code, but the result can be oh so nice.
&gt; In addition, correct me if I'm wrong, but recursion, in this case, is extra bad, for two reasons: 1) Stack space isn't infinite and there exists an input that can cause the program to recurse deep enough to cause a crash; 2) Each recursion requires setting up the stack frame, which isn't needed and basically slows the algorithm down (marginally, yes, but still). The example given is tail-recursive. Nowhere does it recurse without immediately returning. As such a Sufficiently Smart Compiler^TM (which LLVM almost certainly is one) can compile this to standard gotos.
Because according to the README, ‚Äúserious bugs exist and all APIs are likely to change. Code is underdocumented and prototype quality, you probably don't want to use this (yet)‚Äù.
You are creating a streaming future. Wait for GATs (generic associated types)
I urge you to stop innovating to make room for plebs like us. Peace
As long as they don't think they should replace the utility that's better for scripts and automation, then, yeah, why not?
LSD sounds fun. I assume all output is ran through lolcat first
It doesn't implement any network protocol, only files. But you can mount another machine's file system with sshfs, that's what I usually do
Absolutely! We need all hands on deck! For ndarray-stats, you can take a look at this [issue](https://github.com/jturner314/ndarray-stats/issues/1) where we are discussing the future roadmap. Speaking of the Rust scientific/ML ecosystem at large, there are multiple opportunities to contribute: * [ndarray](https://github.com/rust-ndarray/ndarray) is the equivalent of NumPy. Long-running project, there is a [collection of open issues](https://github.com/rust-ndarray/ndarray/issues/597) as well as open PRs to be reviewed and functionality that still has to be implemented! Take also a look at ndarray-rand, in the same GitHub repo * [ndarray-linalg](https://github.com/termoshtt/ndarray-linalg) for linear algebra. Its documentation could benefit from some additional love and I am sure there are opportunities to contribute new features and/or improve the existing ones * there are ongoing discussions [here](https://github.com/rust-dataframe/discussion/issues) on how to design an implement a Rust equivalent of Pandas * I was interested in doing a new coordinated effort to bootstrap a Rust equivalent of Scikit-learn, using existing libraries for arrays and linear algebra. There have been some attempts in the past, but they are mostly unmaintained right now. As soon as I manage to set aside some time I'd like to take a stab at it and socialize the effort. &amp;#x200B; A good place to discuss these topics is the [science and AI Discord channel](https://discordapp.com/channels/273534239310479360/533004930349531136).
80 characters are the remnants of the punch card era, the glass terminal era, the PC text era, the xterm era, etc. If you have to pick an arbitrary number, 80 characters is the closest thing we have ever had to a standard. 80 characters is demonstrably plenty long enough to have readable code, and everything is tuned to do a good job with it. Well, everything but `rustfmt`, which defaults to 120. I mean, if you're going to go bigger than 80, go to [132](https://retrocomputing.stackexchange.com/questions/7838/why-did-line-printers-have-132-columns), which was the width of old teletypes and lineprinters at least. 120 characters is just a weird width to pick.
Thinking about it after having my coffee this morning, all you're doing is manual looping. So here's how to do that, imo this shows off how named loops in Rust can shine! (forgive any typos, if anyone sees a mistake I'll edit it, not trying to compile this) fn do_stuff (/* args */) { if audio_data.length() &gt; 0 { audio_data.dump_into_buffer(buffer); } let open_file = || -&gt; bool { if let Some(filename) = playback::get_resource() { while audio_data.open_uri(&amp;filename) &lt; 0 { /* stuck looping... what if the file is invalid?*/ }; true } else { false } // maybe an error would be better? } loop 'main { loop 'read_packet { if audio_data.read_packet() == EOF { if !open_file() { break 'main; } break 'read_packet; } } // loop 'read_packet loop 'decode { let result = audio_data.try_decode(buffer); if result == EOF { if !open_file() { break 'main; } else { continue 'decode; } } else if result &lt; 0 { if result != EAGAIN { break 'main; // and handle error } else { break 'decode; } } length += result; if length &lt; buffer.len() { continue 'decode; } else { length -= buffer.len(); } } // loop 'decode } // loop 'main } // fn do_stuff
Just FYI, lots of Mac bugs in Azul. It‚Äôs üëå close to 0.1 release, and I think a lot of those are scheduled for 0.2. But I can‚Äôt wait for Azul once it comes
I use 100 as a hard limit, and 80 as a target for most lines of code, an additionally as a hard limit for block comment wrapping.
Your definition of sequencing (dropping packets received out of order) is rather... peculiar :)
Thanks for saying! Let me make it more clear.
Did you report the mio performance issues you encountered?
Well, this looks slick enough to possible replace my use of [`docmatic`](https://github.com/assert-rs/docmatic) (lighter weight version of `skeptic`).
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/commandline] [Announcing ppcp: A tool for copying files and dirs with progress bar](https://www.reddit.com/r/commandline/comments/bcuagx/announcing_ppcp_a_tool_for_copying_files_and_dirs/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
No we didn't yet, because mio Windows rewrite was planned for GSOC 2019.
There is already an existing issue for Windows on the Mio GitHub, I believe. We just didn't see it until we ran into the issue ourselves, heh.
So in playing with it, it looks like there isn't a way to get this to work as a `dev-dependency`? That is disappointing but with it being so light weight, it probably won't be a problem.
Thank you for your work! Glad to see more of scipy inspired libraries in Rust.
It's a work-in-progress. Once https://github.com/rust-lang/rust/pull/59940 is merge, you'll be able to use it as a dev-dependency.
It makes sense to me for networked games stuff, since you usually only care about the most recent update on sequenced streams. Buffering packets to try to put them back in order would introduce extra latency.
Hmm, it might be possible to solve this more nicely using a procedural macro attribute. That way you wouldn't have to keep track of numbering and instead of invoking the macro for every returned value you just put one `#[future_union]` on the function.
Can you store it as a `*mut u8`, then expose it as a slice with two getters (`fn as_slice(&amp;self) -&gt; &amp;[u8]`, `fn as_slice_mut(&amp;self) -&gt; &amp;mut [u8]`)?
The rust internals thread pointed me to https://crates.io/crates/auto_enums
Ah, so it was meant to use tail-call optimisations. I haven't realized. Thx for the explanation.
Thx for the explanation. I haven't realized that was the goal.
This is very cool. Well done. I don't need to copy with mc any more for wholesome progress bars :)
I really like this idea, although[`fortune -o`](https://github.com/shlomif/fortune-mod/blob/master/fortune-mod/Offensive) is a thing. You probably want to make sure to disable these by default. I sort of wish there was a more fine-grained division of the `off` directory, since a good chunk of the stuff in there is really funny. The problem is that there's a subset that's *actually* offensive, and I'd rather not see those.
Hi Rustceans! &amp;#x200B; I am struggling to figure out why a peice of code i wrote will not compile, here it is! //this works fine struct ArrAndCount{ vec: Vec&lt;i32&gt;, count: usize, } // constructor for the above struct this works fine fn build\_ArrAndCount(vec: Vec&lt;i32&gt;, count: usize)-&gt;ArrAndCount{ ArrAndCount{ vec:vec, count:count } } // something about the if statement is not working fn sort\_and\_count\_inv(mut v1: Vec&lt;i32&gt;) -&gt; ArrAndCount{ if v1.len() &lt; 2 { build\_ArrAndCount(v1,0) }} &amp;#x200B; The problematic function is "fn sort\_and\_count\_inv(mut v1: Vec&lt;i32&gt;)" the compiler error is that the if statement (if v1.len() &lt;2) expects () but receives a struct ArrAndCount, &amp;#x200B; I am finding this compiler message rather unhelpful.
currently I've transmuted it into a \*mut u8, but surprisingly, there are few api's which play nice with those =-P
Quoting the documentation for \`Box::from\_raw\`: &gt;the only valid pointer to pass to this function is the one taken from another `Box` via the `Box::into_raw` function
Why are you creating the chunk of memory and what will you be storing there?
Ah yeah, that seems to do what I meant to propose
I'm creating it to house essentially everything in a process. I will be loading an executable into it, doing some memory rewriting, then running it.
Which is why I haven't used this. Good catch though!
Okay, so it sounds like you want a `Box&lt;[u8]&gt;`, which is basically like a `Vec` but it's missing the capacity field and cannot be resized. The normal way to make one is to take a `Vec&lt;u8&gt;` and call [into_boxed_slice](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.into_boxed_slice) on it. However this 1) requires that you have a `Vec`, whose alignment you can't specify and 2) even if you could specify its alignment, the implementation of `into_boxed_slice` might force a realloc anyway. Fortunately, there's [`std::alloc`](https://doc.rust-lang.org/std/alloc/index.html) and that contains APIs that let you allocate memory with custom sizes and alignments. And it was also recently declared legal to take memory allocated by these APIs and convert them into a `Box`. So with that knowledge and a bit of unsafe, I *thought* you would be able to make your own aligned `Box&lt;[u8]&gt;` like so: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=70384e4b2588c5e6788057fdee935e63 However, it turns out that MIRI will yell at you about this because the `Box` eventually gets deallocated with the wrong alignment parameter passed to it :( So it seems like this might not be a full and proper solution, but maybe you can use the raw alloc APIs and a custom struct to handle deallocation would work? It might be worth experimenting with some different options at least.
Earlier discussion on [users.rust-lang.org](https://users.rust-lang.org/t/sized-error-with-box-error/22748). It appears that someone wanted to fix this but got stuck on some other trait implementations that then caused overlap. Not sure if fixing the `impl Error for Box&lt;dyn Error&gt;` case alone works; might be worth bringing up.
My problem isn't really alloc of the memory. I'm currently using libc to do this (and I have to since I need to set the properties for this page so that it can be read/write/executable, that last one is the big deal). So alloc'ing a chunk of memory from rust would be awesome, but without the ability to set that chunk of memory as executable, it doesn't mean much. This is why I'm trying to take the libc granted memory pointer and known size and convert it in a wrapper into something more rust friendly.
You can use a wrapper with a safe interface, constructor to initialize the pointer and then `impl Drop` to free it through the C interface, and a method that wraps the pointer as a slice of bytes.
Perhaps this will be the direction you want: holding on to \`&amp;str\` slices of the original CSV in your structs? &amp;#x200B; [https://docs.rs/csv/1.0.0/csv/tutorial/index.html#serde-and-zero-allocation](https://docs.rs/csv/1.0.0/csv/tutorial/index.html#serde-and-zero-allocation)
I'm still very beginner (which is why mine is so verbose). But that's pretty cool though! :)
Given an NSView* or HWND that I do not own or create, can I use your API to draw to it? The use case is for application (specifically audio) extensions where the API dictates that the host constructs a window for the extension, which is handed off to the extension as either an NSView* on MacOS or HWND on Windows.
Try putting the whole file into a database. SQLite lets you put it in an in-memory or on-disk database with the ability to run complicated queries to extract the data. You can read the CSV line-by-line to add each entry to the database to reduce memory usage during deserialization, and then at the end you'll have the whole thing in one easy-to-read place.
If you have 50M entries then each line is less than 16 bytes on average. is the file compressed? Every time/memory tradeoff will be initially costly. As suggested elsewhere, using slices would reduce the memory by 1/4th (2x 8bytes). Furthermore you would save another 8bytes by using f32 and losing the padding. Now you gave 2GB. If you need to reduce it further you can calculate the initial position of each line and reparse on demand. (a line fits in cache thus easily parsable, your main dataset is random access thus probably memory limited.) Use a byte array (utf8 is variable width, indexing is linear) for the base csv and a u32 index for a total of about 1GB. Or go unsafe with pointers or (somehow) raw indexing a string). If desirable: use an LRU cache.
Which operations do you have to perform on the data?
At first, it sounds great. But switching to the `&amp;str` means that my record would be `(&amp;str, Option&lt;&amp;str&gt;, f64, u8)` = 48 bytes. 50kk = 2.24 GB + 800 MB of the original file. Ok, this is a bit unfair because I've not included the size of data (e.g. heap memory of String) in my post). Anyway, it still seems quite a lot. This idea, however, makes me think about some lazy processing - read the file to the `Vec&lt;String&gt;` and then deserialize the line whenever I need to access to fields. Much slower but reduces RAM usage significantly.
Absolutely!! This was a huge motivating factor for me writing all this in the first place! (It's ultimately for an audio/sequencing app of my own) There's an OpenWL api method, [wlWindowGetOSHandle](https://github.com/dewf/openwl/blob/master/source/openwl.h#L398)() that does exactly that.
Oh wait, I see now that you're asking about the other side of things. Yeah, one sec and let me think about that. Sorry about jumping the gun on my other reply.
I don't see any point of adding a lifetime to Pin. `Pin` is weird regarding the lifetime system, in a sense that it essentially overwrites lifetimes. Passing a `Pin&lt;&amp;&gt;` for a `!Unpin` type essentially means one should consider the object to be alive "forever until `drop()` is called". This isn't expressible within the lifetime system, since that one is more scope bound. That said `Future`s which have a lifetime are possible to implement - e.g. because they might be referencing other `Future`s or fields which have a lifetime too. There seems to be no need for changing the `Pin` signature for doing it. It doesn't work yet in traits, but GATs might fix that.
I have to read, then filter by a couple of filters (sometimes I filter our 99% of rows, sometimes 0), then group it by one of the fields, select n groups and m elements of each group. The process is basically choosing a relatively small data sample from the file basing on the user criteria.
What's wrong with a `&amp;mut [u8]`?
Wow! This is a really clever idea! Something tells me that I can definitely perform better than db, but it is highly possible that my app would become simpler if I would use db.
Yes, each line of my example is more or less 16 bytes, mostly because the `Option&lt;String&gt;` part of my struct is None. It is possible, however, that this may be much longer, I would assume that one row would never be longer than 128 bytes.
You can probably improve on the memory usage, but the query performance is hard to beat as long as you index the right fields.
For a practical solution, depending on what you're doing, use `berror.as_ref()` to borrow the underlying `&amp;dyn Error`.
Yea it's a very tricky problem and the first feature I look for when evaluating a graphics API, since very few support it. It's a tricky problem and one that nags at most of us.
Okay, so I've never written a plugin of my own, only hosts. So all I know about, is handing the HWND/NSView off to the plugin for it to open its editor window, without knowing what's going on in there. As far as I recall, there's no explicit event forwarding or anything to the plugin window. How does that work from the plugin's point of view? Is there a separate thread/runloop launched to handle the incoming win32/cocoa events? All I know about is the actual audio generation callback, called N times per second while processing. But that definitely shouldn't be touching any GUI state. At least on win32, I could see that the plugin would have to create its own WndClass / callback, create a sub-window inside the provided top-level window, and then process events on its own. All things which OpenWL could reasonably be expected to do, if perhaps with some special flags provided on window creation. Please open an issue for this on OpenWL and I'll look into this tonight. Since I'm into doing audio stuff (from the other side of things), I think this is important functionality to have.
[piet](https://github.com/linebender/piet) is the Rust alternative to yours OpenDL. It's largely unfinished, but at least something. For me, the main problem with Rust GUI (and crossplatform GUI in general) is the lack of a good text layout library. All hope for [skribo](https://github.com/linebender/skribo).
OpenDL implements CoreText, which is a very capable text layout API. It needs more work for sure, but the nice thing about my library, is that you can add any missing API methods with ~3 lines (function signature + call to native CoreText function) to the Mac version, then let me know about it, and I'll take care of the Windows/Linux version ASAP.
&gt; t: also might be nice to add the build directory to the .gitignore and just leave the CMakeLists as the top level build config file... The build system needs some love for sure, especially now that I need to seriously focus on moving to a CI system. At the moment the build dirs contain all the system-specific makefiles (Visual Studio, XCode, CLion/CMake). If/when I move everything to pure CMake, then I can get rid of the build dir or move it somewhere else as a backup build method. But for now I don't want to pollute the root dir with Visual Studio / XCode stuff. Nor do I want to give the false impression to users of those systems that they should be using a root CMakeLists.txt, which is just for Linux right now.
Use std::slice::from_raw_parts_mut.
CoreText is macOS only. And pango quolity is questionable.
You can also read the whole file into a buffer (maybe with mmap, maybe just with `fs::read`) and represent each record as a u32 offset of the start of that line in the buffer (a u32 is plenty for an 800 MB file). 50 million u32s is about 200 MB, so you're looking at 1GB total. Then you do the same thing you said, lazily decode each line whenever you need the content of each record.
Two questions come to mind: - Do the floats need to be f64 or would f32 do? Just looking at the size of each line it makes me wonder if there would be any actual data loss. - How many duplicate strings are there? You might be able to use a string pool to store each unique string only once, reducing each string ref to a single 8- or even 4-byte index into the pool. Only truly helps if there are enough duplicates to offset the overhead of the intern's map and the extra indices.
Another cool transport protocol (peer of UDP and TCP) is [SCTP](https://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol). It can use a stream concept like TCP or you can send discrete datagrams like UDP. It is a reliable transport like TCP, it supports congestion control like TCP. Unlike TCP, it can bind to multiple source and destination endpoints, in order to traverse different (potentially redundant) paths. In a single transport connection, multiple distinct logical pipes can be used to mitigate some [head-of-line blocking](https://en.wikipedia.org/wiki/Head-of-line_blocking). Also SCTP's "explicit partial reliability" can be used to expire old data in flight -- this is similar to UDP's natural latency-preserving effects of packet loss. SCTP is young relative to ICMP/TCP/UDP but it's not new by any stretch of the imagination. I think some of the concepts for SCTP ended up in [QUIC](https://en.wikipedia.org/wiki/QUIC). This library is perfectly awesome, I'm just mentioning SCTP here because it's related to the features implemented here and might be interesting to folks who would use this library.
It sounds like you are doing a database job without a database.
Hmm, perhaps you're misunderstanding what I've written here? My library is **crossplatform**. APIs are agnostic, they can go anywhere. I'm delegating to native CoreText calls on Mac, but I'm implementing / synthesizing them on top of DirectWrite/Pango on Windows/Mac. ie, CoreText Everywhere. No, it won't be pixel-identical across platforms, but the goal is pretty-damn-close. If you can show me degenerate cases -- with Pango or DWrite -- I'll be happy to do what I can to tighten it up for parity across platforms. I have it in the back of my mind that I would love to implement my own text layout library to unify / obviate the separate DirectWrite / Pango implementations of the CoreText API, but that's a massive undertaking and not something I can seriously attempt until much later. For now, they are definitely more than capable of whatever you might want to do. What don't you like about Pango specifically?
Both ideas are good. f64 would save me 380 MB. Intern would work perfectly well for the `String` part but not for `Option&lt;String&gt;` - there should be not many duplicates.
You could use a array based string implementation like this [https://crates.io/crates/arrayvec](https://crates.io/crates/arrayvec) and then do an enum between 2 structs (pseudocode) enum Line { InlinedShort(ArrayString::&lt;[_; 4]&gt;,f64,u8), InlinedLong(ArrayString::&lt;[_; 4]&gt;,f64,u8,String), NotInlinedShort(String,f64,u8), NotInlinedLong(String,f64,u8,String), } might help (you avoid pointers when non necessary). i'm not sure about the memory packing so check with stuff like that [https://doc.rust-lang.org/std/mem/fn.size\_of.html](https://doc.rust-lang.org/std/mem/fn.size_of.html) If you have a lot of redundant strings might also want to intern them (use an id to point to the same string object). (pseudocode) type InternedStringIndex = usize; enum Line { InlinedShort(ArrayString::&lt;[_; 4]&gt;,f64,u8), InlinedLong(ArrayString::&lt;[_; 4]&gt;,f64,u8,String), NotInlinedShort(String,f64,u8), NotInlinedLong(String,f64,u8,String), Interned(InternedStringIndex,f64,u8,InternedStringIndex), } concerning the packing of strings, you might want to make a giant u8 array with just the string parts of your CSV and point the backend of your String to this, or use string slices to this. A mix of all these might actually give you something lighter than the origin in storage.
Oh, my bad. I thought that this is a crossplatform wrapper. How do you handle font/glyph fallback on different OS'es? Or they are platform-dependant?
Oh, my bad. I thought that this is a crossplatform wrapper. How do you handle font/glyph fallback on different OS'es? Or they are platform-dependant?
It depends on the API. VST 2/3 provide some handlers to forward key presses to the plugin (this is done to intercept key commands, plugin signals if they consumed the events or not), not sure if all hosts support it. There's also some resizing messaging going on (size constraints, did the plugin resize, did the host request the plugin resize, etc). In AU the plugin supplies its own NSView for the host's window. You can register an account with Avid to get the AAX documentation if you care about it. IIRC on windows there's no trouble having a separate thread running when the window is created to receive window events on it, but on MacOS you need to receive events on the main (GUI) thread. I'm not an obj-c expert but I believe there is nuance in getting this to work properly. It's good that you care :D most of the time you file these issues with UI libraries and they'll respond "single page apps are most important now, we'll look into it in the future" but then the future comes and dealing with multiple event loops that the window creator doesn't control becomes difficult to manage, so it never happens.
Why can't you read it by lines? Or chunks? Do you really need all of it in memory at once?
QUIC is a really cool protocol; me and /u/dochtman have been working on a futuresy Rust implementation named [Quinn](https://github.com/djc/quinn) for a while.
Yeah, fallback is currently platform-dependent. It's my dim, dim understanding that there are ways to specify fallback behavior with DirectWrite and Pango, and when "we" (me and whoever decides to work with OpenDL) get to that point, then we can explore options to match behavior with CoreText on Mac. But for now, until there's even a functional text editor built atop OpenDL, it's kind of a distant concern. But if somebody comes along and is serious about using my library(s), and they happen to be in the text layout business, then by golly I'll do whatever I can to make it work just like CoreText proper, on Windows and Linux.
But doesnt that mean that you always have to transfer the whole state since you cant rely on the last update being known?
But doesnt that mean that you always have to transfer the whole state since you cant rely on the last update being known?
But doesnt that mean that you always have to transfer the whole state since you cant rely on the last update being known?
Is there a possibility that we can use the ndarray API/abstractions for GPGPU via a CUDA or OpenCL backend? I am wondering because it would be very convenient to be able to allow all of this existing code to work with GPU arrays as well.
But doesnt that mean that you always have to transfer the whole state since you cant rely on the last update being known?
But doesnt that mean that you always have to transfer the whole state since you cant rely on the last update being known?
&gt; Buffering packets to try to put them back in order would introduce extra latency. That's not quite accurate, unless we're counting nanoseconds. Dropping a packet does not cause anything to be delivered faster, it just deems the information in that packet irrelevant.
&gt; Buffering packets to try to put them back in order would introduce extra latency. That's not quite accurate, unless we're counting nanoseconds. Dropping a packet does not cause anything to be delivered faster, it just deems the information in that packet irrelevant.
&gt; Buffering packets to try to put them back in order would introduce extra latency. That's not quite accurate, unless we're counting nanoseconds. Dropping a packet does not cause anything to be delivered faster, it just deems the information in that packet irrelevant.
&gt;Buffering packets to try to put them back in order would introduce extra latency. That's not quite accurate, unless we're counting nanoseconds. Dropping a packet does not cause anything to be delivered faster, it just deems the information in that packet irrelevant.
It is different though, SCTP operates on the transport layer, which has its own problems. This library operates on the application level like QUIN, which makes it much more flexible. Because laminar is UDP based current operating system, middle boxes, firewalls don't have to be updated to know how laminar works, on the other hand. SCTP operates on the transport layer, not all firewalls, middleboxes, operating systems know this type of traffic and might, filter or throw away this type of traffic.
I guess you could load the entire file in memory (single `String`), use `str::char_indices` to find the newline positions. Since a `u32` is sufficient to index your string, you can add `1` to all those positions (include index `0` if your file has no header. Omit the last index when your file ends in a newline. Then write a function that can translate a reference to your input (`&amp;str`) and the starting index (`u32`) to the line. You can now perform all your operations on the indices, retrieving and parsing the lines on demand each time (use `(&amp;str, f64, u8, Option&lt;&amp;str&gt;)` to avoid allocating!). This way you only need an additional 50M * 4 ~= 200MB of additional data in memory. It seems to me that you can avoid most of the reparsing by walking over the indices a single time, and for each entry perform all the filters. Immediately add passing entries to the correct group.
How long lines you fit has nothing to do with screen size. Lots of people get larger screens so that can fit more code side by side, not longer lines I want to fit ideally 4 windows side by side. 2 code + terminal + debugger
SCTP can be, and routinely was, implemented in user-space atop UDP, as is documented in the RFCs. In fact, this is exactly what WebRTC uses.
&gt; Buffering packets to try to put them back in order would introduce extra latency. That's not quite accurate, unless we're counting nanoseconds. Dropping a packet does not cause anything to be delivered faster, it just deems the information in that packet irrelevant.
&gt; Buffering packets to try to put them back in order would introduce extra latency. That's not quite accurate, unless we're counting nanoseconds. Dropping a packet does not cause anything to be delivered faster, it just deems the information in that packet irrelevant.
Minor possible typo: When talking about the implications of varint to usize conversion, you call out the max advisable value as `(2 &lt;&lt; 32) - 1`. Shouldn't this be `(1 &lt;&lt; 32) - 1` or `(2 ^ 32) - 1`?
Hmm.. Perhaps replace the `Option&lt;String&gt;` with `Option&lt;Box&lt;String&gt;&gt;` if it is mostly null? Or with an i32 index into a Vec with strings, negative meaning empty?
&gt; runtime-loading of plugins with a stable ABI in Rust If that's all you need, traditional dynamic libraries with the C ABI will be a lot easier.
QUIC is nifty, and Quinn is a very nice implementation. There's a lot of feature overlap; we considered using it. QUIC's strategic focus, though, is to improve perceived HTTP performance, and things that would otherwise utilize TCP. Laminar's only concern is gaming. Either should be an improvement over stock TCP for most games. =)
&gt; QUIC's strategic focus, though, is to improve perceived HTTP performance This is a misrepresentation. QUIC is intended and effective as a fully general-purpose protocol.
Er..I believe you. You may want to update Google and the IETF WG docs, though.
Regarding the Option&lt;String&gt;, if a reasonable % of the values are None, you're better off with Option&lt;Box&lt;String&gt;&gt;, I bet. 8 bytes plus 1 (though maybe box implements the optimization to store None as null). Trade-off is it's now 32-33 bytes per actual string, but only 8-9 for None. And you might save a bunch of padding (not sure offhand).
Is there a particular current document you're confused about?
It's not. I'm a Python programmer who came to Rust for the improved compile-time safety guarantees. I currently stick to doing plugins using [YAPSY](http://yapsy.sourceforge.net/) in either pure Python or `rust-cpython`-based apps and, if `rust-cpython` didn't exist to compile-time check the memory-safety of my FFI calls and ensure that runtime type checks are generated, I'd stick to working purely in Python for stuff that needs plugins. I do *not* trust myself to work with `unsafe` and the amount of time I spent auditing a single, simple call to `access(2)` to bail out early if given an unwritable destination directory does *not* scale.
Rocket + nginx should do the Job. Its extremely convenient to write a REST API in there. It also takes care of multi threading, so ya clearly u could achieve theoretical better performance with these bare bone libs, but for ur purpose these should be just fine.
I respect the aversion to unsafety, but you're opting into a *lot* of complexity, and indeed library-resident unsafe code, just to avoid a few mildly hazardous pointer conversions.
Yup, I was thinking it was going to be very similar to QML. Since we can assign a name to a widget, it becomes easy to refer to widgets in the application. This way, the program doesn't change - only the layout does.
As long as someone else who I trust more than myself is responsible for it, library-resident `unsafe` code isn't an issue. Also, you seem to misunderstand. All of my projects are either I/O-bound, or rely on compiled Python modules to do the heavy lifting. `unsafe` for anything more than a trivial API call or two is far more cognitive overhead than just dealing with the old, familiar solution of writing something in Python and wrapping as much as possible in `try`/`except` blocks to ensure the main program remains chugging along without corruption, even if it means a unit of work has to be logged as "Failed. Please fix the big and re-submit."
Hmm. I believe HTTP (or HTTP/2) is listed as the first goal in the latest draft of the charter. One moment, I'll have to google, it has been awhile... &amp;#x200B; Ah yes: &gt;Key goals for QUIC are: &gt; &gt;\- Minimizing connection establishment and overall transport latency for applications, starting with HTTP/2; &amp;#x200B; From [https://datatracker.ietf.org/wg/quic/about/](https://datatracker.ietf.org/wg/quic/about/), which is linked off the main page [https://quicwg.org](https://quicwg.org). It doesn't \_seem\_ terribly confusing to me; given the incubating nature of QUIC, I expected a lot of change as it finds its way. There's also this: &gt;Our initial documents cover different aspects of the ‚Äòcore‚Äô QUIC protocol, and also define a mapping of HTTP semantics to it. &amp;#x200B; I'd also suggest updating wikipedia, as the third paragraph starts with: &gt;QUIC's main goal is to improve perceived performance of connection-oriented [web applications](https://en.wikipedia.org/wiki/Web_application) that are currently using [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol).[\[1\]](https://en.wikipedia.org/wiki/QUIC#cite_note-LWN-1)[\[9\]](https://en.wikipedia.org/wiki/QUIC#cite_note-9) &amp;#x200B; I did a quick google search to see if there had been a shift since I list looked at QUIC last year. The verbiage and use cases talked about revolve around HTTP and web applications. Combine that with the official documents seemingly prioritizing it, I'm sure you can see why people not intimately involved in these drafts might end up confused. That perception certainly isn't a negative thing, and it even makes sense as HTTP is used much more than a gaming-specific protocol. If the IETF WG wants people to think of QUIC as a fully general-purpose protocol (though that term is vague enough in terms of capabilities and limitations I'm not sure it has much meaning), that intention and associated information should at least be discoverable, don't you think?
Arent things skipping out on loading bars usually meant to be quicker?
String is a wrapper of Vec, which stores 2 `usize` fields for length and capacity and a pointer. On a 64 bit platform, that's 24 bytes. Since your file is less than 4GB, you know that you don't need 64-bit numbers to hold the length and capacity values, so you could make a version that used `u32`s instead and was only 16 bytes. In fact, you could replace the pointer with a 32 bit index into a buffer and bring each string down to 12 bytes. And since you aren't modifying the values in place, we can have tight allocations and only store length without capacity. Now each string is 8 bytes (32 bit index and 32 bit length). To eliminate wasted padding for alignment, you could switch some or all fields to a column based format (structure of arrays). I think this only makes sense for the u8 in this case. Then for the Option&lt;String&gt;, we could instead make it so that if the length is `u32::max_value()`, then it's actually a `None` for our custom string representation. All together, this brings it down to 25 bytes per record (no padding). The dynamically allocated string data should also be smaller since it's all tightly packed in one arena instead of having separate allocations. I wrote some (untested) example code in the [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f2a1a711632bbea153780df67ddf6436) to help illustrate the details.
Given that you're mandating running on the same port, actix is probably your best bet if you want to stick to Rust alone. If you're willing to use something like nginx, I've recently implemented a decent size REST API with Rocket and ws-rs.
That's pretty much where I'm at for _any_ language. I have VS Code set to display a line at 80 and at 100. Never go past the second line, try to keep it by the first.
Do all your filters require having the whole input in memory? Is it possible to just stream the input?
A few ideas in addition to what others have given: - use structure of array (SoA) representation to avoid padding - if using SoA, use a sparse map for the optional strings if they are uncommon - use Box&lt;str&gt; instead of String - use a small string optimization (use an enum for the string that has a Box&lt;str&gt; variant for large strings, and a u8 array for small strings)
Stalin sequencing.
By not using the db you will end up inventing your own db. It doesn't have to be SQLite, there are plenty of embedded dbs. You can also remove padding, use `mmap(2)` to process the file in chunks. I don't know nature of your actual problem, but when I had to process 1/4TB of cvs, I just set up large swap on ssd in addition to 32gb of ram I already and used ruby. Didn't take as much time as you would imagine.
The desire to read all file at once usually comes from not having a desire to not have to implement batched/distributed map/reduce. Been there, done that.
Is the code below safe, and if so is there any existing library that wraps the unsafety? fn slice_to_bytes(s: &amp;mut [u16]) -&gt; &amp;mut [u8] { unsafe { slice::from_raw_parts_mut(s.as_mut_ptr() as *mut u8, s.len() * 2) } }
Exactly. The posix tools were simple so they're perfect for chaining together for scripts. GNU deviated from that simplicity by adding a lot of flags but the core was still simple. This new wave of command line tools is wonderful for interactive use but we still need the old simple tools for composition
At that point you might as well give up and use async/await üòõ
Convert the AOS to SOA should improve the most, but I'd like to offer two easy improvements to reduce the string size: 1. Once you have lots of small strings, eg length &lt; 7, using https://docs.rs/tendril/0.4.1/tendril/ will reduce the size by inline the str in stacks without using heaps. 2. If you have lots of string but many duplicates, using https://docs.rs/string_cache/0.7.3/string_cache/ will reduce the size by pushing them to a hash table and share string using a pointer
Similar to Stalin Sort? Knock out everything not in order. O(n)!
Just curious, but whenever I evaluate a low level network library, I always want to know a couple of things about it: 1) Do you send any packets that aren't explicitly requested by the user (keep-alive, pings, etc.)? 1a) If so, how frequently and how big are they? 2) If the user wants to send a datagram of 100B, how big will the resulting packet, as sent by Laminar, be in size with header overhead? 3) Does the library require running on its own thread, or can it be polled synchronously as part of a game update loop?
The tail-calls will be eliminated but it doesn't generate the same code as using gotos. [Here](https://godbolt.org/z/aN3llv)'s an example that calculates the number of steps to reach 1 in the Collatz problem, in C++. Note that if n is odd, then 3n+1 is even, so you can jump straight from the end of the odd case to the even case, and indeed, this is what the assembly does (GCC actually just lays the basic blocks out adjacently). [Here](https://godbolt.org/z/1KZTzT)'s the equivalent Rust with your state machine suggestion. The compiler was not smart enough to eliminate the `state` variable and actually thread control straight from the end of the odd case into the even case; it goes back through the global dispatch code.
Dang, miow still has performance problems? Three years ago when I was using it, it would randomly stall localhost sockets in an unrecoverable way.
What you need is an existential type to tag the queue families with the logical device it belongs to, so the operation to move from one queue family to another can demand that the old and new queue families belong to the same logical device. At the moment the only existential type Rust supports is `Self`. Scala's Path-dependent types provide a form of existential typing that would help your use case. I don't know anything about the Vulkan API but I imagine it would look something like this: val ld: LogicalDevice = new LogicalDevice(...); val qf1: ld.QueueFamily = ld.newQueueFamily(...); val qf2: ld.QueueFamily = ld.newQueueFamily(...); val r: ld.Resource = qf1.newResource(...); r.moveTo(qf2); // r.moveTo() can demand a parameter of type ld.QueueFamily, a QueueFamily belonging to the same logical device
Are you familliar with KCP protocol. If so why not use that?
Can you pipe it with, for example, dd?
Hi everyone! This is my first Rust project. Feedback and contributions are highly welcomed!
Is there a reason you need to store all 50 million records in memory?
I've seen some utilities which act with all the fancy stuff when used alone. But when it gets piped to another switch to plain old output format.
It's possible, but people have thrown a _lot_ of time at optimizing database queries. You're doing a DB query, so starting with an actual database seems like a good idea. Then you can use that performance as a baseline if you want to improve something.
I'm confused with your repository organisation
I still think about your project. I think it's so cool.
Actix-web is great! It would definitely be my choice of framework. I like the ergonomics, and it's hard to beat the performance.
The rust directory contains crates. Element is a crate.
I can see how those statements might confer the wrong impression. That said, note that the IETF documents you cite specifically present HTTP as a *model* problem. In any case the charter is dated more than two years ago; there was discussion of a near-term recharter to reflect the increased interest in real-time applications at IETF 104 in Prague last month, so hopefully this will be made more obvious soon. QUIC solves a number of fundamental transport problems, affecting HTTP along with practically everything else that flows over the public internet. For example, the working group is also exploring [mappings of DNS](https://tools.ietf.org/html/draft-huitema-quic-dnsoquic-06), specifically calling out [the latency benefits](https://tools.ietf.org/html/draft-huitema-quic-dnsoquic-06#section-3.3) of doing so. &gt; I did a quick google search to see if there had been a shift since I last looked at QUIC last year. There has indeed been no shift since last year; a general-purpose protocol has been the formal objective for years, if not from the very beginning. It's unfortunate that a Wikipedia editor is mischaracterizing the effort, but not unusual; I would not recommend Wikipedia as a technical reference on any subject. &gt; that term is vague enough in terms of capabilities and limitations I'm not sure it has much meaning If you're interested in the specifics, the RFC lays out the capabilities and limitations of the protocol in exacting detail. It is, however, still useful to be able to describe the general intention in a few words. &gt; that intention and associated information should at least be discoverable, don't you think The normative RFC is explicit here, both in the wording of [the introduction](https://quicwg.org/base-drafts/draft-ietf-quic-transport.html#introduction) and in the technical details themselves. What better place than the authoritative document?
Okay rustceans! I am having trouble solving this problem in rust I have a text file called "numbers.txt" and it looks something like: 1 4 3 How would i go about opening the text file and then looping through the text file adding each line entry into a vector, so ultimately I would like to end up with a vector containing three elements (0,4,3). &amp;#x200B; Apologies if this seems rather trivial, I am very unfamilar with the rust syntax and cannot perform basic i/o easily :(
Thanks, was looking for some pretty PCP.
&gt; If the user wants to send a payload of 100B, how big will the resulting packet, as sent by the library, be in size with header overhead? Out of curiosity, what's the motivation behind this criterion? If you're only sending 100-byte payloads, I'd imagine either you're sending them frequently enough to batch them together into larger packets, or infrequently enough that even a very large overhead wouldn't represent an unreasonable resource drain on an absolute scale, unless you're on an extremely low-power device.
&gt;Does the library send any packets that aren't explicitly requested by the user (keep-alive, pings, etc.)? Laminar runs entirely over UDP, which has no concept of a disconnect event. We deal with this by tracking the time since we last saw any packet from a client. If that time exceeds a certain length (which is configurable), we generate a Disconnect event and pass it up to the application layer, which will handle it however it wants. The library itself does have a heartbeat packet type, which is just an empty packet, that can be sent. If you code a client that only sends data infrequently, you might want to use the heartbeat. If you are sending a stream of position updates, there might be no need to use it. So I think the answer to your question is, yes it can, if the developer wants to use them. &amp;#x200B; &gt;1a) If so, how frequently and how big are they? Frequency is configurable. The size would be the minimum UDP header size, which I believe is 28 bytes for IPv4, plus the Laminar header which is 8 bytes, for a total of 36 bytes. The packet type is encoded in the header, which is in the payload field of the UDP datagram. /u/Daposto can correct me if I am wrong on the exact size. &amp;#x200B; &gt;If the user wants to send a payload of 100B, how big will the resulting packet, as sent by the library, be in size with header overhead? A minimum of 136 bytes, I believe, assuming that you mean the UDP packet header overhead when you say header overhead. &amp;#x200B; &gt;Does the library require running on its own thread, or can it be polled synchronously as part of a game update loop? It does use its own thread. We give the application layer an mpsc channel end, and send received packets that way. You can use either the synchronous or asynchronous methods (recv and try\_recv) to get them. &amp;#x200B; Hope this answers your questions! Let us know if you have more.
You've got a superscript 2 but no footnote 2 afaict?
I doubt you would perform better than a DB. Or yes, maybe if you implement your own DB system because that's what you'll have to do in the end for this kind of use-case. But would the cost of development be worth it?
I think you can fake this. Here is an [example playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=95a2f0224e722241f972f259266f2534) showing a compile error when a queue is used with the wrong device. You give each device a unique type parameter (a unique type implementing `LogicalDeviceTag`). Then operations on a queue can assert that the device and queue have the same type tag at compile time using parametric polymorphism. The reason this is fake, is that there is nothing stopping you from giving 2 devices the same tag, which would let you use their queues with each other. If you can maintain that uniqueness constraint manually, then the compiler can do the rest itself.
By any chance do you have link to associated issue?
Hi! I had a somewhat similar situation a while ago. https://www.reddit.com/r/rust/comments/8ur32t/is_there_a_zerocopy_csv_parser_for_generic_csv/ tl;dr you can use csv-core to parse the file lazily and copy each row into a buffer. the buffer can be reused, making heap memory used constant size. The copying is needed to escape string data. If you filter a lot this saves you much, as you don't need to have all records in memory. If you don't, however, you might want to use a db as others have suggested.
You‚Äôre right, that should work fine.
You missed out on naming it pcp.
&gt; In any case the charter is dated more than two years ago; there was discussion of a near-term recharter to reflect the increased interest in real-time applications at IETF 104 in Prague last month, so hopefully this will be made more obvious soon. Great! However, it is the most up to date charter available and is the one linked off of the QUIC page. I think it is perfectly fair to go by it. &gt;QUIC solves a number of fundamental transport problems, affecting HTTP along with practically everything else that flows over the public internet. For example, the working group is also exploring [mappings of DNS](https://tools.ietf.org/html/draft-huitema-quic-dnsoquic-06), specifically calling out [the latency benefits](https://tools.ietf.org/html/draft-huitema-quic-dnsoquic-06#section-3.3) of doing so. That's great and all, and when/if QUIC takes off, I'll happily use it where appropriate. When I put on my network-game-dev hat, though, I only care if it performs better for my game, and if it is worth the cost of adoption. Trying to keep up with draft protocols, in my experience, is usually a full-time job. &gt;It's unfortunate that a Wikipedia editor is mischaracterizing the effort, but not unusual; I would not recommend Wikipedia as a technical reference on any subject. I mean, it seems to line up with what is put out by the WG's own charter, so I don't know that I'd call it mischaracterizing. It might not line up with what *you* think the goals are, but that seems to be more a matter of internal misalignment within the WG, which I'm assuming you are a part of? As far as not recommending Wikipedia as a technical reference...come now. =) First of all, that isn't a technical reference. Second of all, if you believe it is in error, why not edit it? &gt;If you're interested in the specifics, the RFC lays out the capabilities and limitations of the protocol in exacting detail. It is, however, still useful to be able to describe the general intention in a few words. Yes, I've read it. Again, QUIC is nifty, and Quinn is a nice implementation. I hope it takes off. &gt;The normative RFC is explicit here, both in the wording of [the introduction](https://quicwg.org/base-drafts/draft-ietf-quic-transport.html#introduction) and in the technical details themselves. What better place than the authoritative document? The list of key goals in the most up to date charter on the official site of the effort. ;) But seriously, what is your goal with this discussion? From what I've seen in previous discussions with you, you want to evangelize QUIC and are invested in it. That's great! But please understand that the public perception matters, and right now, you're essentially saying "ignore all that official documentation stuff and believe what someone says on reddit". I mean, really, why would you waste my time, and yours, by asking me to tell you what documents informed my ostensibly incorrect opinion so you can "absolutely correct them", only to end up telling me I shouldn't have believed any of those documents, including the ones put out by the authoritative group? Did you just want to argue?
Nice. I went the lazy way and just made a Vim keybinding that calls Emacs in batch mode(aka invisible mode) and makes it create the PDF. Although by now it's a small tool that can also call Pandoc or export all source code blocks into separate files.
I would not use it, at least not if you're serious about UI layout - the core algorithm is O(n ^ 3), which starts becoming more and more expensive if your app grows. If you have 1000 constraints, and you add a new constraint (you can't bulk-insert btw.), the library will to 1000 * 1000 = 1.000.000 lookups and re-calculate and check all previous constraints. I originally used it for azul (see video, done with cassowary at the point of recording), but then quickly changed it to a custom layout engine, because I tried to layout a table with several thousand cells using cassowary, which didn't work too well: inserting 9 constraints took 46.014¬µs inserting 128 constraints took 970.096¬µs inserting 128 constraints took 774.388¬µs inserting 128 constraints took 763.029¬µs inserting 326 constraints took 8.564865ms inserting 326 constraints took 8.411094ms inserting 326 constraints took 8.340325ms inserting 5210 constraints took 23.067891611s It's really not an efficient algorithm, the only way cassowary is better than the [simplex algorithm](https://www.youtube.com/watch?v=8_D3gkrgeK8) (which it is derived from), is caching the constraints. However, because constraints are "weighted" (with an arbitrary weight like "1", "10", "100"), it quickly becomes a debugging nightmare. When it evaluated 5210 constraints , all I got was a blank screen in the end with no way to be able to see how this result was calculated. Constraint caching also leads to worse testability, due to side-effects. Right now I'm using a 4-pass layout (width first, then height, then x-position, then y-position) with a width-in-height-out algorithm, works okay, but still kind of wonky sometimes.
Rust also optimizes `Option&lt;String&gt;` ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=65c2fcf599af9be8cb2278b20d533b6f)). Additionally with Box it you would have to go through two layers of indirection instead of one.
It's because standard library uses thread-local storage. macOS treats dylibs that use thread-local storage as non-unreloadable, i.e. calling `dlclose` on them is a no-op. This is the related issue: https://github.com/rust-lang/rust/issues/28794.
Are you doing this with mmap? If that's the case, the [`memmap`](https://crates.io/crates/memmap) crate provides an idiomatic and memory safe interface to it that doesn't require assuming the size of a void pointer. As a bonus, it also handles platform differences so it should work on systems like Windows. In the future, before reaching for libc or a direct C library, try looking for a crate that does what you need. Adding third party libraries is incredibly easy in Rust and there are a plethora of libraries for various tasks in a wide range of domains.
I'm choosing random data sample. User defines the size and some filters. I have to group items by String field, then choose n groups and m items from every group. I also try to keep my application as simple as possible.
Well that was simple. Thanks!
I doubt that I'm inventing DB. All I have to do is read the file, filter out some rows (depending on the user, 0 to 99% of items may be filtered out), then group by one field, choose n groups and then choose m items from every group. That's all. DB sounds like an overkill.
I don't think there has been an active effort in this direction, but it would probably be worth it to open an issue on ndarray to discuss it.
Yup! I combined the two :D. I'll fix that shortly, thanks!
Will you write a org-mode spec as you go? Will you write a test suite of example org files?
&gt; arbitrary weight like "1", "10", "100" This is an inherited idiosyncrasy from the chain of implementations (in different languages) that led to the one we see in the crate. The latest iteration of the whitepaper (December 2001) calls for symbolic weights and lexicographic ordering - which is even less efficient, but at least is correct, and not dependent on specific variable range. &amp;#x200B; I have tried using this crate, but after taking a look under the hood decided to re-implement parts of the algorithm from the whitepaper. Ultimately, requirements changed - a linear solver can't handle rotation without some clever (and inefficient) coaxing, so I switched to local propagation; in my case this is sufficient. &amp;#x200B; Looking at the source, it appears to be more or less a direct transcribing of Kiwi implementation (which the crate is said to be heavily based on), up to verbatim copying of internal documentation. There is a global variable, and heavy dependence on reference counting - not all of which is atomic. &amp;#x200B; In practice, solutions provided by the algorithm are non-deterministic (somehow, my implementation did this too) in all but most meticulously constrained problems - crate's example does state that. This means that even the simplest layouts require dozens of constraints, many of which will need recalculation on every change (if they don't then the layout is not constrained enough to resolve smoothly from change to change). I don't have numbers to back any of this up, so, YMMV.
Some observations: your rows are 16 bytes on average. Losing three commas and one newline that's 12 bytes of actual data. Clearly that means you want to avoid any indirection or pointers since that will quickly blow the budget. Even the f64 is therefore likely to just blow it immediately. I suspect there is significantly more structure in the data than you're letting on. What's the range and precision of the numbers? That's actually in those very short strings?
That's pretty cool! I know rust and I use org so if the stars align I might even contribute. Do you have some, help wanted or good first issue?
IM STILL CONFUSED AS TO WTF ORG IS. Is it similar to Markdown? Or is it a Lisp?
If you don't need to modify the `String`, you can use `Box&lt;str&gt;` instead and save one `usize` (the capacity). You can use the `into_boxed_str` method on string for that.
Basically Markdown.
Can you do all this filtering and grouping of rows straight from the original 800mb blob of data, and only store the results of that process as separate row structures?
It can make sense, it just depends. There are roughly two types of streams^1 : - snapshot streams: each message is a snapshot of the state, only the latest matters. - delta streams: each message is a delta from the previous one. The nice thing about delta streams is that deltas can generally be encoded in smaller messages; however you need the full stream from the latest snapshot to figure things out, so dropped messages and out-of-order messages must be dealt with. The nice thing about snapshot streams is that each message is independent from the others, and only the latest matters; however this usually comes at the cost of redundancy. There are usecases for both streams, and as you note there's an exact mapping between the snapshot/delta I talked about here and the sequencing/order as presented in Laminar. ^1 *You can mix and match, to a degree.*
I wrote websocket-lite and the `MessageCodec` is here: https://docs.rs/websocket-lite/0.2.2/websocket_lite/struct.MessageCodec.html Likewise the web socket crate has an equivalent `MessageCodec`: https://docs.rs/websocket/0.22.3/websocket/codec/ws/struct.MessageCodec.html Both crates can also create a websocket client from any `Read+Write`. (Why did I write a new crate the exposes the same functionality as the existing websocket crate? Because I didn't want to allocate any memory after establishing the connection, to allow the lowest overhead possible.)
&gt; fallback is currently platform-dependent. It's my dim, dim understanding that there are ways to specify fallback behavior with DirectWrite and Pango You heard about font-kit? https://raphlinus.github.io/rust/skribo/text/2019/04/04/font-fallback.html
I am confused why there are only partial and incorrect answers here, since there are quite elegant tools in Rust to solve this problem. First of all, using either Box or Vec for this is wrong, ignore any suggestions doing so (the reasons have partially been stated, see the documentation of Vec::from\_raw\_parts and Box::from\_raw). &amp;#x200B; This is what you want to do: &amp;#x200B; * Expose the data to safe code using slices. * Do so using Deref. &amp;#x200B; Slices are made precisely for your use case. And deref makes using your type very convenient, since all slice methods are automatically available (and there are lots of slice methods). &amp;#x200B; Here is a playground example: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=505e7a54f5191cf552870a45f02d14e1](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=505e7a54f5191cf552870a45f02d14e1) &amp;#x200B; You can also add the standard from\_raw, into\_raw and as\_ptr and as\_ptr\_mut methods that the std tools like Box and Vec have. Keep in mind however that modifying the memory through any means other than a &amp;mut reference to your wrapper is undefined behaviour. In particular, this is undefined behaviour: &amp;#x200B; fn modify(m: &amp;MyMem) { // We have a non-mutable reference to MyMem, we get the // pointer, then cast it to a mutable pointer and deref it. let mem = unsafe { &amp;mut *(m.as_ptr() as *mut _) }; // mem is now of type &amp;mut [u8]. modify_inner(mem); } fn modify_inner(m: &amp;mut [u8]) { unimplemented!(); }
line width is not about how many chars you can fit into your screen, it's about how comfortable you can scan/read it with your eyes.
[grimwhisker](https://www.reddit.com/user/grimwhisker) you are almost right. One thing to notice here is that laminar is having different headers for different packet types. So a header could vary on the packet type you sent. Which packets types can be sent? Please give this [section](https://amethyst.github.io/laminar/docs/reliability/reliability.html) in our book a look. &amp;#x200B; Our [technical documentation](https://github.com/amethyst/laminar/blob/master/docs/technical/hearder_design.png) has a nice diagram showing the size and headers which are appended to certain packet types.
I must say this Readme is one of the best examples of a ‚ÄûMotivation‚Äú for a project that I have read yet.
That is because [orgmode](https://orgmode.org/) is a lot of things. It is first and formost a markup language (similar to markdown) and an emacs-mode to work with the markup language. It can be used for literate programming, managing TODOs and a lot more. Since everything is stored in plaintext files (with .org extention) it should be really portable. Unfortunatelly there is only really one library that deals with all the aspects of org-mode: the emacs-mode itself.
Probably just a number he pulled out of his hat to ask how much data Laminar adds to packets.
This is nice, ideally it would be good to have codec in a separate crate, but since you already put unecessary deps, for me, under optional it works too.
There is somewhat of a spec already here: https://orgmode.org/worg/dev/org-syntax.html
Yep, for the pure codec part, the only dependencies should be bytes and tokio-codec itself.
Yeah ripgrep does this. But it's an old trick. Even something as simple as ls engages in this bit of trickery. (Running ls in your terminal will by default put many entries on one line. But using it in a pipeline will put each entry on its own line.)
There's also [https://github.com/snapview/tungstenite-rs](https://github.com/snapview/tungstenite-rs) which I think doesn't handle any IO itself, you can use it with whatever you like. From the readme: It allows for both synchronous (like TcpStream) and asynchronous usage and is easy to integrate into any third-party event loops including MIO.
If you're doing a uniform sample, I think you can process it line-by-line, using memory (approximately) proportional to the final sample by using an "on-line" sampling algorithm: https://en.m.wikipedia.org/wiki/Reservoir_sampling I suspect you should be able to reservoir-sample both the groups and the elements within them.
sqlite is a good way of approaching this, but to work within Rust alone you can do a good job using the SOA method which multiple folks have suggested works very well and you can use it for strings too by storing indices in one big string. To be more precise, you can do: struct Data { string_buffer: String, // the concatenation of all the strings for column0 and column3 column0_starts: Vec&lt;u32&gt;, // start indices in `string_buffer` column0_lengths: Vec&lt;u8&gt;, // the length of each string in `column0` column1: Vec&lt;f32&gt;, // or `f64` if you really need it. column2: Vec&lt;u8&gt;, column3_starts: Vec&lt;u32&gt;, // `u32::MAX` for `None` column3_lengths: Vec&lt;u8&gt;, } As you parse the rows, use `.push_str` into `string_buffer` to add things from `column0` and `column3`. In addition to the string data, each record ends up being 15 bytes / record (19 for `f64`). Make the `length` members `u16` for longer strings, and you go up to 17/21 bytes. In the best case this is 750MB on top of the string data. You can avoid storing the `string_buffer` entirely and instead [memory map](https://docs.rs/memmap/0.7.0/memmap/) the file, then interpret `starts` as offsets into the memory mapped `&amp;[u8]`. Or you can just `file.seek` + `file.read` the strings when needed, if the read latency for str-s is not a big deal.
it's protocol part is too coupled with IO object. Since I'm using hyper I'd prefer something that is more tokio-codec friendly
Since when did /r/rust get political? Shall we start making jokes on dead women and children in the middle east because of the US war crimes?
Wouldn't this be a perfect use case for PhantomData?
One thing I would suggest is try to use [https://github.com/BurntSushi/xsv](https://github.com/BurntSushi/xsv) to identify unique strings and generally query the data before transferring to a database. Table data is rarely completely random so maybe there's only a certain set of strings used. If that is indeed the case then an enum to represent them will massively reduce your problem space. Even if the string's aren't compressible, there is bound to be some structure that might be representable in a few enums perhaps.
You only need to declare them using `mod` in main.rs. Then, the other can do for example `use crate::core;` to get it into the local namespace.
An enum is the size of its largest element, so both of those are at least as large as the OP's original encoding due to `NotInlinedLong`. If the data most commonly falls into the short variants, `Box`-ing the other larger variants may help, but only if it is unbalanced. For instance, this one might be: enum Line { Small(InternedStringIndex, f64, u8), Large(Box&lt;(String, f64, u8, Option&lt;String&gt;)&gt;) } This would even better with a smaller type for the interning index too: `Line` could be as small as 16 bytes.
It's a runtime that allows you to run code that has been compiled to run on WebAssembly. This means you can run webasm outside of a browser.
This can be done line-by-line without having to have the whole thing in memory! https://en.m.wikipedia.org/wiki/Reservoir_sampling https://stackoverflow.com/questions/4340380/how-to-keep-a-random-subset-of-a-stream-of-data
Then I get "no core in root". What exactly should be there? I tried to find it, but I'm confused about it and google didn't exactly help. main.rs: extern crate clap; use clap::{App, Arg}; pub mod lib; pub mod syntax; pub mod core; ... lib.rs: use std::fs; use std::io::stdin; use std::io::Read; use std::error::Error; use crate::core; ^^^^^^^^^^^ no `core` in the root It's error `E0432`. When I asked rustc to explain the error, it said that I might have wrong relative paths. So I tried to use `super::`, `self::`, or `self::karel::` (`karel` is name of my project), none worked.
Yes, this is not a simple single-crate layout and I chose it drawing inspiration from these repos: https://github.com/xi-editor/xi-editor https://github.com/rust-lang-nursery/futures-rs The rationale is it likely be more than one crate in the long run and not only rust code (some glue is inevitable, check xi-editor for example)
I was thinking the same, but I doubt you can use reservoir sampling for the groups themselves, only their content.
While this is definitely outside of the scope of org-rs I entertain that idea. But it will be definitely very hard. I do not have the education for this kind of stuff - I have a dragon book on my table (https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools) but reading it blows my mind. Nevertheless I am willing to help with knowledge I gained anyone who is more apt with the "science"
Yes, and there is also https://orgmode.org/worg/dev/org-element-api.html. These and 2 are my permanently open tabs. But I must say that without reading the source code they are quite cryptic, and full of overloaded terms and confusing. I started org-rs hoping that they will be enough. Boy they are not..
&gt; If you need to reduce it further you can calculate the initial position of each line and reparse on demand. This is exactly what the [`csv-index`](https://docs.rs/csv-index) does. It's also one of `xsv`'s secret tricks for processing large CSV data in parallel _correctly_.
Thanks for noticing, I'll fix it. I refactored readme a bunch of times and forgot to remove it. There I wanted to leave a note something like this - I think that while using elisp source code is crucial for parser, it is less important for other things that build on top of it. So as after parser is finished I hope there will be less need to follow elisp source. I personally hate reading elisp :)
Any kind of help is highly appreciated. Check out contributing guide. The next steps I am planning to take are "parse-objects" function or functions that "current-element" calls - parsers of specific syntax elements. (Like headline parser https://code.orgmode.org/bzg/org-mode/src/master/lisp/org-element.el#L970) Or feel free just to grap any of the TODO or FIXMEs in the code
Hmm, I don't think the OP needs `csv-core` for this. `csv-core` is really only useful in a couple very limited use cases. For example, if you wanted to build your own CSV library but farm out the work of parsing. Or if you are in an environment that does not have dynamic memory allocation. Or if you need to put strict limits on the amount of memory you're allowed to use for each field/record. Otherwise, `csv-core` generally shouldn't be necessary for performance. You should be able to get the same or very close performance using just `csv` itself. (e.g., By using `ByteRecord` and reusing allocations if necessary in a streaming context.)
Thanks! it felt important to me to give a good explanation why yet another attempt at org. And I do like a good readme myslef
The best way to start thinking about it is as markdown on steroids. First of all it is a markup language. All the rest of the bells and whistles are built on top of it. Check out https://karl-voit.at/2017/09/23/orgmode-as-markup-only/ Karl goes to a great length comparing Org to markdown
Thank you! I think NOAA decoding is cool too. If you want to know more just ask
May this cause undefined behavior? ```rust use std::mem; enum Empty {} fn main() { unsafe { let empty: Empty = mem::transmute(()); } } ```
You are correct, I don‚Äôt. I‚Äôm just an outsider pointing out something I think is valuable for outsiders
Oh, that's interesting. I'll have to check it out. I've done something similar for embedding Cargo.lock in the binary: https://github.com/Shnatsel/rust-audit
Yes. Obtaining a value of empty type in any way (transmuting from zero sized type, dereferencing a pointer, `std::mem::uninitialized()`, `std::mem::zeroed()`) is always immediately UB.
Consider renaming `lib.rs` to something else. The convention for Cargo is that `lib.rs` is a separate library crate, so in your case `lib.rs` file is probably compiled twice ‚Äì once as a `main`'s module and once as a separate crate. After renaming, your current solution should work --- So, as an alternative to renaming, would be to go along with that convention and put all the logic in library crate, leaving `main` as a thin wrapper, so, your logical layout would be: &lt;package_name&gt; (binary crate) main.rs &lt;package_name&gt; (library crate) lib.rs ‚îú‚îÄ‚îÄ syntax (lib's submodule) syntax.rs ‚îî‚îÄ‚îÄ core (lib's submodule) core.rs Then, in `main` rs, you refer to: &lt;package_name&gt;::item_in_lib_rs &lt;package_name&gt;::syntax::item_in_syntax_rs In other files, you refer to them using `crate` referring to crate root (which is lib.rs) crate::item_in_lib_rs crate::item_in_syntax_rs
What is the difference between ***::*** and ***.*** ? Coming from python I am struggling to get it for example `io::stdin().read_line(&amp;mut n).expect("Bad input);` &amp;#x200B; I am sorry that I didn't put a lot of effort to find out it myself in the docs, just really want to know right away.
The dragon book didn't age well. There are much better alternatives, perhaps we could suggest a couple if you'd like to tell us what your goals are.
That works flawlessly, thanks! I went with the second solution, which looks really nice to me. I really like this style.
Do you have a github for that?
Exactly. Just want to know the average header overhead.
\`x.y\` is for methods and accessing fields, \`::\` is for inherent methods (methods that don't take a \`self\`) and accessing things inside of modules inherent methods are kind of like \`@staticmethod\`s from Python except you can't call them from values ("instances" if you will), you must call them using \`Type::method()\`
I am sorry to hear that. I am sure the orgmode community is open to your change requests.
I personally think it's hard to beat the Flutter layout algorithm, which generalizes width-in-height-out but is overall quite simple and efficient. It's a single pass, layout information gets touched once, but one interesting bit is that the *order* of traversal is not trivial. For example, in a flex layout the fixed-width children get layout first, then the flex children get layout based on the remaining space. My favorite introduction to Flutter layout is this [2016 talk by Adam Barth](https://www.youtube.com/watch?v=UUfXWzp0-DU).
Org-mode is life. You can't think of it as either one.
I've begun splitting `websocket` crate [into two](https://github.com/websockets-rs/rust-websocket/tree/split_in_two). The `websocket-codec` is independent from Hyper. I'm not sure if it is needed or not (maybe I should just stop trying to revive `websocket` crate) and what API should be between those two parts, especially for error handling.
&gt; but also bad if you need the simplicity I disagree...org is only really as complicated as you ask it to be.
I'm interested, mind suggesting anyway?
That would be great! Half a year ago knew nothing abut parsers, lexers etc. My goals were simple - get familiar with the knowledge domain. Dragon book definitely helped me to pick up some of the most basic things. But it feels that with every next chapter the complexity of the material increases. I would appreciate any materials that are targeted for people who did not graduate from Computer Science
I believe the root of your issue stems from everything in hyper needing to be marked Send.
These are some API design problems I encountered early on when "doing chess programming" in Rust. The current result is published as https://crates.io/crates/shakmaty, which seems to work reasonably well (and is already used to serve tablebases for lichess.org), but it would be great if you have answers or ideas for improvement.
Can I #derive(Clone) for an enum in an eternal crate? If so, I can't figure out how. I can work around it, but thought there might be a more clever answer than re-encapsulating the data in the enum in another enum. &amp;#x200B; I'm looking at this one in particular:[https://github.com/bparli/fastping-rs/blob/master/src/lib.rs#L29](https://github.com/bparli/fastping-rs/blob/master/src/lib.rs#L29)
I apologize for coming across as confrontational; that wasn't my intention, and I appreciate the effort you went to to break out specifics. To clarify, I was trying to express my judgement that the claim &gt; QUIC's main goal is to improve perceived performance of connection-oriented web applications is not supported by current IETF documents, including the WG charter as it stands today. I sympathize that there's a shortage of good high-level documentation available at present. &gt; Second of all, if you believe it is in error, why not edit it? I've now done so.
While diesel does provide the embed migrations functionality as posted above, a word of caution: never auto-run migrations in production. Always run them manually before deploying the new version. Everything else is destined to end in a myriad of problems eventually.
One additional thing: `extern crate` is usually unnecessary in Rust 2018. You can instead just have `use clap` in the modules that need to use clap.
I think I'm beginning to get a better understanding of lifetimes now, but need a bit more clarification. Am I correct in thinking that the reason for needing to manually annotate lifetimes is that the compiler cannot, for some reason, see the state of a program outside of a function? To clarify what I mean, it seems from the "longest string" example from The Book that if the compiler could have seen the lifetimes of the string references passed into the `longest` function as arguments, we wouldn't need to manually annotate the lifetimes. But since we do have to, am I correct in thinking that for some reason compilers kind of forget about previous state when they get to a new function? If I'm wrong, then why wouldn't the compiler be able to easily see this?
. notation is for accessing things which are on objects. :: is for accessing things from modules.
They're all the size of the biggest one, but ArrayString avoid the extra heap allocation that is there in "String". String = array + length + pointer, and then the pointer leads to the actual data in the heap. ArrayString is just 4 bytes (or 5 or 6 depending on what is best). Since most lines are under 16 bytes I suspect the array string might cover most cases.
Rust also optimizes `Option&lt;String&gt;` ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=65c2fcf599af9be8cb2278b20d533b6f)). Additionally with Box it you would have to go through two layers of indirection instead of one.
I'm guessing \`warp::serve\` uses a tokio thread pool somewhere. The problem is that tasks running on a thread pool will occasionally be moved between threads by the thread pool. As for the details of the error, I don't know warp well enough to give an immediate answer.
This is exactly right. Most of the time you don't want to be extremist in any way. However, sometimes you do. For math / data stuff you probably want FP, for games you probably want OOP. Real life, in my opinion, use common sense. You can do function and object composition in Rust, and I would say Rust is the best implementation of true OOP concepts I've seen. Java is known as "the" OOP language but I disagree with that and find its focus on inheritance and classes really bad and not what true OOP is about.
Just tried that yesterday and I'm on the latest Rust release. Can confirm that compiler will not let you do that.
Getting a canonical version number is one of those age-old problems of programming. I don't know if there was a way of doing this before, but now I know there is (at least) one. Thank you.
I later had the idea to fully parameterize over a unique type, which wouldn't be a hard process to automate. Unfortunately all assignments have to be fully deterministic or identity information will be decoupled from upstream markers. Given that only certain flows, which must also be accounted for rigorously, can obtain a correct answer, it's probably too heavy &amp; limited. It probably gets even harder as the hidden parameters fan out to basically all of the Vulkan types. I still wish I knew the property of execution paths that can't erase the identity of an assignment so that I can write a static analysis routine. This is an illustration of what I was thinking, and you can imagine how it breaks as you go downstream: ``` struct Gpu1, struct Gpu2; let device1 = Device.create&lt;Gpu1&gt;(); let device2 = Device.create&lt;Gpu2&gt;(); let queue_fam1 = device1.queue_families().next(); let queue_fam2 = device2.queue_families().next(); let image = device1.magic.storage_image(); // at this point, everything is parameterized over Gpu1 or Gpu2 // fails to type check because the parameterization no longer matches image.memory_barrier(..., queue_fam1, queue_fam2) ```
If you want to be clever you can reduce the space required by quite a lot. I will however cost a little bit of performance as well, but I suspect that the end result will still be quite fast. The trick here is to work with fixed size structure. So some guess work is required in order to figure out the right size. First thing you would need is to get rid of the Option&lt;String&gt; part since you can't "guess" the size of that. You would create 2 different Vecs, one for the Option&lt;String&gt; and another one for the rest. You can store the fixed part in a tuple of the form: (u8, f32, Option&lt;core::num::NonZeroU32&gt;&gt;, \[u8, 8\]). This is assuming you can get away with using f32 for you floating point, otherwise use f64. The small obligatory string should fit on and 8 bytes array, but that might not always be the case. Your code should panic if the string does not fit, and you should then increase the size of the byte array and try again, until you get the minimum size required (you can always write some code to get the max length if you don't want to guess). Notice there is an weird type in there in there. That is the index into another array, that contains the option strings. Notice I'm not using usize for the index, that because on 64 bits platforms usize is u64, so you lose some space, but since we are sure that u32 is enough you will have to down cast the usize to u32 to gain some space. Notice also that I'm using NonZeroU32 for the index. That allows Option to optimize for space. So that means you can't use index zero. Instead of increment on store and decrement on index, I suggest you just push an empty string on the first index of the optional string array so that you start storing real string from index 1. &amp;#x200B; So basically you end up with two Vecs: Vec!\[(u8,f32,u32,\[u8,8\])\] and Vec\[String\]. The second has an unknown size and you cant gain much there. However the first one is very optimized for space. 50 mil \* (1 + 4 + 4 + 8) = 50 mil \* 17 = 810 megabytes! Notice as well that you don't need to represent absent optional string in memory. The Vec\[String\] will only have strings that actually exist. &amp;#x200B; Good luck you decide to follow up on this approach. It will turn something that was quite simple into something quite complicated. However that is the reality of systems programmers. Do to performance constraints we often end up making the simple complicated!
Your own talk [Data Oriented GUI in Rust](https://www.youtube.com/watch?v=4YTfxresvS8) from Bay Area Rust Meetup on June 28, 2018 is relevant as well. I‚Äôve watched it before but it was a good while ago and so I am rewatching it right now. In the talk I mentioned here, you tell a bit about how the Flutter layout protocol works, and how you are using it in [xi-win](https://github.com/xi-editor/xi-win). Is the Flutter layout code you wrote for that project reusable for other projects? If not, are there any plans to make it reusable?
This is definitely good enough. I think automatically generating such tag information for all instances has pretty serious requirements on the compiler, beyond the existing type infrastructure. On the library side, hardcoding just one tag and making unique tags an opt-in signature would be great. Wish I could code it. Any way to feed extra information to the compiler error messages?
It's an advanced interactive markdownÔºå basically an app.
As long as you are just using it - yes. It really allows you to use only the parts you want to. But there is no denial that there are many many markdown parsers out there - implementing one is pretty simple. Org-parsers on the other hand... My point is that from a programmers perspective, org mode is not as easy as I would like it to be.
Yes, but string is three pointers wide, so if the vast majority of them are nine anyway you can save space by using a pointer. The overhead of the extra allocation would be offset by the smaller size of the struct, since the allocations would not need to take place often
Yes, that's becoming [druid](https://github.com/xi-editor/druid). There's still very much an "under construction" vibe, but stay tuned, I'll have big announcements coming up soon, and am also planning to submit to RustConf.
Based on the helpful comments by u/hntd and u/darksonn (thanks!), I revised the `Receiver` stream to return a String or Error wrapped in an Arc. This changes the compile error to `impl futures::future::Future as futures::future::Future&gt;::Error cannot be sent between threads safely`. Any suggestions on how to resolve this? And, if the issue is with items needing to be Send, is the general approach of adding Arcs on the right track?
Is your error type custom? You could box it or do Error+Send
In the `qcell` crate I tried three approaches, integer ID, marker type and lifetime marker. The lifetime one has the best properties but also noisiest in terms of code annotations. That's really the big tradeoff.
You may also want to have a look at Pandoc which has a very good (from my tests) reader for org-mode.
Now that you can `use` macros, it‚Äôs always unnecessary.
Nice, looking forward to see your talk if you do end up submitting to RustConf.
For the theory of parsing, Sipser's book is insanely instructive and quite approachable. Just do all the exercises.
Nice! The point isn't really about the extra byte, however; it's about the fact that it stores 8 bytes total for None, when Option&lt;String&gt; stores 24. I get the impression there are a *lot* of Nones in his file. The point about two layers of indirection is absolutely valid, but less of an issue if you aren't actually invoking the Some path very often.
I've done some basic "draughts programming" in Rust and other languages, and although draughts isn't chess, similar techniques are used to efficiently store and process positions and moves for both games. But I'm by no means an expert. I don't think it's particularly useful to make `Square` an enum if you don't plan to pattern match on it. It ensures that you'll never have an invalid square, but that invariant shouldn't be too hard to maintain when you're using a newtype as long as you keep the base value immutable and you keep the containing module small. The `Move` enum thing is tricky, I think you should probably have it match the memory layout of what Stockfish does (or something similar) if you really care about performance. I've never tried something like this, but maybe you could keep this `Move` type opaque and have it be the main way in which the program stores moves, and whenever you want to pattern match on it, have it dereference to this enum you're currently using. That might not have a runtime cost at all, and even if it does, you're not sacrificing any cache locality with it. Let me know if my explanation makes sense and what you think of this approach. Something I've been playing around with is giving the `Position`/`Move`/`Piece` types a phantom generic type parameter that is either `White` or `Black` to have static enforcement that e.g. you're not applying white move to a position where it's black's turn. I have found that although you may not always know which player's turn it is at compile time, very often you do. It has prevented several logic errors for me before. It's slightly awkward to work with because now your types need a `PhantomData` property, but const generics will make this very elegant!
What is oop about? (Lol "oop")
/r/playrust
Yes, Markdown is like Frankenstein's monster *before* applying electricity, and Org-mode is the monster *after* applying electricity.
I read through that, all be it quickly, I didn‚Äôt see anything glaring that made me think I‚Äôd prefer it to CommonMark markdown, i.e. standardized markdown. Especially with the fact that markdown is becoming a standard extension to many websites. Are there any killer features that Org supports that markdown doesn‚Äôt?
Why would I even record the "capture" in a move? It's not like you couldn't find out from the board (a move can only exists with a given position to do the move from). It looks to me like this format stockfish uses is more optimized for printing the moves, not storing the moves in memory.
Thanks. After playing around with a few boxes, I got past the error I was encountering. Now I'm facing an error relating to `warp::reject::Rejection` not implementing `Error`. I have to step away from my computer/code for a bit, but that strikes me as a more solvable problem. So thanks!
The reason there's no Ord on f32 is because of NaN, since it doesn't follow ordering. There are some crates that wrap floats and assert that there are no NaNs, and you could just wrap with that and sort. use ordered_float::NotNaN; data.sort_by_key(|&amp;(x, y)| NotNaN::new(x as f32 / y as f32).unwrap()) Another option in this case is to use a comparing function (`sort_by`), and you can cross multiply to compare ratios. data.sort_by(|a, b| (a.0 * b.1).cmp(&amp;(b.0 * a.1))) In general, the easiest way to sort floats is to use a comparing function. floats.sort_by(|a, b| a.partial_cmp(&amp;b).unwrap()) // Panics on NaN floats.sort_by(|a, b| a.partial_cmp(&amp;b).unwrap_or(std::cmp::Ordering::Equal))
Yes, use a sort function based on relative ordering instead of key-based ordering. This is implemented by `sort_by`, see here: https://doc.rust-lang.org/std/primitive.slice.html#method.sort_by
Are you perhaps searching for [sort_by](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.sort_by)
https://doc.rust-lang.org/stable/std/primitive.slice.html#method.sort_unstable_by
Check `exa`.
&gt; ople from making theire own scripts but i got a dare from a fri At first glance, this seemed plausible for /rust!
&gt;But there is no denial that there are many many markdown parsers out there - implementing one is pretty simple. Org-parsers on the other hand... Parsing org is easy-ish. The devil is in implementing features that are meant to be provided by parsed syntax - features like tags, property drawers, macros, execution of source blocks, etc.
Put a script called "cargo-mycheck" in your path and put this in it: ``` #!/bin/sh -eu cargo check cargo clippy ``` Don't forget to make it executable with `chmod +x cargo-mycheck`.
All OOP really is is bundling behavior and state (i.e. adding methods to objects and allowing those methods to be aware of the state of that object through a keyword like `this` or `self`. That's it.
Yes, but I would expect a parser to be able to do all of this, wouldn't you? What use is a parser that doesn't support the whole format?
Org supports TODO lists, executable code samples and a lot more that markdown simply doesn't. You can think of it as Markdown meets Python Notebook meets LaTeX, sort of.
Thank you! Very educational answer. I didn't know about |a, b| syntax, so the multiplying wasn't and option for me until now.
In theory, it should be completely unnecessary, but not all crates' macros are implemented in a way that you can separately import them, as they may expand to code that expects other macros to be available as well. Hopefully this issue will go away over time, as those crates get reworked so you can easily import single macros from them.
Define a wrapping type `Div(u32, u32)`. Define `Ord` on this type as `|a, b| &lt;u64 as Ord&gt;::cmp(&amp;(a.1 as u64 * b.2 as u64), &amp;(b.1 as u64 * a.2 as u64))`.
SQL Anywhere is Sybase, right? They had an ODBC driver the last time I checked, which was admittedly a while ago. But if they still do, that's probably the way to go.
Markdown supports todo lists, too, no? As to executable code, is that more the editor support or part of the standard?
Now this is a thing! I almost replied that I know this and that I already use this method in my other projects. But in the other project I read line and use it or discard with some probability. In my current project it is not enough because user defines filters and maybe there is just single one line that should be used. But this is a bit clever - I read rows until I have as many as I want and then with some probability I discard old ones and replace them with new. I think the only issue here is that there are some chances that I will more or less often choose lines from the beginning / end. But with good random algorithm it should not be an issue. Thanks a lot!
When compiling your comment I got this error: error: derailed thought train --&gt; src/main.rs:1:50 | 1 | All OOP really is is bundling behavior and state (i.e.... | ^ un-closed delimiter 1 | ...object through a keyword like this or self). | ^ | Note: Perhaps place a ')' here? | | missing closing delimiter error: aborting due to previous error error: Could not compile `comment` From what I can see of the source code, however, I do see where you were going with that. That makes a lot of sense actually. Thank you for simplifying things.
Oh God it would be awful to implement a parser for org. Not disagreeing with that.
If you're not in the Emacs ecosystem, there's absolutely no advantage to org-mode over any other markup. In the Emacs ecosystem, however, it is an extraordinarily powerful organization tool. The power comes from using Emacs as a complete system around org-mode markup to manage the state of structured, hierarchical documents efficiently and easily. With just a few key strokes you can open, collapse, move, or rename subsections, change states, add searchable properties and tags, create timestamps that can be queried and modified, track the historical state of TODOs (e.g. moving from TODO-&gt;NEXT-&gt;DONE and recording notes and timestamps for each transition), and publish effortlessly to Markdown, HTML, plain text, LaTeX, or PDF. My entire website and blog ([https://loomcom.com](https://loomcom.com)) are written and maintained in org-mode, and published 100% with Emacs, no external tools. In addition to my home page, I primarily use it for tracking my projects and my time. The org-agenda part of org-mode allows me to import my meetings from Exchange, schedule my day, see what I'm working on and what's next, and so on. And it's all just plain text, which is great. Yeah, I'm a fanboy, I admit it.
I do: [repo](https://github.com/igor37/exorg)
Wrong language, but this was an accessible read: &amp;#x200B; [https://compilerbook.com/](https://compilerbook.com/)
Yes, exactly. It‚Äôs a *little* more complicated, but I think the technique should extend more or less straightforwardly to your problem.
True, but it produces different results - the font size for one, and it isn't as lenient when it comes to syntax as Emacs is - for example if you have a line with bold text directly followed with a line break, Pandoc will ignore the syntax.
For executable code it's part of the implementation. For example if you have `test.org` with this document: This section just runs a command. Run C-c C-c to see the output: #+NAME: test #+BEGIN_SRC sh :results test drawer id pwd #+END_SRC This is where the output will go. Press `TAB` to toggle the display of the block. #+RESULTS: test :RESULTS: uid=1000(skx) gid=1000(skx) groups=1000(skx),24(cdrom),25(floppy),27(sudo),29(audio),30(dip),44(video),46(plugdev),108(netdev),111(scanner),115(bluetooth) /home/skx :END: #+END As you can see there are two blocks: * One with a set of commands (`id` + `pwd`) * One with the output. You can add/edit the commands in the first block, and get the results shown inline. Then later you can iterate over those results, and do clever things. Very addictive for inline code examples, and test-scripts. But something a standalone parser would probably not handle.
Thanks üôèüèª checking it out soon
&gt; True, but it produces different results - the font size for one I was referring strictly to the reader. In Pandoc's architecture, output is totally unaware of the original (input) format. The parsers and writers never communicate, they generate and read, respectively, a format-agnostic AST. &gt; and it isn't as lenient when it comes to syntax as Emacs is - for example if you have a line with bold text directly followed with a line break, Pandoc will ignore the syntax. This is a bit of an edge case, since in org the number of line breaks within a stream of emphasized text is configurable. But if pandoc does not match org's standard behavior on such a simple case as bold text it's certainly worth reporting.
The type of the captured piece isn't usually used in chess notation (just x for capture), but it has some other advantages: Locality when ordering a list of moves, potential for faster move making (depending on the board structure), and less state to seperately track for undoing moves. Good point, though. In fact so good, that Stockfish decided *not* the have the capture type :) The way I presented it gives the impression that the C++ and the Rust code are equivalent, but I forgot I added the capture type for the above reasons. Stockfish solves the problem differently: * Move ordering, by generating captures seperately. * Notation, but only ever using very simple notation with two squares and promotion type (e2e4, e7e8q). * Undo, by keeping a stack of full boards. * Fast lookup of the captured piece type, by maintaining an array of piece types for each square in addition to bitboards. (The general question remains, even with one saved byte for the capture type).
&gt; `floats.sort_by(|a, b| a.partial_cmp(&amp;b).unwrap_or(std::cmp::Ordering::Equal))` Hmm, is it okay to do that? It will compare every value as equal to `NaN`, so if `c` is `NaN`, you could have `a &lt; b`, `a == c`, `b == c`, which is inconsistent. I can't find it, but I recall an issue about potential memory unsafety in `sort` in the presence of inconsistent comparisons. I think the implementation was fixed at the time, but one idea that was floated around was to make `PartialOrd` unsafe.
There's also the [org manual(PDF)](https://orgmode.org/org.pdf) which has far more content and details. In my experience it's still neither complete nor sufficiently explained, but it helped me a bit more than the shorter summaries.
I'm using fantoccini and after using the find_all method, I want to be able to call the method attr("innerText") on each element and get the result as a vector of strings. ` .and_then(|mut c| { c.find_all(Locator::Css(".classname")) }) .and_then(|mut v| { //??????? }) ` I already tried googling, but nothing really shows up. If anybody can find a good resource on using fantoccini, it would be appreciated.
Regarding `Square`: So far I never needed to pattern match, but I frequently need to name arbitrary squares. So maybe instead a newtype like this (and similar constructors)? pub struct Square(i32); impl Square { pub const A1: Square = Square::new(0); // ... pub const H8: Square = Square::new(63); } I like your idea for the move enum. Will definitely try it! match m.unpack() { // ... } Statically distinguishing the side to move is an intresting idea. It could be a good compromise between safety an ergonomics. Going one step further would be using an approach like https://github.com/bluss/indexing to tie moves to an exact position, but I am not sure how practical that is. The first time I saw something like it was here: https://old.reddit.com/r/rust/comments/5pk1pu/abusing_the_borrow_checker_to_make_tictactoe_safer/
You can use LaTeX commands inside org-mode documents for anything that's not supported or where you want more control. In other words, it does more than Markdown by default(e.g. I haven't seen any table support in Markdown so far), and additionally can be mixed with LaTeX formulas etc. This is the reason I'm using the format - I can use org-mode files for everything from Todo-lists up to full-blown thesis texts with all formatting I could ever imagine, and all the common features are easier to use and quicker to type than LaTeX.
Scaling &amp; potential for abuse. "Let's refactor everything" all the time is as bad as "let's build it so critical but hard to understand that we can't get fired." Also, tool-assisted audit will produce a measurable output while code smell is subjective.
mmap doesn't allow you to create a non mapped file chunk of memory at a specific location. You can make an anon map sure, and even set it as executable, but not at a specific offset, which I need.
Hi, I *do* think that there are advantages to org mode outside of the Emacs ecosystem. In my opinion, the syntax is more user-friendly when typed (without tool support). It is more logical as well from my point of view. This is why I'd love to see more org mode support outside of Emacs.
May I ask why? It's very common to find new users all for more control then they really need.
I split out the protocol stuff into its own standalone crate: https://docs.rs/websocket-codec/
c.find\_all returns a list of Element-s. You can call the standard map function on that list and inside the closure passed to \`map\` you call \`el.attr("innerText")\` -- though actually I think you need to call \`el.text()\` instead, I don't think "innerText" counts as an attribute, though I may well be wrong here. &amp;#x200B; \`\`\` // ... .and\_then(|mut v| { v.map(|el| el.text()) }) .and\_then(|items: Vec&lt;String&gt;| { // now you have a vec of strings... }) \`\`\`
Thanks for giving feedback. I changed my code to reflect your comments. .and_then(|mut v| { v.iter().map(|mut el| el.text()) }) .and_then(|items : Vec&lt;String&gt;| { dbg!(items); Ok(()) }) Now I'm getting the error the trait `futures::future::Future` is not implemented for `std::iter::Map&lt;std::slice::Iter&lt;'_, fantoccini::Element&gt; for line 65. I think the closure has to return a future.
They aren't there for the compiler (at least all of the time), they're there for people reading and trying to understand the code. You don't want to force them to understand the implementation of the function to understand how it's called.
First, data doesn't need to be Option&lt;T&gt;. Just T would suffice. Second, in add_tail Box gets dropped at the end of the function. You can take a look at implementation in std to see how they do it.
Just a warning that sqlite is full of single-threaded bottlenecks, so the query performance may be easy to beat if you can use something else that is trivially parallelizable.
\&gt; Why reinventing the wheel when we can just copy it! This project takes the only surefire way to get it right - use the original elisp parser implementation as a blueprint! If you do that, licensing your project as MIT sounds like a recipe for trouble
That's not true. Certain cases won't compile unless you manually annotate them. The official Rust book explains they are there for the compiler.
By "they", I was referring to required lifetime annotations. The compiler *could* figure them out itself in more instances than it does currently.
So you're saying lifetimes don't have to be anything programmer ever HAVE to manually annotate? Why doesn't the compiler take care of them then?
That is exactly the question I answered above.
Well "more instances then it does currently" isn't the same as "all instances". Also, you didn't explain why it doesn't then.
It says it allows any number of concurrent readers, so with a program that does one import and a bunch of reads the second part can be multithreaded.
The issue isn't necessarily the types - it's that they're all based on trait objects. If I were using concrete types, it would be easier to deal with. But I wanted the library to be dynamic.
Good luck! I'd be interested in helping out testing it. As someone else pointed out, you might want to revisit the choice of license to avoid issues in the future. Some context https://news.ycombinator.com/item?id=19660989
```rust fn foo(a: &amp;str, b: &amp;str, c: &amp;str) -&gt; &amp;u8 { // ... } ``` This does not compile: ``` error[E0106]: missing lifetime specifier --&gt; src/lib.rs:1:38 | 1 | fn foo(a: &amp;str, b: &amp;str, c: &amp;str) -&gt; &amp;u8 { | ^ expected lifetime parameter | = help: this function's return type contains a borrowed value, but the signature does not say whether it is borrowed from `a`, `b`, or `c` error: aborting due to previous error ``` Depending on the implementation of `foo`, the proper annotations could be any of e.g.: ```rust fn foo&lt;'a&gt;(a: &amp;'a str, b: &amp;str, c: &amp;str) -&gt; &amp;'a u8 { a.as_bytes()[0] } fn foo&lt;'a&gt;(a: &amp;'a str, b: &amp;'a str, c: &amp;str) -&gt; &amp;'a u8 { if c == "hi" { a.as_bytes()[0] } else { b.as_bytes()[0] } } fn foo(a: &amp;str, b: &amp;str, c: &amp;str) -&gt; &amp;'static u8 { &amp;0 } ``` The compiler knows exactly which arguments (if any) the return value borrows from; that's how it determines if your lifetime annotations are correct or not. It could pick one of those options for you automatically. It does not do that because, like I said above, it would make things to hard for humans trying to understand how the function behaves. If I'm trying to figure out how to use `foo` as a user of your library, I don't want to have to read through the implementation of the function to figure out what its actual signature is.
Not until now - thank you for linking that project / blog. The great thing about Rust is that, even though I'm not using it, ya'll are already very deep into just about anything I'll ever need to do in the future, on so many fronts.
One reason not to have the compiler automatically infer more things is to keep it simple and to avoid making compile times longer. But there's another reason that I think is more important: It's a good thing for functions to be explicit about their contract with the outside world, so that it's clear when something is a breaking change. For example, say I start with this function: fn foo&lt;'a&gt;(s1: &amp;str, s2: &amp;'a str) -&gt; &amp;'a str { println!("{}", s1); s2 } Here the lifetime of `s1` is unconstrained, but the lifetime of `s2` is tied to the return value. Now suppose we change the function to potentially return either of the two strings: fn foo&lt;'a&gt;(s1: &amp;'a str, s2: &amp;'a str) -&gt; &amp;'a str { println!("{}", s1); if some_test() { s1 } else { s2 } } That's a breaking change. The lifetime of `s1` is constrained now, and some callers that compiled successfully before won't compile with this new version. And that's not too surprising, because we explicitly changed the signature of `foo`. But what about the hypothetical world where Rust inferred those lifetime constraints? It might be surprising to the programmer that adding that `if` statement internally is a breaking change. And the change might not even have come from `foo` itself; it could be that `foo()` calls `bar()` and `bar()` calls `baz()`, and some small change in the body of `baz` leaked out and broke the callers of `foo`. In large programs that have a lot of dependencies interacting with each other, the implicit contracts between different functions would be difficult to keep track of.
I'm loading an executable so I need to set it in the right locations in memory.
Why do you doubt it? I think it becomes a "double" data structure, that is simultaneously an associative list (group key to value) and also of fixed size with random removal. I imagine it could at least be modelled as something like struct Groups { data: HashMap&lt;String, Option&lt;...&gt;&gt;, selection: Vec&lt;String&gt;, } Seeing a new group name would do reservoir sampling using `selection` and then adjust `data` to match; and adding a new element within a group would do reservoir sampling within `data` if (and only if) the group key exists. (I think one might need a HashSet or clear the sampling info but retain old keys within `data` (i.e. set to `None` with the type above) when removing/"unsampling" a key, to ensure one can identify when a group key is new or not.) This sample isn't uniform with respect to the whole sequence (if there's a million rows in group `a` and one `b`, a sample of size 1 will still choose `b` 50% of the time), but the groups will be uniformly sampled out of all the group keys, and the elements within each group will be uniform within that group too.
[mp4 link](https://preview.redd.it/niiyx53hsas21.gif?format=mp4&amp;s=c8f60204d1ed4d00add53d83207465b7b6a09927) --- This mp4 version is 97.55% smaller than the gif (536.34 KB vs 21.34 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
If you‚Äôre not using `clap`, you can use this: ``` std::env!(‚ÄúCARGO_PKG_NAME‚Äù) ``` and ``` std::env!(‚ÄúCARGO_PKG_VERSION‚Äù) ``` (That‚Äôs exactly how those macros are defined)
Are you writing a kernel or kernel module, or are you trying to do this from userspace? If it's the latter, what do you do if the process you're loading's address space overlaps with your own?
You're correct that it avoids the extra separate storage of a `String`, but the memory required is still `50_000_000 * 64 = 3GB` that the original post is trying to optimise. (As you say, though, that 3GB doesn't capture all the memory required to store this.)
This does look like it has quite similar scope and goals as piet (for 2D) and druid-shell (for window creation). I'm not super attached to my solutions being "winners" but do hope we manage to converge.
userspace, and if it overlaps, I fail.
What about DuckDuckGo?
No clue. I assume it will help there too.
What's wrong is that it's a doubly linked list implementation. :P In all seriousness, [Learn Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/) is effectively required reading for anyone trying to implement a linked list of any kind in Rust, and also serves as a warning that what is easy in most languages might not be so simple in Rust. If you want a way to fix your immediate problem: &gt;!`new_node` is getting dropped at the end of `add_tail` and deallocating what you just finished allocating. To fix this, rather than get the pointer through `let new_node_ptr: *mut Node&lt;T&gt; = &amp;mut *new_node;`, you should be using `Box::into_raw(new_node)`. This will give you a raw pointer and prevent the Box from being deallocated, but you won't be able to directly access `new_node` anymore.!&lt; Please read through Too Many Linked Lists before following that though.
Completely unrelated, but Pornel, what happened to the [gif.ski](https://gif.ski) GUI you were making?
I think it has labelled breaks ? ... but I haven't read this in enough detail to figure out if they would cover this example
I've created a chess engine in Rust that supports various variants. Some initial thoughts: * `Role` is a nice name. I used `PieceType`, honestly yours is much better. * I agree with your conclusions in `Copy` vs non-`Copy`. I used to have much more non-`Copy` types, mostly because I thought in-place mutation would be faster/better than copying and re-inserting. Turns out copy+re-insert is pretty much always faster for &lt;= 8 byte data types, and much easier to work with. * I'm not so sure about your square representation. It never occurred to me to do it that way, although it might be a good idea? Do consider: * You pretty much have to do arithmetic on squares at some point, especially for converting to/from strings, and potentially other things. To keep your "squares are 0-63"-invariant, you risk ending up with a half of a bad u6 implementation. * You'll almost never refer to the squares by name anyway, unless you're doing manual heuristics for things. The exception is (possibly) castling, but that's just a few constants. * Not using a separate `ReverseMove` type seems dubious. Is it even correct in its current implementation? If you do a move that removes castling/en passant rights, or resets the 50-move counter, how do you restore that information when reversing a move? * I would recommend using separate `Move`/`ReverseMove` types for compactness anyway. You will probably never need to store more than one `ReverseMove` at a time, so its size doesn't matter. The size of `Move` does. Put as much information in `ReverseMove` as possible. * Additionally, if your `Board` type changes to include more information in the future, the Move type may also need to grow. With a separate `ReverseMove` type, only that struct needs to grow. * I did my `Move` type as a 3-byte enum for simplicity, which as you pointed out may not perform ideally. However, I would stick with that unless you really really really need that 1% performance boost. It's very nice to work with. Maybe Rust will someday allow you to "overload" the pattern destructuring operator, so to speak. Apologies if I come off as harsh, it's late at night here.
As someone who is not familiar with the concept of an actor system, could you explain some benefits it provides as well as some of the potential downsides?
Should have pointed out the errors I am getting. https://travis-ci.org/cheako/smithay/jobs/520055649#L2704 error[E0277]: a collection of type `std::vec::Vec&lt;(u64, std::boxed::Box&lt;dyn vulkan_drawer::Screen&gt;)&gt;` cannot be built from an iterator over elements of type `(u64, std::boxed::Box&lt;&amp;Display&gt;)` And similar from udev, except it's "std::boxed::Box&lt;Display&gt;)`"
I wrote a simple rust program that collects temperature data on a Raspberry Pi. After a few days, it crashes with the following error: *** Error in `./sensorpi': free(): invalid pointer: 0x76b65f01 *** ./run.sh: line 3: 8 Aborted (core dumped) ./sensorpi How should I approach debugging this? Am I leaking memory, or does one of my dependencies have a safety issue. I don't have any unsafe blocks in my own code. You can see the code and dependencies here: https://gitlab.com/szaver/sensorpi
Thanks for pointing out. I am not used to care about licenses and I will appreciate an advice. Should I license org-rs under GPL? Will it present any risks for the future of the project?
Fantastic work!
Thank you. Box::into\_raw() did it. &amp;#x200B; I carefully worked through all of Too Many Linked Lists before. This exercise is a blind implementation to test my understanding and deeply understand Rust pointers.
 Nice work :) Hope i am not messing something i just though that tokio core is deprecated and everything is moved in to just tokio, just wondering why are u you using tokio core and not latest version of tokio ? :)
I will use latest deps next version
Cool :)
I can't comment about the game, for that you'll want to ask /r/playrust For the programming language - it's always worth learning something new, and doing that learning doesn't have to take up a lot of time per week.
I think r/playrust is what you want. Though the rust programming language might hook you and take up available free time too.
Well,if you want to buy something related to Rust,you can buy these 2 books: \- [http://shop.oreilly.com/product/0636920040385.do](http://shop.oreilly.com/product/0636920040385.do) \- [https://www.amazon.com/Rust-Programming-Language-Steve-Klabnik/dp/1593278284](https://www.amazon.com/Rust-Programming-Language-Steve-Klabnik/dp/1593278284)
Did you try running it in Valgrind or GDB? It's clearly not in your code, but you could probably get enough info to give a bug report to the library who did it, or even find out the bug itself and give a PR.
Markdown supports static checklists, but org mode's toto's are fully interactive, Org-mode's support for embedding executable code is part of the 'standard', but bear in mind that the standard as of now is the reference Elisp implementation inside emacs. There's no standard as such beyond that.
Buy into the hype? Yes. But please don't spend money on it, you're being swindled
If you want to contribute, no problem. I couldn't work on the project last week because I have exams.
Thanks :)
Is this part of Amethyst, out a separate project?
It is a separate project. It is being built as a sort of testbed for rendy and it was and is being used as reference for the integration of rendy into Amethyst, though :)
I think the compiler can't make the conversion Box\&lt;Struct\&gt; to Box\&lt;dyn Trait\&gt; from an iterator on it's own. But this should work: ```rust properties.display.id(), Box::new(Display { instance, physical_device, properties: properties.clone(), data: Cell::new(None), }) as Box&lt;dyn Screen&gt;, ```
If you buy a PC you can play /r/playrust and learn /r/rust.
r/lostredditors
Emacs' org-mode is under the GPLv3, which is a "hereditary" or "copy-left" licence: it gives you permission to make your own version (say, by translating to Rust), as long as your version inherits the licence as well as the code. The idea is that *you* were given permission to make changes to org-mode, so you should give permission to other people to make changes to *your* code, so those other people should give permission to yet other people to make changes to *their* code, and so on. On the other hand, licenses like MIT, BSD, ISC, Apache-2.0 and so forth are "permissive" licences. The developer makes the software available for everyone to do anything, including making proprietary improvements - there's no legal requirement to "pay it forward". Some people really like this kind of rugged individualism, but not the org-mode maintainers (or anyone else involved with Emacs or the Free Software Foundation).
I'm so sorry, but I have to ask: What exactly is this (for)? It sounds like it's some sort of zeroconf-like library for Rust that's also a DNS server?
Nice job! :)
The resolver is a stub resolver for dns, it also has support for mDNS (though there are some outstanding issues here). Otherwise it‚Äôs a standard stub resolver. mDNS is the closest to zero-conf in that area. The client is mainly oriented towards being a decent tool for dynamic DNS management. It supports SIG0 for auth. The server is a traditional dns server, with DNSSEC and dynamic dns, and mDNS support. Caveats again on the mDNS implementation. zero-conf is definitely an area I would like to make simpler with this, but the project isn‚Äôt quite there yet, otherwise it is a capable set of libraries for traditional DNS.
Thanks. I have changed license to GPLv3.
Wow, awesome work
Wow, thank you! This helps me a lot! I only learned enough at the time to write this (and I copied some examples online to help). I'll be doing some research into \`struct\` and \`impl\` to understand how they work in Rust.
Nice work. Remember to add a LICENSE file to it :)
What happens if you try rustup update stable-msvc rustup default stable-msvc cargo --version ?
Thanks! And ah, thanks for the reminder; just added.
Thank you!
Thanks! :)
Gonna keep working on my crates.io commandline tool. https://github.com/peterheesterman/chit
Still working on a [language](https://github.com/sn99/pakoda) though I have to slow down due to exams(coding a parser is pretty new to me) :p
Starting to put together a new tool called `sidefuzz`, which is a fuzzer that automatically finds certain classes of side-channel vulnerabilities.
I have been making an incremental DOM framework that uses zero-sized types, similar to json-in-type. Turning out real great
Is cargo on your PATH?
I believe \`Set&lt;'id&gt;\` provides a way to create what's effectively a unique fake lifetime \`'id\` via the \`Set::new\` "constructor". This way, instead of asking the user to define a unique type like TCell does, it asks the Rust compiler to instantiate a new fake lifetime (the lifetime must be invariant otherwise the borrow checker might do weird things like calculate intersections of lifetimes). &amp;#x200B; It works, but the error messages that you get if the user screws up can be a little confusing since \`'id\` is just a fictitious lifetime (at least last time I tried to do something similar).
Thank you!
Work continues on my virtual microcontroller and programming language compiler that I started at least [ten months ago](https://www.reddit.com/r/rust/comments/8rwpq7/whats_everyone_working_on_this_week_252018/e0uvf7n/). The essential components are all there (lexer, parser, name resolution, type checking, IR code generation, IR to assembly, assembly to object code, object code linker, program execution), but it's still not really useable yet. Compilers are crazy.
Sounds like you could run two `HttpServer`s on two threads. To share state, you could try a futures-aware synchronization primitive like https://docs.rs/futures/0.1.26/futures/sync/struct.BiLock.html or maybe https://docs.rs/tokio-sync/0.1.4/tokio_sync/semaphore/index.html.
I've been editing my post a bit since I first posted it to add some details about what I have so far. In terms of running HttpServer, what I have so far is the same thing you also wrote. Spawn a thread for the admin server and run the public server from the main thread.
What's the reason you back `Square` using `i32`? I use `u32` for that, mainly because that's the return type of the `leading_zeros`/`trailing_zeros` methods on the integer types. But I'm considering to use `u8` instead since it's wide enough to store all legal values. &gt;Going one step further would be using an approach like [https://github.com/bluss/indexing](https://github.com/bluss/indexing) to tie moves to an exact position, but I am not sure how practical that is. That looks great, I had no idea that's possible in Rust. I'm definitely going to give that a go and see how it compares to only statically enforcing the side.
It sounds like the `trust-dns` server could be used instead of `dnsmasq`, `unbound` or `stubby`. Would it make sense to extract part of it to a different binary for those who only want the stub resolver and some adjacent features like configuring forwarding zones and maybe some static hosts? I'm thinking it might be easier to manage than the full server, especially for casual users.
I have plans to do exactly this. I was thinking of making a few different tools to simplify this. This release finally got some of the pieces in place that will allow for building something like what you mention.
What do IDEs have to offer, especially in regards to Rust programming?
Work continues on a cross-api shader language/toolset. Though the way it's going right now, it's slowly turning into a full game asset make-system for my personal projects, not just shaders.
Oh you are right!
Working on an customizable e-book reader via web\_view right now. Still new to rust but not to programming and it's quite challenging at times, but so far I like it.
thanks! this helped a lot
Sorry, I didn't realize I never sent my reply. It sounds like specialization is still a long time away. I'll give the nightly version a shot out of curiosity, but would rather not switch to nightly just for this
You can also check formatting, and your scripts
How did you install? With the installer from https://www.rust-lang.org/tools/install? If so, go to something like `c:\users\$USERNAME\.cargo\bin` do you see cargo.exe? If youi open powershell in that folder (shift-&gt;right-click-&gt;open powershell here), and type `./cargo --version` does it work?
Crate that I support use its own binding to bluez API: https://github.com/Dushistov/bluetooth-serial-port , have any sence to switch to libbluetooth ? 1. It is rather strange crate, looks like bindings created by human and not via bindgen, some problems with bindgen ? 2. There is no `-sys` in its name, is it exactly raw binding, or there is some Rust code wrapper?
Yeah nobody mentioned this, but this is the first thing I thought.
Beginner exercises, you start somewhere
I'd love to see a cross-platform bluetooth API in Rust (similar to CPAL for audio, or winit for windowing, but for bluetooth). Do you have any plans to support platforms other than unix-y ones?
In my benchmarks, arithmetic with the smaller types (`u8`, `i8`) was slightly slower than with `u32` or `i32`. I chose `i8` anyway, to save space in the `Move` enum. Now with your `match m.unpack()` idea I won't have to. I chose a signed type to be able to compute offsets without casting (`a - b`). That's also what Stockfish does. However following the signature of `leading_zeros()` is also a good point. (Previously I needed to cast to the smaller type anyway). Mhh ...
Same! Working through the Rust Book and doing exercises on the Exercism Rust Track.
Thanks!
Thanks, and no worries, it does not come across as harsh at all. * I think `PieceType` is more clear on first glance, but then users have to dance around the fact that `type` is a keyword (`piece.color` and `piece.type` etc.). I followed Scalachess with the naming here (https://github.com/ornicar/scalachess/blob/master/src/main/scala/Role.scala). * Both the newtype and the enum would enforce the &lt;= 64 invariant, possibly with an `unsafe` constructor that doesn't. Arithmetic (internally) requires `transmute` (ughh) to go from integer to enum, and `as` to go from enum to integer, which might be a good argument for not using an enum here. For a library it's hard to predict which square's will have to be named, so there needs to be a way to name all of them. * Yeah, it might be best to keep `Move` as simple as possible and introduce types with more information as needed. As you're saying, the current definition is not even enough for undoable moves in standard chess. Additionally lichess.org has chess variants like Crazyhouse and Atomic, where I need to keep track of promoted and exploded pieces.
Is there a way to have global `rustfmt` configuration in stable Rust? I haven't been able to find anything.
&gt;I chose a signed type to be able to compute offsets without casting (`a - b`) Do you have an example of when subtracting a `u32` from a `u32` isn't sufficient?
Martin Luther reformed church and surely changed the world. Can I quote him? He was an extreme jew-hater, you know Luther was born in 15th century. When he lived they still burned witches. Julius Caesar owned slaves and probably thought that they were not worthy human beings as well; can I println! quotes from his Gallo-Roman-War? Calm down. It's an apolitical quote by a awesome horror author.
Sure. `assert_eq!(Square::A1 /* 0 */ - Square::B1 /* 1 */, -1)`.
I'll be adding some small features to cmdr, my framework for creating interactive command line applications [https://crates.io/crates/cmdr](https://crates.io/crates/cmdr) and I'm working on a demo application for it, rusty-cave which will be an old style text adventure.
Any examples where you can't just reverse the order to get a positive result? :P
Are linked lists in rust really much harder to get right than in c? I haven't read "too many linked lists" but my (uneducated) guess would be that the main difference is that you have to know when rust drops things and how to prevent that in specific cases. But I guess there's probably more to it?
Maybe write a newtype wrapper around the raw data and implement iterator that yields (&amp;str, f64, u8, Option&lt;&amp;str&gt;) values?
Of course not :) But in general, when not working with constants, branching on `a &lt; b` doesn't sound like a good idea when signed offsets are a natural solution.
Why is there a ridiculous abundance of linters for go and very few (just one?) for rust?
The first check that a path exists would be more tidily done via: let md = if let Ok (md) fs::metadata(&amp;args.target) { md } else { panic!("The target file does not exist!") }; But even better, you could use std::path::Path, which supports .exists and .is_dir. Additionally, if your tar files will end with tar, which they normally would, you will then have .extension to check if the extension indicates it is a tar file. You can commonise some more code by producing the command like so: let flags = if md.is_dir() {‚Äù-cvf‚Äù} else {‚Äù-xvf‚Äù}; let _outout = ...
As long as a migration failing halts the deploy, what's the problem?
Please ignore any typos/weird formatting. The above was typed on a phone.
For a programming assignment I have to create a small game, and I decided I'd use this to try Amethyst.
Right, I didn't propose that you branch there, I guess I just haven't needed to subtract squares before (that I can remember). You could always cast to `i32`s in the `sub` implementation, by the way. Might be worth it if `u32` is indeed the more natural choice (apart from subtraction).
Fair enough. Agreed.
Not really a code review, but you may want to run "cargo fmt" to standardise the code formatting. It's a really great tool. [https://github.com/rust-lang/rustfmt](https://github.com/rust-lang/rustfmt)
Without looking at the code, do you know clippy? Can recommend :) Looking at the code, I also recommend rustfmt. Here are some thoughts on the code: * File paths aren't generally utf-8 strings. You comments look like you're aware of that, so I won't comment on that further. * You're showing panic messages to the user, which imho is a nogo. You can have a look at https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/question-mark-in-main-and-tests.html and the related docs on error handling. It's a huge topic, I'd still recommend using a separate `run` function as detailed in the link. * You're duplicating the existence check, which probably doesn't matter performance wise a lot, but makes your logic unclear. I suggest going with `let md = fs::metadata(&amp;args.target)?` (and deleting the direct check) in the aforementioned `run` function and then outputting a proper error message from `main`. * You should check for the existence of `{}.tar` and decide what to do if it does exist.
https://docs.rs/actix-web/1.0.0-alpha.6/actix_web/dev/struct.ServiceRequest.html#method.app_data But you should ask this kind of questions in actix‚Äôs chat
Thank you. I generally avoid chats for asking questions because they are often busy, plus asking on forums or for examples to be added makes it easier for others in the future to find an answer with Google in my experience. That being said, I'll give the actix chat a shot next time I have a question :) Simultaneously to submitting the question to StackOverflow I also posted a request for an example in actix/examples on GitHub. Seeing how simple it is I will close that request with a comment with the link you provided here though.
For what it's worth I wrote a small Bluetooth library for Linux in this PR that should be extracted eventually: [https://github.com/libp2p/rust-libp2p/pull/971](https://github.com/libp2p/rust-libp2p/pull/971) In practice I've noticed that the client libraries of BlueZ are kind of crappy and that it's way better to not use them. However I still need to depend on libdbus, as that's what the Linux Bluetooth stack uses. Writing the same code for Windows and MacOS would be quite a lot of efforts though.
You can bind different apps on different ports. It is more efficient than using multiple threads.
Still happily contributing to https://github.com/svenstaro/miniserve My focus this week will be to revamp the errors, and to eliminate all calls to unwrap and display nice error messages to the user instead of panics in unexpected cases.
I'm writing a compiler for a C-like language
Why does not this thread mention the Discord server(s)? They are very active
Is it planed to make this kind of code to work? enum Irrefutable { Variant(u32), } impl Irrefutable { pub fn value(&amp;self) -&gt; u32 { if let Irrefutable::Variant(value) = *self { value } } } #[test] fn simple_test() { let value = Irrefutable::Variant(123).value(); assert_eq!(value, 123); }
But in this particular case, there are no `break`s .
What would such a closure be borrowing for OPs example ?
This crate was the first step to releasing a cross-platform Bluetooth API, but it is currently held up by a PR for Windows support ( [https://github.com/retep998/winapi-rs/pull/753](https://github.com/retep998/winapi-rs/pull/753)). Might have to add a custom WinAPI version to the crate itself, until that passes...
Thank you, I had a feeling it was the case that spawning multiple threads of my own would be inefficient since actix-web in turn spawns threads. I am trying to do as you suggested but have run into a couple of problems. If I can't figure it out I'll head over to the actix chat and ask there though, like you suggested about the other thing I was asking about in the other thread :)
&gt; `floats.sort_by(|a, b| a.partial_cmp(&amp;b).unwrap_or(std::cmp::Ordering::Equal))` Hmm, is it okay to do that? It will compare every value as equal to `NaN`, so if `c` is `NaN`, you could have `a &lt; b`, `a == c`, `b == c`, which is inconsistent. I can't find it, but I recall an issue about potential memory unsafety in `sort` in the presence of inconsistent comparisons. I think the implementation was fixed at the time, but one idea that was floated around was to make `PartialOrd` unsafe.
Check out [this link](https://areweideyet.com) for some comparisons.
Wouldn't it have to be, given the error is rust-specific and not "command `cargo` not found" or something?
[TiKV](https://github.com/tikv/tikv) is written in Rust.
I am making a cli program to manage time: deadlines, schedule, todo's, etc.
1. The bindings are in the style of the WinAPI crate ([https://github.com/retep998/winapi-rs](https://github.com/retep998/winapi-rs)), which allows for more legible code and less bloat due to macro usage. Additionally, it allowed trivial addition of features so debug and default are not forced upon people.
Writing Rust versions of the GNU coreutils to learn, I've done cat, cp, ls, mv and a few more so far.
I get really nervous about new trust-dns releases. When a web application fails due to low level errors, it's not clear that the underlying issue is the dns resolver. This library can't reach 1.0 quickly enough.
You can use different ports. Or you could handle this differently by using 3 apps: - one bin app for the public endpoints - one bin app for the admin ones - one lib app for the code you need to share between the 2 bin apps (your business logic should be here, with some comon tools for api integration)
Yes, I implemented it as the `LCell` type in my `qcell` crate not long after writing that. It's also more noisy because of all the annotations on functions, which is a shame. (I found the original source of the idea in Rust, which is now linked to from the `LCellOwner` docs, so that meant I didn't have to copy any code from that github repository, which doesn't have any visible license, and didn't respond to my request to add one.)
Don't use Tide. Support ecosystem diversity.
Nice! &amp;#x200B; Would be nice if it was more like the bitflags crate though, e.g. make the user not pass around bit indices, but instead generated constants of some opaque type.
You might want to add some anti aliasing, msaa or ssaa at least :)
just publish a crate. It provides basic support of Vert.x eventbus tcp client. Vert.x is a mirco service framework from Java world, if anyone interested. However, it seems no one is actually using Vert.x with Rust.
Something to be aware of: `doctest` does not work in the 2018 edition unless the developer includes a `use` statement for `doc_comment`. This can be fixed by using an absolute reference to `doc_comment` in the macro definition (i.e. "`doc_comment::doc_comment!(‚Ä¶`"), but I do not remember if this is valid syntax for the 2015 edition.
Nice! Does it support any kind of automatic restart? That's one of the most common features of these sort of supervisors, because you want server crashes to be reported but also restarted.
&gt; The bindings are in the style of the WinAPI crate This is sad. WinAPI case is very specific. 1. API stable as rock, it is frozen and no changes at all, only additions 2. It is huge, plus has many internal connections, so every run of `bindgen` takes significant time, and it is almost impossible to teach `bindgen` to generated one module per API group, you have to generate one huge module 3. There is a lot of users of winapi crate, even if there is typo mistakes, like `BYTE` instead of `WORD`, some body find out. But all of these points are false for bluez. Breaking changes are possible, it is small, so `bindgen` can handle API just fine, and there are small number of users, so if during mechanical translation from C to Rust if you made typo, nobody may notice that something goes wrong. Actually because of the last issue I look forward to remove hand written bindings of bluez inside https://github.com/Dushistov/bluetooth-serial-port (this part was not written by me) and use something better. And code generated by bindgen looks better, then generated by human, until human's one has 100% test coverage.
I'm rewriting my rendering engine in Rust. It's build in C++, but I just couldn't bare the pain of serialization in C++ anymore. So now I'm learning Rust and rebuilding it from scratch!
It worked fine for me in 2018 edition by using the "old" syntax: ```rust #[macro_use] extern crate doc_comment; // you can now call doc_comment's macros everywhere in your crate ```
Another tool that can help you find such bugs is [Miri](https://github.com/rust-lang/miri/). Miri does not support RNGs currently (but soon will), but I don't entirely understand why you had an RNG in there anyway so I [adjusted the code](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ef2b9e1f892b9bdd4892d967cc364c20). Now if you select "Tools -- Miri", it will tell you ``` error[E0080]: constant evaluation error: dangling pointer was dereferenced --&gt; src/main.rs:63:20 | 63 | if (*old_tail_ptr).next.is_null() { | ^^^^^^^^^^^^^^^^^^^^ dangling pointer was dereferenced | note: inside call to `List::&lt;i32&gt;::remove_tail` at src/main.rs:8:5 --&gt; src/main.rs:8:5 | 8 | l.remove_tail().unwrap(); | ^^^^^^^^^^^^^^^ ``` That does not immediately tell you what the fix is, but at least you get a better idea about what is going wrong (namely, `old_tail_ptr` is a dangling pointer).
You are very right about the risk of typos. As such I generated bindings by using regex to match and replace. I also used a program to auto-generate tests for all struct sizes and alignments, similar to the test coverage that `bindgen` provides. Where possible I did replace `static` functions and types with Rustified versions. If people find a lot of problems with the current implementation, or prefer a `bindgen` implementation I will consider making the next version using `bindgen`.
Yeah. I try to avoid the `extern crate` construct, so I just did: use doc_comment::*; It would be nice to avoid that. (I make a point of only ever using absolute references inside macros, to ensure than they can be used anywhere with no "dependencies".)
The Amethyst community is great. If you haven't already, I'd recommend joining the Discord.
It is great to see this get a release and I thank you for your hard work. Although I am not using trust-dns-resolver directly it is currently in my dependency chain via the latest actix/actix-web/actix-http alphas. In fact it looks like this release was the last requirement for an actix 0.8 release which is fantastic. My only criticism, which I suppose is understandable when using alphas that depend on other alphas, is that the move from trust-dns-resolver alpha 2 to alpha 3 caused me a few issues. It looks like the alpha 3 release didn't up the minimum trust-dns-proto version which introduced a breaking change in the 0.7.2 release. It took me a while to realise that I still had 0.7.1 in my lock file. I suppose that I didn't expect a breaking change in a patch release until I looked at the docs which suggested that the entire crate was internal/unstable. I understand that SemVer is different for 0.x releases but with much of the rust ecosystem still using 0.x and Cargo treating 0.x.y as ^0.x.y I feel as though it could have been avoided. The other is that 0.7.2 required a minimum rust version of 1.33 due to exhaustive integer match patterns. I didn't spot it on my own machine but my build pipeline picked it up so I had to update the minimum supported version of rust for my project. Fortunately this release has updated the minimum required version of trust-dns-proto and the minimum version of rust is not a big deal for me. So all in all it was just a case of me using alpha software. It has probably taken me longer to type this than to have resolved my problems.
Well, I don't know how to do that with the new syntax (I have to precise that I don't like it much...). Maybe it's a known issue? I recommend you to open an issue on the rustc repository if so.
This looks like a mistake, you're boxing a reference ('it' is &amp;Display). You probably want to either clone or return &amp;dyn Screen instead of Box&lt;dyn Screen&gt;.
Is this publicly available?
&gt; written in Electron and &gt; high performance In one post do not suits me. We already have Xi that tries to fit into ‚ÄúRust-written high performance text editor‚Äù and from what I remember it is quite ok.
I will say though that Atom focuses on customizable much more than Xi. I have plans to write a plugin in Xi but due to it requiring UI-related features I have given up dealing with Xi for now. The project is a long ways out for a lot of things _(multi cursor, customizable UI, etc)_. Creating the plugin for Atom _(as I'm currently experimenting)_ seems a lot more realistic. Yes, I agree that Electron is not likely to allow as high performance as Xi - yet Atom _(/Xray)_ do things that Xi is likely to never support either. They each have their place. Unfortunately Xi is a high performance dream to me currently. I can't wait to use it when the dust settles a bit. Multi-cursor and plugin UI elements would be big for me.
VSCode has managed to provide high-performance[*] in Electron, but that doesn't mean that the world needs another Electron-based text editor. Microsoft now own both Atom &amp; VScode. [*] Within reasonable desires of productivity, compared to Atom which was an utter performance pig last I used it
Electron with wasm and opengl performs better than today's atom. And Xi is a text editor while xray is a code editor.
Shall the crate handle chess variants / fairy chess / other similar games like checkers or better for it to stay focused on just classical chess? Currently it looks like aiming for performance rather than for customizability.
&gt; better than today's atom That isn‚Äôt quite hard to beat TBH.
Thanks for the suggestion! I have never used either tool, where can I learn more? &amp;#x200B; Right now it takes a few days to trigger the bug, but I will try reduce my read interval to make it happen faster.
I wrote a simple rust program that collects temperature data on a Raspberry Pi. After a few days, it crashes with the following error: *** Error in `./sensorpi': free(): invalid pointer: 0x76b65f01 *** ./run.sh: line 3: 8 Aborted (core dumped) ./sensorpi How should I approach debugging this? Am I leaking memory, or does one of my dependencies have a safety issue. I don't have any unsafe blocks in my own code. You can see the code and dependencies here: https://gitlab.com/szaver/sensorpi NOTE: I posted this in last week's question thread a few hours before it was cleared. /u/Green0Photon suggested trying to reproduce while running in Valgrind or GDB.
Got some help from parent commenter in [the actix-web gitter chat](https://gitter.im/actix/actix-web). The way to go was: Server::build() .bind("", "127.0.0.1:8081", move || HttpService::build().finish(App::new() /* ... */ )).unwrap() .bind("", "127.0.0.1:8080", move || HttpService::build().finish(App::new() /* ... */ )).unwrap() .run(); Where `/* ... */` indicates I've omitted for brevity the actual building of the apps. In my real code I use `.data(...)`, `.service(...)` and `.wrap(...)` calls of course.
Looks like someone has already forked xray and is working on getting things going again. They are looking for experienced Rustaceans to help. &amp;#x200B; [https://github.com/fdionisi/xray/issues/1](https://github.com/fdionisi/xray/issues/1)
In my experience they are both pretty slow. VSCode is somewhat better, but not good enough.
I was excited when I first learned about XRay. The big drawback was using Electron yet again. Of course I get the motivation - easy to have a rich plugin ecosystem and a customizable UI if it is based on HTML + JS. But it's a major drawback. I think https://github.com/maps4print/azul might eventually become an excellent basis for a new editor. I think the acquisition of Github will eventually mean the death of Atom though. Sure, they won't come in and say "we have VS Code, Atom is dead now, stop working on it". That's not how these things work. But give it a few years, a firmer control on leadership structures, and Atom will be de-prioritized and slowly dwindle away. That's my prediction, at least. It doesn't make much sense for Microsoft to maintain the development of two very similar editors, especially if their own product already has a big lead.
&gt; And Xi is a text editor while xray is a code editor. Can you elaborate on this? I don't find the comparison to be fair. Xi is more akin to `xray-core`. That is to say, you're not comparison apples to apples, I feel. I actually made a post on the issue tracker discussing this same point. But I question what of Xray _(more specifically, xray-core)_ is needed, and why it should be used rather than exploiting the work being done on the editing core in Xi. Do you think there is something fundamentally different about the CRDT model Xray is using over that of Xi's?
&gt;&gt;written in Electron &gt;and &gt;&gt;high performance &gt;In one post do not suits me I see a lot of comments that Electron is bad. Why? UI can be done in any language, it doesn't matter unless it blocks the core, which is not. Electron provides nice way to create UI, which allows more to be done with JS and CSS, compared to what allows GTK for example. I know that there's Qt with their QML (which is also JS under the hood), but it is easier for most devs to work with Electron because many people are experienced in Web development nowadays. So why Electron is bad as UI framework? Sure if you write full application on JS it's not going to be as fast as native, but if core is written in Rust or C/C++ it gonna be as fast as if UI was implemented using those languages.
If the purpose was for code sharing only then yes, but this was for the purpose of sharing mutable state between the two apps. Either way, the question is solved now thanks to some help I got from /u/fafhrd91. (See sibling comments ITT.)
This would be a far more interesting project if it would explore emerging technologies instead of using Electron. I would personally explore WebAssembly + WASI + WebRender combination.
electron based means electron front end + rust backend?
I'm implementing a SQL database for fun ([SueQL](https://github.com/sieut/SueQL)) and have been working on logging/recovery the last few weeks. Just got that part done a few days ago. I'm having a lot of fun working on a low-level project with Rust! The next things to come are indices
Yea, in Xray at least. The core editing runtime is a copy on write model written in Rust. Looks like it (xray-core) has a ton of overlap with Xi, but [as is being discussed](https://github.com/fdionisi/xray/issues/1) it differs in some goals that may mean it cannot exploit Xi fully. Which is a shame. I'm not sure another community CRDT editor core can survive. I'm tempted to be involved, but I really dislike the idea of having to re-invent every wheel that Xi is currently solving purely for the sake of in-browser WASM compat.
Running whole browser, with all of browser features, just to edit text is a little overkill IMHO. For example what is the need for WebP decoder in text editing? Or LocalStorage? Cookie management? Or [user-space Xbox pad drivers (which are included by default in Chromium release on macOS)](https://josephg.com/blog/electron-is-flash-for-the-desktop/)? Also the enormous bloat of the memory it takes just to run, not to do anything, just display colourful letters and [blinking cursor](https://github.com/Microsoft/vscode/issues/22900). And, no, [performance will be not even near of native solutions](https://pavelfatin.com/typing-with-pleasure/). Additionally such applications take hell lot of disk space. Of course there will be many people who will say that ‚Äúdisk space is cheap‚Äù but in any way this isn‚Äôt the excuse for needlessly using it to store the same data over and over again, I really have better use for my disk space than storing Chromium 5 times just to display some text. Electron is personification of everything that is wrong with ‚Äúmodern world development‚Äù and the sooner we establish that it is bad the better. IMHO some big application store should disallow all Electron application like it once did with Flash applications and maybe that would prevent that bloat.
Their "revolutionary" UI architectural idea is something that neovim and many others already do, wherein the UI is a thin layer that works only via async. Neovim uses messagepack and decouples the UI logic.
Are you involved with Xi? How mature is the backend? Front ends are all "unofficial", no? How usable in general is it?
&gt; Electron-based I think I see it moving still. Hand me your gun.
Why exactly should we donate time to what looks to be the project of a corporate entity?
People always say "fast enough" but usually fail to cite UI studies and/or provide measurements.
&gt; I see a lot of comments that Electron is bad. Why? It's slow and bloated. &gt; it is easier for most devs to work with Electron because many people are experienced in Web development nowadays. Optimizing for ease-of-development is an incredibly user-hostile attitude.
The goal is to support at least all variants available on lichess.org (https://lichess.org/variant). This means no fairy pieces, 8x8 board, 2 player perfect information game. shakmaty currently distinguishes `Board` (mapping only pieces to squares), `Setup` (piece positions, side to move, castling rights, ep square ... but not nescessarily legal) and a `Position` trait for legal positions, that allows implementing all the variant rules. This is possible without making too many compromises for standard chess performance. I am not opposed to make it more flexible than that, but only if standard chess remains fast.
&gt; It's slow and bloated. I can take the *bloated* argument, because it's really is bloated. But slow? UI itself performs really fast, as long as your machine handles complex web pages. Sure it's not as fast as native UI, but it's not the main bottleneck either. &gt; Optimizing for ease-of-development is an incredibly user-hostile attitude. I disagree. Users may want to hack on the implementation, and if it's easy they may become developers. That's why Emacs has so many packages - it's easy to develop one in Emacs Lisp. Compared to Visual Studio (not code) that isn't optimized for ease-of-development, it's extremely hard to write plugin for it. End user usage experience doesn't really vary if it's easy to develop for application or not. But generally it's better if it is optimized for easy-of-development, but of course it should also mean clean and understandable source code.
Oh, sorry that you had that issue with the third alpha. I‚Äôve been planning to try and build some tests to try and catch the min version issue, as this has happened before. One thing I‚Äôm considering is versioning all the libraries together, which I haven‚Äôt done because I wanted the flexibility of releasing individual crates when needed. Though, that has tended to cause issues. I am working on some automation to use cargo semverver so that I can be more confident with the release versions. And then I could just bump the dependencies between all the crates together.
Might want to reach out on the actix gitter https://gitter.im/actix/actix
Overall approach is reminiscent of [kcov](https://github.com/SimonKagstrom/kcov).
I use VSCode on my workstation, can't use it on my latpop, apparently 4 cores with 16Gb of RAM isn't enough to edit source code. /s
Looks like it is MIT licensed. Is there something better you expected?
It's an anecdotal response to the anecdotal assertion that it's too slow. I'd like it to be faster, but I've settled with using it for well over a year now in my day job. It doesn't actually impede me from doing anything. The development velocity seemingly offered by using Electron outweighs the minimally noticeable performance drop-off. YMMV, this is on relatively high-end hardware.
&gt; as long as your machine handles complex web pages. Why should my machine need to handle complex web pages to edit text?
Not involved, just did some basic research / cloning to get a feel for writing my text editor plugin for Xi. The [Mac frontend](https://github.com/xi-editor/xi-mac) is official, and seems pretty usable. However "core features" are still being discussed and implemented, which to me means largely APIs for plugins. The editor itself focuses largely on nailing the core of editing text, and allowing plugins to do the rest - so it is quite lacking on features for code editing, as there are minimal to no plugins. The API is evolving, and I believe they are solving problems that need to be solved and making good progress. I'd *love* to see Xray use Xi as a backend. Especially since Atom/Xray is going to excel at being a great frontend, and Xi is going to excel at being a great backend, so it's a shame to see Xray doubling up on work. [So far](https://github.com/fdionisi/xray/issues/1#issuecomment-483236989) it looks like two reasons why Xray might be unable to use Xi is that it: 1. Apparently has a goal of being in-browser, WASM compatible. I'd hate to see this stop Xi integration though, as the merit of in-browser for a plugin-rich code editor seems half baked at best. How many LSPs do you imagine will even run in the browser? 2. Focuses on collaboration - hard to say if this is a problem for Xi, but I don't believe it's a goal of Xi's. I will say that if Xray doesn't use Xi, I will question my desire to contribute to the project. I don't believe Xray will be able to gain enough open source traction to make everything work *and* make a competent, powerful and fast CRDT research based editor core. I'd rather place my eggs _(contribution time)_ in another basket.
in case you develop web pages it should
In all seriousness, having Slack open in one of my Firefox tab sucks more memory than the many VSCode windows.
https://github.com/neovim/neovim/wiki/Related-projects#gui and one can continue to use their neovim plugins, which can be [written in rust](https://blog.usejournal.com/a-detailed-guide-to-writing-your-first-neovim-plugin-in-rust-a81604c606b1).
I'm doing some deep introspection on xi right now. I haven't written up my thoughts because I'm overbusy, but will give a preview. First, you're certainly wrong on multiple cursors, that's been in there a while. On the other hand, you're not wrong at all on customizable UI. To add a UI feature basically requires adding to the JSON protocol and implementing both the core side and the front-end side in each of the viable front-ends, of which xi-mac is the only one that's polished. I do see this as a problem, and am trying to figure out the best path forward. What I think is the most promising is to build UI in Rust, which is very much the motivation behind [druid](https://github.com/xi-editor/druid). In fact, druid is the evolution of xi-win, which was an experiment to write the Windows front-end in Rust. I'll have more to say soonish, but did want to update the thread.
Not sure what you are up to exactly. I find [https://github.com/void-rs/void](https://github.com/void-rs/void) interesting.
My guess is a combination of things: - Go has been around longer and is more popular. - Forgetting to check an error value is easier in Go, so the tools that catch those mistakes are more necessary. - Because the "official" `golint` is relatively minimal, the Go community has been inclined to make their own linters. Maybe (someone should correct me here) Clippy was better at getting community involvement into growing itself, which reduced the demand for other standalone linters?
What if I edit running programs? You going to include a full debugger? What if I edit minecraft worlds? You going to include a minecraft clone?
So who uses this? Perverts or Prudes? ;-)
I'll add that parsing is the one aspect of writing a compiler where technical debt is most easily bearable. You need to think long and hard about your grammar and your AST, but the specific code that maps one to the other can be arbitrarily nasty. I'd recommend doing it via recursive descent. Parser combinators are enlightening to know about because they're a good example of how powerful an applicative or monadic DSL can be, but they are functionally equivalent to recursive descent.
The difficulty comes from sorting out the ownership story, especially with bidirectional lists. You pretty much need raw pointer and `unsafe` to do it properly.
&gt; First, you're certainly wrong on multiple cursors, that's been in there a while. Awesome, last I talked with Xi people I was told that I could implement it but it wouldn't be viewable on the UI haha. &gt; On the other hand, you're not wrong at all on customizable UI. To add a UI feature basically requires adding to the JSON protocol and implementing both the core side and the front-end side in each of the viable front-ends, of which xi-mac is the only one that's polished. For context _(since I imagine you care about plugin devs desires for your project)_, I actually don't require too much on the UI front. Some basic info popups in multiple forms, modals, status bar, etc should be plenty. However, while some of these are in Xi-Mac, I wasn't prepared to try and get the missing ones into the editor on my own. Both the editor core and the UI, from the outside, appear in just enough of a flux state as to cause friction for interested devs. While my end goal is to entirely use Xi _(or imo, ideally Xray backed by Xi)_, it just seemed a bit of an uphill battle when I'm still trying to suss out the viability of my editor plugin in general haha. If my tone seemed harsh towards Xi that was not my intent. Rather, I'm too excited for the project and perhaps a bit frustrated that I'm even looking towards Atom _(and currently working on a plugin in Atom)_. Xi really appears great, and I appreciate your work there. :) I would love for you to share your thoughts in https://github.com/fdionisi/xray/issues/1 - as Xray/Xi has been discussed before, but not quite in the context of Xray's deathbed. Perhaps you'd have some insight there.
Could you give a try to https://github.com/GuillaumeGomez/doc-comment/pull/10 please?
This is part of the image forensics features that I've been working on in [sn0int](https://github.com/kpcyrd/sn0int), an OSINT framework. So I guess the answer is forensics. :)
&gt; Optimizing for ease-of-development is an incredibly user-hostile attitude. I disagree. I switched from Sublime Text to VSCode years ago because 1) The development progress was much faster and 2) There are more and better quality third party addons available. User-experience very much benefited from that decision in the end.
Probably social networks and chat apps.
All good suggestions, looks like they work.
Great work! Impressive numbers. But... can it detect whether something is a hotdog, or not hotdog?
&gt; What if I edit running programs? You going to include a full debugger? What if I edit minecraft worlds? You going to include a minecraft clone? No but if you edit Emacs source I would like to include kitchen sink.
We're creating so many abstractions and advanced web layers over electron to the point were writing electron is harder than just traditional GUI's anyway... Could we stop trying to force electron to have good performance when it's clearly not a part of its core design.
No, the implementation is quite simple, it classifies each pixel for skin/not skin, groups them into regions and then does some heuristics on the number and size of those regions. nude-rs, nude-js and nude.py all share the same implementation of [this paper](https://sites.google.com/a/dcs.upd.edu.ph/csp-proceedings/Home/pcsc-2005/AI4.pdf?attredirects=0).
That's not a leak, that's probably either a double-free or an out of bounds write that clobbers some of the allocator metadata. Assuming your code is unsafe-free it's a bug in a dependency. Valgrind is probably the easiest bet. It'll be slow, but not any worse than 5-10x slower than normal. You can alternatively try using address sanitizer but you'll need to rebuild all of your C dependencies as well as Rust code with it.
&gt; Why should my machine need to handle complex web pages to edit text? It doesn't. However if you think that is the goal then you're missing the entire point of the project.
If you search the xray blog series I think you will find mention about Xi-editor and the similarities between them. I think they also commented that had they been aware of it earlier they could have used that as a foundation and could have progressed faster as a lot of the work they did was duplicated between the two projects. I was just wondering if it might be best to investigate what components and approaches Xi could steal from xray and maybe maintain a single project so that it can progress further.
Not yet. It will be once it's reached a minimal level of functionality.
There are fundamental differences between the Xray and Xi approaches to CRDT. &amp;#x200B; Xray's CRDT is designed from the ground-up for collaborative editing. Peers are fully autonomous, each containing a full copy of the CRDT. &amp;#x200B; Xi's CRDT is designed specifically for handling *plugin* edits. The core acts as a central server; plugin edits occur against a specific revision of the document, without the plugin having to handle any CRDT logic. &amp;#x200B; This is a tradeoff. There are some things that have proven very difficult with xi's model; one of these is associating selections with revisions for the sake of undo. I \_believe\_ that in Xray selections are fully part of the CRDT, although I haven't looked into this too closely.
So I currently have a use case like this for the VPN setup at work: I'd like a little daemon that I can configure to have the company's DNS resolver for some specific domains, but forward all other requests to "real" DNS resolvers like [1.1.1.1](https://1.1.1.1). I'd be happy to write some code, but how to do it wasn't very obvious from a first glance at the docs. Want to provide some pointers?
I'm not sure I have a lot to add to that issue, as I've only been following xray loosely. What I think I'll do is write a retrospective of xi along with a roadmap of how I think it could evolve (possibly as two separate blog posts). As an overall theme, I am worried about xray's complexity, just as I am worried about the complexity that has developed for xi as we've tried to figure out how to do more features within the original multi-process architecture. A focus will be simplifying, basically optimizing to make it easier for people to add features.
VSCode seems fast until you try Sublime Text. I used Sublime for a few years before I switched to Atom, then VSCode, and it's so easy to forget just how amazingly fast it is -- or rather, how slow these Electron-based editors really are. While VSCode is (or was, it's been a while) faster than Atom, the last year or so it's started to suffer from the same disease that eventually made me unhappy about Atom: A proliferation of slow, memory-hungry extensions. When you keep piling on modern IDE features like code indexing, Git diffing, linting, background compilation etc. that do all sorts of stuff in the background while you work, these editors end up getting sluggish because of the cumulative weight of all those operations in a language that doesn't really scale all that well. I routinely have "Code Helper" processes that consume 1GB of RAM and lots of CPU.
You are not alone friend!
PM_me_when_HL3, you got a Happy Number in your comment ID! The Happy Number is 635, and your comment ID was eky0635. Here's a link to what Happy Numbers are: https://en.wikipedia.org/wiki/Happy_number. The comment ID is a unique 7 character string which identifies your comment in the sea of Reddit. (I'm a bot by the way, downvote to delete this comment)
&gt; or prefer a bindgen implementation I will consider making the next version &gt; using bindgen As potential user of your library I prefer `bindgen`, but why `either`, `bindgen` has it is own disadvantageous - you need `libclang` and all its dependencies, it is completely ok for everyday development, but if you do some research work and you need just do some bluetooth experiments may be this is not ok. So why not do things like https://crates.io/crates/libsqlite3-sys , it provide too options via features, use pre-generated by bindgen code or strait bindgen usage, the same way possible for your crate, feature to choose between existing code or generated by bindgen.
Just use an Electron app on a computer without extreme high-end equipment and limited storage.
I really need to get working on that mdbook I keep talking about ;) This is in fact what I‚Äôve been planning to do over the next couple of weeks. Again, I‚Äôll make it clear that the integration with the resolver is experimental. I‚Äôm not sure if I like the configuration files atm for it. Let me point you at the test configuration for this feature: https://github.com/bluejekyll/trust-dns/blob/master/crates/server/tests/named_test_configs/example_forwarder.toml At the moment I don‚Äôt have much more details than that. This has more of the other configuration options defined: https://github.com/bluejekyll/trust-dns/blob/master/crates/server/tests/named_test_configs/example.toml I‚Äôm definitely interested in feedback on using the forwarding feature, there are probably edge cases and deviations from the standard that need to be taken care of.
&gt;That's not a leak, that's probably either a double-free or an out of bounds write that clobbers some of the allocator metadata. Assuming your code is unsafe-free it's a bug in a dependency. Thank you for the confirmation and suggestions.
Hey thanks for the feedback! I'll definitely look into this for a 0.2.0 release! My use case was simply a need to keep track of which pins were initialized within each port of a microcontroller; as such indices were a simple solution. But named flags would definitely be a step up - especially for other use cases.
So we should just start contributing to any repository that has permissive licenses? If the project died, there's an apparent lack of interest to continue.
If you just want to edit text, its fast and it handles absurdly huge files. If you want an IDE, or even just edit Rust code vim/emacs style, then it's not even close to being usable.
I hate to be a zealot, but really, why should we care? Electron and Rust are near polar opposites. One is focused on safety and efficiency, whereas the other is a bloated mess of out-of-date, bug-ridden chromium instances. I respect the momentum and love put into electron applications, but the technology is just so incredibly wasteful. &amp;#x200B; Instead of X-Ray, why not spend time contributing to a sustainable GUI ecosystem for Rust? Might I recommend \[Azul\]([https://github.com/maps4print/azul](https://github.com/maps4print/azul)) or \[druid\]([https://github.com/xi-editor/druid](https://github.com/xi-editor/druid))?
You are using `rust-gdb`, right?
&gt; There are more and better quality third party addons available. Optimizing for third-party developers is a completely different decision. I would not call it user-hostile. Saying "who cares lots of people can use electron so that's what you get" is.
No, I just don't care to donate to big open-source just because it's in Rust
Correct. Printing an option results in (gdb) print __option_var__ $1 = core::option::Option&lt;__type_of_var__&gt;
In fairness, Tristan Hume's work on the CRDT was directed at collaboration as well, and we had a demo running on Fuchsia. However, we haven't been pushing this forward, and it has not evolved into a collaboration feature.
16Gb as in 2GB?
&gt; That's why Emacs has so many packages - it's easy to develop one in Emacs Lisp. Compared to Visual Studio (not code) that isn't optimized for ease-of-development, it's extremely hard to write plugin for it. Optimizing the experience for plugin writers is not user-hostile at all. Saying "who gives a shit that your editor is slow, it was easy for me to write" absolutely is.
aren't plugins supposed to handle that kind of stuff? To keep the core lean?
&gt; But in this particular case, there are no `break`s . Well yes, which is why they used `for_each`. The thing is that being able to tell if outer or inner loops are better is not easy, so it makes sense to instead give the programmer the tools to ensure that things work efficiently instead of them having to fight the compiler. The question was: why doesn't `for` compile directly to a `for_each`. that is why not do what the PR proposes, by default for all for loops? And the answer is because sometimes it might be better, sometimes it might be worse.
&gt; Optimizing for ease-of-development is an incredibly user-hostile attitude. The alternative is going native, closed source, and charging $$$ like nearly every native IDE on the same caliber as VSCode or Atom.
Do you view those differences to contribute to the statement of the OP that Xray is a code editor, Xi is a text editor? This was what I was replying to, trying to understand why the author felt Xi was not a code editor in the way that Xray is.
Started working on adding prefix-types to [abi\_stable](https://github.com/rodrimati1992/abi_stable_crates) . Prefix-types are types that can add fields(at the end) in minor versions,designed specifically for vtables and abi\_stable modules (modules are represented as structs of function pointers). Prefix-types will be limited to immutable types,accessed behind shared references,using accessor methods,because if the field does not exist(because it was passed from a previous minor version of the library) it has to provide a default value/panic/return Option&lt;FieldType&gt; from the accessor. This way it'll be possible to evolve a library in minor versions,adding new functionality that requires adding vtable fields,or adding functions to an exported module.
no, I'm not sure what the distinction between a 'text editor' and a 'code editor' is.
Thanks to help from RalfJung, I managed to change my design for [compact_arena](https://github.com/llogiq/compact_arena) to a more traditional branded index based one that should be easier to prove correct. Next, I'll try to experiment with Send/Sync and improve the macros.
I agree, but VS Code is pretty fast for Electron based application. So it depends on code quality. Sure it's not as fast as, say, Sublime Text 3, or Kakoune, but it works faster in some cases than Emacs (usually big files). If it's core was implemented in Rust instead of JS it would be even faster. Oni is great example, though not really because they dropped Electron (phew! that's actually good). I understand that Electron is huge and bloated, but if the core is written in native language, it would matter much much less in terms of speed. Resource usage would still be the mess. To be clear, I don't use Electron based apps, I just want to hear reasonable thoughts why Electron as UI framework is bad. u/Hauleth [provided great example why](https://www.reddit.com/r/rust/comments/bdf3lx/we_need_to_save_xray/ekxqz17/). But slow application core written in the same language as UI is another problem, so I don't really take __slow__ as an argument here.
It does not run the doctest when I do `cargo test`.
Yes.
Microsoft doesn‚Äôt own Atom. They own Github, but that‚Äôs not the same thing.
[removed]
What about writing a single cross-platform high-performance UI using Flutter, now that [Flutter will officially support desktops](https://github.com/flutter/flutter/wiki/Desktop-shells)?
Great post, thanks for sharing :)
It's a possibility, but at the moment I'm most excited about doing all-Rust GUI, both because performance and also because not doing cross-language programming is a potential opportunity for simplifying the whole thing.
 [https://doc.rust-lang.org/std/macro.dbg.html](https://doc.rust-lang.org/std/macro.dbg.html) can be helpful
I use VS Code daily for Node.js and Java EE development on a laptop with a 6th-gen dual core i5, 8GB of RAM, and a $30 bargain bin-tier Kingston SSD. Is that enough?
I will look into libsqllite3-sys to see if it is a viable option. If so, I will implement it when I have some time. Thank you!
I wasn't arguing that anybody should contribute to it. I was arguing that the licensing makes it trivially easy for this to not be a project of a corporate entity, so if that was the hangup, you could just fork it and get over it. If anything, that license and a lack of company-sponsored interest makes it all the more *not* a corporate project.
There are plenty of reason to not contribute. I just don't think "this is an abandoned MIT-licensed corporate project" really qualifies as one.
Nope! Suspicious parents and the prawn addict.
&gt; Electron is personification of everything that is wrong with ‚Äúmodern world development‚Äù and the sooner we establish that it is bad the better. IMHO some big application store should disallow all Electron application like it once did with Flash applications and maybe that would prevent that bloat. Let's not pretend that it doesn't have enormous benefits in terms of development speed as well. I hate slow apps, but there's no way a ton of applications that are widely used today would be as feature rich without electron.
Test data contains only female presenting nipples, which Tumblr said are dirty and shameful, but no potential false positive male presenting nipples, which Tumblr said are wholesome and good for you.
&gt;I see a lot of comments that Electron is bad. Why? In the past I've been pretty okay with electron, but some recent experiences at my job have soured me on it somewhat. It's all fine and dandy if you have *one* electron app running on your computer, but my poor work laptop starts to struggle when I have Fuze, Slack, and VSCode (all of which are electron apps) open at the same time as Chrome plus multiple instances of Excel.
Would be. Just these applications would be designed in better way and would be created slightly slower. There is not a single thing that Electron allows that native environments do not provide.
&gt; There is not a single thing that Electron allows that native environments do not provide. Cross platform GUIs that look the same in each environment without a lot of platform specific code?
I personally was really excited about xray, if i knew more than jack-shit about making a text-editor Id fork but i don‚Äôt think it‚Äôs a novel cause for me to pursue personally. I hope it gets picked up again soon
You have hell lot of cross-platform UI toolkits (GTK+, Qt, wx), and if you do not want to be very platform specific you could always use GLUT to create window and build everything within OpenGL window. There were Java libraries for cross-platform GUIs (see IntelliJ or Eclipse). The only problem is that it required skilled people, you couldn‚Äôt just throw your spare FE developers that are currently drinking soy double latte made from ‚Äúcruelty free‚Äù beans to do the job.
&gt; In the field of photogrammetry, it is common to see 64-bit, 128-bit, 256-bit, etc binary feature vectors extracted from image features to perform image matching. A binary feature vector is just an unsigned integer with each bit representing a single dimension of the data, which is usually uncorrelated pixel intensity or gradient comparisons. Are the feature vectors something like tiny histograms? I'm curious how this would be used, but I know nothing about the subject.
Neovim or (Neovim)[https://github.com/veonim/veonim]?
&gt; You have hell lot of cross-platform UI toolkits (GTK+, Qt, wx), and if you do not want to be very platform specific you could always use GLUT to create window and build everything within OpenGL window. All those cross-platform UIs don't give you a uniform look across different OS's. The latter approach via an OpenGL window would be vastly slower than something like Electron. Would I prefer if spotify, slack, vscode, etc. had native GUIs? Yes. But in reality, if they didn't use electron, they wouldn't have a desktop app at all (or would only have desktop apps for windows/osx). &gt; The only problem is that it required skilled people, you couldn‚Äôt just throw your spare FE developers that are currently drinking soy double latte made from ‚Äúcruelty free‚Äù beans to do the job. You seem to have a strong disdain for FE developers.
Not only do the IDE features do a lot, sometimes they run into errors and consume resources while being an unusable state, forcing you to restart VSCode.
This sounds interesting. Do you have any more information? What workflow/experience you're targeting?
Is it pronounced "buhssuhni" or "boossooni"?
Still procrastinating by writing video games with `ggez`, it seems. Idly wondering if anyone would pay for a private crate hosting service, as if I didn't have enough side-projects.
Nothing that sophisticated, in most cases. In the simplest version, you have a patch of an image and a list of pixel coordinate pairs. For each pair, test if pixel A is brighter then pixel B and store result as a bit in the feature vector. Thus the vector records the results of a sequence of tests. When checking the distance between two vectors, we just count how many of the corresponding tests gave the same result for each vector. This is called the hamming distance, and can usually be implemented as a really fast XOR instruction.
I agree with you... Electron feels more Like the best tool to prototype something very. You can really have a fully functional UI with nice views but the performance are not very predictible (memory/disque loads)... That shouldn't be the case for a packaged and distibuted app...
Not really. Save memo (the cool part of Xray) and the cool CRDT stuff they were doing and fold it into VS Code and Theia. A much better use of everyone's time.
Haha! I prefer "beesweeni".
It is, but my issue is when I record a session with `rr`, and I can't see any values I haven't put in `println`s and `std::dbg`s. It makes debugging somewhat complex bugs a real chore :(
So you take grayscale patches of say 23x23 (to fit in 256 bits), then look up their neighbours in this tree. Is that useful as a first step for things like aligning images?
Cool. One of the things on my bucket list was to ~~steal~~ extract [this](https://github.com/BurntSushi/imdb-rename/blob/master/imdb-index/src/index/names.rs) fuzzy matcher from /u/burntsushi's code. It looks a bit fancier, though.
Just to clarify, I believe /u/jkoudys is referencing the show "Silicon Valley", wherein a character [creates an app to identify hot dogs](https://www.youtube.com/watch?v=ACmydtFDTGs).
Thanks. I plans to support levenshtein automata or a bk-tree when the much larger data scale is required, but the simplicity will be always keep in mind.
Internals thread: https://internals.rust-lang.org/t/9819
If we make it part of the for loop, why not: ```rust for elem in await stream {...} for elem in await? stream {...} ```
&gt; All those cross-platform UIs don't give you a uniform look across different OS's. Qt does. In fact, Qt Quick's big problem is that it *can't* look native on desktop OSes because its GPU-driven rendering doesn't have the "proxy to the OS theming" style options that they put so much effort into on the QWidget API. QWidget-based UIs actually have two layers of customization which can give you a UI that's the same across all desktops: 1. Writing [style sheets](https://doc.qt.io/qt-5/qtwidgets-widgets-stylesheet-example.html) to customize your `QStyle`. 2. Choosing or writing a [QStyle](https://doc.qt.io/qt-5/qstyle.html#details) subclass which doesn't delegate to the OS's theming system. (eg. You can use Linux styles other than `QGtkStyle` on any platform.)
This would be interpreted as (for (elem) in (await!(stream))) which is not what we want. `Stream` is conceptually an `Iterator` that (potentially) requires `await` suspension to get the next element out.
A friend of mine is a moderator of a mid-sized subreddit. I believe he was experimenting with the Python implementation of this algorithm to do automatic detection of porn submissions.
I think that your parse fully expresses the concept of stream - \`await\` is the suspension point of the \`stream\` and I don't know why it's undesireable. &amp;#x200B; Conceptually (not in Rust) \`Stream&lt;T&gt;\` is \`Future&lt;T, Steam&lt;T&gt;&gt;\`, i.e. \`Future\` of element and continuation. I think \`await\`-ing on the stream is exactly what we want - it 's Future at the end.
Did I miss something? As far as I could find in the paper, the images used in evaluation weren't made available ‚Äî who knows what was in them? I am skeptical of the ability of the procedure as given in the paper to detect the difference between faces and bodies, to give just one example. It sure looks like a face would meet the given criteria for "nude": I suppose that this is technically correct, but in this case I'm not sure that's the best kind of correct‚Ä¶
More or less, yes. Patch size varies a lot between methods, as does which pairs of pixels you consider. You could easily use a big patch and small feature vector if desired, it just might not have much descriptive power. There are a few ways to look up neighbors. FLANN (or this tree structure) is one way, but you can also just do a brute-force N^2 all-pairs search. That works fine for small sets of images, since the XOR distance check is fast. And yes, finding correspondences between images is a textbook first step for doing image alignment (though their are other possible ways).
Sure. It doesn't really make a difference in this case since they are both zero sized types. PhantomData is more convenient to instantiate though, so I think that would be the main reason to do it.
You still need to tell the difference between \`Future&lt;Item=T&gt;\` and \`Stream&lt;Item=T&gt;\` even if the latter is just \`Future&lt;Item=(T, Stream&lt;Item=T&gt;)&gt;\`.
Thanks for all the hard work everyone has put in to get to this point. The `image` crate, under whatever provenance, is a vital and high-quality piece of the Rust ecosystem.
I thought about this too, and then realize the issue. Let's rename things to avoid focusing on names: for elem in await &lt;expr&gt; { ... } Now, let's look at the typical meaning of `await &lt;expr&gt;`: let elements = await compute_sequence(); for elem in elements { } Clearly, in the above, the loop is *NOT* async; computing the sequence is, but afterwards everything is synchronous. Let's remove the temporary variable: for elem in await compute_sequence() { } Is a synchronous loop iterating over an asynchronously computed sequence.
I'm eager to hear what the proposed syntax for the regular await will be. After playing with async/await a bit on nightly, the common prefix syntax really is a ill fit for Rust. It requires a lot of awkward parentheses. Yet all of the postfix variants I've seen feel suboptimal too. We'll see.
So... Prudes.
Ah, that's fair. I see your reasoning. My argument is more that just because something is backed by a company and popular, it doesn't mean it's worth continuing. I see now that regardless of my opinion that was not what you were arguing, my apologies!
immoral
image is an awesome crate and I fully support this change. Great work all!
So what performs better, `nude-js` or `nude-rs` compiled to wasm?
It's not equivalent ;)
That's an interesting question, the nude-js tests had to be executed in a browser because the node port is defunct since quite a while. They are using canvas internally while nude-rs would either decode the image in wasm or need some sort of bridge to access a html5 canvas.
I just tested it without \`target-cpu=native\` and it is actually negligibly faster. The quality of the hashes with the fallback algorithm in \`ahash\` is probably reduced, but it doesn't seem to be impacting average performance.
`await for i in stream` does roll off the tongue nicer.
Read subreddit description before posting. (Do it on whole reddit).
What about Gotham?
Thanks for calling this out. I have a blog post partially written on it, but the motivation section alone is 4,000 words, which seems absurd. So I'm trying to figure out how to shorten it. In the mean time though, that fuzzy matcher went through some fairly rigorous testing and evaluation, from an IR perspective, including dynamic stop word detection. The [README describes how to run an evaluation](https://github.com/BurntSushi/imdb-rename/blob/master/README.md#evaluation), although the details are exceptionally light. It even comes with its own truth data: https://github.com/BurntSushi/imdb-rename/blob/master/data/eval/truth.toml The evaluation is parameterized over several things like ngrams, the ngram windowing strategy, the similarity function (levenshtein or jaro) and even the ranking strategy (jaccard vs tfidf vs okapi). The evaluation helped me discover a lot of interesting things, and also helped choose the right default configuration for the name index. For example, here's the summarization output from the evaluation: $ imdb-eval --summarize tmp/eval.12.csv| xsv sort -R -s mrr | xsv table name mrr found size-30_ngram-3_ngram-type-window_sim-none_scorer-okapibm25 0.23958662355294919 0.9019607843137255 size-30_ngram-3_ngram-type-window_sim-none_scorer-jaccard 0.19968821939241913 0.8431372549019608 size-30_ngram-3_ngram-type-window_sim-none_scorer-queryratio 0.19423091505674775 0.6470588235294118 size-30_ngram-3_ngram-type-window_sim-jaro_scorer-tfidf 0.15267397345078657 0.7254901960784313 size-30_ngram-3_ngram-type-window_sim-jarowinkler_scorer-tfidf 0.15267397345078657 0.7254901960784313 size-30_ngram-3_ngram-type-window_sim-jaro_scorer-queryratio 0.1487564399722983 0.6862745098039216 size-30_ngram-3_ngram-type-window_sim-jarowinkler_scorer-queryratio 0.1487564399722983 0.6862745098039216 size-30_ngram-3_ngram-type-window_sim-jaro_scorer-okapibm25 0.14566927479632455 0.7254901960784313 size-30_ngram-3_ngram-type-window_sim-jarowinkler_scorer-okapibm25 0.14566927479632455 0.7254901960784313 size-30_ngram-3_ngram-type-window_sim-jaro_scorer-jaccard 0.14331166508577367 0.6862745098039216 size-30_ngram-3_ngram-type-window_sim-jarowinkler_scorer-jaccard 0.14265807031453184 0.6666666666666666 size-30_ngram-3_ngram-type-window_sim-levenshtein_scorer-queryratio 0.13306468127675558 0.6274509803921569 size-30_ngram-3_ngram-type-window_sim-levenshtein_scorer-tfidf 0.13286097468359667 0.6274509803921569 size-30_ngram-3_ngram-type-window_sim-levenshtein_scorer-okapibm25 0.13166027451230825 0.6470588235294118 size-30_ngram-3_ngram-type-window_sim-levenshtein_scorer-jaccard 0.13081318128905403 0.6274509803921569 size-30_ngram-3_ngram-type-window_sim-none_scorer-tfidf 0.11354892563773417 0.49019607843137253 So the best performing configuration (among windowing 3-grams) was okapi with no additional similarity function. Having an evaluation makes it possible to reason about changes to the search process, and having truth data enables progressively building up your own set of regression tests based on search quality. I highly recommend investing the effort into building an evaluation for tools like this.
It will become ambiguous if it will be decided to implement proposal similar to this one: https://internals.rust-lang.org/t/6625
That doesn't sound like the only alternative. Nothing about 'native' implies closed source.
On another computer I see regression, so it seems to be machine dependent (probably newer processors are faster at AES).
^
In the case of AKAZE, it actually computes the scale space using a few iterations of a special diffusion equation and then, based on the scale of the sampled location, it will sample the pixels and the gradients across the image in an orientation and scale-invariant way, so it doesn't work with fixed image patches at all. The sampling locations have to be approximately the same for a given feature regardless of its orientation and scale for matching to work correctly. ORB samples just 2 pixels and compares them without doing any smoothing or anything, which can be a little rough, but it turns out it is very fast in practice. Since ORB was released, others have been made (like FREAK) that work almost the same as ORB but change sampling patterns and such. ORB does use a fixed square of the image to do its pixel sampling from, unlike AKAZE. ORB is not scale-invariant though, so to compensate it is typically ran at several down-samples in a pyramid (like mipmaps, if you know that), which may result in the same feature being extracted multiple times, but that is necessary to extract it for each scale. &amp;#x200B; There is a lot of really neat stuff out there in this field. Let me know if you have any questions or are interested on improving the Rust photogrammetry scene.
Does cargo.exe need to be in my PATH, or just .cargo\bin?
Hi everybody, I'm currently failing to use a lexer generator called [luther](https://github.com/sbosnick/luther) and I feel I'm missing something simple. This luther thing defines a type `Location` ([documentation](https://docs.rs/luther/0.1.0/luther/struct.Location.html)), which is [defined as](https://docs.rs/luther/0.1.0/src/luther/span.rs.html#77)) pub struct Location(usize); Suppose I have a variable `loc` of this type in my code, how do I get the underlying usize? let number = loc.0; gives me error[E0616]: field `0` of struct `luther::Location` is private --&gt; src/main.rs:11:18 | 11 | let number = loc.0; | ^^^^^ even though the code suggests it is public. And let Location(number) = loc; results in error[E0532]: expected tuple struct/variant, found struct `Location` --&gt; src/main.rs:10:9 | 10 | let Location(number) = loc; | ^^^^^^^^ did you mean `Location { /* fields */ }`? I thought this is what you use tuple structs like. What's going on here? For completeness, here is a small program which I would like to see compiling: extern crate luther; use luther::Location; fn main() { let loc = Location::new(2); let Location(number) = loc; let number = loc.0; } Cargo.toml: [dependencies] luther = "0.1" luther-derive = "0.1"
That proposal already introduces a good bit of grammatical ambiguity. I don't think it'd be unreasonable to force disambiguation in that position just like we currently do for brace-struct initializers on the RHS of a \`while let ... = ...\` loop.
Tantivy can work in memory and it has fuzzytermquery. (Using levenshtein damerau distance). What it is missing is a bit of code to split the user query and build a fuzzyquery using the intersection of the different fuzzy term queries resulting. It is missing because I would like to make it efficient and have decent scoring, which requires a bit of work.
\* and prefix `await future` is used, and you want to have a generator return a `Future`. Note that a "`AsyncGenerator`" already has an await/poll point between the final yielded item and the final generator result. I suspect that's enough for most if not all real cases.
Thanks for making me aware of Exercism!
Are you compiled for debugging? When I try `rust-gdb` this is what I get: $ cat option.rs fn main() { let arg = std::env::args().nth(1); match arg { None =&gt; println!("no argument"), Some(s) =&gt; println!("argument: {}", s), } } $ cargo build Compiling option v0.1.0 (/home/bart/prj/rust/option) Finished dev [unoptimized + debuginfo] target(s) in 0.27s $ rust-gdb target/debug/option GNU gdb (Debian 8.2.1-2) 8.2.1 Copyright (C) 2018 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type "show copying" and "show warranty" for details. This GDB was configured as "x86_64-linux-gnu". Type "show configuration" for configuration details. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type "help". Type "apropos word" to search for commands related to "word"... Reading symbols from target/debug/option...done. (gdb) break option::main Breakpoint 1 at 0x4ea7: file option.rs, line 2. (gdb) run x Starting program: /home/bart/prj/rust/option/target/debug/option x [Thread debugging using libthread_db enabled] Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1". Breakpoint 1, option::main () at option.rs:2 2 let arg = std::env::args().nth(1); (gdb) n 2 let arg = std::env::args().nth(1); (gdb) n 4 None =&gt; println!("no argument"), (gdb) print arg $1 = core::option::Option&lt;alloc::string::String&gt;::Some("x") (gdb) quit
When I run rustup update stable-msvc I get [this error](https://imgur.com/a/as9yZee)
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/XXHTsoS.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20ekyz1f6)
The cost and effort of developing a cross-platform native app kinda does.
This link appears to be broken. Any chance someone could post a working link?
I'm kind of interested, since vision/photogrammetry is my day job and Rust is a hobby. :) The tooling was pretty immature when I tried porting stuff over a couple of years ago, but it may have improved by now. I'm kind of spoiled by C++ and domain-specific libraries for almost everything under the sun... interesting than BRIEF. I was kind of in a rush this morning.)
Do you have the full code please so I can take a look and try to figure what's going on?
You might be surprised what a nazi dictatorship coup will pay for. Though i'm more worried about the drones and satellite facial recognition myself.
I was more thinking of the standpoint of totalitarian theocratic regimes.
Tuple struct fields behave exactly like their named counterparts; they are private unless marked `pub`. Unfortunately, looking at the API there doesn't appear to be any way to access this value in safe code. You'll need to petition the author to make the field accessible somehow: * mark the field `pub` (though this is a forward-compatibility hazard) * implement `From&lt;Location&gt; for usize` which provides the reciprocal `Into&lt;usize&gt; for Location` * provide a method which returns the value You can of course fork the crate and add this yourself; the author might appreciate a PR though.
No problem! It's a pretty cool site.
for line in file.lines() { let lines = lines?; // ... } I assume `lines` is supposed to be `line` ?
The rust example seems to return an iterator of tuples not an iterator of vectors. Why did you want it to return an iterator of iterators when there's only 2 elements in that tuple?
&gt; Let's not pretend that it doesn't have enormous benefits in terms of development speed as well. I hate slow apps, but there's no way a ton of applications that are widely used today would be as feature rich without electron. Imagine if all the work directed into electron and electron apps was directed to a similar, but native, solution...
&gt; I think `await`-ing on the stream is exactly what we want - it 's Future at the end. No - we don't want that `Future` **at the end**, we want to `await` on every single "Future" yielded by the stream. A Rust `for` loop: for elem in iterable { ... } Can be desugared to: let iterator = iterable.iter(); while let Some(elem) = iterator.next() { ... } In the async case, what we want is: let iterator = stream.iter(); while let Some(elem) = await iterator.next() { ... } But the `for elem in await stream` style can - with already accepted async-await syntax - be desugared to: let iterator = (await stream).iter(); while let Some(elem) = iterator.next() { ... } Say there are two items in the stream, one of them available immediately and the other will take some time. With the first approach, `iterator.next()` returns a `Future` for the first item, then we `await` it, process it, and then call `iterator.next()` to get the second item, `await` on it - and yield control to the reactor because it is not ready yet. This is the desired behavior - handle each item as it becomes available. But with the second approach, we only `await` once - on `stream`. There are two possible behaviors here: 1. It returns immediately, we process the first item, and then block until the second item is ready. 2. It yields control back to the reactor, and only gets it back when both items are ready. The first behavior is unacceptable - async code should not block the reactor when waiting for things to happen. The second behavior misses the point of async streams - to be able to process each item when it is available.
What a weird take.
Hopefully this will come in handy for anyone working with Rocket and Prometheus; the idea was for it to be as simple as possible. Feature requests / code review / pull requests welcome. Oh, and thanks to the folks at PingCap for their work on the Prometheus library, and to Sergio et al for Rocket!
The code is [here](https://nest.pijul.com/dragonmaus/getopt). With the `doc_comment` macro, `cargo test --doc` produces the following output: running 8 tests test &lt;::doc_comment::doc_comment macros&gt; - (line 10) ... ok test src/opt.rs - opt::Opt (line 11) ... ok test src/parser.rs - parser::Parser (line 14) ... ok test src/parser.rs - parser::Parser (line 37) ... ok test src/parser.rs - parser::Parser::next (line 178) ... ok test src/parser.rs - parser::Parser::next (line 193) ... ok test src/parser.rs - parser::Parser::next (line 208) ... ok test src/parser.rs - parser::Parser::next (line 225) ... ok test result: ok. 8 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Switching to `doctest` and removing the `include_str` invocation produces the following output: running 7 tests test src/opt.rs - opt::Opt (line 11) ... ok test src/parser.rs - parser::Parser (line 14) ... ok test src/parser.rs - parser::Parser (line 37) ... ok test src/parser.rs - parser::Parser::next (line 178) ... ok test src/parser.rs - parser::Parser::next (line 193) ... ok test src/parser.rs - parser::Parser::next (line 208) ... ok test src/parser.rs - parser::Parser::next (line 225) ... ok test result: ok. 7 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
Uninstall, reinstall, restart?
Hmm I use gdb 7.12.0, so I think that's it. Thank you!
i mean, it starts to have pretty bad problems at 2gb - 4gb when you also have a browser open, dual core i5 + ssd + 8gb isn't really 'low end'
There's a PR for that: https://github.com/sgrif/diesel.rs-website/pull/74
Rust is probably not the best option for this kind of thing. `Iterator` has some commonalities with Haskell's list, but they are *very* far from the same thing. `Iterator` isn't a type like a list for one, and is instead a trait, equivalent to a typeclass or interface. `Vec` really is what you would use when returning ordered collections. For one, you'd need a dedicated type just for your internal iterator, and if you're using standard combinators, you'd need existential types since closures all have unique types and are unnamable. Rust in general isn't great when it comes to multidimensional collections. Heck, you're reusing the result of `prod xss` for every element in `xs`, and since `Iterator` maintains internal state to track what the next element to return is, you'd need to clone the entire iterator for each element, something which Rust requires you make explicit. You would be much better off using slices for your input and `Vec`s for your output, even though they are strictly finite.
 &gt;but it returns an iterator of vectors, and not an iterator of iterators (and it is extremely verbose) Rust doesn't have HKT, or Currying. So expressing an iterator, which can recursively iterate over its own elements (to any depth) is kind of impossible to represent statically ahead of time. As this creates an `dyn Iterator&lt;Item=dyn Iterator&lt;item=dyn Iterator&lt;...&gt;&gt;&gt;` which is impossibly long (actually infinitely long to correctly represent).
Somewhat related is this interesting story about "dong detection software for LEGO Universe": https://twitter.com/glassbottommeg/status/604407061380640768
I‚Äôm working on yet another toy programming language written in Rust. It‚Äôs called [leaf](https://github.com/IntrepidPig/leaf), although the version on GitHub hasn‚Äôt been updated in a while. I‚Äôm actually in the process of a rewrite from scratch, because I can‚Äôt help myself. Working on leaf, I‚Äôve noticed that Rust works really well for writing programming languages, and especially parsers. Not that I have any experience writing programming languages in any other languages, but while writing leaf I‚Äôve found myself really enjoying features like enums, iterators, slices/lifetimes, lack of exceptions, etc. Enums, newtypes, and other type safety features have allowed me to effectively eliminate any worries of unexpected invalid state in the compiler. Slices and lifetimes, combined with custom iterators have allowed me to write a parser that does the absolute bare minimum of allocations. A lack of exceptions allows for very clear error paths throughout the compilation process. Also the performance Rust makes possible makes it good for implementing the language virtual machine as well as the compiler. I don‚Äôt think it‚Äôs entirely a coincidence that Rust is such a good tool for writing programming languages. It probably helps that rust was designed with the programmer in higher regard than some other languages, and that it was created with the task of creating it‚Äôs own compiler in mind, so it makes sense it would be good at implementing languages similar to it. As for my goals for the language itself, it started as a learning experience, but if I were to have any technical goals for it, I would say it‚Äôs meant to be a decently (but not competitively) performant (thus the compilation to bytecode rather than interpretation), but very portable and easily embeddable (thus the compilation to bytecode rather than native code), and a focus on ease of use and correctness. I plan eventually on adding cool type system and other language features to accomplish that final goal, but the project hasn‚Äôt matured to that point yet. So uhh that‚Äôs my project. Thank u for coming to my ted talk.
Just wrote my [first crate.](https://www.reddit.com/r/rust/comments/bdmwms/show_rustaceans_platform_agnostic_mpu6050_imu/) An MPU6050 IMU driver. Had a lot of fun doing it!
what about like python \`async for elem in elements()\`
I think `for await? elem in iterator` makes the most sense, but none of the options look very good. I see lengthy discussions on github about this in the future. Recently I found out about the try_fold and try_for_each methods on iterators. [`futures::TryStreamExt`](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.14/futures/stream/trait.TryStreamExt.html#method.try_for_each) has similar methods that I could see myself using: // stream: impl Stream&lt;Item=Result&lt;T, Err&gt;&gt; stream.try_for_each(|x| { // do something with x: T Ok(()) })?;
Okay. I did it. Don't use it though, please! Instead, read what /u/boomshroom wrote. It took me a _immensely_ long time to figure this out but I took it as a toy challenge to translate the Haskell snippet into Rust whilst preserving the original structure. My code throws a lot on the heap, uses dynamic dispatch and clones a lot! But that's inevitable. It probably also is cache-unfriendly. Whatever, here is the bloated beauty: use std::iter::{empty, once}; fn prod&lt;J: 'static, I: 'static, T: 'static&gt;(mut xss: I) -&gt; Box&lt;dyn Iterator&lt;Item = Box&lt;dyn Iterator&lt;Item = T&gt;&gt;&gt;&gt; where I: Iterator&lt;Item = J&gt; + Clone, J: Iterator&lt;Item = T&gt;, T: Clone, { if let Some(xs) = xss.next() { Box::new(xs.into_iter() .flat_map(move |k| prod(xss.clone()).map(move |xs| { Box::new(once(k.clone()).chain(xs)) as Box&lt;dyn Iterator&lt;Item = T&gt;&gt; }))) } else { Box::new(once(Box::new(empty()) as Box&lt;dyn Iterator&lt;Item = T&gt;&gt;)) } } Let's look at an example invocation: let v = prod(vec![vec![1, 2].into_iter(), vec![3, 4].into_iter()].into_iter()); println!("{:?}", v.map(|x| x.collect::&lt;Vec&lt;_&gt;&gt;()).collect::&lt;Vec&lt;_&gt;&gt;());
Paragraph four: &gt; Framing this as an ‚Äúasync for loop‚Äù and making the syntax something like `async for elem in stream` makes some intuitive sense, but I think its actually a mistake when you investigate further. `async` modifies things to make them create a future of something instead of evaluating to that thing directly - this is not what this syntax does. What this does is yield from the surrounding async item when the next item in the stream is not ready yet - exactly the same thing as what the `await` operator does to futures already.
Very cool, congrats on another ripgrep release! I dig the version number change from `0.10.0` to `11.0.0` üéâ
I can now understand the ambiguity. Thanks for explaining how it desugars - I didn't know that.
hmm that seems logical to not have two versions of the syntax that works different in different places. i completely missed that part i even looked for that üôâ
This solution is not as short nor recursive, and it applies only to lists of lists of u32: `fn prod(list: Vec&lt;Vec&lt;u32&gt;&gt;, next: &amp;Vec&lt;u32&gt;) -&gt; Vec&lt;Vec&lt;u32&gt;&gt; {` `let mut result = vec![vec![0; 0]; 0];` `for item in list {` `for subitem in next {` `let mut result_item = item.clone();` `result_item.push(*subitem);` `result.push(result_item);` `}` `}` `result` `}` &amp;#x200B; `fn main() {` `let list = vec![vec![1, 2], vec![3, 4], vec![5, 6, 7]];` `let mut result = vec![vec![0; 0]];` `for item in list {` `result = prod(result, &amp;item);` `}` `println!("Result is {:?}", result);` `}`
&gt; Due to two recent occurences of suspicious activity, my focus has been on the security of The Piston Project Any details on this?
Why can't await require a mandatory block? This language requires blocks on if's and match's expressions. That makes them a bit noisy but also plain clear. In this context, it wouldn't feel unnatural if I have to write ```await {stuff} ```. The good thing is that it enables you to place the ? without any confussion in all circumstances. See: * ```for await { element? } in stream {...}``` * ```for await { element }? in stream {...}``` * ```let data = await { operation? };``` * ```let data = await { operation }?;``` * ```if let await { data? } = operation {...}``` * ```if let await { data }? = operation {...}``` * ```if let await { Ok(data) } = operation {...}``` * ```if let Ok( await { data } ) = operation {...}```
I am happy to see tantivy to be feature completed on fuzzy and regex searching. I've forked tantivy and tried to fix the FuzzyMatcher, but finnaly the website was migrated to flexsearch.js (and simsearch now). In fact, even though tantivy and the library from /u/burntsushi are much more reliable on large dataset than simsearch, they target totally different use cases. simsearch tries to convince you to embedded a search engine into your cli programe and won't let you afraid of the impact on startup time. I don't know the details of /u/burntsushi's library, but clearly tantivy is a little bit too heavy in this case. Do you have loads of structured, schemaed documents to index, or even want to restore them? Please use tantivy. Do you want to perform search on small dataset with fast startup time and with just a few lines of code? You can give simsearch a try.
- https://github.com/PistonDevelopers/piston/issues/1257 - https://github.com/PistonDevelopers/piston/issues/1274 Also, see "Improved Organizational Security" in the blog post http://blog.piston.rs/2019/02/08/what-is-happening-7/
Is the [crate](https://crates.io/crates/ripgrep) going to be updated too? I install ripgrep via `cargo install`.
Ah right! Forgot about that. Thanks for the reminder. Should be good to go now.
Wow, so fast! Thanks!
That worked, thanks.
Thanks for your suggestion. It's seems pretty useful to formalize and stablize the search process. I'll try to bring it in in the next update. For now, I haven't found any precision issue and ngram performs bad in my previous test... so weired.
Still trying to use a C library in Rust targeting wasm32-unknown-unknown. After researching a lot of materials, I ended up with providing common C functions like `malloc` (implementation for it in wasm-sodium repo found) for the C library, so I can avoid having to do it in JS. I had to learn a lot of things (basically C) and many things in Rust are still unclear and I should probably write a proper blog post. For those interested, that's the current state (only compilation step): - libwebp C files are compiled to bytecode with clang (some lines were commented out) - switched to wee_alloc allocator for `#![no_std] and smaller binary size - libm is used for math and quicksort for, well quicksort - lib.rs with implementations for C functions (malloc, free, memmove etc) are annoted with `extern` and `#[no_mangle]` and also compiled to bytecode - all .bc files are linked with wasm_ld Things that failed: - compiling to object files first did not work because the rust object output is different than in clang - using the wee_alloc example did break something, at least I got a linker error but implementing abort with wasm-bindgen (see wasm-sodium libc stub) removed the panic handler requirement which meant less unstable features needed - libc doesn't want to work with nightly or wasm, so avoid it or create own type definitions - use `cargo rustc` to link the crates properly I hope that working with C libraries becomes with the wasi target easier, so my current efforts are later still useful. What would make things easier if wee_alloc could provide those lang items and panic handler stuff too. Furthermore, when alloc becomes stable, things should be clearer. I wish there were more blog posts and examples or that this kind of build steps could be automated by the compiler.
I'm hoping to make headway into my networking chapter for [Rust in Action](https://www.manning.com/books/rust-in-action?a_aid=rust&amp;a_bid=0367c58f&amp;chan=reddit). I sent an updated manuscript to the editors this morning and a new MEAP version should be with readers this week. I have also started drawing fun little images about Rust and its community. They've been relatively popular on Twitter: * [Why Rust? A 5 quote phrasebook](https://twitter.com/timClicks/status/1117731338646249473?s=20) * [What does Rust offer programmers? Safety and control. Giving you both the tools and the confidence to write fast programs](https://twitter.com/timClicks/status/1116643571677810690?s=20)
This is super interesting. I look forward to your blog post.
Not really sorry. It's mostly just meant for my own personal use. I write a lot of personal projects in C++ in order to experiment with new techniques/technologies related to my line of work, so having a powerful but easy to use/works out of the box solution for my assets/shaders is quite a must. But because of the type of techniques I can't use premade engines so I just roll my own stuff. I had a system before but wasn't 100% fan of it so decided to redo it in rust as a learning rust practice.
Use this all the time. Thanks!
I updated rust and my cargo dependencies don't work, I assume I need to recompile them. Is there a command for this?
Neat! Seems handy, and it's always good to see `proptest` applied to the sorts of libraries that need it. If you don't mind an unsolicited minor suggestion, have you considered using [NonZeroUsize](https://doc.rust-lang.org/std/num/struct.NonZeroUsize.html) for the `capacity` parameter in the constructor(s)? It would clarify the intent regarding the non-zero-size requirement and turn a runtime panic into a compile-time guarantee.
How does it compare/what is different to existing frameworks?
That's all good and well, but I'm wondering what he prefers.
Great work! Did you encounter any bumps in the road?
I used enum_primitive crate https://github.com/iopq/strenum/blob/master/src/lib.rs Not sure if that helps you
[Playground Link](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=a737d53d1c68a6da8611ab2e2d79ebd0) This includes a verbatim translation of the Haskell code, and with (ideally) the same semantics as well. It also includes a 79 line implementation of lazy evaluation and a 42 line implementation of a Haskell-style lazy linked list. The 2 lines themselves expanded into 9 lines, but if you were OK evaluating `prod(xss)` multiple times redundantly, it could be as low as 6. It is *EXTREMELY* unidiomatic Rust code and is only something you would dare use if you absolutely needed to write Haskell in Rust. That said, the fact that it's possible to write this at all is pretty impressive given what Rust is really intended for. Pretty much all of it can be used in a freestanding environment without an OS, and the `parking_lot_core` crate is pulled in solely for more efficient spinning, since the lazy evaluation implementation is designed to (hopefully) be thread safe. It's not inconceivable to write a DSL for Rust that can behave like Haskell and yet still run on the bare metal. Heck, since Rust lets you have closures allocated on the stack, you don't even need memory management to deal with lazy values.
So I logged off of a server yesterday with a full gear kit, a bolty, and a mp5 but when I got on today I was completely naked. I wasn‚Äôt killed nor was I raided. How is this possible? Can you be looted through walls? Does gear despawn after awhile on live bodies?
I think`curry!()` would be a sweet macro.
The more the merrier! Everybody is certainly welcome to build whatever he wants. ... But you made an incorrect statement and an incomplete statement about tantivy so that's my job to correct it.
Sounds like a memory leak. Were you using unsafe Rust?
TSAA is planned, but lower priority for now ;)
Hi everyone! So I'm having an issue with the \`cannot move out of borrowed content\` error. The thing is, I understand \_why\_ it is saying that I cannot do that, but I just don't see any easy workaround, except returning \`Self\` from the method, which obviously muddles the interface of the struct quite a lot. Care to check my [SO](https://stackoverflow.com/questions/55699848/rust-returning-self-to-avoid-moving-out-of-borrowing-content) question to see if anyone may help me? Thanks!
Wrong subreddit my man
That assumes that we actually have the skill to do so. Given that revelation and my inability to audit rust-cpython myself, I think I'll look into switching my PyQt+rust-cpython projects over to some kind of "have the Python frontend spawn the Rust backend as a subprocess and communicate over a named pipe" replacement for rust-cpython once their designs settle down to a release-ready state.
While I appreciate the effort, PyO3 [has flaws that could invoke undefined behaviour](https://www.reddit.com/r/rust/comments/azit15/i_made_a_super_simple_example_guide_of_how_to/ei89s8e/?context=3) and I haven't yet seen proof that rust-cpython is free of them. (I'm not trying to be hypocritical or alarmist here. I'm risk-averse enough that, when I get back to working on my Python-Rust hybrid projects, I'll be investigating options for converting the FFI boundary into a named pipe between a Rust-free Python frontend process and an `unsafe`-free Rust backend process.)
Impressive performance. Great job. Never heard of this until now. Will switch from ag to ripgrep!
Rust does have type inference; but Rust is still a statically typed, strictly typed language. &amp;#x200B; If Rust can determine absolutely the inferred type based on the context, it will do so. If there is any amount of ambiguity as to what the type should be, the Rust compiler will make sure that you provide that information. &amp;#x200B; In less strict languages (dynamically typed and/or loosely typed) these requirements may be a little more relaxed, and your program may just fail, or be casted to a type that works at run time.
WhatIfIToldYou.jpg... that "rust" is not just the name of a game and you're on the wrong subreddit?
ExampleCategory is equivalent to std::men::Discriminant&lt;Example&gt;, which is an opaque type that represents the variant of an enum. You can construct a Discriminant&lt;T&gt; from an enum T with the std::men::discriminant() function.
Tons of utilities are being written better than ever in Rust! I also recommend fd (replacement for find) and exa (replacement for ls).
Type inference for Rust is undecidable both because of multi-parameter type classes (known to be undecidable and demonstrated with `.collect()`) and rank-3+ types (also known to be undecidable). So sure, as you cannot take any term (expression) in Rust and assign a type to it from that type, it is correct to say that Rust is only partially inferred. We can also note that Rust lacks the [Principal type](https://en.wikipedia.org/wiki/Principal_type) property. Not only is type inference undecidable in Rust, type *checking* is also.
Those were some pretty good comparisons and this fully answers my question.
Rust requires type declarations on functions; these cannot be omitted even if the code would be unambiguous without them. In some situations, Rust will also assign a default type to ambiguous expressions (namely, i32 in integer contexts and f64 in floating-point contexts)
r/playrust
Someone else can write up a nicer answer, but try this: fn next_token(&amp;mut self) { self.current_token = std::mem::replace(&amp;mut self.peek_token, self.lexer.next_token()); }
I compare between the syntax and soon I will make benchmarks and add them on the repository
Layer-7 slow HTTP DOS Tool that handles sockets in parallel called "lor-axe". [Github](https://github.com/ajmwagar/lor-axe)
/r/playrust
Thanks! I'll look into it. Glad to know.
One of the best programs written in Rust. Thanks!
There are a couple libraries that make interfacing with Rust from Python much easier! I recommend to checkout pyo3 and rust-cpython for bindings as well as pyo3-pack for bundling.
TIL. I don't think I've seen this in the wild, very cool.
Thank you very much! But what about this error message: error[E0532]: expected tuple struct/variant, found struct `Location` --&gt; src/main.rs:10:9 | 10 | let Location(number) = loc; | ^^^^^^^^ did you mean `Location { /* fields */ }`? Does that tell me something meaningful or is it just weird behavior of the compiler?
lsd is also good. Check it out.
You might enjoy this article :) https://blog.burntsushi.net/ripgrep/
Thanks! These are pretty much exactly what I was looking for.
This is pretty impressive! Nice bit of work to answer a Reddit question.
This seems to be a bug with the version of the compiler you're using; I get a rather different error on the latest stable (modified example): https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=38a4a20ca946e189d48eb0751a4ad253 error[E0532]: expected tuple struct/variant, found struct `Foo` --&gt; src/main.rs:10:9 | 10 | let Foo(val) = foo::get(); | ^^^ constructor is not visible here due to private fields The main error message is still rather confusing (it makes a bit of sense since the actual shape of `Foo` shouldn't appear as a tuple struct to you since it's all private) but at least the help message is actually helpful.
I don't think there's any direct link between not being able to infer a type for some terms and strong typing. For example, as noted in the [Principal type](https://en.wikipedia.org/wiki/Principal_type) article, an expression in ML can be assigned a unique principal type. This is also true of Haskell 98. If you enable extensions in Haskell, e.g. `{-# LANGUAGE RankNTypes, MultiParamTypeClasses #-}` then you lose this principal type property and a unique type can no longer be assigned. You can consider Rust as a language where versions of these "extensions" are always enabled. Aside: static typing is assumed because ["dynamic typing" is I think a misnomer](https://stackoverflow.com/a/9166519/1063961); there's no such thing as "dynamic typing" because types, unlike *run-time tags* are a static dicipline -- [I agree with Bob Harper](https://stackoverflow.com/a/9155610/1063961) in [calling](http://lists.seas.upenn.edu/pipermail/types-list/2014/001733.html) so called "dynamically typed languages" uni-typed languages because values are conceptually a sum-type of every possible value in the language. One might take [an extrinsic curryist view](https://lispcast.com/church-vs-curry-types/) and provide a type system atop of a uni-typed language; examples of this include typescript. However, in those cases, the type-system added atop is really a different language.
Not really! Didn't have to fight the borrow checker very often, actually! Cargo just gives such awesome compiler errors, as well, which makes things easier.
Thank you for pointing that out! I wasn‚Äôt aware of that. We will see what we can do here. The code has been tested on macOS and Linux. The layer between Python and Rust is relatively small though. I will check whether the bug can happen in our case, and try to prevent it.
This is really informative. Thank you for all of the clarifications. I've never heard of the notion of calling "dynamically typed languages" uni-typed languages. That is a very interesting perspective, and I'm excited to read more about it.
You are welcome. :) If you are interested in type theory more broadly, I would recommend picking up [Types and Programming Languages](https://www.cis.upenn.edu/~bcpierce/tapl/) and giving it a read.
You know, I think I am interested in that. I'm about to get my Bachelor of Computer Science in 6 months, and I've been giving a lot of though about what interests me as a potential path for a Master's degree. The more I use languages like Rust and Haskell, the more interested I become in the design of languages and type systems as a whole, though I am still very much an amateur. &amp;#x200B; I appreciate the recommendation, and I will certainly look into that book.
Cool! There might be projects related to Rust / Haskell and its development that you could consider for your masters. &gt; though I am still very much an amateur. Everyone starts out that way. Personally, I haven't finished my masters yet because Rust ate all my time... ;) &gt; I appreciate the recommendation, and I will certainly look into that book. You may also want to check out Agda, Idris, and dependently typed programming in general, where programs are often regarded as proofs, if you decide that type theory / PLT is an interest of yours.
Is there a list of coreutils -&gt; RustReplacement? Also, just in terms of dev share- ripgrep is probably THE most used piece of rust code in existence. It ships with Microsoft's VS Code ;)
Thanks for sharing! I always wanted to learn about arithmetic coding, and this is the most readable implementation I have seen so far.
Write the correct code that works? There is 0 anyone can do without your code and the error you get.
Thank you for your work! I can't imagine without Rg now.
Adding sound support to my game
&gt; Add `-I` flag as a short option for the `--no-filename` flag. Thanks for this. I use rg to send input to another process very frequently, and this new short option is super handy.
Thank you! I started writing something like that, but ended up fighting the borrow checker, and lost. Looks like I still have a lot to learn! Can you explain why these `static` are needed?
Bit of a poor wording here ? ‚ÄúProceding from the basis that we this syntax would use the await keyword‚Äù (we this)
&gt;Proceding from the basis that we this syntax would use the await keyword I'm not a native speaker, but I think this sentence doesn't parse. If you have `&amp;mut blog`, you might want to edit that ;)
Wow! Thank you, this is impressive. And the final `prod` function looks very natural and idiomatic. I still haven't finished reading the rest of the code, I hope I'll be able to understand it. Your list type looks very useful. Is there a crate somewhere that does something similar? If not, would you consider submitting this code to crates.io ?
Great to hear :) Looking forward to seeing what you cook up
Oh my God! This is amazingly monstrous. Good job.
Wish I could be on that team at MS. I would love to have been the one to say, "Hey, for the 'search' user story, I think I know a good open source tool we can use!"
The problem is that if you *are* invoking undefined behaviour, tests can't catch it because it's a matter of the optimizer being allowed to assume that something will never happen and rewrite code based on that. If you invoke undefined behaviour in your code, it could work fine now, but any future change to your code **or** the optimizer could cause it to break in ways that could be very subtle. (Hence the old bit in the C world about undefined behaviour giving the compiler license to do anything up to and including causing demons to fly out of your nose.)
There's also [setuptools-rust](https://pypi.org/project/setuptools-rust/) if pyo3-pack doesn't suit your needs.
I am working on another project but am unsure to continue (for now): It depends on asynchronous computation, but I am not sure to wait for futures being moved to stable. Good tokio examples are also hard to come by.
Awesome! This finally inspired me to get rg onto my workstation, and a pretty relevant workload went from taking 48s to 13s \\,,/ Thanks a lot!
this is because that argument is a closure, essentially `.map_err(|_| ())` is simply throwing the error away by mapping the error from send to the unit type `()`. I think this is to mitigate needing a special implementation of whatever error to just do nothing on error , could be wrong though
It's a quick way to get the program to typecheck by making all possible error types the same. The reason for that is \`and\_then\` requires the error type in Self to be equal as the error type in the result of the closure passed by parameter, otherwise you would end up with the possibility that two different types are the result of the compuation (I might have botched that phrasing, feel free to ask for clarification). e.g. ```rust Err("a").and_then(|_| Err(1)) // type could either be Err(&amp;str) or Err(i32), illegal in eyes of type checker ``` I wouldn't necessarily consider it a good pattern as the error (and their valuable information) are completely lost in the process. "But in the above code, they are passing no parameters to the function." the `_` in `|_|` acts as an ignored parameter
This is a great idea ! This pattern feels very natural in rust, and allows for good performance. I was even surprised it did not exist already when I started writing [json\_in\_type](https://github.com/lovasoa/json_in_type).
I just started rust version of [dezoomify](https://github.com/lovasoa/dezoomify/) : [dezoomify-rs](https://github.com/lovasoa/dezoomify-rs). It will allow downloading very large zoomable images, that cannot be downloaded in the browser.
Implemented in the current version, as additional handle type so users can choose to use it or not as they like. [https://docs.rs/arc-swap/0.3.11/arc\_swap/cache/struct.Cache.html](https://docs.rs/arc-swap/0.3.11/arc_swap/cache/struct.Cache.html)
OK, thank you!
Well, it was what I thought, thanks!
Now try awaiting in a Future that returns a Future that returns a Future.
I prefer a new iteration construct: `await_for` / `for_await`. Recycling `for` for a completely different purpose feels like unnecessary complexity for me at this point. If we get ATCs, and if we retrofit `Iterator` with these, such that streams can implement `IntoIterator`, and if we have `await`/`?` in patterns, then we can always deprecate `for_await`, and consider tweaking things in `for` to make things work.
Here what I get with both cargo commands: ``` &gt; cargo test Updating crates.io index Downloaded doc-comment v0.1.4 Compiling doc-comment v0.1.4 Compiling getopt v0.4.1 (/home/imperio/rust/getopt) Finished dev [unoptimized + debuginfo] target(s) in 4.08s Running target/debug/deps/getopt-b9b36aab6a6ec05f running 11 tests test tests::blank_arg ... ok test tests::double_dash ... ok test tests::bad_opt ... ok test tests::missing_optarg ... ok test tests::multiple ... ok test tests::no_opts_1 ... ok test tests::no_opts_2 ... ok test tests::no_opts_3 ... ok test tests::single_dash ... ok test tests::single_opt ... ok test tests::single_optarg ... ok test result: ok. 11 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Running target/debug/deps/getopt-f5feeeb1a36d4529 running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Doc-tests getopt running 8 tests test &lt;::doc_comment::doc_comment macros&gt; - (line 10) ... ok test src/parser.rs - parser::Parser::next (line 193) ... ok test src/parser.rs - parser::Parser::next (line 225) ... ok test src/parser.rs - parser::Parser::next (line 178) ... ok test src/parser.rs - parser::Parser::next (line 208) ... ok test src/opt.rs - opt::Opt (line 11) ... ok test src/parser.rs - parser::Parser (line 37) ... ok test src/parser.rs - parser::Parser (line 14) ... ok test result: ok. 8 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out ``` And the second: ``` &gt; cargo doc --test error: Found argument '--test' which wasn't expected, or isn't valid in this context USAGE: cargo doc [OPTIONS] For more information try --help imperio@imperio-XPS-15-9560:~/rust/getopt$ cargo test --doc Finished dev [unoptimized + debuginfo] target(s) in 0.01s Doc-tests getopt running 8 tests test &lt;::doc_comment::doc_comment macros&gt; - (line 10) ... ok test src/parser.rs - parser::Parser::next (line 208) ... ok test src/parser.rs - parser::Parser::next (line 193) ... ok test src/parser.rs - parser::Parser::next (line 225) ... ok test src/parser.rs - parser::Parser::next (line 178) ... ok test src/opt.rs - opt::Opt (line 11) ... ok test src/parser.rs - parser::Parser (line 37) ... ok test src/parser.rs - parser::Parser (line 14) ... ok test result: ok. 8 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out ``` Looks like it's working as expected...
Thanks, after reading this I realized I know nothing about Rust after 2 years of actively using it.
Please add a README explaining what your project does and how to use it. Even if its just a toy project, it's just good practise. Moreover, like others mentioned use clippy and rustfmt. Most editors have plugins for rust and run rustfmt every time you safe. You can find more information at [areweideyet.com/](https://areweideyet.com/).
Here's a (slight) improvement, IMO. Cuts down on a type annotations and works with non-static lifetimes: use std::iter::{empty, once}; fn prod&lt;'a, I&gt;( mut xss: I, ) -&gt; Box&lt;dyn Iterator&lt;Item = Box&lt;dyn Iterator&lt;Item = &lt;I::Item as Iterator&gt;::Item&gt; + 'a&gt;&gt; + 'a&gt; where I: Iterator + Clone + 'a, I::Item: Iterator + 'a, &lt;I::Item as Iterator&gt;::Item: Clone + 'a, { if let Some(xs) = xss.next() { Box::new(xs.flat_map(move |k| { prod(xss.clone()).map(move |xs| Box::new(once(k.clone()).chain(xs)) as Box&lt;_&gt;) })) } else { Box::new(once(Box::new(empty()) as Box&lt;_&gt;)) } } fn main() { let v = prod(vec![vec![1, 2].into_iter(), vec![3, 4].into_iter()].into_iter()); println!("{:?}", v.map(|x| x.collect::&lt;Vec&lt;_&gt;&gt;()).collect::&lt;Vec&lt;_&gt;&gt;()); }
&gt;Rust doesn't have HKT Does this really require HKT though? &gt;or Currying I also fail to see what currying has to do with whether this can be expressed in Rust. &gt;an iterator, which can recursively iterate over its own elements The output iterator is supposed to iterate the elements of the input iterator, not itself ‚Äì again, not seeing a fundamental reason why this couldn't be done. &gt;is kind of impossible So you're not sure either? :P I'm not trying to sound harsh, but if you're going to mention HKT then I'd hope for reasons why HKT play a role here (I genuinely don't know enough about HKT to know if they do). Now it sounds to me like you only brought up HKT and currying because those are things that Haskell have and Rust doesn't have.
&gt; EDIT: Oh btw! You can actually write your test as follow: Yeah, that is what I meant by "Switching to `doctest` and removing the `include_str` invocation". With version 0.2.4 of your crate, it does not run the test in my README.md file. $ darcs w hunk ./Cargo.toml 15 -doc-comment = "0.1" +doc-comment = "0.2" hunk ./src/lib.rs 20 -doc_comment::doc_comment!(include_str!("../README.md")); +doc_comment::doctest!("../README.md");
Not sure I'm understanding. `cargo update` will update the version numbers in your `Cargo.lock` if you want to do that, but it shouldn't be needed. Then just `cargo build` and/or `cargo build --release` and you should be good to go. If you are depending on things outside of `crates.io`, they may be rebuilt from source when you build: that's OK, I presume?
I see. Well done! I honestly got back to reddit as quick as I could once I got it to compile (it became late), so yeah, I did not optimize it further.
A `static` lifetime actually is not required. You can do it for any lifetime `a` (see [/U/nwydo](https://www.reddit.com/user/nwydo)'s comment below mine). An earlier version of my code which still relied on `Vec`s did that as well but I somehow lost it in the process.
My (very limited) understanding is that `Box&lt;dyn X&gt;` is actually `Box&lt;dyn X + 'static&gt;`, i.e. the type that is boxed is required to live for the static lifetime unless otherwise specified. With this in mind, you can actually avoid the `'static` requirement by overriding this implicit lifetime in the return type: fn prod&lt;'a, J: 'a, I: 'a, T: 'a&gt;(mut xss: I) -&gt; Box&lt;dyn Iterator&lt;Item = Box&lt;dyn Iterator&lt;Item = T&gt; + 'a&gt;&gt; + 'a&gt; I'm sure someone else has a better explanation though.
Addenda re. "dynamic typing": An interesting point re. the extrinsic curryist view is made in https://www.reddit.com/r/programming/comments/2cavea/church_vs_curry_types_two_conflicting_perspectives/cjdulfd/. In particular, the direct extrinsic view of adding a type system atop some untyped operational semantics is not workable for Rust &amp; Haskell because trait/type-class resolution (either by dictionary passing or by monomorphization) actually influences the dynamic semantics of Rust &amp; Haskell programs.
No, you are completely right. It defaults to `static`.
ngl i have no idea what that means can you help me out wym by whole reddit
Doesn't look bad at all. You could consider changing the `Iterator` bounds to `IntoIterator` bounds, too.
I think Firefox has ripgrep beat. :)
/u/long_void _is_ bvssvni :)
I can live with that. Also, postfix macros could happen some day, making it \`\`\`await!(),await!(),await!()\`\`\`.
I ended up writing a dodgy little REST API generator using a proc-macro for my code. Sadly it's not public, but I might be able to extract that bit if people are interested. It uses diesel though
I made a lib called [bus\_queue](https://crates.io/crates/bus_queue) . for that exact purpose, check it out.
I assume that you are performing the benchmark with a high concurrency level. Specifically there are more simultaneous incoming connections that what the server is allowed to handle in terms of open files. There seems to be a bug(?) that causes high latency when the server can't accept new connections anymore, causing it to not serve existing connections for some time either. &amp;#x200B; With an open file limit of 1024 (the default on my system) I can reproduce the problem using \`ab -c972 -n10000 http://localhost:4544/\` (sometimes only from the second run onwards). Reducing the number of concurrent connections by just one, down to -c971 makes the problem go away. The exact numbers may vary for you. Increasing the open files limit for the server using \`ulimit -n 2048\` also makes the problem go away, until I increase the number of concurrent to 1996, where the problem reappears.
One big advantage of using the method in your linked article is that the resulting python code+rust library can be compatible with python2 and python3 for the platform you compiled on (like Linux x86 or Windows). If you use PyO3 or rust-cpython, you're linking your rust library directly to python, so it will need to be recompiled got every version of python you want to use. I'm using [milksnake](https://github.com/getsentry/milksnake) for packaging a cffi-based package, and the resulting wheel can be used with python3.7 on my system, or python2.7 on the production CentOS box without recompiling, which is super convenient. The README example for milksnake also uses cbindgen to create a C header file that CFFI can directly import, instead of writing the C definitions by hand. I also found the [Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/) invaluable in writing both the rust and python code.
Maybe [https://github.com/uutils/coreutils](https://github.com/uutils/coreutils) ?
&gt;schemaed documents This is not an uncommon need. Ex: title/name + description, question + answer etc. No plan to support this I guess? &amp;#x200B; Looks very nice though! I was looking for a project like this a while ago. I'm learning Rust so simplicity is definitely appreciated.
How in the hell are we supposed to get sample pictures of naked people to test this damn thing?!
Yeah, I never [go to deep into writing a solution](https://www.reddit.com/r/rust/comments/bcviq1/how_can_i_reduce_the_size_of_string_struct/ekv5iur/?context=0) for a /r/rust comment. Extra nerd-snipe: there is almost certainly a way to remove one of the two allocations using `itertools::Either`, but I couldn't do it in 1h or so.
``` PUSH JERK ``` God bless you for taking a step forward automating the process to sift through some of the horrible nudity agencies have to deal with. ``` POP JERK ```
You're absolutely. To fix this, I decided to only support 2018 edition of rust. The version has been updated to `0.3`. I tested with your crate and everything worked as expected.
If just being able to compare isn't enough, and you need to name the variant, there is the [enum-kinds](https://crates.io/crates/enum-kinds) crate, which generates pretty much the code you wrote.
You can input any infomation you want into it, but there are no weighted fields and the contents is not restorable, which means you need an additional database to lookup the origin content by id or just use the document as id if the document only consists of a few string fields.
Oh wow, that's interesting, I didn't know that you had to recompile. That's a good reason to go down the route instead.
"could happen today" should not be guidance for current language extensions. What if they don't happen?
Hi People, Maybe not an easy one. I'm profiling rust on Windows with AMDuProf and I can see that I am currently spending a majority of the time \~90% of a 150 seconds run inside two windows libraries: ucrtbase.dll and ntdlll.dll. Does anyone know how I can find where these libraries are being called from Rust?
Syntactically, rust uses braces like this for block syntax, where the body can/usually does contain multiple statements. I'd consider it an antipattern to have multiple separate statements inside an `await`. Additionally, this has the same problem as the mandatory-parentheses options from the blog post: the order in patterns and in other code is reversed (`for await { x? }` vs. `await { fut }?`).
How mature are the current web frame works and are there any decent ORMS? Looking to do small personal projects with Rust to learn the basics. Most of my experience is with Rails/Sinatra + Active Record.
Use them all daily, they rock!
Code like `|_| ()`, `|_| {}` or sometimes a simple `drop` is called a 'toilet function', it just discards all values present in a single stream. For example it ignores all errors in `.map_err(|_| ())`, or another word, it does nothing for all upcoming errors.
Then make a macro: `nesting_await!(3,your_nesting_future)`
Seems the website has ceased to exist?
What should I implement to support turning some specific type T into a `'static str`? E.g. I might have a struct like enum PersonError { TooOldError, } I want to be able to do something like let s: &amp;'static str = PersonError::TooOldError.into() but I can't get it to work with Into. How should I be doing this?
Which one? The post is there.
Really? I get [this](https://i.imgur.com/dE8a5js.png) when I visit it.
I tend to just have my crate rely on a particular git sha from my fork until either I work around the lack of PR merge, or it gets merged and released.
Nice! That worked. I just got a question though: why is this necessary? I guess I don't understand borrowing rules as much as I thought I did. Why is Rust not just invalidating \`self.peek\_token\`, and the validating it again when it reappears in the second line? How is that different from what \`mem::replace\` achieves? In SO someone said it is due to \`panic!\` (something could panic while re-validating \`self.peek\_token\` through \`self.lexer.next\_token()\`), but really, if you delete that line, the compiler still says this is moving out of borrowed content and can't be done! So I guess what I am asking is why this rule exists, and what does \`mem::replace\` achieves that can't be done through safe code.
That crate is outdated. But, it looks like there's good activity in the [Rust Embedded Workgroup USB stack issue](https://github.com/rust-embedded/wg/issues/40).
Loads for me....
There is significant opposition to postfix macros. We‚Äôll see.
I recommend you to read [the Nomicon](https://doc.rust-lang.org/nomicon/) - there's a lots of interesting stuff about Rust's internals and *"special purpose"* functionality.
I think you can use the patch version to point to your fork while you are still setting your dependency to the published version. see patch: [https://doc.rust-lang.org/cargo/reference/manifest.html#the-patch-section](https://doc.rust-lang.org/cargo/reference/manifest.html#the-patch-section)
Try here: https://web.archive.org/web/20190416130116/http://smallcultfollowing.com/babysteps/blog/2019/04/15/more-than-coders/
DoumanAsh, why are you interested in another implementation than using the Actix/Tokio stack?
To make sure I understand this - this is more akin to Python simply running local binaries, not c-ext libraries, right? I know WASM includes sandboxing/etc, I'm familiar with it; I'm asking more of if this is akin to running a binary or running a library.
I usually fork the repo, commit the changes I want to make (typically the ones that are in a pull request to the main repo), then modify Cargo.toml: # TODO - Update some_dep once PR #123 gets merged # some_dep = "1.2" some_dep = { git = "https://github.com/some_org/some_dep", rev = "YOUR_SHA1_HERE" }
Thanks!
If they had `&amp;mut blog` then we couldn't read it.
I still remember first using this, being floored by the performance, and thinking, "huh, some really cool stuff is being built in rust." (long time ago). thanks for the hard work!
I would suggest you to use NonNull for the pointers, they will help you to not screw up with null.
Neat! Thanks for sharing. :) Mind if I share some constructive feedback? You should definitely make the difference between this and [`crossbeam`'s MPMC](https://docs.rs/crossbeam-channel/0.3.8/crossbeam_channel/) channels more obvious in the "obvious" places -- you're pretty clear here in this Reddit post, but you should make the justification for the crate's existence more front-and-center in the README and API docs. It will make it easier for people to evaluate this crate! Also, your README refers to a "Reducer" in the second section, which never appears again. I take it this was a previous name you had in mind for the API?
&gt; In this setting, every function of the program has a precondition (a set of things that need to be true for the function to be called) and a postcondition (a set of things that need to be true at the end of the function). [DbC](https://en.wikipedia.org/wiki/Design_by_contract) fans should make their voices heard on [RFC 1077](https://github.com/rust-lang/rfcs/issues/1077). Wouldn't it be great if there were a popular rust idiom or language feature to express Design By Contract? Yes, libraries are good, but the ubiquity of a common mechanism is better.
Can't help you with `libusb-rs` (I don't have Windows), but if you have a HID device there's also `hidapi`.
People hired (maybe hired by prudes) to prosecute perverts! I've worked in criminal forensics, and any tools to detect nudity are valuable tools for prosecuting child porn.
Woot, design by contract! For anyone interested, I maintain a DbC crate called [`adhesion`](https://docs.rs/adhesion/0.5.0/adhesion/). :)
If you just deleted that line, then peek\_token would be left invalidated. But, even if you just reorder things it'll still complain even though it's technically valid, since there's no possible way to panic between the assignments. fn next_token(&amp;mut self) { let replacement = self.lexer.next_token(); self.current_token = self.peek_token; self.peek_token = replacement; } However, detecting this would be difficult for the compiler, and would have limited use. You would have to have a specific set of lines in certain order, and then probably wouldn't be detected if you started making it more complicated. It'd have too many implicit requirements. Using mem::replace makes it explicit what's happening. It's possible that some day this will be valid rust code, since a better lifetime analyzer is in the works, but I don't know if this would be covered, or even should be.
Is work towards support for "USB firmwares" relevant for this kind of thing, where someone just wants to access USB devices on Windows PCs?
Amazing work! I'd really love to see more happening in this field. &amp;#x200B; Recently, I wrote my first small crate that needs \`unsafe\` code. Being naturally scared by \`unsafe\`, I'd love to formally verify that the code does not contain bugs. I already formulated precise preconditions, invariants and postconditions in the doc comment and tried to "proof" the correctness of methods by annotating each line with some comment which describes the state of each variable. But since none of this is checked, it could be buggy as well, so I gained hardly anything... &amp;#x200B; A question regarding this post: so the goal is to transpile Rust to F so that it can be annotated as F\* and then be automatically checked. What if the Rust code changes? It would be a shame if the user would have to do all the transpiling and annotating again, right? Would it be possible to add these annotations already as special comments in the Rust code which are also transpiled?
Good stuff. Only thing I didn't like about ripgrep is the color scheme (red matches on black background). But this \`\~/.bashrc\` line solved that: &amp;#x200B; \`alias ff='rg --colors "match:bg:yellow" --colors "match:fg:black" --colors "line:fg:yellow"'\` &amp;#x200B; Now it looks like ag/silver searcher, which has super apparent matches thanks to black text on a yellow background. &amp;#x200B; I love it! Drop-in replacement, faster than AG, better Unicode support, and searching big projects really rapidly.
I've added the code and errors that I am getting
Rocket + Diesel is your best bet. I love it
I am using diesel through rocket\_contrib and the `diesel_postgres_pool`
I am using diesel through rocket\_contrib and the `diesel_postgres_pool`
Or, as an alternative, the `strum{,-macros}` crates' [`EnumDiscriminants` derive](https://github.com/Peternator7/strum#EnumDiscriminants). :)
This looks really cool! The syntax appears to be expressive and powerful: Enums are like in Rust. Maps are similar to Rust structs, but with a more ergonomic syntax. It also has tuples, pattern matching, and even currying. I will definitely keep an eye on this language.
That seems to happen when you force https.
It is worthwhile to note that DbC is being proposed for standardization in ISO C++ - could be useful to look at their discussions to see what they're doing and avoid potential mistakes in Rust.
Thanks, that seems like what I am looking for. I have attempted to use both `patch` and `replace` but am getting the same error in both cases: &gt;error: failed to verify package tarball &gt; &gt;Caused by: &gt; &gt; failed to select a version for \`winapi\`. &gt; &gt;... required by package \`io\_bluetooth v0.1.0 (E:\\dev\\src\\bluetooth\\target\\package\\io\_bluetooth-0.1.0)\` &gt; &gt;versions that meet the requirements \`\^0.3.7\` are: 0.3.7 &gt; &gt; &gt; &gt;the package \`io\_bluetooth\` depends on \`winapi\`, with features: \`bthdef, ws2bth\` but \`winapi\` does not have these features. &amp;#x200B; The section of my `cargo.toml` related to \`winapi\` looks as follows: &gt;\[target.'cfg(windows)'.dependencies\] winapi = { version = "0.3.7", features = \["impl-default", "bthdef", "guiddef", "handleapi", "processthreadsapi", "winbase", "winerror", "winnt", "winsock2", "ws2bth", "ws2def"\] } \[patch.crates-io\] winapi = { git = "https://github.com/Wodann/winapi-rs.git", branch = "feature/bluetooth" } &amp;#x200B; Why would the verification process still check against the [crates.io](https://crates.io) dependency?
I agree with all your points. It looks like the paradigm of using HTML/CSS for UI design has it's strong use case though. The best of both worlds could may be in a lightweight "lib\_html\_css\_renderer\_rs" crate as a Rust library that doesn't have all the bloat and only supports core html and css stuff. Thus we can combine the performance of Rust and put to good use the all the html/css skills out there for super nice UIs. Just ditch the JS VM horror from this equation...
Just replace HTML with function calls like in the React, and we will be there ;)
Well, looks like it's not a bug per se. When the server in hyper fails to accept a connection, it waits a second before it tries again by default. You can turn that off, but then it simply crashes. &amp;#x200B; Waiting for a whole second seems excessive compared to the workload that is being benchmarked, and many others as well, so maybe asking for the sleep time to be made configurable would be sensible. &amp;#x200B; Other than that, increasing the open files limit or reducing concurrency will bring latency to more sane levels.
When publishing the crate, you can't rely on the patch section. That is only used locally, AFAIK. If you'd like to release your crate, you will need to fork the upstream crate, and publish your version on crates.io.
&gt; Rather than building an ad hoc verification framework for Rust, I am planning to use F* Why did you pick F* (and not Coq)?
The kind of validations that you can do with F* and other proof systems are a bit beyond me, but I feel like this kind of approach could also be used to make fuzz testing easier, which might be nice if you have an intuition that your approach is correct but do not know how to construct a proof.
I don't think tokio has own websocket implementation? As for why, is because I might need websocket client outside of full fledged web frameworks. If I need websockets in my server, I'd use the one in actix-web, but for client only there ain't much options
You might delete and make a new post so that people see it.
Very hard to find naked pictures on the internet. /s
Publish your changes in your forked repo and you that Url and branch/commit in your cargo.toml.
Even though I like the idea, I don't think it should be in Rust. I'm increasingly worried about feature creep in the Rust language.
Not criticizing, just inquiring: what is the purpose of an async for loop? Generally when I integrate async io in a program I have other things going on in the same context that need to be managed in between newly ready events. But with an async for loop, aren't you essentially looping on `poll(..)` (but only running code on each event)? What's the difference between an async for loop and looping on a synchronous io call, like `read(..)`?
In terms of dev share though, it's possible vs code is more widely used than firefox (stack overflow survey for 2019 shows just over half of developers use vs code to some degree)
&gt; Does this really require HKT though? Yes, if you want full static typing. [The working example](https://old.reddit.com/r/rust/comments/bdlna5/is_there_a_good_rust_translation_of_these_2_lines/ekzbrho/) uses dynamic dispatch, V-Tables, and type casting to work around this. &gt;The output iterator is supposed to iterate the elements of the input iterator, not itself As you can see from [The working example](https://old.reddit.com/r/rust/comments/bdlna5/is_there_a_good_rust_translation_of_these_2_lines/ekzbrho/) there is internal recursive iteration going on where this method can accept types of the signature `Iterator&lt;Item=Iterator&lt;Item=Iterator&lt;...`. So yes, it is recursively iterating. &gt; So you're not sure either? Well I dropped out of my mathematics program so I know I'm normally wrong when I try to explain CS concepts. Resolving this recursive iteration type chain is to my knowledge undecidable at compile time, without Currying iterating over the type signature producing a chain of self-applicable functions to handle the internal recursion.
Why I should use rust ( difficulty level 10) or pytgon (level 5) whilsg i can use amazon rekog or similar. Or tensorflow, you name it. There are plenty, big corporate offeeing taas. Mlaas
When async/await syntax becomes stable, can it replace code that currently uses `futures`? What would that look like?
I don't really see a reason for putting that mechanism in the language itself though - it can just as well be developed into a library ecosystem using a common interface.
Oh now I get it
I would note that the version of `DbC` presented for standardization in ISO C++ has a large emphasis on run-time verification: how to specify the "level" of the checks at compile-time, how to activate them at run-time, how to report (or not) violations, etc... It could be used by formal verification, I suppose, but that is neither here nor there.
You can‚Äôt publish your own crate with a git dependency though, which is what the op is asking for I believe
As others have mentioned, that won't work when you release an update to your crate, which is what OP is asking about
My understanding is that F* has better automation than Coq.
&gt;That works well as long until you try publishing: &gt; &gt;error: crates cannot be published with dependencies sourced from a repository &gt; &gt;either publish \`winapi\` as its own crate and specify a version as a dependency or pull it into this repository and specify it with a path and version &gt; &gt;(crate \`winapi\` has repository path \`https://github.com/Wodann/winapi-rs.git?branch=feature/bluetooth\`) I guess I will just have to pull it into my repository then..
Can you enforce a range bound on the input to a function? Like I have fn hi(k: i32) {} but I want `k` to only be on range `1..5000`. If it were small, I'd use an enum, but that's not really viable here. &amp;#x200B; I would also like to not use a macro.
Isn't this basically already supported through the use of assertions?
Well, vendor it to your repository is a choice.
This looks interesting, but what happens at runtime if the contract is violated? Does it always panic, or is there some kind of error handling mechanism?
Any plans to support WASM for use in a web app?
Make sure to not to miss the Servo case studies [here](http://blog.merigoux.fr/en/2019/04/16/textinput.html) and [here](http://blog.merigoux.fr/en/2019/04/16/bloom-filter.html).
Have you looked at the examples? In short, you get to decide; the macros simply move around the pre- and post-condition slots you fill. :)
One of the things I really liked about D is it has native support for contracts, and they are simple to write and simple to read. They are only enabled during debug builds too, however afaik, they are not integrated at the typechecker level for static analysis.
You can create a custom type that enforces the crate bound at construction.
There are some proc-macros to do run-time checks, but you should generally put a `debug_assert` to check those. `assert` is good too to most cases, but sometimes unsafe is used to improve performance so `debug_assert` will do.
Wrote a [port](https://docs.rs/restruct_derive/0.1.0/restruct_derive/) of Python's \`struct\`-module
You can read about D's native support for contracts here: https://dlang.org/spec/contracts.html
Indeed, HTTPS Everywhere was the culprit. Though I've never gotten any kind of error like this, which is fun.
Can someone explain Option&lt;T&gt;, Some&lt;T&gt;, None to me in a very noob friendly way and why and when it's mostly used? I just finished chapter 6 in The Rust Programming Language book. I feel like it clicked for a second but it just keeps fucking with my brain. I'm pretty noob if you couldn't tell.
Nice! I guess all the safety-guarantees sometimes come at a price. I can live with that for the convenience of not having to manually manage memory, though. I guess I was coming from other languages and somehow translated invalidate to just set to null, but is nice to see Rust will just not allow itself to have absolutely any variable where it must be forced to say at runtime "I just don't know what this is" or "this is null?", even when it sometimes it is overly restrictive. &amp;#x200B; Thanks for the explanation!
It's used any time you "might have a value or might not". For example, take a look at the `pop` method on `Vec`. Your vector might have elements in it, in which case `pop` will take off the last one and give it to you as a `Some`. But if your vector's empty, there's nothing for `pop` to give you, so you get a `None` instead. Like this: let mut myvec = vec![5]; // The first pop returns something. assert_eq!(Some(5), myvec.pop()); // But the second pop can't, because the vector is empty. assert_eq!(None, myvec.pop()); Another similar method would be `str::find`. It might find the substring you're looking for, in which case it returns `Some(usize)` to tell you where it is. But if it doesn't find it anywhere, it returns `None`.
An enum (and Option is an enum) is a type whose values come from one of potentially very many variants. You can express boolean values as an enum very easily: enum Boolean { False, True, } Thus, any value of type Boolean can either be `Boolean::False` or `Boolean::True`, just like any value of type Option can either be a `Option::Some` or `Option::None`. In addition to just being of a certain variant, enums can also carry data with their variants. `Option&lt;T&gt;` is defined as follows: enum Option&lt;T&gt; { Some(T), None, } So if a value of type `Option&lt;T&gt;` is of the Some-variant, it carries a value of type T, but if it's of the None-variant, it carries no data. This is useful for expressing, well, optional things directly in the type system. Some functions may return an `Option&lt;T&gt;` if the result is not always present - e.g. retrieving the path to the desktop directory, which may not exist on linux computers. It can also be used to model parameters as something that is not required - additional options that can be used to customize what exactly the function does, but that are not necessary.
Yes, that is the intent. I'll try to give an example. Current futures code for reading from a file: let task = tokio::fs::File::open("foo.txt") .and_then(|mut file| { let mut contents = vec![]; file.read_buf(&amp;mut contents) .map(|res| { println!("{:?}", res); }) }).map_err(|err| eprintln!("IO error: {:?}", err)); tokio::run(task); Async-Await code: let task = async { let mut file = await!(tokio::fs::File::open("foo.txt"))?; let mut contents = vec![]; let nread = await!(file.read_buf(&amp;mut contents))?; println!("{}", nread); }.map_err(|err| eprintln!("IO error: {:?}", err)); tokio::run(task); The details are likely wrong in this translation, I haven't been following too closely and async/await is a moving target. The gist should be right though; you're still creating futures and executing them on some event loop but the compiler helps create the state machine so you don't need many many nested levels of combinators and closures. It also should help with error messages with e.g. mismatching types and also enables borrowing across yield points, etc.
Right now I'm going to learn more about a modified version of a program someone gave me.
That second snippet you put in uses `tokio`. When everything is stable, will you still need an external crate, or will all the basic functionality be in the standard library?
I posted a few weeks ago that I was building a multiple queue/path structure so that you can impose arbitrary sort ordering and filtering while maintaining a the underlying queue/stack structure. It turns out that moving elements between paths is a really useful feature which requires some really fancy iteration footwork. So I'm struggling to find the best syntax for an iterator adaptor which can bind values out of an arbitrary point in a chain of iterator adaptors. So far it seems like I'm going to go for a ```format!``` like call structure, but I'd like it to also look as much like a ```for ... in``` statement as possible. I'm probably going to have to settle for less than my grand vision.
``` #[cfg(test)] mod tests { #[test] fn it_works() { let x : Option&lt;i32&gt; = None; assert!(x.is_none()what is going on here); } } ``` Anyone know what is going on with the `assert!` macro? Why does this test fine? rustc v1.31.1
I haven't seen any proposal to move types other than `Future` into the standard library. I wouldn't be surprised if it happened someday, but until then a library maintained by the same people is almost as good.
I really love anyone discussing program verification with respect to rust. Automated methods need to absolutely be a first class consideration with respect to programming language design, and rust has so much potential.
You can also try running your tests under `miri` -- at least if you're not using threads.
Is this work significant beyond academia? I don't understand the implications..
This is really neat, but I feel like it'd be a nightmare to try to manage tuples for particularly large structures (i.e., a filesystem superblock). Will there eventually be a facility for named fields?
To cite @boomshroom: &gt;It is *EXTREMELY* unidiomatic Rust code
What do you mean by ‚Äúc-ext libraries‚Äù? You can compile a C library to Wasm, and then uses it inside Python. You can also run a binary, that is compiled to Wasm.
Why wouldn't it? You assign None to x and then ask x if it is None. Of course it'll say yes.
You could have your function return some sort of Result, and then the first thing you do is check if k is in the range and return an Err if it isn't.
Yes, I'm going to add those; the syntax will allow one to specify the names of fields.
Yeah, but if you have a bottleneck anywhere that isn't the CPU then adding pretty stuff doesn't affect anything. If the slowest part is the disk in this case for example, the bars won't make it slower.
Tangential question: Are there any Property Checking tools for Rust currently?
Or agda?
I've never seen something ignore characters before. Why is "what is going on here" ignored?
I've been talking to a few people already who are interested in a DbC library that offers proc macros to define pre/post conditions which are automatically turned into `debug_assert`s and doc comments. In particular, [hellow](https://github.com/hellow554) was interested in starting such a library. This would already be a great start, I think!
Yep, that's the plan, thanks :) But as far as I understand, miri only does dynamic analysis, meaning it can only find bugs in code paths that are actually used, right? A "static" solution would be more awesome, because then the correctness proof wouldn't depend on the test coverage.
I am still new to rust and I'm stuck hitting my head against this for a while. I'm trying to write a crypto library that uses finite fields. I don't want to implement finite field arithmetic myself if I can avoid it and I've found numerous libraries for out on cargo and github. Most of these don't compile (feature flags that don't exist anymore). I can see that [ring](https://github.com/briansmith/ring) was originally started as a project using finite fields. However, [the documentation](https://briansmith.org/rustdoc/ring/rand/index.html) doesn't look like it actually exposes any of that in the API. Am I understanding this correctly? Does anyone know where I can get an implementation of finite fields I could use? Also how to approach these big libraries? I'm a little surprised by the lack of documentation but maybe I'm just not looking in the right places.
Oh, I thought that was a comment from you. Yeah that's wierd, must be something in how the macro is parsing its contents.
Nice, didn't know about `NonZeroUsize`, sounds like a good idea to me, thanks for the suggestion!
My understanding is that game networking usually uses partial snapshots: small snapshots of the state of a specific small element of the game. Then you can send partial snapshots of things that are more important to maintaining the illusion of simultaneity more frequently. By this design, deltas would be identical in size to the partial snapshots, since something like "position" vs "change since last position" would be 3 numbers in any case, for example. So I am confused about what the advantage of a delta stream is.
Constructive feedback is always welcome! You're totally right, the front pages do need some love, heck I even left behind the name of [my other library](https://crates.io/crates/reducer) from which I stole the README!
Wonderful! I'd love to find SOMETHING to facilitate writing packed binary parsers. :)
Yes, but the sibling was telling you about assert macros. You do want to have a good test suite for your crate, right? :-) Once you have it, try miri.
By c, I meant: Correct me if I'm wrong, but Python has the ability to import C libraries and call them, as if they were effectively local Python functions, right? Is this WASM binaries akin to that C library import? Or is it more akin to running binaries on the local system.
I packaged this now to get this into peoples' hands and break it. For example, \`c\_char\` is a signed char everywhere (there is also \`c\_uchar\` after all) like one would expect. Except when it's not, like on ARM where \`c\_char\` is actually unsigned; I did not know that and it break compilation
Yeah...that's something I had to fix with \[\`procfs\`\]([https://github.com/eminence/procfs/pull/30](https://github.com/eminence/procfs/pull/30)) recently. :)
What if function does IO? Would verification work in this case?
Doesn't it seem really weird for this to have such an ambiguous name like "runtime"? Maybe something like \`asyncrt\` would be better?
mhhh the example is confusing, typo? use std::futures::net::TcpListener; async fn main() -&gt; std::io::Result&lt;()&gt; { let mut listener = TcpListener::bind("127.0.0.1:8080")?; println!("Listening on {}", listener.local_addr()?); #[spawn(parallel)] for await? listener in listener.incoming() { println!("Accepting from: {}", stream.peer_addr()?); let (reader, writer) = &amp;mut stream.split(); await? reader.copy_into(writer); } } where is `stream` coming from and why is the binding `for await? listener` never used in the for loop?
The guy working on Oxide uses Coq, and OP works for inria where Coq work is significant, eventhough they also have some teams in partnership with Microsoft, hence my question.
i think the binding is supposed to be `for await? stream` there, that example isn't real code.
This is super cool and interesting will follow it closely!
not sure. they look like the best group to ask about it.
I've been trying to follow along with the async progress in Rust as closely as I can and this is really exciting to see. I've been heavily leveraging Tokio and futures on stable for quite some time and seeing all of this progress has me really tempted to switch to nightly so I can start taking advantage of these sort of features sooner, rather than later.
Why not use systemd services?
I think, if you want to publish to crates.io, you‚Äôll want to copy the crate into your own repo as a private sub-module. It‚Äôs not ideal, but it will work.
&gt;We don't know what the future holds, but for now we've chosen not to target micro controllers. While I don't work with microcontrollers themselves, this does make me concerned that `no_std` support will get pushed to the side and won't be compatible. I would hope that even if the default runtime doesn't support `no_std`, it would still be possible to do something like `core_runtime::Runtime`.
&gt; ..for client only there ain't much options then [Actix HTTP Client](https://github.com/actix/actix-web/tree/master/awc) looks like a very good place to start. I'm also interested in this, so I'd be happy to help figure it out.
&gt; I think this favors space-separated syntaxes, either of these, because they clearly separate the operator from the pattern: Not true. ‚Äòawait &lt;expr&gt;‚Äô evaluates to a value. While ‚Äòfor await &lt;ident&gt; in &lt;expr2&gt;‚Äô is binding a value to an ident. Meaning it‚Äôs just as bad as postfix macro like syntax. If async is a confusing async loop, then the simple solution would be replace the async keyword with await. ‚Äò[await] for ... in ... {}‚Äô.
I've got a composite trait somewhere saying: pub trait CBFn: FnMut(&amp;State, &amp;E) + Send + 'static {} When I try to pass a closure in to a function that takes in a trait object matching it: fn fun_function(f: F) where F: CBFn {} it fails. However, if I replace the composite trait (CBFn) with the traits it was composed out of, it does work. &amp;#x200B; I don't get it. Can someone explain to me why it doesn't work?
Yes, runtime already seems to mean several different things.
`ucrtbase.dll` and `ntdll.dll` are the two dynamic libraries providing all the underlying APIs used by Rust's `std` on Windows. This is everything from opening and reading files and network sockets to starting threads and allocating/freeing memory. I would ignore those and look for the `std` function calls that accumulate the most time. If you're profiling in release mode it'll help to have debuginfo turned on so the profiler can give you function names. You can do this by adding the following to your `Cargo.toml`: # if you're doing `cargo run --release` [profile.release] debug = true # if you're doing `cargo bench` [profile.bench] debug = true It will also help if you force on frame pointers so the full call stack is always reflected (otherwise some functions may be omitted from the profile if they got optimized out or inlined). The easiest way to do this is to set it in the `RUSTFLAGS` environment variable: set RUSTFLAGS=-Cforce-frame-pointers
This is extremely cool!
You still have to implement `CBFn` for the types you want it to apply to, e.g. a blanket impl: impl&lt;T, E&gt; CBFn for T where T: FnMut(&amp;State, &amp;E) + Send + 'static {}
Hey, I'm someone who does work with microcontrollers, also a member of the embedded-wg. I actually had a really great chat with Yoshua before he published this work, in particular to find the best way possible to include a path for embedded devices, including microcontroller systems. In particular, I think (and made a case to this effect) that trying to support these devices at the current stage would in fact be a negative goal for the project. There are a number of key building blocks that make `runtime` a possibility - include heap allocations, operating system primatives such as sockets, threads, etc., that don't have a widely accepted abstraction layer at the moment, though I hope that `embedded-hal` can someday grow to include these. The entire Rust team, with every interaction I've had with them, including online, at conferences, at the all hands, etc., has always been interested in how they can better support smaller and more constrained devices, all the way down to bare metal systems. For example, Boats [mentioned on twitter](https://twitter.com/bitshiftmask/status/1114186406149095424) that futures would be included in core, and there is a path forward for async/await as well. Embedded Rust is still a bit behind the desktop/server Rust ecosystem, but is catching up quickly. I'm happy to chat more, but I really would like to reiterate how much I disagree on the likelihood of a future where no_std support is pushed to the side. Between things like stabilizing alloc, and discussing std-aware cargo, I'd like to think that it's more likely that std vs no_std becomes a smaller gap - or not a gap at all.
Sorry I‚Äôm new and understand none of this
It was on a modded server so maybe. I‚Äôm pretty new to the game and don‚Äôt know what that is
Thanks for your help! I'll give these changes a go and see if I can get more detailed information. Do you have any recommendations for profilers? I was running tests today on Windows but will be back to good ol' Linux tomorrow.
Thank you for the kind words.
I've had a fine experience just using Visual Studio actually. If you open it without a project you can go to `Debug -&gt; Performance Profiler -&gt; Choose Target -&gt; Executable` and then choose your executable in `your_project_dir\target\release`.
I've been using VSCode so far but several people have recommend Visual Studio for profiling now so I will give that a go too. Thanks for your help!
I wonder how you see a large-scale async/await system being built up in Rust. For example a protocol stack where each layer has a number of possible asynchronous messages that might pass in or out on each interface to an adjacent layer, and a lot of internal processes, for example sequences of actions that run independently of one another and depend on async responses from other parts, along with timeouts and so on? Async functions would be ideal to handle long sequences of actions, e.g. a simple protocol conversation to a remote party, alternating between "send data" and "wait for response or timeout". The problem is how to plumb them into the larger system, e.g. how to talk to the adjacent layer and get data back. I've seen how to do this in a very minimal actor runtime in Rust. Passing around actor-references, actor-callback references, and queuing messages does the job. However I can't quite see how this is going to work with async/await, even though async functions would really help with coding the sequences of actions. Would I still need something like an actor runtime to do all the plumbing? Would it be best to see this as fundamentally an actor system with added async/await functions rather than trying to do everything with async/await? I'm just trying to get my head around this.
Really terrible name, though
I really like this, especially the ability to distinguish between (1) and (2). I was actually thinking of something like `(await element)?` for (1) and `await (element?)` for (2), using parens for grouping, but either of those seems preferable to a bare `await? elem` or `await elem?`.
Ahhh apparently I can't read, that was in the very first sentence. I've never tried to publish a crate with a git dependency but thinking about it now, it makes sense that you can't.
Wow this is huge, async looks better than ever. It took me an hour to convert tokio-async-preview server to use this and it made the code much more simpler!! (no more compat and weird maps and hacks, and all await return easy to understand types)
I made a fast wc: https://github.com/Freaky/cw
This sub is for the programming language called rust, try r/playrust for the game.
\`&amp;\*db\` is what you need. Your linked post has more info.
How similar is Rust to Swift? I have a game written in Swift and using Metal. I've had a gutfull of C family and openGL or java and the like, so wondering if Rust and Vulkan could be somewhat similar. Or is this madness? Also i've found Rust seems to have Vulkan wrapping, is it nice? has anyone worked with it before?
That data ins't really stored anywhere centrally right? It is just in blog posts and people minds atm? I might build out a simple version of this with some alternatives added to chit directly and see if people contribute more things to the "index". You have got me thinking
There is [proptest](https://github.com/AltSysrq/proptest).
Oh snap! I thought I was posting on r/programmingcirclejerk, hence my tone. Whoops!
Await-blocks could have special rules if there is the need for that, but also in your case a lint would do. &amp;#x200B; This syntax looks a lot like struct destructuring and struct constructors, but there is a key difference. Structs in patterns and code contain the same types, but await-blocks don't. That's definitely a point of friction that should be considered.
That doesn't work, I get this: ``` error[E0282]: type annotations needed --&gt; src/main.rs:30:13 | 30 | let _ = sql_query("SELECT 1").load(&amp;*db); | - ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ cannot infer type for `U` | | | consider giving the pattern a type ```
Disclaimer: It is entirely possible I don't know what I am talking about here. I am no expert. This looks like it's just getting rid of a load of boilerplate required to set up the the async plumbing - it doesn't add any functionality that doesn't already exist (unless you consider the runtime abstraction functionality). I'd assume an actor model would be built on top of this, as has been done before with the prexisting async stuff by the likes of Actix, which is built on top of Tokio. Tokio itself is built on top of Rust's async features. Or maybe Tokio just implements async interfaces? I don't really know what the implementation looks like. I assume that there is already some level of cross-lib compatibility, though, since runtime_tokio::Tokio exists. Regardless, I'd think that if you have decided to go with an actor framework, you will be coding against that abstraction almost exclusively. Whether that actor framework provides an escape hatch to access the lower level async abstraction directly, and how many hoops you have to jump through to gain such access, is probably just up to the actor framework's author.
That is different error. [http://docs.diesel.rs/diesel/dsl/fn.sql\_query.html](http://docs.diesel.rs/diesel/dsl/fn.sql_query.html) &amp;#x200B; if you see the docs, you cannot use `sql_query` to query tuples and if you need to load using `sql_query` then you need to have `#[derive(QueryableByName)]` on the struct.
Why did you expect it to? The code does not do anything unsafe, it's just a bug in your logic. It would potentially be a cool clippy lint, but it definitely shouldn't be a compile error.
I think you could start a separate thread for receiver and then wait for it to join. Not sure if it can be enforced in compile time. This is mostly a logical bug IMO.
You can spawn multiple for loops each awaiting different things, or the for loop could be one future combined into a larger future combining multiple operations. For example, you could have a server that spawns a request handler for each connection being served, with each request handler await-looping over incoming requests.
Coq automation is powerful and mature, but it is indeed missing a `z3` tactic. ;)
If you're interested in this domain, check out the *Software Foundations* series of workbooks. I did the first volume in about 30 hours spread across two weeks, and that was night and day for my understanding of formal verification.
Wrong subreddit. This is about rust the programming language, not rust the game.
oh shit...
I'm confused. I'm a Rust noob, but I thought Rust already uses monads everywhere. Isn't Option a monad?
Are those loops really that much nicer compared to the already working ``` while let Some(item) = await!(stream.next()) { ``` or potential ``` while let Some(item) = stream.next().await() { ``` I'm not convinced. In C#, where the syntax turned out to be `foreach await (var value in asyncStream)`, it made more sense due to the lack of pattern matching and thereby the ability to handle an end of stream. But that's not an issue in Rust, where it looks like we wold be mainly saving to type a low amount of characters. Regarding streams in general I would be happy if more energy would be spent in figuring out how to make them truly interoperable with and composable from `Future`s rather than to focus on syntax. While currently streams can be created from futures, it's not possible to await futures inside stream implementations and hand-written state-machines have to be used. Once that has been fixed and the usefulness of streams in an async-await world has been proven it seems a lot more appealing to think about syntax sugar.
Did you try paying the maintainer?
Nice work with integrating lots of bits and pieces in the ecosystem in one crate for a quick starting experience! However as one comment on the content, I would be very cautious with these kinds of statements: &gt; Why is Runtime Native the default? &gt; We believe Runtime Native provides a balanced implementation that works well for most scenarios. &gt; The codebase is small and comprehensive, and the algorithms simple yet performant. If there is a "works well for most scenarios", it should be backed up by more arguments, numbers or experience. E.g. we know that Netty in Java-world works well for most users, but I wouldn't claim the same for a new Rust runtime. Regarding this offering: I think of the Juliex implementation more of a toy project than something I would want to use in production for a workload that has high performance requirements. In the same sense I might not want to use a pure singlethreaded IO reactor (which Romio is). While this will really work well for a lot of users, and while the simplicity might be appealing to some users, it might also turn out to be disappointing for other users which might expect a "simple yet performant" async IO runtime for Rust to perform better. Since the native runtime is also not really more native than Tokio, calling it the SimpleRuntime or ReducedRuntime might give a better indication to users about what to expect from it.
Yeah, I guess now that it is separated from actix-web... But well, I already made my own HTTP client based on hyper and I added websocket upgrade to it already
Agree 100%.
Error message says `let first = &amp;v[0]` is immutable borrow. Does it help?
I would rather explicitly choose runtimes/keep them as values rather than doing this macro magic? What happens if I want initialise a runtime that wraps another runtime, for say instrumentation or this crazy batching idea I'm implementing?
It's lazy evaluated, since you're not using \_first or \_v for anything the compiler will skip the previous steps .
But how last line is impacting this? I am fine with compilation error but this should occur in both cases whether I write println statement or not. How is the \`println\` line related to compilation error.
Without print, `first` is never used.
The problem is that pushing to a vector might reallocate it. Reallocating a vector invalidates any reference pointing in. Rust prevents this with its type system: you are not able to do any mutating while you have references pointing in. If you delete the println, it is smart enough to notice that the reference _first isn't used any more, so it considers it "dead". That's why it then allows mutation. If you want to push to a vector, you might have to store the existing locations you want to keep track of, as just indices to it, instead of references.
Ok. In that case, below code should throw compilation error. **let mut** \_v: Vec&lt;**i32**\&gt; = vec!\[2, 4, 6\]; **let** \_first = &amp;\_v\[0\]; println!(**"{:?}"**, \_first); \_v.push(8); &amp;#x200B; But this is compiling.
[https://www.reddit.com/r/rust/comments/be3axi/not\_able\_to\_understand\_the\_behaviour\_of\_vector\_in/el2ttcr/](https://www.reddit.com/r/rust/comments/be3axi/not_able_to_understand_the_behaviour_of_vector_in/el2ttcr/)
What error do you expect?
What this looks like in Rust 2018 with compiler inserted drop statements: let mut _v: Vec&lt;i32&gt; = vec![2, 4, 6]; let _first = &amp;_v[0]; _v.push(8); // error -- mutating _v, but immutable reference _first isn't dropped yet because it is used later println!("{:?}", _first); drop(_first); drop(_v); Without println: let mut _v: Vec&lt;i32&gt; = vec![2, 4, 6]; let _first = &amp;_v[0]; drop(_first); _v.push(8); // this is fine, the immutable reference was already dropped drop(_v); &amp;#x200B; As a side note, before Rust 2018 introduced Non-Lexical Lifetimes all references wouldn't be dropped until the end of a block, so your example without the println will not compile in Rust 2015, but will compile in Rust 2018. &amp;#x200B; To get it to compile in Rust 2015 you would have to do: let mut _v: Vec&lt;i32&gt; = vec![2, 4, 6]; { let _first = &amp;_v[0]; } _v.push(8);
What you're seeing is called "nonlexical lifetimes", and it's one of the big new features of the 2018 edition. (It might get backported to the 2015 edition at some point too, not sure?) In short, the compiler is able to reason about the last time a borrow is _used_, rather than just looking at when the variable it's attached to goes out of scope. The case you're looking at is kind of trivial, since you could just delete the unused variable. But there are some other cases where nonlexical lifetimes has made a big difference. Look at this one: if let Some(i) = &amp;x { // do some stuff with the borrow... } else { x = Some(6i32); } In the `if` branch we're borrowing `x`, but in the `else` branch we're assigning to it. The 2015 edition compiler doesn't understand this, and it gets worried that the mutation and the borrow overlap. But the 2018 edition accepts this code just fine.
Nope, this is due to non-lexical lifetimes.
What you are seeing is due to non-lexical lifetimes. \_first is dropped after the last time it is referenced. In Rust 2015 you will get the error you expect because \_first won't be dropped until the end of its surrounding scope.
`push` would invalidate the `_first` reference, so the compiler doesn't allow you to do that. It doesn't matter whether `_first` is used or not, as long as it's before `push`.
Ok. You have written a very important point \`Reallocating a vector invalidates any reference pointing in. \`. It means if I use \`\_first\` before pushing element to the vector(doesn't matter how many times), I won't get any compilation error but as soon as I use \`\_first\` after pushing element to vector, I will get compilation error because it will invalidate all references pointing in. Please let me know if we are on same page.
Its because of a feature called non-lexical lifetimes: https://stackoverflow.com/questions/50251487/what-are-non-lexical-lifetimes
That's fine cause it uses the borrow before the mutation, once you mutate \_v the borrowed value becomes unsafe. It's to prevent dangling pointers.
thank you
What's up with the milk knife in the sidebar?
Yes, that's the idea. However, there's some more depth to it: the Rust compiler doesn't now anything about "reallocations" or that doing that might invalidate the references. That is purely a worry of the programmer who originally wrote the Vec type. The safety check is encoded in the type system using the immutable and mutable references. \`push\` is a method that takes the vector as a mutable reference, and that's incompatible with there being immutable references at the same time. When you call \`push\`, you are creating a mutable reference, and compiler won't allow that if there exists an immutable reference at the same time.
Thanks. Nicely explained. I also got a link [https://stackoverflow.com/questions/50251487/what-are-non-lexical-lifetimes](https://stackoverflow.com/questions/50251487/what-are-non-lexical-lifetimes) , where it is explained in detail. I believe Rust documentation should be updated accordingly.
Still working on Pushrod ... it's refreshing to see that there's a real need for a GUI library of sorts. The hardest part of the project is going to be the text editing, and drag start/stop with elements so I can create sliders and such. But that's definitely coming.
YES!! I've been awaiting your return :) Please keep making fun Rust stuff!
An option is essentially a list with a maximum length of 1. It can have `Some` element or be empty/`None`
I'm probably misunderstanding what a CPU does, but what about instruction prefetching, ie: i've read that sometimes it's faster for a cpu to execute both/all possible branches at once with hardware parallelism and then figure out which applies latter... though to be honest this is a problem that other languages have too, so they must have solved it.
Any ideas about a timeline for this? I'm in the middle of writing some CAD software for work and currently I'm just using WebGL via wasm_bindgen/web_sys directly. And I have to say. I'm not a fan of the GL family of APIs
I have used both, but so far have not used ndarray for any heavy lifting, and can't comment on performance differences. In principle, ndarray should be at least as fast as numpy I think. Being Rust, you are more in control of memory allocation and copying.
No language cares about speculative execution (which is what you're really after; instruction prefetching is related but far simpler). It's the job of the CPU to get that right. Access invalid memory? The CPU needs to catch that and ignore it unless that execution branch becomes the real one. Not being quite perfect in ignoring all the side effects from this is what leads to the Spectre and Meltdown vulnerabilities, though. Executing all branches is not what CPUs do, by the way. Instead they take a guess at which branch will be chosen ("branch prediction") and execute that, until they know for sure.
Side note: prefixing variables in Rust with an underscore means that they are unused. This is not just a convention; the unused variable warning of the Rust compiler is suppressed by the prefix. You should not prefix variables that you actually use with an underscore.
I am very curious in what you find out. Although if you are interested in pursuing machine learning at all, you should do these projects in Python (even if you do them in Rust first). The entire ML industry is very heavily geared around Python, and ML teams are unlikely to know Rust. Often they are more math focused and less comfortable with programming syntax in general, so anything that eases communication friction is advisable. That said, I am very interested in how well Rust handles common tasks that I might do with NumPy. I was just pondering porting a noise-based image generation Python script that uses NumPy over to Rust.
Shouldn't you be able to write a simple declarative macro for `for await?`?
but they'd have to be completely separate tasks right? otherwise, 'a: async for awaited item in promise(coroutine(yield(from))) { // or whatever // do stuff with the io, order of execution unknown, handled by unseen runtime } 'b: async for awaited different_item in promise(coroutine(yield(from))) { // or whatever // do stuff with the other io, order of execution unknown, handled by unseen runtime } any coordination between the code in the body of loop `'a` and the body of loop `'b` is going to be pretty perilous and deadlock prone, even with threadsafe synchronization, since the order of execution is indeterminate. I guess in the case that you have two completely independent tasks, you can run them in parallel this way, but again, that'd be very unusual in my experience. Possibly I'm misunderstanding how it would work, or why it wouldn't be so hard to share state between those two blocks?
Nice. Web view is such a neat project. I've used it from C# with [ASP.NET](https://ASP.NET) core. &amp;#x200B; The menu code is pretty interesting too. Wonder how much work it would be to add menu support for Windows and Linux too? A small library with cross platform menu support and a C API for use with web-view could be really useful.
If libraries are good but not widely used, either they aren't as good, or there is some underlying issue that must be identified. That issue doesn't clarify what is it. AFAICT libraries like `adhesion` are good enough for most people using them.
I hear this particular maintainer is partial to bunny pictures üê∞. If that fails they do have a [patreon page](https://www.patreon.com/retep998)
There is a rust crate called adhesion that implements that. The art of DbC is, however, on proving which checks aren't necessary to execute at run-time, and remove them. Neither C++, nor D, nor adhesion, are able to do this. Ada + SPARK can, and the approach being explored here could do so as well.
I have been thinking about this for quite some time. My idea would was to use rust in the backend and elm for updating the UI. Though I haven't had a proper idea for a useful application yet.
It will depend what you are doing. Numpy often calls out to optimised C code to implement methods, which should be as fast as or faster than rust if the arrays are large enough to hide overhead. If you are manipulating the Numpy array using custom python code element by element it will run at python speeds and you can expect it to be way slower than the equivalent rust code. I've used both, but not for the same project so I don't have a benchmark for you.
Just curious, why would you use Rust with an embedded browser? It makes your program consume huge amount of ram for no reason, so Rust‚Äôs main point ‚Äî efficiency ‚Äî is lost. Why not just create the app in typescript or something?
 I was mostly responding to how it's different from making a blocking call. I think you're right that in a lot of cases an async for loop won't give the needed level of granularity when multiple event handlers are multiplexed on a single task.
Have you considered adding a macro that let's you specify this using rust types instead of a format string? Maybe something that looks a bit like this: restruct! { name = Tea; endian = little; i32 * 2; f32; bool; } I think it would be much easier for people who aren't already familiar with the Python module to work with.
I don't think it would be hard. I'm going to start working on implementing menu, tray, dock and maybe window decorations in rust for Mac. I'm just wondering if writing a objective-c bridge would be better than using the objc crate. Maybe someone can contribute other implementations. At least to have for the 3 big platforms. Webview is also being rewritten in C++. Maybe they expose more APIs, but I think it will remain almost the same.
so let me get this straight: everywhere this ? is used, the code could actually panic out? wow, almost better to change the language to only use that sigil if you actually want to handle an error
Yes. I had this idea some time ago too. Just yesterday I wanted to see if it would work. Im going to start experimenting, since the app I want to make is just a clone for "raptor chart interpreter" since it only runs natively on windows and we use it a lot on school, and wine makes it look and work like it's a windows 98 program.
Thats the way the language works allready. If you write ? you either unpack the value inside the Result::Ok or you return to the caller with a Result::Err you do not panic
I'm definitely in the mindset that the work that goes into development is more than coding, and (at least in commercial environments) see a dearth of good meeting facilitation/communications skills. That said, I've also seen when non-technical people or people unfamiliar with the project get put into meeting facilitation roles. I can be good, but that often involves the facilitator finding ways to get familiar with the way software constrains a solution and solves a problem. In a way good outsider facilitators have to start thinking like coders. As a concrete example: You cannot take good summary meeting minutes if you're unable to understand the technical discussion. Often such summaries are outright misleading. This leaves full transcription of discussions which is super hard and also too verbose for interested parties. This is a long-winded way of saying communication skills are already hard (eg finding the right level of summary) and only dramatically harder if you're not down in the dirt of what you're trying to communicate. I would hope to see more on how to mentor these other roles on what is going on in the development process, and this would be a very useful for any software engineering team to look at as well. My traditional approach has been to try to push some of these tasks down to participants and rotate them amongst participants (eg chairing meetings, minutes, and other organization activities). In those contexts I was often able to lead on a good training program on how to chair good meetings that all participants had done so there was a clear structure. However, this wasn't in a software engineering context and I would be skeptical about how widely such a "push down" approach would be embraced.
Have you tried using [form](https://github.com/djmcgill/form) on bindgen's output? It does a pretty good job of splitting modules in a single file out to a reasonably structured project.
&gt;The entire ML industry is very heavily geared around Python, and ML teams are unlikely to know Rust. They should... me, having just wasted two days trying to speed up some data preparation / sample extraction task written in Python using parallelization, while knowing that this would have been a breeze (i.e. one-liner) in most other programming languages (like Rust, C#/F#,...) Most of the python code I see either runs on 12.5% CPU (1 of n cores) or contains overly complex and hardly ever well working parallelization code.
I think it's ergonomics, ecosystem, and I don't think efficiency is lost. As I said in the post, I'm also using rust for the front-end so it is very ergonomic to write almost the whole app in a language you really like. Some of the front-end is also compiled to WASM but I'm not sure if that increases the performance because I don't even know what gets compiled. It's also good to have more options to choose from. Regarding efficiency, I think a lot of apps could benefit from rust efficiency. There are apps that only need a friendly UI. Just like 20 minutes ago I downloaded an app to boot Linux in a USB (Etcher) and the app's weight was +100 MB, and I'm pretty sure almost all that weight is from the electron UI and it just has a simple window with 3 images and 2 buttons. Or maybe a git UI client that just talks to libgit and shows you the info in a pretty UI. Or just a utility someone wrote for, idk, check hardware temperatures and instead of using the terminal, you have it in your tray. I think writing these apps in rust would be a good idea, they would be fast, ergonomic and lightweight. It doesn't embed the browser, though. It uses the native browser in your system, so if you're on Mac it'll use webkit. That means that if you're using windows with a old version of IE it won't work.
You probably want to use [xargo](https://github.com/japaric/xargo) to build a std tailored to your target (and no_std).
How are you measuring your binary size? With arm-none-eabi-size, or the size of the elf file? The latter won't be an accurate representation, due to the extra contents of the elf file format. You can also check out [Heapless](https://docs.rs/Heapless) if you would like something like Vec, but more no std friendly.