This seems unnecessarily rude. While I don't agree with the parent comment and think it could have been worded more constructively, calling them a troll seems unfair. 
That's accurate, but we want to reach that state next year, not 5 years from now. The only technical blocker is GATs, which is being prioritized after the 2018 edition ships.
When I read the thread that was their only talking point about "rust is in transition".
While I'm sure you've got the best intentions, your comment (and /u/jnordwick's as well) is way too vague to be helpful. &gt; It is constantly in flux What is? The language? Some libraries? Async IO? &gt; the documentation is always dated enough to the point of not being usable for anything more complex than the basics What documentation? Async IO documentation? Language/std docs? Some crate's docs? &gt; this stuff is pretty essential to practically getting stuff done and introducing rust components in a work and team-setting What stuff? People are doing this successfully right now so unless we know what you're running into, we can't fix it. &gt; I myself keep trying to replace small scripts and similar things I would usually write in python or similar with rust equivalents, but some of the practical aspects make it lacking. What practical aspects? Are you running into gaps in the ecosystem? Are you running into bugs in the compiler? 
I would be happy to be proven wrong. However, i want to emphasize that I mentioned 5 years in reference to the asynchronous rust ecosystem stabilizing, not async / await reaching feature complete.
Just finished implenting [rewrite](https://github.com/Lucretiel/rewrite), a small CLI tool that lets you do this: ``` # has this (or something like it) ever happened to you rustfmt &lt; src.rs &gt; src.rs # try this instead rewrite sec.rs -- rustfmt ``` I wrote this tool in advance of a new project I'm starting called reflow, which is a language-agnostic, partially syntax aware comment reflow tool. Lines up your comments at 80 characters, while still being aware of paragraphs, indentation, simple formatting, and code blocks.
Right. It's a balancing act. I think there's probably a disconnect somewhere, but I don't know where. The problem with communication is the illusion that it has ever taken place at all. There's certainly some middle ground between "major additions that completely change the landscape of async programming" and "nothing new every getting added." :-)
This looks great! I couldn't tell from reviewing the source, and I'm currently trying to update my nightly so I can check: does this work? println!("{}", await!(async { "Hello, world!" })) It looks like it might not because the overriden `await` might not support awaiting the futures returned by async functions and async blocks. Is that correct? But it also looks like you re-export std's await as `std_await!`, so users can use that?
Thanks, added to the thread
The indexing operators `a[x]` are to be used when you are absolutely sure that the item exists. This is true in many other languages: * C (invalid index leads to undefined behavior) * C++ (invalid index leads to undefined behavior) * Java (invalid index throws an exception) * Python (invalid index throws an exception) * etc. Same applies for Rust stdlib types, like `Vec`, where `vector[x]` will panic if `x` is out of bounds and the way to go if you're unsure is to use `get()` which does return an `Option`. Sadly, you will have to implement standalone methods and `Index`/`IndexMut` can not be used for your use case.
Expensive in which way ? And what do you mean by productive ? In terms of performances, that's often true but Tokio and Futures are advertises as zero-cost (in the sense: it makes code as fast as if you hand-written the logic by yourself). I don't know how much these promises are held though or how much they are achievable at all. In terms cognitive overhead, that really depends on the abstraction but that's often very false. Good abstraction makes you productive with few concepts as long as you are using them for the purpose they are intended to. The whole field of software engineering is about dealing with abstraction, for the better: hand-crafting your own TCP packets in assembly isn't the most productive way of writing a web server :).
&gt; Good abstraction makes you productive with few concepts as long as you are using them for the purpose they are intended to. That's the ideal, but [all abstractions leak](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/). Avoiding abstractions entirely is bad, but they should be built and used with the understanding that they can't possibly always make thing simpler, and in the cases where the user needs to deal with the complexity, the extra complexity from layered abstractions stacks.
Ah, I see, you're using two different traits and duck typing! Very clever.
&gt; Would it be realistically possible to expand the team? We constantly expand our teams and form new teams, to the point where "core developers" is a meaningless term already. But given that more and more code in more and more areas is written, your strategy means that this team must ever grow. This is in itself a problem. &gt; I'd view it mostly as an experiment. We don't fear writing experimental code, so why should we fear trying out some process and see if it works? People aren't code, so different rules apply. If you want to have a curated set of crates, form it outside of crates.io first, try to keep the project going for 2-3 years. Also note that such things have been proposed ("Rust platform") and met with heavy criticism.
Thanks :-)
If you do this yourself you will just be recreating the Vulkano bindings. It makes more sense to just fork Vulkano and add/modify as needed if it ever falls behind what you need. &amp;#x200B;
Wrong sub, /r/playrust is what you want.
Getting back to my image processing roots (my Rust roots anyway) by building an implementation of a [multiple vantage point tree](https://github.com/abonander/mvp-tree-rs) which partitions a search space using only a distance function. I'm going to use it to find image duplicates and edits using my [img_hash](https://crates.io/crates/img_hash) crate and Hamming distances between hashes. It's full of unsafe code and doesn't even pass the few tests I've written for it yet, but still pretty exciting. Also got a failing test on `multipart` that I need to take a look at, should probably address that first.
GCC doesn't have a flag we could use to make it use LLD?
Maybe there is a crate for this or you can create a "local" crate either on github or in your project. [Cargo guide dependencies](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html). Hope this helps with avoiding copying.
As my first real rust project I'm trying to write an org-mode parser in rust. My first attempt at parsing headlines works but involves a lot of unnecessary cloning and copying, so I'm planning to restart with: \- assuming the whole file is small enough to be loaded in memory (which seems reasonable?) \- lifetime of parser/lexer = lifetime of source string \- lexer and parser simply maintain slices into source string instead of copying things around
C code is exactly like unsafe Rust code. Your wrapper library is supposed to validate data at the edge, ensuring that the C code cannot trigger UB. If the C code is buggy and it triggers UB *even when you followed all the documented invariants*, that's a bug in the C code, not you're wrapper.
Yeah, but unfortunately on codeforces you don't have access to any external crates, you just upload a single file of code and it should do the job using only standard library (moreover, it should do so in limited amount of time and memory).
&gt; we do have stuff like a crate named "reqwest" solely because "request" and "requests" were taken Which, I might add, is bucking unpronounceable, guaranteed to be mangled by autocorrect or even mistaken for a typo by humans. Ugh.
What stuff is essential For use in a company? Asynchronous IO? That's probably untrue for many companies.
Thanks, glad you enjoyed it :) I was a bit unsure about the detail level, hopefully I managed a reasonable balance.
I've created a hashmap where the values are vectors. If the key exists, I want to push the inserted value to the end of the vec. If the key doesn't exist, I want to create a new key-value pair. Since these are both mutable operations on different parts of the data structure, my naiive implementations are running afoul of the borrow checker. https://play.rust-lang.org/?gist=80feabb475a967226796dc766ec5704e&amp;version=stable&amp;mode=debug&amp;edition=2015 Might be a simple fix, might require a different data structure. Any thoughts? Thanks
I think OP has the right mindset. He isn't expected to do a full audit, but __that would be a very cool thing to do__! Indeed, if OP knows that `foo` has this bug, he __shouldn't__ wrap it into a safe function (but instead correct the bug or simply not expose the API to Rust). After all, with `foo_wrapper` we can trigger UB from safe code!
Do you think that this could be won by the recent proposal to add \`\`\`&amp;out T\`\`\` and \`\`\`&amp;init T\`\`\` as additional reference types to the Rust Programming Language where \`\`\`&amp;out T\`\`\` represents a reference to write-only memory and \`\`\`&amp;init T\`\`\` represents reference to unitialized memory that is "write-once"? If this would be added to the language, do you think you could be more effective on squad assaults? Inquiring minds want to know.
Sidenote: I'm just a rust beginner but I think a if let Some() {} if let Some() {} pattern would be a bit nicer and I think does the lifetime inference the way you want? Haven't pulled up the compiler yet (so sorry) but I think so.
That's a great explanation! Thanks. 
When you do `command | sponge output`, sponge creates `output.somesuffix`, which it renames to `output` when everything is finished.
Wow that rusoto crate is no joke
I've really been enjoying this series so far. I haven't been actively following along yet (aka typing in the code myself, though I plan to). A lot of juicy info to help me better understand the language, and doing so with exactly my target use case (building languages, though at some point I want to do LLVM, but starting with a language VM is a good place to begin).
Emacs, VIM, Eclipse, VSCode, KDevelop, etc, etc, etc.
But you can type it one-handed on QWERTY keyboards! 
I think it would be appropriate to wrap a C function in a Safe wrapper provide the following is true: * The C-Code in question isn't known to have serious bugs * The "Contract" for the C-Code is well-defined enough that you can create a C-Wrapper that enforces the appropriate pre-conditions (inputs) and can check the post-conditions (output) to ensure that the C-Code cannot be invoked with arguments that are known to lead to UB as stated in the contract of the C-Code's documentation You cannot put as "Safe" wrapper around C-Cod if any of the following are true: &amp;#x200B; \* The C-Code in question is known to have UB and security bugs even in the presence of being called with arguments that meet its contract \* The contract, as defined by the documentation of the C-Function, has no way for you to enforce in Rust code &amp;#x200B; For these latter kind of C functions/libraries, the best you can do is wrap it in and "unsafe" Rust wrapper, but, I would question why that would ever be a useful/worthwhile thing to do.
I agree, that's basically how you operate when making a FFI to call rust code with the C ABI. If you deref a pointer you must check that the pointer is not NULL, just to define the behavior, it can be anything except UB. The same should be applied when calling C code from rust.
In both of those cases, you could effectively insert an `else { drop(s) }` after the `if` block.
No, quite the opposite. Coroutines get compiled into some hidden struct, but that struct can still live on the stack like any other struct might. The async IO story is designed to keep Rust's "zero cost abstractions" party going, and to support no_std situations where you don't have a heap allocator. That said, a lot of async IO scenarios are expected to use heap allocation. For example, if you're a webserver handing requests, you probably going to put each Request future in the heap as it executes, to free up your main loop to await another connection. (Otherwise you'd need to arrange for all the requests executing in parallel to live somewhere else on the stack, which would either dramatically limit your parallelism or requirie some kind of giant up front futures buffer.) Because each future is of a static known size, though, that allocation can happen in a single call, and in general the overhead can be very low.
&gt; How would pure syntax sugar suddenly remove the need for tokio? ✖️ How would pure syntax sugar suddenly remove the need for tokio? ✔️ No longer have to be dead-coupled with `Tokio` Do you know something called "Adapter Pattern"? It's similar, because the `async/await` standard is in the standard lib, everybody should design their `async/await` according to the standard, including `Tokio`. So in the future, you can design your own work only with `async/await` in mind, without considering the underlying layers too much. You can also swap `Tokio` for another async IO lib, making `Tokio` an adapter, thus REMOVE THE NEED TO BE DEAD-COUPLED WITH `TOKIO`, if this could make you understand better. Now, do I explained everything that I already explained few comments ago and got down voted? BTW, since I already got many down vote, I don't think I still need to maintain my altitude any more, so, just a simple question: how many people here know anything about "Design Pattern"? No, no, no, another question first: How many people here are maintaining a project that is over 30 thousand lines of code, and still managed to kept everything (dep, mod etc) up to date without too many developmental delay? I think it's 0 because I saw no body even consider the future effect of coupled code here. Everybody was talking about "Hey, why you want to remove `Tokio`?", "How does `async/await` work without `Tokio`?". That, to be honest, was stupid and annoying. In an ideal world, everything third-party should be an adapter that can be gotten rid of at anytime, so you can have better guarantee that your project is future proved. Because if something turn bad or changed, it can be completely replaced without change many of your existing code. That's be benefit of why it's a good thing to put `async/await` to the std. And please, continue downvote me. I will no longer post anything here, because I don't always like to write Computer Engineering 101 for 5 years olds.
It seems like this patch won’t support “async fn” since “async fn” is using futures 0.3.
Oh right - my bad. I was thinking of Futures.
Correct. And (for OP) this isn't just a Rust-specific thing. In C, these are represented by INADDR\_ANY and INADDR\_LOOPBACK. &amp;#x200B;
Perhaps so, but this is a subtle distinction at best, and it's not reasonable for someone just learning about Rust and/or async networking in Rust to understand it.
I wish someone would/could burninate this usage of the term "isomorphic". Next thing you know, CI/CD will be replaced by "homeomorphic devops". 😬
You can see the examples are working. “async fn” is provided entirely by Rust and the stdlib, not by the futures crate. 
Tokio re exports some traits for convenience. 
Going to take a small break from project-rs and answer more questions on reddit. I feel like I've made a lot of progress, but need some more time to just relax. (Yes, I know I've been working on a single project for two weeks ;)
&gt;Let it be namespaced using the github username/org. Let's not repeat Go here. You already have to register to publish crates on crates.io, use that username.
Any recommendation for database for fast prototyping, atm I am inclined to go with mongodb? Not a big fan of relational database for whipping out things quickly
Hopefully it does so safely, ie, without rewriting any other files by accident?
So, what's the story with trying to make edits to the standard library? If this has already been answered, feel free to link to that. In that case, or even if discussion is ongoung, could we perhaps make a pinned Reddit Topic about it? Basically, if I want to make edits to the stdlib, why does that mean I have to go through the utterly interminable build process for the compiler every single time? It seems like even if I correctly tune my stages, I have to rebuild it at least once. I have a lot of tiny little edits I've been playing with, mostly to Iterator implementations, but I feel completely stonewalled by tbe build process.
I'm trying to figure out how to save and load a container of boxed dyn traits. It seems that, to use serde, I have to write my own deserializer and the derived serializer does not hold onto the type information... Anyone know alternatives or workarounds? &amp;#x200B; [https://github.com/dtolnay/erased-serde/issues/25#issuecomment-416092573](https://github.com/dtolnay/erased-serde/issues/25#issuecomment-416092573)
I'm trying to build a very simple data structure Registry which uses HashMap internally and I have a borrowing problem ( *can't borrow as mutable because borrowed as immutable* ) when using both hashmap.get and hashmap.insert: [https://pastebin.com/TVbEQzdy](https://pastebin.com/TVbEQzdy). I changed `&amp;self` to `&amp;mut self` but for some reason it doesn't help. Any suggestions?
Thanks guys.
It's not orthogonal: If we had a way to access children in `update()` so that we could update their state without having to change our own state and returning `true` from `update()`, we wouldn't need to re-render our DOM to be able to update our childrens' states. &gt; What do you think about my suggestion of having different children types instead of different enum variants? Too impractical? The same component type can occur as a child in different parent components. As I understand your approach, this would require creating a new wrapper newtype for every occurrence of a child component in another parent component (and impl'ing/deriving a trait for it), which is more verbose than having one enum variant per child+parent combination. Or am I misunderstanding what you mean?
This book looks great.
&gt; that makes me wish Rust had garbage collection But then it wouldn't be Rust. The whole point of Rust is to get all these nice high-level abstractions at zero-cost. If you're ok with having a GC you might as well use Haskell / Ocaml and then you'd also have HKTs / first-class polymorphic modules..
 The issue is because `HashMap::get` returns an `Option&lt;&amp;u32&gt;` and borrows the hashmap until it is dropped, even if it is a `None`. Since your value is just a `u32`, you could convert the result e.g. pub fn resolve(&amp;mut self, name: &amp;str) -&gt; u32 { let id = self.id_by_name.get(name).cloned(); match id { Some(id) =&gt; id, None =&gt; { let new_id = self.id_counter; self.id_counter += 1; self.id_by_name.insert(String::from(name), new_id); new_id } } } Then you're just matching on an `Option&lt;u32&gt;`. [playground](https://play.rust-lang.org/?gist=52493e1ec09498d2ba12e61f7abbfb0a&amp;version=stable&amp;mode=debug&amp;edition=2015) Another way to is to do an early return if you found a key: if let Some(id) = self.id_by_name.get(name) { return *id; } ... There's also the [Entry API](https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html) for this usecase of "get or insert with", when you only need to return a reference (the early return wouldn't work without NLL) but it requires an actual key, so it'd waste string allocations in this case.
This is a hard one, because the type information is basically erased. How would it disambiguate between the different structs? I.e, `struct A` and `struct B` would both serialize to: {} When deserialising, what should be returned? You might want to think about using [tagged enums](https://serde.rs/enum-representations.html). But without knowing the full extent of what you're trying to accomplish, I'm not sure what would be appropriate. 
I see. Thanks for the explanation!
Thanks, great explanation!
You can't have both an immutable reference and a mutable reference at the same time. You can do something like this: https://gist.github.com/0a1fe32e531fa61e5e1922700fd6a7bf This shortcuts the immutable borrow, returning immediately
lol
At the risk of making a fool of my self, I must ask: how is an `&amp;out` reference different from a normal non-mutable reference? Do you have a link to the rfc in question? 
Why not import the macros with `use`?
Rust with GC* is pretty much an open niche and will be the next big language at some point. *Compiled, strict, sum types, generics, multicore, mostly imperative.
I think it's pretty funny tbh.
Oh yeah sure that's what I meant.
Reinterpreting pointer as another type triggers UB unless aliasing rules allow that.
I think Swift could fit that bill, if they started to support more platforms as first tier.
It uses mkstemp.
Moving some stuff at work over to Rust (finally!). For now that means CLI scripts, but there'll also be a small web service or two that I'll be porting over. Also, [I made this thing](https://github.com/runiq/hackertyper.rs) to get my feet wet.
This is extremely exciting! With this I think I'll finish rewriting some python web services into rust+actix+tokio+futures. I had started before, but the logic got almost impossible to represent with callbacks and it felt extremely clumsy compared to python's asyncio. I'm glad I can just plug this in and go! I realize things will break with nightly and such, but just having something to play with is great.
Btw, any idea why this happens: When I bind to `0.0.0.0` with `tarpc`, I can ONLY connect from non-localhost machines? (On both arch linux AND Win 8.1) https://github.com/google/tarpc/issues/176 And obviously, when I bind to `localhost`, I can ONLY connect from within `localhost`. But I need to be able to accept connections from clients running on `localhost` AND from outside (other machines on the LAN).
If you actually want to be able to do this recursively, for arbitrary types, you can do it with a trait: &amp;#x200B; [https://play.rust-lang.org/?gist=4187cb4591b065f62546887f8a5d32bd&amp;version=nightly&amp;mode=debug&amp;edition=2018](https://play.rust-lang.org/?gist=4187cb4591b065f62546887f8a5d32bd&amp;version=nightly&amp;mode=debug&amp;edition=2018) &amp;#x200B; There's not really any way to implement the trait generically, since you'd have two conflicting \`impl RecursiveLen for T\` items (one for atoms like \`i32\` and one for collections like \`Vec\`). However, with a macro, it's pretty straightforward to write an implementation pattern and list all the types you might need it for.
While it's (currently) impossible to implement the trait generically (that is, for all `T`), it's pretty straightforward to build a trait that does this (even recursively) and use a macro to implement it for all types you might need: https://play.rust-lang.org/?gist=4187cb4591b065f62546887f8a5d32bd&amp;version=nightly&amp;mode=debug&amp;edition=2018
Could we eliminate drop flags from the run-time completely by using move-analysis to insert those `else { drop(s) }` blocks?
The better way to do this is to use the [`Entry`](https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html) API. Essentially, you call .entry() on your Hash Map; this returns a "slot" called an Entry, which can be used to get or set the value at the slot. This way you only have to perform the hash + lookup once!
I anal but I think we will have better standing if we never do it. Fwiw, I think such a lawsuit is completely baseless and without merit but that's a lawsuit for you. 
Why do you say this will not support futures 0.3 then? All the basic future combinators just produce implementations of `std::future::Future` so should work the same way. Or is this more, “we don’t explicitly support it, but if it works it works”? I guess it’s not possible to use futures 0.3 combinators directly on Tokio futures since they’re still 0.1, but you won’t be able to use futures 0.1 combinators on the futures returned by async fn/blocks either.
[Here's a list!](https://www.reddit.com/r/rust/comments/98o0rm/rustconf_made_me_want_to_write_more_rust/e4i98it/)
[My Little Procedural Macro &amp;ndash; Chris Wong](https://docs.google.com/presentation/d/1mosh3qanPqw3qkqUXab6BkE45H7JhRcV1u4IlTCLp9c/edit)
I have the same aspirations. However, I'm trying to understand how tokio and futures (and async/await) ties in with the actix model. 
I think as of the latest version it's safe to say actors are built on top of tokio? For instance, you can return a tokio future from an actor spawn method, or wait your actor on completion of a future, or return a `Box&lt;Future&lt;&gt;&gt;` from an `actix-web` handler. You need to start the actix actor runtime in addition to the tokio one, but it still all runs on tokio and can interop with futures at the lower levels.
A destructor may have side effects, so the time it runs (at the end of the scope vs. after an expression that (conditionally) moves it) is relevant. There was a debate about "static drop semantics" (the implicit else one) vs. "dynamic drop semantics" (current behaviour) a few years ago. The latter one.
There's a formatting help link under the post box. Indent text with four spaces to format it as code. Even better is a Rust Playground link where people can play with your example.
&gt; I'm glad TLS is going to be removed. Ah sorry, do you have more data? I am not able to find any source via Google about this decision, and what will be used instead. 
Some questions worth asking: * When you say you're connecting from localhost, are you connecting to 127.0.0.1, "localhost", or your public IP? * Do you have IPv6 enabled? * Do you have a hosts file with an entry for localhost? * Are you in a domain that has a localhost.mydomain entry in DNS? 
I will love to have an eBook that gather all the design patterns of Rust. Awesome job!
Awesome!
It's a write-only reference, while `&amp;mut T` is a write-read one, i.e. compiler will prevent you from dereferencing it or coercing into `&amp;T`. See e.g. this [thread](https://internals.rust-lang.org/t/pre-rfc-partial-initialization-and-write-pointers/8310/12) for discussion.
Is [the task context RFC](https://github.com/cramertj/futures-rfcs/blob/task-context/task-context.md) enough?
Oh good lord, you fuckers are invading Michigan? Get the fuck out.
You almost never need to abstract over types that have `new`. That's because, when you are constructing something, you usually need to know the concrete type of what you are constructing. Type conversions are a different story but, as the blog post discusses, types like `Rc` make that hard to abstract over in this case too.
to be sure, you can trigger UB from safe code, but that will always be true. I feel like the issue maybe becomes more salient when you compare it to undiscovered bugs or subtle misuse of their api. In either case, maybe you've done your best to validate that it works, exposed a safe function, and all is well. Somewhere down the line you discover a segfault. Happily because this is the only unsafe block in your program its easy to pinpoint. At this point you cannot make your function unsafe unless you want to break all calling code, so its really just as much a bug as if you had a logical error. In trying to extend that logic back, if you know your interface **will** be possible to be made safe (e.g. \`foo\_wrapper\` as a rust function takes no arguments and doesn't return anything related to the call to the C code, so therefore it doesn't leak anything into/from that call); is it **really** wrong to call it safe right off the bat regardless of whether you know if the call `to `foo has UB because at worst you could simply switch out the C code.
A next episode will discuss about targetting NodeJS as a native module with [Neon](https://www.neon-bindings.com/). I think it might help you too!
I assume you are talking about the feature image on the header. This is a picture from Mars, http://www.esa.int/spaceinimages/Images/2018/06/Uzboi_Vallis, not from Michigan.
I mean generally I agree, though I'm not sure if my example quite got across the whole point. If I can describe a public api for something in rust, it feels like that should be safe regardless of internal calls to unsafe C code (and regardless of whether I know if I am upholding C invariants) because that internal unsafety is an implementation detail of the safe interface im exposing (which at worst, i could swap out for (maybe slower) safe rust code). It feels like any discovered segfaults are simply bugs (and not incorrect exposing of safe functions) in the same way it would be if someone discovered a bug in the implementation of std-lib implementations with unsafe internals.
Imagine `foo` was an unsafe Rust function. Treat it the same way
you're probably looking for /r/playrust/
Typically the software that you’re building in Rust (or any other language for that matter) wouldn’t have the ability to change the public IP address of a server/computer. Here are a few suggestions: If you are hosting your server via an online provider, such as GCP or AWS, you may be able to request an IP change (I believe AWS has an automated change feature upon request). If you are hosting your server on your own local network, depending on your network configuration, you will need to have your router assign a new address for the device. I would do some research on how to do this with your particular configuration. Lastly, if for some reason the above two methods are not appropriate to your situation, and you own a server/have access to a server where the IP cannot be changed, and you wish to “prettify” it, I would recommend getting a custom domain from a site such as NameCheap or GoDaddy and using an A Record to redirect traffic from a certain host to your server IP. If you need further assistance, feel free to send me a message on Reddit.
Thank you so much for your help!
&gt; Do you know something called "Adapter Pattern"? The [Adapter Pattern](https://en.wikipedia.org/wiki/Adapter_pattern) does not require that adapters be a part of the standard library. &gt; everybody should design their async/await according to the standard, including `Tokio`. [sic] There is a de-facto standard interface for asynchronous tasks, [it's called `futures`](https://crates.io/keywords/futures). The `Future` trait moving to the standard library does not change the fact that there is already one extremely common crate used by rustaceans for asynchronous work, it's just getting moved from an external crate into the standard library. &gt; So in the future, you can design your own work only with `async/await` in mind, without considering the underlying layers too much. Currently: design your work around `futures::Future`, after `async/await`: design your work around `std::futures::Future`. &gt; You can also swap Tokio for another async IO lib, making `Tokio` an adapter, thus REMOVE THE NEED TO BE DEAD-COUPLED WITH `TOKIO` [sic] What exactly is preventing developers from writing a different library at the same level as `tokio`, using the `Future` trait? How does `async/await` change this, aside from moving the `Future` trait into `std` instead of `futures`? &gt; And please, continue downvote me. I will no longer post anything here, because I don't always like to write Computer Engineering 101 for 5 years olds. Have you considered that you're being downvoted due to an inability to incorporate constructive criticism and acknowledge that you're wrong? Condescending comments are rarely taken well, especially when the author demonstrates a lack of understanding of the topic at hand. Conflating `futures` with `tokio`, for example.
&gt; filter() is basically Ruby's select()—unfortunately standard Rust has no reject(), so we use Rust's syntax for a closure here instead, much like the Ruby select { |s| !s.empty? }. So `c.reject(cond)` is basically `c.filter(|x| !cond(x))`? Does it really carry its weight? &gt; Rust's dedup() takes a much cheaper path: iterate over the collection and remove consecutive repeated elements. This is less flexible, but consumes very little memory. To nitpick: It does not consume any memory. As you noted though, sorting is required: `sort` consumes memory, `sort_unstable` doesn't. &gt; finally we instantiate EntropyRng, its generic secure random generator. You might want to use `StdRng::from_entropy()` or `thread_rng()` instead. It will will use a deterministic CSPRNG that is initialized with `EntropyRng`, which is a lot cheaper. It matters if you want to generate lots of passwords, but this seems like an unlikely use case. &gt; "Speed" is the easy answer, but Rust's only about twice as fast here—450ms vs 250ms on my ancient Xeon. Did you use `cargo run --release`? I don't think it matters much, because the runtime is probably dominated by syscalls to get entropy. You should be able to massively improve performance for both cases using a CSPRNG as I suggested above (this applies to Rust and Ruby).
As a result, you now need nothing more that a nightly toolchain to build embedded programs for the ARM Cortex-M architecture: https://github.com/TeXitoi/blue-pill-quickstart/blob/master/.travis.yml
main.rs can import from lib.rs using extern crate "libname". lib.rs cannot import from main (I guess you could if you had a module named main?) More importantly lib.rs and main.rs are considered separate namespaces. Each .rs file is. Move the the test to main.rs or move the add_two function to lib.rs and import it in main if you need it there.
You want r/playrust
if and only if you are using the latest versions of cortex-m, cortex-m-rt and cortex-m-semihosting (if you are using that one). Older versions of those crates require arm-none-eabi-gcc to build.
Thank you for the quick reply. So at least I'm not just missing something obvious. So this means tests for the 'root' module always need to be in main.rs? I would've like to keep test code seperate, but so be it. At least I can stop breaking my head over this.
An interesting read. Great post! I'm really looking forward to the next steps :)
Yes, that will just need a `cargo update` most of the time. https://github.com/TeXitoi/blue-pill-quickstart/commit/0452cf6749483628c1ca399bebf8f091f4e3cf05
Starting my rust journey by writing a compiler/vm I'm quite enjoying the rust experience, but there are still quite a few things that are leaving me with questions Definitely need to finish reading the rust book I can definitely see myself working a lot more with this language 
Why?
Not sure really
You're exactly right and that is exactly the motivation for static drop semantics. However, it changes the semantics of the code because it's changing when destructors run, e.g. https://play.rust-lang.org/?gist=0d564d3a1257121d5e35049479e3ba40&amp;version=stable&amp;mode=debug&amp;edition=2015. https://github.com/rust-lang/rfcs/pull/320 is what a brief search found as the dynamic drop RFC that was accepted.
So if I were to develop something for Cortex-M from scratch, what would I need? Just install nightly cross compiler using rustup and that's it?
You may also want something to flash and debug, thus openocd and gdb-arm-none-eabi
I’m confused. The book says “One final note: Tests cannot be run on a binary file. To see more on file arrangement see the Crates and Modules section.” Main.rs would be considered making a binary wouldn’t it? So you can only test library modules? 
Nitpick: we don't know what would the above program do. It might segfault, eat your laundry, wipe the hard drive or cause end of the Universe. If you know a certain function invokes UB under certain conditions, you must design the safe API such that calling the from safe code function under those conditions is impossible. Some examples: In case of your example, if you know for sure that the function invokes UB, it must accept `!` type, which makes it uncallable. If your function invokes UB when you pass it `42` as an argument, you must either: * Create a newtype `struct NotTheAnswer(u8);` and impl `fn new(u8) -&gt; Option&lt;NotTheAnswer&gt;` returning `None` if the argument is `42`. Then require `NotTheAnswer` as an argument. This approach is very elegant and helps eliminating some checks, but it's boilerplate-y * Accept `u8`, but panic/abort/exit if the argument is `42` * Accept `u8`, but don't call the function if the argument is `42` - this is likely the worst idea (undebuggable) If you need some internal API, the best choice is to put it into a separate module and make the interface of the module safe, so that not even your own crate can use it incorrectly. If not, you should use `unsafe`. Try to keep it as small as possible. If there are some unrelated parts of API, best to make module for each of them. (Single responsibility principle.)
I haven't yet published any crates but I intend to and I choose stable for a variety of reasons: 1. That's the way it's intended to be. Browsers had to switch from vendor-prefixing unfinished features to either locking them to channels like Firefox Nightly and Chrome Canary or putting them behind `about:config` / `chrome://flags` toggles to deter people from treating them as more stable than they are. 2. I value ease of maintainability. It's the whole reason I'm migrating my efforts from Python to Rust. I didn't start coding for Rust until 1.0 came out for that reason. 3. Supporting stable makes your crate available to the widest range of potential users.
I usually write for stable since a lot of applications prefer using that as much as possible. I only write for nightly if there a certain feature I *have* to have. 
For 99% of libraries, they should target stable. Because 99% of applications should target stable. (Some libraries might want to target (stable - 2) or similar to give users some slack time to update Rust.) However, for that 1% (rounded), there's some nightly feature that makes a notable difference in how the library might be written. In those cases, targeting nightly is inevitable. Right now the big one is async/await/pinning along with the edition. If you're experimenting with any of that, you need to be on nightly. But for libraries that want to be used, stable is the correct choice. Many will then offer a semver-exempt feature flag to build against nightly and offer integration with some of the more complete and less unstable of the unstable features.
To expand a little, the "entry API" means the value returned by [`HashMap::entry()`](https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.entry), which represent a possibly-empty slot in the hashtable. 
I'm writing a library. I'm currently on nightly because because the only reasonable way to implement what I want is an attribute macro. I expect to move to stabe when 1.30 comes out. Side note: I think you can make a library work on stable and enable benchmarks only if the user is building on nightly.
Isn't multicore support super immature in OCaml?
The `tokio::await!` macro should work with both 0.1 and 0.3 futures.
I care about stability, reliability and maintainability. As far as I'm concerned nightly does not exist.
&gt;Rust with GC* is pretty much an open niche [...] &gt; &gt;*Compiled, strict, sum types, generics, multicore, mostly imperative. Scala is pretty close to that. The only issue is that you have to deal with the JVM, but for projects where a GC is acceptable, the JVM should be OK. Scala-native is very promising, though.
I believe you are looking for /r/playrust
I always target stable. I generally use stable for everything except running Clippy. With Criterion, you can even do benchmarking on stable (and it's a better experience than using the std benchmark framework)!
I’m loving these posts! I would never have considered compiling WASM to an Asm.js target, but it’s good to hear that the results are worthwhile.
&gt; So `c.reject(cond)` is basically `c.filter(|x| !cond(x))`? Does it really carry its weight? I certainly use it often enough in Ruby to appreciate it's there. `reject(&amp;:closed?)` is a lot tidier than `select { |f| !f.closed? }`, particularly if it's in a chain with other calls, and it's annoyed me more than once that Rust only has the slightly ambiguously-named `filter`. &gt; To nitpick: `dedup` does not consume any memory. Not even a bit of stack space?
I think so. Again, I've never tried it, but from what I know, a main.rs can do all the module type stuff a lib.rs can do, as well as import lib &amp; it's submodules as a crate. So I would think that'd include having a test module.
I've got an FFI struct whose last member is a variable length array. The simplified rust version looks like this: #[repr(C)] struct VariableSize { data: OtherStruct, number_of_packets: u32, packets: [PacketStruct;0], } What's a good way to go about allocating such a struct with a dynamic size? The `packets` member must be contiguous with the rest of the struct, so it can't be broken out into a Vec. I'm aware of value generics eventually coming down the line, but I want to choose number_of_packets at runtime. (for the curious: actual application is the urb struct in linux usbfs.)
&gt; Extend 'Unresolved Reference' inspection to highlight trait method calls if the corresponding trait is not in the scope. Also, provide quick fix to import this trait 🙌🙌🙌
Thx
The associated type is kinda "a part of" the overall type. Think of how `Vec&lt;String&gt;` and `Vec&lt;u32&gt;` are related but not actually the same, because the abstract T in `Vec&lt;T&gt;` has been filled in differently for the two vectors. 
\&gt; hides all of this explicit logic for the price of having to stick to 0.1. futures in the \`await!\` macro. &amp;#x200B; This is incorrect (see the above thread).
I tried... but couldn't get it to work reliably. It probably is a misunderstanding on my part, so I just stuck w/ extern crate w/ \`#\[macro\_use\]\`.
No current plan given that new future work is still experimental and I am not aware of the plan for making it stable.
Amazing work!
You haven’t broken the rules, but I think the problem most people have is with the principle of what you’ve done. While not technically disallowed, you’ve reserved a huge number of crate names which someone might want to use tomorrow for a crate they are actively developing when you might not develop them for months, years, or ever. If I were you, I would contact a Rust team member and ask them to remove these crates from your account. You can always re-register them later if you decide to develop them, but there’s no reason for you to have reserved these now.
I said this because \`tokio-async-await\` does not use the new task system. It sticks w/ the 0.1 task system. If the context argument from std (nightly) \`Future\` is used, it will panic. &amp;#x200B; \&gt; you won’t be able to use futures 0.1 combinators on the futures returned by async fn/blocks either. &amp;#x200B; I do not think this will be a common case.
I realize this does change the semantics of the code, if you have Drop implementations with observable ordering side-effects. However, I wonder if we could provide a way to easily opt into it, to eliminate runtime drop flags.
And soon, clippy-preview will be available on the stable channel! 🎉
Would be useful to document those problems in an issue, since I would consider this a Rust 2018 blocker.
Unless you cannot deliver the functionality / API / performance you want without nightly, go for stable. And I say this as one of the biggest nightly users ([clippy](https://github.com/rust-lang-nursery/rust-clippy) uses the lint API (but will be on stable soon!), [mutagen](https://github.com/llogiq/mutagen) and [overflower](https://github.com/llogiq/overflower) use proc macro attributes and specialization and [flamer](https://github.com/llogiq/flamer) uses proc macro attributes). Even if your code can benefit from nightly features, it's still probably a good idea to put that behind a cargo feature. E.g. servo's [smallvec](https://crates.io/crates/smallvec) crate has the `union` feature that allows a leaner memory footprint, and I recently submitted a PR with a `specialization` feature that will only work on nightly for now. Nightly users can benefit from those features, while stable users can have the stability they want. Lastly, you don't need nightly for benchmarks. You can either use [bencher](https://crates.io/crates/bencher) or [criterion](https://crates.io/crates/criterion) to benchmark on stable. The former is mostly straight port from nightly's bench feature with a few custom macros in place of the (rightly unstable) `#[bench]` annotation, while the latter offers a more refined API and greater statistical rigor at the cost of taking more time for benchmarks – time I consider well spent.
It's possible for associated types to be used in method signatures. I believe that's the reason you must specify the associated type when creating a Trait Object for a trait that has an associated type.
Ok, so it’s purely supporting the subset of the `std` futures API that async/await is using, it may or may not support custom `std::future::Future` impls depending on whether they use the same subset or not. I think it would be clearer to state that, and that as a consequence a lot of `futures 0.3` will not be supported either (really, it’s actually only a small subset that uses `task::Context` so the majority of the combinators will still work).
It cannot know because the type definition without the explicit `Bar` is ambiguous. Let's say you have both of these implementations available: ``` struct Bar; impl Foo for Baz { type Bar = String; } struct Quux; impl Foo for Quux { type Bar = u32; } ``` and you also have the following (non-compiling) struct definition: ``` struct Da { field: Foo, } ``` Notice the type specifier `Foo` above is just a bare trait (actually written `dyn Foo` in Rust 2018) and not a concrete type. You cannot leave the value of `Bar` out because it's literally part of the trait definition. You must specify which _kind_ of `Foo` you would like `field` to be for the code you wrote to make sense. If you want Rust to choose from one of the available implementations of `Foo` when struct `Da` is initialized, use generics instead: ``` struct Da&lt;T: Foo&gt; { field: T, } ``` The code above will do what you expect and tell Rust to choose from any available type `T` that implements `Foo` when the user instantiates `Da`.
Wow, no wonder it takes so much time these days
sparse is a simple compression format used for Android disk images. The AOSP contains tools, called `img2simg` and `simg2img`, for compression and decompression, but building them requires checking out and building huge amounts of code. To make this less of a hassle, I decided to rewrite those tools in Rust. Putting this out here in case anyone else also finds it useful. Also, this is the first Rust project I actually finished, so constructive criticism is welcome :) 
I guess the glance was too cursory. But it has to be 0.3 futures with a `Result` output, right?
It does not, the Tokio version of \`await!\` is equivalent to \`std\`'s except that it \*also\* adds the ability to await on 0.1 futures.
I assume you are using [tokio-async-await](https://crates.io/crates/tokio-async-await)? This only works with futures 0.1, not 0.3. Maybe that's your problem
This is written in Go though. In only contains a Rust client "sdk" to the server.
&gt; We may have to write a parallel dpkg &amp; apt replacement. Does this imply that a future Pop_OS will RIIR apt? I can get behind this :)
The whole premise of Rust safety is that you shouldn't be able to trigger UB from safe code, ever. Absolutely all instances of this happening are bugs. Not undocumented features, not tricky semantics. There is no wiggle room, they are bugs 100% of time. This is an improvement compared to C imo. ... but well the reality is that as of 2018 [the compiler itself has soundness holes](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22) each of which triggers UB from safe code. And we know that many dependencies out there contains bugs (be it C code called from Rust, or Rust code itself), some of which may trigger UB when called from safe code. Those bugs should be fixed. But more importantly, bugs aren't actually unavoidable, and memory safety bugs in special __must__ to be avoided. We have tools to formally verify software and with time those will only become easier to use. There's a project to provide an operational semantics of Rust that will enable us to say exactly what's UB and what's not, mathematically. Perhaps some day we will have a verified Rust compiler, like CompCert. So, &gt; to be sure, you can trigger UB from safe code, but that will always be true. I have high hopes that some day this won't be true. :(
Could someone ELI5 lifetimes to me? I'm slowly working my way through the rust book, and am halfway through the grep project. But I just cannot wrap my head around lifetimes, or why they are needed. If they're similar to another concept in c++ or python that anyone is aware of, it could be helpful to use that to explain how they work in rust.
Stuff like just quickly setting up a webserver to handle some requests, for instance. You'll want it to handle these asynchronously along with being able to asynchronously make HTTP calls to other services and maybe handle a database connection. In Go for instance, this is all ready to go -- your basic HTTP server is there, your basic HTTP client, sqlx, and the concurrency is built into the language, so you don't even have to think about it. In rust I had to do quite a bit of digging to do, I had to decide on one of the many HTTP frameworks which all seemed kinda incomplete and I really wasn't sure which of these was even used or tested by anybody. And then I didn't know how any of this would interact with database drivers or a HTTP client library -- would these all need to be written for the same async I/O framework? How would they play together? etc. Not that I like go much as a language, but I think the practicality definitely drives a lot of the success there. In any kind of microservice architecture you'll probably need a couple CRUD-style services that give you some sort of projection over a table in your database, and you'll probably want to deploy those in HA, and they need to accept HTTP requests and probably make HTTP requests, and with go and a couple others you can just get that out of the way in an hour or two. This was for my particular needs at any rate, I'm sure other people don't need exactly the same thing.
I believe the proper way to signal that the last member of the struct is dynamically sized is ``` #[repr(C)] struct VariableSize { data: OtherStruct, number_of_packets: u32, packets: [PacketStruct], } ``` Such a struct can't live on the stack, so it would need to be dynamically allocated somehow. If your C library hands you pointers to already-allocated instances of the type then you shouldn't have to worry about doing it yourself though.
Apologies for being thick today. Looking forward to giving it a whirl!
I’ve seen a few of your PSAs about nightly changes, and I’d just like to say I really appreciate them! Breakage is a part of working on nightly, but seeing a warning beforehand definitely reduces the amount of head-scratching when my builds break, so thanks u/japaric!
Do you want the more technical explanation about type inference, projection, and specialization? 
Stable. Nightly doesn't offer anything I need, and I personally dislike trying to ride the bleeding edge. Been cut too many times by software that did.
I would love to say yes, but I'm worried If I could understand it, but if it would help me to understand why I can't just expect rust to know what might go into a field/collection, then I'm all ears. So to answer your question yes please.
Yeah. For Rc and Arc, you would have to call make_mut first, and that wouldn't be zero-cost like the conversion for Box would be. I guess this conversion serves a different purpose from the one in the Own trait, and we would need both.
Not every company creates services that handle and dispatch events concurrently. Believe it or not there are other programs being written out there.
This is all great info, thanks!! PS as somebody who works on ASP.NET apps all day at work, you can get very, very far before async web frameworks become important :)
Yeah, that's true, but a lot of companies do end up needing them at some level at some point, at least. I'm having a hard time imagining a SaaS company that doesn't, for instance.
I had the same question initially, until I realized that it's really about trait-bounds, and have an analog in how Rust requires Trait-bounds to call methods on a generic parameter at all. Consider trait MyTrait { fn my_fun(&amp;self); } fn use_trait&lt;T: MyTrait&gt;(some_obj: &amp;T) { some_obj.my_fun(); } Now, in good old C++, for example, you could have left out `: MyTrait` and discovered during compilation whether a specific `T` has a `my_fun()` defined. (Otherwise, boom) In Rust (and modern C++ through *concepts*), however the design decision was to go for explicit. That is, if use\_trait actually want to do stuff to `T`, it must declare what things it want to be able to do. That is;` use_trai`t* only accepts types matching a given criteri*a. We're specific about the expectations of` `T. Now, back to associated types. trait MyTrait { type Target; fn my_fun(&amp;self) -&gt; Self::Target; } fn use_trait&lt;T: MyTrait&lt;Target=String&gt;&gt;(some_obj: &amp;T) -&gt; String { some_obj.my_fun(); // We can now _know_ that it will return a string, hence we can return it. } Here, the same theme recurs. In good old C++, well, it does not even translate very well. Rust, however opted for explicit rather than implicit, so we know that the only `T` acceptable for use\_trait is one that explicitly matches `Target=String`. Just like being explicit that T must be something that implements` MyTrai`t. If nothing else, it means the documentation for use\_trait will automatically show this constraint. It becomes a part of the specification of the function, rather than an accidental consequence of the implementation. I would also guess that compilation-times are somewhat helped by not needing to search potentially very big domains for a combinations of types that happen to match the current implementation. (Possibly by accident. See for example` boo`l in C++) Now, if you really don't care about which type `Target` is, Rust supports that too. fn use_trait&lt;Target, T: MyTrait&lt;Target=Target&gt;&gt;(some_obj: &amp;T) -&gt; Target { some_obj.my_fun(); // We can now _know_ that it will return a string, hence we can return it. } Here, I can only speculate on the design-rationale to require an extra generic-parameter instead of simpler syntax on the bound of `T` (for example simply allowing not specifying `T`). My guess would be that it was deemed common enough to need to use the `Target` type in more places. It has to go somewhere, in this example we also declare that `use_trait()` will return the `Target`\-type of `T`. OTOH, the only example I can come up with where I would not need `Target` for some other part of the declaration, is if `MyTrait` had a function that would give me an opaque `T`, which I was supposed to feed back into some other function of the same instance for `MyTrait`. But that sounds like a non-rustic design, and I cannot see any example of where I'd actually want that.
My "benchmark" was just the runtime of a plain call, making a single passphrase. Here's the breakdown: * read: 2.779751ms * lines/map/filter/collect: 32.963721ms * sort: 213.606234ms * dedup: 3.215102ms * generate: 36.905µs So, a better optimisation might be using a HashSet: * read: 2.840394ms * lines/map/filter/collect HashSet: 83.527551ms * collect Vec: 4.769669ms * generate: 23.497µs Or shaving off a few more milliseconds with fnv: * read: 2.887125ms * lines/map/filter/collect FnvHashSet: 76.476549ms * collect Vec: 4.566745ms * generate: 23.634µs Alternatively we could throw my 24 virtual cores at it with rayon: * read: 2.821539ms * par_lines/map/filter/collect: 14.804369ms * par_sort: 38.587079ms * dedup: 3.375263ms * generate: 31.665µs
Yes, I'm quite sure. ASP.NET is 20 years old at this point. It fully supports async programming of course, but it's up to you to use the async code instead of the synchronous code. Which is basically the case for the full .Net stack. Everything from http requests to db connections to file IO is sync by default with the ability for the developer to opt in to async functionality. With a 10+ year old code base, we have not done that lol. ADO.NET (the db layer) has built-in connection pooling but it doesn't have anything to do with async. Incoming requests are handled by a Windows kernel module (`http.sys` smdh) and I don't really know anything about that layer.
huh. Yeah, that's kinda one of the issues with opt-in async; if it's opt-in and just one part of the chain doesn't, that's a huge pain in the ass to re-ify. Like when e.g. your database driver only works sync and now you have to fork it off into a thread or whatever, which isn't necessarily a huge deal, but means you're back to using threading primitives and whatnot. Erlang and go really got this right, because everything is async by default (you don't even have to think about it) and opting out of async is not even really possible (I mean, you can just spawn one goroutine/erlang process I guess). Also your workload gets automatically distributed across as many cores as you have available, and basic useful primitives like message pools and fork-join style threadpools etc are there. Although go schedules cooperatively (as opposed to erlang which schedules preemptively) so you can still end up in a situation where all your scheduler queues are clogged up and become unresponsive (although your code would have to be kinda bad to end up in that situation)
Sorry, I completely missed the dynamic dispatch-involvement in the original question. (As a side-note, now I fully understand the rational for the `dyn` keyword). Furthermore, I did some tests, and discovered that for generic code with compile-time dispatch, Rust apparently DOES do inference of associated types. I suppose it may be useful if you only care for some of the associated types when the trait defines many. In your example, the reason why it won't let you get away without specifying associated types, is that the exact type cannot be known at compile time. You've requested run-time dispatch, but Rust has no RTTI, so full requirement on type needs to be given at compile-time.
&amp;#x200B; If interested i have opend an issue in tokio repo [https://github.com/tokio-rs/tokio/issues/584](https://github.com/tokio-rs/tokio/issues/584) can leave some suggestions.
But there is a constraint, the `Component`, I just don't get why I can't do: type ComponentCat&lt;'m, Comp&gt;= HashMap&lt;ID, Component&lt;'m, ValueType=Comp::ValueType&gt;&gt;; To say to the compiler, get it from component I'm passing in, It knows what to expect, And it knows where to get the information from to figure it out, or at least that what I expect of it. I thought the point of Generics was so that: "I can pass in `Struct S` so long as it implements `trait X`". It's kind of pointless becuase it's more like: "I can pass in `Struct S` so long as it implements `trait X`, but if `trait X` has associated `Field Y` then I can only pass in `Struct S` that implements `trait X` that can only have given`Type Z` for `Field Y` because the rustc compiler doesn't know to ask `Struct S` what type `field Y` is so It can build a list of possible types for `Field Y`". 
When using `Arc&lt;Mutex&lt;MyThing&gt;&gt;`, when does it sometimes end up as follows: 1. Get the Arc to variable `foo` 2. Call `clone()` on `foo` to get a reference to the Mutex 3. Lock the Mutex with `.lock()` 4. But oh no, suddenly the compiler craps out because `Arc` has no method `lock()`, even though I cloned the reference out of it? I could chain dozens of `clone()` calls in there but they all would just return the same `Arc`. Same with `Arc::clone(..)`. This gets even more fun when that Arc setup is wrapped inside an `Option&lt;..&gt;`.
It took around two weeks last year, and we have twice as many talks this year. So that sounds about right.
Do... you have a question here? Perhaps some code that doesn't compile? Yes, `lock` is a function on `Mutex`, not `Arc` (but when you have an `Arc` around something, you can call methods on the inner object due to `Deref` coercion). 
It is what you want on a conceptual level, but it also makes any pointers to the struct into fat pointers. And since this is something you're doing for FFI purposes that might not be what you want.
Hm, that's strange. Yea, "compiler artifacts" is rustc. Which exact command did you run? Do you have anything in `config.toml`? 
Working through feedback on the crypto rust backend for my encrypted chat demo. Got out first outside contributor! [https://github.com/ColbyCypherSociety/ChatDemo](https://github.com/ColbyCypherSociety/ChatDemo)
Yeah as good intended as it is it doesn't do the task of helping people map from one language to the other. It detracts from people familiar with the language but not the library, in that they can't tie to idiomatic things (because it follows foreign idioms). It doesn't help people familiar with the library because it just seems like what they did on their previous language with extra steps (instead of being able to see the advantages that the language has). Finally total newbies don't benefit from this, as they only gain cargo-cult that doesn't make sense and become frustrated dealing with this. And you still have to do the mapping from C/vulkan concepts to Rust/Vulkano concepts if you are trying to learn something from a C tutorial to implement it in rust. On the other hand I think that it's a great iteration, it's impossible to not grab needless things from previous languages/tutorials when building your own.
I'm not actually sure that Nemo157 is correct. Could you ping me in gitter directly? I would need more context.
You bet, I'll push a branch to the repo and update this post as well, thanks!
I don't know, the raw pointers and struct sizes look great: https://play.rust-lang.org/?gist=3ee82abbf004f0feeda6fb939e15c390&amp;version=stable&amp;mode=debug&amp;edition=2015 But, I'm learning that there's no way to allocate such a struct whose length is not known at compile time. Soo close! 
The strategy here is going to be to rewrite the loop to entirely be \`async\` / \`await\`. &amp;#x200B; The following should work (assuming you switch the \`resolve\` fn to async / await) &amp;#x200B; let framed = Framed::new(socket, Http); let (tx, rx) = framed.split(); &amp;#x200B; tokio::spawn\_async(async move { while let Some(request) = await!([rx.next](https://rx.next)()) { let res = await!(app.resolve(request)); await!(tx.send(res)); } }); &amp;#x200B; &amp;#x200B;
On the whole the code looks very reasonable. There's a couple places where you use a match on a Result or Option where a combinator might have saved you some typing, but that's really the only nit I have from skimming it.
On the downside, renaming things is a PITA and you had it first, dammit! On the upside, after reading that issue I now know about many famous writers from all over the world to check out...
Actually, I figured out what you were trying to do and I replied with the solution below. Hope that helps.
This is the solution I was looking for! Didn't even need to ping you on gitter :) Thanks a ton for the help, hopefully I'll have a nice looking release for thruster soon!
[removed]
So exciting! We've been working hard on this. :)
Generiiiiics woo! I hope they maintain binary compatibility with go 1, would SUCK to have go 2 / 1 be another python 3 / 2
They're marked `#[doc(hidden)]`, but they can be imported if compatibility isn't a concern (for hobby projects, etc.). I think the wrapper is something like `tokio::async_await::compact::backward::Compat::new(async_future)`?
Well, yeah, you're starting to brush up on the limitations of the current engine and why there is work to move to using the Chalk engine instead. Ideally, rustc will be able to do that type of reasoning for associated types. 
No, they really based it more on C++ Concepts.
Or Haskell typeclasses
Thanks for the help, but this is a very weird api design to me. Why isn't it possible to or_insert and then and_modify? I get it in terms of type signature, but I don't understand the api design decision. Because the basic implementation of and_modify and then or_insert causes a use-after-move, like https://play.rust-lang.org/?gist=20693088603aa299a6e474a333cddcae&amp;version=stable&amp;mode=debug&amp;edition=2015. If it were possible to do it in either order, I could or_insert an empty vec, and then do my standard and_modify. As is, it's still solvable by or_insert of an empty vec, and then passing the entry's value to a closure which does the modify, like https://play.rust-lang.org/?gist=63ae2d3bd1215ae3e2ef32e766a3de63&amp;version=stable&amp;mode=debug&amp;edition=2015 However, that's pretty hacky and unreadable in my opinion. Am I misunderstanding this, or is my case just really unusual?
[removed]
I'm happy to see a error handling proposal, and I will follow it with great interest. I find that handling errors is a really hard problem to get right: on the one hand, you don't want to skimp on that code, lest your application or library be brittle; on the other hand, you don't want to obscure the happy path of your code with pages of error checking. I think Rust — with the `?` operator — is on the right track, but there's room for improvement. Suppose we want to decode an object from a file on disk, we can use the `?` operator to make sure the happy path is as clear as can be: fn load1(filename: &amp;Path) -&gt; Result&lt;Point&gt; { let f = File::open(filename)?; let mut rdr = BufReader::new(f); let point = bincode::deserialize_from(&amp;mut rdr)?; return Ok(point); } If we only care about bailing out of the function, the `?` operator is great. However, it is of no help if we want to include log messages. fn load2(filename: &amp;Path) -&gt; Result&lt;Point&gt; { match File::open(filename) { Err(e) =&gt; { error!("could not open {}: {}", filename.display(), e); return Err(e.into()); } Ok(f) =&gt; { let mut rdr = BufReader::new(f); match bincode::deserialize_from(&amp;mut rdr) { Err(e) =&gt; { error!("could not decode {}: {}", filename.display(), e); return Err(e.into()); } Ok(obj) =&gt; { return Ok(obj); } } } } } What was 4 lines is now 18 lines, the logic of the function is now spread out in a sea of indentation and curly braces. We can reduce the mountain of code by using combinators. fn load3(filename: &amp;Path) -&gt; Result&lt;Point&gt; { File::open(filename) .map_err(|e| { error!("could not open {}: {}", filename.display(), e); e.into() }) .map(|f| BufReader::new(f)) .and_then(|mut rdr| { bincode::deserialize_from(&amp;mut rdr) .map_err(|e| { error!("could not decode {}: {}", filename.display(), e); e.into() }) }) } Though it's shorter and not as deeply indented as `load2`, it's not very pretty either. Neither of the solutions that provide more value to somebody running the program — the log messages — are as easy and as satisfying to write as the version using the `?` operator. If we could take the `?` operator and *somehow* (magic hand wave) add our logging code, that would be ideal. I've seen the Go 2 proposal for error handling only this afternoon, I'll need a bit of time to read it, think about it, and go and compare it with other languages (e.g., Zig). P.S.: While I was writing the code for this comment, I made an error in my initial version of the combinator code: fn load4(filename: &amp;Path) -&gt; Result&lt;Point&gt; { File::open(filename) .map_err(|e| { error!("could not open {}: {}", filename.display(), e); e.into() }) .map(|f| BufReader::new(f)) .and_then(|mut rdr| bincode::deserialize_from(&amp;mut rdr)) .map_err(|e| { error!("could not decode {}: {}", filename.display(), e); e.into() }) } If the file cannot be opened, we get *two* log messages: ERROR 2018-08-29T00:06:11Z: show: could not open /tmp/lol: No such file or directory (os error 2) ERROR 2018-08-29T00:06:11Z: show: could not decode /tmp/lol: io error: No such file or directory (os error 2) So in addition to being not super pretty, it's not hard to make a mistake.
not multicore, no real ecosystem, ugly syntax and not mostly imperative as far as i know
Seems a bit too OO for me at a glance, not sure i want to be involved with anything that invisible setter functions. I really just want go with tagged unions and maybe generics. 
Yes, this has always been possible. Look at the Tokio repo. Everything is *very* decoupled. Look how a runtime is implemented, it is just pulling the various components together. And yes, the `h2` library will work with anything that satisfy the `AsyncRead` / `AsyncWrite` traits... there just isn't anything else right now.
You can do this: ``` type ComponentCat&lt;'m, Comp&gt;= HashMap&lt;ID, Component&lt;'m, ValueType=&lt;Comp as Component&lt;'m&gt;&gt;::ValueType&gt;&gt;; ``` That's no better than `type ComponentCat&lt;Comp&gt; = HashMap&lt;ID, Comp&gt;;` though, and it won't solve your problem (which seems to be that rust doesn't have run time type information). Also note that you can't store trait objects directly in a HashMap, you'll need to box them: `type ComponentCat&lt;'m Comp&gt; = HashMap&lt;ID, Box&lt;Component&lt;...&gt;&gt;&gt;;` Further, your `Component::new` method is not object safe (see https://doc.rust-lang.org/book/second-edition/ch17-02-trait-objects.html#object-safety-is-required-for-trait-objects).
I think Rust would benefit from "diverging refutable patterns" or "if guard let". That would keep the happy path unnested while allowing arbitrary code in the error handling path, a "middle step" between ? and a full match. They were an RFC and it was postponed before but is doesn't seem farfetched to get accepted if someone would revive it and drive it home. (There were some remaining concerns with the surface syntax IIRC)
I see it's licensed MIT in the Cargo.tom file but can you commit a LICENSE file in the root? (Assuming you wish to license it under MIT).
We could add logging like this: ```rust let f = File::open(filename).map_res(|e| { error!("Could not open {}: {}", filename.display(), e); e })?; let mut rdr = BufReader::new(f); //... ``` This way we keep code similar to original one. Although, if there was non-modifying `Result::peek_err` function, code would be even simpler(not that it is hard to define it). Another aproach is to define an immediatly-called lambda, and peek into its error, but it might be harder to find error context. Although I am not sure if we should use this construct, but we could implement try/catch using macro that generates this construct + logging part.(if it is unclear what this paragraph is about, feel free to ask for examples)
Ok.
I want to make the spotlight equivalent for Windows... because the integrated search functionality is really, really sub-par.
While I completely understand the perspective and all the trouble that we got from Python 2/3; did we learn nothing from C++? I guess there's really no winning with this problem. Maybe big-bang language updates are the real issue. For example Rust and Ruby have introduced (and deprecated!) language features incrementally.
&gt; Use a logging implementation that locks the output stream Which Rust logging crates lock the output stream?
Awesome, I love Selenium.
Wouldn't it benefit if we could do, if everything is an expression ``` fn load1(filename: &amp;Path) -&gt; Result&lt;Point&gt; { let rs = { let f = File::open(filename)?; let mut rdr = BufReader::new(f); let point = bincode::deserialize_from(&amp;mut rdr)?; return Ok(point); }; match rs { Err(e) =&gt; { error!("bleh"); return Err(e.into()); } Ok(obj) =&gt; { return Ok(obj); } } } ```
**binary** compatibility, not source code itself. 
the restrictions make me wary, and the efficiency statement says that performance will be on par with dynamically checked interfaces which seems at least to me imply this is just sugar around a package private interface 
Thanks, that did the trick. &amp;#x200B; So when dealing with the heap and I need to increment something, I need to use usize?
Your formatting is broken; reddit does not support the triple backticks for code blocks, indent by 4 spaces instead
As I understand, it's the goal of the the `try` keyword RFC. Still, there is an issue in your code: your logging statement can't tell whether the error came from `File::open` or `bincode::deserialize_from`.
&gt; they're automatically mounted at the root, you don't need to re-export them. Does this mean we can't force importing them from a module and not at the root? And that macros declared with the same name in different modules are not possible?
I want to support IE in my Yew app, too.. How much slower would a Yew app be in ASM.js? When compiling a Yew app to wasm and then to ASM.js, is there a way to optimize away the stdweb DOM-access FFI?
I often use something like `let x = if let ...`, but I do find it a bit awkward.
You would be forced to indicate lifetimes when the compiler can't infer them for you. For example, if you had a function `fn a(&amp;self) -&gt; &amp;B`, `&amp;self` would be inferred to `&amp;'a self` and `&amp;B` would be inferred to `&amp;'b B`. In types, you can't infer the lifetimes. If I had a `string_refs: &amp;Vec&lt;String&gt;`, that would be invalid because there is no lifetime. If there's just one lifetime, it's inferred to live as long as the type itself.
Congratulations! Sounds like you already have some of the criteria for graduation into and out of incubation as well.
&gt; When an error check fails, it transfers control to the innermost handler, which transfers control to the next handler above it, and so on, until a handler executes a return statement. That seems surprisingly tricky. If I have two error handling blocks in a function, but the second one does a return, then code in the first won't be executed? But defer statements made near the same point *would* be executed, if I'm understanding right.
Any time you're accessing memory it will need to be an a usize. Stack, heap, buffer lengths, any of it.
Maybe the word "Modern" is misleading, because someone would think I am introducing a fancy new tool. As far as I am concerned, we say C++ developing is modern, though it is an old language. So, sure, gbd is very old, but it is still a popular and powerful tool in this decade. In face, I just want to tell some new contributors that they could use gdb if they need. As I said in the article, there are still lots of people never use gdb before.
Yup, like editions in Rust.
I definitely want to work on my combinator foo, thanks for reminding me!
I like to think of traits as contracts rather than actual objects and so they don't have any data themselves. Serializing a contract doesn't make much sense, you want to serialize the data itself. For some reason what you're describing is reminding me of an entity component system like specs-rs. There are also a few neural net libraries floating around that might point you in the right direction.
So we no longer will be able to troll Gophers that they have no generics? Welp...
C++ is adding basically the same thing under the name "Concepts." It's had related mechanisms for a while and is mostly codifying them and making them nicer to use.
`?` is not mutually exclusive with combinators: ```rust fn load5(filename: &amp;Path) -&gt; Result&lt;Point, Error&gt; { let f = File::open(filename).map_err(|e| error!("could not open {}: {}", filename.display(), e))?; let mut rdr = BufReader::new(f); bincode::deserialize_from(&amp;mut rdr) .map_err(|e| error!("could not decode {}: {}", filename.display(), e)) } ```
Why not implement a trait for Result that calls a function if Err(ref e), then returns self so that the function could be written like this? fn load(filename: &amp;Path) -&gt; Result&lt;Point&gt; { let f = File::open(filename) .peek_err(|e| error!("could not open {}: {}", filename.display(), e))?; let mut rdr = BufReader::new(f); let point = bincode::deserialize_from(&amp;mut rdr) .peek_err(|e| error!("could not decode {}: {}", filename.display(), e))?; return Ok(point); } 
Btw, I already changed all the code to avoid unnecessary Option&lt;T&gt;'s.
OP, are you the author? This looks very interesting (if I can wrap my head around it). &amp;#x200B; Am I correct in understanding that this project introduces both a new model of computation and a new programming language based on it? 
Yeah is shaping up nicely. I plan on messing around with it later this week!
Is that binary compatibly though?
This works well until you try to use it with imperative control flow constructs such as `return`, `break` and `continue` as well as loops; once you do start to use those mechanisms, a macro is a better solution because a lambda changes the location to which those control flow constructs return to.
The biggest issue with Python 2 and 3 was that Python 2 mixes strings and bytes together and also does implicit conversion between those types (soft typing). This is especially painful because Python is a dynamic language. All other changes are mechanic. This issue would be nearly unnoticeable in Go or Rust, because of a type system. The program would refuse to compile until you would fix all errors, it would point every line with issue so fixing it would be trivial. The Unicode issue on Python is also, because Python 3 became stricter and the issues are actual bugs. So with Go or Rust you would just think that the compiler for those languages just became better at finding errors.
Someone pointed out that they said that performance will be on part with dynamically checked interface, that implies that the genetics might end up just being a syntactic sugar.
Why doesn't == move? I don't understand why I don't have to write &amp;v == &amp;w whenever I compare two vecs. Which other places have this magic property, and can I make my own?
`generational-arena` links to the wrong crate.
stdweb already compiltes to ASM.js (see https://github.com/koute/stdweb#running-the-examples). I don't know how Yew would work if you compile the WASM file to ASM.js. That's a good question! I haven't enough knowledge about Yew internals.
what is binary compatibility here? Go is all about single static binaries, not distributing dynamic or static libraries.
it got a package manager with 1.11 just a few days ago, and the drafts propose better error handling at the same time they propose generics. Go supports immutability, and I'm not sure what you mean by scopes... variables are lexically scoped just like Rust.
Nightly, but when possible, try to make nightly opt-in behind an `unstable` cargo feature so that the library also works on stable. I then target a particular stable version on CI, and have all other build bots use nightly to test most of the library. I consider upgrading the stable Rust version a major breaking change.
One should also use `cargo outdated` on CI and `dependabot` to make sure your library always uses the latests dependencies. I hate it when many different versions of serde get pulled in for my binaries because some crates don't seem to check this often.
You can build an extension trait with a `tap_err` method for Result and then do this: fn load1(filename: &amp;Path) -&gt; Result&lt;Point&gt; { let f = File::open(filename) .tap_err(|e| error!("could not open {}: {}", filename.display(), e))?; let mut rdr = BufReader::new(f); let point = bincode::deserialize_from(&amp;mut rdr) .tap_err(|e| error!("could not decode {}: {}", filename.display(), e))?; return Ok(point); }
&gt;it got a package manager with 1.11 Still experimental. &gt;better error handling It's questionable. Not better. &gt;Go supports immutability Really? Can I mark variable as `const`? &gt;variables are lexically scoped just like Rus But `defer`has a whole function scope.
Yup, length, indices, etc. are typically always `usize`.
&gt; This works well until you try to use it with imperative control flow constructs such as return, break and continue as well as loops; once you do start to use those mechanisms, a macro is a better solution because a lambda changes the location to which those control flow constructs return to. Why would your error logging require to influence the control flow?
Public service announcement 
It's not the logging itself that would need to influence the control flow; but perhaps you want to do logging *and* `continue;` with `.ok_or!(_ =&gt; continue);`. Here, the logging is not the essential logic, the `continue` is, but the logging is nevertheless included to make debugging easier. We use this construct in `rfcbot` for example.
They want fast compile speeds, later they can make it compile time, but a lot of users probably don't want to make that trade off right now.
I agree, but the parent post wanted binary compatibility (not sure why)
Your inner loop reads byte-by-byte: ``` for b in buffer.iter() { if b == &amp;nul { ``` What if you instead do some binary arithmetic to [operate on larger sizes using bit arithmetic](https://play.rust-lang.org/?gist=d4629347ad8b39540ed29cce538ab6f6&amp;version=stable&amp;mode=debug&amp;edition=2015)? I don't know, but seems worth a try. 
If the buffer gets re-used, it doesn't matter much that it may be larger than necessary.
I put box in a cell: let notify: RefCell&lt;Box&lt;dyn FnMut()&gt;&gt; = RefCell::new(Box::new(|| {})); next I borrowed it: let mut ref_mut = notify.borrow_mut(); now for some reason I cannot call it, `ref_mut()` gives an error: error[E0596]: cannot borrow immutable `Box` content as mutable --&gt; src/main.rs:6:5 | 6 | ref_mut(); | ^^^^^^^ cannot borrow as mutable As a workaround I can call it as `(&amp;mut *ref_mut)()` but why is this `&amp;mut *` required? 
I think the Chalk Integration would solve my problem as it looks like is one of the things it talks about is literally what I'm trying to do. Do you know when this would happen?
`map_res`? Did you mean `map_err`?
&gt; extern crate failure; // For throw!(..) Where did you get it from? There is no `throw!()` in failure: https://docs.rs/failure/0.1.2/failure/#macros
There is a theoretical option to statically link LLVM libraries into the compiler, but I haven't yet succeeded experimenting with it.
With rust as a compile target, you restrict your language to the semantics / a subset of Rust. Maybe have a look at [cranelift](https://crates.io/crates/cranelift), which is a code generation backend intended to be used in firefox as a wasm backend and in rustc as codegen for debug mode.
I mentioned Cranelift in my post and I am aware of it. Right now, for me there is no particular reason to use Cranelift instead of LLVM, as LLVM provides more optimizations and more targets. Also, is there a problem in limiting yourself to a subset of Rust? As long as limit yourself to a subset of a tiring complete language, then you should be ok. Theoretically, you can even use brainfuck as compile target!
&gt; Stuff like just quickly setting up a webserver to handle some requests, for instance. You'll want it to handle these asynchronously along with being able to asynchronously make HTTP calls to other services and maybe handle a database connection. In Go for instance, this is all ready to go -- your basic HTTP server is there, your basic HTTP client, sqlx, and the concurrency is built into the language, so you don't even have to think about it. In rust I had to do quite a bit of digging to do, I had to decide on one of the many HTTP frameworks which all seemed kinda incomplete and I really wasn't sure which of these was even used or tested by anybody. And then I didn't know how any of this would interact with database drivers or a HTTP client library -- would these all need to be written for the same async I/O framework? How would they play together? etc. Well, it's kinda good at rust as well now. The only difference is that you know you could use `sqlx` in go, but you don't know analogues in Rust. Well, I can name at least `actix-web+diesel+r2d2`. It's enough to build a web server, actor model is quite understable and scallable, and it work really fine. When I work with rust I see two main pain points: async code and no_std which breaks every second week. But default flow "build webserver on anything and use react/angular/vue as frontend" is fully working in Rust.
Certainly. Thanks. My brain just somehow substituted those two :)
Sorry, badly formatted question, yes. So when I clone an `Arc` it is meant to return a new `Arc` instead of dereferencing during clone? I misunderstood the module documentation then, I assumed that when I clone `Arc&lt;Mutex&lt;MyThing&gt;&gt;` it would return a pointer to `Mutex&lt;MyThing&gt;` as described: &gt; Invoking `clone` on Arc produces a new pointer to the same value in the heap. (Arc documentation)[https://doc.rust-lang.org/std/sync/struct.Arc.html] Maybe the "same value" in that sentence could be reworded as "same Arc value" or something. Will need to keep this in mind, and thanks for pointing out `Deref` coercion, that makes it clearer now! :) 
IIRC Scheme is pretty differtent from CL and keeps changing.
With `macro_rules!` macros, yes to both, because they don't really participate in the module system properly within a crate. I believe `decl_macros` don't have this limitation (but haven't checked). The crate boundary gives a point at which the compiler can hide the legacy weirdness away and start treating macros the same as normal items for importing. There is a hacky solution if you _really_ want to present a nice module structure including macros, you can create a sub-crate that defines all your macros, then re-export them via `pub use subcrate::macro_name;` at the correct point in your main crate's module hierarchy. You'll probably run into issues if you're using `$crate::` stuff though as that will likely need circular references between the macro defining and runtime defining crates.
Being said, you are not only working over Linux with epoll. For example, Tokio runs over windows IOCP as well. You *have* to have *some* abstraction if you don't have to disriminate users of others platforms.
&gt; I ust wanted a fast non blocking epoll loop, I basically needed to write it myself. What if you don't have epoll in your system?
That's something I've been wishing from a Rust-like scripting language. Keep the rich Rust types, borrow checker (and accompanying thread safety and lack of GC), and ecosystem, but remove the layer of distinction between static and dynamic dispatch, which would *drastically* simplify the language API as used by a script writer. Essentially, assume every dispatch is dynamic dispatch. Copy values passed by value, everything else passed by ref, hide away refs/derefs, auto-box and auto-unbox like Java or C# does. Behind the scenes, the compiler would be free to make optimizations to switch to static dispatch when it's safe to do so, but don't make the user deal with it. So much stuff just goes behind the scenes, static Trait vs dyn Trait being one small example. That, and make it be able to transpile (or at least invoke) normal Rust functions (source compat) or libraries (binary compat) behind the scenes. Then RustScript could be used for more lightweight scripting where performance is less critical, and any heavy part can easily be extracted to a normal rust piece of code and invoked. Do that, and more implicit type casting, and RustScript is ready to go. It would still be fast (thanks to most cases being optimizable by the compiler to static dispatch behind the scenes), but a lot simpler, less verbose, and lower barrier of entry. Even rust compiler uses Python internally for some administrative scripting tasks, and that's the kind of problem RustScript could solve.
&gt; The runtime was for generating a single password, so it was almost certainly dominated by reading all the lines in the dictionary, filtering, stripping and deduplicating. Fair enough, I was assuming you benchmarked generating lots of passwords at once. &gt; Nope, I'd actively want to avoid doing that. Use urandom, use urandom, use urandom, oh wait why isn't Ruby using urandom. This is outdated, on Linux you should prefer `getrandom`. In any case, it is extremely common to initialize userspace CSPRNG, this is basically how stream ciphers work. The documentation of `getrandom` explicitly states: &gt; These bytes can be used to seed userspace random number generators or for cryptographic purposes. 
I cannot really read your data structure example code, but as a one of the maintainers of [specs](github.com/slide-rs/specs) I can give insight how we do this. The simplified version is that we have `HashMap&lt;Id, Box&lt;Storage&gt;&gt;` where `Storage` is trait that provides everything that we need. We are actually using `Any` and `mopa` crate to do some reflection to make it more flexible, but the basic ideas is there and I think you can get away with just trait objects.
The lack of generics and verbose error handing are my two biggest issues with Go, nice to see they agree! Looking forward to see how this plays out.
Your second solution is in principle what I would do: ignore \`and\_modify\`, and do \`or\_insert\` followed by a push. However, you've added a bunch of completely unnecessary clutter to your design. I'd do something like this: [https://play.rust-lang.org/?gist=28171dffef8f74240057b2a40b06b3a4&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=28171dffef8f74240057b2a40b06b3a4&amp;version=stable&amp;mode=debug&amp;edition=2015)
I think the cleanest answer to your problem is to use `map_err` in conjunction with `?`. E.g. (using a slightly different example that will compile on the playground) fn load1(filename: &amp;Path) -&gt; Result&lt;String, ErrorMsg&gt; { let mut file = File::open(filename) .map_err(|e| format!("Failed to open file {:?}: {}", filename, e) )?; let mut contents = String::new(); file.read_to_string(&amp;mut contents) .map_err(|e| format! ("Failed to read contents for file {:?}: {}", filename, e))?; return Ok(contents); } This is about the same level of noise as most other methods
I think there's something wrong with "Updates from Rust Core" section: The "merged in the last week" links to `https://github.com/search?q=is%3Apr+org%3Arust-lang+is%3Amerged+merged%3A2018-08-13..2018-08-20` and there are some duplicates from previous week (like `Self` in type definitions or `TokenStream::extend` speedups)
Hi, could you help me resolve a compilation issue? What am I missing here: #[cfg(feature = "fail")] pub extern crate failure; #[cfg(feature = "fail")] #[macro_use] pub extern crate failure_derive; #[cfg(feature = "fail")] pub use failure_derive::*; #[derive(Debug)] #[cfg_attr(feature = "fail", derive(Fail)] pub enum SomeErr { #[cfg_attr(feature = "fail", fail(display = "disaster")] Disaster } $ cargo build --features fail error: argument never used --&gt; src/lib.rs:32:37 | 32 | #[cfg_attr(feature = "fail", derive(Fail)] | ^^^^ 
It may be confusing, but clone() will always produce a value of type Self, so calling clone() on an Arc has to produce another Arc. 
&gt; No issues were submitted to CfP this week May I ask to include https://github.com/PistonDevelopers/image-png/issues/80 in the next one? It's been featured once already, but it still needs love.
I can see how being a hater can be tough
Of course variables can be const...
/u/ralphlinius good luck and keep us posted!
* /u/raphlinus
&gt; In any case, it is extremely common to initialize userspace CSPRNG, this is basically how stream ciphers work Yes, and ARC4 is a stream cipher from the late 1980's. It's a pretty wonky choice the result from a bug report that asked SecureRandom to avoid defaulting to OpenSSL's userspace CSPRNG, which it did: on Linux (via getrandom()) and Windows (via CryptGenRandom).
Instead of targeting Rust itself, or using a compiler backend's intermediate language like cranelift's IR or LLVM's IR, or any other sensible approaches, you could also target [MIR](http://rust-lang.github.io/rfcs/1211-mir.html), an internal representation rustc uses. It's probably easy enough to generate, but right now it's not guaranteed to be stable in any sense. If you'd like to have borrow checking, targeting MIR allows you, in theory, to run that part of rustc. Also, there is Miri, an interpreter for MIR that with a bit of love might work for you. I'm pretty sure there was a WIP repo of someone trying to compiler MIR to WASM, too (but you can use rustc for that, too). If you have too much time on your hands, this might be the *perfect* option for you!
Switched and it worked flawlessly! Shame RLS isn't available with this nightly, does anyone know if I can install RLS component from a previous nightly and use that?
Thanks for your response! Yeah, I am familiar with MIR. However, I haven't planned any type of borrow checking in my language and therefore won't benefit from it. Also, I think it might be quite hard to emit a valid MIR considering how low-level it is. 
Yeah, the documentation was confusing me there, making me think that clone with Arcs do a deref into the Arc contents instead of cloning a reference. :)
So if I make my own type, == will autoborrow, and + won't (and I can't change either of those things). Is that right?
Yes. I believe so.
You can manually opt in to it by writing the `else { drop(...) }`s yourself, since the compiler should only emit them when necessary. There could probably even be a lint for it. That said, I'm not entirely sure of the value of eliminating the drop flags now that they're just stack booleans: the consume minimal memory and are "optimal" in terms of obviousness to an optimizer.
Go only has the equivalent of Rust's const. There is no equivalent of Rust's 'let' only 'let mut'. It's one of the things that always bugged me about Go, even C has it.
Prior art in Elixir, the "with" macro, snippet from some code I worked on: with {:ok, activities} &lt;- ActivityIndexService.load(source_id, params) do conn |&gt; render(data: activities) else {:error, :source, error} -&gt; # handle invalid source {:error, :params, error} -&gt; # handle invalid params end You can combine error handling with pattern matching, 
Am I the only one that writes code like this, using the `failure` crate? let file = File::create("myfile") .context("failed to create file")?; It's pretty perfect as far as what Go is concerned with. Unfortunately they can't really go this route because they lack other things like RAII, generics (for now), traits, type inference, etc.
&gt; Even rust compiler uses Python internally for some administrative scripting tasks, and that's the kind of problem RustScript could solve. As I understand it, the reason for using Python there is so that you can compile the Rust compiler without having Rust already installed on your machine. Python is universally available on *nix and easy to install on Windows so it's a good choice. 
Fixed, thanks!
I've added it to this week's issue and will also add to the next one.
&gt; music synthesis game What does "music synthesis" mean?
I ask a similar thing in [https://www.reddit.com/r/rust/comments/94c4m9/is\_possible\_to\_ship\_rust\_compiler\_like\_a\_stand-alone\_exe\_or\_lib\_to\_transpil/e3kmfxo/?context=3](https://www.reddit.com/r/rust/comments/94c4m9/is_possible_to_ship_rust_compiler_like_a_stand-alone_exe_or_lib_to_transpil/e3kmfxo/?context=3) \--- I think you must decide between have it easy or have it fast (LLVM or C). After use Rust more, their semantics will be very hard to fight as a target, a compiler target need to be more flexible to allow for you own semantics. &amp;#x200B; Exist many other possible target, not only .NET, Java but also Lua, Pascal, Nim, etc. 
Now the race is open: who will get const generics first, Rust or Go :).
&gt; At first glance, they allow multiple authors to claim names like http, but that simply means that people will need to refer to those packages as wycats' http or reem's http, offering little benefit over package names like wycats-http or reem-http. I disagree. Prefixes differ from namespaces in the important respect that I can *own* a namespace, but I can't own a prefix. 
I think they're talking about internal data structures being represented the same. Like how we have flags to tell the compiler we want stuff to be represented the way C does for interoperability. If the compiler works for v1 and v2 of Go, but the layout of the data is different, it could cause issues with existing v1 binaries that haven't been compiled with v2.
You're looking for /r/playrust. This sub is about the programming language.
`arc4random` doesn't use ARC4 anymore though, the name is misleading. On OpenBSD it uses ChaCha20. I don't see what is wrong about it. This is how the OS should provide randomness: With a CSPRNG seeded with 256 bits of hardware noise.
Yes, the name is misleading. OpenBSD really should have picked something else. https://github.com/freebsd/freebsd/blob/release/11.2.0/lib/libc/gen/arc4random.c Latest release of FreeBSD, ARC4 with wonky fork detection that shrugs at the thought of pid wraparound.
I'm trying to figure out what is an idiomatic way to avoid using some unwraps. Are unwraps bad? I'd prefer to use "?", but maybe that is too complicated. I'd appreciate a general code review on this small file if you have any ideas. Thanks! [https://github.com/richardanaya/aws-lambda-api-rust/blob/master/src/lambdas/rust-api/src/main.rs](https://github.com/richardanaya/aws-lambda-api-rust/blob/master/src/lambdas/rust-api/src/main.rs)
&gt; Latest release of FreeBSD, ARC4 with wonky fork detection that shrugs at the thought of pid wraparound. :( They should just take the OpenBSD implementation at this point.
Perhaps there's some way to make a hook in the `failure` crate or such to implement something like this? It does look like it would be nice.
They have for FreeBSD 12. Hopefully DragonFlyBSD follows suit. NetBSD's used ChaCha20 since version 6, but even that only went EoL recently, so wonky versions are sure to still be in circulation. I dread to think what the #ifdefs to use arc4random() safely are going to end up looking like :/
You might want to have a look at [Dyon](https://github.com/PistonDevelopers/dyon).
&gt; Your formatting is broken; reddit does not support the triple backticks for code blocks, indent by 4 spaces instead I think triple backticks work, at least with new-style reddit.
Have it easy is not an option, if you plan your language to gain any kind of value :) What do you think about using LLVM libraries?
I could have sworn there was one before; Anyways, you can make one if you need one: macro_rules! throw { ($why: expr) =&gt; { Err::&lt;!, _&gt;($why)? } } 
Perhaps something along the lines of [Electroplankton](https://www.youtube.com/watch?v=ttFoK8BTXM4)?
Thanks!
But you still get compile-time type-safety, right?
That sounds like a fully general-purpose solution to a broad category of problems, which would be great for minimizing the amount of library code added, but at the cost of adding complexity (and some boilerplate to configure the solution at each call-site). Now the reader has to learn how `ok_or!` works, and constantly watch out for missed `throw!`s to understand what the control flow is doing.
Working on a simple chip8 emulator https://gitlab.com/NateDogg1232/chip8-rs
So that's one of the main questions I'm wrestling with. The sound engine absolutely will be. I'm quite excited in fact about the potential for Rust in audio, because of the combination of high-level expressiveness, performance, and safety. For the game logic and UI, though, I'm facing a choice between prototyping using Web tech (running the audio engine through wasm) and doing it as a native application, written in Rust. The former is definitely easier and I can get to a prototype more quickly. Doing it all in Rust will take longer but the improved performance might be worth it. If I do that, it will be Windows-first. What would push this decision over the edge is help porting the UI to other platforms.
What about a Lisp for the higher-level stuff?
Well sure; but you will have to learn the library functions of the crate regardless to understand the semantics; However I agree that macros can be too strong a solution sometimes. Generally speaking, I think we don't need to use a one-size-fits-all approach; sometimes a macro works well, sometimes something else works better.
No, it was meant to be vague :) Sorry. I'll have much more to say before too long.
It's *almost* possible to build rustc like that. By changing as many of the `crate-type = ["dylib"]` instances to `crate-type = ["rlib"]` as I could in the TOMLs, I was able to get it down to only librustc, libprocmacros, and librustc-codegen-llvm being dynamic. At that point the three issues were that there is no actual code in the compiler codebase to support statically-linked codegen backends, that dynamic librustc-codegen-llvm had too many export ordinals when pulling in static librustc, and that libprocmacros had this weird thread panic error when used statically.
Thank you! And I have a good news: I followed your good advice and dual-licensed LibreAuth under CeCILL-C or CeCILL 2.1. This change has been made through [this commit](https://github.com/breard-r/libreauth/commit/696281c5d1e4683ae4944e313886927ecb10f5b4) and I will soon release a version on crates.io with this new licensing. This way, the community will be able to use the library from projects under any license.
&gt; This works well until you try to use it with imperative control flow constructs such as &gt; `return` &gt; , &gt; `break` &gt; and &gt; `continue` &gt; as well as loops; Actually, I would see this as a selling point. Now, the trivial stuff is a one-liner, while any change to control flow requires a more verbose version calling attention to the peculiar situation. 
**Rule 2: Keep comments constructive.**
Seems like something of very limited use. Callbacks and rust go together like water and oil.
They're type parameters, they allow structs to be 'generic' In C, we might make a struct like this struct Vector3f { float x; float y; float z; } This is meant to represent a 3 dimensional vector. It uses floats - but what if we want a vector composed of `double`s? Then we'd have to declare ANOTHER struct like so: struct Vector3d { double x; double y; double z; } With generics, we can add it as a type parameter instead. So, in rust, the struct might be more like `Vector3&lt;f32&gt;` and `Vector3&lt;f64&gt;`. This is also true for `Vec`, the little `&lt;T&gt;` part of the declaration is the type parameter, and we call `Vec&lt;T&gt;` a generic struct
You should do whatever you are most comfortable with :)
I would say it's a nominal vs structural difference. In C++ concept, you declare that *somehow* there's a `.quack()` method on the type, without specifying its provenance: maybe it's inherent, maybe it's inherited from some interface/class. Therefore, in a sense, concepts are still very much about *duck-typing*; you happened to find a type that can `quack`, you conclude it must be a duck... even though it could be a doc^1 . On the other hand, Rust is nominal. When specifying the bounds a type must have to implement `Conceptually`, you *name* them. If the type accidentally has the same method from another trait, or as an inherent impl, it still doesn't match. Thus, ducks and docs are properly identified, and you don't accidentally get a Peking Doc^2 on the table. ^1 *Quack doctors, [that is, fake doctors](https://en.wikipedia.org/wiki/Quackery).* ^2 *Peking Duck, it's a famous Chinese dish.*
Yes, in the sense the Lambda Calculus is also a model of computation and a programming language. It is not a practical language though, one should add a few things such as native integers and IO to achieve that.
**Rule 2: Keep comments constructive.**
MIR is more general than Rust. If MIR isn't a good match for your language's semantics, how could Rust be?
I agree with you, it will just require a little bit of time to understand a fairly undocumented format, as well as find the required internal rust libraries to deal with it. But I can assume that adding borrow semantics to the language can be fairly beneficial, if I ever decide to target MIR. What are your thoughts?
I would imagine having to go through rust will absolutely destroy your compile times. I would go for LLVM IR instead. 
You may be right, I haven't thought about this. However, people are pointing out a possible use for MIR.
Oh wow. I can't believe I take that for granted in Rust...
Yeah, const generics will let us do even cooler things, like pass in a number as a type param too - this means we can have a struct that's something like `Vector&lt;3, f32&gt;` for a 3 dimensional vector made of f32s - the d r e a m (although obviously this example is mad impractical)
LLVM is a heavy dependency. And probably easier to deal with a language like C/Pascal and let their compilers to do the heavy lift. "easy is an option" if you wanna ship someday. If you have your own IR you can later transpile to any other target or upgrade to LLVM. &amp;#x200B;
&gt; Pure rust. GTK+ is a pain to setup and distribute. Having a simple clone repository of app, cargo build --release, copy binary from target/release would be awesome. This is the biggest issue for me with so much rust software.... Cargo doesn't make it easy to specify or enumerate non-rust dependencies and a lot of people just assume that random software or libraries are installed when setting up their crates.
I think you may actually be right :D And yes, I have a plan to introduce my own form of low-level MIR for analysis and as an IR for backends. Also, the initial idea was actually to allow pluggable backends. This way you can always start with implementing a simple JS backend and, while working on more performent LLVM one. For a backend you only have to implement an emitter and basic API implementations, such as FS, etc.
As I write on [https://talk.remobjects.com/t/potential-way-to-do-almost-cross-platforms-guis/15647](https://talk.remobjects.com/t/potential-way-to-do-almost-cross-platforms-guis/15647) I think is possible and much better to just "left-out" the UI and focus on a truly, almost, cross-platform toolkit: \----- Is well know the problem of try to do a cross-platform GUIs. But in the other end, the necessity to do that have increased with the arrival of mobile and the emergence of OSX as a viable target for commercial apps. Is kind of ironic that is easier to port a full 3d-game but a “simple” business app is a huge undertaking :). The key, IMHO, is decouple some tasks (kind of separate “back-end” UI from “front-end” UI). We can do “partial/almost” cross-platform UI, if we think that some stuff can *actually cross cleanly:* * **Layout** (the big one, IMHO) with something like [https://yogalayout.com 18](https://yogalayout.com/). This one was my main block before. * A *well defined way* to separate the back from the front UIs. The *ELM architecture* is a good contender ([https://www.elm-tutorial.org/en/02-elm-arch/01-introduction.html 5](https://www.elm-tutorial.org/en/02-elm-arch/01-introduction.html)) (called Update-Model-View, similar to react + redux but simpler and easier to call servers/async) * Units calculation, like fonts, pixels and stuff like that. * This is like have "CSS" but just logic. A big chunk of the logic is totally cross-platform and “only” need to adapt the render of controls. This way of working allow to work with pure objects for the *model* and the *view* without actually commit to *exactly* what is the view UI. Instead, is delegated to the “update” side. It can totally be just in-memory, testeable object. * Dispatching, events and similar stuff, that is not visual. This need a bridge but I don’t think will be complicated. Then finally, the rest can be fully native: * Controls * Drawing * Animations * Call to native libs How this could look? Is exactly a compiler/interpreter that you send: &amp;#x200B; Window View Label(text="hello world") And the library deal with it. Separatelly, exist renderes per toolkit (Coccoa, HTML, Win32, etc) that get the tree and build the controls. Some "controls" can be symbolic (like "Button") to get easy cross-platform. This mean that we build components instead of a class hierarchy and is possible to swap what is a “control”, like, from HTML to iOS Views without moving the rest of the logic. So, you send (this is a DSL or by code, maybe later a html-ish version but honestly I think code is far more flexible and easy): Form Field(Label="UserName", Edit(PlaceHolder="Write your user") and each target decide which actual controls to use. However, target real native controls is something that is truly necessary, so is possible to be specific: Form when(toolkit=UIKit) Field(UILabel="UserName", UiTextBox(PlaceHolder="Write your user") This mean is necessary to have a basic "renderer" that anyone could extend. The basic one just give a tree and make things 100% testeable. Then you do: UIKitRender = Render when Button giveInstead UIButton... and this mean that anyone could extend. So, if I wanna to turn all my UIButtons into a UIFlatButtons I just extend from UIKitRender and swap. All my code get the same and still got my upgraded UI. &amp;#x200B; So, this look like ReactNative/Elm but not JS, and most of the logic is in the back-end. Wish to have a coding partner to do this 📷
Might just be my lack of experience in using it, but yoga seems super complicated. When I tried UWP, I really liked the StackPanel+Grid combo, where those are components, and widgets are added as children to them: https://docs.microsoft.com/en-us/windows/uwp/design/layout/grid-tutorial In response to your main idea, I simply think that's a bad idea. I really DON'T want a super flexible mobile supported framework. I just wanted a bunch of widgets I can make a cross-platform desktop app with, done in native rust. It doesn't have to look native, it just has to look modern (unlike gtk's default theme). Especially considering how piston ended up, trying to add too much flexibility seems a really bad idea to me.
&gt;Make your block a closure and I think that'll work the way you want. &gt; &gt;\`\`\` let rs = || { let f = File::open(filename)?; let mut rdr = BufReader::new(f); let point = bincode::deserialize\_from(&amp;mut rdr)?; Ok(point); }(); &gt; &gt;if let Err(\_) {error!("bleh")} rs &gt; &gt;\`\`\`
Do you think it would be suitable for any niche applications? Alternatively, would it be feasible to create a low-friction interrop with Rust code?
They say const generics are explicitly out of scope for their (early draft) proposal - I don't imagine the race will be even close
Pure Rust is possible. It's an explicit goal of the [xi-win-ui](https://github.com/google/xi-win/tree/master/xi-win-ui) work. I will note that this is easier on Windows than some other platforms because the platform provides advanced things like text layout using a mostly-C ABI. On Linux (for example) you need to loop in libraries like HarfBuzz.
Literally every function that takes a Fn argument is using a callback. What on earth are you talking about?
The big one I've been trying to work on is adding `try_fold` to all the iterators that don't have it already.
Obviously. And usually those APIs are a PITA to use as they cause a ton of borrowing issues and force you into ugly patterns.
I had a similarly positive experience learning rust by writing a prolog interpreter.
&gt; -Elm/Relm data flow style, as opposed to widget inheritance, which is hard to do in rust. &gt;... &gt;- Simple, XAML like layouts. A simple system with Vertical and Horizontal boxes, and Grids where you can specify this element takes up 2 rows and 1 column, etc, without touching pixel values (just ratios) would be great. Part of what makes elm great is that there isn't a separate syntax for declaring UI. UI is declared in Elm. Not sure this could be accomplished ergonomically in rust, but you lose much of the benefits of Elm without the type-checking that declarative UI in Elm offers.
Hmm... This is a good little post on how to deserialize something that can be a string or number in json. However for this specific case, I would probably serialize the u64 mac address as a string in mac format, which avoids the problem altogether and is probably what you want anyways. Then you just need to document that the mac address is always a string.
I think the niche of languages that would want to target Rust or MIR is narrow. In particular, if Rust's borrow semantics aren't a cornerstone of the language's design, there are other mid-to-low-level intermediate languages that are likely a better fit, like WASM as you mentioned.
I'm chugging along with https://github.com/bvinc/gxi in pure rust. It's a little painful for various reasons, some of which I saw you touch on in your talk about xi-win-ui. GTK's object model doesn't feel very rusty. The initial event loop was pretty hard to set up. Creating a custom widget that derives from another and implements a gobject interface was extremely difficult. It'll get easier when `gnome-class` is finished. Setting up closures for handling events was pretty difficult. I've got all of my state wrapped in `Rc&lt;RefCell&lt;...&gt;&gt;`. Sometimes I find GTK functions that recursively call the main event loop and I have to be careful not to have any state borrowed during those function calls. The GTK-rs project is great, but occasionally I hit some functionality that hasn't been implemented yet. I saw that you do all of the text rendering yourself. I'm currently making calls to pango for all of my text rendering and style modifications, and I redraw the entire screen each frame. It's working out pretty good for now.
I don't have any recommendations - I'm not familiar enough with the rust landscape to say. MongoDB used to be terrible, but it's gotten a lot better in the past few years. That said, Postgres also has some nice json document support in it, you might want to take a look at it, but the mongo rust support is probably better than then postgres json rust support.
Any reason you want to use the std lib? I'd probably solve it with actix or a websocket library, as I don't particularly need the performance benefit of managing my own buffers.
You want /r/playrust
I agree with most of what you say, but we clearly have different priorities when it comes to how native something looks and feels. You may be willing to accept things like VSCode and Discord, but I value my applications looking and feeling native more strongly. To ensure my GUI-bearing creations feel native on my KDE desktop, I either write them with Python+PyQt (simple stuff) or I willingly incur the added complexity and dependency burden to add PyQt and rust-cpython to my Rust projects so Python can serving as a QWidget-based analogue to QML. Likewise, in my upcoming migration from Kubuntu 14.04 LTS to 18.04 LTS, I plan to replace most/all of my remaining GTK+ applications in response to how GTK+ 3.x has enabled and encouraged a much less Qt-like look and feel over the last four years. &gt; but things like file open dialogs, and notifications should definitely be native. You actually understate how important this is. Thanks to the push for Android-esque sandboxing and permissions for desktop Linux via Flatpak and snapd, things are going in the direction of either accepting whatever out-of-process common dialogs the desktop gives you via the dbus-based portal APIs or including a big, scary "unrestricted filesystem access" entry in your permissions manifest. Qt and GTK+ already transparently substitute portal-provided common dialogs as backends for their internal common dialog APIs when appropriate. (If you choose OK, the file/folder gets bind-mounted into the sandbox so sandbox-unaware code continues to just work.) Likewise, with the ongoing push toward Wayland, the capability to implement various kinds of desktop notifications is going away as the Wayland API doesn't offer applications X11-level explicit control over how and where the top-level windows they request will be displayed.
Learning Vulkan and gfx-rs &amp;#x200B;
I came across Spiro a few weeks ago (via reading your dissertation on splines - I want to get better at building beautiful charts) and was wondering what would happen if you hadn't moved to Google. All the best for your new adventure, I am certainly looking forward to monitoring the blog! 
&gt;Any reason you want to use the **std lib**? I absolutely blindly assumed there was some level of http handling there. I see that's not the case... Will look into [actix](https://github.com/actix/actix) and [reqwest](https://crates.io/crates/reqwest).
Another route would be something like the Futhark GPU language
I checked and you're right. Pretty terrible of Reddit to have incompatible subsets/supersets of markdown.
There is socket binding of course, but it's all blocking I/o. Hyper is the http library of choice for many. Actix and actix web are a nice asynchronous server designed for web requests.
Are you planning on writing a GUI library for Rust?
Username checks out :P
Ok, that makes a bit more sense, thanks for the explanation.
We've had const generics promised for so long already... but at least now there is a PR open to implement it.
Its not that easy to write a gui library. gtk+ has over 800k lines of code, the qt project multiple millions.
For your toolkit: * Do you need layout? * Do you need a DSL/Library/Framework for it? * Do you need logic for validations, pixel calculations, etc? * Plan to support react or elm or mvc? * Need events, process thing in the background perhaps? All of this is my idea. Every toolkit re-implement them in one way or other, and then couple it with the actual controls and drawing. This is just it. A core of UI logic. Then maybe some will go for the simple thing and other like me need to support mobile, desktop and web. Imagine as if you can get "css, html, DOM calculation" but not the actual render or javascript engine. 
&gt;post-fix macros &amp;#x200B; YES! I want this so much!
Hello, I'm working on Gitpod and I'm thrilled to see the link being posted here. I'll stick around, in case questions come up.
Citation required - that very much depends on how the code looks. If it doesn't contain a lot of generics that need to be typechecked and instantiated, the translation from Rust to LLVM IR is probably the least concern. Remember that rustc still spends most of its time in LLVM.
I agree with much of what you've talked about. Don't have time now for a full response but check out [Arc](https://github.com/mehcode/arc) when you get a moment. Quick points: * Retained, not immediate * Native widgets but with custom rendering being first class * Yoga for layout (would love someone to Port yoga to pure rust but don't want to tackle that right now) * macOS only right now but in the middle of Windows support
This was a good reminder that I should do something other than _writing_ code all day (i.e. _writing about it_ is good too!). I've been working on building a set of [CRDT](https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type) data structures in Rust to learn more about them, maybe I'll write up that process!
Will the repo for xi-editor move away from Google's github account?
Redox OS is working on this very problem with OrbTK. The ECS framework that it will be built on is currently under construction.
What issues?
I think I hit most of these points - I recently implemented layouting and hot-reload in my UI framework ([video demo](https://www.youtube.com/watch?v=kWL0ehf4wwI)) and it uses only [42MB and 0.2% CPU](https://discourse-cdn-sjc1.com/business5/uploads/rust_lang/original/2X/6/6aa44c4092783c8b4aba75e451ae71ad73a449ad.png), which is roughly as much as a QT Quick app. [Here's a nicer looking screenshot, very early in development](https://discourse-cdn-sjc1.com/business5/uploads/rust_lang/original/2X/7/75fd56913128e8b142b9c7f8696cb3dd6608915d.jpeg) - CSS doesn't necessarily mean heavyweight like Electron - if you care about performance I think you can find a middle ground between easy-to-use and lightweight.
Minor point, the library that sits under VS Code is called Monaco. It also sits under Matt Godbolt's Compiler Explorer.
Everyone always forgets about [Conrod](https://github.com/PistonDevelopers/conrod) whenever this sort of thing comes up. Looks pretty good IMO, and it's pure Rust/OpenGL.
I just wish more bloggers would pick a target audience. I see too many blogs there that are written for Rust devs but then spend 400+ words explaining the option enum. Others are intro blogs that throw code at you that is correct, and even explain what the code does. But they usually fail to explain *why* the code is written the way it is, or they belittle the reader who doesn't understand the post ("the newbies guide to rust: .... obviously we use enums")
Not if they're exported. That's always been the case. What's new is that you can rename them on import so that macros with the same name from different crates can be used together. This is because `macro_rules` is a very hacky old system. The new macro system using `macro` will use exactly the same name resolution as every other kind of item.
Hmm sounds like this could be fixed with snapaks Dev environments or even better rust containers
This is probably a very personal choice i.e. write/edit as long as you need to, and when you can find time. Writing to teach/show is much easier than writing just so you have something to show a potential employer.
Was it the boomerang theme? Thats basically what I'm planning, ship Materia on windows and macOS, not on linux. I tried the boomerang project but I found the widgets looked really tiny and completely flat
No. Java interfaces, Haskell typeclasses, and Rust traits, are "nominally typed." Just because a type supports a method called `to_string()` doesn't mean that it implements the `ToString` trait/typeclass. This also means that traits/typeclasses with no methods, like `Send`, are not implicitly implemented by all types. C++ concepts, Go interfaces, and, apparently, Go contracts are "structurally typed." If a type supports a method called `String()`, then it satisfies any contract, implements any interface, and matches any concept that requires a `foo.String()` method call to work. This model is, in practice, not bad in 99% of application code, but kind of falls apart in weird edge cases like marker interfaces where you end up having to add no-op methods just to control what actually implements it.
I mean at least for my purposes, SVG is mostly done now. It can do lines, rects, curves, circles, polygons, vectorized text with tranlation / rotation, putting text on a curve, hit-testing texts, caching shapes, loading &amp; parsing SVG files - for now I think that's enough. Not perfect, but it's something. Gradients in SVG and instantiated shapes are missing yeah, but I don't need them right now so that can wait. Gradients are difficult. But the next step is integrating the SVG with the rest of the framework, so I can control the SVG / custom OpenGL drawing using regular widgets, think of Inkscape or Illustrator, the SVG drawing (which is just a OpenGL texture) is just one part of the UI. I don't have that much time to work on azul this week, but I do expect something usable around December, maybe. Once I get the layout done, widgets like lists or tree views or tables are easy to add if the foundation is done correctly. But getting that right is hard, like absolute / relative positioning, centering, flex and scrollbars / overflowing content, etc. Layout will be the next focus for the next few months, but after that programming and styling the actual widgets should go pretty fast, esp. with hot-reloading. It is being worked on, but it just needs time.
Np, I'm definitely excited to see how azul ends up! Ill check back in a few months than and see how it's progressing :)
Quick update: I have now re-implemented the parser entirely in Nom and therefore removed the LALRPOP dependency. Next step is to add the `no_std` feature. Everything's good so far, I am glad I took the time to do this :)
Rust is free http://rust-lang.org Or did you want r/playrust
Sounds great. Have you considered porting e.g. [Avalonia UI](http://avaloniaui.net/) ([demo video](https://www.youtube.com/watch?v=21LYHJok82s))'s XAML renderer to Rust as a starting point? This would allow using actual XAML, so you could potentially use existing visual XAML design tools, and use existing XAML control themes. It also seems compatible with your other goals (except Elm/Relm data flow style, which I'm not familiar with; it sounds like that might throw a wrench in the works).
I think the way it should be done is with a Rust-y front end API that wraps multiple backends (Vulkan + Metal, ideally). The reason for this is that OpenGL is deprecated on OSX Mojave, and any GUI crate that doesn't accept that fact is useless for those of us who need to target MacOS. There are still folks whose primary markets are Mac users. &gt;Trying to bind to every platform's api is a massive undertaking That's true, but it's also likely the most stable path forward. 
gfx-rs solves the issue of multiple graphics backends. And what even is native? macOS only has cocoa, but linux has gtk/qt/others, and windows has win forms, wpf, and uwp
Hey your recent xi windows layout talk is my favourite rust talk. Good luck.
It's a work in progress. Next release will fix most of these issues (more things generated and less need for `Rc&lt;RefCell&lt;...&gt;&gt;`).
r/playrust
Please do, the area of CRDT (and related Operational Transformation) doesn't have enough clear writing and explanation.
Are those just bindings for Rust or a complete (re)implementation in Rust?
Working on [yet another text encoding crate](https://github.com/cessen/text_encoding). The main differentiating factors (and thus the reason I'm writing it) between this crate and the [other](https://crates.io/crates/encoding) [two](https://crates.io/crates/encoding_rs) text encoding crates I'm aware of are: 1. \`no\_std\`, so it can be used pretty much anywhere. 2. Does absolutely nothing fancy API-wise, preferring a dead-simple, low-level, zero-allocation, flexible API. Error handling, buffer allocation, character replacements, etc. are left entirely as the responsibility of client code. 3. It's intended to grow (over time) to support as many text encodings as possible, rather than being limited to e.g. only the WHATWG standard. In a nut shell, it's intended to be a low-level component for supporting whatever text encodings you want in a Rust library or application. The other two encoding crates could (in theory, I'm not suggesting doing this) be implemented on top of this one, whereas the reverse is not (at least conveniently) true. The crate is still very WIP and largely undocumented, so I don't suggest anyone use it yet. But if you're interested in contributing, let me know! My first goal is to have correct support for the entire WHATWG standard. And after that, continue on with even more encodings, as well as start focusing on performance, adding crate features to include/leave out some encodings (since some of them have quite large tables), etc.
Maybe trying to build a unified zero-cost abstraction over epoll, kqueue, and iocp isn't possible or worth it. 
I would love to start blogging, but my problem is that I'll be doing something cool and I'll think to myself "oh, I bet people would like to read about this, I should blog about this", but I know that if I wait until afterward I'll forget all the important context and details that made the problem interesting, so I need to alternate back and forth between writing the code and writing the post, and then each distracts the other and none of it gets done. :\
Wow! That's fantastic, very well tested and great usage of Rust Strengths (incorporating implicit flows into the Type System).
I've found myself before spending a long time trying to get idiosyncratic use cases to work with serde, until I realized, just write a custom function for that case. As amazing a library as it us, sometimes it's more trouble than it's worth. 
Oh my god, they actually did rewrite it in rust! That's... better than I expected.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [Google has embraced RIIR! Checkmate, C++!](https://www.reddit.com/r/rustjerk/comments/9belca/google_has_embraced_riir_checkmate_c/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Including half the Option/Result API?
I'm a security guy first, Rust guy like 4th. I've actually followed your work for awhile now lol. I read your post and I chuckle about your methodology (using bug trackers is hilarious and genius), and the post flows fairly well. You introduce Rust, quickly explain "it's safe, unless you use unsafe" (this may be slightly vauge for security people totally unfamiliar with Rust, but I think it's fine), methodology, foundation of memory unsafety, libjpg example, stdlib exploit, rustlang response, culture, and moving forward. It's exactly the flow I expect from any blog post of responsibly disclosed exploits. As a rust guy I read about 12 paragraphs that aren't related to the title that I already know, three of which kind of bash on how programmers don't care about security. Halfway through "into the woods" we finally get to the first paragraph that really matters and the reason a developer probably clicked your link. Then we talk about versioning and culture problems, which probably do matter to the reader at this point. So from my perspective, great post. Most developers would likely find it lengthy and not very to the point. I'm on mobile right now and traveling tomorrow, but I'm totally up to continue discussion about this on any blog posts!
Good luck /u/raphlinus! I look forward to reading more blog posts from you and seeing where your music synthesis takes you. :-)
But we already have cap'n'proto https://github.com/capnproto/capnproto-rust How do they compare? Capnproto also does the thing where there's no parsing stage. Seems like there might be a redundancy here and it's not clear flatbuffers should become the standard.
How does this compare to [ndarray](https://github.com/bluss/ndarray) feature wise? It's probably the most popular Rust crate for doing operations that require n-dimensional array support. 
I think we could get pretty close to GTK with 100K or less. There's a lot of duplicated effort in GTK and Qt that extends beyond the GUI system. We have the whole ecosystem of crates to take advantage of. I think we just need more people to come over to the Redox OS project to volunteer to be a part of the OrbTK group.
What's the issue? Storage? You can stick them all into a Vec, and just iterate over that to get each one
Could you elaborate a little more? Still pretty new to Rust.
This is why I think the only realistic way to do it is to build on an existing C++ library, at least at first. Of course, this shouldn't affect the API of the GUI library, but it would IMO be crazy not to use something already existing in its implementation. Of course, I might be not completely objective here, but it's just sad to see the number of people rewriting more or less the same GUI code again and again and again.
Not... In my experience? No more than implementing the same logic imperatively. It's true that you have to manage the lifetimes of your references, but that's best practice anyway.
I'd recommend reading chapter 8 of the rust book as it covers this topic pretty well: https://doc.rust-lang.org/stable/book/second-edition/ch08-00-common-collections.html
I can definitely relate to that...
I’ve read about vectors and I’m using one to store player names. I’m just having a problem thinking of how to use a struct instance in a vector.
? Rust changes it's ABI all the time, if you want binary compatibility you more or less have to use the C abi.
 struct PlayerName(String) let names = vec!["foo","bar","batz"]; let player_names = names.map(|n| PlayerName(n));
What's the issue you have? Once you have the user input telling you how many instances to make, you just create new structs in a loop: `for _ in 0..user_input_number { let m = MyStruct { x: 0 } }`. If you want to access all the structs later, store them in a Vec
&gt;CnP is still on version 0.7 says to me that its author doesn't consider it stable I'd be inclined to read that as humility, considering how long it's existed and how much prior experience the lead dev has. &gt;Providing a Rust implementation for a particular protocol does not mean anyone is asserting it must become "the standard" for anyone Sure, the only person here proposing that one or the other format becomes the standard is me. This is what disturbs me. Not even the projects seem to share this stance. I sometimes feel as if I am the only person who has not forgotten that resources are finite, or that interoperability is good.
In the beginning i found writing a custom function a little daunting, so i tried to avoid it. Eventually i had to do enough times it became more familiar. Its definitely a little cumbersome to writing custom functions all the time, but you'll be assured that it will produce valid json (and/or any other format that serde supports). 
Sure. In which case you can use the [HardwareAddr](https://docs.rs/interfaces/0.0.4/interfaces/struct.HardwareAddr.html) struct from [the interfaces crate](https://docs.rs/interfaces/0.0.4/interfaces/) to represent the MAC. That way you can keep everything type-safe rather that use a string. Pick your poison :). My original usecase was to deserialize a number from its hex representation as a string "0x1234" or an integer 4660. The Mac address thing came after, and i don't completely love that solution for my case, but right now my code is working well with that in place. 
Construct, and then `push`? Maybe a more complete idea of the problem you're tackling might help.
So, if I were reviewing your examples, my main critique would be that you've suggested some kind of exclusive dichotomy between `?` and the `Result` functional adapters. I've found I've had the most luck when I combine them: use `map_err` to convert errors, and `?` to return them. I generally believe that `and_then` is hardly *ever* preferable to `?` in terms of code clarity. Additionally, generally I'm of the philosophy that functions that returns errors generally should not be responsible for logging them; it's preferable to use a structured error type, return a structured error, and let your caller decide whether to log it / do something else with it. I followed this approach with [rewrite](https://github.com/Lucretiel/rewrite/blob/bf893a3fc3c77372758fd9f577a81709fcdafc8c/src/main.rs#L215-L296); notice all the \`.map\_err(...)?;\` throughout the highlighted function. However, if you want your function to log, you can still use a combination of \`?\` and \`map\_err\` for a more elegant but less functional design: // Log an error, then return that error macro_rules! log_error ( ($err:ident =&gt; $fmt:expr $(, $arg:expr)*) =&gt; (|$err| { error!($fmt, $($arg,)*); $err }) ); fn load2(filename: &amp;Path) -&gt; Result&lt;Point&gt; { let file = File::open(filename).map_err(log_error!(err =&gt; "could not open {}: {}", filename.display(), e ))?; let mut rdr = BufReader::new(f); let result = bincode::deserialize_from(&amp;mut rdr).map_err(log_error!(err =&gt; "could not decode {}: {}", filename.display(), e ))?; Ok(result) } Even if you don't like the macro, this spells out your intent clearly. I find it much more readable than either the combinator or the "\`match\` everything" examples.
 struct Foo { data : i32 } fn main() { let mut vector = Vec::new() for i in 0..10 { vector.push (Foo { data : I }); } }
That looks like that’s exactly what I want.
This is great. Has there been a verification of unsafe usage? (I am more worried about soundness issues and such).
I know but it only compiles to ASM.js using emscripten, which I don't want because it's a huge POSIX runtime with unnecessary indirection layers..
Indeed. Accessing a Vec with brackets will panic on out of bounds access though, so either your program logic has to ensure there can't be any out of bounds access, or you use the .get(index) function instead, which returns an `Option`.
It's called an index but yes. Like others said read the book but I wanted to give a brief code example just for reference. 
I think this has to do with, when some say "a GUI in rust", they really mean a platform native GUI that looks exactly like the OS gui without having to write specific code for each platform. I can group these in 2 categories. Platform Native GUI: (Behaves the same, but with subtle platform specific difference) - gtk-rs - winapi-rs - cocoa-rs - libui-rs Uniform GUI: (Looks the same regardless of the platform) - conrod - azul - webkit - orbtk So, conrod, won't be mentioned a lot, since it is geared towards games. Azul is geared towards html/css mindset. Orbtk has a very simple and intuitive code, while looks consistent and beautiful, it is only native to Redox-OS look and feel. People wanted to have a GUI toolkit that can: - look native to major OS platforms - look native to mobile platforms More options: - can be published as a webapp. - can be wrapped with a web-view (if the target platform has ugly default UI). - can be published as text ui that will run on the terminal (for ultimate portability). Rust projects we can use: https://github.com/gtk-rs/gtk https://github.com/retep998/winapi-rs https://github.com/servo/core-foundation-rs/ https://gitlab.com/objrs/objrs https://github.com/tomaka/android-rs-glue https://github.com/gyscos/Cursive So, if we are going to meet this requirement, we would have to create an abstraction which leverage the use of #[cfg] feature flag for each of the target. The elm architecture is the most well accepted paradigm and it has been adapted in some rust projects: https://github.com/antoyo/relm https://github.com/DenisKolodin/yew While relm and yew are specific to gtk and html respectively, this can be adopted to be component based and each component will have a corresponding native control to each of the platform native GUI or event a text UI. Components can still be expressed with virtual DOM, diffing can still work on native GUI and diff patches can be applied. 
I’m almost half way through, although I’m rereading some things as I go along so more advanced stuff makes sense.
This is really good advice. Thanks! I actually went with an outline at the top for this article. But now it seems I've found *another* such vulnerability. If I manage to reproduce the crash outside my fuzz harness, I'll just split the post in two - one on how to discover such vulnerabilities and another on why they occur and how to get rid of them.
Sounds good. Thanks for the work you do! I'm always willing to proof read, and there is a Rust community group for helping with blog posts. I don't recall their name right now though.
I finished the Rust Book. I've been tinkering with some projects and got quite good grasp at Rust. What is the recommended Rust fullstack web framework? I have experience with Express (NodeJS) and Phoenix (Elixir). 
Thanks for the links to discussions on the related articles/blog posts!
http://www.cryptopals.com/sets/2/challenges/12
To do that, do `(*arc).clone()`, but that would be a waste since you're using an Arc anyways :)
When I read the thread yesterday about tokio being too complicated, I was thinking that somebody should write a very simple mainloop library that looked more like other languages. Just like this one. :-) Too bad `insert_idle` can't take a FnOnce due to the "can't call it when boxed" problem though. 
I don't see any unwraps in your file :) I'm half-sure that `Option&lt;T&gt;` implements `Into&lt;Result&lt;T&gt;&gt;`, so you can use `?` on it, but I might be wrong. At the last expression in `establish_connection`, the `Ok(x?)` is unnecessary, which is just returning the error if any (in which case `x` would be `Err(...)`) and then wrapping the `Ok(...)` (which is `x`) inside another `Ok(...)`, which doesn't seem to be what you want.
Have you tried leaving breadcrumbs along the way? It could just be some scribbled notes on what the key points you want to write up in the blog post. Or maybe "TODO Neat-algo-post" comments in the code which help you reconstruct your thought process.
Ha! Reading this thread I was wondering if ECS might help solve some of the GUI problems, but I thought "hey, I'm a total n00b with graphics and UI, I'm probably just mashing buzzwords together."
Thank you. I will try actix-web then since futures looks like it will simplify stuff like NodeJS (hopefully) ! I am okay with writing the front end with JS though prefer it to be as minimal as possible!
&gt; [...] The sound engine absolutely will be. I'm quite excited in fact about the potential for Rust in audio [...] I'm facing a choice between prototyping using Web tech (running the audio engine through wasm) Does wasm have a good story for audio yet? The impression I got is that [it's still missing some things](https://github.com/tomaka/cpal/issues/92). cpal has added an emscripten backend since that bug was filed, but it seems to [still have some major drawbacks] (https://github.com/tomaka/cpal/blob/master/src/emscripten/mod.rs#L25) for interactive applications.
&gt; Not sure this could be accomplished ergonomically in rust I'm newbie to Rust, but I was expecting its macros are capable of doing this kind of stuff.
Yes, I think good wasm audio is possible, but the space is still evolving. For decent performance, you have to use AudioWorklet. I [prototyped](https://github.com/raphlinus/synthesizer-io/tree/master/synthesizer-io-wasm) something using ScriptProcessorNode, but that's going to be really bad when the js thread is doing other heavy lifting. I haven't tried cpal on web (though I just now switched to cpal instead of just using core-audio, so that it'll work on non-mac desktops).
&gt; perfectionism takes over and I spend an hour tweaking a single paragraph. Ah yes, I know that feeling too well. One bit of advice that I've found helpful for dealing with this (can't recall who said this) -- separate out writing and editing phases. Pick one phase and stick to it during a session. Don't switch. And take breaks between sessions, so that you can re-read the words afresh. It felt very strange at first, but I slowly got used it to it and avoided getting trapped in infinite editing loops. Maybe this is helpful to you too :). Looking forward to your upcoming blog posts, no pressure :P.
Any plans to move to stable in the near future? Being on nightly is a pretty big show stopper for a lot of people.
Stable for what?
Building OrbTK requires nightly rust
&gt; Why is player_name[i] not having ownership taken and given to the create_player() function? You're using `to_string(&amp;self) -&gt; String`. I don't see how this function could return anything but a clone of the original string. This clone is then consumed in `create_player()`.
It's not really usable in its current state, so you aren't missing anything yet.
I am trying to write a generic function. https://play.rust-lang.org/?gist=cf64a679cfc8e770293f183ac03106db&amp;version=stable&amp;mode=debug&amp;edition=2015 I don't understand why it is needed to again have a partialord trait bound, which I already provided.
Exactly this experience. I would think I know something, but when I put it into words, I realize all the gaps are plain and clear. So unless I want to write a crappy blog post that handwaves over stuff, I have to go back and properly research it. Sometimes it is even worth to write your thoughts on the subject even if it is unclear if they can be published. For example, I have tried to write several times about how bad the OO is, only to realize it's only the opinion rooted in no clear facts or data. Some encouragement for non-native speakers (like myself). I noticed that I can write a blog post way faster know (if I know the material - it's like 4 hours). However at first I would struggle with it for days. What this "struggling" is? Well, re-reading previous paragraphs and realizing the sentences do not flow right. It's always a lot of re-reading and rewriting.
Excellent!
In the end, I might try to go the WASM path, because it's the only truly portable IR out there, that I know about. The only problem left is the architecture: how do you make it simple enough, so that it doesn't get confusing, when you are trying to introduce another platform? Let's say, someone decides to make an ActionScript backend for flash (for some reason). This WASM IR it might look like this NMIR (Nord MIR) -&gt; \[WASM Emitter\] -&gt; WASM -&gt; \[Result Emitter\], where both emitters can be easily changed or extended. For example, running compiler in the browser, you might want to use Bynarien + Some JS interop generator as an emitter combo. While running on the machine, that contains LLVM, you might want to use LLVM + Cranelift as a combo that will allow you to emit native binaries. LLVM is not present? Just use Bynarien + Cranelift! However, even though this will theoretically work, there is still might be a problem: I planned to allow to use native libraries cross-platform, meaning that all of them will have to be compiled to WASM and then linked in with the project itself via something like LLD. However, it will only work on platforms supporting LLVM and most of the libraries (this is a speculation) won't compile without the STDLIB stub, provided by Emscripten, for example, which for me is a very unnecessary dependency.
It depends. You might end up in a Java situation where the answer is "it depends".
&gt; Too bad insert_idle can't take a `FnOnce` due to the "can't call it when boxed" problem though. Yes, that's exactly the reason. I settled to only allow `FnMut` for now because I didn't feel like banging my head on this issue right now, but if there is some clever trick which allows to box an `FnOnce` and still be able to use it, I'd be happy to integrate it!
To be honest, that was my initial feeling about it when I started working on wayland crates 3 years ago. After 3 full redesigns of the crates, I came to accept that actually, sometimes callbacks are the way to go. And I believe handling the wayland protocol is one of these times. When you have to handle what is basically hundreds of event sources, each with its specific kind of events, managing a gigantic enum of all possible events to dispatch them to the appropriate routine quickly becomes nightmarish.
I gave it a quick test. I could run my toy tetris game using pancurses in its console! Not really playable due to lag, but still really amazing. The autocompletion seems to be the "complete to any word seen" kind though, not based on the type, but much better than nothing.
I'd like to add that if you want to blog, we support you: There's the content team https://github.com/rust-community/content-team. It supports you at getting started with blogging by providing a pre-configured [blog template](https://github.com/rust-community/rust-lang-blog-boilerplate) and the [content-o-tron project](https://github.com/rust-community/content-o-tron) for review and mentoring. 
I didn't know about this crate, but it seems to solve every problem I had with other crates! Also, sorry for the misanderstanding, but I don't think I used the term "N-dimensional" correctly to describe my crate since it does only 2D operations for the time being (it was only a possibility for future versions, I don't know why I put it there... never a good idea to change things late at night it seems). So concerning N-dim features, my crate does nothing of the sort for now, and for 2D features, it only contains basic matrix operations (add, subtract, dot, transpose) and data structure-like functions (get, set, map, into\_iter). ndarray seems to have many more functions to construct/transform its arrays at the cost of an API a little harder to learn. &amp;#x200B; **tldr:** \- simple-matrix is not N-dimensional (only 2D) \- It has simple matrix operations, but not complex ones \- ndarray does have N-dimensional capabilities \- It has a great range of functions that can cover more complex problems \- But that makes its API a bit harder to learn
&gt; When you have to handle what is basically hundreds of event sources, each with its specific kind of events, managing a gigantic enum of all possible events to dispatch them to the appropriate routine quickly becomes nightmarish. Without knowing exactly how it works, the general solution are trait objects and logic to route an event to the right trait object. 
This is certainly great work and imagine nightmare to review with github UI :D
 &gt;You're using `to_string(&amp;self) -&gt; String`. I don't see how this function signature could allow to return anything but a clone of the original string. It could also return things like `String::from("rustcvswvj")`.
Just curious -- I'm not familiar with sparse images -- why not generate/validate checksums by default?
Well, providing a struct implementing a specific trait that will be converted into a trait object is not very different from providing a closure. With the difference that if you require a trait, your user is forced to create a new struct and implement the trait for it every time, while a closure can be defined with a much lighter syntax. Actually, just my previous version of the wayland crates used a trait, that was auto-implemented for closures, allowing the user to specify a closure or a struct implementing it. The issue was that it caused issues with inference, and forced the closures to be heavily type-annotated. On the other hand, if a closure is required, it is very easy to actually use a struct and/or a trait: just provide a closure that captures the object and forwards the event to the appropriate method. Taking all that into account, it seems to me closures are actually the most ergonomic interface for this. The ideal would be if it was possible to manually implement the `Fn*` traits for any struct, but apparently there is no plan to stabilize that...
What does “native” mean on a GNU/Linux system?
I understood the question not as how to create `String` from `String` or `&amp;str` but why there is no problem with borrowing.
The `PartialOrd` bound that you provided is `T: PartialOrd&lt;T&gt;` (because rhs defaults to `Self`, in this case it is `T`). However, you are comparing `&lt;T as Div&lt;T&gt;&gt;::Output` with `f64` - so the given bound is completely useless here. To make this compile I see a couple of options: 1. Add a bound `&lt;T as Div&gt;::Output: PartialOrd&lt;f64&gt;` 2. Add a constraint `&lt;T as Div&gt;::Output = T`, and change existing bound to `PartialOrd&lt;f64&gt;`
It used to mean "matches the look and behaviours defined by whatever unified Qt + GTK 2.x theming solution you've hacked together" (eg. A theme like QtCurve, QGtkStyle plus a GTK+ theme, etc.) Since GTK+ has started to diverge from Qt more drastically at the widget level while simultaneously pulling a Firefox and trading power for maintainability in their theming API, there's now no longer such a thing as a "GNU/Linux system" unless you choose which kind you want to aim to be native on: 1. KDE and LXQt 1. Subset of UI elements still common to Qt and GTK+ designs 1. GNOME and other desktops which rely on applications designed for GNOME.
I am not a GUI expert, but I'd like to disagree with the XAML bit. To me personally it seems like "GUI in code + live reloading" is the most productive way of creating GUIs. It's better than GUI designers, because they can't render UI 100% correctly and they can't show interactions. I **really** love how flutter does things (although, I haven't actually tried it, it's rather that all other models I've worked with had shortcomings :) ), and it seems to me that, long-term, it makes sense to build a Rust stack similarly. Specifically, I'd suggest to * Use webrender + pathfinder to implement the rendering layer (which is handled by skia in flutter) * Implement layout + styling. No idea how to do this nicely, but, at the first blush, it seems like subsetting DOM+CSS might be a good idea? If display is always grid, and box-sizing is always border-box, the resulting model should be easy to work with, and it should be possible to reuse existing implementations and knowledge. * For live reloading, the promising route seems to be to add a WASM interpreter to the app, so that GUI's are WASM files, loaded (and reloaded) from external files, which call into the underlying layout/style/render infra via host bindings. * I don't know how the WASM GUI should communicate with the main app, but I think serde + proc macros should make it possible to write glue code between an app and each particular GUI relatively concisely, while keeping the interface between the data model and GUI extremely clean (yay testing!). * It's not actually clear what language to use to target WASM GUIs :) Rust has an obvious advantage of being the host language and having a great WASM toolchain, but I don't think Rust is the easiest lang to develop GUIs in. Other to interesting candidates are Elm (which is build for GUIs) and Kotlin (which can target WASM, and which is well-suited for GUIs due to built-in support for DSLs). 
It's hot-reloading only for CSS, right? Looks very promising, though I wish to be able to hot-reload the whole GUI as well :)
Apologies, I was being pedantic. Given the name of the function and assuming it won't do something completely unexpected, you are of course correct.
&gt;What issues? Everything's statically linked... An error in the linker, due to incompatible data layout? (Unless Go doesn't support binary libs?)
We're flexible :) It depends on the candidate
If only diesel got better :P
For performance reasons, unfortunately. CRC has a significant impact on performance considering images can get quite large. Also, the original implementations of the sparse tools don't do checksums at all, so you don't really find sparse images with valid checksums in the wild anyway. So computing/validating checksums only makes sense if you use android-sparse for both compression and decompression. The primary use case for android-sparse, I imagine, is decompressing a sparse image generated by AOSP's img2simg so it can be mounted. For this you don't need checksum validation (since the sparse image has no checksum) but you probably want speed.
That Raph, god speed!
&gt; Cargo doesn't make it easy to specify or enumerate non-rust dependencies and a lot of people just assume that random software or libraries are installed when setting up their crates Cargo might add a feature to do this but at the end of the day you need a good FFI story and you need to reuse some of the work that's already been done. GTK is 700,000 lines of C. You're not going to replace that overnight, and replacing it *to make builds easier* is just not going to happen. 
In general, macros tend to be an bad way of doing this. Rust's macro system isn't advanced enough for a type-checker, much less enforcing purity and the like. 
I think you've pretty much describe "Azul".
I think this is highly variable. Personally: I usually come up with the idea for a post and will think about it without a plan in mind over a really long period of time. I have a bunch of posts which I've been thinking about but not in a structured way. Sometimes I will note this stuff down, I have a file full of unstructured ideas and subpoints. Then I'll decide to actually write it and will think about it a bunch in the days leading to it (usually I won't have time to immediately write). The actual writing is a couple hours usually, often spread out over many days. And then review and edits take some more time. All in all it's not much net time spent, but the time spent stretches across a long duration. Once I start properly writing I usually finish it -- I may come back the next day but not wait till the next week.
If you're comparing to gtk/qt. Rust would require a fraction of that because lots of high quality implementations already exist as crates. Both qt and gtk implement their own std. 
Thanks for the detailed answer. &gt; It used to mean "matches the look and behaviours defined by whatever unified Qt + GTK 2.x theming solution you've hacked together" (eg. A theme like QtCurve, QGtkStyle plus a GTK+ theme, etc.) That’s my point. On Windows, or Mac OS, there is a “right” look and feel, a fixed theme applications have to abide by. In GNU/Linux world (or BSD, or whatever), there is no central authority making the rules, so there are several solutions (GTK, KDE, Qt to name a few), none of them being the “right” one.
you are missing a semicolon after `Vec::new()`
&gt; (GTK, KDE, Qt to name a few) KDE uses Qt for its widgetry and provides a custom configuration GUI. The solutions significant enough to have a claim to authority are: 1. Qt's QWidget API (KDE applications, LXQt, etc.) 2. Qt's Qt Quick API (Widgets for KDE's plasma shell) 3. GTK+ (GNOME, Xfce, LXDE, etc.) ...and, before Qt Quick and GTK+ 3.x shook things up, we'd reached a point where `QGtkStyle` allowed Qt to treat GTK+ as the single authority.
What do you think about [creating DOM programmatically in WASM](https://www.reddit.com/r/rust/comments/9bapwt/thoughts_on_what_a_good_gui_system_would_need/e534rfb/) and achieving hot-reloading via reloading WASM ? :-)
Yep, it's the closest thing to what I am describing, though it only can hot-reload CSS, and not the whole of GUI.
This can be slightly improved by using `Vec::with_capacity(10)`
I mean, yes you can do it, but are you going to write WASM by hand? WASM can't really be directly used as a "scripting language". You'd still need a language that can generate WASM (the selection of those are right now pretty small), and if you use Rust, you have the same compile time problem again, but now with WASM as an intermediate target, which complicates things and isn't much of improvement. What would solve this problem is if Rust had a stable ABI, then you could compile azul into a DLL, which would probably solve the compile time problem. Or someone writes a Rust JIT, but that's unlikely to happen. And you also need a WASM VM to send values back and forth and actually run the code between Rust and WASM. However, what you can do fairly easily is to run scripts (such as from a Lua / Python / JS / whatever) - languages that already have an interpret-and-exectute part (pseudocode): struct MyApp { script_filepath: String, python_vm: PythonVm, } impl Layout for MyApp { fn layout(&amp;self) -&gt; Dom&lt;Self&gt; { self.python_vm.exec(reload_file(self.script_filepath).unwrap()) } } Here the Rust app is essentially a "container" for the VM, and as long the VM / language of choice can give you back a `Dom&lt;MyApp&gt;` (which could be done in wrapper libraries), this would work (and in release mode you could `include_str!()` your python script so it's embedded in the binary). This is how I intend to later do language bindings for other languages, the main loop runs in Rust and the Rust binary calls external VMs / scripting languages to execute some code. The problem with prototyping is that you usually want the code in a compiled language (such as Rust), but these languages aren't quick to reload (because they are compiled). So I think XML-hot-reload is right now the easier solution instead of embedding an entire VM, i.e. something like: &lt;component name="render_dom"&gt; &lt;div id="parent"&gt; &lt;p id="child-1"&gt;Hello&lt;/p&gt; &lt;div id="child-2"&gt;{{ render_gl_texture(&amp;self.data) }}&lt;/div&gt; &lt;/div&gt; &lt;/component&gt; ... gets then translated / "compiled" to a seperatate `ui.rs` file: fn render_dom(&amp;self) -&gt; Dom&lt;Self&gt; { Dom::new(NodeType::Div).with_id("parent") .with_child(Dom::new(NodeType::String("Hello".into())).with_id("child-1")) .with_child(render_gl_texture(&amp;self.data).with_id("child-2")) } ... but this way you can hot-reload the UI and do the layout quickly. If the XML parser can't find a function (such as `render_gl_texture`), it should just display an empty rectangle, expecting that this function will be later implemented in the actual Rust code. This way you can still do the layout and style your DOM using hot-reload and later care about actually implementing `render_gl_texture` in Rust. Hot-reloading should just get you off the ground for the design / prototype, you shouldn't expect to write your entire app in XML. So you are expected to throw away the XML at some point - but the good thing is that a DOM is recursive, so you can do a part of your UI in Rust, and at the same time doing prototyping a sub-tree in hot-reloadable XML, i.e.: fn layout(&amp;self) -&gt; Dom&lt;Self&gt; { // the parent is implemented in Rust Dom::new(NodeType::Div).with_id("parent") .with_child(Dom::new(NodeType::Div).with_id("child-1")) // The layout of the child tree can be hot-reloaded from XML .with_child(Dom::hot_reload("new_feature.xml")) } So at some point, you compile `new_feature.xml` into Rust, copy the resulting `fn new_feature()` somewhere and throw the XML away because your feature is now in Rust. The XML is really just about prototyping the layout and styling and the rough UI structure - dynamically generating a DOM is doable, but you'd need to decide on a scripting language to do that, WASM isn't really suitable for that. JUCE (C++) for example uses LLVM-JIT for hot-reloading, that could also be an option, using the Rust compiler frontend to generate LLVM bitcode and LLVM-JIT for the backend.
Hi, often, if there isn't one already, all it needs someone to get one started :). Pretty often, it helps to just get one announced. It doesn't have to be big and you don't necessarily need talks. If there's at least one person showing up, you have something to work with.
/u/zzyzzyxx described the problem, so I'll just add two possible solutions: - Make string2 live longer than result, by declaring it above. - Make result hold an owned copy of a string, instead of a borrowed slice, using .to_string or .to_owned (they're equivalent in this case).
Frankly, I would be very happy with a pure rust wxWidgets, Tk or imgui. You don't found a new city by building skyscrapers.
I agree Conrod looks great and I hope for it's success... but frankly I've yet to see an actual application actually use it any time in the last two years.
I'm excited to follow the new blog - just added it to my RSS reader. It's also nice to see LLD get finalized, which should make it easier to bring Rust-as-first-embedded-experience folks on board. Finally, it's always fun to see the crate number tick up.
Note that the author of CnP wrote Protocol Buffers 0.2 while at Google.
An unexpanded macro is, but you can write macros that expand to something that type checks well. It does require a lot of boiler plate on the library side though to support the macro output.
It's an issue for sure, but making the GUI pure Rust is not possible. At some point it will have to talk to the system and for that it will use dependencies. So making the packaging or describing of dependencies more robust is the way to go.
I'm doing something similar in Haskell right now (from scratch, not based on anything). It's been a great way to get to know the language better, as well as producing a library I actually have a use for. Maybe when I'm happy with it I will try porting to Rust :). I've been making use of quite a few GHC extensions so it will probably need some reworking. It's a really good project for learning a new language as it covers a lot of fundamental areas: file (and possibly streaming) I/O, binary parsing, text parsing, some distinct domains, some common so you get a better feel for how to organise modules etc. Designing a good API is the main challenge I feel. I also started writing something in D back in uni: https://github.com/chrismanning/utl
At least in C++, the FlatBuffers API includes verification functions, which bounds-check all pointers in BFS. So, if you load untrusted data, verify the buffer once and then use it as you like.
You might need to manually deregister a previous connection when dropped. I don't think that happens automatically.
I can only emphasize what others have said: &gt; Nightly doesn't exist. (Unless it does, which is if you intend to release your library roughly the same time your favourite nightly feature is stabilised). To provide my own rationale: When you target nightly, you are targeting features that could potentially disappear for good, and that's not far away from writing code in an imaginary language. You wouldn't do that unless you wanted to actually invent the language and test it's proposed behaviour this way. I believe nightly should receive the same treatment.
 fn jail_roll(player: &amp;mut Player) -&gt; bool { should fix your problem. The issue is that "Player" is already the name of a type, and so it can't be the name of a variable. Renaming it as "player" will fix your issue, as long as you also apply that change throughout the function
Post the whole program.
Well you didn't include the code calling the function, but this looks like since your function argument is capitalized, it makes it the same as the type name, which rust then sees as an incomplete pattern binding, producing the error. Try making the argument be `player` instead of `Player`. The standard rust style for variables is lowercase, which also prevents this problem from occurring.
THIS IS SO FUCKIN' COOL Also, I hate you because I wanted to make something like this. Do you have any thoughts/plans like bringing up a test environment through k8 or something like that? Is there any thoughts on how you could add personal workspace customizations (so, for instance, could I layer preferred Linux tooling like ripgrep on top of a github repo? Or if a project is identified as Python, I could add a Python specific tool?).
The crate [https://crates.io/crates/enum\_primitive](https://crates.io/crates/enum_primitive) provides a macro enum\_from\_primitive! for enums that allows the conversion from numeric type to enum type.
This is why I think is better to have a thin backend and do the actual widget writing in the environment with the rich APIs. Is orders of magnitud less work and you don't reimplement the wheel neither fight against how that UI was made.
Oh this looks very relevant.
You could replace its build system with something that "just works" like the gcc crate. This is also a ton of work, of course, but it'd be a nice direction for some of these crates to go in. Most crates wrapping small libraries like zlib-sys do something like this already.
 Why is this not allowed and is there a workaround that doesn't involve me just using indexing? fn consume(mut a: &amp;mut [u32]) { while !a.is_empty() { a = &amp;mut a[1..]; } } 
You're doing god's work. Anything that lets me disable cortana for good. 
Seems like that easiest solution here would be to impl a method with a big match statement that returns a Result. You could also impl TryFrom (can't remember if that is stabilized yet). You would have a bit of code duplication, but seems like the simplest solution.
I haven't had time to check your code, but my first hypothesis is that you may be bumping up against Python's Global Interpreter Lock. (Python's execution model is fundamentally non-parallel and any manipulation of a Python variable or call to a Python function must acquire the Global Interpreter Lock.)
That is not true. From the moment rust had a FFI it became possible to trigger UB from safe rust. It's impossible to ensure the pointer passed was not dropped for example.
Well, still same error. &amp;#x200B; Here's what I've changed the function argument variable to: fn jail_roll(JailedPlayer: &amp;mut Player) -&gt; bool { println!("{} is in jail", JailedPlayer.name); JailedPlayer.jail_count += 1; let first_dice = rand::thread_rng().gen_range(1, 7); let second_dice = rand::thread_rng().gen_range(1, 7); println!("First dice is: {}", first_dice); println!("Second dice is: {}", second_dice); if first_dice == second_dice { println!("{} got out of jail!", JailedPlayer.name); JailedPlayer.jail_count = 0; return false; } if JailedPlayer.jail_count == 3 { println!("You must pay $50 to get out now."); JailedPlayer.jail_count = 0; return false; } true } Here's the whole code (near the bottom is where the jai\_roll() function is called): extern crate rand; #[allow(unused_imports)] use rand::Rng; use std::io; #[allow(dead_code)] struct Player { name: String, doubles_roll: u8, jail_count: u8, in_jail: bool, } fn get_number_of_players() -&gt; usize { loop { let mut number_of_players = String::new(); io::stdin().read_line(&amp;mut number_of_players) .expect("Failed to read stdin."); let number_of_players: usize = match number_of_players.trim().parse() { Ok(nop) =&gt; nop, Err(_) =&gt; { println!("Please enter an integer."); continue; }, }; if number_of_players == 0 { println!("You can't play and not play at the same time. This isn't Quantum Theory."); continue; } return number_of_players } } fn create_player(name: String) -&gt; Player { Player { name, doubles_roll: 0, jail_count: 0, in_jail: false, } } fn jail_roll(JailedPlayer: &amp;mut Player) -&gt; bool { println!("{} is in jail", JailedPlayer.name); JailedPlayer.jail_count += 1; let first_dice = rand::thread_rng().gen_range(1, 7); let second_dice = rand::thread_rng().gen_range(1, 7); println!("First dice is: {}", first_dice); println!("Second dice is: {}", second_dice); if first_dice == second_dice { println!("{} got out of jail!", JailedPlayer.name); JailedPlayer.jail_count = 0; return false; } if JailedPlayer.jail_count == 3 { println!("You must pay $50 to get out now."); JailedPlayer.jail_count = 0; return false; } true } fn printnls(newlines: u8) { for _ in 0..newlines { print!("\n"); } } fn main() { println!("How many players?"); let number_of_players = get_number_of_players(); let mut player_name: Vec&lt;String&gt; = Vec::new(); for i in 0..number_of_players { let mut name = String::new(); println!("Enter the name for player number {}.", i + 1); io::stdin().read_line(&amp;mut name) .expect("Failed to read stdin."); player_name.push(name.trim().to_string()); } let mut player: Vec&lt;Player&gt; = Vec::new(); for i in 0..number_of_players { player.push(create_player(player_name[i].to_string())); } let mut turn: usize = 0; loop { loop { if turn &gt;= number_of_players { turn = 0; } if player[turn].in_jail { printnls(100); } if jail_roll(&amp;Player[turn]) { println!("blah"); } } } } &amp;#x200B;
You want r/playrust.
You're likely to get better advice on /r/playrust than you would from a programming language subreddit =P
Genuinely curious - are there better UIs for code review?
Two folks already pointed you to the right subreddit, but hey, I like when people answer the question regardless. It's friendly. A lot of folks tend to tap ARs instead of spray when spraying doesn't work. So, in other words, just use those only two shot bursts or just tap single shots. Rust may have a weird range for the AK that differs from other games, so you might be best served by tapping at range and spraying when up close. This is what I do with the standard AR in Fortnite and it works pretty well. Of course, spraying at range can work well as a suppression tactic, but that won't usually get you any kills. You probably know all of this, but figured I'd give some tips anyway just in case.
 extern crate rand; #[allow(unused_imports)] use rand::Rng; use std::io; #[allow(dead_code)] struct Player { name: String, doubles_roll: u8, jail_count: u8, in_jail: bool, } fn get_number_of_players() -&gt; usize { loop { let mut number_of_players = String::new(); io::stdin().read_line(&amp;mut number_of_players) .expect("Failed to read stdin."); let number_of_players: usize = match number_of_players.trim().parse() { Ok(nop) =&gt; nop, Err(_) =&gt; { println!("Please enter an integer."); continue; }, }; if number_of_players == 0 { println!("You can't play and not play at the same time. This isn't Quantum Theory."); continue; } return number_of_players } } fn create_player(name: String) -&gt; Player { Player { name, doubles_roll: 0, jail_count: 0, in_jail: false, } } fn jail_roll(JailedPlayer: &amp;mut Player) -&gt; bool { println!("{} is in jail", JailedPlayer.name); JailedPlayer.jail_count += 1; let first_dice = rand::thread_rng().gen_range(1, 7); let second_dice = rand::thread_rng().gen_range(1, 7); println!("First dice is: {}", first_dice); println!("Second dice is: {}", second_dice); if first_dice == second_dice { println!("{} got out of jail!", JailedPlayer.name); JailedPlayer.jail_count = 0; return false; } if JailedPlayer.jail_count == 3 { println!("You must pay $50 to get out now."); JailedPlayer.jail_count = 0; return false; } true } fn printnls(newlines: u8) { for _ in 0..newlines { print!("\n"); } } fn main() { println!("How many players?"); let number_of_players = get_number_of_players(); let mut player_name: Vec&lt;String&gt; = Vec::new(); for i in 0..number_of_players { let mut name = String::new(); println!("Enter the name for player number {}.", i + 1); io::stdin().read_line(&amp;mut name) .expect("Failed to read stdin."); player_name.push(name.trim().to_string()); } let mut player: Vec&lt;Player&gt; = Vec::new(); for i in 0..number_of_players { player.push(create_player(player_name[i].to_string())); } let mut turn: usize = 0; loop { loop { if turn &gt;= number_of_players { turn = 0; } if player[turn].in_jail { printnls(100); if jail_roll(&amp;Player[turn]) { println!("blah"); } } } } } &amp;#x200B;
[i](https://github.com/jcageman/calendar.git) wrote my first library this week for rust. Would anyone willing to give me some feedback on it? &amp;#x200B; [https://github.com/jcageman/calendar.git](https://github.com/jcageman/calendar.git) &amp;#x200B; Feedback i got so far: * for my interval type i can use something like [https://doc.rust-lang.org/std/ops/enum.Bound.html](https://doc.rust-lang.org/std/ops/enum.Bound.html) to make it more compact
Thank you I messed up, i was posting in playrust one xD . Im sorry
Line 101, `&amp;Player[turn]` should be `&amp;mut player[turn]`.
My approach to print out each and every combination would be recursive tree traversal. You basically start with a cent and combine it with each other possible coin. So cent + cent, cent + quarter and so on... Now you can subtract the results these combinations make from the original input and use that result to go deeper into the tree. The stopping condition would be, if any combination has a bigger sum than the value you try to represent. For example if you want to get all combinations for 20 cents and you combine a cent with a quarter, that result is invalid and there's no need to go deeper into the tree. So if you asked the program to show you 0.06€ with 1ct, 2ct, and 5 ct, you'd get the following: get\_combinations(\[1,2,5\], 6) 1 + 1 (valid, so we subtract 2 from 6 and go deeper into the tree with this:) \-&gt; get\_combinations(\[1,2\], 4) (we also remove 5 because 5 can not represent 4) 1 + 2 (still valid, so we go deeper) \-&gt; get\_combinations(\[1,2\], 3) 1 + 5 (valid but 6 - 6 = 0 and thereby the end of a branch) If you combine all traversals by depth, you'd get something like this: 1 + 1 + 1 + 1 + 1 + 1 1 + 1 + 1 + 1 + 2 1 + 1 + 2 + 2 ... 1 + 5 2 + 1 + 1 + 1 + 1 2 + 1 + 1 + 2 ... and so on. As you can see, some combinations may be the same but in a different order. You can fix that by sorting each combinations and then remove duplicates. Now, I'd even write a quick and dirty function for this but I'm on mobile. So I hope this makes it clear and understandable. I'm sure there are more efficient ways but this is the first example that came to mind :)
[It has not yet been stabilized yet.](https://github.com/rust-lang/rust/issues/33417)
Oh Jesus.
Yes, but you wrap the FFI in safe code, otherwise it's useless... So safe code can trigger UB.
I believe https://crates.io/crates/num-derive does what you want, assuming you don't mind a dependency on `num-traits`. Rust lets you specify enum discriminants manually: const FOO: u32 = 14; #[derive(FromPrimitive, Debug)] #[repr(u32)] enum Something { A = 3, // can be any constant B = 7, C = FOO + 1, } Working example: https://play.rust-lang.org/?gist=4c918b62d9d85af000d9ff5fafc7078b&amp;version=stable&amp;mode=debug&amp;edition=2015
Are there meaningful perf benchmarks between Cap'n Proto, Protobuf2/3, and Flatbuffers? I wonder what impact there really is between these. I get moving from Json to one of these could have significant impact, but once you're using even Protobuf, which is the 'slow' format of the 3, what are the real-world gains? Genuine question. My experience has been that moving to Cap'n proto or flatbuffers adds complexity to code, so I'd like to think I'm getting real perf back.
The main problem here is caused by the assignment. Even this code does not compile: fn consume(mut a: &amp;mut [u32]) { a = &amp;mut a[1..]; } And here are a few possible fixes: fn consume1(mut a: &amp;mut [u32]) { while !a.is_empty() { a = &amp;mut {a}[1..]; } } fn consume2(mut a: &amp;mut [u32]) { while !a.is_empty() { let temp = a; a = &amp;mut temp[1..]; } } And I thought I understand what's happening here, but by my understanding both of these should work too: fn consume3(mut a: &amp;mut [u32]) { while !a.is_empty() { a = &lt;[u32]&gt;::get_mut({a}, 1..).unwrap(); } } fn consume4(mut a: &amp;mut [u32]) { while !a.is_empty() { let temp = a; a = &lt;[u32]&gt;::get_mut(temp, 1..).unwrap(); } } However, `consume3` refuses to compile with the same error, and I have no idea why. So I'm afraid I can only show you a working version, but I can't explain why exactly it works.
Why would it be problematic to depend on `num-traits`?
What? Why? You're either processing them serially as in this case or if you're working in phases, you can filter the error results out from each incremental step and save them for later or whatever.
It feels very strange. It also kinda seems like a hack since I *think* it has to be checked at runtime? Maybe I'm misunderstanding that.
It is not checked at runtime. In fact there's not really any way to do so, without basically including a a full compiler with every program.
Ok. I guess I just misunderstood because the syntax looks very much like executing statements.
hey thank you! :-D \&gt; add personal workspace customizations? you can use your own Docker images for your Gitpod workspace. This works by putting a .gitpod-file into your git repo. In the .gitpod-file you can define what Docker image should be used when opening a Gitpod workspace. Inside your own Docker image you can have whatever tools you like: ripgrep, python tools, the exact python version you etc. If you don't want to install everything from scratch, you can inherit from Gitpod's default workspace image: [https://hub.docker.com/r/gitpod/workspace-full/](https://hub.docker.com/r/gitpod/workspace-full/) \&gt; Do you have any thoughts/plans like bringing up a test environment through k8 or something like that? You can create a Docker image with kubectrl inside and then connect form you workspace to you own Kubernetes cluster. You'll need to get the cluster from some cloud provider. Additionally you can use telepresence to make your Gitpod workspace-container act exactly as if it was inside your cluster. &amp;#x200B;
\&gt; lag we try to prevent lag by running Gitpod in multiple regions on this planet. Where are you located? \&gt; autocompletion Autocompletion in Gitpod should be better than "complete to any word seen" because the rust language serve (1) is integrated in Gitpod. Can you say what git repository you tried it on? &amp;#x200B; &amp;#x200B; 1: [https://github.com/rust-lang-nursery/rls](https://github.com/rust-lang-nursery/rls) &amp;#x200B; &amp;#x200B;
I'm biased as its maintainer, but I think it would only be a problem if you were trying to avoid non-std dependencies altogether.
I mean, it's pretty basic stuff, rust's datastructures are all well documented and explained in the book. Give it a try, it will explain a lot of things that you wouldn't even think it was possible (and that easy). Vectors are specifically in the 8th section (Common Collections). https://doc.rust-lang.org/book/2018-edition/foreword.html
They probably don't really grasp how generic works.
Could I suggest making it possible to specify the gitpod file inside the dashboard? I was just trying gitpod out with a project I use sometimes and although I could maintain a fork of it, being able to just tweak those settings without having to request the project maintainers to accept the gitpod file OR keep juggling a rebase on top of changes I want to make would be nice. It'd also make it much easier for projects that do integrate gitpod files to allow for users to customize their experience.
[cargo is the equivalent.](https://doc.rust-lang.org/cargo/getting-started/first-steps.html) you almost certainly don't need anything else.
oh, so this is the NPM equivalent for rust, awesome.
[Here is a very naive version which prints solutions:](https://play.rust-lang.org/?gist=abf108ad94f11861909864f4ba329fbd&amp;version=stable&amp;mode=debug&amp;edition=2015) but it will be very slow as it does not attempt to memoize or otherwise avoid work which has already been done. The solution used by the Rust rosetta code (and most other languages) is a \[Dynamic Programming\]([https://en.wikipedia.org/wiki/Dynamic\_programming](https://en.wikipedia.org/wiki/Dynamic_programming)) solution which is very fast, but does not compute individual solutions.
It's not strictly Rust, but I absolutely *loved* your post on [the `font-size` property](https://manishearth.github.io/blog/2017/08/10/font-size-an-unexpectedly-complex-css-property/). It's become my go-to favourite whenever I need an illustration of the fractal awfulness of software, easily outdoing the [previous champion](http://miksovsky.blogs.com/flowstate/2005/10/the_fractal_nat.html).
Here's something that's slightly optimized. You could at least use it as a starting point https://play.rust-lang.org/?gist=24f76375465d2279342eb5c305682d28&amp;version=stable&amp;mode=debug&amp;edition=2015
Could you hyperlink to the mentioned code?
Ah, now that I'm rereading that it sounds more ominous than I intended. There's no reason in particular. I suppose you might not want to add a dependency just to use a single function from a single trait, but Cargo makes it so easy that it's not really a concern. Especially since `num-traits` is depended upon by a lot of other crates, so there's a decent chance that your project transitively depends on it already.
That's a really good point about the features potentially going away. I always target stable just because I wouldn't want to make people download another toolchain just for my library, especially since I don't need anything specifically in nightly yet.
Wrap the ECS in a hash table, train a neural net to implement a reactive GUI, add a blockchain to make sure all your design contracts are met, and then give it a cute name for good measure.
How do I do a "press enter to continue" type of thing? I don't want to capture anything in stdin other than I suppose the enter key to continue the program.
Read a line and discard the result?
If I could do it without needing a variable, that'd be great.
A few weeks ago, I was lucky enough to convince my company to explore rust for our next mobile game. Since then I've been doing a lot of homework, going down some dead ends, and making a few pull requests! \`winit\` iOS needed some love to fix a minor bug, and remove the hardcoding of an opengles backend. \`gfx\` and \`metal\` needed a little bit of massaging, but were almost entirely there. &amp;#x200B; The community has been wayy more accepting of PRs than I expected. &lt;3
Wow really, that's super neat! Would be interesting to see what the performance comparison is like - not sure how expensive the gfx-rs layer is these days. Would be neat to get the DX12 and Metal support though.
&gt; The elm architecture is the most well accepted paradigm and it has been adapted in some rust projects: It's just MVC. 
I like the Filter Idea. also the approach of how Rust based frameworks are taking it more simple makes it more productive. but i think it's all about Community. will it get the community it deserves or not! 
Is there a way I can import `rustfmt` and use it like a crate? (I'd imagine it provides some method I can apply to a string?)
Why do you need the closure? This is enough: let value = self.info.entry(item).or_default(); if !value.contains(&amp;info) { value.push(info) } (Also, depending on expected numbers of items and ordering requirements, you can make it even easier by using sets instead of Vecs.)
gfx-hal seems so cool, I really want to get into it. Am I right in thinking that you have to more or less already know Vulkan in order to actually use it at this point though? As there's really not much documentation yet, but it seems to map pretty perfectly to Vulkan..
I tried it with [https://github.com/bofh69/rust-teris](https://github.com/bofh69/rust-teris) from Sweden using firefox. I'm a bit unsure of how our network performs though, they've blocked most everything but http/https and websockets to port 443 in the firewalls, but I don't notice much lag with websocket echo services, nor when writing on the console before starting the game. Is it not safe to share the URL to the running workspace, is it? cargo run starts the game (make the console quite big first). You play it with hjkl, space and quit. It is not much of a game though. Regarding the autocomplete; I tried to add code somewhere in game\_loop, where I wrote "win." and got functions belonging to Game as autocomplete suggestions, but when I tried now it worked correctly. Perhaps RLS hadn't yet scanned all the code and some fallback gave all identifiers? 
For that case, we have https://github.com/gitpod-io/definitely-gp. It hosts external configurations for projects on GitHub. Just make a PR and everyone will benefit from your configuration.
I've started playing with gfx-ll recently and I read about stuff like queues, descriptor sets etc. and all those things were documented in Vulkan docs. After a while I've decided to read a tutorial from vulkan-tutorial.com. I've read the first few chapters and so far it seems like gfx is mostly based on the concepts from Vulkan. I hope gfx devs are going to release the documentation soon though.
It sounds like you're approaching the problem from the wrong angle. &gt; a u32 that also happens to usually correspond to a nice name for human use The name of an Enum is irrelevant. Rust is not reflective. i.e. Renaming a variable in the source code should have no effect on execution. But i can think of 3 options. 1: array const names : [&amp;'static str;3] = [ "Zero", "One", "Two" ]; assert!(names[1] == "One") 2: do something similar to http status codes ( https://docs.rs/http/0.1.10/src/http/status.rs.html#43 ) 3: Serde 
Thanks for the feedback. I cannot reproduce it, unfortunately: https://ibb.co/fqS1DU If you have further details please file them here: https://github.com/gitpod-io/gitpod
Thanks for your reply. Here is my [code](https://github.com/revsic/AlphaZero-Connect6/blob/master/Connect6/src/policy/alphazero_policy/mod.rs#L200), but I already use gil acquire/release routine in my rust-python bindings. ```rust let (value_vec, policy_vec) = { // acquire python gil let gil = Python::acquire_gil(); let py = gil.python(); // convert parameter to python object ... } ``` And in my profiling, the cpu usage is used to allocate vector or convert pylist to rust-vec. But, I think it will be a good hint ! Thanks
I noticed some delay, though: https://github.com/gitpod-io/gitpod/issues/41
The author seems to be quite happy about it: https://twitter.com/bcantrill/status/1035335403186806784
Placeholder crates are usually trivially identifiable, especially some of the recent spam. While I haven't tried, I assume the crates.io owners would be responsive to manually removing them? ie. if I come along with a new crate, with demonstrable functionality and code, but the name is being squatted on, just ask them to remove the existing crate? The process for claiming a taken (but unused) name on GitHub is pretty painless, same process could be applied here.
Maybe a temporary conspiracy can succeed, but this mechanism at least protects the normal compilation of the programs depending on that crate. And then the conspiracy is certainly not sustainable, things will eventually get better, so there will be no problems. Besides, voting is not the point of this mechanism, we can do voting to resolve name confliction, we can do other things to resolve name confliction too, like let rust core team member choose which crate own the name and even freeze that name. The point of this mechanism is just we create a way to interoperate crate naming, without breaking any other crate's compiling process.
That’s fine for getting a basic setup working. But it’s a not insignificant security risk and it means that there is still only a single easily allowed config. How about this: if you detect in a user’s github repos that they have a repo named “definitely-gp”, you pull the config file from that repo?
My favorite part about the commit diff is how cargo simply replaces the makefiles. Cargo is just awesome! 
Gfx supports metal mostly (can run dota 2). Vulkan backend has close to zero overhead
Yeah, so cool! Looking at the new README has helped get me up to speed - I really like the fact that it has moved to being a thin abstraction over Vulkan!
&gt; the crates.io owners would be responsive to manually removing them. How? We can regard a crate with just one hello_world function as a placeholder crate and remove it. But can we remove a crate with two hello_world functions? So we need a mechanism of `name.uuid = "semver"` in where `uuid` is the only identity of a crate. With this mechanism, we can do everything to the crate names without breaking any other crate's compiling process.
Just did so.
 In Fancy Pants Editor, the Code Block doesn't have a syntax highlight. &amp;#x200B; In markdown, indenting by four spaces doesn't have a syntax highlight too. It seems Tripple backticks do the same as indenting by four spaces.
In the Old Reddit (which I think everyone still uses by preference) triple backticks don't work: https://old.reddit.com/r/rust/comments/9br8wv/can_we_support_anonymous_union_type_like/
Yeah the new reddit is an abomination.
I'm sure they'll be quite happy together.
Forever after.
I enjoyed browsing the 1000-line c linter written in perl. Bet that felt good to remove. if (/[^&lt;&gt;\s][!&lt;&gt;=]=/ || /[^&lt;&gt;][!&lt;&gt;=]=[^\s,]/ || (/[^-&gt;]&gt;[^,=&gt;\s]/ &amp;&amp; !/[^-&gt;]&gt;$/) || (/[^&lt;]&lt;[^,=&lt;\s]/ &amp;&amp; !/[^&lt;]&lt;$/) || /[^&lt;\s]&lt;[^&lt;]/ || /[^-&gt;\s]&gt;[^&gt;]/) { err("missing space around relational operator"); } Errm
Following your comment, I just added the build of a static library in [commit 04f855d](https://github.com/breard-r/libreauth/commit/04f855d005a879010066e2451bb9ac4408949644). Have fun! :)
The code is interestingly (if somewhat oddly) procedural, you can feel the C background e.g. the hand-rolled options parsing atop getopt (oddly so in fact, `Opt` seems entirely unnecessary, I guess it exists for readability?), the procedural management of duration/start/end (rather than case analysis), the match-y assertions on `statemap.ingest` and `statemap.output_svg`.
Wow, there is actual [rsx (jsx for rust)](https://github.com/DenisKolodin/yew#jsx-like-templates-with-html-macro), nice!
I'm interested in reading blog posts about your progress with that audio game, and why you made certain decisions, and any other audio experiments.. Wasm audio is possible but outside of the browser, you can do more expensive synthesis methods &amp; effects :) Btw, I'm currently working on a music live-performance software where I wrote the core in Rust and then wrote a ui-webapp for it, also in Rust, using Yew compiled to wasm.. I'm communicating via websockets (using actix-web in the server) using shared message types.. (And all the assets of the frontend are embedded in the executable.) 
In this case, you should build non-zero-cost abstraction, because you *have* to make futures work on all Rust targets.
I'm sure you mean well, but you really need to learn how to read my dude. Look through the posts of this subreddit. Do you really think this is about the Rust game? ;-)
Try /r/playrust instead.
I think learning Haskell will make you a better programmer period.
If Haskell can do anything you don't know yet, and you learn that thing, you'll probably be a better programmer afterwards, for worst case you'll learn how *not* to approach a problem. You might want to take a look at different applications of dependent typing as well. I found it to be quite an eye opener, but now I'm also unhappy when working with a "normal" programming language ¯\\\_(ツ)\_/¯ Here are some examples: * Idris/Coq/Agda/... are functional languages with a full dependent type system and a bit of a focus on theorem proving * ATS (and F-star, I believe) are dependently typed and include linear types as well * Ada has a strong emphasis on safety and while it does not have a full dependent type system, it can still parametrise array types by their range of valid indices, for example.
&gt; You will get a friend request and they will tell you to put "https://rustspin.com/#" on your profile Don't worry, this won't cause problems around here: as long as I hold mutable borrow to my profile page, nobody can read it. /s
Unless somebody hacks steam, but that would have to be in an `unsafe` block and likely get flagged during a code review. 🤔
Learning a functional language will probably make you a better programmer. It did to me. However, I'd suggest learning Erlang instead of Haskell. Erlang is where the functional features really shine - they are actually useful and make programming a great deal simpler. Plus Erlang has influenced Rust a great deal. Haskell, on the other hand... Let's put it this way: the most popular Jabber server, Slack backend, Discord backend and even cell phone towers run Erlang. As for Haskell, there's xmonad and a bunch of DSLs written in it, and that's basically it. This speaks volumes about the utility of the language. I can attest that https://learnyousomeerlang.com/ is an excellent course, and it's free. There's http://learnyouahaskell.com/ too, if you so desire.
&gt; I can attest that https://learnyousomeerlang.com/ is an excellent course I saw people in HN said it's sooo bad and they reach level of "plz do not read this book". in Haskell community Haskel for first princ. is the best book 
&gt; 2,886 additions and 6,246 deletions. 
Who said Perl was a noisy language?
Note that there is two, quite distinct ideas in Haskell that will make you better programmer: the other is programming in pure functions (functions that don't rely on external state and don't have side effects) and the other is the advanced type system. I find it very interesting that pure functional programming is to enable ultimate composability (referential transparency) whereas advanced type system are all about \*restricting\* composability only to places it actually makes sense (but preferably no further). These ideas support each other in case of Haskell, but they don't require each other. Rust has (not quite but increasingly so) an advanced, Haskell-like type system. That type system, formally speaking, is all about the upside down A's and backward E's. On the other hand, programming with pure functions is something that many functional programming languages have (that's basically the definition of functional programming!), even if they didn't have a type system at all. Rust does slightly encourage purity in the sense that it makes harder than your average language to have global mutable state, but it doesn't really pursue it to the end. (Which is arguably a strength of Rust, as a Very Practical Systems Language.) I think that yes, learning Haskell will make you better programmer because it forces you to uses some ideas you would do without when programming Rust, but that are very valuable ideas to know, even if you wouldn't use them all the time.
Let me share a few more applications that are written in Haskell: - [postgrest](https://github.com/begriffs/postgrest) - [Project:m36](https://github.com/agentm/project-m36) - [wire-server](https://github.com/wireapp/wire-server) - [matterhorn-client](https://github.com/matterhorn-chat/matterhorn) - [Stack](https://github.com/commercialhaskell/stack) - [git-annex](https://git-annex.branchable.com/) - [PureScript](https://github.com/purescript/purescript), [Elm](https://elm-lang.org/), [Agda](https://github.com/agda/agda), [Corrode](https://github.com/jameysharp/corrode/), [husk-scheme](http://justinethier.github.io/husk-scheme/), [Futhark](https://futhark-lang.org/), [LambdaCube3d](http://lambdacube3d.com/) compilers and the list goes on and on. A few cool libraries: - [Haxl](https://github.com/facebook/Haxl) - which helps facebook fight spam - [Reflex + Reflex-dom](https://reflex-frp.org/) - FRP for your browser - [Shake](http://shakebuild.com/) - A great framework for building build systems - [Turtle](http://hackage.haskell.org/package/turtle) - write shell scripts in Haskell And [a few companies that use Haskell](https://github.com/erkmos/haskell-companies). Also, I suggest using [Haskell Programming from First Principles](http://haskellbook.com) to learn Haskell and not LYAH. LYAH will not help you gain much experience with Haskell, certainly not practical one. 
Benchmarks of cap'n proto vs protobuff have been posted on this sub few weeks ago https://github.com/ChrisMacNaughton/proto_benchmarks/blob/master/README.md , they give quite an edge to cap'n proto. And I suppose flatbuffers have performances quite similar to cap'n proto
Its never a bad idea to do some functional programming in general. Another aspect why its good to have some basic understanding of haskell that a lot of interesting reading material about programming concepts use haskell or haskell inspired pseudo code for examples. Btw, i suggest you have a look at elm. Its quite similar to haskell, but a lot simpler and the error messages are A LOT friendlier. Its also a lot of fun to have shiny front end web stuff in the first days of learning the language instead of pushing numbers in lists around a terminal window ;)
Awesome! :)
Yeah, I'm not particularly convinced by the OP's rationale either. The status codes approach you linked sounds the closest to what they are after. My take on the problem spec is: "I want to assign special meaning to certain \`u32\`s, but not all, and give them user-friendly names". Then the status code approach seems to correspond exactly.
You make a great point! I like it. Perhaps i will do that in my code. Thanks for the suggestion! The purpose of the Mac address in my larger project was to create a unique (and reproducible) identifier for any given computer. Once my code ingests the mac address it will use that to identify the data it captures. Its not a perfect solution, i should probably be using a generated UUID type. That's planned in the future, but right now there are bigger fires. I do like your new-type approach, [its explicit, which is much better than implicit](https://www.python.org/dev/peps/pep-0020/). &amp;#x200B;
&gt; All programming languages can be described mathematically, there is nothing magical about Haskell that makes it "extra" math-like. No one would support the idea that PHP is "mathematical" in any meaningful sense. When people relate Haskell to mathematics, they are trying to communicate something about the culture surrounding the language, and this kind of perspective undermines that message. &gt; Why does Haskell have this crazy reputation that you need to study and understandall these theoretical concepts before you can use it? The community brought this on itself. It isn't necessary to learn any category theory at all to become proficient at Haskell, of course. But I don't think you can learn the language without reading at least a few academic papers and maybe learning the very basics of logic, (perhaps denotational semantics or something).
Erlang is a dynamically typed language and lacks the concept of traits/classes. If you are looking to reinforce Rust knowledge, Haskell has more in common with Rust and would be a better choice. That said, Erlang is a fine language. The concepts of share nothing concurrency and fault tolerance are well embodied here. Time spent studying Erlang would not be wasted. Thumbs up for learnyousomeerlang.
I think it is perfectly possible to become fully proficient in Haskell without ever being within a hundred yards of any academic paper. Logic works exactly the same in Haskell as in imperative languages.
Interesting that you mention Agda. Someone just posted https://plfa.github.io/ to r/ProgrammingLanguages and I looked at it briefly but it looks too much like a theorem prover to me and I wasn't so sure I wanted to get so deep into type theory as to define number sets with signatures, etc. How were dependent types an eye opener? It seems like much of the usefulness of this can be done using easier features of Ada (or SPARK for whatever Ada doesn't do).
https://GitHub.com/myrrlyn/tap-rs
https://GitHub.com/myrrlyn/tap-rs
The tap crate, https://GitHub.com/tap-rs, does exactly this
I wasn't under the impression that I needed to be a type theory or lambda calculus expert to learn Haskell, the real idea was to do the opposite and not study that stuff directly but learn as much of the practical results from it as possible. Tell me if I'm wrong but the reason I mention Haskell is that it seems like the goal there is to make it the kitchen sink of any useful idiom or concept anyone has ever come up with. Like there are at least 10 or something ways of defining Fibonacci in Haskell. I'm not sure if the same is true of Erlang for example.
I have tinkered with Erlang a bit a long time ago and that's the main reason I know anything at all about functional programming. The main reason I mentioned Haskell is that it seems like, whereas Erlang had more practical objectives, Haskell seems more like the goal was to create a kitchen sink of every feature that could possibly be useful. So I thought it might be more educational as to the range of ways to define and express things.
In the rls-vscode extensions, why is `rust.wait_to_build`set so high? I lowered it to 200, and the rls seems so much faster now
Only about 40 LOC of makefiles is actually in use, though.
Oh man, I've been anxiously waiting for this talk since Humio announced it on Twitter. Thanks for linking, I'd forgotten about it because of work stuff!
I'm learning it by going through vulkan tutorials and figuring out how it maps. You can generate cargo docs from the source which helps to find things. 
Haskell is fun and nice to learn, but Rust doesn't benefit from it in any unique way. A lot of the unique magic of what Haskell provides are hard to do because of a greater care for memory layout and just done in a less abstract way overall for efficiency.
Not really. &gt; I'd like to stick to things that are more practical than proving theorems or understanding why ZFC is soooo much better than ZF without the C. This is entirely unrelated to Haskell and functional programming in general. 
Oh wow, what a timing. I just started writing my own very similar thing yesterday. Just some months ago I gave up on tokio and switched to mio, then quickly started thinking there is a need for some simple callback library that can cover all the cases where futures is just complicated over-engineering. I uploaded my prototype at [https://github.com/spersson/looper](https://github.com/spersson/looper) . There's no documentation there yet but my basic idea was to do it all without any refcount sharing. For cases where one IO handler (event dispacher I think you called it) needs to add other event sources or perhaps trigger actions on other IO handlers (for example an incoming event on mpsc channel causes sending of message to all connected tcp clients) that would need to happen not via Rc-refcell shared ownership, but indirectly via knowing the token of other handlers and just queing up events to them, on an event queue that is passed around as a &amp;mut. &amp;#x200B; I will take a closer look at your code over the coming days and study more what the different design tradeoffs are. Thank you so much for sharing your work!
wow, this is awesome :D There might be interesting ways to assemble nom and combine existing parsers
Dependent types allow you to express pretty much any property you want as a type. In JavaScript, there are no types nor compile-time checking. In Java, you can have the type of functions from `Int -&gt; Int`, and that'll only type-check if your function indeed receives an Int and returns an Int. In Agda, you can have the type of functions `(a : In) -&gt; (b : Int ** b &lt; a &amp;&amp; b % a == 0)`, which receives an Int `a` and only type-checks if it returns a smaller divisor of `a`. By using that same idea you can check pretty much anything at compile-time, you can check and prove that your app users will never have a negative balance, or that your game will never be in a state you don't want it to, or whatever. That's a huge jump from Haskell.
I know, I ment that as an example of how I didn't want to get into stuff that was too unrelated. (I mean it's not *totally* unrelated as set theory is related to type theory and lambda calculus but it's getting kind of far away from anything practical.)
&gt; The only real limitation here is that the error types are not compatible which can cause some error information to be lost when going between crates. Maybe they could factor that out into a third crate and share it between nom and combine (and others).
Why aren't they using structopt-derive ? 
Duplicate. [Previous post and discussion](https://www.reddit.com/r/rust/comments/89aiyw/mesalink_a_memorysafe_and_opensslcompatible_tls/).
Yeah it's just my personal frustration about other build tools. It's really hard to use anything else after cargo 
I'm wondering what \[this\]([https://github.com/mesalock-linux/mesalink/blob/ab88b3c18545111b48d808905b1d35719f77ed1e/src/libssl/safestack.rs#L160](https://github.com/mesalock-linux/mesalink/blob/ab88b3c18545111b48d808905b1d35719f77ed1e/src/libssl/safestack.rs#L160)) does : &amp;#x200B; let \_ = unsafe { Box::from\_raw(stack\_ptr) }; &amp;#x200B; &amp;#x200B;
I don't know how to interpret that either. If this can introduce UB in safe Rust then it's just wrong.
I might be interested in helping. Please PM me! I write forensic data parsers for a living (normally in C++), and after writing a few parser prototypes in Rust my advice would be...consider what code qualities you want when maintaining this parser. What I mean in this case is that when you're writing binary parsers, it's WAY important to be able to debug things. Reverse-engineering in ANY form (and yes, there's going to be some even with an official spec) is already hard enough, and after doing this for a living I'd definitely optimize for life down the road as opposed to banging out code now. `nom` (and other parser combinator libraries, it's a hard part of the design) adds a lot of friction to rolling custom errors, especially with the macro-oriented flow. In my experience (and I welcome corrections from people who know more than me!) it's not trivial to bisect your debugging edits into code written against `nom` even AFTER you've gotten over the learning curve with the macro-based flow. Your tolerance for debugging in this way may be different than mine, but I'd definitely suggest trying to roll your own binary parsing before feeling like you NEED `nom` -- you might be surprised to find that it's not so bad. :)
Category theory or any math is not needed to use Haskell. There are some abstractions which sound scary at first, but it is easier to just see how they are used than try to force a bunch of CT concepts in a short period of time. Understanding those abstractions via category theory can be an OK approach for people/entities which are already comfortable with related mathematics concepts.
There's a no-op `drop` function in the prelude that might express this better.
Last time I tried structopt I couldn't make custom validation messages. I removed it instantly.
Nice. But now my brain which only ever sees the shortcomings of the world wonders the following: Could this be a custom derive macro? And then included in std? And then back-ported to apply to a bunch of container types? Would that be overkill?
drop will not free the memory. The code above would.
Re bench only on nightly: try the criterion crate
I I don't dispute that it will make you a better programmer over all, but if I was to make a list of the things you could do to improve at Rust specifically, learning Haskell would be quite low down on that list.
Rust was name after the fungus so I prefer infested. 
This is an understandable viewpoint, but my take is the reverse. Rather than math being a doorway to Haskell or any other language, Haskell is often a great doorway to the underlying mathematics of languages. I totally agree that you don’t need the mathematical basis before starting to learn Haskell—it’s just once you get there, the abstractions become ever more revealing than other languages. This also might just be correlation rather than causation. Because people who want to know more gravitate to Haskell, people who learn Haskell often have a greater understanding of certain abstract concepts. But hey, if that’s where the community is, it’s probably a good place to go.
I'm not working at Inria, I just found this PhD position about designing a framework to check memory-safe programming languages (Rust and Mezzo mentioned). So maybe it can interested a student here who's looking for a PhD in France.
I don't know. But maybe its just when I learned Haskell, made it have a profound impact on me. So I learned it in 1st year of university after doing some Java in high school. I thought all languages were C-like syntax and oh boy was I wrong. I was so lost in the first couple of weeks. Haskell challenges everything you know about "traditional" languages (Java, C, C++) and makes you re-evaluate basic principles, such as: types, variable assignment, algorithm construction. It still amazes me that quicksort in haskell can be like 3 lines of code. Yes, there probably are a lot of things that will have a more immediate impact on your rust programming. But learning Haskell (or any pure or at least very functional language) will, at least im my opinion, make you a strictly better programmer long term, no matter what language you choose. 
I guess i took the phrase "Dropping a raw pointer" too literally.
You can use a `struct Cb&lt;T: FnOnce&gt;(Option&lt;T&gt;)` and implement `FnMut` for this (which would use `Option::take` to extract the function and call it.
Maybe worth adding that this is only safe with pointers that come from Box::into_raw.
Coolness. I've come across your easyvst crate, your other stuff sounds interesting too!
Doctypes and custom entities should be cast back into the fiery chasm from whence they came :-p How is namespace support?
Oh never mind the readme contains that information (yes). Are you familiar with c#s linq/xml features? I imagine something like that could be done in Rust quite easily.
Well, in all fairness regular expressions have always been cryptic-looking. ¯\_(ツ)_/¯
&gt; Are you familiar with c#s linq/xml features? Never heard of it.
:D We will have to see, there are still a lot of parsers where detailed errors aren't important.
I hope DTD will be removed some day. And `xml:space` and whitespaces handling in general should be well specified or deprecated all together. 
Don't forget Pandoc!
Hmm. So let's say I have a file with some Rust code in it. I modify it using a program. Can I then pass the file to rustfmt? Or does the file properly have to be a part of a cargo project, upon which I should then run `cargo fmt`?
The compiler statically inserting the drop calls would consume no memory at all.
so, a counterpoint to that :) There are quite a lot of [ways to debug a nom parser](https://github.com/Geal/nom/blob/master/doc/making_a_new_parser_from_scratch.md#debugging-the-parsers). You can even [get a hexdump of data going into a parser](https://github.com/Geal/nom/blob/a88a6f8d3fe3cf41ef682bbfec1fd72f08edcf95/doc/error_management.md#debugging-macros). Parsers written with nom usually hold very well against fuzzers, since most of the data consumption and offset calculation is already handled. While handrolled parsers, even written by careful and experienced developers very often end up full of flaws. There are a lot of useful patterns for binary formats, like supporting TLV, permutations, big and little endian number parsers, and bit level parsers. Thanks to that, nom has been successfully to write a lot of binary format parsers, like [some used in suricata](https://github.com/rusticata), a tool used to track security issues in network flows. It is also suitable for [video formats](https://github.com/rust-av/). So, I tend to disagree with you, but as the author of nom, I'd like to see your code, I think I could get some insight to improve nom, or at least help you get it into shape :)
Any good pointers for how you built the iOS app in Rust?
Learning Rust made me a better Haskell programmer. Learning a pure functional language will make you a better programmer in general and some of that improvement will apply to your Rust skills.
There are more stuff I "forgot" :)
I watched the talk, yes :)
Probably difficult to agree on a common trait, at least not without a ton of work. The traits combine currently uses aren't that great even https://docs.rs/combine/3.5.1/combine/error/index.html#traits and have a rather ad-hoc nature about them.
Nice! The the complexity of vulkan, how much work has already been put into `gfx-rs`, and the deprecation (especially the deprecation) is a really good reason to look to rust right now. Tech stacks already have to change.
&gt;Why does Haskell have this crazy reputation that you need to study and understandall these theoretical concepts before you can use it? Example: [https://wiki.haskell.org/Zygohistomorphic\_prepromorphisms](https://wiki.haskell.org/Zygohistomorphic_prepromorphisms) &amp;#x200B; It seems Haskell was created to academics. That's why I like Rust so much, because it has the best things out of Haskell, leaving the complicated things outside. 
This discussion might also interest you: https://internals.rust-lang.org/t/extending-impl-trait-to-allow-multiple-return-types/7921
Does this deal with the Billion Laughs attack? Does it support external entities? https://www.owasp.org/index.php/XML_Security_Cheat_Sheet#Billion_Laughs
In my opinion, it's because words like classes, members, and objects are familar. The familiarity provides a some context, which terms like monad and functor lack. If you want to know more about what a monad is, you'll quickly run into the mathematical definitions. I do agree that the best way to understand the maths behind Haskell is to learn to use the language and its constructs first, just like kids learn to add, subtract, multiply and divide without studying the mathematical properties of those operations. Once you have a feel for using them, the maths involved will be easier to understand. 
True, but perl is designed to make you want to reach for them even when there's no reason. Perl: if ($var =~ /^prefix-/) { err("$var started with 'prefix-'") } Python (for instance): if var.startswith('prefix-'): raise ValueError("var started with 'prefix-'")
Why not learn Rust to be a better Rust programmer?
I'm working on a couple PRs that should make it easier. What I want to get in PRs in the next couple days. - Workaround metal calls that don't exist on iOS (just 2/3 of them are required for that example) - Running `glsl-to-spirv` in a build script, then `include_bytes!`ing the outputted SPIRV (maybe not a good fit for example code?) - Tweaking the `WindowBuilder` setup with these two lines use winit::os::ios::WindowBuilderExt; let wb = wb.with_root_view_class(class!(MTKView) as *const _ as *const _) What probably won't be in a PR - Building quad as a library and linking to it in an xcode project. I don't recommend building rust code as part of Run Script. Xcode sets a bunch of environment variables that will break `build.rs` scripts that compile C/C++ libs - `cargo-dinghy` apparently has some ways to automatically package up projects and send them to device, but I haven't spent much time mucking with it.
Nested/indirect entity references are not supported yet, so "yes". You will get an error. External entities are not supported and not planed. Recursive entities are supported and will lead to an error.
Depending on how complex you wanted to get, you could also store 3 `u16` or 6 `u8`s in your type, to reap the space optimization benefits. It'll be just as efficient, but probably a bit more workable, and you can still derive common operators: #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)] struct MacAddress([u8; 6]); This will probably make it easier to write a `Display` impl, too.
Well yea of course, but while doing so I encounter things like "enums are similar to algebraic types in Haskell" and they don't match other things I'm familiar with from other languages, so this inspires a certain desire to learn at least some of the things that inspired the design in Rust. Most of my lack of knowledge is in the types system area as it applies to functional programming. (Other functional languages I've used were things like lisp or erlang.) It's sort of like how you don't really want to learn about OOP from only learning Python.
I don't understand the question. Presumably OP already knows Rust (otherwise they probably wouldn't be trying to "get better"), so "learn Rust" isn't really meaningful advice. Learning a different programming language can give a person a new perspective on programming languages that they already know. For instance, I have seen several people remark on how learning Rust has made them a better C or C++ programmer.
English link: https://jobs.inria.fr/public/classic/en/offres/2018-01012 (there's a toggle at the top of the page, but hey) There's also a special condition mentioned, which I imagine may lead to some difficulty for foreigners (especially non-Europeans). If anyone in the know could share what it means exactly it could be useful. See: &gt; Defence Security : &gt; This position is likely to be situated in a restricted area (ZRR), as defined in Decree No. 2011-1425 relating to the protection of national scientific and technical potential (PPST). Authorisation to enter an area is granted by the director of the unit, following a favourable Ministerial decision, as defined in the decree of 3 July 2012 relating to the PPST. An unfavourable Ministerial decision in respect of a position situated in a ZRR would result in the cancellation of the appointment. 
Thanks, I'd seen those but didn't find them too compelling. It's something though.
Hey, it's `nom`s author! Yay! :D I would love to hear some tips! If I could use `nom` without the caveat I talked about above I DEFINITELY would use it. It's much, much easier to read `nom` usages than trying to fit lots of low-level parsing code in one's head! Responding to your suggestions: * &gt; are quite a lot of ways to debug a nom parser The docs you've linked here seem to have had an overhaul since I last looked (I last looked ~4 months ago...IIRC?), or maybe I missed them the first time. Thank you so much -- I'll be interested in porting some of my code over and seeing if I'm wrong. I'd love to be! * &gt; While handrolled parsers, even written by careful and experienced developers very often end up full of flaws. What flaws are you discussing here? It's much, much easier to avoid the problems I'm mostly worried about with C++ in Rust -- but I'm assuming you're talking about concerns above memory safety? Please PM me about my code -- I'll set up a repo with the code I struggled to scale out with `nom` and do my best to take advantage of any time you'll give me.
Srsleh...at this point, why isn't there a crate for combining arbitrary parser combinator crates into new crates?
I've fidgeted a bit with Rust and am curious if there's an equivalent of the C `strpbrk` which splits strings based on any one of a list of characters. Specifically what I'm doing is breaking a text stream into lines but setting some metadata on the line based on whether it was delimited by a newline or carriage-return. I struggled with this in Go as well and ended up with a tiny C shim that preprocessed the stream before feeding into the code. I could loop over the string myself, applying each character to a switch statement or something, but I believe there's an optimized and way more clever solution to the problem. It's also likely that I'm way overthinking it and trying to prematurely optimize a fundamentally simple task. Feel free to tell me that too. =D
The best way to become a better Rust programmer is to program and read Rust, period. That said, I believe it is valuable to learn an ML-family (for me, this was Scala) and C, in order to understand the two worlds that Rust (kind of) bridges.
Which would then mean the entire function should be marked `unsafe`, I'd think.
&gt;All programming languages can be described mathematically, there is nothing magical about Haskell that makes it "extra" math-like This seems like one of those meaningless "technically true" distinctions that takes liberties with what "math-like" even means. Haskell is *semantically* math-like. The obvious examples are function purity and immutability. &gt;Why does Haskell have this crazy reputation that you need to study and understandall these theoretical concepts before you can use it? Probably because these concepts are exposed and constantly flaunted. Monads are everywhere, and not just in practice, but in name. People use monads all the time in other languages, but are none the wiser. The idea that haskell is unapproachable is not undeserved, and simply saying "Go learn it, it's easy!" is a great way to make people just feel like idiots when they inevitably find it unapproachable.
&gt;https://rosettacode.org/wiki/Count\_the\_coins#Rust Great solution, thanks !
As I understand it, Inria made OCaml and use OCaml to write the theorem prover [Coq](https://github.com/coq/coq). Recently Inria released paper about [adding linear types to OCaml](https://arxiv.org/abs/1803.02796), which spoke glowingly of Rust. Now I guess they want to use Coq to prove some properties of Rust and/or OCaml. Neat!
In my case, definitely. Not only with Rust, but Functional Programming in general so that it's so much easier to learn new Functional Languages.
It's one of those things where at the start it looks like a ham sandwhich got in a fight with a mallet...then you start to understand what is going on....then you feel powerful as you start writing just a few characters to pull off amazing things...then you realise that you know speak computer, and your code doesn't make sense to any other human being except your fellow computer speakers. It's amazing and powerful, but I wouldn't use it for anything I would want any other human being to read/understand. Readability has value in a great many contexts. Terse has value in few.
First mention of Rust in the talk: 1:00:30; for those who want to skip to it.
Agreed. The one thing I would say is that Haskell has stuff like lazy evaluation so certain patterns will run fast in Haskell that won't in other languages.
I guess it comes down to priorities. Sounds like OP's priority is Rust, yours is programming in general. Haskell is one hell of a rabbit hole to jump down if your true interest is a non-gc'd language that strongly discourages using linked lists and that - to my knowledge - does not have tail recursion optimisations.
not strictly true, it's safe with any pointers that come from the same allocator, which is likely to be the global allocator. Which can typically used to allocate memory yourself via `std::alloc::alloc`.
If you want to learn functional programming, read SICP. If you want to learn type theoretic reasoning, read TAPL. If you want to program Rust, don't program Haskell.
It'll be called either omnomnom or regurgitate.
sfackler listed three attempts on plietar's iteration of the proposal: https://internals.rust-lang.org/t/pre-rfc-anonymous-enum/4806/2
There's no single function that provides that, but you could use [`str::find`](https://doc.rust-lang.org/std/primitive.str.html#method.find) to give the index of the next match, and then slice it like [this](https://play.rust-lang.org/?gist=5dcc4e5ac461a8fb40947092f62c2c1a&amp;version=stable&amp;mode=debug&amp;edition=2015). If you're using nightly, you can wrap it up in a [handy iterator](https://play.rust-lang.org/?gist=babbb6a756b517b9a2ededf9434fc98a&amp;version=nightly&amp;mode=release&amp;edition=2015).
The 5 line Haskell "quicksort" is not actually quicksort: https://stackoverflow.com/questions/7717691/why-is-the-minimalist-example-haskell-quicksort-not-a-true-quicksort#7718269
&gt; Example: &gt; &gt; https://wiki.haskell.org/Zygohistomorphic_prepromorphisms ​I've been using Haskell in big projects for a few years and I don't know what that is or hear people talking about it. It's mostly being linked by people that try to intimidate other people which probably don't know Haskell. &gt; It seems Haskell was created to academics. Maybe, it's still a darn useful language for practical applications. &gt; That's why I like Rust so much, because it has the best things out of Haskell Maybe some things, but Haskell definitely has a few really great things that Rust does not. Let's try not to spread FUD please?
It's not that bad. It's so-so, but hardly bad.
&gt; Let's try not to spread FUD please? I'm just talking about my personal experience, I tried to use Haskell, and just about I could finally understand monads I found the monad transformer barrier. I like Haskell too, but sadly it's not practical for me. However Rust only has the ownership barrier, once you dominate that, you can create code in a easier way (at least easier than haskell).
Little spelling thing I noticed: In the first 3 points of updates from the rust core, the word stabilise is written in 3 different ways (one of them is not correct in any English style afaik). 
Rust needs a local/movable reference concept. Something that can be updated when the container is moved, and that must refer to something local to the movable unit ... Making move the default semantic was a bold move *cough, not intentional*, and it pays off in a lot of respects, but a local/movable reference would solve most of the downsides that came with it.
Does it work on machine integers? I am reading Type Driven Development with Idris and so far I was able to prove things only on algebraic data types like `Nat`. Can you prove something about arrays? As far as I know, Idris lacks arrays.
The goal was to create a testbed language for FP research. It was and still is (imho) a resounding success, and Rust would probably look quite different had it not existed. I learned Haskell first and it helped learn Rust for sure, but I'd never go back to Haskell. It is still what it was designed to be, and I'm not an FP researcher. Try for example to figure out what the best practice is for error/exception handling, or how to do it across libs that have a different take on the matter. Take a couple aspirin first.
I can link scary-looking concepts too: https://doc.rust-lang.org/nomicon/hrtb.html
Fuck I wish this position would have been open last year :(
IMHO, the main benefit is its pureness. I makes it tedious to use side-effects everywhere so the programmer is forced to think hard about whether here is the right place for a database access or there is the right place to read the system's time (Sounds harmless? yeah, until one has to debug a stack of 20 null-pointer exceptions that happened due to a method that only causes a runtime error at certain dates. Rarely/Never gonna happen in Haskell). It forces one to write as many pure functions as possible. The CT learning can be useful, but most of it will be implicit. The constructs learned are basically design patterns like in OO but on fire: They are very general and type-checked. (Unfortunately not law-checked, so it is possible that a programmer does not keep the promise of his design pattern). This will deepen a mathematical view of solving a problem by programming, but I think the practical usefullness decreases rapidly when the language does not offer these constructs. Replicating moinoids, profunctors and isomorphisms in Java feels... wrong.
Interesting! But shouldn't a threadpool be able to handle more requests than a single thread? Why do I see the regression? I also tried your suggestion using the tokio runtime, but that delivers an even worse regression: ``` test a_1_request ... bench: 493,164 ns/iter (+/- 88,639) test a_1_request_varnish ... bench: 494,079 ns/iter (+/- 176,862) test b_10_requests ... bench: 2,764,238 ns/iter (+/- 539,468) test b_10_requests_varnish ... bench: 2,791,454 ns/iter (+/- 736,575) test c_100_requests ... bench: 25,099,743 ns/iter (+/- 3,289,924) test c_100_requests_varnish ... bench: 25,351,795 ns/iter (+/- 6,651,651) test d_10_parallel_requests ... bench: 6,219,904 ns/iter (+/- 9,117,715) test d_10_parallel_requests_varnish ... bench: 2,052,180 ns/iter (+/- 351,446) test e_100_parallel_requests ... bench: 26,660,365 ns/iter (+/- 29,415,783) test e_100_parallel_requests_varnish ... bench: 9,954,134 ns/iter (+/- 1,210,667) test f_1_000_parallel_requests ... bench: 124,075,967 ns/iter (+/- 15,442,296) test f_1_000_parallel_requests_varnish ... bench: 84,745,385 ns/iter (+/- 2,332,628) ``` While my server now can keep up with Varnish in serial requests, the parallel requests have worsened yet again. Sending 100 requests in parallel (1k requests total) is ~50% slower in Hyper 0.12 compared to 0.11. Also the serial requests (no parallel requests) have a ~25% regression. Something is very broken here, it is just not obvious to me yet where the problem is.
The feeling I've gotten is that it's not something I'd use extensively since it seems like the idea was to implement everything anyone has ever come up with (and probably implemented first in scheme/Racket/etc) except without the sugarless s-expressions. The problem is when you end up with 10 ways of doing everything you end up with something with a few too many ways of doing everything like Perl5 and pretty soon everyone is looking at code going "wtf?"
Nice blog, and nice article! Coming from Ruby and having almost no Rust experience, the angle is perfect for me.
Thank you very much for that work, I was fearing to have to do it myself and you're bringing back my hopes for iOS.
Welcome to nightly :) Some APIs got moved in `std` and the various async / await related crates are partially done updating to match the change... it should be working again in a few days.
I'm interested in your opinion on the top 2-3 things you could do to improve at Rust specifically. Speaking as someone who wants to get better at Rust. &amp;#x200B;
Hey Sergio Any chance these talks will be recorded and shared?
This helps a lot. My understanding of the entry api was poor, and this helps a lot. This is a way better/clearer solution. Thank you very much
Sorry :) I ended up figuring out how to use ‘failure’ better with much less unwraps
s/¯\(ツ)/¯/¯\_(ツ)_/¯/g 
Hey all, I’m new to Rust and wanted to share a small little project I’ve been polishing on for the last week. I was super pleased to see how all these projects fit together so well and were quite stable. I didn’t find many places showing them all together so I hope this offering to the community helps someone. My only wish was that it was easier to compile Diesel for PostgreSQL. I had to resort to a docker image to compile everything just right for AWS Linux. I really learned a lot from doing this. I’d really enjoy code suggestions if you see anything. Next up is building a far more complete site that has a locally running dev server to avoid pushing to AWS so much. If there are any Tokio experts out there, is it possible to drive a web server without a socket?
There was a old port of rar to java i'm still using in java projects. One gotcha i had to handle was the missing support for 'solid' archives. Well not missing per-se, i 'only' had too add a facade to make sure that when extracting a solid archive i 'obeyed the order' and if the user requested as a item 'earlier in the order' i had to reset the stream, and if he requested a item 'further in the order' i had to extract all the files between the cursor and the item into the void before handing out the stream.
This is a really great project. I even think it could make building easier on certain platforms where I feel like I’ve run into compiling libssl from source problematic. If this takes of for C libs, then I might actually feel comfortable dropping support of OpenSSL in favor of solely offering Rustls. I do wish the project was a little more upfront and center about the use of rustls for much of the implementation. First paragraph in addition to the section halfway down the page.
Are you building a library or an application? `main.rs` and `fn main()` suggest application, but the everything else suggests that you're building an API wrapper. For libraries, returning errors is unquestionably preferable to unwrapping. No one likes it when the library they're using panics on non-fatal errors.
Awesome! I'm using the same aws lambda lib right now for a project of mine. Nice work. The code looks good, wish I had suggestions, but nothing sticks out.
I sympathize but I'm dealing with a large Typescript project and I *really miss* being able to *actually* see what types are allowed where and when.
It's just called from an extern "C" function from C and tests. As stated, this is very common for when you have an object allocated in Rust and which is returned to C (usually be releasing ownership via [`Box::into_raw`](https://doc.rust-lang.org/std/boxed/struct.Box.html#method.into_raw)) and then makes it back into rust via from\_raw. It could, of course, be marked (and arguably should) but is hardly something of great concern from my perspective.
drop literally does what the code does (ends the lifetime of the memory): [https://doc.rust-lang.org/src/core/mem.rs.html#790](https://doc.rust-lang.org/src/core/mem.rs.html#790) `pub fn drop&lt;T&gt;(_x: T) { }` 
You could make the deprecated attribute conditional on some Cargo feature which you then enable in CI: #[cfg_attr(feature = "no-from-error", deprecated = "prefer specialized conversion to `From&lt;std::error::Error&gt;`")] I thought deprecated did work on impls though. I'll have to test it when not on my phone but are you perchance using `?`? The syntax sugar may not be triggeribg the deprecation lint, or perhaps it's using `.into()` instead, in which case the deprecation warning might not trigger either.
Yeah, using `?`. I had thought it worked on `impl` too, but it makes sense that it's just because of the circumstance. 
Do you mind testing my hypothesis by trying calling `.from()` explicitly? It won't help your situation much since you're trying to lint on implicit conversion but it'll be interesting to see if it does work or not. If it's not convenient I can try it myself when I get back to my computer.
I'm doing something similar for a board games by email service I run, which looks like: * Elastic Beanstalk + S3 for the web service * Lambda + API gateway for game logic (each game is its own function) * RDS (Postgres) for the DB * SNS for inbound and outbound email * Travis CI for CI and CD Was a bit of effort to set up but runs beautifully now. Planning to migrate to Kubernetes though - one of the goals of the project is learning and that's something I'd like to play around with.
Fun!
1. It doesn't have the performance characteristics of quicksort. 2. The original quicksort paper specifies that it is in place.
Honestly, I find lifetimes, borrowing, ownership, and control over layout to be considerably more complicated notions than most things in Haskell. And this is coming from someone who is working on the design of Rust as a language. Over time, I think there has been a trend to close the gap in what Haskell can do and Rust can't. Generic associated types and associated types are examples of this and I hope we will continue with this.
It is a shockingly smooth experience, frankly.
I hate to ask the obvious question, but what does this offer as an improvement over return values?
Learning Haskell specifically will help you in Rust. And learning Rust will help you in Haskell. The reason why this is so is because both languages have parametric polymorphism at their core as well as type classes (traits). Haskell has had *a lot* of influence and it shows. I would highly recommend learning both Rust and Haskell.
the one thing I'm thinking is wouldn't it be a better idea to make an exokernel and have the wasm vm be a library os kinda like [ExOS](https://github.com/gwoplock/ExOS)
Nice work! Here are some hopefully helpful comments: 1. I'd recommend making your code conform to `rustfmt` style guidelines as that is what most Rust programmers are used to reading, so it will help get the message (which was *great*) through more effectively. 2. In Rust, `if foo { bar } else { baz }` is an expression rather than a statement; this means that you can write things like `let quux = if foo { 1 } else { 3 };`.
What are the locked deps?
And errors coming out of macros tend to be confusing and frustrating.
I thought if I locked `futures-core-preview-0.3.0-alpha.3` to alpha.2, it would work, but that just gave me more errors. 
I think you're overvaluing how important native look and feel is. Windows is already like 12 UIs mashed together, and the web is thousands. Everybody has a different UI in Linux. Every game provides its own UI. And yet people manage. Most of the decisions you make in a UI are irrelevant once you've made it sufficiently usable. Native/Not Native is just splitting hairs on a luxury.
Have you tried it? I tried it. It had basically no useful widgets. And implementing them wasn't really doable, because the code was (for all intents and purposes) convoluted and undocumented.
Looks good!
So it appears that impls are *not* affected by `#[deprecated]`; though in other positions the compiler forbids the attribute altogether, on impls it doesn't even warn. It looks like stability is just not implemented for trait impls: https://github.com/rust-lang/rust/issues/39935 There is the open question of whether or not this is *meant* to work, though. I remember it being discussed in another issue but I don't remember the conclusion.
Good job! I'm interested in this kind of posts because I'm learning Rust too. Initially I thought it means Rust is 2 times more verbose than Python, but then I noticed in Rust variant there is a [careful input error handling](https://github.com/e14tech/rmonopoly/blob/master/src/main.rs#L13) which is [absent](https://github.com/e14tech/monolopy-dice/blob/master/monolopy.py#L39) in Python solution. Although Rust way of reading strings and parsing stuff from stdin is definitely more verbose than most mainstream languages. I'm learning through [codeforces challenges](http://codeforces.com/problemset) and my major complain about Rust as of now is in fact the need to copypaste [generic input scanner](https://pastebin.com/RYxxcsVp) to every problem file. If external libaries were allowed I would use [https://crates.io/crates/text\_io](https://crates.io/crates/text_io).
I was in a similar position, it was always on my todo list to learn Haskell but since switching to Rust I never had a need for Haskell and did everything in Rust.. At my job I had to port our Polymer frontend to something that works in IE, too. Since I wanted to use a statically typed language, I looked for alternatives. At first I tried Elm but it required a lot of boilerplate because of lack of something like traits/type-classes and components don't own their own state so it requires a lot of wiring, and the JS FFI sucks. So I started learning [PureScript](http://www.purescript.org/) which is like Haskell but strict instead of lazy, and compiles to JS. I learned it all from the free [PureScript book](https://leanpub.com/purescript/). It doesn't cover advanced stuff like lenses but there's [another book](https://leanpub.com/lenses) for that. Also the people in the PureScript Slack are very helpful. So if you're looking for a language that you can use to complement Rust, I'd suggest PureScript. I ported our Polymer frontend to PureScript using the [Halogen](https://github.com/slamdata/purescript-halogen/) framework (which is the most expressive frontend framework in the PureScript ecosystem, and much better than Elm, React/Redux etc.). Be warned though, after learning PureScript you'll miss higher-kinded types in Rust, especially when you're used to Halogen and then use Yew: https://github.com/DenisKolodin/yew/issues/350 PureScript is definitely worth learning (and more useful/complementary if you already use Rust for everything that's not a web frontend) but I wish we had HKTs in Rust so we could express the same kind of UI patterns in Rust that Halogen uses (to allow inline/async type-safe querying of child components etc.).
Interesting! A few things that can help you shorten the Rust one down: * `"\n".repeat(100)` helps you remove the `printnls` function * Making a small `input` function that does what the python one does would probably help * It's perfectly okay to have small blocks on one line, e g `else { break; }` can be on one line, but this is of course a matter of taste * Remove the game_loop comments in the middle :-) 
Hard? Yes. Dangerous? Yes. Better than C/C++ (and probably most language out there)? Yes. I strongly believe this is where rust can shine over any other
Not a rustacean but: I see no need for player vector to be mut if not for creation; so I would move creation to a function and return a non-mut vector.
Hello all, I am writing a program which actually should plot two variables with time. Since rust doesn't have any plotting libraries currently, I want to use python My question is, is there any crate where I can write data into a file with variables and values, such as "time=[1., 2., 3.]" and "vel=[1., 2., 3.]" and "title="Time vs velocity" Which could be easily read by python and able to plot
Looking great! I was working on a similar [project](https://github.com/shouya/ray), but I ended up begin reading a CG textbook before I can continue. Too much theoretical things to learn lol.
You can also redeclare a variable to be non-mutable. let mut vec = vec![]; vec.push(1); let vec = vec; 
In this case, the problem seems to be using regexps to parse expressions. I strongly suspect that that code will give an error on a relation operator inside strings and comment.
There's no actual official etymology behind the name "Rust". The fungus one is just one people like to grab onto.
Looks great! Just one question: why terraform? 
SPE3D right now supports the automatic download of links either out of a .dlc file or pasted in manually. Right now only Share-Online is supported as content provider (premium account). I'm really keen in your detailed requirements! Can you please open an issue at the repository [here](https://github.com/Roba1993/SPE3D) and describe in detail which features you need? (Which download sides/ Premium or Free account, etc.) I will read through them and try to make them possible :)
I found that repository on GitHub too. Do you have any experience which versions of RAR archives this library supports? From my perspective only the pre 3.0 versions.... Maybe I'm wrong here Oo? &amp;#x200B; It seems like you have some knowledge in this area. When you have time, please support the rust-rar project. To your point, I'm completely with you, the library should handle this detection and wrapping automatically.
I'm not a 'real' programmer so i'll demur on helping especially on a high complexity project like a compressor. I honestly can't recall if the library had any problems supporting extracting newer versions except for one thing i noticed that i'm not sure if it's the fault of the library or the fault of java png or jpeg support: Some (but not nearly most, like one in 2 hundred) images came out with the colors shifted. Still recognizable with wrong pallete. I didn't bother investigating if the bytes were different when extracted by the native and by junrar, i only used it to extract txt and images really.
[The code i was talking about is here.](https://github.com/i30817/bookjar/blob/master/subprojects/bookjar-decompress/src/i3/decompress/RarExtractor.java)
Good point! It actually works without the `Cb` struct (it would not have been possible implement `FnMut` on stable for it), but capturing the user's `FnOnce` in an option, in an `FnMut` closure: https://github.com/Smithay/calloop/commit/29f7e89b453cae3ba014bb26fa6d17f6598f3e85
It doesn't wonder me, because dynamic languages tend to need less code.
I've been coding for a little over a year ( I started with python ) and started RUST about two weeks ago - I too have noticed that everything I do in python is tiny (lines of code) compared with RUST... But, after running a few big (100,000 line) .csv files through Rust I think it's worth it. Thumbs up to everyone chiming on on the possible optimizations -- if there is one thing that's definitely the same about Rust &amp; Python it's that both of their communities are awesome, welcoming and are not only committed to developing the language but helping others develop their skills in it. 
Nice and brief summary of some important points to remember! Just out of curiosity, how would you describe the diffrence between the last two points? i.e. the difference between multiple immutable borrows and "share an object with multiple parties" using [std::rc::Rc](https://doc.rust-lang.org/std/rc/struct.Rc.html)?
As I said maybe they are just being a name vigilante and not trying to extort money? https://www.reddit.com/r/rust/comments/9aaanw/cargo_crate_name_reservation_spam/e57g1u5/
Thanks for the feedback! I haven't used rustfmt yet so this is a good opportunity to do so. I will use it and update the code examples in the blog post. I made a mistake calling it an if statement, I know it's an expression, good catch! I will update too :)
Not sure what you mean by that. In order to get a mutable reference to an object, the object must be mutable.
Check out the `structopt` crate - it's amazing! 😁
Thanks! The difference is that when using `Rc` you can **leave the current scope** and still be sure to get the access to the `Rc` wrapped data right. 
Good read! Thanks
Yes sorry, I mean you can make a non-mut vec to mutable object only if you use reference to object, right?
Impossible to distinguish, unfortunately. If you value keeping names for quality crates, you might be interested in my idea posted in this thread.
I don't think it's nitpicking. Without in-place sorting Quicksort isn't actually quick. Half the beauty of Quicksort is the way it leverages one piece of memory to do divide and conquer recursively and safely.
The simplest way is probably using the `serde` and `serde_json` crates to serialise the data as JSON, then read that back in using Python's `json` module.
To my knowledge there isn't something comparable yet. It would be fantastic if there would be though! Probably the biggest unresolved question is how to build automatic certificate renewal. [acme-client](https://github.com/onur/acme-client#library) exists, but it seems to require a bit of work to automate certificate renewal completely. But if you're interested in the topic, looking into combining acme-client and Hyper would probably be a good starting point! ✨
Happy Cake Day jackie_pwn_asses! Today you are You, that is truer than true. There is no one alive who is Youer than You.
Cool, I actually did the same thing a few months ago. Btw the guy from two minute papers created a [ray tracing course](https://www.youtube.com/playlist?list=PLujxSBD-JXgnGmsn7gEyN28P1DnRZG7qi) based on pbrt. I haven't watched it yet but it is probably good.
This is also something I've been thinking about. I'm not aware of any, and I may actually build one at some point -- but for now it's not so near the top of my to do list.
`Vec::with_capacity` could be the better choice. Or as you use of Python to I/O-bound, it will be possible to modify the code to call cpp-tensorflow model and python for only I/O. I will test it and thank you for your advice !
Do you mean vulkano's glsl-to-spirv crate? https://crates.io/crates/glsl-to-spirv Vulkano will most likely discontinue it in favor of shaderc-rs https://github.com/vulkano-rs/vulkano/pull/947
&gt; the argument and return type are established by type inference Is there a principled reason for why one doesn't declare those types, as one does in ordinary functions, or is the reason pragmatic, along the lines of "it matches how people will usually want to use closures"?
&gt; the argument and return type are established by type inference Is there a principled reason for why one doesn't declare those types, as one does in ordinary functions, or is the reason pragmatic, along the lines of "it matches how people will usually want to use closures"?
&gt; An example of this might have been to only fix one instance of `for i in 0..vec.len()` with a message "I saw this a few times, figured you might not know about it. You might be able to improve the rest of your Rust code with this pattern." I guess that's one way to see it, but it feels way too close to just opening an issue with "hey you should change these bits" and dumping the grunt work on the maintainer's feet. With a full but focused PR, I feel the maintainer can just close it if they don't care or want to apply it differently and merge it if they like the changes.
Wouldn't you need the OpenSSL package and tell the compiler to link that instead of your system OpenSSL? The last time I tried to build anything with OpenSSL + Raspberry Pi I had to pull the specific packages from Debian and set some environment variables. Did they solve that problem in the build script by now or is that just one step missing in your tutorial?
You actually can declare arguments' types using: |arg: &amp;T1, arg: T2| { ... } Not sure about the return type though.
i'm pretty sire that you can also declare the return type..
It would be less ergonomic but more precise; C++ lambdas work like this.
There's a principled reason for functions needing to be declared explicitly, which doesn't apply to closures - not part of public api 
[You absolutely can!](https://play.rust-lang.org/?gist=db896c4f43fa6d4732ebd8b20e2312e5&amp;version=stable&amp;mode=debug&amp;edition=2015)
I am a rust noob, but in my first project I used `serde-json` (the toml implementation had problems with enums, but I would try that first) and stored the default configuration as a struct in the source. When the configuration file was missing, I just serialized the default one and wrote it to the disk.
the [sozu HTTP reverse proxy](https://github.com/sozu-proxy/sozu) has the [sozu-acme](https://github.com/sozu-proxy/sozu-acme) project to request certificates and set them up automatically without restarting the proxy. It is still a command to run regularly (cron or whatever), but it could be a nice starting point for what you want to do.
Oh! Can such annotations include everything that an ordinary function declaration can have?
`impl Trait` is not accepted. But I guess any concrete type is.
&gt; `impl Trait` is not accepted. What is the reason for that?
I don't see how it's less ergonomic. Right now I constantly need to alias variables. How is that more ergonomic?
If you need a reference, someone's started doing the book in rust already. https://github.com/wahn/rs_pbrt
I'd use TOML. It's nicer for humans to deal with than JSON: it's more lenient about formatting (it doesn't require *exactly* n-1 commas in a list or map), and it allows comments. As for defaults, basically what NyxCode said: implement `Default` on your config structure, and use that if the user doesn't provide one. Can't help you with key bindings.
&gt; the toml implementation had problems with enums If you had the same problem I did: #[derive(Clone, Debug, Deserialize, Serialize)] #[serde(untagged)] pub enum PeepMarker { Circle { circle: PeepMarkerCircle }, External { external: PeepMarkerExternal }, } This lets you use `[peep_marker.circle]` which implicitly sets `peep_marker` to the `Circle` variant. It's a dirty, filthy hack... but it works! 
You don't need a hypothetical new syntax for what you want. I do this all the time with anonymous blocks. let foo = ...; some_api({ let foo = foo; move || { foo.something_here(); } }); foo.something_else(); It gives you the same scoping, but doesn't require single-use syntax.
The last problem is the hardest and doesn't really have a solution that I know of. You can lock things behind feature flags and make your code generic over traits you implement on A and B types, but your users must use the same version of A and B as you do.
As an argument type, it's impossible because closures can't be generic (except over lifetimes). As a return type, it's unneeded - `impl Trait` allows you not to name the return type, which you don't have to do for closures anyway.
&gt; closures can't be generic Perhaps the answer is obvious if you know more than I do, but why is that?
I've seen people use macros for this common pattern. Seems a valid use, because yes it's a pain.
It's not the question you asked, but I've used the [gnuplot](https://crates.io/crates/gnuplot) crate for simple plots. 
Ah, but when you _pass_ closures you need an explicit generic parameter using the right function trait.
Full-on Hadley-Miller type inference can deduce argument types (just as we have with closures) but there was a deliberate design decision to require functions to be explicit.
What I am looking for is basically a proper (singly-)linked list that can do O(1) insert/delete given that I have the pointer. Unfortunately, I can't seem to find a crate for this and the one in `std::collections` does not support the necessary operations. Does anyone of you know a crate that contains such a list?
In general, working with out params and error codes is vastly inferior to result types, and should not be encouraged. I'm sorry if I sound harsh. I think it's still cool that you wrote an rfc though.
The downside with the macro approach is that it breaks rustfmt and that's why I try to avoid doing tha tnow.
Perhaps I don't understand what you mean ... GHC can infer typeclass constraints, I'm not sure why rustc couldn't do the same for inferring trait bounds. There will be an additional problem with polymorphic mutable references but it can adopt the OCaml solution. Barring that though, inference should be able to work in a lot of cases.
That is a VERY neat trick!
Not sure what you mean. Rust's requirements for type annotations in function signatures is basically a compiler-enforced convenience. It enables a few nice things you can't easily do in OCaml, like variable-sized number literals without needing annotations, but otherwise it's more of a human requirement than a technical one.
Well that depends on what the goals are :). I've found that in Haskell, sometimes the function type gets too complicated and I can't get it right. So I delete the signature, ask GHC what the inferred type is, then copy it, and try to simplify it if possible. You can't do that with rustc right now. However, there is a big benefit to the current system -- you have the guarantee of being able to typecheck function bodies in parallel.
&gt; Variable-sized number literals Haskell has an Integral typeclass for integer literals and RealFloat/Floating typeclasses for float-like literals which mostly solves this problem. &gt; compiler-enforced convenience In a way, it is convenient for a library user, I agree. But you can have a compiler warning for missing signatures like in Haskell to get nearly the same benefit. For a library/application developer, it makes things mildly inconvenient because you can't just write the function body and automatically "fill" all the type signatures by asking the compiler. This is especially useful if your function type is more complicated than you can immediately understand.
Overall what I was saying was that statically and strongly typed does not imply you need annotations (at least, in a majority of cases) -- an example for this is demonstrated by the inference for closures that is already done by rustc.
My understanding is that you simply don't. You can't bind to C++ code, let alone C++ code using the the standard library. The solution here, i believe, would be to create C bindings to the C++ code, and then have Rust bind to those. The C Bindings should just call the C++ code, and take/receive pointers and do the appropriate casts internally. From Rusts point of view, it's an opaque pointer. Example extern "C" Class* className_methodName(Class* classPointer, [primitive args]) { classPointer-&gt;methodName([args]); } Of course, that gets pretty tedious real quick to do manually for everything you might want to use, but i don't know of any automatic solutions for this. If anyone else does, i'd love to hear about it.
&gt; You can have a function parametric over a type T that uses a closure that has T as part of its type. Oh, OK!
What does `&amp;out T` do that `&amp;mut Option&lt;T&gt;` doesn't?
Yeah, turns out the fix was quite easy. I just added that line and it works. 100% functional rust lambda now.
apparently you need to use whitelisting and opaque types: see the [c++ bindgen docs](https://rust-lang-nursery.github.io/rust-bindgen/cpp.html). If bindgen still can't handle the thing you need you can always write some simpler c-style helper functions and bind those.
I had already muddled through enough of Rust to realize that closures captured their environment through some sort of anonymous struct type. The real eye-opener in this article for me was the material about `'static`, a concept I must confess I failed to grasp because of the name. I'd managed to understand: 1. `'static` is the lifetime of `static` items; 2. `'static` is not outlived by any other lifetime; ...but failed to truly grasp that #1 is just an accidental, not essential fact about `'static`, and would never have imagined that a runtime-allocated and locally-scoped `move` closure can indeed have a `'static` lifetime. Help me check if I'm understanding this right: 1. Anonymous closure types have a parameter for the lifetime of the environment they capture, and no closure may outlive its environment; 2. A closure with a `'static` environment is one such that it is syntactically impossible (not just ill-typed!) to write a program where the closure outlives its environment. Some example cases: * A closure that captures no variables. * A `move` closure, because it's environment is owned by the closure.
Never seen blocks used like this. Interesting.
AFAIK it was a design choice. Rust tries to give you errors as closely to the point where tgey arise as it can. It would be unfortunate to break bunch of crates, just by mistypping method name and thus having different function type. Also how would you handle this case: ``` trait A { fn foo(&amp;self); } trait B { fn foo(&amp;self); } fn test(x) { x.foo(); } ```
That's pretty much it.
I just signed up for a free heroku account, want to deploy my actix based server that uses diesel with postgres (&amp; postgis).. Is there a guide for that too, somewhere? 
Well, when you say 'more', it just sounds like 'different' to me. I'd rather we spend our time learning to swim in the ocean instead of trying to boil it away. The cost of consistency could mean degradation of experience with alternative designs, and that's a steep cost, even if there is a decentralized way to implement it.
\&gt; Rust tries to give you errors as closely to the point where tgey arise as it can. I'm assuming that you're trying to imply that "allowing omission/inference of function type signatures \_can lead to\_ non-local type errors which are hard to debug" -- if that is the case, then I fully agree with you. However, this is not a problem in practice while writing Haskell because folks add type signatures once they've finished prototyping (or perhaps even before). \&gt; It would be unfortunate to break bunch of crates, just by mistypping method name and thus having different function type. I'm not sure why crates would break. Could you give an example? To be clear, I'm not saying that people should omit type signatures. IMO, they shouldn't. \&gt; Also how would you handle this case: \[..\] There is no sensible way to type-check it -- it should lead to a type error. You can make a very similar example with Rust as it is (without omission of function signatures): [https://play.rust-lang.org/?gist=eceb16f5944fedcc07ced6e5596eaef7&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=eceb16f5944fedcc07ced6e5596eaef7&amp;version=stable&amp;mode=debug&amp;edition=2015) trait A { fn foo(&amp;self); } trait B { fn foo(&amp;self); } impl A for i32 { fn foo(&amp;self) {} } impl B for i32 { fn foo(&amp;self) {} } fn main() { let z = [10.foo](https://10.foo)(); }
You can rename it on import with `use v8_sys::std as whatever;`, like so: https://play.rust-lang.org/?gist=eb11a218cff966487e082300c6efb40f&amp;version=stable&amp;mode=debug&amp;edition=2015
&gt; Well, when you say 'more', it just sounds like 'different' to me. The Clearlooks Ttk theme replicates the recurring design elements of the generation of Qt and GTK+ themes prior to "flat design" (which I've never liked anyway) that, as long as the colors are close enough, I can forget that it's not actually the same theme. The rest are very distractingly distinct in one way or another. &gt; I'd rather we spend our time learning to swim in the ocean instead of trying to boil it away. Agreed. That principle is why I'm using `git gui` even though there exist more Qt- or GTK-native alternatives. All of the potential sources of friction are tallied up and `git gui`'s UI design makes the not-quite-natice Clearlooks Ttk theme excusable. &gt; The cost of consistency could mean degradation of experience with alternative designs, and that's a steep cost, even if there is a decentralized way to implement it. I prefer the reduced stress of feeling the UI design fade into the background so I can focus on my data. That means making my applications' theming and UI and UX design principles as consistent across my applications as is feasible. Many of these apps based on things like Electron or React Native are as grating in one way or another as using a badly ported Linux application on Windows or MacOS. That said, if something really does have network interaction, hypermedia, and rich text as core elements of its purpose, I have no problem using a web-based app. (eg. I'm currently working on a browser-based unified-data-model PIM tool because it's less work than patching up anything else I could find to fit my needs.)
Are the parameters compile time or run time constants? The equivalent to a function pointer typedef in Rust looks like this //type alias for a function pointer type FuncType = fn (f64) -&gt;f64; //Function that takes a function as an argument fn foo (func : FuncType) {} If you just need a variable number of floats as an argument you can use a vector. If it's more complicated you can try using generics or traits, it depends on what you need.
Thank you! If I am understanding what I read correctly, normal functions can be coerced into closures. So a regularly defined function could also be passed using this syntax?
You can just use a vector then 
I'm writing a macro\_rules macro - is there anyway when a compiler error is generated (because the expanded macro leads to a compilation error) to specify which part of the macro argument (the span) the error points to?
When you say you have been using cargo, have you just used the basic one-line commands, or have you been writing [build scripts](https://doc.rust-lang.org/cargo/reference/build-scripts.html)?
Mutability of variables is almost entirely a compiler/human-only concern. It's not faster to redeclare a variable as immutable. It's only advantage is that you're telling the reader of the code that they do not need to worry about it being mutated later on in the same scope.
[Yep](https://play.rust-lang.org/?gist=7dd37f90b22f19dba61265a07db46356&amp;version=stable&amp;mode=debug&amp;edition=2015). 
 &gt;I'm assuming that you're trying to imply that "allowing omission/inference of function type signatures _can lead to_ non-local type errors which are hard to debug" Yup. This is exactly what i meant. Thank you for clarifying. &gt;However, this is not a problem in practice while writing Haskell because folks add type signatures once they've finished prototyping I agree with you, but one of the reasons i love rust for: it makes an error from what otherwise would be considered just bad code. Although this makes it not the best choice for prototyping. &gt;I'm not sure why crates would break. Could you give an example? My initial idea was about mistyping `x.bar()` as `x.baz()`, and having inferred `X: Baz` instead of `X: Bar`. If users of the crate update it, then they'll have a bunch of errors because they haven't implemented Baz trait. But the more i think about it, the less realistic it seems to be. &gt;There is no sensible way to type-check it -- it should lead to a type error. My fault. I might have been too fast with this one. 
I've been doing build.rs and was thinking that's the right way to go, since it would be cross platform. I've only used it for preprocessing, so converting assets and putting them in the right folders, and compiling libraries like SDL2. My concern is with external stuff. Say if I had a blender3d. blend file. I can use the commandline blender commands to convert it to an obj with texture and materials how I want it. But to do this I'd have to use the `std::process::Command` and that doesn't seem that elegant for me because it being a rust thing I'd except all of it to be rust. So should I treat build.rs like MAKE or is it just a helper for compiling dependencies and not really a "packager" 
Hurray :) might be worth a issue against the Readme, I imagine there are a lot of people who run into that particular gotcha 
you have to remember that in rust wvrrything is an expression. i use blocks like this in bash scripts too, and i wish every language had them. I'm often aurprised when i remember that javascript doesn't. 
I'd suggest sticking with `build.rs`. You can get _pretty_ close to a shell-like command syntax using /u/timcameronryan's [commandspec](https://github.com/tcr/commandspec/), which creates the correct `std::process::Command` for you. With regard to elegance—this is a tricky problem in _any_ language. Scheme-style macros (like the kind Rust has) are one type of solution.
This is mostly right. Rust got it slightly better than C by not having three separate meanings for `static`, but unfortunately we still ended up with two. `'static` has nothing to do with `static` items, yet it's still sometimes defined as "the lifetime that lives for the entire program". **False**. `'static` simply means "is not and does not contain any non-`'static` references". The only thing wrong in your post is that you _can_ construct a non-`'static` `move` closure -- by moving references into it. Like this: let mut x = 5; let rx = &amp;mut x; some_func(move || { *rx += 1; }); But a `move` closure won't _implicitly_ take references to the variables you capture, so it's much easier to make a `'static` closure. 
Im sensing a fundamental missunderdtanding of programming here, but I'm not sure where. The reason behind this is that Java does not consider some types as ref types. But there are ref versions of some type, i.e. Integer, Boolean. You cannot actual add base impls (or whatever the term for none-trait impls) to classes outside your packages. You can still implement trairs you own for primitive types though, thus the method: to_string
What does your multi dimensional array trait look like at the moment? 
Not sure what you're really asking, but I've used it in game jams and it's great.
/r/playrust
CMake is something that's both widely used and not too ancient (autotools) / non-scalable (bare make), learning it is practically useful in any case. If you are more interested in something fun than useful-at-work, then there are those new ~hipster~ build systems like Meson, that even support Rust natively. Ninja isn't something that needs to be *learnt*, it's a very low level build description that's generated automatically by higher level build systems like CMake/Meson.
You should be using cargo and build.rs
...and, if you need something beyond what `build.rs` can give you (eg. post-build tasks), check out [cargo-make](https://crates.io/crates/cargo-make). (It also supports a virtual `@shell` script runner which will translate a very limited subset of Bourne shell script to a Microsoft batch file if you run it on Windows.)
Hey, Not 100% sure what you mean by support. AWS is moving, at rather slow speed, towards fully dockerized environments. After ECS, it recently make it's kubernetes public. Lambdas are currently limited to a subset of languages, but I wouldn't be surprised if a docker version will arrive in the future. What are the current limitations you are encountering ?
Lots of the bits and pieces are "weird" only when considered from the perspective of a dedicated Java programmer. Through that lens Rust is *very* weird, though the sad truth is more than Java's view of the world is unnecessarily limiting. (Not hating on Java, much, it's the first language I learned. But it conflates lots of things that shouldn't be, and since it was marketed so hard even as a young language it never had a chance to correct them.)
The parameters are there because C doesn't have closures. Since Rust does have closures - the parameters should be passed as part of the closure.
You're welcome! If you haven't tried out `clippy`, https://github.com/rust-lang-nursery/rust-clippy/, yet I recommend trying that out as well; it can really help no matter your level of skill wrt. Rust :)
I've seen Ninja around so thought I'd give it a try, yeah and it looks like its something that generated from a build system. Didn't really seem to fit too well with what I was trying to do. Thanks for the reply! Though I'm interested in the new ~~hipster~~ build systems..
Fwiw, I read the "nothing in the type of Condvar" to mean that the type itself doesn't enforce the single-mutex property. You could imagine a Condvar owning an Arc&lt;Mutex&gt; for example, or some other pattern by which the type makes it impossible to screw up the usage, but that isn't the case. .. is what I took from the sentence.
There's been a few blog posts about this sort of thing, perhaps you could dig through previous This Week In Rust posts?
A minor note: Python does allow `(8).__str__()` or `8 .__str__()` (note the space before the period). The input `8.__str__()` fails only because the Python lexer interprets `8.` as a floating point literal, regardless of what follows. The Rust lexer is a bit more clever and performs some lookahead.
I believe the YouTube hello rust channel has one
1) It has a reduced overhead (no need to store a discriminant for the enum). 2) It ensures a write-only contract, (especially useful for Os managed resources, such as hardware interfaces) 3) It can provide a way to initialize a variable in place
Yes, this RFC does not encourage the use of out params for error codes, only for direct initialization and to enforce a write-only contract in an unsafe-free way.
If all you're doing is `use ::v8_sys`, this definitely sounds like a bug in `uniform_paths`. Have you filed an issue in the rust repository?
Return values have to be moved around, &amp;out params can be used to directly initialize values. &amp;uninit can be used to modularly initialize a value *in place*, and also removes moves. Moves can be expensive for large types. That said, this is NOT a replacement for return values. This is an optimization when you would move something around a lot, or are initializing large values. Also relying on the optimizer to optimize out moves is not robust.
The fact that Java dispatches methods by boxing it's data on the heap and bundling them with vtables which are chased to find the corresponding instance method... is a peculiarity of Java. The fact that it also has 'primitive' types which *don't* do this is a further peculiarity. As the author points out, in Rust `8.to_string()` is just sugar around a static function call. We know the exact type and function at compile time, so why wouldn't it be? Primitives in Rust are simply the base types you can use to build other types, they aren't otherwise special. And the less said about Python's 'object' 'model', the better.
Actually `fn a(&amp;self) -&gt; &amp;B` would be inferred as `fn a(&amp;'a self) -&gt; &amp;'a B`. The lifetimes of returned references have to be bound to the lifetime of references that are passed in. If there's only one lifetime being passed in, then there's only one possible lifetime that could be given back. This is why the compiler infers `fn a(&amp;'a self) -&gt; &amp;'a B` from `fn a(&amp;self) -&gt; &amp;B`. If there were multiple lifetimes being passed in, like `fn a(&amp;self, other: &amp;A) -&gt; &amp;B`, you have to specify which lifetime `&amp;B` is bound to, either the lifetime of `self`, or the lifetime of `other`.
That's true... but this literally just a single boolean in a few cases. It's not a boolean for every value, nor is it even a boolean for everything with a destructor, and they only exist on the stack. Even other systems languages are usually fairly okay with throwing "random" extra stuff onto the stack, e.g. stack protectors. Additionally, I don't think there's any other opt-in switch that changes the semantics of code and especially not the control flow (correct me if I'm wrong), and it doesn't seem like this would be a valuable use of developer time, nor a valuable way to break that rule, given how this seems unlikely to have a noticable affect on most code (again, correct me if I'm wrong). I could totally imagine a clippy-style lint along the lines of "this value is conditionally moved here and so requires a dynamic drop flag, consider also dropping it in other branches", but I can't see Rust having an actual language rule that gives (implicit) static drop semantics, at this point.
Primitives in Rust aren't special (or at least, not this way). All types get called like this (except for trait objects).
You're right! According to the [lifetime elision rules](https://doc.rust-lang.org/nomicon/lifetime-elision.html), if there is only one lifetime, Rust will bind both references to the same lifetime! Thanks for correcting!
Welp, I've got a lot more learning to do just from looking at your code lol.
I did.
Well for one thing your using println!(). Calling it many times in a loop like that is a bad idea, it's not very fast I think. I think using the stdin functions would speed it up, but don't quote me on this
I recall reading that println is heavier than printf, or at the very least it does something different with stdout. Maybe it does locking when printf doesn't? 
Python doesn't really have primitives. It has built-in types, but that really just means that a type is implemented directly in the interpreter; that you don't have to write any code or import any external module to use it. Python integers totally have methods, and behave just like every other type.
That's a good suggestion. I'll dig through and see what I can find.
Thanks, yeah I'm leaning towards PyO3 at the moment based on what I've seen.
Post the code you already have? There's also [reqwest](https://crates.io/crates/reqwest), which I find a little more ergonomic and is built on Hyper.
&gt; I was curious about the speed between the two languages This is a very hard question to answer, if it can even be answered. But I can certainly tell you that the comparison programs you provided are not good choices. You mention "All the program does is count up by one." I'm not sure if you literally believe this, but your programs mostly spend their time printing, not incrementing an integer. More importantly, you're benchmarking `printf` vs `println!`, parts of standard libraries that should never be in the hot path. I don't mean to be rude, but drawing any inference from these example programs is in very bad form, whether or not the inference turns out to be correct.
Try this use std::io::Write; fn main() { let stdout = std::io::stdout(); let mut lock = stdout.lock(); for counter in 0.. { writeln!(&amp;mut lock, "Hello, world! The counter is: {}", counter); } } There may still be differences in what these do, like flushing.
so good, thank you heaps for this
Yes, even JavaScript has a big surprise there: primitives are passed by value, while everything else is passed by reference.
Note that by exploiting the runtime internals, you can actually run Rust on Lambda: https://github.com/srijs/rust-aws-lambda
&gt; And the less said about Python's 'object' 'model', the better. I'm actually curious what your opinion is on this.
I don't blame them for making this mistake, I'm sorry if I came off like that. But I would hazard that a lot of println's complexity is due to format!()
Looking for r/playrust?
Thanks, I think hyper is too much for what I'm trying to do (make a few API calls). I ended up being able to set a custom header with reqwest pretty quickly/easily. You're right though, that doc page is clear and I'd already looked at it. I just can't seem to figure out how to connect that with the [Client examples in the docs](https://hyper.rs/guides/client/advanced/). 
This isn't unique to Rust at all, though.
So `8.to_string()` seems to be like this: lea rax, [rip + .Lbyte_str.u] mov rsi, rax ; Cool stuff right here call &lt;T as alloc::string::ToString&gt;::to_string@PLT I'm a bit surprised by this part, for two reasons: 1) It's not calling i32.to_string() but something that looks like a trait object. Shouldn't we do static dispatch here (even in debug mode)? 2) When looking at `.Lbyte_str.u` (or rather, the corresponding value in [playground](https://play.rust-lang.org/?gist=cc2b32d914f4c9bbbec23d46377a6d06&amp;version=stable&amp;mode=debug&amp;edition=2015)), all I find is zeroes. I was expecting something like a vtable or data pointer? 
[removed]
Redox supports multiple displays?!
Not really, it's mirrored.
Pictured is a T520, a P50, and a custom desktop running Redox baremetal
&gt; `jackie_pwn_asses!` I spent more time than I'd like to admit trying to make sense of this rust "macro" joke. 
Yeah Just saw this stream - playrust doesn't allow live stream,, its not my stream so not sure why but cheers all the same. 
Chromium has a tool called GN for that (stands for Generate Ninja 😄)
The compiler won't let you do that. An immutable object cannot be borrowed as mutable safely.
It's better not share, but incorporate. In some dedicated repository (if it's about third-paty crates) or bh sending a PR to the rustc itself (if it's about stdlib).
D'oh, you're completely right. So if I have one `8i32.to_string()` and one `9i64.to_string()` then I end up with two functions having the exact same name. Argh, that's confusing... And here's the other mystery: .Lbyte_str.v: .asciz "\b\000\000" How can this be "8i32"? Well, first `.asciz` means to add a null byte at the end, so that's why there are three instead of four characters. `\b` is not hexadecimal for anything - it stands for backspace which translates to the decimal value of 8.
Ahh. Yes that is what I'm talking about, good to know about shaderc-rs! Have you found out if the compilation to SPIRV can be done on device? FWIW, glsl to SPIRV conversion in a build script is actually what I'd want to keep the app size small.
Does Redox do that? If so, it still counts ;) Or is it the setup you have it in?
I think the gpu just does that by default
Thanks for the post. I learned a lot after reading it. It seems the accepted answer to this [stack exchange post](https://softwareengineering.stackexchange.com/questions/189856/is-garbage-collection-needed-for-implementing-safe-closures) is wrong. &gt; As the other variables, rust closures come in various flavors. Stack closures, the most common ones, are for one-shot usage. They live on the stack and can reference anything. Owned closures take ownership of the captured variables. I think they live on the so called "exchange heap", which is a global heap. Their lifespan depends on who owns them. Managed closures live on the task-local heap, and are tracked by the task's GC. I'm not sure about their capturing limitations, though.
It is wise to be thoughtful of taking in new dependencies, but looking at reqwest's \`Cargo.toml\` file, it appears to be on current versions of major libraries, so it's probably fine. I use reqwest as well, so if it's got some bus-factor issues I'd be curious to see what you saw that indicated it wasn't as well maintained.
I am trying to parse an rss feed using the rss crate. I have this &amp;#x200B; `extern crate reqwest;` `extern crate rss;` `use rss::Channel;` `use std::io::BufReader;` &amp;#x200B; `fn main() {` `let uri = "`[`https://newrustacean.com/feed.xml`](https://newrustacean.com/feed.xml)`";` `let mut body = reqwest::get(uri).unwrap();` `let channel = Channel::read_from(BufReader::new(body)).unwrap();` `for item in channel.items().first() {` `println!("{:?}", item.enclosure().unwrap().url());` `}` `}` &amp;#x200B; I can get the first audio link using first(). What if I want to get the second or the third or more than one? The documentation says channel.items returns &amp;\[items\] which I think is a reference to an array. Maybe I am mistaken. I tried channel.items\[0\]() but It doesn't work. Can someone point me in the right direction. &amp;#x200B; Also, the rss documention says rss can get a feed directly from the url but I haven't been able to make that work either so I used reqwest. &amp;#x200B; Thank you in advance for any help. &amp;#x200B;
rustc: Trait bound is not satisfied; consider adding a where bound me: It's already there? 0\_o Troublesome impl: impl&lt;'a, T: FromPest&lt;'a&gt; + Sized&gt; FromPest&lt;'a&gt; for PhantomData&lt;T&gt; { type Rule = T::Rule; const RULE: T::Rule = T::RULE; fn from_pest(pest: Pair&lt;'a, T::Rule&gt;) -&gt; Self { let _ = T::from_pest(pest); PhantomData } } Error: error[E0277]: the trait bound `T: FromPest&lt;'a&gt;` is not satisfied --&gt; src\lib.rs:36:5 | 36 | const RULE: T::Rule = T::RULE; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `FromPest&lt;'a&gt;` is not implemented for `T` | = help: consider adding a `where T: FromPest&lt;'a&gt;` bound error[E0277]: the trait bound `T: std::marker::Sized` is not satisfied --&gt; src\lib.rs:36:5 | 36 | const RULE: T::Rule = T::RULE; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `T` does not have a constant size known at compile-time | = help: the trait `std::marker::Sized` is not implemented for `T` = help: consider adding a `where T: std::marker::Sized` bound = note: required because of the requirements on the impl of `FromPest&lt;'a&gt;` for `std::marker::PhantomData&lt;T&gt;` [Full source on GitHub](https://github.com/pest-parser/pest_deconstruct/blob/ea4e96ed865784847f5bc5c5c2ac47009ac271d4/src/lib.rs#L34-L41)
Rust is supported on AWS. Just build your application for linux and it should be able to run 99.9% of the time. You can upload and run binary files on AWS.
If that's a big surprise, then so are rust's `Copy` and non-`Copy` types. To be fair, I won't say these are inconsistent or surprising. They are just the design of different programming language and newcomers have to learn.
Yes, and what's more, if a closure doesn't capture anything, you can coerce it to a regular function, so you can create an array of functions without having to either box them, or declare every single one separately: let t: Vec&lt;fn(i32) -&gt; i32&gt; = vec![|a| a + 1, |a| a * 2];
It seems like relying on RVO is reasonably robust in Rust, specifically, since it can do all the lifetime analysis stuff that other languages don't do and can inline that stuff in a pretty straightforward way.
There's nothing special about primitives here -- you can do the same with other unboxed types, like `struct Foo(bool, u8);` C++ does the same thing, it's just that there's no syntactic mechanism to impl on primitives in C++. Java's actually the outlier here -- it performs dynamic dispatch on _everything_ so it needs to be able to dereference things to find methods -- but many languages have some level of static dispatch. I feel like there's some misunderstanding of what a primitive _is_; in Java primitives are unboxed but that is not the defining property of primitives. Rust doesn't autobox things so this question is kind of irrelevant. It's also worth noting: Not all Rust primitives are unboxed! `Box&lt;T&gt;` in fact [is a special kind of primitive](https://manishearth.github.io/blog/2017/01/10/rust-tidbits-box-is-special/), and in the past `String` and `Vec&lt;T&gt;` were also primitives. 
Nah. Objects are also passed by value. It's just that the value *is* a reference, so mutating it mutates through a reference.
You might want to look into using GDB/LLDB for now. The issue isn't just with datetime types, it's with Rust doing a lot of things differently from C/C++. Look at the last line in your debugger screenshot, there's an enum like `Option&lt;T&gt;`. The debugger has trouble with understanding enum discriminants. Some features like trait objects [require changes to the debugger's source code](https://github.com/rust-lang/rust/issues/1563) to work properly, so it's unlikely Microsoft will (for now) add Rust support in their debugger.
If "on device" means on an iphone then I have no idea.
But why is format more complex than a simple printf format? The compiler could translate to simple concatenation and basic formatting in code. Why is it complex?
This is kool. The logo itself needs a designer. It'd be extra dandy if the design would incorporate the gear.
The point is that this subreddit is about the programming language "rust" and not the game "rust". 
8..__str__() works
I don't think `size_of_val` is what you want here, it's just telling you what size the structure is on the stack, not the pointer..? See https://play.rust-lang.org/?gist=41aa9e9950b74dfcc7c84e23576c432f&amp;version=stable&amp;mode=debug&amp;edition=2015 `*const Fat&lt;[u64; 3]&gt;` is 8 bytes, whereas `*const Fat&lt;[u64]&gt;` is 16. 
Good point, I was thinking about it. Would be nice if every crate could have its own visualisation files. My visualisation for duration could indeed be submitted to rustc itself. One repository with a natvis per crate that can be bundled into one.
This will increase my understanding of rust
Thanks for the information! I will deep dive into the Java-unrar lib and try to understand what they are doing in detail. Java is at least a language I had in the university some years ago.... From the RAR author perspective is legally okay to develop your own decompressor. Compressing is something which is only allowed by RAR itself. I'm also not a 'real' programmer, I just do something in my personal time :)
What are GATs? 
Maybe just drop the 'R' and make it smaller.
Or drop the "R" without adding anything.
I'd guess the differences aren't due to the formatting part, but due to locking stdout to prevent torn writes in multi-threaded applications. There might also be flushing related differences, though I think the C code flushes as well, so that's probably not the case here.
If you're considering wrapping what amounts to less than 10 lines of bash/Dockerfile/etc with cmake/make, I might recommend visiting your doctor instead.
I think the point is that static dispatch is the default in Rust. This applies to primitives as well, so they are not "weird", but rather consistent. Java and Python only have dynamic dispatch, so they are quirky with their primitives, and it seems the author expected similar quirks in Rust.
That's a float not an int
Thanks, 
Please do! One of the great strengths of rustc is its helpful error messages; it's fine if one cannot understand the concepts behind an error message, but the error message should give you all the information you need to either fix it right away, or google said concept.
I wonder how dropping the "R" and then replacing the "o" with the remaining logo would look.
Good to know. Thx
So, basically, Java is a bit weird language - I always felt that way 😀. Anyway it's nice too see how learning Rust helps author look under the hood and discover more efficient ways things can be.
Does that mean they support arbitrary binaries?
[removed]
player is mutable, is te vecor containing it that i suggest to make immutable
thanks, quite informative. Personally i also had issue with pure rust crypto liba as missing some curves i need.. soon or later i will find the right project to start with
[removed]
This kind of code is also valid in other modern languages like Kotlin. Kotlin wraps Java primitives in its own type system to get rid of the Java `int` vs `Integer` distinction, so you can write extension methods for methods.
There's also [cHTTP](https://github.com/sagebind/chttp) as an alternative, which is a libcurl wrapper. (Full disclosure: I am the author.)
How is your experience with running rust binaries using go lang? is it great?
Hello all. I'm considering picking up a lower level language to use while I learn a little more about what's going on closer to the hardware, and while I'm at it learn certain topics more in depth, starting with data structures and algorithms, generally I think I want to build a solid foundation in one language as I build out my understanding of programming and CS. As you may imagine, I'm far from an experienced developer, I know a bit of Python, a little JS and C. Would it be a bad idea to try using Rust for this, or should I go with something more traditional like C++ - or something else entirely? 
Good point.
I didn't know that. Neat!
A common alternative I've seen is let vec = { let mut vec = vec![]; vec.push(1); vec };
As others pointed out, std::fmt is slow. You could try my crate [fast_fmt](https://crates io/crates/fast_fmt), but if I remember correctly, stdout isn't implemented yet.
[compiler explorer](https://godbolt.org/z/WJXdrY)
whyyy?
`void*` is not a "_variable number of parameters of the same type_" - it's a pointer to anything. And because it can point to anything, you need to pass it to something that knows what it points to in order to use it. In this case - the `function` field of a `struct gsl_function_struct` should know how to deal with its companion `params` field. This emulate a closure. When you create the `struct gsl_function_struct` you create a parameters struct which manually captures the environment (or captures anything else - you do it manually anyways) and a function that knows how to work with it, and pass them together as an higher order function. Here is a small example of how it can be used. For such a simple case it's probably easier to loop manually, but a usage complex enough to justify the code overhead of emulating closures in C will be too big to show here. #include&lt;stdio.h&gt; #include&lt;stdlib.h&gt; struct gsl_function_struct { double (* function) (double x, void* params); void* params; }; double* map(double* numbers, int length, struct gsl_function_struct mapper) { double* result = malloc(length * sizeof(double)); for (int i = 0; i &lt; length; ++i) { result[i] = mapper.function(numbers[i], mapper.params); } return result; } void print_numbers(double* numbers, int length) { printf("["); for (int i = 0; i &lt; length; ++i) { if (0 &lt; i) { printf(", "); } printf("%lf", numbers[i]); } printf("]\n"); } double* power_and_addition(double* numbers, int length, int power, float addition) { struct mapper_params { unsigned int power; float addition; }; double mapper_function(double x, void* params) { struct mapper_params* params_ = (struct mapper_params*)params; double result = 1; for (int i = 0; i &lt; params_-&gt;power; ++i) { result *= x; } result += params_-&gt;addition; return result; } struct mapper_params params; params.power = power; params.addition = addition; struct gsl_function_struct mapper; mapper.function = mapper_function; mapper.params = &amp;params; return map(numbers, length, mapper); } int main() { double numbers[5] = { 1.1, 2.2, 3.3, 4.4, 5.5 }; print_numbers(numbers, 5); print_numbers(power_and_addition(numbers, 5, 3, 6.6), 5); return 0; } (please excuse my lack of memory management...) Note that `power_and_addition` uses the `void*` parameters to "capture" `addition` and `power`. I could, of course, put anything there - it doesn't have to be limited to existing variables - but with language supported closures you can also declare new variables just to capture them. Here is a similar implementation in Rust - that uses a closure. I've ignored some stuff I could use (`f64::powi`, `Iterator::map` and `impl Trait`) to make it more similar to the C version - with the main different being the usage of closures: fn map(numbers: Vec&lt;f64&gt;, mapper: Box&lt;Fn(f64) -&gt; f64&gt;) -&gt; Vec&lt;f64&gt; { let mut result = Vec::new(); for number in numbers { result.push(mapper(number)); } result } fn power_and_addition(number: Vec&lt;f64&gt;, power: usize, addition: f64) -&gt; Vec&lt;f64&gt; { let mapper = move |x| { let mut result = 1.0; for _ in 0..power { result *= x; } result += addition; result }; map(number, Box::new(mapper)) } fn main() { let numbers = vec![1.1, 2.2, 3.3, 4.4, 5.5]; println!("{:?}", numbers); println!("{:?}", power_and_addition(numbers, 3, 6.6)); } Since Rust has closures I don't need a special struct - but internally the closure I send contains the same info as the one sent in the C version - a pointer to the function and (a pointer to) some fields needed by the function.
Indeed. Java is the one standing out, really, in that its few built-in value types can't be method call subjects. I think Go is an other big one? I could be wrong, but I think none of its builtin types have methods and it's not possible to define methods on non-package-local receivers or on interfaces.
I have a tuple struct: struct Vec3&lt;T&gt;(T, T, T); how do I implement std::convert::from such that I can convert Vec3&lt;T&gt; to Vec3&lt;U&gt; where U: From&lt;T&gt;. I tried: impl&lt;T, U: From&lt;T&gt;&gt; From&lt;Vec3&lt;T&gt;&gt; for Vec3&lt;U&gt; { } but I get conflicting implementation in crate \`core\`: \- impl&lt;T&gt; std::convert::From&lt;T&gt; for T;
Damn, you're right. I was on mobile so I couldn't try it out
Hi, co-author of the rust-aws-lambda crate here. It’s great to see folks pick up our work and share the code / provide feedback, so thanks! We’re aware that compiling for AWS lambda is a bit of a painpoint, and it’s something we’re actively working towards improving. FWIW, we just merged a PR yesterday that adds more doco and examples for docker-based builds. A thing that I’ve been hacking on this weekend is better support for the type of API Gateway integration that you are using in your project here. I just [pushed the first cut of this](https://github.com/srijs/rust-aws-lambda/commit/2ca835544d5413e72e22281263e5d3c4410bcc6c), in case you’re interested in giving it a shot. If you want, I can also try to send a PR your way to integrate this, just let me know! When you say ‘drive a hyper::Server without a socket’, I’m not entirely sure what you mean (and for what purpose). Could you go into more detail there?
I don't think you can. When `T` = `U`, you'd have two applicable implementations of the trait, and Rust won't allow that. Best you can probably do is just provide a `cast` method or somesuch. Or, if you're *really* set on using `From`, you could use an intermediate type (*i.e.* convert `Vec3` -&gt; `Temp`, then implement `From&lt;Temp&lt;T&gt;&gt; for Vec3&lt;U&gt;`).
Also you can use &amp;out to enforce a write only contract in a way the type system cannot easily copy. For example struct Foo { pub public: u32, private: u32 } How to enforce that sometimes you can only write to public, but most of the time you can read and write.
C++ as well, although there's been discussion about somehow unifying free and member function call syntax since the CLang times, I guess. Of course, C++ doesn't have a way to add methods to existing user-defined types either. Free functions are often preferred anyway unless there's a need to access private state.
Yes. That's a true fact about regex.
Another 10 out of 10 episode!
If all you need is to run a standard set of commands, maybe with some simple parameters, I recommend [Just](https://github.com/casey/just), although IIRC it doesn't have perfect Windows support (yet).
Personally I'd suggest C, if you're on a quest for deeper computer science insight. But you could go either way (Rust or C). Here's why. Given your comment, about wanting to learn more about the bare metal underneath, it kinda seems like you want to code an OS. Doing that certainly teaches you about the bare metal. And it flexes a _lot_ of fundamental data structures. My assumption may be wrong, but I'll stick with it and hopefully my comment is applicable anyway. Coding down to bare metal is stupidly easy with C. As is implementing most common data structures. I could write a linked list in C with ease in a handful of lines of code. Rust would take more thought, and even then many forms of linked lists can be exceedingly difficult to write in purely safe Rust. You can drop down to unsafe Rust to do it easier, but it'll still take more lines of code and thought. C has a rich history. Most all of modern computing is built on it. Learning and using it will give you insight into why things are the way they are today. And more appreciation for our advanced tech like Python and Rust. Examples and documentation on how to do low-level X, Y, or Z are plentiful in C. And the debugging infrastructure for low-level C hacking is robust. Last time I tried to write something low level in Rust and then debug it, it was ... awkward. That may have improved by now; not sure. Rust is built first and foremost with the idea of providing powerful, zero-cost abstractions. You're meant to use it to write high level code that compile down to something as performant as anything you could write in C. That's amazing. But for _learning_ that's not as useful. And while you can write low-level code in Rust and throw the abstractions away, it's not Rust's _primary_ goal. So it's a path that's less tread, and thus less ergonomic. (To make my point clear. In the real world, I'll always vote for pure Rust implementations, even for operating systems, embedded, etc. where you need to write down to the metal. Because even at the metal Rust as a language and compiler provides a lot of niceties that make the low-level code you have to write more _robust_ compared to if you had written them in C. But I'm advocating for C in the context of _learning_, because coding low-level in C is easier, more straight forward, and more historical.) So I'm recommending C because it'll be easier to learn low level stuff with it, and it gives you a nice taste of history. And having C in your toolbelt will always be useful. But there's also a reason to choose Rust. If in addition to wanting to learn low-level computer engineering, you're also interested in learning a useful programming language for use afterwards, you may opt to use Rust _anyway_. Low-level stuff will be a little bit more painful, but maybe that's okay. The biggest plus here, however, is that as of today there already exists a handful of really high quality tutorials and examples on how to write an OS from the ground up in Rust! And because they were so recently written, they're very modern codebases. If you search for similar tutorials/guides for C you're going to run into a lot of stuff that targets, for example, 32-bit machines which ... isn't really applicable these days :P So today you can follow along with these Rust guides, learn a bunch of low level Rust, and a bunch about low-level computing, all at the same time.
You're taking a reference to something you own, then trying to pass both the thing you own and the reference out. This is *never* going to work; it's fundamentally not compatible with how Rust manages memory. If it *did* let you do this, it would invalidate the reference held by the implementation of `lines`. Your only choice is to not write that code, and do something else instead. For one, you could [split the function in two](https://play.rust-lang.org/?gist=de8f3a3a3211421f0c6cd6558e505648&amp;version=stable&amp;mode=debug&amp;edition=2015) so that the first function constructs and returns something that contains `command_stdout`, which will then be owned by `main`. The second function then borrows from *that*. The alternative would be to write your own version of `str::lines` that *owns* the string rather than borrowing it. Or finds the line break manually.
It looks like a child made it, right?
O is for oxygen. Nice
you will probably find this part of the Rust Reference helpful: https://doc.rust-lang.org/reference/expressions/call-expr.html#disambiguating-function-calls see also the note in that section and the linked RFC at the end
Did he say rusticians? like beautician
I tried making an alternative implementation [here](https://github.com/hello-rust/show/pull/45) (creating new maps and calling union on them in a reduce). Would be interested in someone who knows what they're doing (read: not me) wanted to benchmark this or write an even more different implementation.
As they say, there is nothing more permanent than temporary. Yes, you start hacking and get something working fast -- next thing you know a part of the business relies on that in production... If you leave all unwraps and expects in code -- that would be go's version ditto. One can probably improve this using failure crate.
&gt; So should I treat build.rs like MAKE or is it just a helper for compiling dependencies and not really a "packager" build.rs runs before the final build artifacts are assembled, while with make you can run stuff after the compilation as well. There have been proposals to add cargo support for a post-build.rs script, but they have all been turned down since. I suggest you call cargo from a makefile, and use make for any post-processing steps or any non-library related sources. Putting the resource processing into build.rs is bad because IIRC build.rs also runs for stuff like rls or clippy, which shouldn't need this at all.
Can you give a more complete example?
https://play.rust-lang.org/?gist=15c78cb1c9a31d08d3fa7d94368048c0&amp;version=stable&amp;mode=debug&amp;edition=2015 The trait method had a `self` reciever so it was consuming the NumberWidget value which was not possible since that value is unsized.
Your trait wants to take `self` by value, but there are two problems with that: 1. Function argument is a trait object, which is `!Sized` value. That is, `widget_operations` does not now the exact size of the value behind the reference, which is fine because it only has to deal with the reference. However, when you want to call `get_number` you need to now sizes of all parameters to be able to call it. That's the reason for the first error. 2. Your function takes argument by reference. So the value is only borrowed, but you want to move it out - so you get the second error. You can fix this in two ways: 1. Change `get_numbers` to take `self` by reference. 2. Don't change the trait, but make `widget_operations` take the parameter by generic type, instead of as trait object: fn widget_operations&lt;T: NumberWidget&gt;(nw: T) { ... } To decide which solution is better you'll need to think about `NumberWidget` trait. Does calling `get_numbers` need to consume the widget it's called on? If no, use first solution. If yes, use the second.
Thanks. Do you know what makes std::fmt slow in this basic case? I had also assumed the macro and traits would let this be fast. 
I think the more idiomatic Go code you'd see in the wild for this kind of scenario would be using channels rather than passing in the map, and wouldn't spawn one new goroutine (or thread in Rust's case!) per command line argument - you'd instead use a task pool. Also interesting to see that the Rust version falls back to using outside libraries while the Go version uses the Go standard library only... Seems slightly unfair to me, as the two programs aren't really a fair comparison.
I only skimmed the GitHub issues and roadmap -- does it support FastCGI?
&gt; Also interesting to see that the Rust version falls back to using outside libraries while the Go version uses the Go standard library only... Seems slightly unfair to me, as the two programs aren't really a fair comparison. It's more a difference of philosophy than a difference language. Go comes with batteries included, so it's idiomatic to keep to the standard library; especially given its relatively poor package management. Rust comes with good package management and a deliberately small `std`, so it's idiomatic to pull in 3rd party dependencies. I don't see any unfairness there.
Is there no way of asserting T != U so that the definition is safe from that ambiguity?
But it shouldn't be slower tho. The problem here is that the rust version that calls println is slower than the C version that calls printf
Update: Filed a [Rust issue](https://github.com/rust-lang/rust/issues/53908) to address the unhelpful error.
I understand how anonymous types in C work, and I understand why you're comparing it to a closure. What I'm disagreeing with is that OP isn't using the GLSL struct as a closure, and they aren't trying to capture their environment. Simply using a type alias for a function that accepts a vector as an argument is sufficient. 
The main issue is it uses trait objects internally, so it has the problems caused by dynamic dispatch. Additionally, stdout in Rust locks the stream each time. As far as I know, printf in C does it too, but I guess the locking might happen multiple times in case of Rust. (Or more than in C.) Kind request to those wanting to downvote: could you please explain the reason behind downvoting? I'd love to improve my communication, but I'm unable to see what is the reason I'm being downvoted. :(
Thanks! Btw, do you already have plans for how the editing in Xi will work? E.g. will it be inspired by Vim, Sublime Text or [Kakoune](http://kakoune.org/)? Or will the editing experience be totally left up to the different UI frontends that are using the Xi core? Kakoune is an interesting evolution of the modal editing concept: &gt; vi basic grammar is verb followed by object; it’s nice because it matches well with the order we use in English, "delete word". On the other hand, it does not match well with the nature of what we express: There is only a handfull of verbs in text editing (delete, yank, paste, insert…​), and they don’t compose, contrarily to objects which can be arbitrarily complex, and difficult to express. That means that errors are not handled well. If you express your object wrongly with a delete verb, the wrong text will get deleted, you will need to undo, and try again. &gt; Kakoune’s grammar is object followed by verb, combined with instantaneous feedback, that means you always see the current object (In Kakoune we call that the selection) before you apply your change, which allows you to correct errors on the go. http://kakoune.org/why-kakoune/why-kakoune.html --- I think it would be cool if Xi could work like a cross-over between Sublime Text and Kakoune. There's also another interesting project, based on a neovim core which makes it work similar to VSCode: https://www.onivim.io/
Thanks for the comprehensive answer, especially the design decision bit as I'm still figuring that out for Rust. I figured out the reference thing after a while, but it ended up highlighting some poor design on my part (thinking of things too much like structs with data, and less like objects with methods, leading to getting into borrowing traps a lot) and I ended up refactoring a bunch of it so that I was doing more calling methods to do work and less directly modifying struct fields. I'm hoping this'll help me keep ownership scopes in better check.
haha, I agree it might not be needed for such a small scaled project, but I was thinking more of using this small thing to play with different systems and figure out what works best.
&gt; My personal hope is that once we wrap up work on the MIR borrow-checker (NLL) – and we are starting to get close! – we can start to think about self-references and how to model them in Rust. I’d like to transition to a Polonius-based system first, though. What's "Polonius"? I've read that post ("An alias-based formulation of the borrow checker") before but it doesn't mention "Polonius"..
Thanks for the suggestion, tested that. With Hyper 0.12, current_thread in the example server, rustnish and the benchmark code: ``` test a_1_request ... bench: 404,544 ns/iter (+/- 76,139) test a_1_request_varnish ... bench: 496,506 ns/iter (+/- 58,646) test b_10_requests ... bench: 2,254,271 ns/iter (+/- 491,662) test b_10_requests_varnish ... bench: 2,738,153 ns/iter (+/- 451,015) test c_100_requests ... bench: 21,212,313 ns/iter (+/- 6,240,095) test c_100_requests_varnish ... bench: 25,091,225 ns/iter (+/- 2,756,588) test d_10_parallel_requests ... bench: 2,175,054 ns/iter (+/- 902,021) test d_10_parallel_requests_varnish ... bench: 2,670,715 ns/iter (+/- 375,557) test e_100_parallel_requests ... bench: 10,356,026 ns/iter (+/- 3,172,349) test e_100_parallel_requests_varnish ... bench: 13,446,007 ns/iter (+/- 1,480,462) test f_1_000_parallel_requests ... bench: 103,056,643 ns/iter (+/- 20,178,800) test f_1_000_parallel_requests_varnish ... bench: 116,460,142 ns/iter (+/- 4,308,353) ``` Old Hyper 0.11: ``` test a_1_request ... bench: 361,274 ns/iter (+/- 82,046) test a_1_request_varnish ... bench: 483,029 ns/iter (+/- 73,047) test b_10_requests ... bench: 2,094,918 ns/iter (+/- 375,726) test b_10_requests_varnish ... bench: 2,636,597 ns/iter (+/- 334,773) test c_100_requests ... bench: 18,781,164 ns/iter (+/- 3,311,875) test c_100_requests_varnish ... bench: 24,602,224 ns/iter (+/- 3,397,456) test d_10_parallel_requests ... bench: 2,064,934 ns/iter (+/- 563,021) test d_10_parallel_requests_varnish ... bench: 2,528,772 ns/iter (+/- 388,665) test e_100_parallel_requests ... bench: 9,935,970 ns/iter (+/- 2,844,076) test e_100_parallel_requests_varnish ... bench: 12,799,160 ns/iter (+/- 1,430,808) test f_1_000_parallel_requests ... bench: 99,506,000 ns/iter (+/- 18,912,943) test f_1_000_parallel_requests_varnish ... bench: 113,512,371 ns/iter (+/- 8,902,206) ``` Good: we are consistently faster than Varnish again, yay! Bad: overall 3% conformance regression since Hyper 0.11 of the hello server and/or the client benchmarking code. So in my single computer (but 4 CPU core) scenario Hyper is only able to compete with Varnish if we eliminate Tokio multithreading. Varnish is multithreaded with 2 threadpools and potentially very many threads, why can it handle that so much better than Tokio? Just for kicks I did a [proxy prototype with actix-web](https://github.com/klausi/rustnish/blob/actix-web-test/src/lib.rs) and tested that: ``` test a_1_request ... bench: 850,921 ns/iter (+/- 160,601) test a_1_request_varnish ... bench: 491,303 ns/iter (+/- 93,077) test b_10_requests ... bench: 4,681,433 ns/iter (+/- 820,323) test b_10_requests_varnish ... bench: 2,688,944 ns/iter (+/- 337,940) test c_100_requests ... FAILED test c_100_requests_varnish ... bench: 25,815,695 ns/iter (+/- 3,817,378) test d_10_parallel_requests ... FAILED test d_10_parallel_requests_varnish ... bench: 2,638,493 ns/iter (+/- 806,195) test e_100_parallel_requests ... FAILED test e_100_parallel_requests_varnish ... bench: 13,446,694 ns/iter (+/- 2,021,638) test f_1_000_parallel_requests ... FAILED test f_1_000_parallel_requests_varnish ... bench: 116,439,195 ns/iter (+/- 6,492,382) ``` So. Much. Worse. And even panics with 500 errors here, I'm probably using their HTTP client wrong. Changing `workers(1)` in the actix-web server did not seem to have an effect. I think I'll stick to Hyper for now :-)
I've used custom parsing functions but I don't know if that's a good fit for erroring.
You're probably looking for /r/rustjerk.
Thank you so much for the in depth response, it's been quite enlightening. &gt; it kinda seems like you want to code an OS Well that wasn't really a goal I had in mind, but now that you mention it I reckon that would be pretty fascinating! I think I'll probably start looking more into that. Particularly what you said regarding zero cost abstractions and how they're intended to be used makes me think that of the two I *would* probably be better off sticking with C, so I'll most likely go that route for now. I'll be sure to stay conscious of avoiding particularly outdated material too. Thanks again!
&gt; Another key thing to understand is that the borrow checker does not “control” when drops happen – that is controlled entirely by the syntactic structure of the code. The borrow checker then comes after and looks to see what could go wrong if that code were executed. Whoah. Somehow, I've been using Rust for _years_ (just for hobby projects &amp; keeping up with changes, never anything serious), and I never realized this. I've never felt like I've had a fluent understanding of the borrow / lifetime checking, and would often be frustrated by these kinds of "dropped too early" errors, because it seemed to me like the compiler was saying, "I need this thing to live for just one more operation, but I decided to throw it in the garbage for no reason beforehand, and that's your fault." I was annoyed that the borrow checker wasn't "smart" enough to just hold on to a value for a little bit longer if it was still needed by the very next _n_ methods chained off of it. Reading that clarification that it doesn't actually decide where the drops happen clears up a lot for me.
One my phone, so haven't been able to test this, but Cursor&lt;String&gt; would wrap ownership of your string. It implements BufRead, which offers you "lines()", again taking ownership of the cursor. So, I think something like `Cursor::new(String).lines().map(...)` will do what you are looking for.
It's odd that this article doesn't mention `Pin` at all. Isn't `Pin` ultimately supposed to enable self-referential structs? Or will it only ever work for structs that the user doesn't write explicitly?
r/playrust
r/playrust
Pin provides a standard API to allow talking about non-movable things, which is a requirement for self-referentiality, but it itself won't enable that. In the case of async functions, the compiler itself enables the self-referentiality for the anonymous type that represents the generator state. If we want to do that manually for now, raw pointers are the only game in town, I think.
We have a few rust microservices. Our services, rust and other, are built in a docker container, and run in another. AWS just runs the image, and publish a port. The SDK is just sugar over a "ReST" API. You should be able to just do web requests. A proper lib would be great, but I wouldn't hold my breath for an official one.