How many are parked?
What about RAM usage? Java vs Rayon :D Also, is Rayon used in Servo/Stylo?
&gt; I think You're correct!
The "summary given" took the opportunity to repeatedly announce that the author's views on the gender identity of Chelsea Manning override Manning's own, and that insulting her by misgendering is somehow the appropriate way of reconciling that difference. I know we live in slightly-unstable times wrt. social norms around gender identity, but it's really not hard to accept the existence of trans people as what they say they are and avoid insulting them at every opportunity. It's part of the social norms of this space to make that (minuscule) effort, clearly posted on the wall.
what hardware?
This applies if your traffic model is "many small requests". I'm working on business reporting apps, and most of our performance problems (both time and memory wise) are when there are fewer requests, but some run very large reports and need very large render jobs. Ultimately, I'm hoping parallelization can happen in both stages (parallel across requests, and parallel for large jobs within a request), and the language/framework can automatically optimize for best use of cycles.
Thanks for the info fellow LWA fan! Two last questions, is it possible for a custom derive to either add fields or panic if certain fields aren't there (these fields would be used in the generated impls)? Is it also possible for the derive to ensure that the struct is specified as #[repr(C)]? Basically I'm trying to abstract away some details that apply to almost every ffi struct in my current project.
(do you have this on GitHub? ) r.e. the &lt;ID,T&gt; vs &lt;T,ID&gt; maybe you could just add a typedef that you export aswell, struct IdVec&lt;ID,T&gt; type VecId&lt;T,ID=usize&gt; = IdVec&lt;T,ID&gt; // or .. type VecId&lt;T,ID=Index32Of&lt;T&gt;&gt; = IdVec&lt;T,ID&gt; //alternative.. giving a default unique index for any unique type used; maybe that could also be captured as an associated type That will increase the instant usability out of the box.. you could wrap it in a sub mod if you didn't want it polluting the namespace then i could just use sid_vec::id_vec::VecId To further clarity the choice ```&lt;T,ID&gt;``` , it allows the index type to be defaulted ... I would personally use such a type as the default across the sourcebase (e.g. ```VecId&lt;T,ID=usize&gt;``` and you just write ```VecId&lt;T&gt;``` where you don't care to specialise it) the other handy function I'd be after is from_fn() (did they move that somewhere else?) what it might look like.. struct Mesh { vertices: VecId&lt;Vertex&gt;, triangles: VecId&lt; [Index32&lt;Vertex&gt;;3] &gt;, //etc }
*Very* cool! Thanks a lot.
Rust: Maximum resident set size (kbytes): 1599788 Java: Maximum resident set size (kbytes): 1624240 C++: Maximum resident set size (kbytes): 1966104 According to the "time -v" command being used directly with the benchmarks, excluding the build process, running on Linux natively.
Fair enough. I still think someone who would "go out of their way" to study an emerging language such as Rust, probably wouldn't be asking homework questions online.
&gt; and the language/framework can automatically optimize for best use of cycles. Ideally, this is what Rayon is designed to do. It's _potential parallelism_, using a technique called _work stealing_. It doesn't force the jobs to run in parallel, which would create resource contention and slow things down if there aren't any more physical threads idle. There are worker threads running on each thread of the physical machine, and new jobs are pushed onto a queue. Whenever a worker thread is idle, it tries to pull more work off of the queue. The basic primitive of Rayon is "join(task1, task2)", which will push task2 onto the queue, then execute task1. After task1 is finished, join waits on task2 to finish, or begins processing task2 if no one else has taken it from the queue. There is a cost associated with this, but it's pretty low overhead, so if the server is receiving lots of connections, each connection would mostly run on one thread, pretty efficiently. If the server is largely idle, each connection could distribute work across a number of threads to complete faster. Serde doesn't support Rayon at this point, though, so that's all hypothetical.
Sure. I just wanted to point out that there are Rust university classes already, which I think is cool :)
This is a bit big for an early project, but I'd love to have your help on crates.io when you're ready :) The backend is a Rust server and the frontend is ember, and there are a number of issues that involve making changes in both, so I think it could be a great place for people like yourself :) https://github.com/rust-lang/crates.io
On the match, depending on which side of the or gets evaluated to true, k might have two distinct lifetimes. If we match with `(&amp;Kind::Var(v), k)` then `k` will have the same lifetime as `b`. If we match with `(k, &amp;Kind::Var(v))` then k will have the same lifetime as `a`. These two are different, and therefore they mismatch. Within the body, if `k` was used, then the compiler would not be able to figure out what lifetime it is supposed to be at compile-time. This is why the code compiles if we force them to be the same lifetime in the function definition. The compiler error could be more discriptive because this: ``` expected type `&amp;Kind` found type `&amp;Kind` ``` doesn't help. Although, if we explicititely show the lifetimes as different in the function definition instead of eliding them, then the error becomes more helpful. 
Same with -O3?
FWIW the same machine using only 16 threads is only slightly slower, so I think it just doesn't scale much higher. $ RAYON_NUM_THREADS=16 ./benchmarks/rust/run.sh + cargo run --release Finished release [optimized] target(s) in 0.0 secs Running `target/release/rust` sort 11050 ms sort_unstable 3659 ms par_sort 1260 ms par_sort_unstable 633 ms 
The benchmark may need to sort a larger dataset for it to scale to these really high core count machines. It's probably finishing too quickly? I dunno.
I do find it hard to understand what Kotlin has that Scala, Groovy, Clojure, JRuby, Jython, Ceylon and the rest did not have.
Started a [browser POC](https://github.com/cretz/rust-qt_cef_poc) using CEF and rust-qt just to get it to a cross platform state before I build a real browser doing some of the things I want. I have abandoned it in favor of a C++ version until rust-qt gets [more mature](https://github.com/rust-qt/cpp_to_rust/issues/53).
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cpp] [Default rust sort is faster than std::sort for random integers](https://np.reddit.com/r/cpp/comments/6jup22/default_rust_sort_is_faster_than_stdsort_for/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Looks like we'll need parallel partitioning in quicksort, after all. :) For those out of the loop: `par_sort_unstable` is a quicksort that simply executes recursive calls in parallel, that's all. The parallel sort in C++ in addition to that parallelizes partitioning, and that gives it the edge in this benchmark. We could use parallel partitioning in Rust as well, but since the pivot must be shared between threads, that'd introduce a new type bound `T: Sync`. We think that is too restrictive, but there is a solution: using specialization we can perform parallel partitioning only if the bound is satisfied, and fall back to sequential partitioning otherwise. We'll do that as soon as specialization gets into stable Rust (maybe even sooner), I promise!
I can highly recommend the book that came out of that paper: https://books.google.de/books/about/Purely_Functional_Data_Structures.html?id=SxPzSTcTalAC&amp;redir_esc=y&amp;hl=de Even if you don't end up using any of the contents (and might even understand only half of it), it has a great introduction into reasoning about them through worst-case and amortized analysis (https://en.wikipedia.org/wiki/Amortized_analysis). 
&gt; (maybe even sooner) What are you thinking? Just a nightly cfg, or some deeper unsafe magic?
I see. The numbers are not really 'random': https://github.com/stjepang/par-sort/blob/master/benchmarks/rust/src/main.rs#L11 Are the results reproducible with numbers from a RNG? Details: http://en.cppreference.com/w/cpp/numeric/random
But then why does the problem go away if I change or comment out the next branch?
Wow, I'm all for Rust implementation being fast, but please use -O3 at least, and compare with -Ofast to show that you tried to beat it at least with C++ code https://stackoverflow.com/questions/3005564/gcc-options-for-fastest-code
`-O3` is not really unsafe in 2017, IMHO.
If you're comfortable working in larger projects, consider contributing to Servo. It's fairly welcoming to newcomers. There's a curated list of beginner friendly tickets, and a fairly good mentorship community, and good documentation. 
Ahh OK, thanks. I need to understand why in that many people run for the nightly
jetscii only helps if you have a way to efficiently turn those searches into something for `all`, which isn't easy through the exposed `find` interface (`find_not` would work though). Indexing a `[bool; 256]` is OK but doesn't SIMD well; using four `bytecount`s will probably be a lot faster.
Cool, I'll make it all work somehow. Thanks for all the useful info, time for experimentation!
IMO, Kotlin is to Java as Coffeescript is to Javascript. In otherwords, it mostly behaves just like Java and is the same programming paradigm that Java uses, it just adds some niceties. The good thing about Kotlin is that it is so close to Java that interop is a snap. All the other above mentioned Java alternatives have interop headaches due to the languages being different enough. The bad thing about Kotlin is that it is so close to Java. Yes, it buys you some polish and features that you may have been wanting. But, much like coffeescript, the hurdle of using Kotlin and getting everyone else to use Kotlin might be higher than your team is willing to pay. I don't see a single ground breaking feature of Kotlin that would make me want to dump java or start adding Kotlin. Maybe for a new project, but the hassle of adding it to an old project is too high.
That's only implementation-defined, I think. Though, there's a more portable way involving a branch + arithmetic if necessary, which then gets optimized to a no-op on 2s-conplement platforms.
Interesting, I've been meaning you mess around with rust and game hackinf
If you compare that, make sure you also check which standard library is used. Clang on Linux often still uses the GNU libstdc++ rather than LLVM's libc++.
We have Lombok in Java that deals with the boilerplate stuff. The reason why I'm not happy about adding Kotlin is that Java has some badass refactoring tools. I don't Kotlin is there at the moment.
Thanks for the explanation, so because the others language uses unstable, to gat a fair idea nightly has to be used. I'm still very new in rust and if I'm gonna use it it will be for MCU, so I guess I'll wait until there will be a little better support for the platform I care.
Oh, yeah, no I can totally believe you're right. But it'd be fun to quantify it, and also to see how the results vary with the string length (if at all).
(cross-post from Discourse) Calling a closure trait object works the same as calling any method on any trait object, [as you can see here](https://godbolt.org/g/QrWCXN). You dereference the vtable pointer (at some offset) to get a pointer to the call function, and then execute an indirect call. This double indirection could be replaced with a single indirection, using an optimization similar to GHC's "Tables next to code". You replace the vtable pointer with a pointer directly to the call function, and then store the rest of the vtable (size, align, drop glue) immediately before it in .text. Has this optimization been considered for Rust? Clearly it's more important in GHC, where essentially everything you do is a call to a boxed closure. But Rust could benefit too, and it seems like a relatively straightforward change. It could apply to any trait object with a single method (ignoring `drop`). One issue is that this involves intermingling code and (read-only) data in .text, which may upset LLVM or some linkers. I think GHC added support to LLVM specifically for this use case.
&gt; We could use parallel partitioning in Rust as well, but since the pivot must be shared between threads, that'd introduce a new type bound T: Sync. Just out of curiosity, does this make the C++ version potentially incorrect if used with types that can't be safely shared between threads?
The author linked the comment on /r/cpp: https://np.reddit.com/r/cpp/comments/6jup22/default_rust_sort_is_faster_than_stdsort_for/
When building an enum, why can we `match` on it immediately but cannot compare on it? (I know mechanically why the latter is true, but not the former, and I'm also asking in the logical/semantic sense). Example: enum Variant { One, Two, Three, } let var: Variant = Variant::Two; match var { Variant::One =&gt; {}, Variant::Two =&gt; {}, Variant::Three =&gt; {}, } This works out of the box: no decorations required on `Variant`. if var != Variant::Three {} if var == Variant::Two {} ~~`if let Variant::One = var {}`~~ Edit: Don't code from memory, you will ALWAYS be wrong and embarass yourself. These do not work; we are required to `#[derive(PartialEq, Eq)]` on `Variant`. I presume the answer to this is "for any type `T`, `a:T == b:T` desugars to `::std::cmp::eq&lt;T&gt;(a, b)`" but ... we don't need those traits in place to `match` over variants, so clearly there must be *some* mechanism in place to handle discriminating against enums even without `#[repr(C)]` or `impl {Partial,}Eq for Variant` on them. This is a pretty minor complaint, but while working on something that has to do state discrimination, it's been irking me fairly often. That and I sure would like a `if let Success != var {}` syntax to capture multiple forms of failure early, and skip over for the one success condition, to complement the current `if let Success = var {}` which only enters for the one success condition. `match var { Fail1 | Fail2 =&gt; {}` is good, but induces two levels of indent and requires exhaustiveness in the discriminants, whereas in the `if let` I am specifically only interested in the truthiness of one variant and don't care about the others at that moment. ---- Also, while I'm listing problems I found at work, is it possible to turn an `&amp;[T]` into an `&amp;[T; n]` if I can prove that everywhere I use the former, it satisfies the length requirements of the latter? I'm guessing that's a compile-time-integers sort of problem and the answer is thus "not yet", but I would really love some compile-time-proven length safety there without having to do copies...
We've all been there lol You're correct though that other than `use` statements, the `super` stack becomes necessary, which is less than awesome.
That is *so* weird. `--` is creating an empty `&lt;h2&gt;`, and being genuinely empty it is collapsed (whereas even a ZWSP makes a paragraph non-empty). I presume this is parsing it as an underlined heading, crazy though that be. And people wonder why I prefer reStructuredText to Markdown!
Changing the next branch affects inference, though I can't say precisely how. Intuitively, if you omit the `ref`, the inner `u64` is copied, which means no lifetime is needed in that arm, which means there are fewer constraints on the first arm and it can be solved.
Non-Mobile link: https://en.wikipedia.org/wiki/Amdahl%27s_law *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^84892
I think this probably just reflects the sorting function in the Rust standard library has been written/updated more recently than the one in the c++ standard library. And hence is using a slightly more advanced sorting algorithm.
You seem to imply one compiler implementation is a problem, while it isn't. As long as that implementation is open, freely available, and can target many architectures, there is little reason to have different ones. It's not you will get vendor-locked-in into it, or it's restrictive licensing or technical limitations will prevent you from using it, which were the main reasons to have competing implementations of compilers in the past. If you want you can get your own implementation by just clicking "Fork" button on the github repo.
It might be helpful if you could post a minimal example that has everything necessary to show exactly what the error is (i.e. something on [play](https://play.rust-lang.org) or a snippet that others could try compiling and get exactly the error you're having), as there's no reason I can think of that you cannot just insert a return statement like you want. The only thing I can think of is that you don't seem to be returning anything at the end of the function if the loop does not return early, which could cause the type mismatch error.
Wow! How exciting, I really enjoyed the guide. Thanks for sharing. 
Rust community is very self-conscious, and self-restricting. It wouldn't promote or encourage such initiatives. On the other hand, the whole proposition is a bit naive. There's plenty of people who are very excited about Rust but underestimate how much work it is to rewrite things. There are some projects, that are in smaller scope rewriting things in Rust: https://github.com/uutils/coreutils I'd say, using Rust for new projects, when it makes sense, and building shared ecosystem is the most effective way to obsolete legacy, memory-unsafe software. With rich enough ecosystem, and more existing software in Rust, at some point, people will start using Rust by default because of it's technical merits. 
Oh this is fun! Here are my results: OS: Manjaro 17.0.2 Gellivara CPU: AMD Ryzen 7 1700 @ 3.75GHz Java Arrays.sort 9202 ms Arrays.parallelSort 1293 ms C++ std::stable_sort 10595 ms std::sort 8670 ms __gnu_parallel::stable_sort 2339 ms __gnu_parallel::sort 1062 ms tbb::parallel_sort 1284 ms Rust sort 5627 ms sort_unstable 4553 ms par_sort 1423 ms par_sort_unstable 906 ms
Is this similar to thin traits?
My synesthesia weeps. :(
I agree that Rust is an amazing language, and it is wonderful. I *wish* that all of our computer infrastructure was written in Rust. Right now, the standing policy is that we should strive to write the best software we can in Rust, and people will switch to it if it is better. Organizing an effort to systematically rewrite core software is too similar to the RIIR that people are becoming allergic to. Arguably, you could eliminate most CVEs by writing your software in a high-level language like JavaScript. The problem is people aren't willing to sacrifice that much performance, which is why Rust is so attractive as an option to fill that role. It is verboten to just insult everyone else's choice of language, like [this article](https://llogiq.github.io/2017/06/16/no-rust.html) talks about. &gt; The project, team or company may already have substantial investment in another language (both in code and know-how, as redditor mockery0 aptly reminds me), so switching to Rust may obsolete some of this It definitely doesn't win friends for Rust. If you want to start an effort to make a Rust-alternative to a specific piece of software, then make some progress on your own, and once you have anything at all to show, invite others to join you. It will be better received that way.
Yeah, it's a setting. The argument for it is that it makes variables easy to spot and distinguish.
RIIR is a meme promulgated by _transitiontech.ca_, and is way overblown. We should be RingIR the stuff at the core of the infrastructure, I'd shoot for zlib first. The biggest barrier is that AFAIK, Rust can't call directly into C++ nor can it is easily expose itself to C++ as C++ code. Everything had to go through the C ABI. Something about C++ not having one ...
The first version is too colourful for me :P.
Dunno what that is, link?
I'm not a JVM expert, but the significance of JVM warmup was discounted by a group of hackers who run the most comprehensive cross-language comparison: [the language shootout](https://benchmarksgame.alioth.debian.org/sometimes-people-just-make-up-stuff.html). Their data shows that JMH makes less than a 10th of a millisecond difference and it actually makes some short-running programs paradoxically slower. A group at Oxford King's College looked at the performance of "warmed up" JVM solutions like JMH as well. [Their results were even *worse* for JMH](https://arxiv.org/abs/1602.00602).
Having trait objects use thin pointers (pointer to a block of memory containing vtable and object value) instead of fat pointers (two pointers, one to vtable another to object value). This is usually not talked like it's a transparent "optimization" the compiler can choose to make, but as a repr thing (like `#[repr(thin)]`) Niko Matsakis wrote about thin traits a number of times. [Here](https://github.com/nikomatsakis/fields-in-traits-rfc/issues/15) is an issue on his prototype of the [fields in traits RFC](https://github.com/rust-lang/rfcs/pull/1546). Also [in this blog post](http://smallcultfollowing.com/babysteps/blog/2015/10/08/virtual-structs-part-4-extended-enums-and-thin-traits/). The idea of thin traits was also referenced [in this rfc](https://github.com/rust-lang/rfcs/pull/1524), that proposed custom layout for `&amp;T` and other reference types depending on `T` (nowadays it's a fat pointer if `T` is unsized, and just a pointer if it isn't)
Aww... I like IPv6... :( I could set up a IPv6 reverse proxy, but I don't think it would be that useful.
&gt; I have slow RAM at 2133MHz Lol that's nearly twice as fast as mine.
&gt; I guess Java is tuned to the max (old language, lots of companies using it etc.). Eh, developments in other languages make their way into Java thanks to the sheer volume of the behemoth. Optimizing compilers have come a long way since Java was introduced. 
You are correct, I was going from memory and thought "within five minutes is fine, right?" and I was not right.
&gt; Their data shows that JMH makes less than a 10th of a millisecond difference and it actually makes some short-running programs paradoxically slower. Why is that paradoxical? JMH is designed to make benchmarks accurate, not to somehow speed up the JVM (though it does make sure that the benchmark runs enough iterations to get profiled by C2). JMH actually prevents some optimizations, so that you don't get *incorrect* benchmark results. For example, if you write to a variable and never read it, the JVM can (and does) optimize out the store, dramatically speeding up your benchmark but giving you useless results in any real-world context. With JMH you can "consume" the value to prevent this optimization.
From what you say and from skimming Niko's post, it sounds like method calls on thin traits would still involve two indirections. And the restrictions on implementing thin traits would not apply to TntC optimization. TntC is more like the `Option&lt;&amp;T&gt;` optimization; it's fully transparent from the perspective of semantics. It would also be hard to combine TntC with thin traits, because both the concrete value and the call function code have statically-unknown size. You can't just use a fixed offset from one to get the other. So I think the two proposals are very different, and in fact they conflict. (But since thin traits are explicitly marked, you could just suppress the optimization in those cases.)
You would expect such a difference to be most substantial in short-running programs. i.e startup time comprises a greater percentage of the total wall-clock time of a short-running program and thus the expectation that it will have a larger proportional effect.
&gt;Why is this allowed? How would you prevent it? *Why* would you want to? There are plenty of good reasons to strictly evaluate a lazy infinite iterator. For one, if you never do this, then the iterator will never do anything. You'll either call `collect` or use a loop; either way you're going to eventually evaluate in an unbounded manner. &gt;Wouldn't it make more sense for FromIterator to force the provided iterator to be a FixedSizeIterator? No, because `FromIterator` is not required to do any iteration. You might be building another lazy iterator. Or something that only needs a few things from the start of the iteration.
While it could be interesting to look at the rate of change of individual languages, I think we should be careful comparing absolute values because the scope of what a single library does tends to vary between language comunities. Thus two "equal-sized" languages with different conventions regarding libraries can have wastly different package counts.
Hi there! I work on the Protocol Buffers team at Google. But my comment here is purely recreational, as a Rust enthusiast. It's great to see Protocol Buffers support for Rust! I highly recommend running your implementation against the [protobuf conformance tests](https://github.com/google/protobuf/tree/master/conformance) (I created these originally). These will test a lot of edge cases whose correct behavior is not entirely obvious from reading the specs alone. If you pass the conformance tests, you are doing pretty well. The conformance tests are still pretty incomplete (they don't cover proto2 at all yet), but they are a great way to stress your implementation.
Is this 'real code' or just a benchmark?
to implement protocols?
The thing is that there still are ergonomic issues around Rust (my main issue - the extremely _deep_ matching. I just found some fairly basic code which is 8 levels deep: For example, take a simple login. You need to: fn -&gt; match query_string -&gt; match username -&gt; match password -&gt; compare username to password. In other null-safe languages (Kotlin), you'd use the ? operator (so this whole thing could be trimmed down to two ifs (is there username, compare username and password to known)). Sometimes, when I find myself nesting so deeply, I have a strong temptation to throw in an unwrap just to save myself the error-handling, but then I remind myself that this removes Rusts main advantage.
&gt; So, it changes the stable_sort performance for reasons I don't understand Well `-O3` enables more optimizations. I could understand not using `-Ofast` for C++, but I don't think using `-O2` is a fair comparison. 
Not only that, but he actually endorsed the MIT license for some projects (such as codecs).
Hi @haberman, prost is already running the conformance tests, check out (https://github.com/danburkert/prost/blob/master/conformance/src/main.rs) for details. A vanilla 'cargo test --all' will run the suite. It passes all tests except JSON input/output tests, which it skips (JSON is not a goal for prost). In addition, there is fuzz testing against the TestAllTypes type from the protobuf repo. Having proto2 conformance tests land upstream would be great, thanks for your work on this! The conformance tests helped a lot in shaking out bugs.
When you have lots of services that you have to connect to make something work (billing system, payment system, ad data, etc.) all of them having a protocol buffers interface is a great way to enforce a schema for their API. It gives you enough flexibility to modify the schema, without everything that depends on it crashing because the API changed. The natural tendency for a lot of beginners is to just use JSON to interchange data between services. This leads to disaster. 
Right now I have a client that heavily makes use of protocol buffers for communication with the server. For this I used the most popular rust-protobuf, which while it works forces you into an inefficient way of doing things. I hate the fact that the protobuf structures take ownership of the data. The PB API I am talking to does not match my internal structures. Thus when I create a PB struct to serialize, I must clone my data just so I can serialize a PB message. I see you made the same design choice and I think it's a mistake. Next time I'm using a PB library it will be quick-protobuf because they have Cow for strings and vec's. I think this is the correct choice. 
prost is written primarily for use in a futures/tokio context where having lifetime parameters on objects that interact with async contexts is extremely painful. Additionally, the usecase prost was written for isn't pushing a huge amount of raw `bytes` fields arounds, so optimizing for a zero-copy hasn't been a priority. That being said, Cow&lt;'a&gt; isn't the only solution to zero-copy - prost could, and likely will given enough interest, add the ability to make `bytes` and `string` fields be `Bytes` instead of `Vec&lt;u8&gt;`/`String`. Since `Bytes` is ref-counted, this is effectively zero copy (it's similar to an `Arc` wrapping the buffer).
Cool project! Really unfortunate [naming collision](https://en.wiktionary.org/wiki/prost#Romanian) though. EDIT: Wasn't trying to be impolite. It's just very peculiar since the adjective is strikingly derogatory in Romanian.
Hmm, that is unfortunate. The project was originally named `proto`, but I renamed it so as not to conflict with `tokio-proto`, since I plan to use them together. `prost` was picked because it's a conjoining of `pro`tobuffers and Ru`st` (as well as a play on the German word).
Agree that I don't really get why it's called "clone on write". On the other hand, still like the name. Every time I try to remember which import to use, I have this mnemotechnic rule where I ask myself "Can I borrow your cow?" and then I know it's "use std::borrow::Cow" and that makes me inexplicably happy. 
I made an IPP library for Rust with examples and command-line ipp utility: https://github.com/dremon/ipp.rs
Zum Wohl! (Meanwhile I have long been of the opinion that rust is a very good language to write drunk)
Is there a way to host it somewhere else? Perhaps on the same server as rust-lang.org.
Perhaps this is of interest? https://google.github.io/flatbuffers/ No mention of Rust yet.
Nothing wrong with protocol buffers. I just disagree with the mapping of protocol buffer types to Rust data structures in most Rust pb libraries. 
Yes, getting a `Result` results in this kind of cuteness: let session = match_query(q)?.match_username(n)? .match_password(p)?.authorize(); The Kotlin trick is chaining non-null, which is equivalent to `Option`. As an aside, I'm not convinced it's generally a good idea to use `?` on `Option` - it's not an error type, and would result in fairly generic 'failed to unwrap' errors returned to the library user. 
To be fair you could have a `FiniteIterator` trait with impl-s for transformers which preserve it (I think that's actually all of them), as well as an `AssertFiniteIter` wrapper with a corresponding `.assert_finite()` transformer. Then, with a time machine, we could have added `FiniteIterator` bounds for `count`, `fold`, `collect` etc. Still doubt it would have been worth it.
No need! I made a PR for the applet, that only imports the OS X specific native package if you are actually running macOS (and notify-rust if you're running linux respectivley)
Just because an iterator is finite doesn't mean it can reasonably be collected. An iterator that enumerates all IPv6 addresses would be finite, but I imagine collecting it into a vector would be [beyond most of our RAM budgets](https://blogs.oracle.com/bonwick/128-bit-storage:-are-you-high) :p
&gt; The natural tendency for a lot of beginners is to just use JSON to interchange data between services. This leads to disaster. Why'd JSON lead to disaster while protobuf wouldn't? I don't think protobuf automagically keeps you from screwing up the API with incompatible changes. It has to be designed the right way - but the same applies to JSON, doesn't it?
The mere fact that protobuf has a .proto file that defines the API and types are static. Json has neither of these things. Even if a serializer stores an integer, the deserializer may return a double. A small code change can also completely change the output type. Obviously protobuf can't save you from shooting yourself in the foot and changing the API from one version to another in an incompatible manner. What it does is define a clear path for upgrades. It's a contract between a service and a client. It tells you how upgrades should look like and when the service upgrades it's API, it publishes the .proto file first. This extra step is extremely important when you are building something that is being used by other people/teams. Json is way too dangerous as it is too easy to completely change the API. &gt; It has to be designed the right way - but the same applies to JSON, doesn't it? Comparing JSON and .proto is just like comparing a weakly typed language to a statically typed language. The advantages of static types really shine when you are a part of a large team working on the same project. Obviously if you do everything right a loosely typed language will work. But the larger your team is, the bigger the chance of mistakes and incompatibilities between parts of the system.
Great summary, thanks.
Well, there is [JSON Schema](http://json-schema.org) of course.
If you have a "recursive" type (ie type A can produce type B which can produce type A, and so on) as in a strongly typed state machine, does it make sense to split up your library such that: lib.rs has all struct definitions, A.rs actually implements A B.rs actually implements B Otherwise I'm concerned about circular imports: if the definitions live with the impls (which does at first seem reasonable) then you'll likely get stuck
--&gt; 20 Nov 2016 -- seems out of date, unless I am mistaken and have missed something. 
Do you have any old projects you could try reimplementing in Rust? Edit: You could think about writing a simple interpreter for a simple language. That way you also learn something about how languages "work".
Sorry - I meant injections, XSS and the like. All these vulnerabilities that are due to the programmer using one type (i.e. string) to represent all kinds of data that might be malicious and unsanitized, and then losing track of whether a piece of data is safe for use (e.g. to be sent to DB) or not. Considering that they are build in RustI suspect that the frameworks itself might be fairly bug free (not logical bugs, though). 
Thanks, that helps. Still think that an explicit error is better, but I see its usefulness now
&gt; because of reasons like this. I thought the problem with that was the *asking* part - to which the obvious answer would be "patches welcome"! A 'centralized place' would be nice to coordinate the development of such patches.
&gt; It would be great to see Grpc implementation based on this. There are at least two grpc implementations: * https://github.com/stepancheg/grpc-rust * https://github.com/pingcap/grpc-rs At least mine can work with any protobuf implementation (but you need to generate stubs yourself).
I think what you want to do is include a set of C++ header files that do whatever proxying/wrapping is necessary for idiomatically linking to the Rust API, transparently to the rest of the code (and efficiently, via inlining). Such C++ files would be part of the project, but wouldn't be "included with the crate" in any real sense. It would be up to the developer to compile them with the preferred C++ toolchain. The "call directly into C++" is definitely a more severe problem. In general, it requires making the C++ code accessible via a C API and this may be quite non-trivial. It may even require some serious smarts within the build system whenever e.g. C++ templates are involved.
I think this project [truffleHog](https://github.com/dxa4481/truffleHog) is interesting and simple, But I am not sure whether I could translate it from Python to Rust.
This project looks like so interesting, I will check this.
&gt; I meant injections, XSS and the like Rust provides type system that is sufficiently expressive to allow people design interfaces that prevent many types of errors. More importantly (in my opinion), it tends to attract people who care about safety. At the very least, it differentiates strings from numbers and other things and does not allow to mix them accidentally. Every DB api I've used so far provides a sane way of passing arguments. &gt; Considering that they are build in RustI suspect that the frameworks itself might be fairly bug free (not logical bugs, though). This is my experience so far. I recall for example how buggy Mysql drivers for Python were at their early days, and Rust has no such problem. &gt; I have seen that there is Iron, Nickel and Rocket - what would you recommend to try? Iron is most popular and my preferred choice, though it requires you to be familiar with Rust and web development. If you aren't, you may find other ones easier to start with. Rocket requires nightly, so this may rule it out for some people.
Sure, I mean, my library is called "pest". It just seems to have a different kind of vibe when not in English.
What I read (or remember reading) did not contain the assertions you mention, nor the insults. I think you're reading too much into what was written. I still stand by my opinion.
It's always fun to write a CHIP-8 emulator. It's easy and you can learn a lot about language features.
&gt; impl Sync on their structs scares me a little [Fixed](https://github.com/stepancheg/rust-protobuf/commit/6d28afbd05b12b842d50c95be9031315905fd7f0). 
It does if both input and output iterators are finite.
Good templating frameworks should implement escaping of output by default. For example, in a html template the default could be to escape all variables using html entities, unless the variable is of the type AlreadyEscaped&lt;T&gt; (a wrapper type, might be better solutions for marking such bindings). Note that this does not help against all types of XSS (for example if your template contains inline javascript that contains template substitutions), but it is a great help for both safe coding and fast auditing / reviewing. The key point is that the fact that a variable needs escaping is known in the code, so it should be specified in the code and not in the template file. A secure web framework should have some solution for getting resources from restricted paths. This is to make sure that when I'm trying to load a stylesheet "resources/" + themename + ".css" indirectly (via a minifier or combiner script) a user cannot inject "../../../../../etc/passwd\0" and retrieve the /etc/passwd file. Yes, themename should be validated, but such validations are easy to get wrong and the framework should at least protect against basics like "../" and especially nul byte injection (which Rust by itself does not do annoyingly enough). A modern secure web framework should probably have cross-site request forgery protection built in for all POST requests. Session cookies should probably have the httponly flag set, and if served over https it should have the secure flag set. Secure defaults for headers like X-Frame-Options, X-Content-Type-Options=nosniff and other things. Lots of stuff like this. Of course none of this stuff is *required* to do secure web development, but I've seen all of these things cause tons and tons of vulnerabilities and many modern web frameworks do have these protections these days. It's been a while since I checked out webdev in Rust, but last I checked there wasn't a single framework that ticked all these boxes and in general felt like it was coded by someone who knew what he was doing in terms of building a safe-by-design no-sharp-edges framework. 
fwiw, in German "Prost!" is the equivalent of "Cheers!", i.e. what people say when they raise their glasses (or beer bottles).
&gt; It's been a while since I checked out webdev in Rust, but last I checked there wasn't a single framework that ticked all these boxes For many of those things, existing Rust frameworks are to low-level to provide them, or not enough opinionated. You may expect that the features they provide are not completely moronic (like exposing system files), but if you are going to do web development in such new language you will need to write lots of such things yourself, Rust will only help you with ensuring that you don't make certain errors in the implementation. 
Two problems with that: 1) There is a set of problems that non-Turing languages can't express 2) Proving language isn't Turing complete is a pain.
Not even worth considering
I guess in case of `tokio`, one simply reads whole message into single buffer and then deserializes that (at least that's how I approached it). In that case that buffer could be borrowed. I think that you might be missing the fact that "zero-copy" solutions also provide zero-allocation. This is also the case of `quick-protobuf`, if I remember correctly. `Bytes` sounds like an interesting solution too. `String` version of this would be great too.
Ever heard of [Cap'n Proto](https://capnproto.org/)?
&gt; I just disagree with the mapping of protocol buffer types to Rust data structures in most Rust pb libraries. Me too. However, I think that `quick-protobuf` does it right. Doesn't it?
I have been unfortunate enough to work with that. I find it very difficult to read and understand.
How does this compare to performance of C++ proto code generated by the official implementation?
Right. I'm just saying, there's not-so-obvious pitfalls in the "do it yourself" direction and I personally would not recommend developing anything beyond a webservice-with-token-authentication on a platform that does not have opinionated and well-designed functionality in these categories. You'll be tempted to spend as little on things as you can because it's not the important part, and it will hurt you later on. 
Protobuf inner messages are length-delimited. You need to compute sizes of the whole message tree (and store them somewhere) before serializing the message. Previously rust-protobuf serialized cached sizes in external temporary vec, but it is slower than storing sizes in fields inside of messages. (Cached size field is the way official C++ and Java protobuf implementations work).
Didn't know that, thank you.
:O Super happy to see this. I ended up having to do protobuffer de-serialization by hand in a recent project as the current protobuf crate would return empty objects all to often on completely valid data :\
Are you saying that you get a compilation error? Post the compiler output.
You have declared a pub struct Shortcut&lt;'a&gt; so you need to use that specific name (the lifetime annotation is part of the name) every time you want to refer to that type. So you need to write supported: Vec&lt;Shortcut&lt;'a&gt;&gt; 
This is great and all, but ... how do I read a PBF file with this? I have now generated the Rust bindings for the OpenStreetMap PBF file format: https://crates.io/crates/osm-proto-rs and here is a small OSM PBF file: https://github.com/sharazam/small-test-pbf-file - how do I read the header with the bounding box, for example? Thanks in advance and great work on this library.
You can add the lifetime specifier like so: `Shortcut&lt;'a&gt;`, but there is a bigger problem with the signatures. At line 28 inside the impl for `ShortcutEq&lt;'a&gt;`: pub fn new(&amp;self) -&gt; &amp;ShortcutEq { &amp;mut self.pressed = Shortcut{id: ShortcutId::Pressed, keys: &amp;mut Vec::new()}; &amp;mut self.supported = []; } I can probably guess what the intended purpose of this function is, and I think the main issue arises from line 15: pub struct Shortcut&lt;'a&gt; { pub id: ShortcutId, pub keys: &amp;'a mut Vec&lt;u8&gt;, } Here, `keys` takes a mutable borrow of a `Vec&lt;u8&gt;`, but who should take ownership of this `Vec&lt;u8&gt;`? If the owner should be the struct itself, then the lifetime specifiers along with the borrows will not be necessary.
Also `pressed: &amp;'a Shortcut&lt;'a&gt;`
Many thanks for the extended answer! &gt;:)
That is what I thought - basically, it is very well possible to have fun with Rust serving on the web, but for complex things the software is not written yet. Especially for a novice web developer. 
Whoah, this is awesome. Stylish is exactly what I was looking for recently. Your blog is also cool, but I wish it had an RSS feed, I opened a Github issue.
Interesting. Currently `prost` is quite naive and re-computes as necessary, which is obviously `O(n^2)` on the level of message nesting. My plan was to fix this using the external temporary stack method. Did you do any digging on the reason why the external stack is slower?
Thanks, i've gone ahead and added one.
Cool. I assume by stubs you mean you need to output special definitions for `service`s? `prost` does have this capability, although it's currently pretty raw and under-documented: [`ServiceGenerator`](https://docs.rs/prost-codegen/0.1.0/prost_codegen/trait.ServiceGenerator.html). Everyone needs something different for `service` definitions, so I made it pluggable from the get-go.
Not sure yet. The goal is to hook it up to the Protobuf upstream benchmark suite, but performance hasn't yet been a priority yet (in the sense that profiling hasn't been done yet, but obviously performance was considered when designing it).
Let me know how it goes if you try it out. It's still early for `prost`, but I'm pretty confident that it's 'correct' in the sense that encoded inputs == decoded outputs. It's passing the upstream protobuf conformance suite. One of the motivations for writing the library was rust-protobuf's failure to decode unknown enum values, which appears to be ['by-design'](https://docs.rs/protobuf/1.4.1/protobuf/error/enum.WireError.html). That is not an acceptable divergence from the spec, in my opinion (my usecase relies on being able to handle unknown enum values gracefully).
I find Rocket to be better as it has many examples, great documentation, and is consistently getting better. Compared to Iron which is lacking in many of those respects. Really nightly is it's only downside
&gt;I am am thinking of moving either to a more type safe language when it comes to web development (currently using Python). As such, I thought to dablle with the extremes (Haskell or Rust). Haskell's type system is more advanced than Rust's. It's also easier to write code to escape input in Haskell, in my opinion. By contrast, Rust is much faster and it cross-compiles beautifully. &gt;Haskell seems to have you covered (in a straightjacket) - what about Rust? Types aren't really stronger in Haskell than Rust. In fact, in Haskell, the type inference is better so you can write less code. &gt;I have seen that there is Iron, Nickel and Rocket - what would you recommend to try? I've used Iron in the past and I liked it, but it's a bit Spartan. Stuff won't work out of the box, but if you're making a big web app that's not really a problem from a functionality standpoint. Can't speak to security since I made a static site.
&gt; This is great and all, but ... how do I read a PBF file with this? I have now generated the Rust bindings for the OpenStreetMap PBF file format: https://crates.io/crates/osm-proto-rs and here is a small OSM PBF file: https://github.com/sharazam/small-test-pbf-file - how do I read the header with the bounding box, for example? &gt; Thanks in advance and great work on this library. Nice! I'm not familiar with the OSM format, but from reading [`fileformat.proto`](https://github.com/scrosby/OSM-binary/blob/master/src/fileformat.proto), I can outline some rough steps: * Read the file into a `Vec&lt;u8&gt;` (there are faster ways, but this is the simplest). Pretty sure there is something in the stdlib to make this easy defined on `Read`. Wrap the vec in a `std::io::Cursor` to get an implementation of `Buf`. * Read the network-byte-order length prefix using `Buf::get_u32` (is it actually a u32? That file doesn't specify). * Call `cursor.take(len)` to get the length-restricted `Buf` impl, * Pass that into `BlobHeader::decode` Hope that helps.
Hmm interesting. I think I'm still going to play around with it, since I like the current ergonomics of having the fields in message structs be public (and not having accessors). My understanding is that if the data fields are public, a built-in len field can't work because the length could change without the len field being updated or cleared. I assume `rust-protobuf` clears/updates the len field after every call to a mutable accessor?
Interesting. My usecase for protobufs doesn't (currently) include `gRPC`, so I haven't researched it much.
explicit and obvious is better than implicit and magical
Wow, there is always so much to do! It's true that Protocol Buffers are very mature, but there are always lots of things that need improving or fixing. For example, note that [we have 388 open issues right now on GitHub](https://github.com/google/protobuf/issues). We also spend a fair amount of time looking for inefficiencies and optimizing them. Protocol Buffers are used everywhere at Google, so anything we can do to reduce CPU usage by small amounts saves Google a lot of money. Reducing code size can have big payoffs too, especially for mobile. The fact that this kind of detail work is economically justifiable is one of the things I love about working on the team. There's also just a fair amount of work that comes along with keeping up with the times. Protocol Buffers predate C++11, and we still compile as C++03 for our open source release. It would be nice to update this to the more modern standard, but we have to manage the change in a way that isn't too disruptive for users. Another example: we have some thread-local behavior, but some people are starting to use our software with thousands of threads which leads to a spike in memory use. We have to figure out how to solve that without impacting performance. So my day-to-day is: fixing bugs, optimizing, refactoring, answering user questions, reviewing changes written by other team members, and sometimes developing completely new code for new features.
Nope, just hard work and persistence. I used to do this, but ended up slipping at some point. 
The project has been called the benchmarks game for a decade, when you can't get that right… &gt; less than a 10th of a millisecond difference typo? 10th of a second? &gt; actually makes some short-running programs paradoxically slower Please be specific -- which programs? Don't assume JMH measurements will be significantly different for your program. Don't assume JMH measurements won't be significantly different for your program. Measure.
&gt; BTW, that doesn't work well with default values with syntax 2. I'm currently also trying to make fields public, but I'm not decided yet what to do with default values. Yah I spent a long time thinking about this. The way it's handled in `prost` differs a bit if you're used to the C++ implementation, but it works alright. What happens is that a .proto such as syntax = "proto2"; package foo; message A { optional int32 a = 1 [default=13]; } [will](https://github.com/danburkert/prost/issues/5) output this Rust code: #[derive(Clone, Debug, PartialEq, Message)] pub struct Foo { #[prost(int32, optional, default="13", tag="1")] pub a: Option&lt;i32&gt;, } When you decode an empty serialized message into a `Foo`, the `a` field will be `None` (indicating that it's 'unset'). However, there is a hidden accessor generated by the #[derive(Message)] that looks like this: impl Foo { fn a(&amp;mut self) -&gt; &amp;mut i32 { match self.a { Option::Some(ref mut val) =&gt; val, Option::None =&gt; { self.a = Some(13); match self.a { Option::Some(ref mut val) =&gt; val, _ =&gt; unreachable!(), } } } } } So this lets the application access the field directly to get `Option` semantics, or you have the option of calling the 'mutable' getter, and getting back a mut reference that is automatically filled in with the default value.
I would say no. AFAIK thin traits is about thin pointers: that is, instead of a trait pointer being (v-ptr, data-ptr) it's instead just (data-ptr) and the first word of "data-ptr" is "v-ptr". In a sense, the proposal here is the opposite: - kmc_v3 proposal (table next to code): immediately accessible function ptr, - fat pointers: 1 dereference to get to function ptr, - thin pointers: 2 dereferences to get to function ptr.
&gt; Arguably, you could eliminate most CVEs by writing your software in a high-level language like JavaScript. Hardly. I mean, the original motivation for Mozilla was to avoid **50%** of CVEs which were due to memory issues by using Rust instead. 50% is not bad, but it's hardly most. There are many CVEs which are just programmer errors (like not using bound parameters for SQL queries and thinking you can just escape the string...).
Have you looked at [serde-protobuf](https://github.com/dflemstr/rq/tree/master/serde-protobuf)? It took away the pain of using the popular `rust-protobuf` in my generic protobuf parser.
If you want to `unwrap` out of a borrowed `Option&lt;T&gt;`, you can call `as_ref` to convert it into a `Option&lt;&amp;T&gt;`, like this: `self.pressed.as_ref().unwrap().keys.len()` Edit: I should also say that if you want a mutable reference, then `as_mut` is what you want.
Not the author, but yeah, this isn't really true unless they're talking about `go get`. `dep` is the future but isn't used by default yet.
Non-Mobile link: https://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^85178
You might find [this article](http://smallcultfollowing.com/babysteps/blog/2016/10/24/supporting-blanket-impls-in-specialization/) interesting. It discusses how we could get something similar for `Copy`/`Clone`.
Oh, I agree it varies. I am just *really wary* about giving the impression that simply using Rust is sufficient to avoid CVEs. - Heartbleed was caused by reusing a buffer without clearing it first (and then lack of bounds checking), - Cloudbleed was caused by reusing a buffer without clearing it first (and then lack of bounds checking), - GOTO Fail was more a logical/lack of test issue, - ... and all were bad.
Just to make a general point that I haven't seen others make, the general idea is that you'd use it wherever you would otherwise use JSON for internal APIs. It will generally be significantly smaller over the wire and faster to parse. Performance is generally the main consideration as far as I'm aware.
Thank you for the added info!
Yah, I just stole the Option::get_or_insert impl since it's not on stable yet.
Darn I was hoping for an error from Diesel
People with different backgrounds have different experiences.
&gt; Makes me wonder what your gender/skin color has to do with your insights into a programming language. I think this is actually a lot cleverer than the usual tokenism you find in the tech community wherein these things get mentioned. They are *specifically* looking for people who are statistically less likely to be invested in existing/legacy tech, and trying to make Rust easier to grok from first principles for these folks. That's a good way of avoiding the failure case of ridiculously overengineered products (whether these be C++/Java/.NET, or Python/Ruby/the ECMAScript "ecosystem"!)
If you want to specifically care about "injections", you're pretty safe. Every templating system I've seen escapes by default. Diesel is secure against SQL injection attacks. I'd be shocked to see anything made in the last 5 years that makes it even remotely easy to introduce an XSS or SQL injection vulnerability though. Those are the sort of problems that are easy to fix, and anybody making their first library knows about. CSRF, session hijacking, DoS vectors are the ones I'd be more concerned about, and in general protection from those in Rust is poor at the moment.
Why not? I've used it in some projects.
Very good, I just shared my non-native English speaker insight. These projects address the first problem I observed, that is the lack of development tools that other language ecosystems possess. 
Note: in addition to the Go version being quite verbose, it's also the only version that only works on integers.
I don't have the time to write an adapter at the moment, but I'm really interested in helping someone to implement it. Diesel is designed to support these sort of things being added from other crates.
&gt;That's a good way of avoiding the failure case of ridiculously overengineered products (whether these be C++/Java/.NET, or Python/Ruby/the ECMAScript "ecosystem"!) Java/C# are "overengineered" by definition. They rely on enviroments and have OOP built into them. C++ suffers from the lack of direction set up by its creator. First off, Stroustrup did not set up an aim regarding what the language should be capable of solving, rather he went with the idea that it should be able to do anything. C is clear cut because it was written specifically for one thing with clear goals in mind. This resulted in implementation of tons features people thought would be cool to have in the language, making it overly complicated. Rust has clear goals in mind, performance and safety, if the creators hold on to them there won't be problems. 
&gt; more ergonomic structs [Working on that too](https://github.com/stepancheg/rust-protobuf/issues/219).
&gt; Because Rust is Turing-complete and the halting problem is undecidable? This is actually not a precise answer, because it's possible for a Turing-complete language to make a type distinction between routines that truly require a full Turing machine to run and routines that can run on a less powerful machine. This is a growingly popular (but still experimental) idea in the pure functional programming world, but I haven't seen an imperative design along the same lines. There are some well-understood ideas on how to restrict the power of an imperative language (see, e.g., [Hoftstadter's toy language Bloop](https://en.wikipedia.org/wiki/BlooP_and_FlooP)), but I haven't seen any examples of a language take makes a type-system distinction between bounded and unbounded looping. Also, in the imperative world there isn't as much incentive to tackle this. In pure functional programming there's the Curry-Howard aspect of it—an unrestricted Turing Complete language cannot be used as a logic for proving theorems—so there's that incentive to make the distinction.
I guess we have to agree to disagree. This is the issue, fwiw: https://github.com/stepancheg/rust-protobuf/issues/186
I believe the author wants to say that Go has an extensive standard library (which is true). I'm horrified by the available package managers (I'm working with Go every day).
Oops, sorry, you are talking about `CodedOutputStream`. Yes it creates a buffer indeed when writing to `Write`. But buffer size is equal to size of `BufWriter` buffer, so effectively there is no buffering, because `BufWriter` skips buffering when passed slice is larger than `BufWriter` internal buffer. And it does not allocate buffer at all when writing to `Vec&lt;u8&gt;` or to `&amp;[u8]`.
That's the most recent blog post. The site was last updated [in March](https://github.com/bashyHQ/arewewebyet).
&gt; "if it compiles, it works" idea. Rust doesn't have that; Rust has: &gt; If it compiles and you didn't use any unsafe blocks and don't use any other code which incorrectly uses unsafe blocks then there won't be any undefined behaviour. Obviously for instance creating a vector of 4 elements and indexing the fifth compiles but "doesn't work" but the behaviour is _defined_, it will panic rather than "anything goes". However to your issue, the `FromIterator` trait's contract does not _at all_ specify that it needs to even run or exhaust the iterator until it produces `None`, it can not run it at all ,it can go on _after_ `None` to see if it starts producing values again. so that's why the type system does not protect you here. It does not protect you in the same way it doesn't protect you against: mut v = Vec::new(); loop { v.push(0); }; `FromIterator::from_iter` just takes ownership of something which can be converted into an iterator like an iterator itself typically and produces "something" from it. That need not be a collection and the `Iterator::collect` name itself is a misnomer which implies the result is always a collection. In particular `Result::from_iter` in the stdlib stands as an interesting example that _need not_ consume the entire iterator. It consumes it up till the first `Err` it encounters and it produces not really a collection but a `Result&lt;X,Y&gt; where X : FromIterator` so it in practice produces a result that contains a collection _if_ the iterator is exhausted without encountering an `err` but the `Ok` can again be anything that implements `FromIterator` on the appropriate value. 
Meh, Go is good for some things, but it's not really a good language. Unless you actually want to write something in Go, I wouldn't advise learning it. 
You are real close to getting it to compile. You need: * On line 115, change `as_ref()` to `as_mut()` * On line 94, change `&amp;self` to `&amp;mut self` Now there is a few warnings and weird bits (e.g. matching on bool), I'd recommend running clippy if you haven't done so already.
&gt; I see you made the same design choice and I think it's a mistake. FWIW, the reference implementation does the same thing. It's one of the arguments for why PBufs are a good serialization format: You can use the structures directly from memory and there's no separate copy step to put them on the wire. I know it doesn't help your situation, but there is a reason for doing it that way.
Wherever you want. Modules are there to serve you, not the other way around. :-P I'd just put it in the common module.
You're framing this with the assumption that everyone is already equally welcome, when the project is coming from the other direction. The survey provided data that shows there are groups who are underrepresented in the Rust community. We both believe that those groups have no bearing on people's ability as engineers, so why are the equally-qualified people who happen to be in those groups not represented as strongly? The only possible answer, given the assumption that e.g. women and people of color are no more or less qualified, is that there is something else discouraging them. This project is an attempt to counteract that factor, not to give people something you don't have.
The Rust project has limited resources. Paying for flight, hotel, and ticket is going to take away from other things. But I think that's a weak argument, this program overall seems pretty good and I expect it will be a net benefit to the community.
[removed]
PDF warning
This seems pretty good. I like that it's not just a handout of special benefits. It's an active, structured attempt to bring people into the community, and they're expected to contribute. Good luck! I also realize it will make some people uncomfortable. You're not a bad person for feeling that way. There's no way for social policy to make everyone happy, it's a give and take that has to be continually debated by the community.
Oops, yeah, should have mentioned that in the title. I'm used to reading papers, so it wasn't something that occurred to me.
Are people afraid of PDFs?
I took a look and the code around encoding/decoding varints (and computing lengths) needs some work :-)
Hi, You're getting downvoted because of rule #4 - no zealotry. If you want to critique or praise a language, you should back up what your comments with something interesting and insightful. Please try to make sure you do so in future :)
True. I tried to avoid implying that- my point is only that *something* else may be discouraging them from participating. Even if those factors are external to the community, they're still worth trying to counteract.
Please cite your statistics.
&gt; What this project is doing is noting which groups may feel less welcome (perhaps using data like this), and attempting to bring more of them into the community. Wouldn't &gt;50% "no" always be the expected answer to a question like "are you a member of an underrepresented group?". I mean if you want to work to change those numbers around there's no real issue with it, but the numbers for underrepresented groups will always be low specifically because of the definition of "underrepresented group". A single data point like that one may not indicate that people feel less welcome at all.
The question asks if you are a member of an underrepresented demographic *in technology*. If Rust winds up with numbers in those categories that are higher than they are for tech-in-general, or closer to the general population, then they're probably not underrepresented in the Rust community in particular. (50% is not really a relevant number here.) But yes, you do also need data points for tech-in-general or the general population.
It depends what you mean by "identity politics". If you mean respecting people *regardless* of personal attributes, then that's great. I don't really consider that political, just basic respect. On the other hand if you mean ranking everyone according to the oppression olympics to determine who's most virtuous and worthy of respect, then yeah, keep that shit out of here. But I don't think this program is an example of that. It's about bringing people into the community, with responsibilities, and not about showering favors on certain groups.
While underrepresentation is merely a correlation, it is a very strong one. The reason so many women don't go into STEM fields is because they're not welcomed; again and again they give examples and testimonies to this. Programming itself is also still very much a white person's game; examples such as Google's gorilla image recognition gaffe or [this unintentionally racist video game](http://www.kotaku.co.uk/2017/01/12/how-we-accidentally-made-a-racist-videogame) should highlight that STEM (especially CS) has a long way to go towards true equality. Specific niche communities have very little stability because they're small enough to be widely variable in makeup. It'll be common to see extremes; either extreme majority or extreme minority demographic makeup. In Rust's case, like most small language communities, it appears to be trending towards "everyone is white and male" rather than "more people than average are not white and male." To change this balance will require deliberate effort and it isn't discriminatory to want to change an already unbalanced system.
I'm concerned about this, as well, especially since existing team members and contributors may be too busy to take on another responsibility set, and therefore may not be able to take advantage of this opportunity. I think team members and active contributors should absolutely get extra consideration for mentoring or helping with costs.
It really screws up mobile browsing for me, especially if I'm on mobile data. I tend to avoid pdfs on my phone entirely and open them exclusively on my computer since it's just much easier to work with.
deleted ^^^^^^^^^^^^^^^^0.2654 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/44607)
I picked up working on [oxidoc](https://www.github.com/Ruin0x11/oxidoc) some more. I finished a small TUI written with Cursive and now I'm spending more time on the internals to make the documentation search more complete and useful. I'm hoping to use the current rustdoc as a metric and aim to make searching more convenient somehow.
Exactly this approach worked great for Idris.
Waiting on IO is an example of something that may diverge, yes.
&gt; Another great selling point for Go is it's focus on types and interfaces (if you're not using interfaces you really should be). A very weak notion of "interfaces" that often end up being equivalent to Java 1.4 `Object`. Also they are structural, so a `BitVector` and an `EngineTransmission` will both support the same `shift(int)` interface. This obviously means fewer errors can be caught at compile time. (Downvote me if you want, but these are substantive criticisms and not "language bashing".) &gt; C, C++, Java Developers: Another language in a style that should be syntactically familiar to you, but Rust is a completely different paradigm on memory management. Rust memory management is very similar to modern C++, aside from the safety aspect. Ownership and borrowing are also very important in C — if you find a C programmer who disputes this, you should stay well clear of their code. Java, fair point.
Because I'm incredibly stubborn and I'm not gonna let no phone tell me how to live 😎
If anyone's counting (excluding blank lines, tests, and comments): * Nim: 19 lines * Go: 60 lines, only works on integers * F#: 5 lines * Rust: 26 lines * Clojure: 5 lines So the pure functional style really shines in terms of conciseness — [but they aren't sorting in-place](https://stackoverflow.com/questions/7717691/why-is-the-minimalist-example-haskell-quicksort-not-a-true-quicksort).
I have never seen this. If I had to guess, it would be that the root module has no name, but you said `piston::&lt;unnamed&gt;::` not just `&lt;unnamed&gt;::`...
I will check this, thanks for your share :)
[removed]
I wish there was more diversity (heh) of suggested projects. Most of them don't even involve writing Rust code. I know it's hard to find good intro projects that involve core compiler hacking, but it can be done and it would be nice to have those options among others. There are plenty of people in underrepresented groups with compilers or systems experience, and we don't want to give the impression that technical expectations are lower. I suppose this means I should mentor a project, but I don't have the time :/
I want to apply, but I honestly don't know if I'm the sort of person you want applying. I mean.. I GUESS I'm "diverse", but I already sort of participate in the rust community, I'm just mostly really.. quiet about it. Are you looking for people who would otherwise not be a part of the rust community at *all*, or for people who just want to contribute back to core tools / crates etc? Edit: I also want to say that I really appreciate this kind of effort! I know this is just one data point, but I've found rust's community to be pretty darn open and welcoming already frankly, but I think this is a good idea and I hope it goes well.
this cute kitten does cheer me up :)
Probably comes from rustc [here](https://github.com/rust-lang/rust/blob/4079e6128f6cff3270ed2b0ebdc62fb6b1f4b5d7/src/librustc/ty/item_path.rs#L156). Doing this: // If `cur_def` is a direct or injected extern crate, push the path to the crate // followed by the path to the item within the crate and return.) Looks like Piston is [re-exporting sub-crates](https://github.com/PistonDevelopers/piston/blob/master/src/lib.rs), and maybe this is odd? Looks like it's trying to refer to `piston::event_loop::Events`, but I'm not sure why rustc treats the reexported crate is unnamed. Maybe give that a try? I'm just spit-balling here, as I don't know much about either system. EDIT: `Events` is a trait though, and your error is reporting a type, so maybe that won't work.
The fact that this is so controversial makes me feel unwelcome
Have been working on [Lattice](https://crates.io/crates/Lattice) the Window Manager. I am currently trying to add examples of what a full sized project might look like. This is made quite awkward due to the fact that Lattice manages the render loop whereas other frameworks tend to let the programmer tear it apart and manage state however they want, then render. As a design choice, it is really clean for small projects, however for larger projects it is not clear how to manage program state without resorting to Mutex Boxed or Cell types. This will be a learning experience for me too, because I am writing the library as I go. We'll see how it turns out, hopefully it will be a viable high-level window manager eventually.
On this topic &gt; Finding Missing Pieces in the Crates Ecosystem I've often wondered whether functionality currently implemented as command line apps might be more useful as a library crate with a command-line shell app. For instance, it would be cool to have programmatic access to at least some of the core unix utilities (https://github.com/uutils/coreutils). Or to tools like ripgrep. To support this effort, it might be useful to implement some kind of pipe abstraction (based on channels?) so that tools that were formerly command line-only apps could still be used in a unix-style way. Not sure that this falls into the subject of missing pieces, but it could make existing pieces more broadly applicable.
[removed]
Trying to get more people in the community using ways that might push people who otherwise already were within the main demographic is not good. I absolutely hate bringing any kind of ideological views to a language. I love the technology, but hate how you're trying to label it. Please, stop trying to push your "diversification agenda". You're driving otherwise interested people like me away.
FYI, this post has been removed from /r/rustjerk. It's a sub for good natured humor related to Rust. Please, no passive-aggressive posting of /r/rust threads there.
&gt; People with different backgrounds have different experiences. People with different technical backgrounds, you mean.
Reddit users seem very sloppy about correctly using downvote--it's supposed to be used to downvote posts that do not contribute meaningfully to discussion, and instead it gets used as a general "I don't agree with this opinion" button. I don't agree with all of the opinions here, but I'm certainly not downvoting anything. EDIT: And I am, of course, getting downvoted for saying this.
I see a lot of good comments bringing up good objections to the possibly discriminatory language used. Why do you consider the comments an embarrassment?
I do believe so. Unless I’m remembering an old version and they changed it in the past year or two.
This isn't social studies, it's a technical forum on a technical subject. I had interpreted diversity as more an expression of the lack of participants that fall outside of the language-design / tooling-design / library-design space. These could simply be developers working in other spaces or people with programming problems that don't usually identify as developers (or at least have roles where software development isn't their core role and not an output of their core role). My interpretation has the dimensions of race/gender/language/social-status simply not being a factor in the goals of this project. Yes seeing technology skills broaden in social areas where they're under-represented would be nice to see but surely that's not what this is about. Surely we're just wanting to broaden the diversity of rust developers across the may-varied places where software development is applicable to expose (and hopefully therefore improve) where rust lacks production-ready solutions in it's core libraries, externally maintained crates, tooling or documentation. Am I wrong? Has rust really turned SJW?
Yeah. Every practical language is multiparadigm. Yes, even Haskell.
I have to somewhat disagree. I, as a cis white male from North America feel that things like this say "we don't want your contributions here". And let's be frank, you are offering payment (hotel rooms, conference tickets, etc) based primarily on sexual orientation, gender, or race. I get the motivation, but I feel it is misguided. Paying someone because they are a minority is as bad as paying someone because they aren't one. And honestly, I think you guys are running dangerously close to a discrimination lawsuit. You are basing hiring decisions on pretty much all of the protected classes and have written down that it is a primary factor. This isn't a legal threat from me, but you might want to run this by some lawyers if you haven't already. I will still support rust, gay rights, civil rights, femanism, etc. I even support outreach to those minority groups. But giving out prizes primarily based on someone being in one of those minority groups feels wrong, just as it would for a majority group.
&gt; My interpretation has the dimensions of race/gender/language/social-status simply not being a factor in the goals of this project. Yes seeing technology skills broaden in social areas where they're under-represented would be nice to see but surely that's not what this is about. &gt; Really? It doesn't seem that way to me. They put it directly above the apply line. That implies its an important trait in factoring in if you get chosen or not. Explicitly mentioning this and then leaving out that they will not be using such traits in how they choose people leads me to believe they will be using those traits to choose people. &gt; Surely we're just wanting to broaden the diversity of rust developers across the may-varied places where software development is applicable to expose (and hopefully therefore improve) where rust lacks production-ready solutions in it's core libraries, externally maintained crates, tooling or documentation. Broadening the diversity of technical backgrounds is a very good idea. It's much needed to expand Rust into ares of game development, for example, where the language could conceivably shine the most. The second quoted paragraph is explicitly not about that however. Edit: Quoting the definition of "especially" as used in that paragraph. "used to single out one person, thing, or situation over all others". &gt; Am I wrong? Has rust really turned SJW? I hope it hasn't or it will be the death of the language. It's okay for now but if this gets deeper then people will start to get excluded based on their lack of diversity. I don't want to see this language die.
The reason given by the designers was "generics are complicated, we'll do it later". That was 8 years ago. To be fair, generics *are* complicated. A large part of the design effort in Rust was in getting the generics system right (though, it has a few other properties that make this extra tricky). But generics are so essential to good software design that it's worth the complexity. It's certainly *more* complex to retrofit them later on. There's really no excuse for releasing a static language in the 21st century without having generics as a core part of the design. The weird thing is that people come up with contorted explanations for why the lack of generics is actually a good thing. The overriding goal in Go is to make the language simple enough that you can learn it in a day. I don't understand why this is important for a tool that you will hopefully use for many years. Go is also a language [designed around contempt for its users](http://nomad.so/2015/03/why-gos-design-is-a-disservice-to-intelligent-programmers/). Here's a quote from Rob Pike: &gt; The key point here is our programmers are Googlers, they’re not researchers. […] They’re not capable of understanding a brilliant language but we want to use them to build good software. This attitude pretty much ensures I'll never use Go in a professional capacity. I don't want an employer to "use me" by giving me bad tools, and I don't want to work with people for whom expectations are so low. If you think that only "researchers" can handle generics, then you haven't been paying attention to any trends in programming language design since the 1960s. And indeed that's the impression I get from Go. A good language provides abstraction capabilities (like, say, generics) that allow programmers of varying skill levels to collaborate on subproblems of varying difficulty. Go, much like old Java, just pulls everyone down to the lowest common denominator.
Thank you for making the most balanced post in this thread. Both sides are probably downvoting you.
PDF is an incredibly complicated format that's sort of the poster child for potential for hiding malware. https://www.youtube.com/watch?v=54XYqsf4JEY
Is it not true that the notion that a group with more people from minorities is inherently better than one without is discriminatory and prejudicial?
Not at all. Such a group will have a greater breadth of life experience and perspectives, and will be less likely to discriminate, intentionally or otherwise, against others.
If you're seeking to diversify based on experiences and perspectives then are there not better ways than to select based on race/gender?
&gt; why was the rest of the data in that survey ignored It wasn't, this whole year has been full of projects addressing it. Your post shows a distinct lack of care for increasing the usability of Rust and instead values the status quo to the point of ignoring the very premise of the project- that we have concrete reasons to believe social diversity *does* contribute to technical quality.
It would be handy if there was a tool that could suggest derives for your code that are standard things to do. This is especially helpful for people new to Rust such as myself. I didn't even realize there was a derive keyword or what things can be derived until I saw it being used by others.
&gt; Your post shows a distinct lack of care for increasing the usability of Rust and instead values the status quo To the contrary. I want this increased the most, as a new user to Rust. &gt; ignoring the very premise of the project- that we have concrete reasons to believe social diversity does contribute to technical quality So again, you're admitting here that the premise of this project is increasing social diversity with the hope that it may contribute to technical quality. I'd love to be pointed to scientific studies that show that social diversity (of every kind) has direct and measurable increases to technical quality after it has removed or accounted for any factors of technical background diversity. Lacking that, I would argue that social diversity is good goal, but it is orthogonal to increasing the quality of Rust as a language for new users. Being welcoming of all backgrounds is important, without singling out any specific background.
Not if you're trying to make a language more accessible to the groups that use it the least, and those groups happen to include people of color and women.
Btw. this interactive study to slight biases and the biased demographics they create was very entertaining and insightful, I highly recommend it: Parable of the Polygons - a playable post on the shape of society http://ncase.me/polygons/
Well, this barrier (at least in its current form) spins when waiting, which wouldn't be acceptable in the std lib (and should probably be mentioned in the docs now that I think about it). This is likely the right thing to do for applications that care about the latency of barrier synchronizations, since thread sleep/wakeup is pretty expensive, but is probably not the right primitive for everyone. A compromise could be reached by using a spinlock that eventually yields such as https://amanieu.github.io/parking_lot/parking_lot_core/struct.SpinWait.html though.
Just released 0.1.1 which will at least yield eventually if it spins for a long time. Technically we could do even better if we put the thread to sleep eventually by using a fallback `Mutex`, but that requires some further tweaking.
Hi thanks for the info, would it probably be better to post it there? 
I looked it up and yes the API is quite similar. But they're using C++ and we are using Rust. We have a better solution to the problem. We have safe borrowing. 
You want /r/rustservers
[removed]
Sorry to burst your bubble, but Rust has ALWAYS been sjw. That's just not visible inside the rust bubble--mostly because the people who are hardest hit by that are silenced here.
There are not, but if you started one, I'd show up. Rarely the Bay Area meetup has drinkups in Mountain View.
You should add a bench with a 10ms delay and see how it fares to stdlib
I'm not really well versed enough in Rust that I'd consider myself able to start one. Hopefully someone else comes up with one.
To those downvoting /u/savage884: please take a moment and read the [reddiquette](https://www.reddit.com/wiki/reddiquette), especially what it has to say about downvoting.
[removed]
Docs.rs build documentation automatically for every packages. You can add link to it in the Cargo.toml file to have a link to it from crates.io.
How about transformers that can make an infinite iterator finite? e.g. `take_while` can't know if its predicate will ever be false, but if you the programmer know it, you may still want to collect it.
If time allows, I would be happy to join.
I see, thanks for clearing it up!
&gt; This doesn't push anyone out, except people who are so unreasonable that they don't want to be part of a community that's trying to be inclusive. There is a real discussion to be had about allocation of limited resources, and the appropriateness of allocating them based on demographic characteristics. I approve of this program, but it's not unreasonable that people will have qualms. We don't have to agree on everything!
&gt; Am I wrong? Has rust really turned SJW? This diversity emphasis has been part of the language from the very beginning. Actually I would say it's less so now, after the departure of several early contributors who were a lot more hardline / extreme about identity politics.
I don't understand your point here. That sentence was more about the fact that pattern matching forces you to handle all cases.
You might be right. I'm not sure I understand the operational semantics of what the would entail well enough to say so though.
Maybe we could have a trait for piping between unix-like apps, and write code like: fn main() { for i in 0..10 { cat.file(format!("trace_file.{}", i)) | grep("-in profile"); } } Not very strongly typed, but might work.
Sorry, i didn't no that this exists
Oh, I see, maybe we could have written it in another way
Correct me if I'm wrong, but isn't it unfair to compare JMH to a compiler that makes these optimizations that JMH suppresses them? For profiling, I can see the role that JMH would play in reducing the the side effects of using JVM when benchmarking. But when comparing languages you want them to be running more or less how they would perform during normal use.
Fair enough!
You can take Caltrain! The Mozilla SF office is close to the Caltrain station.
I have solved similar problems in the past by having a separate datastructure of the same shape with the metadata. This eliminates range checks and it can be allocated on the stack. This is not possible in Java and C++ AFAIK since it requires some type level programming with traits and associated types.
You don't need to be! Sometimes all it takes is some interest, some motivation and a couple of people interested as well. A lot of meetups started as casual meetings in a cafe/bar/some-other-place just losely discussing the topic with just 2 or 3 people. You are also welcome to [talk to the community team](https://community.rs/) to see how we can help connect people.
Uhm, if there are data structures in the stdlib that use `sync::Barrier` internally, perhaps they should have a swappable barrier, as a type parameter that defaults to `sync::Barrier` (just like hash tables have a swappable hash implementation).
Is it so unreasonable to want to be valued solely on the merit of your contributions? I fit in many of these categories, yet I almost never disclose it because I don't want my identity to taint how critical people are of my work.
[removed]
[removed]
[removed]
&gt; if you follow every possible control flow path and no control flow path reaches an exception you can prove an absence of exceptions. To do that you need to test all possible values of all variables. For example, if a function receives a `MyStruct` parameter, which is a struct that has 2^1024 possible values, to guarantee that the code behaves correctly for all cases with tests alone you need to test it for all possible 2^1024 inputs. Which is not scalable. You can instead devise a proof using mathematical induction. Integrating this with the language gives you the tooling of modern formal verification, which is more powerful than writing unit tests.
&gt; Showing gratitude to reviewers and team members for their work is an orthogonal issue that should be tackled independently of this one. I don't know for others but I'm personnally investing much more than 3 to 5 hours a week on Rust. It's more like 3 to 5 hours a day on week days in fact, for the past two and a half years if not more. Yet I clearly can't afford to pay for a plane for the US, a hotel and the conference entry fee. In fact because of the 200$ or so entry cost I'm even hesitating to go to Zurich this fall even though I live close by. I don't have anything against integrating minorities, but reading that people would get invited for free for little work was a bit disappointing. 
The embarrassment is him not stating which comments he disagrees with.
[S-expressions] (https://en.m.wikipedia.org/wiki/S-expression)? They are dead simple, easy to parse and predate json by a couple of decades to boot. :) 
C#, and js might be overengineered. Not Java. Java is a REALLY simple language. C++ is also easier to learn and use than Rust imo.
How about not telling people how to use the vote buttons. It is virtual internet points. No body is losing anything. Vote ratings help judge how the opinions are distributed.
&gt;This doesn't push anyone out, except people who are so unreasonable that they don't want to be part of a community that's trying to be inclusive. It pushes me out, and I don't want an "inclusive" community. I want a community based on individuals merits. Not a community based on individuals skin color or sex. If having a "diverse" enough community doesn't work without artificial respiration (trying to get people on board simply based on their physical attributes), maybe those people weren't fit for the community to begin with? I'm a strong believer in Darwinism, and I believe it applies to programming excellently. Be good or be out. Edit: downvotes without any counter arguments? You're childish. Check out the reddiquette while you're at it. 
Western would be the same. 
No body in here mentioned being unwelcoming to others.
I ended up using `std::process` and `youtube-dl` - it's just too good to not use :)
&gt; Actually I would say it's less so now, after the departure of several early contributors who were a lot more hardline / extreme about identity politics. This is off topic at this point, feel free to PM me, but I'd like to hear some of this back history as someone new to Rust. Links are welcome.
I saw it a few times, but it was always for very precise categories (mostly students) and I wasn't in them.
&gt; Applications are open to anyone who would not normally attend, That's the wording in Rust conf, which actually is pretty good at this. In most conference website the only thing you get is a line at the bottom of some webpage that says something like: "If you feel you should attent but can't for economic reasons please send an email to this address explaining why and we'll do our bests to help". If you don't actively look for it, it's very easy to miss, but all conferences have something like this or an email address that you can use to contact the organizers. /u/imperioland Meeting C++ has a students program: https://meetingcpp.com/index.php/newsreader/items/announcing-meeting-c-student-program.html where student is defined as between 18-25 years old. Still, if you do not qualify you can contact them and they will try to help. Everybody understands that even if you are not a student, paying 1000$ for the trip, 500$ for accomodation, and 500$ for the ticket, for something to what you are contributing in your free time is a lot of money. Most of the people get sent to the conference by their companies which pay for everything. It isn't very hard to sell sponsoring a student to your company. "Hey for 1000$ donation that reduces your tax bill we get publicity of sponsoring the conference, which attracts talent, and get to know a high-profile community member that we might be interested in hiring". Its basically a win for every company.
&gt; but I stand with my original post that this is a completely orthogonal issue to what is being discussed here. Until recently my point of view on Rust is that it was this small developping language with little funding. I felt like I was contributing to "a better world" (as cliché as it sounds) by writing libraries for free in a langage that would in the future prevent crashes and safety holes. I felt surprised when I saw a few months ago that tokio (IIRC) was receiving money for some full-time development. Money is sparse in open source. And today by reading this blog post I learn that Mozilla would pick random people ("random" in the sense that there doesn't seem to be any interview or skill requirement to join the program), ask them to perform in total between 39 and 65 hours of work and give them approximately 1500$ in return. Oh, and they prefer if you're from an underrepresented community. I don't belong to an underrepresented race/community, but what I am is poor. And it feels bad to see that the organization you "worked for free" for 20 to 30 hours a week for the past two and a half years screws you up and starts giving out money to people for little contribution. EDIT: I'm quoting you saying that this is orthogonal, because my point is that money is very limited. For me the benefits of inviting underrepresented people is much much lower than for example the benefits of hiring a second alex crichton with that same money. 
I don't think JavaScript's problem is being over-engineered. It was originally designed and implemented by one person in 10 days.
That would be fine if it weren't for the fact that downvotes decrease the visibility of content. Downvotes hold more power than just "virtual internet points." They control what is shown to site users and what is not.
Yes and that's another problem. I think we're facing a vision (or maybe I'm just completely outdated?) I can't agree with: "we have to have minorities". Whereas I agree we should be *open* and *welcoming* to them, but I don't see why it'd be achieved by disregarding the current community. Also, since they're part of a minority, shouldn't it be logical that they're still a little number in the community (proportions and stuff)?
At a cursory glance: 255 is too big for i8. You probably mean u8 instead. Anyways: why you're getting that exact result depending on target is unknown to me. Undefined behavior maybe?
Can you post a working playground link (https://play.rust-lang.org/), where the problem can be recreated?
&gt; Whereas I agree we should be open and welcoming to them &gt; ... &gt; Also, since they're part of a minority, shouldn't it be logical that they're still a little number in the community (proportions and stuff)? Yes. IIRC the problem is that it is not unusual that potential contributors in these minorities do not join the community unless there are already people from those minorities in the community. So it's a bit like the snake that bites its own tail. Sometimes this happens on its own, sometimes it doesn't. As the community gets larger, the danger that they will never joing gets larger. So I can see how it might make sense to actively try to get them involved now that the community is growing exponentially. I am not saying that throwing money at the problem is the right solution, but somebody decided that it was worth the money. We'll see if it works. &gt; but I don't see why it'd be achieved by disregarding the current community. While I can see why seeing this might hurt, I bet the decision wasn't taken on lightly. First, this is a problem worth solving. $1500 per person for 5-6 people is nothing. For this money, you might pay a high-profile dev 1-2 months, but nobody will quit their full-time job for a 1-2 month job security. I can see how for funding opensource devs full time Mozilla would need 50k-100k per year per dev, which is 1-2 magnitudes larger than this. Third, we don't know where this money comes from. It might be a donation with strings attached, like "you can only use it to increase the representation of minorities in open source". In this case, I doubt there is a better way to spending this money. 
As an aside, you will also want to use `{:02x}` in the formatting string, otherwise color components smaller than 16 will only have one character.
Good job reducing the problem. Even easier to see: Copy the second println before the first one. [Playground](https://is.gd/8nakl0) Remember to switch to release mode. fn main() { let f = 128.0; println!("#{:x}", f as i8); println!("{}", f); println!("#{:x}", f as i8); } *edit* Even weirder: [Playground](https://is.gd/MTpRRv)
Good point, thanks.
So it was indeed a stupid user. Thanks!
I don't know about the user, but the undefined behaviour is an actual compiler bug as pointed out by CryZe92: https://github.com/rust-lang/rust/issues/10184
Maybe he was referring to [this article](http://yager.io/programming/go.html)?
Did see on the Stackoverflow survey Go had hit 4.3% use and was the 3rd most wanted. Rust was the most loved of any language. https://insights.stackoverflow.com/survey/2017#technology
My specific use-case is decoding a protobuf message with a `.fdset`/FileDescriptorSet.
I'd also like to know where the assumption that a community is underrepresented comes from. Do we know how many trans people there are in the programming community, for example? 
I honestly don't know. Do you have a reference for that? As mentioned above though, the win doesn't just come form spinning, but rather mostly from a more efficient and scalable barrier algorithm (which doesn't use a Mutex at all) 
I simply mentioned OTHER people bringing him up, and consider this relevant to the discussion on sjws.
*Stupid user* (not my words) because of using `i8` instead of `u8`, resulting in an actual compiler bug...
Field needs to be read and updated from different threads. Field stores cached message size. It is safe, because when field is used, user has only immutable reference to the message, message is not changed, and order or loads and stores is not important. It is atomic only to guarantee that loads and stores are atomic. Memory ordering is not important, so loads and stores are "relaxed". They are as cheap as simple `usize` field. FYI, this is how C++ version of protobuf works. Practically `UnsafeCell&lt;u32&gt;` can be used for field, but `UnsafeCell` (in theory) does not guarantee atomicy of writes, so it is `AtomicUsize`.
I thought overflow was defined to wrap around in Rust?
... and something like [`DynamicMessage`](https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/DynamicMessage)?
Your arguments are a gross mischaracterization of the project we're discussing, and they are the exact sort of thing the Rust community decided to exclude from the start.
&gt; Reddit users seem very sloppy about correctly using downvote I strongly suspect it's less 'sloppiness' and more 'active disagreement'.
Float to int conversion can result in LLVM bitcode with undefined behavior, which is a compiler bug. LLVM doesn't have a fast and safe way to do float to int conversions so fixing this bug is difficult.
Statistics. But since those are the third kind of lie (besides lies and damned lies), it's all about how you read them. There are few transpeople in the programming community, but there are also very few transpeople altogether. And iirc, they are overrepresented in programmers compared to their share of the overall population. Make of that what you will.
"People just starting out in tech" can be ambiguous to the point of just being unhelpful. Some people may have VASTLY more experience than others, and still regard themselves as "starting out" because that experience isn't of the formally recognized sort.
&gt; Is it so unreasonable to want to be valued solely on the merit of your contributions? That you feel you should avoid disclosing your identity is *precisely* the sort of problem this is trying to solve. So no, that's totally reasonable. If you personally would prefer to continue without disclosing your identity, that's fine. Hopefully someday you won't feel like it would taint people's opinion of your work.
What about an opt-in to safe (but not necessarily fast) behavior? If this isn't in an inner loop, I'd probably be willing to burn tens of cycles/pipeline flushes just to make sure it's correct.
I agree: only skills should matter. Everything else is irrelevant.
I don't. The basic idea is that *currently*, people in underrepresented groups are underrepresented for some reason *other* than skill (because we agree those attributes aren't a factor for ability). The likely explanation is factors like social conditioning and the unconscious bias that lead to it. These affect us even on the internet where we don't always see those things about a person, because social conditioning affects both 1) our behavior and 2) their willingness to deal with it. Active efforts to counteract those existing biases in our community are not attempts to favor people for their non-technical characteristics. They are attempts to counter pre-existing factors that work against them, so that we can then *truly* evaluate everyone's contributions based on technical merit. An analogous point was made in this sub on a similar thread- civility is the foundation of quality technical discussion. When technical discussions turn into heated arguments, it distracts from the actual issues. So that's why we have rules about patience and empathy- and by analogy, that's why the team is going out of their way to find technically skilled contributors who would otherwise not participate for non-technical reasons.
Overflow of unsigned types wraps around, of signed types is UB (blame C and llvm for this). There's also the issue that casting floats to ints out of range is (apparently?) UB, per [this issue](https://github.com/rust-lang/rust/issues/10184).
But the comment I was responding to was.
Regardless, I've just seen many people making this mistake, and wanted to make that clear.
&gt; I'd be willing to bet minority groups are underrepresented because there's less of them.. "Underrepresented" doesn't just mean "less." It means "proportionally less." About 50% of the population is women, less in programming (but I do not believe for intrinsic reasons like you imply with your comparison to construction), and even less in open source. I can see why someone would be frustrated with efforts like this if there weren't such a difference in numbers between programming and the population, or especially between open source and programming-in-general. But it's pretty clear at this point, both from the numbers and from the words of actual people in these groups, that there are problems with programming and open source culture. This project thus *is* an attempt to "see people as people." Asking them their opinions and trying to accommodate them, so they can feel just as much a part of the community as those who aren't currently made to feel unwelcome.
The Rust survey collected demographics, but I haven't looked at them – if somebody wrote a blog post comparing the numbers with general tech, open source and population at large, I'd be interested to read. https://news.ycombinator.com/item?id=14658750 This comment points out that Rust does awfully at the male/female ratio of Stack Overflow survey. On the other hand I find it surprising considering how nice the Rust community is, but on the other hand the tech - low level - open source - early adopter - hobbyist combination might be generally even more biased than the overall tech field is.
Though to be clear, undefined behavior should not be possible here. It's the result of a longstanding impedance mismatch between rustc and LLVM which we've only recently devised a semi-satisfactory plan to address.
I wouldn't say it's the user's fault; triggering a codegen bug is squarely on the compiler's shoulders, regardless of how the user triggers it. :)
How anyone is made to feel _unwelcome_ to Rust still remains a mystery to me. Let's see, someone decides they want to learn Rust. They'll probably go read up on some tutorials, try doing some easy tasks with the language, and then decide they want to do a little project of their own using it. They come across a problem while trying to do something. Now, they have multiple options to go forward. They can ask questions here on reddit, on IRC, multiple different forums and so on. I don't see how these platforms can be discriminative against the user. Now they decide that Rust is a fun language, yay! So they want to get more involved with it. They'll start regularly hanging out on the irc channels for example. Those irc channels are heavily moderated, so the chances of facing discrimination are really low. In what way will these minority people face discrimination / unwelcomeness in the Rust community? Also, I still see no reason why the individuals themselves would want to make a point of a group they represent. Programming communities probably aren't the best place to discuss anything race and / or gender-related, these communities exist as a way for programmers to discuss programming. &gt;But it's pretty clear at this point, both from the numbers and from the words of actual people in these groups, that there are problems with programming and open source culture. Or these particular groups of people just don't see programming as something they'd want to spend the rest of their lives doing.. Which I happen to see as the most likely option. People really are different, and gender can matter in these things. &gt;This project thus is an attempt to "see people as people." No, this project is an attempt to try to get individuals from minority groups to join the language community, by raising their physical attributes as a more important merit than their skills. The same thing as what some (quite horrible) companies do when they're performing "diversification". "Oh, sorry, you were a good applicant with an excellent track record, but unfortunately we're looking for a more diverse set of employees, so you didn't make it this time :)". Shouldn't that be illegal? I don't know, but it happens, and they're essentially throwing away the value of knowledge and skill, and seeing "group status" as a more important factor. This is what I fear the Rust community is trying to do as well.
I've been thinking about trying to start one for around a year. SF isn't practical for me to get to pretty much any day. I usually talk myself out of it because I'm pretty introverted, don't really know people and don't even know how to begin looking for a location to host it. That and I'm pretty noobish with Rust. That said, if anyone has ideas or wants to help out feel free to message me.
Yeah, more generic programming would be quite nice. But also, I imagine, hard.
Interpreting an u8 wrongfully as i8 is a user error, regardless of how the compiler treats it ;-) (I agree, a codegen bug is a compiler bug, no matter what)
Getting from SJ to SF via train is still quite a trek. And it doesn't help everyone who's around the SJ area (like me down in Santa Cruz).
All your examples are at least related to your technical ability, which makes perfect sense in a job offer.
&gt; How anyone is made to feel _unwelcome_ to Rust still remains a mystery to me. That is why this project exists- to find out. One particularly high-profile example is Google's image recognition accident in which they identified black people as gorillas. The explanation, IIRC, was that their training data was just skewed toward white people. Understandable oversight for a bunch of white people to make- which is why it's important to go out of our way to avoid that sort of thing. Obviously a compiler doesn't do image recognition- the point is that nobody thought to consider that particular failure mode because it didn't affect them. Accessibility (for e.g. blind, deaf, colorblind) is a much less controversial example with the same principle. So the goal here is to find out *if*, and if so *what* failures we might have in the tools, documentation, etc. around Rust. &gt; People really are different, and gender can matter in these things. Gender is 1) not the reason for the low numbers of women in CS (they started out much higher and only went down after social changes), and 2) not the only underrepresented group we're talking about here. This is an especially terrible argument if you don't have any evidence to back it up, because the assumption should be that it's irrelevant. &gt; they're essentially throwing away the value of knowledge and skill In this context, this is a strawman. Rust isn't a company interviewing potential employees, it's an open source project. The compensation this handful of people will receive is minuscule and not costing you anything. You're free to go to the same conferences, and even to apply for [a scholarship ticket](https://tilde.wufoo.com/forms/rustconf-scholarships/) if you can't afford it.
Indeed, I would expect concurrent pipelines with the need to observe the full picture built by the previous stage to be a case where barriers shine.
Have you seen Clojure's [Extensible Data Notation](https://github.com/edn-format/edn)?
But but but... Hyper 0.11? 😇
I have. It's a very clean, reasonable and readable extension to S-expressions. It looks very neat and useful, but I haven't had the time to hack any clojure so I haven't used them in pratice yet and I haven't seen them used in any other language.
Though it would be a fun project to write up a ML script to do this 😃
I'm not talking about terminology minutiae, if that's all you're worried about. (Though really, getting upset about someone renaming "slave" is *at least* as much a waste of everyone's time.)
[removed]
Even if the diversity side doesn't pan out, the projects themselves still all sound useful to me- rustdoc improvements, more clippy lints, a better crates.io interface, more rust tutorials, more utility crates. Those are all things that are important regardless of accessibility and inclusiveness- it's just also good to look at them from that perspective while working on them.
&gt; Overflow of unsigned types wraps around, of signed types is UB This is not true for Rust.
[removed]
You're right, didn't think of those. The technique still works, but you would have to use Vec for repeated fields and Box for recursive fields, so the stack allocation advantage is lost.
Thanks! I've very much enjoyed working with rust over the past few months. I admit the borrow checker took awhile to get the hang of and I suspect my code is less than idomatic in some places, but it is a great language. I hope the project is interesting enough to garner some help from the community so I can continue to learn.
Eh, like any large organization I'm sure there's a huge difference in every way just going team to team, department to department.
I managed to get an FNMut to use a scoped lifetime, however the scope variable gets passed through to every object and the whole library becomes littered with explicit lifetimes. ``static`` is just more sane and sanitary, all things considered.
I took a quick look at the code, and I think clippy would likely be a good place to start. I see for loops that push into a vector and call 'iter()', which I think a lint would likely catch since there are more idiomatic ways to do that (like a .map().collect()). Also noticed a fair amount of unsafe code in the seccomp code - specifically transmute, which is always a scary one. May be worth auditing/ writing tests around that if you haven't already. Really cool though.
This repo has 3 commits done by one person. Good to see Rust being used, but lets not exaggerate.
This is such a great effort, keep up the great work! &lt;3 &lt;3 &lt;3
Parser combinators are less powerful than what parser generators can do, in terms of expressiveness and efficiency. And we've known parser generators since the 70s. So I'm not sure what the point is of the title of the article.
Rust jobs and polished domain specific libraries are still hard to come by, so what Rust needs for mainstream adoption (among others) is the enterprise world. And Oracle is the definition of enterprise.
There's been some heated discussion on this thread, so I wanted to share my thoughts as part of Rust's leadership. Rust's community is one of its greatest assets. That is not an accident: from the very outset, the project has placed equal weight on "human" and "technical" aspects---indeed, it has seen them as inextricably intertwined. To make Rust's core ideas work at scale, we've had to push hard on human-oriented affordances: ergonomics, learnability, documentation, and fostering a welcoming community in which people feel comfortable asking questions at every level of knowledge, knowing they'll be treated with respect. Similarly, one of the most exciting and promising aspects of Rust is its ability to empower a much wider range of people to do systems programming. This is, again, not an accident. Even if all you care about is Rust's marketshare, this is *huge*, because there are a lot more people out there with systems programming needs than people who are prepared to write C++. Our roadmap for this year has, as two major focuses, improving learnability/accessibility and improving mentoring at all levels of the community. You can disagree with whether those *should* be the goals, but they are. We are doing a lot of work, in a lot of venues, toward these goals (see, for example, the expansion of the subteams and shepherds). This initiative is another part of this work. Our survey results from last year (https://blog.rust-lang.org/2016/06/30/State-of-Rust-Survey-2016.html), and preliminary analysis from this year, show that there are substantial gaps in the audiences Rust is currently reaching, some of which are quite a bit worse than the typical underrepresentation in tech. In short, while we are a welcoming and inclusive community, we are not yet a terribly diverse one along at least some dimensions. Increasing this diversity is something many of us would like to do, both for its own sake, and because it will improve Rust's ability to reach new audiences that might not traditionally find their way to our community (and, empirically, are not). It's totally fine if you don't see that as an important goal, but some of us do. I worked with Carol and others to develop this initiative, and have been extremely excited about the way that it's not a mentoring program, but rather one in which people bring in their skills, we bring ours, and in the end everyone wins. And I've been blown away by the response: almost 200 applicants in a little over a day! It's going to be amazing. What saddens me about this thread is its focus on a sort of "zero-sum" view where we're all fighting over a slice of the pie. First of all, this is one initiative among many: there are scholarships for Rust conferences, and sponsors like Mozilla frequently pay for subteam members and other volunteers to attend events, and are funding several open source Rust projects this year. The core team would like to expand this in a more formal way, and expand the set of sponsors; more on that soon. But secondly, and more importantly, our ambition is to grow the pie! The rationale around this year's roadmap is closely tied to that goal. And as I said above, this initiative is one of the many ways we're pursuing that goal. TL;DR: I'm incredibly excited by the huge number of ways we're growing the Rust this year, from the ergonomics initiative to the Libz Blitz to mentoring to async I/O and, here, to Increasing Rust's Reach. I can't wait to see what the participants come up with! 
True, though it looks like more of a code dump with a couple of fixes than a barely-started project.
Actually, on the subject of powershell, tools as libraries has yet another benefit. You could create a dll wrapping that tool, and then have a powershell module be able to call functions from that dll, since Powershell is just .NET and .NET can of course call functions from native dlls. That way you'd be able to preserve structured data without having to convert everything to and from strings!
Liekly just a transition from one source control to github, since the commits are "push everything".
&gt;Mutex and Once only require 1 byte of storage space, while Condvar and RwLock only require 1 word of storage space. On the other hand the standard library primitives require a dynamically allocated Box to hold OS-specific synchronization primitives. The small size of Mutex in particular encourages the use of fine-grained locks to increase parallelism. This isn't a good thing. Atomic locks should **always** be at least 64bytes (not bits) in size (on modern hardware), and preferably aligned to 64bytes but^rust^cant^do^that [False Sharing](https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads) is when you have 2 (or more) *atomic* operations that end up on the same hardware cache line. Now when ever something interacts with one, it ends up interacting and synchronizing with *all* on a hardware level. This can slow down operations in non-deterministic ways (based on system load/malloc library/os memory subsystem). Granted the gain from not using a system mutex is generally so large in most cases that this barely matters in practice. It is like doing a `_mm_pause()` in a *non-contended* spin-lock. Its a gain, but so rarely you have to do some extreme mirco-benching to see it. 
Stickying [Aaron's comment](https://www.reddit.com/r/rust/comments/6k1lz0/announcing_the_increasing_rusts_reach_project/djklgv5/) &gt; There's been some heated discussion on this thread, so I wanted to share my thoughts as part of Rust's leadership. &gt; &gt; Rust's community is one of its greatest assets. That is not an accident: from the very outset, the project has placed equal weight on "human" and "technical" aspects---indeed, it has seen them as inextricably intertwined. To make Rust's core ideas work at scale, we've had to push hard on human-oriented affordances: ergonomics, learnability, documentation, and fostering a welcoming community in which people feel comfortable asking questions at every level of knowledge, knowing they'll be treated with respect. &gt; &gt; Similarly, one of the most exciting and promising aspects of Rust is its ability to empower a much wider range of people to do systems programming. This is, again, not an accident. Even if all you care about is Rust's marketshare, this is huge, because there are a lot more people out there with systems programming needs than people who are prepared to write C++. &gt; &gt; Our roadmap for this year has, as two major focuses, improving learnability/accessibility and improving mentoring at all levels of the community. You can disagree with whether those should be the goals, but they are. We are doing a lot of work, in a lot of venues, toward these goals (see, for example, the expansion of the subteams and shepherds). This initiative is another part of this work. &gt; &gt; Our survey results from last year (https://blog.rust-lang.org/2016/06/30/State-of-Rust-Survey-2016.html), and preliminary analysis from this year, show that there are substantial gaps in the audiences Rust is currently reaching, some of which are quite a bit worse than the typical underrepresentation in tech. In short, while we are a welcoming and inclusive community, we are not yet a terribly diverse one along at least some dimensions. Increasing this diversity is something many of us would like to do, both for its own sake, and because it will improve Rust's ability to reach new audiences that might not traditionally find their way to our community (and, empirically, are not). It's totally fine if you don't see that as an important goal, but some of us do. &gt; &gt; I worked with Carol and others to develop this initiative, and have been extremely excited about the way that it's not a mentoring program, but rather one in which people bring in their skills, we bring ours, and in the end everyone wins. And I've been blown away by the response: almost 200 applicants in a little over a day! It's going to be amazing. &gt; &gt; What saddens me about this thread is its focus on a sort of "zero-sum" view where we're all fighting over a slice of the pie. &gt; &gt; First of all, this is one initiative among many: there are scholarships for Rust conferences, and sponsors like Mozilla frequently pay for subteam members and other volunteers to attend events, and are funding several open source Rust projects this year. The core team would like to expand this in a more formal way, and expand the set of sponsors; more on that soon. &gt; &gt; But secondly, and more importantly, our ambition is to grow the pie! The rationale around this year's roadmap is closely tied to that goal. And as I said above, this initiative is one of the many ways we're pursuing that goal. &gt; &gt; TL;DR: I'm incredibly excited by the huge number of ways we're growing the Rust this year, from the ergonomics initiative to the Libz Blitz to mentoring to async I/O and, here, to Increasing Rust's Reach. I can't wait to see what the participants come up with! 
Oracle is hostile to open-source pretty much across the board. A huge spread of open-source projects needed a hostile fork after Oracle acquired Sun, to name one example.
We have not yet announced any of the results of the survey in any form.
If you mean the raw data, we never release that due to privacy concerns. If you mean the aggregated survey results, we're currently working on producing our analysis. It will take some time, as there are several thousand to go through.
&gt; Oracle is hostile to open-source pretty much across the board. Oracle is many teams and many people.
Ahh thanks
I stand corrected. ([here's an article](http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/) about that)
Deterministic builds are hard. This is when you build the same source on different computers, and get the same SHA-256 from the binary/library. Normally this is a long semi-informed process of trial and error. But one hard and fast rule, if you change flags... you change the shasum. --- Likely this is because *no target* specifies a `generic x86_64` which ensures certain features are not used (like SSE, SSE2), while `target x86_64` may enable that (as SSE1/2 are *technically part* of the x86_64 ABI. 
Did you consider using Tokio ?
Agreed, any we should commend and support any steps towards openness. Oracle has a bad reputation but we should encourage positive output no matter the source.
Thanks. I was sure that was the first thing I tried.. that was what I wanted to do originally. lol.
It is hardly an anti-badge to completely remove the possibility of several dangerous security bugs from a program although I admit this badge wouldn't be as useful for Rust programs.
Maybe unit testing isn't such a good badge. Do you have better ideas?
Do you have better ideas for badges?
Peer reviewed. We should have the ability for people to mark given crates (+ version ?) as reviewed by them with comments raising issues, ideas, etc. I could get unit test coverage manually, locally via some `cargo` plugin. A social network around code reviews would be an awesome project. :) 
Possible? Probably yes. Practical? Probably no. You need a way to preempt the executing thread. You could try with signals etc. but that can leave your program in a weird state. If you run your own code to handle events, you could add preemption points when appropriate. If you can not, you can spawn a new process for for each task, and kill it on timeout. That might be a bit costely if you want to handle a lot of events.
Yes, it's safe - as in you won't have data race. But if there are multiple mutexes that are often used together and are locked not necessarily in the same order every time, it's very likely you'll get a deadlock. So I'd recommend you to rethink your design so to reduce the number of mutexes locked at once.
Looks good but as it's GPL this means that it won't be usable as a library for anything proprietary/commercial (without itself being GPL). Was there a reason why you chose this license instead of something else?
Wait! Does that mean that we have to create a fork of Rust and switch over to that now?!
To expand on what connorcpu said, there's four conditions to satisfy for deadlocks to be possible: 1. **mut**ual **ex**clusion: **check**, by inspection of the above code. 2. **no preemption** (that is, locking can't be undone from outside the locking thread): **check**, since `std::sync::Mutex`es can't be unlocked from the outside 3. **hold and wait** (that is, a thread needs to hold multiple mutexes at a time). Whether or not this is true will depend on how you use the above code. 4. **circular waiting** (or, that there's a cycle of threads each waiting for a lock which another one is holding). Again, will depend on your threading code. Like connorcpu said, one way to prevent deadlocks is to ensure that (3) can't happen by only ever holding a single lock simultaneously. Sometimes that's not possible, though, usually because doing so would hurt performance. An example of that would be if some of your threads wanted to use both `one` and `two` at the same time, but other/most threads only wanted to use a single one of them. If you put both behind a single mutex to avoid (3), the threads which only wanted to use either `one` or `two` would be forced to prevent all threads from using the other one, even though said thread isn't using the other. So another typical way to avoid deadlocks is by preventing (4) through [lock ordering](https://www.mikeash.com/pyblog/deadlocks-and-lock-ordering-a-vignette.html).
There is also https://github.com/tailhook/vagga I haven't used it myself, but I like the fact that it doesn't use a daemon process. 
Well, nvidia-encode is a C library as well, so that might not fit the bill either. It sounds like this person is after a pure-rust encoder.
interesting. I hadn't seen that myself. Both railcar and runc can run without daemonization if you use the run command. For example: `sudo ./railcar run foo`
See also: https://en.wikipedia.org/wiki/Dining_philosophers_problem
I have zero projects. Lets say I want to start a new project from scratch?
So I have redone everything in case I as missing anything. I make the new project and I have a simple hello world. Here is a picture of the error I get when I try to build it. http://imgur.com/a/RcQd8 Also, when I click run, it says to edit configuration.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) https://i.imgur.com/F1BbIBz.png ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[state_of_imgur](https://np.reddit.com/r/u_imguralbumbot/comments/6i1huv/imgur_has_gone_to_shit) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20djl3rs1) 
So, you are using the MSVC toolchain version of Rust, which means you need Visual Studio installed for it to find "link.exe", the linker that puts the final touches on your program before it's ready to run. Right now, there is a bug with the MSVC toolchain that will be fixed by the end of next month, so even if you have Visual Studio installed, you might have to run a "vcvars" batch script that Visual Studio provides before it works. It's also possible to use the GNU toolchain, by opening a terminal and running `rustup install stable-gnu` to install the GNU toolchain, then running `rustup toolchain uninstall stable-msvc` to remove the MSVC one. With the GNU toolchain, you won't need to Microsoft's tools. For the moment, I would recommend the GNU toolchain if you want things to be easier to get started with.
The point of having a small `Mutex` is precisely so that it ends up in the same cache line as the data that is it protecting.
try typing "rustup default stable-gnu" into the terminal, then "cargo run" again. Or you might need to just create a new project in IntelliJ, it could be pulling some old settings from when you first created the project while using the MSVC toolchain. Or you might need to reboot? I'm really not sure. I mostly use Linux, so I'm not familiar with all of the gotchas of using Windows with Rust.
Take me under your wing I need this knowledge
Sounds like you have some heavy cargo you're not telling us about?
Oh... Maven wasn't their software was it?
Ah, well, the reality is that `collect ()` is basically an `assert_finite()` already. Or the next question will be, "why is it allowed to assert finite on something that's clearly infinite?"
Yes, it is.
I'm not sure what you are trying to achieve but I highly suspect, this would help: struct HashMaps { one: HashMap&lt;String, u64&gt;, two: HashMap&lt;String, u64&gt;, } struct A { hash_maps: Arc&lt;Mutex&lt;HashMaps&gt;&gt;, } This would avoid the deadlocks. Bonus points: faster (fewer atomic operations, just one lock), smaller memory footprint (no need to store two mutexes), probably cleaner code.
I genuinely appreciate that. I'd really love to see some of Sun's old attitude back. I suppose I'm just a bit bitter about the closed doors development of, primarily, ZFS still.
Cheers, I'll look into it! This looks really helpful! I'm happy to use a C library if it's the best way, I'd have just preferred to keep the project in pure Rust if possible.
In your `ShortcutEq` trait, `Option&lt;ShortcutId&gt;` can't be passed around - since `ShortcutId` is a trait and therefore could be any size. Imagine if you implemented `ShortcutId` for both `u8` and `u32`, for example. When you use a trait as if it were a normal type (such as in `Option&lt;ShortcutId&gt;`) it implicitly is given a `'static` bound, so that's really `Option&lt;ShortcutId + 'static&gt;`. What that message is telling you is that in order to be stored in an option, the argument to `Option` must implement `Sized`, which that does not.
Wow exciting! Does supports Hidpi? Almost all the other ones (like luakit, etc.) based on gtk2 and unfortunately doesn't support neither smooth scrolling nor hidpi displays.
As someone who's been fighting with making decent makefiles recently, this is really hecking cool!
I'm still continuing on porting our nodejs microservices to Rust. Recently I faced a problem, I needed to wait for mongodb and redis instances to get ready (running on containers). So I wrote a relatively small macro (https://gist.github.com/umurgdk/700be82f9bb55065e18bdbc88fc49f27) to make it easier to retrying to connecting to those services again and again until the given timeout (duration) is reached. The macro basically takes a number of closures (n = number of services you want to connect/wait) and running them in parallel until they return Ok(val). If any of the closures are still failing after timeout whole macro will return Err(()). Otherwise it unwraps the inner results and returns an Ok((v1, v2, v3)) tuple. I'm still working on the ergonomics, the code doesn't look that good :/ But I already start using it on the microservice port i'm working on. I would be very happy, if anyone can give some feedback and/or tips about using the macros. 
I think the first example is doing exactly what you want. You just need to adjust the code at the bottom to "unwrap" the nested writers, and retrieve the underlying `File`. Rather than: a.finish().unwrap(); match fo.finish() { you want: match a.finish().unwrap().finish().unwrap() { The reason for this is that your Builder `a` has taken ownership of the `fo`Writer on this line: let mut a = Builder::new(fo); So you must ask `a` to give `fo` back to you rather than using it directly (which is what the handy `finish` method does, assuming that the method on the relevant Writer is actually called `finish`. (This depends on the library you are using, for example, this one https://docs.rs/tar/0.4.13/tar/struct.Builder.html would require you to call `into_inner` instead of `finish`)). If you want to write to an in memory buffer instead of a file, then you can have a `Cursor&lt;Vec&lt;u8&gt;&gt;` (created via `Cursor::new(Vec::new())` like you suggested) as the inner writer in place of the `File`. You can then do what you like with this data once you've unwrapped it using `finish`/`into_inner` to obtain the underlying `Vec&lt;u8&gt;`. In order to write from multiple threads I believe you would need to wrap the `Writer` in an `Arc` (Atomic reference counted variable), which would handle the thread synchronisation for you), alternatively you could have a dedicated writing thread, and send messages to it from multiple threads using a Multi-producer Single Consumer channel `std::sync::mpsc` from the standard library.
I imagine this refers to futexes, which are *f*ast *u*serspace m*utexes*: http://man7.org/linux/man-pages/man7/futex.7.html You might be able to make more of this deep dive than me: https://locklessinc.com/articles/mutex_cv_futex/
This is not a theory paper, but a pragmatics paper. It does not claim parser generators are novel. It claims that in the context of rust and nom, parser combinators are more applicable than ever, and specifically to attacking a particular source of security holes, which they attribute to using parsers implemented in C/C++. That this benefit is applicable only to a limited subclass of languages, that is a minor (though important) qualification, as long as it applies to enough languages of practical importance. For these languages, their title essentially claims there is not longer any excuse for the parser to be a huge source of vulnerabilities, therefore existing common practice is obsolete. Hope that helps. I for one think its a good paper inside its reference class!
Apparently, [yes](https://blogs.igalia.com/carlosgc/2017/02/10/accelerated-compositing-in-webkitgtk-2-14-4/), (see also [this](https://bugs.webkit.org/show_bug.cgi?id=141782)). I never tried that, thought. I plan to add an option for smooth scrolling.
To be honest, I prefer OP's take on it even if its only advantage is not using the dreaded make-like syntax.
It's the `Future`. (And `Stream`, and everything else).
I don't think it is for the `WebView` since there's [a function to enable that](https://webkitgtk.org/reference/webkit2gtk/2.9.2/WebKitSettings.html#webkit-settings-set-enable-smooth-scrolling). I've just remembered that I already have [the setting](https://github.com/antoyo/titanium/blob/master/src/settings.rs#L76) to enable this option in titanium.
&gt; So, now the fns of ShortcutEq&lt;T&gt; accept any Type T that implements Debug. Because Shortcut derives the trait Debug, it's a valid type for ShortcutEq&lt;T&gt;, correct? Yes. &gt; How can I bound ShortcutEq&lt;T&gt; to only accept concrete types of a genericShortcut&lt;T&gt; You have to create your own trait and bound on that. Note that you can bound on the intersection of multiple traits e.g. `T: Debug + Eq` will only accept types which implement both `Debug` and `Eq`. &gt; I also struglly to understand where to add the annotations, to the struct or to the impl and so on. I haven't understood that. ;( Yeah it's not really simple, and lifetime annotations are even more troublesome sadly. 1. You have to understand that generic type annotations only mean something within a scope, there is no intrinsic relation between the T of struct ShortcutEq&lt;T&gt; and the T of impl &lt;T&gt; ShortcutEq&lt;T&gt; you could also have struct ShortcutEq&lt;AThing&gt; and impl &lt;Bob&gt; ShortcutEq&lt;Bob&gt; and it'd work the same 2. you have to understand whether you are *declaring* or *using* the type annotation, for instance in `struct` you're *declaring* a generic type associated with a structure, the generic type can then be used *within* the structure. For the impl block however the generic type before `for` is the declaration and the one after *is already a use*. Generic types are just variables. 3. read the error messages, and importantly read the associated help text e.g. &gt; error[E0207]: the type parameter `T` is not constrained by the impl trait, self type, or predicates If you [look up E207 in the error index](https://doc.rust-lang.org/error-index.html#E0207) it expands on the issue and provides example. Things are nowhere near perfect yet, but a lot of work has gone into these messages still. &gt; Tryingt to tell the program that DefaultShortcut is of type &lt;T&gt; I don't understand what you're trying to do here.
I gotta know: does just require tabs?
the difference is that NPEs happen at runtime, when your boss or client is trying to use the software. With Rust, those errors are happening at compile time. (it's certainly possible to have Rust panic at runtime, especially if you tell it to, of course)
Same here. I found it helpful to take a break after the second attempt, and go learn OCaml. It has a lot of similar ideas, but you can learn them without also having to deal with the borrowchecker. When I came back to rust, it started clicking more.
I think it is because luajit is appearing before tst in the link command. You could try adding println!("cargo:rustc-link-lib=static=luajit-5.1"); to your build.rs.
That's a very good call - I did the exact same thing with F# :)
1. With the way you're writing this, no one is going to take you seriously. 2. Rust is not a "M00hzilla" project - it's an independent community, and people work on things they consider a priority. If you want compilation speed so badly, there's lots of issues for you on Github to work on. 3. How does one even "solve" compilation speed? Edit: 4. It was me who downvoted you, not Steve.
Would just like to add that I also downvoted, chances are Steve hasn't even seen this since it's been posted for 4 minutes. I am curious about what the smallest "% upvoted" reddit will show is though
&gt; 1. With the way you're writing this, no one is going to take you seriously. It's the only way I can get through to Rust developers. &gt; 2. Rust is not a "M00hzilla" project cmon now, it is &gt; 3. How does one even "solve" compilation speed? By putting every last ounce of resource they have into providing a fast dev compiler backend and only production builds will use the slow mode. They even have a proposal with Cretonne but I see ZERO focus on that. Instead we get meaningless little comfort fixes for Rust syntax which only serve to complicate Rust as a language even further. 
Oracle wants full copyright over any committed code. They have abused this in the past to close off an open-source project and sell open-source contributions under a proprietary license without contributing their own changes back to the community. I'll grant an Oracle team good faith the moment an open-source license is enough for them.
I can see that. 
Wrong subreddit, you need this https://www.reddit.com/r/playrust/
Crettone isn't a magic fix, it is basically replacing LLVM with a brand new code base. It will take a huge amount of work to finish and even more to optimize to a point where it could possibly be better. 
so you are saying that it IS a magic fix but it just takes a lot of work. ok. also it dont need to be better, just faster.
Oh, I get it.
I can compile it by adding this line to `build.rs` after the invocation of gcc and removing `#[link(name = "luajit-5.1")]` from `binding.rs`. I tried only with the first modification, but your comment gave me the idea to remove the `link`-line. I am using ArchLinux (with 4.11.6-3). Why is the order relevant to resolving the symbol?
Just have to say... I think its way cool how everyone is so positive in reply to this. A very supportive and encouraging community. Pretty awesome.
I am using [the documentation on build scripts from crates.io](http://doc.crates.io/build-script.html) for this.
I mean that whole characterization I actually agree with. But it seems like just the reason to be cautious about this. Most women engineers I know you can much more easily make flee by putting emphasis on the fact that they are women before the fact that they are just engineers than making posh jokes. I'm sure you would agree that we don't want to reproduce the worse cases of tokenism that this industry has produced. That said, Rusts community has a bit of a bad reputation on the matter and though I have little reason to think it's deserved, I think if we do such outreach efforts we should at least be more subtle about it. The controversy in this thread is evidence enough of it, by virtue of sheer existence. 
You can fork it, sure, and you can set up your own project around it. The problem is with considering Oracle's version as your upstream. You commit some code, open a pull request, sign the CLA. A while later, Oracle decides to put its engineers on the project, moves it to internal, starts selling the updates without releasing the source. There's a difference between using Rust in a closed-source setting and having a history to being actively hostile to the contributors of open-source projects you're responsible for, in my opinion.
Reminds me of breaking the Monad Barrier back when I was learning Haskell. I cried for about a week. Go learn another language, man. Get some perspective. Maybe one day you'll come back and wonder what you found so hard in the first place.
Just want OP to know that I also had this experience.
This was great! I am _really_ looking forward to an episode about Chalk. There's no way this would have fit into a fifteen minute minute episode, but I would love to read/hear a breakdown of the history of this effort (e.g., [Ticki's Pi Types Trilogy](https://github.com/rust-lang/rfcs/issues/1930)). Understanding historical context for an RFC (and therefore the forces that shaped it) is often the most difficult part of groking it. 
[removed]
I'm writing a CLI tool to transform openapi to other format (https://github.com/JordiPolo/oatool) It may have 2.000 of lines max, no macros, nothing fancy and really terrible code. It depends on clap and serde as bigger dependencies. When compiling with LFO, release mode and static binary after stripping I get a binary of 3MB. It seems really big for what it does. Am I doing something wrong?
Sorry to hear it! I hope you change your mind and come back but I understand Rust isn't for everyone. As people have pointed out the IRC channels and forums are extremely friendly and might help you get it. Hell, if you need help even feel free to PM me. I'll always be happy to help walk through your code and help if I can. It's tough but once it clicks its all worth it. But whatever you decide to code in I wish you nothing but productive, efficient, bug free code!
(FWIW, there are folks working on Cretonne, from the WASM team, not the Rust team, which is why the progress is less evident)
There's a subtle distinction between what you've written and what is written in the article-- their `BiFunc::call` isn't generic-- the `BiFunc` trait itself is generic, something like this: trait BiFunc&lt;X, Y, Z&gt; { fn call(&amp;self, X, Y) -&gt; Z; } The Rust version of their `chooseStringWeird` function would be something like this: fn choose_string_weird&lt;F&gt;( randomChoice: F, head: String, tail: String) -&gt; String where for&lt;T&gt; F: BiFunc&lt;T, T, T&gt; This is sort of a contrived example because higher-rank types aren't necessary to write this function-- we could have just as easily specified `F: BiFunc&lt;String, String, String&gt;` and our function would have worked just fine. But I'll do my best to explain what's going on here. The higher-rank part is that bound at the bottom-- the weird unfamiliar `for&lt;T&gt; F: BiFunc&lt;T, T, T&gt;`. This says that our `randomChoice` variable must be some type `F` such that, for any `T`, `F: BiFunc&lt;T, T, T&gt;`. There's not currently a way to write something quite like this in Rust, though as you discovered you can often collapse the `for&lt;T&gt; F: MyTrait&lt;T&gt;` bound into a trait with a generic method (`F: MyTrait` where `MyTrait` has a function generic on `T`). There is an [RFC issue](https://github.com/rust-lang/rfcs/issues/1481) for this feature to be added to the language. It actually [already exists for lifetime bounds](https://doc.rust-lang.org/nomicon/hrtb.html), so it's likely that this will be added to the language eventually.
Lol I started doing this shit when I was 14 or 15 too actually. I'm 18 now.
deleted ^^^^^^^^^^^^^^^^0.8000 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/53013)
&gt; Ternary operator `let var = if cond { "a" } else { "b" }` works.
I've used that as well, but I prefer the ternary operator. I like having a consistent format for conditionals and I never liked assigning a variable to a conditional like that. I've always felt that ternary operators are for one-liners, `if, else` is for multi-liners only. There's no good reason, just personal preference! 
You're not assigning "a conditional" to a variable - it's just that most things in Rust are expressions, including conditional operators.
Learn C first, if you don't understand how memory 'works' (i.e. a better model than java's 'there is no stack or heap, only objects') you'll never understand rust, even then it's pretty tricky;)
I'm sorry that your struggling with the language. But I hope you might give it another try. I am also mainly a Java dev, and it definitely took me time, easily a month, before I felt like I could write any decent code or feel the least bit productive. - There are a couple strategies for developing Rust software that I had to change from the way that I do in Java. Mainly, I now write code in much smaller snippets. When you say that you hit hundreds of errors, that implies to me that you've maybe written too much before trying to get it to compile. Start small and then build up from there, use the `#[test]` facility to validate each step a long the way. I will often write portions of a function, and then throw in `unimplemented!()` at the end just to validate the first part compiles, and then move on to write the rest as a strategy of going line by line. - Sometimes type inference hides what you actually think a type is, it can be useful in the beginning to be very explicit with your types so that you validate your expectations. Over time it becomes easier to rely on inference for things as you become more comfortable. - Really get to know the pointer types and the rules for them. Java has basically (ignoring primitives) one pointer type, and everything is shared by reference. Spending some time to really grok the difference between `self`, `&amp;self`, and `&amp;mut self` is very much worth it. `&amp;self` is basically all Java has (and `&amp;mut self` isn't even a concept there). - Get to know `Rc` and `Arc`... Java is a garbage collected language, it handles so much for you for shared pointers, etc. `Rc` and `Arc` can give you back a lot of that feeling of a GC. - Generics play a different role in Rust than in Java and it can take a bit to grok the difference. Java Generics still have polymorphism at play, where Rust does not. The Generics in Rust actually generate additional code for each variant of the Generic. Where as in Java it's basically just sugar over casting from Object to a specific type. To bring back some of the Java feel, you can use `Box&lt;Trait&gt;` (owned) and `&amp;Trait` (shared) objects to get the polymorphic feel of Java into Rust. - Oh, and use `error_chain!` it will make your life so much easier when returning errors from functions. A lot like just throwing Exception in Java... Anyway, Rust is a steep learning curve from Java, it was hard for me to learn so you're not alone. I do hope that you don't totally give up on it though, b/c if for no other reason, I still love that programs launch with no delay, no waiting for the JVM to load, specifying classpaths, any of that... it's freeing.
1) MX 2) SOA 3) A and AAAA
Ah, thanks for the clarification. But doesn't this also mean that it is theoretically possible to make polymorphic functions and closures be passed around as values without upgrading the trait system to have complete higher rank bounds? (By generating traits and implementations wherever necessary? ... even though it would be a super-ugly under-the-hood)
What you just described from Ruby is legal Rust, believe it or not. let foo; if bar { foo = thing_one; } else { foo = thing_two; } There's no reason to box a vector to return it--a vector is just a few pointers to a dynamically sized array on the heap. Actually, there's not any reason to box any expressible type for the purpose of returning it. The only return value that needs to be boxed would be a boxed trait object. If you don't know what that is yet, don't worry about it. References and lifetimes kind of go hand in hand. I think the thing that took me the longest to get is that there is always some anonymous lifetime associated with a scope, even if you haven't stuck `'a` next to anything. I keep meaning to do a video on that, because it took me three years to finally get what that means. &gt;.&lt;
I'm still trying to. Gaming keeps me with windows installed, and then I end up spending less time in Linux because I have the tools to do stuff over in windows too. Until I'm back in windows full time. Then 6-months later I try again.
Thread parking is just a general term for a thread being blocked, waiting on something else to happen. You could easily design an event loop around [mpsc](https://doc.rust-lang.org/std/sync/mpsc/). The event loop would just continuously read events from the consumer/receiver side of a channel, and act on them. When there is no event ready in the channel, the thread is parked automatically until there is something for it to do. Another thread would have the producer side of the channel, and it could feed events into the channel as things happen, while it goes about handling other things in the mean time, rather than waiting on the events to get processed. Or, depending on your definition of an event loop, what I described above could be backwards from what you would want.
Hmm, not going to happen for me. :p
You might know this already, but [rust-learning](https://github.com/ctjhoa/rust-learning) has a large collection of resources, including a section on lifetimes. Regarding the ternary operator, while I absolutely respect your preference for it, I doubt this will ever be implemented given Rust's design philosophy, but it's probably something you can get used to.
My first experience with C(++) was actually quite similar to my first experience with Rust: basically not understanding how memory management worked and giving up (except C(++) let me compile but segfaulted while Rust didn't want to compile).
I'll spend some time adding examples over the weekend. In the mean time take a look at the tests in this file: https://github.com/bluejekyll/trust-dns/blob/master/server/tests/client_tests.rs I'm being hast and loose with error handling and bounds checking for brevity, you'll want to clean that up. For each record type you'll need to build a different query (sorry for the formatting, I can never figure out Reddit's formatting rules): Setup the ClientConnection: ``` let addr: SocketAddr = ("8.8.8.8", 53).to_socket_addrs().unwrap().next().unwrap(); let conn = UdpClientConnection::new(addr).unwrap(); let client = SyncClient::new(conn); ``` Then send the query, A: ``` let name = Name::parse("www.example.com.", None).unwrap(); let response = client.query(&amp;name, DNSClass::IN, RecordType::A).unwrap(); let record = &amp;response.answers()[0]; if let &amp;RData::A(ref address) = record.rdata() { assert_eq!(address, &amp;Ipv4Addr::new(93, 184, 216, 34)) } else { assert!(false); } ``` AAAA: ``` let name = Name::parse("www.example.com.", None).unwrap(); let response = client.query(&amp;name, DNSClass::IN, RecordType::AAAA).unwrap(); let record = &amp;response.answers()[0]; if let &amp;RData::AAAA(ref address) = record.rdata() { assert_eq!(address, &amp;Ipv6Addr::new(...)) } else { assert!(false); } ``` MX: ``` let name = Name::parse("example.com.", None).unwrap(); let response = client.query(&amp;name, DNSClass::IN, RecordType::MX).unwrap(); let record = &amp;response.answers()[0]; if let &amp;RData::MX(ref mx) = record.rdata() { let name = mx.exchange(); ... } else { assert!(false); } ``` SOA: ``` let name = Name::parse("example.com.", None).unwrap(); let response = client.query(&amp;name, DNSClass::IN, RecordType::SOA).unwrap(); let record = &amp;response.answers()[0]; if let &amp;RData::SOA(ref soa) = record.rdata() { let mname = soa.mname(); let rname = soa.rname(); ... } else { assert!(false); } ``` If you hit any bugs, please file an issue! https://github.com/bluejekyll/trust-dns/issues
If you understand C and C++ memory concepts then the impetus and premise of Rust are far more salient. C, C++, and Rust all took me multiple attempts and I'm still learning things.
Yeah totally. I hated rebooting just to play a game. Plus not alt tabbing to my normal setup. And performance on Linux is still garbage for a lot of games. I dual boot now to play games every once in a while but it's mostly there as a "just in case a really good game comes out" .
Trying to port over my C++ interpreter to Rust and I have lifetime issues that I cannot solve without using deep copies (which I must avoid). How can I get it to compile it so it doesn't complain about the lifetimes? I'm banging my head against the wall for 1 hour. https://is.gd/UvpLRX
Co-author here! Some perspective: &gt; Why are you telling me it's a macro? Because the `!` is significant, and you'll see it, and should know what it means. &gt; why aren't you telling me why its important? Because in order to do so, you need to understand a *lot* about the rest of Rust, and this is "hello world." It's actually impossible to explain everything the first time you see it, because everything is interlocking. &gt; is that why the book doesn't get to macros for twenty more chapters? Writing macros is both very rare, and going to change in the future; while we'll still support the older way of writing macros, there's stuff in the pipeline that's really what you should learn. By the time you get into learning how to write macros, you should already be pretty comfortable with the entire rest of the language, so they're put in the end. Once that appendix is actually there, you'll be able to skip ahead to it and check it out if you want. 
Java is much more straightforward than C++ too. OP could be giving up on C++ too for all we known.
&gt; by generating traits and implementations wherever necessary I'm not quite sure what you mean by this. Say you wanted to write a function like this: fn process_debugs&lt;P: DebugProcessor&gt;(p: P) { p.process("a"); p.process(3); } trait DebugProcessor { fn process&lt;D: Debug&gt;(&amp;self, d: D); } And and say you want to pass a generic function into `process_debugs`. To do that, you need a blanket impl of `DebugProcessor` for all functions that can take a debug type as input. That's the part where you run into trouble: impl&lt;F&gt; DebugProcessor for F where for&lt;D: Debug&gt; F: Fn(D) { fn process&lt;D: Debug&gt;(&amp;self, d: D) { self.call(d); } } But you can't write this impl because we don't have higher-ranked trait bounds for types (the `for&lt;D: Debug&gt; F: Fn(D)` thing). Sure, you can work around this by manually creating a new zero-sized type and implementing `DebugProcessor` for that, but that's not quite the same thing.
It's just a monoid in the category of endofunctors /s Seriously though I too remember getting it after having gone back through Learn You a Haskell for Great Good a second time. When it clicked it was a bit overwhelming.
For some friendly competition, I’d like to mention my own `domain` crate. It’s got a resolver which has [some examples in its documentation](https://docs.rs/domain/0.2.1/domain/resolv/index.html). For looking up raw records, I’d recommend `lookup_records()`.
yes it is possible. In fact, i wrote a few updates for seccomp-sys which were merged. I didn't tackle adding those to the higher level library though. It could probably be done.
Needing this much history to explain "Hello, world!" is a tough reality. That said, I've read the rust book a couple of times and have learned a lot from it .
Is it possible to write/read exact number of bits to/from file? I'm writing an LZW compression implementation and need to write 9-12 bitsets, so was wondering if it's possible or should i manually pack/unpack u16?
You need to manually pack and unpack- actual storage hardware can only read/write at block granularity, RAM only at cache line granularity, and the CPU only at byte granularity. So doing that packing is only the last in a chain of parts doing the same thing.
&gt; It seems complicated at the beginning, but Rust is much more straightforward than C++. What an accomplishment
I had to stop myself from crytyping an angry email to some mailing list. I'm serious.
Also here: https://www.reddit.com/r/rust/comments/6cdpf7/system_programming_in_rust_beyond_safety_pdf/ (also submitted by me lol)
Angry cry typing? I kind of want to hear this story now
As a beginner in both C++ and Rust, my difficulties are not in regards to verbosity or strictness, but with the lack of some features that made me give up while trying to implement data structures and C ffi stuff. I was having a hard time figuring out how to do linked lists the rust way, then I looked into the `collections` module of Rust and saw that that they are using a bunch of unstable features. To me it seems that `unsafe` rust is very much a work in progress as well, when I wanted to access a field in a struct that was accessible via a pointer field in another struct, the compiler suggestion got me in a real life loop of `try doing (*foo.bar).baz` and `try doing (**foo.bar).baz` or something similar. I'm taking a break after months of trying the language until it reaches 2.0.
&gt; Please don't mistake my previous comment as hyper critical Not at all! It's good feedback.
Totally! Can you file a bug please? https://github.com/rust-lang/book
Lying to hide complexity is acceptable, even desirable when teaching. For a beginner, `println!` may as well be a function with a weird name.
If you're happy with hardcoding the sizes, yes. I ended up with a couple of macros similar to what the array_ref crate offers.
&gt; that "Zero-Cost Abstraction" is subverted for those needs. Don't worry, it will not. &gt; Simply put I would never dream to write a web framework in Rust It's actually surprisingly ergonomic, depending. We're still sort of working out frameworks that play to Rust as a language rather than being clones of other frameworks, though.
&gt; and it's transphobic in the sense that it denies a trans person their identity, and tries to force the wrong one on them. Only if it was said out of malice rather than ignorance – why assume malice? (rhetorical)
You're looking for r/playrust. This subreddit is for the Rust programming language.
That's why I said "depending" :)
I think the problem started with the "skimming the book" bit. That might work when moving between two very similar languages (you could probably get running with C# from Java by that technique), but Rust has a lot of new things that you need to know and sometimes you have to start from scratch. Also, I read one of your previous posts and one thing stood out - there were a lot of people saying "I don't understand what you are trying to do". That can be a problem in *any* language. Rust certainly has its own quirks, but if you don't understand why a Trait that doesn't implement anything isn't very useful and why the item implementing the Trait should probably have been stored by reference instead of by value, then that indicates a lack of grounding in the fundamentals which might well have come from skimming the book instead of reading it carefully. You also seem to assume that generics work in a way that they don't (oddly, they don't work that way in *Java* either, so I'm not sure where you got your knowledge from). One thing you might have done (although no-one suggested this, so I don't know if it's really that good an idea) is to show us the code in Java. That would give us an idea of what you are trying to do, sans any Rusty complications, which could make it easier to translate into Rust. It might not work, but it's worth a shot.
You might have better luck in /r/playrust
Done! https://github.com/rust-lang/book/issues/787
&gt; and this didn't fall in that category. _Purely_ subjective. And 'rhetorical' meant I wasn't actually asking a question... ;-]
Do you guys who find Rust hard think you are "damaged" by other programming languages? I mean once you learn to do something one way, all other ways seem wrong until you 'get' it. History has unanimously demonstrated that the human mind is not capable enough to tackle a language like C. This does not matter very much as long as you don't care about things like security and you have a decade to digest the code and fix all the errors. In this context is Rust really harder than your favourite language? Or just raising the bar on what is considered acceptable code? Results through years of iteration might be OK in some environments, but in today's world where your money or even your identity might get stolen if just one vulnerability exists in the code you use, perhaps this paradigm of taking a decade to straight out the bugs in a codebase is not acceptable any longer?
If you don't want an answer, don't reply to me. Of course my interpretation of malice is subjective, that's a pointless observation. 
I'm afraid that isn't an option. It is for a generic container when returning a point's parents on a 2D grid. [source](https://github.com/bpglaser/red-mountain-resize/blob/master/src/grid.rs#L109) The result is immediadly consumed in an iterator. [source](https://github.com/bpglaser/red-mountain-resize/blob/a748af690c988190efe69a724ee8a08c708279b6/src/carve.rs#L189) However, the current setup is kinda ugly.
Sorry, I messed up by saying 2.0, what I wanted to say was: until the people who know more than me use the language for long enough and figure out the many ways to do the things I'm not good enough to do on my own. About the raw pointer thing: What I wanted to do was something like `int x = foo-&gt;bar-&gt;baz` but I've failed to find ways to make it work. Again, as a beginner, the only way I could make it work was by creating multiple variables like `let a = &amp;(*foo)` and then `let b = &amp;a.bar` and finally `let x = (**b).baz`. Hope I'm not sounding as "Oh in this other language this thing is easy, and rust makes it hard!", this isn't what I'm trying to say here . Just that, for me (a noob), it got complicated fast and made rust a little less enjoyable than when I was doing simple safe stuff. I'm not a native English speaker, so if I'm being ambiguous, please reply and I'll try my best to clarify.
Yup! https://doc.rust-lang.org/std/iter/#implementing-iterator
&gt; Sorry, I messed up by saying 2.0 Ah no worries! &gt; About the raw pointer thing: Yeah; what I'm saying is basically "you're absolutely right that this isn't simple; in this case, it was a design decision to make it so." So your experience makes complete sense!
Lying is never OK. Something is seriously wrong if you cannot explain a concept in a few sentences and resort to lying around it.
Thank you very much! I totally understand now &lt;3
Thanks Steve!
You might have better luck by going to the IRC channel, and asking someone there to help you fix a compiler error. But to do that right, you'll want to come up with a _very small_ program that demonstrates the error first, that way the folks in the channel can understand the problem immediately without needing to understand the rest of your code. (Unfortunately that can be a lot of work, but it's really really good work that often helps you figure out what was wrong on your own.)
Definitely.
&gt; There will never be a 2.0, so you'll be waiting a long time! Never ever ever? Is this gonna be like Java, where at some point you just adopt the point number as the actual version number?
&gt; Never ever ever? I mean, I can't predict the future, but nobody is planning for or even advocating for a 2.0 seriously. &gt; Is this gonna be like Java, where at some point you just adopt the point number as the actual version number? I don't think anyone has suggested it, but we'll see :)
If you're coming from Java, a language with no manual memory management, no stack allocation, no type inference, no tuples, no pattern matching, no explicit pointers or references, no sum types, highly OOP/ inheritance oriented, etc etc etc, there's about a million things in rust that will be super new and confusing.
&gt; Do you guys who find Rust hard think you are "damaged" by other programming languages? What? No, not at all. What a ridiculous idea. &gt; In this context is Rust really harder than your favourite language? Yes it is. It's significantly harder than Python, in terms of scope and accessibility and rigor. &gt; Or just raising the bar on what is considered acceptable code? Rust requires a significant up-front cost in terms of whole program design and data flow, and deep knowledge of how the system works under the hood. Comparatively, Python is relatively hidden about how it works under the hood and while it has some serious gotchas, those come out far into the learning process.
The first thing I would do (okay did) was get lost in a rabbit hole trying to figure out what the bang meant.
Then Scala should be a pretty easy jump for you! A lot of the stuff in Java should be pretty applicable to rust. Scala should give you some fluency with things like fancy type systems and immutability and such. Scala also uses a lot of syntax that rust uses, and there are lots of shared concepts (even when the syntax is different) so I bet it would make a great bridge.
The OP is about a Java user struggling with Rust. Your condescension didn't actually contribute.
Rust is a Chinese finger puzzle. The more you thrash about and struggle, the harder Rust seems. But if you instead take a step back, try a different approach, and calmly go with the flow, everything falls into place. I haven't had a single difficulty issue with Rust in the last year and a half. To me it sounds like you're trying to use the wrong approach to s problem, and Rust is giving you a hard time because what you're doing is incredibly unsafe.
You can brush it aside as "that's life". Or you can accept that it's plausible that Rust has shortcomings in its onboarding process. I sympathize with the OP. I've poked at Rust briefly several times over the last 4 years. But every time, I found it difficult to get past basic technical troubles the language gave me. You could slot me the same way, but I learned Haskell with less trouble. It was still a difficult and long process, but I was always able to find immediate help for my beginner issues. And there were plenty of good books, examples, tutorials, blog posts, and videos on YouTube to make sure even when I did get stuck on something, I always had something else to learn in the meantime until I could get it resolved. Rust is severely lacking resources for beginners. 
It might be clearer if you rewrote it to use different names for the `String` and `&amp;str`, like [this](https://is.gd/iKCBT0).
If you don't have any experience with managing memory in algorithms, rust doesn't make a lot of sense. With people being taught garbage collected languages in school, it's a difficult leap to make. I have C++ experience so it makes sense to me.
I came here from the Rust blog, all of those are most important to me as an end user. Question 3 is especially important since the builds cost time on the build service I use, and I do testing for --release and debug separately. Is it something that would be really difficult to visualize? It'd be well worth the time unless it's really complex, I can compute the results myself but that goes for all of the other logs and data in the rest of my toolset. A centralized visualizer that you know is doing it accurately takes a load off of everybody.
Improving the learnability of Rust is a focus of this year; in general the community has acknowledged it and is working on it.
deleted ^^^^^^^^^^^^^^^^0.4641 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/25004)
Items marked `const` aren't actually variables, they're global symbols for a value known at compile time, and can be used anywhere those are required, such as defining a constant which will be used as the size of a statically-sized array
I would imagine you'd have the same problem with supported.push(Shortcut{id: 3, keys: quit_k}); supported.push(Shortcut{id: 1.0 keys: quit_k}); Because as soon as you add the first item, the rust compiler says "Aha! This is a container of `Shortcut&lt;i32&gt;`" and then you try to put a `Shortcut&lt;f64&gt;` into it and all hell breaks loose. You *want* it to be a container of `Shortcut&lt;S&gt;`, but those don't exist. One practical reason they don't exist is that `Shortcut&lt;S&gt;` doesn't have a consistent size, so you can't allocate space for a bunch of them. The other is that the types of things needs to be determined at compile time and `Shortcut&lt;S&gt;` just isn't a type (this is where people start talking about "higher kinded types" and I start nodding like I get it). Now that I've stated what I think the problem is, I should note that I don't know enough rust to be able to bang out a solution. You're welcome. But this looks like the sort of thing that "trait objects" can solve. First, you'd define a trait `S` for `Shortcut&lt;T&gt;` and then make a container of either `&amp;S` or `Box&lt;S&gt;`. I can't guarantee that this will work, because I'm new here myself, so perhaps you should ignore what I say until someone who knows what they are talking about comes along.
Bummer! I personally find that in-person help is really useful, so I might try to seek that out if I were you. But yeah, I feel your pain, rust can be really frustrating. I personally found it worth it to try to work through it, since the community, package manager, performance, and safety guarantees are amazing.
An enum with only one variant isn't very useful. It looks like you could just delete "GenericShortcutId" from the code and it wouldn't affect anything. your Shortcut struct has one generic parameter, which is the type of the id field. You could use basically any type there. S is not actually connected to GenericShortcutId in any way, currently. So, you should be able to write supported.push(Shortcut{id: CommonId::Quit, keys: quit_k}); without any problem, but I haven't tested it. The issue is that the Vec can only contain one variant of `Shortcut`, since each variation is a completely different type, and a Vec can only hold values of a single type. This applies whether you use GenericShortcutId or not... that enum with one variant isn't making any difference in the end result. The way to express this problem would be something like this: #[derive(Debug)] pub enum GenericShortcutId&lt;S&gt; { New, Open, Save, Help, Quit, Custom(S) } /// A shortcut consists of an id and a combination of keystrokes /// id can be of any generic type #[derive(Deserialize, Clone, Debug)] pub struct Shortcut&lt;S&gt; { pub id: GenericShortcutId&lt;S&gt;, pub keys: Vec&lt;u8&gt;, } pub enum MyId { Increase, Decrease } and supported.push(Shortcut{id: GenericShortcutId::Quit, keys: quit_k}); supported.push(Shortcut{id: GenericShortcutId::Custom(MyId::Decrease), keys: decrease_k}); S would then represent the user's custom enum type, where they can add as many enum variants as they desire. The default ShortcutIds would just be variants in the GenericShortcutId, but the additional Custom variant is where the user's variants would be attached. The user is *only* allowed one enum type. This is important. They can add as many variants into that type as they want, but there can only be one definition of S in a vec. You can have separate vecs with different definitions of S, which is what makes it generic, but a vec instance must have a single concrete type.
Also, for whoever is wondering, [constant let binding can be slower than const](https://github.com/rust-lang/rust/issues/36001).
Well, sad to report that I did use Linux for several years but then ended up switching back. Linux is better than Windows in so many ways, but gaming on Linux with Wine just wasn't worth the hassle (at least back then). And dual booting was pretty cumbersome too. I still have a Virtualbox Ubuntu VM though, but I can't get GPU acceleration to work properly so it's unbearably slow.
&gt; no type inference Well, let's say limited type inference &gt; highly OOP / inheritance oriented Overuse of inheritance is generally frowned on as being a restrictive and fragile approach in Java - interfaces, not classes are preferred with composition (in an increasingly functional manner, if not well supported by the grammar) being increasingly common. &amp;nbsp; But I agree that the trip from Java programmer to Rust programmer is a rocky road. Worse than the language differences however is the immaturity of libraries and their tendency to break compatibility. Java has a massive eco-system with decades of documented examples using a wide selection of mature libraries for many many situations. Rust is just not there yet. Edit: I should say, as this sounds more negative than it should - I like the Rust language and hope to see it and the supporting eco-system mature. I think it will always be a tough transition from Java but hopefully, eventually, only for the necessary differences in the language (even if, as seems likely, Java gets value-types, better inference, and pattern matching).
How does the `std::marker::Sized` trait relate to closures? Here's the context. I am trying to populate a u8 array with random bytes, using the [rand crate](https://doc.rust-lang.org/rand/rand/index.html). I want to use `OsRng` if possible, otherwise, default to `thread_rng()` (both implement the `Rand` trait, although obviously with different quality). Here's the code in question. use rand::os::OsRng; // quality source of randomness use rand::thread_rng; // "meh" source of randomness use rand::Rng // the trait both OsRng and thread_rng share // . . . let mut seq = [0;10]; // This is what I am trying to populate w/random bytes let fill = |rng: &amp;mut Rng| { let mut gen = rng.gen_iter::&lt;u8&gt;(); // 1st compile error for i in 0..10 { seq[i] = gen.next().unwrap(); // 2nd compile error } }; match OsRng::new() { Ok(mut rng) =&gt; fill(&amp;mut rng), Err(_) =&gt; fill(&amp;mut thread_rng()), }; This gives me two errors when I try to compile. 1st error: `error[E0277]: the trait bound 'rand::Rng: std::marker::Sized' is not satisfied` 2nd error: `error: no method named 'next' found for type 'rand::Generator&lt;'_, u8, rand::Rng&gt;' in the current scope` For the second error, I also get the following note. `the method 'next' exists but the following trait bounds were not satisfied: 'rand::Rng : std::marker::Sized'` I've tried looking the rust docs for std::marker::Sized, but I can't seem to figure out exactly how to get the closure to work.
Thank you!
RemindMe! 5 years
I will be messaging you on [**2022-07-01 00:38:14 UTC**](http://www.wolframalpha.com/input/?i=2022-07-01 00:38:14 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/6kg4fv/i_give_up_zero_progress_in_rust_programming/djmmlgg) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/6kg4fv/i_give_up_zero_progress_in_rust_programming/djmmlgg]%0A%0ARemindMe! 5 years) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! djmmloe) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Hmm, I guess i've been looking at the book and it just kinda jumps you into the deep end of chapter 2: use std::io; fn main() { println!("Guess the number!"); println!("Please input your guess."); let mut guess = String::new(); io::stdin().read_line(&amp;mut guess) .expect("Failed to read line"); println!("You guessed: {}", guess); } I think I wish it were even slower than how it introduces concepts. I dunno, I'm too new to judge this in great detail. But, I feel like I would have appreciated memory ownership being talked about much much earlier. I feel like it could be discussed immediately after finding out how to declare variables. Before strings, or implementations. I'd order it something like: 1. println! 2. read only variables + tuples 3. basic structs 4. memory model and explanation of Box 5. intro to ownership and lifespan
thank you
Awesome. I have to agree - Rust is a bit complicated, there's no way I would have learned it as quickly if it weren't for the excellent commitment to documentation and tooling.
heh apparently OP has never tasted C++ STL errors. having learned C++ and Haskell before learning Rust was probably helpful for me, it's good to have more points of reference. isn't Java a managed language anyway? there's not much else other than Rust to really compete with C/C++ in my book. mostly I stick to either C (or C++ with some of the object-oriented conveniences) or Rust, full-blown C++ to me was to hap-hazard and not principled extension of C. I know it has evolved in recent times, but like Haskell at this point it's accumulated too much technical debt, in the same way I prefer something that has the benefit of hindsight, like Idris to Haskell or Rust to C++.
Yeah this would be a perfect candidate for that. I'll keep my eye on it.
IMO there's a certain level of complexity that you cannot avoid.. other languages cheat by using a garbage collector (complexity / performance tradeoff). It's not going to be for every task. (EDIT to slant this statement better..'not for everyone' - rather it's not for every *scenario*)
The year of the Linux desktop came with [Windows 10](https://msdn.microsoft.com/en-us/commandline/wsl/install_guide).
Oh but FizzyFuzzyFitzgerald, I like seeing your username, it's so fun to say... I really hope you come back to rust sometime. I mean, think about all the stuff you already knew before: loops, conditionals, variables, functions and the like. In a way, you already knew a lot of rust :) you just have the fun parts left And come on man, 1 crate on crates.io != 0 progress... You've done it before you can do it again
F# is a superset of OCaml with awesome tooling via VS Code. Definitely give it a strong try.
That comes off as fairly pretentious. "Our language is more sophisticated. Not everyone is up to our level." As far as I can tell, the difficulty isn't that there are more rules your programs have to conform to, but rather, no one seems to do a great job of articulating what those rules are. (Or they aren't prominently advertised). 
Rust could really use a **Learn You Some Rust for Great Good!**. My dream team would be * Fred Hebert http://ferd.ca/ * Conrad Barski http://landoflisp.com/ * and Roberto Ierusalimschy https://en.wikipedia.org/wiki/Roberto_Ierusalimschy
I'm about to do something similar! Do you have any advice or "gotcha's" to watch out for? 
Short version: A `Vec` can only contain one type. A `Shortcut&lt;GenericShortcutId&lt;CommonId&gt;&gt;` is a different type from a `Shortcut&lt;GenericShortcutId&lt;MyId&gt;&gt;`. To store them in the same `Vec`, you need to somehow convert them into a common type.
i mean. it's really more complicated... anybody CAN learn it, but not everybody WANT to spend that much time on it (cost/return). especially since the doc story about some essentially new stuff is far from ideal (for instance lifetimes having different semantics according to the spot they're used at). Another thing is that C++ is harder to learn but you can just learn a small piece of it and kinda do stuff. The minimum piece of Rust to swallow to be able to operate happens to be bigger (even if the total is massively smaller).
Hey, I love Rust too. But Rust feels so... restrictive. I mean you cannot add perform i8 + i32! Neither can you do Option&lt;i32&gt; + i32! This is *intense*! Of course, the result = explicit conversions everywhere which makes itself harder to read. Then again stuff like 22/7 is allowed. I wonder why didn't it choose to be strict and prevent the truncation. Also suppose you are doing some procedural/linear-imperative style programming. let a = 15; //... let x = &amp;a; //... let y = &amp;a; //... //Now you want to change a //damn I have to go back and change mut a. Fair enough, let's do it. //Then you realize you may have to change the mutability of x and y accordingly let x = &amp;mut a; //definately out of the table -- Risk of data race or dangling pointer I mean these are not bad practices but these make it hard for a new comer to get into Rust. Specially if you are coming from a very tolerant language like Python or D etc. 
its realistic, not pretentious. There is a clear tradeoff between complexity, performance, and ease of use. Rust goes for maximum performance, which means a greater cost in lower ease of use. C++ and Rust achieve the same performance; but in rust you pay with more annotations/compiler errors; in C++ you pay with more debugging. Java is easier to use, but you pay for that with a garbage collection runtime , which costs more memory . &gt;&gt; "Not everyone is up to our level."" I'd put it differently - not every task has the same requirements. Sometimes the greater ease of use /faster dev time is the correct choice. Thats what I mean when I say 'its not for everyone' - It would be silly to recommend rust for *all* programming work. If you really *need* the performance, then you pay the extra language complexity or C++ debugging to get it.
There's another reason why println! et al. are macros: they're variadic, meaning they take a variable number of arguments. Rust doesn't have variadic functions though.
Published a new Crates You Should Know episode: [Rocket](http://www.newrustacean.com/show_notes/cysk/rocket/)!
If you drink, I'd suggest having some hard liquor handy, as this whole endeavor is a huge pain right now. I've been tweeting angrily all afternoon at the problems I'm encountering. I was having trouble compiling my program inside QEMU: https://twitter.com/jimmycuadra/status/880921937165209600 But then discovered this: https://twitter.com/jimmycuadra/status/880924233546649601 That second tweet was premature though, because it was so slow I couldn't distinguish whether or not it had hung or was really still compiling. I decided to try to let Docker Hub do it for me, only to discover that multi-stage builds are not yet available there, because they don't update Docker fast enough (ironic!): https://hub.docker.com/r/jimmycuadra/dashl/builds/bla7fviqs8fabsh98bs6fyn/ However, on Docker Cloud, you can use the (now old) edge version of Docker which supports multi-stage builds. But then I just ended up getting the same segfault, even with `--jobs 1` specified. I can't figure out how to get a public link to the build on Docker Cloud, even though the repository is supposedly public. The whole thing is a mess.
I think the criticism of /u/ChaosCon is valid, and that that paragraph can be improved a bit. It's currently not clear from that paragraph that the fact that `println!` is a macro is merely an implementation detail that's not important at all if you're only using `println!`. On the contrary, it even seems like it's calling it *important* that it's a macro, which makes it even more frustrating that no explanation is given of why it's a macro. The confusion is not helped at all by mentioning metaprogramming, with again no further clarification, because there's not actually any metaprogramming going on here. People in this thread are suggesting to add a hand-wavy explanation of why it's a macro, to make it less frustrating. But in my opinion that's a design-by-committee solution. This is hello world. None of this macro stuff belongs in a hello world explanation. When you're only using `println!`, it's totally acceptable to think of `println!` as a regular function that happens to have a `!` in its name. So the fact that it's a macro, or why it has a `!` in its name, doesn't need to be explained or even mentioned at all. The only problem with that is that if you explain `println!` as if it's a function, you're writing false statements. That should probably be avoided, even though I think it does result in the smoothest learning curve. But still, I would keep the mention of macros to a minimum, and clearly emphasize that the fact that it's a macro is only an unimportant implementation detail. If we could've written `println!` as a regular function, we would've. Here's how I would rewrite that whole section: &gt; In this line, we call the function `println!`, which prints one line of text to the screen. We pass one argument to `println!`, to tell it what to print: the string `"Hello, world!"`. &gt; *Note: For technical reasons, `println!` is actually a macro, not a normal function, which is why it has a `!` in its name. But when you use `println!`, this is not important, and you can think of it like a normal function. For more explanation about macros, see Appendix E.* No more than that. Brevity is important in tutorials, especially in hello-world tutorials.
To add on about higher kinded types a bit, let's start with `Shortcut&lt;S&gt;` and `Shortcut&lt;i32&gt;`. We could say that the "type variable" `S` has been bound to `i32` in that case. Now let's think about `Shortcut&lt;S&gt;` just by itself (and this is where things stop making sense in rust, but bear with me). What is `Shortcut&lt;S&gt;`, syntactically? It's a thing that, when given a type, produces another type. That's really similar to the concept of a function, if you think about it: a function is a thing that, when given one or more values, produces another value. Cool! So `Shortcut&lt;S&gt;` is something like a function, but operating on types instead of values. Now where can we go from here? With functions, we can talk about their type signatures. Type signatures tell us the types of arguments a function takes as well as how many arguments it takes. (I'm going to use Haskell's notation for type signatures here, since Haskell has HKT.) So for example, a function's type signature might look like `f:: String -&gt; Foo`. That means the name of the function is `f`, and it takes a `String` and produces a `Foo`. That's all well and good, but what about whatever signature Shortcut should have? It takes a type and produces a type, so we could write something like `Shortcut:: * -&gt; *`, if you say that `*` just means "some type". And it turns out that that's exactly what Haskell does. But we still haven't said what that signature really is yet. It isn't talking about values, so it's not a type signature. Instead, we call it a "kind" signature. This is where the "kind" in "higher kinded types" comes from - we're talking about things that are one step up from types. Sort of the "type of type". So why "higher kinded"? That is because in languages that support it, we have the ability to write kind signatures like `Bar:: (* -&gt; *) -&gt; * -&gt; *`. Let's think about that: that's a thing that takes in something that produces a type (if given one), and a type, and produces a type. If you think about it, doesn't that feel similar to the `apply` function? Its type signature is `apply:: (a -&gt; b) -&gt; a -&gt; b`. It takes in a function that takes an `a` and produces a `b`, and an `a`, and gives us back a `b`. Recall that any time a function takes another function as an argument, or produces a function, we say it's a higher order function. So this is why they're called higher kinded types: because we can write kinds that express things that. Cool! So now we have a much more powerful way of creating types and telling the compiler about them. That's my understanding of higher kinded types in a nutshell.
I hope they solve the problem of evaluating expressions in cost type parameters soon after the basic feature lands. At least for numerics. Like they said, this is important for linear algebra libraries. For example, appending a new row to a matrix would need to know that the input has N rows and the output has N+1. I'm really looking forward to having a well typed multidimensional array library!
Oh fuk. Well, it'll be an adventure if nothing else. It might also be my descent into crippling alcoholism, but that's another story. ^(I'll be making a GUI app targeted for the Pi. Wish me luck!)
There are two ways to look at this: A. **Implementation:** `const` means that the value is baked into the code itself, which is locked down to being read-only by the OS during execution. (That's what names like "NX-bit", "ED-bit", and "Hardware DEP" are referring to. Code can't be overwritten, and data can't be executed... unless it's a JIT runtime like a JavaScript engine, in which case, it has to either manually manage marking things as non-executable or opt out entirely, because JITing *is* executing data from the OS's perspective.) This also means that the values are defined at compile time, rather than runtime, and you can't assign something which requires initialization code, like `Regex::new` to a `const` because it would require the compiler to run that code at compile time and ensure that doing so won't result in something like [xkcd #221](https://www.xkcd.com/221/). Ordinary `let` bindings live on the stack and, under some circumstances, can be made mutable and then made read-only again. (I remember reading a blog post about the utility of this technique for making APIs more robust a few months ago.) B. **Theory:** The distinction between a `const` and an ordinary `let` binding serves a purpose similar to requiring that types be specified in `fn` declarations, despite closures (`|x, y|`) serving as proof that the compiler is capable of inference in that sort of situation. 1. Whether something in the module scope is `const` or `static` is part of the ABI and should be explicitly specified in order to reliably guarantee that the ABI remains stable. 2. Rust places a significant amount of value in the principle that small changes should have local effects, so code remains maintainable. Inference support must be added with caution.
I personally really enjoy the ability to get really performant code without feeling like I'm playing russian roulette with pointers. The other thing is libraries generally seem to be of higher quality (I don't know why exactly) than what I'm used to in JS/Python. On a more cynical note, right now pretty much everyone using Rust does so by chance so surveys that measure "loved among those who (currently) use it" is going to have one hell of a survivorship bias.
Match doesn't work based on equality, it works based on types (roughly speaking). As a counter example, you could have an enum with variants This::Positive(u8) and This::Integer(i8), where Positive(106) == Integer(106), but match still needs to be able to discriminate between the two, because they are different types.
You can add an else branch to the if let to get your inverse condition. It would look like: if let Success = var {} else { panic!() } Or you could give it normal if/else formatting.
It's uh... almost the opposite of "C with memory management". For all the common types you'll use day to day, the memory is managed for you via lifetimes and the Drop trait. Rust is like Java with a fancier type system, and no runtime overhead except the overheads you personally choose to accept.
From a practical point of view, I assume the Rust compiler uses this information to do better "constant propagation": this means that the value of the variable is substituted directly wherever it is used at compilation time, so effectively the final assembly might not ever reason about the variable itself. Depends on the code of course, but this optimization happens even in languages that do not have such strong guarantees of immutability.
&gt; Even though it's harder, a GUI app in Rust is infinitely more satisfying than using Electron. If you like using Rust with Qt Quick, another combination you might want to bookmark is [rust-cpython](https://github.com/dgrunwald/rust-cpython) with either [PyQt](https://sourceforge.net/projects/pyqt/) or [PySide](https://wiki.qt.io/PySide). That would allow you to use the QWidget API to draw GUIs that feel much more native on desktop OSes with Python serving a role similar to QML. (Except that, since Python is a full-blown programming language and the bindings predate QML, you'd have full access to draw the division between Rust and Python wherever works best for you.) Here's an [example](https://imgur.com/2yQMBZI) of something I'm working on using that combination.
The intro tries to call this out; if you don't want to dive in, just skip 2 and go to 3.
It's nothing to do with closures specifically. The problem is you declared the parameter `rng: &amp;mut Rng` as a reference to a trait object (of trait `Rng`), while the `gen_iter` method is defined only on concrete implementors (you can see `where Self: Sized` in the function definition, which means "this method can't be called on a trait object"). You can define `fill` as a generic function (there's no way to declare a generic closure at the moment): fn fill&lt;R: Rng&gt;(rng: &amp;mut R, seq: &amp;mut [u8]) { let mut gen = rng.gen_iter::&lt;u8&gt;(); // 1st compile error for i in 0..10 { seq[i] = gen.next().unwrap(); // 2nd compile error } } 
Using [last year's hard drive prices](http://www.statisticbrain.com/average-cost-of-hard-drive-storage/), that's 0.0055 cents' worth of storage, so I don't think it's very important, and frankly that seems reasonable to me for a program that size. If you are into space optimization, though, see [here](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html).
I wouldn't say *best* practice. It's certainly the simplest, because you don't have to think about whether your struct outlives its referents, but if you know the referents will live long enough, you can create some very efficient systems. So let's just say that having struct own their members is a good idea until you have a better idea.
&gt; I mean you cannot add perform i8 + i32! I think this is probably a good thing - I haven't often had errors with these kinds of implicit conversions in C++, but when I do, it can be hard to figure out what's going on sometimes (though perhaps comparison of signed to unsigned integers is worse). Most C++ linters will also warn you about these kinds of things, even if it isn't a compile error like it is in rust. &gt; Neither can you do Option&lt;i32&gt; + i32! This is *intense*! What type would that even be? What is None + 1? &gt; Of course, the result = explicit conversions everywhere which makes itself harder to read. And you also have less places where you get surprised by behavior because types implicitly converted in a way you weren't expecting. &gt; Then again stuff like 22/7 is allowed. I wonder why didn't it choose to be strict and prevent the truncation. Probably because disallowing that but allowing x/y where x and y are integers would be a little inconsistent. (and integer division is often quite useful)
Algebraic data types. Performant functional iterators. No trade-off between memory safety and great performance. 
If you haven't already, I suggest reading [Too Many Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) for deeper insight into why Rust was designed that way. The gist is that: 1. Linked lists inherently don't play well with modern CPU designs, so Rust chose to advantage more useful things at their expense. (ie. 99% of the time, a linked list will be the wrong data structure to choose if the language doesn't force you into using one.) 2. Using things like linked lists as code katas for Rust is deceptively difficult because Rust chose to advantage real-world use over rewriting difficult-to-get-right infrastructure that can be written a handful of times and easily reused via cargo. Or, even more succinctly, "Judging Rust based on how easy it is to implement a linked list is about as useful as judging Python based on how easy it is to implement a performant game engine. You can't judge a language based on a single task that it's explicitly not intended to help you with."
Right. It occurs to me after the fact that `if var == Variant::Two` can just be done as `if let Variant::Two = var` to satisfy that. I'm still not thrilled with empty `if let` arms (`if let Variant::Three = var {} else { /* actual logic */ }` but ah well.
For me, the best part of Rust is 'zero overhead abstraction'. I can make a bunch of iterator adapters like `for item in the_vec.into_iter().filter(...).map(...) {`, and it will be at least as fast as if I had written out all the transformations in the loop manually. To add onto that, these costless abstractions like iterators can easily be extended between functions using generics, and a special version of any function that operates on a generic parameter will be created for each specific type it's used with. There are quite a number of other nice things, but the general feel is that the compiler has your back. It won't accept solutions which can error due to memory unsafety or data races, and it even leaves out `null` pointers which can implicitly cause null-pointer errors on any variable access in languages like Java.
I use Rust instead of Python for my I/O-bound work because it's got a much stronger type system, so I can focus more on my logic and less on my bookkeeping, giving me a much higher confidence that, if my code compiles, it'll probably do what I intend. &amp;nbsp; As for some of the things /u/link23 mentioned, plus a few more, here are a few examples: &amp;nbsp; **Algebraic data types:** In addition to "product types" (structs), Rust has "sum types", which means that it has tagged unions the compiler can enforce proper use of, and they're very well integrated into the language. Constructs like this let you prevent fatal unit mix-ups at compile time: enum Temperature { Celsius(i32), Fahrenheit(i32), Kelvin(u32), Rankine(u32), } When you want to retrieve the value, the compiler will require you to handle every possible case, even if it's just an explicit "otherwise, unwind the stack and die with an error message" fall-through case. (In fact, Rust has `unimplemented!()` and `unreachable!()` macros so such cases can be succinct and easy to `grep` for, both during development and in production.) This is also useful for things like implementing JSON serializers which don't compile unless they're guaranteed to output valid JSON. (If you're wondering, both names, which come from set theory, refer to the possible values the new type can have, as a function of the members it's built from. `A{a, b} + B{c, d} = C{A(a), A(b), B(c), B(d)}`) &amp;nbsp; **No unexpected `NULL`s:** Instead of `NULL`able values, Rust returns an enum called [`Option&lt;T&gt;`](https://doc.rust-lang.org/std/option/enum.Option.html) which can be either `Some(T)` or `None`. Thus, you can tell what you need to handle from a function's type signature and the compiler won't let you forget. ...and, if `T` or any of its members (in the case of a struct) are marked as `NonZero`, then the optimizer will use a zero value on that field to represent the `None` so there's no memory overhead. &amp;nbsp; **No uncaught exceptions:** Instead of returning an ignorable integer or raising an exception you may not know you need to catch, Rust uses an enum called [`Result&lt;T, E&gt;`](https://doc.rust-lang.org/std/result/enum.Result.html) which can be either `Ok(T)` or `Err(E)`. As with `Option&lt;T&gt;`, this means you can see when a function can fail purely from the function signature and the language won't let you forget to do *something* with the errror case, even if it's just unwinding the stack and dying. (Both options and results have an `.expect("custom failure message")` method for that which returns the value from the Some/Ok variant.) This feature alone has taught me a lot about POSIX API failure conditions that I never realized. (eg. `getcwd()` can fail and there's no way around that because the kernel itself enforces the rule that you may not have permission to know your current working directory's full path.) &amp;nbsp; **Performant functional iterators:** You can write code like this, and it'll compile down to the kind of loop you'd write by hand... *and* the language can guarantee at compile time that you're not mutating while iterating in a dangerous way: let doubled = collection.iter().map(|x| x * 2).collect::&lt;Vec&lt;_&gt;&gt;(); for thing in other_collection { // do something } (The "turbofish operator" (`::&lt;&gt;`) is necessary because `collect` can output various different types of collections and this line doesn't provide enough context to infer the return type.) &amp;nbsp; **Session types:** Because Rust has compiler-enforceable move semantics, local type inference, and support for implementing methods on only certain forms of a generic, you can write really clean interfaces which compile-time enforce proper use of anything which can be represented as a state machine. While I don't remember [hyper](https://hyper.rs/)'s interface exactly, here's a paraphrase of the relevant characteristic as it would apply to preventing the infamous PHP errors we've all seen at least once: let request_a = Request::new(); request_a.add_header(...); let request_b = request_a.start_body(...); request_a.add_header(...); // ERROR: Tried to access moved value `request_a` request_b.add_header(...); // ERROR: Type `Request&lt;StreamingBody&gt;` has no such method `add_header`. &amp;nbsp; **Never forget to free memory*:** As long as you don't use `Rc&lt;T&gt;` or `Arc&lt;T&gt;` to create a reference cycle, your entire program has a clearly-defined tree of ownership that allows `free` calls to be inserted automatically at compile time, and you can't forget to do it. &amp;nbsp; **No data races:** The "ownership and borrowing" aspect of Rust's type system verifies shared/exclusive locking at compile time, and the constructs which wrap `unsafe` blocks in a safe API to allow you to opt for runtime locking in more complex situations will build on the ownership/borrowing to provide mutex guards that you can't forget to acquire or release. As a result, you can write safe and performant multi-threaded code ridiculously easily because it's impossible to forget to acquire or release a lock and transferring exclusive write permission when not using runtime locking is as simple as passing a reference (just a pointer, under the hood) which the compiler uses as a permissions token while performing its verifications. &amp;nbsp; **Immutable by default:** You'll be surprised how easy it is to write const-correct code when you're writing `mut` rather than `const` in your type signatures. (Plus, since you can use `mut` on the `self` parameter in methods, you can write APIs where some methods are always callable, but others are only callable if you hold an exclusive reference to the object.) &amp;nbsp; **Hygienic macros:** Rust macros have sane scoping rules for variables and are applied to the parsed [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) of your code, rather than by raw text substitution, so you can use them without worrying about "insane/confusing action at a distance". Procedural macros are also in development. &amp;nbsp; **Safe, not crippled:** Rust is designed with the understanding that not everything can be verified by the compiler. If you need to implement something which the compiler can't verify, `unsafe` blocks relax Rust's rules with the understanding that you are responsible for ensuring Rust's invariants are restored by the end of the block. This "wrap `unsafe` in safe interfaces" principle is how Rust's standard library is constructed. &amp;nbsp; **Easy C FFI in both directions:** Rust compiles down to C-compatible machine code with no heavy runtime to complicate embedding. Through the use of `unsafe` blocks (needed to call C functions), `#[repr(C)]` annotations (used to request C-compatible struct representations), and the [`CString`](https://doc.rust-lang.org/std/ffi/struct.CString.html) and [`OsString`](https://doc.rust-lang.org/std/ffi/struct.OsString.html) types (Rust doesn't use null-terminated strings), it's easy to call C libraries from Rust or embed Rust libraries in C programs. ...and, through this, people have implemented higher-level wrappers like [rust-cpython](https://github.com/dgrunwald/rust-cpython) and [neon](https://github.com/neon-bindings/neon) (Node.js). &amp;nbsp; **Mature code optimization:** Rust is built on LLVM and inherits all of the same optimizations as llvm-clang. In benchmarks, Rust performs comparably to C and C++ with the notable exception of SIMD instructions, which haven't yet had their API stabilized and, thus, are generally considered ineligible. &amp;nbsp; **Broad platform support:** With [varying degrees of assurance](https://forge.rust-lang.org/platform-support.html), Rust supports basically every platform with an LLVM code generator. For comparison, the only platforms supported by at least one major Linux distro which Rust cannot yet target are Itanium and RISC-V. Furthermore, efforts are underway to make Rust a viable development option for various microcontroller families, with the main holdup for AVR (eg. Arduino) and MSP430 architectures being the fixing of bugs in their LLVM backends. (Though, as a tongue-in-cheek black mark against Rust, I *will* say that I have to use either DJGPP (GCC), Watcom C, or Free Pascal to develop software for the Windows 98, Windows 3.1, 32-bit DOS (DPMI), and 16-bit DOS environments on my retro-gaming PCs.) &amp;nbsp; **etc. etc. etc.** I can't sit here all night, so I'll leave it up to you to discover the rest. I will give one hint though. Rust's use of structs and traits, rather than classes and interfaces, makes for an intoxicating and cache-friendly combination once you get out of the habit of thinking in terms of classical inheritance. (For example, I can hang custom methods off types I didn't define, without the fragile monkey-patching common in languages like Ruby.)
&gt; Chelsea Manning is a female soldier That's an interesting assertion. Biology defines a female "the sex of an organism, or a part of an organism, which produces non-mobile ova". Since Manning's body does not satisfy this definition, I must conclude that your assertion is false. &gt; [stating that a person is not a female is] transphobic in the sense that it denies a trans person their identity, and tries to force the wrong one on them. I've unfortunately failed to find a formal definition of transphobia to validate this claim. If you know of a formal definition (published papers or books well-received in their respective fields) we could use to continue this discussion, I'd sincerely appreciate being directed to it. Since you have yet to provide support to your assertions, my opinion of the summary given still stands. If you still believe I am wrong, please provide solid arguments to support you assertions.
I've worked with a ton of languages and I hate to admit it but Rust has been one of the hardest to work with besides maybe Haskell, and that's just because I'm not very comfortable with pure functional concepts. I absolutely love Rust, the syntax, the features, the metaprogramming and macros... It feels like such a solid language and I really want to be good at it. But it's been much harder than I like to admit. In some projects, lifetimes are just easy by the nature of the problem and I don't run into one compiler warning about them. In another project, a toy game engine, it starts becoming the hardest part of the project and I end up having to refactor just to get rid of errors and I'm not sure it's even the best way to do it. The nature of the language forced me to refactor into a structure that didn't feel intuitive to me. I think it might just be the nature of the borrowing rules. The compiler warnings are pretty clear, and they point you right where it's bugging out. But the whole borrowing thing forces you to plan things out in a way many might not be used to. The docs are awesome, the compiler honestly seems pretty great to me. I absolutely love cargo. Just feels like tons of things were done right with Rust. But abiding by the rules of borrowing is just tricky sometimes. If I were to suggest anything to help learnability, I think it might be examples of hard borrowing problems, and patterns to use and patterns to avoid in regards to borrowing. At its simplest, Rust is pretty easy, but it's when you run into hard borrowing problems that you start to really have trouble moving on, and docs and simple examples don't really express the sort of problem solving you might need to do. Something that might've helped me more would've been a tutorial showing a somewhat hard borrowing problem, what pattern to avoid that you might be tempted into trying and what pattern works best. Show best practices with code structure when multiple structs might be sharing/depending on the same data with some special lifetime. That's been the problem for me at least. Everything else has been super easy. The docs are great, the packaging is top notch, the language is really easy to read and write. It's just sometimes you run into a weird borrowing thing and it all feels alien and as much as I re-read the rules on borrowing, I just can't figure out how the hell it all applies to my specific problem.
It looks like your requirements are that: 1. Users should be able to define their own ShortcutId types 2. You need to be able to process a collection of shortcuts uniformly 3. You need to be able to clone a collection of shortcuts. 4. Something to do with Comparators, which I've not looked at yet. I'll look at how you'd solve the first three in Java (answer: trivially), and some ways you might unsuccessfully try to implement it in Rust. Then I'll give some Rust code that (compiles and) attempts to emulate the Java implementation as closely as possible. This Rust code won't be very idiomatic, but the steps we take to get to it will hopefully make the compiler errors you've been getting a little less cryptic. If anyone spots any errors in what I've written then please say and I'll edit the post. I'm not a Rust expert myself, so might have gotten some terminology or explanations wrong. In Java you would presumably write something like the following: interface IGenericShortcutId { } class Shortcut { List&lt;byte&gt; Keys; IGenericShortcutId Id; } And everything just works. This is because in Java: 1. everything is boxed, and 2. there's a garbage collector. The first means that all instances of Shortcut will have the same representation regardless of the concrete type of Id - the Id field is always just a pointer into the heap. The combination of the two means that the language doesn't need to distinguish between owned and borrowed values - passing a Shortcut into a function just involves copying a pointer. And the compiler doesn't need to track who owns the memory this points at as the runtime will handle this in its garbage collector. What about Rust? A bit of googling reveals that traits are 'sort of like interfaces', so let's try those: trait GenericShortcutId { } struct Shortcut { id: GenericShortcutId, keys: Vec&lt;u8&gt; } No luck: error[E0277]: the trait bound `GenericShortcutId + 'static: std::marker::Sized` is not satisfied --&gt; &lt;anon&gt;:4:5 | 4 | id: GenericShortcutId, | ^^^^^^^^^^^^^^^^^^^^^ the trait `std::marker::Sized` is not implemented for `GenericShortcutId + 'static` | = note: `GenericShortcutId + 'static` does not have a constant size known at compile-time ... You can't store raw traits. Some more googling shows traits being used as bounds in generics, and via trait objects. Let's first try making Shortcut generic: struct Shortcut&lt;S&gt; where S: GenericShortcutId { id: S, keys: Vec&lt;u8&gt; } This compiles, so let's define some shortcut id types and try to use it. #[derive(Clone, Debug)] pub enum MyId { Increase, Decrease } impl GenericShortcutId for MyId { } #[derive(Clone, Debug)] pub enum UserDefinedId { Open, Save, Quit } impl GenericShortcutId for UserDefinedId { } fn main() { let mut shortcuts = vec![]; shortcuts.push(Shortcut { id: MyId::Increase, keys: vec![1] }); shortcuts.push(Shortcut { id: UserDefinedId::Open, keys: vec![2] }); } More compiler errors: error[E0308]: mismatched types --&gt; src/main.rs:22:20 | 22 | shortcuts.push(Shortcut { id: UserDefinedId::Open, keys: vec![2] }); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected enum `MyId`, found enum `UserDefinedId` | = note: expected type `Shortcut&lt;MyId&gt;` found type `Shortcut&lt;UserDefinedId&gt;` In retrospect this version was never going to work - Shortcut&lt;MyId&gt; and Shortcut&lt;UserDefinedId&gt; are totally different types. Ok, let's try trait objects instead. These look a bit more like Java interfaces - trait objects are essentially a pointer to an object, together with a pointer to its implementations of the trait's methods. This gives us something like property 1. of Java from above - trait objects are all the same size. So the compiler will let you store trait objects pointing at values of different types in a single collection. Trait objects are represented syntactically by &amp;T, so maybe the following will work: trait GenericShortcutId { } struct Shortcut { id: &amp;GenericShortcutId, keys: Vec&lt;u8&gt; } Apparently not: error[E0106]: missing lifetime specifier --&gt; src/main.rs:5:9 | 5 | id: &amp;GenericShortcutId, | ^ expected lifetime parameter error: aborting due to previous error(s) Rust doesn't have Java property 2. - it's not garbage collected. This means that you can't just pass around pointers to objects and let the runtime deal with cleaning them up. Something needs to own the object, and at some point that something like go out of scope. If you have a reference to an object then the compiler needs to be able to prove that the reference won't outlive the object itself. This is handled using lifetimes, but for now let's sidestep this topic by continuing with our Java-y approach. Instead of a pointer to someone else's memory, we'll store a pointer to our own heap-allocated memory. In Rust this is done using Box: trait GenericShortcutId { } struct Shortcut { id: Box&lt;GenericShortcutId&gt;, keys: Vec&lt;u8&gt; } This at least compiles. Let's try sticking some of these into a Vec: #[derive(Clone, Debug)] pub enum MyId { Increase, Decrease } impl GenericShortcutId for MyId { } #[derive(Clone, Debug)] pub enum UserDefinedId { Open, Save, Quit } impl GenericShortcutId for UserDefinedId { } fn main() { let mut shortcuts = vec![]; shortcuts.push(Shortcut { id: Box::new(MyId::Increase), keys: vec![1] }); shortcuts.push(Shortcut { id: Box::new(UserDefinedId::Open), keys: vec![2] }); } This also works! However, we're not quite out of the woods yet - we don't yet handle cloning Shortcuts. I'll cover this in a reply to this post, as my full reply exceeds the reddit character limit. Second part here: https://www.reddit.com/r/rust/comments/6kjnmo/so_close_still_miles_away_generics/djmwlzi/
Part 2! Let's try cloning a Shortcut: fn main() { let shortcut = Shortcut { id: Box::new(MyId::Increase), keys: vec![1] }; let cloned = shortcut.clone(); } More compiler errors: error[E0599]: no method named `clone` found for type `Shortcut` in the current scope --&gt; src/main.rs:21:27 | 21 | let cloned = shortcut.clone(); | ^^^^^ | = help: items from traits can only be used if the trait is implemented and in scope; the following trait defines an item `clone`, perhaps you need to implement it: = help: candidate #1: `std::clone::Clone` This makes sense - the compiler doesn't know how to clone a Shortcut because you haven't told it how to. Let's try just sticking a derive onto our definition of Shortcut. This attribute will tell the compiler to automatically produce an implementation of clone for Shortcut by cloning each of its fields. #[derive(Clone)] struct Shortcut { id: Box&lt;GenericShortcutId&gt;, keys: Vec&lt;u8&gt; } Still no luck: error[E0277]: the trait bound `GenericShortcutId: std::clone::Clone` is not satisfied --&gt; src/main.rs:6:5 | 6 | id: Box&lt;GenericShortcutId&gt;, | ^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::clone::Clone` is not implemented for `GenericShortcutId` | This compiler error is pretty helpful - the compiler can't clone a Shortcut by cloning each of its fields because it doesn't know how to clone the id field. And our GenericShortcutId is totally generic - there might exist implementations which can't be cloned. So let's insist that GenericShortcutIds be cloneable: trait GenericShortcutId : Clone { } #[derive(Clone)] struct Shortcut { id: Box&lt;GenericShortcutId&gt;, keys: Vec&lt;u8&gt; } This produces a somewhat more cryptic compiler error: error[E0038]: the trait `GenericShortcutId` cannot be made into an object --&gt; src/main.rs:5:5 | 5 | id: Box&lt;GenericShortcutId&gt;, | ^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `GenericShortcutId` cannot be made into an object | = note: the trait cannot require that `Self : Sized` The real problem here is that only 'object safe' traits can be used via trait objects. I'm a little hazy on the details of all of this myself, but I'll explain the concrete issue in the case of our Clone bound (and you can read more in [this](http://huonw.github.io/blog/2015/01/peeking-inside-trait-objects/) [series](http://huonw.github.io/blog/2015/01/the-sized-trait/) [of](http://huonw.github.io/blog/2015/01/object-safety/) [articles](http://huonw.github.io/blog/2015/05/where-self-meets-sized-revisiting-object-safety/)). The problem is that Clone looks like this: pub trait Clone { fn clone(&amp;self) -&gt; Self; fn clone_from(&amp;mut self, source: &amp;Self) { ... } } At first glance, this looks similar to the following Java interface: interface ICloneable { ICloneable Clone(); } However, it's different in a very important way: the return type of the Clone method on the interface is ICloneable, while for the clone method of the trait it's Self, i.e. the concrete type implementing the trait. In the Java version I can give you an ICloneable, and as everything is boxed this is really just a pointer-to-something-cloneable. Cloning it gives back a pointer-to-something-cloneable. But suppose it were possible to pass around objects of type &amp;Clone in Rust. What would the type of b be below? let x = SomeTypeImplementingClone; let a: &amp;Clone = &amp;x; let b: ??? = a.clone(); In this case the type of x is visible, but in general when given a value of type &amp;SomeTrait the compiler has no way of knowing the actual concrete type being pointed at. The solution to this in our case (i.e. for the sake of emulating the Java version as closely as possible) is to instead insist that Box&lt;GenericShortcutId&gt; can be cloned, i.e. that we can clone pointers to heap-allocated shortcut ids: trait GenericShortcutId { fn box_clone(&amp;self) -&gt; Box&lt;GenericShortcutId&gt;; } (See also: https://users.rust-lang.org/t/solved-is-it-possible-to-clone-a-boxed-trait-object/1714/6) This is like the ICloneable interface above - you give me a pointer to a heap-allocated object of unknown type implementing some interface, and I give you back a pointer to a heap-allocated object also of unknown type which also implements the interface. We can now implement Clone for Box&lt;GenericShortcutId&gt; using the box_clone method: impl Clone for Box&lt;GenericShortcutId&gt; { fn clone(&amp;self) -&gt; Self { self.box_clone() } } Now we need to implement box_clone for our id types: #[derive(Clone, Debug)] pub enum MyId { Increase, Decrease } impl GenericShortcutId for MyId { fn box_clone(&amp;self) -&gt; Box&lt;GenericShortcutId&gt; { Box::new((*self).clone()) } } #[derive(Clone, Debug)] pub enum UserDefinedId { Open, Save, Quit } impl GenericShortcutId for UserDefinedId { fn box_clone(&amp;self) -&gt; Box&lt;GenericShortcutId&gt; { Box::new((*self).clone()) } } Note that this isn't quite the same as what we had in the Java version - there we just copied pointers whereas here we're cloning the underlying object and allocating a new object each time. And finally, a full code sample that handles requirements 1. to 3.: trait GenericShortcutId { fn box_clone(&amp;self) -&gt; Box&lt;GenericShortcutId&gt;; } impl Clone for Box&lt;GenericShortcutId&gt; { fn clone(&amp;self) -&gt; Self { self.box_clone() } } #[derive(Clone)] struct Shortcut { id: Box&lt;GenericShortcutId&gt;, keys: Vec&lt;u8&gt; } #[derive(Clone, Debug)] pub enum MyId { Increase, Decrease } impl GenericShortcutId for MyId { fn box_clone(&amp;self) -&gt; Box&lt;GenericShortcutId&gt; { Box::new((*self).clone()) } } #[derive(Clone, Debug)] pub enum UserDefinedId { Open, Save, Quit } impl GenericShortcutId for UserDefinedId { fn box_clone(&amp;self) -&gt; Box&lt;GenericShortcutId&gt; { Box::new((*self).clone()) } } fn main() { let mut shortcuts = vec![]; // Insert shortcuts containing ids of different types: shortcuts.push(Shortcut { id: Box::new(MyId::Increase), keys: vec![1] }); shortcuts.push(Shortcut { id: Box::new(UserDefinedId::Open), keys: vec![2] }); // Clone a shortcut: let shortcut = Shortcut { id: Box::new(MyId::Increase), keys: vec![1] }; let cloned_shortcut = shortcut.clone(); // Clone a Vec&lt;Shortcut&gt;: let cloned_shortcuts = shortcuts.clone(); } Hopefully that helped at least a little! Please say if anything (everything?) isn't clear.
I will definitely read the Too Many Lists book, thank you for pointing it out. I agree with both your points there, I just thought it would be a nice exercise. Don't worry, I did not judge Rust based on how hard it is to implement X, it's just that I was hitting too many roadblocks (due to my own knowledge) so I decided to give it a break for now. Rust is a really nice language to write code in.
Thanks. Out of curiosity, why is it that generic closures can't be defined, when generic functions can?
I had the same story as you, Steve. I'll tell you how to make it less bad- learn powershell for 2 weeks. THey may not have a good console host but powershell itself blows everything out of water and I actually felt more powerful and home than linux.
There's just no syntax for it. There was [an RFC](https://github.com/rust-lang/rfcs/pull/1650) but there wasn't that much interest and it was postponed at least until the trait system implementation is overhauled.
Hahaha, good luck! What are libs are you using for a GUI in Rust?
No. Rust doesn't have a stable ABI, so there isn't really any point. The best you can do is publish it as though it were a pre-compiled C library (*i.e.* using the C ABI for everything).
maybe just code in Scala + Cats or TypeScript + [fp-ts](https://github.com/gcanti/fp-ts)? That's what I do right now. tbh, now I don't really code in Rust too. But would love to go back later
I current use msys2 on windows for my bash shell needs. A considerable number of packages for it, and even let's me use Unix tools to compile windows programme, without faffing with cross compilation.
I see, that makes sense. Do we anticipate a binary-only sharing feature when the ABI is stable?
I haven't heard of anything like that and, given how much planning is still to be done for any ABI stabilization, it wouldn't surprise me if they're deferring all of it until the surrounding stuff is more concrete. That said, I could be wrong and I'd like to hear of any relevant RFCs that I might have missed.
\**shrug*\*. Insofar as I'm aware, there's no serious effort to stabilise the ABI, so it's kind of a case of asking "do we expect high speed internet access when we get interstellar travel?"
Thank you.
Yeah PS is really awesome!
For me, it solves the exact problems I had with C++ (memory bugs with threading). It also has great features (traits, enums).
Thanks for the heartfelt response. I agree this would be cool, but it's real hard to collect up those "hard borrowing problems."... it's tough.
Yay! :)
I'm still very much a beginner at Rust, but I remember back in the early 2000s I repeatedly tried to pick up Haskell, noped the hell out of it whenever I hit monads and gave up, to try again a year or year and a half later, and ended up doing Scheme intensively for a few years. Then sometime around 2008 or 2009 I tried Haskell again and finally I started to "get it." I think part of it was the teaching materials and online examples just had gotten better in the meantime (Haskell didactic materials in 2002 were not nearly as good as present-day Rust materials!), but the other part is just that you can't always force the learning process to happen at demand—you have to expose yourself to the shock of new, fundamentally unfamiliar ideas first before you can unlearn the old ones, because your first instinct is to try and make them fit into the ideas you already have. I'm having the same experience with Rust. I pick it up for a week or two every couple of months, drop it, and then pick it back up again. It's been over a year now and only recently did I feel like I've begun to understand lifetimes for example. They're type variables that are instantiated to types that denote scopes, and the type checker uses "outlives" as a subtyping relation when it unifies them. And yet somehow I, who had learned a lot of the relevant theory beforehand from doing Haskell, failed understand that at first in spite of the fact that there were lots of Rusters *telling* it to me straight. Perhaps a year from now I'll even understand when to stack allocate vs. when to Box, and two years from now when to use Rc/Arc or Cow instead of Box. At this point in my life I know I won't manage to grok this big mass of intricately interlinked information quickly on demand, and that's cool with me. It's interesting, so I'll just keep having periodic goes at it every couple of months.
Author of the blog post here. Glad you found it useful :) We have now integrated this technique in all of our base images so for example you can use `FROM resin/raspberrypi3-debian:jessie` and use the `RUN [ "cross-build-start" ]` technique mentioned in the blogpost. We haven't announced it yet though so.. shhh.
The error about syscall 384 is safe to ignore but it is fixed in our official resin.io base images anyway. It's syscall `getrandom(2)` but all programs automatically default to reading from `/dev/urandom` if it isn't available. About the segfault we've also hit it while building Rust projects and we haven't found a solution yet. If you have any ideas we'll be happy to try. 
The really cynical part of me thinks that it's at least *partially* because once you spend a massive amount of time learning something your mind has to post-hoc justify it somehow.
18 month ago I was choosing a language to implement some server at my job. There was four variants, and two of them was Rust and Go. In both I've implemented same chunk of server's logic with networking and other common things. While reading the docs, Rust seemed to me a great language with generics, lambdas and other features which I didn't understand "yet". And Go was seemed to me too simple, and not so "new" as Rust. But eventually I feel frustrated also about rust syntax and too complicated ideas, as an author of this post. And after working with Go for past months I feel only the happiness. :) But sometimes the idea to try again Rust visits me too ))
We will likely *never* get something fully opaque. Why? Types. For situations like these, the best thing that *may* end up happening, long-term, is a backwards-compatible *compiler metadata* format, and a way to strip out source positions and names of everything (except names through which types and functions are exported). MIR is lowered enough to qualify as "binary", somewhat similar to Java bytecode - so if you could publish a `.jar` with only `.class` files, then that mode for Rust libraries would also work for you. ~~You could also make sure there is *no MIR*, if you have no generic APIs~~ (**EDIT**: see below the reason that you can't use machine code, at least when *any* types from dependencies are involved). You couldn't use machine code though, *everything* would have to be MIR (even if "obfuscated"), and it would have to be sanity-checked *because its dependencies may have changed* (the standard library changes every release). If you don't mind having one library release for each stable Rust release, we could *already* add that stripping mode, in fact I don't think private module hierarchies *ever* need to be accessible, only the leaves themselves, and all you'd have to do afterwards is use empty strings for anything not public or not exported by name and encode no spans. As a contribution opportunity (I'm willing to mentor someone on this), I'd start with the spans (include no per-file information and use `DUMMY_SP` instead of *any* `Span`), then with simplifying the the recursive hierarchy encoded in crate metadata (don't include nodes not reachable through a path - this might be incompatible with the new macro system and its fancy hygiene though). **EDIT**: demo of the new macro system, showing private items being hygienically referenced by a macro: https://is.gd/y9JUty (this exact example though would be an error with https://github.com/rust-lang/rust/pull/42125 because it leaks a value of a private type - you'd need to do https://is.gd/1G0Pb1 or something).
At least in Rust your errors are compile-time.
I was an angry little 17-something, and up to that point my experience with programming amounted to Python with a side of C++. My functional programming experience was Python 3 iterators (which I was very proficient with) and toy examples in Common Lisp. After trying to wrap my head around Haskell for like, four days straight and not being able to write anything but toy programs that did no I/O, I was very frustrated and started writing this big rant about why ‘they’ were wrong to implement monadic I/O and that it was _beginner unfriendly_ and why couldn't they just do it the _normal way._ Suffice it to say, when I wrote my own monad (reimplementing `Maybe a` from scratch without looking at existing code) less than a week later, I felt pretty stupid.
Fearless programming. What's simply amazing about Rust, is that it's taken every lesson and battle scar I've learned over my career, wrapped them all up in a bow and guaranteed the I'll never need to worry about them again.
You seem to want existential types which AFAIK are not available in Rust. In Scala you would call the type Shortcut[_]. Another option in Scala is to make the type parameter S a type member of a trait Shortcut, in Rust this doesn't seem to be possible because even if you box the trait it requires you to specify the type member, i.e. the trait Shortcut by itself is not really a type in Rust as it would be in Scala. I really don't know why this limitation exists.
Wow. Wthat you very much and Lol. because you basically described my approached to tackle the problems. I went from one compiler error message to another, read about the error and tried to fix it. What I found at the end very helpful wasn't the compiler message bit the description of the error code at https://doc.rust-lang.org/error-index.html The final code snippets you provided are also basically what I wanted to achieve in the beginning, using a empty trait as marker to tell other fn that enum ThisId is a Id and ThatId is an Id too. So it's possible, and the code is even 'self explanatory' if you know the fundamentals of rust. &lt;EDIT: following is a bad example of comparing autoboxing, autobxing isn't exactly what the case here is, it's not boxin primitives 1 and 1.0 to make it compute add)&lt;/EDIT&gt; I mean, yes, I know rust doesn't autobox, rust doesn't garbage collect etc., but it's a totally different thing to know it and to understand so one can provide a suitable solution. That requires go get the rust fundamentals straight, and I am not there yet. :) Without having the fundamentals straight this is a painful way of learning. Although many people are trying to be very helpful, they throw advices about rust features at me that sound they are from a different universe. In reality beginners like me, just iterate to the next one.77 The current state of my rusknowledge feels like "Ah yes,ok. that's why. Ehh. No.." Reading your two comments was very helpful. I read about Boxes but never applied them to my code. It's really strange, I knew it, and it#s abvious that variants of two different enums are of different types and that boxing them into a Box type makes them a Box type, but obviously my brain isn't wired correctly to apply that if not pointed to it externally, by someone else like you. Another approach of boxing was given by /u/coder543 who put a Custom field into my Id enum to box the custom ones. I think I get that one too now. Maybe. Let#s see until my next project :) Your tutorial got a little bit complex when it came to cloning. I think I have to stumble upon cloning errors again :) Also, it's a different thing how you learn a leanguage. I learned Java in university, in various courses, with good books and tutors pointing students into the right direction. Everyone was on the same level, and the tutor wouldn't suggest to do this or that, knowing that the knowledge is available. (which often happens online - Person A asks for advice, B, C, and D sggest to learn a another language, to do the fancy noone knows about secret nightly feature approach and another one doesn't understand the problem of Person A. :) I am not complaining, the guys are very helpful, but sometimes the advices don't match with the experience level. Yours was a really good example of how to doing it. Maybe people should state where they are coming from. Your examples showed, what I did wrong, it recovered the entires development phases with up and downs like in the gartner hype cycle and more importantly it described why things work in Java, but not in rust.. Maybe, when rust matures, there will be books and little projects, that do that too. I was in the military and the way of teaching things was to show, explain, repeat, drill to make sure the recruts really understand and don't just know about a thing, as I explained earlier. I think I will be able to amend my code to either your suggesttion, which is closer to my initial thought, I'd realize it. I may also do what /u/543 suggested, which is closer to my existing code. Above all, I went throigh all phases of satisfaction, disappointment and delusion, to enlightment and maybe I'll reach the state of productivity in rust programming one day. I am actually proud of myself. I first put hands on rust in November last year 1.10 , but never touched it really, Once a week I started a little project and did simple things, and stopped when there wasn't able to proceed. This project is the first one that actually would make sense, and I am almost where I wanted it to be, within two days. Thank you for your help - to others too. 
[removed]
Ah, OK, thanks!
Check out diesel.rs for use as an ORM.
Your Rust code looks really good, it seems like a good example to show what good Rust code looks like!
Agreed. Really nice example. Not too fancy, not too basic, does something interesting and relatable.
[HN discussion](https://news.ycombinator.com/item?id=14675431)
Just like Ion, job control is not implemented yet :(
&gt;:( [Here is a picture of a kitten to cheer you up](https://i.redd.it/yr01t7xz5rwy.jpg)
Lies! That's TWO kittens! :D
1. Many great ideas in the language, forming coherent whole. 2. More importantly, great deal of thought put into every feature. There are many ideas that are not unique to Rust, yet Rust manages to add something that greatly increases their value. For example you can have different traits with the same method names. 3. Lot of essential things done just right. Dependency management, cargo, 6 week release cycle. Somehow many Rust competitors don't do it so well. 4. It attracts people who care about what they do, which results in many great libraries representing state of the art in their domains.
Error handling done almost entirely within the type system means that once your code compiles it probably runs. Honestly makes life so much better
It is a bit of an ergonomic wart, but it seems to be what we've got for now. Maybe propose an RFC?
I’d attend/help. :)
Yeah, I definitely need to check out the Ionide extension again - there were a few little things that made it a pain to work with last time I tried, but it sounds like development is moving really fast on it, and the stuff that works well works REALLY well. Damnit, I think you just sent me back down the F# rabbit hole again :p
I would like to mention that most manufacturers provide DOS based BIOS update tools.
Great, I'm glad it helped! I've just checked the latest copy of the Rust book and it now contains [a section describing a situation similar to yours](https://doc.rust-lang.org/stable/book/second-edition/ch17-02-trait-objects.html). It even mentions the Self : Sized error when implementing clone. However, it stops at "you can't do this", and if you're new to Rust it's not obvious that chapter 17 of the book is where you go to learn how to do something that's straightforward in the language you're coming from. The book itself is in a bit of a bind here - this chapter can't come too much earlier because quite a lot of Rust concepts have to be introduced first. It's also the first place most people will look for example Rust code, so it should generally only contain idiomatic Rust, whereas if you're trying to convert some code from e.g. Java into Rust there's some value in knowing the most direct translation of your code into Rust that compiles, even if the result if pretty weird by Rust standards. You can always improve the design later, but it's motivating to have a starting point that actually runs! It would be nice if there was a guide somewhere translating between standard OO concepts and practises and their Rust equivalents, but as with everything this requires someone to actually write it. The translation could involve two steps: 1. the most direct translation of the starting code into Rust, and 2. more Rust-y approaches to doing the same thing. Maybe the best approach would show examples of translating ~1k LOC projects from other languages into Rust, but it would be a huge chunk of work to find or create suitable starting projects, do the conversion, and explain the different design choices made in the Rust versions. An unavoidable issue is that learning Rust is fundamentally harder than many other languages. Even with all the documentation in the world, the design choices Rust makes force the programmer to care about things that happen automatically in other programming languages. In particular, memory safety without garbage collection, and a focus on zero cost abstractions, have to come with some ergonomic cost. Rust is a systems programming language that can also be enjoyable to write other sorts of programs in. But there is a genuine tradeoff - avoiding a garbage collector makes the programmer do more work, and if your programs work perfectly ok with a garbage collector then this is extra effort for nothing. In many cases the extra effort is worth it - there are lots of domains where the combination of memory safety, high performance and no runtime are crucial. And lots of others cases where you're not constrained in this way, but the expressivity of the type system, lack of null pointer exceptions, and other nice properties of the language make it worth the effort of manually wrangling lifetimes. But you still have to understand and consider issues that just don't occur in a lot of other languages, and there's an unavoidable learning curve. The lack of inheritance makes this harder - you'd have the same ownership and memory management issues in C++ (although there they'd happen at run time rather than compile time. Which is worse in the long run, but does mean you can at least run your code, rather than banging your head against the compiler for hours), but because there's inheritance you can write code similar to what you're used to and just use shared_ptrs everywhere. Ok, this post was just a load of waffling! Good luck with your project.
I think the README is missing a simple answer to: why should I use Cicada over another shell? --- A (possibly shallow) comparison with other shells, explaining the differences, and when one would use Cicada rather than sh, bash, zsh, etc... would be quite useful. From my cursory reading, it seems that Cicada aims at being a drop-in replacement of `sh`, am I right? Did I miss something? I don't know...
Looks a bit like Flask, judging from a quick glimpse. Has anyone written a more complex project with this framework e.g. with login, sessions/cookies/DB access? Checked the repository - how is the front end of the Rocket.rs website [1] rendered? [1] http://rocket.rs 
are you unable to read?
I built a REST API with Iron and Diesel. What else do you want?
He asked for REST-api tools and you told him to use diesel.rs as an ORM. You basically didn't answer his original question until now.
"No", and "probably yes with procedural macros, although you'd still have to import all those traits which could get ugly".
When i took a break for few months and tried again (learning some web stuff), the primary hurdle i found was "the various ways in which Rust declares variables, different for methods, struct and traits"; i am still not clear if this statement is even correct, but i am learning and i relearn as i go along, thats the way to go if you are obsessed with positives of Rust platform. But yes i take this opportunity to point out there Rust must fix this variation in variable declaration, or all OOP guys will be left out high and dry (excluding some die hard exceptions like me ;-)
Rocket does handle sessions and cookies. I would have to assume that people wrote some projects with it considering how often it gets posted on this subreddit. You are right that it looks like Flask.
Is an ORM not a REST-api tool?
Can you explain the advantages of this over other approaches?
Why are functions on the won't do list? Pretty much guarantees never using for scripting.
Of course not. As the name says it's about object-relational mapping. Normally in web dev it means the part that converts your data between the database and the actual program and its object model. One example from the java side of things is Hibernate.
C++ is more straightforward than Rust as well, as long as you don't care about runtime errors and memory leaks.
Update: 8% speedup thanks to this optimization. Thanks again!
For conversions like your second example we do have the [`From`](https://doc.rust-lang.org/std/convert/trait.From.html) and [`Into`](https://doc.rust-lang.org/std/convert/trait.Into.html) traits.
&gt;What I'm curious about is what makes programmers fall in love with it. So, what's the deal? What's so lovable about it? So, I came at Rust from the script kiddie angle. Instead of being a grizzled C/C++/Haskell veteran who actually understands why Rust is different, I just find the tooling great. Cargo, rustup, crates.io, are all very good (compared to my experiences with Python, Go, C, C++).
Using `const` to define some constant in Rust is analogous to `#define` in C/C++. You can think of it as telling the compiler to sub in the value inline every time it sees the constant's name. Immutable variables still take up space on the stack and exist at runtime, whereas constants only exist in the source code. In `const x: u32 = 5`, the `x` variable doesn't actually have a location in memory.
It's not ideal, but the best way would probably be to compile as a `cdylib` (`*.dll` or `*.so` depending on your platform), then distribute it as a C library with an accompanying C-style header file. 
Yes, but only for your own enums, and only for such that have a single parameter which take an argument. For foreigen enums its not possible to implement the `From` trait.
Generics, expressions, left and right of statements exist in Java as well though. If you just wrap everything in an Arc, and use clone() for everything, you get Java like objects.
Felt this way the first time. Making a PRQuadTree nearly ended me. But the second time around it was a cake walk. I didn't even feel like I learned anything in the in between time. Varies person to person though. Good luck with your bull pointers :P
I have written a small PoC rocket diesel + sessions + auth project. It doesn't do much yet, but I plan to extend it once I have a bit more time (and 0.3 is out. currently requires rocket master). Basically want to use this as bootstrap project. (or cargo template, once they are back) edit: link: https://github.com/belst/rusty-diesel-rocket
Will be implemented soon. I just implemented SIGTERM handling yesterday, and SIGINT a week ago.
I don’t know what infix means, but from your examples I assume it’s method call syntax. You can make a trait to add methods to any types (including those from the standard library or other libraries): trait MyStringExt { do_something(self, n: u32) -&gt; String; } impl MyStringExt for String { do_something(self, n: u32) -&gt; String { // ... } } The new methods will be available wherever the trait is "in scope". From another module: `use foo::bar::MyStringExt;` As Quxxy mentioned, you could use procedural macros to generate that code semi-automatically.
Will keep an eye on procedural macros, thanks for the hint.
[removed]
Procedural macros seems the way to go. I really love how welcoming this community is. Should have made clearer that I understand how to use traits in Rust :| so that the answers could be more appropriated to my knowledge level.
One feature of an `sh` replacement is very low resource usage, especially memory, since `sh` is used to spawn many, many, too many scripts in parallel. Every kilobyte counts and if the most trivial dummy shell script uses __more than__ 500k, it's a hard sell as a drop-in replacement in terms of performance. Memory safety is nice to have, but shell scripts already have all kinds of leverage to wreak havoc so that alone won't be able to sell it as a replacement for `dash` and others. This is meant to be supportive and motivating criticism, definitely not negative. If I failed to express myself as intended please let me know.
It isn't, and it's honestly kind of annoying how people write "extension traits" as hacks to get the method call syntax (what you call infix). It would be nice in some ways if `f(x,y)` was just the same as `x.f(y)` and this whole `self` keyword didn't need to exist, no need for `impl` on a datatype. Just define `fn` in a module and static methods are really just a namespacing hack to begin with.
Should have preordered a DRM free e-book while I still could. Bring back DRM free e-books please OReilly Media.
Feel free to open issues if you need some help. I don't know which direction to take with my codebase so any input helps a lot!
Write an RFC for `|&gt;` operator
Great post. Channels are a tremendously powerful feature and imo a very easy sell to other developers.
It's possible to make `trait Foo` and `impl&lt;T&gt; From&lt;Bar&gt; for T where T: Foo`.
So Rocket on its own allows the [full range of REST style routing](https://rocket.rs/guide/requests/) including * Routing on method: GET, PUT, POST, DELETE, HEAD, PATCH, and OPTIONS * Routing on request Content-Type, such as `text/xml` or `application/json` * Variable extraction from path and query, e.g. GET /users/&lt;user_id&gt;?summary_only=true Using crates like [jsonwebtoken](https://crates.io/crates/jsonwebtoken) or [frank_jwt](https://crates.io/crates/frank_jwt) you can easily (using annotations) build in support for authentication of paths using JWT. You can also use Rocket's APIKey trait to implement your own authentication types. In terms of response Rocket has JSON support out of the box, and [serde](https://crates.io/crates/serde) will do XML for you if you want that. As /u/PolloFrio mentioned, if you want to talk to a database, Diesel.rs works particularly well, and [redis-rs](https://github.com/mitsuhiko/redis-rs) provides good access to Redis if you want a document store or just a cache. What else do you think you need to build a REST API specifically? 
You might be looking for `let foo = env::args().nth(1).as_ref().unwrap_or("hello");`
While PolloFrio's suggestion may not have answered your question, that's no reason to be insulting and rude.
Thanks Unpatched :) I completely agree about channels being a great feature.
[removed]
[removed]
That's pretty much what I came here to say. Without functions, this will never be anything more than a toy project.
Awesome!
&gt; This is meant to be supportive and motivating criticism, definitely not negative. If I failed to express myself as intended please let me know. Not at all, I agree with the analysis. I have no idea whether Cicada delivers on those topics however.
I honestly never get this story; people who want to switch to some Unix (typically some Freedesktop/Linux system) but are seemingly quite content with Windows I mean... why? It's almost like someone talked you into feeling guilty for not using Unix so you try desperately to force yourself while seemingly Windows works fine for you; what are the advantages of Unix in your opinion?
Can you say more? How are they different?
[removed]
I believe he means Rust has the memory management (as opposed to the program) while in C it must be handled manually.
I'm honored to hear that! I always try to run rustfmt and clippy on my stuff to follow some semblance of best practices. I will say this, it definitely takes a while to get a hang of a "nice" way to structure projects. This was a bit of a toy project but it still had enough complexity that I had to think about how to lay it out. I feel like it took a while for me to get the hang of that with Rust. But now I think I have a good feel for how to structure things.
&gt; You can also use Rocket's APIKey trait to implement your own authentication types. Just a minor correction on this point. APIKey is just some arbitrary type in a code example. They call the feature [Request Guards](https://rocket.rs/guide/requests/#request-guards), and the trait to implement is [FromRequest](https://api.rocket.rs/rocket/request/trait.FromRequest.html).
At the same time, though, virtually everyone who's poured that amount of time into Rust at this point has done it voluntarily. It's only been taught in a handful of optional school courses designed around it, and the jobs that touch it are new and rare. So maybe it's more of a survivorship bias, if we're being cynical. :)
In general, publish/subscribe systems tend to be based on unreliable connections, are not very distributed, may not have proper authentication and may not scale up that well. This approach tries to fulfill this type of requirements. With Mles protocol, the server side has very lightweight processing needs which should help in scaling up. The server does most of the processing during first message received from client. After the first message, it just passes information forward. With the distribution approach the possible high load should be able to be shared quite evenly in a tree like structure, where the leafs may have the least processing power. In addition, clients may run their own protocol on top of Mles with minimal dependency to Mles protocol itself. http://mles.io has some examples of use cases.
Roberto is really good at writing. I feel his style is very similar to kerninghams.
Edit: I have decided I will post this on [SO](https://stackoverflow.com/questions/44865737/println-panics-when-called-concurrently) as it does not seem so easy to answer I am trying to rewrite some signal handling in Rust that we are studying in university in C, here is what I have so far: extern "C" { pub fn signal(sig: u32, handler: extern fn (u32)) -&gt; extern fn(u32); } pub const SIG_INT: u32 = 2; extern fn interrupted(_: u32) { println!("Interrupt"); } fn main() { unsafe { signal(SIG_INT, interrupted); }; loop { println!("Hello"); } } The problem is that the above code always panicks at runtime with 'already borrowed: BorrowMutError' as soon as you interrupt it at the println!. I am really new to Rust and don't understand this. I was under the impression that both println!s are in a safe context and should not panick, or is println! not thread-safe? If I remove either of the println!s it runs fine
In one of the examples you explicitly don't call join (because of infinite loops). Will the OS reclaim the threads when the program quits? Because this could make something I was working on a lot easier.
I haven't looked at this code in particular, but yes, an OS will reclaim any threads once your program exits. Rust does a thing that's a lot nicer than Go w/ threads and channels, too. In Rust, unlike Go, when you create a channel there are two halves, a sender and a receiver. If all the senders are gone (i.e.: have been dropped, possibly because their threads have finished), the receiver can know this and will end iteration. Or, if the receiver has been dropped, the sender can know (IIRC it returns an error if you try to send to a channel that no longer has a receiver) and you can just exit your worker thread. In Go, channels don't give you such guarantees, so you have to manually create and manage WaitGroups to know when all your producers have finished. It's much nicer in Rust. :) 
Hi Raptor. As I understand it yes, the OS does reclaim those threads when the program quits. When the main thread (ie the thread that main was initially called on) finishes, all of the other threads that have been spawned will be killed.
&gt; 3) CNAME - ~~Cononical~~ **Canonical** Name FTFY
I gave up on Haskell about six years ago due to never managing to work out how to scrub the IO type from things so that the rest of my code would work. It was fine for maths, though.
Thanks! Oh. And look at that VSCode has a spellchecker...
The easiest way to get off-the-ground is by `impl`-ing `From` for the error types. // Assuming: // - MyError is an enum you created // - MyError has a StdIoError variant that takes an std::io::Error impl From&lt;std::io::Error&gt; for MyError { fn from(e: std::io::Error) -&gt; Self { MyError::StdIoError(e) } } fn do_the_thing() { match read_file() { Ok(s) =&gt; { ... }, Err(MyError::StdIoError(e)) =&gt; println!("Got a std::io::Error: {:?}", e), } } fn read_file() -&gt; Result&lt;String, MyError&gt; { let file = File::open("/path/to/file.txt")?; } You could use a crate such as [error-chain](https://docs.rs/error-chain/) but I do not have much experience with error-chain so cannot speak to the usability of it or if it really helps with depth of error chains (I can't image there is a way around this, unfortunately).
Mostly from the programmer stand point. It's where a lot of stuff seems to happen open software wise. While rust made an effort to support windows, many other open technologies don't, and while certain efforts over the years have made it easier for stuff to support windows, sort of, without the need for many projects to massive work, it often still doesn't get done. Windows as an OS though, does plenty suit my needs otherwise. It runs my computer, and I can do what, for the most part, everything that I need to on it.
The simplest solution is to use [map_err](https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err). Lets say we have fn do_something() -&gt; Result&lt;SomeType, LowLevelError&gt; { ... } At some depth, you want to call this function, but return "less granular" errors, so you write fn blah() -&gt; Result&lt;SomeOtherType, HigherLevelError&gt; { let correct_result = do_something().map_err(|e| transform_the_err(e))?; ... } this way you get your OK value if it succeeds, and otherwise you map the error to HigherLevelError, and propagate upwards with the `?` operator. Additionally, I know [error-chain](https://docs.rs/error-chain/0.10.0/error_chain/) is considered *the thing* for more complex error handling, but that's not something I've looked into yet.
map_err is definitely your friend especially when needing a consistent type from a Future or Iterator. I highly recommend error-chain for the From and Into trait implementations for error conversion. Any new Rust project I start now has error-chain right from the beginning.
Are there any semantic differences for `Foo` and `Bar` defined below, or are they equivalent? struct Foo&lt;'a, 'b: 'a&gt; { foo: &amp;'a Vec&lt;&amp;'b i32&gt;, } struct Bar&lt;'a&gt; { bar: &amp;'a Vec&lt;&amp;'a i32&gt;, }
Thing is, you never need to scrub the IO from your code. You need to isolate your logic from your IO so you can do IO to input data, then process data with logic, then do IO to output data. Ideally your `main` should look like main = do x &lt;- readSomeData let x' = processData x writeSomeData x' where reading and writing does as little processing as possible, and processing does no IO at all. If you need things like logging, you can use pure alternatives like `Writer`.
What about DeadBeef?
Personally, I haven't used it and doesn't seem to be available on Windows. Nevertheless, I'll try it to see how it goes. Thanks, mate!
Also, what do you mean by "writing an audio player"? Do you plan to implement codecs from scratch? That's why you need a fast language? If not - you can stick with PyQt and get the same results, because GUI which only manages audio backends can be written in any language.
Honestly, this is the best use case for python.
Isn't this because those groups are also just smaller in the general populace and also smaller within programming? Rust shouldn't divert its attention to trying to solve political problems in my opinion. Rust doesn't have enough power to be able to influence that kind of thing, and for it to try to do so would cause some of its focus to wander, which would weaken its position in the area that it dominates in, which is being a really good programming language. I'm just speaking realistically here. It's nice that the rust leaders are aware of these problems, but it's not their problems to solve. Continuing to advocate for an open community is the best solution, rather than actively seeking to target subgroups. It may seem like a more passive approach, but a language like rust can't afford to get into this volatile topic so aggressively. 
&gt; Is there an ideomatic way around this? What a lot of people don't seem to know is that `try!($exp)` (and `?`) more or less expands to: match $exp { Ok(x) =&gt; x, Err(e) =&gt; return Err(e.into()), } So it uses `.into` to try to convert it to the appropriately typed error type. So if you implement your own error type you can implement the `From` trait to get this conversion automatically. The idiomatic way is to have an error type specific to your care typically and write a `From` to convert all other error types you use into that. If it's not common enough to this you can use `Result::map_err` to perform a quick conversion like: foo().map_err(|e| MyErr::from_string(format!("{}", e)))? 
This book was def one of the biggest casualties to me of the O'Reilly transition. I'm thankful I bought the PDF on a sale a while back since anything bought already remains available in those formats.
I use MPV/libmpv. There is the following [mpv crate](https://crates.io/crates/mpv) for Rust bindings to libmpv. Great experience, the command reference/docs aren't the best but you can figure it out with google and stack overflow. I use it in [surge](https://github.com/sevagh/surge), my command-line music player. Here's the code which actually does MPV things: https://github.com/sevagh/surge/blob/master/src/player.rs
The point is not the relative sizes of groups in the Rust community. The point is that those groups are underrepresented in the Rust community (and open source in general) compared to tech-in-general and the general population. That makes it very much Rust's problem to solve, and the ones making this topic so volatile in the first place are likely part of the problem.
If you're writing a library or otherwise wants to follow what's currently best practices, check out [Starting a new Rust project right, with error-chain](http://brson.github.io/2016/11/30/starting-with-error-chain). For more options, see [the error handling chapter](http://stevedonovan.github.io/rust-gentle-intro/6-error-handling.html) of the Rust gentle intro. But the easiest thing to do, if you are developing a standalone program (and not a library), is to turn all errors into `Box&lt;Error&gt;`. That way you can use `?` anywhere without much hassle, because all errors implement the [`Error` trait](https://doc.rust-lang.org/std/error/trait.Error.html). If you go this route, define a `type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;Error&gt;&gt;` and make all erroring functions return `Result&lt;T&gt;`. Such local `Result` has precedence in definitions like [`std::io::Result`](https://doc.rust-lang.org/std/io/type.Result.html).
I thought about the same thing, and it's probably right. However, I have more experience with the Rust ecosystem than the Python ecosystem so I decided to just do it in Rust.
Yes, there is a difference. See [this example](https://is.gd/X8bYBI). Try uncommenting the line in `bar` to see the error that would occur. Basically, the reference to the `i32` needs to live as long as the `Vec` (but no longer), so I can't copy the reference out and then drop the `Vec`. There is no limitation of this on `Foo`, since the additional lifetime annotation means it can have a different lifetime.
This is what I was looking for. I was reading The Rust Book (second edition), [*A Shortcut for Propagating Errors: ?* chapter](https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html#a-shortcut-for-propagating-errors-). It described the expansion to match (referring to a code sample in the previous chapter) but the code sample didn't have `.into()` call in it. Also elsewhere I read that Rust doesn't do implicit conversions. That's why I was confused. Rust has so many specific error types. How one could effectively propagate them without conversion. I wonder if this type casting bit should be included in the book. Without it the whole concept seems much less useful than it really is. /cc /u/steveklabnik1
Try using [the nix crate](https://docs.rs/nix/0.8.1/nix/index.html) for signal handling.
Ah, sorry for misunderstanding!
People who say Rust doesn't do implicit conversions are full of it it does plenty of them: 1. `&amp;Foo` will get implicitly converted to `*const Foo`, and `&amp;mut Foo` to `*mut Foo` 2. `Foo` will get implicitly converted to `&amp;Foo` in method call syntax. 3. `&amp;Foo` will get implicitly converted to `&lt;Foo as Deref&lt;Target=Bar&gt;&gt;::deref(&amp;Foo)` if a type `&amp;Bar` is needed. Rust has many, many implicit conversions. This isn't one of themthough; this one is explicit. It just so happens that everything intos into itself.
In that example, why do you use a for loop with its param dropped rather than a loop statement?
Thanks for the tip, however part of our course is writing this stuff by hand instead of using existing libraries. Nontheless I tried the nix crate using the sigaction method, but I have exactly the same problem, so I don't think my problem lies in the signal handling, but with println! failing with the concurrency, which I thought it should not.
`rodio` for audio, does not play mp3. There is a `play` library, which can play mp3 tracks. However, you're better off with libvlc. Don't go with Electron. Yes, it will look beautiful, but see - nobody wants a 150MB music player on top of the three Electron apps (Discord, web browser, spotify, etc.). People want to run more than one app at a time. I can, however, not give you a good alternative for Rust - GTK is your best bet right now: https://youtu.be/hLR8R0Zl0yY?t=62 . I have been working on my own GUI framework [here](https://github.com/sharazam/explorer) - http://i.imgur.com/ygwOxN5.png . It's built on top of pure OpenGL and relatively simple layout code, based on CSS' `display:flex`. However, I don't have much time to work on this, just wanted to say.
They are not equivalent. The difference is what you can do with the references you get out of the vectors. Here's an example: https://is.gd/YyGDM8 With `Foo`, you can retrieve a reference and keep it around longer than the vector itself. With `Bar`, you cannot.
Of all the music player's I've used. MusicBee and Lollypop are my favorites by quite a margin. I use Lollypop now since I'm mostly linux, I tend to not be a poweruser I just want to navigate to a release and play it. I tend to really like visual navigation, with a very powerful fuzzy search mechanic. Regex search is nice too, but I want to be able to fuzzy search on song, artist, album by default. MusicBee is the king of fuzzy searching imo. Organization by Artist then by release is also a big thing for me. Also really easy to use queues are super important to me. Lollypop's is nice but it needs a dedicated screen, not just keeping a drop down open. The drop down features are nice though, so you have the option to not jump to a brand new screen/tab. I've sort of wanted to start a similar Rust music player project, but I've never done UI before. I'd certainly try to involve myself in some regard though.
I assume you're asking about the ones that are `for _ in 0.. {` No good reason really. I should actually change those ones to be loop statements like you're suggesting. I think at the time of writing, I was coming from the previous examples, where it is `for _ in 0..5`
How often does a rustacean use unsafe code? Are there common scenerios?
In that case, yes you cannot use `println` since that locks the `stdout`. I tried making something myself just now, but it became too difficult to do. You'll need to dig into the underlying primitives for putting text into a buffer. This will get annoying, because it's shared global state. This is honestly much easier to do in C, since C is much easier about global mutable state. Not to say this isn't possible to do in Rust, it's just difficult to do safely since the original unix signals aren't really safe to begin with...and that's what the `nix` crate is for :P
Or a shell script?
`ghcl` has good argument parsing with `clap`, good config handling with `yaml` and `app_dir`, good error handling with `error_chain`, and cross platform support. Those are all hard to to do with a shell script.
I think your iTunes gripes are a bit too much... iTunes - doesn't support anything that is not blessed by Apple (see FLAC), yet out of all you listed is the most usable in my case. Second only to Spotify. Neither of them support Airplay or Chrome cast out of the box. Neither of them have multi-source support within same queue. Neither of them have guest mode (except for iTunes) where user can add things to the queue. Neither of them have multi-room support (except for device aggregation and multi-airplay in iTunes) Neither of them have TV friend interface (see Spotify for Android TV and possible iTunes + apple tv) All of them look like spreadsheets or have very limited functionality. Some don't support play queue. Some don't organize music files (see how iTunes does it). This more of OS gripe, but on OS X I can search music from iTunes with no troubles. Which is handy. Look how dope Github's wrapper around itunes! 
I had no idea that DNS can be used over TLS. I wonder how many DNS servers and OSes support this.
&gt; Also, what do you mean by "writing an audio player"? Do you plan to implement codecs from scratch? I mean to develop a music player, like the aforementioned options above. A player with a modern, good-looking UI/UX that lets you play your entire music library as soon as you install it that also works as a management tool; where you can tag your albums properly, rip your CDs, calculate ReplayGain tags, add missing album covers, etc –that kind of stuff. &gt; you can stick with PyQt and get the same results, because GUI which only manages audio backends can be written in any language. Could you elaborate further on this? From what I understand, you're saying I can use PyQt to develop the UI and use any language I want for the backend.
Can you file a bug please?
It depends on what you're doing. I use unsafe for two things: FFI wrappers, and my operating system project. Even in the OS, it's not much. Implementing your own data structures is another time where it's common. 
Hey, that's pretty nice; although I not a fan of CLI-based music players, your work there is great, especially being YouTube-based. I'm going to check it out later :) You plan on developing it further?
thats an interesting point - how C++ has it's C like subset , and a spectrum of subsets in-between . the one thing that keeps stabbing me in Rust is how easy overloading is in C++; people keep saying 'traits allow ....' but in C++, I can write a piece of code using one type, test it, then stick 'template&lt;..&gt;' in front of it, and use it for other types. I've usually got to write some sort of test for other reasons (i.e. verifying that the logic is actually correct). So I get compile-time polymorphism without having to figure out how trait bounds should work, how functions should be grouped ... and have had 20 years of applying this
I want a music player that looks like Google Music. Currently using Clementine on Ubuntu. I use a symlink to point my Music folder to a different hard drive. It sometimes confuses my music players. Not sure if that's what I'm supposed to be doing, but it seems like that should just be supported out of the box.
I wasn't aware of rodio. Seems like a young project, but looks great. I'm probably better off with libvlc, but I'll keep in mind the former for reference. Thanks for bringing it up! Yeah, Electron is definitely out of the question. Performance here is top priority. Thanks for the YouTube link, I'll be checking it out later and I'll keep an eye on your project and hopefully, lend you a hand as well :)
Why did you think `~/Library/Application Support/ghcl/config.yml` would be a good location for the config file on Mac? It should really be the same as on Linux (`~/.config/ghcl/config.yml`)
Great to see a fellow MusicBee user over here :D Yup, MB works pretty great, I'm a big fan. I just wished it had multi-platform support. I wouldn't be here developing this idea if it was available on Linux. Lollypop is also great, my only concern with it is the lack of gapless playback with MP3/M4A. Acc. to the main developer, it's a [GStreamer/MPEG issue](https://github.com/gnumdk/lollypop/issues/708) and unless it's fixed over there (something that doesn't seem feasible anytime soon), Lollypop will be lacking it. And I really appreciate you lending me a hand on this project, I'll make sure to contact you if happen to pick Rust as the language for this.
Strongly disagree. As someone who maintains Python and Rust programs that are cross platform, the Rust programs are much easier to maintain and generally have fewer installation problems without any additional work on my part.
I'm aware iTunes works really well on macOS, but as a Windows/Linux user, it's not an option anymore. On Windows, freshly installed and with a small library, you won't have any problems. But as the size of your library grows, iTunes really struggles. &gt; yet out of all you listed is the most usable in my case. Second only to Spotify. I don't see how iTunes is more usable than Dopamine or Lollypop. &gt; All of them look like spreadsheets or have very limited functionality. Are you sure about this? Have you ever used MusicBee or Foobar 2K? Foobar might look like a spreadsheet (which is no different than iTunes, really), but it has a ton of functionality. Even Clementine which is a lot simpler than Foobar has a lot more power than iTunes. Also, Dopamine and Lollypop doesn't look like spreadsheets whatsoever. &gt; Some don't support play queue What kind of music player doesn't support play queue? &gt; Some don't organize music files (see how iTunes does it). Could you please elaborate further on this one? I understand that no music player ever will be a **silver bullet** for everyone out there (mine included), so pointing out **no support for Airplay/Chromecast**, **lack of guest mode** and that kind of stuff is senseless, to be honest, especially on a **desktop** music player. That said, this thread is not, by any means, a rant of the sorts about the aforementioned music players. It's about developing one on Rust. I mentioned those music players as I've used all of them for a long time now and I want to work on something that covers most of the things I'm looking on a music player.
Nybbles and bits nybbles and bits! 
For future posts, describe what the crate for is in the title, not just that there is a crate. This is my opinion, at least.
Yes, I have plans for it, but you know how $WORK and $LIFE get in the way sometimes. Primary annoyance now is that it takes time for `youtube-dl` to realize it's already downloaded a song. So if you do: search beatles yellow submarine play 0 That streams selection 0 with `libmpv`'s `youtube-dl` streamer. If you toggle download on (and I should make this persistent in the config): search beatles yellow submarine play 0 &lt;wait for youtube-dl to download the file&gt; This will actually download the file to `~/.local/share/surge/music`. Finally: search beatles yellow submarine play 0 &lt;wait for youtube-dl to decide that it's going to download the file that already exists&gt; For that reason I want to cache search results in a HashMap - something like "search terms -&gt; { results, downloaded paths }".
You neglected to mention [Audacious Media Player](http://audacious-media-player.org/), which I'd suggest you look into. It's cross-platform, designed to have Foobar-like flexibility in its default frontend (I run it in a narrow configuration with a single `{position} {artist} - {title} {stretch gap} {length}` column), but with support for multiple frontends (as in-process plugins), and it carries along what is likely the most comprehensive library of format support of any audio player which can run on Linux. You might just want to write a "frontend" for it which establishes a multiprocess client-server configuration. ...or, if you'd rather go in the other direction and don't need many formats supported, [mpd](https://en.wikipedia.org/wiki/Music_Player_Daemon) is a headless client-server music player first and foremost, and quite a few frontends have been written for it over the years. That said, if you still want to do this, there are three ways you can use PyQt for the frontend: 1. Do as I do with non-multimedia applications and use [rust-cpython](https://github.com/dgrunwald/rust-cpython) to comfortably expose a backend written in Rust to a PyQt frontend. (Here's a [screenshot](https://imgur.com/2yQMBZI) of one such project, where I'm in the middle of migrating the backend to Rust to take advantage of the stronger type system.) 2. Use PyQt's bindings to the [QtMultimedia](https://doc.qt.io/qt-5/qtmultimedia-index.html) module and just let [the OS's media framework](https://wiki.qt.io/Qt_5.7_Multimedia_Backends) handle format support. (eg. GStreamer on Linux) 3. Use PyQt with PyGST to hook up to GStreamer directly and deal with the fact that, in exchange for the ability to write custom format plugins only once, you'll be carrying along extra boilerplate, ignoring any format plugins users have installed on non-Linux platforms, and may not get any hardware acceleration which would otherwise be offered. Keep in mind that, for both of the latter two options, there's been a fair bit of effort exploring and improving the ability to write GStreamer format plugins in Rust, since parsers for untrusted data are the area which can benefit most from a safe language like Rust. (And, if you do want to write a format parser, might I suggest [nom](https://github.com/Geal/nom)?)
Your SSL cert is bad. The http site redirects to the https site, but the SSL isn't set up correctly, so there is no way to access the demo.
I'm just going with the defaults from `app_dirs`. From what I understand, that path is what applications normally use on MacOS.
Interesting! Do you still see a use case for Python then? Great work on ripgrep BTW, I use it all the time :)
You want r/playrust/, r/rust is a subreddit for the [Rust](https://www.rust-lang.org/) programming language.
THIS IS THE WRONG SUBREDDIT. BEFORE POSTING, YOU SHOULD CHECK WHAT A SUBREDDIT IS ABOUT. YOU PROBABLY WANT /r/playrust. ALSO, YOUR CAPSLOCK KEY APPEARS TO BE BROKEN. (I'M SHOUTING ON PURPOSE BECAUSE I'M USING A WIRELESS KEYBOARD QUITE A WAYS FROM MY COMPUTER.)
You should have check [Hub](https://hub.github.com) which provide this (and some more) in much more natural way. 
Interesting. I'm surprised they recommend aliasing `git` to `hub`. The tool seems a lot more general than `ghcl`, but it'll probably always be GitHub only (as it's created by GitHub). Personally, I'd prefer setting up the repo once with `ghcl` and then using normal `git`, as opposed to always using a git wrapper. I can certainly see the advantages of `hub` though.
You can use Git normally when using a Hub. This is only a thin wrapper that extends built in functionalities with GitHub improvements. It doesn't get in a way with any other host that I am using. 
I have to say that I have never ever seen a CLI application put configs in that directory, my `~/.config` instead is where every one of them lives. Now Cocoa GUI applications however usually put them in the Library folder and I think that's where `app_dirs` gets it from. Well whatever, the majority seems to disagree with me, I just think it's weird for the config to be there.
deleted ^^^^^^^^^^^^^^^^0.4557 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/35968)
If it's important, you can always put `alias ghcl="ghcl -c ~/.config/ghcl/config.yml"` in your shell rc.
These days, I use Python for short scripts or very rough prototyping. I also use it in projects that are targeted towards non-programmers, as many folks seem to be able to pick it up a bit and hack things together as needed. They probably wouldn't be able to do that with Rust (or numerous other languages).
&gt; In case GTK/Qt happen to be out of the equation, a headless server approach would be feasible under Rust? If the answer is yes, how was your experience with it? Any thoughts worth sharing? Is there any performance trade-offs I should be aware of? Have you looked at [mpd](https://www.musicpd.org/)? I'm not entirely sure what you're trying to accomplish, but it might be helpful.
I'm not sure if that's the best way to think about it, since `let`-style immutable variables can also be 'inlined' (and likely will be) which would mean that they too would not have a location in memory. I think a better distinction to make would be that a `const` variable must have a known value at compile time, where as an immutable `let` may or may not have a known value at compile time.
This sub is for the Rust Programming language. Try r/playrust
This is the most meme use of rust. write a bash script and stop it. 
&gt; Yeah, combined with the fact that they might appear in the message randomly scattered. Exactly. &gt; Is prost the only implementation that does this? `quick-protobuf` does it for recursive structs, but when I looked at it a few months ago it wasn't able to detect co-recursive structs. In case you're interested, this is the guts of how `prost` recognizes nesting: https://github.com/danburkert/prost/blob/master/prost-codegen/src/message_graph.rs. Also, related issue brought up a few days ago: https://github.com/danburkert/prost/issues/13.
Is it only available in paperback...?
And now we have [SIGTSTP](https://github.com/redox-os/ion/commit/d9506aa6c8a7851981547736161a168ccf0ad69b) handling, `bg`, `wait`, and `jobs`.
What's the reason of you telling me what to do?
middleware. rocket doesn't support it.
I think I'm going crazy. I am an experienced programmer but I am severely struggling to even implement a binary search tree, even with searching and looking at others' implementations. I know this is a common question so I'm struggling to understand why I can't find any good information on it. Following the pattern in http://cglab.ca/~abeinges/blah/too-many-lists/book/, I created a basic data structure with `Box`es and `Option`s, and am writing the `pub fn insert(&amp;mut self, value: T)` method, and I just can't make it work. I'd like it to be iterative. Playground: https://is.gd/sDxD8f. I happened to come up with a similar data structure and method as this SE post, https://codereview.stackexchange.com/questions/133209/binary-tree-implementation-in-rust. And it looks like their regular `locate` method which looks like mine works fine. But their `locate_mut` is completely different and I don't understand why at all. I first don't understand the error message in my example, what is `target.0`? It's not a tuple. Second, why does he have to match against `{anchor}`? What's the point of creating a new scope like that? I don't even know if this is idiomatic code, for some reason it's incredibly hard to find examples of data structures in Rust (compare with searching "binary search tree in Haskell"), and all the examples I find are either in full libraries with a lot of extraneous code making it difficult to understand what's important, or in random StackExchange questions/gists. In all cases they do some weird black magic that is not covered anywhere in the Book at all, or they're recursive (I'd rather not run the risk of blowing the stack), or both. I'm just incredibly frustrated, I feel like I missed some sort of tutorial that explains everything. Everything in the book about references and ownership and mutability makes sense to me. Finally some miscellaneous questions about the language. 1. I'm finding it incredibly difficult to know what type a variable is. If I do `Some(ref node) = Link` for example, how am I supposed to interpret x? Is it a reference? Isn't it weird that in this block of code, node is a reference, whereas maybe before node would refer to an actual Node? 2. Similarly, the syntax `fn (&amp;self)` makes no sense to me. If "self" is a reference and not the actual object, what's the purpose of the first &amp;? Is it just an annotation? Isn't it confusing that the same word, "self", is sometimes a object, sometimes a reference, sometimes a mutable reference? If I see `&amp;node` I have no idea what it's referring to without inspecting the code around it, since I don't know if came from a `Some(ref node)` maybe, then it would be a reference to a reference even though it looks like a reference to a struct. 3. What does the wording "moved out of" mean? The compiler doesn't tell me what is moving and where it was moved out of. 4. I feel like sometimes I'm not handling the Box code myself but the code still works. Does the compiler automatically take the object out of the box for me sometimes? In what ways is using a Box similar to using &amp;? It seems that *box refers to what's inside it... Thanks for reading. Another request, if there are any more tutorials like http://cglab.ca/~abeinges/blah/too-many-lists/book/, I'd be interested.
He acknowledged that &gt; demo has self-signed cert.
https://tools.ietf.org/html/rfc7858 I don't know the answer to OSes and or servers at this point. But I do know of at least one server and client at this point ;)
I'm trying to figure out exactly why i can be moved into threads multiple times: use std::thread; static NTHREADS: i32 = 10; // This is the `main` thread fn main() { // Make a vector to hold the children which are spawned. let mut children = vec![]; for i in 0..NTHREADS { // Spin up another thread children.push(thread::spawn(move || { println!("this is thread number {}", i) })); } for child in children { // Wait for the thread to finish. Returns a result. let _ = child.join(); } }
`NTHREADS` is an `i32`, which is a `Copy` type. When you take ownership of a `Copy` type, like you do with the reference to `i` in the line `println!("this is thread number {}", i)`, it performs a copy and not a move.
Here's a suggestion: write a frontend for [mpd](https://en.wikipedia.org/wiki/Music_Player_Daemon). Mpd keeps running in the background (in my case, with a systemd user service, but there are other setups that don't involve systemd), and you open the frontend only to control it, like changing the playlist.
The meme is in getting _other_ people to try to rewrite their program in Rust, not in actually going out and writing the code yourself. The author even gave a rationale for why Rust over a Bash script in a comment on this page.
I suspect that your question is disingenuous, but I'll answer anyway for the benefit of the thread: the reason I said what I said (which wasn't, if you read carefully, "telling you what to do") is this: I'm invested in Rust, and by extension, the Rust community. I want it to be a welcoming and positive place because I believe that leads to a greater number of contributions to the ecosystem. Perhaps more importantly, I also have a simple preference for taking part in communities that aren't pointlessly vicious. That's why I'll try to politely point out when people are being unnecessarily rude or otherwise spoiling the atmosphere. The Rust community is quite positive and welcoming in general, though it's not perfect. It can only get better through a concerted effort to steer the conversation towards constructive discourse and away from content-free, mean-spirited and unhelpful comments.
&gt; in a comment on this page For the lazy: https://www.reddit.com/r/rust/comments/6komft/ghcl_github_clone_automatically_fork_clone_and/djnucz6/ &gt; `ghcl` has good argument parsing with `clap`, good config handling with `yaml` and `app_dir`, good error handling with `error_chain`, and cross platform support. Those are all hard to to do with a shell script.
What community isn't positive and welcoming?
`println` may be thread-safe, but it isn't [async-signal-safe](http://man7.org/linux/man-pages/man7/signal-safety.7.html). When a signal occurs, there is no context-switching like you get when switching between threads; your signal handler will run on whataver thread the signal was delivered to. So if SIG_INT is received inside your `println!("Hello")` at a point where it has a mutable borrow active, that *same borrow* will be active when your signal handler calls `println`. A similar problem occurs with functions that use locks or mutexes; if a lock is held by a function, and the signal handler calls that function, it may try to acquire that lock *in the same thread*, and hang. Generally, all you should be doing in a signal handler is setting a flag (or writing a single byte to a pipe -- look up the "self-pipe trick") that can be detected and handled by your main program.
[removed]
If you liked Winamp 2 then check out Audacious with the classic skin. My favourite music player on all operating systems by an absolute mile.
If I were to work on a music player, I'd likely use it as an excuse to push development of pure-rust audio and gui tools. I'd probably use the following: - [cpal](https://crates.io/crates/cpal) for simple cross-platform audio I/O - [audrey](https://github.com/RustAudio/audrey) for audio format decoding/encoding - [sample](https://github.com/RustAudio/sample) for any processing that might be required - [m3u](https://github.com/mitchmindtree/m3u) for handling new and existing playlists - [conrod](https://github.com/PistonDevelopers/conrod) for GUI This would require a lot of upstream work though, so probably not advised if you want to get something going very quickly!
The job posting page was updated: https://jobs.lever.co/buoyant &gt; Remote applicants: we're open to remote work for this position if you have a history of remote work. Remote applicants in the US only please (for now!).
I haven't read the second edition of the rust book yet, but I had a quick look at the error handling chapter and I think the one from the first edition was more exhaustive. I recommanded people to read this error handling chapter from the first edition of the book for this reason.
Even after accepting the bad cert, I just have s blank page. Using Firefox mobile under android.
&gt; Audacious Also note that it runs on Windows and Linux, and is currently using 12 megs of RAM, which is mostly in visual plugins. It's a good player.
Interesting, what's the difference between recursion and co-recursion?
Agree. Distributing any script is a pain, but still, Rust is overkill for this.
&gt; a modern, good-looking UI/UX It's just buzzwords. If you need a native-looking GUI - stick with Qt (garbage on macos). If you want a completely custom UI - also Qt or even QML. But QML is memory heavy. Or even Electron (lol). &gt; rip your CDs Just use Flacon. No need to create yet another combine. &gt;any language I want for the backend. What kind of backend do you need? Everything are already implemented and there is no need to rewriting it to Rust (maybe except taglib).
 use std::io; fn main() { loop { let mut f = String::new();//figure out why this needs to be in loop io::stdin().read_line(&amp;mut f) .expect("failed to read line"); let f: u32 = match f.trim().parse() { Ok(val) =&gt; val, Err(ff) =&gt; { println!("{}", ff); continue; } }; println!("{}", f); } } When I put "let mut f = String::new()" before the loop, I get a "invalid digit found in string" error after the first iteration(assuming a number is input). Why do I need to assign a new empty string each time? I've tried changing "let f: u32" to "let mut f: u32", but no difference.
Right, seems to work only in Chrome.
Hmm, makes sense, do I need to only use Rc when there is mutation involved?
interesting! I take it for your OS you use it for assembly stuff?
Yes. The halting problem may be undecidable in the general case, but it should be fairly simple to see that an loop has no paths that exit the loop. Same as this case. Iter::cycle() will *always* be infinite, Iter::take() will *always* be finite, Iter::take_while() may be infinite or finite. Just because you can't prove it 100% of the time doesn't mean you can't prove it 70% of the time.
`Box&lt;Error&gt;` is probably the most useless error I can imagine. It has performance cost and all it can do is print a message. Could be `String` as well.
It actually has support for a form of middleware, look into fairings.
Well, it would be `Arc&lt;T&gt;` instead of `Rc&lt;T&gt;`, because `Rc` isn't safe to share between threads (it uses a non-atomic ref count), and you would need it if you were *sharing a reference* across threads instead of *transferring ownership*. If there was mutation involved, I think you'd need something like `Arc&lt;Mutex&lt;T&gt;&gt;` (if it was single-threaded and you needed a shared mutable reference, it would be `Rc&lt;RefCell&lt;T&gt;&gt;`).
&gt; As long as you don't use Rc&lt;T&gt; or Arc&lt;T&gt; to create a reference cycle, Can you actually create a reference cycle with Rc alone? I was trying to create a cycle to make sure it wouldn't happen in the wild and I came to the conclusion that reference cycles are impossible without a RefCell as well.
I was trying to optimize for conciseness and intuitiveness, so I limited my type signatures to the simplest indispensible components with names that can be easily guessed to mean "reference-counted".
What's the performance difference between a Mutex and a Channel? And would it be more efficient in your piston example to always keep the 2nd thread running instead of spinning up a new thread every 300th frame? Excellent article by the way!
&gt; Just because you can't prove it 100% of the time doesn't mean you can't prove it 70% of the time. How does this help in a statically-typed language where you either require a trait, or don't?
From [the `read_line` docs](https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_line): &gt; Read all bytes until a newline (the 0xA byte) is reached, and ***append*** them to the provided buffer. (emphasis mine) &gt; Why do I need to assign a new empty string each time? Calling [`clear`](https://doc.rust-lang.org/std/string/struct.String.html#method.clear) is probably more idiomatic.
That kind of thing would require a fundamentally global analysis. Neither of HKT and specialization involves a global analysis, so this wouldn't work.
At least chrome allows you to proceed even though the cert is bad.
&gt; We navigated some difficult and long-overdue discussions about moderation, the CoC, and related topics. While we have more work to do here, we managed to tease out some of the core problems that need to be solved, and now have a good foundation for ongoing discussion. Hats off to the moderation team, in particular, both for the care they've taken in the past, and their listening ear during the discussion. What were the problems here? This was very vague.
I started to use it and I had some difficulties on Mac OS X using it. It appears the developer is primarily on Linux so sometimes there are some bugs from that. It works well after the bug was fixed however. I'm planning to use it to write a modtracker (from the amiga) player, but we'll see how that goes. The guy who wrote it is pretty prolific, and it looks like he's using rodio and cpal (which he wrote) and others to write his own game. https://crates.io/users/tomaka?sort=downloads https://twitter.com/tomaka17/status/870371128048590852
I am await a bunch of new RFCs. :)
From what I understand, HKT would allow writing a type for which user decides whether it should use `Rc` or `Arc`. Instead of explicitly deciding, he could let compiler decide for him. If compiler can prove that `MyStruct&lt;T&gt;` is `Send` for given `T` why it should be unable to choose the right `T`?
You can definitely make a type which either has Rc or Arc, but I don't think Rust will ever add implicit switching between them. Part of the nicenss in rust is that _you know what things cost_. If this was added, a small inadvertent Send bound on something in one location in the codebase could potentially reduce performance throughout the entire program which uses a shared type without any indication why it chose Arc rather than Rc.
It does if you have a type that's `Send` and automatically becomes `!Send`, but if you have a type that's `!Send` but becomes `Send` when explicitly annotated `Mrc + Send` you're propagating those constraints anyway.
Perhaps it's because of: https://bugzilla.mozilla.org/show_bug.cgi?id=1187666 So a walkaround is to go to: https://85.255.1.138:8002 (websocket address) to allow adding exception in Firefox. After that everything should work (at least works for me in Firefox) BTW: It's designed for bigger screen than mobile.. so I'd expect bad rendering on small screens ;)
I will sound like an elitist bastard, but in addition to all the great things people already said, part of Rust's appeal to me is its compiler's unwillingness to accept quick'n'dirty hacks. I know libraries I import in my project have been thought out by competent people, not haphazardly thrown out together from StackOverflow snippets.
This. I haven't looked at `mpd`'s protocol at all; but I was thinking about this a few weeks ago and thought that writing new `mpd` compatible frontends (one or more of basic CLI, curses-like CLI, Web UI or GUI) first, then a new backend in Rust would be a great way to leverage the existing code while development of all the different libraries happened. It would also allow those that really like one of the current `mpd` frontends to switch to a safer pure-Rust backend once that was achieved. From what I saw when I was looking into this the libraries for actual audio processing are really not there yet in Rust (or if they are they're hard to find). I was able to [throw together a hacky player](https://github.com/Nemo157/bcc-rs), but it's just using unsafe wrappers of C libraries (I say unsafe because I encountered segfaults while using this client despite not writing any unsafe code, never bothered tracking down why since this was a quick half hour hack).
In go when sender side of channel explicitly closed, receiver receives error 
&gt; We laid out an actionable plan for advertising our success stories, including a specific direction for whitepapers and our blog. Thanks, @carols10cents and @shepmaster, for helping us figure out how to make Rust "boring" in the way that companies want! Particularly excited about this. I've personally had a hard time selling Rust as a viable solution at work because of this. [Friends of Rust](https://www.rust-lang.org/friends.html) has been a great start, but there is more work we can do on this front to make it easier for us to convince tech leads that Rust is something they can bet confidently on.
Rocket has recently added unreleased support for middleware, it calls them Fairings. There's an example here: https://github.com/SergioBenitez/Rocket/blob/master/examples/fairings/src/main.rs They'll likely ship in 0.3 and will likely be used to implement CORS and related functionality: https://github.com/SergioBenitez/Rocket/issues/25 There are more professional web-developers than me in this forum, if you could enumerate the things you want middleware for (CORS, logging, auth), others may be able to suggest idiomatic solutions to the particular needs you have using the existing tools. 
So still not good for me. Too bad. :) Thanks for the info!
&gt; Fairings that's not middleware, it's just similar to it. Can I create my own, custom middleware of any kind I wish? No. Whereas in Iron I can.
Imma gonna stop you right there, dive straight into bikeshed mode, and demand it'd be called `Mc` because of all the potential names (e.g. `Vec&lt;Mc&lt;VecFace&gt;&gt;`)!
Farings aren't full-fledged middleware that Iron has. Middleware in Iron is more powerfull. 
Yep. But if you have multiple senders, which one closes the channel? The common pattern is to use a WaitGroup and have a separate goroutine close the channel once all senders have finished. It's a lot of extra manual bookkeeping/boilerplate that you just don't have to do in Rust. 
Perhaps you meant /r/playrust?
Middleware is a way of implementing features, not a feature itself, and consequently so long as you refuse to say what extra features you want on top of pure REST (CORS, CSP, JWT, validation, logging, etc.) no-one can help you. What perplexes me is that If middleware was what you needed, and you knew Rocket did not support it, why in your original post did you ask for a &gt; REST API web framework which I can use together with Iron or **Rocket**. Anyway, I wish you luck in your project, but this discussion is too vague and peculiar for me to continue with it. 
You really only need assembly to perform initialization on-boot. Check out /u/phil-opp's excellent [Writing an OS in Rust](https://os.phil-opp.com/) series. I can't really think of specific examples for other unsafe stuff. 
Oh lol my bad mate ! will remove this post
I am positively stunned at the amount of items mentioned in this list, any two or three sound like a huge leap forward already, but all of them? It's sounds like Christmas before Christmas. I am really looking forward to the upcoming RFCs.
I can't really get why I get error with this piece of code. #[macro_use(bson, doc)] extern crate bson; extern crate mongodb; use mongodb::{Client, ThreadedClient}; use mongodb::db::{ThreadedDatabase}; use mongodb::coll::Collection; fn db_users() -&gt; Collection { let client = Client::connect("localhost", 27017) .expect("Failed to initialize client."); client.db("test").collection("users") } fn db_users_find_by_username(searchterm: &amp;str) -&gt; Option&lt;Vec&lt;&amp;str&gt;&gt; { let cursor = db_users().find(Some(doc!{"username" =&gt; searchterm }), None).unwrap(); let mut users: Vec&lt;&amp;str&gt; = vec![]; for result in cursor { let item = result.unwrap(); let value = item.get_str("username").unwrap(); users.push(value); // this isn't working: "`item` does not live long enough" //commenting out the line above will result in a successful compilation //println!("{}",value); // this is fine however } if users.len() == 0 { None } else { Some(users) } } fn main() { if let Some(somevec) = db_users_find_by_username("somebody") { println!("{:?}", somevec); } else { println!("no success :(") } } I get the following error with this code. error[E0597]: `item` does not live long enough --&gt; src/main.rs:22:21 | 22 | let value = item.get_str("username").unwrap(); | ^^^^ does not live long enough ... 26 | } | - borrowed value only lives until here | note: borrowed value must be valid for the anonymous lifetime #1 defined on the function body at 16:1... --&gt; src/main.rs:16:1 | 16 | / fn db_users_find_by_username(searchterm: &amp;str) -&gt; Option&lt;Vec&lt;&amp;str&gt;&gt; { 17 | | let cursor = db_users().find(Some(doc!{"username" =&gt; searchterm }), None).unwrap(); 18 | | let mut users: Vec&lt;&amp;str&gt; = vec![]; 19 | | ... | 27 | | if users.len() == 0 { None } else { Some(users) } 28 | | } | |_^ error: aborting due to previous error(s) Can someone explain why is it happening and how to solve this? I experimented with simpler types, and it worked as expected.
That bringing a type called `A` into scope would change the meaning of this drastically is undesirable. Not _necessarily_ a blocker, but definitely undesirable.
 type A = (); impl Struct&lt;A&gt; {} What does it mean? **Edit**: Ok, now, consider the following: use some_lib::prelude::*; // 500 lines of code impl Struct&lt;A&gt; {} What does *that* mean?
Ion is fantastic right now for me as a fish replacement (noticeably faster, and the interface _feels_ better, I can't describe it). Adding Ctrl^C made me switch to it for a lot of things. Good work man
Check out Let's Encrypt for free SSL certs. If you can Rust, this will be the easiest part. Kudos on taking the plunge!
For context, https://www.oreilly.com/ideas/were-reinventing-too Oreilly has stopped all retail sales on their website, which means no more DRM-free epub/mobi/pdf and no more print book to ebook upgrades. All books previously purchased are still available in your account for download and will still be updated as edits come in.
First of all if you want to have a good user experience on different operating systems, stay away from GTK+. If you want to have very stylish user interface QT is very hard to use (it has it is own system). And when it comes to rust you can easily use builtin widgets with gtk but you can make your own gobject classes (it wasn't possible last time I checked). Same for qt, your rust code will be full of workarounds and hacks. I make a prototype music player before. The only option for now you have to use every platform's native GUI library (linux, gtk?) Actually I would say C# (yes csharp) is like the only option. Since its native for windows gui, and it has excellent(seriously !!!!!!!) macOS cocoa bindings. Umm and gtk2 for linux (which sucks with HiDPI). You can create a core library which handles all your business logic about playlists, fetching album covers etc. And then you can create native projects in c# again for each platform and code/design the UI from scratch. If you want to check, I have an old version in github (https://github.com/umurgdk/xplayer), but it's slightly different then your idea. I was doing streaming player to combine all the streaming services (supports spotify, soundcloud, youtube). If you want GUI not TUI I would stick with one platform in the beginning or use something like conrod (might be a terrible solution) 
&gt; Part of the nicenss in rust is that you know what things cost. If this was added, a small inadvertent Send bound on something in one location in the codebase could potentially reduce performance throughout the entire program You could solve this with a pattern of using `Rc` whenever possible and `Mrc` where expressly needed (near-deprecating `Arc` in its current form). That way the only unforeseen change is from `Mrc` to the more efficient `Rc`. You might even want to add a special lint that warns on such changes, so that folks can see where an explicit `Rc` might give better performance guarantees.
[removed]
Yeah that is what i was talking about, thanks for the clarification
I don't know the answer, but hop on Diesel's Gitter. You'll certainly get the answer you need there
nit: `cycle()` is empty (finite) if its input is empty. `repeat()` is a better always-infinite example, but even that may not hold for abnormal conditions, like a panic in `clone()`.
Yep! `Box&lt;Error&gt;` is the easiest, but not the most useful. I prefer `error-chain` even on small projects, but there's a bit of boilerplate to add.
That solves it, thanks! Though, IMHO, this is not an elegant solution...
I'm hoping that some of the work in the tooling in the next few months will help with [this rustup bug](https://github.com/rust-lang-nursery/rustup.rs/issues/932). It's currently a blocker for my Haskell/Rust FFI library and it seems weird that using the preferred way to install Rust makes it next to impossible to use shared object files. I know it's not an easy thing to fix, but I do hope that the tooling team looks into this going forward as it's caused problems for [RLS as well](https://github.com/rust-lang-nursery/rustup.rs/issues/765)
I finally managed to implement STUN (RFC 3489) using tokio (https://github.com/manuels/stun3489/). It was pretty hard to manage tokio and sometimes it felt like applied Category Theory.
I don't think that's a good idea. The meaning of impl Struct&lt;A&gt; {} would change depending of an actual type `A` being in scope or not. That's why you explicitly need to list type parameters. Note that multiple `impl` blocks with differing bounds or concrete types on `A` are legal and even good style.
I haven't used Diesel yet but going by [this page](http://siciarz.net/24-days-rust-diesel/) there seems to be an API for partial selection: let users_with_cat_photos: Vec&lt;String&gt; = users::table.select(users::username) .inner_join(photos::table) .filter(photos::url.like("%cat%")) .group_by(users::id) .load(&amp;conn) .expect("Error loading users"); println!("{:?}", users_with_cat_photos); You could also just immediately destructure the row struct, keeping only the columns you want.
That's not the kind of global analysis I mean, for this to work you'd need some mechanism that takes function bodies into account in a global analysis.
&gt; If compiler can prove that MyStruct&lt;T&gt; is Send for given T why it should be unable to choose the right T? You're describing global inference here. Well, not even that, something more complicated; because it's backtracking from trait impls. The compiler _could_ figure this stuff out. It would be expensive, and it would not be a result of just adding HKT and specialization. In fact, specialization wouldn't play a role at all. What you describe is a wholly new feature. In general Rust has tried to stick to local analyses, with such constraints wholly specified at function boundaries, so this is unlikely to happen. Especially since it's whole program analysis, not even just restricted to the crate. Rust lets you pick Rc and go and fix the compile errors by swapping it for Arc, which already fills this niche pretty well. 
Discussions of moderation often involve discussions of specific incidents, so this is deliberate.
What exactly do you mean by "simpler types"? I am guessing they were copyable types, like `i32`. Strings are not implicitly copyable because they refer to allocated memory on the heap. The `get_str` function returns a borrowed `str` whose lifetime depends on `item` itself, which only lives for one iteration of the loop. So you're trying to return a vector of references to strings that have been long since deallocated! What you need to do is return a vector of *owned* strings, that is `Vec&lt;String&gt;`, and explicitly clone them when inserting: `users.push(value.clone())`.
I appreciate that the moderation team keeps such information private, both for reasons of the privacy of individuals involved, and because public discussion of moderation decisions almost always causes more problems than it solves. However, I'm wondering if it might be good for the moderation team to start keeping and releasing some anonymous statistics on moderation actions on a quarterly or annual basis, to give some indication of how often the code of conduct is being enforced, and what that enforcement primarily consists of. I feel like a lot of people have questions about whether the CoC and moderation in the community is excessively oppressive. I don't think that it is, but that sentiment comes up on occasion, and it might help to dispel people's worries if they could see how often it actually comes up in practice. For instance, if on some regular basis, you posted statistics about: how often moderation issues came up due to different categories of behavior mentioned in the CoC (making people feel unwelcome based on various personal attributes, sexual or unwelcoming nicknames, meanness/rudeness, public insulting, demeaning, or harassing, private insulting, demeaning, or harassing, spamming, trolling, flaming, etc), and also on what form the moderation took based on the moderation policy (private warning, temporary exclusion, permanent exclusion, disputed moderation action), that might help alleviate some people's concern about overreach of moderation, or some peoples concern that moderation may not be happening enough (I know that there were concerns about this in the past). The simplest would just be to count up numbers based on which part of the CoC was violated, and separately count up moderation enforcement actions. Some more information could be given by also including cross-tabs; for each part of the CoC, what types of moderation action occurred. Of course, for privacy reasons, you might want to break down statistics into groups like "0", "1-5", "6-20", "21-100" instead of exact numbers, or avoid including cross-tabs for groups which are too small (fewer than 5 incidents, say). I think that releasing these kinds of stats would help provide a little more transparency about the moderation team, without breaching anyone's privacy. Of course, if all of these numbers are too small to bother with other than excluding spammers, say (like, 5 or fewer incidents in a year or quarter that were not spam related), then just reporting that would also be interesting information.
We used to do this. The fact of the matter is that there are very few actual such "incidents" per year, so posting any detaitls would be deanonymizing. Aside from spammers and randos who just pop up and scream a lot (which we just ban). However, this was one of the things that we did discuss, and we do wish to do this better.
Pulling my hair out here. I'm trying to connect my laptop to my desktop over a tcp socket. Extremely simple stuff, no tokio, just std tcp stuff. Server, running on desktop. Its IP on the local network is 168.192.1.42 fn main() { let listener = TcpListener::bind("127.0.0.1:34254").unwrap(); println!("listening..."); for stream in listener.incoming() { match stream { Ok(stream) =&gt; { println!("connected client."); }, Err(e) =&gt; { println!("connection failed: {}", e); }, } } } The laptop is the client trying to connect, it is also on the local network, its ip is 168.192.1.106 fn main() { let mut stream = TcpStream::connect("168.192.1.42:34254").unwrap(); println!("connected"); } Now I run the server, it waits for connections, I run the client but it never connects. I run WireShark on desktop and laptop to inspect the traffic. The Desktop Server filters on `ip.addr == 168.192.1.106` to see laptop traffic and the laptop filters on `ip.addr == 168.192.1.42` to see desktop traffic. On the laptop client's WireShark I see the client is sending SYN, never getting a response, retransmitting SYN 2 times and then it returns an error which unwrap displays on screen. On the desktop servers' WireShark shows nothing, no connections. This is a stupid simple home network, the router modem is running stupid standard firmware that came with the device. It's all stupid simple default stuff. :pulls hair out:
[removed]
Yeah, I hear that. Even just a regular "there were over 20 spam and blatant trolling incidents causing instant ban, and 1-5 incidents of any other type, of which all resulted in only a private warning" or something of the sort would probably help out a little bit. But yes, I do understand the concern if there are too few incidents for statistics to be meaningful without de-anonymizing.
If you `bind` to `127.0.0.1`, the server will only ever accept loopback connections. You'll either have to bind to the IP that the interface connected to the laptop has, or `0.0.0.0` to bind to all interfaces.
I have one line of unsafe in [optional](https://github.com/llogiq/optional) (to create a slice of one element) and one in [bytecount](https://github.com/llogiq/bytecount) (transmute `&amp;[u8]` into SIMD)
&gt; Calling clear is probably more idiomatic. And conceptually more efficient, since the existing allocated capacity is reused.
You'll likely get a more timely answer to these sorts of questions in [our gitter room](https://gitter.im/diesel-rs/diesel) &gt; Partial selection . Selecting only the columns of interest and having that deserialise into a lighter-weight struct. Call [`.select`](http://docs.diesel.rs/diesel/prelude/trait.SelectDsl.html#tymethod.select). As you mentioned, you'll want to have a new struct for that purpose (or deserialize into a tuple). Keep in mind that if you ever do just have a one-off case, you can define a struct inside the body of a function. &gt; Retrieving a subset of information after insert (say the optimistic locking identity - id &amp; modified_time) rather than the entire entity which could be much more expensive. Call [`.returning`](http://docs.diesel.rs/diesel/query_builder/insert_statement/struct.InsertStatement.html#method.returning). It behaves identically to `.select`, but maps to a SQL returning clause. (I'm assuming you're using PG which is the only backend that Diesel has a driver for which supports a returning clause) &gt; Aggregated or denormalised selection, let's say a join to get a count of comments - this would obviously require some way to express a more complex select clause for a query, examples seem to show some support for more complex where clauses (though not anything particularly exotic. See the [`associations` module](http://docs.diesel.rs/diesel/associations/index.html) for details about defining associations between tables, which allows you to call the [join methods](http://docs.diesel.rs/diesel/prelude/trait.JoinDsl.html). &gt; In the absence of these capabilities what is the recommendation for now? Fall back to direct SQL and hand-written deserialisation against the connection - that is, avoid Diesel entirely for these cases? If you ever need to do something that isn't supported by our query builder, you can always fall back to raw SQL and continue to use Diesel for deserialization by using the [`sql` function](http://docs.diesel.rs/diesel/expression/dsl/fn.sql.html)
There is a nice crate to make signal handling more Rustic: [chan-signal](https://crates.io/crates/chan-signal)
Thanks! I changed the server's address it binds to to `0.0.0.0:34254` Now after running the server, windows firewall popped up. I allowed the program to connect on the home network (and entered the admin password while doing so). Then I ran the client again and it still times out, I can see the SYNs and its retransmissions, but the server doesn't get anything... I'll try to see if I didn't fuck up any firewall related stuff. EDIT: Just not working :/ Server doesn't get any incoming connections.
Uh... by using a trait?
Specialization as in: a form of inheritance?
No, [specialization](https://github.com/rust-lang/rust/issues/31844), a way of "specializing" trait implementations.
Specialization means that you can implement a trait for a generic type *and* for a more concrete type, giving a more efficient (but hopefully semantically identical) implementation. An example is `ToString` (providing the `to_string` method), which is implemented for all types that have `Display` implemented. The default implementation goes through what `format!()` does, while `str` and `String` have it specialized to just return a copy of themselves. 
Concerning Windows and its firewall, I can't really help. Can you still connect from a local client?
Running the client and server on the same machine works flawless as expected. A friend is trying to help me out, running the exact same code on his desktop&amp; laptop. Same issue, the client cannot connect to the server at all and just times out.
Not really. Specialization means you can implement the same trait twice for the same type, as long as one of the implementations is more specific so the compiler can disambiguate (e.g. one is a blanket impl and another is specific to that type). This can play a part in implementing some form of inheritance, but it's not enough on its own and it's useful for plenty of other things.
To me it seems this is more a "how do I structure my program" question than a "how can I make this work" question. &gt;If the user types search other song + play, I want to be able to say, "OK, user wants to play a different song - suspend/exit the continuous playback thread". Why do you want to exit that thread? Why not execute cmd in a different thread and connect it with the input thread via channels. In the cmd thread you have a loop which checks the channel for input and executes the commands if there are any. 
Hi Morris. Performance is a tricky beast to reason about, especially when you're looking at multiple threads, CPU caches, etc. It will usually come down to what you're doing with them. I think if performance is important, implement your algorithm with both and benchmark to see which is faster for your particular problem with real data. Regarding spinning up a new thread every time, yes it would be much more efficient to keep the second thread around and reuse it. Unfortunately, it also would have added more complexity to the demo, so I opted for simplicity over performance.
Any details on the `no_std` stuff?
So first let's start with the lifetime annotations of the given code example. It's unlikely that you want to associate the lifetimes of `F: Fn(&amp;A, &amp;B) -&gt; C` to the function `zip_with`. _Especially_ if you don't want the lifetimes from the parameters of `zip_with` to be associated with the output. In this particular case, the lifetimes parameters of `F` are certainly associated to the lifetimes of `zip_with`, but let's ignore this for now since you seem to be interested in cases where this is not true. So let's start off with deleting _all_ the lifetime annotations in your codebase, and explain what's going on. (Also, we are going to remove the reference in front of the closure, because that's definitely not what you want here). The issue you get is a strange type mismatch resolving `for&lt;'r, 'r&gt; &lt;[closure@&lt;anon&gt;:41:28: 41:42] as std::ops::FnOnce&lt;(&amp;'r usize, &amp;'r usize)&gt;&gt;::Output == _` The `_` part means that rustc wasn't yet able to figure the type, of what appears to be the output of the given closure. Which is strange, since if you annotate the closure like `|&amp;x, &amp;y| -&gt; usize { x + y }` it still argues about something or the other. I'll be honest, it's not clear why this is, but seems to be a type inference issue more than anything else. One fix is to give type annotations in the closure like so: let e = a.zip_with(&amp;b, |&amp;x: &amp;_, &amp;y: &amp;_| x + y); A link to this example, with all the lifetime annotations removed and this fix, is here: https://is.gd/k56bKs. So the next question might be how does the elision work here. You seem to have a good understanding of the `fn foo(&amp;'s self, other: &amp;'s thing) -&gt; Out&lt;'s&gt;` elision. By default, yes, it's like an accessor and ties the lifetime of the output to the lifetime of the input, requiring `Out` to live no longer than shortest lived thing from the inputs. As for the function itself `Fn(&amp;A, &amp;B) -&gt; C`. This get's elided to `for&lt;'a&gt; Fn(&amp;'a A, &amp;'a B) -&gt; C`. The difference between the two are this: 1. From your example, an explicit `F: Fn(&amp;'a A, &amp;'b B) - &gt; C`. This will require that the inputs to `F` must live at least as long as `'a` and `'b`. This can be restricting in some scenarios. For once, if you are _returning_ `F` this may not even make sense. You are giving someone a function, and this function only takes parameters that life at least as long as this thing that was called ages ago? That's a brutal restriction. However another big restriction here is that inside `zip_with`, if you construct a reference you wouldn't be allowed to use this to call `F` since the newly created reference couldn't possibly live longer than `'a` and `'b` (which contain the function scope). For instance, this would not work: fn zip_with(&amp;'a self, b: &amp;'b B, f: F) -&gt; Vec&lt;C&gt; { let a = &amp;0usize; let c = f(a, a); // Error, a does not outlive `'a` or `'b` .... } 2. For the example `F: for&lt;'a&gt; Fn(&amp;'a A, &amp;'a B) -&gt; C`. This again says that `C` must outlive `'a`, just like before. But the difference here is that `'a` is determined _when F is called_. So the previous example is fine! You can call `c = f(a, a);` from a new created reference. What you won't be able to do is to use that `c` in the output (without cloning or something) since we now know that `c` does not outlive the parent zip_with lifetime. I like to think of these differences by understanding _when_ lifetimes are substituted into their bounds. Others like to think of it as a quantification saying something like `for&lt;'a&gt;` really means `for all 'a`. Eitherway, I'd recommend this stackoverflow answer to learn more about HRTB: https://stackoverflow.com/questions/35592750/how-does-for-syntax-differ-from-a-regular-lifetime-bound. If you'd really like to get into more details about this (though it's probably not completely necessary) you can read the _first half_ of this blog post (try to read between the lines of with old rust syntax): http://smallcultfollowing.com/babysteps/blog/2013/10/29/intermingled-parameter-lists/. I hope this clears up the lifetime questions you had a little bit at least. As for your question: **My intent is that no references escape, i.e. all return values are new stack values/new allocations owned by the output; ..**. The only way I know how to do this is to use `'static`. In this case you could write `C + 'static` for instance, but I'm not sure why you would want this restriction. Rustc will notice if it's static when the function is called. For instance, your example (or my example) try this: let e = a.zip_with(&amp;b, &amp;|&amp;x,&amp;y|x+y); std::mem::drop(a); std::mem::drop(b); println!("{:?}",e); You'll notice that this is not an error, because rust has figured out that the `e` doesn't contain an lifetime references to either `a` or `b`. Ok, and one last note. Associated types will restrict the types that can be used in an trait implementation. For example, implementing `ZipWith&lt;Other=Vec&lt;B&gt;&gt;` on `Vec&lt;C&gt;` limits the the use of `ZipWith` to only the scenario of another `Vec`. This is sometimes desirable, when you want to assert that there is a unique type parameter for a given triat implementation. But in this example, it appears that no such guarantee would be necessary, and that it should work for any two iterables.
&gt; We iterated through a half-dozen potential module system revamps, and by the end of the week finally landed on an idea we think satisfies all known constraints and will likely be palatable to new and old users alike. I admire this incredible optimism. Good luck!
Thank you so much! PoC is working now. By simpler types I meant Strings and &amp;str. I'm aware of the Copy-Types. Now I can continue my project :)
I probably shouldn't read Reddit while eating...
Well, I was thinking that there's no way to implement it more efficiently anyway. (BTW, do you know that `File::open()` allocates?) But potential inability to tell why performance reduced is really concerning.
Please be specific and don't just call it "boring". It's reliability and predictability that companies want. The keyword is *risk minimisation*.
 let guess = "42".parse::&lt;u32&gt;().expect("Not a number!"); let guess: u32 = "42".parse().expect("Not a number!"); What is the difference between these two? What is preferred? 
Hence the air quotes.
It says "WebSocket Protocol Error: Unable to parse WebSocket key." both in Firefox and Chromium.
Thanks for the detailed reply.. I wonder if in time there will be tools developed for greater visualisation of this sort of thing . I even wonder if we could give example code thats debugged the old fashioned way and have some tool guess annotations ('in this source, it seems to be used this way, so these annotations would guide similar use elsewhere..') &gt; but I'm not sure why you would want this restriction. Basically from years of C++ I have 2 simple cases in mind most of the time, i.e. what you can reason about fairly intuitively in a language lacking these annotations; - **'the accessor'** ( as we've covered above; I remember the discussion pre 1.0, i gather this was 85% of the cases or something..) - and the opposite extreme: **"no pointers for you to worry about .. only ones which RAII handles for you".** . I suppose another way to express that would be: '**if you can see a pointer.. you should worry about it** (e.g. a return value that is a reference, or 'pointer-to-pointer' output parameters),... **otherwise, a thoughtful programmer would not hide something dangerous inside the output**'. We might have had to intuitively guess which is which from context.. the ability to formally mark is certainly very welcome - I am definitely sold on the idea that 'the more information you can express formally, the better', because it's an unambiguous form of communication; The problem that we might be running into here is, however, that this communication is encoded in a way that is still quite hard to read and to write (but hopefully it will get easier/better over time.) I guess the lifetime annotations also give us the opportunity to handle more cases 'in the middle ground' safely, which will certainly be interesting. I see the cases like 'choosing between 2 inputs', etc. I suppose what I really have intuitively form C++ is a binary approximation('the lifetime is very long / the lifetime is very short, relative to what you're thinking about right now..'),- whereas in reality there is a sliding scale. &gt; let e = a.zip_with(&amp;b, |&amp;x: &amp;_, &amp;y: &amp;_| x + y); yes I was advised about this on the IRC channel aswell, and about the fact that 'it was an inference issue rather than a lifetime issue'; My preference would be to write more in declarations/definitions to make the user-side code simpler.. so in this specific example, even if it means peppering the def with lifetimes, to avoid that.. i'm happy to do so. R.e. the potential for 'hidden references' .. I suppose we would try to avoid this with 'visitor patterns' .. you send a function through a data structure to do modifications inplace/ doing some accumulation, and you get the result; whereas we might have a case like 'get a list of references to interesting nodes.' However in most of what I've done in the past, I would not want to perform allocations for temporaries. Allocations are usually infrequent, for long-lived data. 
&gt; Do you still see a use case for Python then? I've used it in science labs. PIs love it, partly because it's easy to pick up, but also because in science you need to get your results to run once, on your computer. I'd hate to be a library author for scientific python though. 
Thanks for your reply! I'm looking forward to your second article.
If you added Mrc at all though, I suspect it would be used in cases where Rc is more appropriate anyways. It would be just as fast, until it isn't. I think a better solution would be to add a lint to clippy or another project that could warn for places where you have an Arc but don't need Send. Keep in mind if you're doing global inference, this would include other projects - if a library includes Mrc, and it's used by a binary that forces it to be an Arc, who would get the 'Rc changed to Arc' warning? What if the binary always needs it as an Arc, and that warning would then just be a useless message output on every compile?
&gt; I wonder if in time there will be tools developed for greater visualisation of this sort of thing . I even wonder if we could give example code thats debugged the old fashioned way and have some tool guess annotations ('in this source, it seems to be used this way, so these annotations would guide similar use elsewhere..') Oh yeah. One such tool that I would love to have is a closure resolution. Something that would tell me exactly which kind of borrow each element was given, and the derived trait: `Fn`, `FnMut`, or `FnOnce`.
Every C and Go programmer could say what you just said and apply it to parametric polymorphism, which Rust has. "But how do you know it won't choose an inefficient &lt;T&gt; because of some function you called that operates on i64 when you only needed i8?"
Hey! Sorry for the late answer, $LIFE happened. Thanks for the very much appreciated suggestion. Seems like MPD is the way to go. What would you use to achieve a nice-looking GUI for Windows/Linux/macOS?
Wow, thank you so much for linking all that stuff. Looks incredible. To be honest, I'm still debating which way I'm gonna take to develop this, but I'm definitely not planning to get something up-and-running in a matter of days/weeks. I still appreciate your advice a lot. And yeah, I also think this would be a great opportunity to push audio-related stuff in pure Rust, everybody wins! :D
Thanks for your insight on rodio, mate. Much appreciated. Let me know how that modtracker you're planning to write goes :)
Yeah, I've been looking at it, seems like the _de facto_ option for music-related stuff. What I'm planning to do is to develop a good-looking, multi-platform music player that also lets you manage your music library in full.
Could you please explain, how implementation `Mrc` might look like?
Thank you for the excellent detail. I'll look into all of this (and the gitter room). I had issues trying to deserialise into struct that didn't include all columns - given you expect this to work, the issue must have been mine and not diesel. I'll give it another go and use the gitter room for assistance. Yes I'm using Postgres. While not all databases support the returning clause (and by not all, I mean most), many can return a generated identity (not enough for the optimistic locking though, if the differentiating column is filled db-server-side). I presume diesel will have to grow into supporting the nuances of different databases. 
TBH I'm not sure. I just intuitively felt it should be possible but didn't try to do it.
&gt; I had issues trying to deserialise into struct that didn't include all columns Right, the struct needs to include all of the columns that you select.
Hello! Sorry for the late answer, $LIFE happened. First of all, I tried Audacious and while it has some improvements over Rhythmbox, it's definitely not what I'm looking for. Thanks for mentioning it, tho. That said, a headless, MPD-based backend seems like the general consensus, as it's been mentioned several times on this thread and over /r/golang. The first approach you suggest seems pretty doable and interesting enough; from what I understand, the backend would be written in Rust (by me) and it'd have access to a PyQt-based frontend thanks to rust-cpython, right? &gt; Use PyQt's bindings to the QtMultimedia module and just let the OS's media framework handle format support. (eg. GStreamer on Linux) Could you please elaborate further on this one? re: nom (thanks for linking it; I wasn't aware of it); do you mean that, if I plan to write a GStreamer format plugin on pure Rust, should I use nom as a starting point? Thanks for the much detailed insight, mate. Really appreciated.
Definitely true, but it's at a different level. When calling a parametric function, everything that can change what T is is within that function itself - that's an acceptable amount of inference for my taste. It can be brought to a bigger scope by also having the calling function be parametric, but then it's explicitly widening it. With the proposed Mrc, something in a completely different crate with code that doesn't interact at all in the program, that just happens to be using the same struct with an Mrc inside it, could cause the other code to be less efficient.
&gt; Rust lets you pick Rc and go and fix the compile errors by swapping it for Arc, which already fills this niche pretty well. That's nice, but what's lacking is the round-trip. Is there a whole-program linter (you could call it a linker linter, haha) that warns you for choosing `Arc` where there is no `Sync`/`Send` constraint and `Rc` would do just as well?
Nope. In general Rust programs tend to be written with minimal cost first, adding costs as necessary, so generally you _want_ to start with Rc and add Arc only if necessary. Of course this doesn't cover the case when Arc was necessary but isn't anymore. Meh.
True. Sometimes you do need a guarantee that the efficient case will be used, which is a rationale for things like explicit tail calls (`become`) and explicit SIMD. But that's *all* you need. There's no sense in making a language (or an optimizer) dumber for "fear that users will come to rely on its smarts too much".
Wrong subreddit ;) 
&gt; it would be used in cases where Rc is more appropriate anyways. It would be just as fast, until it isn't. That's users going out of the way to shoot themselves in the foot. It's not something that a language can sensibly prevent.
It seems you're against the idea of writing a music player in pure Rust (something I don't plan to, btw; this thread's idea is to have a starting point for this, cherry-pick what already has been written and then implement it my way); sorry if I'm getting the wrong signal here but the way you express yourself feels like you're against this. That said… &gt; It's just buzzwords. Uhh, they're not. You could develop a fantastic backend for an application, but if it looks ugly and/or it's super complicated to use, you're in for a treat. &gt; If you need a native-looking GUI - stick with Qt (garbage on macos). If you want a completely custom UI - also Qt or even QML. But QML is memory heavy. Or even Electron (lol). See? That's the problem. I don't want to write something that will look great on some OSes and garbage in others. That's not the point. Neither is something memory-heavy —something which it's not really a big deal since most modern PCs/laptops have at least 8GB RAM, but it's still a concern, nonetheless. &gt; Just use Flacon. No need to create yet another combine. Who said something about writing a CD ripper? I don't plan to do so if something's already out there and I can plug it into my application. And if that were the case, why do I need to install several applications to get things done when I could have it all in one place? &gt; What kind of backend do you need? Everything are already implemented and there is no need to rewriting it to Rust (maybe except taglib). As I stated before: who said something about rewriting stuff in Rust? I don't plan to do so unless necessary. I'm looking for what's already implemented (like MPD, libvlc, Qt, etc), see if it has bindings for Rust and do whatever's needed to develop this idea.
They would be going out of their way, but not that much I don't think. If there was a type named literally "magic rc" which was "as efficient as you need it to be", would a new user of rust have any reason _not_ to grab it for every use case?
I need to do more naked programming myself. Count me in!
Hi! Yeah, I know GTK looks like garbage outside of Linux, I thought about Qt because of how it looks with Telegram Desktop but I'm taking your advice on it. &gt; I make a prototype music player before. The only option for now you have to use every platform's native GUI library (linux, gtk?) Actually I would say C# (yes csharp) is like the only option. Since its native for windows gui, and it has excellent(seriously !!!!!!!) macOS cocoa bindings. Gotta be honest here: I was completely unaware of this. I learned C# at university but forgot most of it; seems like I'll be retaking it if this is the case. Thank you for bringing this up. &gt; You can create a core library which handles all your business logic about playlists, fetching album covers etc. And then you can create native projects in c# again for each platform and code/design the UI from scratch. From what I understand, you're suggesting I should write the backend on Rust and implement the GUI from scratch with C#, am I right? Thank you very much for the insight, man. I really appreciate it. EDIT: I assume you mean these [bindings](https://github.com/mono/monomac), correct?
This is totally TWIR QotW material!
My bad 
Nah. A true "magic ref" would compile down to nothing in case of a tree-like ownership pattern, and compile up to full GC for potentially-cyclic portions of the reference graph. Then if "users grab the magic for every use case", you'd just end up with a plain-vanilla AOT garbage-collected language, like C#/Java.Next()/OCaml/Haskell/Go etc. But there's a reason efficiency-oriented languages have all sorts of special cases, and most users know how to use them!
hmm, i guess i would just install cantata on linux, and linux on windows/macOS
Not sure. It looks like GTK is becoming the preferred UI toolkit of Rust, specially since GNOME core devs are investing time into porting stuff to Rust. See [Rust and GNOME meeting notes](https://internals.rust-lang.org/t/rust-and-gnome-meeting-notes/4339) and [gnome-class: Integrating Rust and the GNOME object system](http://smallcultfollowing.com/babysteps/blog/2017/05/02/gnome-class-integrating-rust-and-the-gnome-object-system/). However, GTK doesn't have a cross-platform look and feel as good as Qt. And.. the state of Qt bindings don't seem to be awesome right now (I would be glad to be wrong on this). There are two qml bindings, [qml](https://github.com/White-Oak/qml-rust) and [qmlrs](https://github.com/cyndis/qmlrs). There's [rust-qt](https://github.com/rust-qt/cpp_to_rust) that binds directly to the C++ lib, and which looks a little better. Anyway, I would just use [gtk-rs](http://gtk-rs.org/) because it seems more feature complete. It's still not a stable library though.
Christmas in July...
Right now, `Arc` is being used when `Rc` is more appropriate (eg: in libraries that happen to be used in a single threaded case). The converse also happens: a library that uses `Rc` but then can't be used in some situations (this one bit me recently: ncollide uses `Rc` internally so it can't be used with specs) Fixing this through the ecosystem would require a lot of boilerplate. edit: an `Arc` that sometimes doesn't need synchronized access is just an optimization, like `Rc` that sometimes doesn't need to increment/decrement its counter. Rust programmers are used to have optimizations applied on a best effort basis.
Somewhat off-topic: What's the reason to use iTerm(2) vs plain Terminal? I find myself using the latter and I don't remember why I chose it, because I do remember having tried iTerm.
For example, because in iTerm2 you can cmd-click on filename to open in editor.
&gt; The first approach you suggest seems pretty doable and interesting enough; from what I understand, the backend would be written in Rust (by me) and it'd have access to a PyQt-based frontend thanks to rust-cpython, right? Yes. `rust-cpython` supports both embedding and extending, so you could have either Rust or Python sitting at the top of the call stack... though, I personally think it makes for a more pleasing architecture if the scripting language is at the top and glues together compiled modules which could theoretically be reused in other projects. (Especially when the scripting language is also the language with the Qt event loop bindings.) &gt;&gt; Use PyQt's bindings to the QtMultimedia module and just let the OS's media framework handle format support. (eg. GStreamer on Linux) &gt; Could you please elaborate further on this one? Qt contains high-level abstractions like [`QMediaPlayer`](https://doc.qt.io/qt-5/qmediaplayer.html) and [`QMediaPlaylist`](https://doc.qt.io/qt-5/qmediaplaylist.html), built around a platform-neutral "whatever the OS's native codec pipeline is" API wrapper. It's almost a ready-made "media player in a reusable library, just add UI" as-is. The main caveat is that, since it uses the OS's native media framework, it can't load GStreamer plugins when running on platforms with non-GStreamer media frameworks as the officially blessed option, like Windows, MacOS, and Android. (That's why I pointed out the alternative option of binding to GStreamer directly. I mentioned PyGST because I know that works in concert with PyQt and PySide and would still be able to load Rust-based GStreamer plugins, while I've never researched GStreamer bindings for Rust.) &gt; re: nom (thanks for linking it; I wasn't aware of it); do you mean that, if I plan to write a GStreamer format plugin on pure Rust, should I use nom as a starting point? Yes. Here's the series of blog posts I mentioned on the topic, which does exactly that for an FLV demuxer: [[1]](https://coaxion.net/blog/2016/05/writing-gstreamer-plugins-and-elements-in-rust/) [[2]](https://coaxion.net/blog/2016/09/writing-gstreamer-elements-in-rust-part-2-dont-panic-we-have-better-assertions-now-and-other-updates/) [[3]](https://coaxion.net/blog/2016/11/writing-gstreamer-elements-in-rust-part-3-parsing-data-from-untrusted-sources-like-its-2016/) [[4]](https://coaxion.net/blog/2017/03/writing-gstreamer-elements-in-rust-part-4-logging-cows-and-plugins/) There's also [this talk](https://www.youtube.com/watch?v=W_mnFFqpMpQ).
SECTION | CONTENT :--|:-- Title | Sebastian Dröge &amp; Luis de Bethencourt - GStreamer &amp; Rust – A perfect match Description | GStreamer is a highly versatile, cross-platform, plugin-based multimedia framework that caters to the whole range of multimedia needs. It can be used basically everywhere, from embedded devices like phones, TVs or drones to desktop applications or on huge server farms. In this talk we will discuss how Rust is the perfect match for GStreamer to evolve from its C roots and safely enter the future. Be it for application development on top of GStreamer or for the development of plugins, where the a... Length | 0:30:14 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
But with HKT you can have a generic `T` that abstracts between `Arc` and `Rc` right? (or even [with associated type constructors](http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/#parameterizing-over-smart-pointers-and-thread-safety)). But then, I'm not sure how to have `T: Send` in some cases.
I can agree libraries exposing types with either Rc or Arc is non ideal, but I don't think this is the solution. IMHO the best way to deal with this is a `RefCounted` newtype in the crate which defaults to containing Rc but can be switched to Arc by an optional cargo feature. With it Arc-&gt;Rc as an optimization, I would favor predictable performance over the compiler opportunistically taking every possible optimization. I really feel that explicitness would be better here, to show people that they _are_ loosing some speed when requiring something to be Send.
Would releasing the *number* of incidents be deanonimizing?
Specialization might be a building block for Rust's story on inheritance, but it's a separate feature. For its possible relationship to inheritance, see those 2015 articles: [specialize to reuse](https://aturon.github.io/blog/2015/09/18/reuse/) and [virtual structs part 4](http://smallcultfollowing.com/babysteps/blog/2015/10/08/virtual-structs-part-4-extended-enums-and-thin-traits/) (note those ideas aren't implemented in Rust so far)
Haskell solved this by having a syntactical difference between generic variables (always lowercase) and concrete types (must begin with uppercase letter). Rust decided to distinguish them by declaring which identifiers are type variables. It's a trade-off.
In this example they're semantically equivalent, though I think the turbofish `::&lt;_&gt;()` syntax is preferable for a couple reasons: 1. It connects directly with the fallible operation `.parse()` and makes it clear that this method is what requires the type hint 2. You can add method calls or other infix expressions which change the end type without breakage because `.parse()` still knows the right target type and there's no type annotation on `guess` that needs to be updated
Excellent. I was thinking the same too but I'm just a beginner. Perhaps they should update the [tutorial](https://doc.rust-lang.org/book/second-edition/ch02-00-guessing-game-tutorial.html#comparing-the-guess-to-the-secret-number)? Forgive me if I'm nitpicking 
Eh, six of one, half a dozen of the other. Turbofish syntax looks more foreign than giving a variable binding an explicit type, so it should probably be introduced alongside generics. The generics section of the version of the book you're looking at is actually very anemic, hopefully they're planning on adding more. A good time to introduce turbofish syntax would be in discussing how to deal with inference errors, which doesn't seem to come up where I would expect it to.
The example above is corecursion, this would be recursion: syntax = "proto3"; package foo; message A { A recursive_field = 1; } Almost like a linked list of sorts.
&gt; On Windows, freshly installed and with a small library, you won't have any problems. But as the size of your library grows, iTunes really struggles. Define large. I had Windows library with ~100k tracks if not more and it was pretty fine. &gt; I don't see how iTunes is more usable than Dopamine or Lollypop. Never used Dopamine so can't tell, but interface doesn't look like it can be usable with large libraries. Lollypop looks like slow clone of itunes and acts that way as well. Unless you not on Mac I see no reason to use it. &gt; What kind of music player doesn't support play queue? Half of the players listed by you. Dopamine looks like doesn't have a queue. &gt; Could you please elaborate further on this one? What more to elaborate? I like give player music files and see it all neatly organized like `&lt;artist&gt;/&lt;album&gt;/&lt;sequence number&gt;_&lt;track_name&gt;` &gt; I understand that no music player ever will be a silver bullet for everyone out there (mine included), so pointing out no support for Airplay/Chromecast, lack of guest mode and that kind of stuff is senseless, to be honest, especially on a desktop music player. You asked what I don't like in players I answered. Other than what I listed above i'm 100% satisfied with Spotify, iTunes and Plex. &gt; Are you sure about this? Have you ever used MusicBee or Foobar 2K? Foobar might look like a spreadsheet (which is no different than iTunes, really), but it has a ton of functionality. Even Clementine which is a lot simpler than Foobar has a lot more power than iTunes. Also, Dopamine and Lollypop doesn't look like spreadsheets whatsoever. Dopamine has functionality level of Plex. Foobar2k...well you're right it has tons of functionality and doesn't looks like spreadsheet. I tried using that one awhile ago, nearly impossible with large library to find what you want. Plus I'd take iTunes spreadsheet over this anytime. Lollypop looks like spreadsheet just as much as iTunes looks like spreadsheet, which is pretty much mandatory if you want to support large libraries. However I care about _all_ music only when I create playlist, 90% of time I only need to find a playlist and an album. Some times I want to add one specific song the the queue. MusicBee I guess is okay, but I don't care about music on windows personally. &gt; no support for Airplay/Chromecast, lack of guest mode and that kind of stuff is senseless, to be honest, especially on a desktop music player. Why not? I guess guest mode is a bit too much, but again you asked what I don't like about players today. If player did something like http://on.here/ but for music that would be great. Airplay/Chromecast/BT or ability to control player from another device (see Spotify) is must for me. Literally the only reason I switched from iTunes.' Oh also, I don't think any of them except for iTunes support library sharing across network which is the must have for me. 
I don't see what that has to do with my point. You can have a generic T like that, but you can't get the compiler to choose.
Depends on how you define "incident" really. Again, this was one of the things we did discuss, and I plan to write an email to the mod team and discuss it further, so we may do something here. I'd rather not discuss it further now.
&gt; &gt; &gt; As long as you don't use Rc&lt;T&gt; or Arc&lt;T&gt; to create a reference cycle Or call [`std::mem::forget`](https://doc.rust-lang.org/std/mem/fn.forget.html). But yeah, the pervasive use of RAII in Rust is nice to avoid memory leaks in practice.
The thing is, why aren't *other* languages as loved as Rust? What makes Rust different?
Yes, that's my purpose and my pleasure. thx.
Hyper 0.11 is not suitable for higher level framework abstraction for jobs. Too many future and functional style coding. That is not comfortable for generous people. 
you can refer: https://www.reddit.com/r/rust/comments/6k943c/sapper_another_rust_web_framework_now_updated_to/
Do you have some example code you can publish?
Is that a trick question? What does it mean? Is it like NaN but for types?
Yeah, that's the problem with GTK: Outside of the Linux world, it looks pretty ugly. The problem with Qt, from what I've researched, is that it's written in C++, object-oriented, of course, which makes one-to-one mapping pretty hard to achieve (see, as example, C++'s classes vs. Rust' traits) re: Qml —seems like it's memory-heavy, and that's one of the things I'm trying to avoid. I'll check it out, tho, to see how well it fares.
The first code block means `impl Struct&lt;()&gt;` today. You can also do things like impl&lt;i32&gt; Struct&lt;i32&gt; { ... }
took me 2 years to fully grasp it. Although I was only doing it in my spare time which is nigh impossible to find now.
It's a bad idea because it already means something, and if you play the "only if `A` doesn't exist in scope already" card, the second case is meant to show that this is a *really* bad idea, because now a change in a different file can subtly break code elsewhere.
You don't need HKT to do this, you only need higher kindedness to let the user select the pointer type independent of the type its pointing to. https://is.gd/Wj2dtQ
I see. That second approach would be nice if it wasn't for that caveat you mentioned. Nevertheless, it's still interesting and will take a further look on it. And thanks a lot for linking those articles and that video. I'll check them out as soon as I have a chance. Thank you so much, mate.
&gt; but again you asked what I don't like about players today. I planned to write a thoughtful argument w/r/t what you wrote earlier, but that line I'm quoting won't make me do it. Where in my original post (or my reply to your comment, for that matter) I asked for the things you don't like about music players? I asked for advice on how to build one on Rust. You completely missed the point of the thread.
can you speak to the architecture of how this is done? I've been wanting something like this for a while! Great job working on it! :)
&gt; Now after running the server, windows firewall popped up. I allowed the program to connect on the home network Sanity check: is your connection actually using the 'home' network, as opposed to a public network? IME Wi-fi connections in particular have a tendency to switch back to 'public' occasionally (possibly caused by OS updates) and I have to manually set them back to private rules. Also, does your laptop's firewall have a rule disallowing outgoing connections on that port?
what's special about it?
Yes you can write core library in Rust also, but then you need to create bindings in c# for your rust library. Also either you have to make sure your rust library is thread safe or you have to make the synchronization on c# bindings project. (actually writing a wrapper in c# for future-rs would be great). For the Mac (and other bindings for ios and Android) check Xamarin. I use xamarin before for both mobile apps and desktop apps, and I would say it's the best for code sharing. And it has great documentation. 
Do I need format! here? ....expect(format!("Failed when {} with {}", context, data)) Makes the lines so long they get broken by rustfmt :( 
Representation-specialisation like this was one of the things discussed as a possible use for specialisation back when it was first being discussed (2015, I think), including this specific case, although I'm not sure it was ever written down beyond IRC logs. In any case, the only easily distinguishable case where `Rc` is sufficient is when the containing type is not `Send + Sync`, and this works now with the current (nightly) specialisation, without HKT: https://play.rust-lang.org/?gist=489fd1b935eea68b732c8bc01ee2d413&amp;version=nightly&amp;backtrace=0
One can get [pretty far](https://play.rust-lang.org/?gist=489fd1b935eea68b732c8bc01ee2d413&amp;version=nightly&amp;backtrace=0) with some definitions of "contexts that don't require Send", i.e. ones where the internal type is not `Send + Sync`.
No, it doesn't. There is currently no global analysis that looks into both struct and function bodies. Your example works because you have only one function, not a complex network of functions sharing the Mrc.
(I dramatically rephrased my comment to be more specific since you read it.) In any case, the uses of the Mrc is irrelevant there: everything there is determined by the type it contains which is all statically known. If one, as I imagine you're thinking, wants to downgrade to `Rc` when the pointer is never actually used in a threaded context (even if the contents is safe to do so), then yes, that requires global, even dynamic, analysis, but my version doesn't care at all about the complexity of the network of functions using the Mrc.
Curious about the module system revamp. The last proposal I saw I didn't agree much with.
Yes, otherwise you cannot put your context &amp; data into the message.
&gt; but my version doesn't care at all about the complexity of the network of functions using the Mrc. I fail to see how this is the case, the reason your version works is that the Mrc is _immediately_ used in a function that has a `T: Send` bound. In general the use case of an Arc or Rc will be in a much more tangled web. Maybe I've misunderstood the original question.
That's my claim: it's precisely the large barrier to entry that makes its adherents so passionate about it once they crack it. That doesn't mean that the community wants to keep the large barrier to entry (note that 2017's goals are in a large part around accessibility: both on the technical and contributor front).
Previously, Rust was used for IRC-based C&amp;C, [[1]](https://www.reddit.com/r/rust/comments/51xf9n/rust_meets_the_dark_side_linux_backdoor_written/) [[2]](https://www.reddit.com/r/rust/comments/52hfp0/rust_in_the_wild_new_linux_trojan_discovered/). This one is Telegram-based C&amp;C, included in what seems to be a production grade cyberweapon.
I don't think you've understood what that code does. If `T: Send + Sync`, then so is `Mrc&lt;T&gt;`, and if `T` is not then neither is `Mrc&lt;T&gt;` but also neither is `Arc&lt;T&gt;`. That is to say, `Mrc&lt;T&gt;` behaves identically to `Arc` in this respect. As you know, all of the analysis that makes `Arc` work in a thread safe manner is local, and `Mrc` is identical. The only way to observe the thread safety of these pointers is when used directly in functions with Send/Sync bounds, as those bounds propagate up the call stack, this how the analysis remains local.
I see, thanks! 
No problem. Also, I should probably explicitly mention that, if you do use rust-cpython in the "Python application with most of its guts in a Rust library" configuration, there's [setuptools-rust](https://github.com/PyO3/setuptools-rust) to automate the integration of cargo into Python's `setup.py` build automation. (That's also something I'm using in my own creations... [with one workaround](https://github.com/PyO3/setuptools-rust/issues/2).) ...plus, that configuration essentially uses the QWidget API, Rust, and Python to implement the architecture that Qt developers have been encouraging with the Qt Quick APIs and C++ extensions, glued together by QML at the top level.
My dev-channel ChromeOS decided to switch the screen off and on in half-second intervals, so I've been installing Fedora and now see if I can get stuff to work (ah, the usual ritual of a new Linux install). I'll manage my TWiR parts, and that'll probably be it. 🙁
I understand what it does, but the decision will only be local here; is my point. You won't be able to do something like store it in a struct or pass it to another function without knowing the thread requirements beforehand. As in, I don't see this as very _useful_, the useful kind of analysis here requires cross crate global analysis.
Point. I tend to unthinkingly lump that in with the C FFI it enables, which then gets filed away as "Duh! Of course all bets are off then." **EDIT:** That said, `std::mem::forget` being callable from safe code does help to draw attention to one of the realities people may never have thought about before: It's impossible to guarantee that destructors will run in any meaningful sense of "guarantee" without bringing in a heavy fault-tolerant runtime. Otherwise, keeping destructors from running is as easy as `kill -9 &lt;PID&gt;` and there's nothing the language can do about it. Knowing that encourages "detect dirty state and recover" approaches like journalling or delegating your persistent state to a transactional data store of some kind.
Working on [printpdf](https://github.com/sharazam/printpdf). Last week I did line drawing (regular, bezier), overprint and blending modes + line styling (line dashing, coloring, line cap + line join styles). This week: images (JPG + TIFF), fonts and maybe annotations + forms. Maybe I'll experiment with transparent PNG files, but they are harder to do, since you need to read out the alpha channel and set it seperately as a soft mask.
This excites me more than any other porting project I've seen as, if it came to fruition, it would have a noticeable impact on my life. libgjs.so segfaults so regularly and reliably many, many times a day that it's just become a part of my life to watch gnome-shell crash and load back up every few minutes. Any fix would make my life better.
You will be able to store in a struct just fine and also pass to another function without extra concerns for thread safety beyond what is normal in Rust. Could you be more specific about what you're meaning?
&gt; See? That's the problem. I don't want to write something that will look great on some OSes and garbage in others. That's not the point. Neither is something memory-heavy —something which it's not really a big deal since most modern PCs/laptops have at least 8GB RAM, but it's still a concern, nonetheless. The point being made was that Qt's QWidget API is the best choice for looking native on all platforms... and it still falls short on MacOS. There really isn't any good way to fit in on all platforms without writing at least two frontends. (MacOS and "everything else")
Sorry, I wasn't clear -- yes, the analysis of "oh T is Send/Sync I can Arc this" works, but there's no analysis of the _use_ of Mrc (i.e. if it is being shared across threads or not), which is what AFAICT is being asked for.
It depends. I was excited before I started learning it, based on descriptions similar to the long list of features I posted, and I continue to be excited. ...though, admittedly, some of that may be because I haven't needed to unlearn much so far to get my mental models to click.
And people say Rust isn't good enough to use in production...
Thanks for helping. My friend managed to wrangle my test program into something that works for him so I'm experimenting with it after I'm home from work.
I am working on [Pris](https://github.com/ruuda/pris), a domain-specific language for designing slides and other graphics that compiles to pdf. Over the past weeks I replaced the [`lalrpop`](https://github.com/nikomatsakis/lalrpop)-based parser with a hand-written one. This reduced the build time of a clean release build by 85%, and reduced the binary size of a stripped release binary by 20%. Apart from that it generates better error messages.
Could you provide the link giving this error? 
It's the one you gave: https://85.255.1.138:8002
I've intended to do some embedded rust experiments on some STM32 boards I have lying around, but a trip to Paris will make the time sparse.
Two questions pop up in my mind: - what crates are they using if any ? - knowing the crates an application uses would lead to a kind of signature. Is it then possible (in theory) to track s.o. with this information using the log files of the crates.io server(s) ?
Yes, I thought I made this distinction clear in [my comment](https://www.reddit.com/r/rust/comments/6ks0f8/specialization_hkt_awesome/djpn0uw/) above. (Nit, you've got the condition backwards: "T is Send/Sync, I *must* Arc it", or, equivalently, "T is not Send+Sync, I can get away without Arc", given one *can* always place any data in an Arc.)
The screenshot shows use of rand crate.
Not sure if it counts as a "Rust" project, but I'm trying to cross compile [termplay](https://github.com/legolord208/termplay). It's seemlingly impossible. Apart from that, I'll probably just be bored the whole week like always. Man I wish everything wasn't already invented
Ey, that's awesome! Have you tried Ubuntu? What are some pros to Fedora over it?
&gt; I wonder if in time there will be tools developed for greater visualisation of this sort of thing . I even wonder if we could give example code thats debugged the old fashioned way and have some tool guess annotations ('in this source, it seems to be used this way, so these annotations would guide similar use elsewhere..') Well, a borrow visualizer for RLS is being [worked on](https://internals.rust-lang.org/t/borrow-visualizer-for-the-rust-language-service/4187), so progress is certainly being made.
Well I finally decided to sit down and learn Rust and have chosen a torrent client as the project to do so with. Nothing to show right now as I only started last night, I've Bencode encoding+decoding done and torrent parsing. Took a little longer than I would have liked since I had to read a lot of documentation but I'm liking the language so far, no gripes yet. Edit: Actually for anyone who reads this; suggestions for async File and Network IO? I know of Tokio for Network but not sure about File IO. 
[Redshift](http://jonls.dk/redshift/) is very nice, providing that eye-friendly red tint to monitor image after sunset. It would just be very nice if the adjustment happened according to the ambient light color and brightness instead of the calculated sunset time, especially now that it's still close to the midsummer so sun sets pretty late (23:06 today says a weather page). I've been playing with an old webcam I have and the [rscam](https://crates.io/crates/rscam) crate with the intent to continuously adjust the monitor according to the actual lighting. The library was pretty easy to get working - didn't take too many lines to grab an image from the camera and display it with [sdl2](https://crates.io/crates/sdl2). With an image in YUV mode the brightness comes in one channel and the color info in two others, so it will hopefully be easy enough to detect brightness and light color independently. I'm assuming pointing the camera at the (white) ceiling and averaging the pixels into a single value gives me a nice representative color value. The [UV plane](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/YUV_UV_plane.svg/300px-YUV_UV_plane.svg.png) of YUV looks like I could get the approximate redness/blueness of a color value just by looking at how close to the top left or lower right corner it is. I won't even attempt to do the monitor adjustment part by myself. A glance at the redshift source reveals it's not trivial. Just running redshift in oneshot mode with calculated values ought to be good enough.
To clarify what Steve is suggesting, you'd have three threads: 1. rustyline, which produces events 2. background thread, which produces events 3. playback thread, which receives events Then you'd use something like [`std::sync::mpsc`](https://doc.rust-lang.org/std/sync/mpsc/) (a Multi-Producer, Singler-Consumer queue) to allow both sender threads to push events to the receiver.
Didn't servo do something like this already?
You couldn't do a rewrite at home?
As I understand Servo doesn't do anything for GNOME Binding, which GJS is about.
Since `expect` takes a `&amp;str` I guess it's really intended to be used with string literals. Of course, you can create a `String` with `format!` and make use of the `&amp;String` -&gt; `&amp;str` Deref coercion, but this won't be the most efficient way of doing things if you need to include context and data because the `format!` expression is *always* evaluated and it *always* creates a temporary `String` if you need it or not. In a tight inner loop you should probably replace that with (...).unwrap_or_else(||{ panic!("Failed when {} with {}", context, data) }) The `panic!` macro has formatting already built-in. And in this case, formatting the custom panic message is only executed when necessary.
&gt; knowing the crates an application uses would lead to a kind of signature. Is it then possible (in theory) to track s.o. with this information using the log files of the crates.io server(s) ? What if they downloaded the crates while being behind Tor?
Ah yes thanks! Now I see it.
By cross-compile do you mean build a binary for a different platform, or get the program to be able to compile on a different platform full-stop? If compiling works and you're just after a binary, the lazy way is to hook up travis-ci and/or appveyor and just use the artifacts from there.
They mainly talked about binding spider monkey, which servo did. For the rest, I have no idea but I guess the bound between gnome and this spider monkey binding needs to be done.
That would be an option. But I thought Tor wasn't 100% secure anymore ? (OK, that gets a bit off-topic... ;-) Could they also just download a lot of crates (or all) and use a local repository for cargo ?
Great work OP! This looks like a very nice implementation. :-) I do have a nit though. In particular, I'm looking at this comment and subsequent `unwrap_` functions: https://github.com/sdleffler/qp-trie-rs/blob/42b4cee00e9b01a6cdbe4cc7ec7a8815c0a2aca9/src/node.rs#L337-L340 Many of those functions use `unsafe` internally, which is fine, but the functions themselves should *also* be declared as `unsafe` because it is the *responsibility of the caller to uphold safety*. In particular, if the caller calls `unwrap_leaf` on a `Node::Branch`, then they get undefined behavior despite the fact that `unwrap_leaf` is not `unsafe`. This is definitely a no-no in Rust land. (I understand that these functions are not in the public API, and therefore, you could make an argument that all uses are safe since you can actually enumerate all uses. Nevertheless, if a function's safety depends on the caller to uphold certain invariants, then the function itself should be marked `unsafe`. To do otherwise is to leak memory unsafety into safe code.)
Yes, it is possible to use Cargo without connecting to crates.io, and they most likely did so.
Basically making it work on another platform, yeah. Even though I wish I wasn't dependent on Travis, I might actually have to use that. But then again, I don't know if [trust](https://github.com/japaric/trust) supports custom dependencies. Have left an issue asking that, but no response yet. I guess we'll have to wait and see ¯\\\_(ツ)_/¯
&gt; But I thought Tor wasn't 100% secure anymore ? IIRC the best attack so far against the protocol itself is to somehow make a client use an entry node and exit node that you both control at the same time and then try to perform a statistical correlation on the payloads sent and received by these two nodes. It's much easier to try and find exploits in Tor browser or applications that e.g. completely bypass Tor or accidentally leak your IP address.
Writing an interpreter for Emacs Lisp. I've never written anything of this complexity before, so I figured I might as well complete this rite of passage before I start school this fall. So far I have basic arithmetic working!
for function let a_float: f64 = 1.0; for struct struct Point { x: f32, y: f32, } And traits actually no idea but this works type T = Self;
I've finally bit the bullet and have spent a small amount of time working on [weld](https://github.com/RoyJacobs/weld), a GUI layer on top of Webrender. Hopefully it will be my first non-trivial Rust project, we'll see. The goal is to take some concepts from Flutter and Elm and allow you to define your UI as a tree of Components. These Components can 1) add a State struct at any level that contains observable fields and 2) may have (multiple) children. For instance, conceptually this should define a simple application (more or less pseudo-code): Container { state: { counter: 0 }, children: [ Button { clicked: |state| { state.counter++ } }, Label: { caption: |state| { "Clicked #times: " + state.counter } } ] } The idea is that any time State is accessed in a Component it will bubble up to the place where the appropriate field is defined (accessing "state.counter" in the example will bubble up to the top level Container). In the case of the label's caption, it should have some machinery to detect that the caption's only dependency is "state.counter" and it should only re-render whenever that specific field in the state is changed. For now I'm trying to get this built with a lot of boilerplate required :) I don't have a ton of free time so hopefully I can chug along quietly. Are there any recommendations for reactive stream libraries that I could use? I've found [carboxyl](https://github.com/aepsil0n/carboxyl) but other suggestions are welcome.