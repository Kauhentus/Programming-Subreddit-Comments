No, don't use unsafe to allow a &amp;mut reference to overlap any other live reference. Because this function and anything like it anywhere else become poorly defined: fn oops(n: &amp;mut Node , i: &amp;Interface) { n.calculate(); i.tweak(); n.calculate(); } The optimizer may reason: &gt; n is a unique pointer, therefore the `tweak` call can't influence `calculate` so I'll put the two `calculate` calls together. This gives *at least* better cache coherency, but if I inline both I can eliminate redundant work... I haven't done much of any compiler hacking yet, but if I underestand correctly, Rust currently tells LLVM that &amp;mut with a cell is not noalias. However the standard library sorta implies that this may change. For example, the `get_mut` methods on various cells (including `Mutex` and `Atomic*`) certainly *would* result in bad aliasing data passed to the optimizer. For your approach to be correct, you need to ensure that you never do anything like that bad example. Seems like asking for trouble. Bottom line: use another `Cell` or `RefCell` to contain the mutable part of the Node, give `calculate` an `&amp;self` signature. 
No worries. I meant Rust (Rust is the one that has a borrow checker and manual memory management). But probably OCaml would be a good introduction to both languages. They're all in a generally related family, and learning something about any one of them will likely pay off in the other two.
I think it should be possible to implement all of Vimperator's functionality for embedded Servo, yes. In fact it must be, because Vimperator doesn't really do anything that's fundamentally different or would require more powerful access than what you need to implement a general-purpose browser. While we want to meet more specialized embedding needs, too, building a general-purpose browser will definitely be possible with libservo.
Ok, that sounds like it requires the above-mentioned ability to expose Rust functions to JS, to call in-content JS functions from Rust, and the ability to intercept user input. All of those will be possible. As for manipulating the DOM using Rust, there are a number of ways to go about that, all with their trade-offs. I agree it's an important use case, but it's not yet clear how granular and powerful this needs to be. Having a perfect 1:1 mapping of capabilities is very likely to be an excessive amount of work.
i need this badly lol
Simple polymorphism can be expressed in Rust with an `enum`. Define `Animal::Duck` and `Animal::Cow` and so on. Then there are three kinds of methods. - A method that is implemented only using other `Animal` methods is straightforward. - A method defined for only one kind of Animal is defined *for that variant type*. Code that calls it will need a `match` statement or similar. - A method defined for all Animals but with different behaviour would be associated with Animal and have a match statement inside. IMO, this is is *extremely easy to read* compared to OOP. You can trace execution with your eyes without needing the language reference or a live debugger to puzzle out dispatch. (Dynamic polymorphism is "assigned GOTO".)
Fair enough.
No. We have not ported the kernel or drivers to other architectures.
Why this works? fn read_file(filename: &amp;str) -&gt; String { let mut string = String::new(); let mut f = File::open(filename).expect("Unable to open file"); f.read_to_string(&amp;mut string).expect("Unable to read string"); string } But this does complain about string not living enough: fn read_file(filename: &amp;str) -&gt; Vec&lt;&amp;str&gt; { let mut string = String::new(); let mut f = File::open(filename).expect("Unable to open file"); f.read_to_string(&amp;mut string).expect("Unable to read string"); string.split("\n").collect() } If Rust is able to know that some data is in the heap and it can track it over the boundary of the function (the first case). The second case is similar but the pointer(s) are in a Vec instead of a String to the same allocated memory in the heap.
even "Rewrite Rust in C++" .. 
You're really enthusing me; I can't wait to start! Thank-you so very much.
&gt; I truly can't understand why someone downvotes a call for help that is not a trivial question that can be answered by a google request. Reddit lies about up/downvote counts, it's quite possible nobody downvoted you.
Yeah, this isn't really the use-case for `Borrow`, which is basically for data structures. They should use AsRef.
Quoting myself (and Carol): https://doc.rust-lang.org/book/second-edition/ch12-03-improving-error-handling-and-modularity.html The organizational problem of allocating responsibility for multiple tasks to the `main` function responsible is common to many binary projects, so the Rust community has developed a kind of guideline process for splitting up the separate concerns of a binary program when `main` starts getting large. The process has the following steps: * Split your program into both a *main.rs* and a *lib.rs* and move your program’s logic into *lib.rs*. * While your command line parsing logic is small, it can remain in *main.rs*. * When the command line parsing logic starts getting complicated, extract it from *main.rs* into *lib.rs* as well. * The responsibilities that remain in the `main` function after this process should be limited to: * Calling the command line parsing logic with the argument values * Setting up any other configuration * Calling a `run` function in *lib.rs* * If `run` returns an error, handling that error This pattern is all about separating concerns: *main.rs* handles running the program, and *lib.rs* handles all of the logic of the task at hand. Because we can’t test the `main` function directly, this structure lets us test all of our program’s logic by moving it into functions in *lib.rs*. The only code that remains in *main.rs* will be small enough to verify its correctness by reading it. Let’s re-work our program by following this process.
One of the points of "Reflections on trusting trust" is that it's not really a thing that's possible to solve: &gt; The moral is obvious. You can't trust code that you did not totally create yourself. ... No amount of source-level verification or scrutiny will protect you from using untrusted code. 
In the first case you're returning an owning string `String`, which owns its data. It returns (moves) the owning handle (`string`) so the ownership is transferred to the caller of the function. In the second case you're returning a vector of string references `&amp;str`, which doesn't own the data, it refers to the content of `string` which is only valid inside the function. You could return a vector of owned strings as an alternative: fn read_file(filename: &amp;str) -&gt; Vec&lt;String&gt; { let mut string = String::new(); let mut f = File::open(filename).expect("Unable to open file"); f.read_to_string(&amp;mut string).expect("Unable to read string"); string.split("\n").map(|s|s.to_owned()).collect() } 
IntelliJ ships its own JRE, are you overriding it?
Started preliminary work on a [fork of SQLPop for MySQL queries](https://github.com/ilsken/mysqlpop). I'm hoping to use it as the building blocks for other MySQL related tools (for example, detecting intrusions by generating a fingerprint of queries normally run by an application and alerting when an anomaly is detected)
Not everyone agrees its a good idea, it's true. Why is it scary to you?
Current plan is to do a feature freeze at the set required for rustc 1.19, but might work on slowly working in new features once everything is cleaned up (constant generics are one that would be interesting to implement).
Cycle collector
would to_owned() make allocations (create a new heap object per string data) or it's just to point to the compiler that ownership moved hands but the memory layout is the same? It kind of sucks though, I'm adding some code here which is not really modeling my problem but kind of dealing with the language :(
&gt;Why is it scary to you? "Scary" probably isn't the right word; maybe "fragile"? It just feels like the kind of thing I would've early in my programming career when I couldn't figure out the right way to do something. More practically, now my build server (and everything else that wants to compile my code) needs a whole database to look at, which seems excessive, and I don't understand the benefit.
Cycle Collector
Sorry. I have no experience with multi core devices so I can't give you any pointer. It seems, though, that the problem is OpenOCD in this case: it's not managing to connect to the device. You'll have more luck asking the OpenOCD community how to deal with this dual core micro. Also I'm not sure if the default linker script provided by cortex-m-rt will work in this case; your device may need a special memory layout since it has two cores.
Totally! These reasons make sense. &gt; now my build server (and everything else that wants to compile my code) needs a whole database to look at This can totally be a reasonable restriction, and in my understanding, Diesel doesn't *require* that you connect to a DB for this reason, it's just the default. &gt; I don't understand the benefit. It's like any other correctness check; it's one more thing that the compiler has validated is correct. You can't forget to write a migration, or get your models out of sync with the database.
I suggest giving [F#](https://fsharpforfunandprofit.com/why-use-fsharp/) a look: the succinctness of Python (and then some) and the power of OCaml (minus functors, plus computation expressions), and you can use it as [a scripting language](https://fsharpforfunandprofit.com/installing-and-using/#shell-scripts) or a compiled language. -- ^(Shame about that runtime, though... ;-/)
I'm not sure, I hope someone more knowledgeable can chime in. Meanwhile, maybe this helps for your use case? https://github.com/Kimundi/owning-ref-rs
And given two compilers `mrustc.gcc` and `mrust.clang` one should arrive at the same output binary given the same input. That would mean that either 1. Both gcc and clang were compromised 2. None were compromised 
I liked the concept of F#, and C# come to that, a lot. It appears to be higher level than Go or Rust and so I didn't mind a GC. Wrote a very few things in C# 0.1 or something, but that's before I really transitioned away from MS. I loved the introspection giving the drop-and-play potential that Linux has anyway; I guess everything has that now, but it was new to me. My MS days are over. I still have to maintain family Windows machines and it still annoys me that each version/update has fewer facilities than the prior! That runtime is 'something else' isn't it through?!
how was your experience?
F# was created by MS (MSR, actually) but it is owned by [the community](http://foundation.fsharp.org/). Retaining a grudge against MS products is understandable (if unfortunate), but it doesn't really apply to F#. F# works great on non-MS platforms; Windows doesn't even enter the picture here.
Hi, first of all I'm sorry you're running into problems! Hopefully we can figure this out. Make sure you're running both Cores powering client and server. From a brief glance, I see you're using `core.spawn(server);`. Spawn won't do anything unless the core is already running. Try using `core.run(server);` instead.
Sounds like a bug to me, might be worth filing.
Absolutely amazing. I was mostly into C++/Python/JS before this, and Rust kind of solves the WTFs of all three. I am now a permanent Rust fan and am looking for bigger projects to contribute to :)
On windows you use a `named pipe` while on linux you use a `socket`. If you are using `rust/gnu` in say cygwin then you are embedding some logic to the windows `named pipe` acts like a `socket`.
I believe mercurial handles this use case quite well.
What are Servo display lists like? One silly idea I had in mind was creating a new Servo based command line browser. But I'm not sure if it feasible to render to text mode from display lists
Is there no way to use structopt to automatically bridge strings to enums like you manually do for the "filter" option?
It allocates a new string. If you wanted to do the `&amp;str` version, you could pass the `string` in as an argument to `read_file`.
This won't help for this situation, or at least, not directly. The only way I can think of using it is way over-complex.
But where would I file it, is it just some unsafe code in the mysql crate, or filing it in the compiler itself?
&gt; I am imagining a sane alternative to Electron and React Native React Native uses the native UI toolkit of the device IIRC, we don't need servo if we want a Rust-based equivalent of react native.
I'd file it against mysql first, and then if it's determined to be a compiler bug, file it against the compiler. Until you've determined exactly what the bug is, it's hard to say what exactly it should be, but mysql is the first suspect.
That's pretty cool! It always surprises me how real you can make graphics look by nailing the lighting. It looks like there's a significant amount of noise, though. Is that a result of limited computational time, or the particular way your raytracer works?
When I disabled named pipes in the xampp mysql server config, it would fail to connect when I forced it to use the named pipe (the mysql crate client impl). But when I told it to use a socket, it connected just fine, then segfaulted when I tried to use it. If i enable named pipe, it connects through named pipe just fine, then segfaults like in the other example. Unless i misunderstood, i think that points to it not being a named pipe issue? (also not using cygwin, but i do have some msys2 stuff installed)
It would probably be worth filing a ticket containing a small example program that demonstrates the issue and a backtrace if you are able to get one. I'm not sure if this is a Rust compilation issue, or an issue with the MySQL crate. If you can provide the above information, then it might be worth filing a ticket with [Rust first](https://github.com/rust-lang/rust/issues), but if it turns out it's an issue with the crate file an issue in their bugtracker instead.
Yep, I limited the ray samples. This frame took around 45 minutes to render on whatever I had. I'll try increasing them and leaving this overnight and see what happens. Also, I am looking at further optimisations. SIMD, for instance (which I read isn't available on stable Rust yet).
Using a mountain of JavaScript. My meaning is a cross platform GUI engine that performs well, which RN certainly does not.
Interestingly enough, the JavaScript spec doesn't assume a GC. A Js implementation which would allocate objects until the webpage is closed would be valid from the TC39 POV.
Explicit SIMD is (kind of) available on nightly. Check out simd crate. You could also try rewriting some code so that autovectorizer could pick up by itself, perhaps? Sure it can't vectorize everything (leave alone do it well) but it's probably worth a try.
Consider using my crate [`numeric-array`](https://crates.io/crates/numeric-array), which when used with the correct rustc flags can generate SIMD instructions automatically for all of the component-wise traits implemented for it. For example: let a = narr![f32; 1.0, 2.0, 3.0, 4.0]; let b = narr![f32; 5.0, 6.0, 7.0, 8.0]; let c = a + b; assert_eq!(c, narr![f32; 6.0, 8.0, 10.0, 12.0]); will generate a single `VADDPS` instruction to add all of those elements together.
I'm not familiar with autovectorization. Need to look it up, thanks for the suggestion :)
Nice! I am using a lot of vector operations, this would probably speed things up.
Basically `numeric-array` makes it really easy for LLVM to autovectorize component-wise operations while also just acting as an array. However, it needs those correct rustc flags, which are basically just `RUSTFLAGS = "-C opt-level=3 -C target-cpu=native"`
&gt; looking for bigger projects to contribute to :) Lucky you, because the `impl period` has just begun, and there is a [brand new nifty site to help you find projects/issues to contribute to :\)](https://www.rustaceans.org/findwork)
This is crazy, I just used the above rust flags in my current code and things just sped up like anything. I'm going to rewrite my vector structure using `numeric-array`. I wonder what will the speed gains be with that 😁
Yep, we're hoping to make such a thing, but we need to lay down infrastructure first. If you're interested in helping out, let me know.
Yeah, by default Rust/LLVM generate very generic CPU instructions that can probably run on anything a decade ago. You have to use those flags to tell it to take advantage of more modern CPU features. Also, after taking a look at your code, you might want to try out the `nalgebra`crate before using `numeric-array`. It will have some more useful algebra/geometry features for you than my crate.
Is there some way to access internal structures with this, e.g. the layout tree or style info?
So is MySQL segfaulting for your connecting programiming?
Do you know https://github.com/pcwalton/libui-rs
Thanks! I'm going to give this a shot.
By the time you get display lists we’ve already laid everything out (down to glyphs) at arbitrary pixel positions. For "text mode" rendering you’d wait the layout algorithms to be aware of the grid’s constraints.
Better than git maybe (last I checked (years ago) git had O(n^2) memory usage related to size of a file committed) but it still forces a client to check out every version of every large binary file ever. The largefiles extension helps but I've never gotten it to work *really* well. git-lfs is easier to use but last I checked (fewer years ago) nobody had server software for it but Github.
I think most Rust internal data structures will always be considered unstable: the next Servo commit can change them in incompatible ways. A more viable way to get info about the page is to inject JavaScript in it and use standard web APIs like CSSOM for style info, and possibly one day https://drafts.css-houdini.org/box-tree-api/ for layout data.
Submitted a PR, https://github.com/rust-lang/rust/pull/44751
One other thing you could consider adding to your raytracer is the awesome [`indicatif` progress bar](https://crates.io/crates/indicatif), so you can track how far along a render is!
&gt; Multi-threaded implementation using Rayon. 480x320 image at 100 samples took around 46 minutes to render. Were you running with optimizations, in release mode? On my i7-7700K, I just ran `cargo run --release --example one_weekend` in 1m53s.
I just asked in a separate comment if you used `--release` mode, because that will give you the `opt-level` and also turn off debug-assertions. Adding `-C target-cpu=native` is just gravy on top. :)
It was a config issue somewhere, no idea where but msvc is working for me right now. Not an issue with the mysql crate as far as I'm aware, think it might be to do with my error logging.
Yep, I just found about the release mode optimisations from this thread. I was blown away by the reduction in runtime! I am going to add another entry to the changelog soon (now that I know that this is order of magnitudes faster, I am going to be a little greedy and go for a thousand samples 😅).
This looks cool! But I am not sure if this will work with Rayon. I go through each pixel this way: result = (0..ny).into_par_iter().map(|y| { (0..nx).into_par_iter().map(|x| { // trace da rayz }).collect() }).collect(); I can't increment the progressbar in there 😕.
Before I knew better I had tons of stuff in the main.rs and compilation times were much worse, just fyi. 
Yeah, I'm fine with it being unstable and targeting a single version though: I'm just interested in the data for a project of mine. Didn't know about the Box Tree API, that's really cool. I imagine nothing supports it yet? :(
FWIW, adding `RUSTFLAGS=-Ctarget-cpu=native` got me down to 1m46s -- not bad, but clearly the main improvement was just in enabling optimization at all. :)
You could wrap it in a `Mutex` to update it from separate threads. Doing this on every pixel is probably too much, but after each row shouldn't be too bad.
json_typegen is awesome, but is there a way to make all the structs and members `pub`? It would be very useful!
[`AtomicU64`](https://doc.rust-lang.org/std/sync/atomic/index.html) should be enough, right? You could increment per-pixel and track what percentage of pixels have been finished.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cpp] [mrustc: Alternative Rust compiler written in C++ • r\/rust](https://np.reddit.com/r/cpp/comments/71lax0/mrustc_alternative_rust_compiler_written_in_c/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Actually, `indicatif` handles this just fine. It seems the author was careful in their design. No need even for a Mutex as /u/CUViper suggested or an AtomicU64 as /u/cramert suggested. Everyone hold onto your hats! [Pull request is here.](https://github.com/ranveeraggarwal/rust-raytracer/pull/1)
Went down to 3m40s for me. Compiler optimisations are awesome.
This is great! I will put this on my todo list along with a spec-based renderer (define objects via json/toml).
Sure, but then you need something outside the thread pool to also watch that atomic for updates. But actually, it looks like `ProgressBar` is already built with a `RwLock`, and its methods all takes `&amp;self`, so it's probably fine to update this from separate threads. https://docs.rs/indicatif/0.7.0/src/indicatif/progress.rs.html#430-432
You've run into the fairly generic "trying to mutate a collection while iterating over it" problem. Luckily, since you're using `Vec`, there's one very easy workaround. Instead of looping over the elements of the vec directly, loop over the indices of the vec, and pull out each element in the body of your loop. Then the loop itself won't keep the vec borrowed, and you'll be able to do what you were trying to do. The key difference here is that looping over elements means (under the hood) you're holding pointers to the vec's internal storage. If you were to then do something like append to the vec, you could invalidate those pointers when the vec reallocates itself. Even if you're not mutating the vec itself, and just its elements, you could wind up with two `&amp;mut` references to the same element, which is undefined behavior again. Keeping indices instead of references means that all your actual borrows are very short lived (usually confined to single statements where you use the index), and you don't have those problems.
I personally would strongly prefer people did this that they separate the binary into `src/bin/$projectname.rs` instead of having both `lib.rs` and `main.rs` in the same directory.
[it's already done](https://github.com/ranveeraggarwal/rust-raytracer/pull/1)
Like everything in main.rs, or just all the mods declared in main.rs?
Thanks for the PR! This looks beautiful.
I've been going [through the same series](https://github.com/seenaburns/raytracer) (but hacky parallelization instead of rayon) as an intro to rust/graphics. Overall it was great, and made me a fan of Rust. The biggest hurdle was moving to using trait objects once I started working on the BVH of Ray Tracing: The Next Week. As the project grows to add new models and materials, making everything generic with trait bounds greatly simplified the complexity of codebase. Trait objects, which I found absolutely critical, were a challenge at first especially around object safety. Other than that the small things added up and made things readable and predictable, like options, only allowing explicit conversion between int/float made things readable and predictable, and the ease of using closures.
You probably want to use flat_map here instead of collecting early. Additionally, though unsure, you could run jobs for small blocks of pixels, like 2x2 squares or bigger. That should improve performance a bit too.
Rayon iterators should be able to figure out the job division on their own. It's not literally scheduling separate jobs for each pixel.
I've seen some discussion about Cargo maybe changing this, but currently, that's not the default, and so that's what's in the book. (I know *you* know this, but for others reading :) )
This looks nice, I too will be moving to the next book after this. I had thought of using trait objects for materials, but decided against it then due to the complexity you mention. Now, I will make sure to understand them and integrate them in my existing codebase before moving further. Thanks for the tip 😄
That's clear, but having many very-short-living jobs isn't really good for performance. rayon's ThreadPool uses stealing deque which isn't very free to steal from. In your case it is doing about 1360 steals per second each involving several atomic operations. Using longer jobs would therefore potentially increase performance by not doing too many steals.
Wow! I was just going to compliment the choice of name, but as a Java developer, struggling to get more rust to my life, the article provides incredibly clear insights.
Fantastic writeup, thank you! I wish someone would have told me about your [view structs](https://blog.rom1v.com/2017/09/gnirehtet-rewritten-in-rust/#mutable-data-sharing) method for sharing mutable data when I started rust a year ago!
You have a point there, but still i can see "90% upvoted" next to the "points". 
wait... you were doing all of this with no optimizations?! `--release` must be lifechanging! The debug builds are useful for rapidly testing changes, but they're sooo slow.
Are there articles/blog posts/detailed questions on the usage and use cases of the Box type. The Rust book and documentation are light in details.
This is actually really nicely done for a beginner. My only advice would probably be replace some of the Box&lt;Error&gt; return types with io::Error or an io::Result&lt;T&gt; type. It's not something that's super important but adds some clarity to your code
Right, what I'm saying is, that's a lie.
Yeah that's just a quick and dirty way I've done it because it took me a while before error handling in rust "clicked" for me. I think I get it now so I'll be trying to do that in my spare time over the next few days.
Would be cool if we find a solution! I will extract everything important into a runnable application tomorrow (in about 8 hours). Maybe it is more efficient if we all have something runnable. And thanks for the "run" tip. I may understand way less then i thought. 
I would also like to add that I am really intrigued by the functional side of rust. If you can suggest areas where I could use some of the functional features of rust let me know.
Yeah, I didn't know of the different until today. It was definitely lifechanging.
I just realized it's tethering backwards. Wow.
Are you sure you want Rust then? Go and Swift are similar to Rust but use pervasive garbage collection instead of Rust's pervasive awareness of ownership and aliasing. Rust's advantages are less "this language manages memory really well" and more "this language is very well suited to aggressive optimization and concurrency without compromising correctness."
cargo supports both conventions out of the box though, there's no setup today to make `src/bin/$projectname.rs` work, same as `src/main.rs`. My preference goes beyond compatibility with my pie-in-the-sky module proposals - as soon as you want to add a submodule to the binary it becomes very confusing IMO to have some modules be part of `lib.rs` and some `main.rs` and have to read code to figure out which go with which.
You probably could, but it will be a bit complicated to get a toolchain and libraries set up. The released versions of Rust don't yet support AVR, so you have to [build your own](https://github.com/avr-rust/rust), and then you'd probably need to update that arduino library to be compatible with the Diavolino.
I'm not sure I agree, this is an issue with rust currently that's not unique to the given case. Where you want to return return owned data in addition to different views on said data. Once self-referential structs, or self referential tuples (e.g. `return (owned_string, vec_with_references_to_string)`) are added to the language it becomes a non-issue. 
I promise you it's not creating such short-lived jobs. I even turned on logging, just to be sure -- I got 6139 calls to `join` and 146 stolen jobs *in the entire run*. That number of joins works out to an average 25 pixels per job. If you want it larger than that, you could just call `with_min_len` on the inner iterator.
I think the point is that binaries should basically never have a submodule.
I see, thanks for clarifying
Just for reference: https://medium.com/genymobile/gnirehtet-reverse-tethering-android-2afacdbdaec7 &gt; Yeah, that’s a weird name, until you realize that this is the output of this bash command: rev &lt;&lt;&lt; tethering 
Generally, there are a few cases when you'd use the box type directly. In order of how often it will come up: 1) Owned trait object (e.g `Box&lt;Debug&gt;`) 2) Allocating a large contiguous block of memory that can't fit on the stack (note that there is a bug that this might not work in debug mode) 3) Reducing size of an enum by boxing the largest variants (at the cost of the pointer indirection) Generally, functions shouldn't return `Box` objects unless doing so is necessary to transfer ownership. By returning a `Box` you force an allocation at some point, which may not be necessary if it's not long lived. The caller can decide by putting it in a box themselves. 
Thanks but I'm not sure I understand what you are saying (it is a bit cryptic). That's why I'm looking at a detailed guide of how Box works. 
The reference rustc was bootstrapped from OCaml originally.
*gasp*
&gt; The use of ::std in paths is mainly personal preference I do this too. I ran into a few issues a while back where `use &lt;cratename&gt;` wasn't working but `use ::&lt;cratename&gt;` was, so now all of my `use` statements are absolute. It will probably slightly annoy people who read the code, but it's habit at this point.
Thanks for all the effort in making it easier to get started with big projects like bindgen. :) 
I didn't know there *was* a reverse tethering tool, let alone a rewrite of an existing one.
Ah, ok sorry. So you can think of Box like unique_ptr from C++, or the result of malloc from C++ (except with automatic freeing). It just allocates some data on the heap, and the box value itself is the reference to it. 
Right, it seems to me as a language constraint which could be fixed under the same model. If you can get a Vec&lt;&amp;str&gt; from a String and work on that without ownership issues. It's weird I cut/paste the code into a function for modularity and now we have ownership problems.
I agree, but it might be misleading to have them on crates.io, since license isn't made very prominent (I imagine most people don't look too hard). My hope is that in the future cargo will support using multiple repositories similarly to apt. Then someone could set up a repo that is copyleft-friendly.
I have put some code here that you might find interesting: https://play.rust-lang.org/?gist=8dfac1e407c5e57502a4676ac9860af5&amp;version=stable It makes `Storage::new()` less clumsy to use, and it makes `register_to` work without requiring a `Weak` reference to upcast from. I'm not sure if either of these things are interesting to you. In Rust `::new()` is just a static method like any other. It can return anything you want. Traits can be implemented on a complex type like `Rc&lt;RefCell&lt;Storage&gt;&gt;`, so then you can have a `register_to` that works directly on such a type.
feel free to use it! I even got releases for osx, windows, and 'linux' (not really sure which, to be honest - it was from the template I used) [here](https://github.com/BaconSoap/branch-destroyer/releases). I recommend sanity checking the list of branches it will destroy by running it *without* `--for-real` once, but everything turned out OK for me (besides protected branches, which it can't delete anyway).
In case you use gitter, you can also ask questions at https://gitter.im/tarpc/Lobby!
I am trying to use the curl library what am I doing wrong. [package] name = "hello_cargo" version = "0.1.0" authors = ["PPs"] [dependencies] curl = "0.4.8" then I run cargo build. But when I do cargo run and on the top of the code there is use curl::http; I get mabye missing an extern crate curl 
i would love to use it, but i think im not brave enough to do automatic branch pruning xd
&gt;If you can get a Vec&lt;&amp;str&gt; from a String and work on that without ownership issues. It's not that simple. What you're trying to do with your original code would be illegal (undefined behavior) in C or C++ too. Taking a reference and working with it after the memory it's referencing has been dropped is just a hard error, and Rusts ownership model caught it for you. The string that you read into has to continue living somewhere when you want to keep references to it around, and what /u/steveklabnik1 suggested - declaring it outside your function and passing it as an argument to it ([like this](https://play.rust-lang.org/?gist=0c211b23b132e91d28a9a0b00bfd3054&amp;version=stable)) - is one solution that currently works, what I suggested would just make things a bit simpler.
You need to declare `extern crate curl;` once in the source of your program (e.g. in`main.rs`). Every crate you're using needs a `extern crate` declaration.
You're basically describing a GC.
I understand the memory should not be freed or you are in trouble. But if you return a String, Rust knows that memory is in use, that string points to it so it will not free it even if the variable in the function goes out of scope. Ideally when I create a Vec&lt;&amp;str&gt; I'd like to get the ownership moved there without extra allocations. Then return that. I think that's different from a GC. I'm good with the ownership semantics. It seems than in this case they force me to allocate more data inside a function while I would not allocate the data if I were not doing this inside a function. And that's what seems unnatural to me. 
Is (the un-patched version of) `core` still broken on the AVR fork?
Thank you.
Ah, I think I see where you're getting at. That's just not how the ownership model works though. `&amp;` references are only "borrows", they don't own the data and Rust takes care that the owner of the memory, which there can only be one of, lives at least as long as each borrow. Borrows aren't promoted to owners automatically like you describe, it always needs its owner to coexist. You're not forced to do extra allocations here though, you just have to (in this case) declare the owner outside of the function and pass it into it, see the working example I linked in my previous comment.
Have you looked at using something like [clap](https://github.com/kbknapp/clap-rs) for argument parsing instead?
*Should* also be &gt; crates you should know
&gt; In Rust ::new() is just a static method like any other. It can return anything you want. I should mention that `new` isn't special at all in the eyes of the compiler, it is just convention.
Right. That's what I said?
Any plans on releasing those updates soon?
Just opened an issue: https://github.com/servo/servo/issues/18597
IMO your comment implies that `::new()` is always a "static method like any other" which isn't the case.
It would have been more clear, in my opinion, to say: &gt; A common convention in Rust is to have a static function named `::new()` which...
It's a list of things like this: https://github.com/servo/servo/blob/89d5780570894a54774542e79585b79ece3f2dce/components/gfx/display_list/mod.rs#L597 &gt; But I'm not sure if it feasible to render to text mode from display lists I think it is. And if it's not possible, it needs to be.
Has anyone done anything about libclang's C API not being able to represent C types that are found in the wild? For example, it completely fails when trying to bind some complicated (but still just C!) types from the DX11 headers. The structs will be missing fields, unions sometimes completely disappear, and it leads to a lot of sadness.
This is an excellent and fascinating write-up and I learned a lot about getting around common non-trivial borrow checker problems while reading it. Your solutions were very elegant.
Holy crap, `--release` took 46 minutes down to 2? That's really impressive!
Thx for sharing! Maybe you could refactor the parts when you loop through the tasks collection with the index by using enumerate(): let foo = vec![1, 35, 64, 36, 26]; for (i, item) in foo.iter().enumerate() { println!("The {}th item is {}", i+1, item); } Slightly more elegant than incrementing the index manually.
you're looking for https://www.reddit.com/r/playrust/
Any particular reason you'd use Box and not Vec for #2?
Or does it just speak that poorly about the LLVM input right now haha. 
About your example, is good, I've tried it and works well. But I was trying to get slightly more ergonomic with something like read_lines.map(...) instead of declaring the string and then passing it. About the ownership, in my mind String is the owner, but then you do .split().collect().own_it() or something like this and Vec&lt;&gt; is the new owner of the memory and its items &amp;str can borrow that memory. I guess that's now how it works and each item needs to be owner of its own memory?
The semantics are different. A `Box` always holds exactly one thing, like a single large struct. A `Vec` holds zero to many things of exactly one type and can change over time. If you had to relate them, a `Box` is a `Vec` with one element that went to Neverland and forgot it could ever grow.
Putting the grammar under version control in the rust git or elsewhere would be a good start
Previously: https://www.reddit.com/r/rust/comments/70wb82/impl_future_for_rust/
This is the project I [mentioned](https://www.reddit.com/r/rust/comments/70t099/whats_everyone_working_on_this_week_382017/dn5s2fi/) in the "What's everyone working on this week" thread. rustup is a great tool, and I'm glad that there's a standard, well-thought-out tool available on all Rust's tier-one platforms. However, rustup is quite complex, there's a lot of different things that can affect what happens when you run "cargo build", and I suspect if it did the wrong thing it might take quite a while to pin down what had gone wrong. I wanted to make a tool whose configuration was easy to find, and whose result was easy to clean up. While I [previously](https://www.reddit.com/r/rust/comments/66g5by/tricking_rust_into_following_the_xdg_base/) cared a lot about having Cargo follow the XDG Base Directory specification, now I'd much rather have rustbud manage these disposable environments (and let rustbud cache things in XDG-compatible locations). I should also admit that I've only really tested this code on x86_64 Linux so far. Bug and success reports from other platforms welcome!
I get forbidden on clicking any of the "learn more" it goes to Dropbox paper and then forbidden message. Tried I tried performance for example 
Hm, let me check with the folks upstairs and see what I can do.
I've just tried every single "Learn more" link and they all load for me. Tried in both Firefox and Chrome. I've also tried both logged in and logged out of Dropbox, so I can't imagine what's causing it. Will keep asking around. Can you give me more details about your system?
That API is very very early stages.
strange ... why should anybody lie ... crude world.
Here we go: The first Push is kind of that what is currently in my program: https://github.com/schoeppl/tarpctest
You must probably mention this all in your readme.
If you encounter such bugs, it would be nice if you could open an issue with a minimal reproducible example :) 
&gt; Focus documentation primarily on `tokio`, rather than on `tokio-proto` Is that due to some flaw in `tokio-proto`, or just a desire to get the basics solidified first? (Or something else?)
I'd recommend looking at `structopt` for parsing options from the command line (it uses `clap` behind the scenes), and `error_chain` if/when your error handling grows more complex, but it's unlikely.
I know this is a joke, but I've had a long-standing dream project or reimplementing Rust using Rust and the [nanopass approach to compilation](https://www.cs.indiana.edu/~dyb/pubs/commercial-nanopass.pdf) in a purely-functional style. Rust has all the tools of ML, and writing a functional compiler in it would be dreamy (and, I'd expect, easier to contribute to).
I figured the project README wasn't the place for talking about other projects (like rustup) or previous efforts that weren't the project in question (like my blog-post). The "only tested on x86_64 Linux" perhaps should be in the README, but I'm hoping it won't be true for very long!
Rocket and Iron both use Hyper internally, but Hyper 0.10 rather than the latest Hyper version 0.11. Hyper 0.11 switched it's whole model to one of "asynchronous" I/O, using futures. This allows anything using hyper-0.11 to handle an almost infinite number of idle connections without any additional operating system threads - and any web app using it would be able to handle many more requests without using additional resources. Iron and Rocket will most likely update to using hyper-0.11 eventually, but it is a large difference in how almost everything works - and hyper took a long time itself to make the switch to asnychronous IO. You can still do a web app in Iron or Rocket or Hyper 0.10, but it will not be able to handle millions of concurrent requests to one application. Using hyper itself, version 0.10 or 0.11, will be a lot more "manual" than either Iron or Rocket. Hyper implements the underlying protocols, so it would be up to you what to do from the moment a client has requested a URL. There are no routing tools, nor static file serving tools - these are all part of libraries built _on top of_ hyper (like Iron, Rocket). In my personal opinion, sticking to Iron or Rocket at the moment is a good plan. They'll eventually update to hyper-0.11, and when that happens you'll get all the benefits of asynchronous IO, hopefully without as much churn or work as it would be to build everything from scratch.
Since rustup is the official way to install rust I'd argue that a motivation for why to use rustbud over rustup is the first thing people would want to see in the readme. (or at least some kind of comparison)
Wow, this lib looks awesome. I should definitely use it. Thank you.
I never programmed in C/C++. I came from JavaScript/PHP. I think part of the problem is that the book/community expects that we are coming from other system programming languages? So we have another curve to learn? Is it advisable that I learn C before rust?
Indeed, that's interesting, and it's a valid solution for this particular sample. However, this just provides syntactic sugar for the call to `register_to()` itself: you still need to pass the `Rc&lt;RefCell&lt;Storage&gt;&gt;` along the whole chain of calls leading to `register_to()`. Suppose that instead of calling `register_to()` directly, we call `f()`, which calls `g()`, which calls `h()`, which under some conditions decides to call `register_to()`: in that case, `f()`, `g()` and `h()` would need to handle explicitly the `Rc` instance.
By boxing you don't mean putting things behind a box, right?
I doubt that gcc and clang produce the same output binary for any program. Not even hello world, so...
Fair enough. I put what I felt were the most important advantages of rustbud in the first paragraph of the README, but perhaps I need to unpack it a little bit. I'm worried about coming across as dismissive or disparaging of rustup, but you're right, that *is* going to be the first question on everybody's mind.
mods declared in main
Are you using a phone/tablet with the Dropbox app? I heard there were some problems with that.
I'm having this problem when using an iPad but not from my android phone.
it's maybe the beginning of borrow checker cookbook... I for one would like to have something like that!
I did, in 2014 :) http://lists.llvm.org/pipermail/cfe-dev/2014-July/037985.html ... but it's just one instance of a more general problem: clang-c is often an afterthought. Clang's AST is fine, libclang's C API exposure of it is, IME, frequently not. I guess it needs some fuzzing with csmith. FWIW, this particular case has been fixed by now.
While we're at it. I recommend using `cargo check` (Instead of build) until you're ready to do a test run. This reduces compile times when you just want to find out if it type checks and passes the borrow checker.
Hyper and rocket/iron are different things. Hyper is an HTTP library. It helps you make HTTP requests, and it also lets you listen for HTTP requests, parsing any that come in, and lets you craft a response. Iron and rocket are a layer above this, and are web frameworks. They internally use hyper, but they do a lot more work for you. With iron/hyper you tell them what URL paths ("routes") to listen at, and specify how to handle each one with a higher level API. Use iron/rocket if you are creating a web service or other kind of server. Hyper is for lower level work on the server side (e.g. designing a framework) or for making requests on the client side with a lot of control over the contents. The `reqwests` crate is a higher level wrapper for client side requests which is generally what you want.
It said. No http in the root
You loose extensibility then. What if in my case I want my library's users to implement Animals themselves ? I can't with an enum. This, and decoupling : this is what you win with Dynamic polymorphism. 
Ok sorry
I think an honest comparison to related projects helps users understand what problems it actually solves. 
You need to `match` on it, because it returns _either_ a `[u8]` or a `[u16]`, and you don't know which it is until runtime.
Using Dropbox from android also gave me problems but without the app it's fine. I think it has more to do that paper doesn't work in the app properly.
Any reason why such an impl for `AsRef` doesn't exist?
Not sure but it may be related to coherence rules and/or specialization.
There was an announcement that they fixed something in LLVM, so once it's merged, it could work.
Are there any situations where `AsRef`is suitable but not `Borrow`?
I was unclear. If I create a program X and compile it with both clang and gcc. That program applied to source Y, should create the same binary. I was not saying that clang and gcc should produce the same output. They should both produce output, that when run, produces the same output regardless of the compiler that generated it.
In the other thread and below in this one, it sounds like a lot of people have trouble from mobile devices. I don't have that problem, but I get frustrated by how Dropbox keeps on doing full-screen overlays trying to encourage me to sign up for Dropbox so I can comment on these. I'm just trying to read them, and I don't particularly want a Dropbox account, and I find it rude to interrupt my reading. Even after I dismiss the full-screen overlay, Dropbox takes up a large amount of vertical space with a sticky header and a footer both asking me to sign in or sign up. Is there a reason that this particular sprint used Dropbox, rather than just some Markdown files on Github, or even Google Docs?
Hyper (server) is super usable all by itself! I think all the talk about how hyper is "low-level" is not great, as it puts people off even looking at using hyper directly. The fact is it has a really nice API (basically just `Request -&gt; Response`) and has some nice tools for parsing requests and building responses. See [server.rs](https://github.com/hyperium/hyper/blob/master/examples/server.rs) for an example of how simple a hyper 0.11 app can be. I think the big pain points for me in using hyper directly are path routing and (kind of strangely) writing cookies back to the response. If your path routing is pretty simple, you can handle it just like in the example above. If it's more complicated, you could use something like my [reset-router](https://github.com/kardeiz/reset-router) (which is just a couple hundred LOC) or build something similar. For the cookies issue, you just have to manually set the cookies on the response when necessary. It's a little cumbersome, but I think it is preferable to the alternative: for example, Rocket tries to set changed cookies on every request, whether you are even using cookies or the request has anything to do with cookies: https://github.com/SergioBenitez/Rocket/blob/master/lib/src/rocket.rs#L233.
Instead of making it a submodule of the binary, why not make it a submodule of `lib`?
Thanks! That seems to work.
Say I have a C-like enum with just labels and no other attacked data. Is it possible to create a set from that enum that is stored bitmapped? In case that is not clear: if my enum has 20 members I only want to store an u32 and each bit represents the presence of one option of the enum. I see how I could do that manually for one specific enum, but this is rather cumbersome and not very elegant.
Very interesting, I'll be awaiting the rest of the series! Side question - do you have a specific software/trick for the illustrations, or are they just handmade in inkscape/gimp/...? They look nice.
The [bitflags](https://crates.io/crates/bitflags) crate may do what you want
If I have a RefCell&lt;T&gt;, I can save a Ref&lt;T&gt; that can be coerced to &amp;T. But when I have RefCell&lt;RefCell&lt;T&gt;&gt;, can I store a reference to T in some type that can be coerced to &amp;T? Could not figure out a safe way, since I need two Ref's, but I can not store them in the same struct, right?
Sounds like you're trying to use the HTTP type without importing it first in the root (main.rs or lib.rs). If you don't want to do it there, you can either import it only in the module where you're using it, or fully qualify the path by calling `curl::HTTP` instead of just `HTTP`.
u/nasa42 QOTW?
It's not necessary to learn C before Rust, but you will need to become accustomed to system topics such as the difference between the stack and the heap. C has more resources to teach you that, but there's definitely enough for Rust to teach you it. For a quick tldr for the particular topic: in Javascript and PHP most things are allocated on the heap (this is because it has a garbage collector and is dynamic typed). In Rust, everything is allocated on the stack by default. When you allocate on the heap, you can use that memory outside of the stack frame it was created in (eg outside the function it was made). When you allocate on the stack it will be destroyed automatically when that frame (function) ends. In Rust, we try to allocate on the stack as often as we can, because it's faster than using the heap (because we need to ask the kernel for more memory). Any type that contains a Box (or is dynamically sized, like String or Vec) is allocated on the heap. Dynamically sized types need to be allocated on the heap (because on the stack you will run out of space quickly, and even everything is close and you can't be sure the memory is contiguous) 
Since many aspects of Rust are designed to solve the shortcomings of C/++, especially with regards to how memory is managed, a primer on that will definitely improve your understanding of the language. However I don't think you have to really **learn** C, rather try to find a few articles on how memory works and how to think of the stack and the heap and the common pitfalls associated; that should get you going. Perhaps people can recommend some resources here? Beyond that, don't worry: many people here have come straight from high-level/managed languages (me) and they're fine! 
Came here to say the same thing! I read the readme and all I got was why not to use rustbud :) The first paragraph is not that clear on why you should use it. Your first comment here is more insightful.
To add to this, [Rust By Example](https://rustbyexample.com/flow_control/match/destructuring/destructure_enum.html) might help.
Thanks! They are handmade with Inkscape :) 
So, out of curiousity, did you use any libraries for arguments parsing? I've actually found [`structopt`](https://github.com/TeXitoi/structopt) (especially the fairly [recent support for subcommands](https://docs.rs/structopt-derive/0.1.0/structopt_derive/#subcommands)) to be an incredibly elegant solution to args parsing, though there are some use cases that are not covered, albeit less frequent. Have you given libraries like this a look? EDIT: I see that a sibling asked about [`clap`](https://github.com/kbknapp/clap-rs) -- `structopt` is a `derive`'d version of `clap` that captures arguments as structs for even more automatic parsing. It's kind of like the awesome [`serde`](https://github.com/serde-rs/serde) serialization library for CLI args! :)
what is the difference between stdout and println!
I think the short answer is that the `owning-ref` crate can do what you want, though hopefully there's a way to restructure your code so that you don't have to do this :) https://github.com/Kimundi/owning-ref-rs (specifically https://kimundi.github.io/owning-ref-rs/owning_ref/struct.OwningHandle.html) &gt; If I have a RefCell&lt;T&gt;, I can save a Ref&lt;T&gt; that can be coerced to &amp;T. This is sort of true. You can save the `Ref` in any variable or container that has a strictly shorter lifetime than the original `RefCell`. In that sense, the same rule applies in the 2x case: You can save the second `Ref` in any variable or container that has a strictly shorter lifetime than the first `Ref`. Out of curiosity, what are you building?
It's so that spammers have a harder time figuring out the voting algorithm.
Have you taken a look at the docs for `stdout` and the `Stdout` object that it returns? - https://doc.rust-lang.org/std/io/fn.stdout.html - https://doc.rust-lang.org/std/io/struct.Stdout.html The short answer is that `println!` prints something immediately, but `stdout` returns an object that implements `Write`. But they are indeed talking to the same pipe, and using a lock behind the scenes to coordinate control of it.
I have been reading through this codebase and I have to admit, it's really well documented and is easy to navigate through. Thanks for this and the whole impl initiative!
The time crate is all of the stuff that used to be in std::time, but we didn't feel was good enough to stabilize. It's basically abandoned; it's the last crate in https://github.com/rust-lang-deprecated/ from that process and in the last two years, nobody has claimed it.
I checked the documentation. Couldn't find anything about curl::HTTP but I found curl::easy::Easy which I was able to make it work.
I have been using plain Hyper lately, and have built a tiny router on top of it. I gotta clean the code up and actually release it sometime :)
Cool, thanks :) Looks like it uses raw pointers almost exactly like I'm doing already though. Thought it maybe could be achieved using safe rust, without third-party crates. I'm basically doing some 3d graphics :)
Haha if I earned QOTW I'd be the happiest nerd
That's sad, ".seconds()" is a lot cleaner than "from_secs", and SQLite only implements stuff for TimeSpec. But hey, I'll try to move to std::time then, can't be too hard.
Good chance you've already considered this, but just in case: when you have a set of shared objects, and multiple other collections that want to refer to them, it's often easier to just put all the objects in a shared `Vec` (or [slab](https://github.com/carllerche/slab)) and replace all the references with indexes.
I believe that the reason that Dropbox Paper was used for this was because the Rust developers have been using it for a bit now for collaboration and decided to extend the experiment to a more widespread audience. Given the amount of resistance encountered so far I'd say it's relatively probable that something else will be chosen in the future, though of course I'm not the one making the decisions.
&gt;Anyway, here's a more practical way to prevent deadlocks: don't use locks, and use lock-free data structures instead (those are implemented with atomics). They have constraints and tradeoffs though, and aren't necessarily better than locking data structures. Anyway see this excellent post written by /u/ticki_ that describes an atomic hash table. An excerpt &lt;3
&gt; Namespaces would also allow for cleaner forking of crates w/o some releasing serde2 &gt; I don't consider that a desirable feature, and has no bearing on the typosquatting argument. For the record, there are plenty of advantages to namespaces, and I think crates.io will get them someday, but I tire of claims that namespaces will solve every problem under the sun. Disagree actually, I think it is germane to typesquatting, but it actually makes it worse. Firstly, namespace make names longer and the longer the name, the more opportunities arise for making a typo. Secondly, and more importantly, if there's an ecosystem of forks and it's common for people to be using various namespaced versions of common packages, it becomes very difficult for a newcomer to a package to figure what the mainstream or "blessed" version of the package is, and very easy for them to be tricked or accidentally use a malicious version of the same package. 
Have you tried chrono?
&gt; the reason that Dropbox Paper was used for this was because the Rust developers have been using it for a bit now for collaboration and decided to extend the experiment to a more widespread audience `true`
bindgen is under very active development, maybe file some bugs?
It would be most helpful if you would help in bindgen development by fixing the specific things that are broken for you, you could get people mentor you too: "Hi! We'd love to have your contributions! If you want help or mentorship, reach out to us in a GitHub issue, or stop by #servo on irc.mozilla.org and introduce yourself."
Especially now that Impl Period has started: http://fitzgeraldnick.com/2017/09/21/come-hack-on-bindgen-with-us.html
Sadly, I think that chrono is in a dire need of some love too. It's basically in a transition phase where it uses the types imported by `std::time` and the `time` crate, and trying to deprecate the latter, but there seems to be no one that would roll their sleeves and do the work, so it has been in that limbo for a long time. Nevertheless, it's the de facto standard of 3rd party time crates.
has there been any consideration to adding a few convenience functions to `std::time`?
Unfortunatelly, the goals of impl period are focused elsewhere than on C++ bindings.
I haven't heard anyone really talk about `std::time` in a long time. That's not to say that such things were rejected or anything, just that nobody has taken up the cause.
What level of familiarity with Rust should be met in order to help contribute? :D
Already did that. Still having some timeline estimate would be nice. Also trying to minimize problems takes some time (especially, if I do not want to include whole STL hell in bug reports).
Is it possible to get the source files somewhere? Or a writeup on how to create those quickly?
You're assuming they were created quickly.
Also I would expect some better answer than: "File some bugs." Especially since bug filing is nontrivial, since here we want to do some root cause digging and file better bug than "this big chunk of C++ does not work". I am more looking for answers like: - Will bindgen support STL anytime soon? - Will bindgen support share_pointer anytime soon? - Will there be reasonable support for destructors (especially in composition of things)? If answer to things above is no, then I will move to writting C wrappers.
The best thing you can do is file good issues with bindgen that have standalone test cases and steps to reproduce :) https://github.com/rust-lang-nursery/rust-bindgen/blob/master/CONTRIBUTING.md#using-creduce-to-minimize-test-cases General advice: whitelist the bare minimum of things you need, make all of `std::.*` opaque. &gt; It is mostly quite easy C++ code, no heavy templates usage The STL is full of heavy template usage, so even though a particular class might look simple, if the header is including STL files, and the simple looking class contains STL things, then it almost assuredly is not as simple as it seems. &gt; Unfortunatelly it fails bindgen tests The tests that `bindgen` emits to assert that we generate the correct size, alignment, and field offsets? If you could create a standalone, reduced test case, that would be very valuable! &gt; also misses important destructors for many classes (mostly shared_ptr, which is used quite a lot in CNTK). My hunch is that these destructors are inline functions, which don't typically end up in object files with symbols that we can link to reliably. We need to document this catch better. &gt; Now, my question is: Is there any change that bindgen will get better in generating C++ bindings I know I sound like a broken record, but: the best way to help bindgen get better at generating bindings to the C++ you're dealing with is to file issues with good test cases for those hiccups you're running into :)
You're assuming they were assuming they were created quickly. However, I think they just wanted to know if it would be possible to get a writeup on how to create them quickly.
One of our goals is fuzzing to uncover hidden bugs where we do things like generate incorrect layouts, and fixing those bugs. If you have code that triggers layout tests to fail, then we've just skipped that first step and can move right into the second step!
Interesting! I wonder if you'd consider joining the [rustup working group](https://paper.dropbox.com/doc/rustup-mngGQUtX1UkBay3wgOGJi) during the impl period, to see if you can influence the direction of rustup itself.
I was thinking of something that does both of these things. Basically, a bug with almost exactly the original post: "Hey I am trying to use bindgen to wrap this API, but some stuff is missing. Is this stuff in the works?" This is because bindgen is some library; a bug report is a quick way to actually talk to the maintainers, who may or may not read this. I can't give you any definitive answer to your questions because, well, I don't work on bindgen. In this case though, /u/fitzgen did see your posts, so it worked this time!
Thanks for reply! I made whole std::* opaque. Already filled two bugs (one of them is unfortunatelly with std::map, did not know how to reduce it further). 
A couple reasons: 1. The lib usually has more modules (as Steve suggested in a sibling comment, the binary almost always has only a single file). 2. You can have multiple binaries, which can all live in `/bin`, but a cargo package can only have the one library. 3. It works out of the box with cargo, whereas cargo doesn't by default know where to look for the library except `src/lib.rs`.
I want to second aturon's comment. Now is a great time to have a big impact on what happens with rustup in the future.
&gt; Especially since bug filing is nontrivial, I mean... so is fixing bugs, so is supporting *all of the STL*. Making progress requires *hard work* from *everyone* involved here, but its the only way to improve the situation and make progress :) &gt; Will bindgen support STL anytime soon? Likely not anytime soon, since the two projects that are most invested in bindgen (Stylo in Firefox, Servo's usage of SpiderMonkey) are C++ code bases that have histories from before the STL existed, and so have grown their own alternatives, such as MFBT (Mozilla Framework Based on Templates). The STL is starting to make appearances here and there in the code, but generally we haven't needed workable bindings to STL things, just needed to make sure that types that contained STL things ended up with the right size/alignment etc. Also, so many STL functions are inline functions, which creates a situation in which our hands are fairly tied. &gt; Will bindgen support share_pointer anytime soon? I don't have anything specific to add for std::shared_ptr. Similar situation. &gt; Will there be reasonable support for destructors (especially in composition of things)? As long as the destructors are not inline, then this should be pretty robust already. If you can file an issue where it isn't working for a non-inline destructor, that would be very valuable.
Looks like next year should feature a stdlib blitz.
Thanks for answer! How should I write this match statement? Can not find appropriate example on the Internet...
I'm not aware of any issues with the ASTs that libclang provides for C types off the top of my head, but it wouldn't surprise me. I've found issues with templated aliases in the past. The best thing to do is what you've done: file issues upstream so they have a better chance of getting addressed and we can find out when they're fixed and can stop working around them.
No problem :) But really, bindgen isn't *that* big: $ tokei src/ ------------------------------------------------------------------------------- Language Files Lines Code Comments Blanks ------------------------------------------------------------------------------- Rust 46 23260 16705 3848 2707 ------------------------------------------------------------------------------- Total 46 23260 16705 3848 2707 ------------------------------------------------------------------------------- 
In the web version, just add a visibility to the name field. E.g. for [the point example](http://vestera.as/json_typegen/?example=point) enter "pub point" or "pub(struct) point". The same thing works for the macro and CLI in the code in the master branch, but have not released it on crates.io yet. Hope to get that done this weekend. Feel free to [open issues](https://github.com/evestera/json_typegen/issues) for any further feature requests. Can't promise speedy implementation, but feedback from actual users is always useful and of course taken into consideration. :)
Ownership can be thought of in some sense as "what am I responsible for freeing when I am freed", and it is static by type. A Vec is always responsible for freeing exactly its own buffer, and calling free on anything within it. (`for item in buffer { free(item) }; free(buffer);`). For it to be aware of any further things to free, all the various items within would have to somehow track the items they point to and know when those can be freed. What there are a pointers to multiple strings? Or pointers to other slices of strings? Or pointers into special stream buffers? Or strings that have multiple vectors pointing inside them? Some kind of GC would be needed to manage such a general case. Perhaps in this case you might thing it would be easy to track, but shared ownership is fundamentally complex in the general case.
Thanks for those answers, super helpful! Re destructors: I understand the inline destructor situation, there is probably not much to do. What about: class A { public: ~A(); }; class B { public: A x; }; It would be nice to have ability to invoke A destructor by destructing B. (I know that you are against automated Drop traits, but maybe making that configurable would help a lot).
For practical use right now, what I would recommend is using bindgen with everything opaque (that should make it much more likely to get the right sizes for types), with method and function generation turned off, then use the cpp crate to call C++ methods/functions. This has worked out really well for an unreleased project I'm working on that binds to a C++ library that even makes heavy use of shared pointers.
We're happy to mentor! From the OP: &gt; Don’t be shy—we want and need your help, and, as per our roadmap, our aim is mentoring at all levels of experience. To get started, say hello in the chat rooms for any of the work groups you’re interested in! Alternatively, hit up the IRC channels linked from the sidebar here (perhaps start with #rust-internals) and see if anyone has any beginner issues on hand.
Check out [structopt](https://github.com/TeXitoi/structopt) too.
That looks good. Do you have any examples/pointers to give me some faster start? (better than link to cpp crate)
After looking at a couple of videos about the stack/heap concept and the allocation process in c (malloc/free), I'm kinda starting to "get it". I don't think the concept is difficult. (or understanding the basics) Thinking in the abstract, it seems to me that managing memory will be an incredible hassle full of errors. Given that a standard solution will lead to the GC solution, then it seems to me that C developer are managing the memory of each allocation alone? This doesn't seem efficient and I can see how this could go terribly wrong with a newbie. The Rust ownership/borrow model looks simple from a "first look". But I guess I have to get my hands dirty on some code first before making a final claim.
After looking at a couple of videos about the stack/heap concept and the allocation process in c (malloc/free), I'm kinda starting to "get it". I don't think the concept is difficult. (or understanding the basics) Thinking in the abstract, it seems to me that managing memory will be an incredible hassle full of errors. Given that a standard solution will lead to the GC solution, then it seems to me that C developer are managing the memory of each allocation alone? This doesn't seem efficient and I can see how this could go terribly wrong with a newbie. The Rust ownership/borrow model looks simple from a "first look". But I guess I have to get my hands dirty on some code first before making a final claim.
I stumbled upon a few videos on youtube. I would not say they were "perfect" but kinda did the job. There is also a video about Box&lt;T&gt; but am on mobile now and can't get a youtube link.
It would help a lot if you post the actual error message?
I see, that makes sense.
Yes, in C you manually manage it. It's very error prone, and some people just cheat and use reference counting (which is a poor man's GC). Try Rust, I think you'll find it's as low level as C with some extra bells, but without any of the foot guns (in safe rust at least). If you find your self missing the GC, but liking the type system, look at scala or Haskell in particular. 
I kinda fall in love with rust a few months ago. Not going to cheat on it very quickly.
Take a look at the `match` example here: https://rustbyexample.com/custom_types/enum.html
I'd love to know too. I still didn't entirely grasp the difference between the two.
There have been some reports asking whether this is on-topic, so allow me further elaborate upon the on-topic policy: 1. If the article mentions Rust by name, or 2. If the article mentions a software project predominantly written in Rust by name Then it is on-topic enough to allow upvotes to decide its fate. In particular, rule 2 there is why posts about Redox, Pijul, TikV, et al have always been allowed despite often not mentioning Rust. (These two rules do not necessarily exclusively define what is on-topic on /r/rust, although I don't have any counterexamples in mind right now; please continue reporting posts if you think they might be off-topic.)
So I'm looking for a way to "print out" details about the variables I'm working with. One way is to do println!( "{:#?}" ); Which prints and formats the value of the variable. Except that I think it'd be better if there is a way to display the "type" of the variable (and maybe sub-variables for a struct/enum type). So instead of printing only the value, it also prints the type. Something like that u32&lt;5&gt; I found this: https://stackoverflow.com/questions/21747136/how-do-i-print-the-type-of-a-variable-in-rust But isn't this useful that it should be in the "prelude" libraries? 
Does `spawn_server` ever return? The server future shouldn't return until shutdown.
This would be awesome. I'm building a Vulkan application and would love to use servo for GUI without jumping through the numerous hoops required for OpenGL interop. Of course, it'd be even nicer if webrender supported Vulkan directly so nobody has to reimplement everything it does.
I tried to use Rust's chrono library since the docs of time said it was deprecated and it was a pretty bad experience. I just wanted to time the execution of some parts of my code, as in, I pass you a closure, and you tell me how long it took to run. I searched throughout the docs for 15 minutes trying to figure out how to do this until I gave up and switched to the old time library where this turned out to be trivial ([`time::span`](https://docs.rs/time/0.1.38/time/struct.Duration.html#method.span)). I think "time" is one thing that C++ does right. They have a library of clocks ([`&lt;chrono&gt;`](http://en.cppreference.com/w/cpp/chrono), durations, rational numbers in [`&lt;ratio&gt;`](http://en.cppreference.com/w/cpp/numeric/ratio/ratio) using type level consts, etc), a library of very fast date algorithms [`&lt;date&gt;`](https://github.com/HowardHinnant/date/blob/master/date.h), and on top of that, timezones [`&lt;tz&gt;`](https://github.com/HowardHinnant/date/blob/master/tz.h). I really like this "layered" approach to time: one can use times and dates without having to buy into time zones. On the other hand, using Rust's chrono, it seemed like I had to use timezones just to time the execution of a function... which is just overkill. A lot of information about the design and use of C++'s date and time libraries is excellently summarized in this document: https://github.com/HowardHinnant/date/blob/master/README.md C++ gets some things better than others, but a lot of people use C++ time and date utilities and it's one of the few C++ things nobody ever complains about. The design is impossible to use incorrectly without getting a compiler error, and extremely intuitive to use. We should just steal all of this, but since this is reddit, we can actually ask the author first if he would have done something there differently in hindsight. Invoking the master of time, creator of move semantics, `std::unique_ptr`, `&lt;mutex&gt;`, `&lt;thread&gt;`, ... author of libc++, and everybody's favourite aerospace engineer, /u/howardhinnant : with the hindsight of `&lt;date&gt;` and `&lt;tz&gt;`, would you have done something differently in `&lt;chrono&gt;` if you had the chance to start over?
/r/playrust 
Anyone know how cache friendly that parallel iterator is?
Invoked! :-) Yes. I would not introduce high_resolution_clock. Nobody knows what it is supposed to do, and it constantly gets used incorrectly. And I would ensure that minutes is 64 bits instead of 32. &lt;date&gt; is not actually standard. It is merely proposed right now. And using &lt;date&gt; with 32 bit minutes is prone to overflow if you stray outside of a few thousand years. Oh, and I would introduce the date stuff quicker than 6 years later. Although I actually tried to do that and got it wrong the first time...
Thanks for your insight; this is certainly an area where Rust needs to improve in the future, and hearing from people who've done it before is very helpful :)
There is no option to do this yet.
"quickly" as in "not painstakingly figuring out the basic techniques required to get those effects all on your own". ;)
... and still without heap allocation or unreasonable overhead. smoltcp should be quite usable in small server scenarios now, though there are some known issues with client scenarios, like lack of gateway support, or the thing where trying to connect to a host that is down results in a gigantic ARP flood.
First I tried to re-implement the library with the example shown above - which worked - but was really ugly (and as a the comments here pointed out, its not the proper way to do it). So I tried a few more different approaches and finally came up with the following https://play.rust-lang.org/?gist=49c64c1fab44be1570f6ced5dffbe93b&amp;version=stable which feels way more natural. Besides the copy&amp;paste of the (hopefully soon auto) delegated method calls, its smaller and way more clearer. The port is now done in that fashion (well, the actual structs are wrapped in Arc's but that is because of the libraries nature...)
thanks you for example, please, answer the last question: is it possible to get result (not the enum, but actual value that was returned) outside `match` statement? Or should I just write different cases for all possible types?
As a collaboration device that might be fine - I really don't have anything to say about that. But as a publication device Dropbox Paper seems to be a total failure. It seems to break A LOT of mobile users.
&gt; Yes. I would not introduce high_resolution_clock. Nobody knows what it is supposed to do, and it constantly gets used incorrectly. Thanks for answering! Can you elaborate on this? I've only used two `&lt;chrono&gt;` clocks: `steady_clock` for when the time must be monotonic for correctness, and `high_resolution_clock`everywhere else because... well, tbh I don't know. In these cases I don't care that much about the clock as long as it appears to work and I haven't bothered to learn the trade-offs between `high_resolution_clock` and e.g. `system_clock`. &gt; &lt;date&gt; is not actually standard. I thought it would be part of the standard by now, you have had the date header in your github for years, so that's what I've been using. The only other C++ library for dates that I know is Qt and... I am not going to bring all of Qt in as a dependency when yours is one single tiny header that works great.
Generally speaking, the parallel iterators just bisect the input, so each job ends up with a continuous block to work with on their own. That's not counting any outside data that the `map` closures/etc. may reference. In this case, the input is just a range, so there is no real cached data to speak of, but in the `map` they all share the same `&amp;cam` and `&amp;world` data. Hopefully that will be cached well, but rayon doesn't know anything about it. There's a sort of hidden input for the `collect()` output vector, which is also getting bisected and written by separate jobs in continuous chunks.
If you just want the length do something like let len = match result { DecodingResult::U8(v) =&gt; v.len(), DecodingResult::U16(v) =&gt; v.len(), }
fwiw, I've written about this as well: https://robigalia.org/blog_drafts/2016/12/23/what-time-is-it.html
I submitted the first proposal only in May 2016. I wanted to get some field experience in before trying to standardize it. Standardizing without field experience is a classic mistake both within the C++ community, and in other communities. The committee wasn't even able to look at it until a year later because it was overwhelmed with getting C++17 out of the door. Just wrote the following about the differences between the `&lt;chrono&gt;` clocks today: https://stackoverflow.com/a/46365721/576911
This thread is a goldmine. I’ve been writing a raytracer in Rust as a hobby project and it’s interesting to see the similarities and differences. I initially tried rayon for parallelization but ran into issues which I couldn’t figure out, so I switched to a manually multi-threaded model with one thread per cpu core and each thread pulls a “row” off a queue to render and adds the result to another queue for joining into the final image once all the rows are done. It works pretty well but it’s not particularly elegant. I’m motivated to give rayon another shot. :) 
Wrong subreddit. You want /r/playrust.
Yeah it was iOS opening in the Dropbox mobile app.
Thanks! That link is very helpful! In particular the bit about `is_steady` in the comments! I have indeed been using `high_resolution_clock` "wrong" all this time. In the sense that I was only differentiating between `steady_clock` and `high_resolution_lock` which... makes no sense. I should have just used `steady_clock` instead.
A wonderful glitch indeed; and I'm talking about the one that made you post this here. You are looking for /r/playrust
im a dumbass
That an IDE is heavier by definition.
I'm not sure I understand your questions. Code examples of what you're trying to do would help us give you better answers. I *think* you're asking something like this. "How can I extract a value contained in an enum, when different enum variants contain different types of things?" And indeed, you can't just return the contained value in each branch of a match, because then the value of the match expression wouldn't have a consistent type. You have a few different options. You could convert each branch into the same type somehow. (/u/corbmr's example does this with `len`.) You could declare all but one of the branches `unreachable!()`. Or you could move all the code that uses each type into the match, so that it doesn't need to return a value.
This is great!
This is not the Rust you are looking for. You want /r/playrust.
Shouldn't it be a smolARPflood?
I think the error message came from using an outdated tutorial. Like I said when I opened the documents couldn't find anything about curl::http but I found curl::easy::Easy which worked like a charm.
You're looking for /r/playrust :)
I think the main reason why there isn't more demand for that feature is that before too long you'll get used to knowing the type of every variable and expression. Rust is statically typed and doesn't (with few exceptions that aren't helpful) preserve type information at runtime. So if you don't know the type of a variable, you must use a compiler error to inspect it For example, `let mut test = mystery_variable; test = ();` 
I'm unfamiliar with this sort of thing. Is there a motivating example?
Fighting with the borrow checker is kinda painful at first - build up your vocabulary! The thing that helped me the most was being able to put to words each line of code that I was writing in Rust that I picked up from watching Aaron talk about his code. If there's symbology you can't put to words, odds are you don't fully understand what that code is doing. It's a little tedious at first, but so was every language before it became second nature. Also helpful is knowing where the IRC channel is. `irc.mozilla.org` `#rust-beginners`. Super awesome people in there.
Recent CCleaner exploit: - stage 1: corrupted CCleaner binary reports host information to command server, and allows downloading binary. - stage 2: downloaded binary connects to command server and infects host with a "fileless" "thingy". - stage 3: "fileless" "thingy" does stuff on infected host (unknown, AFAIK the fileless payload has not been recovered yet). Some determined attackers have extensive resources and know-how at their disposal. DDC raises the bar, but it doesn't eliminate the risk.
`Stdout` can also be locked manually which significantly increases throughout for repeated printing but blocks other threads attempting to use it (and could cause a deadlock with `println!()` invocations in the same thread since I don't think it's reentrant).
This looks really interesting! Exposing the api to reassemble tcp streams from packets would be amazing.
If I may suggest, in the README it's not quite obvious which features are supported/planned/not support (the "bold" not does not necessarily stand out). It may be better to have subsections in each of the main sections (supported/planned/not supported).
And RFC 2000 is going to be accepted (Const Generics, how appropriate that it gets such a number!)
smoltcp is a network stack. So the main motivation is to embed it in operating systems. Someone is currently trying to embed smoltcp in Redox for example. Also, it can be pretty useful for embeded devices that needs a minimalistic networking stack, since it can work without heap allocation. Maybe /u/whitequark already uses it in other projects?
I often build dormant 3rd party projects that require `nightly` and getting them to build again is really hard. `Cargo.lock` doesn't record the compiler version and just saying `nightly` isn't enough information. One has to infer it from the commit dates and then do some git-bisect like magic to find (maybe, just maybe) the compiler that the person was using. The next one, is that someone could have a `build.rs` that contains malware. It might be nice to generate containers (rkt, docker, etc) that contain the toolchain and record that container hash in `Cargo.lock` or the `rustbud-build.log` 
To provide a counterpoint to the other commenter, the main reason I believe this isn't more widely available is that no one's bothered to tackle it. [It's definitely on the wishlist](https://github.com/rust-lang/rfcs/issues/1428) to make this available in some form or another, if only for debugging. If you have some ideas to contribute, please feel free. This feature definitely appears to require a champion.
Could you wrap CNTK with C++ code that bindgen _can_ generate bindings for? Seems easier than manually creating a C wrapper.
https://github.com/sappworks/sapper
that's not it
Obviously this doesn't help existing dormant projects that don't document which version of nightly they work with, but in a world where rustbud was widely used, I would expect projects that use nightly to use a `rustbud-spec.toml` like: [toolchain] channel=https://static.rust-lang.org/dist/2016-07-09/channel-rust-nightly.toml ...which documents which Nightly version is supported, and makes it easy for contributors to set up a compatible environment. The idea of setting up a container rather than just a directory is nice, but although that would make automated building fairly simple, it would make interactive development much more difficult: I want to set up an environment then start my editor and my terminals and have all my usual configuration and conveniences available, and containers (particularly Docker) very deliberately make that difficult. That said, it probably wouldn't be difficult to build a `rustbud-lock.json` → Dockerfile converter, and that kind of extensability is exactly the reason I decided to make lockfiles use JSON.
With rustdoc, we can embed code examples into doc comments in source files and have them be compiled and executed as part of `cargo test`. Is it possible to do the same with regular markdown files? Is it even possible to have rustdoc render separate markdown files, with or without embedded examples? The use case here is for longer-form prose documentation (eg. getting started guides, migrating-from-$TOOL guides, etc.). It would be nice to have code examples in such files compiled to prevent them from getting out of date. If rustdoc can't currently do that, what is the recommended way to write such documentation?
&gt; (`.for_each` is nightly only) It's stabilized now :-] https://github.com/rust-lang/rust/pull/44567
Have you seen [Shio](https://github.com/mehcode/shio-rs)? I use it for a small API in production.
I would check out [Shio](https://github.com/mehcode/shio-rs). It's a very small interface on top of Hyper 0.11 designed to make writing asynchronous web applications simple.
[RFC 1990](https://github.com/rust-lang/rfcs/blob/master/text/1990-external-doc-attribute.md) which adds support for including markdown files was [just approved](https://github.com/rust-lang/rfcs/pull/1990) a few days ago, and it looks like [work is moving forward](https://github.com/rust-lang/rust/pull/44781) as of just a few hours ago.
After learning Rust, it's impossible to learn C++. Nothing there makes any sense anymore. :/ Just kidding. Well... sort of. :D Since Rust is the young and new, there are not that many people that started with Rust and then want to learn C++. Rust evangelists are focused on the opposite road: making someone that knows C++ (or something else), learn Rust quickly. Generally if you know Rust, you should have much easier time learning C++, than someone that doesn't. However be prepared for a lot of disappointment. Head to r/cpp , and see what they recommend as a modern learning resource. Edit: They link to this: https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list in a sidebar.
what does it have to do with rest api?
There are a ton of c++ resources out there. You are overthinking and over-complicating yourself.
I've found a lot of the talks from the past few years of CppCon to be very interesting. https://youtu.be/LDxAgMe6D18
It'd be interesting to try and compile the [benchmarksgame-rs](https://github.com/teXitoi/benchmarksgame-rs) entries with mrustc to compare performance.
I look forward to reading your future blog post on "Learning C++ from Rust"!
Is there a way to splice an identifier into an expression in a macro? I'm trying to use a destination `vec` as a string as a key for a `HashMap`. For example, what I want to be able to do is: macro_rules! push_into { ($tovec:ident) =&gt; ( for s in lookup["$tovec"].split(' ') { if some_condition { $tovec.push(s); } else { $tovec.push(s.some_transformation); } }); } Using `format!` doesn't work because it uses (sanely) the variable value rather than the variable name.
Diesel needs to know the exact schema of the database you connect to. What better way to get the correct schema than to ask the database for it? You can use `diesel print-schema` (using Diesel's CLI tool) to, well, print the schema Diesel infers from your database. As this is regular Rust code (using macros), you can just write it to a file and use it instead of `infer_schema!` in places where you can't/don't want to connect to a DB at compile-time. But, whenever you change the schema of your database, you need to remember to update this. 
It's a micro framework on top of Hyper that allows for a clean way of designing a REST API rather than using Hyper directly. I'm using Shio currently for a small REST API in production.
[Apocalypse of John](https://www.kingjamesbibleonline.org/Revelation-Chapter-1/) (King james translation) More seriously, I agree with others just jump in and go, Knowing Rust you'll write better C++ code than regular C++ beginners. Don't forget to : * delete your objects :-) * once you're a bit familiar with the syntax, get a good design pattern book, to see what to expect from typical OO code. 
`&lt;&lt; setprecision(4) &lt;&lt; setw(5) &lt;&lt; var` I want format!() back. Or printf, I'll even take that.
I started with Iron for a web app, then looked at the executable size and thought: "Screw it, I'll just use hyper directly". And it turns out I don't need most of the stuff Iron offers to make the web app I need.
how much smaller?
There is a guide to Rust for C++ Programmers. Just read that "in reverse". As for a book like the The Rust Programming Language for C++, that book is probably styled after "The C Programming Language" by Kernighan and Ritchie and the similar "The C++ Programming Language" books. These are authoritative, easy to get into, and will cover all the core features of the languages as concisely and elegantly as possible. I'd suggest starting with "The C Programming Language", and learning to write object-oriented code in C, before moving onto "The C++ Programming Language". Although their STYLES have diverged a lot, I think anyone working with C++ should have a strong foundation in C first.
There being sooo much reference material for C++, a lot of it mediocre or outdated, does in some ways make it more difficult for a newcomer to ramp up. Try searching for C++11 or C++14 to get relatively modern stuff.
Maybe I end up with couple of helper methods to implement things, which bindgen fails to do (e.g. destructors for shared_ptr, ...).
Yes :)
That is awesome. We are very much in agreement. I think having the build tooling call a container for `build` and `test` should be doable. I don't think I was advocating for everything to live in the container (editors, etc). I have definitely used command line compilers embedded in containers, you can map the CWD into the container so it has access to the whole file tree.
could be useful in scenarios like https://en.wikipedia.org/wiki/Unikernel
The best I've used is Java's standard [`java.time`](https://docs.oracle.com/javase/9/docs/api/java/time/package-summary.html) library (note: this is not the old and incredibly broken `Date`/`Calendar` types). The `chrono` crate seems superficially similar to it (or more likely its predecessor, JodaTime), which is a good thing.
There's a "[Short intro to C++ for Rust developers: Ownership and Borrowing](http://nercury.github.io/c++/intro/2017/01/22/cpp-for-rust-devs.html)"
You can always just `#include &lt;stdio.h&gt;` and use `printf` if you miss it that much.
Are you looking for `stringify!($tovec)`?
learncpp.com is all you need Edit: So far, couldn't find anything better, that website is up to date and it shows the language step-by-step with a lot of examples ;)
I certainly agree that something along these lines would be a good teaching tool and convenience for writing error messages. (Particularly in macros.) 
I guess it would be. Thanks.
It's already exposed, look at storage::RingBuffer and storage::Assembler.
Yes, we use it in [ARTIQ](https://m-labs.hk/artiq).
All features are divided into "supported" and "not supported as of yet". There is no protocol feature that will explicitly never be supported by smoltcp, it is a matter of implementation. I'll see what I can do to improve readability.
The smol TCP stack that could.
Since you already know the basis of working with memory (dynamic vs static allocation) I'd recommend starting with some "intermediary" books about C++14/17. What I'd go with is: Effective Modern C++ (Scott Mayer) and C++ Concurrency in Action (Anthony Williams)... the 2nd edition of the later will probably be out by November, so if you're taking this learning experience slowly you may as well read the former and wait for a bit until the more up to date version is out. Both of these are great in the sense that they will make you have the right questions in mind once you are finished reading them, or, at least, that was their effect on me. Finally, keep in mind that RUST and C++ aren't so different, in my opinion the main differences between them are: * You can pass &amp; in "unsafe" ways and the compiler may not warn you. * Initializing, copying, moving and "destroying" (when something bound to a single scope exists that scope) are configurable actions, built into a type by the user rather than "deduced" by a compiler. * The compiler is mostly "unaware" of threading, there are some basic warnings for stuff like passing a reference to a thread, but overall it will let you do fuck all, be that clever or unsafe * Templates are Turing complete and you can do some really clever, "clever" and outright insane shit with them (for a primer read: Practical C++ Metaprogramming), however the amount of excitement over what is called "template metaprogramming" is mostly disproportional to its usage in real life scenarios * It has various OOP semantics built in the language (the most prevalent of which are inheritance and the virtual keyword), in 99.99% of cases their existence is a trap meant to produce runtime error and much better (and safer) design can be achieved with proper use of templates or common sense. * The default way to pass a value to a function is rust is to "move" it (change ownership of the value without modifying the underlying memory), whilst the default in C++ is to "copy" it (just copy the value and give access to the copy, not the original). However C++'s compiler will turn a large amount of "copies" into "moves" and much like you can explicitly and implicitly copy in Rust in certain cases, so can you explicitly and implicitly move in C++, however going deeper into this subject would require a few pages. Lastly, if you want to get "EXCITED" about learning C++ instead of the trendier, safer, arguably less complex and faster growing rust, I'd recommend watching this video: https://www.youtube.com/watch?v=6nsyX37nsRs It's a lot of filler but the mechanisms presented here, if implemented, are a great showcase of why the language has potential for greatness if the projects you undertake using it are complex enough. (Do note: These are my opinion, I'm presenting them as facts because writing "In my opinion" after each sentence got a bit tedious)
*Effective C++* and *Effective Modern C++*.
Pretty good, a nitpick is just that &gt; let mut f = match File::open("task.list") { ... }; works, no need to bind File::open("task.list") first
&gt; - It has various OOP semantics built in the language (the most prevalent of which are inheritance and the virtual keyword), in 99.99% of cases their existence is a trap meant to produce runtime error and much better (and safer) design can be achieved with proper use of templates or common sense. Gild-worthy
I can't remember correctly, so I won't provide any numbers. It's pretty easy to do a "Hello world" app in both and see how much of a difference there is between the two anyway.
I wonder if [cpp_to_rust](https://github.com/rust-qt/cpp_to_rust) would work better than bindgen for your case.
In most cases you shouldn't use manual new/delete. Rather use smart pointers. 
Looks, nice but I feel it needs more examples for dummies like me ;)
Better yet, C++17 since that has been more or less de-facto standardized for 1 year and some books are already written with it in mind.
There are libraries that implement `print("{}", x)`, I think one was called `fmt` but I'm not sure.
Agree, but the key is in the "Most cases". Most of the other cases I know from real world $$ paying jobs : * interfacing with an external/3rd parties libs. Hi Qt ! (tbh, I haven't done any qt for a while, it might be better with Qt5) (And ok, that remark is still valid if you want to write ffi code for rust). * legacy codebases written in pre-modern-c++ era ( the dude wants to learn c++ to find a job, does he ? ) * super-hyper-optimized code that can't avoid the cost off one more layer of indirection. 
You missed a bullet point about exceptions ... (I am just dropping this here). 
This may be of interest: [Rust for C++ Programmers](https://github.com/nrc/r4cppp)
Both C# and F# will compile and run on Linux now!
If you're just programming for fun... No need for safety :p That said, I transitioned from C to Rust really quickly. The only big difference is the borrow checker/lifetimes, and not having to malloc/free everything. I like Rust significantly more than C, something I never thought I'd say. The only time I've struggled with anything is Rust is trying to port my lisp interpreter from C. Pointers/raw memory are harder to work with due to the safety constraints.
https://crates.io/crates/mdbook is used for a lot of guide-style docs.
To be clear, you can run `rustdoc` on markdown files; it's that you can't use a separate file to be your function/module documentation.
Thank-you for my well deserved poke in the eye! Yes, I suppose in have an anti-MS bent that is stronger than I though. I honestly hadn't realised! Born of bring unable to get into the MFC libraries through Borland Owl! I really liked C#; didn't get into F# - and I miss the auto complete of VS IDE and those in VBA. (know a quant who doesn't live for spreadsheets - and hate those s/he has to maintain?). I tried an early MS Code ( IDE ) binary on my machine but it wouldn't fire up ( on Exherbo ). I'm trying to learn (to exit) Vim though; but I know it's not an IDE. If Haskell gives me grief, I'll have a play with F# for self-healing. It has a OCaml background, I seem to remember.
`#include &lt;cstdio&gt;` when you're in a C++ codebase please
I don't ever know what a borrow checker us! Something to do with credit checks or long division?! I hear the sentiment! I was a pre-sales fixer for a long while: if I couldn't explain something to someone, I didn't know what I was talking about properly. Thank-you for rust-beginners nudge. I couldn't see it on Riot/Matrix's IRC. Found Rust on Freenode. Is Mozilla the same as Moznet? Saved!
Something something something runtime! 😁😉
&gt; Nevertheless, it's the de facto standard of 3rd party time crates. Is it? `time` has more crates depending on it. And anecdotaly, I found `chrono`'s API a little bit over-engineered. While `time` just works for me ,despite its official deprecated status. It's closer to what I was used to in C, too.
Paul Walker says hello! Too soon? My coding probably isn't great! I really (really really) mean to get me some Rubycop sadism as soon as I get my Wayland/Sway working again. The console isn't cutting it. I can see this borrow checker is going to be an admirable foe. Someone else here (on phone or would tip a /u/) said something similar. My decent C code, the stuff I'm proud of, is on 5¼ floppy.. I was early twenties; it was an old 386 even then - marriage made in hell. I folded it in quarters for the more recent 1.44 floppy but it would be read it. Line end formatting issue, I guess. 😋 I'm probably going to try to rewrite that stuff in Rust for kicks. In my sharp '90 suit. Wish I could get into it. You guys are making me salivate for my rust fix!
[.NET Core](https://github.com/dotnet/coreclr#net-core-common-language-runtime-coreclr) is really not that scary. Certainly worlds better than the .NET Framework's CLR colossus.
I wasn't serious, but I know you know that!
Huh, I would have thought that features were divided into "supported" and "not intended to be supported", because the README states: &gt; *smoltcp* is missing many widely deployed features, whether **by design** or simply because no one implemented them yet. To set expectations right, both implemented and omitted features are listed. (bold added) "Omitted" doesn't suggest "will be included later", to me, but rather "intentionally omitted", and there's nothing, in the lists that follow, that indicate whether something is not supported by design or not supported because not yet implemented. At any rate "no protocol feature that will explicitly never be supported" and "missing many features … by design" are hard to reconcile.
The main reason I read project readmes is to answer the question "do I want to use this, instead of/in addition to the stuff I'm using right now, or to solve a problem I currently don't have a tool for". Positioning a project in the solution space relative to alternatives (in this case probably including my system package manager) is probably among the better ways to answer that question. ymmv.
Are there a lot of GO jobs? I've been trying to do the same of studying c/c++ to get out of webdev. 
Thanks!
Flow based programming as tool sounds awesome!
Thought this might be interesting to people here given recent conversations about security issues in Cargo. The issues are far from Rust-specific so it's worth seeing how other language teams face them. One thought I had in particular was a service that peer reviews packages and certifies them free of malicious code, plus more robust crypto signing of particular versions/downloads.
I guess you can say he didn't handle exceptions.
See also https://www.reddit.com/r/rust/comments/70aq3b/attackers_are_typosquatting_package_names_in_the/
Consider looking into orbtk from redox for GUIs.
&gt; While the default pip client utility is unlikely to ever implement typo detection due to the additional dependencies required, the higher level pipenv client (which also incorporates virtual environment management) has been enhanced to check for similarities to the top 1000 most popular downloads from PyPI and notify the user if the package they're installing is similar to, but not the same as, one of those names: Feels like this would be easy and very effective. Attacking unpopular crates will still be a possibility but with significantly fewer impacted users - still an issue for a watering hole attack though. I think in general it seems fine to say "this crate name is too similar to another" personally. Or, given incredibly similar naming, alert someone to audit the crate for obvious malice.
I don't want to borrow the coffee, I want to consume it. 😀☕
I'd suggest you look for Rust jobs as well as C++ jobs. There are more of them than you think. 
This reminds of a software we use at work for these purposes, called "nifi"
Wow, yeah, thanks for sharing. Looks pretty full on. I'll have to check it out :)
Thanks for the suggestion. Keen to learn more but can't see much information on the [github page](https://github.com/redox-os/orbtk). Do you know any resources for it?
Oh oops, that paragraph was written long ago when I thought that IP reassembly et cetera were unviable to do. I should just fix it.
CAnnOT MoVe OUt OF BORrOWeD CoNTEnT
I kinda want to write some of this at some point. The other day I explained "modern C++" move semantics &amp;c via Rust and it was fun.
 mem::swap(&amp;mut coffee, &amp;mut water);
error: type mismatch expected `Coffee` but found `Water`
I just love these duct tape rules which C++ is full of, which kinda improve the old things but not really. "Including cstdio imports the symbol names in std namespace and possibly in Global namespace. Including stdio.h imports the symbol names in Global namespace and possibly in std namespace." 
And I want to derive(Clone, Copy) it.
&gt; Copy This world has finite liquid. Don't be like your neighbors who use C++, manually invoke `clone` to make sure to not allocate more liquid than absolutely necessary.
&gt; Luis Name matches. OP is posting OC!
You need to reword your question then others will be able to help. Do you mean how to get the URL path for the HTTP request? 
~~stdio.h never imports anything into std namespace. It's not all _that_ complicated... &gt;_&gt;~~ Apparently it is... :-S
DON'T COPY THAT COFFEE!!! Sorry, I'll see myself out.
The C++ standard includes the libraries, which happen to be a few more than Go has, specially concerning generic programming.
 #[derive(Replicate)] &gt; Computer, Coffee, one cup, hot
That's the problem. I would read it's API docs. The developers don't seem as interested in promoting it, but it has a highly convenient API for UI design. It might be the best I've seen in Rust so far.
&gt; super-hyper-optimized code that can't avoid the cost off one more layer of indirection Unless I'm mistaken, C++'s `unique_ptr` is just as efficient as a raw pointer. But make sure you don't use it after moving it, because the type system can't help you with that.
expected `Beverage`, found `&amp;mut Beverage`
I personally found it more helpful to read Effective C++ before Effective Modern C++. My background: knew C and Java, attempting to teach myself C++. Effective Modern C++ mostly went over my head, its hard to use those features effectively when you aren't using them at all. Effective C++ on the other hand, immediately pointed out all sorts of things I was doing wrong on a regular basis. YMMV.
But there's no cargo so using any library is a PITA. And that's why "one header only library" is such a big thing. But that's why the libraries are usually very shallow in functionality. And you still don't get autoupdates, and ... For me, C++ is just unbearable anymore. Thankfully I get paid, any time I have to touch it. :D
As it is causing problems, we should fix them ASAP. Or, failing that, end the experiment and move the content to some page hosted at rust-lang.org.
Yep, great takes and more or less reflects my feelings. But really it all comes down to this: &gt; Oh the other thing is the whole company looks like a pump and dump ICO block chain company and I want nowhere near that space in general. This is just the icing on the cake.
With writing unit tests (using stainless), I often like to use the pattern #[cfg(test)] describe! thing { before_each { let mut thing = Thing::new(); } it "has some property on creation" { assert!(thing.some_property()); } it "loses property after modification" { thing.modify(); assert!(!thing.some_property()); } } Because of the way stainless works, the `before_each` gets effectively copied before each of the `it`s. This causes a compiler warning: warning: variable does not need to be mutable --&gt; src/thing.rs:31:13 | 31 | let mut thing = Thing::new(); | ^^^^^^^^^ | = note: #[warn(unused_mut)] on by default Unfortunately, annotating the `it` sections explicitly seems impossible. That is: #[cfg(test)] #[allow(unused_mut)] // has no effect describe! thing { #[allow(unused_mut)] // causes compiler error before_each { #[allow(unused_mut)] // has no effect let mut thing = Thing::new(); } #[allow(unused_mut)] // causes compiler error it "has some property on creation" { #[allow(unused_mut)] // has no effect assert!(thing.some_property()); } it "loses property after modification" { thing.modify(); assert!(!thing.some_property()); } } This has lead me to split my tests: #[cfg(test)] describe! thing { describe! immutable { before_each { let thing = Thing::new(); } it "has some property on creation" { assert!(thing.some_property()); } } describe! mutable { before_each { let mut thing = Thing::new(); } it "loses property after modification" { thing.modify(); assert!(!thing.some_property()); } } } But I dislike both the unnecessary extra level of nesting and the repetition of the construction code (which is sometimes not quite this trivial). Does someone who knows `stainless` better than I have any ideas for other ways I can get around this? I'm unwilling to `#[allow(unused_mut)]` for an entire module, since I find that in other cases it produces quite useful warnings.
I would totally do that if I wasn't taking a C++ college class.
Please add a license.
That was the answer I was looking for. Thank you one more time! P.S. Just an idea: I think if someone writes a blogpost about this types of match statement with explanation why language is designed in such way and what is common workaround it would be super useful for newcomers like me. Nor book neither Rust by Example site show where and how "extremely powerful control-flow operator called match" should be used. 
I'm going to start reading all compilation errors out loud in this fashion.
It was a birthday present! https://twitter.com/luisbg/status/911606749320417283 OP doesn't repost.
Good call! Will do. Tomorrow. BSD I imagine.
Well, I do admit it was the second C++ book I ever read, the first being a short primer by Bjarne himself, but at the time I was also coming too the language with only ~7 months of programming at my side and only in GC language which abstract over stack&amp;heap. My experience with it was that it made me research some of the behavior of features I needed to understand to get the examples in the books (e.g. you need to know how a mutex works to understand lock guard and how const methods work to understand mut) whilst explaining to me how some "modern" features work by replacing old ones I needed not concern myself with (e.g. nullptr &gt; null and enum class &gt; enum). So overall, I feel like someone familiar with RUST would already "know" a lot of the stuff from Effective C++, than again, I only ever glanced over that book and never fully read it, so my opinion isn't worth much. Than again, I could recommend over a dozen books, but I often find keeping the number low is helpful and those two are the ones I feel most strongly about.
Hey, you're right!
There's also plenty of jobs outside of web development that aren't C++. 
[removed]
You're looking for /r/playrust. This is a sub about the programming language Rust
How could I check if a file is hidden? I am on Windows. So I cannot just presume all hidden files are those starting with a `.`.
unique_ptr is 0 cost. shared_ptr is not.
*Well neither is Rust's `Rc`* *or `Arc`, so Rust and C++ are* *no different in this regard.* ______________________________________________________________________________ ^^^-english_haiku_bot
Oh my bad. Sorry.
let coffee: Coffee = water.into();
I didn't think Diesel required nightly any more? This is great otherwise!
Oops, my bad, it's the rocket.rs I'm using required nightly :D thank you so much, fixed!
Awesome :)
Maybe this is more what you're looking for? https://blog.rust-lang.org/2015/04/17/Enums-match-mutation-and-moves.html
With the `winapi` crate, you should be able to use `kernel32::GetFileAttributesW` and check against `winapi::winnt::FILE_ATTRIBUTE_HIDDEN`. ([official doc here](https://msdn.microsoft.com/en-us/library/aa364944\(VS.85\).aspx))
Thanks for the suggestion. After I started to add it in I was googling how to add OS specific code via the `cfg`, and came across `std::os::windows` in the standard library. In there is an extension which allows me to get this info without needing the `winapi` crate.
This is actually supported in the stdlib! You just need to import the windows-specific `MetadataExt` trait: use std::fs::windows::MetadataExt; let file: File = ...; // however you got your `File` let meta = file.metadata().unwrap(); // or handle this `io::Result` let attrs = meta.file_attributes(); // FILE_ATTRIBUTE_HIDDEN = 0x2 // https://msdn.microsoft.com/en-us/library/windows/desktop/gg258117.aspx let is_hidden = attrs &amp; 0x2 != 0; 
This subreddit is for the Rust programming language. You're looking for /r/playrust :)
How does this library compare to Hyper? Is it meant as a competitor? And does it use the new Http types crate?
I want one. Where can I get one?
I have no strong feelings on this but there seems to be consensus around dual licensing See https://rust-lang-nursery.github.io/api-guidelines/necessities.html#c-permissive EDIT: Oh, I guess it says BSD works just as well.
I like the colors you're using on your site. Styles for ::selection {} is missing btw.
Thanks man :D it not missing, it was intended to be black :D 
Can I order one? Where can I order one?
&gt; But that's why the libraries are usually very shallow in functionality. It also blows up compile time.
 let money: Money = water.into::&lt;Gold&gt;().collect()
I've pushed my latest work on this approach to https://github.com/dylanede/chrono-engine-rs.
You could consider using Qt with Widgets or QML(QtQuick 1 or 2). There was a recent Rust bindings generator support that KDE now maintains iirc. This gets you cross platform support that should look good/consistent across platforms. And **there are some add-ons for node/flow based graphs** I remember seeing. You can also mix the different types of UI I mentioned at the start, so traditional UI with a canvas or GL view, might even be able to open up a separate app window like Conrod and share the backend logic(not sure if OS will think this is more than one program in taskbar/dock or not). Web technologies might also be an interesting option with readily available libraries for providing node graphs, but probably not as nice to integrate or for performance I guess? With QML and Qt 5.10 or 11 I think it was(released later this year) they are providing hardware accelerated shape primitives for GPU powered canvas. I know that Substance Designer(popular artist tool with node graphs) uses Qt.
Sure, I don't have the files handy but I'll try to think about putting them online tomorrow. I am used to inkscape (and I am a very slow writer, especially in English), so making these didn't take very long in comparison with writing the post. That said I probably spent half an hour per illustration so it wasn't as quick as I'd like.
I once redesigned (well, prototyped) a C++ codebase to replace many header includes with forward class/struct declarations. Compile time (debug) halved. And this was a long time ago when the code was basically C with classes, without any templates.
Gone with MIT in the end. Up there now. Thanks for the link. Interesting to see.
Thanks for the response. Interesting to read. I felt that I'd seen that Qt was a hard fit with Rust but maybe that applies to most GUI frameworks as they generally revolve around mutating trees of objects. I suspect if I was more informed then a mixed approach of a traditional GUI framework plus an OpenGL canvas solution would make the most sense. I was keen to avoid a browser based solution as I wanted to keep a quick boot up time but perhaps a Qt solution with an integrated web view would be suitable. Thanks for the thought.
A shame! But understandable if they don't feel it is a in a good place for others to start using it as it then becomes a support burden for them.
aaah yes, The brightness of my monitor was so low :D
I am back! Thank you! No, now that i use .run instead of .spawn for the server, this did not return any more. I added a thread for the server. Now I am back to an error message where I have no idea what it means. 
I will joined the group. I will also ask there.
There's a `#[missing_trait_impl]` joke here, but ripgrep failed to find it in the code. Let's just say it's probably for the best that there is no `impl From&lt;Water&gt; for Gold`.
`time` is much lower-level than chrono. `time` basically allows to you to get timestamps and do very simple calculations on them. In particular, time has no notion of a calendar, or other human-centric views on time. Chrono is calendar and human focused. It has a wide range of formatting/parsing functionality and some more useful higher-level datatypes that allow more sophisticated calculations. It is also optimized for calendar-like operations, so it should be faster than `time`, even though it's also more ergonomic. That said, it *definitely* needs more love. lifthrasiir wrote it but I believe his work is consuming significantly more of his time than it used to. I am trying to keep the lights on by dealing with tickets (so it doesn't feel abandoned) and fixing things when I have time, which is unfortunately rarely. If anyone wanted to jump in and help out there is a _ton_ of obvious work do in chrono.
This line of the error message: &gt; = note: required because of the requirements on the impl of `std::marker::Send` for `&amp;&amp;engine::Engine` is saying that it is not safe to share reference to an `engine::Engine` between threads. Your example is very big and does not reproduce the error so... it is hard to tell. You can either clone the `Engine`s between threads, or make sure that access to them is synchronized by putting them behind a `Mutex`. There are some other alternatives but you probably want to start with the simplest thing that works.
It's hacky as hell but you could try creating a file containing the `allow` line, and using `include!("allow.txt");` where you want it in the code. The order of macro invocation might make it work? Or put those specific tests in their own inline module, and `#![allow()]` that? Either way, you should file an issue in the stainless repo
I've been wanting async websockets!
Ahh excellent
tk-http uses network buffers while hyper uses a streaming body. In my experience this makes tk-http much easier to build an API on. It doesn't use the http crate right now, but I think the tk-http devs were involved so I could see that changing in the future.
Thanks for the link, that's very similar to what I want to do. I will definitely have some questions on how you did things, especially in terms of how you designed the traits and structs (I come from a C++ background and am still getting my head around how to use Rust effectively)
Awesome work!
This source has quotations and says otherwise: https://stackoverflow.com/questions/10460250/cstdio-stdio-h-namespace
I can't help you, but surely the author can! cc: u/vandenoever
what are you talking about
You want /r/playrust
I saw your other post and commented there but you are in the Rust programming language subreddit. This guy has enough with C plus plus and came here asking for help.
Fyi, your cookie can't have a user_id in it beacause anyone could edit the cookie to be someone else. There seems to be a few crates to do session management on iron: rust-secure-session and iron-sessionstorage.
i realy don't understand why this won't work... i want basically what is given as "Example: Futures" from https://github.com/google/tarpc just without using ".handle(reactor.handle());" in the client options.
You can, if you ~~encrypt~~ sign it. That's the approach taken by Rocket.
Why can't you let the node have direct ownership of the interface and have external code only take references?
Ultimately, you are either trusting the client entirely, or you would need some kind of persistent storage. You would have to check the cookie value against what's stored and mark a cookie data in the persistent storage as logged out. 
It's been a long road. I'd love to find a cross platform solution that runs on rust. I know qt very well but haven't tried this cpp to rust project on mobile 
@retep998 How can you instruct cargo to pass `/SUBSYSTEM:CONSOLE,5.01` to `link.exe` during a build?
I wrote an app with qt which uses rust lib to do some fast processing. It was pretty easy to do once you get the hang of dynamic linking. I'm not completely sure if this is the kind of answer you were looking
Yo, I tried to do this a couple weeks ago and couldn't get it working. Just successfully built on Travis! Thanks dude!
I'm glad it help! :D 
I've not used it on mobile only on desktop. The last time I compiled a Qt / QML app for mobile was for my Nokia N900. Having said that, I can try to help with any issue you have. The rust-qt-binding-generator helps wit the binding between rust and Qt/QML, but you need to set up the build system yourself. I've written two blog posts on the subject and the source code has a demo application in `demo/`. https://www.vandenoever.info/blog/2017/09/04/rust_qt_binding_generator.html https://www.vandenoever.info/blog/2017/09/10/time_for_rust_and_qml.html 
I can't speak for Iron/Hyper but in rocket you would use the Cookies response guard in a route to get a cookies instance and then to create the cookie use something like: `cookies.add_private(Cookie::new("user_id", user_id));` This is encrypted to prevent the client from tampering with it. To check the cookie you could write a response guard for a UserID(String) type that checks the user_id private cookie exists and then use that guard in all your routes which require the user to be logged in. To log the user out you'll need a logout route that again uses the Cookies guard before calling: `cookies.remove_private(Cookie::named("user_id"));`
I'm not as familiar with qt stuff but I hope others in this thread can get you the resources you need to get started :)
I second employing peer review as means of mitigating these types of threats and using cryptographic signatures to achieve it. I expect many crates are independently audited by multiple entities. However, since these entities have no standard way of sharing their findings, these findings remain private. As long as liability is explicitly disclaimed, I'm confident that many entities that understand the value of opensource would also not mind publicly endorse crates they audited as means of driving development costs down (especially companies). A web of trust might not have been the best way for the general public to authenticate email, but it's a good fit for a software development peer review system. A cryptographically authenticated peer review system would also solve the authentication issues that plague the current system by replacing the requirement of trusting crates.io/github with trusting multiple entities instead. Also, offline keys!
No worries! I'd be happy to explain. I was also a C++ programmer before coming to Rust a few years ago, so I know how it goes.
Do you really need to store a Vec of lines? Or could you use string::split directly in the loop which eventually consumes that Vec? (Indeed, could you just read the file directly in that loop?) Reading files into strings is bad programming practice usually.
First, just as a basic disclaimer, I'm not someone specialized in computer/web security, and I might very well be missing something obvious - I only took a short look into Rocket's documentation just now. Grain of salt etc. Now that the disclaimers are out of the way, I have to say that this approach makes my security sense tingle. That is, at least if the user_id cookie is the only thing used to decide if a user is logged in or not. The encryption probably does prevent an attacker from making up a new cookie by guessing, but if some real user's cookie in any way leaks to the attacker, the user has pretty much lost their account, at least as long they can't get a new id. A Secure + HttpOnly cookie (so only sent over HTTPS and not accessible by JavaScript) can make leaking less likely, but I personally think the commonly used solution of generating a random session identifier, with some kind of session database stored server side, is more preferable.
Oh and if you find the build is so slow, consider add the cache to your config: cache: cargo
I've been a sub here for almost a month and jay finally realized this isn't the videogame rust it's a language. I've been tryina to figure out why nothing has related to the game lol
Yep, did that and rustfmt/clippy checks as well :)
I'm not sure any of the Rust bindings are mature, but have you looked at luajit?
Personally I prefer doing it the way you suggested; using a random session identifier. However I would also like to point out another alternative, which is the following: - You store user_id in encrypted form as suggested by others, BUT - additionally you keep an "expire" timestamp inside the same encrypted cookie (note: I'm *not* talking about the unencrypted expire property here, though probably it would have the same value, but as I said I'm talking about putting the timestamp inside of the encrypted data also). This expire timestamp encodes the exact time at which the cookie becomes invalid, say 24 hours, 7 days, 30 days, whatever amount of time you think is reasonable, into the future. When you get the cookie from the client you decrypt it and you first check the timestamp. If the timestamp is expired then you reject the cookie as invalid and redirect the user to the login page. - Furthermore, in order to avoid total compromise in case of a lost cookie, you require the user to provide their password again if whenever want to change any of the following: * Their password, or * Their e-mail, or * Any of their other important account details. - Additionally, consider making deletion of data undo-able for some amount of time greater than the time that a cookie is valid. So if someone has stolen a cookie from a user and the thief deletes user-data, the user can restore the data within the given timeframe. --- That being said, if you already are persisting user data (their password, their e-mail, etc) server-side I don't see any reason to do what I said above instead of also persisting random session identifiers.
Oh, I agree completely. It's just the decision makes for the project need to decide how important accurate authentication is. (putting it another way: if someone can easily spoof another user, how bad is it?) 
Tokens (like [JWTs](https://jwt.io/introduction/)) are the current state of the art for authentication--I don't think anyone's put together a crate for using these yet. The idea here is to cryptographically sign each session identifier with a secure hash, putting together both (and optionally some other data like expiration) into the cookie. This lets the site/service check the cookie to see if it's been tampered with. This would require a) the browser keep the cookie secret, and the site keep secret the key for the secure hash. You wouldn't have to store all of the generated cookies, but a blacklist may be a worthwhile add-on.
How is this compared to https://github.com/cyderize/rust-websocket ? 
I'm trying to extract a deserialize-from-file procedure into its own function, and I'm running into an issue with the explicit lifetime arguments. It works fine when I enclose the procedure in a block, so I'm confident there's nothing wrong with the actual lifetimes: let obj: CustomStruct = { let mut mem = String::new(); use std::io::Read; std::fs::File::open("data.toml").expect("Couldn't open file") .read_to_string(&amp;mut mem).expect("Couldn't read file"); toml::from_str::&lt;CustomStruct&gt;(&amp;mem).expect("Couldn't parse file") }; Yet in its own function I can't get the required explicit lifetime annotations to work: pub fn from_toml_file&lt;'de, 'ret, T: serde::Deserialize&lt;'ret&gt;&gt;(path: &amp;'de str) -&gt; Result&lt;T, Box&lt;std::error::Error&gt;&gt; { use std::io::Read; let mut mem = String::new(); std::fs::File::open(path)?.read_to_string(&amp;mut mem)?; Ok(toml::from_str::&lt;T&gt;(&amp;mem)?) } let obj: CustomStruct = from_toml_file("data.toml").expect("Couldn't deserialize data"); error: 10 | let r = toml::from_str::&lt;T&gt;(&amp;mem).unwrap(); | ^^^ does not live long enough 11 | Ok(r) 12 | } | - borrowed value only lives until here ([doc of toml::from_str](https://github.com/alexcrichton/toml-rs/blob/85a1c8a5d7d58f11d9057a592fcd8637c9e62b4f/src/de.rs#L67)) How would I do this correctly?
Alright, reading the docs again right after I posted this question, I noted the existence of `serde::de::DeserializeOwned` for this exact use case. So I just have to change the function signature from pub fn from_toml_file&lt;'de, 'ret, T: serde::Deserialize&lt;'ret&gt;&gt;(path: &amp;'de str) -&gt; Result&lt;T, Box&lt;std::error::Error&gt;&gt; { to pub fn from_toml_file&lt;'de, T: serde::de::DeserializeOwned&gt;(path: &amp;'de str) -&gt; Result&lt;T, Box&lt;std::error::Error&gt;&gt; { and it works fine. But since [`The DeserializeOwned trait is equivalent to the higher-rank trait bound for&lt;'de&gt; Deserialize&lt;'de&gt;`](https://serde.rs/lifetimes.html#trait-bounds), I'd still like to know how I'd do this with lifetime parameters myself.
Totally right! And it's probably easier to manage session state stored that way for whatever can be serialized easily and doesn't take too much space.
Rhai creator here. Happy to chat with you about ways you can improve Rhai. I haven't had time to maintain it unfortunately, so I'm happy to see others trying to push it forward For specifically going multithreaded, my cousin and I also worked on a language called ChaiScript (which inspired Rhai), which is multithreaded. You can optionally disable it for performance reasons. Not sure if any of the lessons there carry over, but it's worth a look.
I haven't tried to compile this but I'm betting all you need is pub fn from_toml_file&lt;'de, T&gt;(path: &amp;'de str) -&gt; Result&lt;T, Box&lt;std::error::Error&gt;&gt; where for&lt;'ret&gt; T: serde::Deserialize&lt;'ret&gt; 
Oh you don't have to use webview with Qt, they have QML which can give you some benefits similar to web, hardware accelerated 2D primitives(like rectangles or other shapes) on a canvas type of window. Rust has had some issues with Qt, but recently in the last month a new project came out that does a different approach with binding. [Here](https://www.reddit.com/r/rust/comments/6xwfxe/rust_qt_binding_generator/) is the r/rust discussion with link to website.
It compiles, thanks! I haven't seen `where for` before (or used HRTB's for that matter). I guess I should read the nomicon...
I think having a well-supported up-to-date contract library will be the best first step. Any addition to the rust language will need planning, a syntax, and an implementation. What better way to sandbox and work on these than a compiler plugin? -- In my opinion, what rust has now works plenty well enough. Inline documentation well documents what invariants each function must uphold, and tests (inline to the documentation and set below the code) verify this. Do test cases and documentation _not_ function well enough for design-by-contract? If not, what syntax would you imagine adding that could clarify things further than they already are?
This is exactly the sort of thing I need. I've been messing about with a combination of a `build.rs` and bash scripts in order to automate the build of a website built with Rocket. I'm gonna give this a punt and see how I go!
Is this project still active? I noticed that the last commit was 11 months ago.
You don't need to trust the client. Another option is to sign your token/cookie with some crypto-random private key. This has the advantage of not needing persistent storage, and should scale better to many users. On the other hand, you can't invalidate a specific token without adding persistent storage or invalidating all tokens at once(changing the private key)
If you're going with cookie storage, then there's no need to store anything meaningful inside the cookie itself, I recommend having the cookie be some sufficiently long and randomly generated string, that is stored inside the database along with the session data. e.g, the following database table: cookie| user_id| issued_at| expires_at ---|---|----|----| sfkDI0GJwrhy0ar815yhjhq4h| 1 | 09/25/2017 00:00 | 09/25/2018 00:00 mvaxkgdpkgjdj08ue08tj1cjN| 2 | 09/25/2017 03:00 | 01/01/1970 a client with the cookie 'sfkDI0GJwrhy0ar815yhjhq4h' is considered to be authenticated. a client with the cookie 'mvaxkgdpkgjdj08ue08tj1cjN' is not, because his cookie was expired.(in this case, manually invalidated by setting the expiry date early) Because a cookie is a long, random and opaque string, there's no way for an attacker to tamper with it or guess somebody else's cookie. Just ensure that the cookie is generated via a crypto-random secure RNG.
design by contract gives the language itself structure to catch even more errors. Contracts are not a replacement for Tests and vice-versa: both should be practiced seriously. i will humbly point you to two links for the same: http://codebetter.com/patricksmacchia/2010/07/26/code-contracts-and-automatic-testing-are-pretty-much-the-same-thing/ https://softwareengineering.stackexchange.com/questions/220726/contract-based-programming-vs-unit-test for a company, the whole point of "trouble of switching to rust" is anyway to make more "robust software" (just like jvm is more for portable binary, ..), otherwise we would have been comfortable in the existing platform ecosystem . isn't it? 
Which is exactly why somebody should start with a compiler plugin. You can't make an RFC proposing this feature if you don't even have a detailed design for what it would look like ;)
This is on my ten-years list – creating a lint that checks embedded contract annotations. However, some things have kept me from working on it so far: * there are still a lot of low-hanging fruit regarding correctness checks we can do even without annotations (I.e. more/better clippy lints) – this will likely benefit more code, as DBC may be powerful, but certainly not easy * the compiler internals are still in flux. Writing something that needs as much information about the code as a DBC checker would for now be an exercise in frustration * also, like clippy, it would only work on nightly, further restricting the code it may be applied to That said, DBC can guarantee correctness with regards to a specification. It cannot however rule out specification errors, only inconsistencies. Also many requirements can already be encoded in the type system with less hassle, so there is a rather large design space.
`#[allow(unused_mut)]` can actually be applied to `let` statements [as of last week](https://github.com/rust-lang/rust/pull/44590). (I presume you are using nightly already due to stainless.)
`#[allow(unused_mut)]` can actually be applied to `let` statements [as of last week](https://github.com/rust-lang/rust/pull/44590). (I presume you are using nightly already due to stainless.)
+1
You should give Nix a try.
&gt; I don't think anyone's put together a crate for using these yet. [TADA!](https://crates.io/search?q=jwt)
Thats a shame... Even amazon shows that it wont be released until March 2018...
*That* is good to know (and timely). I most not be as up to date as I thought!
This is the best thing ever 10/10 would meme.
Was a helluva weekend
You might want to look into [Adhesion](https://github.com/ErichDonGubler/adhesion-rs), another existing library for contract programming in Rust, which was inspired by D's. However, there are some rather nasty corner cases in DBC, which make a correct implementation very difficult; especially hard is handling invariants in a sound manner. See [this discussion](https://www.reddit.com/r/rust/comments/6ooinu/adhesionrs_v020_contract_programming_in_rust_with/dkjd3kc/) in which I pointed out one such issue to the author of Adhesion (who handled it very well). Properly handling invariants that involve impurity requires global reasoning that can be incredibly expensive, and may not even be possible in some cases.
Finally! I am completed now. 
Fun VS feature: are you familiar with the VS extension formerly known as Pex: https://msdn.microsoft.com/en-us/library/dn823749.aspx? It's like a white-box fuzzer, using a SMT solver to pick inputs that make the execution path go through new code. On the DBC side, there's also support for contracts: https://github.com/Microsoft/CodeContracts. It can use both static (via SMT) and run-time checking. I haven't used them much, but it you be better to implement that as a separate tool, since it tends to be on the slow side.
Newbie questions: are these contracts checked on compile time or at run time? And if on run time do they just panic? 
I'm looking into generating code from Relax NG schemas. For many programming languages this is not pretty. Rust has structs that may be tuples and enums that work as tagged unions. This makes the generated code mostly palatable. Blue sky goal: generate read/write/memory model code from Relax NG. Then use compile-time optimized XPath (via macros) to access data in a nice way. 
I'd resurrected my [icmp](https://crates.io/crates/icmp) socket crate and targeting to make it looks very similar to `std::net::UdpSocket` finally.
I'm looking into updating the [avr-rust](https://github.com/avr-rust/rust) fork to the current Rust master branch. The current fork is based off Rust from several months ago, and so once I merge my branch, avr-rust users will be able to use many more new Rust features
Might as well start learning Rust then. You are already part of the community. 
I'll spend the next four days mentally and physically preparing for RustFest, and then arrive tired, exhausted, and in need of much caffeine in Zürich. Also, I'd be happy to welcome new reviewers to Diesel! https://github.com/diesel-rs/diesel/issues/1186
From the readme &gt;Status &gt; &gt;Rote is basically unfinished and on hold indefinitely. The actual rule and task running works rather well, and is very fast, but the tool isn't fleshed out, nor is the Rotefile syntax finalized. This is not recommended to be used outside of experiments. &gt; &gt;I don't have enough personal bandwidth to work on Rote at this point, and Rote deserves more thought to be put into its design. I fully intend to revisit Rote in the future, as I believe it is something that is sorely needed today as a "spiritual successor" to Make. Lua may or may not be the right script language, though coroutines might make the run process faster. &gt; &gt;Go ahead and download Rote, try it out, see what you like and what you don't. I'd love to hear your opinions; I'm always listening via email (me@stephencoakley.com) or on Twitter (@sagebind). 
My experience of using contracts as built-in language feature in D makes me very skeptical of its general applicability. The very assumption that program can be sufficiently tested for programming errors (to the point when those can be removed and their violation becomes UB) simply does not hold for many (most?) application kinds. At work we ended up using custom library solutions despite the fact contracts are D built-in.
Hmm, I don't understand some of the emoji choices though. Increment makes sense, as does one of the "jumps" being a frog. I'd like to see the poop be "output", since it's what I tend to output every day. The rest seem arbitrary? Or did you have a reason behind the choices?
Perhaps they want to include some of the usability improvements currently pending and being fleshed out in the current impl period? I think the book would be a lot nicer if it included major language cleanups around NLL (non-lexical lifetimes), the modules/extern crate cleanup and especially impl Trait (along with the possible 'dyn Trait' sugar, but that might still be to far out). Those changes have a huge impact on learning the language for somebody who wants to get started with Rust.
I get this error: error[E0119]: conflicting implementations of trait `std::convert::From&lt;concat_ref::ConcatRef&lt;'_, _&gt;&gt;` for type `concat_ref::ConcatRef&lt;'_, _&gt;`: --&gt; src/concat_ref.rs:34:1 | 34 | / impl&lt;'a, T: From&lt;U&gt;, U&gt; From&lt;U&gt; for ConcatRef&lt;'a, T&gt; { 35 | | fn from(fr: U) -&gt; Self { 36 | | panic!() 37 | | } 38 | | } | |_^ | = note: conflicting implementation in crate `core` Where is the conflict? I suppose it has something to do with From but I can't figure it out.
I knew it was gorillas.
Sorry, I don't think From or Into is really applicable for this conversion, the official documentation on this subject calls this process transmutation: unsafe { std::mem::transmute::&lt;Lead, Gold&gt;(heap) };
Almost done with Tera 0.11: whitespace control, default args for macros and fixing quite a few issues too Next up would be (hopefully) finishing [Gutenberg's site](https://github.com/Keats/gutenberg)
Please, if you ever design a logo for the program, use some ancient Egyptian styling. It probably won't be *cool*, but I find the idea oddly satisfying.
I am trying to spawn a thread with the same lifetime as a struct / "object" - and am trying to do it the same way I would do in C++ and keep a handle to the thread as a struct member. But since JoinHandle&lt;T&gt; is a generic, it is a bit tricky to declare the correct type. Am I barking up the wrong tree here ? Is there an more idiomatic way to accomplish this, or an easy way to determine the correct type for my handle ?
I like 🙏... Gotta pray for some input!
Thanks for the link. Interesting to see so many positive responses about the Qt bindings and especially interesting if KDE might adopt them. I've done a little Qt before but I'm out of touch. I'll try to take another look.
The ideas of DbC are quite appealing, but in practice I've used it for years in D language and I didn't see it fulfill most of its promises (unlike unit testing), its Return-Of-Investiment was small. D DbC lacks some features (like accessing the precedent state of a variable) but I think even filling those holes isn't enough to change the situation. Perhaps the way to make DbC sufficiently useful in Rust is to handle it as in SPARK (Ada), as (mostly) compile-time enforcement. We should fight against the desire to push every feature inside Rust. I think that there are few small and mostly automatic compile-time features that could improve the reliability and efficiency of Rust programs without requiring frequent annotations as DbC. Features like spotting bugs in C-like match: fn main() { let x: u8 = 5; match x { 0 ... 100 =&gt; (), 100 ... 255 =&gt; (), // 100 covered two times _ =&gt; (), // required } } Explicit flow-analysis-based type coercion: fn abs(x: i32) -&gt; u32 { if x &gt;= 0 { u32::from(x) } else { u32::from(-x) } } Similar flow typing on slice bounds: fn foo(a: &amp;[u32; 3]) -&gt; &amp;[u32; 2] { &amp;a[1 ..].as_array() } fn main() { let b = [10, 20, 30, 40]; let c = foo(&amp;b[.. 3].as_array()); } Interval types and integral subyping: let x: u8[0 .. 4] = 8; // Compile-time error. let v = [0u8; 8]; let idx: u8[v.range()] = 3; v[idx] = 10; // No array bound test here. And few more things.
This is a recent tutorial. https://medium.com/@marekkotewicz/building-a-mobile-app-in-rust-and-react-native-part-1-project-setup-b8dbcf3f539f He targets iOS and Android but he uses React Native if I remember properly.
 The solution ended up being that I don't actually need to really transfer the Engine between threads as Engine itself doesn't really safe state. Thanks a lot for pointing that out, because because of that, I was able to figure it out
Awesome! I will definitely look into it, although I am not much of a C++ programmer myself, and contact you when I get time.
Summoning /u/steveklabnik1!
This is weird, I have no idea why or even how I ended up replying to your comment. I actually meant to reply to the other top-level comment talking about Rocket's cookie system. Hopefully you and others reading my comment aren't as confused as I seem to be. Anyway, it's true that the lower level of security can be completely okay too. Even just plain Basic authentication + HTTPS can be good enough for, say, an app or site that's only in personal or internal use.
Writing a Rust book has to be the toughest undertaking these days.. keeping up to date must be hard and going out of date after release, really easy! Good luck to the authors.
Nothing a little pizza-sushi-karaoke on the first night won't fix!
Good job Nick and the other 52 contributors listed on github! I'm using Neovim and I got all the RLS features working without banging my head to the wall too much (you can see some of them at work [here](https://imgur.com/a/NPsMO)). Minitutorial, if anyone is interested! * We need [racer](https://github.com/racer-rust/racer) and [rustfmt](https://github.com/rust-lang-nursery/rustfmt). RLS uses them behind the scenes. * Neovim can't speak to the RLS out of the box because it doesn't understand LSP (the standard protocol language servers use), so we need a plugin. I use [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim). Install with your favourite plugin manager and follow the official instructions to configure it. * For completion I also use [deoplete](https://github.com/Shougo/deoplete.nvim). It integrates with LanguageClient-neovim seamlessly. Install with your favourite plugin manager and follow the official instructions to configure it. That's it!
I'll be working on Molten (style preserving TOML parser) and hopefully taking it out of stealth. Also I'd like to experiment with the recently published rust-qt-binding-generator to see if it'll be the answer to my GUI woes in Rust
Maybe [just](https://github.com/casey/just) is relevant to your needs?
Last week I noticed, that LanguageClient-neovim is marked as feature complete on LSP page and gave it a try and I agree - it works great :) However RLS needs more work still. As for now it works worse than python LS and better than clangd (C/C++ language server).
I added lazy formatting to [prefixopt](https://crates.io/crates/prefixopt). This should reduce the number of string-allocations. For the next features I'll need to learn procedural annotations. I'll probably hold off unless there is a specific interest. 
&gt; {"jsonrpc": "2.0","id": 3,"method":"textDocument/hover","params":{"textDocument":{"uri":"file:///Users/nick/version-controlled/chefi/src/main.rs"},"position":{"line": 110,"character": 25}}} &gt; (There is actually a little bit more boilerplate to indicate the size of the message). So, for each token one hovers on, ~200 bytes of JSON payload are sent to the RLS? *Sigh*... I really don't understand why we must stick to text-based protocols for communications between processes. I wish Microsoft had known better :(
Time (s), frequency (1/s), density (kg/m^3), energy (J), mass rate (kg/s), volume rate (m^3/s) are other quantities (and their SI units) that you may find useful. I also suggest [NIST 811 appendix B](https://www.nist.gov/physical-measurement-laboratory/nist-guide-si-appendix-b) for reference.
Signing would be more suitable than encryption for the purpose of trusting it. Note that there is nothing preventing you from signing and encrypting. (edit: also, encryption isn't really enough, not without some mechanism preventing reuse, otherwise you can do replay attacks)
Indeed, time and frequencies are a must for a 1.0 release. I'd add Torque (Nm) and angular position/velocity/acceleration. For a 1.1 release, all the electromagnetism quantities could also be added.
There are issues with using JWT for sessions (e.g. http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/ ) 
Yeah, they're absolutely random. Now that I think about it, practically we could have made the Emojis mean more than they do, but we just each chose 4 emojis we liked and went with it. However, because the Parser and Interpreter are split up almost entirely, it would be relatively simple to change the program to work with any combination of Emoji And by relatively simple I just mean going into the grammar file and changing the Unicode values to whatever
And you get 💞 as an output EDIT: Also, the opposite of increment is excrement.
Standard library can't do this because of the `'static` bound of `thread::spawn` - it means *no borrowed content* or *cannot contain a reference to anything that can be freed.* The crates `crossbeam` and `rayon` have a safe version of the idiom you want. The parent thread must execute in a closure instead of getting a `JoinGuard` with a lifetime. I would also consider it okay to define an `unsafe` `spawn_scoped` with the old signature. The only restriction on the caller is to ensure that the destructor of `JoinGuardScoped` is actually called. This can be satisfied by simply leaving it in a local variable.
It's portable, extensible and easy to use from JavaScript. But I fully agree with you otherwise :).
You're right. Others, too, have mentioned the drawbacks of this method, and it's certainly easier to get horribly wrong. I didn't want to get into too much detail since I assumed it wasn't what the OP wanted.
Little bit of [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) work. I've been doing some [proof-of-concept](https://play.rust-lang.org/?gist=72128204e5072d2057338b2bc3a4cc23&amp;version=stable) work in the playground to implement conversion between units that can support non-float underlying storage types. EDIT: Poor of concept working! https://play.rust-lang.org/?gist=0cbf173fdda2afc651301ec623696d0f&amp;version=stable
It's a local protocol so who the hell cares? Oh noes 200 extra bytes over a pipe!
Definitely not October. You can see each chapter's progress through the process here: https://github.com/rust-lang/book/projects/1 Chapters 2-8 are basically done; we're still editing all the other ones. EDIT: Some further details here: there were some private things that prevented work on the book for a long time, and caused delays. Those things are now 100% resolved. I, more than almost anyone else, wanted it to be shipped already. Things happen sometimes. It's now full-steam ahead. Last we talked, the target was December, not March. We'll see!
I did this in Ruby a long time ago: https://github.com/steveklabnik/mojikun
https://github.com/rust-lang/rfcs/issues/1077
Yeah, as it turns out lots of people have done the same thing. We didn't know, and it's also Rust. Was a good learning experience at the least Your emoji choices make much more sense, though haha
please make ide for emojicode
I'm more concerned with decoding/encoding speed. But, it is still a whatever for this application. Json is super common and fast enough since this isn't exactly a high throughput sorry if scenario.
It is way better than XML, easier to handle with microservices in different languages, more extensible than a binary format, and sending KB of data in memory is not going to cause too many issues. As noted above, the decoding is the problem if anything for larger responses. I am sure if it becomes an appreciable issue that some binary version can be devised as an alternative in the future.
I'm writing bindings for [Xamarin/Microsoft's flex](https://github.com/xamarin/flex) then, hopefully, putting together a small demo via [glium](https://github.com/glium/glium). No real reason other than to learn more FFI, stumble over OpenGL, and build out a small ui/'widget' system.
I’ve only heard it in passing, but I’ll check it out!
And this as well.. thanks for the suggestion!
I am having some issues with clang not finding symbols in my native lib. If anyone is interested in lending a hand / time I'd be very appreciative.
It is pretty much unusable on a laptop for me though, just takes too long to run.
My alma mater have done brainfuck interpreter assignment as part of 101 programming, chances are that hundred of these projects on github are ours.
Please provide benchmarks to show that this is an issue before complaining. I bet it isn't and you could not gain anything from using a more efficient format: Val Markovic did [a benchmark comparison](https://plus.google.com/u/0/+StrahinjaMarkovi%C4%87/posts/Zmr5uf2jCHm) way back for YouCompleteMe - decoding, encoding, sending was not a bottleneck locally.
I added the shortcut `Shift-Insert` in my crate [`mg`](https://github.com/antoyo/mg), which is a minimal GUI library à la girara based on [`relm`](https://github.com/antoyo/relm), an idiomatic GUI library. This shortcut paste from the selection clipboard into the command line entry. I also added this shortcut to my web browser [`titanium`](https://github.com/antoyo/titanium) which is based on `mg`.
 I've recently made a lot of progress on what I'm now calling a Web Application Scripting Language, basically it's a template language to build interactive client-side applications that can also be rendered server-side (with actual data) without a javascript interpreter on the server using only a statically compiled Rust binary. I just pushed an updated documentation site which includes a mostly-functional TodoMVC demo. https://tmzt.github.io/isymtope/ The scripting language aspect of it is similar in some ways to elm, but does not expect a developer to be familiar with topics such as type theory and monadsor even with ML or Haskell like languages, and borrows it's functional aspects from Rust. It is also intended to be modular, so the actual syntax can be replaced with other template languages. This version uses Redux and IncrementalDOM, but the actual functionality it's using in those libraries could easily be replaced with something smaller and more focused on the rehydrated HTML use case.
Welp, that would do it
How are you hosting (what appears to be a non-static) site like this using GitHub Pages?
Trying to actually catch up on [ggez](https://github.com/ggez/ggez/) some. Some awesome contributors have created sprite batches and custom shaders, which were big big wishlist items, so I need to pick up the pace and fix a pile of smaller bugs and feature requests so we can make a 0.4 release. :D
Note that the benchmark doesn't take into account the energy consumption.
I'm not sure what you mean, the embedded apps/iframes are all prerendered using the tool I've built. The site itself is currently built with cobalt.rs. Basically the default expression of each reducer is used for the initial render and the demo has no server-side state.
Oh totally! It's a lot of fun; this one is super over-engineered to show off different parts of what would be in a usual, larger language.
Yeah, my knee jerk reaction is based one me doing the legwork to migrate a project I took over to a standard set of licenses.
I was excited to charge in here and give a shameless plug, but to my pleasant surprise I already got plugged! :) I've been overhauling Adhesion to support more `fn` definitions and multiple contract `fn`s in a single `contract!` block, and I'll be handling the end result of that discussion (made into issue [#24](https://github.com/ErichDonGubler/adhesion-rs/issues/24)) soon -- it's next on my priority list, as it's a breaking change and I'd prefer to get it changed sooner rather than later. Also, do you have a Github account? I'd love to tag you in the aforementioned issue -- PM me when you have a second.
Sagebind here. I basically just added that since you guys are all looking at it today and probably wondering...
you can do much better in modern C++ with variadic templates. I don't know if anything has made the stdlib yet but you can easily make functions like ```print(foo ,bar,baz,...)```, ```file.write(x,y,z,w,...)``` etc. I'm pretty sure boost has something 
macbook pro's touchbar is a perfect place for that
There is an `impl&lt;T&gt; From&lt;T&gt; for T` in the standard library. That conflicts with your impl if `U = ConcatRef&lt;'a, T&gt;`.
Yup, it's eternaleye. (I'm vitnokanla here because eternaleye was taken; "vitno kanla" is pidgin Lojban for "eternal eye").
I took a java class last semester and got a 48... I think you're better off without me lol.
I'm not going to lie, the 'jump backward' being a frog seems pretty fitting.
Thanks! Something worth looking into.
Lol
Thanks a ton! I'll play with this and report back.
Excellent. Thank you! For Time I was hoping to defer to std::time::Duration but frequency might mean I revisit that.
What's the story for doing functional style immutable programming in Rust? Things like immutable lists and trees. Are there any patterns that reduce the number of calls to .clone() you need to make because of shared ownership, when you know everything is completely immutable?
Sagebind here, thanks for sharing my project! As I just recently pointed out on the project readme, Rote is not currently active, but not due to lack of inspiration. I loved writing Rote and want to revisit again in the future when I have more time and energy on my hands. I'm not completely happy with everything in there, particularly the "batteries included" goal and the Lua API, which I'd like to revisit. Rote was intended to meet a huge need that I see all the time in development with task runners and build tools. My favorite tool and biggest inspiration is Make, but that has its own warts and issues, namely no way to write functions and use boolean logic in tasks, among others. I've tried nearly every task runner and build tool out there, but most of them have the same issues: (1) bloated with features, (2) high runtime requirements (need nodejs, ruby, etc. to run the runner), or (3) illogical or overly complex ways of writing tasks (XML, giant JSON object, big subclass definitions, etc.). I'd love to hear some input on this topic, maybe other people have a different experience than I do with runners.
Fully understand! I'm just really looking forward to getting the full book in paper :) Thanks for the update. 
Me too :) Any time!
Hmm. If someone multiplies a Force and a Length, how could they indicate they want Torque rather than Energy/Work?
Trying to really get back into Rust. Been working on a GBA emulator just for the heck of it (which is really an ARM emulator). Forces me to become comfortable with the big pillars of the language. I come from a C++ background, so getting my head around borrowing was a little crazy, but I love it now. Plus the Rust syntax just translates nicely for me coming from C++. I love me some strongly typed languages :) https://github.com/DaveKram/gbaemulator
For production code this Rust version should be faster
This is super interesting to me, because I'm writing an LSP server for a different language atm. Mind if I ask how long a usual build takes in rust? For lua, the language I'm using, I can finish one 1-2k line file in about .2 seconds average case, so I haven't started looking into threaded builds, but I worry that the smarter I make the static analyzer the worse this is going to get. 
RLS doesn't need the internet to work IIRC. Are you having trouble installing it with no internet access? This might be tricky.
Sometimes, I am really annoyed by the *Good Enough* mantra so often encountered in engineering. I am annoyed because the bar for good enough should depend on the size of the audience, and when one picks a protocol for use at large, picking JSON instead of, say, ProtocolBuffer or Thrift, is just *sloppy*. You can attempt to justify the choice with a benchmark, and we can discuss its validity at length^1 , however I am not even interested in a benchmark. Would you use bubble sort instead of intosort on arbitrary data with the justification that since it's only ~100 elements it's "good enough" for your usecase? Doesn't it seem silly to use a O(N^2 ) algorithm instead of a perfectly fine O(N log N) one? The "Good Enough" mantra is what gives us bloated applications. Sure in *isolation* their performance is fine, however much like a parasite their presence will affect the performance of all *other* applications on the system. The "Good Enough" mantra is probably what causes my CLion editor (Professional edition) to regularly *freeze* for seconds to minutes on a recent I7^2 . The "Good Enough" is a plague; and like all plagues it nibbles us little by little. ^1 *The benchmark measures a completely different situation too: the RLS has a cache of the files, and they are already pre-compiled and analyzed, thus the hover action is just a look-up in already prepared map and therefore the overhead of using JSON is much more keenly felt. Profiling would reveal how much.* ^2 *I have a high suspicion that a number of operations are performed on the GUI thread because in IntelliJ they were fast enough... and that it turns out that on a CMake/C++ project they are not.*
Yeah, this was my intention. 
You were looking for r/playrust.
I mean, I wouldn't necessarily agree about that. One cool thing is that Lsp fairly easily allows for remote development scenarios, and there's actually been quite a bit of work put into that. 
\o/ Want to join [this discussion](https://github.com/killercup/cargo-edit/issues/69)? :)
Have you seen [Frink](https://frinklang.org/)? It has most comprehensive [unit data](https://frinklang.org/frinkdata/units.txt) file I've ever seen with also many interesting comments. 
Thanks! That's part of the reason we did it, just to get a little more insight on how programming languages work. :-) The other reason being boredom
&gt; Damn you, 16th CGPM! lol
Is there any code I can look at? I was playing around in this area too: https://twitter.com/LegNeato/status/898378834633936896 Cargo integration is pretty sparse for iOS. With all the packaging and such I decided the best way is to actually use Buck or Bazel, which has support for Rust rules and knows all the mobile-specific packaging/platform rules. https://github.com/acmcarther/cargo-raze will help there too.
Continuing work on [tarpaulin](https://github.com/xd009642/tarpaulin) the code coverage tool. Last week I got syntex_syntax integration working so now it filters out lines that show up as coverable that aren't i.e. struct definitions, derive macros. It also now lets you exclude test only code from coverage statistics. Closed a tidy 4 issues in doing so and published another release! Now tarpaulin has features that would otherwise require comments or regex arguments to achieve in lcov or kcov This week I'll be looking at what comes next. So that will be looking into closing some existing issues and moving towards my next big feature drop, branch coverage! I might also have a general refactoring to tidy things up.
And just as important, it'd be very hard to find a language that does _not_ have a json library of some kind. Even toy and niche languages will have some support for ascii strings and with that you can cobble together a json library: a more advanced binary format necessarily means you have less reach in this direction, and that's kind of important for a language integration protocol.
Things are only mutable if they have a `mut` in their signature, or contain a type with internal mutability (e.g. some kind of `Cell`). There's not so much need for pure immutability because Rust lets us control sharing, so we get mutable xor shared.
Is that Swift ?
TWiR, final RustFest talk preparation, perhaps a bit of clippy work.
*fires up [INTERCAL](https://en.wikipedia.org/wiki/INTERCAL)*
And after reaching a certain maturity they can propose a LSP 2.0 with more efficiency in mind.
What you're looking for should be on the Request object you get in your handler: https://docs.rs/iron/0.5.1/iron/request/struct.Request.html
It doesn't matter. Neither the size of the message nor the encoding/decoding has any significant affect on latency. And JSON is really convenient (decoders/encoders in every language, easy to debug, etc.). Using JSON rather than some binary format is avoiding premature optimisation.
That's kind of a 'how long is a piece of string' question. But in general, builds are too long. So we have to rely on trickery (and in the long-run, incremental compilation) to be responsive.
You could download and source and build it. VSCode needs a little more configuration with this approach, it is documented in the repo.
&gt; Also, the opposite of increment is excrement That's great, didn't think of that wordplay :)
Could you point me to where it is documented on the repository? I seem to miss it.
This isn't the case. Unfortunately, while these improvements are going to *land* during the impl period, there's no guarantee that they will *stable* at any given point. If anything, new major editions of the book will be coordinated with epochs.
LanguageClient is feature-complete? Weird - it doesn't support code lens yet...
you got me, you found the super secret project Apple HQ is working on
"Good enough" is the basic of engineering: you make a trade-of complexity, easy to debug and easy to monitor and parse, vs. raw speed. LSP is mostly spending the time in the interpreter / compiler side and not in the [de]coding of the communications. If you have language server that is faster than the parser and decoder of JSON, or so fast that during a profiling the decoding of JSON is significant, you can be sure that you have a very bad JSON library. Only because decoding JSON is a much smaller subproblem of a full compiler. When you are talking about algorithmical complexity using the O notation, you are forgetting C, that for certain sizes of N can make O(N^2 ) a better solution that O(N log N). You can find this kind of decisions in all fields related with engineering.
I've been experimenting with writing an actor framework that's built over the top of tokio to provide the event loop. It can fully integrate with the futures crate to provide the ability to pipe results from futures/streams into an actor's mailbox, along with being able to spawn sinks as actors of their own that forward any messages from their mailbox to the sink itself. So far I've been successful in doing this and I've operated some proof of concept services using this continuously for a few weeks now. It's definitely not a production ready product, though. There's a lot of open ended questions (especially around error handling) and it can probably use a substantial amount of polish and performance optimizations. One of the primary motivators for doing this was that I'm trying to keep the project I'm writing compiled entirely with rust stable. Using just raw futures/streams for the level of complexity I was going for got unwieldy and hard to maintain. Since coroutines (and this async/await) are still in very early experimental stages, I decided a better alternative to making the code easy to reason about was to adopt the actor pattern (a pattern that had already been naturally emerging with my existing streams based code). So far I'm incredibly happy with the results.
Thanks for the write-up, Nicholas! Very accessible and insightful.
Writing a ray tracer. I usually do that when I want to play with a language. I also usually give up when my refractive go awry, we'll see this time (still haven't got to do path tracing, ever)
Few languages implement contracts with compile-time checks (SPARK comes to mind). The trouble here is that either the compiler will reject many valid programs for seemingly no reason, or it will be very complicated. So yes, for most times contract violations might be something like a Rust panic. And Rust has `assert!()`.
You can download the [source](https://github.com/rust-lang-nursery/rls) and then use a regular `cargo build --release` to compile the rls. With this, you can use the _Rust (rls)_ VSCode extension and configure the hidden ["rls.path"](https://github.com/rust-lang-nursery/rls-vscode/blob/3795e31001a39ad31e35481618e7423fab7037e5/src/configuration.ts#L37) option. If you'll encounter a problem with loading shared libraries, be sure to check out [Library issues](https://github.com/rust-lang-nursery/rls/blob/master/debugging.md#library-issues) and Debugging section in general.
Pepe the Frog represents a leap backward for humanity????
&gt; Using JSON rather than some binary format is avoiding premature optimisation. I respectfully disagree. Especially when libraries for encoding/decoding protocol buffers (for example) are equally available in a great many language. I've already posted a lengthier comment in this thread if you wish to know more about where I stand.
Do you know about [GNU Units](https://www.gnu.org/software/units/)? They have a text file that lists a whole bunch of units. You might get some inspiration from them. Or, you could find a way to parse that file with a macro and generate units at compile time. The drawback there is that including it would probably require you to be GPL compatible.
Some kind of GUI misadventure - going for a high-ish level, SDL-based, XML templated kinda thing. Basically a front-end rust library for web programmers to scratch my own itch.
&gt; more extensible than a binary format And how is being binary prevents extensibility? There are perfectly extensible binary formats.
I agree with the trade-offs being a basic of engineering, however I disagree with JSON being a good trade-off *in this case*. Specifically, I would agree to JSON being a good (because simple) choice for *prototyping* such a solution, however I disagree with it remaining a good choice *at scale*. Indeed *reuse* is another basic of engineering, and therefore I find the choice of JSON baffling given that *other formats* already exist, with libraries/bindings for most if not all mainstream languages: ProtoBuf? SBE? I understand the reluctance of designing a dedicated protocol indeed, certainly, but scorning existing ones is surprising. Furthermore, I *disagree* with the idea that interpreting/compiling should be pulled in this comparison. The server behind LSP should interpret/compile/analyze *asynchronously*, when the files change, and results should therefore already be ready for consumption for operations such as *show type*, *goto definition*, etc... ie, all the read-only definitions. I have some doubts that the overhead of decoding the query and encoding the reply are indeed small compared to the overhead of a look-up for those small operations. Cap'n'proto or SBE, by opposition, can decode messages at 0 cost (for native languages, at least). So, thanks for the lesson on algorithmic complexity (introsort is not quicksort); but I'll have to disagree with the idea that JSON is good enough here.
Nice crate. BTW: It could be useful to add a constant for each unit let length: Length&lt;Kilometer&gt; = 2.0 * measurements::f32::KILOMETER; 
Wow! Thanks for all this work, it's great to see people committed to long-term, high-quality projects like this. I don't really use JS, but I'd love more options for GUI in Rust, so the Electron part interests me; Could you give a quick overview of the state of that? Are there any roadblocks that can be worked on to enable it further?
Thank you very much.
Practice makes perfect. No one got to where they're at without quite a few failures
You've walked into complicated territory there. The difficulty with physical unit systems is that units can be multiplied and divided arbitrarily to form new ones. It seems you're going for the convenience in the simple case. I do like the plethora of convenience functions for conversion you have there. I am sceptical when it comes to the simple case staying simple. For usability, I find it important that you can multiply and divide whatever type you have and have it work out to the correct dimension in the end, e.g. `pressure * length1 * length2` and now you have a force. This passes through unit of `Pa m`. That's not directly meaningful but still useful. If you create special structs for non-base units, you're either going to fall short of a lot of useful complicated dimensions (e.g. for intermediate values) or the number of implementations for `Mul` and `Div` is going to explode (`N^2`). Even then, you'll be missing some units that you haven't defined. In general, the dimensionality of each base unit can go arbitrarily high. It may not even be an integer. You basically need number values in your types. It seems all of your units have an incorrect `Mul&lt;Self&gt;` implementation that returns type `Self`.
I had a silly idea of doing the same exact thing. Instead of using Rust I was thinking of forking the brainfuck source code and just changing the default symbols to emoji, then bootstrapping from there. This is a lot more effort than I was toying around with. 👍
Any GUI experiment is a good experiment. Post updates!
Thanks, will do! It's still very early stage. :)
Fair. I guess I assumed you meant a format which would require new breaking protocol versions and wasn't backwards compatible, but its clear that things like Google's protocol buffers do have this capability.
Sure, thank you for asking! 😊 Electron support pretty much Just Works, although it depends on a build workflow that's a bit fragile. There's a guide that explains how to build an Electron app with Neon: http://guides.neon-bindings.com/electron-apps/ And a simple hello world Electron example you can start from: https://github.com/neon-bindings/examples/tree/master/guides/electron-apps/simple-app There are two major improvements I'd like to make here: one is to integrate Neon support into the Electron tooling so you don't need my hacky electron-build-env library to set up the environment variables for the build to work. The other I briefly mentioned in the post, which is to get the right extensibility hooks into cargo so that cargo can properly cache the results of an Electron build vs a plain Node build of a neon app. Currently there's a build wrapper tool called `neon` that configures builds and attempts to do the caching correctly, but this pushes developers out of the standard cargo workflow (and it's unclear to developers when you have to use the wrapper and when you have to use cargo). So I'm really excited about the cargo extensibility initiative!
&gt; Electron support pretty much Just Works That's huge. Many rust devs will still shy away from a chromium + JS runtime requirement, but I think the integration of `ripgrep` into VS Code shows that Rust + Electron can be plenty fast enough for a lot of tasks. I'll try it out as soon as I have time
would love to hear your perspective on Nix as a build runner.
The bubble sort comparison isn't apt, because bubble sort has no advantages over faster sorts. Json has advantages over binary formats. I agree the relative merits of their respective advantages are up for debate.
Now that the intellij plugin has started implementing code completions based on type inference, I'm wondering if that will light a fire under the RLS team to move away from Racer?
The size of Box is the size of a pointer. The thing its pointing at might be big or small, but its on the heap, somewhere else, so it doesn't count towards the size of this specific struct.
I don't think you'll get much traction on bikeshedding over the trait implementation syntax. And especially now that 'impl Trait' is a thing with existentials in return position and representing trait bounds in argument position. We are solidifying even more the 'impl Trait for ..' pattern. Personally, I like the way it is now, but we've digressed.
Can't open the nest to report this issue, while compiling cargo install pijul ``` error: cannot find macro `eprintln!` in this scope --&gt; .cargo/registry/src/github.com-1ecc6299db9ec823/pijul-0.8.0/src/commands/fs_operation.rs:55:33 | 55 | eprintln!("{:?} is already in the repository", file_) | ^^^^^^^^ ```
For this case the dimensions don't answer uniquely for you. You need to keep track yourself. (Common trick question given to first year physics students,) 
About the more complex immutable data structures: internal sharing requires reference counting, which is basically mutation, since there is no traditional garbage collector, and if you aren't using an arena or some other allocation strategy, all the little granular items have to individually heap allocated. Of course if you are using these sorts of data structures, I guess you aren't expecting performance. But the real problem is that the controlled mutability Rust provides turns out to be a cleaner solution then strict immutability most of the time. Safe usage of ephemeral values is enforced by the mutability types.
This might be a dumb question, but isn't any non primitive type field in struct stored in heap anyway? eg. struct Foo { } struct Test { foo: Foo } or struct Bar&lt;'b&gt; { child: Option&lt;Foo&lt;'b&gt;&gt;, data: &amp;'static str, } struct Foo&lt;'a&gt; { parent: &amp;'a Bar&lt;'a&gt;, } Why do you need to specify a `Box` type?
&gt;This might be a dumb question, but isn't any non primitive type field in struct stored in heap anyway? Nope, non-primitives don't magically go on the heap. You have to specifically put them there if you want them there. 
&gt; and if you aren't using an arena or some other allocation strategy Arenas sound like exactly what I was looking for! The I can do something like: enum List&lt;'a, T&gt;{Null(), Cons(T, &amp;'a List&lt;'a,T&gt;)} and every time I have a new list, I just get it from the arena.
The [first newsletter](https://internals.rust-lang.org/t/the-impl-period-newsletter-week-1/5971) is up!
To clarify, I'm not the original author - that was @jocull. I picked it up to help me write a driver for the Raspberry Pi Sense Hat - a relatively low cost board with Temperature and Pressure sensors among other things. I even put together some [workshop materials](https://github.com/thejpster/pi-workshop-rs/). It seemed to make sense to use a modicum of type checking to help beginners avoid mixing up their units. In the specific case of `Pressure * Length * Length`, I was hoping that `Pressure * (Length * Length)` would cover it, but you are right, it's a deep rabbit hole and I don't know how far I want to go down it. The incorrect Mul impl should be gone in my working branch, along with a bunch of other improvements. Unless I can't see it for looking.
Learning a bit of Wayland. I'd like to acknowledge [Victor Berger's *beautiful* generic Rust api](https://github.com/Smithay/wayland-rs). It needs a starter guide and perhaps a more ergonomic layer (like Xlib vs Xcb), but I feel that it's a excellent example of what low level but safe APIs can be. Unfortunately I've been unhappy with my development system. VirtualBox doesn't seem to have particularly good DRM or fbdev support, so I'm stuck with X whether or not I want it. wlc doesn't seem to work without x and with is kinda laggy. I'm also playing with the idea of writing a software only (NopenGL?) Wayland compositor with a strong focus on low latency. I feel (literally, it's a gut feel thing compared to lxde) that Wayland is sometimes held back by OpenGL (buffering a couple frames is no good) And there's not much in the protocol that requires GPU compositing...
I mean, as long as you never intend to free memory... Languages with generational GC get away with using a simple pointer bumping strategy, after each collection, they move the items which survived to a different place in memory and start over. Without a GC you can't really move things like that, and so you are stuck with your arena til you get rid of every data structure that might contain a reference in.
A spiritual successor to Make? That rings a bell... "redo", I think it was called?
&gt; Last we talked, the target was December December would be awesome, especially if it happen before Christmas. I know *I* have some downtime in December, and I like to write code/learn new things, so I'm sure there are plenty of others like me. Also, December is a time when corporate budgets get finalized, so getting purchases approved can be easier for quite a few people during that time. And finally, January is resolution season, so it would be awesome to have it ready for people who want to learn Rust as a resolution. However, I'd much rather wait and have a higher quality book than see it be rushed through, and I'm sure most of us here completely understand if it slips a little. We're cheering for you! Go go gadget Rust book!
How do you start programming in Rust? I've fully read rustbyexample.com and am ready to start . . . But I've about 15 years of Java behind and immediately try to think in classes. Should I just use structs as classes for everything? Would that be correct?
Wrong sub, buddy :D
&gt; isn't any non primitive type field in struct stored in heap anyway? That is indeed common in other languages. In Rust, this is not the case.
What is with the endless hate against XML? I agree the closing tags are a little more verbose than JSON, but you also get xsd, xpath, xslt, namespaces... I'm sure all of these things are *possible* with JSON, but with XML there are actual standards and tooling. Of course I agree with /u/matthieum that a binary format would make more sense in this particular example, but if the choice were between XML and JSON, I don't see why XML would be worse. It's a shame XHTML never really took off.
Right, the Nest is having issues at the moment. Thanks for reporting anyway! I believe your problem comes from your version of Rust, `eprintln!` has been introduced recently.
This kind of story is near and dear to me; it's actually how and why I started learning Rust myself :)
I think the reasons people hate XML are twofold: 1. That while XML is a decent markup language for documents it is often abused for things it was not meant for, like object serialization and config files. 2. How complex XML and its ecosystem is. External entities, XSD, XSLT, that DTDs may sometime be fetched over HTTP, etc. And the libraries for XML have horrible APIs in quite many programming languages, and these libraries often do not support all of XML, or have really poor support for some parts. I have seen far too many people suggest that you should strip all namespaces when parsing, only due to crappy library support from them.
Thanks for the support man, I switched my major to graphic design and I'm a lot better at that. 
In general I'm sympathetic with this argument, but isn't JSON also useful here because it's part of the language server protocol? (I assume the LSP dictates JSON, I'm not too familiar with it.) So in order to switch to something else, you have to ditch LSP, which is another trade-off. So I'd say we have something like this for the picture: JSON | A more efficient solution ---|--- LSP (some free integration) | efficiency familiarity | speed simplicity | elegancy not a bottleneck | ...something else? I'm trying to be generous in this comparison to the ProtoBuf solution, but I honestly don't think it wins. If you look at it from this angle, isn't it a pragmatic approach to stick with JSON until it becomes a problem?
Hello! Thanks for your time. I want to have a Board object that contains and owns both a map of "spec" structs (here using String as a placeholder) and a list of Token objects that references the "spec" objects. I'm getting the following error: error[E0495]: cannot infer an appropriate lifetime for autoref due to conflicting requirements --&gt; src/lib.rs:39:44 | 39 | let kind = self.tokenKinds.get(&amp;ch).unwrap_or_else(|| | ^^^ | note: first, the lifetime cannot outlive the anonymous lifetime #1 defined on the method body at 36:5... --&gt; src/lib.rs:36:5 | 36 | / fn loadTokens(&amp;self, code: &amp;String) { 37 | | for (y, line) in code.lines().enumerate() { 38 | | for (x, ch) in line.chars().enumerate() { 39 | | let kind = self.tokenKinds.get(&amp;ch).unwrap_or_else(|| ... | 44 | | } 45 | | } | |_____^ note: ...so that reference does not outlive borrowed content --&gt; src/lib.rs:39:28 | 39 | let kind = self.tokenKinds.get(&amp;ch).unwrap_or_else(|| | ^^^^^^^^^^^^^^^ note: but, the lifetime must be valid for the lifetime 'a as defined on the impl at 18:1... --&gt; src/lib.rs:18:1 | 18 | / impl&lt;'a&gt; Board&lt;'a&gt; { 19 | | fn new(code: &amp;String) -&gt; Board { 20 | | let mut newBoard = Board { 21 | | tokens: Vec::new(), ... | 45 | | } 46 | | } | |_^ note: ...so that expression is assignable (expected Token&lt;'a&gt;, found Token&lt;'_&gt;) --&gt; src/lib.rs:42:34 | 42 | self.tokens.push(Token::new(kind)); | ^^^^^^^^^^^^^^^^ The minimal code causing this is: use std::collections::HashMap; struct Token&lt;'a&gt; { kind: &amp;'a String } impl&lt;'a&gt; Token&lt;'a&gt; { fn new(kind: &amp;'a String) -&gt; Token { Token { kind } } } struct Board&lt;'a&gt; { tokens: Vec&lt;Token&lt;'a&gt;&gt;, tokenKinds: HashMap&lt;char, String&gt; } impl&lt;'a&gt; Board&lt;'a&gt; { fn new(code: &amp;String) -&gt; Board { let mut newBoard = Board { tokens: Vec::new(), tokenKinds: HashMap::new() }; newBoard.loadTokenKinds(); newBoard.loadTokens(&amp;code); newBoard } fn loadTokenKinds(&amp;self) { self.tokenKinds.insert('?', String::new()); self.tokenKinds.insert('@', String::new()); } fn loadTokens(&amp;self, code: &amp;String) { for (y, line) in code.lines().enumerate() { for (x, ch) in line.chars().enumerate() { let kind = self.tokenKinds.get(&amp;ch).unwrap_or_else(|| panic!("Found unrecognized char '{}' at {}, {}", ch, x, y)); self.tokens.push(Token::new(kind)); } } } } 
It's not a dumb question :)
I don't think XML is more or less suitable for object serialization than JSON. I agree XML can be annoying for config files (I particularly hate maven's `pom.xml`, which for some unfathomable reason doesn't seem to use attributes), but JSON is no better in that respect. Almost all of the complexity of the XML ecosystem is optional. You can use XML without using XSD, XSLT and DTD. Most of my XML-experience is in c# (`XmlReader`, `XmlDocument`, `XDocument`...) , where disabling the resolving of external entities is very easy. I imagine most (all?) libraries that support automatic loading of external things will also include an option to disable this behaviour. Of course the billion laughs remain. Best not to accept XML input that starts defining doctypes and entities... :D
This is likely to improve compile times in debug mode quite a bit! Nice work from /u/acrichto!
Make it LSP 4.0
https://github.com/Microsoft/language-server-protocol/issues/211
To expound on this, the *reason* Rust allows you to allocate complex structs on the stack is actually quite straightforward: the stack is *extremely fast*. Allocating stack space consists of bumping a single pointer. (The downside is that it's inexorably tied to the execution pattern of the program; if you want to allocate something and then return it, the stack won't do, because the space you just allocated will be freed as soon as you return.) For lots of structs (especially small ones), allocating on the stack and treating them as "values" (much like primitive types) is much, much more efficient than dealing with the overhead of tracking heap allocation.
I would read the Rust programming book (second edition), too. Rust is a functional language which makes it harder to write OO code, though it is somewhat feasible (there is a chapter in the book called "Is Rust Object-Oriented?"). For what do you need classes? I'm interested because I've never written any serious OO code (Ruby in school) and never had the need for it.
By default Rust stores everything in the stack. You have to specify that you want things to be in the heap through special functions. Dynamic types such as `Box` or `Vec` behind the scenes handle allocating some of their contents on the heap (and keeping a handle to it) but the handle and other content they may have (for example `Vec`'s length) is stored wherever they are stored, by default stack.
I haven't read the latest version of that book, though I did read early drafts. Same overall content, but a different approach, and they spend different amount of time on different things. Compare the TOC for example. I think the page-count is similar-ish; that one might be slightly longer. Read both :)
The problem with these XML tools is **that they are needed**. With JSON, you have a much better mapping of the JSON structures to native(or, at least, _common_) data structures of most languages - making these tools usually redundant. Consider the following XML example: &lt;?xml version="1.0"?&gt; &lt;people&gt; &lt;person&gt; &lt;name&gt;John&lt;/name&gt; &lt;age&gt;19&lt;/age&gt; &lt;/person&gt; &lt;person&gt; &lt;name&gt;Smith&lt;/name&gt; &lt;age&gt;42&lt;/age&gt; &lt;/person&gt; &lt;person&gt; &lt;name&gt;Bobby&lt;/name&gt; &lt;age&gt;35&lt;/age&gt; &lt;/person&gt; &lt;person&gt; &lt;name&gt;Roberts&lt;/name&gt; &lt;age&gt;64&lt;/age&gt; &lt;/person&gt; &lt;/people&gt; If I wanted to find Bobby's age in a script, I could have used the common XPath implementation most languages have. For example, in Python: import xml.etree.ElementTree as ET tree = ET.parse('data.xml') age_of_bobby = int(tree.find('person[name="Bobby"]/age').text) print('Bobby is %d years old' % age_of_bobby) Simple enough. Now, let's look at a JSON equivalent: [ {"name": "John", "age": 19}, {"name": "Smith", "age": 42}, {"name": "Bobby", "age": 35}, {"name": "Roberts", "age": 64} ] We want, in a Python script, to find Bobby's age. But we don't have XPath. We have [jq](https://pypi.python.org/pypi/jq) - but it's far from being a standard. Well, worry not! We can just do it in... Python! import json data = json.load(open('data.json')) age_of_bobby, = [person['age'] for person in data if person['name'] == 'Bobby'] print('Bobby is %d years old' % age_of_bobby) JSON concepts translate so well to Python's - arrays are lists, objects are dictionary, and primitive types have their equivalents. And this holds for most dynamically typed languages. With static languages you have to either define a schema(and let some library deal with the (de)serialization) or work with sum types - but even then it's much closer to the language's concepts than what you get with XML. If you want to do the same in XML without XPath: import xml.etree.ElementTree as ET tree = ET.parse(open('data.xml')) for element in tree.getroot(): name_element, = (e for e in element if e.tag == 'name') if name_element.text == 'Bobby': age_element, = (e for e in element if e.tag == 'age') age_of_bobby = int(age_element.text) break print('Bobby is %d years old' % age_of_bobby) Much less elegant, isn't it? That's XML's concepts don't match well with Python. That's why only XML has something like XPath and friends - to solve problems that formats like JSON simply don't have. XSD, on the other hand, is solving a real problem common to schema-less data structure formats - that's why [JSON Schema](http://json-schema.org/) is much more popular than jq.
&gt; So in order to switch to something else, you have to ditch LSP, which is another trade-off. Indeed, the original comment said this: &gt; I wish Microsoft had known better :(
Rust does not readily support both owning data and keeping references to that data within the same struct, yet. Sometimes you can work around the limitation with the `owning_ref` or `rental` crates, but honestly it'll probably be easier if you can restructure your code so you don't require this.
Oh, alright then. Thanks!!!
Thanks for sharing that article. It's a good challenge for using JWTs to replace sessions. There are trade-offs to consider, and a developer needs to be aware of them. 
Thanks for sharing that article. It's a good challenge for using JWTs to replace sessions. There are trade-offs to consider, and a developer needs to be aware of them. 
If you don't have a crypto-random secure RNG, you can substitute it with a secure hash and a less secure RNG. edit: You would need another source of entropy, though, which is effectively hand rolling your own secure RNG... which is hard to do correctly, so yeah, find a secure RNG!
Indeed, this works. Awesome!
Units of information (bits, bytes, etc.) would be a useful thing to have, I think. Especially with both base-10 and base-2 SI prefixes (kilo- and kibi- etc.)
Awesome! :D Glad you found something you really like. Besides we need good graphic designers to design some really pretty user interfaces for software as well. Best of luck :D
Not evolving Iron further sounds good to me. Having said that, I think the permission problems still have to be solved, so that bug fix updates can be made for existing users of the framework. Additionally, there should be a big disclaimer in the repo and the crate README about it being in bug fix only mode and advising people to migrate off it. I've added a comment here: https://github.com/iron/urlencoded/issues/68#issuecomment-332056828 (Feel free to add me to the owners/team as well, I'm willing to help as I'm still using iron at the moment.)
I suspect you wanted /r/playrust - Please remember to check the topic of a subreddit before posting.
I would argue that something like xpath would be nice to have when querying JSON documents in an SQL database, since SQL is a declarative language and xpath is closer conceptually. In theory one could integrate xpath/jq queries into the SQL query planner to get better cost estimates.
Thank you!!
I use hmac encryption to create a session ID when a user logs on, and I store the hashed value of their session token in a cookie and in the database. When they make requests they provide the cookie, which is then checked by the database. When they log out I just make a sql query to remove the cookie. There are probably plenty of ways to complete this though.
&gt; there is a chapter in the book called "Is Rust Object-Oriented?" Thanks, it perfectly answered all of my OOP questions. I've started on that book but abandoned midway, as by example seemed easier and faster. &gt; For what do you need classes? I'm interested because I've never written any serious OO code (Ruby in school) and never had the need for it. All the things that said chapter mentions: group functions that solve a common functional goal together and let them share a state (classes), hide some of the data and functions from the public API as they represent internal details that nobody should know about and most importantly should not be able to call, and have sub-type polymorphism (basically Java interfaces). The only thing that Rust doesn't do according to the text - the full class inheritance - is actually the feature I almost never use in Java, as class inheritance, whenever it grows, always brings many pains.
Here is [a basic example of plain Hyper](https://hyper.rs/guides/server/hello-world/). Hyper itself doesn't have a built-in routing system, but for simple routing you can just use `match` as in [this echo example](https://hyper.rs/guides/server/echo/).
I used neon a few months ago for a side project and it was great! There were a couple things that took me longer to figure out than I’d have liked so I created a [pull request](https://github.com/neon-bindings/examples/pull/2) to the examples repo. Might have slipped thru the cracks, any chance you could take a look? I’d be interested to contribute more in the future as well. 
Games are always a challenge. I strongly recommend you using GGEZ game engine. You could keep things easy by just proposing an arcade game.
Same here!
New week, same AWS SDK work on [Rusoto](https://github.com/rusoto/rusoto). Recently merged three new services: Athena, Application Autoscaling and X-Ray. Coming up: builder pattern for request objects, a helper macro for DynamoDB and trying out SCCache to improve compilation times. Blogging: I didn't get the test-first development with Rust blog post started, so back on that, too!
Not sure if this is the right place, but since you ask, here are some examples of why classes are needed: Regardless of whether a particular language supports it as a construct, you always have interfaces. Material systems have them, like a car, you've got a wheel, pedals and that's how you operate and then there's lots of stuff going on under the hood that you aren't required to know about in order to use the system. Same in code. There're always logical components, like this code should implement logging messages to a file, so here's a log() function, but whatever's going on inside doesn't concern an end-user, he just knows the contract: call log() and the message gets stored somewhere. Classes allow you to clearly specify that interface and hide the implementation. All the data that the classes need are stored within them, there is no accessing global variables or anything outside. Clear separation allows changing the impl without affecting the users. Sub-type polymorphism allows stuff like, here I'd like to get a map (collection) as an argument and I don't care how that map is implemented, be it an in-memory hash map, or a map persisted to the local filesystem, or a map stored in a database over network, etc. Classes also clearly group functions together. In C, if there are say 3 functions that all operate on the same struct, you'd probably prefix their names identically to indicate they're part of the same logical component. Like, you have a file parser, with fp_open(), fp_parse(), fp_close() all of them taking the same struct as an argument. With classes, the functions would simply be part of the Fp class, like (metacode): class Fp { func open() func parse() func close() } And those functions will always have access to the class's data (or rather, a class instance AKA object). It's the same thing, but explicitly expressed in language and hence easier to use. So, whenever you want to write an app or a library you're always thinking in components, each with their own contract on the public methods, public state, and private methods/state. Sure you can do it like in plain C, it's just more error prone, doesn't protect against tight coupling (end-users directly rely on the internal state of the lib they're using) and doesn't make it any easier for the end-user as he sees much more than he needs. When you come to a bank operator with the goal of opening an account you don't want to know how their branch works under the hood, you just want to state your intention and give the minimal required information for the operation to complete with as less headache as possible. That's what carefully designed classes give you.
I think it'll be possible to in-build it when procedural macros and/or compiler plugins are finished. This feels like a feature that is very design specific; there are a lot of ways to approach the problem and the decision making process for rust is very slow, steady, and deliberate. I may be wrong about this, though; I don't have a solid understanding of what compiler plugins and procedural macros will look like. This could also be something left to an external tool. Javadoc is like this - it's not formally java syntax, it's just special formatting of comments.
That did slip past my notice, thank you! I'll take a look asap. Examples and even just anecdotes about things that tripped people up are enormously useful. 😍
Another Java dev here. One of the hard parts of learning Rust is *unlearning* the idioms of other languages that don't work well. When I write Java code, I'm concerned how I lay out my data first, then I'll code the desired functionality. In Rust, this is even easier thanks to algebraic data types (and the fact that Rust objects don't chase pointers, like Java objects). Traits let us extend behavior after the fact. In Java, we'd need to implement interfaces instead, giving us less control what implements which. 
I am still a noob, learning both NodeJs and Rust and I love both. Anyway I can contribute?
Any idea on how much this could change things? Are we looking at 10% faster, or more than 2x? I don't know enough about compilers to know what increasing the number of code units from 1 to 32 means and feel very much like [today's XKCD](https://xkcd.com/1894/).
[Image](https://imgs.xkcd.com/comics/real_estate.png) [Mobile](https://m.xkcd.com/1894/) **Title:** Real Estate **Title-text:** I tried converting the prices into pizzas, to put it in more familiar terms, and it just became a hard\-to\-think\-about number of pizzas\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1894#Explanation) **Stats:** This comic has been referenced 1 time, representing 0.0006% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dnip4ke)
This will be really nice for larger projects. Exciting stuff! :D
You might be interested in [Processing](https://processing.org/). It's sort of a a simplified Java aimed at the visual arts.
/u/acrichto posted a collection of preliminary benchmarks [here](https://gist.github.com/alexcrichton/e05d16cf9038043a9c293be02e2f5bab). Here's the relevant section comparing the numbers for debug compilation with different numbers of CGUs: This is a comparison of how long it takes to compile the `cargo` crate in *debug* mode, using the specified number of codegen units. cgus= 1 Duration { secs: 25, nanos: 987906757 } cgus= 2 Duration { secs: 19, nanos: 634406885 } cgus= 4 Duration { secs: 16, nanos: 760811018 } cgus= 8 Duration { secs: 14, nanos: 575499872 } cgus=16 Duration { secs: 14, nanos: 149127165 } cgus=32 Duration { secs: 14, nanos: 495588126 }
To add to what others have said a lot of values "partially live on the heap" if you will. As far as the rust runtime is concerned it isn't actually part of a the value but conceptually it is. Like say a Vector. As far as the rust runtime and compiler is concerned what it is three words; that's it; it is always three words no matter how many elements are in the vector and consequently `mem::size_of::&lt;Vec&lt;u32&gt;&gt;()` is 24 on a 64 bit machine where a word has a size of 8. Now the standard library does ascribe meaning to these words. One word in the library is treated as a pointer to the heap, the other word as the number of elements in the vector and the final word as the capacity the vector has left remaining before it needs to be re-allocated to grow. The vector itself being the three words completely lives on the stack but the _buffer_ it manages which is what you think of when you say "the vector" lives on the heap. We actually have an interesting situation then of three types: `Vec&lt;T&gt;`, `&amp;[T]`, and `Box&lt;[T]&gt;`; `Vec&lt;T&gt;` is actually closer to `&amp;[T]` than it is to `[T]`. We already explained what `Vec&lt;T&gt;` is so what is `&amp;[T]`? This is _two words_; a pointer to _somewhere_ (can be to the stack) and a length. Unlike a Vector this does not manage the resource it points to and the lifetimes in the type system ensure that what it points to must outlive it. Then there is `Box&lt;[T]&gt;` this is in between `Vec&lt;T&gt;` and `&amp;[T]` again we are dealing with two words, a pointer and a length but this is again always a pointer to the heap and behind the scenes this does allocate and deallocates the memory on the heap it points to but it has no buffer size unlike a vector; its length and buffer are effectivel always the same and it cannot grow or shrink unlike a vector. Because of this relationship we can freely convert between a `Box&lt;[T]&gt;` and `Vec&lt;T&gt;` and the former is basically a vector you can't extend. In both cases we can take a `&amp;[T]` from it as long as it is outlived by it. Finally there is also `[T; N]` whre every N is a different type. This is again fully on the stack and its size is the size of T * N. There are no extra words pointing to something here nor extra words for buffer and length. The length is statically known and can't grow or shrink and we can indeed also take a `&amp;[T]` from this
Holy community outreach batman!
Previous discussion: https://www.reddit.com/r/rust/comments/725ni8/simple_auth_in_rustironhyper/
We can not know the size of things on the heap statically. We must know the size of things on the stack. So even though the type may be recursive and infinite, on the stack, the size is static.
I run it on a 5-yr-old MBP and it seems fine...
so?
Did you see that in most of the tokio_* repositories are examples for the specific tokio piece? For example tokio_tls or tokio_serde_json. 
Linking to that might be useful for others coming to this thread.
It's Rocket, but you might want to take a look at this: https://github.com/SergioBenitez/Rocket/tree/master/examples/session.
I just finished an OO project for a class that was supposed to be in Java in Rust. I wrote both versions and the noticeable difference was that I was *passing* the most important struct in my program everywhere, whereas in Java it was just calls *to* it. For me you have to get out of the idea that in Java you're separating objects by methods whereas in Rust you are separating objects by the data(structs). In Rust it will seem like you're causing tons of overhead by passing structs but Rust doesn't copy data or duplicate references, it simply *gives* the data to function being called (and if done in my case) gives it back after it's done. So maybe let your Connection module consume a User and pass the User back to your main when it's done. Slight difference due to how Rust is unique in how it handles lifetimes and borrowing. So instead of `User.send_chat()` you'd do a `Connection.send_chat(User::get_message())` Edit: here is a link to my source code for both versions. The Java version is unfinished, but seeing as you're a Java developer I'm sure you can fill in the blanks. Navigating to docs/spec and viewing the PDF there should help you understand the program. If not let me know I can grab a copy of the assignment for you. https://github.com/LogoiLab/ProjectOne
Shouldn't the connection object be exclusive for a user? In my view a channel would hold a list of users that are in the channel. You could arc/rc for sharing an object. With mutex/cell you can also achieve interior mutability, this means that the object does not need to be marked as mutable to the exterior world ^^
then link google.com too
and in php? 
I'm confused: what's the difference between storing "user_id" in a session and cookie?
~~Could you elaborate on the differences? Or is there any good explanation available?~~ Edit: I guess the difference is that "network buffers" mean you call encoder.write(buffer) a bunch of times, while the streaming body means you have to create a stream of bytes that represents the response. Is that more of less correct?
I've been having issues with out of memory problems (despite my 12 GB of RAM) with as few as 2 codegen units, so I'm not sure about 32 :o 
You can try a [gotham.rs](https://gotham.rs) framework. It's a thin layer above hyper, and it has it's own router and middleware manager. There is also an [example-app](https://github.com/gotham-rs/example-app). Gotham is still early in development and has some limitations, but it was good enough for my pet project.
You have to draw the line somewhere :-) Will the chapters be updated when those features land? As these are intended to be ergonomics improvements? Officially publishing a next edition of the book corresponding to official epochs sounds great.
I think you can run the script from the `target/build/something` directory.
https://github.com/iron/iron-sessionstorage/blob/master/examples/login.rs
This is a good question, and is something I have been struggling with too - though I come from a C# background. We need a "Rust Design Pattterns" book.
I think you're looking for this? [Rust Patterns](https://github.com/rust-unofficial/patterns)
i found the script. through if i try to run it, it panics $ ./target/debug/build/qpp-828f3425bd5bc0d0/build_script_build-828f3425bd5bc0d0 thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: NotPresent', /checkout/src/libcore/result.rs:860:4 note: Run with `RUST_BACKTRACE=1` for a backtrace. now i debug the build.rs with `panic!()` :/ 
Try `RUST_BACKTRACE=1`. It might panic while looking for an environment variable that's usually set by `cargo`.
Increasing the number of codegen units might actually help here since https://github.com/rust-lang/rust/pull/43506 landed, as the compiler can now split things into smaller chunks and will immediately free memory of finished tasks. The heuristic for deciding whether to generate more work for LLVM or complete existing work is still geared towards throughput rather than keeping memory consumption low. But I could imagine making this a tuneable parameter.
&gt; Is there any code I can look at? Kind of. It's about this library: https://github.com/dbrgn/candidateparser I can already call it from C and I have integration in Android through JNI. But the iOS integration is still to be done.
Hi! code::dive is a conference organized by Nokia labs in Wrocław. Due to the languages they use in production the main topic of the conference was always C and C++ and some Java. This year it will be the 4th time they are organizing it. From what I remember this year it's the first year that there will be Rust focused lectures. I counted 4 explicitly named ones so far: - Alex Crichton: Concurrency in Rust, - Benedict Gaster: Save (er) GPU programming with Rust and OpenCL, - Pierre-Henri Symoneaux: Building microservices with Rust, - Alex Crichton: Intro to Rust. I thought that you might be interested. I've attended it previews years and my impression was very good. They also invited programming gurus like Andrei Alexandrescu and Scott Meyers. Here you have whole agenda for this year: http://codedive.pl/#program-section .
I’m not asking for an auth. solution which already exists. 
Not sure I understand. That crate implements sessions via signed (but not encrypted) cookies. You say you want to: &gt; write a user_id into a session That's done here: try!(req.session().set(Login { username: username })); In this case, the `Login` type (and thus the cookie) stores the username, but you could change that to an user id. &gt; check if “user_id” exists in a session a cookie exists before each request let login = iexpect!( req.session().get::&lt;Login&gt;().ok().and_then(|x| x), ( status::Unauthorized, "text/html".parse::&lt;iron::mime::Mime&gt;().unwrap(), "&lt;a href=/login&gt;Log in&lt;/a&gt;" ) ); Done like this in that example. The code tries to retrieve that cookie. It's done directly in the handler in this case. I'm sure `iron` offers the possibility to do this automatically (in a middleware), but I'm not too familiar with it. &gt; manually remove it when a user logs out Done here: try!(req.session().clear());
Sort of. Of course it would need a lot fewer TODOs. Maybe Design Patterns is not quite what I was thinking, it's more like a version of Scott Meyer's Effective C++ for Rust, coupled with Design Patterns, coupled with API design guidance. I guess the result would be something akin to "Rust: The Definitive Guide." I know that some of these things exist scattered around the web but I have not seen anything comprehensive, and of course Rust is a moving target. I really would prefer to buy a paper book too. 
Doesn't LSP need access to the local filesystem so it can read the rest of the project's files?
With a dual-core hyperthreaded CPU, how much benefit will I see? Wouldn't &lt;number of cores&gt; × 2 yield better results?
You can help! For many patterns, it makes a lot of sense to team up one experienced and one inexperienced Rustacean. This ensures that Tue amount of jargon stays limited.
I haven't but won't they be examples of how to use those tokio_crates and not of how to use tokio itself?
To use these Tokio crates, you also need to use tokio itself ^^ these examples helped me to understand all this Tokio stuff a lot better. I also fought the last 2 weeks with tokio/futures and page long error messages ^^
There’s a "jobserver" to limit the amount of parallelism based on CPU thread count.
I'm sure there are! For one, if you just want to try playing with Neon and see if you hit any confusions or pain points, jump onto the Slack and ping me, or file an issue. If you want to try your hand at some of the open issues, I've tagged "help wanted" issues as ones that I think would be particularly suitable for contribution: https://github.com/neon-bindings/neon/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22 I'm happy to chat in real-time on the Slack to see if we can figure out what might be of interest to you!
I can't compile with --release on an old RPi
While a binary format would be faster I think you are missing (part of) the point of the LSP. It is supposed to be easy to support by any combination of editor and language. To achieve that JSON is a far better choice since you can get a good JSON parser in any language. That said, the LSP could be extended to support different (binary) formats for language + server combinations which support it without to much fuss. Indeed there is an issue open for that exact extension https://github.com/Microsoft/language-server-protocol/issues/211.
Do you know if the talks will be made public? I'm curious about the OpenCL + Rust one, but couldn't find anything at a quick glance.
Right now, new stuff lands in Appendix G: https://doc.rust-lang.org/book/second-edition/appendix-07-newest-features.html And then they get folded back into the main text on the "once an epoch" schedule. That said we're kinda new at this so that's just the plan, we'll see how it actually works.
For a small-but-nontrivial project, you could check out my, ahem, [meme server](https://github.com/Xion/rofld) which I developed precisely because I wanted to check how Tokio works in practice :) [The service definition](https://github.com/Xion/rofld/blob/master/src/server/service.rs#L22) is probably a good starting point.
&gt; Few days ago we saw this message from @jackpot51 on the Redox chat: “Gentlemen, I am going to port libservo”. Yes! some libservo work is on the way &lt;3 Awwwwh yeah, that's super exciting!
Wow, that's pretty significant! It'll be interesting to see how other projects are affected! Thanks for the link!
&gt; Would you use bubble sort instead of intosort on arbitrary data with the justification that since it's only ~100 elements it's "good enough" for your usecase? Doesn't it seem silly to use a O(N²) algorithm instead of a perfectly fine O(N log N) one? It's funny that you say this, because in reality sorting functions usually use insertion sort which is O(N²) for small N, because it is faster. &gt; The "Good Enough" mantra is probably what causes my CLion editor (Professional edition) to regularly freeze for seconds to minutes on a recent I7. The optimize everything mantra could be the reason that there's not enough time to actually profile what is the bottleneck. Or to do architectural restructuring so that those operations are asynchronous from the GUI.
So far they made them public (however not sure if all of them). I think they also live-stream. Here you can find those from 2016: http://codedive.pl/index/year2016 .
Rust is very much not a Kingdom of Nouns language. I have no idea what the topic of `send_message` should be. And I'm certainly not going to invent a `MessageSender` just because I need to send messages. In English I would say "the program sends this message to this user or channel." So the program is the subject/topic and `send_message` is a free function. If the program manages multiple connections per process, then `send_message` would be a method of the open connection. This way I keep track of when and where the program may access a channel. (Helpful for sending atomic sequences.) Next that type `User`. I don't literally have a user in my program. I have "things I know about a certain user", which probably make sense to keep together but might not. A consequence of this design is that `send_message` is called by shared reference (`&amp;` not `&amp;mut`) to a user. If I want to make the function polymorphic between sending to users or to channels, I could define a `enum MessageTarget&lt;'_&gt;` with `&amp;User` and `&amp;Channel` variants.
I'd wrap that bb in an Arc&lt;Mutex&lt;T&gt;&gt;, though maybe I don't know what I'm talking about. Futureproofs you for multithreading though.
Whoa that's awesome. You are my hero. Not because you have given me a non-trivial example to understand tokio, but because you have given it in the form of a meme server. I have no words to explain how grateful I am. P.S. Will it be alright if I dm you when I have some doubts with implementations?
Ah thanks. On it, then. 
Ah, I see. In that case, throughput should be near-optimum.
Cool, thanks! I will monitor their website then for some news.
Absolutely. I don't promise I remember all the details (as it's been a couple of months), but I'm happy to help. Most of the time you should be able to find me in one of the Rust IRC channels, too.
You kinda need to know the size for the heap as well. All of the allocations' sizes are decided at compile-time (in the context of this post), heap or stack. The thing is, here we go around the "unknown size" problem by splitting the object into an unknown number of multiple fixed-sized objects (i.e. containing pointers to the other objects), which we know how to allocate, be it on the stack or the heap.
You can make some headway by handling the things which need to be mutable as parameters, rather than fields. So: user.send_chat(&amp;mut connection); That keeps the lifetime of the borrow down to just the time it's actually needed, and ensures that the method can only be called by a client who has control of a connection (mutable borrows are like capabilities in this respect). I often end up with a similar approach in Java, even without the design pressure exerted by lifetimes. If a user can do all sorts of different things, which might or might not require a connection, and might even be useful when there is no active connection, it feels a bit weird to make the connection a field; that says it's a permanent, essential part of the object. Better to make it a parameter that you pass in as and when needed. Even better, pass it in behind an interface, or pass in a specific aspect as a lambda: BiConsumer&lt;UserId, String&gt; sender = connection::sendMessage; user.sendChat(sender); That softens the coupling between the domain concept of a user and the infrastructure concept of a connection.
Does the just right process architecture mean plugins can still crash Firefox? Because ugh. And most chrome tabs are cow so they share the core pages. The engine is only loaded once and remapped per tab.
There is one plugin in Firefox: Flash player and that is isolated in the [GMP sandbox](https://wiki.mozilla.org/Security/Sandbox). WebExtensions cannot crash the browser. If they do, then it's a browser bug and will be fixed. Firefox v56 is the last one supporting legacy extensions. If you use legacy extensions, they can crash it. I don't use legacy extensions, run Nightly and get 2 updates per day and don't remember the last time it crashed. I have 27 WebExtensions and this thing flies like a beast!
I like this project, but fixing committed compile errors is ridiculous...
I think it's important to note that Rust is not alone in this. Many "systems programming languages", including C and C++, follow the approach that things aren't on the heap unless you ask it to be. I even somewhat disagree with other comments here that imply (but don't actually say, and perhaps didn't mean to come across as such) that Rust is storing things "on the stack" to be faster. It's not. It's keeping them off the heap because you never asked them to be on the heap. The rule that "non-primitives go on the heap, the rest stays on the stack" is a Java thing (Literally, even; C# has `struct` types, JavaScript and friends don't really specify what goes where, LISPs and friends put everything conceptually on the heap always), and I think it would help if we help people understanding that the defaults they have learned are not universal; that they are not "necessary" defaults. Another thing to note: it's not really "on the stack" vs. "on the heap". It's more of an "inline" vs. "out-of-band" thing. `(A, B, Box&lt;C&gt;)` doesn't mean that `A` and `B` go on the stack, and `C` goes on the heap. It means that `A`, `B`, and the pointer to `C` are _together_. See for instance a type like `Box&lt;(A, B, Box&lt;C&gt;)&gt;`. Clearly, the Rust compiler is not able to keep those `A` and `B` on the stack, since there is no stack frame that is guaranteed to outlive the tuple.
The idea is that the lsp server runs on the remote server, the lsp client runs on your local text editor, and the lsp protocol is the only thing that needs to be sent over ssh. It actually works quite well. 
Just in case anyone wants to try this out today, you can add [profile.dev] codegen-units=32 to your `Cargo.toml` file and your debug builds will instantly start building using 32 codegen units. (tagging /u/llogiq and /u/tomaka17)
I wrote [fectl](https://github.com/fafhrd91/fectl) "process management tool". I was trying to understand how to write tokio apps. If you just need asynchronous functions then tokio works very well, but if you want to express async control flow, then it becomes ugly very fast. I ended up writing actor library [actix](https://github.com/fafhrd91/actix)
The performance is very impressive. 
Think of all the performance things that are in the pipeline in LLVM, Rust, Stylo and WebRenderer. It already beats Chrome at some benchmarks, it even loads some Google pages faster. It will totally blow the competition away in 2018 and it will do it with lower memory. Obviously it will not be more popular than Chrome since Mozilla does not have the marketing money Google has.
`ammonia` is nearing the `1.0` milestone. If anyone is interested in a crate like this, we would love to get some feedback on the API before it gets frozen.
&gt; C doesn't have a way to store fixed-length arrays in a struct, as far as I know, it absolutely does struct mytype { char name[12]; }; is the same as #[repr(C)] struct mytype { name: [c_char; 12] }
It would probably have to be `Arc&lt;Mutex&lt;RefCell&lt;T&gt;&gt;&gt;`, right? `Arc`+`Mutex` make it `Send` and `Sync`, and `RefCell` would allow it to give out multiple &amp;mut refs
It might be more popular than Chrome at some point. People tend to notice speed, especially since non-developers don't buy new computers every two-three years like we do. 
&gt; I was passing the most important struct in my program everywhere, whereas in Java it was just calls to it But this struct could have methods just like Java classes have methods.. right?
`Mutex` is *already* the concurrent version of `RefCell` (and so is `RWLock`).
I have some email stuff going on that might help: https://github.com/djc/tokio-imap -- should demonstrate a protocol client library pretty well https://github.com/djc/mailsync -- basically a collection of batch programs built on top of tokio-imap and rust-postgres/tokio-postgres 
I wish ticki would focus on getting TFS to build more than writing out subsystem stubs that do not compile. This is especially important if trying to make it compile requires architecture changes, that are much harder to make if you have a larger codebase
People hate change. Moms and pops will never switch on their own. They do not care about performance. They can click the gmail bookmark and then go make coffee.
Note that AFAIK the caller allocates on stack and passes a pointer in case of large structs.
[I have provided a full example here.](https://play.rust-lang.org/?gist=a8cc97788cb461ce63ac3203a00650e6&amp;version=stable)
Ion actually supports 16.7 million colors.
They also have shit computers and when they ask their sons how to make it go faster they will install firefox if it is known to be faster. 
Yes, syntactically and somewhat semantically you can call Rust structures like you can an object in Java. However, to ensure that the borrow checker doesn't yell at you, it's good to get in the habit of learning to pass these structs around instead of making a hierarchical structure. There's no inheretence in Rust, and while you can compose objects (and you should!) it doesn't allow multiple objects to own and mutate the same sub object (not without rc and refcell of course, which isn't scalable across everything in the project). 
Many people switched to chrome in the mid-2000s because it was noticeably faster at that time.
And because all the web sites were telling them to.
Too bad to see RustType had to be taken over by Redox. I was hoping that one would take off on its own. Oh well. At least it has a good home.
The way I interpret this is that in Rust, you are injecting dependencies everywhere (and not necessarily storing it in a field). You need to do this because it's the safest way to prove who owns the data and a certain point in the execution. As someone who has to maintain a Java code base at work, I find the Rust approach to be much easier to follow. It forces the programmer to be more aware of the dependencies within the application and how they interact (eg what mutates what) 
Do I understand the last paragraph correctly that Quantum will also be in the Android version? 
After 2 versions or so... Want to test the desktop then dump the old style system.
It was not "taken over". It was not being maintained, and the maintainer, dylanede, is now sharing write access with Redox.
This is the best tl;dr I could make, [original](https://blog.mozilla.org/blog/2017/09/26/firefox-quantum-beta-developer-edition/) reduced by 92%. (I'm a bot) ***** &gt; Results vary based on the computer and apps you&amp;#039;re actively using, but one thing that&amp;#039;s relatively consistent is that Firefox Quantum is about 2X faster than Firefox was a year ago. &gt; Firefox has historically run mostly on just one CPU core, but Firefox Quantum takes advantage of multiple CPU cores in today&amp;#039;s desktop and mobile devices much more effectively. &gt; If you&amp;#039;re already among the Firefox faithful, you&amp;#039;ll automatically upgrade to Firefox Quantum on November 14. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/72l3dz/start_your_engines_firefox_quantum_lands_in_beta/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ "Version 1.65, ~216881 tl;drs so far.") | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr "PM's and comments are monitored, constructive feedback is welcome.") | *Top* *keywords*: **Firefox**^#1 **Quantum**^#2 **we&amp;#039;ve**^#3 **new**^#4 **fast**^#5
Yes but also somewhat of a pain to actually write, no? Instead of: let user = User::new_using_connect(connection); user.send("Hello"); user.send("Goodbye"); user.send("Whatever"); You have: let user = User::new(); user.send(connection, "Hello"); user.send(connection, "Goodbye"); user.send(connection, "Whatever"); Also it's not 100% the same because the `user` can't easily remember things about the `connection` across calls. For example suppose you had to look up formatting preferences for the connection. You'd have to do that on every `send()` call in the latter case. (Ok not great example but you get the point hopefully.)
They really weren't. The "best experienced with Internet Explorer" phase mostly died out with after IE6 when Firefox started to become popular.
Let's say we have two files: // foo.rs use bar::Bar; pub fn foo() { Bar:: } And: // bar.rs pub struct Bar; impl Bar { pub fn bar() { println!("hi"); } } 1. I'm in `foo.rs`, with the cursor after `Bar::`. 2. I trigger completion. 3. The LSP client sends the current file's text and the cursor's location to RLS. 4. RLS reads `bar.rs`(or maybe it could have done it before) and updates it's internal index. 5. RLS returns the completion results(`["bar()"]`) This works because RLS runs on the same machine as the LSP client, and more importantly - the same machine as **the source code** - so it can easily red `bar.rs`. Now, if RLS would run on a remote server - how would step 4 work? Will the client have to send **the entire codebase** to RLS over the wire? 
To understand this, try to figure out the size of Cons(T, List&lt;T&gt;). It should be a contigious piece of memory that can store both a T and a List&lt;T&gt;. Assuming T has a known size, we just need to find the size of List&lt;T&gt;. So the size of List&lt;T&gt; involves finding the size of Cons(T, List&lt;T&gt;). Assuming T has a known size, we just need to find the size of List&lt;T&gt;. This just repeats because of this recursive declaration. When we add in a Box, it is of a known size, as someone has mentioned it the size of a pointer. So a Cons(T, Box&lt;List&lt;T&gt;&gt;) is a structure with a size that can store both T and a Box. We no longer have to recurse and find the size of List&lt;T&gt;. These sort of structures in system languages usually allocates a single block of memory to store all of its members. When you have a pointer, that usually means a seperate allocation of memory is needed and the pointer will now have the address to it. Pointers are of a known size, so the size of the memory it points to does not influence the structs size.
Ah, so I think there's a bit of confusion. The idea is remote development. So foo.rs and bar.rs on both on some server elsewhere that you'd normally have to ssh into. As you said, the important thing is that RLS runs on the same machine as the source code. 1. So you're in a local copy of `foo.rs`, with the cursor after `Bar::`. 2. Your local text editor triggers completion. 3. The LSP client sends the current file's text and the cursor location to RLS on the remote server. 4. RLS reads `bar.rs` and updates it's internal index. There's no problem with this because to the RLS, all of the files are on its machine. 5. RLS sends the completion results back to your local text editor.
The linked article does say "we took over the maintenance of the RustType crate, it now lives here under the redox-os Github organization."
If the user is modifying the connection that much, it probably should own it (that way it doesn't have to remember the state that's only borrowed to it). And I never said you can't pass it in the constructor, just that to do so requires a bigger commitment in terms of mutability. In this case all of the users's methods use it so it's fine for the user to own it (e.g your first example). In this case this example can be exactly the same as in the Java version, it's just harder to share that connection with others. Which I see as a feature, since if multiple objects own the same connection and can mutate its state (such as close the connection...) that would break other parts of the code (such as the `User`). I'd rather have to opt in to shared ownership of an resource (such as a connection) than to have weird bugs spring up later because I expected my connection to be only modifiable by me.
&gt; Orbital experienced bunch of unused code remotion Uh...did you mean "removal"? :)
I had to install beta after reading this, and I can confirm it's really something. Amazing work by all involved! For those running ubuntu/mint/forks here's the ppa and steps https://forums.linuxmint.com/viewtopic.php?t=212650
Why not just use a `match`? It might even get compiled down to a lookup table.
I tried RLS with nvim a few months back. Didn't go very well at the time. Thanks to your comment I gave it another spin today. Holy crap it's _good_. Worked flawlessly so far on my workspace projects. This has improved my workflow by an order of magnitude. Thank you!
Maybe use an intermediate type with just two methods: as_torque(), as_work() One would have to write (f * l).as_torque(), but I doubt it's possible to do something more elegant in Rust.
I don't believe that there is a very much simpler method of doing so. I would love to see something like: let mut x = [DELIM; 256]; x[0] = ZERO; x[' ' as usize] = SPACE; x['A' as usize ... 'Z' as usize] = CHAR; x['a' as usize ... 'z' as usize] = CHAR;
&gt; but isn't JSON also useful here because it's part of the language server protocol? Indeed, my whole argument being that I wish LSP was built on top of *another* protocol :)
As a crude hack for debugging processes that are indirectly started like this, you can edit it to `SIGSTOP` itself at the beginning of `main`. Then find the PID with `ps`or the like, attach gdb to it, and continue when ready.
Some people did (many of my geek friends) but most people switched to chrome because it was force-installed by third party software (any kind of freeware you dl on SourceForge) 
Nightly crashed around once every 5 minutes on my computer one day a few weeks ago. The next update fixes it though.
is there a bug report?
They will be recorded and made publicly available. Also I think they will be retransmitted in live stream (but I'm not 100% sure)
Just from looking at the API docs, I can already see a problem: Your "conservative set of defaults". For anything other than a primitive comment form, it's wholly inadequate, and the API expects users to do their own research to discover all of the tags and attributes they're supposed to allow. (Much better to either follow or at least offer the "make it safe with minimal mangling" philosophy used in sanitizers like [DOMPurify](https://github.com/cure53/DOMPurify) (Node.JS/Browser. See also their [Security Goals &amp; Threat Model](https://github.com/cure53/DOMPurify/wiki/Security-Goals-&amp;-Threat-Model) document.). As-is, it invites users to either limit their XSS filtering to only their comment forms (ie. you're screwed if an attacker gets article-posting permissions) or make the HTML equivalent of the mistakes described in Eevee's [The Dark Corners of Unicode](https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/). Beyond that, looking at your "conservative defaults" doesn't give me confidence in ammonia. (You seem to have chosen them based on personal experience, rather than by a more solid metric. As such, they are a disaster in the making when ammonia starts to get used in non-latin languages, academic contexts, etc.) Here are all of the tags that are included in the configuration I built for the `lxml.html.clean` call in my static site templater which are missing from yours: ### Tags which are perfectly reasonable to use within an article * `abbr` and `acronym` (Used with the `title` attribute to create tooltips and provide supporting information to assistive technologies.) * `aside` (Used for indicating an aside, so CSS can apply fancy typesetting to it and assistive technologies can handle it better.) * `bdi` and `bdo` (Used to prevent Unicode LTR/RTL swapping characters from mangling the entire page, and to fix flaws in how a span of text's directionality is getting rendered.) * `center` (Harmless and generated by some JS frontends or markup parsers.) * `cite` (Used within `q` and `blockquote` to indicate the attribution) * `data` (Used to annotate a human-readable piece of data with it's machine-readable counterpart.) * `details` and `summary` (Used for implementing expander/collapser widgets without JavaScript.) * `dfn` (Used to indicate the "defining instance" of a term. Basically, a clue for anything which wants to implement some kind of "What does this mean?" or "Jump to definition" functionality.) * `div` (Harmless and sometimes used to work around bugs or edge-cases in how the content interact's with the site's CSS) * `figure` and `figcaption` (Used for imparting extra semantic context to an `img`, `code` block, etc.) * `footer` (Used for indication the footer for a `section`, `article`, `aside`, or `nav` element. Like a `div` with extra meaning.) * `h4`, `h5`, and `h6` (If you're allowing `h1`, `h2`, and `h3`, then disallowing these just comes across as the kind of over-opinionated which drives people away.) * `hgroup` (A harmless and partially-implemented, but retired-in-some-standards experimental extension to HTML intended to allow proper outline building for markup like `&lt;hgroup&gt;&lt;h1&gt;Title&lt;/h1&gt;&lt;h2&gt;Subtitle&lt;/h2&gt;&lt;/hgroup&gt;`. * `ins` (If you're going to allow `del`, you might as well also allow the other half of the "indicate edits" duo.) * `kbd`(Used to indicate user input. Try `&lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt;` on GitHub or StackOverflow.) * `map` and `area` (Image maps may be archaic, but they're not deprecated.) * `mark` (The equivalent to highlighting with `background-color: yellow`that actually carries semantic significance.) * `samp` (Used to indicate a sample of a program's output, such as in a terminal.) * `span` (Harmless) * `small` (Harmless ever since browsers implemented minimum font sizes and has expressive power. I think I also saw it generated by a BBcode parser.) * `q` (This is to `span` as `blockquote` is to `div`) * `ruby`, `rp`, `rt`, and `rtc` (Used for pronunciation annotations for asian text. Rendered in a manner somewhat similar to the `sub` and `sup` tags you already allow.) * `time` (Used to annotate human-readable times with their machine-readable forms. For example, to provide both an "X days ago" and a concrete timestamp in a post or comment's header.) * `tt` (A harmless precursor to tags like `code` which wasn't deprecated until HTML 5.) * `u` (If you're going to allow `strike`, despite it being one of those "no semantic significance. Consider CSS with `span` instead" tags, you sould also allow `u`. Heck, `u` is part of the Bold/Italic/Underline trinity that all "rich text editors" seem to consider essential, while `strike` is less likely to be offered.) * `var` (Used to indicate a variable in a math or programming expression.) * `wbr` (The HTML-level equivalent to a Unicode soft hyphen character, used as an invisible "prefer here if you need to break for word-wrap" hint.) #### Table tags * `caption` (Gives the table a title without putting it in a cell) * `col` and `colgroup` (Used to assign `span` attributes and CSS properties once for all cells in a column) ### "Div with extra semantic meaning" tags which operate at a higher level than "in an article" but are still safe to use within the "content region" of a page template * `article` * `header` (Used to indicate the header for a "sectioning context". For example, the header to the site template as a whole or the header to an article, containing the title, author citation, estimated reading time, etc.) * `nav` (Used to cue assistive technologies as about things like site navigation headers and in-article tables-of-contents.) As for attributes, there are quite a few you're missing. For example, here are just the ones I use in my own static site templater, excluding some you'd probably want to add as well: * The various attributes unique to the elements you're wrongly excluding * The `align` attribute (It may be deprecated or obsolete in all contexts, but it's still harmless. Let the user set stricter defaults that fit *their* needs.) * `&lt;* lang=""&gt;` (Indicate the language that an arbitrary subtree of the DOM is written in.) * `&lt;a hreflang=""&gt;` (Provides a machine-readable hint about the language of the target resource) * `&lt;del cite=""&gt;`, `&lt;ins cite=""&gt;`, `&lt;q cite=""&gt;`, and `&lt;blockquote cite=""&gt;` (Provides a URI to explain the change or provide attribution for the quote) * `&lt;del datetime=""&gt;` and `&lt;ins datetime=""&gt;` (Provides a machine-readable timestamp for the change) * `&lt;ol start=""&gt;` (Used to start counting at something other than 1) * `&lt;td colspan=""&gt;`, `&lt;th colspan=""&gt;`, `&lt;td rowspan=""&gt;`, and `&lt;th rowspan=""&gt;` * `&lt;td headers=""&gt;`, `&lt;th headers=""&gt;`, and `&lt;th scope=""&gt;` (Used to semantically mark up tables for assistive technologies and/or machine-parsing.) * `&lt;table summary=""&gt;` (Deprecated, but do you really want to strip a harmless cue for assistive technologies?) Beyond that, I can easily see people getting confused by the lack of "the default is" notes on the API doc entries for things like `link_rel`. (I'm *still* confused. The information on panics says it's set by default, but not to what, the default settings documentation doesn't mention it, and the `link_rel` part recommends setting it to `noopener`.) Finally, one place where I notice that your API is less powerful compared to other sanitizers is that your URL scheme filter can't be used to constrain valid target domains the way a regex or a filtering callback.
Vtables always start with a destructor, a size and an alignment, before all the trait methods.
Uhg half of my addons aren't compatible with the beta. It is blazing fast. Are there any decent alternatives to lastpass?
No, it's not: https://godbolt.org/g/5Tc6iA But even if it did manage to optimize it, having an explicit table would still be better, because it has a predictable behavior. If someone comes later and modifies the code, or the compiler version is updated, it can suddenly stop doing this optimization, and you wouldn't know about it.
I think with browsers there is a real trend of people following developers. FireFox is great, and it's great it's getting way faster, but the tools still more improvement. This is a major issue for switching. It's that 90/10 factor, where I feel the tools are only about 10% away but would take a lot of effort to cover that gap.
Good point, that explains how it is possible to get sizes of trait objects. So I assume `size_of_val` intrinsic works like this: * For `T: Sized`, return `size_of::&lt;T&gt;()` * For `[T]`, return `transmute::&lt;_, Repr&lt;T&gt;&gt;(slice).len * size_of::&lt;T&gt;()` * For trait object, take size from vtable. And `align_of_val` does corresponding thing with alignment. Correct? One remaining point is how structs with last unsized member are represented. For example, how does `Rc&lt;str&gt;` manage to deref to `&amp;str` correctly? Because it does not seem to contain slice length directly (source is [here](https://doc.rust-lang.org/src/alloc/rc.rs.html#432-448)).
Yes, I was also hoping I could write something like this, clean and simple. Too bad it's not possible :(
Thanks for the comprehensive list of "safe" HTML tags. We should definitely use more permissive defaults. I filed https://github.com/notriddle/ammonia/issues/54. &gt; Beyond that, I can easily see people getting confused by the lack of "the default is" notes on the API doc entries for things like link_rel. Filed as https://github.com/notriddle/ammonia/issues/55. &gt; Finally, one place where I notice that your API is less powerful compared to other sanitizers is that your URL scheme filter can't be used to constrain valid target domains the way a regex or a filtering callback. That would be https://github.com/notriddle/ammonia/issues/47.
LastPass has promised to update the extension prior to FF57's launch.
I work on actor library [actix](https://github.com/fafhrd91/actix), should be close to 0.1 release
&gt; The benchmark measures a completely different situation too. No, not quite. The benchmark is concerned with something that happens on every keystroke in an editor and unders this budget investigates how much encoding/decoding matters. It doesn't. This is the same situation for the LSP. You bring up doubts that JSON is sufficient and mention that other solution would be drop-in and better, but you do not provide examples, data, benchmarks or implementation to back that up. Just your gut feeling that this design choice is wasteful. I doubt using anything else but JSON would have made LSP so successful. For example, I have plenty experience with protobuf and it is hard to integrate it in some places - for example there is limited language support reducing the reach of the LSP protocol would it use it. Debugability would also be reduced. Protobuf has its places, but for the goal of he LSP, plain text + JSON is a good choice: Humans can read it and every language on earth has JSON parsing support. Most languages (e.g. Rust) even have a lot of optimization effort put into JSON specifically since it is so important. JSON messages are also trivially extendable with extra data to extend the protocol. Also: Good enough is good enough - time debugging and developing matters too. This is optimizating the 1% as stated in my benchmark link above, probably a waste of time and energy. 
&gt; When we create a local variable, it goes below the return instruction pointer (i.e. you’d have to write backwards) safestack presumably? &gt; I hope to try some other classic attacks on Rust to see what happens. Try UAF's https://play.rust-lang.org/?gist=07efcc7390d5cf3233c15e2696478a6e&amp;version=stable
As part of the work on build system integration, the Cargo team is [collecting information](https://paper.dropbox.com/doc/What-do-Rust-tools-need-from-the-build-system-bxX9pq7l2E7Djq9J7dAy7) about what Rust tools need from a build system. Today, tools largely assume and use Cargo for these purposes. Our ultimate goal is to provide a single, uniform interface -- perhaps through Cargo -- that tools can rely on for all of their build system needs, but that will interface with external build systems as needed, without the tools having to know anything. In other words, we want Rust tools to "just work" regardless of how the Rust project is integrated into a larger build system context. But to do this design, we need to fully understand the needs of Rust tools. That's where you come in! Please have a look at the above doc and add your thoughts, liberally.
They're talking about Google putting Google Chrome advertisements on their hompage (i.e. the most visited website in the world).
I suspect Alex Crichton was selected among the Rust team because his name ensured the first place in the list of speakers. Well done gents!
Bitwarden is awesome and it's FOSS. Lastpass will be ready in November.
Since the Redox developers might be too modest to mention this, friendly reminder that anyone can sponsor Redox development via Patreon! https://www.patreon.com/redox_os Or more donation options here: https://redox-os.org/donate/ 
Rc&lt;str&gt; can be thought of as being laid out like the tuple `(*const (RcHeader, str), usize)` Just like how with Box&lt;TraitObj&gt; it gets laid out like `(*const (), *const TraitObjVtbl)`
&gt; Nightly Uhh... Nightly is by its very definition a "Work In Progress", and its very purpose is to gain exposure so as to locate bugs. It's not exactly surprising that it would therefore *contain* bugs. Of course, we all wish it didn't :)
&gt; that Rust is storing things "on the stack" to be faster. It's not. It *is* faster. A single stack allocation for an entire structure is a single increment of the stack pointer. A heap allocation by itself is far more complex and slower, and if you're doing one for each non-primitive item in a structure, it's an enormous difference in performance. Compounding this issue, the stack is almost guaranteed to be in the processor's cache, whereas an arbitrary memory address is almost guaranteed to _not_ be in the processor's cache, which means you're introducing a massive CPU stall while you wait on far memory. Deallocating heap memory is not free, whereas deallocating the stack is simply returning from the function. [More info here](https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap/80113#80113), if you want. EDIT: Obviously, Rust does not decide whether to store an object on the stack or heap based on "struct vs class" like some languages, _anything_ can be on the stack or in the heap, and that's up to the user of the structure, but if you have a structure that is on the stack, a non-trivial member will be inlined in the struct on the stack, rather than pushed off to the heap like in some other languages.
Why not do that for all structs?
&gt; Is a buffer overflow possible? &gt; Not really. &gt; Buffer overflows rely on the fact that the buffer is pushed to the stack before the return instruction pointer (and, of course, a missing bounds check). Rust sticks bounds checks all over the place, but even if you bypass those, either through abuse of unsafe or custom types that skip bounds checks, the stack memory layout makes it really difficult (if not impossible). The OP is specifically targeting ROP here (Return Oriented Programming), there are other forms of buffer overflow which may aim at overwriting bits of the heap, etc... instead of the stack. And of course, an unsafe index operation with a negative index (bitwise interpreted as a really large index) can perfectly reach "back".
This is really cool! But what about SpiderMonkey it seems much slower than Google V8? Will it rewrite in Rust with much more optimizations?
That has been changed to "Other important news is that we are now maintaining the RustType crate, which can be found here, under the redox-os Github organization."
This wording has been changed
I have changed it to be more accurate. Since there are 4 different ANSI color encodings, I have listed them like this: "Ion now supports 8 color, 16 color, 256 color, and 24-bit color using standard ANSI encodings."
&gt; &gt; The benchmark measures a completely different situation too. &gt; No, not quite. The benchmark is concerned with something that happens on every keystroke in an editor and unders this budget investigates how much encoding/decoding matters. It doesn't. This is the same situation for the LSP. The benchmark does measure a completely different solution: it ships the *content of the files* with each query. From the link: &gt; Let's assume that the files are 25kb. So 100kb (uncompressed) needs to be shipped to the server for every keystroke in the editor. At a typing speed of 60 words per minute, we have a 200ms budget for the round trip. At this point, of course having a verbose protocol matters little, the bulk of the payload is in the files themselves. --- This is, however, not what I wished to point. Measuring the end-to-end latency is only half the story, it is also important to account for *efficiency*. What if the JSON encoding/decoding, *in the case of the RLS*, takes 75% of the response time when a binary protocol would be 10x faster (resulting in an overall drop of -67.5%)? We don't know. JSON was picked. There doesn't appear to be any study which compare the overhead of using JSON over ProtoBuf/Cap'n'Proto/SBE/&lt;insert name here&gt;/... for the various usecases of the LSP. &gt; Just your gut feeling that this design choice is wasteful. My experience (admittedly in a different domain) is that JSON parsing is extremely expensive compared to binary formats and should be reserved to rarely used paths (configuration is a good example where it works pretty well). My experience is that JSON also opens a variety of bugs due to being delimiter-based (file names will need be escaped or encoded, as well as code fragments, as well as...); on top of adding another source of inefficiency. The gut feeling of the designers of LSP doesn't exactly reassure me; I would have preferred they did their homework and presented benchmarks. It's not "good enough" if there's no measure of how well it does compared to other solutions.
Of course it is faster to store it inline. But Rust doesn't do it _because_ it's faster. Rust stores the value inline because you didn't ask it to move the value elsewhere. If you asked it to (e.g., with a `Box&lt;T&gt;`, or an `Arc&lt;T&gt;`), it would have moved it out-of-band, even when that's slower.
Ha this is exactly what I'm going to do. My mom uses a ~$200 laptop and her primary application is chrome right now.
Last I heard, it sounded like if that were to happen, would be far away still. Not sure about the speed thing though. The latest benchmarks I can find are Octane, which was retired when google discovered engineers were over-optimizing for it at the expense of real world performance, and Firefox was only a bit behind there. But I am curious where the data comes from.
An interesting paper on manual memory management; although I find the claim rather *overreaching*. **TL;DR: Using the 64-bits address space, the allocator will unmap mostly freed pages and handle segmentation faults raised by the host with either a redirect (lazy patching) for moved object or an exception for freed objects.** The authors claim they achieve temporal memory safety and type safety, however I do not see: - references to stack objects being correctly handled, - references to objects in shrunk arrays being correctly handled, - references to objects in unions being correctly handled. And I am also not clear how they handle hashing of pointers: interpreting the pointer as an integer and hashing that will not work with lazy patching. So, the paper is relatively interesting, but I do not see how to extend the approach to languages such as C, C++ or (unsafe) Rust, and therefore it seems limited in applicability to compiling managed languages to native code. Still, the particular allocation strategy described may be interesting as another defense in depth for Rust programs (to help defend against incorrect unsafe code).
&gt; I wish ticki would focus on getting TFS to build more than writing out subsystem stubs that do not compile. Or at least not commit them. I regularly write large swaths of code which contain holes and don't compile, but I don't push them upstream in that state!
There's a crate called [init_with](https://crates.io/crates/init_with), that creates a static array from a function that generates each element from an index. That would let you write this: enum Token { ZERO, SPACE, CHAR, DELIM, } fn token_init(index: usize) -&gt; Token { let c = (index as u8) as char; match c { '\0' =&gt; ZERO, ' ' =&gt; SPACE, 'A' ... 'Z' =&gt; CHAR, 'a' ... 'z' =&gt; CHAR, _ =&gt; DELIM, } } map = &lt;[Token; 255]&gt;::init_with_indices(token_init);
"a few weeks ago" might be around when we enabled stylo on nightly for the first time, it was super crashy (specifically, Rust panic-y) for like a week then. Since then it's been much better. Nightly used to be _super_ unstable but for like a year it's been actually pretty pleasant as a main browsing instance. It only gets wonky around the time of introduction of large new features (like stylo, or activity stream, or w/e). I can live with that.
Oh right, I see: `let rcbox_ptr: *mut RcBox&lt;str&gt; = mem::transmute([ptr as usize, value.len()]);` And that size is only for the last field of `RcBox` - the string itself. So from that I would deduce that when you have a pointer to unsized struct (which has last unsized field), the size next to pointer is size of last field, instead of whole struct. I also checked LLVM IR that compiler emits, and indeed it seems to work like that. 
I looking for a bit more clarity regarding `UnsafeCell` and FFI. I'm guessing that `UnsafeCell&lt;*mut _&gt;` is the correct pointer type for accessing a region of memory aliased between Rust and something foreign. Specifically I've been creating X11 `XImage` and Wayland `wl_buffer` objects. My concern is that the optimizer needs to know that writes to these areas must happen before FFI calls like `XPutImage` and `wl_surface::attach`. The Wayland case has the extra wrinkle of shared memory via `mmap`. I know that UnsafeCell causes rustc to not emit `noalias`, but I don't quite understand when and why this is necessary when doing FFI.
Your commit messages on this project are wonderfully entertaining
Eh. Adblock on mobile with sync to desktop was enough for me. Add the performance, and I'll be getting everyone around me moved over.
Installed Firefox Nightly after seeing the hype. The hype is real. I've felt that Firefox has seemed perceptively slow, especially under Linux for... more than a decade. *Not anymore.* If I could get the font rendering to stop being slightly different than every other application on my machine, I'd switch back from Chrome. And oh goodness, the Photon work has paid off. The UX has felt haphazard since Australis and it now feels much more cohesive to bottom. The customizable panel, the comprehensive menu. The simplified preferences... Really amazing stuff. Reminds me I need to go put my money where my mouth is and donate to Mozilla. &lt;3 to those who helped make this!
 let size: u32 = read_string().parse(); let arr = vec![0; size]; Here, we know the size required for the stack, but the size for the heap is unknowable. I am not sure I quite understand your second paragraph though.
Lookout for [the dwarfs](https://en.wikipedia.org/wiki/File:Capgeminiusz_Programista.jpg)! :D
SpiderMonkey is not much slower than V8...
It sounded like that was unlikely, due to very large cost to rewrite with small potential gains to be had. But you never know, things may change; someone may try it.
There's another point. Perhaps the struct is in the heap anyway, but if its members were heap allocated then accessing them will require following two pointers. Also allocating the whole thing will require many heap allocations instead of just one, fragmenting the heap.
Oh wow! I've been trying to drop Chrome(ium) for years now, but each time I tried to go back to FF, it was just way too slow on Linux (Windows felt much snappier). But the beta changes everything, it feels really snappy and smooth. I'm sold, and FF will be my default browser as soon as... There is a good Vim extension that's compatible. Sadly Vimperator and VimFX are not. :/ There is Vimium-FF, but it's really buggy on 57. Any recommendations for an alternative? (Ublock is my only other essential addon, and it seems to work fine on beta).
Isn't the HTML5 video DRM also a plugin?
*gets the megaphone* *screetch* *taptap* Marketing is only partially money, it only makes some things easier.
Many people switched to Firefox some years before that.
If everything you do is sequential, you'd probably want to pass mutable references to your connexions on a per-use basis to each of your methods, as others have suggested. Depending on whether you need your Connection to have all that many methods or not and whether you need to deal with return values (which, considering how IRC works, you probably don't), however, this sounds like a good use case for a [multiple producers, single consumer queue](https://doc.rust-lang.org/std/sync/mpsc/), since both Channels and Users can send data through your connection at any given time, but it's being used more as a shared bus than as a mutable object. 
Can anyone on a Mac tell me if it runs as well on Mac as it does Windows? 
That's what Microsoft believed as everyone was switching to Chrome.
It runs way faster on Mac, I've not compared to windows as I do not use it.
Thank you. Will try if I find the time (really need to finish my slides for the RustFest talk first).
N ot the same API as flash. It's different (I'm not a dev)
I'd love to be there. Alas, with two RustFests, my travel time for this year is exhausted.
Good to hear! 
Short version: speed and register allocation. Medium, partially-accurate version: It's faster to copy a register or two than to do memory access, but it's also faster to do memory access once than to do it more than once. Long, fully-accurate answer: With a smaller struct could fit in the same cache line as the rest of the stack frame, copying leads to good cache behavior, especially if the function in question can use the output as a temporary. If it's big enough that the copy will cause a cache miss, it's probably a good idea to avoid copying whenever possible, so we can eat an extra indirection on all operations. 
This is actually just how we write Java... most data is immutable, most IO is owned by services to which we past fairly lightweight objects, etc. The only "under the hood OOP magic" comes from Hibernate, and it tends to be limited to a few layers of the application, cause nobody wants to track transaction scopes and detatched objects with lazy references and similar garbage. So yeah, the design is basically always `connection.send_chat(user.get_message())`. Actually, most of the libraries I worked with follow similar patterns. I have very rarely seen the traditionally espoused OOP design where "things know how to send themselves" or whatever, and find doing the same thing in Rust to be very natural. The closest I can think of is when something is basically just a builder pattern, which feels like it can be fairly easily transformed into one that does not require any IO objects internally. 
Great, makes sense, thanks! If the struct is really small (just wraps a u32, for example), can the compiler optimize that to just setting a single register? I know C calling conventions are complex for returning structs, and I wonder how rust and llvm do it.
*cough* the real solution here is to use a reader monad, but thats not a thing in Java OR Rust *cough*
Is there any difference between debug (what the author seems to be using) and release builds here?
&gt; The first thing that I noticed is how small the stack for each function is–it’s only 2 bytes: &gt; address &gt; 0x7fff5fbffa80 top of frame &gt; 0x7fff5fbffa78 rip &gt; 0x7fff5fbffa70 rbp/arglist/locals. Typo; you mean 2 pointers. Also the tables are really hard to understand; you don't lay out the full stack for each example, you just look at the locals and the stack frame separately and expect people to put the two together in their heads. I have some issues with the content: * You point out that in C locals are stored below the return address on the stack while in Rust they're stored above it; neither C nor Rust really define anything about how the stack is structured, that's entirely up to the platform's ABI. If you're on Mac then C will use the Mac ABI, whatever it is. Rust will do whatever LLVM thinks is a good idea because when compiling pure Rust LLVM has all the information it needs to make those sorts of decisions. If you call a C function from Rust, it will presumably follow the ABI for the target platform. I'm also unconvinced that this actually has any security implications; it's *nearly* as easy to underflow a buffer as overflow it, if (like many lazy C programs) you use a signed `int` for an index. * You don't compare apples-to-apples Rust and C code. You show one thing in Rust, then an entirely different thing in C, then see how they are different. * You try to do a stack smash with a buffer allocated on the heap. If you want to smash the stack you should probably do it on the stack.
In Servo the JS runtime is used to manage DOM and some other resources. I don't know how much of that is in Quantum, but improvements in JS runtime performance could be important.
My suggestion would be to keep an eye on Vimium. It's been working great for me, the only thing that doesn't work yet that I used is `F`. It's only recently started porting, and with an influx of new users with Fx 57 it should probably improve soon.
Great, keep up the good work! I really like the book so far and impatiently await the final release 😃
Can't you use monads in Rust?
&gt; And oh goodness, the Photon work has paid off. It's amazing, UI changes are usually never received well, but I've been following the comments on Photon for a while, and there actually are many positive ones. The performance increase I'd expected to be received well, but apparently they did a good job on this, too. Also: RemindMe! 1 week has /u/colemickens donated already? :P
I've been pretty fortunate—my designs have generally worked well in Rust, without too much fuss. I think that some of that was caused by that fact that I've written a lot of Lisp and Haskell in my life, and so I tend to be biased in favor of functional programming and (mostly) immutable data. In your case, a lot will depend on how you structure your program. Is there any multithreading going on? Are there delayed, asynchronous responses? **The simple version: Everything is single-threaded, nothing is async.** In this case, I'd probably build the bot like a web server: There would be a top-level loop that listened for incoming messages, constructed an `IrcRequest` object, and looked up a handler routine. Then I would pass the `IrcRequest` object to the handler routine, and expect it to return an `IrcResponse` object. trait Handler { fn handle_request(req: &amp;IrcRequest) -&gt; Result&lt;IrcResponse&gt;; } You could set up a system for routing requests depending on what's in the IRC text. An alternate design might be: trait Handler { fn handle_request(conn: &amp;IrcConnection, req: &amp;IrcRequest) -&gt; Result&lt;()&gt;; } Here, instead of returning a result, the handler would call methods on `IrcConnection` directly when it wanted to respond. Note that `conn: &amp;IrcConnection` here is immutable, because—if we implement it correctly—we don't need to actually change anything in the `conn` object. Instead, we just read and write the underlying socket. In a more complicated design, you might actually implement `conn` as a wrapper around an `RefCell&lt;ConnectionImpl&gt;`, allowing some secret internal state for things like buffers or whatever. And as for the user example, I'd actually move the object to the connection itself: impl IrcConnection { // ...other methods here... pub fn message_user(user: &amp;User, message: &amp;Message) -&gt; Result&lt;()&gt;; pub fn message_channel(channel: &amp;Channel, message: &amp;Message) -&gt; Result&lt;()&gt;; } In each of my examples, you can see that I'm minimizing the amount of code which tries to hang onto an `IrcConnection`. Users, channels, etc., have no access to the connection at all, and handlers only receive an `&amp;IrcConnection` that they're not allowed to hold onto. **A multithreaded chat bot.** Here, the easiest thing to do is to have a one connection per thread. **An asynchronous chat bot.** I would _not_ recommend this project for a Rust newbie, because you would need to use Tokio directly, and that's not a good way to get started, because the error messages can be giant and evil. But work is being done on `impl Trait`, `#[async]` and `await!()`, and that should make Tokio much nicer to use. By next summer, there's a good chance that Rust will have very nice high-performance async programming.
Did this. Saved 0.05 seconds. YMMV.
I tried it on Alacritty, the terminal emulator, and it shaved off about 10 seconds, which was roughly 14%. If your source code isn't large enough to have a substantial compile time, it's not going to save you much tjme. Linking time wouldn't be helped by this.
HN has a big thread about vim extensions https://news.ycombinator.com/item?id=15339057
In terms of why it's necessary for FFI: If Rust assumes something will not change because you never modify it (either because you only have an immutable reference to it, or even if you have a mutable reference but you don't modify it (because logically to Rust only you can modify it)) then it will cause race conditions. Rust will try to reduce loads from memory as much as it can, so if it can optimize by not fetching from memory if it "knows" it hasn't been touched since you last got it it won't. By putting it in an `UnsafeCell` then Rust will not make that assumption and always fetch it. Off topic, but what are you writing that requires such low level manipulating of both X11 and Wayland primitives?
I think `UnsafeCell` has more to do with situations where you're going to take pointers to storage _within_ the cell, like `UnsafeCell&lt;SomeStruct&gt;`, and less to do with situations where you're holding a pointer to someplace else? (Though it might be that the location you're pointing _to_ is inside another `UnsafeCell`.) Is the optimizer allowed to move writes across opaque function calls? I assumed it wasn't, for exactly this reason.
Hello! Another simple option would be to use serde_derive's [serialize_with](https://serde.rs/field-attrs.html#serdeserializewith--path) to implement this. I've updated your example [here](https://play.rust-lang.org/?gist=4b84ee57bde81d19c2e96e443750b168&amp;version=stable).
Nice! I didn't know about that field attribute. I've [updated it further](https://play.rust-lang.org/?gist=3b5fd975057430dfd5a586bb733e2f96&amp;version=stable) so that the `serialize_array64` function is generic over _any_ 64 value array. For Serialization, we can actually go even further, and make it [generic over _any_ type or length of array](https://play.rust-lang.org/?gist=09ed06e679955e5c1e31fc6888dd96ae&amp;version=stable). For Deserialization, I *think* you would have to implement it for each array length beyond 32 that you're interested in. You actually might not have to. tagging OP: /u/Kvikal 
It would be easier as a vector library. Force cross length is (vector) torque, force dot length is (scalar) work. 
The only way to keep XML sane is to require that input only use a subset of the permitted features from the standard, whereas supporting all of JSON is trivial. Also you need a schema to decide what's a number/string/boolean with XML, whereas with JSON that's implicit in the encoding. JSON isn't perfect either -- the commas are a pain in the neck when editing and are completely redundant in the encoding -- but it's better than the alternative.
Sorry, but it doesn't work. init_with works only with arrays smaller than 32 elements, because Rust doesn't have const generics yet.
No higher kinded polymorphism. The Associated Type Constructors RFC was merged though, which is a whole other rabbit hole, but it helps a bit, though I am not sure the reader monad would be worth using without extensive syntactic support either way.
One of the reasons for this is that it's less safe than it sounds. In this case there's already some complexity for the compiler to figure out; `loadTokenKinds` must not be called after `loadTokens` has been called, for example, because it can cause `tokenKinds` to reallocate. However, since a `HashMap` allocates things at a stable location on the heap, we at least don't have to worry about what happens if the larger `Board` struct moves around... ...that's not true of other data types though! If `tokenKinds` was a tuple of ints, say, and you had references into it, those references would be _pointing to the stack_, and moving the `Board` in any way would invalidate them.
&gt; safestack presumably? Are you sure? As far as I've read, that would only apply if you stored dynamically accessed things on the stack (like arrays) but the code only stores plain integers. Also, I am not even sure the auther is correct. At least for me locally, the stack layout is exactly the same as expected from C. And this excerpt from the article: 0x0000000100003148 &lt;+8&gt;: movl $0x3,-0xc(%rbp) 0x000000010000314f &lt;+15&gt;: movl $0x4,-0x8(%rbp) Here, `3` and `4` are moved to `rbp-0x8` and `rbp-0xc` respectively. If rust doesn't do some funny stuff to RBP, this is an address below (assuming stack grows downward) the return address/saved bp. Just like in C.
This may be sacrilege but Powershell combined with the InvokeBuild module is remarkably usable for build scripting. Edit: and it’s cross platform. 
&gt; Are you sure? Nope.
Is a local variable good enough if the code in between might panic? I know destructors are _supposed_ to be called, but I remember scary stories about situations where that doesn't happen?
Because they saw the ads on TV.
Reading the paper right now, it appears all these require additional runtime checks, yeah? Every time that you dereference a pointer it'll need to determine whether the data is still valid, and AFAIU this can't even be ameliorated by branch prediction. Furthermore, there's this quote: *"We do not guarantee that all dereferences to deleted objects will throw an exception. While the weaker semantics is crucial for achieving good performance, it introduces non-determinism and may result in exceptions that only surface during real use."* So not only are its safety checks dynamic, they also admit false negatives, unlike a sound type system. The rest of this paper is going to have a hard time making up for that. :P
Which features would you omit to keep XML "sane"? In my opinion removing DTDs leaves a very sane subset (I think XSD is nicer anyway).
implementing Deserialization was... nontrivial. [Here is an example with it.](https://play.rust-lang.org/?gist=7b1e6161bbb93a1d9db662623e226649&amp;version=stable) /u/Kvikal 
IIRC, Boost deals with this using integer parameters in a single common dimension-aware type and using addition and subtraction as necessary in its templates. 
So basically, instead of chasing segfaults, one has to chase `DanglingReferenceException`s. It's the same thing, just marketed as "harder to exploit". No, thank you.
I tried it on ggez, which usually takes 10-20 seconds to build on a 4-core i7 laptop... so not a huge project, but not tiny either. The 0.05 second difference is when I build all dependencies as well; I don't know how that interacts. Trying to build ggez alone: With `codegen-units=32`: Finished dev [unoptimized + debuginfo] target(s) in 8.8 secs 17.76user 0.48system 0:08.23elapsed 221%CPU (0avgtext+0avgdata 602212maxresident)k with no `codegen-units`: Finished dev [unoptimized + debuginfo] target(s) in 10.98 secs 10.84user 0.28system 0:11.13elapsed 99%CPU (0avgtext+0avgdata 592900maxresident)k So, 2.1 seconds shorter, or about 20%... honestly not terrible. Though since the build with all dependencies is unaffected, I assume that some of those are taking 20% longer as well. Also amusing that it's taking 17.8 seconds of CPU time vs. 10.8 to do the actual build with `codegen-units=32`; it just is capable of spreading nearly twice as much work over more cores. Anyway. `codegen-units` is situationally very helpful but it's not a panacea.
&gt; it appears all these require additional runtime checks, yeah? I understand it in this way too. Funny that they claim reference counting is expensive...
Also, the main reason the average Joe uses Chrome nowadays is due to Chrome's aggressive preinstallation and bundling deals Google has struck.
This is only the case for people with some technical ability. The general population tended to fall into Chrome via sideload mechanisms.
Well it technically is harder to exploit, which might make it a decent target for transpiled C or C++ code. But yes, it doesn't look like it's trying especially hard to compete with Rust on performance and security.
I just saw, F is already fixed on master, waiting for a release.
Oops, I'd forgotten about that. If you want, you can patch `init_with` itself to cover arrays larger than 32 elements fairly easily (it's built on a recursive macro), or you can do something like this: let unsafe_map = [[Token; 17]; 15]::init_with_indices(|i| [Token; 17]::init_with_indices(|j| token_init(17*i + j)) ); let map : [Token; 255] = unsafe { std::mem::transmute(unsafe_map) }; (If you're willing to accept an array 256 long, then the numbers become the much-more-obvious 8 and 32 instead.) 
I just got back to my personal computer, which has an 8-core / 16 thread Ryzen 1700X in it, and I did some testing with ggez. Here are my results: mode | codegens | time #1 | time #2 ----| ---- |-------|------- clean build | 1 | 69.3 | 67.6 clean build | 32 | 61.48 | 60.8 `touch lib.rs` | 1 | 17.4 | 17.3 `touch lib.rs` | 32 | 8.43 | 8.36 These results are _very_ nonlinear to the number of cores, but with a ton of brute force, it looks like a 2x speedup for iterating on changes on `ggez` on this machine. A clean build is like 13% faster. On a machine with fewer cores, I could easily see the clean build not being any faster, and only marginal results with the iterative changes. When you say 4-core, is that 4-core / 8-thread, or 2-core / 4-thread? A lot of laptop "i7" processors are really only dual core. If it's with a true quad core, the speedup you experienced isn't too exciting.
*Maybe* the optimiser will remove almost everything, since the code have no real side effects.
It would be easier to list the features I'd support, rather than the ones I'd omit. For one project we settled on: UTF-8 only, tags only, no attributes, only using 3 of the predefined entities. For text-formatted data transfer you don't need much else. For this project we especially needed it to look very clean, trying to avoid any obviously redundant information, so tagging types with attributes was out. It validates as XML, XML tools can be used for checking and transformation, it's readable by anyone, and we don't need a huge XML library to parse it. XML tools might destroy some whitespace information, but we have to live with that.
 My biggest take away is that an allocator that has compile time object lifetime annotation information allows for extremely large performance gains by clustering data that lives and dies together. The system has _some_ good ideas. It is extremely informative in how to do reference update in JIT'd VM environments, I learned a ton. The central thesis seems lacking.
Still no native Wayland support through :( 
Is it in the android beta yet? 
Looking through crates that use proc macro hack, I found this: https://docs.rs/array-macro/0.1.1/array_macro/ From a first glance it looks promising.
&gt; it was just way too slow on Linux (Windows felt much snappier) Have you force-enabled OpenGL compositing in about:config?
&gt; I'm also unconvinced that this actually has any security implications; it's nearly as easy to underflow a buffer as overflow it, if (like many lazy C programs) you use a signed int for an index. Signed-ness doesn't matter if your offset is pointer sized, `0 - 1 + p` works out the same no matter which you use.
Looks good, but I suspect it might require you to turn up the macro recursion limit. (And subsequently kill your recompile speed)
4-core/8-thread. It's weird, yeah.
Nightly is life changing. Best browser I've ever used hands down. I can't wait until FF57 is fully released. I was a Firefox user a long time ago and I'm _so glad_ that they're the best choice in browsers again.
I haven't tried it or figured out how you'd write it, but what if you left it in C code and used it from Rust as an extern object?
Lastpass has been the only painful addon loss for me since switching to Nightly Firefox. I've begun to use lastpass-cli and written some convenience scripts that I can access from the shell or other tools that can access the shell like Automator, Keyboard Maestro, or TextExpander to make getting my passwords less of a pain in the ass. Honestly I'm glad for it now because I don't need to rely on an extension anymore, but I do miss the handy Lastpass form fill. edit: im an osx user, but I'm sure there are equivalent tools for windows and linux users.
This year I started using FF, I still use Chrome at times but FF is my primary browser in Android, Mac and Windows. The only thing not matching chrome level is dev tools. At times my JS app in dev live reload mode won't launch in FF but chrome it works. So Chrome is still used for development. 
Plus there are actually a surprising number of "only works in chrome" pages
~~recommends~~ installs for them FTFY
&gt; Also, I am not even sure the auther is correct. Even based on their own memory diagrams they aren't. The only difference between the C and the Rust diagrams is that the C one is drawn upside down wrt. addresses. The overall conclusion is also unfortunately misguided. They tried overflowing buffers located in static storage and the heap and from that conclude that stack buffers can't be overflown to overwrite the RIP. It'd be relatively easy to demonstrate stack smashing with an array and unsafe code (as in deliberately evil unsafe code).
Yeah, but none of them do, as far as I'm aware. Hopefully Mozilla can be the first, though.
Those are exactly the questions I have. Side effects must happen in sequence. How do I tell the complier that accessing memory counts as a "side effect"? Without being as strict as `volatile`? In theory the compiler could take a broad enough view to see that I never read from a framebuffer and optimize away all those dead stores and their data dependencies i.e. all rendering. Oops. I think you're right about opaque function calls. But I want to be sure. 
Panic will either unwind all the local variables that should be unwound or abort the process. The scary thing about panic is that it causes unsafe blocks to exit early, so you have to be careful to not leak broken invariants. 
If by 'them' you mean FF and Chrome, you are correct, but a number of Linux browsers do run natively on Wayland (Epiphany, Midori, Qupzilla). Hopefully FF will follow soon.
If you're using nightly, you can temporarily add a call to [`std::intrinsics::breakpoint()`](https://doc.rust-lang.org/nightly/std/intrinsics/fn.breakpoint.html) in your build.rs.
If you're willing to use some nightly features, you could define a trait to set a range, and implement it for slices. You could then just grab a slice of your array and call the function. [Example](https://godbolt.org/g/tzrDQY). It's not quite as pretty as the usage that Nokel gave, but it's not too bad.
Runtime memory defragmenting without needing to stop the world should be the headline feature! The safety guarantee is ho-hum. "Safety" in Rust also means the compiler tapping you on the shoulder to say "that looks like iterator invalidation," "you forgot to synchronize," and "but what if you have a null here?" Preventing use after free and buffer overflow only scratches the surface. Even if Rust isn't the Next Big Thing when it comes to optimized system-level languages, whatever language *is* the Next Big Thing will have a safety model derived from Rust. 
If you're willing to take a look, I swapped away from LastPass to KeePassXC and KeePass2Android.
The fast path (simple deref to live location) has no overhead. They're doing the clever stuff inside the Windows equivalent of a segfault handler. That second point is a problem though.
Have you tried it on some cloud based drive? The main benefit of LastPass is that it is synchronized across... half a dozen devices including phones for me and my wife.
Thanks for your comments. I tried *really* hard to get the buffer onto the stack. Rust wouldn't put it there. Even with a non-mutable &amp;str like "hello, world" will be allocated on the heap. It's been a while since I've looked at stuff like this, and I've always been directionally challenged. I got that bit wrong, and I'll update my post, along with some more apples to apples code. Rust: fn main() { let local = "hello, world"; } [rust](https://i.imgur.com/iAnrBSm.png) C: int main ( int argc, char **argv ) { char buf[100]; strcpy(buf, "hello, world\0"); return 0; } [c](https://imgur.com/USHixSN) In Rust, the pointer to the string is circled in red, and the return address is circled in blue. In C, the string is circled in red and the return address circled in blue. 
&gt;If I could get the font rendering to stop being slightly different than every other application on my machine, I'd switch back from Chrome. I'm on mobile, so forgive the lack of detail, but you can change the font renderer in the about:config to Cairo from the default skia renderer. I just did it today, and it made a good difference. (I believe there's currently a compatibility issue with the latest fontconfig that destroys kerning and quality of fonts. It made my eyes bleed) I'll edit later when I get home/remember to
&gt; neither C nor Rust really define anything about how the stack is structured, that's entirely up to the platform's ABI. While you're right about Rust as defined by it's RFCs not defining the stack's structure, it is NOT up to the platform's ABI. In the end, the compiler decides how it's going to handle the stack. The ABI only specifies the stack layout for "external" function calls, not every single function call made in the binary. &gt; I'm also unconvinced that this actually has any security implications; it's nearly as easy to underflow a buffer as overflow it, if (like many lazy C programs) you use a signed int for an index. Writing to addresses below instead of above is not an underflow, it's still an overflow. I've yet to see a Rust structure which accepts signed integers for indexing, so that already makes it a lot harder.
I have a `Vec&lt;(i32, i32)&gt;`(no `(0, 0)` pairs) and I want to order it by angle (the result of atan2 function). I tried to do this: v.sort_unstable_by_key(|v| (v.1 as f64).atan2(v.0 as f64)); but apparently "the trait `std::cmp::Ord` is not implemented for `f64`". I know that there is no proper total ordering for IEEE floats because NaNs. What is the idiomatic way to do this? A lookup table? Mapping to pairs first?
Yeah I keep it in Nextcloud.
Most ordinary people don’t use bookmarks or browser history. Instead they google facebook or whatever it is that they want to use. It’s rather depressing, really.
I can always predict what the sections about Rust will say, and while they vary, almost nothing surprises me. Why they we're less inclined to go with the other languages is always the interesting part to me. Of course you still get mentions of stuff like dangling pointers. But there is so much to consider beyond just the things Rust seeks to fix. Needs with frameworks, apis, libraries, etc. all weigh into why a lang is a natural choice or not. FFI seemed particularly important here.
Firefox is always my default browser, but I always have Chrome in my PC, because I use chrome for web-developing. To be honest, Chrome's dev tool is so polished and neat
That's a good trick to remember. Thanks.
How do they do that? They can easily compile their code to jvm code?
Some threads about servo ago I asked and a servo dev said they have no plans to re-write SpiderMonkey.
That sounds like exactly what volatile is for? (What about it is too strict?) Though I don't know what the least-unstable way to do volatile in rust is.
Why is a static str allocated on the heap?
If you _know_ you won't have NaNs (i.e. if you would consider it a bug to have them), you can just unwrap the result of `partial_cmp`: v.sort_unstable_by(|a, b| { let ang = |v| (v.1 as f64).atan2(v.0 as f64); ang(a).partial_cmp(ang(b)).unwrap() });
About 6 months of work, pretty nifty.