Yeah, we focussed on Haskell, JS and Prolog. Most of the assignments were in Haskell, which I think helped hammer home concepts. The last assignment was an interpreter for a toy imperative language, written in Haskell and utilising Parsec.
The difference I think is that I is... well you. I is very singular in its meaning. 'We' says you the author, the reader, and more importantly the community at large. When you write a research paper/proof you are claiming it to be truth. That truth is not just the author and what they found or their opinion, that truth is the entire academic field at large (regardless of how profound that truth is).
Good to hear (my younger brother is a freshman at Santa Cruz in CS). My paradigms class at SJSU did Prolog, Scheme, Fortran and some other obscure ones I can't remember.
HOW AMBITIOUS ARE YOU THE ANSWER IS YOU ARE INCREDIBLY AND OVERWHELMINGLY AMBITIOUS. [IMPLEMENT ADDRESS SANITIZER (asan) SUPPORT!](https://github.com/rust-lang/rfcs/issues/670)
(The real (more real) answer is that there is a lot you can do, but the precise answer will depend on your prior knowledge and motivation. Come lurk in #rust-internals and we'll be happy to get you set up with something to do!)
k doing. See you in 3 weeks. Closing the programming hatch now.
Sounds good. I'll check it out tomorrow for it is 1:30 AM here.
Starting from a blank slate, I think it would be fairly easy to do this. All you really need is an abstract zero-sized non-`Copy`^1 `IO` type as a capability token. The basic primitives in `std` which are effectful require an `IO` token. (Any user-declared effectful `extern` functions should do likewise.) Then any function which wants to do IO needs to be passed an `IO` capability. If a function does not have access to one, you can infer that it is pure. Or more precisely, all effects a function may have are reflected in its signature: a function may only mutate something if it gets passed an `&amp;mut` reference (capability) to it,^2 may only "mutate the outside world" if it gets passed an `IO` capability, and so on. This is also essentially what Clean does, and what GHC does under the hood of the `IO` monad (but must keep it abstract, because it can't enforce linearity in the type system). ^1 Non-`Copy` and non-`Clone`, but we can allow making a copy if you have unique access. (So roughly "copy through `&amp;mut`" instead of "copy through `&amp;`".) What we give up by doing this is that otherwise, if the `IO` capability were truly linear, then it would have the effect of linearizing all IO done by any threads, because one thread would need to pass the `IO` cap to the other in order for it to be able to do any IO. But this is probably not something we would want anyways (too painful, and "unique access to the outside world" is an illusion anyways - it's *inherently* shared with everyone else in the world). The basic property we want to preserve is that an `&amp;Fn` closure (modulo its arguments) can be inferred to be pure - it doesn't get to hide away an `IO` cap in its environment, which this preserves. ^2 We'd also be requiring the methods of `Cell`, `RefCell`, `Atomic` and so on to take an appropriate capability. I have [a bunch of notes](https://github.com/glaebhoerl/rust-notes/blob/master/my_rfcs/Purity%20for%20%28almost%29%20free.txt) on this if you want to read more. I'm not as sure about what could be done if we're *not* starting from a blank slate, which we aren't.
This is not helpful, but may I ask why you have TraitPoint and TraitRectangle, considering only one thing implements it, it seems like unnecessary code duplication
For most cases you don't need that. Just write generic code for the trait Write and it works with all types of output streams. If you definitely need it to be generic at runtime either use dynamic dispatch or write a short enum that does what you need.
The best answer I ever had in my practice of asking =) I really like Rustlang for health and friendly community - it reminds me Rails community about 5 years ago. Thank you very much for full-dress and gradual answer!
With associated types, probably yeah. (Second bullet.)
Iterator and container are quite orthogonal in general. You can iterate by-ref, by-mut-ref, and by-value. So `my_vec.iter().position(..)` will actually be passing references *anyway*. Meanwhile `my_vec.iter().find(..)` will actually be passing references-to-references.
I don't pretend to understand this. The report seems utterly confused.
I prefer to write academic papers in the 2nd or 3rd person. Past tense 2nd person is under-utilized in publications, IMO. Present tense 2nd person would be fun as well. "You are in a dark room, with a computer" 
I have suggested they should consider adding something like the 'holes' idea in haskell as a stopgap (an '80% solution', something thats a step forward without having to wait for a rock solid IDE capable compiler); The idea would be inserting placeholder symbols (e.g. underscores or something else deliberate) - added to the AST - in incomplete source to "ask the compiler". It would tell you suggestions in compile output, and could just pretend the placeholder just inferred whatever needed to try to finish compiling, type checking etc as much as it can around it. (I don't know exactly how clang works, but would a placeholder AST node be a step toward true realtime autocomplete later?) I think this would be easier to implement than figuring out all the asynchronous partial compilation that an IDE might need. It would be directly useful in the standard compile-edit cycle that programmers editors handle; This might actually be more useful in different ways too, since most IDE autocomplete goes on forward type information, but often Rust is inferring backwards from the output. You could ask more sophisticated queries, using multiple arguments not just the first, etc. Later that information could be collected into drop boxes in more advanced IDE plugins or emacs extentions to give a more intuitive GUI IDE like experience. (i.e hover on the placeholder to see a dropbox of suggestions..). I think assists like this are a really big deal.. incredibly useful for discovery. So much time is spent searching codebases rather than programming. It's also why I want UFCS in C++ (as explained in the herb-sutter proposal) and the momentum of C++ tooling with dot-autocomplete is what really keeps me using C++ still.
Cool! I will give that a try :)
Hmm. Even *Python* has the `is` keyword for comparing pointers. Perhaps we ought to reconsider how important this is... eg. &gt;&gt;&gt; x = [1,2,3] &gt;&gt;&gt; y = [1,2,3] &gt;&gt;&gt; x == y True &gt;&gt;&gt; x is y False Edit: add example
Can't you call [`freopen`](http://doc.rust-lang.org/num/libc/funcs/c95/stdio/fn.freopen.html)? [Like this](https://stackoverflow.com/questions/584868/rerouting-stdin-and-stdout-from-c). (it apparently [works on Windows](https://support.microsoft.com/en-us/kb/58667) too)
same as `&amp;big_int_1 + &amp;big_int_2`
Cool! I've been wondering how TDD would work in Rust. I should give it some practice.
What about compiler support for not caching a particular memory location in a register? I guess you declare those in the inline assembly?
We have a tag for 'easy' issues: https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy I always welcome additional examples in documentation. :)
What cool data structures you guys need?
Mostly I think we need someone to sit down and work on optimization. Find realistic usecases, look at the performance and generated assembly, and work towards making that better. I'd also be interested in seeing shoot-outs of Rust data structures against other languages, as this is something I get asked about a lot. More generally there's interest in persistent and intrusive data structures. A pairing heap that supports decrease_key and increase_key efficiently *and* safely would be very interesting. A lot of cool stuff is blocked on A Better Rust for things like generic integers, custom allocators, type constructors, and so on.
I can only imagine you in a trench coat standing under a streetlight, looking over your shoulder. /u/Gankro sidles up to get a glimpse of the open car trunk next to you. Beautifully engineered persistent trees sit next to bootleg hash tables. "You got a Judy array?"
Honestly I'm hoping JetBrains picks up Rust for an IDE sometime in the future. I might be a little biased here (/r/IntelliJIDEA - shameless plug), but I think they're one of the best IDE makers out there. There's a Rust plugin in development but it's slow-going. RustDT is interesting but it's far from complete (I don't think it even supports opening existing Cargo projects yet) and I never really liked Eclipse to begin with. The Eclipse platform has never been very spritely or robust. I'm excited for SolidOak but I can't really use it until it gains Windows support, if it ever does. I guess I could try to help in that department. I think getting better IDE support should be a relatively high-priority goal post-1.0, because a good IDE, or a lack of one, can make or break a language. 
That's awesome, but just learned it's patented..
The borrow checker runs at compile time, refcounting doesn't. The borrow checker does a full static lifetime analysis. For refcounting you only need to know when the object is dropped. The borrow checker allows only multiple readers or one writer. Refcounting allows multipe writable aliases. (Edit: This is wrong, RC in Rust doesn't allow mutation unless you use a cell, like regular data)
I want to add something that I was initially confused about, which caused a lot of frustration with the borrow checker when I was starting out in Rust. Reference counting governs when the contained value is destroyed. The value will stick around as long as there are references to it. Borrow checking does the opposite. It makes sure there can be no references to a value after it has been destroyed by being moved or dropped. Borrowed references cannot extend the lifetime of an owned value.
I have a pairing heap implementation [here](https://bitbucket.org/minno/coursera/src/a3c40df7fa543170a9578f918f7612720f5dde59/algorithms_2/assignment_4/dijkstra_min_heap.rs?at=master). It's old Rust and not generic, so I'm not sure how much use it'd be.
This is very insightful. Thanks.
&gt;return vec![i] + &amp;prime_factors(num / i) I didn't know we could add vectors. Hey that means I can add strings as well, cool! A bit more on topic, I wrote atkin's sieve today into my project euler library and I was just comparing the output to a sieve of erastothenes up to a million when doing optimisations. With the test around I was doing some blind optimisations on some loops. No thinking needed, that was nice. Well, less thinking.
How'd you get rust syntax highlighting? I'm also doing a paper on rust (OS-dev related) and haven't been able to get it to look anywhere near as nice.
I used the Minted package for LaTeX, which defers to Pygments. On Arch Linux it was bundled in a scientific LaTeX package (albeit an outdated version). https://github.com/gpoore/minted
I did think a little about configurable branching, but figured I'd get fixed branching working first. There was a package for Church encoded integers kicking around a while ago that would probably be sufficient for my purposes. I think the NibbleVec logic would need to be generalised a little more.
Here's the thing, Rust used to incorporate purity. At one point functions were *pure by default* any function that wasn't pure had to be preceded by an `io` tag (much like mut). This was really implementing a io monad in a way that was very tied down to the language. Why was it removed? Because we don't really want pure functions, we want pure functions that have side-effects that have no dependence on the function itself. Just like we don't really want true immutability, we want the promise that the programmer won't change the values that matter (but some internal values may change). A simple case for this is logging: logging by definition is a non-pure operation, yet there's a lot of benefit of being able to have our functions log what they do. The problem is that this means that pure functions will be disconnected from the systems that are used in systems programming to observe what is happening, effectively turning them into obtuse black boxes which are hard to debug and everything would become `io` because it needed to (with a comment that the function didn't have any important side effect, just some logging and metrics for debugging purposes). Since it would probably degenerate to all functions being io by default, it only makes sense to push that. Rust's macro/plugin system might allow for something like `constexpr`, for those rare cases when you actually do want something that is pure on it's own.
You're welcome! Rust can look daunting at first, but the rules it enforces are straightforward once you start thinking like the compiler does. In the meantime, we're happy to help. :)
&gt; Are there any good IDE plugins for Rust? There are some, but I use `vim`, so I can't tell you how good they are. which IDE do you use? &gt; What debugging tools are available? You can use `gdb` or `lldb`: http://michaelwoerister.github.io/2015/03/27/rust-xxdb.html &gt; What about unit testing libraries? Built in: http://doc.rust-lang.org/nightly/book/testing.html &gt; How's the Syntastic, ctags, [...] support? Yup, we can make `ctags` files.
This subreddit is about Rust programming language, not the game.
I like Emacs + racer + flycheck. Normally I'm a Vim guy but it works great for me. ymmv
&gt;Which IDE do you use? Vim, Visual Studio, and the Jetbrains suite. I'm thinking of switching to Emacs + evil.
We distribute official stuff for vim and emacs. There is https://plugins.jetbrains.com/plugin/7438 for Jetbrains stuff, and https://github.com/pistondevelopers/visualrust too, though that's a bit dated.
&gt;seems like a lingering perf hazard I don't understand your concern. It's the same as some_vec.push_all(&amp;second_vec) or string.push_str(&amp;second_string), isn't it? What situation are you thinking off in which the '+' would lead you away from better performing methods?
Sublime Text 3 + racer (rust auto complete), SublimeLinter-rustc (rust linting, amazing! My only "must have"), git gutter (git status in the side gutter), advanced new file, sidebar enhancement, vintageous (vim emulation way better than built in "vintage mode"), and vintageous origami (split pane support with vim bindings). 
No it's not. When you do, 3 + 5, it doesn't mutate the 3 to become 8. It creates a new int, 8. vec + vec should create a new vector, and then push_all both operands.
I haven't looked at the implementation, but can't it just push it to the self vector and return it?
Does racer only work with Sublime Text 3? Or will it work with Sublime Text 2?
You probably can, but to stay semantically correct, it should be `+=` .
I also [graphed our downloads over time](https://docs.google.com/spreadsheets/d/1VozV1fwz4bgRlPwhkCDHTqwBeHHCH1-QL4yh47EPpVg/pubchart?oid=199500654&amp;format=interactive)!
I've only used it with ST3, but I don't believe I've seen anything saying it *won't* work with ST2. [GitHub.com/phildawes/racer](https://github.com/phildawes/racer) has more info
I like that solution since it doesn't introduce new syntax and is completely back compatible.
I use Visual Studio at work (and I'm loving the debugging features! [C#, btw.]), and Sublime Text (not really an IDE but a superb text editor) otherwise.
&gt; Which is to say that the standard GADT examples all seem to be about the kinds of things that compiler writers do, like embed domain-specific languages or build typed abstract-syntax trees. But it didn't seem particularly relevant for the kind of systems programming that I think about. I get where you're coming from but I think the statement is adequately well-explained in the article.
What up fellow slug! This paper was really interesting--nice job! I like reading other people's thought processes as they code in Rust. I'd definitely be interested in hearing how Rust compares to Go with a little further optimization. If you're not too sick of the project at this point you should post an update!
How cool? Super cool! 
Ohh, and it exposes a bug in `rustdoc`: [must use](http://carllerche.github.io/eventual/eventual/struct.Stream.html) probably should be hidden.
https://en.wikipedia.org/wiki/F.D.C._Willard
I agree, Rust support in IDEA would be great as it's my favorite IDE. They already have good support for [C/C++](https://www.jetbrains.com/clion) so integrating Rust should hopefully not be a big effort.
Awesome that you're putting so much effort into this, it really is a hugely important library, and something other languages can only dream of. That being said, the documentation needs a lot of love. I think you should focus more on how someone might use the library, rather than how it works internally. While that's certainly interesting, and invaluable for power users, it shouldn't be the first thing you present to potential users.
Cool library :) Is it appropriate to build an async tcp library with this ? A "native" support of thread pools could be great to handle a lot of connections.
I don't see why rust shouldn't do implicit TCO. You don't have to explicitly request other optimisations, why should TCO be different? Re: systems languages: gcc does TCO in C, doesn't it?
Rust is not much like C/C++, what could you even reuse in an IDE? As an aside, there was a thread a few days ago about what rustc needs to support for an IDE to use it as a library (which seems like the best way forward).
I think you meant that you write all your code in emacs.
AFAIK, the problem is typically that TCO that breaks silently can be problematic - not having TCO should be treated as a bug. Getting it for free might make people rely on it when they shouldn't or the compiler optimizations aren't guaranteed (or portable).
No I think he writes all his rust in mail 
And here I thought he mails all his emacs in rust.
Thanks! And good catch. It's now fixed.
nice lib! I should put aside my [feeble attempts](https://github.com/viperscape/oyashio)! also, what's up with carl following no one on github? rebel
I thought it was a feature
I'm not familiar with such C++-isms, and can't picture what you're describing in Rust, sorry
Yes it would be appropriate. I may have something in the works, but it isn't quite ready yet... hopefully I'll be posting it up soon.
Well, syncbox (https://github.com/carllerche/syncbox) has a thread pool. As reem pointed out, Eventual is written to be decoupled from execution details. You use futures to represent computations that get scheduled on a thread pool pretty easily :)
I kept hoping someone would kind of summarize what distinguishes this from the one in std::sync, but no one has done it yet and I still feel clueless. Of course, I still want to make something with it just because! Um... Would anyone be so kind as to enlighten me? 
Would serde (or other serialization efforts) ever make Rust's `[serialize](http://doc.rust-lang.org/serialize/index.html) obsolete? (if this happens, will serde replace it?) Actually I just saw it says "deprecated in favor of rustc-serialize on crates.io" - but it's still listed as unstable, not deprecated.
`serialize` has a weird stability history. It used to be what everyone used. But as I'm sure you've guessed, it wouldn't be a good idea to stabilize it. *But*, it's really useful both inside the Rust distribution and outside. So I think they've kept `serialize` in tree and copied it out to `rustc-serialize` so that folks can use it on crates.io. The intent was for some alternative (e.g., `serde`) to develop out-of-tree. You should probably consider `serialize` to be an internal crate in the Rust dist. `rustc-serialize` will hopefully be supplanted by something else (e.g., `serde`).
Oh well, I just tried, and I can't have a feature named the same as a dependency..
* Supports both sync &amp; async. So you can either block the thread and wait for the value or set a callback that gets invoked later. * Computation builders (aka monadic functions). This just means that you can build up computations on the futures &amp; streams w/o the value being realized. For example. `future.and_then(...)`, `future.or_else(..)`, `stream.map(...).take(3)`... * There are functions to compose various futures / streams. For example, `join(...)` takes multiple futures and returns a new future representing the completion of all the arguments. `select(...)` takes multiple futures and returns a future representing the completion of the first one, `sequence(...)` takes multiple futures and returns a stream representing the completion of the arguments in the order that they completed. For example, assume `http::get(...)` returns a future representing the HTTP response. let uris = [...]; // say 10 URLs // Responses is a stream of the completions of the HTTP requests let responses = eventual::sequence(uris.map(|uri| http::get(uri))); let successful_count = responses.map(|resp| resp.status()) .filter(|status| status == 200) .count() // Returns Future&lt;u64&gt; .await(); // Waits for the value This describes a computation in terms of the steps without binding it to any scheduling details, so you could, for example run this entire computation on a thread pool in parallel (or do fancier things).
That's pretty neat. What would that eventual::sequence() thing from your example do without any other changes?
You need something at the end of the chain to "fire" the computation, but you could do: for response in eventual::sequence(uris.map(|uri| http::get(uri))).iter() { // do something with response } Where `iter()` takes a stream and returns a synchronous iterator that waits for each value to be completed. Again, there is nothing specifying where the computation runs, so the actual requests could be spread out across the thread pool and then the original thread synchronously iterates through them.
If you mark a dependency as optional, it becomes a feature too.
Haha! No, sorry, I mean... If I do just consume them, like, in the loop you wrote up there, will they happen sequentially or each on their own thread or...? I'm bad at asking questions this morning.
Seems like you would only need to compile LLVM-Asm to C. Not easy, but not nearly as hard either.
[Bonus new crates.io feature:](https://github.com/rust-lang/crates.io/pull/142) Right-click on the search field and choose "Add keyword for this search." If you choose the keyword "crate" then you can just type "crate hyper" in your browser's address bar to do a crates.io search. (These are instructions for Firefox; Chrome and other browsers have similar features.)
I recall it was something about being poorly maintained.
I, for one, welcome our Crustacean overlords. Mind the capitalization though, or you risk getting involved with [phishing](http://www.youtube.com/watch?v=ISeK_yOfffc). Maybe now Crust will finally support the [limit operator (--&gt;)](http://stackoverflow.com/questions/1642028/what-is-the-name-of-the-operator) as well.
It seams to me like this is not really an apples to apples comparison. There's servo that's rendering a page without any plugins and UI chrome compared to firefox rendering the page with UI chrome (XUL) and whatever (if any) plugins.
I can't believe nobody thought about this before. It feels so obvious now. All this debating and bike shedding feels so stupid. What were we thinking?
I agree, it's very mysterious. However, `Vec::push_all` (which is what the `io::Write` impl for `Vec&lt;u8&gt;` uses) does get a lot more use than the `io::Write` impl for `&amp;mut [u8]`, so I wouldn't be surprised if we're just missing something obvious.
The README should probably mention what "Chef" and/or "Delivery" is about, what problem it solves.
It is my intention that we will deprecate `serialize` and `rustc-serialize` in favor of `serde`. We just need to get the story straight on how we'll generate the impls in stable rust. I'm hoping to get [syntex](https://github.com/erickt/rust-syntex) to the point where it's easy to use it for codegen, but it still has a ways to go before it's ready for widespread use.
I sure did, Bob.
Drawbacks? N/A Guess that settles it!
In other news, Java and Javascript have decided to merge together as well! The new language will be called..... *Java-script*.
I don't see how C, C++, or Objective-C have any relevance to the content of this subreddit. We are already suffering beneath the weight of a concerted bombardment of off-topic spam submissions today and our moderation team is strained to the breaking point. Please, everyone, keep topics relevant to the appreciation of obscure fungi and photos of yourselves cheekily prancing through the woods with a trumpet .
Installing from source on Linux is typically `./configure; make; sudo make install`. Doesn't the last part have identical risks? Even when installing from your package manager, aren't there typically installation scripts from the packages that run? Not sure what privilege level that would run as though. Besides, I'm already running rustc from my user account. [At that point](http://xkcd.com/1200/)...
Once you could compile LLVM into machine code for practically all platforms, the C backend got a lot less useful.
I love the expressiveness of `signed short u8`. Great language ergonomics.
/u/reem very helpfully pointed out that the semantics I'm looking for don't really make sense :( If you can get a mut ref, you can drop the value pointed to, with something like std::mem::replace(some_mut_ref, Big). So the idea of preventing a drop/move without preventing mutable borrows doesn't really make sense.
I'm noticing that Rust still has a good number of basic integer types missing; `u128` for representing UUIDs, `u24` for storing RGB triples as well as seven-digit phone numbers, as well as `u34` and `u37` for 10 and 11 digit phone numbers respectively. I do appreciate that the current design enables the use of `signed u32` and `signed u64` for storing potentially negative IPV4 and IPV6 addresses.
Looks cool -- giving it a try now! Edit: it runs, but I'm getting symbol lookup errors when trying to compile anything..
Linux or OS X? If Linux, please re-download. I uploaded a new one with a different run script and it may help.
`rustc-serialize` was forked from `serialize`, and the old `serialize` has been deprecated for end users. It'll eventually be made an internal-only library for the compiler.
`serialize` appears to be used in `librustc`, `libsyntax`, `librbml`, `librustc_back`, `librustc_trans`, `librustc_driver`, `libtest` and `librustdoc`. This is all inside of the main `rust` repository, which does not include Cargo. If your next question is, "Why isn't Rust built with Cargo?" then I don't have a great answer for that because I don't know. I'm sure it's part requires-a-lot-of-work, part bootstrapping-becomes-harder and part something-else-that-I-don't-know-about. Sometimes duplication is OK. :-)
The world of computers is very, very large. The number of obscure embedded chips with a (probably, closed-source and buggy) C compiler is vastly more than the number of backends LLVM supports or will ever support. Some businesses or entire industries are stuck on one of these platforms, for one reason or another. For that matter GCC supports plenty of platforms that LLVM doesn't, like Motorola 68k or 8-bit AVR. You can read more about the diversity of C compilers in this [excellent article from the makers of Coverity](http://cacm.acm.org/magazines/2010/2/69354-a-few-billion-lines-of-code-later/fulltext).
In generic case – yes. But I wanted to build a specific object and somehow forbid swapping it out.
Being able to compile to C doesn't do you any good if those closed-source C compilers are too buggy to accept generated output. :)
As a simple addition, prefixes could also apply to collections (allowing for the use of fewer bits to track capacity, length, etc); the elegance of `short Vec&lt;unsigned short u8&gt;` speaks for itself.
Something called "crust functions" actually used to be part of the language, for calling between C and Rust before the runtime went away.
What's the difference between swapping out and just modifying all the fields?
`signed Vec&lt;...&gt;` would allow for removing elements from an empty vector, and if you're running out of memory just allocate a vector with negative capacity: the applications are endless.
`fn(i32) -&gt; i32` is the type you want for a bare function. Note that you can't create a bare function using closure syntax; it has to be an actual function item. [Playpen code](https://play.rust-lang.org/?code=struct%20S%20{%0A%20%20%20%20f%3A%20fn%28Vec%3Ci32%3E%29%20-%3E%20i32%2C%0A}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20s%20%3D%20S{%0A%20%20%20%20%20%20%20%20f%3A%20super_magic%2C%0A%20%20%20%20}%3B%0A}%0A%0Afn%20super_magic%28_v%3A%20Vec%3Ci32%3E%29%20-%3E%20i32%20{%0A%20%20%20%201%0A}).
You shouldn't give template parameter to `Box::new`. Just let Rust create temporary `Box&lt;SomeAnonymousClosure&gt;` and it will automagically coerce to `Box&lt;Fn(Vec&lt;i32&gt;) -&gt; i32&gt;`. So, to put it together, the following just works: let s = S{ f: Box::new(|x| 1) }; If you want not to waste one word and store only pure functions, then `fn(Vec&lt;i32&gt;) -&gt; i32` should work too, but unfortunately, I'm not sure you can use closure literal as a pure function.
If I'm reading this right, this is intended for any target language? I've been looking for an example for embedding Rust into Go.
We could even codify this such that every `Vec` is actually a handle to two allocations, one negative and one positive, and we grow each in lockstep! Did... did we just *solve* memory management?
At the risk of being incredibly trollish, I have had to use Chef extensively and it doesn't really solve any problem at all. 
Java_No_Script_S02E04_XViD_DVD_RIP.wmv
A Rust dylib with functions exported with `extern "C"` should be compatible with any runtime that can load C-ABI dynamic libraries. I know Go has [cgo](https://golang.org/cmd/cgo/), but I haven't looked in to how easy it is to use.
This was more a choice of tool, over a choice of platform/language. I haven't found a scaffolding framework that works as well as yeoman (I would certainly be open to suggestions). I like that anyone can make a generator, throw it on npm, and it's available to everyone to install. In this vain, I really wish there was a `cargo install`. Otherwise, the tool is unwieldy to install: clone the git repo, maybe check out a tag, then `cargo build`, and soft link the binary to your bin. That said, making a scaffolding framework in Rust would be a fun/useful project. I'll definitely keep it in mind when deciding on weekend projects.
Just to give a counter point: We have just started using Chef at my workplace after deliberating between it and Puppet, and I, at least, am very happy with it. It is certainly loads better than the makeshift hodgepodge of bash/python/PowerShell scripts we (still) use.
If you need to do what Chef is built to do, I agree it is better than hodgepodges of scripts (as long as the scale of your operation is large enough to overcome cost of adoption and Chef's overhead) I assert that if you need to do what Chef is built to do, you've already lost. If you need to provision 1000's of bare metal machines, that's what neboot + (yum|apt|pacman) is for. If you need to install and configure applications and servers on 1000's of machines, VMs or otherwise, you should use containers. Containers completely removes the class of problems that Chef/Puppet was built to solve. It doesn't help solve the problem, it literally removes the problem. This is why I say Chef doesn't solve a problem. In addition, if you worry about resource utilization, you might likely end up with a machine service multiple duties, and when you start installing multiple suites of applications on a server, you run a very real risk of the deployment process of one project messing up the configuration of another project. Chef will happily do this for you, it will just keep re-running the scripts. Containers solve this problem as well. 
Thank you, I will look into it. Seems like there is no better way possible.
That really hits the nail on the head. I'll have to check how protobuf would suit my usage otherwise. But the JIT/dynamic code technique seems really the way to go.
The code as given above looks equivalent to: let mut iter = line.chars(); for ch in iter { if !condition {continue;} // do something... } Am I missing something?
You could just use `continue` keyword in such situation, I think.
&gt; We have just started using Chef at my workplace after deliberating between it and Puppet, and I, at least, am very happy with it. Was Ansible part of that discussion? I've been using it at work and it's been an absolute dream in a lot of ways.
I got into Emacs while checking out Clojure. It's a damned shame more people don't use it. It's understandable, though. LISP is perceived as alien and even frightening, and Emacs is somewhat config-heavy in general. I've really gotten a lot of mileage out of [Emacs Live](https://github.com/overtone/emacs-live). It bundles a lot of nice things out of the box, and I have to say it has a few tweaks that make Clojure and Clojurescript a dream to write. Normally I'd be more the type of person to configure things myself, but I just don't have the time or patience to put together a really nice Emacs setup on my own. I've added to my config, obviously. I still really need to get into org-mode.
Both of those things will probably have to be platform specific. On Linux, you can listen for X input events and use Xcomposite for screenshots.
That would be nice. I'll give it a try this weekend if I can find the time and update the post with my findings!
In case you're tired of waiting for building cross-compiler you can get [pre-built package](https://github.com/vhbit/rust/releases/tag/ios-latest) with all required archs. Also, here is an [example of integration](https://github.com/vhbit/ObjCrust) - in general, the easiest way to get it running on simulator or device is to compile everything rust-related into a static lib and manage all the frameworks from Xcode project - it saves a lot of time and you have to use Xcode anyway.
Oh awesome, thank you! I didn't even look into the build scripts section thinking they were exclusively for building deps and code generation. I'll definitely try this and update the post.
This is for NPM, but we do constraints the exact same way, so works for Rust too!
Cool. Never knew about the caret. You'd expect to see it a lot more. You see `~` a lot, but `^` should give you more recent versions while preserving compatibility.
The carat is the default for Cargo, so you don't see it as often even if you use it all the time :)
There's no reason you can't use Rust for that. It won't particularly help with the arcane platform-specific details, but it shouldn't get in your way either. You can probably find example code in C or C++ and translate it. Servo is [adding X11 clipboard support](https://github.com/servo/servo/pull/5479), maybe some of that code is useful.
Came to say that. Awesome work!
We are already used to things breaking anyway. But come back to me when things stop breaking, I'll freak out from that point onwards. 
Note: You can put these as a `rustc-flags` key in .cargo/config too. 
yay :D
&gt; but the project has conceded that they'll never implement them all. Not sure where that's been said; though we do have a long way to go.
Thank you :) The loss of a convenient way to do this is pretty annoying.
&gt; Even today, there were still breaking changes happening. The release hasn't yet been cut, so until that time, stuff is still subject to change.
I must've heard that in an early servo presentation. Maybe things have changed since then, but I remember the presenter saying things to imply that creating a complete firefox-level browser engine is a 100 developer-year project which is outside of the scope of the servo project. Has that view changed?
No. It's a huge amount of work to be competitive with SpiderMonkey/v8, and the safety guarantees of Rust go out the window when you add a JIT compiler.
I'd like to have a pure Rust, pure interpreter implementation of JS, that you could use in Servo's hypothetical "paranoid mode". Most ordinary webpages that aren't benchmarks / games don't stress the JIT. And I'm not going to demand top notch GMail performance if my top priority is not getting pwned by the NSA. This is not a "plan", it's just something that I personally would like to see. :) Ideally, someone from the Rust community would contribute an ECMAScript interpreter (I've seen a few in progress) with the [necessary tweaks](https://javascript.spec.whatwg.org/) to use it in a Web context. We would also need to get its garbage collector wired up to Servo's DOM in the manner of today's SpiderMonkey integration. Supporting two GCs for the DOM could be a pain...
How much overhead do you anticipate will result from needing to cross a language boundary between Servo and SpiderMonkey?
The Rust time and the Servo team work quite closely, I'd expect that any performance bugs encountered would be a high priority for investigation.
I haven't used Chef, but where both Puppet and Chef conceptually feel large (see [their](http://docs.chef.io/) [documentation](http://docs.puppetlabs.com/puppet/) vs [Ansible](http://docs.ansible.com/intro.html) docs*), I think Ansible is closer to doing one thing well and that is running commands remotely in an agentless fashion. Rather, than use a programming language or a DSL, I've also found it be convenient to work with YAML (and Ansible's built-in modules) to define infrastructure. I think Puppet and Chef buy you a web UI and auditing capabilities, and you'll have to spring some money for Ansible Tower if you want some of those things. \* that is not to say more documentation implies necessarily harder/worse software
This is awesome!! I was also concerned about the security of the Travis builders. I'll update my post tonight to direct security concerned users to this.
The research is ongoing, so there is nothing written up yet, I'll keep r/rust posted when they publish something. Glad you like the article, I'm not actually on the core team, but I hope they are also fans of the arena approach :-)
I haven't done anything with Piston myself, but the error looks like you're missing a shared library on your system. My guess is that it's a non-Rust library. I'm not sure what you're supposed to do on Windows, but you probably need to find and install `libfreetype`.
~~Hello fellow Windows user!~~ ~~I had this problem before and you definitely need the `libfreetype` dll file. Here, let me give you a set of instructions that may or may not help you.~~ ~~1. [Click here](http://gnuwin32.sourceforge.net/packages/freetype.htm) to get to the download page for the Windows version of libfreetype. 1. Under the "Downloads" header, click on the "Binaries" [zip link](http://gnuwin32.sourceforge.net/downlinks/freetype-bin-zip.php). 1. Extract the `freetype-2.3.5-1-bin` zip file. 1. In the `bin` of the extracted `freetype-2.3.5-1-bin` folder, copy the `freetype6.dll` file, this is the file you're looking for. 1. Paste this sucker in the `src` folder of your project folder or wherever you have your libraries linked.~~ Please ignore this and follow /u/tomaka17's advice, which is [found here](http://www.reddit.com/r/rust/comments/319bno/pistonrust_dependency_problem_in_windows/cpzqkak). 
Perhaps something similar to [duktape](http://duktape.org/) can be done with safe Rust? Its performance is comparable to Lua, not as good as modern JIT compilers but not that bad either. (actually, even including duktape itself would decrease the bug surface. It's ES5.1 compliant so I don't think it would introduce too much bugs. There's [a Rust binding](https://crates.io/crates/duktape) but it currently doesn't compile)
A Servo branch that uses duktape would be a fascinating experiment. Even if it can't handle the full scope of Web content, there will be Servo embedders who have more control over content, and want a smaller footprint than SpiderMonkey can provide. (Though, iirc, you can do an interpreter-only build of SM, and it even works on iOS.)
Just like a lot of Rust projects have "build passing" Travis banner, it would be helpful to have two (or more) banners: one for beta/stable Rust, and other for nightly.. even for libraries that are supposed to target stable Rust. At a certain point, one might ask whether a rustc pull request breaks libraries at crates.io, and how many; and even whether their error messages are all similar, or are wildly varying. And bors could even lint against that.
I've never had trouble scrolling on release builds; but I don't use release builds that much so I'm not sure (and debug/nopt builds are slow overall)
I've done quite a few graph experiments (not much to show the world though - at least not yet), so it's interesting to compare our experiences. First; and this is not specific to graph nodes but to every larger object, is that I often see `Rc&lt;RefCell&lt;Node&gt;&gt;`. However, in larger objects, often some struct fields never change during the lifetime of that object, while others do. E g, the node might have an "id" field that remains constant, but the "edges" field might change. Hence, that could instead be modelled as `Rc&lt;Node&gt;` where `Node` is struct Node { id: i32, edges: RefCell&lt;Vec&lt;Rc&lt;Node&gt;&gt;&gt;, } This way, we get a compiler guarantee that the id field never changes during the lifetime of the Node (almost; in theory you *might* be able to do `get_mut()` on the `Rc`). Also, if every mutable struct field has its own `RefCell`, that would also somewhat reduce the risk of RefCell panics as the locks are smaller. I've never tried the `TypedArena` approach. The reason is mainly that if the graph lives for the duration of the program, and a lot of nodes are added and removed during that duration, you end up with ever growing memory usage as the dropped nodes are never recycled. As for `UnsafeCell`, ever since dbaupp in quite strong terms [told me not to use it](http://www.reddit.com/r/rust/comments/2qzw7m/safe_patterns_with_rcunsafecellt/), I haven't dared. But it's good to see that his opinion is not undebatable. :-) I'd like to point out that returning a node is still possible in the `RefCell` case, except you don't return a `&amp;Node` but instead a `Ref&lt;Node&gt;`. Due to the `Deref` it would be just as ergonomic to the caller. I agree that the `&lt;'a&gt;`s are annoying boilerplate. And you never get rid of them either: struct Mold&lt;'a&gt; { id: &amp;'a str, } struct Yeast&lt;'a&gt; { mold: Mold&lt;'a&gt;, } struct Funghi&lt;'a&gt; { yeast: Yeast&lt;'a&gt;, } ...and so on. There is certainly room for improvement w r t lifetime elision here. For that reason I tend to prefer the `Rc` approach to memory management, at least for now. I also have no good solution to the safe initialisation problem. E g, consider Mold owning some Yeasts, but there needs to be back references to the owner: struct Mold { yeasts: Vec&lt;Rc&lt;Yeast&gt;&gt;, } struct Yeast { mold: Weak&lt;Mold&gt;, } There's, AFAIK, no way to properly initialise the mold and the Yeast to hold references to each other (without using extra containers such as `RefCell` / `Option` etc), even though the relationship remains constant during the entire lifetime of both the mold and the yeast. Maybe `unsafe` is the least bad option here?
Okay, it's April 3rd now. Where my beta at?!
You can specify a build matrix on Travis, e.g. for building on nightly and beta at the same time. I wonder if there are separate "build passing" images for each version tested.
`url` and `encoding` have been updated for beta a few hours ago. (`cssparser` as well, but I don’t publish regularly on crates.io. Though I could, if anyone wants it.)
If you don't know it yet, check out Rust by example. There used to be a lot code not working, but it seems pretty up to date from what I just saw. Together with the book and the official docs (which you really should use right from the beginning) this should keep you busy I guess. Anyways, have fun ;) 
Not per build matrix item, but you can have one per branch, e.g.: https://travis-ci.org/padrino/padrino-framework.svg?branch=psych-fix
&gt;&gt; I've never tried the TypedArena approach. The reason is mainly that if the graph lives for the duration of the program, and a lot of nodes are added and removed during that duration, you end up with ever growing memory usage as the dropped nodes are never recycled. &gt; &gt; This is not a problem in practice as often as you'd think. Frequently you don't want to drop the majority of the graph nodes until you are done with the graph. And if you copy all the reachable nodes to a new graph every once in a while and drop the old graph you can pat yourself on the back for implementing a copying and compacting garbage collector :p
Quick note: we haven't publicized it at all, but the guidelines now live at http://doc.rust-lang.org/nightly/style/ . I don't think there has been much drift yet, but yeah. We want to get more of those RFCs done before we link to it officially and such
Yeah, hanging out on IRC can help _a lot_. People drop by with questions all the time, so you will get a lot of exposure to code. You will then have a chance to think about each problem yourself, and read explanations/solutions given by other(more experienced) people in the channel. And of course you will be able to ask all the small and big questions you have, and (hopefully) get a quick reply!
[clap](https://crates.io/crates/clap) is beta compatible as of today ;)
The meme is "`do` notation interacts poorly with early returns" or something, you'd have to ask one of the people advocating that position.
&gt; Rust should probably have sugar for Monad and also for Applicative (we can't do the latter with library-defined infix operators like Haskell does). Alternately, Rust could gain support for library-defined infix operators :)
All traits have an implicit type parameter - `Self` which is a type, but for monads it should be not a type but a type constructor (i.e. function from types to types, like `Vec`, `Option`, etc). What you are trying to write is like `trait Monad&lt;Self, T&gt;` where both `Self` and `T` are types but it should be like `trait Monad&lt;Self&gt;` where `Self` is not a type but a type constructor which is not possible in current Rust. This is my understanding, correct me if I'm wrong.
Congratulations to the Rust team! Very exciting!
Added to the list!
Added.
Added.
Congrats everyone! You all are awesome &lt;3.
It's worth remembering that &gt; We don’t plan on making functional changes to stable content, though naturally we may make minor corrections or additions to the library APIs if shortcomings or problems are uncovered (but the bar for such changes is relatively high). So, an almost-end. 1.0.0-final is where the end truly is.
str_words
Ah yes. This one doesn't have an external crate. More context: https://github.com/rust-lang/rust/issues/15628 The ticket has a small snippet of code with equivalent functionality you can just drop-in until we make the call.
I made a Dockerfile to run the beta if anyone wants to play with it without installing https://registry.hub.docker.com/u/djhworld/rust-beta/
`convert` is already stable, `path_ext` is still in flux, I can't imagine it will take a very long time.
Yeah, my bad. See https://github.com/rust-lang/rust/pull/24018 (To clarify: the original PR was supposed to land before beta, but wound up being pulled, and I forgot that it about the stable-&gt;unstable change.)
Thanks, for what it's worth I think removing MarkerTrait/PhantomFn is great, wish it could've made it into the beta :) Will we still be able to remove the deprecated API before 1.0? It'd be nice to go into 1.0 without already having deprecated stuff. Edit: Oh, actually just looked at the commit that says "though these will likely be purged for 1.0" :)
You can add [sha1](https://crates.io/crates/sha1) to it now and [redis](https://crates.io/crates/redis) as well now.
Maybe maintain a `stable` branch of the repo?
What should I do with crate publishing?
With Rust, new features land behind a feature gate, so that they remain unstable until the design phase / shake out of bugs is done. These can only be used on nightly, so they don't affect stable users. So the situation is a bit different. http://blog.rust-lang.org/2014/10/30/Stability.html has more.
&gt; That also depends. If you're making software just for yourself, sure. That might often be the case. But if you have thousands of users of your software, my bet is that at least a few of them starts to use your software in ways you did not expect. E g, by adding and removing nodes every second. And then they ask you why your software has a memory usage of 3 GB after three days. Quite frequently, you're designing a single graph for a given "run" with *no* node deletions possible until the end of the run. I'm not talking about writing a generic graph library. Note that if users can add arbitrary edges, you are going to have equally serious memory leaks with `Rc` since it lacks cycle collection. By contrast, the arena approach cannot have this problem--once the arena is freed, so are all vertices, regardless of the existence of cycles. If you really want a generic graph library, garbage collection with cycle detection is by a considerable margin your best option. &gt; Well, it's when you refactor your code to include one reference somewhere and as a result you have to sprinkle five different structs with &lt;'a&gt; everywhere. And an hour later you realize that reference was a bad idea anyhow, and then you remove it, and then you have to remove all &lt;'a&gt;s again. That's when it's starting to get frustrating. (And yes, it has happened. More than once.) I have done the same thing, but I also have to do that in many other cases--adding a generic type parameter, for example. That isn't a reason to use a worse solution (and in many cases, `Rc` is the worse solution). It *is* a reason to work towards reforms like those nrc outlined in his blog post, and IDEs that help automate the refactoring process.
Sorry, I wasn't clear. The characters from the individual lines are interleaved. I added the output from one of the runs to the post.
Follow https://github.com/rust-lang/rust/issues/21724
I was vaguely around the D world during the D1/D2 megadrama, so I lived that too. No bashing taken. :)
Yes, I agree with /u/heinrich5991 . If we didn't have a deadline, we could stretch these changes out forever. You also have to remember that with the RFC process, changes may have _landed_ now, but are in the works for a while. For example, IIRC, the conversion changes that landed last week? That work started in December. You also have to remember that the perfect is the enemy of the good. We could spend forever trying to make Rust perfect, or we can take what we have and start working on more than just `rustc` and Servo. :)
See https://github.com/rust-lang/rust/pull/24029. This also has an explanation why it happens currently and why it is a grey zone.
&gt; It would be a very small change to stop using `Unique` and instead write an `unsafe impl Send for ...` which would make the crate usable on stable Rust. Is there any downside in doing this? I’d like as many libraries as possible to be usable on beta/stable. For those that can’t, we should work on addressing the reasons. For example, we need to figure out a good story for code generation to replace most compiler plugins (a.k.a. procedural macros).
The search on doc.rust-lang.org seems to be missing some results e.g. when I search for sort_by I get no relevant results but it's clearly at https://doc.rust-lang.org/std/primitive.slice.html
Thank you! this is https://github.com/rust-lang/rust/issues/23511 , which we've milestoned to fix for 1.0. Sorry about that!
I have been using my own script for updating and it will just pull the latest of each and install them. It has worked fine for me so far. The reason for not using rustup.sh is that I wanted it to only download a new version if it was newer that my current version, so I decided to roll my own.
I always wonder if someone steps back from contributing to Rust when his email adress is posted online in a blog .... a paradise for spammers. I would definitely.
The only downside is that it using `Unique` feels like the right solution, becuase it makes the ownership obvious to anyone reading the code. I agree though that having the crate be usable on the beta is more important, so I published a new version of the crate that runs on beta, and I'll keep the `Unique` one around for the next stable release.
Looks like your TWiS PR paid off well :D
Please leave a comment on https://github.com/rust-lang/rust/issues/24028 so that we know which APIs to focus on stabilizing!
"using the first full 1.0 release of Rust." Mozilla fobs us off with a beta and keeps 1.0 for themselves ..... 
Regarding lifetimes, I found [this] (http://arthurtw.github.io/2014/11/30/rust-borrow-lifetimes.html) blog entry to be quite valuable as a supplement to the official documentation.
Rust-Crypto now compiles against beta as well.
hmm, just reinstalled beta with `multirust update beta` and still have errors regarding `convert` being unstable.
Replying to myself - file existance could be checked through `std::fs::metadata()` so `path_ext` is not that important.
 #[link(name = "c")] extern { static mut errno: c_int; } should do it. I don’t know if there is a sane cross-platform way of handling this kind of errors…
I think it's a webdev issue with devs trying to automatically set focus post load.
[Winapi](https://github.com/retep998/winapi-rs) has been updated to work with beta. It's been feature free for a while, I just needed to deal with `Copy: Clone` in a few places.
I meant I don’t know if windows has an equivalent to the __errno function.
On Windows you use the [`_get_errno`](https://msdn.microsoft.com/en-us/library/wwfcfxas.aspx) and [`_set_errno`](https://msdn.microsoft.com/en-us/library/hf1920a7.aspx) functions if you really need to work with `errno`, such as when using C standard library functions, which you shouldn't be using on Windows.
Yesterday, while making a crate beta-compatible I came across the same issue. I ended up using this piece of code: ``` Error::last_os_error().raw_os_error() ``` See [the documentation](http://doc.rust-lang.org/nightly/std/io/struct.Error.html#method.last_os_error)
The header image in the Rust 1.0 article was an... interesting... choice for an article about a programming language.
A slice of rustaceans, because we're `[Rustacean]` and we're the cutting edge.
It's a dynamically-sized type, which means that any number of Rustaceans can exist! Hooray!
Using `HashSet&lt;Rustacean&gt;` would make lookup faster, assuming that we can be uniquely identified.
He objects to it readiness but doesn't really qualify it except to say it's not on Windows. I know it's not ready, but that's a pretty trivial detail to focus on. How ready is this for users of Unices, for example? That's all that matters to me, Windows support is a non-issue. What can't I do with Rust on Debian that would turn me off?
It's a risky move, if we later implement `Clone` we'd be excluding some of us... I guess we could come up with a new implementation of `Hash` at that point though, so it could be alright.
There is also the possibility of using Ids as references rather than pointers. in https://github.com/nical/vodk.rs/blob/master/geom/src/halfedge.rs i have a graph data structure (ConnectivityKernel), that has vertices, half-edges and faces. there are lot of bidirectional references in this structure: pub struct HalfEdge { pub next: EdgeId, // next half edge around the face pub prev: EdgeId, // previous half edge around the face pub vertex: VertexId, // vertex this edge origins from pub opposite: EdgeId, pub face: FaceId, } pub struct Vertex { pub first_edge: EdgeId, } pub struct ConnectivityKernel { edges: Vec&lt;HalfEdgeData&gt;, vertices: Vec&lt;Vertex&gt;, faces: Vec&lt;FaceData&gt;, // ... } etc. Ids are basically strongy typed offsets in thevector of the connectivity kernel. The data structure isn't finished, and I haven't made performance measurements yet, but I assume there is a tradeoff between being able to fit more elements per cache line (ids are 16 bits vs 64bit pointers on my laptop) and the extra indirection and bound check due to indexing in a vector a lot. Being able to easily mutate things (I can add and remove stuff in the graph) without having to fight against the borrow checker is nice although this method basically dodges what makes rust's type system unique. So far I am happy with this method because it is simple to im[lement and flexible (but again, I need to measure the performance impact of doing things this way). [edit] fixed formatting
That would be necessary anyway. I guess we can try to future proof it by adding an instance number of some sort to the id.
I thought that at some point they were asking folks to not post the solutions to the challenges, but the challenges are pretty old by this point so maybe they don't care. Are they still doing new ones? Also, is there a reason that you're unwrapping a string containing a hex value rather than just using a hex literal directly?
I saw some @users.noreply.github.com , that's always an option. And as mentioned below, with mailing lists it was already open. 
They have posted solutions for other languages themself: http://cryptopals.com/sets/1/challenges/1/cpp/ As far as I know they are working on set 8 currently. The hex string is too long for a literal: error: int literal is too large
A box of rustaceans
That has been deprecated in favour of terms with less cultural-appropriation baggage attached to them.
I use rust-openssl in my project, it works fine in Beta.
There are more users of Firefox on *Windows XP* than on all desktop Linux put together.
That explains it, I see.
All those emails are publicly accessible on their Github pages already.
With benchmarks, you can use cargo features to only enable them on nightly until it's stable. I'm not sure about the status of `volatile_set_memory`. http://users.rust-lang.org/t/using-unstable-apis-tell-us-about-it/157 &lt;- you should post here.
It'd be neat to provide the DOM hooks to inhibit this misfeature from a user script. I guess you want to make sure all focus changes were instigated by a deliberate action by the user (kind of like pop-up blocking).
[List of words containing rust.](http://www.morewords.com/contains/rust/) **My favorites:** Becrusted. Crustiest. Frustules. Frustums. Procrusteans. Rusticators. Upthrusts.
We can be uniquely identified: http://www.rustaceans.org/
Alright, then :)
All strs are also osstrs, not all osstrs are strs. In other words : you've (probably) done the right thing by converting str to osstr instead of osstr to str.
An empty feature was what I was referring to.
https://github.com/lfairy/maud/commit/3866afbe2ae26547b3efe88ddb60c03f8cb2ea92.patch
Ironborn :p
Obviously, the correct answer is a **crate of rustaceans**.
It looks like `str` implements `PartialEq&lt;OsStr&gt;` and vice-versa. You should be able to compare them directly with `==`. That said, if you are doing this comparison repeatedly it might be better to convert your hardcoded constant into an OsString.
I've actually never seen Rust code that attempted to just use `Rc&lt;T&gt;` everywhere - most people like the challenge of writing 'pure' Rust without runtime accounting. I'd be interested to hear experience reports. Anecdotally though, with a lot of mutable `Rc` boxes managing the complexity of dynamic borrow errors becomes a problem. I don't think `Gc&lt;T&gt;` does anything to solve that though. 
When I view this normally I see two paragraphs that are almost content free. I thought 'this is a non-article'. I had to turn on reader-mode to see an actual article.
I think it's also hard to use just `Rc&lt;T&gt;` becuase you'd _still_ have to do lots of conversions to call library stuff, I'd imagine.
Can you run `rustc --version` and confirm you're really using the right Rust? As you can see, it has been stabilized: http://doc.rust-lang.org/nightly/std/convert/
 True I try Rc a lot. It not help with libraries. As I say in head when I write everything my self I don`t have any problem with Rust and pointers. We need good tutorial or doc how write reusable lib.
Re volatile_set_memory, I think the only stable option is to implement it in c, compile it with the GCC crate, and then call it via ffi. That's what I did for this function in rust-crypto. You can find it in src/until.rs. feel free to steal it if it meets your needs or let me know if it can be improved. As far as I know, GCC doesn't implement memset_s or equivalent which would be better than rolling the functionalit manually.
I'm talking about 'OsStr::to_string', which requires 'convert' feature and it's still unstable (on mobile, can't provide link)
Using unsafe isn't a failure! Sometimes it's necessary like when working with FFI code. All the safe abstractions we have are built on top of "unsafe" code.
I also can't read it. Do you have a link to a readable version?
Nice work. I so wish we would have this internally in 1.0...
Thanks for all the hard work so far! Keep it up people.
My game uses a ton or `Rc&lt;RefCell&lt;T&gt;&gt;` (I didn't feel it was complex enough to warrant an ECS when I started, but perhaps I was wrong), unfortunately. Luckily, I haven't had many problems with dynamic borrows occurring at the same time, but staring at all the `Rc::new(RefCell::new(blah))` and `blah.borrow()` and `blah.borrow_mut()` makes me disgusted with myself. Many times I don't care if there are multiple mutable borrows and wish there were something like `&amp;only` on top of `&amp;mut` and `&amp;`. 
Really? I assumed it was a joke because its a systems language, so it was on the metal.
Thanks for the help everyone. I've updated sodiumoxide to version 0.0.4 and pushed it to crates.io. Now it works with rust 1.0 beta.
The `Reflect` trait is blocking piston-image.
Why there and not on one of the forums?
This is just the place aturon told me to link people to, I am but a messenger. :)
Eew. I feel betrayed by github, but... how did you get it? is this crawlable? The only link I see is &lt;link data-pjax-transient="true" href="/lfairy/maud/commit/3866afbe2ae26547b3efe88ddb60c03f8cb2ea92.patch" rel="alternate" type="text/plain+patch" /&gt; I doubt a lot of spam crawlers would catch it.
 let rc = Rc::return_(7); let rc = rc.bind(|&amp;x| Rc::new(x * 3)); println!("{:?}", rc); let b = Box::return_(7); let b = b.bind(|&amp;x| Box::new(x * 4)); println!("{:?}", b); In the examples you are fixing the concrete type ahead of time. I think that a proprer implementation would enable the use of the same code for defining and manipulating both `b` and `rc`, and differ between them either through type inference or type annotations (giving an error if this isn't possible). (well, a Haskell-like implementation at least)
Then how would you explain this subreddit's April Fool's prank?
"Converting" `str` to `OsStr` takes O(1) time and does not really do any conversion at all, like `str::bytes()`. (The other way around takes O(n) time to check that the data is well-formed UTF-8.)
You're right! I was under the impression that OsStr might be a 'wide character' format or something on Windows, but it looks like they are [actually stored in a modified utf8 encoding](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/windows/os_str.rs#L34). So "converting" a normal string slice to OsStr is an nop. Which then makes me curious - why aren't OsStrings stored in whatever form Windows uses natively?
Oh, yeah, that was me. I was feeling pretty cool when I did it, too. EDIT: Thanks for the flair.
We're over 9,000. I think we can.
At this point, I imagine that the majority of people who have 'stopped using rust' simply got tired of the constant breaking changes. No one has really been using it in any significant capacity, and then stopped for technical reasons as far as I'm aware. If your question is 'What is the technical superiority of Rust over C++ 11?', that's a different question, that I'm sure many people can answer. Here's my $0.02 on the topic: - C++ templates are stupid, but without massive backwards incompatible changes, they will never go away. Rust generics are much *much* better. - C++ still requires a C-style split of header and source for files; this will probably never go away either, and it's a pointless legacy issue. - Rust has a 'tests first' approach; the test running is built into the compiler, and the std library is heavily tested. Major C++ projects (&gt;_&gt; UE4 say...) still have a 'whatever' approach to testing and automation. This is probably a community thing, and it is slowly changing, but Rust is still far far ahead. - Rust inherently makes use of the equivalent of C++'s unique_ptr&lt;T&gt;; many coding standard for C++ require the use of this to prevent memory leaks; but it's haphazard. Rust will always have fewer memory leaks than C++, simply because in C++ memory management is not checked (as it is in rust) - Rust prevents many sorts of memory corrupting errors, making it easier to write security critical components in. C++ will probably never have anything of the same capacity. However, I think it's pretty important to understand that Rust isn't a generic solution for every problem. You *can* solve (pretty much) any problem using rust, but that doesn't mean that you *should*. Pick the tool for your task. If you want to quickly built a high performance website, don't pick rust. The ecosystem for that doesn't exist yet. Pick javascript, or ruby, or python. If you want to build a production quality high performance game, don't pick rust. The ecosystem for that doesn't exist yet. Pick C++ or C#; specifically one of the free engines like UE4 or unity. If you want to build a complex multiplatform application, don't pick rust. I'm quite serious; the windows ecosystem for rust is really pretty rubbish at the moment. You probably want to pick C# for this. All of the issue I've listed above are 'at the moment'; people are actively working on making a rust a good choice for these things too... but, the language isn't even out yet! I think it's still a little early to be asking 'who has rage quit rust for technical reasons?' 
A flock of rustaceans, maybe?
I agree with your points, but my only disagreement would be the fact that you didn't mention Golang for high performance websites. 
This is a nice one.
Yeah, go's also a great choice for network services; although perhaps I would say the ecosystem for web frameworks isn't quite as developed as some of the other languages, it's definitely faster and has a great parallel computing story. There are definitely a number of things I would recommend Go for rather than Rust. 
I wonder, can Rust do all the low level stuff C++ can? Or is there anything that can be done in C++ and can't in Rust?
To my knowledge, if you can't do something in safe Rust you should be able to make it work in unsafe Rust (and then ideally build a safe interface around it). Building with C++ code is probably the only thing Rust can't do that C++ can.
What was the subreddit's april fools day prank? I don't think I came here that day.
Well, ideally you minimize the amount of unsafe code you write, and the unsafe code you *do* write is carefully written and maintained to have no errors, to maximize the amount of times the compiler can help you. It's also different in that Rust has a lot of different architecture around supporting types, acquiring locks, etc, and you'll still be using those features, written in more safe code, even inside your unsafe blocks, while in C++ you don't have so many assurances.
I might be misunderstanding you, but this compiles right now: fn bar&lt;M&gt;() -&gt; &lt;&lt;M as HKT&lt;i32&gt;&gt;::T as HKT&lt;String&gt;&gt;::T where M: Monad&lt;i32, C=i32&gt;, M::T: Monad&lt;String, C=String&gt; { let m = M::return_(1); let n = m.bind(|x| M::T::return_(x.to_string())); return n; } Using it appears to be a problem right now, as inference seems to be making strange assumptions and I can't pin down what it is choking on. I probably am missing some bound on the function somewhere. EDIT: This one works no problem though: fn bar&lt;M&gt;() -&gt; &lt;&lt;M as HKT&lt;i32&gt;&gt;::T as HKT&lt;i32&gt;&gt;::T where M: Monad&lt;i32, C=i32&gt;, M::T: Monad&lt;i32, C=i32&gt; { let m = M::return_(7); let n = m.bind(|x| M::T::return_(x * 3)); return n; }
Unsafe rust still has many safety features enabled.
- For iteration, as /u/just_a_null mentioned, `iter()`, then `map()` and `filter()` provide what you want. - For JSON, `serde` is the succeeder of `rustc-serialize`, and is probably what you want to use. - For SQLite, the `rust-sqlite` crate probably does what you need. I personally haven't used it, but it looks like it provides what you would need. Note: neither `serde` nor `rust-sqlite3` currently compile on the beta, though this is likely to be quickly rectified. Since the beta was literally released yesterday, a lot of crates which will support it haven't had the time to update yet. - For reflection, https://doc.rust-lang.org/std/any/ is what rust provides. `Any` is the only reflection support rust has right now, though it works pretty well for what it does. That page provides documentation for how to use it. Rust doesn't support looking through the definitions of types at runtime (for example, rust doesn't support getting a list of methods a struct implements, or a list of types defined in a crate at runtime). - http://doc.rust-lang.org/book/generics.html explains generics pretty well, it should be a bit more of an explanation than rust-by-example.
Yea, I realized that as I was eating dinner. I decided to drop the recursive version anyways. I'm about to update the post, but the difference is a lot less dramatic now.
More or less. The key difference is that you can often create a completely safe interface to that code that doesn't sacrifice any performance. This is frequently not the case for C++. Thus, to ensure memory safety you only have to get the unsafe code right; in C++, you have to get all the rest of your code right, too.
Updated the blog post and code on GitHub! Rust is still 2x faster (in this stupid horrible contrived example) but in order to see that I had to loop through the fib call 100,000 times in both the Rust and PHP versions.
It's sort of cliché to ask this, but it's worth asking given that the guide you're using does not ask you to compile with optimizations: did you use `cargo build --release`, or just `cargo build`? I wouldn't be too surprised either way, since this strikes me as the sort of thing where the PHP version might just be about as fast as the optimized Rust (since it's a very simple program). But if you didn't build Rust with `--release`, your program is likely to be dramatically slower.
Nice! Went from 0.76s to 0.58s. So from ~2x to roughly ~3x PHP's version.
Also, I wouldn't expect this to matter the slightest in this benchmark, but PHP integers are all signed but your Rust type is using `usize` rather than `isize`. And if you want to be sure that PHP's numeric width is the same as `isize`, check `PHP_INT_SIZE` (unlike the former tip, this latter one matters a lot in numeric microbenchmarks).
I wouldn't count on it, given that [the difference between `opt-level 2` and `opt-level 3` is statistically indistinguishable from random noise](http://people.cs.umass.edu/~emery/pubs/stabilizer-asplos13.pdf). (But then, I did recommend `-O3` for `gcc`, so clearly I'm taken in as well :)).
`PHP_INT_SIZE` is 8 on my machine, which is the same for Rust's `isize` I believe. Switching to `isize` didn't have a noticeable effect.
A library truly as powerful as LINQ needs to be able to do more than just lazy list comprehension. Another cool feature about LINQ is the ability to translate C# code into a domain specific query. For example, Entity Framework allows you to write code that looks like a normal C# LINQ query, but the query is actually translated into SQL, which allows you to use the full performance of your SQL database while still getting statically checked queries (i.e. no magic strings).
I'm a C++ programmer and I don't use Rust because: - When I first tried to learn Rust, it was very early in its development and at the same time I was learning Go. So, naturally I decided to see how Rust's channels work. And I took a look at rust's library source code. I wish I never did. Years of C++ tought some of us that metaprogramming is just a no go for any serious code. It's not "maybe", you just don't do it. Well, here we can argue that generic containers are a form of metaprogramming and people love them and they are harmless, but that's basically what this is all about. If you want an example of a harmless generics added to a language, look at C#. Generics are very restricted and it's probably for good. Rust's metaprogramming capabilities scare me. - When I decided to try Rust again, an overwhelming amount of incompatible language changes was the biggest problem for me. It was really hard to get started with rust code, because the code you see on the internet just doesn't work anymore and all you have is basically the rust itself and projects which are very active around its development. But yeah, to the point that I just said: I'll try it later. - Then I've noticed the whole int/uint thing in Rust and all the discussions about it and realized, that Rust devs don't know what to do about it. Of course with such a non-technical topic there are many opinions, but I know which one is correct. Since I'm no one and I claim this is a non-technical topic, just find Going Native 2013 conference video called "ask us anything" where all the C++ gurus discuss size_t and integer types and that using size_t in STL was a really big mistake. For me rule is very simple. You just use "int" (which is a 32-bit signed integer) unless you have a technical reason not to. And some of such technical reasons are: you need to pack things (into a struct), you don't care about sign (bit masks/flags), you need to store large values (greater than 2 billion). It's is SUPER important in a language without automatic type casting. The language called Go does it right, except at some point they fucked it up by making "int" instead of being an alias to "int32" a system-dependent type. But that decision is less harmful. This problem affects a lot the way people do APIs in a language. We suffer from it in C++ and we'll be suffering from it in Rust. And Rust went with STL's way (usize == size_t). Look at massive cross-platform projects.. say UE4 or .NET or Qt, they all use 32-bit signed integers as much as possible. It's for a reason. - Bindings. You see, C++ is very popular simply because it's backwards compatible with C (almost). I do automatically hate any language/environment where this word "bindings" exist. And while Rust is friendly to C, you can't avoid saying "bindings". In my strong opinion (I even tried to write a prototype language myself once: https://github.com/nsf/krawl), the only solution to this problem is actually using C/C++ compiler and allowing to work with C/C++ headers directly. Yes, I know rust is kind of capable of doing that via compiler plugins and such. Maybe it's not that bad. But given the amount of middleware which is actually written in C++, you still have that word in your mouth. Bindings, bindings, bindings, just write bindings, just generate bindings... yuck. There is no solution to that problem, except not inventing new languages. - http://web.eecs.umich.edu/~bchandra/courses/papers/Hoare_Hints.pdf - "The readability of the programs is immeasurably more important than their writeability.", `fn max_by&lt;B, F&gt;(self, f: F) -&gt; Option&lt;&lt;Self as Iterator&gt;::Item&gt; where B: Ord, F: FnMut(&amp;&lt;Self as Iterator&gt;::Item), &lt;F as FnOnce(&amp;&lt;Self as Iterator&gt;::Item)&gt;::Output == B` is it all really worth it? Sorry for a few of very strong opinions here, but I'm trying to convince myself that Rust is indeed "The C++ replacement" we're eagerly looking for. Except my guts tell me that it's not. I'm glad that Rust doesn't include exceptions, which is the biggest C++ language design mistake, but is Rust better than C++ by a large margin? I'm not quite sure, we'll see.
That's exactly what I expect as well, but until I see this study repeated using the output of rustc specifically I feel obligated to try both. :P
You are close to right. `-O3` (and Rust's `-C opt-level=3`) is mostly about enabling autovectorization (won't affect non-vector-friendly codes) and increasing inlining thresholds. Given that this is very simple one-function code, I guess there would be no visible performance benefit from opt-level 2 to 3.
Turns out you can just edit the `Makefile` to use `-O3`, but that didn't really effect anything.
Not to respond to all of your points in detail, but: * I don't understand your point about generics. Rust's generics are very restricted compared to C++ templates. And what does that have to do with the way channels are implemented? In any case, Rust's standard library is generally not considered very idiomatic Rust code (although that's changing). * Integers pretty much work like you say they should work at this point. The default is `i32` and the other types were renamed. * The signature of `max_by` can be (and probably is?) written: fn max_by&lt;B, F&gt;(self, f: F) -&gt; Option&lt;Self::Item&gt; where B: Ord, F: FnMut(&amp;Self::Item) -&gt; B Putting everything on one line is good for winning cheap internet points, but not much else.
AFAIK, http://doc.rust-lang.org/std/io/struct.Error.html#method.last_os_error does approximately the same thing, getting the last os error - it just gives you an Error instead of a raw integer.
i haven't implemented it yet, but the function signature would be something like fn sequence&lt;T, F&gt;(v: Vec&lt;F&gt;) -&gt; &lt;F as HKT&lt;Vec&lt;T&gt;&gt;&gt;::T where F: Applicative&lt;T, C=T&gt; + HKT&lt;Vec&lt;T&gt;&gt;
That `max_by` function remind me of Perl's One Line Noise, but it's a personal choice. And everyone can use another more clear style even using Perl.
I was talking about generics as the only acceptable form of metaprogramming and Rust has a little bit more than that. At that time channels as an example were implemented with very crazy macros and it was hard to even understand how they work. Metaprogramming makes it super hard to reason about the code. If now it's less used, I'm only happy. Just saying that was a problem for me back then. It's not about syntax and that integer literal is i32 by default. It's about things people do in a standard library. People will look at standard library and think this is the way to do things. Standard library should represent the language in the best possible way. "You just need to format it right", yeah, what an argument.
I am under the impression that many of the problems with C++'s `size_t` are because C++ does implicit conversions between primitive integer types and there are no overflow checking. Rust does no implicit conversions, and does overflow checking in debug builds. 
If you hit an OOM, then you are doing something wrong, the way operating systems work basically doesnt allow OOMs and you have to be doing baremetal kernel programming to get an OOM nowadays. Rust is inherently and fundamentally safe compared to C++ NN (for any value NN). Rust will always be safer, and will always not have something has horrific as templates. Borrowing and lifetimes are the same as in c++, except they are explicit in Rust, and if you make the mistakes in Rust , you will make them in C++ too, except they are compile time errors in Rust, and who knows what in C++. (sorry I just felt like arguing your claims, I upvoted the post so more people will reply hopefully!)
If you dont like rust, dont use it. No one is forcing you. Unsafe rust is closer to C++, practically, but it still has better semantics, a package manager and a good (ie. single) cross platform compiler; these are tangible benefits over C++. You could do a lot worse than imagine rust as basically 'C++ with a built in formal verification (http://en.m.wikipedia.org/wiki/Formal_verification) precompiler'.
Non-mobile: http://en.wikipedia.org/wiki/Formal_verification ^That's ^why ^I'm ^here, ^I ^don't ^judge ^you. ^PM ^/u/xl0 ^if ^I'm ^causing ^any ^trouble. [^WUT?](https://github.com/xl0/LittleHelperRobot/wiki/What's-this-all-about%3F)
&gt; Years of C++ tought some of us that metaprogramming is just a no go for any serious code. What? Are you from game development? I know they have *very* specific culture there regarding using of C++ features, but it's not even close to the common picture and templates (not of boost-level of trickery of course, but still) are widely used in "serious code".
I hope so, but that's a technical side of a question and in my opinion as I said, it's a non-technical question at the end. "I'm writing an API, what type should I use?", and the answer here should be as simple as possible. Because APIs evolve over time and you can't change them later. So, just lean strongly towards simplicity and that's how things work in many projects it seems. C++'s `size_t` is actually an assumption we make, because default allocator uses it. The reality is this: `typedef typename allocator_type::size_type size_type;` and then all the member functions return this "size_type". Overgeneralization, violation of YAGNI, don't do that. But given my Go experience and this is a language with no implicit conversions as well, using as less as possible integer type variations is good for eliminating type casts. You don't want to write type casts everywhere. When people say "Go feels like a scripting language", that's part of it. APIs need to talk to each other and if one API uses i32 as indices and the other uses usize it ends up being really bad. That's why there should be a strong and a well define standard option. In fact it's so important, that adding an explicit "default integer" type for that reason alone is worth it. IMHO
These are pretty valid points, except for this one: &gt; fn max_by&lt;B, F&gt;(self, f: F) -&gt; Option&lt;&lt;Self as Iterator&gt;::Item&gt; where B: Ord, F: FnMut(&amp;&lt;Self as Iterator&gt;::Item), &lt;F as FnOnce(&amp;&lt;Self as Iterator&gt;::Item)&gt;::Output == B is it all really worth it? Rust is verbose, I know, but really, thats just a cheap shot. I could drop in a 500 char wide templated std::function expression too, but does it acheive anything? C++ templates are ugly verbose hell. A single typo can generate thousands of lines of errors as the invalid template is evaluated. Does that make C++ a bad language? nope. Like you say, many C++ projects (eg. idsoft) forbid *any* use of templates. Im just saying even if rust has some rough edges, is C++ a shining example of what to do right? (no, no its not) Is go? (hell no! A garbage collector is the wrong choice for a systems language). Still, totally valid points; if you dont want to use rust, dont use it. :)
I suspect the overly long signature is a result of expending and I agree they produce visual noices in the docs, and should be improved. The version given by /u/wrongerontheinternet would still be easier to read even if it were written in a single line, we are not likely to actually write the overly long version in practice. In C++, we may write something like `std::vector&lt;int&gt;`, but the fully expended form of `std::vector` is not that simple. (Template error messages, ouch.) 
&gt;Rust generics are much much better. No way :D You can't even use specialization (that's absolutely critical). And that goddamn coherence always ruins all the fun. And no integral generic parameters. I agree that Rust generics can be better in the future - they have better basis - but definitely not now.
I think this is a quite compelling reason. usize and isize are good for some specific operations (e.g. pointer arithmetic), but in general, i32 is "ridiculously large enough" even for various length-y APIs. (Also, it's faster than usize!) It is already more or less bothersome to cast various numeric types in Rust. Maybe some well-defined implicit type coercion rules would help, but unifying the types used in the standard library sounds interesting and doable. Unfortunately it feels too late at this point of having released beta, but... maybe, before 1.0 final? EDIT: FWIW, Haskell also uses Int32 for various length-y APIs.
I was also initially worried about the fact that it seemed like the Rust 1.0 release was being rushed. This was back when the rumored date was "end of 2014." Fortunately, over the last four months the Rust team and contributors have done seriously great work at polishing up most of the stuff I was worried about, so I'm pretty enthusiastic about the release date at this point. There is still a lot of work left to do (which is one reason I will personally be sticking with the nightlies for a while), but I believe most of it will be backwards-compatible.
`Rustacean` really should be a trait, our community is not uniform and not everyone is of the same `size_of` :). `[&amp;Rustacean]`
&gt; for any serious code Can you please clarify what "serious code" is in your opinion?
Serious as in "seriously big". I meant the size mostly and the amount of time you'll spend supporting it. The bigger the code and the older it is, the harder obscure features kick you. Sorry for a vague term.
You shouldn't use `usize` for "integer". Use `u32` or `u64`, whatever fits better.
That's the reason I stopped working on my library a couple month ago, I'm waiting for Rust 1 to be released.
How about being able (or unable) to handle out-of-memory exceptions for Rust?
Related: There was some discussion about generic SQL bindings here https://github.com/rust-lang/rust/issues/14658 and then here https://github.com/rust-lang/rfcs/issues/798
I mainly use C and Python, I used to be a C# dev. But frankly, C's simplicity is a bliss for me. I did quite a lot of stuff in Rust, but it is very tiring when the borrow checker works against you or when you spend 10 minutes trying to understand why the hell it thinks some lifetime is invalidated. C is not by any means perfect, I am well aware of that, but I know what happens when I do things (except maybe integer promotion but you can work around that.) How the borrows work is a big reason why. You get some automatic borrow somewhere and I have no idea why. Then after 20 minutes maybe I get it fixed, but then I have this nagging anxiety that I no longer know what's really happening. And I don't like that feeling. I want to be explicit about such things, really explicit. Other than that I think most of Rust's features are very good.
Never said C++ is better. We should learn on C++ mistakes. In C++ it feels like there is this idea that library can be written by professionals and used by inexperienced users. That's how boost basically works. "Let us do the hard job". But it doesn't work. Standard library should be in-fact an example of how you should use the language. It's much better acomplished in Go for example.
In my original comment I said: &gt; The language called Go does it right, except at some point they fucked it up by making "int" instead of being an alias to "int32" a system-dependent type. But that decision is less harmful. So, I think the fact that Go made `int` system-dependent is a mistake. And C# does a reasonable decision. However I wouldn't do it that way. I think it's okay to limit built-in arrays to 2G elements, because if you need more, than most likely you're doing something very domain-specific, just use carefully crafted code for your particular task. It's about making a library for 99% of users or making it for 100%, but with additional complexity. I would happily do it for 99% if it gets even a tiny bit of simplicity for that in exchange. You can't make a library that suits everybody. C++'s STL proves that, their allocators never actually was done right, and even today (17 years since they were added to STL, initial STL didn't contain them) we still hear some fuss about making allocators right in the committee.
That sounds like a valid point. Maybe I'm too committee-minded! I do want a way to improve the ergonomics of array indexing in Rust, though. Hopefully reducing the number of the occurrences of `as usize`s!
If rust is very much like C++ in a sense that it can do costless abstractions, such as operator[] overloading. Then I see no reason why a built-in array should support more than 2G elements. Think about it, will there ever be an array literal with more than 2G elements? And things such as string literals and array literals is the only reason to have built-in strings/arrays in the first place. Just like you have const char* (zero-terminated strings) and std::initializer_list now in C++ for that only purpose and convert it to std::string and std::array/std::vector as soon as possible. Btw, it's an interesting thing to test compiler against. Will rust compiler handle 2G+ array literals and 2G+ string literals? And for domains which do use such large data sets, the guys who know their thing can make a library that suits their needs.
I think this problem is related to not only primitive arrays but also containers types, as the primary inconveniences of `as usize` for me were the times when using container types, such as `Vec`.
Yes, the problem in general is related to all library. I was thinking about C# example where their Array type is actually a representation of a built-in array type of the VM. And in CIL (the set of instructions CLR runs on), there is no operator overloading really, but there is a built-in array type. That's why they had to provide this LongLength version most likely.
You are correct that `max_by`'s signature [in source](https://github.com/rust-lang/rust/blob/7155c8d1c03931b1be04c8eba0b9497ae1a494ac/src/libcore/iter.rs#L872-L874) is much simpler. It is not a fundamental issue with the language, "merely" a rustdoc bug. In fact, it is only displayed so horribly in the `std` docs due to being reexported from the `core` crate: it looks [much better in `core`](http://doc.rust-lang.org/nightly/core/iter/trait.Iterator.html#method.max_by) itself. Obviously bugs like this in rustdoc make it horrible to use the docs (it's pretty impossible to read [the signature in `std`](http://doc.rust-lang.org/nightly/std/iter/trait.Iterator.html#tymethod.max_by)), and they're some of the most important bugs we want to tackle in this final polish period before 1.0.
FWIW, the difference between `O2` and `O3` is entirely dependent on what optimisations we (i.e. rustc authors) choose to enable at each level, a comparison of a specific LLVM front-end's behaviour in 2013 doesn't necessarily hold true for a different front-end in 2015. (That said, I believe Rust does just use the default LLVM settings atm.)
&gt; I do not see how C++ can get rid of header.source split in reasonable time-frame. The how is clear: C++ modules, which have been in the work for a long time. (clang has an [experimental implementation](http://clang.llvm.org/docs/Modules.html)) Though it's [still unclear](https://groups.google.com/a/isocpp.org/forum/#!topic/modules/YG1PYgsa9ig) whether modules will ship with C++17. My guess is they'll end up in the next major C++ version after 17. C++ concepts (likely to be in C++17) will make C++ generics more sane (C++ "concept" ~= Rust "trait"). The unsafety of use-after-move and iterator invalidation will never get fixed, but is this really enough of a problem to make C++ programmers learn to deal with the borrow checker?
Can what?
Now that the 1.0 beta is out, it is extremely unlikely that there will be any breaking changes any more. If you want to get back into Rust, now is a good time.
I wanted to write an applications server but lack of libraries and IDE support was a killer. Boostless Asio and Qt Creator/Visual Studio are great productivity tools.
Lack of bindings and libraries that are mature and stable for every little thing I might want to do. I'm goddamn sick of python but I think I'll be using it for a long time to come.
LOL! I get what you are trying to say. I'm not a huge fan of the Erlang syntax. I do love how great it is for concurrency though. One of my favorite aspects of Golang is the fact that you can compile statically linked binary for very easy and clean deployments across clusters. 
Then again the docs don't take that much room in the unified tarball. Using the current Linux x86-64 nightly (333MB uncompressed, 249MB uncompressed without the doc) and default bsdtar compression levels: * gz 105MB * gz no doc 99MB * bz2 96MB * bz2 no doc 92MB * xz 79MB * xz no doc 76MB removing the docs is a 4~6% space gain, switching to a better compression scheme (and keeping the docs) is a 10~25% gain.
Dunno. I expect a max_by to: 1. Be generic over what it is comparing by. 2. The items to compare should have an ordering defined. 3. That the function it takes should take items of the collection, and return the items to compare. Now, in haskell, I might be able to write this slightly cleaner (something like `Ord b =&gt; (a -&gt; b) -&gt; Collection a -&gt; Maybe a`) because I don't have to care about memory management, mutability of functions, contravariance, etc. But yeah, I think it is all worth it. I hope that with time, IDEs can give us automatically specialized versions of functions. So at the very least, when you type `myvec.max_by(' it can at least specialize the Self::Item. 
I've stopped playing with Rust because the concern about safety, while awesome for projects intended to be long running and with a decent-sized team, was painful for learning and prototyping. Rust might very well be more complex than C++11 right now, and definitely requires way more upfront design. Also, the ergonomy of the language at the time was even worse than well-used C++11 (eg. no auto-cast to references), as I had to work around compiler issues way more that I would have liked to. Plus, the syntax was (is?) just not my cup of tea, it had a lot of visual noise and I didn't like it aesthetically. But Rust really has a ton of really great ideas and teached me a lot on how to code solid and reliable C++, so I'll definitely revisit eventually when it's out :)
Alright, in that case I'll start replacing `rustc-serialize` with `serde` right away :)
I haven't really used it yet, because I don't have an immediate need for it, and I've been waiting for 1.0 to dive in more seriously. The main thing that interests me is game development, along with the ability to compile it with emscripten. I've done some simple command line programs, but not much more than that so far.
I expect some time after release there will be a small number of disappointment posts from people who don't like verbosity and strictness. I have already observed here and on HN people who expect a C++ replacement to be at least as elegant as C++, and who don't immediately realize that having more static checks essentially means the compiler will be harder to satisfy.
&gt; &gt; You can't even use specialization (that's absolutely critical). And that goddamn coherence always ruins all the fun. I disagree that specialization is "absolutely critical". I really like being able to look at an implementation, perform the type substitution in my head, and *know* that the method will be called if the type matches. With specialization I have to look through the entire program to see if there's a more specialized implementation. Coherence is also great for similar reasons: you don't have to guess which method will be called. Note that most people probably disagree with me (including heavy hitters like Niko) re. specialization, so it's quite possible it'll make it into Rust. I personally find the code clarity benefits of not having specialization outweigh the minor increases in expressivity that it provides.
Not to delegitimize any of the other arguments, but wouldn't monad syntax sugar effectively replace `try!`? It seems very very similar to the `bind` implementation for `Result`. I would even argue do-notation is a `try!` that has been expanded to work with other interfaces.
i still think you could have a single language that lets you leverage libraries from both worlds. I don't think they have to be mutually exclusive. you could start with C++ and add concepts; or you could start with rust and loosen it up with duck typing. in Rust you could make the looser version an option that is off by default .. and in C++ you could have an option to make not using a concept an error ... then you could have overlap between ecosystems - you wouldn't be forcing people to choose "either or" and hence miss out on (a) the existing sourcebases (contributing to projects in widespread use already) or (b) the other useful features. But it seems this world is infested with enough people who are willing to not just suffer C++ *exactly as it is*, but also defend *why* it works like that, and the kinds of projects that interest me will likely remain in C++. e.g., I regularly encounter people who think UFCS is a bad idea.. that really destroys my faith in humanity..
Ah, yes, I was thinking of `rust-sqlite`. The github repo was named `rust-sqlite3`, so I guess I assumed the crate was as well.
Computers have a hard time keeping up, man.
I need to be able to compile to javascript and I also need to be able to make native mobile apps on Android and iOS. Rust is weak in those areas.
Unsafe only gives you three extra powers: dereference raw pointers, access or update global mutable state, and call unsafe functions. Everything else still works the same. The borrow checker still exists, for example.
OOM is a big problem for us. Our Rust code lives in Linux containers that are limited to a small amount of RAM. If the code in the container abuses this limit it will OOM/panic!(). It would be useful to be able to have some mechanism to deal with this better than unwinding the entire stack. Maybe we could flush a cache to free up some memory... 
Not really true. I used to feel the same about infix operators, but after enough time spent coding in rust, i realized that methods actually are infix operators. With names instead of symbols, but that's fine. No kitten will be heart if you use .bind() instead of &gt;&gt;=. Really.
&gt;Templates are hacked into C++, and they're ugly and nasty to work with. Well, maybe I work with C++ for too long, but I don't see them that way.
Thanks for the correction, I'll edit the post
Would panicking on OOM have a performance impact?
Does rust help prevent fragmentation on 32 bit platforms? 
A formally verified Rust compiler (like CompCert) would be so cool.
Isn't `lldb` basically the same interface as gdb but for llvm languages?
2's complement is still guaranteed.
Nope, `start` has the exact same behaviour as before. Also, from what I can tell, `rust-gdb` loads a couple of Python scripts that have something to do with pretty printing, so I doubt that it changes which method gdb considers as the main one.
I intentionally wrote "reasonable time-frame". No, modules will not happen in many years. Sadly, even if they are standardized they won't be used for libraries for a long time. No universal binary format, backward compatibility problems and maybe more. The situation with concepts is better, IMO. The question is again how quickly will libraries adopt using them.
Yeah that's what /u/dobkeratops said, but I didn't think that was what my original parent meant. But, basically, not inherently, though some of our stuff isn't implemented yet, like custom allocators.
It's not a feature of the subreddit, just a random bot. I've reported it for spam.
We CI test every commit against android, and a volunteer ensures the iOS build doesn't break too often. Emscripten kinda works sometimes, but we need it to get on a newer LLVM version.
Thanks kmc! I had forgotten that mod names would not conflict with structure names. *Edit:* Actually what saved me in this case was defining the struct inside the function. Both are good observations; I've bookmarked this since I often hit this problem in some form or another.
Usually, these kinds of things work best after there are two different libraries to do whatever kind of thing you want a generalized API for, and then they hash it out and come to something.
Youre exactly right, however the code you are writing probably is not baremetal kernel programming, just statistically speaking. The OOM thing was basically a std library choice, and in bare metal programming you wont have the std library. Also in kernel programming, you will also need to make your own malloc, and therefore can handle OOM yourself there. So to recap, in non-kernel environments, you wont hit OOM, in kernel environments, you need to write your own allocator, and can handle OOM there. (at least thats how i understand it)
you really shouldn't report these bots as spam. Contact the creator and ask them to blacklist /r/rust - these bots can be quite usefull
Pretty much one reason: IDE support with autocomplete and error checking. I learn a lot from a language by just playing around wiht the autocompleter and see which type can can what method. I like vim, but using it as an IDE is just... meh. edit: oh yeah. and there really isn't a lot of beginner friendly material out there that works with todays syntax. especially screencast material is pretty much non existant
It just reports them to the actual moderators of the reddit. They can decide if they want them here or not. I find them basically universally bad.
We also need to improve our cross-compilation story, to make it super-easy to be able to just write, say, `cargo build --target=arm-linux-androideabi` and get a deployable binary out of that. (It is currently difficult to get the cross-compiled standard library; basically requires building rust from source with `./configure --target=arm-linux-androideabi`.)
Thanks! Maybe someday we can just write `F: Applicative` and marvel at what once was.
Here's another example: https://github.com/BurntSushi/quickcheck/blob/master/src/arbitrary.rs#L383-L443 --- It's my way of working around the loss of numeric generics in stable Rust. (Although, it appears the `num` crate is now working on Rust stable.)
&gt; Rust now Sounds like you need a vacation :)
Link broken
It works fine for me: ftp://ftp.cs.washington.edu/tr/2015/03/UW-CSE-15-03-02.pdf EDIT: I rehosted it on dropbox for people whose browsers don't support FTP: https://dl.dropboxusercontent.com/u/1302783/UW-CSE-15-03-02.pdf
Does your browser not support FTP?
I'm sure such functionality would be pretty useful. Maybe open an issue for it or even a PR? 
Link works for me (using Firefox).
&gt; Rust memory management has two goals: no memory should ever become unreachable without being deallocated [...] I thought this was not only not the point, but know to be not-the-case with reference counting. (Though perhaps it ends up being the case in the subset the consider)
Is there a good way in the Rust FFI to interface with types that vary in weird ways? E.g., in the_c_lib_interface.h: #if ESOTERIC_MACRO_1 &amp;&amp; ESOTERIC_MACRO_2 #define handle_t uint32_t #else #define handle_t uint64_t #endif void function_1(handle_t arg); I've hit this one before with a Rust ncurses wrapper (there was a mishap in the 64 bit Debian version that caused some arguments to not fit the size as it is on other 64 bit Linux distros).
The enums should all have a tag byte, regardless of its complexity. LLVM should be able to use it for a jump table. I'm assuming regular enums, no #[repr(C)], etc. Also, shouldn't there be only one way to destructure a struct?
&gt; The enums should all have a tag byte, regardless of its complexity. LLVM should be able to use it for a jump table. That's right, but I'm talking about more complex situations. For example: match (a, b, c) { (A::A1, 1, Some(4)) =&gt; ..., (_, 3, None) =&gt; ..., (A::A1, _, Some(_)) =&gt; ..., (A::A2, 2, _) =&gt; ..., (_, _, _) =&gt; ..., } Matching against `a` (assuming it has two possible values `A1` and `A2`) first will give 4-3 partitions, while matching against `b` will give 3-3-3-2 partitions for `b=1`, `b=2`, `b=3` and others. The current code generation prefers the minimal maximum partition size and will match against `b` even though it will result in the larger number of match arms. This is a [well-known heuristic](http://marijnhaverbeke.nl/hob/saga/pattern_matching.html).
I have a question: what are "earlier models of Patina" referred in the report? Is it referring to https://github.com/jbclements/rust-redex?
No. It will, however, be more verbose; because Rust favors being explicit about footguns, and at that level footguns are *everywhere*.
It is, but in that case you won't be using the std library `Box` type (which aborts on OOM), you will directly call into jemalloc/malloc or the kernel (if you'rerolling your own, then whatever allocator you have cooked up). And in that case you can handle an oom just fine. 
I also suggest looking into Elixir. It's a great language.
While this is not the case, it's a reasonable assumption given that Clang originally set out to match GCC's command-line interface, and likewise for lld with respect to ld.
That would be really useful actually, even for platforms where it can't actually produce a binary - with libpnet whenever there's a change to Rust or the standard library I have to update each platform, which isn't easy when I don't have the platforms to hand, so being able to do everything except codegen for the other platforms would be really useful.
I've banned a number of useless/spammy bots from here, I'm reluctant to ban tweet/wiki type bots though, since not clicking through the link can sometimes be useful - people can always downvote/hit report if the bots are an annoyance/violating the rules or CoC.
You'd typically use `#[cfg]` for this - http://doc.rust-lang.org/reference.html#conditional-compilation. You'll usually only need to do something different based on operating system or pointer size, but in case there's something a little more unusual which you need to handle, you could use something like `#[cfg(feature(esoteric_thing_1))]`, and compile with `cargo build --features esoteric_thing_1` - http://doc.crates.io/manifest.html#the-[features]-section
`usize` is not the native integer size. Is the PHP integer 32 bit on x32?
&gt; it should be the correct one but I don’t know what happens in the multi-threaded case that's my point. Whether the symbol exists or not, it's usually not the right way to access it. extern __thread int errno is how it is defined on most systems, and it's just different to your extern declaration, since in the first case it's a TLS symbol. It won't work.
&gt; I think it's okay to limit built-in arrays to 2G elements, because if you need more, than most likely you're doing something very domain-specific Files &gt;2GB are not uncommon and it's not far fetched to want to load such a file to memory to do some processing on it. It might not be the optimal way to process such a file, but it surely should be possible.
I don't believe Rust has a union type like that, nor bitpacking. So your best bet is to write a type that masks over it, using bitshifting internally. I'll note that if Rust *did* have a union type, it'd only be memory-safe to use it for built-in numeric types, so it's unlikely to gain one as it's not generally useful.
Well, that's very sad for me. A project I work on which I was hoping to port to Rust is heavy in code like this. I guess i'll have to keep using C++.
You can achieve it to a degree (no bit packing) using [`transmute`](http://doc.rust-lang.org/nightly/std/mem/fn.transmute.html), by transmuting `&amp;Self` to `&amp;u32` or whatever, but it's some shady business and it may cause invalid states if used incorrectly.
I'll agree with you but I still answered the question in case he did know, so it's not too bad :p
Would probably be simpler to hide the bit-twiddling behind methods. Though it remains more error-prone than using bitfields as you have to get the shifting and masking right by hand. Might be possible to use a macro similar to `bitflags!` to generate the whole type in one shot, methods and all. There's [a `bitfield!` on github](https://github.com/dzamlo/rust-bitfield/), might be worth a look at least as a starting point.
Yes, that would be better if bit packing is mandatory. The tricky part when using a macro is the masking. Macros can't count properly and that's why `bitfield!` is a plugin.
Oh hey, there's an edit here: &gt; look more pythonish Yeah, this is very, very different. What's `var` do? Just `&amp;mut`? &gt; I wish Rust catched the fact that functions are really just global, static, const lambdas The big difference between functions and lambdas are that functions have no environment. I guess in theory you could do some sort of analysis to figure out that there isn't one, and generate more efficient code, but yeah, that'd be a very fundamental change. Thanks for elaborating!
What is the purpose of this type? In particular of the `FooBarBaz` field?
**Background**: I've been using Rust for a little under a year, mostly working on [Playform](https://github.com/bfops/playform). I've been coding for 10-11 years, and I started with C++. My focus and use case is mainly (hobby) game development. I haven't entirely lost hope, but it's dwindling. **Linking with C++**: If Rust wants to hijack the C++ gamedev community, linking with C++ libraries is almost a must. I'm only dimly aware of how horrific that effort is, but I think lots of game developers are much less likely to experiment with Rust if, aside from learning the nuances and complexities of the language itself, they have to deal with using all new libraries too. The barrier to entry is so much higher if you can't link to good ol' Bullet physics, for instance. **Overextending**: I get the feeling that Rust is drifting away from what I originally thought it was, and what I want it to be: a safer, cleaned-up, at-least-as-performant-if-not-better C++, with some clever additions to combat common pitfalls (e.g. lifetimes and borrow checking). More and more pretty (but entirely unnecessary) language features are being added in (e.g. range notation), that add complexity to the compiler and the syntax (part of what's nice about C is that you can basically trace the parser in your head). New language features add more of a barrier-to-entry, and more opportunities for people to needlessly disagree (What should the syntax for inclusive range be? Well, what's wrong with `range_inclusive`? Nobody misunderstands what that does). It's my impression that in part this has happened because of the change in community that has come as Rust has gained popularity: more programmers from non-C++ backgrounds are coming in, and Rust seems to have loosened up in its target audience: now part of the goal seems to be "also can we be pretty like Python?". I've wasted untold hours because of unfamiliar language features in Python, and asking that people learn the whole language up front (to avoid shooting themselves in the foot) is only reasonable if the language itself is very simple. They just don't need to be there. On a similar note, I disagree fundamentally with the creation of a Rust style guide. That's simply irrelevant to the language and to the compiler. I realize it's a *guide*, I can ignore it, etc. etc.. Its existence as an official Rust style guide and not a *Mozilla* Rust style guide just bothers me. **Mozilla**: I've gotten the impression that internal politics affect Rust non-trivially. It's my opinion, I don't have any kind of irrefutable evidence, but it's the impression I've gotten. `strcat` is a name that comes up from time to time; I don't know much, so I won't say much, but apparently this was somebody who provided a voice and point of view (from a language perspective) that more aligned with my own, but interpersonal conflicts caused this individual to leave. There was also a recent ["cowboy coding" incident](http://internals.rust-lang.org/t/memcpy-is-backwards/) that annoyed me and a few other people; if everybody else has to submit RFCs for changes to stable APIs, so should Mozilla employees. **Please**: Rust could be built in layers, with the bare-bones C++-but-better version being the bottom, and the prettier things (like range notation and `if let`) being built in a separate, optional layer on top it ("Rust++", "High Rust", something like that). I don't really think it'll happen, but I miss the KISS vibe that Rust used to have.
This is reasonably common in low-level code for kernels or drivers, when dealing with hardware which packs values as tight as possible. For example, many will pack two 4-bit values into a single 8-bit value which must be sent over the wire as that 8-bit value.
Probably a representation of a hardware register with some bitfields. The entries in the struct are the fields in the register, while the uint32 represents the whole register so you can for example zero it out or copy the whole thing in one go.
For the FFI purposes only, you should be fine with using `u32` everywhere this union is expected - if the C compiler works correctly, it should work fine. If you want to edit particular fields, you need some auxiliary methods and bit fiddling. For example, if you work in little endian, this should do the job: #[repr(C)] struct FooBarBaz { pub foo_bar_baz: u32 } impl FooBarBaz { fn get_foo(&amp;self) -&gt; u8 { (self.foo_bar_baz &amp; 0xF) as u8 } fn set_foo(&amp;mut self, val: u8) { self.foo_bar_baz = (self.foo_bar_baz &amp; 0xFFFFFFF0) | (val as u32 &amp; 0xF); } fn get_bar(&amp;self) -&gt; u16 { (self.foo_bar_baz &amp; 0x3FF0) as u16 } fn set_bar(&amp;mut self, val: u16) { self.foo_bar_baz = (self.foo_bar_baz &amp; 0xFFFFC00F) | (val as u32 &amp; 0x3FF0); } fn get_baz(&amp;self) -&gt; u32 { self.foo_bar_baz &amp; 0xFFFFC000 } fn set_baz(&amp;mut self, val: u32) { self.foo_bar_baz = (self.foo_bar_baz &amp; 0x3FFF) | (val &amp; 0xFFFFC000); } } 
I'm not referring to bitmasks, I'm referring to union types. It's not possible to guarantee type safety for builtin raw pointers either (provided you take dereferencing as a basic operation that is part of their type), but that doesn't make them "not generally useful," at least not to the extent that they aren't in Rust. I seriously don't understand this blanket assertion, especially since it's not the community consensus on this subject.
Where do you need union types where an enum wouldn't work, ignoring FFI? 
Anywhere that you store the tag information somewhere else (i.e. not directly next to the data, and sometimes simply in the control flow of the program). In databases and kernels this is a common pattern for memory conservation. There are also plenty of occasions in Rust itself where a union type would be useful since you want to store two differently-sized data structures in place to avoid future allocations (e.g. during an in-place data structure transformation). Whether it is type safe in safe code is not really the important part: what's important is language level support for storing differently-sized, and potentially differently-packed, data structures in the same memory, aka a union type. Again, I understand that you may not have not had occasion to write code like this, but I have, and Rust's lack of them makes it really difficult to write.
[I managed to shoehorn a quite safe interface into a macro](http://is.gd/7MG4MO) (ohgodsoftheworldwhyamIdoingthis?!). It's horrible, but it seems to work.
I kind of solved the problem by implementing in userspace the parts missing for zero-allocation zero-copy parsing of &amp;[u8] in Cap'n Proto Rust driver (cf. https://github.com/dwrensha/capnproto-rust/issues/25).
Honestly, the *only* place where untagged union is useful is FFI. C unions have two usages - type punning (so you don't have to do pointer casting every time you need to fiddle with bits of float, or if you want to zero whole 4D vector at once, or something like in the OP), and tagged union. Type punning is inherently unsafe, and hardly ever a good idea, and can be done with bitmasks and transmute() if you really need it, and tagged unions are done in Rust via enums.
The functionality is unnecessary, except where memory efficiency is one of the requirements for the software, which is where these patterns are common. Rust itself wouldn't exist if there weren't cases where space and time efficiency were requirements. I don't think that's a very good argument. I also think the fact that it's necessary to complete C FFI is justification enough for language-level support by itself; the solutions people are currently using are horrendous platform-specific hacks. In any case, this is something that the Rust community and core team will ultimately decide, not you or me alone, so let's just agree to disagree :)
&gt; and can be done with bitmasks and transmute() if you really need it Except that Rust doesn't have good support for representing the types as belonging to the same memory in the first place, meaning you have to know details of their representation--which are explicitly unspecified in Rust--which makes the *transmute* inherently unsafe.
&gt; Only the results from the second loop are printed, and the first loop is seemingly ignored. It's not actually ignored, as the warning notes the upper bound overflows (since 256 does not fit in u8) so it iterates on a range between 0 and 0 (exclusive), which is empty.
On the other hand, Rust is supposed to be a language where 99% of your application code should be safe - unsafe is essentially supposed to be for FFI and creating safe interfaces to unsafe structures for your actual logic. Your code shouldn't really be scattered with unsafe{} blocks to access data, because it becomes really difficult to ensure that those blocks are actually used safely - changing the order of function calls in safe code could then wind up with you treating some data as one type when it's actually another and breaking invariants.
As others have said, LLVM has many tricks for compiling match, or a switch/case in C. One of my favorites is illustrated by this code: pub fn ascii_space(x: u8) -&gt; bool { match x { b' ' | b'\t' | b'\r' | b'\n' =&gt; true, _ =&gt; false, } } On my Linux x86_64 machine with `-C opt-level=3`, this compiles into 0: 40 80 c7 f7 add $0xf7,%dil 4: 40 0f b6 c7 movzbl %dil,%eax 8: 83 f8 17 cmp $0x17,%eax b: 77 0e ja 1b d: b8 13 00 80 00 mov $0x800013,%eax 12: 40 88 f9 mov %dil,%cl 15: d3 e8 shr %cl,%eax 17: 83 e0 01 and $0x1,%eax 1a: c3 retq 1b: 31 c0 xor %eax,%eax 1d: c3 retq We can translate this back into Rust: pub fn ascii_space(mut x: u8) -&gt; bool { // 0: add $0xf7,%dil x = x.wrapping_add(0xf7); // 4: movzbl %dil,%eax // 8: cmp $0x17,%eax // b: ja 1b if x &gt; 0x17 { // 1b: xor %eax,%eax // 1d: retq return false; } // d: mov $0x800013,%eax // 12: mov %dil,%cl // 15: shr %cl,%eax // 17: and $0x1,%eax // 1a: retq (0x800013 &gt;&gt; x) &amp; 1 == 1 } What the heck? Here's what's going on: Adding `0xf7`, modulo `0x100`, is the same as subtracting `0x09`. So it will map ASCII codepoints in the following way: ' ': 0x20 → 0x17 '\t': 0x09 → 0x00 '\r': 0x0D → 0x04 '\n': 0x0A → 0x01 The constant `0x800013` is represented in binary as: 00000000100000000000000000010011 Sure enough, the set bits are in positions 0, 1, 4, and `0x17` = 23. The constant is a Boolean lookup table, stored inside the program code so that it doesn't require another memory access. Often these end up being 64 bits, but here LLVM was clever enough to shift the range into the bottom 32. In string-cache we put the most commonly matched HTML tag names at the start of the [interning table](https://github.com/servo/string-cache/blob/master/plugin/src/atom/data.rs#L10). This lets LLVM use this trick to generate better code for the HTML tree builder rules, which are a [1,300 line nested match on tag names](https://github.com/servo/html5ever/blob/master/src/tree_builder/rules.rs). (Or it did at one point; as the comment implies, I haven't looked at the assembly in a while.)
Oh! You can for x in (0u8..) { which will go up to 255.
Sometimes you need to [build and run a C program](https://github.com/kmcallister/ocb.rs/blob/master/ocb_sys/build.rs#L23-L47) from your Cargo build script to get the relevant information. I don't know what to do for cross-compiling. :/ I did work on one C project which would compile a file full of constants / offsets, then open the object file using libbfd to read them out.
After looking into how active and passive FTP work, I can see the issue. I guess I've never used active mode, or maybe I just got lucky. Thanks for letting me know!
It only goes up to 254: http://is.gd/Iwzenh
seems like a bug
It's okay that matching on Rust's unions would be only accessible in `unsafe` code (just like dereferencing raw pointers).
Some things are shifting from `panic!` to `Result` returns where appropriate. If you have a use case where the standard library should return a `Result` instead of `panic`ing, I don't think you'll get much resistance if you ask to have it changed. I don't agree with letting the caller decide though. It means complicating the language and the compiler, and I think it would just mean generating two versions of the function: one panicking, one not.
It was quite cute that you could transfer a file from one file server to another (or a printer), without downloading it to the local terminal. The separate data channel enabled such features.
I hugely second the simplicity of C. Part of what I originally liked about Rust is how relatively simple the syntax was. It's crufted up over the last year. As for borrows, the weakest part of borrows for me is the learning process; lifetimes and borrows are confusing, and it's not necessarily immediately obvious why it's worth thinking about. Now that I'm more familiar with how these work (and the error messages have gotten better), I find the compiler's pretty good at telling me when and why things are borrowed. They're a little quirky, in the same way that nested templates are a little quirky in C++ (specifically the part where you have to end them with `&gt; &gt;` instead of `&gt;&gt;`); the errors will be mysterious and confusing until you understand what the compiler *thinks* is going on. And ultimately, if you don't like the problem of borrows and lifetimes, you can be `unsafe`. And your code will make it really clear that the compiler isn't doing any checking for you. But ultimately that checking has to happen *somewhere*; I definitely prefer using the compiler to carefully auditing and documenting my ownership and lifetime.
Template errors are a bit cleaner in modern versions of LLVM and GCC. I can't vouch for Visual Studio however. Once you are generally familiar / comfortable with C++ templates... you end up really loving them. Of course... when you do reach that point, it can be hard tempering the urge to just use them everywhere. Templates are freaking awesome when you want to do compile time meta programming in C++. Makes the language feel more like a dynamically typed one when needed. I just wish concepts lite / constraints were in.
Presumably if you're cross-compiling, you also have a cross-compiler for C available - wouldn't you just invoke that rather than GCC? (Or pass whatever flags you need to to GCC? I've never actually needed to do cross-compilation...)
AFAIK this is rather non-portable. Neither the C nor the C++ standard define its memory layout (w.r.t. ordering of bit fields). So, you'd be relying on a compiler's implementation details.
&gt; Note that the compiler takes care of freeing the used resources as soon as x goes out of scope. In the C++ world this is called RAII. And in the Rust world :)
It depends on the size of the object. But you're right, rustc and LLVM have some discretion about how to implement by-value semantics. It isn't always a `memcpy`.
That's a job for optimization passes.
By default, a trait object like this: Box&lt;GeomDisplay&gt; is actually Box&lt;GeomDisplay + 'static&gt; Try this: struct DisplayEngine&lt;'a&gt; { elems: Vec&lt;Box&lt;GeomDisplay + 'a&gt;&gt;, } I'm pretty sure this is what your problem is, but I took a bunch of cold medicine today, so who knows ;)
`~T` is basically `Box&lt;T&gt;`. Rust used to have multiple built-in pointers with different sigils, they've all been moved to library types and/or removed.
ah yes
Why? How? I don't see a problem in that code.
Struct representation is well-defined (and correct usages of `transmute` are safe) if the struct is `#[repr(C)]`.
There was [a question](http://www.reddit.com/r/rust/comments/30608a/split_string_on_multiple_delimiters/) here some time ago about using multiple string delimiters. Implementing `Pattern` for `&amp;[&amp;str]` may be worth considering, unless the case falls within the last point of potentially missing impls.
Your example would be better served with `do_something(x)`, since `&amp;&amp;`-qualified member functions aren’t really the same as by-value, `self`-taking methods.
You can't use `transmute` unless the types have equal sizes. You can fake it by creating structures with extra data at the end, but then you have to know the correct padding and alignment, which basically requires you to calculate the numbers manually and hardcode them. It's very error-prone.
Rust used to not opt into move by default (despite the fact that every other language with linear types had move by default). According to those who used the language at the time, it was more considerably more confusing in practice.
Wrong sub comrade. /r/playrust
I admit that I didn't think of that case, but I still think that this isn't much of a problem: The reason why it is recommended against `std::move` is that a certain optimization is easier to perform in that case. Ignoring that advice really shouldn't be much of a problem, unless you are returning huge std::arrays by value, which isn't a very common or good idea to begin with. I would however approach that topic from a completely different perspective: You use moves to path values, that you don't need afterwards, to other functions, which is a completely different topic from returning things from functions.
The linked wiki page https://github.com/sarojaba/rust-doc-korean/wiki/Rust-for-CXX-programmers#pointers-and-references is very out of date on the Rust side of things, and is possibly less helpful than linking nothing. Does anyone know if this page has been updated anywhere?
isn't this approach more or less equivalent with using an arena? your vector of nodes would be the arena in question.
https://github.com/rust-lang/rust-wiki-backup/blob/master/Rust-for-CXX-programmers.rest might be, that was the page right before we took things down
I've basically already done the "enhanced version" of the same code, it's on crates.io and it's called [petgraph](https://crates.io/crates/petgraph). I'll mention another benefit: You can translate one graph to another, for example keeping all nodes the same, but change weights or edges, and you can interchange node indices between the two graphs. Graph algorithms are also very neat when nodes are numbered compactly.
Are you running GNOME on OSX? What is going on here?
Har, yes, I saw that post too.
Both of those ideas are possible (and have been brought up before). But this has already been bikeshedded at length and the gain seems small, IMO. `range_inclusive` or something like `(a..b).inclusive()` is enough for me.
please don't make me recompile servo :&gt;&gt; ah.. the reference images.. :)) yeah... 
I'm getting "Error: Page not found" on that bug link.
I see -- I was confused by [the Info.plist and mach files](http://i.imgur.com/xmDOiNN.png), while the interface was obviously GNOME. I'm guessing the build system guy uses OSX...
probably :&gt; here's [browser.html](https://www.youtube.com/watch?v=U6fgWWQLWa8) on Ubuntu :&gt;&gt;&gt; probably... there are a lot of mozilla devs using apple stuff 
That might make ranges more clear, but it doesn't make the language as a whole more clear. There are only so many times you can make that kind of tradeoff before you get symbol-soup.
leave me alone [that was a command to the autowiki bot]
my last game engine burned me really bad (f## *GL)... but maybe i can create some awareness about this issue (no i can't i'm nobody :(( ) um... mark shuttleworth once g+ one of my posts (does this count?) is there any sort of communication going on between Mozilla and Canonical?
A little of each. Unique pointers did used to be represented with `~`, but the Patina language in the paper is also not exactly the same as Rust in a number of respects..
This is Rust code - it works with Rust's semantics, and in this example `&lt;typeof(x)&gt;::do_something` is an `fn(self)`, which makes `x.do_something()` equivalent to `&lt;typeof(x)&gt;::do_something(x)` (Rust has `x.meth(...) ~ &lt;_&gt;::meth(adjust!(x), ...)`, where `adjust` is some number of autoderefs, potentially followed by an autoref) .
Depends. If you have code like let x = Box::new(5); let y = x; then you're right. Rust's semantics say that it's "like" a memcpy, but the optimizer will tend to just make `y` be another name for `x` rather than making a copy of the pointer. OTOH, if you have something like let x = Box::new(5); let y = Box::new(x); then x's pointer needs to be copied into a heap allocation, whose pointer is then put in y.
Darn, I'm going to be out of town for this one.
Boo! :-)
Yes, but vectors are significantly more flexible than if you used an actual `TypedArena`. For example, a graph implemented with vectors can easily be sent between threads. This comes back to the fact that indices without a graph are inert, so it's perfectly (memory) safe to send a graph even though Rust can't guarantee that all the indices are "dead".
I'm posting this to see what others (who may not follow the discuss forum) think about changes like this. I guess this begs the question: what changes should require an RFC?
[`mach`](https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/mach) is a build/test scripting framework that Gecko and Servo use.
Hey, cool. This has basically been my conclusion recently. I personally went for an implementation along the lines of `Graph = Vec&lt;Node&gt;`, `Node = (Data, Vec&lt;usize&gt;)`. I don't see a clear reason to keep the edge list as a linked-list. Particularly in insertion-only contexts. In my experience you generally want to loop over all the edges or pick some subset. Both of which are best handled by a Vec. As an added bonus for this design you get storable "references" to your nodes for free while looping the graph by just doing `.enumerate()`, and even use the same index set on multiple graphs. e.g. a spanning tree is just a list of parent indices. Or you can build an augmented graph and then easily find the nodes in the original. Edit: oh, and sidetables! e.g. "Oh I want to store &lt;additional property&gt; on each node" -&gt; Just make a new Vec&lt;property&gt;.
You can more or less do the same thing with arenas (re: manual free list) though I'll admit Rust doesn't make it very ergonomic. I am pretty sure there is a crate out there that actually implements it. I agree on the smaller-than-pointers part, though.
I think the problem here is not so much that there was no RFC (though that was part of it), but that this was a silent breaking change to a `#[stable]` API, and that can't be caught at compile time. Even if there was an RFC, the problem would remain - I personally don't read every single accepted RFC, and I imagine many others don't either. A more sensible approach here might've been to rename the function, or to not make the change at all - I find "argument ordering consistency" to be a pretty weak reason to change a `#[stable]` API. I would expect the bar to be higher at this point.
Note that this was still a pre-beta change. A lot of `#[stable]` APIs had breaking changes close to beta specifically because changing them now is almost completely off limits. I'm specifically not saying this shouldn't have gone through the RFC process, or wouldn't have warranted more discussion though. In fact my impression is that some things are rushed a bit due to the fixed release timeline :(.
&gt; but that this was a silent breaking change to a `#[stable]` API, and that can't be caught at compile time. You're right, I think that is an equally if not more important issue. I didn't mean to focus on the RFC aspect so exclusively. &gt;I find "argument ordering consistency" to be a pretty weak reason to change a #[stable] API. I agree. I think it's somewhat bikesheddy at this point to deviate from what people might expect when writing a Rust FFI binding to C code.
This is why I wish rust had first-class support for named parameters. Sure, they can be more verbose, but they also prevent things like this from happening. Another class of bugs that rust could eliminate. They could be implemented with macros/syntax extensions in today's rust, but because they're not standard, most functions wouldn't have support built into them&amp;mdash;the "other people's code" problem. (Actually... I wonder if it would be possible to hook deeper into the compiler code to make this work. Look up the function signature, match parameter names, and generate a function call with the arguments in the correct order. Unsure if all the information would be there at the right time in the compile process, but it's an idea.)
Does it make sense to apply this to the special case of a tree? One where each node has an arbitrary number of (ordered) children, and can get to its parent, previous/next sibling and first/last child in O(1) time. I’m fairly happy with [my reference-counting experiment](https://github.com/SimonSapin/rust-rctree), but I’m also interested in exploring other approaches. (For context, this would be the data structure for a parsed HTML/XML document.)
You'd want a way to match the signature when initialising the application and resolving linked libraries. Compile time only wouldn't protect against the case where the implementation of the library is modified under an already compiled application. Including the parameter names, and their corresponding order in the function signature sounds like the right option. If the library implementation changed, you'd get an error at initialisation time. The simple version could just be a kind of symbol mangling. Under any circumstance you'd have to make use of parameter naming mandatory to completely wipe out these classes of bugs.
Good breakdown. I had many similar feelings and I'm glad to see they'll be refreshing it for 1.0. However, I don't feel that Rust is targeted only at people familiar with stack programming (e.g. C++.) Therefore, it seems sensible to have a certain level of introduction to concepts of managing memory that might be more alien to people looking to branch out from a language like Go or Java. The book (like Rust) isn't only written for us. :)
Unless the cast gets optimized away, this is less efficient.
A big argument against named parameters is that they are a backwards compatibility hazard. Changing something as simple as a variable name might mess up someone's upstream code, and then you will have to bump a major version for a simple seemingly internal refactor. I don't have a dog in the fight, I'd be happy either way, but just wanted to play devils advocate :)
You can do it with ffmpeg in a single command. I'm not sure if it's the best way, but it was easy. [This page](https://trac.ffmpeg.org/wiki/Capture/Desktop) claims you can do it on Windows/OS X too.
Very exciting stuff! I'm very hopeful that type inference gets into the compiler sometime in the 1.0 cycle.
It's portable enough for me, i.e. you can get the same behaviour with Clang, GCC and MSVC and the endian issues can be fixed with ntohl.
Try to implement a generic library like one in which you can add Matrix, vectors, etc and multiply them, with the most efficient implementation for each of the algorithms. The library must be extensible for any new type and combination of types. Later use that library. If I am not wrong, function overloading is going to be important in this case, because we need syntactical uniformity everywhere. Function overloading seems superficial... until you need it. In fact, I think that function overloading is so essential for writing generic, reusable, extensible code, that it cannot be done the same way without it. I did not take a deep look at this, though.
&gt; t seems the Rust community considers overloading to be a misfeature in C++, they want you to be more specific with function naming. it does still dispatch on the first parameter, and there's multi parameter traits. That is going to kill generic code. In generic code you need the same name for the same thing, but a different implementation. So I am pretty sure that compile-time function overloading is pretty essential in generic contexts.
The guide needs an Option to choose for beginners and experienced programmer. Nobody wants to learn the ABC again if he knows it and nobody wants to interpretate poetry if you can barely read sentences. The worst thing about the programming sector is the total lack of didactic everywhere. I have to say you may be be great in developing high quality abstract code stuff but 99% of all people in the IT are just worthless when it comes down to teach the things. That's the reason almost every book about IT is shit. Pay a teacher or some pedagogic person to evaulate those things and you will be loved by every newcomer.
been spoken, but otherwise, yes.
Not anymore.
I am pretty sure C++ is the only language that has a chance in hell of integrating cleanly with C++ I am not https://github.com/dobkeratops/compiler I've given up recently as a 1man language with zero community seems futile but I think this experiment proves it would be possible to get the benefits of Rusts' cleanup, whilst retaining C++ compatibility. my pet language copies Rusts' syntax, just uses C++ adhoc overloading, but still adds some ADTs, pattern matching.. traits could be optional like C++ concepts will be. I believe these features could be retrofitted to either a C++ compiler (like SPECS), or to Rust as a looser dialect. (I didn't personally feel confident enough to fork either clang or rustc.) There's quite a few people answering here, "want C++ compatibility" .. are there enough to collaborate and get this done ? What I'm after is the 95% of C++ and 95% of Rust that I like blended together.
It seems that it does according to the documentation. Sadly I can't use libc in the Beta channel, so I'll do that once libc is stable. 
I'd like to add that the actual signature of the &gt; fn max_by&lt;B: Ord, F&gt;(self, mut f: F) -&gt; Option&lt;Self::Item&gt; where &gt; Self: Sized, &gt; F: FnMut(&amp;Self::Item) -&gt; B, contains generic bounds which I think should make the error message if passed the wrong type better then with C++ templates (I'm guessing I haven't dealt much with templates but I've read that the lack of something like this in c++ is what causes template expansion explosion).
TIL :)
The article's design is neat because it's simple to access all incoming edges for a node, even if the graph is directed.
You should also consider making `add_element` accept `T` by value: fn add_element&lt;T: GeomDisplay&gt;(&amp;self, elem: T) { self.elems.push(Box::new(elem)) }
I agree that it is important, and that we should strive to maintain it on most cases, but I don't think it is worth alienating the community with a silent, segfault-causing, breaking change to a `#[stable]` API. I understand why other people with different experiences might want to draw the line a bit further, however (I've never done anything serious with PHP).
While it works in Rust, your whole point was that the equivalent C++ doesn’t quite work out the same. And my point is that `fn foo(x: Bar)` matches `void foo(Bar x);` in terms of semantics, but fn foo(Bar x) fn foo_method(self) are a teeny bit different from void foo(Bar&amp;&amp; x); void foo_member() &amp;&amp;; and there is in fact no `foo_method` equivalent. So for the sake of your example I’d say use a function. As an example, this is valid C++ that does what I believe we call 2 partial moves in Rust-land: auto x = std::make_unique&lt;int&gt;(3); auto y = std::make_unique&lt;int&gt;(6); auto t = std::make_pair(std::move(x), std::move(y)); // first move auto p = std::get&lt;0&gt;(std::move(t)); assert( p &amp;&amp; !t.first ); // second move, still fine auto q = std::move(t).second; assert( q &amp;&amp; !t.second ); If we hadn’t used `std::get` but instead an `std::pair&lt;T, U&gt;`-taking function, then that second assert would yell at us.
Unfortunately, a revert at this point would cause another silent breaking change. People that already changed their code would see it break on runtime (possibly segfault) again, and somehow figure out that they need to undo the recent fix.
It doesn't help solve the relatively minor issue of libraries being broken, but it does solve the long term issue by switching back to many people's preferred order. I assume /u/pcwalton is focusing on the latter rather that the former. I say minor because libraries broken by the change or the revert are "just" temporary pre-1.0 things; sure, it hurts, but only a few hundred/thousand people for a week, or month. If the argument order is fundamentally much worse, that hurts everyone who uses those functions for years.
Some time ago there was a great series called "Rust for C++ programmers" (which, interestingly, ended up teaching me some C++ concepts, since I already knew Rust). Maybe it would be a good addition to the official docs if updated and reformatted (it is a noncontiguous series of blog posts).
Thanks. I ended up with this: http://pastebin.com/99vCcvX8
return type of given expession. 
Does anybody know how to use Racer with multirust? I have libsyntax in ~/.multirust/toolchains/nightly/lib, but there is no src dir in the multirust directories. Does this mean I have to build from source?
Saying "properly typed" sounds a bit judgmental here. It really depends on the surrounding code, and why you're doing the copy in the first place. It doesn't sound "improper" to me to have a single function that modifies a struct and then copies it over to another location, for example (in which case both pointers would've been mutable).
Looks like arena is not yet stable and thus not available in the beta channel. As there is also no external crate for it, but it still lives in the main tree, the only thing you could do is copying the [source](https://github.com/rust-lang/rust//blob/beta/src/libarena/lib.rs) into your own project for now, or stay on nightly for now.
Can't you use `std::rt::unwind::try` instead of spawning a thread? At least while you're on the nightly branch.
I'm not for that, at least I want to make it clear that some sections are basic low level programming and not Rust specific, therefore skippable. That might work.
They're not complaining that the memcpy equivalents ares backwards compared to C, they're complaining that they're backwards compared to the last version of Rust.
&gt; This is why I wish rust had first-class support for named parameters. Sure, they can be more verbose, but they also prevent things like this from happening. Another class of bugs that rust could eliminate. You'd need more than just first-class support for named parameters. You'd need to drop support for unnamed parameters. Nobody can reasonably be expected to use named parameters to a memcpy function on the off-chance that a stable part of the standard library suddenly reverses its parameters.
What are you using `rustc_private` for?
Yeah, I went to bed feeling pretty shitty about myself from this post, (you know which one, not the OP) to be honest about it. Even though I've written C since I was a child, and C++ in the pre-modern era. While it's true that systems hasn't been my professional area of focus, I see that as a good thing for Rust, not bad. If Rust is just for C++ people, it will fail to catch on. Pointed criticism, as in the OP, is good, but borderline personal attacks is not. But separate from that, I've been planning some TOC changes to the book that should help alleviate this sort of issue, I've been thinking about it for weeks. I wanted to wait till beta dropped first. So, expect some changes, and I think you'll like them. EDIT: PR laying it out here: https://github.com/rust-lang/rust/pull/24178
&gt; Yeah, I went to bed feeling pretty shitty about myself from this post Aw, dont feel bad, you're doing a great job (considering you done almost all of it yourself) &gt; If Rust is just for C++ people, it will fail to catch on i completely agree with you (although they do fill similar niches) &gt; I've been planning some TOC changes to the book that should help alleviate this sort of issue looking forward to it :)
Props for keeping your cool. Malcontents taking over legitimate attempts at discussion cause me no end of stress. As for the proposal, i would suggest at least a rule of thumb to prefer starting an rfc if you aren't sure
Why not just skip the sections you're already familiar with? There is no rule saying that you have to read it cover-to-cover. And to extend that further, instead of the book, why not just go straight to the Reference spec?
Haters gonna hate. I know it sucks and I'm *not* telling you to "just shrug it off", but keep in mind that many hundreds (thousands?) of people are reading the guide and aren't being jerks about it on the mailing list. This thread does show an example of the excellent community building that happens on official rust channels: positive reinforcement via inclusive responses to "outsiders", and not hesitating to call out bad behaviour. Regarding the constructive criticism of the OP, it would probably be sufficient to include links to the next section at the start of "shared concepts" sections. E.g. in the Pointers chapter you have this text: &gt; If you aren't familiar with the concept of pointers, here's a short introduction. Pointers are a very fundamental concept in systems programming languages, so it's important to understand them. Just changing that so something like: &gt; Pointers are a very fundamental concept in systems programming languages, so it's important to understand them. We've included a short introduction to the concept of pointers below, but if you are already familiar with pointers from another language such as C or C++, you may wish to skip straight ahead to the explanations of Rust's pointer types, starting with `[References](#references)`. (Maybe I should send a PR for this...)
I know your history, you have said it in interviews and the like, and I know that you have experience writing low level code, all I was trying to say was that you lately have been huge in the Ruby community and therefore are writing for that audience. I am sure of your knowledge in the field of systems, I would never question that, and I am proud to say that we have such a great writer and as knowledgable person in the community as you. Sorry if it came across like you do not know what you are doing, because I am sure you do. Due to the structure of the book (which I love!) I am sure that some simple TOC changes, along with some notes of chapters being skippable to a more knowledgeable crowd, the book can be even better, maybe I should have mentioned that. I am confident that you will make the right decisions, thank you for giving me your feedback, I will work on my tone :)
Slightly off topic. But can I link a static library created using Visual C++? Or should I must use GCC in Windows?
It's cool man, we all say mean things at times without meaning it. I've done it too. No worries, let's just focus on the work to be done in the future, okay?
Thanks for the kind words.
Have you checked out syntex?
You can probably assume that it's ASCII.
You might be interested in http://simonsapin.github.io/wtf-8/
compiler has it, but it doesn't provide any interface to access it outside (i.e. from racer in this case)
It might be kind of cool if there was a "choose your own adventure" way to learn Rust. For example, if you're coming from a C/C++ background, you don't need to read the section on how pointers work. There could be a link in the margin that let you skip to the next appropriate section on Rust. We could also have a link to expand the explanation or link to an external resource that explains the content in greater detail. We could even have "paths" through the documentation that automatically expand or skip certain sections. A "Rust for C++ programers" could skip most of the explanations on pointers and move semantics and maybe focus more on the trait system and functional aspects of the language. A "Rust for Haskellers" could skip most of the FP and trait stuff and focus on the memory management. Etc.
Why would you change the variable name in a function definition other than in order to change the API, though?
It was absolutely a mistake to push this through without an RFC, and I apologize for signing off on it. It wound up causing some painful fallout, and it's clear that many have strong opinions about the order here that weren't taken into account. Of course, this kind of thing won't happen in the future, since we won't be able to make changes to stable APIs. The main question now is whether, and how, we should reverse this change. I'm going to suggest that discussion on the next step happen in the [ongoing discuss thread](http://internals.rust-lang.org/t/memcpy-is-backwards/1797/), where there are already a number of interesting suggestions. Let's try to reach a consensus there before taking action.
"Rust is a work-in-progress and may do anything it likes up to and including eating your laundry."
The beta deadline is the result of a lot of factors, including pressure from lots of people, most of whom don't follow the subreddit and RFCs, to stabilize the language. It is *not* "self-imposed" and definitely not arbitrary.
Perhaps some kind of hyperlinked, tree-based concept editable by community members given consensus.... I have come up with an innovative term, "Wiki", which translates approximately to "clusterf!ck".
I hadn't seen syntex\_syntax - thanks for the pointer! I suspect by the time rust 1.0 drops racer may also need some of the librustc_* crates, but I guess these could also be mirrored as standalone crates too.
I'm very sorry to hear about the productivity loss due to this change; as I've said elsewhere, I'm the one who signed off on it without an RFC, and that was absolutely a mistake. Going forward: * We do have a code review process, and a marker for "stable" APIs. This kind of change to a stable API should never be merged after 1.0 * But if it did by accident, it would first go through a beta cycle, so reports of breakage would give us a chance to fix it before the next release. * Moreover, /u/brson has been working on some amazing CI tooling that will allow us to test releases against the crates.io ecosystem and detect breakage that way. Altogether, starting at 1.0 final, the process of upgrading Rust should be a very smooth one.
Yes, it was an ill-advised last-minute change that should've undergone more discussion. I don't think the deadline is to blame, though; no matter when we decide to ship, there will always be those last couple of warts we're trying to remove. Rather, it was a bad call on my part signing off on the change without more input and so closely to the deadline. Mea culpa. As I said [above](http://www.reddit.com/r/rust/comments/31p33q/memcpy_is_backwards/cq48v9c), I don't think this kind of thing is likely to happen after 1.0, for a variety of reasons. All that said, there's [ongoing discussion](http://internals.rust-lang.org/t/memcpy-is-backwards/1797/) about whether we should take any further steps on this change during the 1.0 beta cycle.
See https://www.reddit.com/r/rust/comments/31qhyu/using_arena_in_beta/ and https://github.com/rust-lang/rust/issues/24153
Good point. I guess I'm kind of only paying attention to the influences I don't like =P.
I'm not saying the deadline played no role, just that this is an inevitable aspect of *having* a deadline: you'll be tempted to make last-minute changes. And we clearly need a deadline for release. It's worth remembering the big picture here. We decided to release alpha2, rather than go straight to beta, precisely to gain more time and experience with a portion of the `std`library. During the last two cycles, the *overall* pace of breaking changes has decreased enormously. (Not saying there's no breakage, just that the volume has slowed to a trickle.) And we've also been leaving plenty of time for experience prior to stabilization in general. I think this decision was an isolated mistake.
Landing changes concurrently with declaring them stable is not an isolated occurrence (do I need to dig up PRs or can we just agree on that?). While I think it's great that you decided to do a second alpha, I don't think that's as significant a concession as you make it out to be, b/c when you announced that second alpha you simultaneously announced there would only be one beta (when previously you had implied at least 2) and set a firm final release date (when previously it was 'when the betas are solid').
Usually, adding "Rust" is superflous: the entire book is about Rust, so you could add that to every single chapter. (and also thanks)
You can prevent dangling indexes easely: Index{idx: u32, counter: u32} NodeWrapper{counter: u32, data: NodeData} fn get(vec: &amp;[NodeWrapper], index: Index) -&gt; Option&lt;NodeData&gt; { let node = vec[index.idx]; if node.counter == index.counter { Some(node.data) } else { None } } Bump counter by-vec on each push or by-wrapper after each rewrite.
I'd be OK with this, you don't want to have to support two different sets of functions, do you?
I remember reading this idea before in a few earlier threads. It feels like that would make it WAY too easy to miss something. Not all Haskellers have equal knowledge, same with C++, or us interpreted folk. Especially since a language might have a concept, but it doesn't map exactly like it would in Rust so you get to this point of "is this different enough to warrant an explanation?" Segregating people based on assumed prior knowledge and directing them all down a specialized learning path created with incomplete information about their experience sounds like added complexity that would do way more harm than good. I for one am really curious and excited about the TOC overhaul steveklabnik is working on, because he's obviously put alot of thought into it. People are both smart AND lazy, which is a glorious combination. If a person sees the beginning of an explanation they already know, they'll mentally flip to skim mode and get passed it...the same way people have been reading for centuries. The only reason it feels like its such a big deal is because we are all actively looking for ways to improve it. I have trouble believing, though I could be wrong, that people were so offended by a few paragraphs explaining basic things that their experience with Rust was radically tainted.
You're arguing an awful lot against something I never said. Deadlines: great. Having a core leadership team: great. Allowing deadlines to pressure you into bypassing process: not so great. Making a promise (by labeling something stable) that you immediately have to break (b/c it had no time to bake and ended up being a poor decision): not so great. As much as everyone wants Rust to be here as soon as it can, please keep in mind that in five more years nobody at all will remember May vs August, but they'll still be living w/ everything marked stable when the hammer drops.
Do you ever get stuff done or do you find yourself stuck with irrelevant details such as this most of the time?
For `std::get&lt;0&gt;` and pairs it would be `T&amp;&amp; get(std::pair&lt;T, U&gt;&amp;&amp;);`.
C++ is all about precise control over data. Having an extra pointer when you don't need it is a pretty important detail. Everything I've worked on in anger has involved trimming bytes all over the place as a necessity. if you're ok with extra pointers willy nilly, why not just use a garbage collected language
Well it depends on the size of the objects you're managing. If the size is much larger than a pointer, I don't care about an additional one. In the codebase i work on objects can be linear arrays of, say, 16 GiB each.
Uses 2 spaces for indentation, heretic! :D
Oh, `var` would be just `mut`, pure difference in taste there :P The &amp; wouldn't be there because I think it would make sense to have reference/alias by default, or at least let the compiler decide which one is better. 
Gotcha, thanks :)
FWIW: I'm new to Rust, have never used C++ professionally and this really resonated with me. I would also like to see a much more thorough treatment of traits, ownership and lifetimes in the guide. It should start early and pervade the whole thing. Without a deep understanding of how that stuff works you cannot even write trivial rust programs. I read through the guide and found myself incapable of doing simple things without a lot of struggle and googling. I still don't fully understand what is going on it a lot of situations. I didn't mind learning about cargo. It seems useful and I never felt it got in the way.
There is `std::fs::copy` and `std::io::copy`, don't know if there are more copying functions.
Hypothetically, you could do this with something like [shoggoth.rs][1] or [dimensioned's peano.rs][2], which implement type-level numbers, or implement your own type-level numbers (difficult, confusing). Then, you could have the ::new method take the modulo and thus safely implement Add, Sub, Mul, Div, etc. // example code, never compiled, just off the top of my head struct ModN&lt;N: Natural&gt; { n: u64 // or whatever } impl&lt;N: Natural&gt; ModN&lt;N&gt; { fn new(value: u64) { ModN { n: value % N.to_int() } } fn value(&amp;self) -&gt; u64 { self.n } } impl&lt;N: Natural&gt; Add for ModN&lt;N&gt; { type Output = ModN&lt;N&gt;; fn add(self, rhs: ModN&lt;N&gt;) -&gt; &lt;Self as Add&gt;::Output { ModN { value: (self.n + rhs.n) % N.to_int() } } } // etc I'm not sure how rustic this would be, but it would probably get the job done. [1]: https://github.com/epsilonz/shoggoth.rs [2]: https://github.com/paholg/dimensioned/blob/master/src/peano.rs
It may be that the reduced-panic parser may help this problem. If you have time, could you paste an example into a gist or maybe [file an issue](https://github.com/phildawes/racer/issues) - thanks!
The core and graphics APIs has been redesigned after Rust changed coherence rules. All systems are operating under normal parameters.
Rust is one of the most rightward drifting languages that I know of, so 2 spaces makes perfect logical sense.
The same argument can be made against static typing: Changing a parameter's type will break someone's upstream code. From writing my fair share of Obj-C code changing parameter names very rarely leads to any trouble upstream. Either the interface is marked as stable and isn't to be touched or it is given that breaking can occur. The problem is the same with or without named parameters. But with named parameters code readability improved significantly. You can read through Obj-C code without switching between files to find a method's signature to see what parameters it exactly takes. Yes, an IDE should help out there - but guess what Rust is currently lacking :) 
Thanks for that, I didn't know about the rust-wiki-backup. I changed the link accordingly.
I agree. Fork the language.
Yes, if you rely on deeply nested code. Btw you shouldn't...
&gt; In the general case, `1.(x+1)` will compile any program which compiled on `1.x`. Does that mean 1.3 will not neccessarily compile 1.1 code, or did you mean something like `1.x` will compile `1.y` for `x &gt; y`?
There really does need to be separate guides for people with systems programming experience and those without. If people with previous experience read the current guide they'll quickly assume they already know everything and miss something important, but if you direct the guide at C/C++ developers then lots of other people will be completely lost.
Does it build with beta rust?
&gt; For example I'd love to read more about implementation details, memory layout, One of the reasons this has historically not been written about is that none of this is guaranteed. Once you document it, peole rely on it, and once they rely on it, it's de-facto stable.
If only there was a character that had the meaning "indent this", but whose display in an editor could be configured...
Yes, it is possible to use "tabs for indentation, spaces for alignment" in a way that produces correct results no matter how wide a tab is. But I've never seen a large codebase actually stick to that discipline. I'm sure some projects manage, and there must be tools to help with it. But it's also going to be an obstacle and annoyance to each new contributor. I don't think it's worth the limited flexibility that you get.
The [ordered collection](https://github.com/google/hat-backup/blob/master/src/hat/ordered_collection.rs) module seems weird to me. Unless they're intentionally restricting the methods available to `BTreeMap`, I would have thought an extension trait would be easier.
I didn't say anything about using spaces for alignment.
&gt; Sorry, that was an unfortunate choice of words - I wasn't trying to be judgmental No problem :) Now I realize my response came out a bit more confrontational than I intended, so I apologize as well. &gt; Personally I would absolutely require that the source pointer be const (using "as *const &lt;T&gt;" if necessary) That's a good habit to have, but it looks noisy, and I wouldn't expect most people to do it. It's a bit like doing `(&amp;my_vec)[0]` instead of `my_vec[0]`, just in case someone implements `Index` for `Vec`.
That's no worse than wanting to rename a public function and not being able to. Personally the problem of fixing the API is an exaggerated issue. It doesn't come up in practice IMHO.
Below C++11, no less!
That's probably because of [existing](https://google-styleguide.googlecode.com/svn/trunk/cppguide.html#Spaces_vs._Tabs) Google [style guides](https://google-styleguide.googlecode.com/svn/trunk/javaguide.html#s4.2-block-indentation).
It should be okay to move the release date for one month or two, if there's a genuine need. I remember the first Ubuntu LTS wasn't launched in April, but in June (Dapper was Ubuntu 6.06, not Ubuntu 6.04). This kind of violated their self-imposed discipline of releasing each 6 months, but it wasn't repeated after that. And it wasn't a disaster. A project that has a general deadline but don't have a specific release date is the Linux kernel. They release every 2-3 months but Linus will have as many -rc as he feel necessary. Of course he ships with known bugs (or else he wouldn't ship at all) but not all bugs are created equal. I think something in need here is a way to determine which crates in crates.io are calling the affected functions (alongside the filename and line number of those calls). I think a shallow copy of each git repository, plus a grep script would do the trick. Or, at very least, the beta compiler should emit a warning whenever those functions are called, saying that the parameter order changed. The best way to avoid a silent error is to always warn.. Perhaps a "second beta" (or rather, a release candidate) would be worthwhile.
A deduplicating backup program was my ambitious thing I wanted to try doing it rust. Maybe I'll try contributing to this instead. I'm using attic right now but using something written in python makes me nervous. edit: hmm, CLA...
&gt; That's a good habit to have, but it looks noisy, and I wouldn't expect most people to do it. Well, considering that `copy`/`copy_nonoverlapping` are marked unsafe and you aren't supposed to use them willy-nilly I think it would be a fair requirement to make - it's not like you're going to have hundreds of lines of code where you use those functions.
Use `max_by` like this: `array.iter().enumerate().max_by(|&amp;(_, e)| e)` EDIT: Nope, this isn't available on beta. I need to start testing my code before submitting. This works: `array.iter().enumerate().map(|(x, y)| (y, x)).max()`
There's `max_by` and `min_by`: array.iter().enumerate().max_by(|&amp;(_, item)| item)
Sounds interesting, using a continuous range inside the key space for the edges of a particular node is smart, but the edge lookup performance becomes dependent on the total number of edges (instead of the number of edges of a particular node).
Thanks, 14427. That's certainly one way to get around the index being first! But [as noted below](https://www.reddit.com/r/rust/comments/31syce/using_iterators_to_find_the_index_of_the_min_or/cq4r6xw), it looks like using iterators leads to a performance loss over the conventional method.
I just can't help thinking of AT&amp;T vs. Intel assembly language syntax. Reasonable people can differ on if dst,src or src,dst feels more natural.
This is what I came up with, but I can't get it to work because I suck at lifetimes :P http://is.gd/GC7em4 However, why do you need to abstract over things that can borrow? If you know the function is going to borrow the object, can't you just borrow before you call the function and pass in a `&amp;S`?
is space at a premium these days?
My results are even wilder: $ rustc max-index.rs --test -O &amp;&amp; ./max-index.exe --bench running 4 tests test tests::test_max_index_for ... ignored test tests::test_max_index_iter ... ignored test tests::bench_max_index_for ... bench: 9540 ns/iter (+/- 26) test tests::bench_max_index_iter ... bench: 39808 ns/iter (+/- 57) test result: ok. 0 passed; 0 failed; 2 ignored; 2 measured Without optimizations, the gap is much narrower, but the iterator version still loses by a mile: $ rustc max-index.rs --test &amp;&amp; ./max-index.exe --bench running 4 tests test tests::test_max_index_for ... ignored test tests::test_max_index_iter ... ignored test tests::bench_max_index_for ... bench: 322161 ns/iter (+/- 14992) test tests::bench_max_index_iter ... bench: 503015 ns/iter (+/- 23560) test result: ok. 0 passed; 0 failed; 2 ignored; 2 measured 
Yeah, it threw me for a loop, too. (Pun intended) I'm running it through a profiler to see if anything interesting comes up.
Yeah, that kind of surprised me. C++ is my language of choice, but only because it's practical, not because it's inspirational. I *did* find C++0x inspirational, but that was when the features started getting implemented a decade ago. The implication I'm inferring from this is that there's still a large number of people still stuck on C++98/03 in their day jobs, which is a right shame. And after all these years it's kind of surprising to see system programming languages gaining so much favour again. The top four favourite languages are all systems languages!
The new image for rust-highfive is awesome.
The opposing argument is command line tools use cp srt dst
Is any one really using Rust for their day jobs though? I suspect part of the reason rust is ranked this high is that only a few enthusiasts are working with it right now.
Using a match expression in a method impl puts you at 16 spaces for the first code that actually does anything. That seems excessive.
&gt; you need to plan too much upfront, it becomes a pain when you don't know for sure which functions which types will have, you'd have to have lots of single function traits, and micromanage a heirarchy of groupings... its' just as annoying as header files. Yes, this can be a problem. It is the same problem as when you have a hierarchy of classes upfront and later you want to change it. It does not work ad-hoc, which is a problem when evolving code I guess. &gt; I believe in organic programming, you don't pretend you understand exactly how everything will work upfront - you learn about the problem through experimentation (if you could predict everything in your head.. you wouldn't need a computer), and you want code in a form that is malleable, easy to move things around Totally agree. This is how things actually work in my experience. 
&gt; Since tuples are compared in order, this could have been nicely solved with array.iter().enumerate().max(). You could always map-and-swap no? Or "hand roll" it: just zip your seq with a range. 
Question to devs: are there parts of Piston that you consider fairly stable, or is everything still liable to change?
First question: yes. http://is.gd/4JJ2e5 fn main() { let test = [0, 1, 2, 5, 10, 15, 999]; for i in &amp;test[3..] { println!("{}", i); } } As for your second question, do you mean like this? http://is.gd/h6kquj fn main() { let test = [0, 1, 2, 5, 10, 15, 999]; let foo = &amp;test[3..]; // start at 5 let bar = &amp;foo[1..]; // start at 10 println!("{:?}", foo); println!("{:?}", bar); }
Also see this: http://doc.rust-lang.org/book/arrays-vectors-and-slices.html
Too hard to bootstrap cargo on my OS. Too hard to use others' code without cargo.
Swift and Go are not systems languages.
yup this is exactly what I was talking about. I couldn't find anything about this in the rust book. Thanks for the clarification.
Simply worked! Awesome. I'm still learning rust, would never imagine any of suggestions. Thanks!
Rust and C++11 might have the same bias.. people love learning about it, but can't really use it at their job yet.
You might consider just stating this up front when you recommend tabs over spaces.
This change improves consistency as Rust's collections have the `len` method, not the `size` method. I believe the change itself is quite simple. Unfortunately this didn't get into beta. Now that this is a late breaking change, is it an acceptable one? Or is the "deprecating `size_hint`" alternative acceptable? 
The core is fairly stable, but in order to use the loop in benchmark mode it probably needs some extra settings. I also discovered an issue with nested loop this morning that requires some of the state can be moved from the event iterator to the window, but this won't have any effect on the usability.
This is pretty exciting news! You are awesome!
I forgot, for the last point I read this rfc https://github.com/rust-lang/rfcs/blob/master/text/0192-bounds-on-object-and-generic-types.md . Is this documented at a better place or are users expected to read the RFCs? Im not saying it is wrong if it were so but Im just wondering if it is.
Wrapping `b` in a `std::cell::Cell` would probably solve this.
I get the feeling that I might have to create the Vector with Box, because that is the only way to transfer owner ship of the Vector back to the calling function. I could be wrong.
less_than_p is a variable in the qs function. A reference to it which you try to return out of qs will not be valid after qs finishes executing. You can try to return less_than_p by value or return a Box::new(less_than_p) .
Would the `flat_map` method of iterators help? http://is.gd/RHAfZW let result = (0..9).flat_map(|number: u32| vec![number].into_iter()); for i in result { print!("{:?} ", i); } println!(""); let result = (0..9).filter(|i| i % 3 == 0).flat_map(|number: u64| vec![vec![number,number]].into_iter()); for i in result { print!("{:?} ", i); }
And when I return or pass by value, the mem is always allocated in the stack?
Yes and no. When you pass a struct by value, it is indeed stored on the stack (actually may be in registers too, but that's not really important). But the `Vec` struct contains of only three words: length, capacity and... a pointer to the actual data allocated on the heap.
&gt; It's a shame enumerate takes a backwards approach and puts the index in the first position of the enum, i.e, (i, value) as opposed to (value, i) is this again one of these stupid "we can't break it in beta!!!" things?
That's right. And when you have `Box&lt;Vec&gt;`, the only thing stored on stack would be one pointer. And generally speaking, you shouldn't use `Box&lt;T&gt;` unless you really have to – when you just can't use plain `T` (eg. recursive data structures or objects without compile-time-known size) or have a really good other reason .
&gt;You might consider just stating this up front when you recommend tabs over spaces. This is going to sound super dumb but I had simply forgotten that other people are interested in aligning things. I had intended my original reply to /u/msiemens to be in the same lighthearted spirit as his comment; what my reply was missing in retrospect was a smiley. I thought their idea that using 2 spaces would be "heretical" was a signal to readers that this was a holy war and that there wouldn't be much point to a serious attempt to resolve the difference. In that lighthearted spirit, including the idea of abandoning alignment in my reply would make it sound clunky. Since people do seem to be seriously discussing the idea, here's a fuller explanation of my position, although I'm sure you've heard it all before. My preference for tabs comes from a desire to "say what I mean". If someone mucked about with a project of yours, silently replacing **all** of your N-space indents with N-1, but left everything else alone, how angry would you be? How much trouble would you go through to fix it? My guess is (and this might just be because of my peculiar viewpoint) that this would not be worth any trouble at all, because the particular number of spaces isn't terribly relevant. The meaning of N spaces in your project before it was vandalized was just "indent this", and N-1 spaces (for N &gt; 2) is just as capable of conveying that meaning in the project post-vandalism. If you accept the idea that the idea you're attempting to convey is "indent this" rather than "indent this with 4 spaces in particular", then when you have the intention of indenting you have a few options. You have the option of rendering your intent into action with 4 spaces in particular, maybe because you think that gives a good presentation of your code. You also have the option of using the "indent this" character built into the character set. It is common for programmers to have the desire to express themselves at the appropriate level of abstraction- to "say what they mean". Since I *mean* "indent this", and not "indent this with four spaces in particular", I would rather *say* "indent this" than "indent this with four spaces in particular". It is often the case that a more elegant solution does not apply because of an inconvenient requirement. If you have the desire to align elements of your code, then using tabs alone won't work. And I can totally believe /u/mozilla_kmc that "tabs for indentation, spaces for alignment" doesn't work in practice for large projects; I haven't put really any thought into alignment because I don't care about it. It seems an excessive concern with presentation rather than content.
See the rust book here http://doc.rust-lang.org/nightly/book/closures.html#move-closures The closure captures b per reference which correctly means it cannot be modified. You need to add the move keyword to the closure which causes b to be copied (move on i32 means copy): a = Box::new(a.filter(move |x| !(x % b) == 0)) as Box&lt;Iterator&lt;Item=i32&gt;&gt;;
Why not do it like this? fn prime_numbers(upper_bound: i32) -&gt; Vec&lt;i32&gt; { if upper_bound &lt; 2 { return vec![]; } let mut primes = vec![2]; for x in 3..upper_bound { if vec.iter().any(|p| x % p == 0){ continue; } primes.push(x); } return primes; } Disclaimer: Haven't compiled or tested this. I'm pretty sure it contains syntax errors and bugs.
When I was learning Rust, I implemented a repository of [sorting algorithms](https://github.com/wackywendell/sorting-rs) myself, and [here is quicksort](https://github.com/wackywendell/sorting-rs/blob/master/src/algorithms.rs#L4-L66). I've been keeping them up to date, so it should still work. Just thought you might be interested...
You can just return the `Vec`, without any `Box` or reference: fn qs(arr: &amp;[i32]) -&gt; Vec&lt;i32&gt; { [...] return less_than_p } And here is a [playpen link](http://is.gd/kcJDgw).
An easy way to get an empty iterator is `None.into_iter()`, though depending on context you may need some more type annotations. (Similarly, `Some(foo).into_iter()` gives an iterator of length 1.)
I'd say they have valid concerns and they are not trolling. Some believe that *every* x.y-beta/x.y-stable(final) pair of releases should be compatible and the proposed change is not worth breaking the compatibility, while some others believe that 1.0-beta/1.0-stable(final) can be special cased and the proposed change is minor enough to be acceptable. I am in the latter camp, but the former camp more consistently stick to the backwards compatibility promise. Though, as brought up in the RFC comments, it is likely that 1.0-stable(final) is already going to have at least one breaking change. `PhantomFn` is deprecated in nighties, and is likely to be removed in 1.0-stable(final). This removal was intended to land before beta, but it unfortunately slipped. This satuation with `PhantomFn` was a bit like the `size_hint -&gt; len_hint` change, which was brought up before beta but no RFC was made in time. EDIT: Clarification. 
Or we can do it without any allocation: fn qs&lt;E: Ord&gt;(arr: &amp;mut [E]) { if 1 &lt; arr.len() { let (mut pivot, mut hi) = (0, arr.len()-1); for _ in 0..arr.len()-1 { if arr[pivot] &lt; arr[pivot+1] { arr.swap(pivot+1, hi); hi -= 1; } else { arr.swap(pivot, pivot+1); pivot += 1; } } qs(&amp;mut arr[..pivot]); qs(&amp;mut arr[pivot+1..]); } }
I think this should be enough. `b` is the only captured variable and it's also `Copy`, so it should not have any bad side effects. The problem right now is that `b` is referenced to and stored in `a`, outside of `for`, making it temporarily immutable for the next iteration.
Why didn't you just try it?
Or, more generically: http://is.gd/JXedfU
Only some of it currently is. I'm slowly going through and updating things like this. One of the reasons it isn't done right away is that an RFC being accepted doens't mean the functionality lands: we have a ton of RFCs that have only their backwards incompatible functionality implemented.
Unfortunately, the argument is being put in a struct, and I'm going to need shared mutable access to it once its in a structures :-/
Not exactly, there hasn't been any proposals about `enumerate`.
No, it was probably a language design preference when it was introduced. I don't think there's really a standard since languages like Lua and Python order it (index, value), but having worked with Ruby and Javascript for so long, I would have preferred it the other way around. :P
I believe this can go both ways: 1. It is a small mistake, so no need to fix it. 2. It is a small mistake, so why not fix it? So we may agree to disagree. :) &gt; It's better to be serious about stability ... Agreed, but IMHO `1.0.0-beta -&gt; 1.0.0` (using the correct semver format here) is a special case where it is okay to have a small amount of breaking changes, without breaking the semver promise. From the [semver specification](http://semver.org/): &gt; `5.` Version 1.0.0 defines the public API. ... &gt; `9.` ... Pre-release versions have a lower precedence than the associated normal version. A pre-release version indicates that the version is unstable and might not satisfy the intended compatibility requirements as denoted by its associated normal version. ... 
Long winding logic tends to make the ! at the start hard to spot. Personal preference.
If you're looking for inspiration, we have a pretty complete implementation of [Rosetta code for Rust](https://github.com/Hoverbear/rust-rosetta), including prime generation with the [sieve of eratosthenes](https://github.com/Hoverbear/rust-rosetta/blob/master/src/sieve_eratosthenes.rs).
Thanks!
Soon [IOCCC](http://en.wikipedia.org/wiki/International_Obfuscated_C_Code_Contest) for Rust? :)
(Please put comments on the RFC, rather than here.)
Thanks, that's working ! Therefore, by adding 'static, does it have an implication relative to the object destruction ?
Indeed, it is better not to depend on "Box" in the argument.
A question, &gt; A yank does not delete any code. This feature is not intended for deleting accidentally uploaded secrets, for example. If that happens, you must reset those secrets immediately. What if the contents of the crate actually need to be deleted (for legal reasons etc), what's the process for removing it?
&gt; Agreed, but IMHO 1.0.0-beta -&gt; 1.0.0 (using the correct semver format here) is a special case where it is okay to have a small amount of breaking changes, without breaking the semver promise. Right. Then that implies there is some budget for how many breaking changes would be acceptable. How big should that budget be? Some might say it isn't worth spending that budget on issues as small as this one.
&gt; And after all these years it's kind of surprising to see system programming languages gaining so much favour again. The days of the "write it now and in 18 months it'll be twice as fast" approach are coming to an end (arguably already have) and the rise of mobile devices with poor battery life has put a much bigger premium on processor hammering languages. I think with the speed of the machines we have now in terms of compilation it's not surprising that we are starting to look at compiled languages with the syntactic niceness of interpreted languages. I live fully in the 'interpreted' world (Python, PHP and Javascript the last compiled language I used for work was Object Pascal) but I'm following Go and Rust closely.
&gt; "improved ergonomics" I'm always in for breaking changes when these words appear. 
Aw, I was hoping for a CLI tool.
I think that it's important that there's resistance to change at this point. It's not that beta is a promise that things won't break. I think that dealing with a few more months of breaking changes is worth saving years of dealing with a function that is out of place. The breaking changes should be slowing down though, the language should be "maturing" to a point were the changes being done at this point are removing "old warts", not adding new features or questioning the underlying philosophy of the language. I think this change does apply that way, but questioning and resistance should be there.
As the project has gotten a bit of premature attention here, I have reacted by updating the README with a list of planned milestones. Contributions are very welcome, but bare in mind that the project is not even feature complete yet, and since that is my current focus, parts of the code are less elegant as could be (to put it politely). Of course, that leaves plenty of low-hanging fruit to be picked :-) Regarding the CLA, it is a requirement for all Google OSS projects that contributors sign it. It is there for legal reasons, and there is nothing I can do about that. If you do consider contributing, do have a look at it early (this is the version for individuals): https://cla.developers.google.com/about/google-individual The code is released under the Apache2 license.
That module came to be as a result of isolating logic from another module that was growing too big. It is entirely possible that it is not written in the most straight-forward way. Could you give an example of an "extension trait"? Do you mean a new trait that is implemented for the BTreeMap type? Extending the existing type with a few helper functions could probably suffice.
You can't yet, you're going to have to box it and return Box&lt;Iterator&lt;Item=u8&gt;&gt;. [See this.](https://github.com/rust-lang/rfcs/pull/105)
Yeah, [there was an RFC](https://github.com/aturon/rfcs/blob/extension-trait-conventions/text/0000-extension-trait-conventions.md) that can probably do a better job of explaining it than I, but its purpose is just as you've said: for extending the functionality of an existing type.
Cheers. I'll have a look at the new readme. I am not sure how much I can contribute, but thanks for the encouragement ;-) Edit: I hate to plug my own project, but in case you want to compare approaches: https://github.com/marcusklaas/backbonzo. I have already some parallelism in place for the backup process. It's mostly a learning project though. The quality isn't near your project's.
Example: http://is.gd/rQcBZV
Rust can be a bit annoying when it comes to closures. You could define a function `xor` that does the *exact same thing* as your closure and it will work. For example: fn xor_iter&lt;T,U,A,B,C,D&gt;(a: T, b: U) -&gt; std::iter::Map&lt;std::iter::Zip&lt;T, U&gt;, fn((A,B))-&gt;C&gt; where T: Iterator&lt;Item=A&gt;, U: Iterator&lt;Item=B&gt;, A: std::ops::BitXor&lt;B,Output=C&gt;, { fn xor&lt;A,B,C&gt;((a,b): (A,B)) -&gt; C where A: std::ops::BitXor&lt;B,Output=C&gt; { a ^ b } a.zip(b).map(xor) } Will happily compile (on the playpen, ymmv).
That's interesting, could it be because one is a function, whereas the other is a closure? Is there any plans to add pure lambda's to rust?
&gt; pure lambda's What specifically do you mean by this?
Out of curiosity: does this use [clog](https://github.com/thoughtram/clog/) to generate the changelog? 
Just as a heads-up, for untrusted plugin-style code you need some means of catching panics in general (since panics include out of bounds errors, division by zero, and many other things that would be too painful to turn into `Result` in any case). There's a preliminary API for this already: http://static.rust-lang.org/doc/master/std/thread/fn.catch_panic.html
Oh ok. Thanks a lot. I feel this may not be the case, but if I wanted to chain functions which were (Iterator, Iterator) -&gt; Box&lt;Iterator&gt;, is there any applicative notation similar to that in the Option trait, so that I could write a bunch of those functions and use a function which takes an (Iterator, Iterator) -&gt; Box&lt;Iterator&gt; function and a Box&lt;Iterator&gt;, returning a Box&lt;Iterator&gt;?
Something that doesn't capture the environment variables, I guess. I'm not sure if it would have any real difference to a closure in rust though.
Can't tell me what to do!
I personally think the new order should be left as-is, and well.. the community seems to agree. The PR was closed, and the discuss thread seems to be leaning toward leaving it the way it is now. "I might have made a mistake and might be undoing it soon. We're not sure. Bear with us." is the best response given the original mistake involved too *little* discussion. If you are worried, make tests.
The issue is small, so it won't occupy much of the "budget" anyway. Also, we may wait and see. If not "many" other breaking changes happen in the beta cycle, then the budget surely can be used on this change.
That'd be an anonymous function, I guess. We don't currently, but maybe someday. Usually, you want an anonymous function to be a closure, I'd imagine...
[This works](http://is.gd/E564Et), but you might get a better solution if you explain what it is you are trying to do. I would also pull the `if let` line out to be a method if getting `String`s from `Foo`s is something you actually do want to do. EDIT: it occured to me after I posted this that you might not be looking for a solution to a problem, but just wondering why it didn't work. mbrubeck answers that.
What would it do? I am sincerely asking. I use linux so I can't think of anything except BASH's IO redirection (`&amp;&gt;/dev/null`).
What's done is done. Assume good faith. Take steps to correct this in the future, but otherwise, I think breaking it again is worse. /end opinion.
Oh, please don't heckle. Congratulate him on the broad success of Go and especially his fine work on its standard library! (I actually met him last year and did just that, along with the usual back and forth about why-did-you-do-this or why-not-that. Overall nice fellow!)
The following Rust translation would work. The trick is that, `type` is defining a type alias rather than a new type. Of course, `struct`-based new types wouldn't work, and that's a good thing to have (if one can intermix `struct Meters(f64);` and `struct Miles(f64);` I would be sad)---that situation is always expected in the nominal type system. type Vec3a = [f32; 3]; type Vec3b = [f32; 3]; fn add(a: Vec3a, b: Vec3a) -&gt; Vec3a { ... } fn mul(a: Vec3b, b: Vec3b) -&gt; Vec3b { ... } EDIT: Reading /u/burntsushi's (helpful) follow-ups, I admit mentioning type aliases was a bit confusing. Please regard this as just one possibility.
I don't think the type system will be any help here. You probably want (for some values of 'want') to write a pair of #[inline(always)] functions that convert between the types, and rely on LLVM to optimize it away (which in this particular case I imagine it will do very reliably indeed). And in Rust you probably wouldn't write a function that adds two slices. Implement `Add` and `Mul` for the types and use iterators (e.g. `a.zip(b).map(|(n,m)|n+m)`).
Unless I am mistaken (I may very well be), in your code `Vec3a` is a fixed-size array of three 32-bit floats, so the `add` and `mul` functions are taking just one single vector each? The original functions in OP (written in Go code) are taking a _dynamically sized_ array of vectors (hence, a copy would be expensive, depending on the size of the array).
So, you prefer reverting the change now and saying, "I made a mistake and am therefore undoing the breaking-change now, but might be reintroducing it later after discussion. Bear with us."? In a worst-case scenario that ends up as 3 silent breaking changes. That, to me, seems like the worst of all worlds. There is broad agreement that it was a mistake to make this change without discussion. There is *no* agreement that the change in itself is a mistake.
Good question! I actually don't know where the documentation exists for `Deref`, but I can tell you this much: `Deref` is a trait with special compiler support. It started out as a trait for pointers to deref to their contained type but are also used by Vec and String to deref to &amp;[T] and &amp;str, respectively -- so: let v = vec![1, 2, 3]; let slice: &amp;[i32] = &amp;*v; But the compiler will also cross-borrow &amp;T to &amp;U if T derefs to U, which is why `add(&amp;bill_vec, &amp;joe_vec)` works if both vec types `impl Deref` and deref to `[f32]`; Edit: it seems I lack reading comprehension today. Vec&lt;Vec3&gt; would only deref to [Vec3] which doesn't actually solve anything. :(
Both your functions (Add/Mul) take two arrays and return a third. There is no reusing here? Anyway, you could easily do something like the following (reuses the storage of array a). #[derive(Copy, Clone, Debug)] struct Joe(i32); fn to_joe(n: i32) -&gt; Joe { Joe(n) } fn from_joe(Joe(n): Joe) -&gt; i32 { n } let mut a = [Joe(5), Joe(13), Joe(0)]; let b = [Joe(-5), Joe(13), Joe(42)]; a.iter_mut().zip(b.iter()).map(|(a,b)|*a = to_joe(from_joe(*a)+from_joe(*b))).count(); println!("{:?}", a); Perhaps your problem would be easier to understand if you used rust syntax to express it.
you're right, I'm sorry. An example I did not express would be e.g. in-place addition: // Add adds the two dynamically-sized arrays of vectors together element-wise, storing the results inside of a. func Add(a, b []Vec3) { ... } Which would not return new memory, but instead _reuse_ the existing memory of `a`. I apologize for not using Rust syntax (I would have liked to, but I don't know it hardly well enough yet)
&gt; So the question then is can a Vec&lt;Vec3a&gt; be fed directly into a function that takes a Vec&lt;Vec3b&gt;? Yes. **If** `Vec3a` and `Vec3b` are type synonyms. Otherwise, I'm pretty sure you need an unsafe cast.
Interesting. Is my understanding that `Deref` essentially "boils down" a type to it's lowest form (i.e. the idea is that `Vec&lt;i32&gt;` can be _dereferenced_ to it's core `[i32]` type)? W.R.T. your edit, would the idea of using a type alias presented by @lifthrasiir work? EDIT: looks like type aliases will work.
Yep. The fact that "this change is small" can be used either for or against the change now that beta is released. I'd say the *content* of the change is uncontroversially desirable. This is a solid "for" in my book. I wish I had submitted this RFC before beta. Now let's wait for the core team's decision. :) 
Ok, so I think we have a winner here. Is there more documentation on [type aliases](http://rustbyexample.com/type/alias.html) anywhere? Specifically what I want to know about type aliases: - Can methods be defined on them? - Can operators (e.g. the addition operator) be defined? 
You can't write out the full concrete type of a closure literal, since it is anonymous, and a new type (and impl of the relevant Fn traits) is generated for each literal. `fn`s are actually the exact same way - the type of `x` in `fn x() { .. }` is *not* `fn()`, but in fact an anonymous, zero-size type, it can just be converted to `fn()`, which is a function pointer. Closures with no captures are zero-sized, and the same as if you used an `fn`. It's got nothing to do with closure sizing. All closures generated by literals are `Sized`. 
You can just use a closure and not reference any other variables. This will generate a zero-sized type, the same as if you used an `fn`. 
Gotcha, so a type alias is effectively naming a type locally just for the reader. Bummer.
Oh, wow. Okay, that makes a lot of sense actually.
That doesn't discuss the cross-borrowing, though, but yeah I guess it should probably go in the documentation for Deref?
(non-dev here) Curious, should the mio still be somehow wrapped on the consideration that there will be future unsupported platforms, or is that too much futureproofing?
To add on to lifthrasirr's reply, the `log` crate itself is now just a frontend, with support for any number of backends. What used to be the `log` crate is now `env_logger`, with `log` literally just providing macros for logging. If you want logging controlled via the `RUST_LOG` variable, env_logger is what you want. If you want a preconfigured log with the settings embedded into the program's code, the `fern` crate can provide that (disclaimer: I am the developer of the fern logging backend).
Those are some big updates. I hope this matures into something other projects can use to implement interesting distributed systems with. Can you give us an idea of what sorts of projects might be interested in using Raft? Databases probably, but anything else?
No, I'm not.
Use [`num` crate](https://crates.io/crates/num) and there is [`num::Integer`](http://doc.rust-lang.org/num/num/integer/trait.Integer.html).
It appears that [`num::PrimInt`](http://doc.rust-lang.org/num/num/traits/trait.PrimInt.html) has what I need.
There is map_in_place() for vectors, which can be used to reuse the allocation.
I've added afl to our testing at work (C++ SDK for custom hardware devices). The number of crashes that fell out of the first few days testing was unreal, but once we'd crossed that stability hurdle we started finding genuine logical errors in various features in the SDK3 and on the hardware. It's a very valuable testing tool and it's great to see it being integrated into rustc.
"concurrent programming language semantics"
And the mention of Niko and affine types.
Exactly my sentiment. I presume achriton or whoever really, made a snap decision and it's probably in good faith and for the best.
Small but great. Can't upvote this enough.
I maintain rusqlite (with frequent contributions from Marcus). Just to be clear, it isn't unsafe in the rust sense of unsafety. What Marcus is referring to I believe is that when fetching rows from a SQLite result set, ideally we would use lifetimes to statically guarantee the validity of each row. Unfortunately that doesn't play well with iterators, so instead we do the check at runtime, which means you can get a panic if you try to use stale rows. There's a specific example of this toward the bottom of the repo's README. In practice this restriction has not been a problem for me, and I think this is better than the alternatives I'm aware of (not being able to use iterators, or doing a fully copy of every row up front). If you start using rusqlite and have feedback, please feel free to make github issues!
&gt; Bitcoin throws a whole pile of obnoxious goldbug monetary theory and ponzi scheme incentives into the mix to spread itself, but at a protocol level that's all it's really trying to do. Does someone know what is being referred to with 'ponzi scheme' in the above text? &gt; You bought your computer from somewhere you trust. Even the decision to trust the person-with-the-most-SHA256-colliding-hardware (bitcoin's current, absurd rule) is a trust judgment. I don't, actually, I often just have little choice beside using it. I still think the state of computer security is poor (which is something I hope will be partially addressed with Rust). Speaking of Rust, I was surprised to see ample source files in C(++) in the Stellar repository. Maybe I'm overestimating Graydon's power in the decision of what language to use, but I was a bit surprised.
I'm curious, how often do you think it's a valid response for a programmer to write tests to check that each of their dependencies doesn't change? Do you have a script to generate them at this point?
I haven't, no. Could you expand on why you think this problem is major? It seems like this is sort of unique to SQLite. It has the restriction that when you're stepping through the rows of a result, you can only access the current row, and moving to the next one makes all previous rows inaccessible. You can enforce this using Rust lifetimes, and [rust-sqlite3](https://github.com/dckc/rust-sqlite3/) does exactly that. It's a trade-off - you get more help from the compiler, but you can't write a for loop over the rows of a query result. I prefer being able to write the for loop. Things that would cause rusqlite to panic would have undefined behavior if you were using SQLite in C.
Of course Mozilla is running the development and spending the money (which seems entirely irrelevant to me - do I get more of a say if I make a donation to Mozilla?). Being in charge doesn't require being biased against external community.
&gt; Does someone know what is being referred to with 'ponzi scheme' in the above text? Disclaimer: I have very similar political biases to Graydon. ~930 people own half of all the bitcoin in existance. Those who get in early make more money. The word _incentive_ is important in what Graydon says, from my perspective: Bitcoin is not a literal Ponzi scheme, but the incentives are very similar. For more on Bitcoin and right-wing politics, see http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2589890 &gt; I don't, actually, I often just have little choice beside using it It doesn't matter if you have the choice to trust them or not: you're still trusting them. &gt; I was a bit surprised. Rust is a pre-1.0 programming language. We don't recommend _anyone_ use it for production until the actual 1.0 release. If I'd worked for Stellar, I'd have suggested the same.
Usually, we'd consider a change to a stable ABI to be significant. In this case, a judgement call was made that a re-ordering of parameters was important enough to make where there wasn't enough time for a full RFC. And as you can see from the resulting discussion, there's reasonable argument for both sides: there's not a lot of 'design' work to be done here. You pretty much have to pick. That said, /u/aturon has said that he regrets not putting it through the RFC process. I personally considered this change to be unfortunate, but neccesary, which is a decision that a leader sometimes needs to make. If this issue was brought up after beta had been cut, I would feel very differently about it.
Welcome to Rust! Check out the following code: use std::io::{self, BufRead}; fn main() { let stdin = io::stdin(); for line in stdin.lock().lines() { println!("{}", line.unwrap()); } } This shows how to read console input in a loop. The `stdin()` function returns a `StdinLock` ([documentation](http://static.rust-lang.org/doc/master/std/io/struct.Stdin.html)) EDIT: updated example
Okay, though I'm not sure why you replied about it then.
Clarifying a position isn't the same as arguing about its correctness.
Fair enough.
About async IO: What is the idea for the concurrency model? * A single reactor thread that dispatches to multiple worker threads * Multiple reactor threads + something that load-balances requests to them * Something else?
`print!` doesn't flush the buffer, and I bet this sample was adapted from an older one, where it did. If you put `println!` instead of `print!`, you'll see every line you type echoed.
Good catch! I'll have to update the example
If you just want to call a function and save the line in a buffer, you can do the following: use std::io; fn main() { let mut stdin = io::stdin(); let mut buffer = String::new(); stdin.read_line(&amp;mut buffer).unwrap(); println!("You wrote: {}", buffer); }
Ah yeah, that post clarifies a lot. Niko's backlog continues to be excellent!
Awesome. :)
What would prevent implementing `map`, etc for streaming interators? I think there would be just `StreamingIterator` trait with all the functions.
Just a quick question if you don't mind, is there anything wrong with writing a function like this? fn get_input() -&gt; String { let mut stdin = io::stdin(); let mut buffer = String::new(); stdin.read_line(&amp;mut buffer).unwrap(); buffer }
From what I understand, streaming iterators can't implement Iterator, because they are a different abstraction. And they are still being researched to see how convenient they can be made.
I think it makes sense. I wonder why there isn't such a function in the standard library.
&gt; I personally considered this change to be unfortunate, but neccesary, which is a decision that a leader sometimes needs to make. That's strange because I thought the whole point of working on a open source project was to gather opinions from a larger number of people that may in fact be better than yours. It's backwards to me to pass through an executive decision that breaks so many things without consulting the community you have worked hard to build.. What I hear from this is "I don't want to work *with* people, I want people to work *for* me for free".
It's more than that. Without HKP, we can't develop a good streaming iterator abstraction. See: http://www.reddit.com/r/rust/comments/303a09/looking_for_more_information_on_streaming/cpoysog
This unsettles me more, not less. If it were viewed as a trivial change (as your first post implied), then I can see how one could think it's reasonable to make without an RFC. But now I'm hearing that this change was *so* important that it didn't need to go through the processes that exist specifically for getting scrutiny and visibility on important changes. That doesn't make any sense. &gt; ...is a decision that a leader sometimes needs to make. Ah, so this is my mistake: I've been thinking of the Rust community as a collaborative, egalitarian one, where every opinion can have an equal voice, and where "I know best so I'll just change this without asking" is laughable. It's incredibly disappointing to hear that Mozilla doesn't share this view. Part of my love for Rust came from how inclusive the community was, a sentiment which arose for me in large part because I didn't feel like Mozilla thought it was better than everybody else, particularly external parties who were/are extremely passionate and personally invested in the future of Rust. For a while, I didn't feel like Mozilla being involved with Rust made it develop differently. That feeling has changed, and clearly, for more people than just myself. I wasn't done with Rust when this thread started, but I think I am now. Sour taste is absolutely right.
Please see my reponse to your sibling.
Thanks!
You're entitled to your opinions, but a comment like this deserves an opposing viewpoint. I've been writing Rust code for over a year now, and the Rust community+core team has been fantastic every step of the way. Collaborative and egalitarian are words that aren't strong enough to convey how awesome they've been. One questionable commit isn't going to change that opinion for me.
&gt; I'd like to hear what he thinks of Rust; and what he finds disappointing with the language. Criticism from a source like that is very useful criticism. That! Enlightened criticism can only help Rust improve.
The lazy in me says: just use mio right now, wrap later if required.
Sorry, let me clarify my statement. The incentives of a Ponzi scheme are not at all similar.
Is this related to the something borrowed in the true clause of an `if let` also being borrowed in the false clause as well? If that was changed I'd be thrilled!
My reading of what Graydon says here is that while "trustless" is in fact a term used in this space, that doesn't mean that outside of the algorithms, trust is not inolved. For example, I'd like to buy something from you with Bitcoin. While the _software_ operates on a no-trust model, I do have to trust you enough that you'll actually send me the goods. And yes, we could do a multi-sig transaction with some sort of arbitration service, but then we both have to trust that the service makes good decisions. "Money" is a social institution that is deeply based in trust. Bitcoin enthusiasts like to pretend that a technical solution to social problems erases the social aspect, but if anything, it magnifies it. See the paper I linked. Anyway, this is offtopic in an offtopic thread, and I have docs to write, so I'll leave it at that.
There's a `Chunks` iterator (and a `ChunksMut`) which may help. http://doc.rust-lang.org/std/slice/struct.Chunks.html [Play Pen Link](http://is.gd/myhgtV)
Oh that might be just the thing, thank you! Of course I should have thought to look in `slice`, not just string and str.. I'm afraid I do find the Rust documentation, where not annotated by a human, to be a bit opaque.
How hard would it be for the compiler to detect that a closure doesn't access its environment, accept that code and emit the closure just as you'd have written it as a normal function? I tried to return an iterator from a function myself a week or two ago and figuring out how to do it by yourself is not fun; it's probably one of the most unergonomic things in Rust. (Also, the crazy return type and having to do `as fn( ... ) -&gt; ... ` in certain cases to make it compile because reasons.)
I'll try to re-frame as a Vec, but I can't find documentation on the vector chunks method, and I'm afraid the example you link to appears to be just hello world?
I could enum A, C, G, and T, but for now I just want to learn how to handle strings, sequences, iterators, etcetera. Defining and implementing traits (which I think I'd need for a proper object-oriented approach) is a skill I'll develop later.
[It's here](http://doc.rust-lang.org/core/slice/trait.SliceExt.html#tymethod.chunks). It's hard to find because of some of the indirects, see the discussion of rustdoc below. What do you mean by 'just hello world'? Do mean simple use of the method, or is it actually a hello world program for you?
What is Homu maskot? Homumura? EDIT: There is a link, doh!
I have less experience in Rust, but I think implicitly muting errors is anti-idiomatic Rust code :) Usage of unwrap is discouraged in official docs.
What exactly do you mean? The [Rust standard library](http://doc.rust-lang.org/nightly/std/) fulfills the same role as the STL does in C++. A stack is a mutable `Vec` — it has `push` and `pop` right there. A set is a [HashSet](http://doc.rust-lang.org/nightly/std/collections/struct.HashSet.html), which has the operations that you expect.
Wow, even a double-ended queue is there. I guess, I am just really bad at using Google then :( Thanks a lot!
Some of the STL falls under option 3 - why would I need a pair type when I could just write `(x, y)` to create a tuple - the very thing a pair type was created to emulate. Secondly, a good deal of the STL is built into the rust standard library: `Vec`, `HashMap`, etc Thirdly, there are some data types that are particularly difficult to implement safely - a doubly linked list for instance is notoriously hard to get working with the borrow checker since you can't have multiple mutable references to the same data. (Luckily it's in the standard library) Fourthly, some data types are essentially the same thing. A stack, queue are all essentially lists with constraints on their operations. A stack is a list where you can only push/pop to the start. A queue is a list where you can only push to the start and pop from the end. The only difference is which operations you are allowed to perform on them You can find more collections [here](https://doc.rust-lang.org/collections/)
Fourth option: the Rust team releases something as a crate as a result of working on Servo or other projects because it's not necessary enough to be in the standard library.
I agree on the point of combining your map calls - try and composing your function calls.
I think the rustic way to return an iterator is to return a struct that implements Iterator, like this fn xor_iter&lt;T, U, A, B, C&gt;(a: T, b: U) -&gt; XorIterator&lt;T, U&gt; where T: Iterator&lt;Item=A&gt;, U: Iterator&lt;Item=B&gt;, A: BitXor&lt;B,Output=C&gt; { XorIterator{ t: a, u: b } } struct XorIterator&lt;T, U&gt; { t: T, u: U } impl&lt;T, U, A, B, C&gt; Iterator for XorIterator&lt;T, U&gt; where T: Iterator&lt;Item=A&gt;, U: Iterator&lt;Item=B&gt;, A: BitXor&lt;B,Output=C&gt; { type Item = C; fn next(&amp;mut self) -&gt; Option&lt;C&gt; { match (self.t.next(), self.u.next()) { (Some(a), Some(b)) =&gt; Some(a ^ b), _ =&gt; None, } } } It is more verbose, but it lets you change much more freely the implementation of xor_iter without changing its return type. 
It's a pity that you don't want to discuss these things. You have interesting ideas and present them well.
I'm not an experienced rust user so I don't know what's "idiomatic" but I rather like the separate `map` calls. Each one is clearly doing a thing and it's easy to read. When I asked before, I think rust does something like Haskell's stream fusion, right? That is, it doesn't map all the way through the collection each time, but will essentially automatically compose the calls as you suggest. Is that the case?
&gt; not represent an arbitrary lifetime but rather the lifetime of the returned Foo struct? `struct Foo&lt;'a&gt;`, means "a lifetime that lasts _as least as long_ as the struct. There's no way to express that it will be _exactly_ as long, specifically. In general, a `struct` with a pointer to itself causes problems.
This is indeed the case. Agreed on the map thing as well. A long sequence of simple operations has a low cognitive complexity and is just as efficient.
Is it a waste of cycles to `map` once for the `entry -&gt; path` conversion, and then again for the `path -&gt; FileData`? Would it make a big difference to create a function that does those two things (possibly more) in one pass?
Rust can transform/collapse the map calls into a more for loop like call. Kind of like stream fusion with Haskell. I'm not sure how well it does it for now, but at the very least it'll get better. That's part of the zero cost abstractions Rust strives for I believe.
Yep. You could always provide this as an alternative iterator though, for those that don't need `Iterator` methods and want to enforce compile-time checking; ~~and it's not like you couldn't reimplement (or copy from rust's stdlib?) `map` and friends~~. Edit: Apologies for the misinformation; burntsushi is right, you can't do this for streaming iterators. (I just tried.)
The iterator methods are lazy, so doing `some_iterator.map(|a|f_0(a)).map(|b|f_1(b))` will not traverse the iterator twice, and performs about as much work as `some_iterator.map(|a|f_1(f_0(a)))` when you compile with optimizations. LLVM is really good/aggressive at inlining short functions.
The only replacement is http://doc.rust-lang.org/nightly/std/thread/fn.sleep_ms.html IIRC, the other stuff requires papering over system-specific deficiencies, and we wanted to start off with lower-level abstractions to begin with.
That's just another thing that makes me excited for Rust. I hadn't even considered LLVM when I asked the question. If the `map` calls are lazy and LLVM optimizes them automatically then I can definitely get behind this type of code/pattern. I had a little taste of functional programming when I looked at Haskell and I saw a lot of nice things. Rust has a good "mix" of things I've seen in several other languages, only more "Rusty" (which is good, because you don't want to be just another clone).
Ok, thanks. It should be straightforward to spawn a thread that will repeatedly sleep and then send a "timer expired" message to a channel. The downside will be the overhead of the dedicated thread, but I can live with that for my scenario. 
Incidentally, this thread is a perfect example of repellent bitcoin community discourse. I have removed the post in question, out of respect for the developers and, equally, a total disinterest in any further contact with the surrounding bitcoin community. Mods might as well kill or bury this thread.
Forgot to say PST. So in 5 minutes from the time of this post.
[Hyper](https://github.com/hyperium/hyper) is probably what you're looking for.
&gt; Premining is not derogatory, in fact I consider it the best method of instantiating a currency. My apologies. I generally see "premined" used as a condemnation of a currency, so that's what I thought you were doing here. &gt; My point is that it is ridiculous to even claim Ponzi schemes are similar; any asset will grow in value and benefit the original participants. Most assets have some sort of intrinsic value. The problem with BTC is the only value it has is that people desire it, and they desire it because they think it has value. Which means that the only way to increase the value of BTC is to get more people to buy into it. There is no demand for the asset beyond that of people who believe it's a good investment (there are, of course, people who are actually trying to use BTC as a genuine currency, but those people are a rounding error when looking at the "value" of BTC). Which means the only way to increase its value is to convince more people that it's a good investment and that they should buy it (or convince existing owners to buy more of it). This is why it's being compared to a ponzi scheme, because that's the exact same incentive that ponzi schemes have. People buy into a ponzi scheme, and then try and convince other people to do so in order to increase their own wealth. And inevitably, the later someone buys into the ponzi scheme, the more likely they are to lose all their money instead of gaining money. BTC has the same problem; as its value inflates, people who buy in at the high values are more and more likely to end up losing their investment when the BTC value crashes (as it has done numerous times, and will continue to do for the foreseeable future). &gt; We might as well say all stocks have "ponzi scheme incentives" as well -- but that would be just as absurd. It would be absurd, because stocks don't work the same way. I'm probably one of the least-educated people about the stock market and even I know that stocks have value for reasons other than the fact that people think stocks have value (for example, dividends provide value, as do stockholder voting rights). Furthermore, stock value reflects the performance of the company (at least in theory—in some cases, such as Apple, the stock market is extremely irrational, but outside of the tech sector it's a bit saner). Owning stock is basically owning a tiny portion of the company, and the company itself definitely has value. You could argue that if nobody buys the stock then it has no value, but that's not a very strong argument, and could just as easily be said about something like Gold (which definitely has a lot of intrinsic value). &gt; Ponzi schemes require an inflow of capital to sustain their value -- none of these assets or even Bitcoin have that requirement. Bitcoin *absolutely* has that requirement. If everybody stopped buying bitcoin, the value would plummet to zero. You might say that the people trying to use it as a currency in its own right would still value it, but that's such a small fraction of the base of bitcoin users that they cannot sustain the economy on their own. More generally, with the value plummeting, everybody would want to sell off their BTC, but without buyers, they literally cannot sell it, which makes it worthless. To put it another way, Bitcoin only has value because people are willing to use fiat currency to buy bitcoin, and the amount of currency they're willing to spend on it is what defines its value. If people stopped using fiat money to buy bitcoin (i.e. that inflow of capital stopped), there would be nothing to give it value anymore. Without that extrinsic value, and since it has no intrinsic value*, it would become worthless. (*some people argue that the blockchain provides intrinsic value, but if you accept that argument it's orders of magnitude less than the current valuation of bitcoin) &gt; Stellar is in a situation, like Ripple, whereby distributing its currency freely it can increase its value. But at the start, it possesses all of them, and can choose deliberately to distribute it in a way that benefits itself at the expense of others if it so chooses. No it can't. The distribution mechanism for new STR was publicly documented from the moment Stellar was announced. The Stellar Foundation has no control over that process, it's determined entirely by the collective voting of all the Stellar users. If the Stellar Foundation were to try and affect the distribution in any way, that would be immediately obvious (as it would be part of the Stellar public record) and would cause everybody to lose trust in the currency, thus driving its value to zero.
There is a good reason (safe) Rust will not allow your struct Tasks as it stands - what if you happen to write `mytasks.arena = TypedArena::new()` at some point when you have references in `all_tasks`? All those references will now be dangling pointers. There is no way you can express the fact that all arena references are going to live as long as the containing Tasks struct, so I'm afraid you have to move to either `Rc&lt;Task&gt;` (and potentially `Weak&lt;Task&gt;` if you need some help with destruction, but it's unstable), or use indexing (as steveklabnik1 suggests).
In theory, it is possible to do trustless transaction in Bitcoin if you can automate verification part. One good example is decrypting hashed messages. There are many hard-to-compute but easy-to-verify problems. Although as I understand current Bitcoin blockchain is not powerful enough to usefully encode most of these problems except hash breaking. Bitcoin blockchain does include [trustless bounty for full SHA256 hash collision](http://sourceforge.net/p/bitcoin/mailman/message/31397880/). Bitcoin was paid to hashed script which receives two arguments x, y and check "x != y &amp;&amp; SHA256(x) == SHA256(y)". You can claim the bounty simply by spending from this script. More interestingly, you can participate in the bounty program simply by paying to this script. I find this aspect of Bitcoin very fascinating, but I agree that for now practical implication of this capability is very limited in the real world.
I'm pretty sure that the timer module just used a dedicated thread under the hood anyway.
As a protip aside, the first one can be rewritten as `some_iterator.map(f_0).map(f_1)`
I agree, restating lazy as practical :) 
I haven't tried it on beta, sorry, since I'm short of time recently (newborn), but maybe it will be of help: https://github.com/dpc/titanos since it used to work fine not that long ago (21 days ago travis says: https://travis-ci.org/dpc/titanos/builds).
AFAIK, you are unable to write `#![no_std]` code in beta. Use the nightlies, it will be a lot easier. Also, `extern crate core` is very useful for all the language stuff that you need (like intrinsics, iterators, markers, ops, etc.)
Thanks, I appreciate that! :) Will come in handy for sure. Unfortunately it doesn't seem to build on my system. It fails when compiling libcore - courtesy of the 1.0-beta changes, I'm sure.. 
In addition to what sanxiyn said, Josh also made the good point about how Google was able to get so many advantages having their analytic stack written in the same language as their production stack. Not only did it cut down on the amount of data transformation, but they were able to share functionality between the two. Analytics were able to scale better, and it became much faster to productionize analytic research. 
I switched to nightly, but I'm still getting the same errors as in the OP.. :/ I guess just don't know what it wants me to do with the sized lang_item.. I had a more elaborate setup to begin with (including `extern crate core`), but stripped it down to the code in the OP in an attempt to get *something* to compile..
Too bad I have not read your comment in time ! The other ones were somewhat discouraging, so I decided not to ask anything. However, I will post the recording of the talk here just for completeness, it was quite some fun.
Ah. I'm using Rust Beta and unstable features are forbidden. I've already had to write my own power function because both integer pow() methods are unstable, and copy partial_cmp source directly into my file. Looks like I'll be copying chunks, too... Thanks for the help!
Rust certainly fits into the same niche as C/C++/Fortran in the world of data science: writing low-level primitives for the languages like Python and R to call, and optimised versions of processing pipelines for running on large data sets (e.g. rovar said that his [blars](https://github.com/rrichardson/blars) was measured as 100x faster than the original [blarpy](https://code.google.com/p/blarpy/)). I agree with you that's it's unlikely Rust will become the language used for data exploration/algorithm development/day-to-day data-science in the forseeable future, but I can definitely see it as one of the first things people go to when they need more speed (that said, Cython is awesome in this space, and Julia sounds good too).
The correct way to deal with this is to construct the struct in two stages. In the first stage, you create the `Bar`, and in the second, you borrow it as `&amp;Bar`. Sample code: struct FooRoot { b: Bar } impl FooRoot { fn new() -&gt; FooRoot { FooRoot { b: Bar::new() } } } struct Foo&lt;'a&gt; { root: &amp;'a FooRoot, // Optional in this case, but useful in less contrived examples. r: &amp;'a Bar, } impl&lt;'a&gt; Foo&lt;'a&gt; { fn new(root: &amp;'a FooRoot) -&gt; Foo&lt;'a&gt; { Foo { root: root, r: &amp;root.b } } } If you want to mutate the `Bar`, you will need to wrap it in a `Cell` or `RefCell` or use something else that gives you shared mutable state safely. This is required for memory safety--even if Rust had a way of initializing structs like this in one function, it wouldn't be safe to mutate all possible types `Bar`. A `TypedArena` in the root can be safely appended to indefinitely while immutably borrowed, which makes it a great fit for this pattern. Also worth noting: people sometimes bring up `Rc` as a way out of this. `Rc` is a bit ergonomically nicer, but is a much more costly version of the same thing--it incurs an allocation, takes up more space, requires reference counting, introduces the potential for accidental cycles resulting in memory leaks, and is still not actually stored inline with the struct (it's stored in the heap). You can nearly always replace it with a simple `&amp;` reference; all you need to do is make sure that the root outlives the last use of the struct. This is generally not very hard, but may require exposing the root - main struct layout to the end user (if you are building a library).
I would probably give FileData a nice constructor method. That will improve your code snippet's messiness by a lot. Maybe you could even replace the FileData mapper with just `.map(FileData::new)` (I just love it when I don't have to write out the closure manually).
@sanxiyn could you elaborate on why Rust is faster than Julia? I believe both use LLVM to compile to similar machine code. Does it have to do with garbage collection? Thanks to elaborate.
If you need an example: [click here](https://github.com/mvdnes/rboy/blob/df3aa4a0fa71987db11c5083fe8ec6a803f53228/src/bin/rboy.rs#L210-L221). I also needed one and found it indeed very easy to implement.
Not yet, but https://github.com/rust-lang/cargo/issues/595
I think I'll add a [Reuterswärd gun](http://sv.wikipedia.org/wiki/Carl_Fredrik_Reutersw%C3%A4rd#/media/File:Carl_Fredrik_Reutersw%C3%A4rd_Non_Violence_-_Malm%C3%B6_1992.jpg) for the following reasons: * It's perfectly safe. * That's how I prefer guns anyway. 
A gun that won't fire unless it knows that it is pointing away from your foot. Or something that *looks* like your foot. But that might be hard to express in a picture.
For the pow: [this](http://is.gd/W0hJHv) compiles and works fine under the beta. If you meant floating point numbers on an integer power, then check out the [num](https://github.com/rust-lang/num) crate, which is meant to replace the deprecated functions in `std::num`. You can see the available stable methods (in `std`) in the documentation for the primitive types' respective crates, for example [f32](http://doc.rust-lang.org/1.0.0-beta/std/primitive.f32.html), [i32](http://doc.rust-lang.org/1.0.0-beta/std/primitive.i32.html). /u/steveklabnik1 Would it be possible to make these functions easier to find? Typing `pow` into the search bar still comes up with the deprecated `std::num` variants, the `std::f32` module docs are not even on the results page.
Oh sorry about that, I forgot to check the issue tracker, and sure enough [there it is](https://github.com/rust-lang/rust/issues/23511).
I see that your library is under LGPL. Considering that Rust usually errs towards static linking, it might mean that providing all object files pre-linked or the full source for the whole application might be necessary. Is this intentional? I've got nothing against the license, I'm just not sure about the practicability. http://copyleft.org/guide/comprehensive-gpl-guidech11.html#x14-10400010.8 http://stackoverflow.com/questions/10130143/gpl-lgpl-and-static-linking Github solves this in libgit2 by using a Linking Exception: https://github.com/libgit2/libgit2/blob/development/COPYING 
:D
It's all good! There's a lot of bugs on the tracker.
Read about [GPL linking exception](http://en.wikipedia.org/wiki/GPL_linking_exception) at Wikipedia. I concur LGPL with static linking is a headache. There are many variants of GPL linking exception, but I recommend GNU Classpath exception. It is approved by FSF, and it is used by Oracle for OpenJDK. No doubt many lawyers were consulted for this.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**GPL linking exception**](https://en.wikipedia.org/wiki/GPL%20linking%20exception): [](#sfw) --- &gt;A __GPL linking exception__ modifies the [GNU General Public License](https://en.wikipedia.org/wiki/GNU_General_Public_License) (GPL) in a way that enables software projects which provide [library](https://en.wikipedia.org/wiki/Library_(computing\)) code to be "[linked to](https://en.wikipedia.org/wiki/Linker_(computing\))" the programs that use them, without applying the full terms of the GPL to the using program. Linking is the technical process of connecting code in a library to the using code, to produce a single executable file. It is performed either at [compile time](https://en.wikipedia.org/wiki/Compile_time) or [run-time](https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase\)) in order to produce functional machine-readable code. There is a public perception, unsupported by any legal precedent or citation, that without applying the *linking exception*, code linked with GPL code may only be done using a GPL-compatible license. The license of the [GNU Classpath](https://en.wikipedia.org/wiki/GPL_linking_exception#The_classpath_exception) project explicitly includes a statement to that effect. &gt; --- ^Interesting: [^ERIKA ^Enterprise](https://en.wikipedia.org/wiki/ERIKA_Enterprise) ^| [^GNU ^Classpath](https://en.wikipedia.org/wiki/GNU_Classpath) ^| [^GNAT](https://en.wikipedia.org/wiki/GNAT) ^| [^GNU ^Guile](https://en.wikipedia.org/wiki/GNU_Guile) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cq7pcx6) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cq7pcx6)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
By the way, MPL 2.0 can also be taken into consideration, @mitchellh, the author of Vagrant, uses it a lot for his new projects. It doesn't use terms like "linking" as much as the GPL, but has other particularities. Relinking can by the way also be a problem on platforms where the application is signed, e.g. iOS. Glad to clear that up before someone runs into actual issues with that.
Thanks for the pointers, but the pow(u32) method on i64 appears to be unstable (stable method on unstable impl?), and compiler suggests `use core::num::Int;` but that triggers another warning that core requires a compiler directive `#![feature(core)]`, and adding that triggers a warning `error: use of unstable library feature 'core': pending integer conventions`... Maybe using `extern crate num;` will help, but did I really need an external crate for something as basic as getting the power of an integer? This operation is so commonplace other languages have operators for it (like Python's `**`). Teething issues, I know; it's not going to drive me away from learning Rust, but it certainly makes it awkward to learn a language when the Beta channel is actually harder to use than the nightlies because compiler directives to enable stuff are forbidden.
For stuff I'd later want to do with the values, I imagine that I would, so I don't want to go down that route when string manipulation works for now. Thanks, though!
It is not unstable: [link](http://doc.rust-lang.org/1.0.0-beta/std/primitive.i64.html#method.pow). Forget the pow that the search function finds (the ones in`std::num`), check the methods in the module description of the primitive types.
Interesting, can you share the code directly?
I try very hard to make the official tutorials accessible to those who don't have systems experience. In fact, systems people often complain that I explain too much ;) It's not _fantastic_ for that yet, but http://doc.rust-lang.org/1.0.0-beta/book/ should have you covered. I linked to you the beta version because I'm in the middle of doing some heavy refactoring of the order and such on the nightly branch, so it's a bit disorganized there.
It's important to note that matching ranges like this are inclusive on both sides. If you really want `b &gt; 20 &amp;&amp; b &lt; 26` like in the op's example code, you actually want `(true, 21...25)`
The method chaining looks a lot like what I write in JavaScript (I copied the Result type over into a library) and that chain is how I would end up solving it there too. For the readability of the code, it's very readable. There are two minor changes I'd make, 1) Rename the variable 'iter' on lines 3 &amp; 4 to be more specific. What are they an iterator of? I cannot tell without going to the documentation. 2) As /u/neutralinostar said, move the FileData creating function to a named function. It doesn't necessarily have to be called FileData::new - it could even be a non-exported function in the module, but it needs to be its own function. You have a lot of chaining going on in and its hard to read. In its own function, having the chaining go top to bottom would make it more readable. There's a larger refactoring possible because you're creating the FileData struct with a possibly invalid filename and then throwing it out instead of checking the filename for validity and throwing out before creating the FileData, but I cannot seem to think of a good way to make that more explicitly visible. Every refactoring I try to it (mentally) just trades off readability of other parts. Perhaps putting the filter into the secondary function as suggested in the second minor refactoring would help there? E.g., instead of `.map(to_filedata)`, make it `.filter_map(to_filedata)` with... fn to_filedata(path: Path) -&gt; Option&lt;FileData&gt; { let name = path.as_path().file_name(); let content = File::open(path.as_path()).and_then(|mut f| f.read_into_string()); // You might prefer a `match` here. if (name.and(content).is_some()) { Some(FileData { name: name.unwrap(), content: content.unwrap() }) } else { None } }
`vec` already is a `&amp;Vec&lt;i32&gt;`
I think that'll have to be it, until the iterating chunks method returns to stability.. Now to read up on implementing iteration in Rust to avoid making a whole in-memory copy of the string.
Ah yes, that's so unusual my eyes missed it :(
`a == true` is the same as `a`. `== true` is redundant.
Small typo: "When parent exists", should be "exits".
How would one apply these concepts across processes instead of threads? I couldn't find any details about how Channels actually work. Any insight would be appreciated. Thanks! 
Thanks! Do you want to send a PR so you can get credit, or should I just fix it? https://github.com/rust-lang/blog.rust-lang.org/blob/gh-pages/_posts/2015-04-10-Fearless-Concurrency.md
~~I realize that mentioning this would kind of muddle the clarity of the post, and it explicitly mentions that the structures are simplified, but `Mutex&lt;T&gt;` requires a `Sync` bound on `T`, not a `Send` bound. A `Send` bound would not be sufficient to guarantee memory safety.~~ (Although, in retrospect, I wonder if `where` clauses are now powerful enough that `Sync` could simply be modeled as `&amp;T: Send`, with `impl !Sync for T` being replaced by `impl !Send for &amp;T`. Obviously, it is too late to change now). **Edit**: Brain fart :)
I couldn't compile this if I had it as `self.handler.call(server)`; hence why I passed it as a singleton tuple
`(self.handler)(server)`
Thanks! It works on beta now so a nice start to the weekend.
Do Rust channels need to actually copy the data sent between threads? (since they share the same address space, the other thread could use the data if it's in the heap - but would need a copy if it's in the stack)
The link I posted doesn't do an in memory copy. Slices don't create a copy, they are like a "view" of an already existing item. In the example, `.to_string()` allocates the string (although there are more efficient ways to do that), and from there the `DnaChunks` iterator just point to sections of that already allocated string. Edit: wording
Hm, I'm confused by this comment -- the [docs](http://static.rust-lang.org/doc/master/std/sync/struct.Mutex.html) certainly make it *seem* that `Mutex` is `Send`-oriented, and that matches my intuition since it's handing out `&amp;mut` references, not `&amp;` references. `Arc&lt;T&gt;` is a different story -- might that be what you were thinking of?
Regarding doing away with `Sync` -- the where clauses are sufficient to never have to bound over it (though it's convenient shorthand), but the deeper issue is that you can give a single blanket implementation of `&amp;'a T: Send` when `T: Sync`. That centers everything around the `Self` type, which plays better with trait coherence rules .
There are three basic methods to convert something into an iterator: * `iter()` : yields `&amp;T`s * `iter_mut()` : yields `&amp;mut T`s * `into_iter()`: yields `T`s.
Would this not be served just as well by assuming `&amp;'a T: Send` for all types, and then strategically opting out where we currently opt out of `Sync`? I haven't thought about it carefully so this might fall down somewhere, but I believe at present `&amp;T: Send` &lt;=&gt; `T: Sync`, so it seems like it should work. From an ergonomic perspective, I agree that it would not be as nice as `Sync`, but I actually think the `Sync` bound is pretty rare in current Rust code.
forking and submitting a pr seems a bit heavyweight for dropping an "s" from a single word, so ... 
This is great. I wanted to write a few lints, and now I can even have tests for them.
Is it possible to use the latest and greatest `rustdoc` but stable `rustc` with something like multirust? ...without being a huge pain ;)
No, really. Fantastic blog post! It's just plain good craftsmanship. Each example carefully introduced one new idea without introducing extra syntactic noise. It makes it much easier for the reader to focus on the key ideas you're trying to convey without worrying about Rust idioms. For example, you use `&amp;Vec&lt;i32&gt;` instead of switching to `&amp;[i32]`. And you used free functions instead of methods on `Channel`. Makes me want to read more of your writing!
[I got it to compile](http://is.gd/XhaFPS), but I still need to look at it to tell you if it is the best way. It depends on if you really want that to be a slice of `String`s.
Your lifetime markers are off. The 'a needs to be put on the input parameter that the output return value is derived from. This is the essence of lifetime parameters -- declare the input to output relation. This is a working version: fn get_descendants&lt;'a&gt;(target: &amp;'a str, words: &amp;'a [String]) -&gt; Result&lt;Box&lt;Iterator&lt;Item=&amp;'a str&gt; + 'a&gt;, &amp;'static str&gt; { match words.binary_search(&amp;target.to_string()) { Ok(idx) =&gt; Ok(Box::new(words[idx..].iter().map(|s| &amp;s[..]).take_while(move |w| w.starts_with(target)))), Err(_) =&gt; return Err("No matches found."), } } - Need to convert &amp;String to &amp;str using a .map() - Need to mark input parameters with the lifetime parameter - Need to mark `Box&lt;Iterator + 'a&gt;` with a lifetime that signifies the life of references inside the boxed values - Need to use `move` on the closure to move the `target` reference as it is, into the closure, instead of referencing it from the function's stack. whew!
Yeah, that's what I do in my working version. I just don't like it when my answer to a problem is just, "Oh, I guess I can't do that."
Since the alternative has fewer allocations and returning a slice is more useful than returning an iterator I don't really see the problem :). Anyway as /u/neutralinostar shows it is possible to do it with an iterator.
In `if` statements it's considered good form to omit the `== true` because the type of the value must be a boolean. However, in a match arm, the reader does not necessarily know the types being matched upon and so I don't think the `== true` is particularly egregious.
I see in the documentation that the Pool is LIFO, is that desireable? OpenSSL had cases where they freed memory and then allocated it again and relied on the behaviour of their custom allocator to return the same memory. To me that seems terrible; better to return a random value from the pool than to enable people to rely on the LIFO property.
If you newtype it like that then I would expect you to be able to derive the traits as usual.
It seems that to have all the benefits of fearless concurrency you do NOT need: - Channels - Send trait The only fundamental piece you need is rustc / borrow checker. Resting on top of the borrow checker, you can do fearless concurrency across process boundaries using your own channel implementation; just remember to ensure that the data you sent over the channel goes out of scope after you send. Maybe wrap send in a move closure to make it easy - but there are other easy ways with the borrow checker. Would anyone say I'm wrong? 
!!! I feel like I need to give you a gold star or something. What about a coupon for free waffle fries? Anyway, for this use case, I kind of agree that the slice is much cleaner, but being able to do something like this is actually pretty sweet for cases where you want to return something that's not all in a row--something that, therefore, can't be represented by a slice. At least that's what I was thinking. I guess the biggest thing I need to learn is that trick with the lifetime inside the `Box&lt;Thing + 'a&gt;` itself, which was pretty neat. Random question, though... Is it possible to make something like this generic, such that the return type is determined by the caller, so that I can skip all this nonsense? I think I'm gonna play with that and see how it goes.
Some types are fundamentally not thread safe, e.g., `Rc`. How does the compiler ensure you can't send that to others threads without something like `Send`?
Moving the stable one aside and then symlinking the nightly one into the stable directory might work. I've done the same for cargo in the past.
What happens to a scoped thread when the thread that started it panics? If the parent thread unwinds, any references to data on the parent's stack are no longer valid. Or does the destruction of the JoinGuard during a panic also panic the scoped thread?
This is *almost* true. Unfortunately, `Rc`, thread locals, and (later) `Gc` mean that not quite every type is `Send`. However, it is now possible to define types like Send [directly in Rust](https://github.com/rust-lang/rfcs/blob/master/text/0019-opt-in-builtin-traits.md), which I believe is now actually what we are doing :) You also need special rules around static globals (I believe that since they are required to be `Sync`, it has to be a language item, even though you can easily define it within Rust). You also need various intrinsics (fences, atomics, etc.) in order to make sure the compiler actually understands the memory model well enough not to ruin your carefully constructed memory safety through aggressive optimizations (as an example I thought of today: Rust sometimes passes structs as pointers, even if they are passed by value semantically; if the compiler didn't know about threads, what would happen if we send the struct to another thread, and the first thread disappeared?). And, of course, you need threads (or low level access to the hardware, but either way it's something external to Rust's type system).
It looks like it will block in the drop: https://github.com/rust-lang/rust/blob/master/src/libstd/thread/mod.rs#L713
That's true. One more reason I'm looking forward to the option to abort on panic :) (and hoping for nothrow).
While allocation is not strictly speaking lock-free, for small allocations like `channel()`'s jemalloc is overwhelmingly likely to use the thread local arena*, which is lock free unless a context switch (which is pretty infrequent on the time scales that jemalloc is operating in) happens at an inopportune time. Deallocation always has to grab a lock, though. \* It's not exactly thread local--there are (I think) two arenas pinned to each core.
I'm not `theiz`, but I wrote [this PR](https://github.com/carllerche/pool/pull/1) that I think handles this nicely.
Wrong subreddit, the game one is http://www.reddit.com/r/playrust. This subreddit is for the programming language called Rust.
Did you find a fix for this issue?
&gt; Nor am I passing `ownership of m` (no box ptr) to the function bleh. I am merely passing a copy of `m` to `bleh`. This is the problem you are having. A Box&lt;T&gt; is an *owned pointer,* but it is not the only kind of ownership. Everything has an owner, including your `m`. By default, function arguments pass ownership (or *move*) the binding being passed in, unless they pass it in as a referencce. The exception to this is for types which implement the trait `Copy`. These are passed by value, merely passing a copy rather than moving ownership. Only some types can implement `Copy`; fortunately the type in your code can implement copy and you can make it do so quite easily by adding `#[derive(Copy, Clone)]` above your enum declaration. Note that `Clone` is a trait which types that implement `Copy` must also implement. More on Box: A box is just an owned pointer to something heap allocated; normally you would box something because you need to pass ownership of it and it does not have a size known at compile time. More on Copy: Types which cannot be `Copy` are those which implement `Drop` (that is, they do something when they fall out of scope; usually deallocating heap allocated data) and those which have a mutable reference as a member, and possibly some other minor cases.
&gt; Are you referring to the common saying "concurrency is not parallelism"? Yes!
You would have to implement it manually still, because deriving would just still require the inner type to have it derived. Since most serialization formats only have a dynamic list for any number of values, I would just go with using a Vec&lt;&gt; in the structs which implement serialize/deserialize, then you can have some method which turns it into the actual type you need (checking for Vec lengths, then turning into fixed sized array) and back again.
&gt; More on Box: A box is just an owned pointer to something heap allocated; normally you would box something because you need to pass ownership of it and it does not have a size known at compile time. To elaborate slightly: `Box&lt;T&gt;` and plain `T` are essentially identical in terms of what you can do with them, as you say, the main point of the form is to have a guarantee about size (either one or two pointers). In particular, if `T` is not `Copy`, the ownership behaviour is the same. &gt; More on Copy: Types which cannot be Copy are those which implement Drop (that is, they do something when they fall out of scope; usually deallocating heap allocated data) and those which have a mutable reference as a member, and possibly some other minor cases. There's one more big class of types which cannot be `Copy`: those which contain other non-`Copy` ones. E.g. `struct Foo { x: String }` cannot ever be `Copy`, because `String` is not `Copy`.
About the specific piece of code and the possibles fixes: when you call `bleh(m)`, you are transefering the ownership of `m` to `bleh` (because `m` is not `Copy`), so you can't use `m` afterwards. The two possibles fixes are: * add the `#[derive(Copy, Clone)]`, so a copy will be performed when calling `bleh(m)` * Use a borrow in `bleh`, like so: `bleh(&amp;m)` (this also requires to change the signature of `bleh`, and the match) I'm fairly new to rust, so if my explanation is wrong, just tell me!
Wow! I read about General Game Playing earlier but could not find it, and didn't know there is a course for it! I'll join the course.
I've been meaning to do this for some time, I'm glad someone else championed it! I've been manually compiling it. Thank you!
Glad to be of help, thanks for the waffle offer, not needed :-) Of course slices are much nicer when we can use them. A boxed iterator ought to have some overhead in fact, but I'm happy that we could demonstrate some maybe lesser known but important rust knowledge. Most importantly of course the use of lifetime parameters.
I agree aswell, this read allowed me to improve my insight and understanding of Rust. The writing and incremental introduction of interesting challenges and solutions kept me reading without exertion.
I think the point was that ignoring or silently recovering from external errors or invalid input can cause confusion later when you reuse and call the function from a new context, and it either skips over or replaces invalid input. I think it's generally better to report such issues to the caller, and let them handle it. However, you're right that it can be perfectly reasonable to substitute a missing value for a default. And returning errors for the part of the input that was problematic while doing the expected action on the rest is tricky (e.g. reporting skipping files with non-utf8 names). Sometimes printing a warning for the user to see can suffice. Other times partitioning the unit provides the flexibility needed. In general libraries, where the use cases aren't fully known, swallowing errors is probably not the best idea, but in the case of OP's program, it's probably OK.
A match arm `if` condition also takes only booleans, as does the `&amp;&amp;` operator. Seems plenty clear here without `== true`.
You can use a different name. Be sure to put timer in the keywords. I don't know, free imagination is necessary (it's my favourite mitigation of lack of namespaces and it's more fun).
This very simply lets you run Rust in a Docker container. It doesn't address or intend to address the use cases for multirust.
The libraries that come with the Rust distribution are allowed to bypass feature staging -- if you look at the source code there are `#![feature(...)]` attributes in lib.rs for these, even though they're running on beta. There's some special casing in the rust build process so that these libraries can bypass feature staging (I don't know the details)
My bad Thank you 
Learning from standard libraries is generally a bad decision because they are often highly optimized and use compiler specific but not standardized/stabelized features.
You probably shouldn't use `usize` for a retry count, choose `u32` or `u64` instead.
On the contrary, the standard library is often recommended whenever someone wants to see quality Rust code in action. Many areas excellently exemplify how to wrap unsafe code that interacts with the system in a safe API. /u/Gankro has done a lot of really great work on the `collections` crate, including `Vec` if I'm not mistaken. Yes, there's a lot of highly tuned optimizations and yes, there is special casing because the stdlib needs features not in the beta. But there's still a lot of really high-quality code. Personally, at this point I still prefer nightly anyways, as most if not all features still gated should be stabilized by release.
This is an interesting read, and I really enjoy the way that it's written. Thanks!
I believe this link provides missing context: http://gstreamer.freedesktop.org/projects/outreach.html
I much prefer the idea of using a `Duration` instance rather than a naked integer (and hope it was expressed in the right unit). I've seen too much wreckage with naked integers.
Inspiring and informative article!
The channel may be dropped after the JoinGuard as the parent unwinds.
I published a rewrite of `TypedArena`: https://crates.io/crates/typed-arena It runs on beta/stable. It’s probably less efficient, but uses much less unsafe code internally. (It’s based on `Vec&lt;Vec&lt;T&gt;&gt;` where inner vectors never grow beyond their initial capacity, instead of raw pointers and manual drops.)
This would indeed be the case if concurrent **checkout** was permitted, but it is not. Checking out from the pool requires mutable access which will prevent concurrent checkout. Checking in does not suffer from the ABA problem. I debated supporting lock-free checkout as well (by using a monotonic counter to track ABA), but decided that it wasn't worth it for the time being. Multi threaded checkout can be done by wrapping the pool with a mutex.
&gt; Rust is now compared with C and not C++ Since January 11th. &gt; regex-dna is not proposed because the benchmarkgame maintainer doesn't want to use cargo and I didn't investigate manual installation. Actually I said -- "Tell me step-by-step what I need to do to install the regex library, and contribute a program that will work with it." As-in -- Tell me step-by-step how to use `cargo` to install what needs to be installed if that's what you want to use. 
It found [two](https://github.com/rust-lang/rust/issues/24276) [issues](https://github.com/rust-lang/rust/issues/24275) in libsyntax. Also I re-found some problems in [tendril](https://github.com/kmcallister/tendril) that I had located before with blind fuzzing. Adapting [the library's randomized tester](https://github.com/kmcallister/tendril/blob/master/examples/fuzz.rs) to afl was very straightforward: fn fuzz() { - let mut rng = rand::thread_rng(); + let mut rng = rand::read::ReadRng::new(io::stdin()); 
Shure, we are working on it :)
Ahh, awesome, I didn't even thank about that possibility. Thanks!
The way we're doing intersection, the `Vec` is actually a source of requests, rather than the thing we are going to hit into. We will iterate through it, stabbing into other `*Set` structures, or in this case just a sorted slice. We just need to `retain` the things that hit, and a simple `Vec` works great for that (and my serialization code works for `Vec` and not yet `*Set` things :)). The `filter` and `select` are ... legacy, I guess? I'm ex-Microsoft, and we used LINQ names like `Select` and `Where` when we did [DryadLINQ](http://research.microsoft.com/en-us/projects/dryadlinq/)/[Naiad](http://research.microsoft.com/en-us/projects/naiad/), but `where` is a Rust keyword, so I had to change that. I suspect I should really make everything Rust iterator idiomatic. These methods are from extension traits on `Stream` types, as part of the dataflow crate, which might not have been clear. Thanks for the read / comments!
I much prefer that idea too, but figured I would wait until Duration is stable.
Right! My bad.
Can you say a little about why? I still don't have a good grasp on when to use which size. When is usize appropriate? Should you always use the largest type unless you specifically want to eke out the best memory usage? Is there any performance implication for u32/u64 on 32 and 64 bit systems?
I'm on mobile right now, but when I get home I'll give you a better explanation. However it is mostly experimentation on my part to see what can be done with macros.
Isn't this possible with Rust? Can't find it in the real documentation that quick but here is an old version: http://smallcultfollowing.com/rust-int-variations/imem-umem/guide-plugin.html.
In general, you shouldn't do retries at fixed intervals, as that can exacerbate any load issues, lead to a thundering herd problem, or other similar issues; for example, if there's a server that drops a connection to 100 clients, and they all start trying to trying to reconnect at periodic intervals, they will likely all try connecting at the same time. If there's any kind of resource contention in the server or network (buffers being filled, lock contention, some kind of race condition, etc), then all of the clients trying to connect simultaneously can cause further failures. The standard way to avoid this is by using randomized exponential backoff. You start with a very short retry timeout; that way if there's just some very transient problem you will still succeed without too long of a delay. But if you fail, you pick your next timeout randomly from somewhere in the range of the initial timeout and twice the initial timeout; then the next time, pick a random timeout between twice the initial timeout and 4 times the initial timeout. Keep on doing this until you succeed, hit some maximum interval and just stay at that interval (with some randomization), or give up. The exponential backoff helps reduce load on the server, which can help it recover if excessive load is the problem, and also reduces the probability of two clients overlapping. The randomization coupled with the backoff means that if there is some kind of resource contention, it will become increasingly less likely that two tries from different clients will overlap in a way that triggers that problem.
I think having just an in memory version would be cool. I don't think LINQ over SQL is a useful abstraction (ORMS suck etc)
I don't know whether they're cheating (special case in the compiler) but https://github.com/rust-lang/regex is a functional compiler plugin for the regex! macro. A quick look turned up a feature attribute do yes, probably doesn't work on beta.
I assume people would sometimes use `Pool` with a type that is not `Reset` (e.g. for any type defined in an external library, as they would be unable to add an implementation for Reset themselves) and would simply use `checkout_raw` all the time, so it doesn't really look like a solution to me. If you were to use a circular buffer instead of a linked list you could switch to safe multithreaded checkouts and the `Pool` would be FIFO instead of LIFO :)
Great answer, thank you!
In Rust the owner is a stack. There can only be one owner at a time. struct MyType { /*omitted*/ } fn bleh(m2: MyType) { } fn main() { let m1 :MyType = /*omitted*/; bleh(m1); } Here ``m1`` is owned by the stack of ``main()``. But when you call ``bleh()``, the stack of ``bleh()`` becomes the owner. Even though ``m2`` is a byte copy of ``m1``, the ownership treats them as if a single entity is handed over to a new owner. This move is necessary to avoid certain memory and other problems. These problems happen when byte copy can not safely replicate an object. For example, let's say that MyType has a member that is a file descriptor. Then both ``m1`` and ``m2`` will have the exact same fd. If ``bleh()`` closes the fd then we will have serious problems if we try to continue to use ``m1``. Similar problems can happen if MyType has a field that points to heap allocated memory (``Vec`` is such as type). If MyType only has member fields that can be safely duplicated by byte copy then simply implement ``Copy``. In that case Rust will not move ownership to ``bleh()`` and you will be able to use ``m1`` after ``bleh()`` has returned. This is done, for example, with numeric types like ``i32``. They implement ``Copy``. fn bleh(m2: i32) { } fn main() { let m1 :i32 = 10; bleh(m1); bleh(m1); //Legal bleh(m1); } 
Excellent suggestion. I will look into this.
If hyper implements asynch http client, it will need a keep alive pool of open sockets. I wonder if this library can be used for that.
&gt;Multi threaded checkout can be done... I was going to ask you if the pool is thread safe. Does this answer mean that it's not?
If anything, it's a nice syntax.
Well, it's "thread safe" in that as long as you don't use any unsafe blocks, you are good. `Pool` is not `Sync`. This means that only a single thread can checkout values from the pool at a time. However, once you have a value, you can send it other threads just fine (as long as the value `: Send`. This is because checking values back into the pool, which happens automatically when the value handle goes out of scope, is perfectly concurrent (and lock free). It would be possible to implement lock-free checkout, but as /u/deficientDelimiter pointed out above, the implementation would be slightly tricky due to the ABA problem.
The implementation in Rust is definitely much simpler. It'd be interesting if Rust had operator overloading. As the older implementations of analog literals show, it can be a bit of a slippery slope. Perhaps when the compiler plugin API is stabilized a bit, it'll be easier (possible?) to write syntax extensions that don't take the form of a !-style macro.
Oh awesome, thanks for the crate! Does it have the problem with access after drop in destructors?
It won't work. You can try it out by replacing isize with a new struct type. You can't move a value out of a borrowed pointer, which is what you'd be trying to do if the value didn't implement `Copy`.
Ohh, sorry, it seems I've misunderstood the title and put too much accent to "easily build with beta". I'd expect something like "Docker image for a Rust builder (based on 1.0-beta)", but ok, I've got it.
You couldn't move it out, because Rust isn't advanced enough for that, but you could clone it if it supports that, or somehow otherwise make a duplicate.
I think it'd be safe just to find all rust/cargo files in /usr/local, and delete them manually. The commands `find /usr/local/ -name '*rust*' -exec rm -r {}\;` `find /usr/local/ -name '*rust*' -exec rm -r {} \;` should do the trick. Not the prettiest, but it will get rid of anything that's made by rust. Probably want to run those commands without the rm -r first just to see what would be deleted, but it should work correctly. -- Alternatively, you could try to find the nightly that you had installed, and download it, then run the script from the tarball manually with `--uninstall`. 
If it takes 5s to generate Rust code, how long does that take to compile? I've had 1000 LOC crates that took over 10s to compile ...
Ah good point! Actually, it is most probably the case since you have to create the channel before you spawn.
Are you referring to this warning in the `arena::TypedArena` documentation? &gt; Safety note: Modifying objects in the arena that have already had their `drop` destructors run can cause leaks, because the destructor will not run again for these objects. I think it would have had, but that’s been solved by [a language change](https://github.com/rust-lang/rfcs/blob/master/text/0769-sound-generic-drop.md). The warning [has been removed](https://github.com/rust-lang/rust/pull/24282).
&gt; It'd be interesting if Rust had operator overloading [It does](http://doc.rust-lang.org/nightly/std/ops/). :)
Still loads for me. It's only a crate of crustaceans, anyway. :p
A question from u/Phlosioneer: &gt; Doesn't Rust fix this problem? I thought as well that Rust would solve the issue, but u/cwzwarich says it is unproven. I was wondering if [the Patina paper](http://www.reddit.com/r/rust/comments/31kq70/patina_a_formalization_of_the_rust_programming/) had proven it, or at least made advances toward proving it.
I noticed when running the command that the libraries have a hexidecimal checksum at the end (e.g. /usr/local/lib/librustc-4e7c5e5c.dylib). There are other libraries not caught in the expression, that also have that "checksum" (e.g. /usr/local/lib/libfmt_macros-4e7c5e5c.dylib), would they be candidates for removal also?
look for /usr/local/lib/rustlib/uninstall.sh
To be honest, after seeing the macro definition I'm linking this to everyone I can... it's silly, sure, but it's also an example of how much nicer a proper macro language can make writing DSLs.
&gt; My understanding from googling around is that these will be made compiler-internal soon, hence the "Rustc" prefix. This is not strictly true: we have an internal version, but there's also the external one posted to Crates.io. We used the prefix because it, as a library, is super tied to Rustc internals and isn't awesome enough to grab the 'serialize' namespace. Serde is the next-gen framework, but as you've seen, isn't awlays 100% there. erickt has been doing tons of great work on it, though.
https://github.com/DanielKeep/rust-scan used to work... but it looks like it would need updating to the latest nightlies, and probably wouldn't work in the beta since it relies on a syntax extension. https://github.com/mahkoh/scan might work in the beta, if updated.
Doof. I meant 'arbitrary user-defined operators'. I think the current handling of operator overloading is a great compromise between flexibility and maintaining simplicity of the language.
/u/burntsushi has an awesome library called [xsv](https://github.com/BurntSushi/xsv) which is just for CSV but i'm sure has some excellent parsing routines as well, might give some ideas.
In my defense, analog literals are a pretty *crappy* idea.
Could you give a quick description of the problem you're trying to solve? Something like, "I'm trying to read 5 integers per line separated by whitespace and determine their GCD." That will help with more targeted advice.
Thanks. :-) So just to be clear, `xsv` is a command line tool for processing CSV files. There is a lot of input parsing, but it might not be directly useful to the OP. Mostly because the nitty gritty details of converting strings to other data types (like numbers) is handled by Rust's serialization library. (This applies to both CSV parsing and parsing `argv` with Docopt.)
I basically stopped updating `rust-scan` when it became clear that it'd never be compatible with stable. I have a stable-compatible prototype that's far more restricted (basically just linear, forward matching), but I don't really have time to flesh it out.
omg yes im so sorry :( 
This is my take on your code: https://gist.github.com/5d11942114dc0dcb3f8b Here's another take without regexes: https://gist.github.com/688e69cfe75282322bdb --- Notably, this contains no uses of `unwrap()` sans writing to stderr. (This also fixes a bug where unexpected EOF wasn't handled correctly.) Here are my notes: * Proper error handling. It can be very tempting to write `unwrap` everywhere, but Rust's `try!` macro and `From` conversion trait make it almost as easy to Do The Right Thing. The trick is that, by convention, error types implement the `std::error::Error` trait, which means they are trivially convertible to `Box&lt;Error&gt;`. As a convenience, there is a `From&lt;String&gt; for Box&lt;Error + Send&gt;` impl so that you can just write plain strings and have them treated as errors. (Actually, that impl is not in the beta! So I relied on a similar impl, `From&lt;str&gt; for Box&lt;Error + Send&gt;`.) * Using a regex simplifies a bit because you can lean on the correctness of the regex to elide some error handling. Namely, that if the regex matches, then the `shy` and `digits` capture groups will refer to a sequence of digits. When I removed the regexes, I needed to do more explicit error handling, which prompted me to introduce `strerr!` because it was annoying to write `Err(From::from(&amp;*format!("...", ...)))`. (Note that in the nightly, and hopefully in 1.0, you'll be able to write `Err(From::from(format("...", ...)))`.) * Your code squirms *a lot* with the digit handling. I think this is probably because of an unknown unknown. If you had known about the [`char::to_digit`](http://doc.rust-lang.org/nightly/std/primitive.char.html#method.to_digit) method, then you probably would have ended up with similar code as me. (The other trick is to iterate over the string with the `chars()` iterator.) * Reading one line at a time using `BufRead` is inconvenient, so I put that into a helper function. (Actually, it might be better to use the `lines()` iterator on `BufRead`, but I found this way to be palatable.) * Calling `collect()` on an iterator makes it a bit easier to handle. This is somewhat of a convenience trade off, because it won't scale to arbitrarily large data. But it makes handling the error case much more explicit. * I couldn't tell from your code what `max_shyness` is, so it is unused. It looks unused in your code too. Better code would probably completely separate the parsing from your logic. I considered doing that, but I thought a smaller diff would be more useful to you.
I re-wrote my example [here][1]. You can generally say 'all other possibilities' with an underscore. [1]: https://play.rust-lang.org/?code=fn%20main%28%29%20{%0A%20%20%20%20let%20tuple%20%3D%20%28true%2C%2019%29%3B%0A%20%20%20%20println!%28%22{}%22%2C%20match%20tuple%20{%0A%20%20%20%20%20%20%20%20%28true%2C%2020%20...%2026%29%20%3D%3E%20%22true%20and%20in%20the%20inclusive%20range%20[20%2C%2026]%22%2C%0A%20%20%20%20%20%20%20%20%28true%2C%20_%29%20%3D%3E%20%22true%20and%20not%20in%20the%20inclusive%20range%20[20%2C%2026]%22%2C%0A%20%20%20%20%20%20%20%20_%20%3D%3E%20%22dunno%22%0A%20%20%20%20}%29%3B%0A}&amp;version=beta
Yeah, I was thinking about that too. A few more implementations of `Encoder` and `Decoder` would go a long way... people are dissuaded from writing their own for simple stuff due to its intimidatingly large API (e.g. many encoding formats people use couldn't handle variants).
oh! of course, it will fall through from the first branch! Thank you. I fell into the trap of thinking I needed to be overly specific with the branches!
A data race with borrowed or owning references requires them to be aliased, which is already considered as undefined behaviour in Rust. Data races involving raw pointers are undefined behaviour, but idiomatic Rust code does not use them in dangerous ways. Rust's volatile is heavier than Java's, and violations of sequential consistency are opt-in.
Most people seem to be making entity component systems. There are several introductions to these, and the Rust version isn't much different from the C++ one. Basically you have Entities that are just unique IDs, and containers of homogeneous components which may have component values that correspond to a specific entity. So for your example, you'd have no type hierarchy, but instead just one component type for whatever stuff a Camera needs, one component for whatever stuff an Emitter needs, one for Animals in general, and then if a Bird or a Snake needs special stuff on top of that, you give them a new component. You run into the same downcasting problem if you want to create a type hierarchy for components in the same container, but modern game architecture wisdom is to have flat memory homogeneous plain-old-data component containers anyway for cache friendliness. I've [written up](http://rsaarelm.github.io/Roguelike-architecture-in-Rust-3/) about my own implementation.
dropck is only interesting with RefCell, through.
Even aside from the various `Cell` types, I don't know if that's true, since I think Rust doesn't currently guarantee any particular drop order within a block (which was the bug that originally motivated it IIRC). Though I suppose that's now tracked (?), so maybe you're right.
Incidentally, changing the last line of example3() to let z : usize = 21; z produces this error (in playpen): error: internal compiler error: trans_local_var: no datum for local/arg 77 found note: the compiler unexpectedly panicked. this is a bug. note: we would appreciate a bug report: https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md#bug-reports note: run with `RUST_BACKTRACE=1` for a backtrace thread 'rustc' panicked at 'Box&lt;Any&gt;', /home/rustbuild/src/rust-buildbot/slave/beta-dist-rustc-linux/build/src/libsyntax/diagnostic.rs:190 playpen: application terminated with error code 101 
&gt; A data race with borrowed or owning references requires them to be aliased, which is already considered as undefined behaviour in Rust. This doesn't quite work, as `&amp;` references may alias (in particular, `&amp;UnsafeCell&lt;T&gt;` may mutably alias). It's up to unsafe code to enforce that this cannot cause memory unsafety or data races (though I suppose you could argue that the only way to mutate an `UnsafeCell` is through a raw pointer, though that too isn't *technically* true because Rust exposes the field).
Interesting ideas... I am not sure how much efficiency you'll gain in practice with your proposed `ARefCell&lt;T&gt;` over a simple `Mutex&lt;T&gt;` though (at least on Linux, mutexes have a really fast fast path when not contended, and you'd still need acquire / release semantics which are a big part of the cost of locks), and I think you would have to change the implementation so that the reference count and the write bit fit within a single word as well (and you'd want a poison bit, too). Not that `Mutex&lt;T&gt;` is quite the same since it doesn't allow multiple readers at once, but with scoped threads or `Mutex&lt;Arc&lt;T&gt;&gt;` you can often emulate it by just grabbing the lock before you start your read sections. And yeah, atomics are the thread-safe equivalent of `Cell`s. Now that we have unsafe traits, an `Atomic` trait might be feasible; it would also be possible to create an `Atomic&lt;T&gt;` struct and have LLVM fail at link time if it couldn't actually generate an atomic version of the type, but I think some people were uncomfortable with that idea.
 &gt; I think you would have to change the implementation so that the reference count and the write bit fit within a single word Well, the `Arc` has weak pointer support and thus two atomic variables inside, so it's probably doable even with two atomic variables, but I agree, it's probably simpler to reserve one bit for write and one bit for poison, and there'll be 30 or 62 bits left to count readers. There's also memory usage (and perhaps kernel resources?) to consider if you have many many of these. I'd assume that both a `Mutex` and an `RWLock` would consume more of that than a single `AtomicUsize`, but I don't know how much. &gt; Not that Mutex&lt;T&gt; is quite the same since it doesn't allow multiple readers at once, but with scoped threads or Mutex&lt;Arc&lt;T&gt;&gt; you can often emulate it by just grabbing the lock before you start your read sections. Sorry, not following. I'm not sure if `Mutex&lt;Arc&lt;T&gt;&gt;` is a typo and you meant the more common `Arc&lt;Mutex&lt;T&gt;&gt;`, or if it's actually some smart way to be able to access `T` without keeping the mutex locked?
To be completely honest, and I'm fully aware this is shallow and will admit as much: It's design is plain ugly to me. Syntax, keywords, operators, it's just nasty. I *really* love the idea of rust, I am just more a fan of traditional language design ala C/++, Java, C\# and friends. Then again, I took the time to learn Python despite me also hating it at first. I hope to be able to use rust for something in the future, if I can find the time.
I've just submitted a bug report with a simplified version: https://github.com/rust-lang/rust/issues/24353
Thanks for your detailed response.
Oh, right - I think that would also be safe to remove with the same checksum, yes. I had forgotten about those files, those are also created by rust.
Not hard at all, I don't think: #![feature(simd)] #[allow(non_camel_case_types)] #[derive(Debug)] #[simd] struct f64x4(f64,f64,f64,f64); fn main() { let a = f64x4(0.0, 0.0, 0.0, 0.0); let b = f64x4(1.0, 2.0, 3.0, 4.0); let c = a + b; println!("{:?}",c); } [Playpen link.](http://is.gd/t1kgmZ) I'm not sure if that translates to anything useful, though. Edit: It looks like this isn't quite the ticket. In the playpen, at least, it's executed using two `addpd` instructions.
I am on the nightlies, I was just curious about whether this existed, and maybe bring it to someone's attention.
Am I the only one who gets confused for a tick when I see "vector" used in this context? #PhysicsMajorProblems
&gt; Well, the Arc has weak pointer support and thus two atomic variables inside, so it's probably doable even with two atomic variables It doesn't need to set more than one of them atomically at a time; the weak pointer only has to check the strong pointer count, and once the strong pointer goes to zero it can never be incremented again. Pretty confident you couldn't do the same here. But maybe you could get around it with some cleverness. Resources are definitely a potential issue. If those are really a concern, and you're confident that your application won't screw up, it's always possible to do a spinlock in a `u8`, though :) &gt; Sorry, not following. I'm not sure if Mutex&lt;Arc&lt;T&gt;&gt; is a typo and you meant the more common Arc&lt;Mutex&lt;T&gt;&gt;, or if it's actually some smart way to be able to access T without keeping the mutex locked? I actually did mean `Mutex&lt;Arc&lt;T&gt;&gt;`, reasoning that you could either use `make_unique` on the acquired mutex, or start sharing it. But because `Arc` clones can outlast the `Mutex`, it wouldn't really guarantee anything useful (though it would if you borrowed the inner value as `&amp;T` for plain `Mutex&lt;T&gt;`). Maybe you can just use `Arc` with `make_unique` as a poor man's `ACell`?
It's a very common name for a "dynamic amortized-reallocation array" datastructure due to C++. I don't like it either.
"An express.js inspired web framework". I think authors should aspire to explain their packages in their own words in addition to referencing their inspiration. I have no idea what express.js is our why I would want it in rust.
&gt;I am stuck with C++ for some more time, but I am curious how to simulate Rust's behavior with C++11 move semantics and unique_ptrs. I know that there are a lot of similarities, but how do I exactly borrow a value, make a read_only reference and other Rust specific things with these instruments? C++ had the idea of strong ownership rules before Rust. Rust encoded them in the type system. 
This isn't really C++ specific, but just by writing lots of Rust code you start to recognize the mistakes the compiler will catch before they happen. I think that knowledge can influence your code in other languages for the better.
I think the authors target people coming from other platforms and it is common to do that as projects do with for example Sinatra from ruby. It is a short and nice way to announce what you are offering. But yes, you are right. they can't forget people who don't know express, even if it is a well known framework for node.js
[You are (mostly) free to use the logo.](https://github.com/rust-lang/rust/issues/11562#issuecomment-50833809) [1] [1] As explained in the comment, however, the logo can be trademarked and you'd rather avoid too excessive modification to the logo.
It seems like a totally reasonable thing for a best-effort compiler lint, but not necessarily something for which there should be a hard error at the language level. (I filed [rfcs#1060](https://github.com/rust-lang/rfcs/issues/1060).) In any case, cases caught by an lint/error like that will involve compile time constants and so the optimiser will remove the checks.
Great!
I think there is nothing stopping us doing this in the future - I would argue that if an error is guaranteed to happen at runtime, then making it a compile-time error is not breaking backwards compatibility. I would hesitate to implement a hackey fix for the easiest case here, better to wait and implement a proper fix (which handles all constant expressions) when someone has the time.
I would like to give a resounding yes! I give some further reasoning why I feel rust is a good first choice for learning systems programming [here](https://www.quora.com/What-do-C-C++-systems-programmers-think-of-Rust). Here are the relevant parts if you don't want to click through to quora: &gt; I've found that Rust has forced me to learn many of the things that I was slowly learning as "good practise" in C/C++ before I could even compile my code. Rather than learning by trying to solve segfaults, debugging my pointer messes, etc, Rust tells me at compile time why what I'm trying to do is probably not a wise choice. &gt; At first I found that this felt quite restrictive and awkward, however 95% of the time I end up discovering that the compiler is completely right and has just prevented me from unknowingly whipping up a meal of pointer/thread spaghetti. It took me at least a good couple of very humbling months before I was able to clearly wrap my head around the borrow-checker. These days I find I very rarely hit compiler errors that I can't solve almost immediately. I also feel much more confident in managing memory and concurrency when I go back to C/C++ thanks to all my hard-learned one-on-one lessons with rustc. As for audio related work, this has been where I've spent 90% of my time with rust. I've found it to be a dream to work with, at least compared to my experience with C and C++ audio work. It is certainly possible to build highly performant, real-time, complex systems like DAWs in rust. If you're interested, check out the [RustAudio Github Organisation](https://github.com/RustAudio), so far it features [simple audio i/o](https://github.com/RustAudio/sound_stream), a [dsp graph](https://github.com/RustAudio/dsp-chain), a [polyphonic synth](https://github.com/RustAudio/synth), [pitch](https://github.com/RustAudio/pitch_calc) and [time](https://github.com/RustAudio/time_calc) calculators and a bunch of other stuff. tomaka is even working on a cross-platform audio backend ([CPAL](https://github.com/tomaka/cpal)) which may some day make a nice, purely-rust alternative to PortAudio (at the moment however it still has a long way to go). I'm really excited to see the rusty audio community grow, feel free to drop by with suggestions, issues, PRs, etc and I'll add you to the group! PS: I hope to one day kick off a free, open source DAW under the RustAudio umbrella - not only would it be awesome to have an open, collaborative, rusty DAW, but it'd be a great place to consolidate and test all the other RustAudio repos in one place too.
Rust is more of a departure from the traditionally understood pointer. You would only use them in unsafe code. Which is not where you would want to start when learning Rust. In fact you're encouraged to avoid it as much as you can. Rust's system is ownership and lifetimes. You explicitly handle the pointers, and the compiler just makes sure you don't leave the house without tying your shoes. Smart pointers are much more akin to what Java does. I'd say learn C. When you hear about pointers it's referring to that style of programming. Which is what Linux would be implemented it. C is a small language, there aren't as many "flavors" of programming as in C++. I'd say start with C. C is very minimal. You don't even have string types. You have to implement all of that yourself. This will give you the best taste for pointers and how things are handled at nearly the lowest level. I say nearly because once C was considered a high level language. Since it abstracted assembly. Anymore C is considered low level. Plus learning C/C++ will probably prime you for Rust. I wouldn't recommend anyone start with Rust. At least not at this time. 
ok I took a data structures course in c, so, although I am a beginnner in C, I would consider myself a false beginner.
Rust really needs some agreement on how to handle smart pointers. I’m afraid to read what I read in the changelog all over the place. There is no reason to why `Box`, `Rc`, `Arc` etc. each need special treatment. If somebody were to create custom smart pointers these are almost doomed to be less useful then the build-in ones (even the prospective Gc will have hard times…). No library will support them explicitly and consumers will not be able to implement third-party traits for them.
I know the basics of Pointers so I think I am ready for Rust. We had to implement all the str functions with pointers, and implement bloom filters and stuff using pointers, but I still consider myself very 'green'
Pointers are pointers. If you did all that, then I think you "get" them. Just it's a whole nother thing to then start implementing them and keep track of what all is happening. That is where the segfaults beings. If you still want more practice implement sorting algorithms. Mergesort is good practice with mallocing arrays, and heap sort is good practice with linked binary trees. Both help you think about passing pointers as arguments into recursive functions.
I found it interesting that, on the topic of dependency management neither of them referenced either Maven Central, or the grand-daddy of all: Perl CPAN. Both of which preceeded npn/ruby-gems by a long shot.
HKT is usually described as the solution for APIs that receive generic smart pointers.. but I don't think this solves the problem of trait instances. Now, [this code](https://github.com/erickt/rust-serde/blob/master/src/de/impls.rs#L661) is mostly the same for any smart pointer. Perhaps there should be a trait `SmartPointer` that `Box`, etc. implements, and then have any type that implements `SmartPointer` also implement `Deserialize`?
I think HKT are absolutely not needed to solve this problem. Rust already has the expressiveness to provide a solution it just has to be formalized. Something like this trait Box&lt;T: ?Sized&gt;: Borrow&lt;T&gt; { fn wrap(value: T) -&gt; Self; fn unwrap(self) -&gt; T; } would probably do it (though I haven't thought about overloading the box operator yet).
That actually makes sense, thanks! This question is about C++ libraries really, because I know, that I can borrow a value from unique_ptr by making a const reference to its value, for example, but is there a better way?
Well references are officially a subset of "pointers" by reference vernacular: https://doc.rust-lang.org/reference.html#pointer-types And they're really the kind of thing you'd call a pointer in e.g. C++, in that you can deref them and re-assign the address as you please. The compiler (and autoderef) just handles a lot of the mess for you.
No. having lifetimes in the type system is exclusive to rust. In C++ you need to know how long the objects live and check mentally if it is safe. Clang has a good static and dynamic analyzer wich can detect some bugs.
Oh cool, always good to hear people on podcasts, the conversations tend to go into areas I never really think about personally. Also, this reminds me: It was [suggested](https://www.reddit.com/r/programming/comments/2ipdpa/floss_weekly_311_the_d_language/cl6pggy?context=3) , by /u/RandalSchwartz, in the /r/programming thread about FLOSS weekly's D podcast that I ask people to contact him about being on an episode. I reckon it would be good publicity with 1.0 coming up.
C++11 move semantics is different from Rust move semantics. When you move value out of variable in Rust this variable becomes non-existent and cannot be referenced anymore and its destructor won't be called. In C++ this is not the case and destructor will still be called.
Thanks, I learned a lot, somehow the fat pointers and implicit coercion wasn't clear to me from the book :)
Probably the second podcast i ever heard.. Does someone have other recommendations for technical podcasts? All i seem to find is podcasts by apple hipsters discussing the new i{Watch, Pad, Book, Thing}
Strcat was in fact a vocal champion for switch in from a one-pointer ~[] to current vec of three words that allows zero allocation for the empty case. I like it.
Well, I'm former physics student too, but I never had this problem for some reason. At the same time I found "vector" confusing in context of SIMD, for example array and vector types in LLVM. According to wikipedia, "vector" is quite a popular term and has a lot of strange domain specific meanings.
Although to be fair, unique_ptr will take care of that. 
`Option::take` in Rust is very similar to C++ move semantics and is quite helpful when that semantics is actually needed.
To expand on this: C++ doesn't really have actual "move semantics" like Rust does. What it has is more like automatically-inserted `swap()` invocations together with every type that has a nontrivial move constructor (~ every type which allocates) being an `Option`. So-called rvalue `&amp;&amp;` references most closely [correspond](http://www.reddit.com/r/rust/comments/2oes6s/cs_rvalue_references_correspond_to_rusts_mut/) to Rust's `&amp;mut`.
hmm, true, I guess I forget that you can catch panics. It still seems like a real edge case of backcompat though - more sticking to the letter than the spirit. I guess we can always just warn.
I would have liked something like "DynArr" more.
Software engineering radio is good, git minutes, Haskell cast, illegal argument (my own), Hansel minutes, javascript jabber, will post actual links when in the morning for others. 
Is this something like the abandoned lightweight threads?
The Hello World tutorial is throwing errors for me. http://stackoverflow.com/questions/29606202/rust-nickel-hello-world-tutorial-throwing-dependency-error-when-run
I don't know much about your level... but assuming you're on windows and don't know what a CLI is, you should : * in "execute" search for `cmd` * type `cd DIRECTORY` to go to the source folder of your game hack * and then do `cargo build` Oh also, cargo and rustc needs to be in your PATH (but my knowledge of windows stops here).
I work on the nickel team. I'm sorry you had such a bad first experience. The examples are out of date and I'm trying to get that fixed soon. However, the problem that you ran into seems to be a real bug in either hyper or rust itself I think. I created an issue to track it: https://github.com/nickel-org/nickel.rs/issues/185
More like Stackless Python's schedule()
i'd recommend not doing this even in a language that supports it. Inheritance is just a shitty way to write code these days.
Sure, but the parent said in C++ the destructor will still be called, which unique_ptr takes care of for you.
This kind of sucks and you were really unlucky as it must look bad. Until it's fixed I would recommend experimenting with nickel.rs on Linux until it's fixed upstream; just load up Ubuntu on VirtualBox. Have fun!
As a temporary workaround one can also just use `cargo build --release` to prevent the checks altogether.
Yeah sorry, was just commenting that there are safety differences, and it won't save you from all your problems, I should have been more clear that I was meaning something related.
http://doc.rust-lang.org/0.11.0/green/ &gt; This library provides M:N threading for rust programs. Internally this has the implementation of a green scheduler along with context switching and a stack-allocation strategy. &gt; Each green thread is cooperatively scheduled with other green threads. Primarily, this means that there is no pre-emption of a green thread. The major consequence of this design is that a green thread stuck in an infinite loop will prevent all other green threads from running on that particular scheduler. This library (coroutine-rs) seems to have exactly the same approach.
Huh. I didn't realise his last name was "Stanford". &amp;nbsp; ^^^^^^^:P
[Pointers and Memory](http://cslibrary.stanford.edu/102/) &gt; Stanford CS Education Library: a 31 page introduction to programming with pointers and memory in C, C++ and other languages. Explains how pointers and memory work and how to use them -- from the basic concepts through all the major programming techniques. Can be used as an introduction to pointers for someone with basic programming experience or as a quick review. Many advanced programming and debugging problems only make sense with a solid understanding of pointers and memory -- this document tries to provide that understanding. &gt; Topics include: pointers, local memory, allocation, deallocation, dereference operations, pointer assignment, deep vs. shallow copies, the ampersand operator (&amp;), bad pointers, the NULL pointer, value parameters, reference parameters, pointer to pointers, dynamic heap memory, memory ownership models, and memory leaks. The article focuses on pointers and memory in compiled languages like C and C++ with occasional notes about Java. 
I don't really see how Rust shields you from learning about pointers, or "how they really work". It shields you from *fucking it up*, but how does it shield you from the concept itself? You still have to know about how memory management works if you want to use owned and borrowed pointers. Maybe it's like Haskell; Haskell doesn't lull you into believing that effects like IO does not exist. It makes you *very* aware of it, and *forces you to be explicit about it*.
&gt; RustAudio Github Organisation Why did I not know about this before? I've been trying to find a compelling project to get into Rust, and this is exactly up my alley of interest. Time to dig in! :D
This is the second time I've seen something Rust-related from that board and neither has been very useful or constructive.
I would say "Aaron Turon's Rust talk at Standford" to properly identify the place and the person. It is "Turon's" because it is possessive. I'm assuming English is not your first language? You're still fine, at least we get the meaning :)
I wasn't saying it shields you, but I am saying Rust's references are a subset of pointers. It's handled through the type system and enforced by the compiler. So you're getting something different in C than what you get in Rust. Which is the whole point of Rust. I think it's important to make mistakes and C allows you to make them. There are invaluable lessons to be learned from C. It's not so much you have to start there, but your better for having touched both flavors. It just makes sense to start with C then eventually transition to Rust. Plus the skill to read C code will be indispensable when you land a job porting over old systems code to Rust :)
To add to this, right now the advice I would give is to use the Rust logo and name as you see fit for noncommercial use, but for commercial use please reach out to somebody on the core team to discuss. Trademark policy around the Rust name and logo is yet unsettled, but I'd suggest [the Python trademark policy](https://www.python.org/psf/trademarks/) as good background for the direction we might go in. 
Cool, well, it reads great, I swear! Of course there are little glitches, but just keep writing it, it will get more natural. And never hesitate to put a "did i word that correctly?" (although maybe not in the title) Anyways, thanks for the link! Just got home, and am watching it now :)
This is an awesome talk/concept btw
Really enjoyed the talk, and I think it used the same animations as Niko did from a talk a while ago (or was that Aaron too...?) I too think a quick slide showing the different prototypes of `spawn` and `join` would have been helpful, but I think they got it in the end. They looked interested and hope to have some more people in Rust from Stanford :)
Node.js is a server side environment for JavaScript. It has a couple built-in modules that you could claim are framework-like such as `http`, but they are entirely ignorable.
&gt; First learn the basics in C and then switch to Rust to see why what all you did was dangerous and mostly wrong. (Otherwise you wouldn't really appreciate Rust). ;) It feels like my interest in PL (Design) is enough for me to be able to appreciate problems that things like manual memory management have. I barely know how to write C, but I feel like I'm able to understand the problems that I keep reading about that are associated with C/++.
Nice work. Now if there was a good UI library I could start porting our applications to Rust ;) Btw. is there a way I can "follow" an organization on GitHub? 
That's interesting, how does Go accomplish preemption? Does it also work in a situation like infinite loop? I thought it was only possible by a help of OS. Or, does it insert a tick checking code after every line it executes?
I can't find the link right now, but one of the Go maintainers gave a talk about this. Basically there is a certain set of prescribed locations a premeption can happen. The ones I remember are syscalls, any go concurrency primitive (go statement, select statement, chan send or receive), most function calls too. Actually did find this stack overflow answer that's relatively comprehensive: http://stackoverflow.com/a/12413618/207868
So first I rewrote your main.rs because there was three things I was worried about: * You did not use lhs at all so the compiler might optimize out the whole computation * You tried to measure addition per addition, but those are reaaaally fast so the majority of the time will be spent doing the get_time() function call and whole kernel talky talky stuff. * You have to use more than a million iterations if you want to make the time spent in the runtim negligible. So here's my modified benchmark code: https://gist.github.com/haxelion/abeab65d96b20e397af3 Now the result: % ./target/release/simd_test Simd : Quat { x: 1211460476.587159, y: 1069237352.663881, z: 519923948.696337, w: 0 } Func : Quat { x: 1211460476.587159, y: 1069237352.663881, z: 519923948.696337, w: 0 } Time for 'simd': 1.530266 Time for func: 1.492152 Diff -0.038114 Sooo the question remains. What does it means? IT'S REVERSE TIME! (Sorry this kind of stuff excite me) Here's the SIMD loop: http://i.imgur.com/5wI02OV.png Here's the Func loop: http://i.imgur.com/CPxRRSB.png If you can't read assembly here's the takeaway: they both use SIMD. However, the one with the function call is more complex but is sligthly faster. Why? I don't know ... there is a involved in processor execution latency. If you want Intel has a 642 pages long manual on that. But you need to really want it. So you see that simd is already used by the compiler anyway and that your simd attribute works as expected ;)
So, just declaring the simd attribute makes it run properly? That's great! Glad I don't have to worry about using the right operations, or telling it how it's supposed to put the values in memory. Thanks!
I hate to be _that_ guy but this is not a great way to write SIMD code. See slide 34, it discusses why this approach gives lack luster results: http://www.gdcvault.com/play/1022249/SIMD-at-Insomniac-Games-How The TL;DR of that talk is that if you are using SIMD you need to be thinking of your SIMD as doing work across multiple Quat's rather then using a SIMD vector to represent a single Quat. Plus, as /u/haxelion pointed out the LLVM is _really_ good at finding obvious SIMD operations and using them. 
Modern C++ tends to gravitate toward `unique_ptr` and RAII, so it's not that much of a jump. You just need to be careful, since there's no borrow checker to watch your back.
This, so much this. Other big warning sign is that it's using an f64... That's not a good idea for getting good SIMD performance (you can only do half as many operations!).
I wanted to use f64 for better numerical stability. Guess it's not really worth it?
Read the whole powerpoint presentation, it was a pretty interesting read (Though C++ SSE code is gross xP). So, what you're suggesting I do for best performance is to keep lists of Quaternions' member fields stored in a central data structure, and then have things store a reference into the lists? (Like, A has quaternion 1, and every list's 1 index refers to part of the same quaternion)
This talk also notes a important implementation detail about interoperation between coroutines and thread-local storages. There were similar concerns when [a coroutine proposal was brought to C++ standardization committee](https://groups.google.com/a/isocpp.org/forum/#!msg/std-proposals/3g6ZIWedGJ8/5c2wrWd8gbEJ). Although the situation in Rust is much better since object migration between threads is prohibited by default, I would like to use coroutines to multi-threaded/work-stealing job scheduling scenario.
It really isn't. If you need to support huge scenes you really want some offsetting scheme anyway. EDIT: note that you almost certainly aren't going to need this! You won't see the difference until you're in the thousands of units (are your scenes really multiple kilometers large?).
Note: you appear to be referring to the values returned by `GetLastError`, which is for *system call errors*, not process result. Insofar as I know, the exit status for a process has *broadly* the same meaning on Windows (*i.e.* 0 = success, anything else = oh no the drapes are on fire). Anyway, there are enough blindly ported \*nix programs on Windows that, even if the convention *was* different, the distinction would by now be completely useless.
This is really amazing and I want new contributors to be able to find it.
Happy to have it hosted somewhere more official and/or link to it from the website or what have you